quality_attribute,sentence,source,author,repo,version,id,keyword,matched_word,match_idx,wiki,url,total_similar,target_keywords,target_matched_words
Security,"557000 1924140.1; 01:10:44.052 INFO ProgressMeter - 5:18554429 10.9 20887000 1924971.5; 01:10:54.053 INFO ProgressMeter - 5:23247594 11.0 21241000 1927979.5; 01:11:04.057 INFO ProgressMeter - 5:25901452 11.2 21588000 1930263.3; 01:11:14.089 INFO ProgressMeter - 5:32482380 11.4 21916000 1930729.5; 01:11:24.106 INFO ProgressMeter - 5:38674297 11.5 22249000 1931652.6; 01:11:34.133 INFO ProgressMeter - 5:49679881 11.7 22573000 1931754.3; 01:11:44.145 INFO ProgressMeter - 5:53234595 11.9 22925000 1934259.1; 04:10:15.659 INFO ProgressMeter - 6:1726401 190.4 23183000 121774.0; 04:10:25.671 INFO ProgressMeter - 6:10206926 190.5 23517000 123420.2; 04:10:31.341 INFO BaseRecalibrator - Shutting down engine; [February 22, 2021 at 4:10:31 AM PST] org.broadinstitute.hellbender.tools.walkers.bqsr.BaseRecalibrator done. Elapsed time: 190.65 minutes.; Runtime.totalMemory()=1268776960; java.lang.IllegalStateException: cigar is completely soft-clipped; at org.broadinstitute.hellbender.utils.Utils.validate(Utils.java:814); at org.broadinstitute.hellbender.utils.read.CigarBuilder.make(CigarBuilder.java:129); at org.broadinstitute.hellbender.utils.read.CigarBuilder.make(CigarBuilder.java:143); at org.broadinstitute.hellbender.utils.recalibration.BaseRecalibrationEngine.consolidateCigar(BaseRecalibrationEngine.java:293); at org.broadinstitute.hellbender.transformers.ReadTransformer.lambda$andThen$f85d1091$1(ReadTransformer.java:20); at org.broadinstitute.hellbender.transformers.ReadTransformer.lambda$andThen$f85d1091$1(ReadTransformer.java:20); at org.broadinstitute.hellbender.transformers.ReadTransformer.lambda$andThen$f85d1091$1(ReadTransformer.java:20); at org.broadinstitute.hellbender.transformers.ReadTransformer.lambda$andThen$f85d1091$1(ReadTransformer.java:20); at org.broadinstitute.hellbender.utils.recalibration.BaseRecalibrationEngine.processRead(BaseRecalibrationEngine.java:118); at org.broadinstitute.hellbender.tools.walkers.bqsr.BaseRecalibrator.apply(BaseRecalibrator.java:189)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7092:8787,validat,validate,8787,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7092,1,['validat'],['validate']
Security,5:41:49.029 INFO Funcotator - HTSJDK Version: 2.23.0; 15:41:49.029 INFO Funcotator - Picard Version: 2.22.8; 15:41:49.029 INFO Funcotator - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 15:41:49.029 INFO Funcotator - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 15:41:49.029 INFO Funcotator - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 15:41:49.029 INFO Funcotator - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 15:41:49.029 INFO Funcotator - Deflater: IntelDeflater; 15:41:49.029 INFO Funcotator - Inflater: IntelInflater; 15:41:49.029 INFO Funcotator - GCS max retries/reopens: 20; 15:41:49.029 INFO Funcotator - Requester pays: disabled; 15:41:49.029 INFO Funcotator - Initializing engine; 15:41:49.471 INFO FeatureManager - Using codec VCFCodec to read file file:///home/shiyang/Project/BGB900_101/TSO_result/TSO_somatic_vcf/112-0005-0031-B1_L1.UP12.tmb.tsv.tso.somatic.vcf; 15:41:49.489 INFO Funcotator - Done initializing engine; 15:41:49.489 INFO Funcotator - Validating Sequence Dictionaries...; 15:41:49.490 INFO Funcotator - Processing user transcripts/defaults/overrides...; 15:41:49.490 INFO Funcotator - Initializing data sources...; 15:41:49.492 INFO DataSourceUtils - Initializing data sources from directory: /home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s; 15:41:49.492 INFO DataSourceUtils - Data sources version: 1.7.2020429s; 15:41:49.492 INFO DataSourceUtils - Data sources source: ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/funcotator/funcotator_dataSources.v1.7.20200429s.tar.gz; 15:41:49.492 INFO DataSourceUtils - Data sources alternate source: gs://broad-public-datasets/funcotator/funcotator_dataSources.v1.7.20200429s.tar.gz; 15:41:49.496 INFO DataSourceUtils - Resolved data source file path: file:///home/shiyang/softwares/gatk-4.1.8.1/achilles_lineage_results.import.txt -> file:///home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s/achilles/hg19/achilles_lin,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6758:4657,Validat,Validating,4657,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6758,1,['Validat'],['Validating']
Security,"6.647 INFO StructuralVariationDiscoveryPipelineSpark - BND_INV33: 240; 17:21:06.647 INFO StructuralVariationDiscoveryPipelineSpark - BND_INV55: 230; 17:21:06.648 INFO StructuralVariationDiscoveryPipelineSpark - DEL: 4488; 17:21:06.648 INFO StructuralVariationDiscoveryPipelineSpark - DUP: 1355; 17:21:06.648 INFO StructuralVariationDiscoveryPipelineSpark - INS: 1675; 17:21:06.648 INFO StructuralVariationDiscoveryPipelineSpark - INV: 0; 17:21:06.648 INFO StructuralVariationDiscoveryPipelineSpark - DUP_INV: 0; 17:21:06.648 INFO StructuralVariationDiscoveryPipelineSpark - CPX: 0; 18/01/25 17:21:07 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 29.0 in stage 61.0 (TID 60915, cwhelan-hg00514-1-cram-samtools-bam-feature-w-1.c.broad-dsde-methods.internal, executor 48): java.lang.IllegalArgumentException: Unexpected CIGAR format with deletion neighboring clipping; cigar elements are: [1190M, 4D, 53M, 2I, 26M, 2I, 31M, 2D, 1450S]; 	at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:681); 	at org.broadinstitute.hellbender.tools.spark.sv.utils.SvCigarUtils.validateCigar(SvCigarUtils.java:134); 	at org.broadinstitute.hellbender.tools.spark.sv.utils.SvCigarUtils.getUnclippedReadLength(SvCigarUtils.java:161); 	at org.broadinstitute.hellbender.tools.spark.sv.utils.SvCigarUtils.computeAssociatedDistOnRead(SvCigarUtils.java:330); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.alignment.AlignmentInterval.readIntervalAlignedToRefSpan(AlignmentInterval.java:634); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.CpxVariantDetector.extractAltHaplotypeSeq(CpxVariantDetector.java:852); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.CpxVariantDetector.access$300(CpxVariantDetector.java:47); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.CpxVariantDetector$AnnotatedContig.annotate(CpxVariantDetector.java:194); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.CpxVariantDet",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4260:5001,validat,validateArg,5001,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4260,1,['validat'],['validateArg']
Security,"6:08:17 UTC 2019] ValidateSamFile --INPUT CQ-NEQAS-2018.ILLUMINA.library.000000000-BCFDC.1.1.sorted.bam --MODE SUMMARY --MAX_OUTPUT 100 --IGNORE_WARNINGS false --VALIDATE_INDEX true --INDEX_VALIDATION_STRINGENCY EXHAUSTIVE --IS_BISULFITE_SEQUENCED false --MAX_OPEN_TEMP_FILES 8000 --SKIP_MATE_VALIDATION false --VERBOSITY INFO --QUIET false --VALIDATION_STRINGENCY STRICT --COMPRESSION_LEVEL 2 --MAX_RECORDS_IN_RAM 500000 --CREATE_INDEX false --CREATE_MD5_FILE false --GA4GH_CLIENT_SECRETS client_secrets.json --help false --version false --showHidden false --USE_JDK_DEFLATER false --USE_JDK_INFLATER false; [Thu Mar 07 16:08:24 UTC 2019] Executing as mpmachado@lx-bioinfo02 on Linux 2.6.32-696.23.1.el6.x86_64 amd64; OpenJDK 64-Bit Server VM 1.8.0_191-8u191-b12-0ubuntu0.16.04.1-b12; Deflater: Intel; Inflater: Intel; Provider GCS is available; Picard version: Version:4.1.0.0; WARNING 2019-03-07 16:08:24 ValidateSamFile NM validation cannot be performed without the reference. All other validations will still occur.; INFO 2019-03-07 16:10:25 SamFileValidator Validated Read 10,000,000 records. Elapsed time: 00:02:00s. Time for last 10,000,000: 120s. Last read position: chr9:32,633,613; INFO 2019-03-07 16:12:22 SamFileValidator Validated Read 20,000,000 records. Elapsed time: 00:03:58s. Time for last 10,000,000: 117s. Last read position: chrM:11,340; No errors found; [Thu Mar 07 16:13:05 UTC 2019] picard.sam.ValidateSamFile done. Elapsed time: 4.79 minutes.; Runtime.totalMemory()=2602041344; Tool returned:; 0; ```. But when run BaseRecalibrator got the _fromIndex toIndex_ error:; `gatk BaseRecalibrator --input sorted.bam --output sorted.baserecalibrator_report.txt --reference GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.bowtie_index.fasta --use-original-qualities true --known-sites snp151common_tablebrowser.bed.bgz --known-sites snp151flagged_tablebrowser.bed.bgz`; ```; ERROR: return code 3; STDERR:; 15:46:35.795 INFO NativeLibraryLoader - Loading libgkl_compression.so from j",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5807:1834,validat,validations,1834,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5807,1,['validat'],['validations']
Security,7 INFO PathSeqPipelineSpark - GCS max retries/reopens: 20; 20:41:37.627 INFO PathSeqPipelineSpark - Using google-cloud-java patch 6d11bef1c81f885c26b2b56c8616b7a705171e4f from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 20:41:37.627 INFO PathSeqPipelineSpark - Initializing engine; 20:41:37.627 INFO PathSeqPipelineSpark - Done initializing engine; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; 18/04/23 20:41:38 INFO SparkContext: Running Spark version 2.2.0; 18/04/23 20:41:38 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 18/04/23 20:41:38 INFO SparkContext: Submitted application: PathSeqPipelineSpark; 18/04/23 20:41:39 INFO SecurityManager: Changing view acls to: zorzan; 18/04/23 20:41:39 INFO SecurityManager: Changing modify acls to: zorzan; 18/04/23 20:41:39 INFO SecurityManager: Changing view acls groups to:; 18/04/23 20:41:39 INFO SecurityManager: Changing modify acls groups to:; 18/04/23 20:41:39 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(zorzan); groups with view permissions: Set(); users with modify permissions: Set(zorzan); groups with modify permissions: Set(); 18/04/23 20:41:41 INFO Utils: Successfully started service 'sparkDriver' on port 36273.; 18/04/23 20:41:41 INFO SparkEnv: Registering MapOutputTracker; 18/04/23 20:41:41 INFO SparkEnv: Registering BlockManagerMaster; 18/04/23 20:41:41 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information; 18/04/23 20:41:41 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up; 18/04/23 20:41:41 INFO DiskBlockManager: Created local directory at /tmp/zorzan/blockmgr-994d8501-06ce-4315-84ff-3c29de358ae1; 18/04/23 20:41:41 INFO MemoryStore: MemoryStore started with capacity 4.0 GB; 18/04/23 20:41:41 INFO SparkEnv: Registering OutputCommitCoordi,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694:6995,Secur,SecurityManager,6995,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694,7,"['Secur', 'authenticat']","['SecurityManager', 'authentication']"
Security,"7:30.580 INFO ProgressMeter - chr1:220837654 4.2 18418000 4417386.9. 10:47:40.592 INFO ProgressMeter - chr1:229536819 4.3 19156000 4417642.0. 10:47:50.595 INFO ProgressMeter - chr1:237917173 4.5 19861000 4410598.8. 10:48:00.598 INFO ProgressMeter - chr1:246682719 4.7 20561000 4403066.6. 10:48:10.604 INFO ProgressMeter - chr2:6733404 4.8 21270000 4397838.6. 10:48:20.605 INFO ProgressMeter - chr2:15144861 5.0 21942000 4385607.8. 10:48:30.607 INFO ProgressMeter - chr2:24131740 5.2 22650000 4381143.4. 10:48:40.610 INFO ProgressMeter - chr2:32916253 5.3 23467000 4397382.8. 10:48:43.217 INFO LeftAlignIndels - Shutting down engine. [August 18, 2020 10:48:43 AM EDT] org.broadinstitute.hellbender.tools.LeftAlignIndels done. Elapsed time: 5.40 minutes. Runtime.totalMemory()=2076049408. java.lang.IllegalArgumentException: the range cannot contain negative indices. at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:727). at org.broadinstitute.hellbender.utils.IndexRange.validate(IndexRange.java:108). at org.broadinstitute.hellbender.utils.IndexRange.shift(IndexRange.java:73). at org.broadinstitute.hellbender.utils.IndexRange.shiftLeft(IndexRange.java:77). at org.broadinstitute.hellbender.utils.read.AlignmentUtils.leftAlignIndels(AlignmentUtils.java:735). at org.broadinstitute.hellbender.tools.LeftAlignIndels.apply(LeftAlignIndels.java:78). at org.broadinstitute.hellbender.engine.ReadWalker.lambda$traverse$0(ReadWalker.java:96). at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184). at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193). at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175). at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193). at java.util.Iterator.forEachRemaining(Iterator.java:116). at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801). at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481). at java.util",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6765:6187,validat,validate,6187,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6765,1,['validat'],['validate']
Security,"8.0/gatk-package-4.1.8.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /home/zepengmu/tools/gatk-4.1.8.0/gatk-package-4.1.8.0-local.jar ValidateVariants -V ../../data/geno/phased/chr1-22.phased.rename.reheader.vcf.gz -R ../../../../index/hg19.fa.gz; 19:53:34.379 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/zepengmu/tools/gatk-4.1.8.0/gatk-package-4.1.8.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Oct 25, 2020 7:53:34 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 19:53:34.606 INFO ValidateVariants - ------------------------------------------------------------; 19:53:34.606 INFO ValidateVariants - The Genome Analysis Toolkit (GATK) v4.1.8.0; 19:53:34.606 INFO ValidateVariants - For support and documentation go to https://software.broadinstitute.org/gatk/; 19:53:34.607 INFO ValidateVariants - Executing as zepengmu@midway2-login1.rcc.local on Linux v3.10.0-1127.8.2.el7.x86_64 amd64; 19:53:34.607 INFO ValidateVariants - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_45-b14; 19:53:34.607 INFO ValidateVariants - Start Date/Time: October 25, 2020 7:53:34 PM CDT; 19:53:34.607 INFO ValidateVariants - ------------------------------------------------------------; 19:53:34.607 INFO ValidateVariants - ------------------------------------------------------------; 19:53:34.607 INFO ValidateVariants - HTSJDK Version: 2.22.0; 19:53:34.607 INFO ValidateVariants - Picard Version: 2.22.8; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 19:53:34.608 INFO ValidateVariants - ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6911:1297,Validat,ValidateVariants,1297,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6911,1,['Validat'],['ValidateVariants']
Security,"86); - Remove AI/AN from VDS docs [VS-726] (#8096); - Add flag for cost_observability table writing to support sub-cohort use case [VS-521] (#8093); - Document STS delivery process for VDS [VS-727] (#8101); - delete obsolete callset_QC directory and its contents [VS-318] (#8108); - doc link typo and add check for control samples in AVRO export (#8110); - Add defaults for scatter_count in GvsExtractCohortFromSampleNames [VS-496] (#8109); - Escape table names properly in ValidateVat WDL (#8116); - Vs 741 fix indefinite freeze in split intervals task when using exome data (#8113); - VAT Readme updates (#8090); - WDL and python scripts to use the VDS in the VAT (#8077); - VS-757 - Use JASIX to make sub-jsons of annotated output of Nirvana (#8133); - add note about permissions for P&S workflow to work (#8135); - VS-759 (and VS-760) (#8137); - VS-765. Scatter the RemoveDuplicates task. (#8144); - update delivery docs based on latest VDS delivery run [VS-770] (#8150); - Add monitoring to index vcf (#8151); - Make some noise when VDS validation succeeds (#8155); - Handle empty genes annotation file. (#8153); - Add escapes for otherwise problematic dataset / table names. (#8162); - New WDL to create VAT tsvs from previously generated BigQuery table. (#8165); - Treat withdrawn samples in sub-cohort prepare correctly [VS-772] (#8156); - Remove unused VAT Creation WDL (#8172); - Gg consistently use dataset name as input parameter (#8173); - AoU cleanup docs, round 1 [VS-671] (#8104); - VDS docs remove samples and correct GT [VS-807] (#8178); - [VS-693] Add support for VQSR Lite to GvsCreateFilterSet (#8157); - VAT Documentation Update Round 1 [VS-531]; - VS-530 VDS creation documentation for AoU (#8169); - Update beta docs to tell people not to use free credits (#8184); - VS-816 Keeping ingestion under quota (#8193); - CromwellOnAzure + Azure SQL DB + AAD first steps doc [VS-805] (#8191); - Edit and re-format VDS -> VAT doc [VS-821] (#8187); - VS-820 Incorporate code to stay un",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8248:31469,validat,validation,31469,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8248,2,['validat'],['validation']
Security,"89); - Pinned typing_extensions python package to 4.1.1 to fix conda environment. (#7802); - WeightedSplitInterval fixes [VS-384] [VS-332] (#7795); - Replace Travis with GithubActions (#7754); - Docker build only lfs pulls main/src/resources/large (#7727); - Clean up gatk jars -- looks like we are not passing them properly in the extract (#7788); - Fix typo that broke git lfs pull (#7806); - Document AoU SOP (up to the VAT) [VS-63] (#7807); - Incident VS 365 clinvar classification fix (#7769); - VS-390. Add precision and sensitivity wdl (#7813); - Quickstart based integration test [VS-357] (#7812); - 365 vat python testing additions (#7756); - VS 396 clinvar grabs too many values (#7823); - Added a test to validate WDLs in the scripts directory. (#7826) (#7829); - VAT Performance / Reliability Improvements (#7828); - VAT naming conventions [VS-410] (#7827); - Rc remove ad from vat (#7832); - bugfix, we were trying to grep a binary file (#7837); - Cleanup scripts/variantstore [VS-414] (#7834); - Merge VAT TSV files into single bgzipped file [VS-304] (#7848); - Handle fully and partially loaded samples [VS-262] [VS-258] (#7843); - Ingest Error Handling Fixes [VS-261] (#7841); - First cut at a python notebook to validate inputs. (#7845); - Compute filter scatter [VS-392] (#7852); - remove withdrawn req (#7844); - Improve import error message [VS-437] (#7855); - Fix Input Validation python notebook (#7853); - Add VAT Validation check that aa_change and exon_number are consistently set. (#7850); - Ingest 10K [VS-344] (#7860); - X/Y chromosome reweighting for better extract shard runtime balance [VS-389] (#7868); - VET Ingest Validation / Allow Ingest of non-VQSR'ed data (#7870); - Fix AoU workflow bugs (#7874); - Curate input arrays to skip already ingested sample data [VS-246] (#7862); - KM upload GVS product sheet (#7883); - Default extract scatter width [VS-415] (#7878); - Volatile tasks review [VS-447] (#7880); - Update Quickstart Integration for X/Y scaling changes ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8248:24455,validat,validate,24455,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8248,2,['validat'],['validate']
Security,"://gatk.broadinstitute.org/hc/en-us/community/posts/360061452132-GATK4-RNAseq-short-variant-discovery-SNPs-Indels-), but then for Haplotypecaller, and you have opened a bugreport to add a feature to ValidateVariants: https://github.com/broadinstitute/gatk/issues/6553. However, it would be nice if you could actually investigate the formatting error. Unfortunately my formatting error isn't the same as reported in the other post. I have 105 error in which the 1st alternative allele is a spanning deletion and the 2nd (and 3rd) is either an indel or snp. It's true that the 2nd and 3rd allele is actually not found in my samples. I even have 7 occurances in which the 1st allele (spanning deletion) has allele frequency 1.00. my code is the following for GenotypeGVCFs:. java -Xms32G -Xmx32G -jar ${gatk4} GenotypeGVCFs -R ${ref} -V ${pipeline}/${name}\_v4.1.6.0.g.vcf.gz -O ${vcf}/${name}\_v4.1.6.0.vcf.gz -L ${pipeline}/${name}\_intervals.list 2> ${log}/${name}\_v4.1.6.0\_genotype.log. for ValidateVariants:. java -Xms10G -Xmx10G -jar ${gatk4} ValidateVariants -R ${ref} -V ${name}\_v4.1.6.0.vcf.gz -L ${pipeline}/${name}\_intervals.list --warn-on-errors 2> ${log}/${name}\_v4.1.6.0\_genotype\_valivar.log. the warning in ValidateVariants and the site look like this:. 14:12:15.126 WARN ValidateVariants - \*\*\*\*\* Input 1st\_v4.1.6.0.vcf.gz fails strict validation of type ALL: one or more of the ALT allele(s) for the record at position chr\_1:1088200 are not observed at all in the sample genotypes \*\*\*\*\* ; ; chr\_1 1088200 . T \*,TAAAAAAAAAAAA 64.39 . AC=8,0;AF=0.667,0.00;AN=12;DP=118;ExcessHet=3.0103;FS=0.000;InbreedingCoeff=0.4286;MLEAC=7,7;MLEAF=0.583,0.583;MQ=58.73;QD=32.19;SOR=2.303 GT:AD:DP:GQ:PL ./.:9,0,0:9:.:0,0,0,0,0,0 0/0:9,0,0:9:0:0,0,113,0,113,113 ./.:10,0,0:10:.:0,0,0,0,0,0 ./.:5,0,0:5:.:0,0,0,0,0,0 1/1:0,0,1:1:0:225,15,0,15,0,0 ./.:0,0,0:0:.:0,0,0,0,0,0 ./.:12,0,0:12:.:0,0,0,0,0,0 ./.:8,0,0:8:.:0,0,0,0,0,0 0/0:3,0,0:3:0:0,0,43,0,43,43 ./.:7,0,0:7:.:0,0,0,0,0,0 ./.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6630:1608,Validat,ValidateVariants,1608,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6630,1,['Validat'],['ValidateVariants']
Security,":01,31] [info] Running with database db.url = jdbc:hsqldb:mem:c4b3296a-4b73-4053-b6bf-d4eeb71c8956;shutdown=false;hsqldb.tx=mvcc; [2019-10-01 02:53:01,85] [info] Slf4jLogger started; [2019-10-01 02:53:02,22] [info] Workflow heartbeat configuration:; {; ""cromwellId"" : ""cromid-876ccf5"",; ""heartbeatInterval"" : ""2 minutes"",; ""ttl"" : ""10 minutes"",; ""failureShutdownDuration"" : ""5 minutes"",; ""writeBatchSize"" : 10000,; ""writeThreshold"" : 10000; }; [2019-10-01 02:53:02,28] [info] Metadata summary refreshing every 1 second.; [2019-10-01 02:53:02,31] [info] KvWriteActor configured to flush with batch size 200 and process rate 5 seconds.; [2019-10-01 02:53:02,31] [info] WriteMetadataActor configured to flush with batch size 200 and process rate 5 seconds.; [2019-10-01 02:53:02,32] [info] CallCacheWriteActor configured to flush with batch size 100 and process rate 3 seconds.; [2019-10-01 02:53:02,32] [warn] 'docker.hash-lookup.gcr-api-queries-per-100-seconds' is being deprecated, use 'docker.hash-lookup.gcr.throttle' instead (see reference.conf); [2019-10-01 02:53:02,40] [info] JobExecutionTokenDispenser - Distribution rate: 50 per 1 seconds.; [2019-10-01 02:53:02,43] [info] SingleWorkflowRunnerActor: Version 46.1; [2019-10-01 02:53:02,44] [info] SingleWorkflowRunnerActor: Submitting workflow; [2019-10-01 02:53:02,49] [info] Unspecified type (Unspecified version) workflow c55a06f3-abc1-4db1-8e0f-ea0303caab2c submitted; [2019-10-01 02:53:02,51] [info] SingleWorkflowRunnerActor: Workflow submitted c55a06f3-abc1-4db1-8e0f-ea0303caab2c; [2019-10-01 02:53:02,51] [info] 1 new workflows fetched by cromid-876ccf5: c55a06f3-abc1-4db1-8e0f-ea0303caab2c; [2019-10-01 02:53:02,52] [info] WorkflowManagerActor Starting workflow c55a06f3-abc1-4db1-8e0f-ea0303caab2c; [2019-10-01 02:53:02,53] [info] WorkflowManagerActor Successfully started WorkflowActor-c55a06f3-abc1-4db1-8e0f-ea0303caab2c; [2019-10-01 02:53:02,53] [info] Retrieved 1 workflows from the WorkflowStoreActor; [2019-10-01 02:53:02,55",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6189:1661,hash,hash-lookup,1661,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6189,1,['hash'],['hash-lookup']
Security,:05.915 WARN HaplotypeCallerSpark -. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. Warning: HaplotypeCallerSpark is a BETA tool and is not yet ready for use in production. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. 09:38:05.915 INFO HaplotypeCallerSpark - Initializing engine; 09:38:05.915 INFO HaplotypeCallerSpark - Done initializing engine; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; 20/08/15 09:38:06 INFO SparkContext: Running Spark version 2.4.5; 09:38:06.440 WARN NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 20/08/15 09:38:06 INFO SparkContext: Submitted application: HaplotypeCallerSpark; 20/08/15 09:38:06 INFO SecurityManager: Changing view acls to: xc278; 20/08/15 09:38:06 INFO SecurityManager: Changing modify acls to: xc278; 20/08/15 09:38:06 INFO SecurityManager: Changing view acls groups to:; 20/08/15 09:38:06 INFO SecurityManager: Changing modify acls groups to:; 20/08/15 09:38:06 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(xc278); groups with view permissions: Set(); users with modify permissions: Set(xc278); groups with modify permissions: Set(); 20/08/15 09:38:06 INFO Utils: Successfully started service 'sparkDriver' on port 33339.; 20/08/15 09:38:06 INFO SparkEnv: Registering MapOutputTracker; 20/08/15 09:38:06 INFO SparkEnv: Registering BlockManagerMaster; 20/08/15 09:38:06 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information; 20/08/15 09:38:06 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up; 20/08/15 09:38:06 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-e8d90ed7-8009-437a-8d5e-571b3a582f62; 20/08/15 09:38:06 INFO MemoryStore: MemoryStore started with capacity 15.8 GB; 20/08/15 09:38:06 INFO SparkEnv: Registering OutputCommitCoordinator; 2,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6750:4339,Secur,SecurityManager,4339,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6750,7,"['Secur', 'authenticat']","['SecurityManager', 'authentication']"
Security,":08.688 INFO PostprocessGermlineCNVCalls - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 12:49:08.688 INFO PostprocessGermlineCNVCalls - Deflater: IntelDeflater; 12:49:08.688 INFO PostprocessGermlineCNVCalls - Inflater: IntelInflater; 12:49:08.688 INFO PostprocessGermlineCNVCalls - GCS max retries/reopens: 20; 12:49:08.688 INFO PostprocessGermlineCNVCalls - Requester pays: disabled; 12:49:08.688 INFO PostprocessGermlineCNVCalls - Initializing engine; 12:49:12.598 INFO PostprocessGermlineCNVCalls - Done initializing engine; 12:49:15.678 INFO PostprocessGermlineCNVCalls - Shutting down engine; [October 29, 2020 12:49:15 PM MSK] org.broadinstitute.hellbender.tools.copynumber.PostprocessGermlineCNVCalls done. Elapsed time: 0.12 minutes.; Runtime.totalMemory()=2457862144; java.lang.IllegalArgumentException: Records were not strictly sorted in dictionary order.; 	at org.broadinstitute.hellbender.tools.copynumber.arguments.CopyNumberArgumentValidationUtils.validateIntervals(CopyNumberArgumentValidationUtils.java:60); 	at org.broadinstitute.hellbender.tools.copynumber.formats.collections.AbstractLocatableCollection.getShardedCollectionSortOrder(AbstractLocatableCollection.java:142); 	at org.broadinstitute.hellbender.tools.copynumber.PostprocessGermlineCNVCalls.onTraversalStart(PostprocessGermlineCNVCalls.java:297); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1047); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); 	at org.broadinstitute.hellbender.Main.main(Main.java:289); Using GATK jar /home/lmbs02/bio/biosoft/gatk/gatk-4.1.8.1/gat",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6924:9617,validat,validateIntervals,9617,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6924,1,['validat'],['validateIntervals']
Security,":30:57 INFO yarn.Client: Requesting a new application from cluster with 4 NodeManagers; 18/01/09 18:30:58 INFO yarn.Client: Verifying our application has not requested more than the maximum memory capability of the cluster (18432 MB per container); 18/01/09 18:30:58 INFO yarn.Client: Will allocate AM container, with 896 MB memory including 384 MB overhead; 18/01/09 18:30:58 INFO yarn.Client: Setting up container launch context for our AM; 18/01/09 18:30:58 INFO yarn.Client: Setting up the launch environment for our AM container; 18/01/09 18:30:58 INFO yarn.Client: Preparing resources for our AM container; 18/01/09 18:30:59 INFO yarn.Client: Uploading resource file:/tmp/sun/spark-5a3e539e-2e2b-4da2-b218-2bda166bd4c0/__spark_conf__7100950787185363106.zip -> hdfs://tele-1:8020/user/sun/.sparkStaging/application_1515493209401_0001/__spark_conf__.zip; 18/01/09 18:31:00 INFO spark.SecurityManager: Changing view acls to: sun; 18/01/09 18:31:00 INFO spark.SecurityManager: Changing modify acls to: sun; 18/01/09 18:31:00 INFO spark.SecurityManager: Changing view acls groups to: ; 18/01/09 18:31:00 INFO spark.SecurityManager: Changing modify acls groups to: ; 18/01/09 18:31:00 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(sun); groups with view permissions: Set(); users with modify permissions: Set(sun); groups with modify permissions: Set(); 18/01/09 18:31:00 INFO yarn.Client: Submitting application application_1515493209401_0001 to ResourceManager; 18/01/09 18:31:00 INFO impl.YarnClientImpl: Submitted application application_1515493209401_0001; 18/01/09 18:31:00 INFO cluster.SchedulerExtensionServices: Starting Yarn extension services with app application_1515493209401_0001 and attemptId None; 18/01/09 18:31:01 INFO yarn.Client: Application report for application_1515493209401_0001 (state: ACCEPTED); 18/01/09 18:31:01 INFO yarn.Client: ; 	 client token: N/A; 	 diagnostics: N/A; 	 ApplicationMaster hos",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4112:11871,Secur,SecurityManager,11871,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4112,1,['Secur'],['SecurityManager']
Security,:50:33 PM EST] org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSpark done. Elapsed time: 0.06 minutes.; Runtime.totalMemory()=1065353216; java.lang.IllegalArgumentException: Unsupported class file major version 55; 	at org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:166); 	at org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:148); 	at org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:136); 	at org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:237); 	at org.apache.spark.util.ClosureCleaner$.getClassReader(ClosureCleaner.scala:49); 	at org.apache.spark.util.FieldAccessFinder$$anon$3$$anonfun$visitMethodInsn$2.apply(ClosureCleaner.scala:517); 	at org.apache.spark.util.FieldAccessFinder$$anon$3$$anonfun$visitMethodInsn$2.apply(ClosureCleaner.scala:500); 	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733); 	at scala.collection.mutable.HashMap$$anon$1$$anonfun$foreach$2.apply(HashMap.scala:134); 	at scala.collection.mutable.HashMap$$anon$1$$anonfun$foreach$2.apply(HashMap.scala:134); 	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236); 	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40); 	at scala.collection.mutable.HashMap$$anon$1.foreach(HashMap.scala:134); 	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732); 	at org.apache.spark.util.FieldAccessFinder$$anon$3.visitMethodInsn(ClosureCleaner.scala:500); 	at org.apache.xbean.asm6.ClassReader.readCode(ClassReader.java:2175); 	at org.apache.xbean.asm6.ClassReader.readMethod(ClassReader.java:1238); 	at org.apache.xbean.asm6.ClassReader.accept(ClassReader.java:631); 	at org.apache.xbean.asm6.ClassReader.accept(ClassReader.java:355); 	at org.apache.spark.util.ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$14.apply(ClosureCleaner.scala:307); 	at org.apache.spark.util.ClosureCleaner$$anonfun$org$apache$spark$util$ClosureC,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7035:6790,Hash,HashMap,6790,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7035,1,['Hash'],['HashMap']
Security,":57.036 INFO ProgressMeter - Starting traversal; 00:05:57.036 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 00:07:26.967 WARN ReferenceConfidenceVariantContextMerger - Detected invalid annotations: When trying to merge variant contexts at location chr16:10185 the annotation AS_VarDP=59|115|0 was not a numerical value and was ignored; 00:07:26.967 WARN ReferenceConfidenceVariantContextMerger - Reducible annotation 'AS_VarDP' detected, add -G StandardAnnotation -G AS_StandardAnnotation to the command to annotate in the final VC with this annotation.; 00:07:26.991 INFO GenotypeGVCFs - Shutting down engine; GENOMICSDB_TIMER,GenomicsDB iterator next() timer,Wall-clock time(s),0.02938786500000001,Cpu time(s),0.029037034000000003; [August 25, 2021 12:07:27 AM EDT] org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs done. Elapsed time: 1.55 minutes.; Runtime.totalMemory()=1807745024; java.lang.NullPointerException; at java.util.HashMap.putMapEntries(HashMap.java:500); at java.util.HashMap.putAll(HashMap.java:784); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorEngine.combineAnnotations(VariantAnnotatorEngine.java:211); at org.broadinstitute.hellbender.tools.walkers.ReferenceConfidenceVariantContextMerger.mergeAttributes(ReferenceConfidenceVariantContextMerger.java:318); at org.broadinstitute.hellbender.tools.walkers.ReferenceConfidenceVariantContextMerger.merge(ReferenceConfidenceVariantContextMerger.java:142); at org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFsEngine.callRegion(GenotypeGVCFsEngine.java:130); at org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs.apply(GenotypeGVCFs.java:281); at org.broadinstitute.hellbender.engine.VariantLocusWalker.lambda$traverse$0(VariantLocusWalker.java:135); at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.stream.ReferencePipeline$",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7437:8055,Hash,HashMap,8055,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7437,1,['Hash'],['HashMap']
Security,"; - 317 remove excess header values in VCF extract (#7786); - correct auth in split intervals (#7790); - Add code to (optionally) zero pad the vcf filename. (#7783); - LoadData `maxRetries` parameterized, default increased [VS-383] (#7791); - Update to latest version of ah_var_store gatk override jar (#7793); - GvsUnified WDL to wrap the 6 core GVS WDLs [VS-382] (#7789); - Pinned typing_extensions python package to 4.1.1 to fix conda environment. (#7802); - WeightedSplitInterval fixes [VS-384] [VS-332] (#7795); - Replace Travis with GithubActions (#7754); - Docker build only lfs pulls main/src/resources/large (#7727); - Clean up gatk jars -- looks like we are not passing them properly in the extract (#7788); - Fix typo that broke git lfs pull (#7806); - Document AoU SOP (up to the VAT) [VS-63] (#7807); - Incident VS 365 clinvar classification fix (#7769); - VS-390. Add precision and sensitivity wdl (#7813); - Quickstart based integration test [VS-357] (#7812); - 365 vat python testing additions (#7756); - VS 396 clinvar grabs too many values (#7823); - Added a test to validate WDLs in the scripts directory. (#7826) (#7829); - VAT Performance / Reliability Improvements (#7828); - VAT naming conventions [VS-410] (#7827); - Rc remove ad from vat (#7832); - bugfix, we were trying to grep a binary file (#7837); - Cleanup scripts/variantstore [VS-414] (#7834); - Merge VAT TSV files into single bgzipped file [VS-304] (#7848); - Handle fully and partially loaded samples [VS-262] [VS-258] (#7843); - Ingest Error Handling Fixes [VS-261] (#7841); - First cut at a python notebook to validate inputs. (#7845); - Compute filter scatter [VS-392] (#7852); - remove withdrawn req (#7844); - Improve import error message [VS-437] (#7855); - Fix Input Validation python notebook (#7853); - Add VAT Validation check that aa_change and exon_number are consistently set. (#7850); - Ingest 10K [VS-344] (#7860); - X/Y chromosome reweighting for better extract shard runtime balance [VS-389] (#7868",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8248:23942,validat,validate,23942,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8248,2,['validat'],['validate']
Security,"; --master yarn-client \; --driver-memory 8G \; --conf spark.driver.maxResultSize=0 \; --conf spark.driver.userClassPathFirst=true \; --conf spark.executor.userClassPathFirst=true \; --conf spark.io.compression.codec=lzf \; --conf spark.yarn.executor.memoryOverhead=600 \; --executor-memory ${execMem}g \; --num-executors $execs \; --executor-cores $cores \; bin/cleanHellbender/gatk/build/libs/gatk-all-*-spark.jar \; ReadsPipelineSpark \; --sparkMaster yarn-client \; -I hdfs:///user/akiezun/CEUTrio.HiSeq.WEx.b37.NA12892.bam \; -R hdfs:///user/droazen/bqsr/human_g1k_v37.2bit \; --programName ${name} \; -O $bamout \; --knownSites hdfs:////user/akiezun/dbsnp_138.b37.excluding_sites_after_129.vcf \; --emit_original_quals \; --duplicates_scoring_strategy SUM_OF_BASE_QUALITIES; ```. exec=24; cores=5; execMem=25. fails with . ```; java.lang.IllegalArgumentException: SimpleInterval is 1 based, so start must be >= 1, start: 0; at org.broadinstitute.hellbender.utils.SimpleInterval.validatePositions(SimpleInterval.java:58); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:33); at org.broadinstitute.hellbender.utils.baq.BAQ.getReferenceWindowForRead(BAQ.java:525); at org.broadinstitute.hellbender.utils.recalibration.BaseRecalibrationEngine$BQSRReferenceWindowFunction.apply(BaseRecalibrationEngine.java:46); at org.broadinstitute.hellbender.utils.recalibration.BaseRecalibrationEngine$BQSRReferenceWindowFunction.apply(BaseRecalibrationEngine.java:41); at org.broadinstitute.hellbender.engine.spark.BroadcastJoinReadsWithRefBases.lambda$addBases$c54addeb$1(BroadcastJoinReadsWithRefBases.java:52); at org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(JavaPairRDD.scala:1030); at org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(JavaPairRDD.scala:1030); at scala.collection.Iterator$$anon$11.next(Iterator.scala:328); at scala.collection.Iterator$$anon$11.next(Iterator.scala:328); at scala.collection.convert.Wrapper",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1234:1070,validat,validatePositions,1070,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1234,1,['validat'],['validatePositions']
Security,"=; 10:33:06.428 INFO SparkContext - Submitted application: SortSamSpark; 10:33:06.446 INFO ResourceProfile - Default ResourceProfile created, executor resources: Map(memoryOverhead -> name: memoryOverhead, amount: 600, script: , vendor: , cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0); 10:33:06.454 INFO ResourceProfile - Limiting resource is cpu; 10:33:06.455 INFO ResourceProfileManager - Added ResourceProfile id: 0; 10:33:06.500 INFO SecurityManager - Changing view acls to: root; 10:33:06.501 INFO SecurityManager - Changing modify acls to: root; 10:33:06.501 INFO SecurityManager - Changing view acls groups to:; 10:33:06.502 INFO SecurityManager - Changing modify acls groups to:; 10:33:06.502 INFO SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); groups with view permissions: Set(); users with modify permissions: Set(root); groups with modify permissions: Set(); 10:33:06.755 INFO Utils - Successfully started service 'sparkDriver' on port 34861.; 10:33:06.784 INFO SparkEnv - Registering MapOutputTracker; 10:33:06.815 INFO SparkEnv - Registering BlockManagerMaster; 10:33:06.827 INFO BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information; 10:33:06.828 INFO BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up; 10:33:06.831 INFO SparkEnv - Registering BlockManagerMasterHeartbeat; 10:33:06.846 INFO DiskBlockManager - Created local directory at /raid/tmp/d6/c66ba827e22dbc38625af1cbc85adc/tmp/blockmgr-8dc41ac8-6cf4-4424-9b15-7e2cbfc9e538; 10:33:06.872 INFO MemoryStore - MemoryStore started with capacity 1076.2 GiB; 10:33:06.886 INFO SparkEnv - Registering OutputCommitCoordinator; 10:33:06.916 INFO log - Logging initialized @3948ms to org.sparkproject.jetty.util.log.Slf4j",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8949:42048,Secur,SecurityManager,42048,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8949,3,"['Secur', 'authenticat']","['SecurityManager', 'authentication']"
Security,"=================================================; 10:33:06.427 INFO ResourceUtils - No custom resources configured for spark.driver.; 10:33:06.428 INFO ResourceUtils - ==============================================================; 10:33:06.428 INFO SparkContext - Submitted application: SortSamSpark; 10:33:06.446 INFO ResourceProfile - Default ResourceProfile created, executor resources: Map(memoryOverhead -> name: memoryOverhead, amount: 600, script: , vendor: , cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0); 10:33:06.454 INFO ResourceProfile - Limiting resource is cpu; 10:33:06.455 INFO ResourceProfileManager - Added ResourceProfile id: 0; 10:33:06.500 INFO SecurityManager - Changing view acls to: root; 10:33:06.501 INFO SecurityManager - Changing modify acls to: root; 10:33:06.501 INFO SecurityManager - Changing view acls groups to:; 10:33:06.502 INFO SecurityManager - Changing modify acls groups to:; 10:33:06.502 INFO SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); groups with view permissions: Set(); users with modify permissions: Set(root); groups with modify permissions: Set(); 10:33:06.755 INFO Utils - Successfully started service 'sparkDriver' on port 34861.; 10:33:06.784 INFO SparkEnv - Registering MapOutputTracker; 10:33:06.815 INFO SparkEnv - Registering BlockManagerMaster; 10:33:06.827 INFO BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information; 10:33:06.828 INFO BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up; 10:33:06.831 INFO SparkEnv - Registering BlockManagerMasterHeartbeat; 10:33:06.846 INFO DiskBlockManager - Created local directory at /raid/tmp/d6/c66ba827e22dbc38625af1cbc85adc/tmp/blockmgr-8dc41ac8-6cf4-4424-9b15-7e2cbfc9e538; 10:33:0",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8949:41912,Secur,SecurityManager,41912,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8949,1,['Secur'],['SecurityManager']
Security,"=com.google.protobuf:protobuf-java&package-manager=gradle&previous-version=3.23.4&new-version=3.25.5)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself); You can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/broadinstitute/gatk/network/alerts). </details>",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/9004:4437,secur,security,4437,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/9004,2,"['Secur', 'secur']","['Security', 'security']"
Security,"? I can take a look a this issue. ---. @vdauwera commented on [Thu Jan 26 2017](https://github.com/broadinstitute/gsa-unstable/issues/1489#issuecomment-275578721). Oh, they gave me access to the files but I never took the next step of figuring out which files are relevant. There are twenty thousand samples... I'm not sure what is the best way to approach this. ---. @ldgauthier commented on [Wed Mar 01 2017](https://github.com/broadinstitute/gsa-unstable/issues/1489#issuecomment-283365248). It would be too computationally expensive and just generally painful to get; that dropped allele. I'd suggest making a unit test with some fake data.; You'll need two positions: one upstream with a deletion to generate the *; and one for the SNP. I think the dropped allele was a 1bp deletion at the; same position that generated the representation with the extra base at the; end. Give that one a really low quality in its gvcf so it gets dropped.; PLs don't really matter as long as they jive with the quals and aren't hom; ref. You can just grab numbers from any other valid vcf. I think you can do; it with three samples: one with the upstream deletion and *, one with the; AC SNP and one with the low quality deletion. Other combinations will; probably also produce the same bug. There may be an even simpler way to reproduce the bug without the low; quality deletion but I suspect this will work. On Jan 26, 2017 10:02 PM, ""Geraldine Van der Auwera"" <; notifications@github.com> wrote:. Oh, they gave me access to the files but I never took the next step of; figuring out which files are relevant. There are twenty thousand samples...; I'm not sure what is the best way to approach this. —; You are receiving this because you commented. Reply to this email directly, view it on GitHub; <https://github.com/broadinstitute/gsa-unstable/issues/1489#issuecomment-275578721>,; or mute the thread; <https://github.com/notifications/unsubscribe-auth/AGRhdKIgGAjH5_n3wlZ0E2A5xw1TeFg1ks5rWV5DgaJpZM4KQT_3>; .",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2959:4669,access,access,4669,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2959,1,['access'],['access']
Security,"@LeeTL1220 Fixed PathSeq test BAMs so that all reads have read groups with an SM tag. This will make them pass the WellFormedReadFilter. To be thorough, I made sure they also check out with ValidateSameFile. The BAMs are now properly sorted, and also I made a small fix so that unmapped mate flags are set properly in the filter tool.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3206:190,Validat,ValidateSameFile,190,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3206,1,['Validat'],['ValidateSameFile']
Security,"@LeeTL1220 This will make it easy to basically re-do the MC3 analysis as if M2 had been there from the beginning. The idea is:. * run M2; * merge M2 variants into MC3; * validate all variants (M2 *and* MC3); * compare all callers on equal footing. It would be nice if there were a barclay annotation for an unsupported feature, but I'm not aware of one. . .",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5007:170,validat,validate,170,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5007,1,['validat'],['validate']
Security,"@LeeTL1220 commented on [Mon Feb 01 2016](https://github.com/broadinstitute/gatk-protected/issues/343). In `CreatePanelOfNormals` make anonymize a flag that defaults to `false`. (i.e. `--anonymize`) In other words, by default, we do _not_ produce an anonymized PoN. We could also use a separate tool that takes a pre-existing PoN and anonymizes it. . To anonymize a PoN:; - [ ] Determine which fields are private. At the very least: `fnt_control_matrix`, `log_normals`, and `log_normals_pinv`. _There may be others -- please investigate as part of this issue_; - [ ] Have `CreatePanelOfNormals` delete the fields as the last step.; - [ ] Make sure that `HDF5PoN` produces reasonable error messages if one of these fields is accessed in an anonymized PoN.; - [ ] Create CLI that can take existing PoN and delete the fields. ---. @LeeTL1220 commented on [Mon Feb 01 2016](https://github.com/broadinstitute/gatk-protected/issues/343#issuecomment-178022285). This is necessary since we may want to share PoNs and the PoN files cannot have any private data. ---. @LeeTL1220 commented on [Wed Mar 02 2016](https://github.com/broadinstitute/gatk-protected/issues/343#issuecomment-191420153). Moving this to later milestone, unless it becomes more urgent.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2835:724,access,accessed,724,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2835,1,['access'],['accessed']
Security,"@ahaessly Could you please take a look at this? We had a request to change this argument which wasn't previously possible since it was hardcoded into the WDL task. Ideally I'd like to expose all of the arguments but even wiring this one through the imported WDL was annoying. I tried making it an input to the task with a value like this:. ```; task M2 {; input {; Int max_reads_arg = 75; }; ...; ```; which looks a lot cleaner (don't have to make sure you wire it through from the main inputs), but when I looked in Terra it didn't actually expose the argument (I'm assuming because the M2 task is in a sub-workflow). Any thoughts on how to make this better so I can expose everything? Or is this the best way to do that at the moment?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6739:184,expose,expose,184,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6739,3,['expose'],['expose']
Security,"@asmirnov239 commented on [Fri Apr 21 2017](https://github.com/broadinstitute/gatk-protected/issues/1000). Right now if a user disables MAPPED filter, which is a default filter for CalculateTargetCoverage tool, it will fail with the following uninformative exception (unless somehow all reads are mapped):; ```; java.lang.IllegalArgumentException: the input location cannot be null; 	at org.broadinstitute.hellbender.utils.Utils.nonNull(Utils.java:549); 	at org.broadinstitute.hellbender.tools.exome.HashedListTargetCollection.indexRange(HashedListTargetCollection.java:152); 	at org.broadinstitute.hellbender.tools.exome.CalculateTargetCoverage.apply(CalculateTargetCoverage.java:298); ```; We should guard against it and throw an exception before the traversal starts if MAPPED filter is disabled. ---. @asmirnov239 commented on [Fri Apr 21 2017](https://github.com/broadinstitute/gatk-protected/issues/1000#issuecomment-296295294). Since there is no direct API call to access the list of resolved filters(after command line parsing) this bug fix will have to wait until [broadinstitute/barclay#38](https://github.com/broadinstitute/barclay/pull/38) is merged",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2976:500,Hash,HashedListTargetCollection,500,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2976,3,"['Hash', 'access']","['HashedListTargetCollection', 'access']"
Security,@asmirnov239 commented on [Thu Sep 29 2016](https://github.com/broadinstitute/gatk-protected/issues/727). Here is the stack trace:. ```; java.lang.IllegalArgumentException: the 'to' index must be between 'from' and the length of the data/position sequence; at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:609); at org.broadinstitute.hellbender.utils.param.ParamUtils.inRange(ParamUtils.java:80); at org.broadinstitute.hellbender.utils.hmm.ForwardBackwardAlgorithm$Result.logProbability(ForwardBackwardAlgorithm.java:141); at org.broadinstitute.hellbender.tools.exome.germlinehmm.GenotypeCopyNumberTriStateSegments.lambda$calculateLog10GP$6(GenotypeCopyNumberTriStateSegments.java:197); at java.util.stream.ReferencePipeline$6$1.accept(ReferencePipeline.java:244); at java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:948); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:545); at java.util.stream.AbstractPipeline.evaluateToArrayNode(AbstractPipeline.java:260); at java.util.stream.DoublePipeline.toArray(DoublePipeline.java:506); at org.broadinstitute.hellbender.tools.exome.germlinehmm.GenotypeCopyNumberTriStateSegments.calculateLog10GP(GenotypeCopyNumberTriStateSegments.java:198); at org.broadinstitute.hellbender.tools.exome.germlinehmm.GenotypeCopyNumberTriStateSegments.lambda$composeVariantContext$0(GenotypeCopyNumberTriStateSegments.java:125); at java.util.stream.IntPipeline$4$1.accept(IntPipeline.java:250); at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110); at java.util.Spliterator$OfInt.forEachRemaining(Spliterator.java:693); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ReduceOps$ReduceOp.evaluateSeq,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2898:302,validat,validateArg,302,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2898,1,['validat'],['validateArg']
Security,"@cmnbroad I updated VariantQC and identified one minor difference in behavior associated with VariantEvalEngine. Contig stratification assigns level based on all the contigs. If user-supplied contigs are given, it should defer to these. This PR addresses this, and adds a test case. Note: I put the getContigNames() method into VariantEvalEngine, but it would also be possible to keep this in Config, but expose a getter for userSuppliedIntervals. It seemed marginally better to keep that private.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7238:405,expose,expose,405,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7238,1,['expose'],['expose']
Security,"@davidbenjamin @ldgauthier: in #6263 you added --force-output-intervals to GenotypeGVCFs, which forces the tool to output variants based on a whitelist of sites. I believe this exposed a pre-existing, not related bug. GenotypeGVCFsEngine.removeNonRefAlleles() currently assumes the input has only one alternate allele. If the gVCF has a site with 3 or more alleles, GenotypeGVCFsEngine.removeNonRefAlleles() isnt going to work as intended. If any NON_REF is found, it *should* remove ALT allele header lines and return the new VC with NON_REF removed. It currently only does this if ""newAlleles.size() == 1"", which I assume is a proxy for not having alternates. That assumes the input had only 2 alleles, which isnt safe. This PR includes a fix for this. When I started investigating this I made a repro case (the attached VCF) and test case in GenotypeGVCFsIntegration test that uses --force-output-intervals to illustrate this. Now that the actual problem is clearer, I could understand if you dont want to add more test data to GATK. . I tried to write a unit test for removeNonRefAlleles(), but it didnt seem like it was going to be easy to make a new instance of GenotypeGVCFsEngine.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6406:177,expose,exposed,177,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6406,1,['expose'],['exposed']
Security,"@davidbenjamin commented on [Mon Mar 27 2017](https://github.com/broadinstitute/gatk-protected/issues/958). We currently have an ICE exome normal-normal analysis set up i.e. you can `cd` into `/dsde/working/davidben/mutect/validations/normalNormal` and `/Users/home/davidben/cromwell/run_sge.sh normal_normal.wdl normal_normal.json` is all you need to get the analysis. Let's set this up for a few other replicate sets, which we can grab from the Palantir wiki.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2961:223,validat,validations,223,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2961,1,['validat'],['validations']
Security,"@davidbenjamin commented on [Sat May 27 2017](https://github.com/broadinstitute/gatk-protected/issues/1112). In `SomaticGenotypingEngine::callMutations` and `HaplotypeCallerGenotypingEngine::assignGenotypeLikelihoods` there is a line of code after the call is made but before the variant is annotated:; ```java; ReadLikelihoods annotationLikelihoods = prepareReadAlleleLikelihoodsForAnnotation(likelihoods...); ```; Is this really necessary? It seems quite defensible to annotate using the same likelihoods from which the variant call is derived. As far as Mutect is concerned, the standard will be whether our validations are better or at least no worse without it.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3022:611,validat,validations,611,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3022,1,['validat'],['validations']
Security,"@davidbenjamin commented on [Sun May 28 2017](https://github.com/broadinstitute/gatk-protected/issues/1114). HaplotypeCaller and Mutect by default assemble reads with kmer sizes of 10 and 25. 10 seems extremely small given the low error rates of Illumina sequencing. It's worth investigating how the Mutect validations are affected by increasing these values. ---. @ldgauthier commented on [Tue May 30 2017](https://github.com/broadinstitute/gatk-protected/issues/1114#issuecomment-305032024). Investigate away, but keep in mind bigger kmers introduce more ""dangling tails"", which may end up dropping evidence at the ends of reads. If you end up diving into the assembly graphs, I'm happy to consult. It's a deep, dark rabbit hole, but I've been there before and I know the way. ;)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3024:307,validat,validations,307,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3024,1,['validat'],['validations']
Security,"@davidbenjamin commented on [Wed Feb 15 2017](https://github.com/broadinstitute/gatk-protected/issues/903). Since most of the work is in setting up the necessary tools and pipelines to evaluate, I will lump the actual act of evaluating on specific data into this single ticket. We need to:. * CRSP specificity: apply Takuto's `mutect2-replicate-validation.wdl` on the CRSP NA12878 replicates.; * CRSP sensitivity: apply the (currently in-progress) hapmap sensitivity pipeline to CRSP data.; * cfDNA: run cfDNA samples and matched solid tumor samples (which we already have from Viktor) and run the concordance tool.; * FFPE: run FFPE and matched non-FFPE samples and run the concordance tool.; * tumor-only: run some TCGA samples with and without their matched normal and run the concordance tool. ---. @davidbenjamin commented on [Wed Mar 15 2017](https://github.com/broadinstitute/gatk-protected/issues/903#issuecomment-286795503). Update: CRSP sensitivity and specificity have been run several times, cfDNA is currently running for the first time. FFPE and tumor-only will use the same wdl as cfDNA, so we'll run those once cfDNA finishes. ---. @davidbenjamin commented on [Mon Mar 20 2017](https://github.com/broadinstitute/gatk-protected/issues/903#issuecomment-287675783). Update: everything done except FFPE and tumor-only. FFPE will use the same wdl as cfDNA.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2942:345,validat,validation,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2942,1,['validat'],['validation']
Security,@droazen I realized I should probably have exposed these methods for protected since we'd need to duplicated them in order to do broadinstitute/gatk-protected#1013. this includes the changes in #2630,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2631:43,expose,exposed,43,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2631,1,['expose'],['exposed']
Security,"@droazen commented on [Thu Apr 28 2016](https://github.com/broadinstitute/gatk-protected/issues/473). This capability would be useful if it turns out that the CNV tools (for example) need to be released much more frequently than the GATK as a whole. We don't want a release of the CNV tools to be blocked for a long time because something else in the toolkit (like the `HaplotypeCaller`) is not ready for release. . There could be a `properties` file in the jar that controls which tools are exposed via the command-line -- this way we could publish a jar that exposes only the CNV tools, for example. An alternative approach would be to use branching and cherry-picking to do this kind of selective release, or split the GATK into even more repositories, but I'm not sure those approaches would be preferable. ---. @droazen commented on [Thu Apr 28 2016](https://github.com/broadinstitute/gatk-protected/issues/473#issuecomment-215491991). This came out of a discussion between myself and @LeeTL1220 . ---. @lbergelson commented on [Thu Apr 28 2016](https://github.com/broadinstitute/gatk-protected/issues/473#issuecomment-215493945). So a gatk release would contain different sets of tools sometimes? Wouldn't that be confusing? It seems like it would be better to always release different jars, or version sets of tools independently and release jars with the latest good release of each individual set of tools. ---. @droazen commented on [Thu Apr 28 2016](https://github.com/broadinstitute/gatk-protected/issues/473#issuecomment-215494432). @lbergelson Well, we definitely still want there to be releases of the GATK toolkit in its entirety. If the CNV tools need to be released more frequently than this, they could be versioned/released separately and periodically incorporated into the toolkit-wide releases. ---. @droazen commented on [Thu Apr 28 2016](https://github.com/broadinstitute/gatk-protected/issues/473#issuecomment-215495326). To be clear, though, this is very much still in the ""t",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2851:492,expose,exposed,492,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2851,2,['expose'],"['exposed', 'exposes']"
Security,"@eddiebroad commented on [Thu Dec 01 2016](https://github.com/broadinstitute/gatk-protected/issues/806). An issue encountered with gatk-protected ""SparkGenomeReadCounts"" tool is a non-helpful ""null"" error message. A non-helpful error ""null"" message was printed by gatk-protected with the command-line below; during the course of trying to use it on/in FireCloud:. ```; + java -Xmx48g -jar fc-7ac504fc-7fe4-4bc1-89d3-7f16317b8ff4/eddie.jar SparkGenomeReadCounts --outputFile this.entity_id.coverage.tsv --reference fc-e2421839-93d5-4ed5-8861-593f00364e54/Homo_sapiens_assembly19.fasta --input firecloud-tcga-open-access/tutorial/bams/C835.HCC1143_BL.4.bam --binsize 5000; Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/cromwell_root/tmp; .....; ......; ......; proceeding with flushing remote transports.; ***********************************************************************. null. ***********************************************************************; ```. To try to make a more helpful error message appear I added a ""catch"" block after a call to runTool in instanceMainPostParseArgs in file CommandLineProgram.java and got a more helpful message about a missing dictionary file: . try {; return runTool();; } ; catch(Exception e) {; e.getStackTrace();; }. java.lang.RuntimeException: org.broadinstitute.hellbender.exceptions.UserException$MissingReferenceDictFile; 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:179); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:204); 	at org.broadinstitute.hellbender.Main.instanceMain(Main.java:95); 	at org.broadinstitute.hellbender.Main.instanceMain(Main.java:103); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:115); 	at org.broadinstitute.hellbender.Main.main(Main.java:152); Caused by: org.broadinstitute.hellbender.exceptions.UserException$MissingReferenceDictFile; 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2922:612,access,access,612,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2922,1,['access'],['access']
Security,"@jamesemery This is related to #6930 . The background is that PedigreeAnnotation is special-cased in GATK, which provides better command-line argument validation, and it will also be used to inject the PedigreeFile, create the SampleDB, etc. This is currently a subclass of InfoFieldAnnotation, and therefore cant be used for GenotypeFieldAnnotation. There shouldnt be this limitation, and this PR tried to address that. The way I propose to do this is to make InfoFieldAnnotation and GenotypeAnnotation into interfaces, with default methods where possible. The existing subclasses all switch from extending them to implementing them. This is generally a trivial difference, but it touches a lot of classes. . All existing classes that previously extended PedigreeAnnotation (formerly a subclass of InfoFieldAnnotation), now extend PedigreeAnnotation and implement InfoFieldAnnotation. This is a minimal difference, but it makes it possible for future classes to extend PedigreeAnnotation, and then implement GenotypeAnnotation. The only part this includes that I didnt like was the fact that the existing InfoFieldAnnotation overrides toString(), which I cant do in an interface. So I created AbstractInfoFieldAnnotation, and all existing InfoFieldAnnotation classes extend that. It's not currently clear to me how critical that override of toString() is. The weakness of this PR is that classes outside the GATK project that currently extend InfoFieldAnnotation would not inherit this. I could keep InfoFieldAnnotation a class as-is, and make a differently named interface behind it.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7041:151,validat,validation,151,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7041,2,"['inject', 'validat']","['inject', 'validation']"
Security,"@jamesemery, researcher has uploaded data to </humgen/gsa-scr1/pub/incoming/Exception_in_SplitNCigarReads.tgz> and has clarified a few other details within the forum thread, e.g. running ValidateSamFile `IGNORE=MISSING_TAG_NM IGNORE=MATE_NOT_FOUND` allows for validation. Thanks for looking into this. ---. Hello,. I am getting the following exception when running SplitNCigarReads on RNA-Seq data using GATK 4.0.8.1:; ```; java.lang.ArrayIndexOutOfBoundsException: 100; 	at org.broadinstitute.hellbender.tools.walkers.rnaseq.OverhangFixingManager.overhangingBasesMismatch(OverhangFixingManager.java:313); 	at org.broadinstitute.hellbender.tools.walkers.rnaseq.OverhangFixingManager.fixSplit(OverhangFixingManager.java:252); 	at org.broadinstitute.hellbender.tools.walkers.rnaseq.OverhangFixingManager.addReadGroup(OverhangFixingManager.java:209); 	at org.broadinstitute.hellbender.tools.walkers.rnaseq.SplitNCigarReads.splitNCigarRead(SplitNCigarReads.java:270); 	at org.broadinstitute.hellbender.tools.walkers.rnaseq.SplitNCigarReads.firstPassApply(SplitNCigarReads.java:180); 	at org.broadinstitute.hellbender.engine.TwoPassReadWalker.lambda$traverseReads$0(TwoPassReadWalker.java:62); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 	at java.util.stream",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5230:187,Validat,ValidateSamFile,187,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5230,2,"['Validat', 'validat']","['ValidateSamFile', 'validation']"
Security,"@kcibul reports that if the CNNScoreVariants python code throws an exception during async batch processing, the GATK tool hangs (specifically, it was happening when GATK was sending a . for a missing annotation, and the python code was trying to interpret that as a number and blowing up). It looks like this happens because `StreamingPythonScriptExecutor::waitForPreviousBatchCompletion` waits for the async write thread `Future` to complete first, before checking the fifo for an `ACK`/`NCK` (which is when the exception would be propagated). If the async write thread is blocked because the fifo is full because the python code isn't retrieving data because an exception was thrown, the java side will hang waiting for the `Future` complete. The solution is to reverse the order of the `waitForPreviousBatchCompletion` checking (ack first, then validate that the async write `Future` completes). There is a [branch]( https://github.com/broadinstitute/gatk/tree/cn_async_python_exception) with a test and a fix for the StreamingPythonExecutor, and a [separate branch](https://github.com/broadinstitute/gatk/tree/cn_cnn_exception) with a test for CNNScoreVariants that also has the executor fix. I need to verify that the CNNSCoreVariants test actually fails without the fix, and then this can be turned into a PR, which I'll do when I return from vacation.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7401:848,validat,validate,848,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7401,1,['validat'],['validate']
Security,"@kdatta @kgururaj It seems like we're losing rsID's in the input gvcf when we load them into genomics db. Is this deliberate to save space? Is it a bug? Is it a configuration option that isn't exposed by `GenomicsDBImport`? . I don't think it's important for production because they pass in a dbSNP at genotyping time so that can be recomputed, but it's causing issues in some of my tests.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2636:193,expose,exposed,193,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2636,1,['expose'],['exposed']
Security,"@ldgauthier this finishes what we started in #4858 and is necessary for the pileup-calls-on-bamouts MC3 validation. The cause is the same, in that Pair-HMM has a tiny bias in favor of shorter haplotypes and thus it prefers deletion haplotypes when reads end inside STRs. In #4858 we broke near-ties in favor of the reference; this PR fixes the case where two alt haplotypes share a SNV and one of them has a spurious deletion. One important sanity check was that when I set `cigarTerm` to zero in `AssemblyBasedCallerUtils.java` no tests broke. This means that the refactoring needed to set up the change didn't affect behavior. I looked at most of the sites where `PL`s and/or `DP`s changed in the integration test vcfs and in every case the difference was from a fake deletion that this PR fixed. I also went through the diff of the bamouts in IGV and found the same thing. Finally, the changes to test vcfs in `GenotypeGVCFsIntegrationTest` and `GenomicsDBImporterIntegrationTest` are a consequence of changes to the `HaplotypeCallerIntegrationTest` vcfs.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5359:104,validat,validation,104,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5359,1,['validat'],['validation']
Security,"@mbabadi commented on [Thu Jan 05 2017](https://github.com/broadinstitute/gatk-protected/issues/842). - [ ] carefully document the exposed parameters of gCNV, mark the tricky ones as advanced and document use case",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2928:131,expose,exposed,131,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2928,1,['expose'],['exposed']
Security,"@mbabadi commented on [Thu May 18 2017](https://github.com/broadinstitute/gatk-protected/issues/1058). - [ ] good choice of default parameters; - [ ] double-check assertion coverage in `CoverageModelArgumentCollection.validate()`; - [ ] if a model is provided, ARD and number of PCs must be overridden (currently, an exception is thrown if there is a discrepancy between model parameters and arguments). Relevant discussion:; **Mehrtash**: We may be able to get rid of a number of these parameters. Though, generally speaking, I'd rather expose more than less, with good default values and bold advanced disclaimers w/ proper documentation as you suggested. This is the case with sophisticated tools like HaplotypeCaller, StarAligner, etc. Soon enough, we will get strange errors from various users many of which can be resolved by changing a certain advanced parameter. Without exposing them, we will have to create patches for them and/or build custom jars.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2995:218,validat,validate,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2995,2,"['expose', 'validat']","['expose', 'validate']"
Security,@mbabadi commented on [Tue May 02 2017](https://github.com/broadinstitute/gatk-protected/issues/1021). - [ ] factor I/O methods out of `CoverageModelEMWorkspace` and to a new class; - [ ] shrink the exposed API; - [ ] rename/refactor `CopyRatioCallingMetadata` appropriately; - [ ] rename/move `MathObjectAsserts` to test,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2979:199,expose,exposed,199,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2979,1,['expose'],['exposed']
Security,"@meganshand Could you review this? It fixes most of the homoplasmic missed calls in broadinstitute/dsp-spec-ops#116. I reviewed all of the false positive that were introduced to our somatic validations when attempting to make this the default in non-mitochondria mode. Everything was due to mapping error, which I do not expect to be an issue in mitochondria, and not an inherent problem with recovering more dangling ends. You will still want to run this branch through some of your validations, however. In mitochondria mode it's the same as the dangling-1-29.jar that I shared earlier with you and Sarah.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5693:190,validat,validations,190,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5693,2,['validat'],['validations']
Security,"@ronlevine commented on [Fri Jul 15 2016](https://github.com/broadinstitute/gsa-unstable/issues/1438). ### Instructions. Follow up to #1432.; Remove the following code from `IntervalUtils. intervalFileToList()` when a new exome, correctly converted interval list (with no -1 length intervals) is released :. ```; if (interval.getStart() - interval.getEnd() == 1 ) { ; logger.warn(""Possible incorrectly converted length 1 interval : "" + interval);; }; ```. ---; ## Feature request; ### Tool(s) involved. Any tool using `IntervalUtils. intervalFileToList()` ; ### Description. Once this change is made, -1 length intervals will be validated and an exception will be thrown. ---. ---. @vdauwera commented on [Mon Nov 14 2016](https://github.com/broadinstitute/gsa-unstable/issues/1438#issuecomment-260495927). From what I understand of the referenced thread, the ""incorrect"" interval list may always be around, so we may never be able to just blow up on it. Would it perhaps be more viable to add an option to toggle the level of stringency, ie choose in the command line whether to blow up or skip on these invalid intervals? . ---. @vdauwera commented on [Mon Nov 14 2016](https://github.com/broadinstitute/gsa-unstable/issues/1438#issuecomment-260496001). @yfarjoun will want to opine on this, I think. . ---. @yfarjoun commented on [Mon Nov 14 2016](https://github.com/broadinstitute/gsa-unstable/issues/1438#issuecomment-260513266). I hope that when we move exomes to hg38 we will correct this silly thing; and a few decades later we will no need this code (hehe). Y. On Mon, Nov 14, 2016 at 6:19 PM, Geraldine Van der Auwera <; notifications@github.com> wrote:. > From what I understand of the referenced thread, the ""incorrect"" interval; > list may always be around, so we may never be able to just blow up on it.; > Would it perhaps be more viable to add an option to toggle the level of; > stringency, ie choose in the command line whether to blow up or skip on; > these invalid intervals?; > ; ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2520:629,validat,validated,629,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2520,1,['validat'],['validated']
Security,"@samuelklee @asmirnov239 @mbabadi I tried to run a 30-sample cohort through gCNV on all canonical chromosomes with 250bp bins sharded in 10k-interval blocks, but PostprocessGermlineCNVCalls gave the following error:. ```...; 19:26:14.967 INFO PostprocessGermlineCNVCalls - Analyzing shard 223...; 19:26:15.107 INFO PostprocessGermlineCNVCalls - Analyzing shard 224...; 19:26:15.259 INFO PostprocessGermlineCNVCalls - Analyzing shard 225...; 19:26:15.260 INFO PostprocessGermlineCNVCalls - Shutting down engine; [May 29, 2018 7:26:15 PM UTC] org.broadinstitute.hellbender.tools.copynumber.PostprocessGermlineCNVCalls done. Elapsed time: 3.34 minutes.; Runtime.totalMemory()=39753089024; ***********************************************************************. A USER ERROR has occurred: Bad input: Validation error occurred on line %d of the posterior file: Posterior probabilities for at at least one posterior record do not sum up to one.; ```. After inspecting the output from shard 225, it seems that the model starts producing nan values after ~1600 warmup iterations (looking at the ELBO log). This shard corresponds to a pericentromeric region chr3:91540501-94090250. . It would be nice to have the option to bypass this error in PostprocessGermlineCNVCalls. Here is the model config for the shard:. ```""p_alt"": 1e-06,; ""p_active"": 0.01,; ""cnv_coherence_length"": 10000.0,; ""class_coherence_length"": 10000.0,; ""max_copy_number"": 5,; ""num_calling_processes"": 1,; ""num_copy_number_states"": 6,; ""num_copy_number_classes"": 2; ""max_bias_factors"": 5,; ""mapping_error_rate"": 0.01,; ""psi_t_scale"": 0.001,; ""psi_s_scale"": 0.0001,; ""depth_correction_tau"": 10000.0,; ""log_mean_bias_std"": 0.1,; ""init_ard_rel_unexplained_variance"": 0.1,; ""num_gc_bins"": 20,; ""gc_curve_sd"": 1.0,; ""q_c_expectation_mode"": ""hybrid"",; ""active_class_padding_hybrid_mode"": 50000,; ""enable_bias_factors"": false,; ""enable_explicit_gc_bias_modeling"": false,; ""disable_bias_factors_in_active_class"": false; ""version"": ""0.7""; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4824:797,Validat,Validation,797,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4824,1,['Validat'],['Validation']
Security,"@takutosato @LeeTL1220 As mentioned, this change scraps all the p values and replaces it with a simple and cheap probabilistic model. All our validations either improve or stay the same and speed is much better. * Spurious active regions are reduced by almost 50%.; * DREAM 4 goes from 40 hours total CPU time to 20 hours. All DREAM genomes now take less than a day.; * Hapmap sensitivity is the same.; * DREAM sensitivities for SNVs and indels all go up a bit.; * Upon manual review we no longer make any obviously bad inactive calls, except for very long deletions, which remain an issue. @takutosato This is a higher priority review than either of the documentation PRs.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3304:142,validat,validations,142,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3304,1,['validat'],['validations']
Security,@takutosato Can you review this PR?. This is a community request and a useful feature for our MC3 validation.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4601:98,validat,validation,98,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4601,1,['validat'],['validation']
Security,"@takutosato I was checking the filter analysis outputs of every M2 validation and this filter hurts much, much more than it helps, probably because other developments have made it less necessary. Let's essentially turn it off by default.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5487:67,validat,validation,67,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5487,1,['validat'],['validation']
Security,"@takutosato If you look at the previous code for realignment to a read's best haplotype it assumes that the read start within the reference haplotype byte array is the same as its start within the best haplotype byte array (see the coordinate passed to leftAlignIndels). This means that left alignment would effectively be deactivated (since the bases didn't line up correctly) whenever the best haplotype contained indels before the read start. This also creates a rare but possible edge case bug where if a read cigar ends in an indel and we miscalculated the read's start in the reference we might get an array out of bounds exception within leftAlignIndels. The recent PR #6427, which fixed some bugs involving left alignment, actually exposed this bug, because the previous code simply skipped left alignment when it encountered an out of bounds index. The fix is in the line `final int readStartOnReferenceHaplotype = readStartOnReferenceHaplotype(rightPaddedHaplotypeVsRefCigar, readToHaplotypeSWAlignment.getAlignmentOffset());` The idea is that we know where the read starts on its best haplotype from the SW alignment. In order to find the corresponding reference base, we follow the haplotype-to-reference cigar up to the read start and count the number of reference bases consumed. For example, suppose the haplotype-to-reference cigar is 30M5D100M and the read starts at (0-indexed) position 50 on the haplotype. We want to know how many reference bases are consumed in order to consume 50 alt haplotype bases in this cigar. That is, we count the reference bases in the 30M5D20M leading sub-cigar, which is 55. Thus the reference start is 55. Conversely, if the haplotype-to-reference cigar were 30M5I100M the read would start after 30M5I15M, with 45 reference bases consumed.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6461:740,expose,exposed,740,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6461,1,['expose'],['exposed']
Security,"@takutosato Since this is an unsupported script that I have already tested to make sure results are the same, don't spend much time on it. Here's the summary:. * Put sub-sampling of hapmap (the most expensive part and a one-time cost because the samples are the same every time) into its own wdl.; * Put the rest of generating the truth into the same wdl as the sensitivity validation. This will make things simpler for the TAG team.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3379:374,validat,validation,374,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3379,1,['validat'],['validation']
Security,"@takutosato The extra strength of normal reads informing the ref allele's annotations improves results (very) slightly in all of our validations. The deeper reason for this change is in anticipation of multi-sample mode, where filtering based on a single INFO field will be simpler and probably statistically more powerful than filtering on a bunch of separate genotype fields.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5518:133,validat,validations,133,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5518,1,['validat'],['validations']
Security,@takutosato These are the changes I made for the most recent GP validation.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3171:64,validat,validation,64,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3171,1,['validat'],['validation']
Security,@takutosato This change doesn't hurt sensitivity in our validations and made M2 25% faster. We were getting a lot of active regions based on single substitution errors in overlapping reads.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5078:56,validat,validations,56,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5078,1,['validat'],['validations']
Security,"@takutosato This dramatically improves `CalculateContamination` by giving more care to distinguishing hom alts from hets. It makes an especially big difference in our tumor-only HCC1143 validations, where the accuracy is now very good (and BTW, ContEst gets these all completely wrong even *with* a matched normal). It also makes the tool work better in targeted panels where there might not be enough hom alt sites by adding a backup hom ref mode that gets triggered automatically. This is based on a Broadie request. I will file a separate issue to update the docs.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5413:186,validat,validations,186,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5413,1,['validat'],['validations']
Security,@takutosato This lets `ValidateBasicSomaticShortMutations` optionally annotate the `eval` vcf with validation `INFO` fields in addition to the standard output of a tsv. Having a vcf is more convenient for some things in MC3.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4999:23,Validat,ValidateBasicSomaticShortMutations,23,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4999,2,"['Validat', 'validat']","['ValidateBasicSomaticShortMutations', 'validation']"
Security,"@takutosato This uses minor allele fraction segmentation, which was already done internally in `CalculateContamination`, to improve tumor-only calling a lot. I also sw modest improvements in some tumor-normal validations. Also, @chandrans @sooheelee this hopefully does away with the problems with `af-of-alleles-not-in-resource` by deriving a defensible default that doesn't result in all calls in tumor-only mode getting filtered.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4509:209,validat,validations,209,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4509,1,['validat'],['validations']
Security,@takutosato Two quick edge cases and new unit tests. These were exposed when fixing other bugs.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6518:64,expose,exposed,64,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6518,1,['expose'],['exposed']
Security,"@tedsharpe @cwhelan please review. - Adds MarkDuplicatesReadFilter (to replace MarkedOpticalDuplicateReadFilter). MarkedOpticalDuplicateReadFilter will be removed in a subsequent PR because the Filter tool currently uses it.; - Changed some types (short to int, float to double) in the DUST algorithm; - Adds HostAlignmentReadFilter for filtering sufficiently well-mapped host reads. The helper function is there to run the test on supplementary alignments. I chose not to expose this as a GATK filter because the definitions of coverage and identity used here could be different than what some users would expect. @lbergelson Addressed your comments from the other branch:; - Added docstring to AmbiguousBaseReadFilter argument; - Made filterOpticalOnly an argument; - Argument variables changed from uppercase to lowercase; - See above regarding the duplicates filters",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2665:473,expose,expose,473,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2665,1,['expose'],['expose']
Security,"@tedsharpe please review. - SVKmerizer takes in an integer specifying the spacing between between kmers. This is is an effective way to reduce the kmer set size without affecting sensitivity much.; - SVKmerShort - added masking function that returns a copy of the current kmer after deleting bases at the specified positions; - Reworded some error messages about kmer length; - Moved and added some hashing functions to SVUtils, which will be used in another PR for the long-typed set classes and de-duplication filter.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2662:399,hash,hashing,399,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2662,1,['hash'],['hashing']
Security,@thebkaufman1995 encountered the following warning when trying to use TSV count files in the gCNV pipeline:. ```; HDF5-DIAG: Error detected in HDF5 (1.8.14) thread 0:; #000: /mnt/scr1/abyrne/HDFJava-platypus-2.11/native/HDF5-prefix/src/HDF5/src/H5F.c line 604 in H5Fopen(): unable to open file; major: File accessibilty; minor: Unable to open file; #001: /mnt/scr1/abyrne/HDFJava-platypus-2.11/native/HDF5-prefix/src/HDF5/src/H5Fint.c line 1085 in H5F_open(): unable to read superblock; major: File accessibilty; minor: Read failed; #002: /mnt/scr1/abyrne/HDFJava-platypus-2.11/native/HDF5-prefix/src/HDF5/src/H5Fsuper.c line 277 in H5F_super_read(): file signature not found; major: File accessibilty; minor: Not an HDF5 file; ```. My guess is this is because we first try to open counts files as HDF5 and then fall back to TSV (catching the relevant exception). Perhaps slightly different versions of the HDF5 library result in these warnings being emitted.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4482:307,access,accessibilty,307,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4482,3,['access'],['accessibilty']
Security,"@vdauwera reported this here #950 :. > Can't seem to do git clone https://github.com/broadinstitute/hellbender/. ```; wmd16-c9e:codespace vdauwera$ git clone http://github.com/broadinstitute/hellbender/; Cloning into 'hellbender'...; remote: Counting objects: 22221, done.; remote: Compressing objects: 100% (142/142), done.; remote: Total 22221 (delta 47), reused 4 (delta 4), pack-reused 22046; Receiving objects: 100% (22221/22221), 36.63 MiB | 3.58 MiB/s, done.; Resolving deltas: 100% (9903/9903), done.; Checking connectivity... done.; Downloading src/test/resources/large/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.bam (76.16 MB); Username for 'http://github.com': vdauwera; Password for 'http://vdauwera@github.com': ; Error accessing media: src/test/resources/large/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.bam (6b1304800e60c0ac0358df137bdad48b7857a36465b04fef3fbbb09380f04746). Errors logged to /Users/vdauwera/codespace/hellbender/.git/lfs/objects/logs/20151005T220016.510795175.log.; Use `git lfs logs last` to view the log.; Downloading src/test/resources/large/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.bam.bai (11.25 KB); Username for 'http://github.com': ; ```. > Looks like I'm failing to download large test files. Do I need to be on VPN for this to work? Or is it expected and I should ignore it?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/952:675,Password,Password,675,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/952,2,"['Password', 'access']","['Password', 'accessing']"
Security,"@vdauwera we should modify the M2 WDLs. ; @davidbenjamin this will improve your sensitivity. Currently Mutect2 uses the MateOnSameContigOrNoMappedMateReadFilter filter that filters out any paired read whose mate maps to a different contig. This filter, if I recall correctly, used to be the hidden filter in HaplotypeCaller code that could not be turned off. It necessitated that I remove 0x1 flags in the GRCh38 tutorial (see section 6.1 of <https://gatkforums.broadinstitute.org/gatk/discussion/8017/>) so as to be able to call variants associated with a sample with an alternative haplotype. This filter is now exposed so that users can disable it. In addition to disabling this filter for ALT-aware data, I recommend we turn it off by default for somatic analyses, for any reference. This allows us (i) to call on ALT-aware mappings if data is such and (ii) call on SNPs and indels generated by putative structural variants that go _across contigs_. I know that this filter is active in the GATK4.beta.3-Mutect2 (see last line):; ```; WMCF9-CB5:align shlee$ gatk-launch Mutect2 -R ~/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -I hcc1143_N_subset500.bam -tumor HCC1143_normal -O 1_normalforpon.vcf.gz; Using GATK jar /Applications/genomicstools/gatk/gatk-4.latest/gatk-package-4.beta.3-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -Dsnappy.disable=true -jar /Applications/genomicstools/gatk/gatk-4.latest/gatk-package-4.beta.3-local.jar Mutect2 -R /Users/shlee/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -I hcc1143_N_subset500.bam -tumor HCC1143_normal -O 1_normalforpon.vcf.gz; 19:26:43.105 INFO NativeLibraryLoader - Loading libgkl_compression.dylib from jar:file:/Applications/genomicstools/gatk/gatk-4.latest/gatk-package-4.beta.3-local.jar!/com/intel/gkl/native/libgkl_compression.dylib; [August 24, 2017 7:26:43 PM EDT] Mutect2 --tumorSampleNam",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3514:614,expose,exposed,614,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3514,1,['expose'],['exposed']
Security,A quick and dirty implementation. The on thing that needs extra scrutiny is going to be the various conditions/failure states in the validate method. I think i caught most of the cases but there might be a gap somewhere.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8724:133,validat,validate,133,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8724,1,['validat'],['validate']
Security,"A quick patch to help out the Variants team, which is struggling with a problematic callset. Note that a similar regularization to the effective number per component probably should have been applied to solve the issue in https://github.com/broadinstitute/gatk/pull/6425. I'm not sure if the lack of this regularization will still lead to convergence issues, but I would hope that the fix that was implemented instead (treating vanishing components as a special case and skipping computation) suffices. As discussed there, we may also want to eventually remove the idiosyncratic finalize step; it’s likely this is the source of issues here, since the correct Bayesian M step is already regularized by the prior. The covariance regularization term added here is standard (c.f. e.g. https://github.com/scikit-learn/scikit-learn/blob/7e1e6d09bcc2eaeba98f7e737aac2ac782f0e5f1/sklearn/mixture/_gaussian_mixture.py#L154), but it may result in non-negligible changes to VQSLODs. As just discussed with the Variants team, we can probably use the WARP validation to convince ourselves that results are functionally equivalent. I updated the exact-match tests without much close examination (by simply forcing IntegrationTestSpec.assertEqualTextFiles to overwrite the old expected files), so someone may want to sanity check them. There were also a few more interactions between the integration tests for different tools than I anticipated. Some tests use output generated by an upstream tool as input and break encapsulation.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7709:1043,validat,validation,1043,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7709,1,['validat'],['validation']
Security,"A seemingly large change PR, but most changes are trivial.; The non-trivial part:. * a new tool `StructuralVariantionDiscoveryPipelineSpark` to run the whole process of SV discovery, by delegating works to `FindBreakpointEvidenceSpark` and `DiscoverVariantsFromContigAlignmentsSAMSpark`, both of which are refactored to accommodate the new tool;; * class `AlignmentRegion` is effectively moved into a new class `AlignedAssembly` (named quite close to the existing class `AlignedAssemblyOrExcuse` but will be moved into a different sub-package in a sequential PR).; * integration tests (local mode and on MiniClusters/hdfs) for all 5 major tools `FindBreakpointEvidenceSpark`, `DiscoverVariantsFromContigAlignmentsSAMSpark`, `StructuralVariantionDiscoveryPipelineSpark`, `AlignAssembledContigsSpark` and `DiscoverVariantsFromContigAlignmentsSGASpark`; a draw back is these integration tests do not test correctness of results but simple tests if these tools run.; * various unit tests. The two paths involving use of Fermi-lite are tested to be running and generating compatible results. The path involves using SGA as the assembler is also running but generates significantly less variants. (see attached run logs).; [differentVersions.txt](https://github.com/broadinstitute/gatk/files/956271/differentVersions.txt). The access levels of the various classes and methods are not optimal now because a serial PR that simply repackaging these classes (hence access levels must be changed) is expected to be generated immediately after this PR is approved.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2621:1321,access,access,1321,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2621,2,['access'],['access']
Security,"A user rightly [points out](http://gatkforums.broadinstitute.org/gatk/discussion/comment/32631#Comment_32631) that different versions of HaplotypeCaller may produce GVCFs that are not directly compatible, causing weirdness when you joint-genotype them with GenotypeGVCFs. . Obviously this is primarily a data management problem (user should control what's in their pipeline) -- but it would be good to provide an additional safety layer by having GenotypeGVCFs, CombineGVCFs or whatever demon is used to invoke TileDB at least emit a WARN message if they see GVCFs produced by different versions of HC within the same input cohort. . Note that the VCF version number is not directly useable for this purpose since changes in the contents of GVCFs can arise within the same version of VCF spec. Also, one could argue that the GVCFs really should all be produced using exactly the same command line arguments -- but validating the entire command line would probably be overkill...",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2129:914,validat,validating,914,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2129,1,['validat'],['validating']
Security,"A12878_S1_md.bam --output hc_variants_7.vcf --bam-output realigned_slice_7.bam --max-reads-per-alignment-start 1000 --min-base-quality-score 0 --minimum-mapping-quality 0 --disable-read-filter MappingQualityReadFilter --disable-read-filter MappingQualityAvailableReadFilter --disable-read-filter NotSecondaryAlignmentReadFilter --disable-read-filter NotDuplicateReadFilter --disable-read-filter PassesVendorQualityCheckReadFilter --disable-read-filter NonZeroReferenceLengthAlignmentReadFilter --disable-read-filter GoodCigarReadFilter --disable-read-filter WellformedReadFilter`; [January 10, 2018 2:39:19 PM EST] org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCaller done. Elapsed time: 91.81 minutes.; Runtime.totalMemory()=7215251456; java.lang.IllegalArgumentException: Invalid interval. Contig:chr5 start:71357769 end:71357768; at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:687); at org.broadinstitute.hellbender.utils.SimpleInterval.validatePositions(SimpleInterval.java:61); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:37); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:49); at org.broadinstitute.hellbender.engine.AssemblyRegion.add(AssemblyRegion.java:335); at org.broadinstitute.hellbender.engine.AssemblyRegionIterator.fillNextAssemblyRegionWithReads(AssemblyRegionIterator.java:230); at org.broadinstitute.hellbender.engine.AssemblyRegionIterator.loadNextAssemblyRegion(AssemblyRegionIterator.java:194); at org.broadinstitute.hellbender.engine.AssemblyRegionIterator.next(AssemblyRegionIterator.java:135); at org.broadinstitute.hellbender.engine.AssemblyRegionIterator.next(AssemblyRegionIterator.java:34); at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.processReadShard(AssemblyRegionWalker.java:290); at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.traverse(AssemblyRegionWalker.java:271); at org.broadinstitute.hellbender.engine.GATKTool.doWo",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4120:1350,validat,validatePositions,1350,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4120,1,['validat'],['validatePositions']
Security,"ATE_INDEX false --CREATE_MD5_FILE false --GA4GH_CLIENT_SECRETS client_secrets.json --help false --version false --showHidden false --USE_JDK_DEFLATER false --USE_JDK_INFLATER false; Sep 16, 2019 2:33:15 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; [Mon Sep 16 02:33:15 UTC 2019] Executing as user@server on Linux 3.10.0-693.21.1.el7.x86_64 amd64; OpenJDK 64-Bit Server VM 1.8.0_192-b01; Deflater: Intel; Inflater: Intel; Provider GCS is available; Picard version: Version:4.1.3.0; [Mon Sep 16 02:33:22 UTC 2019] picard.analysis.CollectWgsMetrics done. Elapsed time: 0.16 minutes.; Runtime.totalMemory()=6996099072; To get help, see http://broadinstitute.github.io/picard/index.html#GettingHelp; java.lang.IllegalArgumentException: The requested position is not covered by this StartEdgingRecordAndOffset object.; at htsjdk.samtools.util.AbstractRecordAndOffset.validateOffset(AbstractRecordAndOffset.java:109); at htsjdk.samtools.util.EdgingRecordAndOffset$StartEdgingRecordAndOffset.getBaseQuality(EdgingRecordAndOffset.java:112); at picard.analysis.FastWgsMetricsCollector.excludeByQuality(FastWgsMetricsCollector.java:189); at picard.analysis.FastWgsMetricsCollector.processRecord(FastWgsMetricsCollector.java:144); at picard.analysis.FastWgsMetricsCollector.addInfo(FastWgsMetricsCollector.java:105); at picard.analysis.WgsMetricsProcessorImpl.processFile(WgsMetricsProcessorImpl.java:93); at picard.analysis.CollectWgsMetrics.doWork(CollectWgsMetrics.java:231); at picard.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:305); at org.broadinstitute.hellbender.cmdline.PicardCommandLineProgramExecutor.instanceMain(PicardCommandLineProgramExecutor.java:25); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:162); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:205); at org.broadinstitute.hellbender.Main.main(Main.java:291); Using",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6163:2502,validat,validateOffset,2502,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6163,1,['validat'],['validateOffset']
Security,ATK. ### Affected version(s); 4.1.4.1; ### Description ; when trying to compile with .gradlew bundle get the error above. * What went wrong:; Execution failed for task ':gatkDoc'.; > Javadoc generation failed. Generated Javadoc options file (useful for troubleshooting): '/usr/bin/gatk/build/tmp/gatkDoc/javadoc.options'. * Try:; Run with --info or --debug option to get more log output. Run with --scan to get full insights. * Exception is:; org.gradle.api.tasks.TaskExecutionException: Execution failed for task ':gatkDoc'.; at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter$3.accept(ExecuteActionsTaskExecuter.java:166); at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter$3.accept(ExecuteActionsTaskExecuter.java:163); at org.gradle.internal.Try$Failure.ifSuccessfulOrElse(Try.java:191); at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.execute(ExecuteActionsTaskExecuter.java:156); at org.gradle.api.internal.tasks.execution.ValidatingTaskExecuter.execute(ValidatingTaskExecuter.java:62); at org.gradle.api.internal.tasks.execution.SkipEmptySourceFilesTaskExecuter.execute(SkipEmptySourceFilesTaskExecuter.java:108); at org.gradle.api.internal.tasks.execution.ResolveBeforeExecutionOutputsTaskExecuter.execute(ResolveBeforeExecutionOutputsTaskExecuter.java:67); at org.gradle.api.internal.tasks.execution.ResolveAfterPreviousExecutionStateTaskExecuter.execute(ResolveAfterPreviousExecutionStateTaskExecuter.java:46); at org.gradle.api.internal.tasks.execution.CleanupStaleOutputsExecuter.execute(CleanupStaleOutputsExecuter.java:94); at org.gradle.api.internal.tasks.execution.FinalizePropertiesTaskExecuter.execute(FinalizePropertiesTaskExecuter.java:46); at org.gradle.api.internal.tasks.execution.ResolveTaskExecutionModeExecuter.execute(ResolveTaskExecutionModeExecuter.java:95); at org.gradle.api.internal.tasks.execution.SkipTaskWithNoActionsExecuter.execute(SkipTaskWithNoActionsExecuter.java:57); at org.gradle.api.internal.tasks,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6466:1093,Validat,ValidatingTaskExecuter,1093,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6466,1,['Validat'],['ValidatingTaskExecuter']
Security,AbstractGoogleClientRequest.buildHttpRequest(AbstractGoogleClientRequest.java:300); at shaded.cloud-nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419); at shaded.cloud-nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352); at shaded.cloud-nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.execute(AbstractGoogleClientRequest.java:469); at com.google.cloud.storage.spi.DefaultStorageRpc.get(DefaultStorageRpc.java:347); ... 17 more; Caused by:; java.net.SocketTimeoutException: Read timed out; at java.net.SocketInputStream.socketRead0(Native Method); at java.net.SocketInputStream.socketRead(SocketInputStream.java:116); at java.net.SocketInputStream.read(SocketInputStream.java:170); at java.net.SocketInputStream.read(SocketInputStream.java:141); at sun.security.ssl.InputRecord.readFully(InputRecord.java:465); at sun.security.ssl.InputRecord.read(InputRecord.java:503); at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:973); at sun.security.ssl.SSLSocketImpl.performInitialHandshake(SSLSocketImpl.java:1375); at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1403); at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1387); at sun.net.www.protocol.https.HttpsClient.afterConnect(HttpsClient.java:559); at sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.connect(AbstractDelegateHttpsURLConnection.java:185); at sun.net.www.protocol.http.HttpURLConnection.getOutputStream0(HttpURLConnection.java:1316); at sun.net.www.protocol.http.HttpURLConnection.getOutputStream(HttpURLConnection.java:1291); at sun.net.www.protocol.https.HttpsURLConnectionImpl.getOutputStream(HttpsURLConnectionImpl.java:250); at shaded.cloud-nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:77); at shaded.cloud-nio.com.google.api.client.http.HttpRequest,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2514:3795,secur,security,3795,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2514,1,['secur'],['security']
Security,Add CheckForNullColumns to and fixed ClinvarSignificance in VAT validation [VS-1156],MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8669:64,validat,validation,64,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8669,1,['validat'],['validation']
Security,Add NIO test that accesses public GCS data while not being authenticated,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5340:18,access,accesses,18,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5340,2,"['access', 'authenticat']","['accesses', 'authenticated']"
Security,Add VAT Validation check that aa_change and exon_number are consistentally set.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7850:8,Validat,Validation,8,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7850,1,['Validat'],['Validation']
Security,Add VAT validation rule #2 [VS-19],MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7374:8,validat,validation,8,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7374,1,['validat'],['validation']
Security,Add VAT validation rule #5 [VS-16],MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7365:8,validat,validation,8,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7365,1,['validat'],['validation']
Security,Add VAT validation rule #6 [VS-15],MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7373:8,validat,validation,8,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7373,1,['validat'],['validation']
Security,Add VAT validation rule #7 [VS-14] and validation rule #6 [VS-15],MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7379:8,validat,validation,8,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7379,2,['validat'],['validation']
Security,Add VDS Validation to the hail integration split,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8343:8,Validat,Validation,8,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8343,1,['Validat'],['Validation']
Security,Add a github action to run womtool validation on all WDLs,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7822:35,validat,validation,35,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7822,1,['validat'],['validation']
Security,Add a loop to the validation,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8732:18,validat,validation,18,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8732,1,['validat'],['validation']
Security,"Add a test that validates than an ambiguous interval query can be disambiguated by the user by providing the interval in a bed file; changes the error message to recommend this alternative; fixes an issue where the error message was displaying the entire interval query multiple times, rather than the specific contigs which make the query ambiguous.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4183:16,validat,validates,16,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4183,1,['validat'],['validates']
Security,Add a test to validate WDLs in the scripts directory.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7826:14,validat,validate,14,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7826,1,['validat'],['validate']
Security,"Add additional validation around duplicated rows in the VAT; <img width=""1418"" alt=""duplicate_AN_or_AC_values"" src=""https://user-images.githubusercontent.com/6863459/220667710-a416ab64-4f9b-475b-9268-ef7b86bfa81e.png"">. This has a successful run (except for one failure that is because it's being run on way less data); https://job-manager.dsde-prod.broadinstitute.org/jobs/07ddde58-ac0d-4229-9f96-d093f5c11682; The failed test is:; SpotCheckForAAChangeAndExonNumberConsistency. Perhaps we want to update this to not run this test if there are less than 10k samples?; Yes we do:; Here's the ticket for that:; https://broadworkbench.atlassian.net/browse/VS-878",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8175:15,validat,validation,15,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8175,1,['validat'],['validation']
Security,Add an argument to GATKTool and GATKSparkTool that allows sequence dictionary validation to be turned off,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1145:78,validat,validation,78,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1145,1,['validat'],['validation']
Security,Add annotation checks to ValidateVariants,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6272:25,Validat,ValidateVariants,25,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6272,1,['Validat'],['ValidateVariants']
Security,"Add argument to disable sequence dictionary validation, off by default",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1136:44,validat,validation,44,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1136,1,['validat'],['validation']
Security,"Add large runtime resource directory to lfs, and expose it to the Docker build.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4530:49,expose,expose,49,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4530,1,['expose'],['expose']
Security,Add optional summary table output to ValidateBasicSomaticShortMutations,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4982:37,Validat,ValidateBasicSomaticShortMutations,37,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4982,1,['Validat'],['ValidateBasicSomaticShortMutations']
Security,Add task for VAT validation #3,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7360:17,validat,validation,17,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7360,1,['validat'],['validation']
Security,Add task for VAT validation #4,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7363:17,validat,validation,17,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7363,1,['validat'],['validation']
Security,Add task for VAT validation #8 & 9,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7364:17,validat,validation,17,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7364,1,['validat'],['validation']
Security,"Add the gcs-connector as a GATK dependency, and write a test showing that GCS access with the Spark local runner works",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3125:78,access,access,78,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3125,1,['access'],['access']
Security,Add validation to SparkSharder to get better information about sequence dictionary errors,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2615:4,validat,validation,4,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2615,1,['validat'],['validation']
Security,"Addded abstract class MachineLearningUtils to provide an interface and; handle common tasks. These include loading data, splitting data into; training and test sets, cross-validation, and optimizing classifier; hyperparameters. Also added XGBoostUtils which provides a concrete implemention of; MachineLearningUtils (by wrapping xgboost4j) and serves as an example; of how to provide access to a 3rd-party machine learning library. Finally, added an example tool: ExampleTrainXGBoostClassifier. This; demonstrates a typical training use case of loading data, training a; classifier, assessing accuracy, and saving the classifier. It also; demonstrates a typical filtering use case of loading a saved classifer,; and using it to calculate probabilities or class labels. This is working towards issue 4922 by providing the tools necessary to; train classifiers in general, but does not provide tools to train a; BreakpointEvidence filter, so does not resolve it. Additionally, this; framework should eventually be extended to provide a bayesian; hyperparameter optimizer. One outstanding problem with these changes is that xgboost4j threading; does not appear to work on OSX, resulting in slower training. However,; it does work on linux.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5146:172,validat,validation,172,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5146,2,"['access', 'validat']","['access', 'validation']"
Security,Added `#` as a character to be sanitized by `VCFOutputRenderer`.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5817:31,sanitiz,sanitized,31,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5817,1,['sanitiz'],['sanitized']
Security,Added a github action to run womtool validation on all WDLs; Also fixed two wdls that were failing validation.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7822:37,validat,validation,37,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7822,2,['validat'],['validation']
Security,Added a test to validate WDLs in the scripts directory. (#7826),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7829:16,validat,validate,16,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7829,1,['validat'],['validate']
Security,"Added a workflow file for enabling the GitHub Action which processes PR comments to determine if they are meant to trigger and CARROT test, and then processes them if they are formatted in that way. BIG IMPORTANT NOTE: Before this is merged, we need to set two secrets for this repo:; - `CARROT_TOPIC_NAME`, which is the name of the Google Cloud PubSub topic that messages will be sent to if a comment should trigger a run, and; - `CARROT_SA_KEY`, which is the service account key JSON for the service account that has write access to the PubSub topic.; If this is merged before those are set, I'm fairly confident we're just gonna get an email saying the action failed each time someone posts a PR comment (CARROT or otherwise), which would be less than ideal. Closes #6916",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6917:525,access,access,525,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6917,1,['access'],['access']
Security,Added experimental tool and exposed some of the AllelicCNV file extension constants. I am adding the tools as requested. Minor additional changes.; @gtiao and @sooheelee . Closes #3196,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3198:28,expose,exposed,28,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3198,1,['expose'],['exposed']
Security,Added in code to change how the best transcript is determined.; Added `#` as a character to be sanitized by `VCFOutputRenderer`. (#5817); Fixes #5822,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5834:95,sanitiz,sanitized,95,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5834,1,['sanitiz'],['sanitized']
Security,Added map-style accessors to all concrete Funcotation classes (Funcotation.`getField`). Fixes #3919,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4176:16,access,accessors,16,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4176,1,['access'],['accessors']
Security,Added requester pays option to Mutect2 tasks that access bams,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6879:50,access,access,50,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6879,1,['access'],['access']
Security,Added the following methods to `GATKTool`:. - `getReferenceDataSource()`; - `getReadsDataSource()`; - `getFeatureManager()`. `Walker` inherits directly from `GATKTool` and overrides these methods to throw an exception if they are called. No walker should need to directly access the data.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4964:272,access,access,272,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4964,1,['access'],['access']
Security,Added validateSampleNameMap command line parameter; Added a unit test; Updated genomicsdb version to 0.6.3,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2733:6,validat,validateSampleNameMap,6,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2733,1,['validat'],['validateSampleNameMap']
Security,"Adding a new method `getVariantCacheLookAheadBases` to `VariantWalkerBase` which allows subclasses to set how far to look ahead when caching variants. This may help reduce memory use in GenotypeGVCFs. This also changes the side inputs to use FeatureDataSource.DEFAULT_QUERY_LOOKAHEAD_BASES which is `1000`, this is the value used by the other tools. I'm not sure if that's the right thing to do, but it makes variant walkers more consistent with other tools. Alternatively we could add a separate configuration method that lets tools change the side input value. We could also expose an optional parameter in the feature input that lets you set that on a per input basis if we need it. . This doesn't seem to have any negative effect on performance for genotypegvcfs, but it's hard to tell from short runs. It's also hard to tell if it's improving memory usage. It doesn't seem to make an appreciable difference at random places in the genome, but I'm hoping it will make a difference in very bad locations that have a lot of variation. Ideally our caches would be based on size rather than number of variants, but that's a more complicated change. fixes #3471",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3480:577,expose,expose,577,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3480,1,['expose'],['expose']
Security,"Adding validation to the SimpleInterval(String) constructor; Making GenomeLoc implement Locatable; Replacing all instances of SimpleInterval( locatable.getContig(), locatable.getStart(), locatable.getEnd()) with the new constructor. fixes #438 and #436",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/441:7,validat,validation,7,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/441,1,['validat'],['validation']
Security,"Adds a new ReadWalker tool, `RealignSoftClippedReads`, that realigns soft-clipped fragments using BWA. This tool is motivated by a specific artifact produced by Illumina DRAGEN v3.7.8 in which reads containing small indels are erroneously soft-clipped, often within mobile element contexts (LINE, SINE, ALU, SVA, etc). This is particularly problematic for mobile element insertion callers such as [Scramble](https://github.com/GeneDx/scramble) that rely on soft-clips for identifying potential insertion sites but do not perform a local assembly. In some cases, these soft-clipped reads are aligned to the incorrect region (confirmed by BLAT query and comparison to BWA alignments). An example of a false positive site produced by Scramble is shown below. <img width=""1008"" alt=""Screenshot 2023-11-16 at 2 09 45 PM"" src=""https://github.com/broadinstitute/gatk/assets/5686877/9d2c1dfd-9673-49f0-9372-c4c9cf6ffd9f"">. This PR includes the new tool and unit/integration tests and some minor refactoring to expose non-Spark BWA read mapping. This tool should be considered experimental until thorough benchmarking and analysis can be performed.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8588:1002,expose,expose,1002,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8588,1,['expose'],['expose']
Security,Adds a tool to sanitize reads. This tool will convert any bases that do not match the reference into bases that do match the reference using the CIGAR as a key for which bases to change. The qualities for bases that match the reference are preserved.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6653:15,sanitiz,sanitize,15,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6653,1,['sanitiz'],['sanitize']
Security,"Adds support for online documentation generation through Barclay (https://github.com/broadinstitute/gatk/issues/2211) via the gatkDoc gradle task. The first commit contains only annotation updates (to target selected classes as documentation targets). A more complete audit/update pass will need to be done; but we need some for now in order to be able to exercise the doc generation process. The second commit contains that actual code and templates for documentation, and the final one upgrades to a Barclay snapshot that has the necessary dependent classes.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2327:268,audit,audit,268,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2327,1,['audit'],['audit']
Security,"Adds updated tools for creating the host reference kmer set (PathSeqBuildKmers) and filtering reads that are low-quality, low-complexity, or come from the host (PathSeqFilterSpark). Sorry for the especially large size on this PR. **PathSeqBuildKmers tool**. Note this has been renamed from PathSeqKmerSpark. Input:; 1) Host reference FASTA; 2) False positive probability (0 create a hash set, >0 to create a Bloom filter); 3) Kmer length (1-31); 4) Kmer base indices to mask (optional). Output:; 1) Serialized kmer Hopscotch set (.hss) or Bloom filter (.bfi) file. For each reference record, the tool generates a list of long's containing the canonicalized/masked kmers. The result is a Collection<long[]> variable, which is then converted to either a PSKmerSet (Hopscotch set) or PSKmerBloomFilter, depending on the desired false positive probability. . The PSKmerSet/BloomFilter classes are basically wrappers for LargeLongHopscotchSet and LongBloomFilter, respectively. They both inherit PSKmerCollection, which provides a contains() function for querying new kmers for set membership and makes loading the kmers for filtering more convenient. These classes also store the kmer size, mask, and false positive probability. They also handle canonicalization/masking on queried kmers. **PathSeqFilterSpark tool**. Input:; 1) Input BAM; 2) Host kmer set file (optional); 3) Host reference bwa image (optional). Output:; 1) BAM containing paired reads that still have mates; 2) BAM containing unpaired reads / reads whose mates were filtered out; 3) Metrics file containing read counts and elapsed wall time at each step (optional). Filtering steps performed on each read:; - If the user sets the --isHostAligned, the read will first be filtered if it is aligned sufficiently well ; - Alignment info is stripped; - A series of quality filters (same as in the previous version of this tool); - Kmerized and filtered out if at least a threshold number of kmers are in the host set (default 1); - Aligned t",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3115:383,hash,hash,383,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3115,1,['hash'],['hash']
Security,"After #5887 goes in. PreprocessIntervals should still allow the use of IntervalMergingRule.OVERLAPPING_ONLY, and we should validate early that intervals are non-overlapping elsewhere.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5891:123,validat,validate,123,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5891,1,['validat'],['validate']
Security,"All that needs to be done here is prove that GenomicsDBImport can run on an 11k sample callset over a single interval without exploding or running out of memory. We don't need to hyper-optimize memory usage, or optimize the instance types for cost, etc. We should also probably pair it with GenotypeGVCFs in a single WDL script, to make sure that tool doesn't blow up either. Once done, we should share the settings we used with red team. Details on how to access the 11k sample set are in a Google doc that has been shared privately.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2633:457,access,access,457,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2633,1,['access'],['access']
Security,"All walkers now have comprehensive sequence dictionary validation performed on their inputs (via the `GATKTool` base class, which is aware of all primary tool inputs and so is able to perform this check automatically -- see `GATKTool.validateSequenceDictionaries()`). At present, we need to do this validation manually in dataflow tools, but it would be nice if we could get it to happen automatically in a base class as it does on the walker side of things.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/669:55,validat,validation,55,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/669,3,['validat'],"['validateSequenceDictionaries', 'validation']"
Security,Also refactored the `VcfOutputRenderer` sanitization code. Fixes #5671,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5817:40,sanitiz,sanitization,40,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5817,1,['sanitiz'],['sanitization']
Security,"Also, update code to use Hellbender's IOUtils instead of htsjdk's IOUtil; for these checks. We have both, presumably there's a reason Hellbender has their own and we should use them (for example, we can only add the hinting in our own). Sample error now:. A USER ERROR has occurred: Couldn't read file gs://foo/sam/m54113_160913_184949.scraps.beginning.sam. Error was: Error 403: jp-testing@redacted.iam.gserviceaccount.com does not have storage.objects.get access to foo/sam/m54113_160913_184949.scraps.beginning.sam. Potential cause: incorrect Google Cloud configuration; see instructions in the README. Fixes: #5468",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5477:458,access,access,458,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5477,1,['access'],['access']
Security,Also:; - Cleaned up headers in some test resources.; - Made sequence-dictionary checking more uniform across all CNV tools.; - Fixed an NPE bug in PlotModeledSegments input validation.; - Improved documentation regarding sex chromosomes in the ModelSegments pipeline.; - Miscellaneous boy-scout activities. Closes #3916.; Closes #3951.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4268:173,validat,validation,173,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4268,1,['validat'],['validation']
Security,Always have git hash in Docker tags to avoid collisions [VS-1086],MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8549:16,hash,hash,16,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8549,1,['hash'],['hash']
Security,"An optimization introduced in https://github.com/broadinstitute/gatk/pull/5466 was removed in https://github.com/broadinstitute/gatk/pull/6885. The latter exposed Smith-Waterman parameters, allowing them to be changed from their default values and thus to possibly violate conditions assumed by the former. We could restore the optimization if we added explicit checks of these conditions.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7441:155,expose,exposed,155,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7441,1,['expose'],['exposed']
Security,"Any objections to exposing SW parameters to the command line? This looks like something we will want to explore for malaria. I'm also not convinced that our current parameters have been justified and/or optimized in any documented way. A few questions:. 1) There are 3 sets of parameters used in various ways, a) haplotype-to-reference alignment, b) read-to-haplotype alignment, and c) dangling ends. Any chance we can evaluate the effect of consolidating at least c), if not all sets? @emeryj I was told that you might be the one to ask about c) in particular; @davidbenjamin speculated that these might effectively yield STR-specific parameters. In general, if there are any quick and readily available evaluations (which ideally include variant normalization), I'd appreciate pointers to them. 2) Any suggestions on what the resulting command line should look like? I don't want to add 12 parameters, in the worst case. I also think that using integer arrays might be clunky. Perhaps I can suggest the use of args files in the doc string---although I don't think that those are expanded in the `##GATKCommandLine`, right?. 3) Should I touch `SWOverhangStrategy` at all? See e.g. https://github.com/broadinstitute/gatk/issues/6576. It looks like we thread both this and the `SWParameters` through many methods and classes, so the code could stand quite a bit of refactoring, but for now I will stick to the minimal changes required to expose. @droazen @ldgauthier any thoughts?. In some simple experiments of changing the a) parameters (from the somewhat questionable `NEW_SW_PARAMETERS = new SWParameters(200, -150, -260, -11)` back to `STANDARD_NGS = new SWParameters(25, -50, -110, -6)`), I've seen that there are non-negligible differences in the calls (beyond representation) at the few percent level, as well as changes in annotations.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6863:1437,expose,expose,1437,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6863,1,['expose'],['expose']
Security,Any test that tries to access a bucket seems to stall indefinitely. I think this has to do with gcloud not accepting our credentials file on travis. I suspect it's trying to open a web browser. I suspect it may need to be reconfigured with a service account key and an explicit authorization step before the build.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/444:23,access,access,23,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/444,2,"['access', 'authoriz']","['access', 'authorization']"
Security,"Apologies for re-opening, this is becoming an increasing issue for those looking to run GATK via Docker or singularity in a multi-tenant environment. Currently:; Docker creation and images provided run with a default user root within the container. Dropping privileges within the instance to a gatk user, would reduce the risk of inadvertent data access or harm when run in a multi-user environment. A possible solution:; Add something like the following within the Dockerfile:; RUN useradd -ms /bin/bash dev; WORKDIR /home/dev; USER dev. Providing:; Making changes like the above would bring the GATK docker container into line with best practice and greatly assist sites which are also looking to apply minimum standards enforcable through 3rd party applications, i.e. Aqua etc.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5959:347,access,access,347,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5959,1,['access'],['access']
Security,"Apple is going to turn on Software Signing with OSX Catalina very soon (sometime this fall or so). While signing GATK will be fine, theoretically we have to sign all of the dynamic libraries that we leverage. OpenJDK did a release a while ago with these security features on and it was a major fiasco. We need to research what the signing requirements are and how they will affect the GATK release process.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6756:254,secur,security,254,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6756,1,['secur'],['security']
Security,ArrayIndexOutOfBoundsException: -87 in ValidateVariants,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6911:39,Validat,ValidateVariants,39,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6911,1,['Validat'],['ValidateVariants']
Security,"As @droazen and I have been investigating, providing the `--gcs-project-for-requester-pays` argument when accessing buckets where the user does not have storage.bucket.get permission will cause failures. This clarifies the argument usage.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6594:106,access,accessing,106,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6594,1,['access'],['accessing']
Security,As I discovered when making the fix in PR #2021 bam files will fail validation if overhang clipping is used when running SplitNCigarRead because the mate reference start position might be changed. The tool can be refactored to perform a second walker pass over the reads in order to identify locations where this will be a problem by checking for sites where the primary read gets clipped by OverhangClippingManager.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2075:68,validat,validation,68,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2075,1,['validat'],['validation']
Security,"As a compromise fix, I have added a check to the validation code that asserts the dictionaries actually exist to save ourselves the potential null-pointer exceptions. @droazen . Fixes #6142",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6147:49,validat,validation,49,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6147,1,['validat'],['validation']
Security,"As a stopgap solution to allow `gs://` access on Spark with the local runner, let's add the `gcs-connector` as a project dependency, and craft a test case the runs a simple Spark tool like `PrintReadsSpark` using the local runner with GCS inputs and outputs. I've already started this in the branch https://github.com/broadinstitute/gatk/compare/dr_fix_gcs_spark_writing, but it's not working yet since the gcs-connector requires some extra authentication-related setup.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3125:39,access,access,39,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3125,2,"['access', 'authenticat']","['access', 'authentication-related']"
Security,"As discussed in https://github.com/broadinstitute/gatk/issues/2471#issuecomment-358040921, we need to refactor `GATKTool` so that all non-Spark tools can comfortably extend it rather than extending `CommandLineProgram` directly, as some tools currently do. In particular, we need to:. * Provide a mechanism for subclasses to selectively disable engine-wide arguments such as `-I` completely (and also the ability to override with their own version of an argument). * Access necessary datasources outside of the engine package. * Add the ability to register input metadata such as sequence dictionaries, so that standard validation rules can be enforced across the toolkit. * Add the ability for each tool to change the defaults for engine arguments such as `--interval-merging-rule`",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4341:467,Access,Access,467,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4341,2,"['Access', 'validat']","['Access', 'validation']"
Security,"As part of #8083 we are drastically rewriting the entire Pileup-Caller infrastructure for DRAGEN-GATK. In doing so we have largely neglected its original functionality in Mutect2 and some of the changes (namely the re-factoring of that code to now happen after trimming like in with the GGA code) are going to impact the overall results for pileupcalling. It seems that we never added a real test of this functionality and its unclear to me currently what the meterics are that we want to assure ourselves that its working as intended. In #8083 I have checked that the code is hooked up manually, but its not clear to me what a proper test looks like for mutect without re-hashing the test samples that were being used in the bacterial project. I'm a little skeptical about adding a test that just asserts ""these results were different somehow"" and yet thats essentially the sort of test i would like and that would have saved me here. I would really like to have something better in place, especially if we are going to keep sharing the pileup-calling code between HC and M2 going forward.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8242:673,hash,hashing,673,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8242,1,['hash'],['hashing']
Security,"As part of my work in the Pipeline Dev team, I created 2 GATK images to address issue discussed [here](https://github.com/broadinstitute/gatk/issues/8684) (ie. having too many docker layers, we hit ACR limits very quickly). The images are in terrapublic, a premium-tier ACR and is publicly accessible. I made two images, one is squashed to just 1 layer, the other is reduced to just 12 layers (from the original 45). With these changes and the fact that terrapublic is on [premium](https://learn.microsoft.com/en-us/azure/container-registry/container-registry-skus#registry-throughput-and-throttling) tier, the maximum docker pulls per minute becomes 833 (ie. 10k readOps / 12 layers) for the reduced-layers image and 10,000 for the squashed one. We have yet to test these in our pipelines but I anticipate the squashed version to be slower since it won’t be able to take advantage of any parallel pulls or caching, hence the two versions to allow pipeline devs to decide which one is better for their use-case.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8808:290,access,accessible,290,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8808,1,['access'],['accessible']
Security,"As per the discussion in https://github.com/broadinstitute/gatk/issues/3246, we need to expose the `IntervalArgumentCollection.IntervalMergingRule` setting as a command-line argument in `IntervalArgumentCollection`. This was exposed in GATK3 as `--interval_merging`/`-im` (see GATK3's `IntervalArgumentCollection`)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3251:88,expose,expose,88,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3251,2,['expose'],"['expose', 'exposed']"
Security,"As reported by @jkobject testing our latest gatk-nightly image, certain non-requester-pays accesses fail with the latest google-cloud-nio version (0.123.23) when `--gcs-project-for-requester-pays` is specified. . The specific issue appears to be checks for the existence of non-existent files in non-requester-pays buckets when `--gcs-project-for-requester-pays` is set, resulting in a ""User project specified in the request is invalid"" error:. ```; code: 400; message: User project specified in the request is invalid.; reason: invalid; location: null; retryable: false; com.google.cloud.storage.StorageException: User project specified in the request is invalid.; 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.translate(HttpStorageRpc.java:233); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.list(HttpStorageRpc.java:376); 	at com.google.cloud.storage.StorageImpl.lambda$listBlobs$11(StorageImpl.java:391); 	at com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:105); 	at com.google.cloud.RetryHelper.run(RetryHelper.java:76); 	at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:50); 	at com.google.cloud.storage.Retrying.run(Retrying.java:51); 	at com.google.cloud.storage.StorageImpl.listBlobs(StorageImpl.java:388); 	at com.google.cloud.storage.StorageImpl.list(StorageImpl.java:359); 	at com.google.cloud.storage.contrib.nio.CloudStoragePath.seemsLikeADirectoryAndUsePseudoDirectories(CloudStoragePath.java:118); 	at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.checkAccess(CloudStorageFileSystemProvider.java:743); 	at java.nio.file.Files.exists(Files.java:2385); 	at htsjdk.tribble.util.ParsingUtils.resourceExists(ParsingUtils.java:418); 	at htsjdk.tribble.TribbleIndexedFeatureReader.loadIndex(TribbleIndexedFeatureReader.java:162); 	at htsjdk.tribble.TribbleIndexedFeatureReader.hasIndex(TribbleIndexedFeatureReader.java:228); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSourc",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7716:91,access,accesses,91,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7716,1,['access'],['accesses']
Security,Audit CRAM code in htsjdk for Path/NIO support,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5209:0,Audit,Audit,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5209,1,['Audit'],['Audit']
Security,Audit Funcotator FeatureCache access patterns,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5143:0,Audit,Audit,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5143,2,"['Audit', 'access']","['Audit', 'access']"
Security,Audit GenomeLocParser overloads for validation arguments.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7300:0,Audit,Audit,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7300,2,"['Audit', 'validat']","['Audit', 'validation']"
Security,Audit MuTect2 headers to describe fragment vs read annotations,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7904:0,Audit,Audit,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7904,1,['Audit'],['Audit']
Security,Audit Mutect2/HC FeatureCache access patterns,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5148:0,Audit,Audit,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5148,2,"['Audit', 'access']","['Audit', 'access']"
Security,Audit R package dependencies,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3047:0,Audit,Audit,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3047,1,['Audit'],['Audit']
Security,Audit ReadClipper code (and clients) to make sure that it can handle empty reads,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4204:0,Audit,Audit,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4204,1,['Audit'],['Audit']
Security,Audit ReadsDataSource for bugs related to header merging and contig indices,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1674:0,Audit,Audit,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1674,1,['Audit'],['Audit']
Security,Audit tools with tests with suspicious FeatureCache misses,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5895:0,Audit,Audit,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5895,1,['Audit'],['Audit']
Security,Audit use of Utils random generators and refactor if necessary.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6112:0,Audit,Audit,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6112,1,['Audit'],['Audit']
Security,Authenticate with dockerhub when running tests on travis,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7102:0,Authenticat,Authenticate,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7102,1,['Authenticat'],['Authenticate']
Security,Authenticate with github from Travis,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3179:0,Authenticat,Authenticate,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3179,1,['Authenticat'],['Authenticate']
Security,Authenticating to dockerhub in travis build,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7204:0,Authenticat,Authenticating,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7204,1,['Authenticat'],['Authenticating']
Security,Authentication to access private GCS buckets,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2394:0,Authenticat,Authentication,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2394,2,"['Authenticat', 'access']","['Authentication', 'access']"
Security,Automatic sequence dictionary validation for spark tools,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/669:30,validat,validation,30,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/669,1,['validat'],['validation']
Security,"Based on the TODO that was in ReadsDataSource.java, I exposed a SamReaderFactory parameter for ReadsDataSource rather than limit it to just validation stringency. Whats the right protocol for adding a test that uses a test file from another package (I'm reaching into the picard test data for a data file for an engine test). Alternatively, is there a better way to test this change ?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/565:54,expose,exposed,54,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/565,2,"['expose', 'validat']","['exposed', 'validation']"
Security,Basic Validator,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3755:6,Validat,Validator,6,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3755,1,['Validat'],['Validator']
Security,Basic testing of mutect2-replicate-validation.wdl still incomplete,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2948:35,validat,validation,35,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2948,1,['validat'],['validation']
Security,"Before our cromwell/WDL tests even start to build the docker image, we could run womtool to validate the WDL. This will catch some obvious errors in much less time.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4802:92,validat,validate,92,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4802,1,['validat'],['validate']
Security,"Bumps commons-io:commons-io from 2.7 to 2.14.0. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=commons-io:commons-io&package-manager=gradle&previous-version=2.7&new-version=2.14.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself); You ca",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/9003:296,secur,security-vulnerabilities,296,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/9003,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,BwaSpark does inappropriate validation of bam sequence dictionary against reference,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2121:28,validat,validation,28,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2121,1,['validat'],['validation']
Security,"BwaSpark is using WELLFORMED as it's read filter. This includes a number of checks that the reads validate against the header. However, most unaligned sam files are likely to have no or incomplete headers. This causes many reads to be unexpectedly filtered. We should define a better filter criteria BwaSpark.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2120:98,validat,validate,98,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2120,1,['validat'],['validate']
Security,"CAL_DIRS in YARN).; 10:33:06.427 INFO ResourceUtils - ==============================================================; 10:33:06.427 INFO ResourceUtils - No custom resources configured for spark.driver.; 10:33:06.428 INFO ResourceUtils - ==============================================================; 10:33:06.428 INFO SparkContext - Submitted application: SortSamSpark; 10:33:06.446 INFO ResourceProfile - Default ResourceProfile created, executor resources: Map(memoryOverhead -> name: memoryOverhead, amount: 600, script: , vendor: , cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0); 10:33:06.454 INFO ResourceProfile - Limiting resource is cpu; 10:33:06.455 INFO ResourceProfileManager - Added ResourceProfile id: 0; 10:33:06.500 INFO SecurityManager - Changing view acls to: root; 10:33:06.501 INFO SecurityManager - Changing modify acls to: root; 10:33:06.501 INFO SecurityManager - Changing view acls groups to:; 10:33:06.502 INFO SecurityManager - Changing modify acls groups to:; 10:33:06.502 INFO SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); groups with view permissions: Set(); users with modify permissions: Set(root); groups with modify permissions: Set(); 10:33:06.755 INFO Utils - Successfully started service 'sparkDriver' on port 34861.; 10:33:06.784 INFO SparkEnv - Registering MapOutputTracker; 10:33:06.815 INFO SparkEnv - Registering BlockManagerMaster; 10:33:06.827 INFO BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information; 10:33:06.828 INFO BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up; 10:33:06.831 INFO SparkEnv - Registering BlockManagerMasterHeartbeat; 10:33:06.846 INFO DiskBlockManager - Created local directory at /raid/tmp/d6/c66ba827e22dbc38625af1",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8949:41845,Secur,SecurityManager,41845,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8949,1,['Secur'],['SecurityManager']
Security,CNNPipelineIntegration tests needs expected results validation,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4537:52,validat,validation,52,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4537,1,['validat'],['validation']
Security,"CNNVariant Update models, validate scores, cleanup training",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5175:26,validat,validate,26,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5175,1,['validat'],['validate']
Security,CNV OncotateSegments does not expose bootDiskInGb runtime parameter,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3566:30,expose,expose,30,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3566,1,['expose'],['expose']
Security,COMPRESSION_LEVEL : 1; 14:19:10.290 INFO PrintReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 14:19:10.290 INFO PrintReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : false; 14:19:10.290 INFO PrintReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 14:19:10.290 INFO PrintReadsSpark - Deflater: IntelDeflater; 14:19:10.290 INFO PrintReadsSpark - Inflater: IntelInflater; 14:19:10.290 INFO PrintReadsSpark - GCS max retries/reopens: 20; 14:19:10.290 INFO PrintReadsSpark - Using google-cloud-java patch c035098b5e62cb4fe9155eff07ce88449a361f5d from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 14:19:10.290 INFO PrintReadsSpark - Initializing engine; 14:19:10.290 INFO PrintReadsSpark - Done initializing engine; 17/10/11 14:19:10 INFO spark.SparkContext: Running Spark version 1.6.0; 17/10/11 14:19:10 INFO spark.SecurityManager: Changing view acls to: hdfs; 17/10/11 14:19:10 INFO spark.SecurityManager: Changing modify acls to: hdfs; 17/10/11 14:19:10 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(hdfs); users with modify permissions: Set(hdfs); 17/10/11 14:19:10 INFO util.Utils: Successfully started service 'sparkDriver' on port 43567.; 17/10/11 14:19:11 INFO slf4j.Slf4jLogger: Slf4jLogger started; 17/10/11 14:19:11 INFO Remoting: Starting remoting; 17/10/11 14:19:11 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@10.131.101.159:45501]; 17/10/11 14:19:11 INFO Remoting: Remoting now listens on addresses: [akka.tcp://sparkDriverActorSystem@10.131.101.159:45501]; 17/10/11 14:19:11 INFO util.Utils: Successfully started service 'sparkDriverActorSystem' on port 45501.; 17/10/11 14:19:11 INFO spark.SparkEnv: Registering MapOutputTracker; 17/10/11 14:19:11 INFO spark.SparkEnv: Registering BlockManagerMaster; 17/10/11 14:19:11 INFO storage.DiskBlockManager: Created local directory at /tmp/hdfs/bloc,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686:3378,Secur,SecurityManager,3378,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686,1,['Secur'],['SecurityManager']
Security,CREDENTIALS`). Here's an example test case: https://github.com/broadinstitute/gatk/commit/8b217f82352ceb55d21d7a5236e879818910d9c9. and the stacktrace:. ```; java.util.ServiceConfigurationError: java.nio.file.spi.FileSystemProvider: Provider com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider could not be instantiated; at java.util.ServiceLoader.fail(ServiceLoader.java:232); at java.util.ServiceLoader.access$100(ServiceLoader.java:185); at java.util.ServiceLoader$LazyIterator.nextService(ServiceLoader.java:384); at java.util.ServiceLoader$LazyIterator.next(ServiceLoader.java:404); at java.util.ServiceLoader$1.next(ServiceLoader.java:480); at java.nio.file.spi.FileSystemProvider.loadInstalledProviders(FileSystemProvider.java:119); at java.nio.file.spi.FileSystemProvider.access$000(FileSystemProvider.java:77); at java.nio.file.spi.FileSystemProvider$1.run(FileSystemProvider.java:169); at java.nio.file.spi.FileSystemProvider$1.run(FileSystemProvider.java:166); at java.security.AccessController.doPrivileged(Native Method); at java.nio.file.spi.FileSystemProvider.installedProviders(FileSystemProvider.java:166); at java.nio.file.Paths.get(Paths.java:141); at org.broadinstitute.hellbender.engine.spark.datasources.NioProviderExceptionUnitTest.test(NioProviderExceptionUnitTest.java:12). Caused by:; java.lang.IllegalArgumentException: A project ID is required for this service but could not be determined from the builder or the environment. Please set a project ID using the builder.; at shaded.cloud-nio.com.google.common.base.Preconditions.checkArgument(Preconditions.java:122); at com.google.cloud.ServiceOptions.<init>(ServiceOptions.java:208); at com.google.cloud.HttpServiceOptions.<init>(HttpServiceOptions.java:153); at com.google.cloud.storage.StorageOptions.<init>(StorageOptions.java:69); at com.google.cloud.storage.StorageOptions.<init>(StorageOptions.java:27); at com.google.cloud.storage.StorageOptions$Builder.build(StorageOptions.java:64); at com.google.c,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2110:1164,secur,security,1164,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2110,1,['secur'],['security']
Security,"CS max retries/reopens: 20; 04:59:43.046 INFO ApplyBQSR - Requester pays: disabled; 04:59:43.047 INFO ApplyBQSR - Initializing engine; WARNING: BAM index file /scratch/ddo/markedsam/C18-436P.sort.rmdup.bam.bai is older than BAM /scratch/ddo/markedsam/C18-436P.sort.rmdup.bam; 04:59:43.556 INFO ApplyBQSR - Done initializing engine; 04:59:43.592 WARN ApplyBQSR - This tool has only been well tested on ILLUMINA-based sequencing data. For other data use at your own risk.; 04:59:43.592 INFO ProgressMeter - Starting traversal; 04:59:43.592 INFO ProgressMeter - Current Locus Elapsed Minutes Reads Processed Reads/Minute; 04:59:45.014 INFO ApplyBQSR - Shutting down engine; [November 8, 2021 at 4:59:45 a.m. PST] org.broadinstitute.hellbender.tools.walkers.bqsr.ApplyBQSR done. Elapsed time: 0.05 minutes.; Runtime.totalMemory()=557842432; java.lang.IllegalStateException: **The covariates table is missing ReadGroup V300019285_L2_ in RecalTable0**; 	at org.broadinstitute.hellbender.utils.Utils.validate(Utils.java:750); 	at org.broadinstitute.hellbender.utils.recalibration.covariates.ReadGroupCovariate.keyForReadGroup(ReadGroupCovariate.java:81); 	at org.broadinstitute.hellbender.utils.recalibration.covariates.ReadGroupCovariate.recordValues(ReadGroupCovariate.java:53); 	at org.broadinstitute.hellbender.utils.recalibration.covariates.StandardCovariateList.recordAllValuesInStorage(StandardCovariateList.java:133); 	at org.broadinstitute.hellbender.utils.recalibration.RecalUtils.computeCovariates(RecalUtils.java:546); 	at org.broadinstitute.hellbender.utils.recalibration.RecalUtils.computeCovariates(RecalUtils.java:527); 	at org.broadinstitute.hellbender.transformers.BQSRReadTransformer.apply(BQSRReadTransformer.java:145); 	at org.broadinstitute.hellbender.transformers.BQSRReadTransformer.apply(BQSRReadTransformer.java:27); 	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195); 	at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipelin",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7549:3519,validat,validate,3519,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7549,1,['validat'],['validate']
Security,"Calling `hashCode` directly on an instance of a Java enum produces a value that depends on the object's memory location and is therefore not stable across machines in a distributed environment. This causes issues when using these objects (or objects that contain them) as keys in Spark RDDs, which by default use `HashPartitioner` to parition by hash code. See this blog post for a summary:. http://dev.bizo.com/2014/02/beware-enums-in-spark.html. This PR modifies all places within the sv tools where we call `hashCode` on an enum, instead computing the hash of the ordinal of the enum value. For @SHuang-Broad",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4621:9,hash,hashCode,9,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4621,5,"['Hash', 'hash']","['HashPartitioner', 'hash', 'hashCode']"
Security,Cannot access pull request for Owner configuration,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3945:7,access,access,7,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3945,1,['access'],['access']
Security,Change CompareSAMs to obey validation stringency; re-enable two integ…,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/604:27,validat,validation,27,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/604,1,['validat'],['validation']
Security,Changed ValidateVariants Doc,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2759:8,Validat,ValidateVariants,8,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2759,1,['Validat'],['ValidateVariants']
Security,Check UUID in read adapter equals() and hashCode() methods,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/653:40,hash,hashCode,40,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/653,1,['hash'],['hashCode']
Security,Clean up the fail fast validation a little.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7821:23,validat,validation,23,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7821,1,['validat'],['validation']
Security,"Closes #4893. Closes #5086. Closes #5684. Closes #4500. Makes #4933, #4958, and #5085 possible. @takutosato Failing tests are superficial. You can begin reviewing. . This is a big PR:. * Refactor of all M2 filtering. Each filter has its own class, and the filtering engine ties it all together.; * Learn allele fraction clustering and somatic SNV and indel priors.; * More probabilistic filters.; * All filters have a common probabilistic threshold.; * M2 determines threshold automatically.; * Rewrite of all M2 documentation.; * Several filters, including strand bias and normal artifact, learn their own parameters. @LeeTL1220 M2 validations look really, really good. @meganshand Once this goes in mitochondria best practices will need to be tweaked again. We can merge the dangling tails homoplasmic fix before merging this.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5688:633,validat,validations,633,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5688,1,['validat'],['validations']
Security,"Closes #5085. This improves validations a bit immediately but more importantly will enable more intelligent filtering on the level of haplotypes, which I think is critical to some of the messy data we have seen. This will also benefit HaplotypeCaller some day. @LeeTL1220 Could you review as far as changes to Mutect2 are concerned?. @droazen Could you review the refactoring of `ReadLikelihoods` / extracting `MoleculeLikelihoods`?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5831:28,validat,validations,28,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5831,1,['validat'],['validations']
Security,"Closes #6235 . This PR allows users to more easily clobber individual theano flags. This can be used to change the location of the theano compilation directory (see the above issue and #4782 for context). These flags are set upon import of the theano module; see http://deeplearning.net/software/theano/library/config.html for details. This solution is a little hacky, hence the code duplication. Ideally, we'd be able to specify this directory (and potentially other flags) as a parameter to the tools. As discussed with @cmnbroad, probably the cleanest solution would be to modify the PythonScriptExecutor to allow environment variables to be specified, e.g. via ProcessSettings. This solution would also cover the initial import of the `gcnvkernel` package for validation purposes, rather than only the imports in the resource scripts modified in this PR.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6244:764,validat,validation,764,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6244,1,['validat'],['validation']
Security,Closes #6829; @mwalker174 Could you please review? . I only added `gcs_project_for_requester_pays` input to tasks that need access to BAMs. Do we also need it for the ones that require reference such as `PreprocessIntervals`?,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6870:124,access,access,124,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6870,1,['access'],['access']
Security,Closes #7672. @ldgauthier This is the bug fix for Sarah Calvo. The allele was lost when trimming caused its haplotype to start with a deletion. The solution is to inject force-calling alleles after trimming. Are you able to review?,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7679:163,inject,inject,163,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7679,1,['inject'],['inject']
Security,"Closes https://github.com/broadinstitute/dsp-spec-ops/issues/366 by putting into SQL what is in English in that ticket:; > All variants in the region, chr19:35,740,407-35,740,469, overlap transcripts with multiple genes and those genes are always IGFLR1 and AD000671.2. Do not consider rows that include a consequence of downstream_gene_variant or upstream_gene_variant in this validation.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7360:378,validat,validation,378,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7360,1,['validat'],['validation']
Security,"Coming from https://gatkforums.broadinstitute.org/gatk/discussion/9358/gatk-runtime-error-read-max-length-must-be-0-but-got-0-with-1000g-bam#latest. There seems to be a bug somewhere in the implementation of pair hmm, which multiple users have run into. The most recent user reported running Mutect2 on two different machines with the same inputs, and same versions of GATK. One run was successful, while the other failed with ; ``` ; java.lang.IllegalArgumentException: readMaxLength must be > 0 but got 0; 	at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:730); 	at org.broadinstitute.hellbender.utils.pairhmm.PairHMM.initialize(PairHMM.java:152); 	at org.broadinstitute.hellbender.utils.pairhmm.N2MemoryPairHMM.initialize(N2MemoryPairHMM.java:28); 	at org.broadinstitute.hellbender.utils.pairhmm.LoglessPairHMM.initialize(LoglessPairHMM.java:7); 	at org.broadinstitute.hellbender.utils.pairhmm.PairHMM.initialize(PairHMM.java:177); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.PairHMMLikelihoodCalculationEngine.initializePairHMM(PairHMMLikelihoodCalculationEngine.java:242); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.PairHMMLikelihoodCalculationEngine.computeReadLikelihoods(PairHMMLikelihoodCalculationEngine.java:177); 	at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2Engine.callRegion(Mutect2Engine.java:207); 	at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2.apply(Mutect2.java:212); 	at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.processReadShard(AssemblyRegionWalker.java:291); 	at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.traverse(AssemblyRegionWalker.java:267); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:979); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:137); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:182); 	at org.broadins",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5543:554,validat,validateArg,554,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5543,1,['validat'],['validateArg']
Security,Command line validation stringency argument for GATKTool.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1439:13,validat,validation,13,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1439,1,['validat'],['validation']
Security,CommandLineProgram.java:195); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:131); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:152); 	at org.broadinstitute.hellbender.Main.main(Main.java:233); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:736); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.io.IOException: Error code 404 trying to get security access token from Compute Engine metadata for the default service account. This may be because the virtual machine instance does not have permission scopes specified.; 	at shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials.refreshAccessToken(ComputeEngineCredentials.java:137); 	at shaded.cloud_nio.com.google.auth.oauth2.OAuth2Credentials.refresh(OAuth2Credentials.java:160); 	at shaded.cloud_nio.com.google.auth.oauth2.OAuth2Credentials.getRequestMetadata(OAuth2Credentials.java:146); 	at shaded.cloud_nio.com.google.auth.http.HttpCredentialsAdapter.initialize(HttpCredentialsAdapter.java:96); 	at com.google.cloud.http.HttpTransportOptions$1.initialize(HttpTransportOptions.java:157); 	at shaded.cloud_nio.com.google.api.client.http.HttpRequestFactory.buildRequest(HttpRequestFactory.java:93); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.buildHttpRequest(AbstractGoogleClientRequest.java:300); 	at shaded.cloud_nio.com.google.api.client.googleapis.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3591:3649,secur,security,3649,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3591,2,"['access', 'secur']","['access', 'security']"
Security,CommandLinePrograms should not be instantiated until arguments are parsed and injected,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/107:78,inject,injected,78,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/107,1,['inject'],['injected']
Security,CompareSAMs ignores validation stringency,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/419:20,validat,validation,20,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/419,1,['validat'],['validation']
Security,"CompareSAMs ignores validation stringency. Running this. ```; build/install/hellbender/bin/hellbender CompareSAMs src/test/resources/org/broadinstitute/hellbender/tools/BQSR/NA12878.chr17_69k_70k.dictFix.bam src/test/resources/org/broadinstitute/hellbender/tools/BQSR/NA12878.chr17_69k_70k.dictFix.bam --VALIDATION_STRINGENCY SILENT; ```. results in this. ```; htsjdk.samtools.SAMFormatException: SAM validation error: ERROR: Record 130, Read name 809R9ABXX101220:5:6:17918:145992, Mate Alignment start should be 0 because reference name = *.; at htsjdk.samtools.SAMUtils.processValidationErrors(SAMUtils.java:439); at htsjdk.samtools.BAMFileReader$BAMFileIterator.advance(BAMFileReader.java:643); at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:628); at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:598); at htsjdk.samtools.SamReader$AssertingIterator.next(SamReader.java:544); at htsjdk.samtools.SamReader$AssertingIterator.next(SamReader.java:518); at htsjdk.samtools.util.PeekIterator.peek(PeekIterator.java:67); at htsjdk.samtools.SecondaryOrSupplementarySkippingIterator.skipAnyNotprimary(SecondaryOrSupplementarySkippingIterator.java:36); at htsjdk.samtools.SecondaryOrSupplementarySkippingIterator.advance(SecondaryOrSupplementarySkippingIterator.java:31); at org.broadinstitute.hellbender.utils.read.SamComparison.compareCoordinateSortedAlignments(SamComparison.java:111); at org.broadinstitute.hellbender.utils.read.SamComparison.compareAlignments(SamComparison.java:68); at org.broadinstitute.hellbender.utils.read.SamComparison.<init>(SamComparison.java:44); at org.broadinstitute.hellbender.tools.picard.sam.CompareSAMs.doWork(CompareSAMs.java:34); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:94); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:144); at org.broadinstitute.hellbender.cmdline.PicardCommandLineProgram.instanceMain(PicardComm",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/419:20,validat,validation,20,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/419,2,['validat'],['validation']
Security,"Comprises the last ~~6 commits~~ 7 commits. (Had to fix a test file dependency. From now on, I'd like to request more encapsulation of test resources. Certainly we should have a common pool of general, rarely changed resources, but sharing of specific resources across packages breaks encapsulation.). @lbergelson I removed a few R dependencies. We should update the base Docker image accordingly and make sure I didn't break anything.; @davidbenjamin I had to change one use of HashedListTargetCollection in CalculateContamination. Also note that FilterByOrientationBias is the sole survivor in the exome package, so you may want to move it somewhere else.; @LeeTL1220 @vruano This removes a lot of your code. Please speak up if there are any utility classes, etc. that you'd like to keep. (For example, I kept the HMM code.) I removed the Target codec and associated classes.; @sooheelee I will update the list of tools for doc updates accordingly.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3935:479,Hash,HashedListTargetCollection,479,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3935,1,['Hash'],['HashedListTargetCollection']
Security,CountVariants in Spark. exposed Loading VariantContexts in parallel,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1496:24,expose,exposed,24,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1496,1,['expose'],['exposed']
Security,Create WDL to validate VAT and add first test,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7352:14,validat,validate,14,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7352,1,['validat'],['validate']
Security,Create separate ValidateVariants validation that go beyond vcf specs,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6630:16,Validat,ValidateVariants,16,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6630,2,"['Validat', 'validat']","['ValidateVariants', 'validation']"
Security,CreateSequenceDictionary needs to expose a utility method to create a sequence dictionary programmatically.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7628:34,expose,expose,34,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7628,1,['expose'],['expose']
Security,Created NioFileCopier that copies files using nio paths (includes; optional progress indicator and integrity validation).; Updated an error message in funcotator to make it more descriptive. Fixes #4549,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5150:99,integrity,integrity,99,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5150,2,"['integrity', 'validat']","['integrity', 'validation']"
Security,Created VAT here: https://app.terra.bio/#workspaces/gvs-dev/RSA%20-%20GVS%20Quickstart%20V2%20/job_history/b5c03ce6-cc74-462a-b81d-8ea102be314e; Validated VAT here: https://app.terra.bio/#workspaces/gvs-dev/RSA%20-%20GVS%20Quickstart%20V2%20/job_history/e6511960-8340-4e74-8f06-6c1a69d848bd (confirming with Rori that the failures are not surprising given it's only 10 samples),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8665:145,Validat,Validated,145,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8665,1,['Validat'],['Validated']
Security,Creating tools and simple command-line for validation,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1240:43,validat,validation,43,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1240,2,['validat'],['validation']
Security,"CrosscheckFingerprints cannot access to ""Requester Pays"" buckets, can it be changed to support the ""--gcs-project-for-requester-pays"" option as in the GenomicsDBImport tool?. ```; code: 400; message: Bucket is requester pays bucket but no user project provided.; reason: required; location: null; retryable: false; com.google.cloud.storage.StorageException: Bucket is requester pays bucket but no user project provided.; at com.google.cloud.storage.spi.v1.HttpStorageRpc.translate(HttpStorageRpc.java:229); at com.google.cloud.storage.spi.v1.HttpStorageRpc.get(HttpStorageRpc.java:439); at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:242); at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:239); at shaded.cloud_nio.com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:105); at shaded.cloud_nio.com.google.cloud.RetryHelper.run(RetryHelper.java:76); at shaded.cloud_nio.com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:50); at com.google.cloud.storage.StorageImpl.get(StorageImpl.java:238); at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.checkAccess(CloudStorageFileSystemProvider.java:736); at java.nio.file.Files.exists(Files.java:2385); at htsjdk.samtools.util.IOUtil.assertFileIsReadable(IOUtil.java:497); at htsjdk.samtools.util.IOUtil.assertPathsAreReadable(IOUtil.java:525); at picard.fingerprint.CrosscheckFingerprints.doWork(CrosscheckFingerprints.java:449); at picard.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:305); at org.broadinstitute.hellbender.cmdline.PicardCommandLineProgramExecutor.instanceMain(PicardCommandLineProgramExecutor.java:25); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:163); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:206); at org.broadinstitute.hellbender.Main.main(Main.java:292); Caused by: shaded.cloud_nio.com.google.api.client.googleapis.json.GoogleJsonResponseException: 400 Bad Request; {; ""code"" : ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7489:30,access,access,30,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7489,1,['access'],['access']
Security,"Currently `GATKRead.copy()` is unable to guarantee a deep copy, since we only have a deep copy method for Google `Read`s (`GenericData.clone()`, which it inherits), not `SAMRecord`s. We should write a deep copy method for `SAMRecord`, hook it up to the `GATKRead.copy()` implementation in `SAMRecordToGATKReadAdapter`, and change the method contract to guarantee that a deep copy will be performed. This is not a huge priority, since `GATKRead` already guarantees that defensive copies will be made of all mutable reference types returned from accessor methods (which means that shallow copies should be safe to use freely), but would be nice for consistency and peace of mind.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/623:544,access,accessor,544,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/623,1,['access'],['accessor']
Security,"Currently `SamAssertionUtils.assertSamsEqual` fails with `""SAM file output differs from expected output""`. It uses `SamComparison`, which prints a lot of helpful information about how the files differ to stdout. This output is often hidden when running it in a test suite though. It's also a bit strange to print error messages to stdout. `SamComparison` should capture this information and provide an accessor to retrieve it instead of dumping it to stdout.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/375:402,access,accessor,402,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/375,1,['access'],['accessor']
Security,"Currently `ValidateSamFile` has a limited list of platforms which does not include `BGI`. We should add `BGI` to the list of valid platforms, and we should review our list of supported platforms to make sure there are no others we are missing.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5517:11,Validat,ValidateSamFile,11,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5517,1,['Validat'],['ValidateSamFile']
Security,Currently build_docker will run for a long time and then fail at the end if you are not authenticated to gcloud. We should have an upfront test for it.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5353:88,authenticat,authenticated,88,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5353,1,['authenticat'],['authenticated']
Security,"Currently in master, intervals from the IAC that have been modified by the engine are further padded, overlapping intervals are merged, and bins are created. WES should be run by specifying bin_length = 0, and the total number of intervals (targets, in this case) should remain fixed. However, current behavior does not prevent intervals that overlap after padding from being merged. Note also that in sl_gcnv_ploidy_cli, bins that contain only Ns are also dropped. We should add validation of the IAC to check for minimal modification by the engine (as is done by other CNV CLIs), and then pad without introducing overlaps or merging if bin_length = 0. If bin length != 0, then the current behavior is fine (since it is conceivable that one might want to bin when running WES).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3981:480,validat,validation,480,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3981,1,['validat'],['validation']
Security,Currently it seems like the pull request build on travis is running the wrong commit's tests in docker. The docker build script takes a commit hash as part of it's inputs and then performs a checkout of that when building the docker. This is failing for the PR builds because the .travis.yml is currently getting the hash from calling rev-parse on the current branch which gives the commit number of master. It should be using $TRAVIS_COMMIT as the hash.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3216:143,hash,hash,143,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3216,3,['hash'],['hash']
Security,"Currently one can indicate if a program argument is optional by setting the Attribute annotation property `optional` to `true`. . Then, it is up to the programmer to indicate a default value for the parameter explicitly initializing the corresponding field with such a default value. It seems to me that we would gain versatility/expressibility if we use java.util.Optional as the type of the field:; - The code can then know wether the user actually gave a value to the parameter using `isPresent()`; currently there is no way to do so as the value provided by the user happens to be the default value.; - The default value may be defined dynamically based on other argument values or input data using `orElse(dynamicDefault)` or `orElseGet(dynamicDefaultLamda)`.; - The current solution prompts to use arbitrary marker constant value to deactivate the functionality; behind the user argument. eg.`maximumDepth = -1`. This constant may in fact be outside the valid ; range for the argument which makes validating it a bit more difficult.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1445:1003,validat,validating,1003,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1445,1,['validat'],['validating']
Security,"Currently our default reads validation stringency as defined in `GATKTool` is SILENT -- should it be STRICT, or is STRICT too impractical/annoying for read-world data?. Prompted by a discussion in https://github.com/broadinstitute/gatk/pull/1439",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1457:28,validat,validation,28,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1457,1,['validat'],['validation']
Security,Currently the only way to create a sequence dictionary from within a GATK tool is to call into the CreateSequenceDictionary tool as if it was being executed from the command-line. This is a hack. We need to expose a method that other tools can call into that will create a sequence dictionary for files.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7628:207,expose,expose,207,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7628,1,['expose'],['expose']
Security,"Currently the script fails when configured to run tests, since it doesn't have access to the large files in the docker image. These need to be downloaded and mounted for the tests to pass, as we do in the docker tests on travis.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3191:79,access,access,79,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3191,1,['access'],['access']
Security,"Currently we have a dependency on having gcloud and gsutil installed and configured in a certain way, but we don't have any documentation about it. . We're getting authentication partially from gcloud auth login, which is being propagated in a way I don't fully understand through the dataflow pipeline options. . We need to understand exactly what's happening and then write an explanation of what a user needs to do to have it work.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1051:164,authenticat,authentication,164,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1051,1,['authenticat'],['authentication']
Security,"Currently, `IntervalArgumentCollection` still uses `GenomeLocs` internally during parsing, despite the rest of the engine using `SimpleIntervals`. This forces us to provide a sequence dictionary when interval arguments are present even if the only input is an interval list (eg., an `IntervalWalker` that purely processes/transforms intervals). We should provide a mode in `IntervalArgumentCollection` in which intervals can be parsed into `SimpleIntervals` without a sequence dictionary. This will require us to fill in a special value such as `Integer.MAX_VALUE` for the stop position of intervals that don't contain a stop position (eg., ""chr1"" or ""chr1:1+""), since we won't know the true contig lengths, but our future query interfaces should all be robust to requests for locations outside of contig boundaries (and not blow up given such requests). This will also require adding some way of determining whether or not an interval has been validated against a sequence dictionary -- perhaps `ValidatedInterval` could be a subclass of `SimpleInterval`.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/298:945,validat,validated,945,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/298,2,"['Validat', 'validat']","['ValidatedInterval', 'validated']"
Security,"Currently, if the GATK doesn't have permission to check whether a GCS bucket is Requester Pays (which is a separate permission from access to the bucket itself!), we get a cryptic error message along the lines of:. ```; User does not have storage.buckets.get access to bucket_name; ```. This is the same error the gsutil client gives in the same situation:. ```; $ gsutil requesterpays get gs://gatk-best-practices; AccessDeniedException: 403 droazen@broadinstitute.org does not have storage.buckets.get access to gatk-best-practices.; ```. Ideally we should detect this situation upfront in the GATK and emit a more informative error message.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6349:132,access,access,132,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6349,4,"['Access', 'access']","['AccessDeniedException', 'access']"
Security,"Currently, in order to create a GenomeLoc, you need to create a GenomeLocParser, which requires either a reference fasta or a sequence dictionary for validation. Sometimes, however, you don't want this level of validation (perhaps you have already checked that the interval is within bounds, making the extra validation wasteful -- this happens in a few places in the new engine). There should be a way to instantiate a GenomeLoc directly, without the need to pass around a GenomeLocParser.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/100:150,validat,validation,150,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/100,3,['validat'],['validation']
Security,"Currently, we need to copy files on S3 to local storage before using; them. This patch enables gatk local and spark modes to access s3a://; files directly to reduce copy overhead and local disk usages. s3a file accesses require additional configuration of core-site.xml; located in CLASSPATH as well as other hadoop applications. Spark; already has hadoop dependencies but local modes need to add hadoop; jars in the classpath. Example core-site.xml:. ```; <configuration>; <property>; <name>fs.s3a.access.key</name>; <value>{Your AWS_ACCESS_KEY_ID}</value>; </property>; <property>; <name>fs.s3a.secret.key</name>; <value>{Your AWS_SECRET_ACCESS_KEY}</value>; </property>; </configuration>; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6698:125,access,access,125,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6698,3,['access'],"['access', 'accesses']"
Security,"Currently, we're instantiating our CommandLineProgram before we've parsed its arguments and injected them into the appropriate member variables. This means that the constructors for our tools (eg., the ReadWalker constructor) cannot use argument values during initialization, which is a big problem. We need to delay instantiation until after arguments are parsed and injected.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/107:92,inject,injected,92,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/107,2,['inject'],['injected']
Security,"DBImport - Callset Map JSON file will be written to /home/test/Software/gatk-4.4.0.0/test/./02/callset.json; 10:19:39.951 INFO GenomicsDBImport - Complete VCF Header will be written to /home/test/Software/gatk-4.4.0.0/test/./02/vcfheader.vcf; 10:19:39.951 INFO GenomicsDBImport - Importing to workspace - /home/test/Software/gatk-4.4.0.0/test/./02; 10:19:40.060 INFO GenomicsDBImport - Importing batch 1 with 2 samples; 10:19:40.075 INFO GenomicsDBImport - Shutting down engine; org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImport done. Elapsed time: 0.01 minutes.; Runtime.totalMemory()=285212672; java.lang.NumberFormatException: For input string: ""G""; 	at java.base/java.lang.NumberFormatException.forInputString(NumberFormatException.java:67); 	at java.base/java.lang.Integer.parseInt(Integer.java:668); 	at java.base/java.lang.Integer.parseInt(Integer.java:786); 	at htsjdk.tribble.readers.TabixReader.getIntv(TabixReader.java:337); 	at htsjdk.tribble.readers.TabixReader.access$500(TabixReader.java:48); 	at htsjdk.tribble.readers.TabixReader$IteratorImpl.next(TabixReader.java:438); 	at htsjdk.tribble.readers.TabixIteratorLineReader.readLine(TabixIteratorLineReader.java:46); 	at htsjdk.tribble.TabixFeatureReader$FeatureIterator.readNextRecord(TabixFeatureReader.java:170); 	at htsjdk.tribble.TabixFeatureReader$FeatureIterator.<init>(TabixFeatureReader.java:159); 	at htsjdk.tribble.TabixFeatureReader.query(TabixFeatureReader.java:133); 	at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImport$1.query(GenomicsDBImport.java:971); 	at org.genomicsdb.importer.GenomicsDBImporter.<init>(GenomicsDBImporter.java:167); 	at org.genomicsdb.importer.GenomicsDBImporter.lambda$null$4(GenomicsDBImporter.java:732); 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1768); 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136); 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Thr",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8517:3552,access,access,3552,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8517,1,['access'],['access']
Security,"DP=1399;ECNT=1;MBQ=36,36;MFRL=209,211;MMQ=60,60;MPOS=34;POPAF=7.3;TLOD=42.57	GT:AD:AF:DP:F1R2:F2R1:SAAF:SAPP	0/1:1327,27:0.019:1354:672,12:655,15:0.02,0.02,0.02:0.0007239,0.005058,0.994; 11	108175462	.	G	A	.	.	DP=972;ECNT=1;MBQ=36,36;MFRL=209,206;MMQ=60,60;MPOS=37;POPAF=7.3;TLOD=15.55	GT:AD:AF:DP:F1R2:F2R1:SAAF:SAPP	0/1:898,12:0.013:910:446,6:452,6:0.01,0.01,0.013:0.002966,0.0009292,0.996; 12	12037318	.	C	G	.	.	DP=975;ECNT=1;MBQ=36,36;MFRL=205,218;MMQ=60,60;MPOS=48;POPAF=7.3;TLOD=15.41	GT:AD:AF:DP:F1R2:F2R1:SAAF:SAPP	0/1:893,12:0.013:905:438,4:455,8:0.01,0.01,0.013:0.004146,0.0007942,0.995; 15	66679819	.	G	C	.	.	DP=870;ECNT=1;MBQ=36,36;MFRL=215,211;MMQ=60,60;MPOS=52;POPAF=7.3;TLOD=25.62	GT:AD:AF:DP:F1R2:F2R1:SAAF:SAPP	0/1:797,17:0.022:814:384,11:413,6:0.02,0.02,0.021:0.004622,0.001165,0.994; 18	42532923	.	T	C	.	.	DP=1402;ECNT=1;MBQ=36,36;MFRL=197,222;MMQ=60,60;MPOS=51;POPAF=7.3;TLOD=41.21	GT:AD:AF:DP:F1R2:F2R1:SAAF:SAPP	0/1:1312,25:0.019:1337:681,13:631,12:0.02,0.01,0.019:0.0009167,0.002842,0.996; 20	31019360	.	AT	A	.	.	DP=1530;ECNT=1;MBQ=36,36;MFRL=198,199;MMQ=60,60;MPOS=44;POPAF=7.3;RPA=7,6;RU=T;STR;TLOD=30.65	GT:AD:AF:DP:F1R2:F2R1:SAAF:SAPP	0/1:1424,34:0.022:1458:673,20:751,14:0.02,0.02,0.023:0.003063,0.0009654,0.996; ```. #### Steps to reproduce; ```; # Call without --alleles option does not produce the variants.; gatk Mutect2 --reference GRCh37.fa --read-validation-stringency LENIENT -I subset_properheader.bam -L enrichment.bed --interval-set-rule INTERSECTION -O unfiltered_noalleles.vcf.gz; # Call with --alleles option produces the variants with presumably high quality scores; gatk Mutect2 --reference GRCh37.fa --read-validation-stringency LENIENT -I subset_properheader.bam -L enrichment.bed --interval-set-rule INTERSECTION -O unfiltered_alleles.vcf.gz --alleles truth_small_variants_NA12878-NA24385-mix_sorted.vcf.gz; ```; The BAM, BED and output VCF files are available for download [here](https://gatk-validation.s3-eu-west-1.amazonaws.com/mutect2-4.1.9.0.zip).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7015:5837,validat,validation-stringency,5837,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7015,3,['validat'],"['validation', 'validation-stringency']"
Security,Data is sensitive and bug is recapitulated in https://github.com/broadinstitute/dsde-docs/issues/3026. CombineGVCFs gives the following error message:; ```; java.lang.IllegalArgumentException: Invalid interval. Contig:HLA-DRB1*15:03:01:02 start:11569 end:11005; 	at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:687); 	at org.broadinstitute.hellbender.utils.SimpleInterval.validatePositions(SimpleInterval.java:61); 	at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:37); 	at org.broadinstitute.hellbender.tools.walkers.CombineGVCFs.onTraversalSuccess(CombineGVCFs.java:415); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:895); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:135); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:180); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:199); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:159); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:202); 	at org.broadinstitute.hellbender.Main.main(Main.java:288); ```; Here are the dictionary lines for two consecutive HLA-DRB1 contigs:; ```; @SQ SN:HLA-DRB1*15:03:01:02 LN:11569 M5:4e0d459b9bd15bff8645de84334e3d25 AS:38 UR:/seq/references/Homo_sapiens_assembly38/v0/Homo_sapiens_assembly38.fasta SP:Homo sapiens; @SQ SN:HLA-DRB1*16:02:01 LN:11005 M5:4a972df76bd3ee2857b87bd5be5ea00a AS:38 UR:/seq/references/Homo_sapiens_assembly38/v0/Homo_sapiens_assembly38.fasta SP:Homo sapiens; ```; Notice the `LN` lengths match up. It appears that our tool is mistaking contig information.; Note that `HLA-DRB1*16:02:01` is the very last contig in GRCh38.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4572:308,validat,validateArg,308,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4572,2,['validat'],"['validateArg', 'validatePositions']"
Security,"Defaults.CUSTOM_READER_FACTORY :; 17:43:53.163 INFO ValidateVariants - Defaults.EBI_REFERENCE_SERVICE_URL_MASK : http://www.ebi.ac.uk/ena/cram/md5/%s; 17:43:53.163 INFO ValidateVariants - Defaults.NON_ZERO_BUFFER_SIZE : 131072; 17:43:53.163 INFO ValidateVariants - Defaults.REFERENCE_FASTA : null; 17:43:53.163 INFO ValidateVariants - Defaults.SAM_FLAG_FIELD_FORMAT : DECIMAL; 17:43:53.163 INFO ValidateVariants - Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 17:43:53.163 INFO ValidateVariants - Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 17:43:53.163 INFO ValidateVariants - Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 17:43:53.163 INFO ValidateVariants - Defaults.USE_CRAM_REF_DOWNLOAD : false; 17:43:53.163 INFO ValidateVariants - Deflater IntelDeflater; 17:43:53.163 INFO ValidateVariants - Inflater IntelInflater; 17:43:53.163 INFO ValidateVariants - Initializing engine; 17:43:53.270 INFO FeatureManager - Using codec VCFCodec to read file file:///Users/louisb/Workspace/gatk/src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleGood.vcf; 17:43:53.287 INFO FeatureManager - Using codec VCFCodec to read file file:///Users/louisb/Workspace/gatk/src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleGood.vcf; 17:43:53.291 WARN IndexUtils - Feature file ""/Users/louisb/Workspace/gatk/src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleGood.vcf"" appears to contain no sequence dictionary. Attempting to retrieve a sequence dictionary from the associated index file; 17:43:53.293 INFO ValidateVariants - Done initializing engine; 17:43:53.294 INFO ProgressMeter - Starting traversal; 17:43:53.294 INFO ProgressMeter - Current Locus Elapsed Minutes Records Processed Records/Minute; 17:43:53.302 INFO ValidateVariants - Shutting down engine; [March 21, 2017 5:43:53 PM EDT] org.broadinstitute.hellbender.tools.walkers.variantutils.ValidateVariants don",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2509:3329,Validat,ValidateVariants,3329,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2509,2,"['Validat', 'validat']","['ValidateVariants', 'validationExampleGood']"
Security,Disk space variables inconsistently exposed in gCNV WDLs.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6995:36,expose,exposed,36,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6995,1,['expose'],['exposed']
Security,"Docker instance running as root, possible security issue for local data access. REVISITED",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5959:42,secur,security,42,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5959,2,"['access', 'secur']","['access', 'security']"
Security,Document how to access spark master page when running hellbender on GCE/dataproc,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/975:16,access,access,16,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/975,1,['access'],['access']
Security,Document how to authenticate to Google Cloud Storage,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2495:16,authenticat,authenticate,16,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2495,1,['authenticat'],['authenticate']
Security,Don't check contig ordering during sequence dictionary validation,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1178:55,validat,validation,55,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1178,1,['validat'],['validation']
Security,Don't check contig ordering in sequence dictionary validation,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1176:51,validat,validation,51,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1176,1,['validat'],['validation']
Security,Double-check validation test,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/557:13,validat,validation,13,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/557,1,['validat'],['validation']
Security,DuplicatesPipelineSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 18:30:54.424 INFO BwaAndMarkDuplicatesPipelineSpark - Deflater: IntelDeflater; 18:30:54.424 INFO BwaAndMarkDuplicatesPipelineSpark - Inflater: IntelInflater; 18:30:54.424 INFO BwaAndMarkDuplicatesPipelineSpark - GCS max retries/reopens: 20; 18:30:54.424 INFO BwaAndMarkDuplicatesPipelineSpark - Using google-cloud-java patch c035098b5e62cb4fe9155eff07ce88449a361f5d from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 18:30:54.424 INFO BwaAndMarkDuplicatesPipelineSpark - Initializing engine; 18:30:54.424 INFO BwaAndMarkDuplicatesPipelineSpark - Done initializing engine; 18/01/09 18:30:54 INFO spark.SparkContext: Running Spark version 2.2.0.cloudera1; 18/01/09 18:30:54 INFO spark.SparkContext: Submitted application: BwaAndMarkDuplicatesPipelineSpark; 18/01/09 18:30:54 INFO spark.SecurityManager: Changing view acls to: sun; 18/01/09 18:30:54 INFO spark.SecurityManager: Changing modify acls to: sun; 18/01/09 18:30:54 INFO spark.SecurityManager: Changing view acls groups to: ; 18/01/09 18:30:54 INFO spark.SecurityManager: Changing modify acls groups to: ; 18/01/09 18:30:54 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(sun); groups with view permissions: Set(); users with modify permissions: Set(sun); groups with modify permissions: Set(); 18/01/09 18:30:55 INFO util.Utils: Successfully started service 'sparkDriver' on port 38793.; 18/01/09 18:30:55 INFO spark.SparkEnv: Registering MapOutputTracker; 18/01/09 18:30:55 INFO spark.SparkEnv: Registering BlockManagerMaster; 18/01/09 18:30:55 INFO storage.BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information; 18/01/09 18:30:55 INFO storage.BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up; 18/01/09 18:30:55 INFO storage.DiskBlockManager: Created local directory at /tmp/sun/blockmgr-b03058d,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4112:5443,Secur,SecurityManager,5443,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4112,1,['Secur'],['SecurityManager']
Security,During alpha we should work out the process of releasing builds to maven central. This may require coordinating with ops in order to handle signing keys and passwords.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1188:157,password,passwords,157,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1188,1,['password'],['passwords']
Security,"EDIT: Parameters are now exposed as individual arguments, so the following quoted text is outdated; see below for more details. > Adds the parameters `--dangling-end-smith-waterman-parameters-table <GATKPath>`, `--haplotype-to-reference-smith-waterman-parameters-table <GATKPath>`, and `--read-to-haplotype-smith-waterman-parameters-table <GATKPath>` to HaplotypeCaller and Mutect2. This allows for input via a TSV containing the column headers `MATCH_VALUE\tMISMATCH_PENALTY\tGAP_OPEN_PENALTY\tGAP_EXTEND_PENALTY` and one row of integers. Enables investigation of #2498 and #5564. Closes #6863 . Just opening this in case anyone wants to play around with it. I'll do some further testing on human and malaria data, but we have already found some cases in the latter for which changing some of the quizzical values to more reasonable ones yields immediate benefits. If anyone has any suggestions for possible evaluations, I'm all ears!. A few notes:. - I still need to add doc strings for the new arguments.; - Per https://github.com/broadinstitute/gatk/issues/6863#issuecomment-705081291, we can wait until after the DRAGEN-GATK dust settles to review/reevaluate/merge.; - At that time, I'll add a few simple integration tests to check that I've properly bubbled up each set of parameters.; - The reviewer might find the diagram at https://github.com/broadinstitute/gatk/issues/6863#issuecomment-707919816 useful.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6885:25,expose,exposed,25,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6885,1,['expose'],['exposed']
Security,ERROR] [system.err] [bwt_restore_sa] SA-BWT inconsistency: seq_len is not the same. Abort!; ... 11:54:40.433 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] org.gradle.api.tasks.TaskExecutionException: Execution failed for task ':test'.; 11:54:40.433 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.executeActions(ExecuteActionsTaskExecuter.java:98); 11:54:40.433 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.execute(ExecuteActionsTaskExecuter.java:68); 11:54:40.433 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.SkipUpToDateTaskExecuter.execute(SkipUpToDateTaskExecuter.java:62); 11:54:40.433 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.ValidatingTaskExecuter.execute(ValidatingTaskExecuter.java:58); 11:54:40.433 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.SkipEmptySourceFilesTaskExecuter.execute(SkipEmptySourceFilesTaskExecuter.java:88); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.ResolveTaskArtifactStateTaskExecuter.execute(ResolveTaskArtifactStateTaskExecuter.java:46); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.SkipTaskWithNoActionsExecuter.execute(SkipTaskWithNoActionsExecuter.java:51); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.SkipOnlyIfTaskExecuter.execute(SkipOnlyIfTaskExecuter.java:54); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.ExecuteAtMostOnceTaskExecuter.execute(ExecuteAt,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2802:1180,Validat,ValidatingTaskExecuter,1180,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2802,1,['Validat'],['ValidatingTaskExecuter']
Security,"EXHAUSTIVE --IS_BISULFITE_SEQUENCED false --MAX_OPEN_TEMP_FILES 8000 --SKIP_MATE_VALIDATION false --VERBOSITY INFO --QUIET false --VALIDATION_STRINGENCY STRICT --COMPRESSION_LEVEL 2 --MAX_RECORDS_IN_RAM 500000 --CREATE_INDEX false --CREATE_MD5_FILE false --GA4GH_CLIENT_SECRETS client_secrets.json --help false --version false --showHidden false --USE_JDK_DEFLATER false --USE_JDK_INFLATER false; [Thu Mar 07 16:08:24 UTC 2019] Executing as mpmachado@lx-bioinfo02 on Linux 2.6.32-696.23.1.el6.x86_64 amd64; OpenJDK 64-Bit Server VM 1.8.0_191-8u191-b12-0ubuntu0.16.04.1-b12; Deflater: Intel; Inflater: Intel; Provider GCS is available; Picard version: Version:4.1.0.0; WARNING 2019-03-07 16:08:24 ValidateSamFile NM validation cannot be performed without the reference. All other validations will still occur.; INFO 2019-03-07 16:10:25 SamFileValidator Validated Read 10,000,000 records. Elapsed time: 00:02:00s. Time for last 10,000,000: 120s. Last read position: chr9:32,633,613; INFO 2019-03-07 16:12:22 SamFileValidator Validated Read 20,000,000 records. Elapsed time: 00:03:58s. Time for last 10,000,000: 117s. Last read position: chrM:11,340; No errors found; [Thu Mar 07 16:13:05 UTC 2019] picard.sam.ValidateSamFile done. Elapsed time: 4.79 minutes.; Runtime.totalMemory()=2602041344; Tool returned:; 0; ```. But when run BaseRecalibrator got the _fromIndex toIndex_ error:; `gatk BaseRecalibrator --input sorted.bam --output sorted.baserecalibrator_report.txt --reference GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.bowtie_index.fasta --use-original-qualities true --known-sites snp151common_tablebrowser.bed.bgz --known-sites snp151flagged_tablebrowser.bed.bgz`; ```; ERROR: return code 3; STDERR:; 15:46:35.795 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/gatk/gatk-package-4.1.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; 15:46:42.808 INFO BaseRecalibrator - ------------------------------------------------------------; 15:46:42.810 INFO BaseR",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5807:2078,Validat,Validated,2078,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5807,1,['Validat'],['Validated']
Security,"E_INDEX false --CREATE_MD5_FILE false --GA4GH_CLIENT_SECRETS client_secrets.json --help false --version false --showHidden false --USE_JDK_DEFLATER false --USE_JDK_INFLATER false; [Thu Mar 07 16:08:24 UTC 2019] Executing as mpmachado@lx-bioinfo02 on Linux 2.6.32-696.23.1.el6.x86_64 amd64; OpenJDK 64-Bit Server VM 1.8.0_191-8u191-b12-0ubuntu0.16.04.1-b12; Deflater: Intel; Inflater: Intel; Provider GCS is available; Picard version: Version:4.1.0.0; WARNING 2019-03-07 16:08:24 ValidateSamFile NM validation cannot be performed without the reference. All other validations will still occur.; INFO 2019-03-07 16:10:25 SamFileValidator Validated Read 10,000,000 records. Elapsed time: 00:02:00s. Time for last 10,000,000: 120s. Last read position: chr9:32,633,613; INFO 2019-03-07 16:12:22 SamFileValidator Validated Read 20,000,000 records. Elapsed time: 00:03:58s. Time for last 10,000,000: 117s. Last read position: chrM:11,340; No errors found; [Thu Mar 07 16:13:05 UTC 2019] picard.sam.ValidateSamFile done. Elapsed time: 4.79 minutes.; Runtime.totalMemory()=2602041344; Tool returned:; 0; ```. But when run BaseRecalibrator got the _fromIndex toIndex_ error:; `gatk BaseRecalibrator --input sorted.bam --output sorted.baserecalibrator_report.txt --reference GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.bowtie_index.fasta --use-original-qualities true --known-sites snp151common_tablebrowser.bed.bgz --known-sites snp151flagged_tablebrowser.bed.bgz`; ```; ERROR: return code 3; STDERR:; 15:46:35.795 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/gatk/gatk-package-4.1.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; 15:46:42.808 INFO BaseRecalibrator - ------------------------------------------------------------; 15:46:42.810 INFO BaseRecalibrator - The Genome Analysis Toolkit (GATK) v4.1.0.0; 15:46:42.810 INFO BaseRecalibrator - For support and documentation go to https://software.broadinstitute.org/gatk/; 15:46:42.813 INFO BaseRecalibrator - Execut",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5807:2262,Validat,ValidateSamFile,2262,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5807,1,['Validat'],['ValidateSamFile']
Security,Early Subset VDS during validation for validation check,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8728:24,validat,validation,24,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8728,2,['validat'],['validation']
Security,"Empirical testing has shown that this tool performs best at scale with cloud buffering; disabled. With cloud buffering on and thousands of concurrent GenomicsDBImport tasks,; we do too many simultaneous GCS accesses (since the prefetcher spawns a new thread for each; reader upon a query) and start seeing intermittent failures, even with aggressive retries.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3110:207,access,accesses,207,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3110,1,['access'],['accesses']
Security,Enable direct s3a:// file accesses,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6698:26,access,accesses,26,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6698,1,['access'],['accesses']
Security,Enable setting validation stringency in ReadsDataSource.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/565:15,validat,validation,15,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/565,1,['validat'],['validation']
Security,Error getting access token for service account,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2514:14,access,access,14,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2514,1,['access'],['access']
Security,Error running gatk seq-format-validation workflow,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6710:30,validat,validation,30,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710,1,['validat'],['validation']
Security,"Error: A JNI error has occurred, please check your installation and try again; Exception in thread ""main"" java.lang.SecurityException: Invalid signature file digest for Manifest main attributes; 	at sun.security.util.SignatureFileVerifier.processImpl(SignatureFileVerifier.java:314); 	at sun.security.util.SignatureFileVerifier.process(SignatureFileVerifier.java:268); 	at java.util.jar.JarVerifier.processEntry(JarVerifier.java:316); 	at java.util.jar.JarVerifier.update(JarVerifier.java:228); 	at java.util.jar.JarFile.initializeVerifier(JarFile.java:383); 	at java.util.jar.JarFile.getInputStream(JarFile.java:450); 	at sun.misc.JarIndex.getJarIndex(JarIndex.java:137); 	at sun.misc.URLClassPath$JarLoader$1.run(URLClassPath.java:839); 	at sun.misc.URLClassPath$JarLoader$1.run(URLClassPath.java:831); 	at java.security.AccessController.doPrivileged(Native Method); 	at sun.misc.URLClassPath$JarLoader.ensureOpen(URLClassPath.java:830); 	at sun.misc.URLClassPath$JarLoader.<init>(URLClassPath.java:803); 	at sun.misc.URLClassPath$3.run(URLClassPath.java:530); 	at sun.misc.URLClassPath$3.run(URLClassPath.java:520). This error seems to be resulting from signed jars and there are recommendations on the web such as exclude 'META-INF/*.RSA', 'META-INF/*.SF','META-INF/*.DSA'; I will greatly appreciate if someone could tell me where to add the aforementioned line in 'build.gradle' file.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2676:116,Secur,SecurityException,116,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2676,5,"['Access', 'Secur', 'secur']","['AccessController', 'SecurityException', 'security']"
Security,Errors in VariantFiltration - possibly due to (or exposed by) async tribble reading,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1638:50,expose,exposed,50,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1638,1,['expose'],['exposed']
Security,Escape table names properly in ValidateVat WDL,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8116:31,Validat,ValidateVat,31,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8116,1,['Validat'],['ValidateVat']
Security,"Even if you know that only some tools are enabled for Spark, its not obvious how to find them. And the tool list has more than one Spark program group, which I didn't notice at first:. Spark Validation tools: Tools written in Spark to compare aspects of two different files; Spark pipelines: Pipelines that combine tools and use Apache Spark for scaling out (experimental); Spark tools: Tools that use Apache Spark for scaling out (experimental)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1291:191,Validat,Validation,191,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1291,1,['Validat'],['Validation']
Security,Every travis build will upload it's test results to gs://hellbender/test/build_reports/<somepath>. The end of the build log shows the publicly accessible url for the test results.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/704:143,access,accessible,143,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/704,1,['access'],['accessible']
Security,"Evidently docker is changing their policy around anonymous users pulling from all docker repos (regardless of the tier for the owner of the repository being pulled from). This might or might not affect us since it looks like travis is pulling from our GCR repo for builds but we should be mindful of workflows that might rely on pulling hundreds of docker images from docker-hub through anonymous web VMs:; ```; On Monday, November 2, 2020 at 9am Pacific Standard Time, Docker will begin enforcing rate limits on container pulls for Anonymous and Free users. Anonymous (unauthenticated) users will be limited to 100 container image pulls every six hours, and Free (authenticated) users will be limited to 200 container image pulls every six hours, when enforcement is fully implemented. Docker Pro and Team subscribers can pull container images from Docker Hub without restriction, as long as the quantities are not excessive or abusive.; In addition, we are pausing enforcement of the changes to our image-retention policies until mid-2021, when we anticipate incorporating them into usage-based pricing. Two months ago, we announced an update to Docker image-retention policies. As originally stated, this change, which was set to take effect on November 1, 2020, would result in the deletion of images for free Docker account users after six months of inactivity. Today's announcement means Docker will not enforce image expiration on November 1, 2020.; ```; This is farther clarified on their FAQ https://www.docker.com/pricing/resource-consumption-updates:; ```; Rate limits for Docker image pulls are based on the account type of the user requesting the image - not the account type of the image’s owner. These are defined on the pricing page.; The highest entitlement a user has, based on their personal account and any orgs they belong to, will be used. Unauthenticated pull requests are “anonymous” and will be rate limited based on IP address rather than user ID. For more information on aut",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6922:665,authenticat,authenticated,665,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6922,1,['authenticat'],['authenticated']
Security,Example Run (AoU) [here](https://app.terra.bio/#workspaces/allofus-drc-wgs-dev/GVS%20AoU%20Echo%20RD/job_history/f4e85f7d-d8bf-45e1-a564-0dd2ae9f3761); New output file here: gs://fc-secure-4c3976f3-d84d-4243-876f-baa9f9a4256f/submissions/f4e85f7d-d8bf-45e1-a564-0dd2ae9f3761/GvsCalculatePrecisionAndSensitivity/85938f82-4731-437e-96a1-140a8ba7fcb7/call-CollateReports/stdout,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8633:182,secur,secure-,182,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8633,1,['secur'],['secure-']
Security,Expose BucketUtils.NIO_MAX_REOPENS as an engine-level argument,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3315:0,Expose,Expose,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3315,1,['Expose'],['Expose']
Security,"Expose Feature headers, and provide convenient VCFHeader access in VariantWalker",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/308:0,Expose,Expose,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/308,2,"['Expose', 'access']","['Expose', 'access']"
Security,Expose GenomicsDBArgumentCollection with CreateSomaticPanelOfNormals,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6746:0,Expose,Expose,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6746,1,['Expose'],['Expose']
Security,Expose HaplotypeCaller `READ_QUALITY_FILTER_THRESHOLD` on the command line,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7034:0,Expose,Expose,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7034,1,['Expose'],['Expose']
Security,Expose IntervalArgumentCollection.IntervalMergingRule as a command-line argument,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3251:0,Expose,Expose,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3251,1,['Expose'],['Expose']
Security,Expose `splitting-index-granularity` to all Spark tools outputting BAMs,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6418:0,Expose,Expose,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6418,1,['Expose'],['Expose']
Security,Expose mapred.max.split.size as a parameter to GATKSparkTool,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1064:0,Expose,Expose,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1064,1,['Expose'],['Expose']
Security,Expose max-alt-alleles constant as user parameter before we don't emit PLs in GenotypeGVCFs and CombineGVCFs,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2956:0,Expose,Expose,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2956,1,['Expose'],['Expose']
Security,Expose maximum-training-variants VQSR parameter [VS-634],MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8029:0,Expose,Expose,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8029,1,['Expose'],['Expose']
Security,Expose more CNN training parameters to the command line,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8483:0,Expose,Expose,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8483,1,['Expose'],['Expose']
Security,Expose more optional parameters for CreatePanelOfNormals in CNV WDL.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3356:0,Expose,Expose,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3356,1,['Expose'],['Expose']
Security,Expose number of samples for emitting denoised copy ratios in gCNV.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5754:0,Expose,Expose,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5754,1,['Expose'],['Expose']
Security,Expose or decrease CHUNK_DIVISOR in HDF5SVDReadCountPanelOfNormals.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4365:0,Expose,Expose,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4365,1,['Expose'],['Expose']
Security,Expose or hide all task-level parameters in CNV WDLs consistently.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3980:0,Expose,Expose,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3980,1,['Expose'],['Expose']
Security,Expose point size in somatic CNV plotting tools.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5748:0,Expose,Expose,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5748,1,['Expose'],['Expose']
Security,Expose spark attributes so they can be set by users,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1107:0,Expose,Expose,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1107,1,['Expose'],['Expose']
Security,Expose the attributes we set automatically in `SparkContextFactory` so they can be overridden by the user if necessary.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1107:0,Expose,Expose,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1107,1,['Expose'],['Expose']
Security,Expose the maximum-training-variants parameter for both INDEL and SNP model creation in the `GvsCreateFilterSet` WDL. Closes https://broadworkbench.atlassian.net/browse/VS-634,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8029:0,Expose,Expose,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8029,1,['Expose'],['Expose']
Security,Expose timeout arg in StreamingPythonScriptExecutor,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4221:0,Expose,Expose,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4221,1,['Expose'],['Expose']
Security,Expose vid_mapping_file JSON in GenomicsDB,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3689:0,Expose,Expose,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3689,1,['Expose'],['Expose']
Security,Exposed Linked-Debrujin-Graph arguments to the help options,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6737:0,Expose,Exposed,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6737,1,['Expose'],['Exposed']
Security,"Exposed Smith-Waterman parameters in HaplotypeCaller, Mutect2, and FilterAlignmentArtifacts.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6885:0,Expose,Exposed,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6885,1,['Expose'],['Exposed']
Security,Exposed ability to blacklist intervals in CNV WDLs.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5027:0,Expose,Exposed,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5027,1,['Expose'],['Exposed']
Security,Exposed bounds for copy-neutral segments in CallCopyRatioSegments.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4263:0,Expose,Exposed,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4263,1,['Expose'],['Exposed']
Security,Exposed maximum chunk size in CNV panel of normals.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4528:0,Expose,Exposed,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4528,1,['Expose'],['Exposed']
Security,Exposed maximum copy ratio and point size for CNV plotting tools.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6482:0,Expose,Exposed,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6482,1,['Expose'],['Exposed']
Security,Exposed more mem_gb parameters and fixed mem_gb_for_model_segments.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4364:0,Expose,Exposed,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4364,1,['Expose'],['Exposed']
Security,Exposed number of samples used for estimating denoised copy ratios in gCNV,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7450:0,Expose,Exposed,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7450,1,['Expose'],['Exposed']
Security,Exposed optional task-level parameters and standardized runtime parameters in CNV WDLs.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4288:0,Expose,Exposed,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4288,1,['Expose'],['Exposed']
Security,Exposes an argument in the mitochondria WDL,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6739:0,Expose,Exposes,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6739,1,['Expose'],['Exposes']
Security,Extract GenotypeGVCFs engine into publicly accessible class/function,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5910:43,access,accessible,43,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5910,1,['access'],['accessible']
Security,FAILURE: Build failed with an exception. * What went wrong:; Execution failed for task ':gatkTabComplete'.; > Javadoc generation failed. Generated Javadoc options file (useful for troubleshooting): '/vsc-hard-mounts/leuven-data/304/vsc30484/git/gatk/build/tmp/gatkTabComplete/javadoc.options'. * Try:; Run with --info or --debug option to get more log output. * Exception is:; org.gradle.api.tasks.TaskExecutionException: Execution failed for task ':gatkTabComplete'.; at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.executeActions(ExecuteActionsTaskExecuter.java:69); at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.execute(ExecuteActionsTaskExecuter.java:46); at org.gradle.api.internal.tasks.execution.PostExecutionAnalysisTaskExecuter.execute(PostExecutionAnalysisTaskExecuter.java:35); at org.gradle.api.internal.tasks.execution.SkipUpToDateTaskExecuter.execute(SkipUpToDateTaskExecuter.java:64); at org.gradle.api.internal.tasks.execution.ValidatingTaskExecuter.execute(ValidatingTaskExecuter.java:58); at org.gradle.api.internal.tasks.execution.SkipEmptySourceFilesTaskExecuter.execute(SkipEmptySourceFilesTaskExecuter.java:52); at org.gradle.api.internal.tasks.execution.SkipTaskWithNoActionsExecuter.execute(SkipTaskWithNoActionsExecuter.java:52); at org.gradle.api.internal.tasks.execution.SkipOnlyIfTaskExecuter.execute(SkipOnlyIfTaskExecuter.java:53); at org.gradle.api.internal.tasks.execution.ExecuteAtMostOnceTaskExecuter.execute(ExecuteAtMostOnceTaskExecuter.java:43); at org.gradle.execution.taskgraph.DefaultTaskGraphExecuter$EventFiringTaskWorker.execute(DefaultTaskGraphExecuter.java:233); at org.gradle.execution.taskgraph.DefaultTaskGraphExecuter$EventFiringTaskWorker.execute(DefaultTaskGraphExecuter.java:215); at org.gradle.execution.taskgraph.AbstractTaskPlanExecutor$TaskExecutorWorker.processTask(AbstractTaskPlanExecutor.java:74); at org.gradle.execution.taskgraph.AbstractTaskPlanExecutor$TaskExecutorWorker.run(AbstractTaskPla,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4155:1505,Validat,ValidatingTaskExecuter,1505,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4155,1,['Validat'],['ValidatingTaskExecuter']
Security,FILTER_READS_WITH_N_CIGAR_ARGUMENT_FULL_NAME; ValidationExclusion.TYPE.ALLOW_N_CIGAR_READS. See TODO in MalformedReadFilter::checkCigarIsSupported,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/186:46,Validat,ValidationExclusion,46,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/186,1,['Validat'],['ValidationExclusion']
Security,"FO DenoiseReadCounts - Using google-cloud-java patch 6d11bef1c81f885c26b2b56c8616b7a705171e4f from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 20:08:45.223 INFO DenoiseReadCounts - Initializing engine; 20:08:45.223 INFO DenoiseReadCounts - Done initializing engine; log4j:WARN No appenders could be found for logger (org.broadinstitute.hdf5.HDF5Library).; log4j:WARN Please initialize the log4j system properly.; log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.; 20:08:45.300 INFO DenoiseReadCounts - Reading read-counts file (BT1813.counts.hdf5)...; HDF5-DIAG: Error detected in HDF5 (1.8.14) thread 0:; #000: /mnt/scr1/abyrne/HDFJava-platypus-2.11/native/HDF5-prefix/src/HDF5/src/H5F.c line 604 in H5Fopen(): unable to open file; major: File accessibilty; minor: Unable to open file; #001: /mnt/scr1/abyrne/HDFJava-platypus-2.11/native/HDF5-prefix/src/HDF5/src/H5Fint.c line 1085 in H5F_open(): unable to read superblock; major: File accessibilty; minor: Read failed; #002: /mnt/scr1/abyrne/HDFJava-platypus-2.11/native/HDF5-prefix/src/HDF5/src/H5Fsuper.c line 277 in H5F_super_read(): file signature not found; major: File accessibilty; minor: Not an HDF5 file; 20:08:49.800 INFO DenoiseReadCounts - Shutting down engine; [May 18, 2021 8:08:49 PM EDT] org.broadinstitute.hellbender.tools.copynumber.DenoiseReadCounts done. Elapsed time: 0.08 minutes.; Runtime.totalMemory()=1789919232; org.broadinstitute.hdf5.HDF5LibException: exception when opening '/hpf/largeprojects/tabori/projects/bmmrd/CNA_project/gatk_cna/gatk/analysis/lgg/cnvponC2.pon.hdf5' with READ_ONLY mode: Not an HDF5 file; at org.broadinstitute.hdf5.HDF5File.open(HDF5File.java:490); at org.broadinstitute.hdf5.HDF5File.<init>(HDF5File.java:82); at org.broadinstitute.hdf5.HDF5File.<init>(HDF5File.java:66); at org.broadinstitute.hellbender.tools.copynumber.DenoiseReadCounts.doWork(DenoiseReadCounts.java:188); at org.broadinstitute.hellbender.cmdline.CommandLineProgram",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7258:4296,access,accessibilty,4296,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7258,1,['access'],['accessibilty']
Security,"FO IndexFeatureFile - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 00:17:06.850 INFO IndexFeatureFile - Deflater: IntelDeflater; 00:17:06.855 INFO IndexFeatureFile - Inflater: IntelInflater; 00:17:06.856 INFO IndexFeatureFile - GCS max retries/reopens: 20; 00:17:06.858 INFO IndexFeatureFile - Using google-cloud-java patch 6d11bef1c81f885c26b2b56c8616b7a705171e4f from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 00:17:06.859 INFO IndexFeatureFile - Initializing engine; 00:17:06.860 INFO IndexFeatureFile - Done initializing engine; 00:17:07.292 INFO FeatureManager - Using codec VCFCodec to read file file://bad.vcf; 00:17:07.310 INFO IndexFeatureFile - Shutting down engine; [January 26, 2018 12:17:07 AM GMT] org.broadinstitute.hellbender.tools.IndexFeatureFile done. Elapsed time: 0.01 minutes.; Runtime.totalMemory()=512229376; java.lang.IllegalStateException: the progress meter has not been started yet; at org.broadinstitute.hellbender.utils.Utils.validate(Utils.java:697); at org.broadinstitute.hellbender.engine.ProgressMeter.stop(ProgressMeter.java:230); at org.broadinstitute.hellbender.utils.codecs.ProgressReportingDelegatingCodec.isDone(ProgressReportingDelegatingCodec.java:104); at htsjdk.tribble.index.IndexFactory$FeatureIterator.readNextFeature(IndexFactory.java:522); at htsjdk.tribble.index.IndexFactory$FeatureIterator.<init>(IndexFactory.java:440); at htsjdk.tribble.index.IndexFactory.createDynamicIndex(IndexFactory.java:326); at org.broadinstitute.hellbender.tools.IndexFeatureFile.createAppropriateIndexInMemory(IndexFeatureFile.java:122); at org.broadinstitute.hellbender.tools.IndexFeatureFile.doWork(IndexFeatureFile.java:71); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:136); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:179); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4269:2968,validat,validate,2968,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4269,1,['validat'],['validate']
Security,FO PathSeqPipelineSpark - Inflater: IntelInflater** ; **09:27:44.735 INFO PathSeqPipelineSpark - GCS max retries/reopens: 20** ; **09:27:44.735 INFO PathSeqPipelineSpark - Requester pays: disabled** ; **09:27:44.735 INFO PathSeqPipelineSpark - Initializing engine** ; **09:27:44.736 INFO PathSeqPipelineSpark - Done initializing engine** ; **Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties** ; **20/03/05 09:27:46 INFO SparkContext: Running Spark version 2.4.3** ; **09:27:47.141 WARN NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable** ; **20/03/05 09:27:47 INFO SparkContext: Submitted application: PathSeqPipelineSpark** ; **20/03/05 09:27:47 INFO SecurityManager: Changing view acls to: phenomata** ; **20/03/05 09:27:47 INFO SecurityManager: Changing modify acls to: phenomata** ; **20/03/05 09:27:47 INFO SecurityManager: Changing view acls groups to: ** ; **20/03/05 09:27:47 INFO SecurityManager: Changing modify acls groups to: ** ; **20/03/05 09:27:47 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(phenomata); groups with view permissions: Set(); users with modify permissions: Set(phenomata); groups with modify permissions: Set()** ; **20/03/05 09:27:48 INFO Utils: Successfully started service 'sparkDriver' on port 49119.** ; **20/03/05 09:27:49 INFO SparkEnv: Registering MapOutputTracker** ; **20/03/05 09:27:49 INFO SparkEnv: Registering BlockManagerMaster** ; **20/03/05 09:27:49 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information** ; **20/03/05 09:27:49 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up** ; **20/03/05 09:27:49 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-990bc09b-b5cf-4d67-8fec-87bfa4a6fa94** ; **20/03/05 09:27:49 INFO MemoryStore: MemoryStore started with capacity 106.5 GB** ; **20/03/05,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6493:4482,Secur,SecurityManager,4482,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6493,7,"['Secur', 'authenticat']","['SecurityManager', 'authentication']"
Security,FeatureManager provide access to a feature iterator without querying for a particular interval. This must work without the need for an index file present.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/647:23,access,access,23,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/647,1,['access'],['access']
Security,FeatureManager provide access to a feature iterator.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/647:23,access,access,23,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/647,1,['access'],['access']
Security,Figure out azure authentication in tests,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8612:17,authenticat,authentication,17,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8612,1,['authenticat'],['authentication']
Security,"FilterMutectCalls failed with ; ```; java.lang.IllegalArgumentException: beta must be greater than 0 but got -87566.7500301585; ```; ""this error only comes after the first pass of filtermutectCalls completed."". ValidateVarinats shows no errors when run on VCF.; ""The stats file was created by mutect2 for each shard and then joined with MergeMutectStats. Similar the read orientation model was built with the f1r2 files from all shards."". @davidbenjamin. --------------; Hi there,. I have a simulated dataset of related samples and currently running Mutect2 on it (10 tumor samples WGS with 130x); I managed to run everything through and now FilterMutectCalls crashes after the first pass through the variants with. ```; [October 1, 2019 12:16:16 PM UTC] org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls done. Elapsed time: 370.68 minutes.; Runtime.totalMemory()=20597702656; java.lang.IllegalArgumentException: beta must be greater than 0 but got -87566.7500301585; at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:724); at org.broadinstitute.hellbender.tools.walkers.readorientation.BetaDistributionShape.<init>(BetaDistributionShape.java:14); at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.BinomialCluster.getFuzzyBinomial(BinomialCluster.java:42); at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.BinomialCluster.learn(BinomialCluster.java:33); at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.lambda$learnAndClearAccumulatedData$7(SomaticClusteringModel.java:131); at org.broadinstitute.hellbender.utils.IndexRange.forEach(IndexRange.java:116); at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.learnAndClearAccumulatedData(SomaticClusteringModel.java:131); at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.learnParameters(Mutect2FilteringEngine.java:156); at org.broadinstitute.hellbender.tools.wa",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6202:211,Validat,ValidateVarinats,211,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6202,1,['Validat'],['ValidateVarinats']
Security,Finished up the import of sequence dictionary validation.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/629:46,validat,validation,46,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/629,1,['validat'],['validation']
Security,First cut at a python notebook to validate inputs.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7845:34,validat,validate,34,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7845,1,['validat'],['validate']
Security,Fix BQSR Dataflow test that was failing due to lack of sequence dictionary validation,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/668:75,validat,validation,75,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/668,1,['validat'],['validation']
Security,Fix Input Validation python notebook,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7853:10,Validat,Validation,10,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7853,1,['Validat'],['Validation']
Security,Fix requester pays access by updating the google-cloud-nio library to the latest release,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7700:19,access,access,19,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7700,1,['access'],['access']
Security,Fix requester pays access harder. #7716,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7730:19,access,access,19,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7730,1,['access'],['access']
Security,Fix tests in ValidateVariantsIntegrationTest,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/659:13,Validat,ValidateVariantsIntegrationTest,13,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/659,1,['Validat'],['ValidateVariantsIntegrationTest']
Security,Fixed a bug where force calling alleles were lost upon trimming by placing allele injection after trimming,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7679:82,inject,injection,82,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7679,1,['inject'],['injection']
Security,"Fixes #7068 . - When adding AC, AF, AN, DP header lines, SelectVariants now checks if these lines are in the original header already and if so, overwrites these lines with the respective standard lines; - Without this check, an issue in htsjdk causes duplicate header lines with the same ID if the description differs. This should be fixed there but this fix provides a downstream workaround; - Modified the integration test validation files, which have been invalid VCF files with duplicate header lines; - Removed addition of AC, AF, AN if `--set-filtered-gt-to-nocall` is set, because these lines will be added later anyway",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7069:425,validat,validation,425,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7069,1,['validat'],['validation']
Security,"Fixes a bug that was exposed in https://gatk.broadinstitute.org/hc/en-us/community/posts/360075631171-BQSR-no-output-table-found. The issue is that bytes are signed in java, and yet we were treating them as unsigned and directly indexing an array with them.....this works as long as you don't have weird characters in your bam/reference...but if you do you get an access error that is non-informative.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7010:21,expose,exposed,21,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7010,2,"['access', 'expose']","['access', 'exposed']"
Security,"Fixes https://github.com/broadinstitute/gatk/issues/611. Uses ""validationStringency"" as the argument; PicardCommandLineProgram currently uses ""VALIDATION_STRINGENCY""; should we align all of these to use the same name?. I've done the same work for ReadSparkSource and GATKSparkTool but it requires a Hadoop-BAM upgrade so its in a separate PR.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1439:63,validat,validationStringency,63,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1439,1,['validat'],['validationStringency']
Security,"Fixes https://github.com/broadinstitute/gatk/issues/6173. I added a single line test that shows the problem, and regenerated the other test files. I didn't write a specific unit test that proves it's solved. Feel free to do so if you think it's necessary.; I validated the output by adding the field name to the output value and checking it by eye against the header lines. This could fairly simply made into a unit test if desired. I'm not sure if there are other large files that need to be regenerated. I had initially said this bug only affects vcf but I think it happens to Maf output as well. I removed a weakly typed method that allowed this bug to occur.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6178:259,validat,validated,259,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6178,1,['validat'],['validated']
Security,"Fixes issue identified by @kgururaj when investigating GenomicsDB; dropping calls (https://github.com/broadinstitute/gatk/issues/3429#issuecomment-324188028); which is due to incorrect VCF header length descriptions. It looks like this mismatch was reported early by @LeeTL1220; in #3296 when validating VCFs. @davidbenjamin provided a partial fix in #3351, generalizing the output; to include the option of specifying R instead of A using; `includeRefAllele`, fixing MFRL and removing MCL. This fixes the 3 remaining cases, MMQ (which breaks the GenomicsDB; example), MPOS and MBQ. Fixes #3296; Fixes #3429",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3490:293,validat,validating,293,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3490,1,['validat'],['validating']
Security,Fixing hash collision issue when adding filter value to the variant context,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3305:7,hash,hash,7,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3305,1,['hash'],['hash']
Security,"For GVS Feature Extract, ~Cohort Extract~ and Prepare Callset we should add a bq labels to indicate the query and tool being. gvs_tool_name (e.g. feature-extract); gvs_query_name (e.g. read-sample-table). Python Prepare Callset:. <img width=""334"" alt=""Screen Shot 2021-05-19 at 9 31 04 AM"" src=""https://user-images.githubusercontent.com/6863459/118821262-1193eb80-b885-11eb-8456-71225b40192b.png"">. Java GVS Feature Extract:; <img width=""346"" alt=""Screen Shot 2021-05-19 at 9 31 25 AM"" src=""https://user-images.githubusercontent.com/6863459/118821247-0e006480-b885-11eb-9d95-99441c6dbebd.png"">. for Feature Extract; update the wdl to take in a query_labels optional string; update the GATK tool to take in a query_labels param; update the GATK tool to validate labels; update the GATK tool to add constant kv labels: ""gvs_tool_name"", ""extract-features"" and ""gvs_query_name"", ""extract-features"" (is there a way to get more explicit in the queries? isn't it just one query?); test that this works with and without a label param passed in. for Prepare Callset; update the wdl to take in a query_labels optional string; update the python script to take in a query_labels param; update the python scrip to validate passed in labels; update the python script to add constant kv labels for ever single query individually and as a default; test that this works with and without a label param passed in. <img width=""717"" alt=""Screen Shot 2021-05-05 at 2 40 30 PM"" src=""https://user-images.githubusercontent.com/6863459/117192554-dd61fa80-adaf-11eb-8996-be1dc266dcc2.png"">",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7233:752,validat,validate,752,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7233,2,['validat'],['validate']
Security,"For `byte[]` attributes, the `GATKSAMRecordToGATKReadAdapter.getAttributesAsString()` uses the default `Object.toString()` (className@hashCode). This is something unexpected for my point of view, because the following code may fail:. ```java; public void testGATKReadGetAttributeAsString(final GATKRead read) {; read.setAttribute(""BC"", new byte[]{'A', 'C', 'T', 'G'});; // this will fail with the current implementation; Assert.assertEquals(read.getAttributesAsString(""BC"").getBytes(Charset.forName(""UTF-8"")),; read.getAttributeAsByteArray(""BC""));; }; ```. This PR fixes the issue by identifying `byte[]` attributes and converting them to Strings by using the default GATKRead charset (UTF-8).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3223:134,hash,hashCode,134,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3223,1,['hash'],['hashCode']
Security,"For a PrintReads command that requires accessing the index, e.g. when specifying `-L` intervals, running locally works but running on `gs://` CRAM fails even if index is explicitly specified. ## Local run (server); A command that accesses a local CRAM runs fine. ```; /humgen/gsa-hpprojects/GATK/gatk4/gatk-4.beta.5/gatk-launch PrintReads \; -R /humgen/gsa-hpprojects/dev/shlee/ref/GRCh38_1kg/GRCh38_full_analysis_set_plus_decoy_hla.fa \; -I /humgen/gsa-hpprojects/dev/shlee/1kg_GRCh38_exome/HG00190.alt_bwamem_GRCh38DH.20150826.FIN.exome.cram \; -O /humgen/gsa-hpprojects/dev/shlee/1kg_GRCh38_exome/test_decram_20171002.bam \; -L chr17; ...; Using GATK jar /humgen/gsa-hpprojects/GATK/gatk4/gatk-4.beta.5/gatk-package-4.beta.5-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -Dsnappy.disable=true -jar /humgen/gsa-hpprojects/GATK/gatk4/gatk-4.beta.5/gatk-package-4.beta.5-local.jar PrintReads -R /humgen/gsa-hpprojects/dev/shlee/ref/GRCh38_1kg/GRCh38_full_analysis_set_plus_decoy_hla.fa -I /humgen/gsa-hpprojects/dev/shlee/1kg_GRCh38_exome/HG00190.alt_bwamem_GRCh38DH.20150826.FIN.exome.cram -O /humgen/gsa-hpprojects/dev/shlee/1kg_GRCh38_exome/test_decram_20171002.bam -L chr17; 14:52:10.763 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/humgen/gsa-hpprojects/GATK/gatk4/gatk-4.beta.5/gatk-package-4.beta.5-local.jar!/com/intel/gkl/native/libgkl_compression.so; [October 5, 2017 2:52:10 PM EDT] PrintReads --output /humgen/gsa-hpprojects/dev/shlee/1kg_GRCh38_exome/test_decram_20171002.bam --intervals chr17 --input /humgen/gsa-hpprojects/dev/shlee/1kg_GRCh38_exome/HG00190.alt_bwamem_GRCh38DH.20150826.FIN.exome.cram --reference /humgen/gsa-hpprojects/dev/shlee/ref/GRCh38_1kg/GRCh38_full_analysis_set_plus_decoy_hla.fa --interval_set_rule UNION --interval_padding 0 --interval_exclusion_padding 0 --interval_merging_rule ALL --readValidat",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3669:39,access,accessing,39,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3669,2,['access'],"['accesses', 'accessing']"
Security,"For example, contig-ploidy disk space is exposed only in case mode. Variable names are somewhat inconsistent, too (`disk_space_*` vs. `disk_space_gb_*`).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6995:41,expose,exposed,41,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6995,1,['expose'],['exposed']
Security,"For ingesting into the aou security boundary, use the optional service account json argument.; This also needs to localize some files manually.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7164:27,secur,security,27,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7164,1,['secur'],['security']
Security,"From @tomwhite . ""Isilon exposes a Hadoop filesystem interface which makes it possible; to use it as a source or sink for Spark. (There are some notes here:; http://www.cloudera.com/documentation/enterprise/latest/topics/cm_mc_isilon_service.html). Note however that you lose the benefits of locality, so it won't be as; fast as HDFS. Definitely worth a try. Also, for a pipeline with; multiple steps, you could use HDFS to store intermediate data, only; reading from Isilon for the source files and writing to Isilon with; the final result.""",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1508:25,expose,exposes,25,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1508,1,['expose'],['exposes']
Security,"From our normal-normal validation. Some irrelevant annotations removed. ```; 3	124464215	.	ATTT	A,ATTTT	.	PASS	N_ART_LOD=-1.573e+00,7.21;RPA=15,12,16;RU=T;STR;TLOD=5.65,4.81	GT:AD:AF 0/1/2:91,12,6:0.183,0.174 0/0:100,13,8:0.166,0.179; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4689:23,validat,validation,23,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4689,1,['validat'],['validation']
Security,Full scientific validation via end to end comparison of filtered results between WARP and BQ,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7179:16,validat,validation,16,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7179,1,['validat'],['validation']
Security,Fully validate HaplotypeCaller walker for production (with help of palantir and/or short variants team),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1640:6,validat,validate,6,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1640,1,['validat'],['validate']
Security,Funcotator - Added map-style accessor for fields.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4176:29,access,accessor,29,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4176,1,['access'],['accessor']
Security,Funcotator - Need a validation tool for data sources,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4380:20,validat,validation,20,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4380,1,['validat'],['validation']
Security,Funcotator - Refactor Funcotation class to use a HashMap for each field,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3919:49,Hash,HashMap,49,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3919,1,['Hash'],['HashMap']
Security,Funcotator should validate datasource version at startup.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5660:18,validat,validate,18,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5660,1,['validat'],['validate']
Security,"G: [kryo] Read: WrappedArray([]); 02:25 DEBUG: [kryo] Read: WrappedArray([]); 02:25 DEBUG: [kryo] Write: scala.Tuple3[]; ...; 02:42 DEBUG: [kryo] Write object reference 1941: HLA-A*24:152; 02:42 DEBUG: [kryo] Write object reference 1945: chrUn_JTFH01001224v1_decoy; 02:42 DEBUG: [kryo] Write object reference 1949: HLA-B*14:01:01; 02:42 DEBUG: [kryo] Write object reference 1953: chr5_GL949742v1_alt; ...; 02:42 DEBUG: [kryo] Write object reference 1942: SAMSequenceRecord(name=HLA-A*24:152,length=3176,dict_index=2919,assembly=null,alternate_names=[]); 02:42 DEBUG: [kryo] Write object reference 1946: SAMSequenceRecord(name=chrUn_JTFH01001224v1_decoy,length=1051,dict_index=2066,assembly=null,alternate_names=[]); 02:42 DEBUG: [kryo] Write object reference 1950: SAMSequenceRecord(name=HLA-B*14:01:01,length=3312,dict_index=2999,assembly=null,alternate_names=[]); 02:42 DEBUG: [kryo] Write object reference 1954: SAMSequenceRecord(name=chr5_GL949742v1_alt,length=226852,dict_index=241,assembly=null,alternate_names=[]); ...; 02:42 DEBUG: [kryo] Write: Array[java.lang.Object]; 02:42 DEBUG: [kryo] Write: Object[]; 02:42 DEBUG: [kryo] Write: byte[]; 02:42 DEBUG: [kryo] Write: WrappedArray([]); ...; 03:20 DEBUG: [kryo] Read: CompressedMapStatus; 03:20 DEBUG: [kryo] Write: Array[java.lang.Object]; 03:20 DEBUG: [kryo] Write: Object[]; 03:20 DEBUG: [kryo] Write: byte[]; 03:20 DEBUG: [kryo] Read: Array[java.lang.Object]; 03:20 DEBUG: [kryo] Read: Object[]; 03:21 DEBUG: [kryo] Write: TaskCommitMessage; 03:21 DEBUG: [kryo] Read: TaskCommitMessage; ```. #### Steps to reproduce; **Command:**; ```; gatk --java-options ""-Djava.io.tmpdir=/scratch"" MarkDuplicatesSpark --input C19CUACXX.1.1-1.sorted.bam --output /scratch/C19CUACXX.1.1.sorted.Spark.Strigency-strict.bam --conf 'spark.local.dir=/scratch' --tmp-dir /scratch --read-validation-stringency STRICT; ```. #### Expected behavior; Finish MarkDuplicatesSpark successfully and output a valid bam file. #### Actual behavior; The bam file is empty.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8134:2892,validat,validation-stringency,2892,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8134,1,['validat'],['validation-stringency']
Security,GATK exposes Picard tools thru its command line interface. The usage syntax is different between these two tool kits and so picard code examples in javadocs don't make that much sense when displayed in GATK's own docs. For now code examples embeded in the Picard repo should stick to picard syntax as a matter of principle. So the solution is to transform those snippets on-the-fly when we generate the gatk-docs. . The is a good opportunity to do so in ```GATKHelpDocWorkUnitHandler``` by overloading the ```getDescription(DocWorkUnit)``` so that any occurrence of a picard.jar example is translated into gatk's version:; ```. <pre>java -jar picard.jar toolName \; ARG1=VAL1 \; ARG2=VAL2 ; </pre>; ```. to this:. ```; <pre>gatk toolName \; -ARG1 VAL1 \; --ARG2 VAL2; </pre>; ```. The difficult part is to find-out the mapping of picard argument names and gatk's exposed picard argument names and whether these need single or double dash. To this end we can use some reflection.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3932:5,expose,exposes,5,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3932,2,['expose'],"['exposed', 'exposes']"
Security,GATK4 ValidateVariants Doc,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2759:6,Validat,ValidateVariants,6,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2759,1,['Validat'],['ValidateVariants']
Security,GATKSparkTool should use stricter validation for CRAMs,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1179:34,validat,validation,34,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1179,1,['validat'],['validation']
Security,"GATKVariantContextUtils.createVCFWriter attempts to determine the output vcf type based on the file extension provided by the user, and defaults to vcf if the extension isn't a recognized type. There is code in VariantContextWriterBuilder (determineOutputTypeFromFile) in htsjdk that attempts to do the same mapping, but isn't public. We should expose that in htsjdk and use it in GATKVariantConextUtils so we can get rid of the redundant code.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2128:345,expose,expose,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2128,1,['expose'],['expose']
Security,"GRCh37, and this will be fine in the vast majority of cases.  There MAY be some errors (e.g. in the Y chromosome, but possibly in other places as well) due to changes between the two references. ; ; 12:37:55.679 INFO  ProgressMeter - Starting traversal ; ; 12:37:55.679 INFO  ProgressMeter -        Current Locus  Elapsed Minutes    Features Processed  Features/Minute ; ; 12:37:56.198 WARN  FuncotatorUtils - Reference allele is different than the reference coding sequence (strand: -, alt = G, ref G != T reference coding seq) @\[chr1:13839497\]!  Substituting given allele for sequence code (TTC->GTC) ; ; 12:37:56.213 INFO  FuncotateSegments - Shutting down engine ; ; \[February 9, 2022 12:37:56 PM EST\] org.broadinstitute.hellbender.tools.funcotator.FuncotateSegments done. Elapsed time: 0.24 minutes. ; ; Runtime.totalMemory()=3139436544 ; ; java.lang.IllegalArgumentException: Invalid interval. Contig:chr1 start:29534 end:14501 ; ;     at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:804) ; ;     at org.broadinstitute.hellbender.utils.SimpleInterval.validatePositions(SimpleInterval.java:59) ; ;     at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:35) ; ;     at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.segment.SegmentExonUtils.findInclusiveExonIndex(SegmentExonUtils.java:95) ; ;     at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.segment.SegmentExonUtils.determineSegmentExonPosition(SegmentExonUtils.java:63) ; ;     at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createSegmentFuncotations(GencodeFuncotationFactory.java:2938) ; ;     at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createSegmentFuncotations(GencodeFuncotationFactory.java:2914) ; ;     at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsOnSegment(GencodeF",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7676:2393,validat,validateArg,2393,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7676,1,['validat'],['validateArg']
Security,Gatk validate variants doesn't report an error on non-spec-compliant headers,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6762:5,validat,validate,5,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6762,1,['validat'],['validate']
Security,Gave SortSam lenient validation in M2 wdl,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4844:21,validat,validation,21,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4844,1,['validat'],['validation']
Security,Generate Avro Files run: https://app.terra.bio/#workspaces/gvs-dev/RSA%20-%20GVS%20Quickstart%20V2%20/job_history/577e77f2-4174-46c0-9d8a-9fdbbd2a27ed. Generate VDS run: https://app.terra.bio/#workspaces/gvs-dev/RSA%20-%20GVS%20Quickstart%20V2%20/job_history/27299041-7779-49d7-b7d3-6c0349f5ffc3. Generate VAT run: https://app.terra.bio/#workspaces/gvs-dev/RSA%20-%20GVS%20Quickstart%20V2%20/job_history/ad1b2687-7df0-4e92-b4e2-b61fcb77cd19. Validate VAT run: https://app.terra.bio/#workspaces/gvs-dev/RSA%20-%20GVS%20Quickstart%20V2%20/job_history/dae4874f-a619-40d4-84b4-066295b76cb2,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8702:442,Validat,Validate,442,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8702,1,['Validat'],['Validate']
Security,"GenomicsDBImport currently doesn't support multi-sample input vcfs. We've had a number of usesr request the ability to import precombined multi-sample vcfs. . People may have old call-sets which they would like to combine with new data, and do not have access to the original single sample gvcfs needed to recombine them in GenomicsDBImport. . It would be good if we could import these directly into GenomicsDB.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6530:253,access,access,253,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6530,1,['access'],['access']
Security,"Go the following:. ```; Current git hash does not match GATK git hash. Run anyway?yes; error: malformed object name 1; usage: git branch [<options>] [-r | -a] [--merged | --no-merged]; or: git branch [<options>] [-l] [-f] <branch-name> [<start-point>]; or: git branch [<options>] [-r] (-d | -D) <branch-name>...; or: git branch [<options>] (-m | -M) [<old-branch>] <new-branch>; or: git branch [<options>] [-r | -a] [--points-at]; ...; ```; Not sure the first error message about the ""hashes"" means perhaps that is the cause though. Assigned to @TedBrookings because I think this is you beast.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3593:36,hash,hash,36,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3593,3,['hash'],"['hash', 'hashes']"
Security,"Goal was to get WGS coverage collection at 100bp at ~15 cents per sample. Since this is I/O bound (takes ~2 hours to stream or localize a BAM, or about the same to decompress a CRAM), cost reduction can be most easily achieved by reducing the memory requirements and moving down to a cheaper VM. . Memory requirements at 100bp are dominated by manipulations of the list of ~30M intervals. There were a few easy fixes to reduce requirements that did not require changing the collection method (which can be easily modified for future investigations, see #4551):. -removed WellformedReadFilter. See #5233. EDIT: We decided after PR review to retain this filter by default and disable it at the WDL level when Best Practices is released. Leaving the issue open.; -initialized HashMultiSet capacity; -removed unnecessary call to OverlapDetector.getAll; -avoided a redundant defensive copy in SimpleCountCollection; -used per-contig OverlapDetectors, rather than a global one. This brought the cost down to ~9 cents per sample using n1-standard-2's with 7.5GB of memory when collecting on BAMs with NIO. Note that I didn't optimize disk size, which accounts for ~50% of the total cost and is unused when running with NIO, so we are closer to ~5 cents per sample. It is possible that using CRAMs with or without NIO and with or without SSDs might be cheaper. Note that OverlapDetectors may be overkill for our case, since bins are guaranteed to be sorted and non-overlapping and queries are also sorted. We could probably roll something that is O(1) in memory. However, since we are I/O bound, as long as we are satisfied with the current cost, I am willing to sacrifice memory for implementation and maintenance costs, as well as the option to change strategies easily. In any case, @lbergelson found some easy wins in OverlapDetector that may further bring the memory usage down, and will issue a fix in htsjdk soon.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5715:773,Hash,HashMultiSet,773,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5715,1,['Hash'],['HashMultiSet']
Security,"Google is deprecating and removing their implementation of the old style GA4GH read and reference API's. . > ; > Reads API functionality is now replaced by the htsget protocol ; > ; > This year, the GA4GH team introduced the htsget protocol to allow users to download read data for subsections of the genome in which they are interested. This is a richer and more flexible approach to working with reads data. It allows you to keep your genomics data in a common BAM file format on Google Cloud Storage and work with it efficiently from your computation pipelines, using standard bioinformatics tools. We have already launched our own open source implementation of this protocol, which you can use to access your reads data. Many popular tools such as samtools and htslib have been updated by the community to support htsget. Documentation is provided here. The Reads API is now deprecated, and will be decommissioned after one year, or after there has been no API activity for one month by those receiving this notice, whichever comes first. ; > ; > Variants API is now replaced by htsget and Variant Transforms ; > ; > The GA4GH team also plans to extend the htsget protocol to cover variant data, and we will extend our implementation of htsget to cover this use case. ; > ; > After analyzing usage of the Variants API, we found that users primarily used it to import variant data and then export it to BigQuery. To save time and effort, we created Variant Transforms, an open source tool for directly importing VCF data into BigQuery. Variant Transforms and its documentation are published here. Variant Transforms is more scalable than the legacy Variants API, and it has a robust roadmap with a dedicated team. We also welcome collaborators on this project as it advances. ; > ; > The Variants API is now deprecated, and will be decommissioned after one year, or after there has been no API activity for one month, whichever comes first. ; > ; > We are excited to move in step with the global ge",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4166:701,access,access,701,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4166,1,['access'],['access']
Security,"HI, ; the following commands were included at my bash script .; after I ran them, I got a log file with ""Tool returned:; 6785087"", I am not sure why the return code is 6785087 , not 0 ???. Anything wrong with my commands ?; Thanks ! . gatk-4.1.2.0/gatk BaseRecalibrator -R $fasta -I $tumor_bam --known-sites a.vcf --known-sites b.vcf ; --intervals t.bed --interval-padding 50 --read-validation-stringency SILENT -O recal_data.table . gatk-4.1.2.0/gatk ApplyBQSR -R $fasta -I $tumor_bam --bqsr-recal-file recal_data.table ; --intervals t.bed --interval-padding 50 --read-validation-stringency SILENT -O recal_data.bam",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6056:383,validat,validation-stringency,383,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6056,2,['validat'],['validation-stringency']
Security,Hand HaplotypeCaller snapshot with first-pass validation issues addressed off to palantir for second-pass validation,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3233:46,validat,validation,46,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3233,2,['validat'],['validation']
Security,HashedListTargetCollection has unnatural contig order,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1754:0,Hash,HashedListTargetCollection,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1754,1,['Hash'],['HashedListTargetCollection']
Security,"Hello, more information on the parameters and runtime can be found here: #7492 . the stacktrace is now:; ```; ...; 22:14:59.985 INFO ProgressMeter - chrUn_JTFH01001653v1_decoy:301 116.6 2161460 18530.7; 22:15:11.142 INFO ProgressMeter - chrUn_JTFH01001673v1_decoy:301 116.8 2161540 18501.9; Using GATK jar /root/gatk.jar defined in environment variable GATK_LOCAL_JAR; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx15500m -jar /root/gatk.jar Mutect2 -R gs://genomics-public-data/resources/broad/hg38/v0/Homo_sapiens_assembly38.fasta -I gs://cclebams/hg38_wes/CDS-02waxZ.hg38.bam -tumor TUHR14TKB --germline-resource gs://depmapomicsdata/gnomad.genomes.r3.0.sites.vcf.bgz -pon gs://depmapomicsdata/1000g_pon.hg38.vcf.gz -L gs://fc-secure-d2a2d895-a7af-4117-bdc7-652d7d268324/cec2a1a6-ffc3-4f1b-ba94-27ae918c56e9/Mutect2/b389d86b-8b0b-4d77-8224-a5a3e3a0b4e5/call-SplitIntervals/cacheCopy/glob-0fc990c5ca95eebc97c4c204e3e303e1/0004-scattered.interval_list -O output.vcf.gz --f1r2-tar-gz f1r2.tar.gz --gcs-project-for-requester-pays broad-firecloud-ccle; ln: failed to access '/cromwell_root/*normal-pileups.table': No such file or directory; ln: failed to access '/cromwell_root/*tumor-pileups.table': No such file or directory; 2021/10/05 22:15:24 Starting delocalization.; ...; ```. I run mutect2 in tumor only mode. ; Interestingly, this error always only happen at the last shard only (every other shard runs to completion). Thanks!",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7494:858,secur,secure-,858,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7494,3,"['access', 'secur']","['access', 'secure-']"
Security,"Hello,. There was at least one prior conversation about migrating or not migrating GATK3 CombineVariants to GATK4. My understanding is that there was a decision in GATK not to migrate CombineVariants, and instead push people to use Picard MergeVcfs. As you know, Picard MergeVcfs is somewhat similar; however, it doesnt merge genotypes. That is a pretty big difference in function. . CombineVariants is one of the few GATK3 tools my lab is still using. I'd like to move us off GATK3 in the coming months. Given GATK has already decided not to migrate it, I would first like to propose that we could port and take it over in my lab's DISCVRseq project (https://github.com/bimberlab/discvrseq). I'm happy to give attribution to GATK, etc. I would likely rename it MergeVcfsAndGenotypes (this is more intuitive to me), but I would otherwise not change functionality much. I'd prefer to do this instead of porting to GATK4 because porting to GATK is going to throw up a lot more obstacles and probably require that I modernize/update a good amount of that tool's code. I appreciate why this is required, but it takes a lot more work from us. If you did not like this, I'm open to considering porting to GATK4. In my initial review, it looked like CombineVariants was fairly self-contained and that most of the accessory code (merging genotypes is the most complex thing) was already migrated to GATK4. Some of you may have already done a more thorough review of it. . What do you think?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7038:1306,access,accessory,1306,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7038,1,['access'],['accessory']
Security,"Here it is. An overview of what's been added:; - metrics package; - a few general metrics classes (e.g. MultiLevelMetrics); - may want to push these down into HTSJDK later; - added some utils; - utils.gene: gene annotation; - utils.illumina: general Illumina-related utils (adapters, etc); - utils.text.parsers: text parsing; - utils.variant: added dbSNP stuff; - MathUtils: added a few basic things (mean, stddev, etc) with unit tests; - tools; - three major packages:; - analysis: metrics + analyses (including necessary Rscripts); - illumina: Illumina parsing + validation; - vcf: VCF manipulation + GenotypeConcordance; - also two smaller packages, fastq and intervals, containing a few tools each; - tests; - all existing tests were ported; still, overall test coverage goes down by ~6%; - all CLP integration tests have been ported to the new argument system; - test data has also been carried over, and is neatly organized; - there are no huge files, and very few above 100KB (just a few VCFs I think); - however, the Illumina test data is pretty big - ~6MB spread over ~1700 files",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/347:565,validat,validation,565,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/347,1,['validat'],['validation']
Security,"Hey folks,. I have a test dataset that interestingly core-dumps or JVM errors with `--smith-waterman FASTEST_AVAILABLE` but not with `--smith-waterman JAVA`. The only thing I can think of is somehow Intel's HMM has a length limitation, as I am using `--assembly-region-padding 1000` to GATK to call 100-1000bp indels (and it works!). I cannot share the test BAM unfortunately. What can I do to help debug further?. I'm using `gatk4-4.1.8.1-0` from `conda create -n debug-gatk4 -c defaults -c conda-forge -c bioconda gatk4`. ```; $gatk ... -version; The Genome Analysis Toolkit (GATK) v4.1.8.1; HTSJDK Version: 2.23.0; Picard Version: 2.22.8; $ java -version; openjdk version ""1.8.0_152-release""; OpenJDK Runtime Environment (build 1.8.0_152-release-1056-b12); OpenJDK 64-Bit Server VM (build 25.152-b12, mixed mode); ```. First error motif:; ```; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x000000010efa9dc2, pid=23946, tid=0x000000000000a503; #; # JRE version: OpenJDK Runtime Environment (8.0_152-b12) (build 1.8.0_152-release-1056-b12); # Java VM: OpenJDK 64-Bit Server VM (25.152-b12 mixed mode bsd-amd64 compressed oops); # Problematic frame:; # V [libjvm.dylib+0x3a9dc2] PhaseIdealLoop::set_ctrl(Node*, Node*)+0x10; #; # Failed to write core dump. Core dumps have been disabled. To enable core dumping, try ""ulimit -c unlimited"" before starting Java again; #; # An error report file with more information is saved as:; #; # Compiler replay data is saved as:; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; ```. Second error motif:; ```; java(24057,0x7000035bd000) malloc: Incorrect checksum for freed object 0x7fd8a8193600: probably modified after being freed.; Corrupt value: 0x2e4630002e47e; java(24057,0x7000035bd000) malloc: *** set a breakpoint in malloc_error_break to debug; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6733:1703,checksum,checksum,1703,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6733,1,['checksum'],['checksum']
Security,"Hi ; I am using GATK 4.1.7.0, and have faced an issue running the seq-format-validation workflow. basically the process is ran but ends in failed state and the main output does not appear. I have attached here the exact command, stderr,validate-bam-inputs.json and validate-bam.wdl. The stdout just says 230. ; I would be grateful for any help on how to solve the issue. ; Best ; zara. <img width=""1280"" alt=""Screen Shot 2020-07-16 at 12 01 12 AM"" src=""https://user-images.githubusercontent.com/61913000/87845900-e6491480-c8e0-11ea-8dc0-ec5b3fbc15a8.png"">; <img width=""1280"" alt=""Screen Shot 2020-07-16 at 12 01 19 AM"" src=""https://user-images.githubusercontent.com/61913000/87845901-e77a4180-c8e0-11ea-8c6a-fb5783949ba3.png"">; <img width=""353"" alt=""Screen Shot 2020-07-16 at 12 00 30 AM"" src=""https://user-images.githubusercontent.com/61913000/87845902-ea753200-c8e0-11ea-96bc-caecee2ccb39.png"">; <img width=""1249"" alt=""stderr1"" src=""https://user-images.githubusercontent.com/61913000/87845904-eea14f80-c8e0-11ea-90bd-235c9205f72f.png"">. (gatk) root@bc3c6aca6231:/gatk/my_data/tools# java -jar cromwell-51.jar run /gatk/my_data/seq-format-validation/validate-bam.wdl --inputs /gatk/my_data/seq-format-validation/validate-bam.inputs.json; [2020-07-14 05:09:22,78] [info] Running with database db.url = jdbc:hsqldb:mem:f10b64bd-d8ca-4428-917b-311fca24c372;shutdown=false;hsqldb.tx=mvcc; [2020-07-14 05:09:29,36] [info] Running migration RenameWorkflowOptionsInMetadata with a read batch size of 100000 and a write batch size of 100000; [2020-07-14 05:09:29,37] [info] [RenameWorkflowOptionsInMetadata] 100%; [2020-07-14 05:09:29,47] [info] Running with database db.url = jdbc:hsqldb:mem:e337a356-2f0c-4389-92c5-255465180f24;shutdown=false;hsqldb.tx=mvcc; [2020-07-14 05:09:29,89] [info] Slf4jLogger started; [2020-07-14 05:09:30,10] [info] Workflow heartbeat configuration:; {; ""cromwellId"" : ""cromid-ca5c695"",; ""heartbeatInterval"" : ""2 minutes"",; ""ttl"" : ""10 minutes"",; ""failureShutdownDuration"" : ""5 ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6710:77,validat,validation,77,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710,3,['validat'],"['validate-bam', 'validate-bam-inputs', 'validation']"
Security,Hi ; We have a forum post asking help for getting GATK 4.1.0.0 conda environment installed using the yml file. ; [https://gatk.broadinstitute.org/hc/en-us/community/posts/18332470602523-Install-GATK-version-4-1-0-0-using-Conda-](url). Looks like restructuring of the default repository under conda took out some of these packages and they are no longer directly accessible. They can be accessed from the forge repo with certain flags. This issue seems to deprecate some of the older but still usable versions of GATK (due to various reasons). Directing people to use the docker version or upgrading to the latest GATK version seems to be the only solution left for now. Any other ideas of how we should pursue this issue? @lbergelson @droazen ?,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8504:362,access,accessible,362,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8504,2,['access'],"['accessed', 'accessible']"
Security,"Hi Chris,. Would you please review this?; And @tedsharpe, feel free to look at the getters in `InsertSizeMetricsCollectorSpark.java` and see if you need more access functions. Thank you.; Steve",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1566:158,access,access,158,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1566,1,['access'],['access']
Security,"Hi all,. Below error occurs trying to access Funcotator data source directory installed on lustre file system. We have a non-lustre mounted fs for cases like this, but I thought it was worth bringing up. ```; org.broadinstitute.hellbender.exceptions.GATKException: Unable to query the database for geneName: null; 	at org.broadinstitute.hellbender.tools.funcotator.dataSources.cosmic.CosmicFuncotationFactory.createFuncotations(CosmicFuncotationFactory.java:244); 	at org.broadinstitute.hellbender.tools.funcotator.Funcotator.enqueueAndHandleVariant(Funcotator.java:404); 	at org.broadinstitute.hellbender.tools.funcotator.Funcotator.apply(Funcotator.java:316); 	at org.broadinstitute.hellbender.engine.VariantWalkerBase.lambda$traverse$0(VariantWalkerBase.java:110); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); 	at org.broadinstitute.hellbender.engine.VariantWalkerBase.traverse(VariantWalkerBase.java:108); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:893); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:136); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:179); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgr",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4413:38,access,access,38,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4413,1,['access'],['access']
Security,"Hi all;; When validation runs on the GATK 4.0.0 release (congrats!) we're running into segfault issues on some `GenomicsDBImport` runs which look to be due to the length of the database path:; ```; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x00007f99a7642c5b, pid=7446, tid=0x00007f99fbfa0700; #; # JRE version: OpenJDK Runtime Environment (8.0_121-b15) (build 1.8.0_121-b15); # Java VM: OpenJDK 64-Bit Server VM (25.121-b15 mixed mode linux-amd64 compressed oops); # Problematic frame:; # C [libtiledbgenomicsdb8843204539247232071.so+0x4fdc5b] std::string::compare(char const*) const+0x1b; ```; Here is a self-contained test case that reproduces the issue:. https://s3.amazonaws.com/chapmanb/testcases/gatk/gatk4_genomicsdb_length.tar.gz. A standard small name and longer name of 105 characters work fine:; ```; gatk-launch --java-options '-Xms1g -Xmx2g' GenomicsDBImport --reader-threads 1 --genomicsdb-workspace-path short_genomicsdb -L chr22:15069-15500 --variant Test1.vcf.gz --variant Test2.vcf.gz; gatk-launch --java-options '-Xms1g -Xmx2g' GenomicsDBImport --reader-threads 1 --genomicsdb-workspace-path long_aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa_genomicsdb/works_aaaaaaaaaaaaaaaaaaaaaaaaaa -L chr22:15069-15500 --variant Test1.vcf.gz --variant Test2.vcf.gz; ```; But when you add an additional character, you trigger the segfault:; ```; gatk-launch --java-options '-Xms1g -Xmx2g' GenomicsDBImport --reader-threads 1 --genomicsdb-workspace-path long_aaaaaa; aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa_genomicsdb/fails_aaaaaaaaaaaaaaaaaaaaaaaaaaa -L chr22:15069-15500 -; -variant Test1.vcf.gz --variant Test2.vcf.gz; ```; Thank you for looking at this and please let me know if I can provide any other information to help debug.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4160:14,validat,validation,14,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4160,1,['validat'],['validation']
Security,"Hi everyone,. I'm facing a similar issue with GATK v4.1.0.0 (HTSJDK v2.18.2 and Picard v2.18.25). I'm using GATK Docker image broadinstitute/gatk:4.1.0.0. Following what I read here, I checked the bam file and everything seems fine:; `gatk ValidateSamFile --INPUT sorted.bam --MODE SUMMARY`; ```; Using GATK jar /gatk/gatk-package-4.1.0.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /gatk/gatk-package-4.1.0.0-local.jar ValidateSamFile --INPUT CQ-NEQAS-2018.ILLUMINA.library.000000000-BCFDC.1.1.sorted.bam --MODE SUMMARY; 16:08:17.382 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/gatk/gatk-package-4.1.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; [Thu Mar 07 16:08:17 UTC 2019] ValidateSamFile --INPUT CQ-NEQAS-2018.ILLUMINA.library.000000000-BCFDC.1.1.sorted.bam --MODE SUMMARY --MAX_OUTPUT 100 --IGNORE_WARNINGS false --VALIDATE_INDEX true --INDEX_VALIDATION_STRINGENCY EXHAUSTIVE --IS_BISULFITE_SEQUENCED false --MAX_OPEN_TEMP_FILES 8000 --SKIP_MATE_VALIDATION false --VERBOSITY INFO --QUIET false --VALIDATION_STRINGENCY STRICT --COMPRESSION_LEVEL 2 --MAX_RECORDS_IN_RAM 500000 --CREATE_INDEX false --CREATE_MD5_FILE false --GA4GH_CLIENT_SECRETS client_secrets.json --help false --version false --showHidden false --USE_JDK_DEFLATER false --USE_JDK_INFLATER false; [Thu Mar 07 16:08:24 UTC 2019] Executing as mpmachado@lx-bioinfo02 on Linux 2.6.32-696.23.1.el6.x86_64 amd64; OpenJDK 64-Bit Server VM 1.8.0_191-8u191-b12-0ubuntu0.16.04.1-b12; Deflater: Intel; Inflater: Intel; Provider GCS is available; Picard version: Version:4.1.0.0; WARNING 2019-03-07 16:08:24 ValidateSamFile NM validation cannot be performed without the reference. All other validations will still occur.; INFO 2019-03-07 16:10:25 SamFileValidator Validated Read 10,000,000 records. Elapsed time: 00:02:00s. Time for last 10,000,000: 120s. La",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5807:240,Validat,ValidateSamFile,240,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5807,3,['Validat'],['ValidateSamFile']
Security,"Hi folks. @chandrans and I have laid out some plans towards updating GATK4 docs for the January 9 release. Our approach is to prioritize documentation around stable Best Practice Workflows. On the docket currently is the single stable workflow--germline SNP and indel calling from DNA data. We will of course update tool docs (excluding Spark and BWA tools) and supporting tutorials. Even for tools we are unfamiliar with, we aim to have at the least a basic description and an example command. Thanks for the documentation you have already done and the help you give us in updating these. If you are certain your workflow will be ready for the release, then please let us know immediately so we can plan accordingly. If your workflow will be ready later, then can you still give us an estimate for your release so we can plan ahead? Thanks. - @davidbenjamin, did I hear you correctly that you think somatic SNV and indel calling will be ready for the Jan 9 release?; - @samuelklee, I know major changes are currently afoot for somatic CNV. Will you make the Jan 9 release for the targeted exomes use-case? What about WGS?; - @mbabadi, is March, 2018 still the plan?; - @jonn-smith, what is the status on the Tool-That-Must-Not-Be-Named?; - @cwhelan @tedsharpe @SHuang-Broad, is SV on for next year or thereafter?. It would be most helpful to users if we also have validation of our workflows as applied to real data. Are there plans to make benchmarking stats available for each of your workflows?. Sheila and I have 30-man days we can give between us towards updating documentation by December 14. Besides Geraldine, we will rely on some of you to review further refinements to documentation from now to December 14. Thanks again.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3769:1365,validat,validation,1365,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3769,1,['validat'],['validation']
Security,"Hi, I encountered the following error while running GATK.; It is hard for me to say what exactly is wrong, and extensive searching has not been helpul. Thanks in advance!. ```; gatk ValidateVariants -V ../../data/geno/phased/chr1-22.phased.rename.reheader.vcf.gz -R ../../../../index/hg19.fa.gz; Using GATK jar ~/tools/gatk-4.1.8.0/gatk-package-4.1.8.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /home/zepengmu/tools/gatk-4.1.8.0/gatk-package-4.1.8.0-local.jar ValidateVariants -V ../../data/geno/phased/chr1-22.phased.rename.reheader.vcf.gz -R ../../../../index/hg19.fa.gz; 19:53:34.379 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/zepengmu/tools/gatk-4.1.8.0/gatk-package-4.1.8.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Oct 25, 2020 7:53:34 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 19:53:34.606 INFO ValidateVariants - ------------------------------------------------------------; 19:53:34.606 INFO ValidateVariants - The Genome Analysis Toolkit (GATK) v4.1.8.0; 19:53:34.606 INFO ValidateVariants - For support and documentation go to https://software.broadinstitute.org/gatk/; 19:53:34.607 INFO ValidateVariants - Executing as zepengmu@midway2-login1.rcc.local on Linux v3.10.0-1127.8.2.el7.x86_64 amd64; 19:53:34.607 INFO ValidateVariants - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_45-b14; 19:53:34.607 INFO ValidateVariants - Start Date/Time: October 25, 2020 7:53:34 PM CDT; 19:53:34.607 INFO ValidateVariants - ------------------------------------------------------------; 19:53:34.607 INFO ValidateVariants - ------------------------------------------------------------; 19:53:34.607 INFO ValidateVariants - HTSJDK Version: 2.22.0; 19:53:34.607 INFO ValidateVarian",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6911:182,Validat,ValidateVariants,182,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6911,2,['Validat'],['ValidateVariants']
Security,"Hi,. I had used ""ASEReadCounter"" with the GRCh37 Genome on my samples and I got results even when I had this warning:; ""IndexDictionaryUtils - Track sitesVCFFile doesn't have a sequence dictionary built in, skipping dictionary validation "". The problem is that now I'm using just the canonical chromosomes as a reference and I'm getting the same warning but the output file is empty. Could someone help me? . Thanks,; Cristian",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6540:227,validat,validation,227,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6540,1,['validat'],['validation']
Security,"Hi,. I'm trying to validate the performance of BwaSpark (I'm running it locally). The input ubam file size is 5.1 GB. It takes 65 minutes for GATK's BwaSpark to complete which is exactly same as bwa-mem. Below is the command that I used to run BwaSpark. Is there any way to make BwaSpark run faster while running it locally or will the performance increase only while running on spark cluster? Please let me know if I had to modify or add any parameter. . Also, please let me know where can I find the complete list of --conf parameters for BwaSpark? (I couldn't find these options in gatk BwaSpark --help). `time gatk BwaSpark --bwa-mem-index-image GRCh37.fasta.img --spark-master local[*] --bam-partition-size 4000000 --conf 'spark.executor.num=5' --conf 'spark.executor.cores=16' --conf 'spark.executor.memory=15G' --conf 'spark.driver.memory=30G' --conf 'spark.dynamicAllocation.enabled=true' -I unmapped_input.bam -O output.bam -R GRCh37.fasta 2> Log_file.log`",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8897:19,validat,validate,19,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8897,1,['validat'],['validate']
Security,"Hi,. Using GATK mutect2's wdl file on Terra (version 21 on agora) I keep getting the same error:; ""pet-102022583875839491351@broad-firecloud-ccle.iam.gserviceaccount.com does not have storage.buckets.get access to the Google Cloud Storage bucket"" . Here is part of the stacktrace : ; ```; 20:59:48.744 INFO Mutect2 - Inflater: IntelInflater; 20:59:48.744 INFO Mutect2 - GCS max retries/reopens: 20; 20:59:48.744 INFO Mutect2 - Requester pays: enabled. Billed to: broad-firecloud-ccle; 20:59:48.744 INFO Mutect2 - Initializing engine; 20:59:54.630 INFO FeatureManager - Using codec VCFCodec to read file gs://depmapomicsdata/1000g_pon.hg38.vcf.gz; 20:59:55.629 INFO Mutect2 - Shutting down engine; [October 4, 2021 8:59:55 PM GMT] org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2 done. Elapsed time: 0.12 minutes.; Runtime.totalMemory()=876609536; code: 403; message: pet-102022583875839491351@broad-firecloud-ccle.iam.gserviceaccount.com does not have storage.buckets.get access to the Google Cloud Storage bucket.; reason: forbidden; location: null; retryable: false; com.google.cloud.storage.StorageException: pet-102022583875839491351@broad-firecloud-ccle.iam.gserviceaccount.com does not have storage.buckets.get access to the Google Cloud Storage bucket.; at com.google.cloud.storage.spi.v1.HttpStorageRpc.translate(HttpStorageRpc.java:229); at com.google.cloud.storage.spi.v1.HttpStorageRpc.get(HttpStorageRpc.java:406); at com.google.cloud.storage.StorageImpl$4.call(StorageImpl.java:217); ...; ```. This happens while it runs the command:. ```; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx15500m\ ; -jar /root/gatk.jar Mutect2 -R gs://genomics-public-data/resources/broad/hg38/v0/Homo_sapiens_assembly38.fasta\ ; -I gs://cclebams/hg38_wes/CDS-00rz9N.hg38.bam -tumor BC1_HAEMATOPOIETIC_AND_LYMPHOID_TISSUE --germline-resource gs://gcp-public-data--gnomad/release/3",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7492:204,access,access,204,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7492,1,['access'],['access']
Security,"I added a test according to #4642 , but can't reproduce the error. The user also noted that the error message was badly formed, which is true because it ended with a colon. Now it looks like:; ""Input src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleBad.vcf fails strict validation of type CHR_COUNTS: the Allele Count (AC) tag is incorrect for the record at position 1:985447, 1 vs. 2""",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6076:263,Validat,ValidateVariants,263,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6076,3,"['Validat', 'validat']","['ValidateVariants', 'validation', 'validationExampleBad']"
Security,I am getting the following exception when I set `--minimum-mapping-quality` to 60 (but not 50). . ```console; $ gatk --version; ...; The Genome Analysis Toolkit (GATK) v4.2.0.0; HTSJDK Version: 2.24.0; Picard Version: 2.25.0; ```. ```console; $ gatk HaplotypeCaller \; -I in.bam \; -L chr7:145945238-145945238 \; -stand-call-conf 0 \; --disable-optimizations \; --force-active -O out.vcf \; --reference /path/to/ucsc.hg19.fasta \; --minimum-mapping-quality 60;; ...; java.lang.IllegalStateException: There is no variation present.; 	at org.broadinstitute.hellbender.utils.Utils.validate(Utils.java:814); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.AssemblyRegionTrimmer$Result.getVariantRegion(AssemblyRegionTrimmer.java:108); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerEngine.callRegion(HaplotypeCallerEngine.java:595); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCaller.apply(HaplotypeCaller.java:273); 	at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.processReadShard(AssemblyRegionWalker.java:200); 	at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.traverse(AssemblyRegionWalker.java:173); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1058); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); 	at org.broadinstitute.hellbender.Main.main(Main.java:289); ```. <details>; <summary>test.sam</summary>. ```; @HD	VN:1.6	SO:coordinate; @SQ	SN:chr1	LN:249250621; @SQ	SN:chr2	LN:243199373; @SQ	SN:chr3	LN:198022430; @SQ	SN:chr4	LN:191154276; @SQ	SN:chr5	LN:18,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7123:578,validat,validate,578,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7123,1,['validat'],['validate']
Security,"I am looking at using GATK and first checked at the docker image using **_docker pull broadinstitute/gatk_**. this container image has 1460 vulnerabilities and a lot of them are critical. ; <img width=""1737"" alt=""Screenshot 2023-02-21 212830"" src=""https://user-images.githubusercontent.com/4427764/220508376-aeead13b-999b-4cfd-a7d6-295241df532a.png"">. Then I decided not to use this image and instead create my own image and just deploy the released version 4.2.6.1 from here (https://github.com/broadinstitute/gatk/releases/download/4.2.6.1/gatk-4.2.6.1.zip). Even this has many vulnerabilities include things stemming from log4j 1.2.17. These have been fixed by log4j team years back in version 2.17.1 onwards. I am really stunned that a popular library like gatk is not keeping up with basic security fixes. <img width=""854"" alt=""Screenshot 2023-02-21 212751"" src=""https://user-images.githubusercontent.com/4427764/220508300-7bfe331d-8286-4950-a6dc-e1f5f97c65d0.png"">. the latest version of docker desktop has integrated image scanning and can very easily highlight the issues listed above. Can we start addressing these issues sooner than later.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8215:795,secur,security,795,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8215,1,['secur'],['security']
Security,"I am running GenotypeGVCFs using a single, combine GVCF produced from CombineGVCFs in GATK4. The file contains 44 individuals yet I am receiving the warning 'InbreedingCoeff - Annotation will not be calculated, must provide at least 10 samples'. Should I be concerned by this? I can validate that my input file contains more than 10 samples by the headers it contains. . This is the code I am running, . java -jar ../../programs/gatk-4.1.2.0/gatk-package-4.1.2.0-local.jar GenotypeGVCFs -R revisedAssemblyUnmasked.fa --variant subset_of_pop.vcf -O genotype_subset.vcf. Thank you, . ----",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6238:283,validat,validate,283,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6238,1,['validat'],['validate']
Security,I checked that it runs now with picard 2.0.1 and GATK3.5 (validation fails though),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1921:58,validat,validation,58,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1921,1,['validat'],['validation']
Security,"I created a minimal branch to clean up the way we were passing around credentials. We create a GCSOptions class instead of a DataflowPipelineOptions when we create the pipeline and pass in secrets in at the point instead at the ReadSources level. ReadSources now takes a pipeline instead of the secrets file location. This isn't a long term solution. We should switch the code to get rid of the GenomicsSecret and instead use the more general secret. I think much of the secets factory junk can go away now (they dated from a time when the Dataflow API wasn't built out much. All tests passed locally. Oddly, I now am sometimes getting a dialog about DSDE needing access to basic information about my Google account, not sure source of the issue (maybe the secret I grabbed?), if it's repeatable, or blocking. I recommend the reviewer patch my branch and test locally.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/513:664,access,access,664,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/513,1,['access'],['access']
Security,I currently have a feature driven walker in gatk-protected that is slower than a read-walker equivalent due to the repetitive Read iterator re-instantiation when accessing overlapping reads using the ReadContext. . Ideally the engine (FeatureManager?) would try to reuse open read iterators instead of creating them for each feature/interval.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1246:162,access,accessing,162,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1246,1,['access'],['accessing']
Security,"I didn't expect Hellbender to crash for this command:. `$ ./hb PrintReads -I CEUTrio.HiSeq.WGS.b37.NA12878.bam -O 4m.bam -L 20:1000000-4000000`; (...); [August 17, 2015 2:04:43 PM PDT] org.broadinstitute.hellbender.tools.PrintReads done. Elapsed time: 0.48 minutes.; Runtime.totalMemory()=412090368; java.lang.IllegalArgumentException: end must be >= start. start:2801961 end:2801960; at org.broadinstitute.hellbender.utils.SimpleInterval.validatePositions(SimpleInterval.java:61); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:33); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:45); at org.broadinstitute.hellbender.engine.ReadWalker.lambda$traverse$19(ReadWalker.java:64); at org.broadinstitute.hellbender.engine.ReadWalker$$Lambda$50/1094674892.accept(Unknown Source); at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183); at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); at java.util.Iterator.forEachRemaining(Iterator.java:116); at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:512); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:502); at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150); at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); at org.broadinstitute.hellbender.engine.ReadWalker.traverse(ReadWalker.java:63); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:370); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:97); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:150); at org.broadinstitute.hellb",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/828:439,validat,validatePositions,439,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/828,1,['validat'],['validatePositions']
Security,"I found they were incompatible. It seems that the interface isn't match. The error log looks like below. Exception in thread ""main"" java.lang.NoSuchMethodError: scala.collection.Seq.aggregate(Ljava/lang/Object;Lscala/Function2;Lscala/Function2;)Ljava/lang/Object;; at org.bdgenomics.adam.models.NonoverlappingRegions.mergeRegions(NonoverlappingRegions.scala:75); at org.bdgenomics.adam.models.NonoverlappingRegions.<init>(NonoverlappingRegions.scala:55); at org.bdgenomics.adam.models.NonoverlappingRegions$.apply(NonoverlappingRegions.scala:169); at org.bdgenomics.adam.util.TwoBitRecord$.apply(TwoBitFile.scala:193); at org.bdgenomics.adam.util.TwoBitFile$$anonfun$6.apply(TwoBitFile.scala:70); at org.bdgenomics.adam.util.TwoBitFile$$anonfun$6.apply(TwoBitFile.scala:70); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.immutable.HashMap$HashMap1.foreach(HashMap.scala:221); at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428); at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428); at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); at scala.collection.AbstractTraversable.map(Traversable.scala:104); at org.bdgenomics.adam.util.TwoBitFile.<init>(TwoBitFile.scala:70); at org.broadinstitute.hellbender.engine.spark.datasources.ReferenceTwoBitSource.<init>(ReferenceTwoBitSource.java:43); at org.broadinstitute.hellbender.engine.datasources.ReferenceMultiSource.<init>(ReferenceMultiSource.java:41); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.initializeReference(GATKSparkTool.java:353); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.initializeToolInputs(GATKSparkTool.java:320); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:311); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2073:1089,Hash,HashMap,1089,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2073,1,['Hash'],['HashMap']
Security,"I have four phased variants in close proximity that have the following pattern:. ```; chrA 10 ... GT:PS 0|1:1; chrA 20 ... GT:PS 0|1:2; chrA 30 ... GT:PS 0|1:1; chrA 40 ... GT:PS 0|1:2; ```. These four variants are wholly contained in a single set of reads. There are of course other reads that partially span them. The first variant is a deletion, while the remaining three are SNVs.; Examining the reads, there are two haplotypes since:; 1. Alternate for the 1st and 3rd read; 2. Alternate for the 2nd and 4th read. I would have expected them all to have the same phase set (`PS`) value. I have a test case I can share privately (let me know a good email to send it to confidentially).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6845:671,confidential,confidentially,671,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6845,1,['confidential'],['confidentially']
Security,"I have noticed that when running spark tools (e.g. CountReadsSpark or MarkDuplicatesSpark) that running with an input in the form ""CountReadsSpark -I gs://my-bucket-dir/my-file.bam."" The tool crashes with the following unhelpful stacktraces:. ```; java.io.IOException: Error getting access token from metadata server at: http://metadata/computeMetadata/v1/instance/service-accounts/default/token; 	at com.google.cloud.hadoop.util.CredentialFactory.getCredentialFromMetadataServiceAccount(CredentialFactory.java:208); 	at com.google.cloud.hadoop.util.CredentialConfiguration.getCredential(CredentialConfiguration.java:70); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.configure(GoogleHadoopFileSystemBase.java:1825); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.initialize(GoogleHadoopFileSystemBase.java:1012); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.initialize(GoogleHadoopFileSystemBase.java:975); 	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2653); 	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:92); 	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2687); 	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2669); 	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:371); 	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:295); 	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.setInputPaths(FileInputFormat.java:500); 	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.setInputPaths(FileInputFormat.java:469); 	at org.apache.spark.SparkContext$$anonfun$newAPIHadoopFile$2.apply(SparkContext.scala:1084); 	at org.apache.spark.SparkContext$$anonfun$newAPIHadoopFile$2.apply(SparkContext.scala:1072); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); 	at org.apache.spark.SparkContext.withScope(SparkContext.scala:679); 	at org.ap",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4369:283,access,access,283,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4369,1,['access'],['access']
Security,"I have three main reasons to propose to move the arguments in CLP to an argument collection that is configurable by downstream tools/projects:. 1. Support hiding some arguments for downstream projects. For example, I do not want to support a config file by the user, but rather decide the settings for the framework and expose only some configuration.; 1. Set custom defaults for some downstream tools (including GATK). For example, a concrete tool might want to force the temp directory to be specified to avoid failures due to no space (and specify that in the documentation).; 1. Support old-style arguments (not kebab-case) for downstream projects that rely on the current argument definitions. I am specially affected by this one, because updating GATK to the 4.0.0 release of January will be a breaking change that will cause some nightmares for my users - and I don't want to do a major version bump yet (I have to re-work a bit my own framework before it). Thus, the first commit of this PR holds the proposal for the new argument collection. As I know that the team is also trying to normalize arguments and documentation, I included two more commits to help with the task (they can be removed if you think that it is better after the argument collection):; * Use `java.nio.Path` for temp directories (to support temp directories in HDFS, for example); * Change arguments moved to the collection to kebab-case (to help with #3853)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3998:320,expose,expose,320,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3998,1,['expose'],['expose']
Security,"I have to deal with this component recently and I found the design rather awkward.... In general between GATK and htsjdk we don't seem to have a proper support for managing and querying Supplementary alignment information from read alignment records:. 1. Querying: implemented in htsjdk consists in forging artificial SAMRecords that contain only the alignment info in the SA tag element... It seems to me that it makes more sense to create class to hold this information alone (e.g. ReadAlignmentInfo or ReadAlignment); SATagBuilder already has defined a private inner class with that in mind ""SARead"" so why not flesh it out and make it public. 2. Writing: currently SATagBuilder gets attached to a read, parsing its current SA attribute content into SARead instances. It provides the possibility adding additional SAM record one by one or clearing the list. ... then it actually updates the SA attribute on the original read when a method (setTag) is explicitly called.; I don't see the need to attach the SATag Builder to a read... it could perfectly be free standing; the same builder could be re-apply to several reads for that matter and I don't see any gain in hiding the read SA tag setting process,... even if typically this builder output would go to the ""SA"" tag, perhaps at some point we would like to also write SA coordinate list somewhere else, some other tag name or perhaps an error message... why impose this single purpose limitation?; I suggest to drop the notion of a builder for a more general custom ReadAlignmentInfo (or whatever name) list. Such list could be making reference to a dictionary to validate its elements, prevent duplicates, keep the primary SA in the first position... etc.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3324:1622,validat,validate,1622,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3324,1,['validat'],['validate']
Security,I noticed some classes that were unused in hellbender.; This exposed some others that were only referenced by unused classes. Made slight cosmetic modification to OpticalDuplicateFinder as well,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/780:61,expose,exposed,61,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/780,1,['expose'],['exposed']
Security,"I noticed that `VcfUtils.getSortedSampleSet` takes a `GenotypeMergeType`. The only case it looks at is `UNIQIFY`. You would expect that calling `getSortedSampleSet(someHeaderWithDuplicateSamples, GenotypeMergeType.REQUIRE_UNIQUE)` should throw, but instead it silently continues. . ex, the following test passes just fine:; ```; @Test; public void testGetSortedSampleSet(){; final HashMap<String, VCFHeader> headers = new HashMap<>();; headers.put(""track1"", new VCFHeader(Collections.emptySet(), Sets.newSet(""sample1"")));; headers.put(""track2"", new VCFHeader(Collections.emptySet(), Sets.newSet(""sample1"")));. final SortedSet<String> sortedSampleSet = VcfUtils.getSortedSampleSet(headers, GATKVariantContextUtils.GenotypeMergeType.REQUIRE_UNIQUE);; }; ```. The method is also lacking any tests or javadoc.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3744:381,Hash,HashMap,381,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3744,2,['Hash'],['HashMap']
Security,"I noticed that the PairHMM implementation argument is hidden in `LikelihoodEngineArgumentCollection` for some reason. Shouldn't it be exposed as an advanced argument people can choose what pair hmm they want?. It's also present in the `UnifiedArgumentCollection`, but it's never used from there. ```; /**; * The PairHMM implementation to use for genotype likelihood calculations. The various implementations balance a tradeoff of accuracy and runtime.; */; @Hidden; @Argument(fullName = ""pair_hmm_implementation"", shortName = ""pairHMM"", doc = ""The PairHMM implementation to use for genotype likelihood calculations"", optional = true); public PairHMM.Implementation pairHMM = PairHMM.Implementation.FASTEST_AVAILABLE;; ```. It seems like we should remove it from the `UnifiedArgumentCollection` and make it either a normal argument or an advanced argument in the `LikelihoodEngineArgumentCollection`.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3553:134,expose,exposed,134,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3553,1,['expose'],['exposed']
Security,"I prepared a clean Bam file following GATK Best Practice and used GATK4 HaplotypeCaller to create a gvcf with ploidy1 option:. '''; gatk-4.0.2.1/gatk HaplotypeCaller --native-pair-hmm-threads 24 -I KU_filtered_sorted_mdup.bam -O HC.KU.raw.snps.indels.g.vcf -R ref.fasta -ploidy 1 --emit-ref-confidence GVCF; '''. When I validated the gvcf, ValidateVariants threw errors at the end:. '''; <br />11:27:55.681 INFO ProgressMeter - Traversal complete. Processed 124689522 total variants in 3.8 minutes.; 11:27:55.681 INFO ValidateVariants - Shutting down engine; [April 10, 2018 11:27:55 AM JST] org.broadinstitute.hellbender.tools.walkers.variantutils.ValidateVariants done. Elapsed time: 3.82 minutes.; Runtime.totalMemory()=4682940416; java.lang.IllegalArgumentException: Illegal character in path at index 15:HC.KU.raw.snps.indels.g.vcf; at java.net.URI.create(URI.java:852); at org.broadinstitute.hellbender.engine.FeatureInput.makeIntoAbsolutePath(FeatureInput.java:242); at org.broadinstitute.hellbender.engine.FeatureInput.toString(FeatureInput.java:314); at java.util.Formatter$FormatSpecifier.printString(Formatter.java:2886); at java.util.Formatter$FormatSpecifier.print(Formatter.java:2763); at java.util.Formatter.format(Formatter.java:2520); at java.util.Formatter.format(Formatter.java:2455); at java.lang.String.format(String.java:2940); at org.broadinstitute.hellbender.engine.FeatureDataSource.close(FeatureDataSource.java:589); at org.broadinstitute.hellbender.engine.FeatureManager.lambda$close$9(FeatureManager.java:505); at java.util.LinkedHashMap$LinkedValues.forEach(LinkedHashMap.java:608); at org.broadinstitute.hellbender.engine.FeatureManager.close(FeatureManager.java:505); at org.broadinstitute.hellbender.engine.GATKTool.onShutdown(GATKTool.java:857); at org.broadinstitute.hellbender.engine.VariantWalker.onShutdown(VariantWalker.java:95); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:138); at org.broadinstitute.hellbender.cm",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4657:320,validat,validated,320,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4657,4,"['Validat', 'validat']","['ValidateVariants', 'validated']"
Security,"I ran GATK 4.1.0.0 Mutect2 on a small (~1Mb) targeted panel. I am using a normal control that is not the same individual (basically to exclude technical artifacts), so I do expect to see more variants than with a proper matched normal. I was getting around 100-300 variants per sample with GATK 4.0.6.0. I am still roughly in the same range for some samples GATK 4.1.0.0, but I am getting 0 for some. The problem seems to be at the FilterMutectCalls stage where I am seeing the following error:; ```; [March 19, 2019 10:43:17 PM EDT] org.broadinstitute.hellbender.tools.walkers.mutect.FilterMutectCalls done. Elapsed time: 0.04 minutes.; Runtime.totalMemory()=8851030016; java.lang.IllegalArgumentException: errorRate must be good probability but got NaN; at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:730); at org.broadinstitute.hellbender.utils.QualityUtils.errorProbToQual(QualityUtils.java:227); at org.broadinstitute.hellbender.utils.QualityUtils.errorProbToQual(QualityUtils.java:211); at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2FilteringEngine.applyContaminationFilter(Mutect2FilteringEngine.java:79); at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2FilteringEngine.calculateFilters(Mutect2FilteringEngine.java:518); at org.broadinstitute.hellbender.tools.walkers.mutect.FilterMutectCalls.firstPassApply(FilterMutectCalls.java:130); at org.broadinstitute.hellbender.engine.TwoPassVariantWalker.lambda$traverseVariants$0(TwoPassVariantWalker.java:76); at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); at java.util.Iterator.forEachRemaining(Iterator.java:116); at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ForEachOps$For",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5821:801,validat,validateArg,801,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5821,1,['validat'],['validateArg']
Security,"I ran the full test suite using a [branch](https://github.com/broadinstitute/gatk/tree/cn_check_cache_thrash) that throws if a tool ever tries to query the FeatureCache using a query interval that is earlier than, but on the same contig as, the one currently cached. Several tests [failed](https://travis-ci.org/broadinstitute/gatk/builds/422089722), including a few of the Funcotator ones:. FuncotatorIntegrationTest.exhaustiveArgumentTest; FuncotatorIntegrationTest.testFuncotatorWithoutValidatingResults; FuncotatorIntegrationTest.testVcfDatasourceAccountsForAltAlleles; FuncotatorIntegrationTest.testVcfMafConcordance. These may be test artifacts, but we should audit the Funcotator cache access patterns and see if this is actually causing thrashing that affects performance. Since the FeatureCache caching strategy assumes queries will be forward-only, it might be an indication that Funcotator performance could be improved by either turning off caching or using an alternative cache strategy.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5143:666,audit,audit,666,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5143,2,"['access', 'audit']","['access', 'audit']"
Security,"I suppressed the warnings we were getting. If we can't fix them lets at least not see them.; It seemed like it was ok to suppress the serialization warnings rather than provide a UUID, since java will fill one in for us. We can add a hash value instead if that's better.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/84:234,hash,hash,234,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/84,1,['hash'],['hash']
Security,I think we need someone with admin access to do this.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/740:35,access,access,35,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/740,1,['access'],['access']
Security,I took over #5367 but since I don't have access to your fork @magicDGS I have created a second branch with my changes. Closes #4860,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5655:41,access,access,41,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5655,2,['access'],['access']
Security,"I would like to keep in some of my tools the read group arguments in sync with the `AddOrReplaceReadGroup` in picard, but currently there is no way of access them. This is a very simple and trivial patch to extract the short/long names to a static String variable to be able to use them. In addition, I refactored the variable names to the camel-case java convention.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2260:151,access,access,151,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2260,1,['access'],['access']
Security,"I'm looking into migrating custom GATK3 variant Info/GenotypeAnnotations to GATK4. The annotate() method in GATK3 was passed a sizable amount of context. This is greatly reduced in GATK4. I understand a desire to simplify, such as not passing the Walker. FeatureContext in particular would be helpful, is there another way to access that from VariantAnnotations?. Stepping back: the one scenario I want to support is to annotate genotype concordance between the input VCF and a reference VCF. In our GATK3 implementation, the user supplied that VCF on the command line when executing VariantAnnotator. This plugin used GATK3's walker.getResourceRodBindings(), which seems analogous to GATK4 FeatureContext, to find that binding. It then queries that VCF to find any VariantContext from the current site. . I realize this is raising a couple issues: a) access FeatureContext from within annotate(), , b) efficiently query VariantContext from another resource, and c) plugin that would ideally provide its own command-line argument. . Are there any existing GATK annotations or other plugins that deal with these issues?. Thanks in advance.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6930:326,access,access,326,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6930,2,['access'],['access']
Security,"I'm pretty sure this is a hadoop-bam issue, but I'm finding that any BAM produced by bwa (VN 0.7.16a-r1181) will not load in Spark. The BAM loads successfully in ValidateSamFile (although it throws errors because there are no RGs). Running it through AddOrReplaceReadGroups makes the error go away. Attempting to load from local disk gives the following error:. `htsjdk.samtools.SAMFormatException: Does not seem like a BAM file; 	at org.seqdoop.hadoop_bam.BAMSplitGuesser.<init>(BAMSplitGuesser.java:88); 	at org.seqdoop.hadoop_bam.BAMInputFormat.addProbabilisticSplits(BAMInputFormat.java:228); 	at org.seqdoop.hadoop_bam.BAMInputFormat.getSplits(BAMInputFormat.java:155); 	at org.seqdoop.hadoop_bam.AnySAMInputFormat.getSplits(AnySAMInputFormat.java:252); 	at org.apache.spark.rdd.NewHadoopRDD.getPartitions(NewHadoopRDD.scala:121); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:248); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:246); 	at scala.Option.getOrElse(Option.scala:121); 	at org.apache.spark.rdd.RDD.partitions(RDD.scala:246); 	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:248); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:246); 	at scala.Option.getOrElse(Option.scala:121); 	at org.apache.spark.rdd.RDD.partitions(RDD.scala:246); 	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:248); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:246); 	at scala.Option.getOrElse(Option.scala:121); 	at org.apache.spark.rdd.RDD.partitions(RDD.scala:246); 	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:248); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:246); 	at scala.Option.getOrE",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3488:162,Validat,ValidateSamFile,162,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3488,1,['Validat'],['ValidateSamFile']
Security,"I'm trying to run Mutect2 in tumor-only mode, for a small panel, and I get this errors at the FilterMutectCalls step. ```bash; [July 26, 2019 9:34:50 AM UTC] org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls done. Elapsed time: 0.06 minutes.; Runtime.totalMemory()=2129657856; java.lang.IllegalArgumentException: errorRate must be good probability but got NaN; at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:730); at org.broadinstitute.hellbender.utils.QualityUtils.errorProbToQual(QualityUtils.java:225); at org.broadinstitute.hellbender.utils.QualityUtils.errorProbToQual(QualityUtils.java:209); at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.lambda$applyFiltersAndAccumulateOutputStats$13(Mutect2FilteringEngine.java:176); at java.util.Optional.ifPresent(Optional.java:159); at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.applyFiltersAndAccumulateOutputStats(Mutect2FilteringEngine.java:174); at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls.nthPassApply(FilterMutectCalls.java:142); at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverse$0(MultiplePassVariantWalker.java:40); at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverseVariants$1(MultiplePassVariantWalker.java:77); at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); at java.util.Iterator.forEachRemaining(Iterator.java:116); at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6058:435,validat,validateArg,435,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6058,1,['validat'],['validateArg']
Security,"I'm using GATK 4.2.1.0-0 tool `Mutect2` to call mutations in a mitochondrion genome, and later processing the VCFs with `FilterMutectCalls` enabling as well the mitochondria mode (`--mitochondria-mode true`). For some reason, this results in **some** of the VCFs to return the following error:. > java.lang.IllegalArgumentException: log10p: Log10-probability must be 0 or less; > 	at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:798); > 	at org.broadinstitute.hellbender.utils.MathUtils.log10BinomialProbability(MathUtils.java:646); > 	at org.broadinstitute.hellbender.utils.MathUtils.binomialProbability(MathUtils.java:639); > 	at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.lambda$calculateQuantileBackgroundResponsibilities$10(SomaticClusteringModel.java:271); > 	at org.broadinstitute.hellbender.utils.MathUtils.applyToArray(MathUtils.java:1035); > 	at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.calculateQuantileBackgroundResponsibilities(SomaticClusteringModel.java:271); > 	at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.initializeClusters(SomaticClusteringModel.java:165); > 	at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.learnAndClearAccumulatedData(SomaticClusteringModel.java:325); > 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.learnParameters(Mutect2FilteringEngine.java:153); > 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls.afterNthPass(FilterMutectCalls.java:165); > 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.traverse(MultiplePassVariantWalker.java:44); > 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1085); > 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); > 	at org.broadinstitute.hellbender.cmdline.CommandLineProgr",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8455:426,validat,validateArg,426,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8455,1,['validat'],['validateArg']
Security,"I'm working on an imputation pipeline right now, and the contigs in the returned VCF header don't contain lengths. This fix to UpdateVCFSequenceDictionary allows me to force an update to the VCF's sequence dictionary so I have a valid VCF I can use with the rest of our tools when both --replace and --disable-sequence-dictionary-validation are set to true.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6140:330,validat,validation,330,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6140,1,['validat'],['validation']
Security,"IET false --use_jdk_deflater false --use_jdk_inflater false --disableToolDefaultReadFilters false; [March 21, 2017 5:43:53 PM EDT] Executing as louisb@WMD2A-31E on Mac OS X 10.11.6 x86_64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_112-b16; Version: Version:4.alpha.2-189-g724fbd0-SNAPSHOT; 17:43:53.162 INFO ValidateVariants - Defaults.BUFFER_SIZE : 131072; 17:43:53.162 INFO ValidateVariants - Defaults.COMPRESSION_LEVEL : 1; 17:43:53.162 INFO ValidateVariants - Defaults.CREATE_INDEX : false; 17:43:53.163 INFO ValidateVariants - Defaults.CREATE_MD5 : false; 17:43:53.163 INFO ValidateVariants - Defaults.CUSTOM_READER_FACTORY :; 17:43:53.163 INFO ValidateVariants - Defaults.EBI_REFERENCE_SERVICE_URL_MASK : http://www.ebi.ac.uk/ena/cram/md5/%s; 17:43:53.163 INFO ValidateVariants - Defaults.NON_ZERO_BUFFER_SIZE : 131072; 17:43:53.163 INFO ValidateVariants - Defaults.REFERENCE_FASTA : null; 17:43:53.163 INFO ValidateVariants - Defaults.SAM_FLAG_FIELD_FORMAT : DECIMAL; 17:43:53.163 INFO ValidateVariants - Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 17:43:53.163 INFO ValidateVariants - Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 17:43:53.163 INFO ValidateVariants - Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 17:43:53.163 INFO ValidateVariants - Defaults.USE_CRAM_REF_DOWNLOAD : false; 17:43:53.163 INFO ValidateVariants - Deflater IntelDeflater; 17:43:53.163 INFO ValidateVariants - Inflater IntelInflater; 17:43:53.163 INFO ValidateVariants - Initializing engine; 17:43:53.270 INFO FeatureManager - Using codec VCFCodec to read file file:///Users/louisb/Workspace/gatk/src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleGood.vcf; 17:43:53.287 INFO FeatureManager - Using codec VCFCodec to read file file:///Users/louisb/Workspace/gatk/src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleGood.vcf; 17:43:53.291 WARN IndexUtils - Feature file ""/Users/louisb/Workspace/gatk/src/test/resour",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2509:2664,Validat,ValidateVariants,2664,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2509,1,['Validat'],['ValidateVariants']
Security,"If --gcs-project-for-requester-pays is not specified, gatk should use the current billing project to access requester pays buckets.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6669:101,access,access,101,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6669,1,['access'],['access']
Security,"If I clone GATK with the ssh URL (`git@github.com:broadinstitute/gatk.git`), and then run a `docker build` command from the root of that clone, I get ssh authentication errors at the `git lfs pull` step:. ```; Step 9/36 : RUN git lfs pull; ---> Running in 1f415556efd2; Git LFS: (0 of 104 files) 0 B / 1.28 GB ; batch request: Host key verification failed.: exit status 255; batch request: Host key verification failed.: exit status 255; error: failed to fetch some objects from 'https://github.com/broadinstitute/gatk.git/info/lfs'; The command '/bin/sh -c git lfs pull' returned a non-zero code: 2; ```. If I do the same thing from a GATK clone created using the https URL (`https://github.com/broadinstitute/gatk.git`), I get no lfs error. This also raises the larger question of whether we are authenticating with github before doing `git lfs pull` during the docker build, as I believe that the quotas for unauthenticated `git lfs` operations are much smaller than for authenticated operations.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7077:154,authenticat,authentication,154,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7077,3,['authenticat'],"['authenticated', 'authenticating', 'authentication']"
Security,"If one of the block compressed VCFs in the list is empty (i.e. it does have proper header lines but there are no variant records, which is perfectly valid) then the tool fails with an IllegalStateException:. java.lang.IllegalStateException: Could not read available bytes from BlockCompressedInputStream.; at org.broadinstitute.hellbender.utils.Utils.validate(Utils.java:697); at org.broadinstitute.hellbender.tools.GatherVcfs.gatherWithBlockCopying(GatherVcfs.java:354)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3218:351,validat,validate,351,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3218,1,['validat'],['validate']
Security,"If the sample file is created by extracting a table from BQ, the file might be in a bucket that only the service account can access. Add an option for using the service account to pull the file.; Also, expose the service account input at the workflow (not the task) level",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7299:125,access,access,125,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7299,2,"['access', 'expose']","['access', 'expose']"
Security,"If you ask HaplotypeCallerSpark for a gvcf.gz it outputs a base pair resolution GVCF with no blocking. This is due to confusion in hadoop-bam / VariantSparkSink. It works fine if you write an uncompressed g.vcf. This is due to a conditional statement in `KeyIgnoringVCFOutputFormat.getRecordWriter(askAttemptContext ctx)`. ```; 		if (!isCompressed) {; 			return getRecordWriter(ctx, file);; 		} else {; 			FileSystem fs = file.getFileSystem(conf);; 			return getRecordWriter(ctx, codec.createOutputStream(fs.create(file)));; 		}; ```. The two branches call two different overloads of `getRecordWriter`. ```; getRecordWriter(TaskAttemptContext ctx, Path out). getRecordWriter(TaskAttemptContext ctx, OutputStream outputStream); ```. The first is public, and overriden to provide GVCF writers in our code, the second is private and doesn't know about our GVCF writer. We could override `getRecordWriter(ctx)` but we need access to a constructor for `VCFRecordWriter` that takes a stream and propagates the ctx which doesn't exist.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4274:919,access,access,919,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4274,1,['access'],['access']
Security,"Implement -L system, enable access to it for tools that request it",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4:28,access,access,28,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4,1,['access'],['access']
Security,"Implement -L system, enable access to it for tools that request it (define how they 'request it' - maybe by implementing an interface or calling a function or overriding some generic hook - part of this issue is to design it).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4:28,access,access,28,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4,1,['access'],['access']
Security,"Implements allele collapsing for ""breakend replacement"" BND alleles, as described in section 5.4 of the [VCFv4.2 spec](https://samtools.github.io/hts-specs/VCFv4.2.pdf). Also:; - Validates symbolic alt allele for non-BND SV classes when attempting to collapse multiple alt alleles.; - Greatly improves unit test coverage for `CanonicalSVCollapser`.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8408:179,Validat,Validates,179,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8408,1,['Validat'],['Validates']
Security,"Implements tool for clustering SVs, built on top of the clustering engine code refined recently in #7243. In addition to a few bug fixes, updates also include:. - `PloidyTable` class, which ingests and serves as a simple data class for a tsv of per-sample contig ploidies. This was necessary for inferring genotypes when input vcfs contain non-matching sample and variant records.; - Modified `SVClusterEngine` to render sorted output.; - Improved code for SV record collapsing (see the `CanonicalSVCollapser`), particularly for CNVs. Genotype collapsing now infers allele phasing in certain unambiguous cases, in particular for DUPs and multi-allelic CNVs. Testing for this has been cleaned up and augmented with further cases to validate this functionality.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7541:731,validat,validate,731,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7541,1,['validat'],['validate']
Security,Improve error message for no-access and disabled-account cases,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2417:29,access,access,29,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2417,1,['access'],['access']
Security,Improve error message in spark tools when trying to access a local file from other nodes,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1417:52,access,access,52,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1417,1,['access'],['access']
Security,"In IntervalUtils, when Picard intervals are parsed and checked for validity, (line 359 `glParser.isValidGenomeLoc(interval.getContig(), interval.getStart(), interval.getEnd(), true)`), if the contig doesn't match the supplied reference (via -R) then the error produced is `has an invalid interval`. The interval is perfectly valid, especially since the Picard interval_list has a corresponding sequence dictionary. I'm not sure if the preferred behavior here is to validate against the interval_list seqdict and then note that the -R reference doesn't match or to error because the -R ref doesn't match. Maybe if the tool requiresReference() and the -R doesn't match throw an error?. I encountered this in the context of a tool similar to SplitIntervals, which requires a reference even if a Picard interval_list is provided. I see that this is a TODO in GATKTool::getBestAvailableSequenceDictionary.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5410:465,validat,validate,465,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5410,1,['validat'],['validate']
Security,"In Mutect2 and HaplotypeCaller, we force-call alleles by injecting them into the ref haplotype, then threading these constructed haplotypes into the assembly graph with a large edge weight. There are several drawbacks to this approach:. * The strange edge weights interfere with the `AdaptiveChainPruner`.; * The large edge weights may not be large enough to avoid pruning when depth is extremely high.; * The alleles may be lost if assembly fails.; * If the alleles actually exist but are in phase with another variant we end up putting an enormous amount of weight on a false haplotype. We can get around these issue with the following method:. * assemble haplotypes without regard to the force-called alleles.; * if an allele is present in these haplotypes, do nothing further.; * otherwise, add a haplotype in which the allele is injected into the reference haplotype. @LeeTL1220 I prototyped this and it seems to resolve the missed forced alleles that Ziao found. @ldgauthier Can you think of any objections to making this change in HaplotypeCaller?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5857:57,inject,injecting,57,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5857,2,['inject'],"['injected', 'injecting']"
Security,"In PathSeqPipelineSpark, the reads are repartitioned to ~5k per partition (by default) just prior to the pathogen BWA alignment step (to ensure an even distribution of work). Currently, some samples with a lot of non-host reads cause 10,000's of sharded BAMs to be written at the end of the pipeline. This PR reduces the number of partitions in the read RDD just before writing to disk in the PathSeqPipelineSpark tool. It exposes a command-line option for the number of reads per partition, with a default value that results in a much more reasonable number of sharded BAMs in even the worst cases.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3545:423,expose,exposes,423,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3545,1,['expose'],['exposes']
Security,"In doing continued profiling of the HaplotypeCaller GVCF mode I have observed that somewhere in the range of 12% of our overall runtime (after i've made my other optimizations) is spent in `VariantContextBuilder.make()` upon further investigation I have noticed that we are currently building a VariantContext object for each pileup in `ReferenceConfidenceModel.calculateReferenceConfidence()`. This means that we are building a unique VariantContext object for essentially every spot on the genome. VariantContext object building represents a significant overhead in terms of validation and construction and memory usage. I suspect that if we were to create some reduced object without as much overhead we could save ourselves a lot of trouble time and memory merging these things. Unfortunately I think the merging of these context objects happens in the GVCF writer which means it won't be a trivial change to make to the engine. Perhaps it is worth investigating what can be done to this code, as it represents another size-able chunk of speedup if we can squash it.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5618:577,validat,validation,577,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5618,1,['validat'],['validation']
Security,In light of the recent #7357 and #7358 it has become clear that we are blind changes that cause the logging outputs for GATK to become unusable because we are spitting endless warnings to stdout. I think we should change our integration tests to capture the log output for each of our tests and assert that none of them balloon beyond some reasonable threshold that would capture these problems (perhaps a megabyte but it would take a little bit of sleuthing to be sure). . I would think the best place would be to add a capture into `CommandLineProgramTest.runCommandLine()` that instead of using the current behavior `injectDefaultVerbosity()` we instead leave the logging output as the default and capture it somewhere explicit where we can make assertions about the size of the outputs. Possibly we could create a dummy logging level that just saves and counts the outputs so we can make assertions about the logs. Ideally this should apply to every tool simultaneously since it would be too patchwork to simply add logging output tests for enough of the tools to protect us manually.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7368:620,inject,injectDefaultVerbosity,620,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7368,1,['inject'],['injectDefaultVerbosity']
Security,"In my case, as an API user, my main usage of GATK is for traverse `GATKRead` and `VariantContext`, so I would like to have in `GATKTool` a simpler way of access to the `FeatureInput<VariantContext>` instead of getting them from `FeatureManager features`. It will be useful in the `VariantWalker` as a step to issue #692, to get all the variants provided by the user in the same walker. My idea is modify the `GATKTool` to include:; - A `public abstract boolean requiresVariant()`, which will be used to determine if we should detach or not all the variants inputs from the `FeatureManager features`.; - A `private void initializeVariants()`, which will implement a way to extract the `FeatureInput<VariantContext>` from `features` and initialize a `FeatureManager variants` or a extended class which includes only `VariantContext` inputs.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1710:154,access,access,154,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1710,1,['access'],['access']
Security,"In particular add output GATKTool.getDefaultToolVCFHeaderLines to the VCF header, and rewrite the integration test for GenerateVCFFromPosteriors so that it validates the equivalence of variant context records, instead of file equivalency",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4267:156,validat,validates,156,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4267,1,['validat'],['validates']
Security,"In particular, we are a little lax on sequence-dictionary validation in the CNV pipelines. However, it might be that this is a necessary evil---it seems sequence dictionaries are somewhat inconsistent even in datasets such as TCGA.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3864:58,validat,validation,58,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3864,1,['validat'],['validation']
Security,"In the VAT validation, give clearer error msg about which clinvar classification values are missing",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7939:11,validat,validation,11,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7939,1,['validat'],['validation']
Security,"In the process of designing correctness tests for `MarkDuplicatesSpark`, @davidadamsphd has come up with a potential set of optimizations to `MarkDuplicatesSpark` that have the potential to improve performance by an order of magnitude. The task here is to meet with @davidadamsphd, get access to and understand his optimizations, and port them to the main `MarkDuplicatesSpark` tool (along with any other optimizations you feel are appropriate).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1100:286,access,access,286,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1100,1,['access'],['access']
Security,In the work on #7295 it became clear that there are a lot of overlapping overloads of the `createGenomeLoc()` method that has already caused some confusion since some overloads will skip the reference validation step. Somebody should audit all of the uses of `GenomeLocParser` and evaluate where validation is and isn't appropriate (possibly if you want an unvalidated genomeLoc use a SimpleInterval?) and wire them accordingly.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7300:201,validat,validation,201,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7300,3,"['audit', 'validat']","['audit', 'validation']"
Security,"In this branch are a number of improvements and changes that form the baseline for the current ongoing evaluation of the DRAGEN/GATK pipeline. This represents the joint work of both msyelf and @vruano. The major improvements in this branch are as follows:; - `EstimateDragstrModelParameters` tool for estimating the per-sample/per-STRType errors for use in the HMM gap open/gap close penalties as well as the necessary changes to the PairHMM loading code in order to adjust the model appropriately.; - Support for using the DragstrParams and flat SNP priors to compute genotype posteriors and the support for using them in the selection of genotypes as well as for computing the QUAL score. ; - Base Quality Dropout (BQD) model which penalizes variants with low average base quality scores among genotyped reads and reads that were otherwise excluded from the genotyper. A number of additional arguments to expose internal behaviors in the readThreadingAssembler and HaplotypeCaller have been made in order to support threading more lowBQ reads through to the genotyper. ; - Foreign Read Detection (FRD) model which uses an adjusted mapping quality score as well as read strandedness information to penalize reads that are likely to have originated from somewhere else on the genome. A number of additional arguments and behaviors have been exposed in order to preserve lower mapping quality reads in the HaplotypeCaller in service.; - Dynamic Read Disqualification, allows for longer/lower base quality reads to be less likely to be rejected by eliminating the hard cap on quality scores and further adjusting the limit based on the average base quality for bases in the read. . Design decisions that I would direct the reviewers attention to as they correspond to potentially dangerous/controversial changes:; - Because FRD/BQD require low quality ends to be included in the models for genotyping, I have added the option to softclipLowQualityEnds (as opposed to their current treatment which involv",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6634:907,expose,expose,907,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6634,1,['expose'],['expose']
Security,"In validateVariants tool, made the default case behave so that it does the validations that can be done, and issues warning messages for the validations that cannot be done (ie, required external files)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5984:3,validat,validateVariants,3,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5984,3,['validat'],"['validateVariants', 'validations']"
Security,"In working with the SampleDBBuilder code I have noticed that there is an argument for validationStrictness which purports to assert that there is a >1:1 mach between the discovered samples in the pedigree file and those in the underlying variantDataSources according to the code on line 83. Unfortunately, as it stands there is no way to input `samplesFromDataSources` into the builder, so these assertions are skipped. There are tests for validation but these only apply to asserting that there are no name collisions between the samples added as pedigree files, which appears to be different.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3949:86,validat,validationStrictness,86,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3949,2,['validat'],"['validation', 'validationStrictness']"
Security,"Includes latest Gencode and an implicit fix for #6564. Had to make some code changes for latest liftover Gencode data(v34 -> hg19). . The associated DS test release correctly annotates data on hg19 and hg38. Left to do:. - [x] Update data sources downloader.; - [x] Update data source version validation code. Code updates:; - Now both hg19 and hg38 have the contig names translated to `chr__`; - Added 'lncRNA' to GeneTranscriptType.; - Added ""TAGENE"" gene tag.; - Added the MANE_SELECT tag to FeatureTag.; - Added the STOP_CODON_READTHROUGH tag to FeatureTag.; - Updated the GTF versions that are parseable.; - Fixed a parsing error with new versions of gencode and the remap; positions (for liftover files).; - Added test for indexing new lifted over gencode GTF.; - Added Gencode_34 entries to MAF output map.; - Minor changes to FuncotatorIntegrationTest.java for code syntax.; - Pointed data source downloader at new data sources URL.; - Minor updates to workflows to point at new data sources. Script updates:; - Updated retrieval scripts for dbSNP and Gencode.; - Added required field to gencode config file generation.; - Now gencode retrieval script enforces double hash comments at; top of gencode GTF files. Bug Fixes:; Removing erroneous trailing tab in MAF file output. - Fixes #6693",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6660:293,validat,validation,293,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6660,2,"['hash', 'validat']","['hash', 'validation']"
Security,Index files should have an integrity check built-in,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5571:27,integrity,integrity,27,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5571,1,['integrity'],['integrity']
Security,Integration Test [here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/a795190c-dcc2-40a7-bfcc-84fa6a4ea0dc); Two failed on ValidateVDS (or rather something upstream). I *don't* think this is an effect of this PR.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8807:149,Validat,ValidateVDS,149,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8807,1,['Validat'],['ValidateVDS']
Security,"Introducing the IntervalLocusIterator which will traverse every locus in intervals, regardless of coverage. Minor changes. Removed imports. AlignmentContextLocusIterator first cut. Still needs unit tests. Putting in the walker. Still needs unit tests. Adding tests (and fixes) so that we can get AlignmentContexts. Adding tests (and fixes) so that we can get AlignmentContexts. Working tests. Beginning migration to a LocusWalker change rather than a separate walker. Merging the emit empty loci into locus walker. Still need warnings and validation of parameters. Next step is the LocusWalker testing. Simple test of the new LocusWalker when it emit empty loci. Addressing PR requests and added ShardedIntervalIterator to save RAM on big intervals. Addressing the rest of the PR comments. Rolling back to int from long. Addressing second round of PR comments. Wrapped LIBS in a factory so that we can encapsulate the retrieval of the best alignment context iterator. Spark empty loci traversal being supported. Rebasing based off of the other emit loci branch.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2731:539,validat,validation,539,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2731,1,['validat'],['validation']
Security,Investigate whether our default validation stringency for reads should be STRICT rather than SILENT,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1457:32,validat,validation,32,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1457,1,['validat'],['validation']
Security,"It looks like picard metrics record at least one more field when the metrics get reported, namely the count of supplementary reads seen. The metrics code should be audited to ensure it matches with picard over the same files.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4777:164,audit,audited,164,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4777,1,['audit'],['audited']
Security,"It seems a lot of users use bcftools on their VCFs, and it sometimes converts floats to integers. For example MQ=31.0 to MQ=31. This change causes GATK tools to error. Is it possible to relax this validation?. ----; User Report; ----. Hi,. Every time I had this message, this was due to bcftools which can change some float values to an integer representation : (e.g : before bcftools : MQ=31.0; after bcftools : MQ=31). . The fact that GATK is very strict on that subject (40.0 is considered as a float while 40 is not) have some advantages and some drawbacks. I hope this problem will be resolved in GATK4 because bcftools is really useful and widely used when dealing with vcf files. This Issue was generated from your [forums] ; [forums]: https://gatkforums.broadinstitute.org/gatk/discussion/comment/43270#Comment_43270",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3734:197,validat,validation,197,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3734,1,['validat'],['validation']
Security,It was noticed while doing #8351 that the `GencodeFunctotation.equals()` method has the following line in it; ``` ; if (geneTranscriptType != that.geneTranscriptType) return false; ; ```. Unfortunately the geneTranscriptType is stored as a Sting and thus this should NOT be expected to succeed in almost any case. As it stands fixing this innocuous oversight seems to break several of the combinatorial funcotator tests and an integration test. Somebody should fix this behavior (easy) and validate that the test changes are within tolerable levels (hard).,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8385:490,validat,validate,490,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8385,1,['validat'],['validate']
Security,It would be better if in addition to / instead of the getter/setter scheme that exists with current `Funcotation` classes we used a `HashMap` to be able to directly get each field by name. This would allow for more programmatic manipulation of `Funcotation` objects.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3919:133,Hash,HashMap,133,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3919,1,['Hash'],['HashMap']
Security,Iterator.java:151); 	at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.next(SamReaderQueryingIterator.java:29); 	at org.broadinstitute.hellbender.utils.iterators.SAMRecordToReadIterator.next(SAMRecordToReadIterator.java:29); 	at org.broadinstitute.hellbender.utils.iterators.SAMRecordToReadIterator.next(SAMRecordToReadIterator.java:15); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); 	at org.broadinstitute.hellbender.engine.ReadWalker.traverse(ReadWalker.java:94); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:838); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:115); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:170); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:189); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:131); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:152); 	at org.broadinstitute.hellbender.Main.main(Main.java:230); ```. I ran the same command again from my computer (not in the cloud) still using the NIO paths and it ran successfully. I've also seen it run successfully when running the same pipeline in the cloud. The only thing I think I've changed is the disk size I'm asking for. I'm in the process of validating the input bam right now.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3316:7467,validat,validating,7467,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316,1,['validat'],['validating']
Security,Jc validate variants fixes issue5862,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5984:3,validat,validate,3,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5984,1,['validat'],['validate']
Security,"Just some thoughts for @samuelklee. For example, CollectFragmentCounts produces the following hybrid-type `@RG` line:. ![screenshot 2018-02-22 15 05 48](https://user-images.githubusercontent.com/11543866/36908820-66b90938-1e0a-11e8-8830-793ff3f71e96.png). ```; @RG ID:GATKCopyNumber SM:HCC1143_tumor; ```; Official format specifications are at https://samtools.github.io/hts-specs/. Let me briefly describe the #choices. ---; If we are to follow conventions used in the alignment world (SAM specs, for interval lists), then... We note data transformations using `@PG` program groups. These can be added successively to the same data file, given unique `@PG ID` fields, and collectively these lines showcase the history of data transformations for a dataset. The `@RG` group is reserved for lane level data and yes, does unify based on the sample or library. ---; If we examine VCFs, the convention is to use `#` hashtags to denote header rows (VCF specs). Double hashtags `##` denote all metadata lines and a single hashtag `#` denotes the line with the column labels. Here are some select rows from an M2 VCF header:; ```; ##fileformat=VCFv4.2; ##FILTER=<ID=artifact_in_normal,Description=""artifact_in_normal"">; ...; ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Allelic depths for the ref and alt alleles in the order listed"">; ...; ##GATKCommandLine=<ID=FilterMutectCalls,CommandLine=""FilterMutectCalls...; ...; ##GATKCommandLine=<ID=Mutect2,CommandLine=""Mutect2 --tumor-sample HCC1143_tumor ...; ...; ##INFO=<ID=TLOD,Number=A,Type=Float,Description=""Tumor LOD score"">; ##Mutect Version=2.1-beta; ##command=FilterByOrientationBias --output hcc1143_T_clean-filtered.vcf...; ...; ##contig=<ID=chr1,length=248956422>; ##contig=<ID=chr2,length=242193529>; ...; ##contig=<ID=HLA-DRB1*16:02:01,length=11005>; ##filtering_status=These calls have been filtered by FilterMutectCalls to label false positives with a list of failed filters and true positives with PASS.; ##normal_sample=HCC1143_normal; #",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4481:912,hash,hashtags,912,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4481,1,['hash'],['hashtags']
Security,"Just the last commit. As requested by @LeeTL1220 to enable Intel to access task-level parameters for subworkflows. Note that this adds an unnecessary amount of boilerplate and will quickly become untenable if there are many identically named parameters. As discussed in #3980, this sort of thing really should be handled by Cromwell, otherwise there is not much benefit to using optional parameters. I've filed #4287 to revert when we can. Closes #3980.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4288:68,access,access,68,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4288,1,['access'],['access']
Security,"K Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 10:33:37.513 INFO Mutect2 - Deflater: IntelDeflater; 10:33:37.513 INFO Mutect2 - Inflater: IntelInflater; 10:33:37.514 INFO Mutect2 - GCS max retries/reopens: 20; 10:33:37.514 INFO Mutect2 - Requester pays: disabled; 10:33:37.514 INFO Mutect2 - Initializing engine; 10:33:37.874 INFO Mutect2 - Shutting down engine; [August 28, 2019 at 10:33:37 AM GMT] org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2 done. Elapsed time: 0.05 minutes.; Runtime.totalMemory()=161480704; java.lang.NullPointerException; at org.broadinstitute.hellbender.utils.SequenceDictionaryUtils.getContigNames(SequenceDictionaryUtils.java:463); at org.broadinstitute.hellbender.utils.SequenceDictionaryUtils.getCommonContigsByName(SequenceDictionaryUtils.java:457); at org.broadinstitute.hellbender.utils.SequenceDictionaryUtils.compareDictionaries(SequenceDictionaryUtils.java:234); at org.broadinstitute.hellbender.utils.SequenceDictionaryUtils.validateDictionaries(SequenceDictionaryUtils.java:150); at org.broadinstitute.hellbender.utils.SequenceDictionaryUtils.validateDictionaries(SequenceDictionaryUtils.java:98); at org.broadinstitute.hellbender.engine.GATKTool.validateSequenceDictionaries(GATKTool.java:769); at org.broadinstitute.hellbender.engine.GATKTool.onStartup(GATKTool.java:711); at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.onStartup(AssemblyRegionWalker.java:161); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:137); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:162); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:205); at org.broadinstitute.hellbender.Main.main(Main.java:291). This Issue was generated from your [forums] ; [forums",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6142:3382,validat,validateDictionaries,3382,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6142,1,['validat'],['validateDictionaries']
Security,"KTool.java:525); 	at org.broadinstitute.hellbender.engine.GATKTool.onStartup(GATKTool.java:728); 	at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.onStartup(AssemblyRegionWalker.java:79); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:138); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); 	at org.broadinstitute.hellbender.Main.main(Main.java:289); Caused by: com.google.api.client.googleapis.json.GoogleJsonResponseException: 400 Bad Request; GET https://storage.googleapis.com/storage/v1/b/fc-secure-bd7b8bc9-f665-4269-997e-5a402088a369/o?maxResults=1&prefix=5c2db926-3b1c-479c-9ed3-a99ce518de91/omics_mutect2/60955825-7723-4bc9-8202-bdd9975bb5c0/call-mutect2/Mutect2/7d737efc-c8be-4a6d-8803-4f786129521a/call-SplitIntervals/glob-0fc990c5ca95eebc97c4c204e3e303e1/0000-scattered.interval_list.idx/&projection=full&userProject; {; ""code"" : 400,; ""errors"" : [ {; ""domain"" : ""global"",; ""message"" : ""User project specified in the request is invalid."",; ""reason"" : ""invalid""; } ],; ""message"" : ""User project specified in the request is invalid.""; }; 	at com.google.api.client.googleapis.json.GoogleJsonResponseException.from(GoogleJsonResponseException.java:146); 	at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:118); 	at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:37); 	at com.google.api.client.googleapis.services.AbstractGoogleClientRequest$1.interceptResponse(AbstractGoogleClientRequest.java:428); 	at com.google.api.client.http.HttpRequest.e",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7716:4064,secur,secure-,4064,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7716,1,['secur'],['secure-']
Security,"Keeping the dockstore as is for now because I may want to run this on a few shards from the 30k while it's still in review. This pr adds a fair amount of work to the bcftools task (ExtractAnAcAfFromVCF) and adds a significant number of columns to the schema: the sample count for all of the samples, as well as for each subpopulation. Note that AC_hemi will be added in a follow on pr; Note that additional validation tests will be added in a follow on pr",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7456:407,validat,validation,407,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7456,1,['validat'],['validation']
Security,Leave validation cluster running at end [VS-901],MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8729:6,validat,validation,6,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8729,1,['validat'],['validation']
Security,"Legacy pipeline (note, the following should only be done after final ModelSegments PR is in):; - [x] Delete prototype tools. (#3887) (SL, PR issued by 12/1); - ~~Add deprecated/legacy tag to legacy pipeline tools. (SL, PR issued by 12/1 EDIT: need further input from @vdauwera )~~; - ~~Update docs/arguments (w/ Comms, see #3853). This will follow deletion of prototype tools. (all, PR issued by 12/15)~~; - ~~(Reach) Collect all legacy code in a new package.~~; - [x] Delete old pipelines. (SL, #3935 awaiting review). ModelSegments pipeline:; - [x] Review and merge denoising PR (#3820).; - [x] Add WDL changes from @LeeTL1220, @meganshand, and @jsotobroad to dev branch. (Note that we exposed PreprocessIntervals.bin_length in these WDLs; I'm assuming that https://github.com/broadinstitute/cromwell/issues/2912 will allow this to be specified via the json, so I reverted this change.); - [x] Make simple improvements to ReCapSeg caller (#3825).; - [x] Review and merge modeling/WDL PR. (#3913 awaiting review. Note that this PR also deletes the old germline WDL.); - ~~Write MultidimensionalKernelSegmenterUnitTest.~~ (SL, punting, filed #3916); - ~~Write ModelSegmentsIntegrationTest.~~ (SL, punting, filed #3916); - [x] Preliminary PCAWG or HCC1143 purity evaluation. (@LeeTL1220) (LL, should be done in time for @vdauwera to present at Broad retreat); - [x] Update docs/arguments (w/ Comms, see #3853). This will follow deletion of prototype tools. (PR #4010 awaiting review.); - [x] Add SM tag and sequence dictionary headers to all appropriate files and sort accordingly. (SL, #3914 awaiting review); - [x] Update tutorial data. (@MartonKN); - [ ] (Reach) Add VCF output.; - [ ] (Reach) Add PG tags to all files.; - [ ] (Reach) Replace ReCapSeg caller with improved version. (@MartonKN). gCNV pipeline:; - [x] Review and merge Python code (#3838). (MB and SL, PR #3925 awaiting review.); - [x] CLI for ploidy determination (cohort). (@samuelklee); - [x] CLI for ploidy determination (case). (",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3826:688,expose,exposed,688,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3826,1,['expose'],['exposed']
Security,"Let's create a mock up of a possible future configuration setup using the Owner library (https://github.com/lviggiano/owner). For the mock up, I recommend we have two configuration files, one containing system properties and the other containing a few general engine settings. . We can select a few system properties from `gatk-launch` for inclusion in the system properties config file (eg., `samjdk.compression_level`, `samjdk.use_async_io_read_samtools`, etc.). . For the engine settings file, I recommend including `codecPackages` (a `List<String>` currently hardcoded in `FeatureManager.CODEC_PACKAGES`), `cloudPrefetchBuffer`/`cloudIndexPrefetchBuffer` (int values) from `GATKTool`, and `createOutputBamIndex` (boolean), also from `GATKTool`. As part of this, we'll have to prove that we can inject the system properties sufficiently early on that libraries such as htsjdk will pick them up.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3126:798,inject,inject,798,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3126,1,['inject'],['inject']
Security,"Likely an analogous problem to #1417. ```; ./gatk-launch MarkDuplicatesSpark -I file:///home/unix/louisb/flag_stat.bam -O file:///home/unix/louisb/testoutput.bam -- --sparkRunner SPARK --sparkMaster yarn-client; ```. results in:. ```; java.lang.IllegalArgumentException: Wrong FS: file:/home/unix/louisb/testoutput.bam, expected: hdfs://dataflow01.broadinstitute.org:8020; at org.apache.hadoop.fs.FileSystem.checkPath(FileSystem.java:654); at org.apache.hadoop.hdfs.DistributedFileSystem.getPathName(DistributedFileSystem.java:193); at org.apache.hadoop.hdfs.DistributedFileSystem.access$000(DistributedFileSystem.java:105); at org.apache.hadoop.hdfs.DistributedFileSystem$12.doCall(DistributedFileSystem.java:645); at org.apache.hadoop.hdfs.DistributedFileSystem$12.doCall(DistributedFileSystem.java:641); at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81); at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:641); at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSink.deleteHadoopFile(ReadsSparkSink.java:200); at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSink.writeReadsSingle(ReadsSparkSink.java:191); at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSink.writeReads(ReadsSparkSink.java:106); at org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSpark.runTool(MarkDuplicatesSpark.java:94); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:257); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:38); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:98); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:146); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:165); at org.broadinstitute.h",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1451:581,access,access,581,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1451,1,['access'],['access']
Security,List data access patterns in Picard/GATK/Foghorn,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1:10,access,access,10,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1,1,['access'],['access']
Security,Long file names prevent cloning GATK on system with encrypted /home,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4718:52,encrypt,encrypted,52,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4718,1,['encrypt'],['encrypted']
Security,"Lots of the test input VCFs (and some expected test VCFs) are invalid: GQs that don't match their PLs (which should get fixed by the time I'm done with #3404 ), the wrong number of PLs for the alleles in the VC (src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/SelectVariants/vcfexample.loseAlleleInSelection.vcf) and probably more issues too. It's hard to be confident our output VCFs are correct when the expected behavior is sometimes wrong. Ideally we should run GATK ValidateVariants and/or vcftools validate on all the test VCFs (input and expected) and ensure files are valid where weren't not testing format/parsing issues.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3407:499,Validat,ValidateVariants,499,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3407,2,"['Validat', 'validat']","['ValidateVariants', 'validate']"
Security,M2 VCFs do not validate,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3296:15,validat,validate,15,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3296,1,['validat'],['validate']
Security,"MIGRATED FROM GATK3. @ldgauthier commented on [Thu Jul 16 2015](https://github.com/broadinstitute/gsa-unstable/issues/1053). Currently ValidateVariants relies on genotypes to transitively check that each alt allele occurs in at least one sample and that the AC adds up. However, this can fail on sites-only files because there are no genotypes. We should use the definition of the info annotations in the header to check how many entries each should have.; ### Outline; - Add a new validation type for info-field counts to enum and to switch statement; - Grab info headers from input VCF with something like GATKVCFUtils.getVCFHeadersFromRods(getToolkit(), variantCollection.variants.getName()) and VCFHeader::getInfoHeaderLines; - In the map() function, for each info header line, call on each VCFInfoHeaderLine getCount(vc) to get the expected number of info annotation entries; - Compare the expected number with a count based on vc.getAttribute(currentVCFinfoHeaderLine.getID()), which will require some additional parsing because it returns an Object; - (Bonus points if you use the isFixedCount() and getCount() functions on the VCF info header line to simplify annotations that aren't according to the number of alt alleles); ### Test data. /humgen/gsa-hpprojects/dev/gauthier/scratch/supportingMultiA.vcf; Should fail AC/AF validation at ; `1 768589 . A C,G 76 PASS AC=1;AF=0.00047;AN=2120`; See results using:. ```; use VCFtools; vcf-validator /humgen/gsa-hpprojects/dev/gauthier/scratch/supportingMultiA.vcf; ```. which outputs:; `INFO field at 1:768589 .. INFO tag [AC=1] expected different number of values (expected 2, found 1),INFO tag [AF=0.00047] expected different number of values (expected 2, found 1)`; ### Notes. Currently, all the validation modes call out to HTSJDK. Do we want to put the new functionality there as well?. ---. @yfarjoun commented on [Thu Jul 16 2015](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-122130280). I think that it is very a",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2507:135,Validat,ValidateVariants,135,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2507,2,"['Validat', 'validat']","['ValidateVariants', 'validation']"
Security,Make GCS authentication work without using dataflow options classes,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/963:9,authenticat,authentication,9,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/963,1,['authenticat'],['authentication']
Security,Make PathSeq test BAMs pass ValidateSamFile,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3204:28,Validat,ValidateSamFile,28,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3204,2,['Validat'],['ValidateSamFile']
Security,Make a bunch of in silico contaminated samples and validate contamination tool,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3256:51,validat,validate,51,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3256,1,['validat'],['validate']
Security,Make sequence dictionary validation a bit less strict,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/877:25,validat,validation,25,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/877,1,['validat'],['validation']
Security,Make sequence dictionary validation in BQSR dataflow work when the reference is in a bucket,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/737:25,validat,validation,25,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/737,1,['validat'],['validation']
Security,Make some noise when VDS validation succeeds,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8155:25,validat,validation,25,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8155,1,['validat'],['validation']
Security,"Makes CreateVariantIngestFiles robust to partially or fully loaded samples. Commit 21828af8f5a925cc331dce6093c0d510042d7b64 is what I actually propose to merge, while commit de673204183a4c45059dc9ea4e05868e2ea6ae59 randomly injects failures covering all the known failure modes. I tested these changes using both commits and was able to verify that partially loaded samples were handled correctly on subsequent attempts to load the sample (unfortunately we can't actually prevent these partial loadings from happening in the first place because preemptions, among other possible reasons).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7843:224,inject,injects,224,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7843,1,['inject'],['injects']
Security,"Makes `CreateVariantIngestFiles` robust to partially or fully loaded samples. Commit a8dc5ea89653a7f94588aa040b49d0264d17f72d is what I actually propose to merge, while commit 118a44604343e8f77d53bcc6545b2360fefbe1cc randomly injects failures covering all the known failure modes. I tested these changes using both commits and was able to verify that partially loaded samples were handled correctly on subsequent attempts to load the sample (unfortunately we can't actually prevent these partial loadings from happening in the first place because preemptions, among other possible reasons).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7831:226,inject,injects,226,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7831,1,['inject'],['injects']
Security,"MannWhitneyU was re-written from scratch in 2016 in GATK3,; but these changes never got ported to GATK4. This new version; produces significantly different results from the version; currently in GATK4, resulting in VERY different values for the; RankSumTest annotations in HaplotypeCaller output. @meganshand informs me that the updated GATK3 version has been; validated in R, and has much better tests than the old version. This is a straightforward port of that version with minimal changes:. -Merged ""MWUnitTest"" and ""RankSumUnitTest"" from GATK3 into a single; test class MannWhitneyUUnitTest; -Ported MathUtils.binomialCoefficient() and wrote new test for it; -Updated RankSumTest class and tests as appropriate. I've confirmed that with this change, the RankSum annotations produced; by the GATK4 HaplotypeCaller closely match those produced by the GATK3; HaplotypeCaller. Resolves #2604",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2605:361,validat,validated,361,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2605,1,['validat'],['validated']
Security,Many times the question comes up of whether variants are lost in HaplotypeCaller and Mutect2 because they are not assembled. It seems like an easy and scalable way to answer this would be to emit an optional sites-only vcf of all variants in the `EventMap` before genotyping. That way we could do internal validations about assembly much faster than currently. and user questions in this vein would not require the IDE or looking at bamouts in IGV. I envision something like this:; ```; gatk Mutect2 -I tumor.bam -O out.vcf --assembled-variants assembled.vcf; gatk SelectVariants truth.vcf --discordance assembled.vcf -O assembly-false-negatives.vcf; ```. @ldgauthier @yfarjoun what do you think about this?,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5426:306,validat,validations,306,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5426,1,['validat'],['validations']
Security,Merge adjacent blocks when validating GVCFs so we use less memory and dont fail when not using an interval argument,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3445:27,validat,validating,27,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3445,1,['validat'],['validating']
Security,"Minimally, VariantWalkerSpark, but we should also audit the other classes included in https://github.com/broadinstitute/gatk/pull/2256/files to see if readFilters are properly propagated.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2338:50,audit,audit,50,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2338,1,['audit'],['audit']
Security,"MisencodedBaseQualityReads Fix Illumina base quality scores in a SAM/BAM/CRAM file; FlagStat A reimplementation of the 'samtools flagstat' subcommand; GatherBQSRReports Gathers scattered BQSR recalibration reports into a single file; GatherBamFiles Concatenates one or more BAM files together as efficiently as possible; LeftAlignIndels Left-aligns indels from reads in a SAM/BAM/CRAM file; MarkDuplicates Examines aligned records in the supplied SAM/BAM/CRAM file to locate duplicate molecules.; MergeBamAlignment Merges alignment data from a SAM/BAM with data in an unmapped SAM/BAM/CRAM file; MergeSamFiles Merges multiple SAM/BAM files into one file; PrintReads Print reads in the SAM/BAM/CRAM file; ReorderSam Reorders reads in a SAM/BAM file to match ordering in reference; ReplaceSamHeader Replace the SAMFileHeader in a SAM/BAM file with the given header; RevertBaseQualityScores Revert Quality Scores in a SAM/BAM/CRAM file; RevertOriginalBaseQualitiesAndAddMateCigar Reverts the original base qualities and adds the mate cigar tag to read-group BAMs; RevertSam Reverts SAM/BAM files to a previous state; SamFormatConverter Convert a SAM/BAM/CRAM file to a SAM/BAM/CRAM file; SamToFastq Converts a SAM/BAM file into a FASTQ; SortSam Sorts a SAM/BAM/CRAM file; SplitNCigarReads Split Reads with N in Cigar; SplitReads Outputs reads from a SAM/BAM/CRAM by read group, sample and library name; UnmarkDuplicates Unmark duplicates in a SAM/BAM/CRAM file; ValidateSamFile Validates a SAM/BAM/CRAM file. --------------------------------------------------------------------------------------; Spark Validation tools: Tools written in Spark to compare aspects of two different files; CompareBaseQualitiesSpark Diff qs of the BAMs; CompareDuplicatesSpark Compares two BAMs for duplicates. --------------------------------------------------------------------------------------; Spark pipelines: Pipelines that combine tools and use Apache Spark for scaling out (experimental); BQSRPipelineSpark Both st",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1669:6290,Validat,ValidateSamFile,6290,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1669,2,['Validat'],"['ValidateSamFile', 'Validates']"
Security,More fix enum hashCode,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4623:14,hash,hashCode,14,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4623,1,['hash'],['hashCode']
Security,"Most methods in `FuncotatorUtils` take a `SequenceComparison` object as input. This should be changed to either:. 1. Take the base fields as arguments (i.e. whatever is accessed in the `SequenceComparison` object). or . 2. For each method taking a `SequenceComparison`, create a `canCall` method that takes a `SequenceComparison` and returns a boolean - whether, based on the assigned fields in the `SequenceComparison` object, you can call the method itself.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3959:169,access,accessed,169,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3959,1,['access'],['accessed']
Security,Moved validation test data out of large files area.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5381:6,validat,validation,6,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5381,1,['validat'],['validation']
Security,"Moving to [GenomicsDB 1.4.1 ](https://github.com/GenomicsDB/GenomicsDB/releases/tag/v1.4.1)release will allow for the direct use of the native GCS C++ client instead of the GCS Cloud Connector via HDFS. The GCS Cloud Connector can still be used with GenomicsDB via the `--genomicsdb-use-gcs-hdfs-connector` option. Using the native client with gcs allows for GenomicsDB to use the standard paradigms to help with authentication, retries with exponential backoff, configuring credentials, etc. The defaults are all hardcoded to match what is in gatk at present. It also helps with performance issues with gcs, see #7070. This version also contains fixes for #7089, although it will require additional support from gatk(will be part of a separate PR).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7224:413,authenticat,authentication,413,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7224,1,['authenticat'],['authentication']
Security,Multi-input Picard tools and metrics should perform sequence dictionary validation on their inputs,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1272:72,validat,validation,72,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1272,1,['validat'],['validation']
Security,MultiVariantWalker sequence dictionary cross-validation is miserable,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6589:45,validat,validation,45,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6589,1,['validat'],['validation']
Security,"Mutect2.wdl: ""pet-@.gserviceaccount.com does not have storage.buckets.get access to the Google Cloud Storage bucket",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7492:74,access,access,74,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7492,1,['access'],['access']
Security,"NIO uses the gcloud system authentication, so we shouldn't need this anymore.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2402:27,authenticat,authentication,27,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2402,1,['authenticat'],['authentication']
Security,"New version allows restricting which users can trigger carrot jobs based on their access to the repository. In this case, I've set it to restrict to only users who have at least write access.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6986:82,access,access,82,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6986,2,['access'],['access']
Security,"Normally one provides passing workflow runs with a PR. For the integration run [that is here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/ab86fb6d-c5d6-48b6-8322-923af691751c). There's also a ""real"" run taking place using this branch [here](https://job-manager.dsde-prod.broadinstitute.org/jobs/db59d5b8-e2ac-4619-9563-aa5631bf053c). However for testing correctness of these changes with respect to the requester pays flag, my pet ""does not have serviceusage.services.use access to the Google Cloud project"". I therefore present instead a [run with my changes](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/9e712055-f466-4929-b6eb-5306f3cde1a0) that fails in exactly the same way as a [run without my changes](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/185506f5-9dc1-4c02-997d-6fe3f5695259).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8552:500,access,access,500,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8552,1,['access'],['access']
Security,Now can specify a master sequence dictionary that preempts all other; dictionaries that are found (in GATKTool.getBestAvailableSequenceDictionary). Added in associated validity checks with new dictionary in; GATKTool.validateSequenceDictionaries. Fixes #2410,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3058:217,validat,validateSequenceDictionaries,217,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3058,1,['validat'],['validateSequenceDictionaries']
Security,"Now that sequence dictionary validation is in, we can re-enable this test,; which was previously failing with a java.lang.OutOfMemoryError due to lack; of upfront validation of the reads vs. reference sequence dictionaries.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/668:29,validat,validation,29,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/668,2,['validat'],['validation']
Security,"Now that there's more rigorous sequence dictionary validation a bunch of dictionaries don't jive with the reference, especially files of the form src/test/resources/org/broadinstitute/hellbender/tools/copynumber/gcnv-postprocess/shard_0-calls/interval_list.tsv",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6957:51,validat,validation,51,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6957,1,['validat'],['validation']
Security,Now the validation test data sets are in the normal git file repository.; This allows them to be visually inspected for differences when they have; changed (during a code review). Fixes #5379,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5381:8,validat,validation,8,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5381,1,['validat'],['validation']
Security,"O ""$i"".snp.vcf.gz; gatk VariantFiltration -R $reference -V $path_BQSR/bqsr1.snp.vcf.gz -filter ""QD < 2.0"" --filter-name ""QD2"" -filter ""FS > 60.0"" --filter-name ""FS60"" -filter ""MQ < 40.0"" --filter-name ""MQ40"" -filter ""MQRankSum < -12.5"" --filter-name ""MQRankSum-12.5"" -filter ""ReadPosRankSum < -8.0"" --filter-name ""ReadPosRankSum-8.0"" -O $""i"".filtered.snp.vcf.gz; gatk SelectVariants -R $reference -V $""i"".filtered.snp.vcf.gz --exclude-filtered -O ""$i"".select.filtered.snp.vcf.gz; #INDEL; gatk SelectVariants -R $reference -V ""$i"".vcf.gz -select-type INDEL -O ""$i"".indel.vcf.gz; gatk VariantFiltration -R $reference -V ""$i"".indel.vcf.gz -filter ""QD < 2.0"" --filter-name ""QD2"" -filter ""FS > 200.0"" --filter-name ""FS200"" -filter ""ReadPosRankSum < -20.0"" --filter-name ""ReadPosRankSum-20"" -O ""$i"".filtered.indel.vcf.gz; gatk SelectVariants -R $reference -V ""$i"".filtered.indel.vcf.gz --exclude-filtered -O ""$i"".selected.filtered.indel.vcf.gz. gatk BaseRecalibrator -R $reference -I $i_bam -O grp1 --use-original-qualities --known-sites ""$i"".select.filtered.snp.vcf.gz --known-sites ""$i"".selected.filtered.indel.vcf.gz; gatk ApplyBQSR -R $reference -I $i_bam -O ""$i"".sorted.dedup.BQSR1.bam -bqsr grp1 --static-quantized-quals 10 --static-quantized-quals 20 --static-quantized-quals 30 --add-output-sam-program-record --create-output-bam-md5 --use-original-qualities; gatk ValidateSamFile -I ""$i"".sorted.dedup.BQSR.bam -O ""$i""_validateSamFile_of_bqsr_bam_file.out; samtools index ""$i"".sorted.dedup.BQSR.bam; done; gatk --java-options ""-Xmx30G"" HaplotypeCaller -R $reference -I sample1.sorted.dedup.BQSR.bam sample2.sorted.dedup.BQSR.bam sample3.sorted.dedup.BQSR.bam -O sample1_sample2_sample4.g.vcf.gz --tmp-dir tmp -ERC GVCF; ```. Secondly, how do I set the ploidy parameter for different samples in the population-based snp-calling?; Finally, for each taxa, there are some samples with relatively high sequence depth (> 10x). Is there any better choices for the snp-calling pipeline ??. Sincerely.; Jing",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8414:2613,Validat,ValidateSamFile,2613,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8414,1,['Validat'],['ValidateSamFile']
Security,"O field at 1:768589 .. INFO tag [AC=1] expected different number of values (expected 2, found 1),INFO tag [AF=0.00047] expected different number of values (expected 2, found 1)`; ### Notes. Currently, all the validation modes call out to HTSJDK. Do we want to put the new functionality there as well?. ---. @yfarjoun commented on [Thu Jul 16 2015](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-122130280). I think that it is very appropriate to validate in htsjdk. On Thu, Jul 16, 2015 at 4:05 PM, ldgauthier notifications@github.com; wrote:. > Currently ValidateVariants relies on genotypes to transitively check that; > each alt allele occurs in at least one sample and that the AC adds up.; > However, this can fail on sites-only files because there are no genotypes.; > We should use the definition of the info annotations in the header to check; > how many entries each should have.; > Outline; > - Add a new validation type for info-field counts to enum and to; > switch statement; > - Grab info headers from input VCF with something like; > GATKVCFUtils.getVCFHeadersFromRods(getToolkit(),; > variantCollection.variants.getName()) and VCFHeader::getInfoHeaderLines; > - In the map() function, for each info header line, call on each; > VCFInfoHeaderLine getCount(vc) to get the expected number of info; > annotation entries; > - Compare the expected number with a count based on; > vc.getAttribute(currentVCFinfoHeaderLine.getID()), which will require some; > additional parsing because it returns an Object; > - (Bonus points if you use the isFixedCount() and getCount() functions; > on the VCF info header line to simplify annotations that aren't according; > to the number of alt alleles); > ; > Test data; > ; > /humgen/gsa-hpprojects/dev/gauthier/scratch/supportingMultiA.vcf; > Should fail AC/AF validation at; > 1 768589 . A C,G 76 PASS AC=1;AF=0.00047;AN=2120; > See results using:; > ; > use VCFtools; > vcf-validator /humgen/gsa-hpprojects/dev/gauthier/scra",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2507:2484,validat,validation,2484,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2507,1,['validat'],['validation']
Security,"O yarn.Client: Preparing resources for our AM container; 20/10/22 12:02:26 WARN yarn.Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.; 20/10/22 12:02:29 INFO yarn.Client: Uploading resource file:/tmp/spark-28ab5ef4-82d1-425e-879f-5056e9b51e43/__spark_libs__7655440475844189559.zip -> hdfs://192.168.0.104:9000/user/jacky/.sparkStaging/application_1603353714322_0004/__spark_libs__7655440475844189559.zip; 20/10/22 12:02:31 INFO yarn.Client: Uploading resource file:/home/jacky/Exec/gatk/build/libs/gatk-spark.jar -> hdfs://192.168.0.104:9000/user/jacky/.sparkStaging/application_1603353714322_0004/gatk-spark.jar; 20/10/22 12:02:33 INFO yarn.Client: Uploading resource file:/tmp/spark-28ab5ef4-82d1-425e-879f-5056e9b51e43/__spark_conf__3248804172036151699.zip -> hdfs://192.168.0.104:9000/user/jacky/.sparkStaging/application_1603353714322_0004/__spark_conf__.zip; 20/10/22 12:02:33 INFO spark.SecurityManager: Changing view acls to: jacky; 20/10/22 12:02:33 INFO spark.SecurityManager: Changing modify acls to: jacky; 20/10/22 12:02:33 INFO spark.SecurityManager: Changing view acls groups to: ; 20/10/22 12:02:33 INFO spark.SecurityManager: Changing modify acls groups to: ; 20/10/22 12:02:33 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(jacky); groups with view permissions: Set(); users with modify permissions: Set(jacky); groups with modify permissions: Set(); 20/10/22 12:02:33 INFO yarn.Client: Submitting application application_1603353714322_0004 to ResourceManager; 20/10/22 12:02:33 INFO impl.YarnClientImpl: Submitted application application_1603353714322_0004; 20/10/22 12:02:34 INFO yarn.Client: Application report for application_1603353714322_0004 (state: ACCEPTED); 20/10/22 12:02:34 INFO yarn.Client: ; 	 client token: N/A; 	 diagnostics: N/A; 	 ApplicationMaster host: N/A; 	 ApplicationMaster RPC port: -1; 	 queue: default; 	 start ti",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6906:3249,Secur,SecurityManager,3249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6906,1,['Secur'],['SecurityManager']
Security,"Once again I've managed to convince David R. to let me merge with some tech debt as follows:; - [ ] Add to GnarlyGenotyper an integration test like testRawAndFinalizedAlleleSpecificAnnotationsThoroughly() for GGVCFs; - [ ] Add a direct unit test for makeReducedAnnotationString() if you exposed it as package-accessible; - [ ] ~Break out finalized key definition, promote getKeyNames and getRawKeyNames to default methods in ReducibleAnnotation interface~; - [ ] One last `ann.getRawKeyNames().get(0)` in GnarlyGenotyperEngine",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6203:287,expose,exposed,287,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6203,2,"['access', 'expose']","['accessible', 'exposed']"
Security,"Once https://github.com/broadinstitute/gatk/pull/3620/ is in, we should be able to remove the download of picard.jar from .travis.yml, and change the M2 WDL to no longer depend having access to it. Workflow calls to picard tools can be replaced with calls to the same tools in GATK, although the argument syntax will have to change from picard style to Barclay style (""I=..."" to ""-I ..."").",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3625:184,access,access,184,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3625,1,['access'],['access']
Security,"Once https://github.com/samtools/htsjdk/pull/327 is merged into htsjdk and propagates to hellbender, let's audit our Spark tools to ensure that we are always serializing headerless SAMRecords",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1072:107,audit,audit,107,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1072,1,['audit'],['audit']
Security,"Otherwise, when json is refreshed, contents of the file are different, hash of the file is different, and call-caching will not register a match, despite the same ""account"" being used. - changed input type from `File` to `String`; - changed the name to make it more obvious/clear. Closes https://github.com/broadinstitute/dsp-spec-ops/issues/327",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7347:71,hash,hash,71,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7347,1,['hash'],['hash']
Security,"Our R dependency is primarily for producing plots. It could be possible to create plots using javascript instead. Javascript plots have several potential advantages but also several major downsides. The biggest and most obvious drawback is that we don't have any code to produce them yet, and they are likely harder to generate and experiment with than R scripts. . The advantage would be that we could avoid requiring an R installation to run hellbender scripts, we could potentially also include interactive plotting or other neat tricks to make the plots more useful. I see 2 possible routes to replacing Rscripts with javascript. The first would be for tools that require graphs to perform some html generation and produce html reports with embedded javascript. The user could then open these in their browser and view the plots ( much like how our test suite report and jacoco is done). . A different option would be to use javascript plotting libraries directly within the jvm to generate SVG. Java 8 has a new javascript engine which is supposed to be reasonably fast and offers access to java objects from within it. Unfortunately it doesn't offer a full DOM like a browser does, so most existing javascript libraries will fall over. It seems like it would take a lot of hacking to get something like d3 to run directly on the jvm. (someone has done something of the kind here: http://jazdw.net/content/server-side-svg-generation-using-d3js) . Other options would be to use the javafx web panes to display a browser directly, or to plot directly on a canvas. Either of these options seem like they would be painful and awful.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/248:1086,access,access,1086,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/248,1,['access'],['access']
Security,"Out of 11 runs on exactly the same data, FilterByOrientationBias fails 6 times and succeeds 5 times. Assigning @LeeTL1220, given prior interaction with user. - User reports this error in: https://gatkforums.broadinstitute.org/gatk/discussion/comment/40412#Comment_40412; - My recapitulation is in: https://github.com/broadinstitute/dsde-docs/issues/2294. Data is at `/humgen/gsa-scr1/pub/incoming/byoo_FilterByOrientationBias.zip`. Command is:; ```; gatk-launch FilterByOrientationBias \; -A 'G/T' -A 'C/T' \; -V test2.vcf \; -P test2.pre_adapter_detail_metrics \; --output ob_filtered2.vcf; ```. Error message changes between:; ```; java.lang.IllegalStateException: Allele in genotype C* not in the variant context [G*, T]; 	at htsjdk.variant.variantcontext.VariantContext.validateGenotypes(VariantContext.java:1360); 	at htsjdk.variant.variantcontext.VariantContext.validate(VariantContext.java:1298); 	at htsjdk.variant.variantcontext.VariantContext.<init>(VariantContext.java:401); 	at htsjdk.variant.variantcontext.VariantContextBuilder.make(VariantContextBuilder.java:494); 	at htsjdk.variant.variantcontext.VariantContextBuilder.make(VariantContextBuilder.java:488); 	at org.broadinstitute.hellbender.tools.exome.orientationbiasvariantfilter.OrientationBiasFilterer.annotateVariantContextsWithFilterResults(OrientationBiasFilterer.java:216); 	at org.broadinstitute.hellbender.tools.exome.FilterByOrientationBias.onTraversalSuccess(FilterByOrientationBias.java:168); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:781); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:115); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:170); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:189); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:122); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3291:774,validat,validateGenotypes,774,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3291,2,['validat'],"['validate', 'validateGenotypes']"
Security,"Passing Integration Test [here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/ad05b4d1-7aed-4482-8b5c-ced7b87d2d37).; Verified that GQ0 dropped in 'hail_lite' run and not in 'hail_vcf' run; (queries of count by state from ref ranges table):. **Hail Lite (Hail path, drop state 0):; state count**; 2 2495387; 3 4773472  ; 4 5959290. **Lite VCF (VCF path, drop_state 40):; state count**; 0 2764630; 2 2495387; 3 4773472. Spun up a notebook and ran the vds_validation.py script on the VDS generated by 'hail_lite'. And it passed:. > 2023-10-04 19:08:01.278 Hail: WARN: cols(): Resulting column table is sorted by 'col_key'.; > To preserve matrix table column order, first unkey columns with 'key_cols_by()'; > checking that:; > * no reference blocks have GQ=0; > * all ref blocks have END after start; > * all ref blocks are max 1000 bases long; > running densify on 200kb region (0 + 1) / 1]; > took 10.9s to densify 0 rows after interval query; > Hail VDS validation successful======================================(1 + 0) / 1]",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8538:981,validat,validation,981,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8538,1,['validat'],['validation']
Security,PathSeqPipelineSpark validation,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8212:21,validat,validation,21,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8212,1,['validat'],['validation']
Security,Performance issues when accessing Reads in Interval/Feature based walkers.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1246:24,access,accessing,24,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1246,1,['access'],['accessing']
Security,Picard tools don't perform validation of the sequence dictionary which will occasionally lead to errors. They should implement the same checking as the rest of our tools,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1272:27,validat,validation,27,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1272,1,['validat'],['validation']
Security,PileupElement : save memory and time by accessing bases and quals directly without copying.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1794:40,access,accessing,40,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1794,1,['access'],['accessing']
Security,PileupElement: save memory and time by accessing bases and quals directly without copying. Showed up on profile in HC,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1794:39,access,accessing,39,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1794,1,['access'],['accessing']
Security,Placeholders for now. We can tweak the actual values once @LeeTL1220 checks effect on validation. Closes #4032.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4046:86,validat,validation,86,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4046,1,['validat'],['validation']
Security,"Please update the GitHub description to use https://www.broadinstitute.org/gatk/ which saves one redirect, and is more secure with rogue DNS servers.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3211:119,secur,secure,119,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3211,1,['secur'],['secure']
Security,Polishing hapmap M2 validation,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3171:20,validat,validation,20,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3171,1,['validat'],['validation']
Security,PoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745); Caused by: shaded.cloud_nio.com.google.api.client.googleapis.json.GoogleJsonResponseException: 403 Forbidden; 443301511749-compute@developer.gserviceaccount.com does not have storage.objects.get access to broad-jg-dev-11k-call-set/JointGenotyping/0cb36821-b8bf-4e6d-a352-07b101f6b7d1/call-ApplyRecalibration/shard-1734/GMKF_Seidman_CHD_WGS_904.filtered.1734.vcf.gz.; 	at shaded.cloud_nio.com.google.api.client.googleapis.json.GoogleJsonResponseException.from(GoogleJsonResponseException.java:145); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:113); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:40); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest$1.interceptResponse(AbstractGoogleClientRequest.java:321); 	at shaded.cloud_nio.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1056); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeMedia(AbstractGoogleClientRequest.java:380); 	at shaded.cloud_nio.com.google.api.services.storage.Storage$Objects$Get.executeMedia(Storage.java:6133); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.read(HttpStorageRpc.java:505); 	... 12 more; ```. This service account does have access to these files because every shard accesses the same files and most of them succeed and when the same task is rerun it does succeed. @snovod should have any other information you may need.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3735:6610,access,access,6610,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3735,2,['access'],"['access', 'accesses']"
Security,"PoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748). I don't understand why if the command is the same:; ```; $GATK_PATH BwaAndMarkDuplicatesPipelineSpark --bam-partition-size 64000000 or 4000000 \; --input hdfs://namenode:8020/$dir_prepro$ubam \; --reference hdfs://namenode:8020/hg19-ucsc/ucsc.hg19.2bit \; --bwa-mem-index-image /reference_image/ucsc.hg19.fasta.img \; --disable-sequence-dictionary-validation true \; --output hdfs://namenode:8020/$dir_prepro$output -- \; --spark-runner SPARK --spark-master spark://$SPARK_MASTER_HOST:7077 \; --driver-memory 20g --executor-cores 4 --executor-memory 8g; ```. Furthermore I have this problem with this version v4.0.4.0-23-g6e1cc8c-SNAPSHOT. > mark duplicate records objects corresponding to read with name, this could be the result of readnames spanning more than one partition; 	at org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSpark.lambda$null$0(MarkDuplicatesSpark.java:109); 	at java.util.HashMap.merge(HashMap.java:1253); 	at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1320); 	at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 	at org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSpark.lambda$mark$62928560$1(MarkDuplicatesSpark.java:109); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$10$1.apply(JavaRDDLike.scala:319); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4820:7087,Hash,HashMap,7087,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4820,1,['Hash'],['HashMap']
Security,Populating the DB SNP validation status field properly,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5046:22,validat,validation,22,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5046,1,['validat'],['validation']
Security,Porting over gvcf validation option to ValidateVariants,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3331:18,validat,validation,18,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3331,2,"['Validat', 'validat']","['ValidateVariants', 'validation']"
Security,"PostprocessGermlineCNVCalls performs a check of the denoising/calling hyperparameter configs used to generate the model in GermlineCNVCaller cohort mode against those used to generate the case-mode result passed to PostprocessGermlineCNVCalls. However, although some of these hyperparameters are not exposed in case mode (since they have no effect on the sample-level parameters inferred in case mode, e.g., `psi_t_scale`), their python default values are nevertheless written to the case-mode config. I think that this results in a spurious mismatch between the cohort/case mode configs, which causes PostprocessGermlineCNVCalls to emit the following warnings in case mode when non-default values are used:. ````; WARNING gcnvkernel.postprocess.viterbi_segmentation - Different denoising configuration between model and calls -- proceeding at your own risk!; WARNING gcnvkernel.postprocess.viterbi_segmentation - Different calling configuration between model and calls -- proceeding at your own risk!; ````. I'm pretty sure that inference is actually performed correctly, but we may want to double check and clean up these warnings. We should probably just copy the non-exposed values from the model config on the python side when running GermlineCNVCaller in case mode. Not sure if there's any way to emit sensible warnings on the Java side. These hyperparameters are still exposed to the Java command line in case mode, they just aren't passed on to the python command line. So the user can change their values from their engine defaults without having any effect at all, but this is probably what we want. Perhaps we can document, though.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6994:300,expose,exposed,300,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6994,3,['expose'],['exposed']
Security,"Previously, a temporary table is created as part of extract of the VQSR features, and it goes into a separate `temp_tables` dataset in the current project -- that is no longer true, and it now goes into the default dataset as a short living temp table with the task name and a hash. This pr should:. - default to the current dataset (with the VET etc tables) rather than a different dataset. - give a prefix to the temp tables so we know which one came from which step. - temp table TTL---not a changeable option, but default to 24 hours across the board. Still to discuss:; Parameterization of the location (dataset) to create the temp table in (default to the default dataset); manual clean up/TTL is a changeable option and TTL is parametrizable (currently the TTL is a parameter for the prepare step -- but then we set a default as 24 hrs in the WDL) . ![Screen Shot 2022-06-10 at 1 27 58 PM](https://user-images.githubusercontent.com/6863459/173121781-4486c1d1-ef7a-4ab8-aa62-fdc5018fd3b9.png)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7742:277,hash,hash,277,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7742,1,['hash'],['hash']
Security,Provide a mechanism for dataflow authentication information to be set once and stay set,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/701:33,authenticat,authentication,33,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/701,1,['authenticat'],['authentication']
Security,Provide a tool for outputting possible pathogen injection site on (human) host,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3458:48,inject,injection,48,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3458,1,['inject'],['injection']
Security,Providing counts for supporting alt reads in the validation normal.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5062:49,validat,validation,49,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5062,1,['validat'],['validation']
Security,Python tools need doc and validation that the conda environment is activated,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4127:26,validat,validation,26,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4127,1,['validat'],['validation']
Security,Qs of reads sharing kmers with putative SV breakpoints for local assembly; FlagStatSpark FlagStat on Spark; MarkDuplicatesSpark MarkDuplicates on Spark; MeanQualityByCycleSpark MeanQualityByCycle on Spark; PrintReadsSpark PrintReads on Spark; QualityScoreDistributionSpark QualityScoreDistribution on Spark; SortReadFileSpark SortSam on Spark (works on SAM/BAM/CRAM). --------------------------------------------------------------------------------------; Spark tools for structural variation analysis: Structural variation analysis tools that use Apache Spark for scaling out (experimental); CollectInsertSizeMetricsSpark Collect Insert Size Distribution on Spark. --------------------------------------------------------------------------------------; VCF: Tools for manipulating variants and associated metadata; CountVariants Count variants in a VCF file; ExampleVariantWalker Example tool that prints variants with optional contextual data; FilterVcf Hard-filters a VCF file; GatherVcfs Gathers multiple VCF files from a scatter operation into a single VCF file; GenotypeConcordance Calculates the concordance between genotype data for two samples in two different VCFs; IndexFeatureFile Creates indices for Feature-containing files (eg VCF and BED files); LiftOverVcf Lifts a VCF between genome builds; MakeSitesOnlyVcf Creates a VCF bereft of genotype information from an input VCF; MergeVcfs Merges multiple VCF files into one VCF file; RenameSampleInVcf Rename a sample within a VCF; SelectVariants Select a subset of variants from a larger callset in a VCF file; SortVcf Sorts one or more VCF files; SplitVcfs Splits an input VCF file into two VCF files; ValidateVariants Validate VCF; VariantFiltration Hard-filter variants VCF (mark them as FILTER); VariantsToTable Extract specific fields from a VCF file to a tab-delimited table; VcfToIntervalList Converts a VCF file to a Picard Interval List. --------------------------------------------------------------------------------------; ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1669:9457,Validat,ValidateVariants,9457,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1669,2,['Validat'],"['Validate', 'ValidateVariants']"
Security,R code does not have access to changes in column names/file formats,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2862:21,access,access,21,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2862,1,['access'],['access']
Security,"READ_PAIR_DUPLICATES READ_PAIR_OPTICAL_DUPLICATES PERCENT_DUPLICATION ESTIMATED_LIBRARY_SIZE; Unknown 0 9951 0 0 0 0 0 0. ## HISTOGRAM java.lang.Integer; duplication_group_count Unknown; 1 9951; ```. MarkDuplicatesSpark; ```; ## htsjdk.samtools.metrics.StringHeader; # MarkDuplicatesSpark --output temp/align/markduplicates/c_lib1.bam --metrics-file stats/align/markduplicates/c_lib1.metrics.txt --input temp/align/bwa_aln/c_lib1_L001.sorted.bam --read-validation-stringency LENIENT --spark-master local[8] --allow-multiple-sort-orders-in-input false --treat-unsorted-as-querygroup-ordered false --duplicate-scoring-strategy SUM_OF_BASE_QUALITIES --do-not-mark-unmapped-mates false --duplicate-tagging-policy DontTag --remove-all-duplicates false --remove-sequencing-duplicates false --read-name-regex <optimized capture of last three ':' separated fields as numeric values> --optical-duplicate-pixel-distance 100 --interval-set-rule UNION --interval-padding 0 --interval-exclusion-padding 0 --interval-merging-rule ALL --bam-partition-size 0 --use-nio false --disable-sequence-dictionary-validation false --add-output-vcf-command-line true --sharded-output false --num-reducers 0 --create-output-bam-index true --create-output-bam-splitting-index true --splitting-index-granularity 4096 --create-output-variant-index true --help false --version false --showHidden false --verbosity INFO --QUIET false --use-jdk-deflater false --use-jdk-inflater false --gcs-max-retries 20 --gcs-project-for-requester-pays --disable-tool-default-read-filters false; ## htsjdk.samtools.metrics.StringHeader; # Started on: March 24, 2021 9:31:36 PM CET. ## METRICS CLASS org.broadinstitute.hellbender.utils.read.markduplicates.GATKDuplicationMetrics; LIBRARY UNPAIRED_READS_EXAMINED READ_PAIRS_EXAMINED SECONDARY_OR_SUPPLEMENTARY_RDS UNMAPPED_READS UNPAIRED_READ_DUPLICATES READ_PAIR_DUPLICATES READ_PAIR_OPTICAL_DUPLICATES PERCENT_DUPLICATION ESTIMATED_LIBRARY_SIZE; Unknown Library 0 9998 0 0 0 0 0 0; ```. MarkDuplica",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7161:2227,validat,validation-stringency,2227,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7161,2,['validat'],"['validation', 'validation-stringency']"
Security,"RN yarn.Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.; 20/10/22 12:02:29 INFO yarn.Client: Uploading resource file:/tmp/spark-28ab5ef4-82d1-425e-879f-5056e9b51e43/__spark_libs__7655440475844189559.zip -> hdfs://192.168.0.104:9000/user/jacky/.sparkStaging/application_1603353714322_0004/__spark_libs__7655440475844189559.zip; 20/10/22 12:02:31 INFO yarn.Client: Uploading resource file:/home/jacky/Exec/gatk/build/libs/gatk-spark.jar -> hdfs://192.168.0.104:9000/user/jacky/.sparkStaging/application_1603353714322_0004/gatk-spark.jar; 20/10/22 12:02:33 INFO yarn.Client: Uploading resource file:/tmp/spark-28ab5ef4-82d1-425e-879f-5056e9b51e43/__spark_conf__3248804172036151699.zip -> hdfs://192.168.0.104:9000/user/jacky/.sparkStaging/application_1603353714322_0004/__spark_conf__.zip; 20/10/22 12:02:33 INFO spark.SecurityManager: Changing view acls to: jacky; 20/10/22 12:02:33 INFO spark.SecurityManager: Changing modify acls to: jacky; 20/10/22 12:02:33 INFO spark.SecurityManager: Changing view acls groups to: ; 20/10/22 12:02:33 INFO spark.SecurityManager: Changing modify acls groups to: ; 20/10/22 12:02:33 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(jacky); groups with view permissions: Set(); users with modify permissions: Set(jacky); groups with modify permissions: Set(); 20/10/22 12:02:33 INFO yarn.Client: Submitting application application_1603353714322_0004 to ResourceManager; 20/10/22 12:02:33 INFO impl.YarnClientImpl: Submitted application application_1603353714322_0004; 20/10/22 12:02:34 INFO yarn.Client: Application report for application_1603353714322_0004 (state: ACCEPTED); 20/10/22 12:02:34 INFO yarn.Client: ; 	 client token: N/A; 	 diagnostics: N/A; 	 ApplicationMaster host: N/A; 	 ApplicationMaster RPC port: -1; 	 queue: default; 	 start time: 1603360953394; 	 final status: UNDEFINED; 	 tracking URL: http://jacky:80",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6906:3325,Secur,SecurityManager,3325,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6906,1,['Secur'],['SecurityManager']
Security,ROC Curve Walker for validation,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2723:21,validat,validation,21,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2723,1,['validat'],['validation']
Security,"R_SAMTOOLS : true; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 19:53:34.608 INFO ValidateVariants - Deflater: IntelDeflater; 19:53:34.608 INFO ValidateVariants - Inflater: IntelInflater; 19:53:34.608 INFO ValidateVariants - GCS max retries/reopens: 20; 19:53:34.608 INFO ValidateVariants - Requester pays: disabled; 19:53:34.608 INFO ValidateVariants - Initializing engine; 19:53:35.169 INFO FeatureManager - Using codec VCFCodec to read file file://chr1-22.phased.rename.reheader.vcf.gz; 19:53:35.594 INFO ValidateVariants - Done initializing engine; 19:53:35.594 WARN ValidateVariants - IDS validation cannot be done because no DBSNP file was provided; 19:53:35.594 WARN ValidateVariants - Other possible validations will still be performed; 19:53:35.594 INFO ProgressMeter - Starting traversal; 19:53:35.595 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 19:53:35.660 INFO ValidateVariants - Shutting down engine; [October 25, 2020 7:53:35 PM CDT] org.broadinstitute.hellbender.tools.walkers.variantutils.ValidateVariants done. Elapsed time: 0.02 minutes.; Runtime.totalMemory()=2114453504; java.lang.ArrayIndexOutOfBoundsException: -87; 	at org.broadinstitute.hellbender.utils.BaseUtils.convertIUPACtoN(BaseUtils.java:123); 	at org.broadinstitute.hellbender.utils.fasta.CachingIndexedFastaSequenceFile.getSubsequenceAt(CachingIndexedFastaSequenceFile.java:340); 	at org.broadinstitute.hellbender.engine.ReferenceFileSource.queryAndPrefetch(ReferenceFileSource.java:78); 	at org.broadinstitute.hellbender.engine.ReferenceDataSource.queryAndPrefetch(ReferenceDataSource.java:64); 	at org.broadinstitute.hellbender.engine.ReferenceContext.getBases(ReferenceContext.java:197); 	at org.broadinstitute.hellbender.tools.walkers.variantutils.ValidateVariants.apply(ValidateVariants.java:236); 	at org.broadinstitute.hellbender.engine.VariantWalker.lambda$traverse$0(VariantWalker.java:104); 	at org.broadinstitute.h",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6911:3238,Validat,ValidateVariants,3238,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6911,1,['Validat'],['ValidateVariants']
Security,Rc vat validation typo,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7366:7,validat,validation,7,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7366,1,['validat'],['validation']
Security,Re-enable BaseRecalibratorDataflowIntegrationTest.testBQSRFailWithIncompatibleReference once sequence dictionary validation is in,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/625:113,validat,validation,113,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/625,1,['validat'],['validation']
Security,"Read counts at different stages of the PathSeq pipeline are now logged using `MetricsFile`. The filter metrics contains the number of reads remaining and number of reads filtered at each step (after filtering pre-aligned reads, low quality/complexity reads, host reads, and duplicates). The score metrics give number of pathogen-mapped and unmapped reads. These metrics are now validated in the PathSeq integration tests, which have also been refactored to use DataProviders instead of separate functions.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3611:378,validat,validated,378,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3611,1,['validat'],['validated']
Security,ReadSparkSink adds a crc checksum file even for local files,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1266:25,checksum,checksum,25,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1266,1,['checksum'],['checksum']
Security,ReadsDataSource: enable setting validation stringency,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/181:32,validat,validation,32,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/181,1,['validat'],['validation']
Security,ReadsDataSource: enable setting validation stringency.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/585:32,validat,validation,32,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/585,1,['validat'],['validation']
Security,ReadsDataSource: expose setting validation stringency at command line,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/611:17,expose,expose,17,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/611,2,"['expose', 'validat']","['expose', 'validation']"
Security,Recent refactoring seems to have introduced a bug in pileup mode that failed to enforce the limit on the number of haplotypes to be considered. With this patch:. - HaplotypeCaller once again respects the limit on haplotypes before genotyping.; - Changed some `HashSet`s to `LinkedHashSets` to preserve determinism.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8489:260,Hash,HashSet,260,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8489,1,['Hash'],['HashSet']
Security,Refactor MT wdl to make validations easier,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5708:24,validat,validations,24,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5708,1,['validat'],['validations']
Security,"Reference, Feature and whatever context fully by injection.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/242:49,inject,injection,49,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/242,1,['inject'],['injection']
Security,Remove the <20 obfuscation for AC; This needs to be removed from the Python (which did the original obfuscation); And the VAT Validation WDL -- which checked on it,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7435:126,Validat,Validation,126,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7435,1,['Validat'],['Validation']
Security,Removes unnecessary and buggy validation check,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8580:30,validat,validation,30,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8580,1,['validat'],['validation']
Security,Rename ValidateBasicSomaticShortMutations to something more in-line with MutationValidator,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5871:7,Validat,ValidateBasicSomaticShortMutations,7,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5871,1,['Validat'],['ValidateBasicSomaticShortMutations']
Security,Renamed existing test for validating generated WDLs.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7829:26,validat,validating,26,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7829,1,['validat'],['validating']
Security,Reported by Intel. Should be a `UserException` instead. ```; ./gatk-launch BwaSpark -I hdfs://sn1:8020/user/$USER/gatk/CEUTrio.HiSeq.WEx.b37.NA12892.readnamesort.bam -R hdfs://sn1:8020/user/$USER/gatk/human_g1k_v37.fasta -O hdfs://sn1:8020/user/$USER/gatk/CEUTrio.HiSeq.WEx.b37.NA12892.readnamesort.bam -- --sparkRunner SPARK --sparkMaster spark://sn1:7077 --driver-memory 8G --num-executors 4 --executor-cores 9 --executor-memory 27g; ```. ```; java.lang.NullPointerException; at org.broadinstitute.hellbender.utils.SequenceDictionaryUtils.getContigNames(SequenceDictionaryUtils.java:464); at org.broadinstitute.hellbender.utils.SequenceDictionaryUtils.getCommonContigsByName(SequenceDictionaryUtils.java:458); at org.broadinstitute.hellbender.utils.SequenceDictionaryUtils.compareDictionaries(SequenceDictionaryUtils.java:234); at org.broadinstitute.hellbender.utils.SequenceDictionaryUtils.validateDictionaries(SequenceDictionaryUtils.java:150); at org.broadinstitute.hellbender.utils.SequenceDictionaryUtils.validateDictionaries(SequenceDictionaryUtils.java:98); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.validateToolInputs(GATKSparkTool.java:402); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:312); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:38); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:108); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:166); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:185); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:76); at org.broadinstitute.hellbender.Main.main(Main.java:92); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAcce,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2020:893,validat,validateDictionaries,893,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2020,1,['validat'],['validateDictionaries']
Security,"Reposting from the Slack channel:. When I run ValidateVariants on an *invalid* VCF without providing a reference or any ""--validation-type-to-exclude"" arguments, I don't get any validation errors. However, if I add ""--validation-type-to-exclude REF"", then I get validation errors as expected. Even when I get validation errors in the second case, the error message seems to terminate abruptly: `A USER ERROR has occurred: Input output.vcf fails strict validation: the Allele Count (AC) tag is incorrect for the record at position 1:1262288, 2 vs. 1 of type:`",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4642:46,Validat,ValidateVariants,46,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4642,7,"['Validat', 'validat']","['ValidateVariants', 'validation', 'validation-type-to-exclude']"
Security,Request: Easy access to FeatureInput<VariantContext> in GATKTool for walkers that traverse VariantContext,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1710:14,access,access,14,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1710,1,['access'],['access']
Security,Requester pays access isn't working,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6179:15,access,access,15,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6179,1,['access'],['access']
Security,"Requires a ""git lfs pull"" to access. File size is ~230 MB.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/927:29,access,access,29,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/927,1,['access'],['access']
Security,Revert explicit GAR references in our Docker build scripts for now. Variants team members are not Methods team members and thus do not have the access required to make Variants GAR repos public in the `broad-dsde-methods` project. Note that Variants images are still ending up in GAR thanks to the magic of DevOps redirects. This PR also retains the Docker image ID-based referencing that was introduced at the same time as the explicit GAR references that are now being backed out. Successful (or at least non-instafailing) [integration run here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/2f00b836-0c2d-41e9-84b1-b8c6a2bea8f6).,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8789:144,access,access,144,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8789,1,['access'],['access']
Security,"Rightnow doing the manual docker build locally would fail. One needs to copy the line in `.travis.yml`. ```; sudo bash build_docker.sh -e ${HASH} -s -u -d $PWD/temp_staging/;; sudo docker run -v $(pwd)/src/test/resources:/testdata --rm -e ""TEST_VERBOSITY=minimal"" -e ""TEST_TYPE=${TEST_TYPE}"" -t broadinstitute/gatk:${HASH} bash /root/run_unit_tests.sh;; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3160:140,HASH,HASH,140,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3160,2,['HASH'],['HASH']
Security,"Run validation tests continuously in jenkins: ReadsPipelineSpark, BQSR etc",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1401:4,validat,validation,4,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1401,1,['validat'],['validation']
Security,"Running on the hg19/b37 NA12878 bam file, I'm getting the following exception in stage 0:. ```; org.apache.spark.SparkException: Job aborted due to stage failure: Task 589 in stage 0.0 failed 4 times, most recent failure: Lost task 589.3 in stage 0.0 (TID 757, cwhelan-na12878-pcr--30x-bam-w-6.c.broad-dsde-methods.internal): java.lang.IllegalArgumentException: observedValue must be non-negative; at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:681); at org.broadinstitute.hellbender.tools.spark.utils.IntHistogram.addObservation(IntHistogram.java:50); at org.broadinstitute.hellbender.tools.spark.sv.evidence.ReadMetadata$LibraryRawStatistics.addRead(ReadMetadata.java:367); at org.broadinstitute.hellbender.tools.spark.sv.evidence.ReadMetadata$PartitionStatistics.<init>(ReadMetadata.java:431); at org.broadinstitute.hellbender.tools.spark.sv.evidence.ReadMetadata.lambda$new$1dcab782$1(ReadMetadata.java:57); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:152); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:152); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:785); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:785); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); at org.apache.spark.scheduler.Task.run(Task.scala:86); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGSchedul",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3462:443,validat,validateArg,443,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3462,1,['validat'],['validateArg']
Security,"SCAN\_WINDOW\_SIZE=1000. When it's set to default value 100, the error message is slightly different but ArrayIndexOutOfBoundsException persists. I have also experimented with different window sizes, all values >1000 give same error at the same read on chrX (details below). The reference fasta file is taken from UCSC: [https://hgdownload.soe.ucsc.edu/goldenPath/hg19/bigZips/hg19.fa.gz](https://hgdownload.soe.ucsc.edu/goldenPath/hg19/bigZips/hg19.fa.gz). Any feedback leading to resolving the issue is greatly appreciated. a) Picard version:. 2.21.6-SNAPSHOT. b) Command script:. java -jar picard.jar CollectGcBiasMetrics \\ ; ; I=sorted.sam \\ ; ; O=gc\_bias\_metrics.txt \\ ; ; CHART=gc\_bias\_metrics.pdf \\ ; ; S=summary\_metrics.txt \\ ; ; R=hg19.fa \\ ; ; SCAN\_WINDOW\_SIZE=1000. c) Error log:. MINIMUM\_GENOME\_FRACTION=1.0E-5 IS\_BISULFITE\_SEQUENCED=false METRIC\_ACCUMULATION\_LEVEL=\[ALL\_READS\] ALSO\_IGNORE\_DUPLICATES=false ASSUME\_SORTED=true STOP\_AFTER=0 VERBOSITY=INFO QUIET=false VALIDATION\_STRINGENCY=STRICT COMPRESSION\_LEVEL=5 MAX\_RECORDS\_IN\_RAM=500000 CREATE\_INDEX=false CREATE\_MD5\_FILE=false GA4GH\_CLIENT\_SECRETS=client\_secrets.json USE\_JDK\_DEFLATER=false USE\_JDK\_INFLATER=false ; ; \[Tue Jan 07 16:48:19 PST 2020\] Executing as [akoch@hpc5-0-3.local](mailto:akoch@hpc5-0-3.local) on Linux 2.6.32-431.11.2.el6.x86\_64 amd64; OpenJDK 64-Bit Server VM 1.8.0\_181-b13; Deflater: Intel; Inflater: Intel; Provider GCS is not available; Picard version: 2.21.6-SNAPSHOT ; ; INFO 2020-01-07 16:51:24 SinglePassSamProgram Processed 1,000,000 records. Elapsed time: 00:00:33s. Time for last 1,000,000: 27s. Last read position: chr5:92,832,908 ; ; INFO 2020-01-07 16:51:53 SinglePassSamProgram Processed 2,000,000 records. Elapsed time: 00:01:01s. Time for last 1,000,000: 28s. Last read position: chr11:121,228,669 ; ; \[Tue Jan 07 16:52:25 PST 2020\] picard.analysis.CollectGcBiasMetrics done. Elapsed time: 4.10 minutes. ; ; Runtime.totalMemory()=4236247040 ; ; To ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6372:1491,VALIDAT,VALIDATION,1491,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6372,1,['VALIDAT'],['VALIDATION']
Security,"SSION_LEVEL : 1; 17:43:53.162 INFO ValidateVariants - Defaults.CREATE_INDEX : false; 17:43:53.163 INFO ValidateVariants - Defaults.CREATE_MD5 : false; 17:43:53.163 INFO ValidateVariants - Defaults.CUSTOM_READER_FACTORY :; 17:43:53.163 INFO ValidateVariants - Defaults.EBI_REFERENCE_SERVICE_URL_MASK : http://www.ebi.ac.uk/ena/cram/md5/%s; 17:43:53.163 INFO ValidateVariants - Defaults.NON_ZERO_BUFFER_SIZE : 131072; 17:43:53.163 INFO ValidateVariants - Defaults.REFERENCE_FASTA : null; 17:43:53.163 INFO ValidateVariants - Defaults.SAM_FLAG_FIELD_FORMAT : DECIMAL; 17:43:53.163 INFO ValidateVariants - Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 17:43:53.163 INFO ValidateVariants - Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 17:43:53.163 INFO ValidateVariants - Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 17:43:53.163 INFO ValidateVariants - Defaults.USE_CRAM_REF_DOWNLOAD : false; 17:43:53.163 INFO ValidateVariants - Deflater IntelDeflater; 17:43:53.163 INFO ValidateVariants - Inflater IntelInflater; 17:43:53.163 INFO ValidateVariants - Initializing engine; 17:43:53.270 INFO FeatureManager - Using codec VCFCodec to read file file:///Users/louisb/Workspace/gatk/src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleGood.vcf; 17:43:53.287 INFO FeatureManager - Using codec VCFCodec to read file file:///Users/louisb/Workspace/gatk/src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleGood.vcf; 17:43:53.291 WARN IndexUtils - Feature file ""/Users/louisb/Workspace/gatk/src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleGood.vcf"" appears to contain no sequence dictionary. Attempting to retrieve a sequence dictionary from the associated index file; 17:43:53.293 INFO ValidateVariants - Done initializing engine; 17:43:53.294 INFO ProgressMeter - Starting traversal; 17:43:53.294 INFO ProgressMeter - Current Locus Elapsed Minutes Records Process",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2509:3060,Validat,ValidateVariants,3060,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2509,1,['Validat'],['ValidateVariants']
Security,"SamAssertionUtils.samsEqualStringent tries to short-circuit file validation by first doing an md5 compare. Most of the time when we run the test suite (in the current tests 171 out of 193), the short-circuiting fails we do the more expensive read by read test. All of these have one or more that fail md5 check (some are probably crams, which IIRC places the file name in the cram header):. MarkDuplicatesIntegrationTest; AddOrReplaceReadGroupsIntegrationTest; ApplyBQSRIntegrationTest; ApplyBQSRSparkIntegrationTest; BQSRPipelineSparkIntegrationTest; BwaSparkIntegrationTest; GatherBamFilesIntegrationTest; HaplotypeBAMWriterUnitTest; PrintReadsIntegrationTest; ReadsPipelineSparkIntegrationTest; SamAssertionUtilsUnitTest; SamFormatConverterIntegrationTest; SortReadFileSparkIntegrationTest; SortSamIntegrationTest; SplitNCigarReadsIntegrationTest; ClipReadsIntegrationTest",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2395:65,validat,validation,65,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2395,1,['validat'],['validation']
Security,SampleDBBuilder validationStrictness argument doesn't do anything,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3949:16,validat,validationStrictness,16,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3949,1,['validat'],['validationStrictness']
Security,"Say hello to Azure SQL Database from `sqlcmd`, Python and Java (via Ammonite) running in a Cromwell on Azure deployment. Since the Azure Batch VMs spun up by Cromwell on Azure appear to have no identity associated with them the workflow currently takes a database access token as a parameter which it passes to the three tasks.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8220:264,access,access,264,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8220,1,['access'],['access']
Security,"See #2488 for context. In short, the internal pathways for authentication changed, breaking some tests. We're pushing forward anyways but need to remember to re-enable the code & tests once we can (should be the next release).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2496:59,authenticat,authentication,59,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2496,1,['authenticat'],['authentication']
Security,"See Issue #7622 for more details. In addition to unit tests, here is how I validated:. ```; ##; # Split the WGS list; ##; rm -rf test_split. ./gatk --java-options ""-Xmx4g $DEBUG"" \; WeightedSplitIntervals \; --scatter-count 100 \; --weight-bed-file gvs_vet_weights_1kb.bed \; -R gs://gcp-public-data--broad-references/hg38/v0/Homo_sapiens_assembly38.fasta \; --dont-mix-contigs true \; -L wgs_calling_regions.hg38.noCentromeres.noTelomeres.interval_list \; --output test_split. ##; # merge all the intervals lists back into one; ##; IL=""""; for f in test_split/*-scattered.interval_list; do; IL=""${IL} -I $f ""; done; ./gatk IntervalListTools --ACTION UNION $IL -O test_split/merged.interval_list. #; # compare it to the original; ##; ./gatk CompareIntervalLists \; -R gs://gcp-public-data--broad-references/hg38/v0/Homo_sapiens_assembly38.fasta \; -L wgs_calling_regions.hg38.noCentromeres.noTelomeres.interval_list \; -L2 test_split/merged.interval_list. ##; # A visual check to see that the ordering is the same, and that the only splits; # are across file boundaries; ##; cat test_split/*-scattered.interval_list | grep -v ""@"" | cut -f1-3 > test_split/combined.txt; cat wgs_calling_regions.hg38.noCentromeres.noTelomeres.interval_list | grep -v ""@"" | cut -f1-3 > test_split/orig.txt; diff -y test_split/orig.txt test_split/combined.txt; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7643:75,validat,validated,75,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7643,1,['validat'],['validated']
Security,"See https://github.com/broadinstitute/gatk/issues/4125 (which I suspect is due to the conda env not being established). @mbabadi @samuelklee @vdauwera Unfortunately we didn't add anything to the doc for these tools saying that they require the conda env. Some suggestions:. - Ideally, we could do something along the lines of what @droazen suggested in #4125, where the script executor validates that the environment is established. In a previous discussion though, @vdauwera expressed some concerns around requiring miniconda (as opposed to enumerating the individual requirements and allowing users to install these themselves - which is harder to communicate, and even harder to validate). We should discuss this further.; - Either way, the tools themselves could catch PythonScriptExecutorException and re-throw it with a helpful message saying the conda env is required.; - Update the tool summaries saying that the conda env is required.; - Update the tool javadoc/gatkdoc with more detail.; - Other ? Blog entry/forum post ?. This shouldn't be an issue for Docker users. We did discover a last minute issue that will affect OSX users though, which has a couple of workarounds described in this [PR](https://github.com/broadinstitute/gatk/pull/4087).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4127:386,validat,validates,386,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4127,2,['validat'],"['validate', 'validates']"
Security,Seeing a test failure due to errors with the service account access token. Possibly related to updating the NIO dependency. We've seen this multiple times today. ; ```; Gradle suite > Gradle test > org.broadinstitute.hellbender.utils.nio.GcsNioIntegrationTest.openPublicFile FAILED; com.google.cloud.storage.StorageException: Error getting access token for service account: ; at com.google.cloud.storage.spi.DefaultStorageRpc.translate(DefaultStorageRpc.java:203); at com.google.cloud.storage.spi.DefaultStorageRpc.get(DefaultStorageRpc.java:349); at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:186); at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:183); at com.google.cloud.RetryHelper.doRetry(RetryHelper.java:179); at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:244); at com.google.cloud.storage.StorageImpl.get(StorageImpl.java:183); at com.google.cloud.storage.StorageImpl.get(StorageImpl.java:197); at com.google.cloud.storage.contrib.nio.CloudStorageReadChannel.fetchSize(CloudStorageReadChannel.java:194); at com.google.cloud.storage.contrib.nio.CloudStorageReadChannel.<init>(CloudStorageReadChannel.java:72); at com.google.cloud.storage.contrib.nio.CloudStorageReadChannel.create(CloudStorageReadChannel.java:62); at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.newReadChannel(CloudStorageFileSystemProvider.java:268); at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.newByteChannel(CloudStorageFileSystemProvider.java:229); at java.nio.file.Files.newByteChannel(Files.java:361); at java.nio.file.Files.newByteChannel(Files.java:407); at java.nio.file.spi.FileSystemProvider.newInputStream(FileSystemProvider.java:384); at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.newInputStream(CloudStorageFileSystemProvider.java:348); at java.nio.file.Files.newInputStream(Files.java:152); at org.broadinstitute.hellbender.utils.nio.GcsNioIntegrationTest.openPublicFile(GcsNioIntegra,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2514:61,access,access,61,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2514,2,['access'],['access']
Security,"Seems a shame to have every Spark application depend on GCS code, just to have access to HDFS. Maybe we could bust this into two pieces: separate out a spark.utils.HDFSUtils that knows nothing about GCS but can handle ""file:"" and ""hdfs:"" URLs, leaving the original gcs.BucketUtils that handles only ""gcs:"" URLs, and delegates non-gcs URLs to HDFSUtils.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1887:79,access,access,79,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1887,1,['access'],['access']
Security,Serious Security Vulnerabilities in GATK,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8215:8,Secur,Security,8,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8215,1,['Secur'],['Security']
Security,"Several of our HGSV snapshot samples are failing with current master due to an exception in `CpxVariantInterpreter`. For example, sample HG00732 fails with this stacktrace:. ```; 18/04/11 14:30:28 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 2.0 in stage 42.0 (TID 60116, cwhelan-hg00732-cram-samtools-bam-feature-w-5.c.broad-dsde-methods.internal, executor 27): java.lang.IllegalArgumentException: Invalid interval. Contig:chr19 start:33757506 end:33757488; at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:687); at org.broadinstitute.hellbender.utils.SimpleInterval.validatePositions(SimpleInterval.java:61); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:37); at org.broadinstitute.hellbender.tools.spark.sv.discovery.alignment.ContigAlignmentsModifier.computeNewRefSpanAndCigar(ContigAlignmentsModifier.java:159); at org.broadinstitute.hellbender.tools.spark.sv.discovery.alignment.ContigAlignmentsModifier.clipAlignmentInterval(ContigAlignmentsModifier.java:42); at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.CpxVariantInterpreter.removeOverlap(CpxVariantInterpreter.java:179); at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.CpxVariantInterpreter.deOverlapAlignments(CpxVariantInterpreter.java:122); at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.CpxVariantInterpreter.furtherPreprocess(CpxVariantInterpreter.java:79); at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.CpxVariantInterpreter.lambda$inferCpxVariant$bdd686a3$1(CpxVariantInterpreter.java:51); at org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction$1.apply(JavaPairRDD.scala:1040); at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.jav",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4648:517,validat,validateArg,517,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4648,2,['validat'],"['validateArg', 'validatePositions']"
Security,Should be validated to the point where production would be willing to use it.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1640:10,validat,validated,10,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1640,1,['validat'],['validated']
Security,"Similar to how `GATKTool` requires a reference when there's at least one cram input, we need to do the same thing in spark. Right place to do this is probably in `GATKSparkTool.initializeReads()` or `GATKSparkTool.validateToolInputs()`",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1181:214,validat,validateToolInputs,214,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1181,1,['validat'],['validateToolInputs']
Security,"SimpleInterval has a constructor that parses an interval String, but without access to a SequenceDictionary its not possible to correctly interpret intervals with contig names such as those used in hg38. It looks like the only non-test consumer of this method is TableCodec. For example:. - `HLA-A*01:01:01:01` is interpreted as `HLA-A*01:01:01:1-1`, but `HLA-A*01:01:01` doesn't exist; - `HLA-A*01:01:01:02N` its interpreted as position `02N` on contig `HLA-A*01:01:01`, which fails to parse, and the contig doesn't exist. GATK command line intervals resolve these by consulting the sequence dictionary. For hg38 at least, there can be no ambiguity and there is always only one correct interpretation. Its possible to construct a legal sequence dictionary that has ambiguities though.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4597:77,access,access,77,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4597,1,['access'],['access']
Security,"Since GenomicsDB can be used with `CreateSomaticPanelOfNormals`, allow for the GenomicsDBArgumentCollection to be exposed with this tool.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6746:114,expose,exposed,114,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6746,1,['expose'],['exposed']
Security,"Since NIO reportedly now works from Spark clients, this bit of; authentication is unnecessary. Removing it greatly simplifies; BucketUtils, and also stops users having to worry about where; to get the AuthHolder from. This work is part of #2402",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2565:64,authenticat,authentication,64,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2565,1,['authenticat'],['authentication']
Security,"Since https://github.com/broadinstitute/gatk/pull/4711, we use a deletion hook to delete the temp directories created by the R executor, but the R executor also deletes these itself. https://github.com/samtools/htsjdk/pull/1315 seems to have exposed this by propagating the exception from the second attempt. See https://gatkforums.broadinstitute.org/gatk/discussion/comment/46733#Comment_46733.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5893:242,expose,exposed,242,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5893,1,['expose'],['exposed']
Security,"Since it's realigning the bam, it shouldn't validate that the file to be aligned already matches the header. This makes it impossible to realign to a different reference or align a headerless file. . This can currently be worked around using `--disableSequenceDictionaryValidation`",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2121:44,validat,validate,44,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2121,1,['validat'],['validate']
Security,"Since the migration from travis-ci.org to travis-ci.com I've been unable to access our coveralls page. The coverage badge on the repo is broken as well. Others seem to be able to access the https://coveralls.io/r/broadinstitute/hellbender page, but I get an ""Access Denied"". It's still commenting on our posts, but it's not very useful without the actual coverage display. . I know @droazen can still see the page, @akiezun, can you? . I filed an issue with coveralls here: https://github.com/lemurheavy/coveralls-public/issues/497 but haven't heard anything back from them.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/381:76,access,access,76,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/381,3,"['Access', 'access']","['Access', 'access']"
Security,"Since we are already injecting Arguments including FeatureInputs and referenceDictionaries... why we need to pass ReferenceContext or FeatureContext in the apply method? . If a tool requires some features, it could access it directly from the feature-input that is already declaring as a member field (of course, once the query api is provided there)... . What is the Optional<FeatureContext> giving us that could not be perfectly supported by an API-enriched FeatureInput object?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/242:21,inject,injecting,21,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/242,2,"['access', 'inject']","['access', 'injecting']"
Security,"Small PR containing fixes for various issues:; - Move CompareSAMs to picard package (fixes https://github.com/broadinstitute/hellbender/issues/139); - Move most of `CompareSAMs.doWork()` into a separate public method, to be used by external unit tests; - Use HTSJDK's SamFileValidator in assorted unit tests, rather than ValidateSamFile (which is just a CLP wrapper); - Insert `--VERBOSITY ERROR` into CommandLineProgramTest, which suppresses most logging output for CLPs that use HTSJDK-based logging (fixes https://github.com/broadinstitute/hellbender/issues/134)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/171:321,Validat,ValidateSamFile,321,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/171,1,['Validat'],['ValidateSamFile']
Security,"So, I have a question that I believe some discussions are necessary, regarding read filtering. The background that triggered this question is when I tried `PrintReads(Spark)` to filter out reads with `ReadFilterLibrary.GoodCigarReadFilter`. As it turns out, that one of the read (long read) have several alignment records, (unfortunately) the primary (i.e. 256 and 2048 flags not turned on) record is the one having a problematic CIGAR, hence filtered out. The alignment records left are&mdash;as expected&mdash;all records with either `not-primary` or `supplementary` flag turned on. . Should one consider such bam valid for analysis?; And more generally, should the collection of alignments after read filtering be checked with `ValidateBam` (assuming the tool checks for that error) as part of best practices?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6433:731,Validat,ValidateBam,731,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6433,1,['Validat'],['ValidateBam']
Security,"Somatic WDLs have them hidden, gCNV WDLs (in sl_gcnv_ploidy_cli) have them exposed. (EDIT: Actually, gCNV WDLs only have them exposed for gCNV-specific tasks. Common tasks such as PreprocessIntervals are also not exposed.). The former makes for cleaner `wdltool inputs` JSONs that contain only the bare minimum inputs, but it is unclear whether FC will allow for task-level parameters to be set. However, this can still be done via JSON, as long as the task is at the main workflow level (although this may change with a C30 hotfix?). The latter makes for messier JSONs and requires more upkeep to make sure everything stays exposed, but should work in FC (unless the workflow is used as a subworkflow?)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3980:75,expose,exposed,75,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3980,4,['expose'],['exposed']
Security,"Some of the GTF files from ENSEMBL do not follow the format that the current `EnsemblGtfCodec` expects. This will cause Funcotator to fail on those files. A complete description (courtesy of ENSEMBL themselves) of their GTF format is as follows (and it differs from what is expected in the code):. ```; #### README ####. --------; GTF DUMP; --------. This directory includes a summary of the gene annotation information ; and GTF format. Ensembl provides an automatic gene annotation for Aedes aegypti.; For some species ( human, mouse, zebrafish, pig and rat), the; annotation provided through Ensembl also includes manual annotation; from HAVANA.; In the case of human and mouse, the GTF files found here are equivalent; to the GENCODE gene set. GTF provides access to all annotated transcripts which make; up an Ensembl gene set. Annotation is based on alignments of; biological evidence (eg. proteins, cDNAs, RNA-seq) to a genome assembly.; The annotation dumped here is transcribed and translated from the ; genome assembly and is not the original input sequence data that ; we used for alignment. Therefore, the sequences provided by Ensembl ; may differ from the original input sequence data where the genome ; assembly is different to the aligned sequence. . Additionally, we provide a GTF file containing the predicted gene set; as generated by Genscan and other abinitio prediction tools.; This file is identified by the abinitio extension. -----------; FILE NAMES; ------------; The files are consistently named following this pattern:; <species>.<assembly>.<version>.gtf.gz. <species>: The systematic name of the species.; <assembly>: The assembly build name.; <version>: The version of Ensembl from which the data was exported.; gtf : All files in these directories are in GTF format; gz : All files are compacted with GNU Zip for storage efficiency. e.g.; Homo_sapiens.GRCh38.81.gtf.gz. For the predicted gene set, an additional abinitio flag is added to the name file.; <species>.<assem",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6488:761,access,access,761,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6488,1,['access'],['access']
Security,"Some tools have had usage examples ported from GATK3 that don't work in GATK4. We should fix ; these. . As well as fixing errors, it would be good to change the javadoc so it references parameters by the constant values instead of hardcoding them. (use `{@value StandardArgumentDefinitions#SOME_NAME}` ). These occur in at least the following tools, (found by `find in path -T`):; - [ ] ValidateVariants; - [ ] VariantFiltration; - [ ] AnalyzeCovariates; - [ ] BaseRecalibrator; - [ ] LeftAlignIndels",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1632:387,Validat,ValidateVariants,387,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1632,1,['Validat'],['ValidateVariants']
Security,"Some tools need to dynamically resize the reference context window based upon other; input. This commit exposes a setWindow() method to allow tools to do this. -To change the reference context size, tools should invoke setWindow() on the; ReferenceContext provided by the engine before invoking getBases()/getBasesIterator(). -Hopefully eliminates the need for tools to create their own reference readers. -ReferenceContext still caches previous query results, but cache gets invalidated; every time the window size changes. Resolves #131",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/136:104,expose,exposes,104,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/136,1,['expose'],['exposes']
Security,Spark large scale validation: allow tests to be run in push-button fashion using a script or similar,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/695:18,validat,validation,18,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/695,1,['validat'],['validation']
Security,Spark large scale validation: requirements gathering and design,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1167:18,validat,validation,18,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1167,1,['validat'],['validation']
Security,"Spark large scale validation: tools to ingest GATK3 outputs, and prepare them as GATK4 inputs",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1169:18,validat,validation,18,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1169,1,['validat'],['validation']
Security,Spark large scale validation: tools to intelligently compare MarkDuplicates results,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1168:18,validat,validation,18,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1168,1,['validat'],['validation']
Security,"Spark tests in Jenkins are failing nightly. They've been failing since August 29th. This command:. ```; gcloud auth activate-service-account gatktestjenkins@broad-gatk-test.iam.gserviceaccount.com --key-file /scratch/testservice.json --project broad-gatk-test; ./gatk-launch MarkDuplicatesSpark \; --shardedOutput true \; -O /scratch/tmp.md.bam \; --numReducers 0 \; --apiKey $APIKEY \; -I $bamIn \; -- \; --sparkRunner GCS \; --driver-memory 8G \; --cluster $CLUSTERNAME \; --executor-cores 3 \; --executor-memory 25G \; --conf spark.yarn.executor.memoryOverhead=2500""; ```. Fails with:. ```; Exception in thread ""main"" java.lang.NoClassDefFoundError: org/apache/spark/Logging; at java.lang.ClassLoader.defineClass1(Native Method); at java.lang.ClassLoader.defineClass(ClassLoader.java:763); at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142); at java.net.URLClassLoader.defineClass(URLClassLoader.java:467); at java.net.URLClassLoader.access$100(URLClassLoader.java:73); at java.net.URLClassLoader$1.run(URLClassLoader.java:368); at java.net.URLClassLoader$1.run(URLClassLoader.java:362); at java.security.AccessController.doPrivileged(Native Method); at java.net.URLClassLoader.findClass(URLClassLoader.java:361); at java.lang.ClassLoader.loadClass(ClassLoader.java:424); at org.apache.spark.util.ChildFirstURLClassLoader.loadClass(MutableURLClassLoader.scala:52); at java.lang.ClassLoader.loadClass(ClassLoader.java:357); at org.bdgenomics.adam.serialization.ADAMKryoRegistrator.registerClasses(ADAMKryoRegistrator.scala:85); at org.broadinstitute.hellbender.engine.spark.GATKRegistrator.registerClasses(GATKRegistrator.java:74); at org.apache.spark.serializer.KryoSerializer$$anonfun$newKryo$6.apply(KryoSerializer.scala:125); at org.apache.spark.serializer.KryoSerializer$$anonfun$newKryo$6.apply(KryoSerializer.scala:125); at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.sc",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2183:801,secur,security,801,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2183,4,"['Secur', 'access', 'secur']","['SecureClassLoader', 'access', 'security']"
Security,Spark version of ValidateSamFile,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5642:17,Validat,ValidateSamFile,17,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5642,1,['Validat'],['ValidateSamFile']
Security,Spawn of VS-1214 which required the ability to run with a wheel. Hopefully we never need to use this but now we would have the ability if we ever need it. Full integration run [in progress](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/6d67fda8-1237-4cd8-bf49-fe582ae7fc13). Runs requiring PMI ops access exercising this new wheel functionality with a Delta-age 0.2.98 wheel:; - [Delta](https://app.terra.bio/#workspaces/allofus-drc-wgs-dev/GVS%20AoU%20Echo%20RD/job_history/7215bdc8-f951-4b84-b9bf-3aaa80eae0a1); - [Delcho](https://app.terra.bio/#workspaces/allofus-drc-wgs-dev/GVS%20AoU%20Echo%20RD/job_history/a336972e-d9f4-4a74-92fe-6ed94d2b5fff),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8692:324,access,access,324,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8692,1,['access'],['access']
Security,"Spin up a public jenkins server for long-running validation tests (and other tests that can't or shouldn't run in travis), or switch from travis to a more flexible CI provider",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1400:49,validat,validation,49,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1400,1,['validat'],['validation']
Security,"Stacktrace is below. It looks like the default port (8020) is not being picked up.; ```; org.apache.spark.SparkException: Job aborted due to stage failure: Task 8 in stage 5.0 failed 4 times, most recent failure: Lost task 8.3 in stage 5.0 (TID 82, tw-cluster-2-w-4.c.broad-gatk-collab.internal): java.lang.IllegalArgumentEx; ception: Wrong FS: hdfs://tw-cluster-2-m:-1/user/tom/small_spark_eval/dbsnp_138.b37.20.21.vcf, expected: hdfs://tw-cluster-2-m; at org.apache.hadoop.fs.FileSystem.checkPath(FileSystem.java:648); at org.apache.hadoop.hdfs.DistributedFileSystem.getPathName(DistributedFileSystem.java:194); at org.apache.hadoop.hdfs.DistributedFileSystem.access$000(DistributedFileSystem.java:106); at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1305); at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1301); at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81); at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1301); at org.apache.hadoop.fs.FileSystem.exists(FileSystem.java:1426); at hdfs.jsr203.HadoopFileSystem.checkAccess(HadoopFileSystem.java:937); at hdfs.jsr203.HadoopFileSystemProvider.checkAccess(HadoopFileSystemProvider.java:75); at java.nio.file.Files.exists(Files.java:2385); at org.broadinstitute.hellbender.utils.io.IOUtils.assertFileIsReadable(IOUtils.java:551); at org.broadinstitute.hellbender.engine.FeatureDataSource.getFeatureReader(FeatureDataSource.java:292); at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:244); at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:218); at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:202); at org.broadinstitute.hellbender.engine.spark.KnownSitesCache.loadFromFeatureDataSource(KnownSitesCache.java:43); ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3468:662,access,access,662,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3468,1,['access'],['access']
Security,Still got to test my Rc vs 923 add validation branch on the integration test now that it's fixed!,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8592:35,validat,validation,35,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8592,1,['validat'],['validation']
Security,"Submitting workflow; [2020-07-14 05:09:30,55] [info] Unspecified type (Unspecified version) workflow 968be82c-eef3-4bdb-a1ab-3d4e2ca70674 submitted; [2020-07-14 05:09:30,66] [info] SingleWorkflowRunnerActor: Workflow submitted 968be82c-eef3-4bdb-a1ab-3d4e2ca70674; [2020-07-14 05:09:30,67] [info] 1 new workflows fetched by cromid-ca5c695: 968be82c-eef3-4bdb-a1ab-3d4e2ca70674; [2020-07-14 05:09:30,68] [info] WorkflowManagerActor Starting workflow 968be82c-eef3-4bdb-a1ab-3d4e2ca70674; [2020-07-14 05:09:30,69] [info] WorkflowManagerActor Successfully started WorkflowActor-968be82c-eef3-4bdb-a1ab-3d4e2ca70674; [2020-07-14 05:09:30,69] [info] Retrieved 1 workflows from the WorkflowStoreActor; [2020-07-14 05:09:30,72] [info] WorkflowStoreHeartbeatWriteActor configured to flush with batch size 10000 and process rate 2 minutes.; [2020-07-14 05:09:30,83] [info] MaterializeWorkflowDescriptorActor [968be82c]: Parsing workflow as WDL 1.0; [2020-07-14 05:09:31,60] [info] MaterializeWorkflowDescriptorActor [968be82c]: Call-to-Backend assignments: ValidateBamsWf.ValidateBAM -> Local; [2020-07-14 05:09:31,82] [warn] Local [968be82c]: Key/s [memory, disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.; [2020-07-14 05:09:35,38] [info] Not triggering log of token queue status. Effective log interval = None; [2020-07-14 05:09:37,15] [info] WorkflowExecutionActor-968be82c-eef3-4bdb-a1ab-3d4e2ca70674 [968be82c]: Starting ValidateBamsWf.ValidateBAM; [2020-07-14 05:09:37,39] [info] Assigned new job execution tokens to the following groups: 968be82c: 1; [2020-07-14 05:09:41,61] [warn] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: Unrecognized runtime attribute keys: disks, memory; [2020-07-14 05:09:41,71] [info] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: /gatk/gatk \; ValidateSamFile \; --INPUT /cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-Val",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6710:3951,Validat,ValidateBamsWf,3951,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710,1,['Validat'],['ValidateBamsWf']
Security,Subset VDS during validation,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8727:18,validat,validation,18,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8727,1,['validat'],['validation']
Security,"Successful run on the quickstart with the new python validation; https://app.terra.bio/#workspaces/gvs-dev/GVS%20Quickstart%20v3%20cremer/job_history/475e425d-5be5-47a7-a2ed-ebbdcb3746d5. Successful run on the 3k callset with samples sets; https://app.terra.bio/#workspaces/allofus-drc-wgs-dev/NHGRI_AnVIL_3K%20Cremer/job_history/1db17d59-c221-4345-be15-7fed27358d6f. Sample set with 3202 samples; <img width=""435"" alt=""Screen Shot 2023-05-22 at 11 48 11 PM"" src=""https://github.com/broadinstitute/gatk/assets/6863459/de5683e3-b927-4fb3-bb06-ff4adc7b5435"">. <img width=""1078"" alt=""Screen Shot 2023-05-23 at 12 23 05 AM"" src=""https://github.com/broadinstitute/gatk/assets/6863459/976a382a-9953-42e7-a53a-0a7a4d15a9b8"">",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8325:53,validat,validation,53,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8325,1,['validat'],['validation']
Security,Support for GVCF validation with multiple contigs,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6028:17,validat,validation,17,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6028,1,['validat'],['validation']
Security,"Suppose the reference haplotype is; TAAGC. . . . TAAGG. . . . and an alt haplotype (SNV at the last G shown) is; TAAGC. . . TAAG**C**. . . Suppose further that we have a read ending in the first TAAGC that has been hard-clipped (to fit the assembly region) to just a 5-base TAAGC stub. Pair-HMM is fully Bayesian and computes the total likelihood of *all* possible alignments of a read to each haplotype. This gives the alt haplotype a factor of 2 advantage because TAAGC matches it in two locations, so there are two perfectly matching alignments instead of one. In log 10 space this is log_10(2) = 0.301, which is greater than our 0.2 threshold for a likelihood to be considered informative. Therefore, by clipping the read and losing the information of its first 96 bases, we end up considering it informative for the wrong haplotype. This can lead to false positives. It *also* causes false negatives because sometimes a read stub from the normal sample get misaligned to the alt haplotype, triggering the normal artifact filter. It also causes problems in our bamout-based MC3 validation.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5060:1082,validat,validation,1082,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5060,1,['validat'],['validation']
Security,Task.scala:96); 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53); 	at org.apache.spark.scheduler.Task.run(Task.scala:109); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); 18/10/17 19:23:59 ERROR Executor: Exception in task 518.0 in stage 0.0 (TID 518); java.io.FileNotFoundException: /home/data/WGS/F002/F002.sort.bam (Too many open files); 	at java.io.FileInputStream.open0(Native Method); 	at java.io.FileInputStream.open(FileInputStream.java:195); 	at java.io.FileInputStream.<init>(FileInputStream.java:138); 	at org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileInputStream.<init>(RawLocalFileSystem.java:106); 	at org.apache.hadoop.fs.RawLocalFileSystem.open(RawLocalFileSystem.java:202); 	at org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:349); 	at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:769); 	at org.seqdoop.hadoop_bam.util.WrapSeekable.openPath(WrapSeekable.java:60); 	at org.seqdoop.hadoop_bam.BAMRecordReader.initialize(BAMRecordReader.java:147); 	at org.seqdoop.hadoop_bam.BAMInputFormat.createRecordReader(BAMInputFormat.java:222); 	at org.seqdoop.hadoop_bam.AnySAMInputFormat.createRecordReader(AnySAMInputFormat.java:190); 	at org.apache.spark.rdd.NewHadoopRDD$$anon$1.liftedTree1$1(NewHadoopRDD.scala:187); 	at org.apache.spark.rdd.NewHadoopRDD$$anon$1.<init>(NewHadoopRDD.scala:186); 	at org.apache.spark.rdd.NewHadoopRDD.compute(NewHadoopRDD.scala:141); 	at org.apache.spark.rdd.NewHadoopRDD.compute(NewHadoopRDD.scala:70); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoi,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5316:5299,Checksum,ChecksumFileSystem,5299,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5316,1,['Checksum'],['ChecksumFileSystem']
Security,Test to validate that CRAM MD5 slice calculation matches samtools.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3430:8,validat,validate,8,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3430,1,['validat'],['validate']
Security,Test to verify that picard interval lists are handled properly by GATK tools. Validates the fix for https://github.com/broadinstitute/gatk/issues/3555.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3827:78,Validat,Validates,78,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3827,1,['Validat'],['Validates']
Security,Tests that need to access data in a GCS bucket (but not run an actual pipeline); need a PipelineOptions object containing our API key. This new method makes; it for them.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/742:19,access,access,19,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/742,1,['access'],['access']
Security,Tests to prove that we can access and query bams in GCS from ReadWalkers,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2407:27,access,access,27,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2407,1,['access'],['access']
Security,"The CNNPipelineIntegration tests for CNNVariantWriteTensors, CNNVariantTrain and FilterVariantTranches executes tool code, but does no expected results validation.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4537:152,validat,validation,152,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4537,1,['validat'],['validation']
Security,"The PathSeq filter repartitioning the reads directly before the BWA host filtering step to even out the load on each partition. This is helpful for typical samples with low pathogen abundance, when ~90% of the reads are filtered before this step. . However, in some sample types such as stool, saliva, or environmental samples, one can have a large number of reads (i.e. ~10M) at this stage so the cost of the repartition shuffle outweighs the benefit of load balancing for the slow BWA step. . This PR exposes a tool argument to skip the repartitioning.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3405:503,expose,exposes,503,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3405,1,['expose'],['exposes']
Security,"The `MafOutputRenderer` changed how some funcotation fields are accessed. . Need to make VCF output consistent with the code in MAF output, and need to make sure it's consistent to the VCF format. Specifically, `VCFOutputRenderer` should use the funcotation map that is now created internally to go through and render the annotations. Specifically use `Funcotation::getFieldNames` and `Funcotation::getField`.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4583:64,access,accessed,64,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4583,1,['access'],['accessed']
Security,The addition of sequence dictionary validation functionality breaks two tests in ValidateVariantsIntegrationTest. These tests are testBadID and testBadID2_OKif_notInDBSNP.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/659:36,validat,validation,36,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/659,2,"['Validat', 'validat']","['ValidateVariantsIntegrationTest', 'validation']"
Security,"The code that composes the result output folder depends on ```git batch --contains HASH``` to pick up a line with a standard branch name (e.g. ``` joe_doe_bugfix```) . However this is not neceserely the case if the current checkout is not attach to a local branch... for example when one does ```git fetch; git checkout origin/master```. In that case a typical git-batch line that gets picked up is ```* (HEAD detached at origin/master)``` and in this case it will use ""origin/master)"" rather than ""joe_doe_bugfix"" to be part of the result output directory name. The problem is the ""/"" and "")"" which causes problems later at least when running copy_sv_results.sh as they are not escaped appropriately. Obvious ways to address this: ; 1. remove that component of the output name as is not needed to make it quite unique.; 2. change the sub-command to handle that situation. ; 3. or fail early (before spinning the cluster) if the GATK git checkout is detached.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3642:83,HASH,HASH,83,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3642,1,['HASH'],['HASH']
Security,"The current `IsUsingCompressedReferences`; It does not pass project id that hosted dataset. ; When the project_id is missing in a BigQuery SQL query, the bq command will use the --project_id flag specified in the command as the default project for resolving dataset and table references.; Add additional parameter to allow passing dest project. . In our case; Error we saw in GCP console:; ```; Access Denied: Table terra-vpc-sc-dev-7ee328ad:1kg_wgs_2022q1.INFORMATION_SCHEMA.COLUMNS: User does not have permission to query table terra-vpc-sc-dev-7ee328ad:1kg_wgs_2022q1.INFORMATION_SCHEMA.COLUMNS, or perhaps it does not exist.; ```. `terra-vpc-sc-dev-7ee328ad:1kg_wgs_2022q1.INFORMATION_SCHEMA.COLUMNS` is wrong - `terra-vpc-sc-dev-7ee328ad` is the user workspace; It should be `fc-aou-cdr-synth-test-2.1kg_wgs_2022q1` - `fc-aou-cdr-synth-test-2` is the project that contains CDR data.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/9023:395,Access,Access,395,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/9023,1,['Access'],['Access']
Security,"The current hardcoded limit restricts us to 16777215 bins, which we can hit as we go below 200bp bins. For a given matrix that needs to be broken into chunks, increasing the chunk size by decreasing CHUNK_DIVISOR will require more heap space. In practice, it's not too hard to build a PoN per contig to get around this limit at the moment. We might start having issues with doing SVD on the entire matrix anyway when we have this many bins. But it might be good to have the option exposed.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4365:481,expose,exposed,481,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4365,1,['expose'],['exposed']
Security,"The current implementation delegates to Hadoop-BAM SAMHeaderReader.readSAMHeaderFrom, which in turn delegates to htsjdk SAMFileReader (which is deprecated). This is fragile and in a couple of cases is succeeding now only because of some existing htsjdk quirks/bugs:. -It succeeds on ADAM files only because the htsjdk code [falls through](https://github.com/broadinstitute/gatk/issues/1280) to using a SAMTextReader on the ADAM stream, which surprisingly doesn't throw but returns a completely bogus header.; -It succeeds on CRAM files even though no reference is passed because the htsjdk code currently creates a default reference with nothing backing it in that case. Since we're never using this reader to access reads, this works now, but this will throw if we take [this htsjdk PR](https://github.com/samtools/htsjdk/pull/400) which enforces passing a valid reference to CRAMReaders. More generally, I think we need to reconcile the need to have a SAMFileHeader with the desire to have alternate read stores, and decide of delegating to Hadoop-BAM is sufficient here.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1346:710,access,access,710,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1346,1,['access'],['access']
Security,The default jar is taken to be the one bundled with the Docker in the CNV WDLs but is an exposed argument in the M2 WDLs.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4072:89,expose,exposed,89,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4072,1,['expose'],['exposed']
Security,"The fact that `ReadCoordinateComparator` does not exactly match the ordering of htsjdk's `SAMRecordCoordinateComparator` has been the cause of a few bugs. It sorts all unmapped reads after mapped reads, whereas `SAMRecordCoordinateComparator` sorts unmapped reads that are assigned the positions of their mapped mates with their mapped mates. The issue is that the `GATKRead` interface does not allow unmapped reads to have a position. Ie., even if an unmapped `SAMRecord` is assigned the position of its mapped mate, calling `getContig()`/`getStart()` on the unmapped read via the `GATKRead` interface will return `null`/`0`. This was done mainly for consistency reasons and to simplify client code. Perhaps we could add `getAssignedContig()`, `getAssignedStart()`, etc. methods to GATKRead to expose the positions that unmapped reads with mapped mates get assigned for sorting purposes, and use these in `ReadCoordinateComparator`. This should allow us to match `SAMRecordCoordinateComparator` exactly, and then `ReadCoordinateComparator` could be used even when sorting for the purpose of writing a bam.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1911:795,expose,expose,795,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1911,1,['expose'],['expose']
Security,"The idea is that this WDL will run all the checks for each release of the VAT table, one call for each validation. The first validation rule (""Validation Check confirms that data is put into the VAT table after completing without an error."") is included as a model for subsequent calls. - workflow should succeed if it's able to try all tests; - workflow output `validation_results` will contain details of each test result in an array of `{""testName"": ""result details""}`:; Example 1 — [fail](https://job-manager.dsde-prod.broadinstitute.org/jobs/2728b55b-5344-492a-951a-48fd416e9d0d); `{ ""EnsureVatTableHasVariants"": ""FAIL: The VAT table spec-ops-aou.rsa_gvs_quickstart.rsa_scratch has no variants in it."" }`; Example 2 — [pass](https://job-manager.dsde-prod.broadinstitute.org/jobs/83e3bd5a-9144-452e-93d9-9f273055177f); `{ ""EnsureVatTableHasVariants"": ""PASS: The VAT table spec-ops-aou.anvil_100_for_testing.aou_shard_223_vat has 294821 variants in it."" },`; Example 3 — [the test wasn't able to run](https://job-manager.dsde-prod.broadinstitute.org/jobs/7179d111-02aa-4bca-a0a0-f55e10e43791); `{ ""EnsureVatTableHasVariants"": ""Something went wrong. The attempt to count the variants returned: Error in query string: Error processing job 'spec-ops- aou:bqjob_r357c4b6fe6b0c6fb_0000017aac301de7_1': Unrecognized name: vid at [1:24]"" }`. Closes https://github.com/broadinstitute/dsp-spec-ops/issues/364",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7352:103,validat,validation,103,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7352,3,"['Validat', 'validat']","['Validation', 'validation']"
Security,The jenkins spark tests are failing with the following error:. This seems to have been introduced in https://github.com/broadinstitute/gatk/pull/3576. ```; code: 0; message: Error code 404 trying to get security access token from Compute Engine metadata for the default service account. This may be because the virtual machine instance does not have permission scopes specified.; reason: null; location: null; retryable: false; com.google.cloud.storage.StorageException: Error code 404 trying to get security access token from Compute Engine metadata for the default service account. This may be because the virtual machine instance does not have permission scopes specified.; 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.translate(HttpStorageRpc.java:189); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.get(HttpStorageRpc.java:339); 	at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:197); 	at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:194); 	at shaded.cloud_nio.com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:91); 	at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:54); 	at com.google.cloud.storage.StorageImpl.get(StorageImpl.java:194); 	at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.checkAccess(CloudStorageFileSystemProvider.java:614); 	at java.nio.file.Files.exists(Files.java:2385); 	at htsjdk.samtools.util.IOUtil.assertFileIsReadable(IOUtil.java:346); 	at org.broadinstitute.hellbender.engine.ReadsDataSource.<init>(ReadsDataSource.java:206); 	at org.broadinstitute.hellbender.engine.ReadsDataSource.<init>(ReadsDataSource.java:162); 	at org.broadinstitute.hellbender.engine.ReadsDataSource.<init>(ReadsDataSource.java:118); 	at org.broadinstitute.hellbender.engine.ReadsDataSource.<init>(ReadsDataSource.java:87); 	at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSource.getHeader(ReadsSparkSource.java:182); 	at org.broadinstitute.hellbender.engine.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3591:203,secur,security,203,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3591,4,"['access', 'secur']","['access', 'security']"
Security,"The latest code in htsjdk, which includes https://github.com/samtools/htsjdk/pull/1454 (changes the Allele class into an interface, and uses SimpleAllele as the concrete implementation) causes the `VariantAnnotatorEngineUnitTest.testCombineAnnotations` test to fail because the order of the list returned by `ReducibleAnnotationData.getAlleles` is different with that change than it is without it (presumably due to the different hashCode/equals implementations). `AS_RMSMappingQuality.parseRawData` seems to assume that the order of the Alleles in the list returned by ; `ReducibleAnnotationData.getAlleles` exactly matches the order of the raw data in the String returned by `ReducibleAnnotationData.getRawData`, since it uses indexed access to the list, but I don't see anything that states or ensures/enforces this. Changing the Map maintained by `ReducibleAnnotationData` into a LinkedHashMap fixes the issue for this test, but that just changes the order to be input order - the real issue is that the contract around how the order of the list and the order of the raw data is maintained isn't clear. This will need to be addressed before we can upgrade to the next release of htsjdk.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7586:430,hash,hashCode,430,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7586,2,"['access', 'hash']","['access', 'hashCode']"
Security,"The manifest file describes the files produced by the GvsExtractCallset task and is uploaded to GCS once all the shards have finished running. The existence of the manifest.txt file can be used to determine if the extraction is complete or not by just using `gsutil` command and not going through Cromwell/Terra. Here's a snippet of what that looks like. ```; interval_number, vcf_file_location, vcf_file_bytes, vcf_index_location, vcf_index_bytes; 0,gs://fc-secure-765db3ba-3e2d-432e-89eb-9efda7430f93/genomic-extractions/66f225d3-35cf-4ff7-a4ec-3d887a86ea8b/vcfs/interval_0.vcf.gz,879403,gs://fc-secure-765db3ba-3e2d-432e-89eb-9efda7430f93/genomic-extractions/66f225d3-35cf-4ff7-a4ec-3d887a86ea8b/vcfs/interval_0.vcf.gz.tbi,1682; 1,gs://fc-secure-765db3ba-3e2d-432e-89eb-9efda7430f93/genomic-extractions/66f225d3-35cf-4ff7-a4ec-3d887a86ea8b/vcfs/interval_1.vcf.gz,871855,gs://fc-secure-765db3ba-3e2d-432e-89eb-9efda7430f93/genomic-extractions/66f225d3-35cf-4ff7-a4ec-3d887a86ea8b/vcfs/interval_1.vcf.gz.tbi,1670; 2,gs://fc-secure-765db3ba-3e2d-432e-89eb-9efda7430f93/genomic-extractions/66f225d3-35cf-4ff7-a4ec-3d887a86ea8b/vcfs/interval_2.vcf.gz,710617,gs://fc-secure-765db3ba-3e2d-432e-89eb-9efda7430f93/genomic-extractions/66f225d3-35cf-4ff7-a4ec-3d887a86ea8b/vcfs/interval_2.vcf.gz.tbi,1629; 3,gs://fc-secure-765db3ba-3e2d-432e-89eb-9efda7430f93/genomic-extractions/66f225d3-35cf-4ff7-a4ec-3d887a86ea8b/vcfs/interval_3.vcf.gz,715565,gs://fc-secure-765db3ba-3e2d-432e-89eb-9efda7430f93/genomic-extractions/66f225d3-35cf-4ff7-a4ec-3d887a86ea8b/vcfs/interval_3.vcf.gz.tbi,1645; ...; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7457:459,secur,secure-,459,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7457,8,['secur'],['secure-']
Security,The name for the `variantContext` (as accessed by `getSource()`) is never populated properly. It needs to be populated in the codec. This field should be populated when the codec is created in `FeatureDataSource::getCodecForFeatureInput`.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4570:38,access,accessed,38,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4570,1,['access'],['accessed']
Security,The new validation tests for `ReadsPipelineSpark` should be easily runnable in either a push-button fashion or on a set automatic schedule (nightly or weekly) via a jenkins server. Depends on https://github.com/broadinstitute/gatk/issues/1400,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1401:8,validat,validation,8,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1401,1,['validat'],['validation']
Security,The presence of gcloud-java-nio on the classpath prevents other providers being used if the GCS provider ID has not been specified (e.g. by setting `GOOGLE_APPLICATION_CREDENTIALS`). Here's an example test case: https://github.com/broadinstitute/gatk/commit/8b217f82352ceb55d21d7a5236e879818910d9c9. and the stacktrace:. ```; java.util.ServiceConfigurationError: java.nio.file.spi.FileSystemProvider: Provider com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider could not be instantiated; at java.util.ServiceLoader.fail(ServiceLoader.java:232); at java.util.ServiceLoader.access$100(ServiceLoader.java:185); at java.util.ServiceLoader$LazyIterator.nextService(ServiceLoader.java:384); at java.util.ServiceLoader$LazyIterator.next(ServiceLoader.java:404); at java.util.ServiceLoader$1.next(ServiceLoader.java:480); at java.nio.file.spi.FileSystemProvider.loadInstalledProviders(FileSystemProvider.java:119); at java.nio.file.spi.FileSystemProvider.access$000(FileSystemProvider.java:77); at java.nio.file.spi.FileSystemProvider$1.run(FileSystemProvider.java:169); at java.nio.file.spi.FileSystemProvider$1.run(FileSystemProvider.java:166); at java.security.AccessController.doPrivileged(Native Method); at java.nio.file.spi.FileSystemProvider.installedProviders(FileSystemProvider.java:166); at java.nio.file.Paths.get(Paths.java:141); at org.broadinstitute.hellbender.engine.spark.datasources.NioProviderExceptionUnitTest.test(NioProviderExceptionUnitTest.java:12). Caused by:; java.lang.IllegalArgumentException: A project ID is required for this service but could not be determined from the builder or the environment. Please set a project ID using the builder.; at shaded.cloud-nio.com.google.common.base.Preconditions.checkArgument(Preconditions.java:122); at com.google.cloud.ServiceOptions.<init>(ServiceOptions.java:208); at com.google.cloud.HttpServiceOptions.<init>(HttpServiceOptions.java:153); at com.google.cloud.storage.StorageOptions.<init>(StorageOptions.java:69); at c,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2110:589,access,access,589,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2110,2,['access'],['access']
Security,"The pull request addresses two issues:. 1. Improved and more robust parsing of FlowBasedReads. Specifically, the code now determines the minimal reportable quality; 2. New tool AddFlowSNVQuality that allows users to convert the flow-based quality format when every base quality reports probability of an insertion or deletion to a conventional format that gives base qualities (total probability of mismatch and probability of each mismatch in separate tags). . We believe that this tool is going to be important for users of the Ultima Genomics data that care about calling SNVs, especially in somatic setting, so the goal was to make documentation more accessible. . Happy to receive feedback about it",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8697:655,access,accessible,655,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8697,1,['access'],['accessible']
Security,The recently-added sequence dictionary validation in `BaseRecalibratorDataflow` does not work when the reference is stored in a bucket -- we should patch it so that it does.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/683:39,validat,validation,39,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/683,1,['validat'],['validation']
Security,"The result of this bug is that if you produce a BAM with Spark, then produce a different BAM with the same name with the walker-framework, then try to read _that_ bam with Spark, it produces checksum (and other more misleading) errors.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1266:191,checksum,checksum,191,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1266,1,['checksum'],['checksum']
Security,"The table names in GvsAssignId were not quoted with backticks, which is fine **except** if your dataset name starts with a number… which is a total valid identifier, but requires quoting. . Recently we had a customer (AoU) supply a dataset with the name `1kg_wgs` which exposed this problem",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7666:270,expose,exposed,270,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7666,1,['expose'],['exposed']
Security,"The tool-specific WDLs we generate in https://github.com/broadinstitute/gatk-tool-wdls don't have the `localization_optional` parameter turned on for args that support cloud access (ie., arguments of type GATKPath), and so always localize.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7094:174,access,access,174,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7094,1,['access'],['access']
Security,"There are a number of GATK code paths that check to ensure that a reference is provided whenever a CRAM input is provided. Since htsjdk now accepts both embedded reference and reference-less (no reference compression) CRAMs, these checks should be removed once we update htsjdk. The CRAM code will defer accessing the reference until one is actually required, and will fail gracefully in the case where it is not provided.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6541:304,access,accessing,304,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6541,1,['access'],['accessing']
Security,"There are params in Extract Cohort that can be tightened up. Extract Tool has two params that are not used by Extract Features and are _already_ in Extract Cohort. The filter_set_name is used in the BQ filtering tables and looks like we can set it to be completely required for any type of filtering. There are 3 BQ filter tables -- 2 are needed for filtering (no matter what?) and 1 (tranches) is needed for thresholding and sensitivity calculations?. Genotype level filtering is true by default, but this doesn't seem like it should effect things after this cleanup. Though technically it should only be true if a filter_set_name has been specified. I will add another comment in the body of the code, but I would like to add this safety gate explicitly. Disable gnarly doesn't need to be a passed in param---so we'll rip it out for now. SNP and INDEL truth sensitivity and SNP and INDEL Lod scores are cumbersome to have to worry about passing in, but I dont see a better alternative. Should there be additional validation on these (where if they are specified, but no filter_set_name is, then they throw an error?)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7293:1015,validat,validation,1015,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7293,1,['validat'],['validation']
Security,"There are quite a few v2.1 CRAM test files being used in GATK that should probably be regenerated and replaced with v3.0 files. There are also quite a few CRAM test files floating around in both htsjdk and GATK that have external blocks with content ID=0 (not valid per the spec) and some of those blocks have no actual content:. gatk/src/test/resources/large/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.cram; gatk/src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTestCRAM.QT_10.cram; gatk/src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/clippingReadsTestCRAM.cram; gatk/src/test/resources/org/broadinstitute/hellbender/tools/print_reads.sorted.queryname.htsjdk-2.1.0.cram; gatk/src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.10m-10m100.cram; gatk/src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.MultiSite.bqsr.pipeline.cram; gatk/src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.noMD.noBQSR.cram; gatk/src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.MultiSite.reads.pipeline.cram; gatk/src/test/resources/org/broadinstitute/hellbender/tools/validation/single.read.cram; gatk/src/test/resources/org/broadinstitute/hellbender/tools/validation/another.single.read.cram. These have external blocks with ID=0, but the blocks have no actual content:. gatk/src/test/resources/org/broadinstitute/hellbender/engine/cram_with_crai_index.cram (0 bytes); gatk/src/test/resources/org/broadinstitute/hellbender/engine/cram_with_bai_index.cram (0 bytes). We should regenerate and replace with v3.0 CRAM files.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6018:1234,validat,validation,1234,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6018,2,['validat'],['validation']
Security,"There are several cases where ValidateVariants does no actual validation, and issues no warning message. This includes the default case, where the minimal set of required args is provided (these are examples from the doc, which should be updated when this is fixed): . `gatk ValidateVariants -V some.vcf`; `gatk ValidateVariants -V some.vcf -R some.fasta`. Either of these silently results in no validation and no warning message, despite the entire VCF being decoded and traversed, because the default validation type is ""ALL"", which includes validation type ""IDS"". But IDS requires a dbsnp arg, and none was provided, so the code short-circuits out. The default case should probably do whatever validation it can, but at a minimum a warning should be logged. Ironically, if you provide an exclusion on the command line via `--validation-type-to-exclude IDS`, then validation is done. Another no-op case is `--validation-type-to-exclude ALL` (also recommended in the doc), which also should probably be rejected, or at least logged, since it silently does no validation and reports no errors. This tripped up [this user](https://github.com/samtools/htsjdk/issues/1117), and resulted in a downstream BCF issue.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5862:30,Validat,ValidateVariants,30,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5862,12,"['Validat', 'validat']","['ValidateVariants', 'validation', 'validation-type-to-exclude']"
Security,"There are two differences in GATK4 relative to GATK3 that are causing bugs in the read clipping code (see #3466 and #3845):. * `GATKRead` does not allow you to set mapped reads to a negative start position or a null contig, whereas the GATK3 clipping code allowed reads to enter such states. * We return a `ReadUtils.emptyRead()` when we completely clip away a read, as opposed to (eg.,) a read with a negative start position and no bases like we did in GATK3. We should audit all usages of the `ReadClipper` (as well as direct usages of `ReadUtils.emptyRead()` itself) to make sure that all client code can handle the return value of `ReadUtils.emptyRead()`, which returns an unmapped read with no bases. I've already audited the usages in `HaplotypeCaller`.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4204:471,audit,audit,471,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4204,2,['audit'],"['audit', 'audited']"
Security,"There currently is no way to access files in a GCS bucket that is not public. I will need this feature in the near future to analyze sensitive data. . Just discussed this with @lbergelson, and it sounds like this is something that is not a ton of work but has just been on the back-burner for a while.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2394:29,access,access,29,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2394,1,['access'],['access']
Security,There is one test in ValidateSamFileIntegrationTest that is commented out since it depends on a change to htsjdk.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1084:21,Validat,ValidateSamFileIntegrationTest,21,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1084,1,['Validat'],['ValidateSamFileIntegrationTest']
Security,"There is some confusing code in MarkDuplicatesSpark for comparison, some of which will cause inherent differences with picard Mark Duplicates. Some time should be set aside to ensure it is all performing correctly and that the differences are justified during validation.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4707:260,validat,validation,260,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4707,1,['validat'],['validation']
Security,"There may be a general need to allow tools to request additional context around the current locus/interval. This currently is implemented for `ReferenceContext` via `setWindow()`, but could be expanded to the other *Context classes as well. . Note, however, that we should not encourage tools to perform arbitrary queries as a general rule, since it would be difficult or impossible to optimize a traversal in which the access pattern is random. If a tool needs to group disparate data items together (eg., mates on different contigs), there should be an initial grouping step to prepare the required data for the main analysis, instead of random queries within the main analysis.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/245:420,access,access,420,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/245,1,['access'],['access']
Security,There needs to be a validation tool for data sources to ensure that they conform to their formats properly. This tool is envisioned to be run just prior to data source release to fix any silent errors.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4380:20,validat,validation,20,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4380,1,['validat'],['validation']
Security,"There should be a robust mechanism to check whether an index file is up-to-date with respect to the file it indexes (eg., UUIDs, hashes, etc.). Modification time alone is not sufficient, since files can get uploaded out-of-order in cloud environments.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5571:129,hash,hashes,129,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5571,1,['hash'],['hashes']
Security,"There should be an option to inform the user when reads do not pass the WellFormedReadFilter. This could be by logging the number of reads failing this filter or exploding (user-specified). Ideally, it would also report which part of the filter they failed. There are a lot of simple ""gotchas"" that can cause reads to fail, like not adding read groups with sample names. To a lay user, this could be very frustrating. In Spark tools that perform their own additional filtering, it can be impossible to tell even when a substantial subset of the input is silently lost this way (very scary stuff!). A tool to detect reads that are not Wellformed (akin to ValidateSamFile) would be helpful, although not for catching bugs like #3453. @lbergelson suggested creating a WellFormedOrExplodeReadFilter, which would allow tool developers to handle this issue at their discretion. I will work on something like this because PathSeq is especially susceptible to the problem.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3454:654,Validat,ValidateSamFile,654,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3454,1,['Validat'],['ValidateSamFile']
Security,"There's a small set of tools that only outputs their results to stdout, making it difficult to use the output in a pipeline/script. This PR adds a way to output simple results from such tools to an (optional) output file. I Added this option to the following tools:; - CountBases; - CountBasesInReference; - CountReads; - CountVariants; - FlagStat. Other tools that might benefit from this (but it will require an API change, so I didn't do it):; - CompareIntervalLists; - ValidateVariants",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7072:473,Validat,ValidateVariants,473,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7072,1,['Validat'],['ValidateVariants']
Security,There's an issue in `VcfFuncotationFactory.createFuncotationsOnVariant` where certain cites that need multiple functotations merged produce incorrect output. The cause is an accidental conversion of LinkedHashMap -> HashMap which scrambles the iteration order of the map. The order is used when writing the fields so the names of the fields end up on different values.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6173:216,Hash,HashMap,216,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6173,1,['Hash'],['HashMap']
Security,There's some bad input in the BQSR test; update the input validation test to make sure it can find reads that are malformed in that way.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/557:58,validat,validation,58,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/557,1,['validat'],['validation']
Security,"These can almost definitely go:; CalculatePulldownPhasePosteriors; PerformAlleleFractionSegmentation; PerformCopyRatioSegmentation; PerformJointSegmentation; XHMMSegmentCaller; XHMMSegmentGenotyper. @mbabadi will touch base with Monkol, but we think these can go:; TargetCoverageSexGenotyper; GermlineCNVCaller. Not sure about these germline validation tools, let me know:; ConvertGSVariantsToSegments; EvaluateCopyNumberTriStateCalls",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3887:342,validat,validation,342,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3887,1,['validat'],['validation']
Security,This PR Creates and exposes the `is_wgs` parameter in the GvsJointVariantCalling wdl.; It follows the rules defined in the ticket VS-1020 as to how to set `is_wgs` and the `optional interval_list` and `interval_weights_bed` inputs,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8515:20,expose,exposes,20,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8515,1,['expose'],['exposes']
Security,"This PR addresses required changes in order to use latest version of GenomicsDB which exposes new functionality such as:; - [Multi interval import and query support](https://github.com/broadinstitute/gatk/issues/3269):; - We create multiple arrays (directories) in a single workspace - one per interval. So, if you wish to import intervals (""chr1"", [ 1, 100M ]) and (""chr2"", [ 1, 100M ]), you end up with 2 directories/arrays in the workspace with names chr1$1$100M and chr2$1$100M. The array names depend on the partition bounds.; - During the read phase, the user only supplies the workspace. The array names are obtained by scanning the entries in the workspace and reading the right arrays. For example, if you wish to read (""chr2"", [ 50, 50M] ), then only the second array is queried.; - In the previous version of the tool, the array name was a constant - _genomicsdb_array_. The new version will be backward compatible with respect to reads. Hence, if a directory named _genomicsdb_array_ is found in the workspace directory, it's passed as the array for the _GenomicsDBFeatureReader_ otherwise the array names are generated from the directory entry names.; - Parallel import based on chromosome intervals. The number of threads to use can be specified as an integer argument to the [executeImport call](https://github.com/francares/gatk/blob/fmc_GenomicsDB_parallel_import/src/main/java/org/broadinstitute/hellbender/tools/genomicsdb/GenomicsDBImport.java#L535). If no argument is specified, the number of threads is determined by Java's ForkJoinPool (typically equal to the \#cores in the system). ; - The max number of intervals to import in parallel can be controlled by the command line argument --max-num-intervals-to-import-in-parallel (default 1); - Note that increasing parallelism increases the number of FeatureReaders opened to feed data to the importer. So, if you are using _N_ threads and your batch size is _B_, you will have _N*B_ feature readers open.; - Protobuf based API fo",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4645:86,expose,exposes,86,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4645,1,['expose'],['exposes']
Security,"This PR adds segments VCF writing to `PostprocessGermlineCNVCalls`. Segmentation (Viterbi) and segment quality calculation are performed by `gcnvkernel`. This PR introduces the following additional features:; - Calls and model shards are not required to be provided in sorted order anymore; - The user can specify the ref copy-number state for autosomal contigs, as well as allosomal contigs; - For both intervals and segments VCF output: now we use either `<DUP>` or `<DEL>` alleles (in place of `CN_x` alleles), depending on whether the most likely copy-number call is below or above the ; contig baseline. The contig baseline state is whatever the user has specified for autosomal contigs, and the contig ploidy state on sex chromosomes (from the output of `DetermineGermlineContigPloidy`).; - Fail-fast validations and better test coverage; - Updated cohort and case WDL scripts and WDL tests",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4396:807,validat,validations,807,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4396,1,['validat'],['validations']
Security,"This PR does most of the work for VS-565. It exposes the interval list and the sample list to whole way up the nested WDLs to GvsJointVariantCallng.wdl. Two minor things of note:; 1. sample_name_list is a File option and not a File because it's only computed inside of a branch of GvsExtractCallset where control_samples is false. If there is other behavior we want in the condition where it isn't computed, just let me know. This isn't an issue when it's run inside of GvsJointVariantCalling for the beta workflow though, and making it work there was the ultimate purpose of the ticket. 2. This PR does not fully complete the ticket. It will also require changes to the actual beta work space to add the necessary columns to the data table sample_set and change the outputs for the GvsJointVariantCalling workflow to map the new outputs to those columns. I have made these changes and test thems in my copy of the beta workflow, and can make the required changes in the one in gvs-prod once this PR is verified and merged.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8010:45,expose,exposes,45,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8010,1,['expose'],['exposes']
Security,"This PR is an attempt at improving SelectVariants by. - Rewriting unclear code;; - Adding documentation where needed; and; - Adding tests. The initial motivation for this code change (#7497) was to improve performance of SelectVariants by adding an option to do the ""INFO-level filtering"" before doing ""genotype filtering."" Our assumption was that this would improve performance because then we would avoid the expensive genotype ""fully-decode"" operation, which turns string format fields into appropriate object/types (int, array, etc.). This is (we think) done in `VariantContext.fullyDecode().`. This turned out not to be possible for the following reasons. First, there are roughly four types of genotype subsetting you could do:. a) By the sample names (`--sample-name NA12878`); b) JEXL (`--select GQ > 0`); c) JEXL by accessing the variant context object (`--select vc.getGenotype('NA12878').getGQ() > 1`); d) Others (e.g. `--remove-fraction-genotype`). a) does not need ""fully-decode."" It turns out b) was never supported (GATK currently removes all variants and succeed.) And from my experiments, c) does not seem to ever trigger calling `VariantContext.fullyDecode().` In fact the only code path I can see that calls fullyDecode() is by setting the `fully-decode` SelectVariants argument, which seems to just call fullyDecode at the beginning just for the sake of calling it (or so it appears to me. The utility of this command line argument is highly dubious.) . It's possible that apache code does something similar to fully decoding that could affect performance. All that is to say that we cannot achieve performance improvement with our original blueprint simply because this expensive ""fullyDecode"" operation seems to be a mythical operation that is never used in reality. So while I could not speed up SelectVariants, I cleaned up the code and added the following new arguments:. * `--select-genotype`: with this new genotype-specific JEXL argument, we support filtering by genotype f",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8092:825,access,accessing,825,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8092,1,['access'],['accessing']
Security,"This PR only has a subset of the tools, but I wanted put something out there quickly to get comments and make sure I'm on the right track.; - Created tools.picard subpackage.; - Extend CommandLineProgram with PicardCommandLineProgram.; - Ported the following CLPs, with tests and small test files from Picard:; - AddCommentsToBam; - CleanSam; - CreateSequenceDictionary; - FastqToSam; - MergeBamAlignment; - RevertSam; - SamFormatConverter; - SamToFastq; - ValidateSamFile. Some notes:; - doWork() returns null for most CLPs. The exception is ValidateSam; in Picard, it returns a meaningful exit code (0 if input SAM is valid, 1 if not). Various unit tests were relying on this behavior. For now, I preserved it by returning a boolean.; - MergeBamAlignment actually involves a fair amount of logic, a la MarkDuplicates. It combines an aligned BAM with an unmapped BAM. Its helper classes have been placed in utils.sam.mergealignment. More information can be found there.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/124:457,Validat,ValidateSamFile,457,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/124,2,['Validat'],"['ValidateSam', 'ValidateSamFile']"
Security,"This PR primarily fixes a bug in the hashCode method of BreakpointAllele that was causing Spark's groupByKey() method to not group identical inversion events together, resulting in duplicate variant calls in the output VCF. . All changes:; - Fix hashCode of BreakpointAllele to use the ordinal of the InversionType enum, which is consistent across executors; - Added Kryo Serializers to several SV classes; - Made the INSERTED_SEQUENCE_MAPPINGS VCF annotation include the assembly id and contig name for each mapping, which is necessary to read them.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2168:37,hash,hashCode,37,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2168,2,['hash'],['hashCode']
Security,"This addresses issue 569 - the cleanup of format errors in bam and sam files in tests. I will send an archive with a README, validations for the post-modification bams and sams, and diffs for the bams to akiezun.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/809:125,validat,validations,125,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/809,1,['validat'],['validations']
Security,"This adds a new folder for large runtime resources to git-lfs. Unlike the large test resources, which are only accessed via a volume mount when tests are run on the Docker image, the runtime resources need to be accessible to the GATK build during the Docker build process, since they're included in the jar. AFAICT there is no `docker build` equivalent to `docker run -v`. So for now the runtime resources are git pulled into the Docker staging area, and thus onto the Docker image. We need this for @lucidtronix 's CNN branch (and possibly for @TedBrookings) if we're going to load models for resources, but longer term, we need a better solution.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4530:111,access,accessed,111,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4530,2,['access'],"['accessed', 'accessible']"
Security,This authenticates us to dockerhub on travis builds that require docker.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7204:5,authenticat,authenticates,5,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7204,1,['authenticat'],['authenticates']
Security,"This class was created to provided for a need to keep a sorted (by location) set of targets. However there is nothing in it that could not really be applied to any locatable in general. . As a matter of fact now I find myself in a situation in where I need the same functionality for a different subclass of Locatables, TargetCollection (and its implementations) have the functionality I need but using TargetCollection looks ugly due to its name and its methods names. The task is the to rename TargetCollection<T> to LocatableCollection<L> and accordingly replace 'target' in methods names for something else (either locatable or a generic name such 'elements'). . Also I recently noticed the existence of IntervalsSkipList which could be an additional implementation for TargetCollection (or rather the new LocatableCollection). So perhaps as part of this task we could unified the skip-list and the hash based solutions under a single common interface.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1538:903,hash,hash,903,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1538,1,['hash'],['hash']
Security,"This code (building off of Louis' fixes) adds the following:; - AuthHolder, a replacement for the PipelineOptions. It stores the authentication info we need for GCS and supports both API_KEY and client-secrets.json. I adapted a few classes to accept an AuthHolder.; - BaseRecalibratorOptimizedSpark, a port of the ""shard"" approach I first did on the Dataflow side. Note that currently this code only performs reasonably for small inputs if you specify -L on the command line (for large inputs it doesn't matter).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/987:129,authenticat,authentication,129,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/987,1,['authenticat'],['authentication']
Security,"This consists almost entirely of using `Utils.nonNull` and `Utils.validateArg` in code ported from GATK 3. There are less trivial but straightforward simplifications of code in `MathUtils` and `ReadLikelihoods`. @droazen and @lbergelson is one of you willing to review this mind-numbing PR, or suggest a victim? It should be quick.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1979:66,validat,validateArg,66,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1979,1,['validat'],['validateArg']
Security,"This constant controls both the maximum number of retries and the maximum number of reopens the GCS NIO library will perform in the face of transient errors. It's currently hardcoded, but should be exposed as an engine argument.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3315:198,expose,exposed,198,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3315,1,['expose'],['exposed']
Security,This epic is to track work on porting and validating VQSR for alpha-3. Feel free to add related tickets to the epic.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2062:42,validat,validating,42,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2062,1,['validat'],['validating']
Security,"This error does not occur with every VCF but at least with the one enclosed below. It passes vcf-validator with default arguments. . To reproduce: . ```; term1$ spark-shell # start you spark local cluster in another screen; ...; term2$ cd /dsde/working/valentin/bugs/gatk-var-walker-ser; term2$ git checkout 58cb99ec ; term2$ ./gradlew sparkJar; term2$ ./gatk-launch ExampleVariantWalkerSpark -V ./in.vcf.gz -- --sparkRunner SPARK --sparkMaster local. ```. ```; The stacktrace starts with:. 17/03/29 16:44:56 INFO SparkContext: Successfully stopped SparkContext; 16:44:56.000 INFO ExampleVariantWalkerSpark - Shutting down engine; [March 29, 2017 4:44:56 PM EDT] org.broadinstitute.hellbender.tools.examples.ExampleVariantWalkerSpark done. Elapsed time: 0.08 minutes.; Runtime.totalMemory()=576192512; java.lang.IllegalArgumentException: requirement failed: The partition coalescer passed in must be serializable.; 	at scala.Predef$.require(Predef.scala:224); 	at org.apache.spark.rdd.CoalescedRDD.<init>(CoalescedRDD.scala:84); 	at org.apache.spark.rdd.RDD$$anonfun$coalesce$1.apply(RDD.scala:466); 	at org.apache.spark.rdd.RDD$$anonfun$coalesce$1.apply(RDD.scala:445); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); 	at org.apache.spark.rdd.RDD.withScope(RDD.scala:362); 	at org.apache.spark.rdd.RDD.coalesce(RDD.scala:445); 	at org.broadinstitute.hellbender.engine.spark.SparkSharder.coalesce(SparkSharder.java:321); 	at org.broadinstitute.hellbender.engine.spark.SparkSharder.joinOverlapping(SparkSharder.java:189); 	at org.broadinstitute.hellbender.engine.spark.SparkSharder.joinOverlapping(SparkSharder.java:126); 	at org.broadinstitute.hellbender.engine.spark.SparkSharder.shard(SparkSharder.java:99); 	at org.broadinstitute.hellbender.engine.spark.VariantWalkerSpark.getVariants(VariantWalkerSpark.java:129); 	at org.broadinstitute.hellbender.engine.spark.VariantWalkerSpa",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2545:97,validat,validator,97,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2545,1,['validat'],['validator']
Security,"This happens whenever the start position of an interval for which intermediate bands must be created is less than the value `of break-bands-at-multiples-of`. For example, an input reference block record with a `start` position (say 1) that is less than the value of `of break-bands-at-multiples-of` (say 10000) would result in the invalid intermediate band interval:; ```; java.lang.IllegalArgumentException: Invalid interval. Contig:chr21 start:-1 end:-1. 	at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:687); 	at org.broadinstitute.hellbender.utils.SimpleInterval.validatePositions(SimpleInterval.java:61); 	at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:37); 	at org.broadinstitute.hellbender.tools.walkers.CombineGVCFs.createIntermediateVariants(CombineGVCFs.java:191); 	at org.broadinstitute.hellbender.tools.walkers.CombineGVCFs.apply(CombineGVCFs.java:134). ```; This doesn't happen in GATK3.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4672:503,validat,validateArg,503,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4672,2,['validat'],"['validateArg', 'validatePositions']"
Security,"This includes:; * the GQ0 --> no call conversion; * the setting of the max ref block size (already 1000, but need to let the VDS know). Bonus:; a validation script for the VDS itself. <img width=""851"" alt=""valid"" src=""https://user-images.githubusercontent.com/6863459/220472873-184c7c51-7b1b-41e7-abca-55d05293e590.png"">",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8205:146,validat,validation,146,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8205,1,['validat'],['validation']
Security,"This is a prototype of the basic infrastructure that must go in to make the junction tree based Haplotype finding work. I have pulled out a toggle for the HaplotypeCaller that that enables a separate ReadThreadingAssembler codepath for haplotype finding. Right now when this mode is enabled `ExperimentalReadThreadingAssembler` is used in conjunction with `JuncitonTreeKBestHalotypeFinder` to extract only haplotypes that show up in our junction trees with evidence of > 3 reads. This still poses problems with dangling end recovery as definitionally those branches never include complete junction tree data. . I will continue to work on this branch (as it is in a somewhat rough state still) but I would like to at least get some eyes on it before i get too deep in the weeds to at least validate the structural approach I have chosen. . Currently known issues in this branch: ; - Tests are failing due to resolution of non-unique reference sink vertexes, I would solicit help as to how best to resolve the case where junction trees point to both a reference stop allele and a continued path.; - There is at least one very degenerate edge case that might cause the code to hang, I would also ask after what is the best way to close out of looping assembly structures that never have reads to close them (i.e. a ""dangling end"" hom-var that happens to point to a non-unique reference base). ; - Probably after discussion the threshold for discarding junction trees will be changed to instead use paths from the discarded tree first. . Resolves #5925",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6034:789,validat,validate,789,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6034,1,['validat'],['validate']
Security,"This is an implementation of a pileup validation tool. Additionally, some testing utilities for creating reads with variants have been added.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3755:38,validat,validation,38,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3755,1,['validat'],['validation']
Security,"This is meant as a group discussion that could happen several places, and here is as good as any. We know that shipping around the header is has a _huge_ cost. So, we need to find a way to effectively strip it from the `SAMRecord` without breaking it. I propose the following.; - Modify `SAMRecord` to use getter methods for the header; - Create a `HeaderSAMRecord` that extends `SAMRecord` and that has a static field for the header. This class would override `getHeader` to return the static; - Use `Broadcast` with `mapPartitions` to set the static on each worker. An alternative would be audit the field usage and do a combination of performing all necessary calls that require the header to when we load the reads and, if possible, making the still offending methods inaccessible. So, @tomwhite , @akiezun , @droazen , @lbergelson , @jean-philippe-martin , what do you all think?. I know @lbergelson previous expressed he didn't like the usage of statics for this purpose.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/900:592,audit,audit,592,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/900,1,['audit'],['audit']
Security,This is often needed since the docker image is big. Expose this parameter with a 20GB value,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3566:52,Expose,Expose,52,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3566,1,['Expose'],['Expose']
Security,"This is rebased off of https://github.com/broadinstitute/gatk/pull/3716, since it depends on code there. Hence, only the second commit needs to be reviewed in this PR. The code and tests are quite similar to that for PlotSegmentedCopyRatio/PlotACNVResults. However, I've changed the R scripts to be more efficient (WGS plots no longer take several hours). Furthermore, PlotModeledSegments is more flexible than PlotACNVResults in that it plots CR, AF, or both on the fly depending on the available inputs. I've also added some more input validation, changed some terminology, and moved over to data.table for reading TSVs in R.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3729:538,validat,validation,538,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3729,1,['validat'],['validation']
Security,This is required for some validation work we're currently doing.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1089:26,validat,validation,26,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1089,1,['validat'],['validation']
Security,"This is something we got to only in a rather basic way in GATK but is very useful to enable in order to save users from themselves. This would involve three components:. 1) Hard min/max values that correspond to limits beyond which values could cause errors/program failures; violation should throw a User Exception;. 2) Recommended min/max values that correspond to limits beyond which values do not make sense for a given analysis functionality for standard use cases; violation should log a WARN entry. 3) Behavior-disabling value if applicable. Let's say we have an argument that provides a threshold for filtering; and it takes min. 4, max. 20. We may want to set it up so that passing -1 disables the behavior controlled by the argument (so in the filtering case, ""-1"" means ""don't filter at all"") without tripping the min value check. . These should all be accessible to the GATKDoclet (or equivalent) for documentation purposes.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/143:864,access,accessible,864,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/143,1,['access'],['accessible']
Security,This method (validateSequenceDictionaries) in GATKTool needs to be modified so that the vcf file names associated with each sequence dictionary are passed into validateDictionaries() to make error messages more useful.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/660:13,validat,validateSequenceDictionaries,13,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/660,2,['validat'],"['validateDictionaries', 'validateSequenceDictionaries']"
Security,This only works for the conventional gather. adding useConventionalGather argument to force using conventional gather. adding --ignoreSafetyChecks to skip pre-validating the headers. continuing the tradition of having no tests for this tool,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2736:159,validat,validating,159,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2736,1,['validat'],['validating']
Security,"This pr adds the subpopulation AC/AN/AF calculations.; It does this by taking in the ancestry table and making sublists of each---then passing that list of samples into the SelectVariants GATK tool. Updated Lucid chart here: https://lucid.app/lucidchart/fee376a4-4b72-481e-a239-a027f7f6ab1f/edit?page=CsG3hy3S1zEH#. Design Doc for this work:; https://docs.google.com/document/d/1FnPu_Jkz2O9rElApAQld0v6iBEFGe22dKarVWcwNxGI/edit. misc:; how should I add the VAT validation to the VAT pipeline? Should it run automatically?. Anvil data version of this table: spec-ops-aou:anvil_100_for_testing.vat_aug19. <img width=""1379"" alt=""Screen Shot 2021-08-11 at 5 38 22 PM"" src=""https://user-images.githubusercontent.com/6863459/129606564-bfc20a68-119a-4072-88b4-aeaf011cc965.png"">",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7399:461,validat,validation,461,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7399,1,['validat'],['validation']
Security,"This produces a resource that will be used as input to an upcoming tool to filter intervals based on these annotations (as well as coverage statistics). Currently, we have an external python script performing this step in the gCNV pipeline. I also updated the AnnotateIntervals task and calls in WDL, but these changes are untested; the reviewer should check carefully for typos. Currently, all annotations are of double type, but I've added code that can support all types supported by the TSV code as well. Additional tracks can also be added relatively easily. Currently, allowed annotations and their corresponding types are hardcoded; we could possibly move this information to the SAM-style header in the future. For the Umap hg19 k100 single-read mappability track and the segmental-duplication track used by the Talkowski lab, annotation of 1kb bins on hg19 takes less than a minute with the default feature lookahead (which is exposed as a parameter). I tested using the Umap multi-read mappability track (which is orders of magnitude larger, but is actually what is used in the external script), but this is much slower (documentation indicates that the single-read track should be used to dissuade this). We should evaluate whether or not using the single-read track suffices for filtering.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5162:936,expose,exposed,936,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5162,1,['expose'],['exposed']
Security,"This pulls the bulk of the pipeline into a separate subworkflow so that the validations (with the mixture samples) can be run. The mixtures have already been subset and tagged, which is why the rest of the pipeline needed to be extracted.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5708:76,validat,validations,76,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5708,1,['validat'],['validations']
Security,"This replaces a secret that requires a pr to fix, and updates the name of one of the others.; Requires 1 more step after this.; * Switch travis variable name from DOCKER_SERVICE_PASS -> DOCKER_SERVICE_TOKEN for clarity; * Replace gcloud encrypted key",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7521:237,encrypt,encrypted,237,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7521,1,['encrypt'],['encrypted']
Security,"This request comes from the forum: . Mutect2 accepts multiple _different_ tumor samples (from the same individual) and calls on each sample at the same time, much like in a time-course experiment. Relatedly, if it's not too much to ask, I'd like to be able to provide multiple `--germline-resource` VCFs. ---; @Sheila and @shlee,; Thank you so much for referring me to the informative article and discussion!; I can't say I fully understand the technical difficulties. But I understood it is nontrivial to implement and joint somatic variant calling should be different from the joint calling of haplotypecaller. I still think it might be worthwhile for Mutect2 to be able to call somatic variants jointly on multiple tumor samples from **an** individual. It would help track somatic variants of a person over time. By the way, the article mentioned that Mutect2 would run without a matched normal. I wonder if Mutect2 now supports the tumor only mode. I remember no variant passed filters in tumor only mode for an older version. (One the other hand, I now think tumor only calling with high false positives would be a privacy threat..). ![](https://public.media.smithsonianmag.com/legacy_blog/snowflake-growth-2.gif """"); Image credit: [Libbrecht lab](https://smithsonianmag.com/science-nature/the-art-and-science-of-growing-snowflakes-in-a-lab-180949243/). This Issue was generated from your [forums] ; [forums]: https://gatkforums.broadinstitute.org/gatk/discussion/comment/45571#Comment_45571",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4327:1128,threat,threat,1128,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4327,1,['threat'],['threat']
Security,"This request was created from a contribution made by ABours on May 29, 2020 18:23 UTC. Link: https://gatk.broadinstitute.org/hc/en-us/community/posts/360067695771-GenotypeGvcfs-has-formatting-issues-in-both-v4-1-6-0-as-v4-1-7-0. --. Hi,. I'm using v4.1.6.0 of GenotypeGvcfs to make a vcf, out of whole genome data from 19 samples (following your recommendations). When I run ValidateVariants to check the output of GenotypeGvcfs I get a error message, which states that one or more of the ALT allele are actually not in the samples provided. A previous user already found a similar error in ValidateVariants (https://gatk.broadinstitute.org/hc/en-us/community/posts/360061452132-GATK4-RNAseq-short-variant-discovery-SNPs-Indels-), but then for Haplotypecaller, and you have opened a bugreport to add a feature to ValidateVariants: https://github.com/broadinstitute/gatk/issues/6553. However, it would be nice if you could actually investigate the formatting error. Unfortunately my formatting error isn't the same as reported in the other post. I have 105 error in which the 1st alternative allele is a spanning deletion and the 2nd (and 3rd) is either an indel or snp. It's true that the 2nd and 3rd allele is actually not found in my samples. I even have 7 occurances in which the 1st allele (spanning deletion) has allele frequency 1.00. my code is the following for GenotypeGVCFs:. java -Xms32G -Xmx32G -jar ${gatk4} GenotypeGVCFs -R ${ref} -V ${pipeline}/${name}\_v4.1.6.0.g.vcf.gz -O ${vcf}/${name}\_v4.1.6.0.vcf.gz -L ${pipeline}/${name}\_intervals.list 2> ${log}/${name}\_v4.1.6.0\_genotype.log. for ValidateVariants:. java -Xms10G -Xmx10G -jar ${gatk4} ValidateVariants -R ${ref} -V ${name}\_v4.1.6.0.vcf.gz -L ${pipeline}/${name}\_intervals.list --warn-on-errors 2> ${log}/${name}\_v4.1.6.0\_genotype\_valivar.log. the warning in ValidateVariants and the site look like this:. 14:12:15.126 WARN ValidateVariants - \*\*\*\*\* Input 1st\_v4.1.6.0.vcf.gz fails strict validation of type ALL: on",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6630:375,Validat,ValidateVariants,375,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6630,3,['Validat'],['ValidateVariants']
Security,"This request was created from a contribution made by Francesco Mazzarotto on March 23, 2022 14:16 UTC. Link: [https://gatk.broadinstitute.org/hc/en-us/community/posts/4892502642075-FilterMutectCalls-haplotype-filter-value-assigned-to-variants-with-different-PGT-tag](https://gatk.broadinstitute.org/hc/en-us/community/posts/4892502642075-FilterMutectCalls-haplotype-filter-value-assigned-to-variants-with-different-PGT-tag). \--. Hello,. I am using GATK v4.2.5.0 to process tumor-only samples sequenced with WES. In a sample, one variant that has been detected with Sanger sequencing (chr14-45137087-C-T) gets filtered out as non-PASS (also) because of the 'haplotype' filter value. As far as the 'haplotype' filter value is concerned, the 'guilty' variant seems to be another SNP 3bp upstream (chr14-45137084-C-T). There are no other variants called within 100bp of the Sanger-validated one (see below). chr14    45136964    .    C    T    .    haplotype;weak\_evidence    AS\_FilterStatus=weak\_evidence;AS\_SB\_TABLE=3,0|1,0;DP=4;ECNT=2;GERMQ=25;MBQ=41,37;MFRL=360,390;MMQ=60,60;MPOS=69;POPAF=7.30;ROQ=17;TLOD=3.20    GT:AD:AF:DP:F1R2:F2R1:PGT:PID:PS:SB    0|1:3,1:0.333:4:1,0:1,1:0|1:45136962\_C\_T:45136962:3,0,1,0 ; ; chr14    45137084    .    C    T    .    germline;haplotype;panel\_of\_normals    AS\_FilterStatus=SITE;AS\_SB\_TABLE=9,1|12,5;DP=27;ECNT=2;GERMQ=1;MBQ=41,41;MFRL=297,326;MMQ=60,60;MPOS=45;PON;POPAF=0.830;ROQ=90;TLOD=59.93    GT:AD:AF:DP:F1R2:F2R1:PGT:PID:PS:SB    0|1:10,17:0.615:27:4,13:4,4:0|1:45137084\_C\_T:45137084:9,1,12,5 ; ; chr14    45137087    .    C    T    .    germline;haplotype    AS\_FilterStatus=SITE;AS\_SB\_TABLE=12,5|9,1;DP=27;ECNT=2;GERMQ=1;MBQ=41,41;MFRL=326,297;MMQ=60,60;MPOS=44;POPAF=2.33;ROQ=93;TLOD=31.76    GT:AD:AF:DP:F1R2:F2R1:PGT:PID:PS:SB    1|0:17,10:0.385:27:13,4:4,6:1|0:45137084\_C\_T:45137084:12,5,9,1 ; ; chr14    45149295    .    AC    A    .    haplotype;weak\_evidence    AS\_FilterStatus=weak\_evidence;AS\_SB\_TABLE=0,0|0,0;DP=1;ECNT",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7809:878,validat,validated,878,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7809,1,['validat'],['validated']
Security,"This request was created from a contribution made by Joyce Anon on April 25, 2022 06:30 UTC. Link: [https://gatk.broadinstitute.org/hc/en-us/community/posts/5573282748699-Error-ShouldNeverReachHereException-FuncotationMap-in-FilterFuncotations](https://gatk.broadinstitute.org/hc/en-us/community/posts/5573282748699-Error-ShouldNeverReachHereException-FuncotationMap-in-FilterFuncotations). \--. FilterFuncotations stops with an error. The input file with the reference genome seems to pass ValidateVariants (no errors). It looks like ""FuncotationMap"" doesn't have enough values to go with the keys. I started with a .vcf file downloaded from Nebula Genomics, and sequentially used CNNScoreVariants, FilterVariantTranches (CNN\_1D), and Funcotator, with default settings. I am trying to find the most pathogenic variants. I considered using FilterVcf to remove synonymous and intron variants, but it doesn't look like it can do that. So then I tried FilterFuncotations, but it returns an error. What I want is some way to sort the variants by severity, to find the most pathogenic ones, but I don't know how to do that. GATK version: 4.2.6.1 ; ; Java runtime: OpenJDK 64-Bit Server VM v11.0.14.1+1-Ubuntu-0ubuntu1.20.04. Excerpt: ; ; \[April 25, 2022 at 2:00:35 AM EDT\] org.broadinstitute.hellbender.tools.funcotator.FilterFuncotations done. Elapsed time: 0.03 minutes. ; ; Runtime.totalMemory()=319815680 ; ; org.broadinstitute.hellbender.exceptions.GATKException$ShouldNeverReachHereException: Cannot parse the funcotation attribute.  Num values: 31   Num keys: 53. Copied from the terminal: ; ; (gatk) aru@BioinformaticsVM:/mnt/sdb/gatk$ ./gatk FilterFuncotations --allele-frequency-data-source gnomad -O ./output/nebulaFilterFuncotations.vcf --ref-version hg38 -V ./output/nebulaFuncotatorAnnotated.vcf --java-options '-DGATK\_STACKTRACE\_ON\_USER\_EXCEPTION=true' ; ; Using GATK jar /mnt/sdb/gatk/gatk-package-4.2.6.1-local.jar ; ; Running: ; ;     java -Dsamjdk.use\_async\_io\_read\_samtools=f",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7865:491,Validat,ValidateVariants,491,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7865,1,['Validat'],['ValidateVariants']
Security,This retains the commit hash and commit number delta part in the version.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4118:24,hash,hash,24,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4118,1,['hash'],['hash']
Security,"This set of optimizations brings the GATK4 HaplotypeCaller performance into line; with GATK3.x performance. Note that HaplotypeCallerSpark is not touched by this PR (that is for a future PR). Summary of changes:. * AssemblyRegionWalker: query all intervals on each contig simultaneously, rather than individually; * GATKRead: Cache adaptor boundary, soft start/end, and cigar length; * GATKRead: add getBasesNoCopy() / getBaseQualitiesNoCopy(); * ReadPileup: speed up stratified constructor; * LIBS.lazyLoadNextAlignmentContext(): don't keep pileup elements unnecessarily separated by sample during pileup creation; * Restore faster GATK3 version of ReferenceConfidenceModel.sumMismatchingQualities(); * RefVsAnyResult: nest within ReferenceConfidenceModel, and allow direct field access; * Remove redundant getBases() call in ReadThreadingGraph; * Fix BaseGraph Utils.validateArg() call; * ReadPileup: replace Collections.unmodifiableList(pileupElements).iterator() with direct return of an iterator that forbids removal; * Kill expensive bounds checking in GATKRead getBase()/getBaseQuality()/getCigarElement(); * Kill nonNull checks in PileupElement; * Kill expensive PileupElement and ReadPileup arg validation; * GATKRead adapter: clear cached values upon mutation",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4031:781,access,access,781,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4031,3,"['access', 'validat']","['access', 'validateArg', 'validation']"
Security,This should http access more seem less in a lot of places. . The way this handles query parameters is not ideal for signed url cases so we'll need to revisit that.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8626:17,access,access,17,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8626,1,['access'],['access']
Security,"This should resolve our git-lfs quota issues, since the quotas; for unauthenticated requests are much stingier than those for; authenticated requests.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3179:127,authenticat,authenticated,127,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3179,1,['authenticat'],['authenticated']
Security,This simplifies the code and didn't affect specificity in our validations. @takutosato can you review this?,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3243:62,validat,validations,62,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3243,1,['validat'],['validations']
Security,This test exposed a bug in Spark Dataflow which is being fixed by https://github.com/cloudera/spark-dataflow/pull/57,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/599:10,expose,exposed,10,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/599,1,['expose'],['exposed']
Security,"This test input is malformed. When I try to read it with the Dataflow code, I get this error:. htsjdk.samtools.SAMFormatException: SAM validation error: ERROR: Record 129, Read name 809R9ABXX101220:5:6:17918:145992, Mate Alignment start should be 0 because reference name = *. Here's the corresponding read:. 809R9ABXX101220:5:6:17918:145992 97 17 69400 37 67M9S \* 71202348 0 ACTCCCCACCTTACCTGACTCCTTCCAGGGTTTGTCGCCTTTCCGGTCCCTGACCCCAGTGGATGGGAGTCTGTCC ?ABDDEEABEECBDBDAB=DEDCDEEBFADABCEAD?EEEDCFE?ABEEE@FCDEEEBF@F?C<E@########## MD:Z:67 PG:Z:BWA RG:Z:809R9.5 AM:i:0 NM:i:0 SM:i:37 MQ:i:0 OQ:Z:DGEGGGGBFGGGGGDF8@@FGFBGGGBGCECCEEDFGGGFGFGGGBDGGF9DBFFGFBF;@>A4@@########## UQ:i:0. @droazen confirms that Picard's ValidateSAMFile utility reports that this bam has multiple errors. We should replace it with a clean input, and update the ""known good"" output accordingly.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/568:135,validat,validation,135,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/568,2,"['Validat', 'validat']","['ValidateSAMFile', 'validation']"
Security,"This tool creates a data file containing a map from reference accessions to NCBI taxonomic IDs, and the taxonomic tree, which includes parent/child relationships as well as other metadata like the reference length and scientific name of each node. . The input files are available from the NCBI FTP server. One is a ""catalog"" file that gives the mapping from reference contig accession to taxonomic ID. There are catalog files available for RefSeq and for Genbank - the tool can take in either. . There are two other files - a ""names"" and ""nodes"" file contained in a single tarball - that contain the scientific names of each node and parent/child relationships. For convenience, the tool takes in the path to the tarball and extracts the two files automatically. The resulting database size is minimized using the given reference. Once the full NCBI taxonomy tree is built, any organism node that is neither in the reference nor an ancestor of a reference organism is removed. The resulting datafile is read in by the ClassifyReads tool (coming in a future PR) to assign relative abundance scores to each taxonomic node. Also made some changed to the way the PSTree and PSTreeNode are serialized (using Kryo read/writeObject instead of read/writeClassAndObject) so that loading old files won't break if these classes change packages.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2730:62,access,accessions,62,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2730,2,['access'],"['accession', 'accessions']"
Security,"This user is receiving an empty output file when running GenomicsDBImport. The user ran ValidateVariants on the input files which was successful. . This request was created from a contribution made by Enrico Cocchi on July 14, 2021 10:31 UTC. Link: [https://gatk.broadinstitute.org/hc/en-us/community/posts/4403568031515-Mutect2-PoN-GenomicsDBImport-creates-empty-DB](https://gatk.broadinstitute.org/hc/en-us/community/posts/4403568031515-Mutect2-PoN-GenomicsDBImport-creates-empty-DB). \--. I am trying to follow GATK 4.2.0 best-practice guidelines for  \[Mutect2 PoN creation\](/hc/en-us/articles/360035531132--How-to-Call-somatic-mutations-using-GATK4-Mutect2). I called variants in my samples as recommended with:. gatk Mutect2 \\ ; ; \-R ${REF} \\ ; ; \-L ${EXOME\_INPUT\_INTERVALS} \\ ; ; \-I ${BAM} \\ ; ; \--sequence-dictionary ${DICT} \\ ; ; \--max-mnp-distance 0 \\ ; ; \-O ${SAMPLE\_NAME}.mutect2.vcf. but I see that the tool is unable to create a proper  `GenomicsDB`  through the  \[GenomicsDBImport\](/hc/en-us/articles/360057439331-GenomicsDBImport) command. Even focusing the analysis on a little interval in which I know I have variants in the Mutect2 generated VCFs, here the  `SelectVariants`  output from one of the VCF I'll use in the  `GenomicsDBImport`  command:. #CHROM POS ID REF ALT QUAL FILTER INFO FORMAT XXX ; ; 1 883625 . A G . . AS\_SB\_TABLE=0,0|12,41;DP=54;ECNT=1;MBQ=0,33;MFRL=0,260;MMQ=60,60;MPOS=31;POPAF=7.30;TLOD=182.40 GT:AD:AF:DP:F1R2:F2R1:SB 0/1:0,53:0.981:53:0,26:0,26:0,0,12,41. \`\`. and here the command to generate the DB:. gatk \ ; . \--java-options ""-Djava.io.tmpdir=/nfs/projects/CNV\_WGS/CHIP-PON-DB/TMP-DIR"" \\ ; ; GenomicsDBImport \\ ; ; \-R $REF \\ ; ; \-L 1:883600-883650 \\ ; ; \--genomicsdb-workspace-path $OUT \\ ; ; \--tmp-dir /nfs/projects/CNV\_WGS/CHIP-PON-DB/TMP-DIR \\ ; ; \-V /nfs/projects/CNV\_WGS/Mutetc2-PON-OUT/Roche-M/fetal0003D.Roche-M.mutect2.vcf -V /nfs/projects/CNV\_WGS/Mutetc2-PON-OUT/Roche-M/fetal0020D.Roche-M.mutect2.vcf -V ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7362:88,Validat,ValidateVariants,88,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7362,1,['Validat'],['ValidateVariants']
Security,"This user received an ArrayIndexOutofBoundsException error when running GenotypeGVCFs. The user confirmed that the headers of their vcf files and the their fasta files have matching IDs and contig lengths. The user also tried running ValidateVariants and received the following error: A USER ERROR has occurred: Input MA1.g.vcf fails strict validation of type ALL: one or more of the ALT allele(s) for the record at position 1A:3456221 are not observed at all in the sample genotypes. This request was created from a contribution made by Alon Ziv on July 07, 2021 12:21 UTC. . Link: [https://gatk.broadinstitute.org/hc/en-us/community/posts/4403256366107--java-lang-ArrayIndexOutOfBoundsException-32772-while-running-GenotypeGVCFs](https://gatk.broadinstitute.org/hc/en-us/community/posts/4403256366107--java-lang-ArrayIndexOutOfBoundsException-32772-while-running-GenotypeGVCFs). \--. i don't get an error but the massge  java.lang.ArrayIndexOutOfBoundsException: 32772 ; ; i use : GATK version used: 4.2.0 ; ; b) Exact command used  this line for Geomics DBImport. gatk GenomicsDBImport -V MA1.g.vcf -V MA2.g.vcf -V MA3.g.vcf -V MH1.g.vcf -V MH2.g.vcf -V MH3.g.vcf -V F4\_1.g.vcf -V F4\_2.g.vcf -V F4\_3.g.vcf --genomicsdb-workspace-path my\_database1AB -L 1A -L 1B -L 2A -L 2B -L 3A -L 3B -L 4A -L 4B -L 5A -L 5B -L 6A -L 6B -L 7A -L 7B. and this for GenotypeGVCFs. gatk --java-options ""-Xmx12g -Xms12g"" GenotypeGVCFs -R Triticum\_dicoccoides.WEWSeq\_v.1.0.dna.toplevel.fa -V gendb://my\_database -O output.vcf.gz --new-qual --tmp-dir temp/. c) Entire error log:. Using GATK jar /home/alonzi/miniconda3/envs/rna-seq/share/gatk4-4.2.0.0-1/gatk-package-4.2.0.0-local.jar ; ; Running: ; ; java -Dsamjdk.use\_async\_io\_read\_samtools=false -Dsamjdk.use\_async\_io\_write\_samtools=true -Dsamjdk.use\_async\_io\_write\_tribble=false -Dsamjdk.compression\_level=2 -Xmx12g -Xms12g -jar /home/alonzi/miniconda3/envs/rna-seq/share/gatk4-4.2.0.0-1/gatk-package-4.2.0.0-local.jar GenotypeGVCFs -R Triticum\_d",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7348:234,Validat,ValidateVariants,234,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7348,2,"['Validat', 'validat']","['ValidateVariants', 'validation']"
Security,"This was unearthed by #7542 and is plumbed correctly in this PR. Note that we need to still address the broader issue of hooking arguments to GenomicsDB - #6456 . GenomicsDB exposes a whole set of export arguments all added in response of gatk requests, some of them are hardcoded by certain tools(e.g GenotypeGVCFs uses --max-alternate-alleles while SelectVariants does not), many are unused.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7576:174,expose,exposes,174,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7576,1,['expose'],['exposes']
Security,Trace:. ...; 11:54:40.426 [ERROR] [system.err] [bwt_restore_sa] SA-BWT inconsistency: seq_len is not the same. Abort!; ... 11:54:40.433 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] org.gradle.api.tasks.TaskExecutionException: Execution failed for task ':test'.; 11:54:40.433 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.executeActions(ExecuteActionsTaskExecuter.java:98); 11:54:40.433 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.execute(ExecuteActionsTaskExecuter.java:68); 11:54:40.433 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.SkipUpToDateTaskExecuter.execute(SkipUpToDateTaskExecuter.java:62); 11:54:40.433 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.ValidatingTaskExecuter.execute(ValidatingTaskExecuter.java:58); 11:54:40.433 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.SkipEmptySourceFilesTaskExecuter.execute(SkipEmptySourceFilesTaskExecuter.java:88); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.ResolveTaskArtifactStateTaskExecuter.execute(ResolveTaskArtifactStateTaskExecuter.java:46); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.SkipTaskWithNoActionsExecuter.execute(SkipTaskWithNoActionsExecuter.java:51); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.SkipOnlyIfTaskExecuter.execute(SkipOnlyIfTaskExecuter.java:54); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.ExecuteAtMostOnceTas,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2802:1149,Validat,ValidatingTaskExecuter,1149,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2802,1,['Validat'],['ValidatingTaskExecuter']
Security,"Travis is terminating our cron job because there is too much log output. ; It seems to be thousands of repetitions of:. ```; 21:44:23.077 WARN DefaultDocWorkUnitHandler - Could not access the field definition for backtrace while searching for SHOW_HIDDEN, presumably because the field is inaccessible; ```. Possibly related to our recent inclusion of picard in our doc output?. See: https://travis-ci.org/broadinstitute/gatk/jobs/289240692",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3710:181,access,access,181,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3710,1,['access'],['access']
Security,"Two .vcf.idx files used by the haplotype caller integration test had; file name lengths > 144. This is incompatible with ecryptfs, which is; commonly used for encrypted home directories on linux. Renaming the; .vcf and .vcf.idx files and updating references to them fixed the; problem. Fixes #4718.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4736:159,encrypt,encrypted,159,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4736,1,['encrypt'],['encrypted']
Security,"UMINA.library.000000000-BCFDC.1.1.sorted.bam --MODE SUMMARY --MAX_OUTPUT 100 --IGNORE_WARNINGS false --VALIDATE_INDEX true --INDEX_VALIDATION_STRINGENCY EXHAUSTIVE --IS_BISULFITE_SEQUENCED false --MAX_OPEN_TEMP_FILES 8000 --SKIP_MATE_VALIDATION false --VERBOSITY INFO --QUIET false --VALIDATION_STRINGENCY STRICT --COMPRESSION_LEVEL 2 --MAX_RECORDS_IN_RAM 500000 --CREATE_INDEX false --CREATE_MD5_FILE false --GA4GH_CLIENT_SECRETS client_secrets.json --help false --version false --showHidden false --USE_JDK_DEFLATER false --USE_JDK_INFLATER false; [Thu Mar 07 16:08:24 UTC 2019] Executing as mpmachado@lx-bioinfo02 on Linux 2.6.32-696.23.1.el6.x86_64 amd64; OpenJDK 64-Bit Server VM 1.8.0_191-8u191-b12-0ubuntu0.16.04.1-b12; Deflater: Intel; Inflater: Intel; Provider GCS is available; Picard version: Version:4.1.0.0; WARNING 2019-03-07 16:08:24 ValidateSamFile NM validation cannot be performed without the reference. All other validations will still occur.; INFO 2019-03-07 16:10:25 SamFileValidator Validated Read 10,000,000 records. Elapsed time: 00:02:00s. Time for last 10,000,000: 120s. Last read position: chr9:32,633,613; INFO 2019-03-07 16:12:22 SamFileValidator Validated Read 20,000,000 records. Elapsed time: 00:03:58s. Time for last 10,000,000: 117s. Last read position: chrM:11,340; No errors found; [Thu Mar 07 16:13:05 UTC 2019] picard.sam.ValidateSamFile done. Elapsed time: 4.79 minutes.; Runtime.totalMemory()=2602041344; Tool returned:; 0; ```. But when run BaseRecalibrator got the _fromIndex toIndex_ error:; `gatk BaseRecalibrator --input sorted.bam --output sorted.baserecalibrator_report.txt --reference GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.bowtie_index.fasta --use-original-qualities true --known-sites snp151common_tablebrowser.bed.bgz --known-sites snp151flagged_tablebrowser.bed.bgz`; ```; ERROR: return code 3; STDERR:; 15:46:35.795 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/gatk/gatk-package-4.1.0.0-local.jar!/com/intel/gkl",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5807:1907,Validat,Validated,1907,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5807,1,['Validat'],['Validated']
Security,Undisabling/fixing tests for ValidateVariants,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/832:29,Validat,ValidateVariants,29,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/832,1,['Validat'],['ValidateVariants']
Security,Unexpected behavior for --validation-type-to-exclude argument in ValidateVariants.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4642:26,validat,validation-type-to-exclude,26,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4642,2,"['Validat', 'validat']","['ValidateVariants', 'validation-type-to-exclude']"
Security,"Unfortunately, projects like TCGA with BAMs from different sequencing centers do not use the exact same sequence dictionary across them. I've relaxed validation in cases where dictionaries are checked across different BAMs so that only a warning is thrown; however, cases where dictionaries should arise from the same BAM still throw an exception.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4758:150,validat,validation,150,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4758,1,['validat'],['validation']
Security,"Unit tests for tool X should not rely on the behavior of instanceMain or doWork in tool Y. . In particular, unit tests that involve comparing/validating outputs should not reference CLPs like CompareSAMs or ValidateSamFile directly. Instead, these CLPs should just be thin wrappers around other classes that have the actual logic. This is already the case for ValidateSamFile, which is just a wrapper for SamFileValidator in HTSJDK. CompareSAMs should be refactored to match this.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/145:142,validat,validating,142,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/145,3,"['Validat', 'validat']","['ValidateSamFile', 'validating']"
Security,"Unlike the other validation rules, this does not test the validity of the VAT, but whether the pipeline completed as we expected it to--so I have added this as the singular test that runs during the pipeline. Validation Rule 2: The number of passing variants in GVS matches the number of variants in the VAT. Please note that we are counting the number of variants in GVS, not the number of sites, which may add a difficulty to this task. Another way to phrase it: ""If I were to make a sites only VCF of GVS and split each passing variant into it's own line, that number should equal the number of unique VIDs in the VAT."". Measure number of unique variants in sites only VCF that is generated. We don't want to count filtered variants so we can't count the GVS table. NOTE:. this pr also has some general cleanup as per discussion with Andrea. ; where would y'all suggest I put the template file for the custom annotations?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7374:17,validat,validation,17,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7374,2,"['Validat', 'validat']","['Validation', 'validation']"
Security,Update GATK dependencies to patch security vulnerabilities,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8352:34,secur,security,34,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8352,1,['secur'],['security']
Security,Update SV split-read strand validation and clustering,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8378:28,validat,validation,28,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8378,1,['validat'],['validation']
Security,Update ValidateSamFileIntegrationTest once htsjdk #369 CRAM bug fix is available,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1138:7,Validat,ValidateSamFileIntegrationTest,7,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1138,1,['Validat'],['ValidateSamFileIntegrationTest']
Security,"Update dependencies to address security vulnerabilities, and add a security scanner to build.gradle",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8607:31,secur,security,31,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8607,2,['secur'],['security']
Security,"Updates (EchoCallset Version):. Changes to scatter width of VCFs generated has changed the amount of data generated in tests, so need to update truth; Adding a new field to extracted VCF Header EXCESS_ALLLELES and that will break the tests.; And why not validate our VCFs for jollies.; Updates 'truth' path for data to match these changes. Integration tests failed due to different number of output VCFs now. So I cherry-picked Miguel's commit on ah_var_store that changed the scatter.; Integration tests *still* [failing](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/8f7b0cc9-4a31-404b-99b3-89e182707e8b) due to the change in VCF Header:. > 6,7d5; < ##FILTER=<ID=high_CALIBRATION_SENSITIVITY_INDEL,Description=""Site failed INDEL model calibration sensitivity cutoff (0.99)"">; < ##FILTER=<ID=high_CALIBRATION_SENSITIVITY_SNP,Description=""Site failed SNP model calibration sensitivity cutoff (0.997)"">; 9c7; < ##FORMAT=<ID=FT,Number=1,Type=String,Description=""Genotype Filter Field"">; ---; > ##FORMAT=<ID=FT,Number=1,Type=String,Description=""Sample Genotype Filter Field"">; 3388a3387,3388; > ##high_CALIBRATION_SENSITIVITY_INDEL=Sample Genotype FT filter value indicating that the genotyped allele failed INDEL model calibration sensitivity cutoff (0.99); > ##high_CALIBRATION_SENSITIVITY_SNP=Sample Genotype FT filter value indicating that the genotyped allele failed SNP model calibration sensitivity cutoff (0.997)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8848:254,validat,validate,254,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8848,1,['validat'],['validate']
Security,"Updates:; - Changes to scatter width of VCFs generated has changed the amount of data generated in tests, so need to update truth; - Adding a new field to extracted VCF Header `EXCESS_ALLLELES` and that will break the tests.; - And why not validate our VCFs for jollies.; - Updates 'truth' path for data to match these changes. Integration Tests:; Passing test against Chr20/X/Y [Here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/985fbc06-36ed-4006-9703-0b86577f704c); Passing test against All Chromosomes [Here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/9d473c81-4742-4188-bc70-1e9371bfcc11)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8846:240,validat,validate,240,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8846,1,['validat'],['validate']
Security,"Upgrading htsjdk to 2.21.0. . This includes a change that relaxes restrictions on loading vcfs with sequence dictionaries that are missing lengths. This effected one of the tests which I changed a bit. We could also implement blanket ban on sequence dictionaries with missing lengths in our sequence dictionary validation code, but we currently allow them for sam/bam as far as I can tell and have tests that take them into account.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6250:311,validat,validation,311,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6250,1,['validat'],['validation']
Security,Use more secure HTTPS URL in GitHub description,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3211:9,secur,secure,9,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3211,1,['secur'],['secure']
Security,"Use setHeaderStrict, which validates the record's reference and mate reference against the new header. Requires disabling the ADAM test in MeanQualityByCycleSparkIntegrationTest due to https://github.com/broadinstitute/gatk/issues/1540.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1541:27,validat,validates,27,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1541,1,['validat'],['validates']
Security,"User Question: I'm trying to speed up the process of calling variants using SPARK. I have access to a slurm HPC cluster, so I guess it's not that straightforward to run GATK in a proper distributed master-slave architecture (if there is any tutorial on how to setup slurm jobs to use GATK Spark tools on multiple nodes I would appreciate it a lot). ; Therefore, I run GATK in local mode with some SPARK threads, eventually speeding up the process by parallelising the number of samples processed simultaneously with GNU parallel. But then, I'm having troubles because some samples crash due to SPARK errors. Perhaps you could send my logs to the developers ? I'm trying to run 8 parallel GATk jobs (8 samples) using 5 Spark cpus on each in a node with 40 cpus. . Best,; Pedro. This Issue was generated from your [forums] ; [forums]: https://gatkforums.broadinstitute.org/gatk/discussion/comment/56193#Comment_56193",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5717:90,access,access,90,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5717,1,['access'],['access']
Security,"User Report:. Hi,. I'm trying to run gatk MarkDuplicatesSpark (v 4.1.4.1) locally, so not on a spark cluster, and provided the option --conf 'spark.executor.cores=4' to tell MarkDuplicatesSpark to use only 4 cores on the machine. However when I check the system load with e.g. top I see that all 44 cores of the system are used by MarkDuplicatesSpark. What am I doing wrong?. command:; gatk MarkDuplicatesSpark \; --tmp-dir /local/scratch/tmp \; -I Control_aligned.bam \; -O Control_aligned_sort_mkdp.bam \ ; -M Control_aligned_sort_mkdp.txt \; --create-output-bam-index true \; --read-validation-stringency LENIENT \; --conf 'spark.executor.cores=4'. ------------------------------------------------------------------. **Solution** is to use this argument: `--spark-master local[2] -> ""Run on the local machine using two cores""`. More details in this doc: https://software.broadinstitute.org/gatk/documentation/article?id=11245. This Issue was generated from your [forums] ; [forums]: https://gatkforums.broadinstitute.org/gatk/discussion/24671/markduplicatesspark-not-respecting-conf-spark-executor-cores-4-option/p1",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6324:586,validat,validation-stringency,586,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6324,1,['validat'],['validation-stringency']
Security,"User has tested GATK3.7 HaplotypeCaller and GATK4 HaplotypeCaller. GATK4 takes ~35 hours while GATK3.7 takes about 18 hours. Original report is here: https://github.com/broadinstitute/gatk/issues/3631 David, I assigned you just so you could take a look. User seems satisfied that GATK4 is faster, but I am just making sure this is expected. I asked for more details on what type of data they are using and whether Spark version is faster (assuming this is from non-Spark version). . ----; User Report; ----. @Sheila,. Hi Sheila,. I repeated the experiment with GATK4.0.0 version. The performance is much better than GATK4beta5 version. Here are the logs: . $ tail -400 NA12892.HaplotypeCaller.err; Using GATK jar /gpfs/software/genomics/GATK/4.0.0/gatk-package-4.0.0.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -jar /gpfs/software/genomics/GATK/4.0.0/gatk-package-4.0.0.0-local.jar HaplotypeCaller --reference /gpfs/data_jrnas1/ref_data/Hsapiens/hs37d5/hs37d5.fa --input /gpfs/projects/NAGA/naga/NGS/pipeline/GATK_Best_Practices/GATK4.0.0/NA12892/bam/NA12892.recal.bam --dbsnp /gpfs/data_jrnas1/ref_data/Hsapiens/GRCh37/variation/dbsnp_138.vcf.gz --emit-ref-confidence GVCF --read-validation-stringency LENIENT --native-pair-hmm-threads 32 --output /gpfs/projects/NAGA/naga/NGS/pipeline/GATK_Best_Practices/GATK4.0.0/NA12892/vcf/NA12892.raw.snps.indels.g.vcf; [January 26, 2018 1:09:58 AM AST] org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCaller done. Elapsed time: **2,133.48 minutes**.; Runtime.totalMemory()=2183659520; real 128010.56; user 436969.62; sys 3030.18. Thanks and Regards,; Naga. This Issue was generated from your [forums] ; [forums]: https://gatkforums.broadinstitute.org/gatk/discussion/comment/45634#Comment_45634",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4361:1320,validat,validation-stringency,1320,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4361,1,['validat'],['validation-stringency']
Security,"User report:. ValidateVariants causes the error:; ```; java -Xms32G -Xmx32G -jar /data/biosoftware/GATK/gatk-4.1.2.0/gatk-package-4.1.2.0-local.jar ValidateVariants -R ~/reference/reference.fasta -V $i -gvcf; ```; And it causes the following error for all my files:; ```; ***********************************************************************. A USER ERROR has occurred: In a GVCF all records must ordered. Record: [VC Unknown @ Super-Scaffold_2:1-4 Q. of type=SYMBOLIC alleles=[G*, <NON_REF>] attr={END=4} filters= covers a position previously traversed. ***********************************************************************; ```. This doesn't cause the error:; ```; java -Xms32G -Xmx32G -jar /data/biosoftware/GATK/gatk-4.1.2.0/gatk-package-4.1.2.0-local.jar ValidateVariants -R ~/reference/reference.fasta -V $i; ```. This Issue was generated from your [forums] ; [forums]: https://gatkforums.broadinstitute.org/gatk/discussion/comment/59104#Comment_59104",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6023:14,Validat,ValidateVariants,14,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6023,3,['Validat'],['ValidateVariants']
Security,"Using GENOTYPE_GIVEN_ALLELES (""GGA"") mode with HaplotypeCaller, I've encountered a couple instances of crashes that I've traced to spanning deletions (of the type considered in #4963).; One case involved the following in the `--alleles` input:; ```; 22	16137300	rs567136176	TAG	T; 22	16137302	rs573978809	G	C; ```; and it crashed with:; ```; java.lang.IllegalStateException: Allele in genotype TAG* not in the variant context [G*, *, C]; 	at htsjdk.variant.variantcontext.VariantContext.validateGenotypes(VariantContext.java:1360); 	at htsjdk.variant.variantcontext.VariantContext.validate(VariantContext.java:1298); 	at htsjdk.variant.variantcontext.VariantContext.<init>(VariantContext.java:401); 	at htsjdk.variant.variantcontext.VariantContextBuilder.make(VariantContextBuilder.java:494); 	at htsjdk.variant.variantcontext.VariantContextBuilder.make(VariantContextBuilder.java:488); 	at org.broadinstitute.hellbender.utils.variant.GATKVariantContextUtils.simpleMerge(GATKVariantContextUtils.java:864); 	at org.broadinstitute.hellbender.utils.variant.GATKVariantContextUtils.simpleMerge(GATKVariantContextUtils.java:646); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.AssemblyBasedCallerUtils.makeMergedVariantContext(AssemblyBasedCallerUtils.java:221); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerGenotypingEngine.assignGenotypeLikelihoods(HaplotypeCallerGenotypingEngine.java:150); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerEngine.callRegion(HaplotypeCallerEngine.java:599); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCaller.apply(HaplotypeCaller.java:236); 	at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.processReadShard(AssemblyRegionWalker.java:291); 	at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.traverse(AssemblyRegionWalker.java:267); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:966); 	at org.broadinstitute.hell",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5336:487,validat,validateGenotypes,487,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5336,2,['validat'],"['validate', 'validateGenotypes']"
Security,"Using HaplotypeCaller with `GENOTYPE_GIVEN_ALLELES` (""GGA"") mode, I came across a couple of cases that crashed, and I traced them to spanning deletions (of the type considered in #4963). The first case involved the following spanning deletion in the `--alleles` input:; ```; 22	16137300	rs567136176	TAG	T; 22	16137302	rs573978809	G	C; ```; and it crashed with:; ```; java.lang.IllegalStateException: Allele in genotype TAG* not in the variant context [G*, *, C]; 	at htsjdk.variant.variantcontext.VariantContext.validateGenotypes(VariantContext.java:1360); 	at htsjdk.variant.variantcontext.VariantContext.validate(VariantContext.java:1298); 	at htsjdk.variant.variantcontext.VariantContext.<init>(VariantContext.java:401); 	at htsjdk.variant.variantcontext.VariantContextBuilder.make(VariantContextBuilder.java:494); 	at htsjdk.variant.variantcontext.VariantContextBuilder.make(VariantContextBuilder.java:488); 	at org.broadinstitute.hellbender.utils.variant.GATKVariantContextUtils.simpleMerge(GATKVariantContextUtils.java:864); 	at org.broadinstitute.hellbender.utils.variant.GATKVariantContextUtils.simpleMerge(GATKVariantContextUtils.java:646); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.AssemblyBasedCallerUtils.makeMergedVariantContext(AssemblyBasedCallerUtils.java:221); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerGenotypingEngine.assignGenotypeLikelihoods(HaplotypeCallerGenotypingEngine.java:150); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerEngine.callRegion(HaplotypeCallerEngine.java:599); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCaller.apply(HaplotypeCaller.java:236); 	at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.processReadShard(AssemblyRegionWalker.java:291); 	at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.traverse(AssemblyRegionWalker.java:267); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:966); 	a",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5337:512,validat,validateGenotypes,512,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5337,2,['validat'],"['validate', 'validateGenotypes']"
Security,"Using VCFTools to validate:; ```; vcf-validator SAMPLE7T-vs-SAMPLE7N-filtered.vcf; ```. I get a massive amount of messages:; ```; .....snip.......; column SAMPLE7N at 19:49136721 .. Could not validate the float [NaN],FORMAT tag [MPOS] expected different number of values (expected 1, found 2),FORMAT tag [MFRL] expected different number of values (expected 1, found 2),FORMAT tag [MMQ] expected different number of values (expected 1, found 2),FORMAT tag [MCL] expected different number of values (expected 1, found 2),FORMAT tag [MBQ] expected different number of values (expected 1, found 2); .....snip.......; column SAMPLE7T at 19:45901415 .. FORMAT tag [MBQ] expected different number of values (expected 1, found 2),FORMAT tag [MMQ] expected different number of values (expected 1, found 2),FORMAT tag [MCL] expected different number of values (expected 1, found 2),FORMAT tag [MFRL] expected different number of values (expected 1, found 2),FORMAT tag [MPOS] expected different number of values (expected 1, found 2); .....snip.......; ```. Sure enough, the header does not match the values for those fields (in the header number=""A""), so the validation errors are correct. Not sure what is the deal with FOXOG, but that may not be a big deal.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3296:18,validat,validate,18,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3296,4,['validat'],"['validate', 'validation', 'validator']"
Security,"Using the `--gcs-project-for-requester-pays` argument to access a requester-pays bucket, I tried `broad-dsde-methods`, `""broad-dsde-methods""`, and `222581509023`, but no dice. The log shows that the engine is reading the argument, but it doesn't seem to be passed to the cloud utils correctly.; ```; 14:23:16.753 INFO PrintReads - GCS max retries/reopens: 20; 14:23:16.753 INFO PrintReads - Requester pays: enabled. Billed to: broad-dsde-methods; 14:23:16.753 INFO PrintReads - Initializing engine; 14:23:18.501 INFO PrintReads - Shutting down engine; [September 23, 2019 2:23:18 PM EDT] org.broadinstitute.hellbender.tools.PrintReads done. Elapsed time: 0.03 minutes.; Runtime.totalMemory()=375914496; code: 400; message: Bucket is requester pays bucket but no user project provided.; reason: required; location: null; retryable: false; com.google.cloud.storage.StorageException: Bucket is requester pays bucket but no user project provided.; ```. `gsutil -u 222581509023 stat gs://fc-secure-2011b97c-a9c9-4a13-8911-f3833be31253/CCDG_WashU_CVD_EOCAD_METSIM_WGS_all/2893803451.cram` works and `gsutil stat gs://fc-secure-2011b97c-a9c9-4a13-8911-f3833be31253/CCDG_WashU_CVD_EOCAD_METSIM_WGS_all/2893803451.cram` produces; ```; BadRequestException: 400 Bucket is requester pays bucket but no user project provided.; ```. I tried the above variations on `export GOOGLE_CLOUD_PROJECT=` in the shell, but that didn't change things. It's possible I missed some combination of the above, but at the very least our docs need clarification.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6179:57,access,access,57,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6179,3,"['access', 'secur']","['access', 'secure-']"
Security,"Using underlying functionality from GenomicsDB to validate/specify cloud url's for GenomicsDB workspaces. This allows for the specification of s3 and azure blob storage uri's in addition to gcs for GenomicsDB workspaces. Currently, there are no tests for s3/az uri's, this is just experimental functionality available if needed.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7271:50,validat,validate,50,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7271,1,['validat'],['validate']
Security,VCF file names in validateSequenceDictionaries,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/660:18,validat,validateSequenceDictionaries,18,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/660,1,['validat'],['validateSequenceDictionaries']
Security,VCF row validation error on gCNV results,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8834:8,validat,validation,8,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8834,1,['validat'],['validation']
Security,VET Ingest Validation / Allow Ingest of non-VQSR'ed data,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7870:11,Validat,Validation,11,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7870,1,['Validat'],['Validation']
Security,VS 923 add validation to cluster creation,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8581:11,validat,validation,11,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8581,1,['validat'],['validation']
Security,VS-1433 add vcf validator to tests,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8903:16,validat,validator,16,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8903,1,['validat'],['validator']
Security,VS-1433.; This PR adds the tool vcf-validator to our variants docker and uses it in our integration test.; It validates that the VCFs have no errors in the `AD` field (which were previously reported by AoU friends).; It also modifies the Beta integration test to only run on WGS samples (previously ran on all samples). Passing Integration test [here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/0c9fb830-7831-4bee-a82c-d0146b250e59).,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8903:36,validat,validator,36,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8903,2,['validat'],"['validates', 'validator']"
Security,VS-402. Add VAT Validation check that aa_change and exon_number are consistentally set.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7850:16,Validat,Validation,16,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7850,1,['Validat'],['Validation']
Security,VS-775 vat validation shards,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8175:11,validat,validation,11,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8175,1,['validat'],['validation']
Security,Validate GenotypeGVCFs walker for production use (with palantir and/or short variants team help),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2071:0,Validat,Validate,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2071,1,['Validat'],['Validate']
Security,Validate SVCallRecord coordinates,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7714:0,Validat,Validate,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7714,1,['Validat'],['Validate']
Security,Validate all existing test BAMs,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/569:0,Validat,Validate,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/569,1,['Validat'],['Validate']
Security,Validate state utility method,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2543:0,Validat,Validate,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2543,1,['Validat'],['Validate']
Security,Validate the tiebreaking code for MarkDuplicatesSpark,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4707:0,Validat,Validate,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4707,1,['Validat'],['Validate']
Security,Validate the walkers BaseRecalibrator/ApplyBQSR for production,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1413:0,Validat,Validate,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1413,1,['Validat'],['Validate']
Security,ValidateBasicSomaticShortMutations will validate variants with reads in the validation normal,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5059:0,Validat,ValidateBasicSomaticShortMutations,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5059,3,"['Validat', 'validat']","['ValidateBasicSomaticShortMutations', 'validate', 'validation']"
Security,ValidateVariants,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/314:0,Validat,ValidateVariants,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/314,1,['Validat'],['ValidateVariants']
Security,ValidateVariants + tests,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/314:0,Validat,ValidateVariants,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/314,1,['Validat'],['ValidateVariants']
Security,ValidateVariants exception message improvement,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6076:0,Validat,ValidateVariants,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6076,1,['Validat'],['ValidateVariants']
Security,"ValidateVariants gVCF mode error ""covers a position previously traversed""",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6023:0,Validat,ValidateVariants,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6023,1,['Validat'],['ValidateVariants']
Security,"ValidateVariants give an `IllegalArgumentException` if a reference isn't provided. . It should be a `UserException`. I don't know but I think there may be modes that don't require the reference, so it may need to give a smart error message. ```; gatk-launch ValidateVariants --variant src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleGood.vcf; Using GATK wrapper script /Users/louisb/Workspace/gatk/build/install/gatk/bin/gatk; Running:; /Users/louisb/Workspace/gatk/build/install/gatk/bin/gatk ValidateVariants --variant src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleGood.vcf; 17:43:53.119 INFO NativeLibraryLoader - Loading libgkl_compression.dylib from jar:file:/Users/louisb/Workspace/gatk/build/install/gatk/lib/gkl-0.4.1.jar!/com/intel/gkl/native/libgkl_compression.dylib; [March 21, 2017 5:43:53 PM EDT] org.broadinstitute.hellbender.tools.walkers.variantutils.ValidateVariants --variant src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleGood.vcf --doNotValidateFilteredRecords false --warnOnErrors false --interval_set_rule UNION --interval_padding 0 --interval_exclusion_padding 0 --readValidationStringency SILENT --secondsBetweenProgressUpdates 10.0 --disableSequenceDictionaryValidation false --createOutputBamIndex true --createOutputBamMD5 false --createOutputVariantIndex true --createOutputVariantMD5 false --lenient false --addOutputSAMProgramRecord true --cloudPrefetchBuffer 40 --cloudIndexPrefetchBuffer -1 --disableBamIndexCaching false --help false --version false --showHidden false --verbosity INFO --QUIET false --use_jdk_deflater false --use_jdk_inflater false --disableToolDefaultReadFilters false; [March 21, 2017 5:43:53 PM EDT] Executing as louisb@WMD2A-31E on Mac OS X 10.11.6 x86_64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_112-b16; Version: Version:4.alpha.2-189-g724fbd0-SNAPSHOT; 17:43:53.162 INFO ValidateVariants - Def",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2509:0,Validat,ValidateVariants,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2509,7,"['Validat', 'validat']","['ValidateVariants', 'validationExampleGood']"
Security,ValidateVariants gvcf validation,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3445:0,Validat,ValidateVariants,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3445,2,"['Validat', 'validat']","['ValidateVariants', 'validation']"
Security,ValidateVariants is smarter about when a reference is and is not required. Closes #2509.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2649:0,Validat,ValidateVariants,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2649,1,['Validat'],['ValidateVariants']
Security,ValidateVariants memory usage is high when using a gvcf as the interval list,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8608:0,Validat,ValidateVariants,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8608,1,['Validat'],['ValidateVariants']
Security,ValidateVariants should have a flag to validate based solely on VCF spec,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6553:0,Validat,ValidateVariants,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6553,2,"['Validat', 'validat']","['ValidateVariants', 'validate']"
Security,ValidateVariants should validate counts of info-field annotation values,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2507:0,Validat,ValidateVariants,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2507,2,"['Validat', 'validat']","['ValidateVariants', 'validate']"
Security,ValidateVariants silently does no validation in use common cases,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5862:0,Validat,ValidateVariants,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5862,2,"['Validat', 'validat']","['ValidateVariants', 'validation']"
Security,ValidateVariants throws IllegalArgumentException if a reference isn't provided,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2509:0,Validat,ValidateVariants,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2509,1,['Validat'],['ValidateVariants']
Security,ValidateVariants: Error reports last (not first) overlapping interval,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8103:0,Validat,ValidateVariants,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8103,1,['Validat'],['ValidateVariants']
Security,Validation of sequence dictionaries from multiple BAMs now throws warning instead of exception in CNV workflows.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4758:0,Validat,Validation,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4758,1,['Validat'],['Validation']
Security,Validation stringency is ignored in LoadReadsFromFileFn,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/745:0,Validat,Validation,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/745,1,['Validat'],['Validation']
Security,Validation tests for on-the-fly .gz/.tbi creation.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3056:0,Validat,Validation,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3056,1,['Validat'],['Validation']
Security,VariantWalker / VariantContext doesn't validate variants at parse-time,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5867:39,validat,validate,39,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5867,1,['validat'],['validate']
Security,"Variants - HTSJDK Version: 2.22.0; 19:53:34.607 INFO ValidateVariants - Picard Version: 2.22.8; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 19:53:34.608 INFO ValidateVariants - Deflater: IntelDeflater; 19:53:34.608 INFO ValidateVariants - Inflater: IntelInflater; 19:53:34.608 INFO ValidateVariants - GCS max retries/reopens: 20; 19:53:34.608 INFO ValidateVariants - Requester pays: disabled; 19:53:34.608 INFO ValidateVariants - Initializing engine; 19:53:35.169 INFO FeatureManager - Using codec VCFCodec to read file file://chr1-22.phased.rename.reheader.vcf.gz; 19:53:35.594 INFO ValidateVariants - Done initializing engine; 19:53:35.594 WARN ValidateVariants - IDS validation cannot be done because no DBSNP file was provided; 19:53:35.594 WARN ValidateVariants - Other possible validations will still be performed; 19:53:35.594 INFO ProgressMeter - Starting traversal; 19:53:35.595 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 19:53:35.660 INFO ValidateVariants - Shutting down engine; [October 25, 2020 7:53:35 PM CDT] org.broadinstitute.hellbender.tools.walkers.variantutils.ValidateVariants done. Elapsed time: 0.02 minutes.; Runtime.totalMemory()=2114453504; java.lang.ArrayIndexOutOfBoundsException: -87; 	at org.broadinstitute.hellbender.utils.BaseUtils.convertIUPACtoN(BaseUtils.java:123); 	at org.broadinstitute.hellbender.utils.fasta.CachingIndexedFastaSequenceFile.getSubsequenceAt(CachingIndexedFastaSequenceFile.java:340); 	at org.broadinstitute.hellbender.engine.ReferenceFileSource.queryAndPrefetch(ReferenceFileSource.java:78); 	at org.broadinstitute.hellbender.engine.ReferenceDataSource.queryAndPrefetch(ReferenceDataSource.j",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6911:2892,Validat,ValidateVariants,2892,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6911,2,"['Validat', 'validat']","['ValidateVariants', 'validation']"
Security,"Variants with the `-no-overlaps` option, a USER ERROR is outputted after the entire tool finishes running, as shown below:. ```; ***********************************************************************. A USER ERROR has occurred: This GVCF contained overlapping reference blocks. The first overlapping interval is [genomic coordinates here]. ***********************************************************************; ```. This error should be generally helpful, but it appears that the interval that is reported in the error message is the _last_ overlapping interval, not the _first_. I'm not super familiar with java, but I'm guessing that `firstOverlap` might be continuously replaced by `refInterval` if there are multiple overlaps, which is inconsistent with expected behavior. . Potentially relevant lines of code: ; - `-no-overlaps` argument description ([lines 192-201](; https://github.com/broadinstitute/gatk/blob/ca33bc953abfa7050b791f049285f5262675cf84/src/main/java/org/broadinstitute/hellbender/tools/walkers/variantutils/ValidateVariants.java#L192-L201)); - `firstOverlap = refInterval` ([line 275](https://github.com/broadinstitute/gatk/blob/ca33bc953abfa7050b791f049285f5262675cf84/src/main/java/org/broadinstitute/hellbender/tools/walkers/variantutils/ValidateVariants.java#L275)). #### Steps to reproduce. Running ValidateVariants with the `-no-overlaps` flag on a .g.vcf with overlapping intervals will cause this error. More specifically, we're running this within WARP's Exome Germline Single Sample v.3.1.7 WDL release. Our command is as follows:. ```; gatk --java-options ""-Xms6000m -Xmx6500m"" \; ValidateVariants \; -V /path/to/our/.g.vcf.gz \; -R /path/to/our/.fa \; -L /path/to/our/.interval_list \; -gvcf \; --validation-type-to-exclude ALLELES \; --dbsnp /path/to/our/.vcf.gz \; --no-overlaps; ```. #### Expected behavior. The error message should report the _first_ overlapping interval. #### Actual behavior; The error message is reporting the _last_ overlapping interval.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8103:1633,Validat,ValidateVariants,1633,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8103,4,"['Validat', 'validat']","['ValidateVariants', 'validation-type-to-exclude']"
Security,"We found this trying to tie out the BQ version of the VQSR annotations with the Evoquer+Gnarly outputs, specifically in the RankSumTest annotations. This never got merged into master. The short story is... the implementation of median in the Histogram class is broken. Precisely, in this line it iterates through the bins of the histogram to find the midpoint index... however the keySet() it gets is from a HashMap and therefore not ordered. That code hasn't been touched in 2 years, so it's been this way for a while. It's tough to catch because of course there is a non-guaranteed ordering to the keys, and in the case of hashmap today when there are < 16 keys will be the hashcode of the keys modulo 16 until there is collision. The hashcode of integers is just the integer... so in our tests we have today it just happens to work because we have a small number of keys and they are close to each other so hash in the order we happen to want. I learned more about [HashMap internals](http://hg.openjdk.java.net/jdk8/jdk8/jdk/file/687fd7c7986d/src/share/classes/java/util/HashMap.java) than I wanted to know in order to make a test case for it :/ . I. A test on data like this breaks:. 1,2,16. as it returns 1 instead of 2 as the median. I have a test for this, and have a fix (basically sort the keys, running through a TreeSet). Thanks to @mmorgantaylor and @schaluva for helping with this",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7131:408,Hash,HashMap,408,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7131,7,"['Hash', 'hash']","['HashMap', 'hash', 'hashcode', 'hashmap']"
Security,"We have a tool, VariantQC, that extends VariantEval. This PR is a minor refactor to expose the code that creates the list of VariantStratifier and VariantEvaluator objects as protected methods, so subclasses could modify them. This should have no functional difference on VariantEval itself. We're hoping to use these changes in order to adapt our tool in response to reviewers, so if there is any way to push these changes we would appreciate it.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5998:84,expose,expose,84,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5998,1,['expose'],['expose']
Security,"We have the basic DREAM somatic challenge, but there's also an RNA challenge, and perhaps others. If it's a similar format of bams, masks, and truth vcfs it would be really easy to set up a validation like the one we currently have on Firecloud.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5427:190,validat,validation,190,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5427,1,['validat'],['validation']
Security,"We need a tool to compare multiple references and spit out a TSV (or similar) detailing what the differences are. Additionally it should be able to spit out a liftover file that will properly move a variant from one reference to another. We should first compare the sequence dictionaries in the references to see if they have equal lengths and checksums - the names may differ and we should track this so we can definitively say which contigs are equivalent. After this, we should walk the references and find out specifically which bases differ between contigs that have different checksums (with some limits on the number of differences between them so we don't get bogged down by `hg19` vs `hg38` comparisons). ; Then it should create a liftover file from those comparisons so the data can be easily converted between the references given. . Additionally, it should be able to take a variant file and a set of references and say:. - whether the variant file ""belongs"" to one of the given references; - if it isn't exactly from one of the given references, which reference is closest; - _optionally_: a lifted-over version of that VCF to the closest reference (with a bunch of warnings, if applicable). This will finally lay to rest the questions raised by [my blog post about ""HG19""](https://gatk.broadinstitute.org/hc/en-us/articles/360035890711). I believe Adam Phillipy had created a perl script that does something similar to this, but a brief view of his github page doesn't show anything like that anymore (maybe it was called `refdiff` or similar). I created a bash script that does something similar to this (see attached), but it only looks at the sequence dictionaries. It produces a table similar to that in the above blog post. For example:. |MD5 | HG38(Homo_sapiens_assembly38.dict) | HG38_WEIRD(genome.hg38rg.fa.dict)|; | --- | --- | --- |; |1e95e047b98ed92148dd84d6c037158c|chr1_KI270708v1_random|1_KI270708v1_random|; |42f7a452b8b769d051ad738ee9f00631|chr1_KI270714v1_random|1_KI270",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6837:344,checksum,checksums,344,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6837,2,['checksum'],['checksums']
Security,"We need the ability to store command-line argument definitions in @ArgumentCollections like in the GATK, to avoid duplicate definitions, and to provide a standard way of accessing the argument values.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/96:170,access,accessing,170,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/96,1,['access'],['accessing']
Security,"We need to add a validation check to ensure that any read input file contains a header (since they're technically optional). There are code paths that assume that a header/sequence dictionary is always present (i.e., some of the SplitReads tests get NPEs if presented with one).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2334:17,validat,validation,17,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2334,1,['validat'],['validation']
Security,We need to look into Java 8 java.util.stream for accessing Read and Variant data,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/9:49,access,accessing,49,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/9,1,['access'],['accessing']
Security,We need to understand the data access patterns in the existing engines: Picard/GATK/Foghorn; @lbergelson and @kshakir already started doing it. Can you move the list here?,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1:31,access,access,31,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1,1,['access'],['access']
Security,"We noticed today that there's no way in GATK4 to change the sigma of the band pass filter Gaussian kernel in `AssemblyRegionWalker`, even though `maxProbPropagationDistance` is settable. For consistency's sake, we should expose the band pass sigma via an arg as well.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5387:221,expose,expose,221,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5387,1,['expose'],['expose']
Security,"We recently discovered that some of the tests we didn't think required google cloud authentication require that gcloud be initialized. Travis didn't catch this because we always initialize gcloud in order to do log uploading. We should change this so it's only initialized during the tests for the cloud tests. . The actual error we discovered didn't require that credentials be correct, only that a default project had been configured so simply logging out isn't enough to trigger it.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2706:84,authenticat,authentication,84,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2706,1,['authenticat'],['authentication']
Security,"We should audit the plugin system (and add tests) to ensure that crazy combinations of enable/disable arguments (like `--readFilter` and `--disableReadFilter`) are disallowed, while useful combinations are permitted. Here's my attempt at an initial proposal:. `--enable X --disable X`: crazy, should be an error. `--enable X --enable X`: error. `--disable X --disable X`: error. `--enable X when X is already on by default in the tool`: warning, but should be allowed -- this is useful for pipeline authors to guarantee that a particular filter will be on, even if tool defaults change over time. We should make sure that the filter is only actually applied ONCE, however. `--disable X when X is not enabled by default in the tool`: warning, but should be allowed -- this is useful for pipeline authors to guarantee that a particular filter will be off, even if tool defaults change over time.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2377:10,audit,audit,10,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2377,1,['audit'],['audit']
Security,"We use the GATKGCSOptions class to hold GCP authentication. It inherits from the Dataflow hierarchy and works well there, but since it doesn't implement Serializable it's cumbersome to work with in Spark. We've created AuthHolder as a replacement. It can do all the things GATKGCSOptions can do, and more (well, except for holding Dataflow debug options but we don't need that anymore). Once #978 is merged in, we need to migrate the code from GATKGCSOptions to AuthHolder. One benefit is that this will allow the Spark code to support client-secrets.json (for access to private GCS files, unlike the API key which only grants access to world-readable GCS files).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1002:44,authenticat,authentication,44,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1002,3,"['access', 'authenticat']","['access', 'authentication']"
Security,"We want something like a hosted jenkins server to run parts of the test suite that can't or shouldn't be run in travis. This includes:. -Long-running validation tests, like those designed by @davidadamsphd for the `ReadsPipelineSpark`; -Tests involving reading data from HDFS.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1400:150,validat,validation,150,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1400,1,['validat'],['validation']
Security,We were seeing failures on spark clusters that manifested as being; unable to find the Main class while running spark submit. The caused was the accidental introduction of a jar signature file; and key from the transitive gnu.getopt dependency. This was causing; signature validation failures since our uber jar did not match the; expected hashes. Fixed by excluding .SF and .RSA files from our jars.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2618:273,validat,validation,273,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2618,2,"['hash', 'validat']","['hashes', 'validation']"
Security,We've been encountering transient 403 errors when using GCS NIO.; It seems that some GCS-related service is incorrectly returning 403 in; certain cases where we do actually have permission to access a resource.; This commit moves us to a google-cloud-java snapshot that retries upon; 403 errors:. https://github.com/droazen/google-cloud-java/commit/6d11bef1c81f885c26b2b56c8616b7a705171e4f. Resolves #3735,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3766:192,access,access,192,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3766,1,['access'],['access']
Security,"We've been using 4.beta.6 to generate new callsets because it has the GenomicsDBImport batching fix and it seems to have introduced transient Auth errors that production was not seeing before. This happens a maybe one shard at every task level and when rerun usually succeeds but as you can imagine is pretty annoying. This happens across multiple tools (GenomicsDBImport, GatherVcfs). Sometimes we get this as the only response from GATK when this happens. ```; ***********************************************************************. A USER ERROR has occurred: Couldn't read file. Error was: Failure while waiting for FeatureReader to initialize with exception: com.google.cloud.storage.StorageException: 403 Forbidden; 443301511749-compute@developer.gserviceaccount.com does not have storage.objects.get access to broad-gotc-prod-storage/pipeline/G101956/gvcfs/DDP_ATCP_42_1.4afb46bb-4009-47c4-9aa0-407e92de0db8.g.vcf.gz. ***********************************************************************; ```. and other times we get a nice stacktrace for this issue. ```; java.lang.RuntimeException: java.util.concurrent.ExecutionException: com.google.cloud.storage.StorageException: 403 Forbidden; 443301511749-compute@developer.gserviceaccount.com does not have storage.objects.get access to broad-jg-dev-11k-call-set/JointGenotyping/0cb36821-b8bf-4e6d-a352-07b101f6b7d1/call-ApplyRecalibration/shard-1734/GMKF_Seidman_CHD_WGS_904.filtered.1734.vcf.gz.; 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher.read(SeekableByteChannelPrefetcher.java:309); 	at htsjdk.samtools.seekablestream.SeekablePathStream.read(SeekablePathStream.java:86); 	at htsjdk.samtools.util.IOUtil.transferByStream(IOUtil.java:141); 	at org.broadinstitute.hellbender.tools.GatherVcfsCloud.gatherWithBlockCopying(GatherVcfsCloud.java:394); 	at org.broadinstitute.hellbender.tools.GatherVcfsCloud.doWork(GatherVcfsCloud.java:143); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineP",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3735:807,access,access,807,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3735,1,['access'],['access']
Security,"We've discovered a number of bam files being used in tests which are not valid BAM files. We should go through all the checked in BAMs, validate them, and replace broken ones. (Except ones that are intentionally broken for testing.) . (added later by @akiezun); In particular, copied from https://github.com/broadinstitute/hellbender/issues/568, NA12878.chr17_69k_70k.dictFix.bam has a problem:; whoever fixes this ticket needs to take care of this input. `htsjdk.samtools.SAMFormatException: SAM validation error: ERROR: Record 129, Read name 809R9ABXX101220:5:6:17918:145992, Mate Alignment start should be 0 because reference name = *.`. Here's the corresponding read:; `809R9ABXX101220:5:6:17918:145992 97 17 69400 37 67M9S * 71202348 0 ACTCCCCACCTTACCTGACTCCTTCCAGGGTTTGTCGCCTTTCCGGTCCCTGACCCCAGTGGATGGGAGTCTGTCC ?ABDDEEABEECBDBDAB=DEDCDEEBFADABCEAD?EEEDCFE?ABEEE@FCDEEEBF@F?CA4@@########## UQ:i:0`",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/569:136,validat,validate,136,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/569,2,['validat'],"['validate', 'validation']"
Security,"When I was trying to use user exceptions in a consistent way independently of the constructor (mostly related with files), I found very weird behaviour with the messages. Here I try to fix some of the things that I was struggling with:. * Support for path in constructors for `CouldNotReadInputFile`, `CouldNotCreateOutputFile`, `MalformedFile` and `MalformedBAM`, in addition to some missing constructors to have the same structure for all of them (with `File` and/or `String`).; * ~~Updated javadoc in `CommandLineException`, including extending classes to make clear that in the GATK framework is not printed out if it is thrown out of parameter validation.~~ __Edited__: this is not longer required, because `CommandLineException` is decoupled from `UserException` through barclay.; * Added a TODO into the `MalformedBAM` constructor that includes a `GATKRead` that is not used.; * __Edited__: added final to constructors.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2282:649,validat,validation,649,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2282,1,['validat'],['validation']
Security,"When `ReadPosRankSumTest.getReadPosition` encounters the second of two deletions with two bases in between it hits the following code:; ```; if ( AlignmentUtils.isInsideDeletion(read.getCigar(), offset) ) {; return OptionalDouble.of(INVALID_ELEMENT_FROM_READ);; }; ```; which returns negative infinity. Those with TCGA access can reproduce the issue by running on the TCGA exome pair ESCA-IG-A3YB-TP-NB at 15:34525804-34525810.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5492:319,access,access,319,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5492,1,['access'],['access']
Security,When accessing the help output for Picard tools (example MarkDuplicates) through the gatk launch script it seems that engine level Picard arguments are not showing up in the help output (example `--TMP_DIR`). The default behavior in picard itself is to hide those engine arguments from the help output behind a special help flag `--stdhelp` which adds all of those arguments back into the help output. We should reintroduce those arguments into the GATK help output for Picard tools.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6811:5,access,accessing,5,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6811,1,['access'],['accessing']
Security,"When running GATK with specific interval(s), the default behavior is to include any variant spanning those interval(s). When running scatter/gather jobs, this behavior is generally not what one wants, since this would result in variants spanning the job intervals getting included twice. In a handful of GATK tools, there is support for something like --ignore-variants-starting-outside-interval, which is probably designed to solve this problem. GenotypeGVCFs supports this. However, the implementation/support is generally tool-level and I dont believe all tools support this. For example, SelectVariants does not appear to. If one wants to run a scatter/gather task that doesnt start with a GATK tool that supports --ignore-variants-starting-outside-interval, you're out of luck. My questions are:. 1) Am I completely missing some existing capability?. 2) There is already some low-level support in the engine for control over intervals. Would you be receptive to a PR that pushes support for ""--ignore-variants-starting-outside-intervals"" lower into GATK? Perhaps into VariantWalkerBase? One possibility would be to create a StartsWithinIntervalsVariantFilter, and override makeVariantFilter() to inject it. I dont think this would be particularly invasive, and could be pretty useful across many tools. As part of this, MultiVariantWalkerGroupedOnStart's argument would get merged with this.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8063:1201,inject,inject,1201,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8063,1,['inject'],['inject']
Security,"When we make enhancements to the walker engine (eg., modify the `GATKTool` base class to support CRAM, or to validate the sequence dictionaries of the inputs), it would be good if Spark tools could also reap the benefits of these changes automatically. We may need to unify (or better integrate) the `GATKTool` and `SparkCommandLineProgram` base classes somehow to make this possible, as well as classes like `ReadsDataSource` (for walkers) and `ReadsSparkSource` (for Spark tools).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/680:109,validat,validate,109,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/680,1,['validat'],['validate']
Security,"While using a custom tool that validates arguments (e.g., certain range for an `Integer` parameter), a way of handling it is override `CommandLineProgram.customCommandLineValidation()` and return an String with the error found. Nevertheless, if parsing the arguments throws a `UserException.CommandLineException`, the error is printed with a concrete format (`printDecoratedUserExceptionMessage`) after the usage. This is different from the custom validation, which is printed without any decoration and before the usage. Although this behavior could be desirable, I expect that if my custom validation thrown an `UserException.CommandLineException` it is printed in the same way as other exceptions, and the exception is re-thrown in the same way (for testing purposes, for instance). But the current behaviour just exit without any error printed because the exception is catched in `Main`. A very minor change is include in the `try` block the custom validation.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2225:31,validat,validates,31,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2225,4,['validat'],"['validates', 'validation']"
Security,"While working on validating #5607 I noticed that at the top of the method `isReadInformativeOfIndelOfSize()` that there is the following breakout condition:; ```; if( read.getLength() - readStart < maxIndelSize || refBases.length - refStart < maxIndelSize ) {; return false;; }; ```; This says that if the readStart is too close to the read.getLenght() then it will break out and not calculate the informativeness of a read. Unfortunately readStart isn't the readbase indexed readStart, its actually the ""IGV view"" offset for the read generated by the pileup for a particular reference position. The actual length that matters to us is: `AlignmentUtils.getBasesAlignedOneToOne(read).length` which is computed later when we realign the read bases to the reference. What this means is that if a read happens to have a long deletion in it then we will end up prematurely marking the read bases as being non-informative despite there being more than enough bases to work with when doing computations. Furthermore, since we realign the read bases later in the codepath, these bases in the gap between the realigned length and `read.getLength()` are still used to compute mismatch likelihood for bases before that point in the read. An example of this issue: I have a read with the cigar ""77M10D24M"", at position 92 of the read (the igv offset so in reality the 5th base into the last element of the cigar) the code returns false due to this condition. In reality `AlignmentUtils.getBasesAlignedOneToOne(read).length - readStart` value is 19, and thus comparable since there are >10 bases left in the read to test. . I have duplicated this behavior in #5607, perhaps it would be easiest to get that branch in first before tackling this issue just so validation for that refactor is easier.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5646:17,validat,validating,17,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5646,2,['validat'],"['validating', 'validation']"
Security,"Will include a top-level abstract Tool class, subclasses for each of the standard traversal types (ReadWalker, LocusWalker, etc.), and a class for each kind of data source (ReadDataSource, ReferenceDataSource, etc.). Initial framework will have placeholders/stub implementations for some functionality, but will support at least traversal by reads with the ability to access overlapping reference bases.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/82:368,access,access,368,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/82,1,['access'],['access']
Security,"With the new GCS NIO reader, it may well be preferable to access large side inputs directly in GCS buckets rather than broadcasting them. This would reduce our memory usage dramatically relative to broadcast, and if the performance is the same or better it seems like the way to go.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2015:58,access,access,58,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2015,1,['access'],['access']
Security,"With this addition, summarizing the results of the MC3 validation will use more GATK, less scripting.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4982:55,validat,validation,55,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4982,1,['validat'],['validation']
Security,Work with palantir and/or short variants team to validate GATK4 version of VQSR,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2065:49,validat,validate,49,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2065,1,['validat'],['validate']
Security,"Would it be possible to expose the [`READ_QUALITY_FILTER_THRESHOLD`](https://github.com/broadinstitute/gatk/blob/9d5727df8db3a475b1ba5f9bff6bc92a322f5633/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/HaplotypeCallerEngine.java#L729) on the command line for 4.9.0.1? I know on the latest branch we have [`--mapping-quality-threshold`](https://github.com/broadinstitute/gatk/blob/7e3d8a1e0c56206345128e3a6125ecc30427deda/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/HaplotypeCallerArgumentCollection.java#L153). For data and regions where we get low mapping qualities (eg. PacBio), a hard-filter on mapq 20 is onerous. I'd also echo the comment in the latter TODO that the interplay between `----mapping-quality-threshold` (new) and ` --minimum-mapping-quality` (old) is confusing upon first inspection.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7034:24,expose,expose,24,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7034,1,['expose'],['expose']
Security,Wrapper around VC object to access SVContext specific annotations.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3476:28,access,access,28,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3476,1,['access'],['access']
Security,"Y. On Mon, Nov 14, 2016 at 6:19 PM, Geraldine Van der Auwera <; notifications@github.com> wrote:. > From what I understand of the referenced thread, the ""incorrect"" interval; > list may always be around, so we may never be able to just blow up on it.; > Would it perhaps be more viable to add an option to toggle the level of; > stringency, ie choose in the command line whether to blow up or skip on; > these invalid intervals?; > ; > —; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > https://github.com/broadinstitute/gsa-unstable/issues/1438#issuecomment-260495927,; > or mute the thread; > https://github.com/notifications/unsubscribe-auth/ACnk0uvegvUmCq7_G7U2PSuTpvIYl0wQks5q-Ox0gaJpZM4JNjE-; > . ---. @vdauwera commented on [Mon Nov 14 2016](https://github.com/broadinstitute/gsa-unstable/issues/1438#issuecomment-260519118). So, would adding a toggle be acceptable? And more importantly, can we make stringent validation default, with the option to not blow up on silly exome files? Will production accept that?. ---. @yfarjoun commented on [Tue Nov 15 2016](https://github.com/broadinstitute/gsa-unstable/issues/1438#issuecomment-260617185). let me talk with production to see if we can post-facto change the exome; file... On Mon, Nov 14, 2016 at 8:27 PM, Geraldine Van der Auwera <; notifications@github.com> wrote:. > So, would adding a toggle be acceptable? And more importantly, can we make; > stringent validation default, with the option to not blow up on silly exome; > files? Will production accept that?; > ; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > https://github.com/broadinstitute/gsa-unstable/issues/1438#issuecomment-260519118,; > or mute the thread; > https://github.com/notifications/unsubscribe-auth/ACnk0tUTNAAyuk3m_2cJ8j_3KYroaqB1ks5q-QpsgaJpZM4JNjE-; > . ---. @vdauwera commented on [Mon Mar 20 2017](https://github.com/broad",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2520:2559,validat,validation,2559,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2520,1,['validat'],['validation']
Security,YNC_IO_WRITE_FOR_TRIBBLE : false; 17:28:28.782 INFO GermlineCNVCaller - Deflater: IntelDeflater; 17:28:28.782 INFO GermlineCNVCaller - Inflater: IntelInflater; 17:28:28.782 INFO GermlineCNVCaller - GCS max retries/reopens: 20; 17:28:28.782 INFO GermlineCNVCaller - Requester pays: disabled; 17:28:28.782 INFO GermlineCNVCaller - Initializing engine; 17:28:34.716 INFO GermlineCNVCaller - Done initializing engine; 17:28:34.723 INFO GermlineCNVCaller - Intervals specified...; log4j:WARN No appenders could be found for logger (org.broadinstitute.hdf5.HDF5Library).; log4j:WARN Please initialize the log4j system properly.; log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.; 17:28:35.689 INFO FeatureManager - Using codec IntervalListCodec to read file file:///media/Data/AnnotationDBs/CNV/Genom/hdf5/../Genom.filtered.interval_list; 17:28:42.892 INFO IntervalArgumentCollection - Processing 2741406000 bp from intervals; 17:28:43.237 INFO GermlineCNVCaller - Reading and validating annotated intervals...; 17:28:51.740 INFO GermlineCNVCaller - GC-content annotations for intervals found; explicit GC-bias correction will be performed...; 17:28:57.410 INFO GermlineCNVCaller - Running the tool in COHORT mode...; 17:28:57.410 INFO GermlineCNVCaller - Validating and aggregating data from input read-count files...; 17:28:57.940 INFO GermlineCNVCaller - Aggregating read-count file 0028-21.hdf5 (1 / 44); 17:29:00.837 INFO GermlineCNVCaller - Aggregating read-count file 0045-21.hdf5 (2 / 44); 17:29:03.690 INFO GermlineCNVCaller - Aggregating read-count file 0098-18.hdf5 (3 / 44); 17:29:06.658 INFO GermlineCNVCaller - Aggregating read-count file 0156-21.hdf5 (4 / 44); 17:29:09.435 INFO GermlineCNVCaller - Aggregating read-count file 0429-20.hdf5 (5 / 44); 17:29:12.235 INFO GermlineCNVCaller - Aggregating read-count file 0779-18.hdf5 (6 / 44); 17:29:14.939 INFO GermlineCNVCaller - Aggregating read-count file 1030-20.hdf5 (7 / 44); 17:29:17.822 INFO GermlineCNV,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7234:5312,validat,validating,5312,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7234,1,['validat'],['validating']
Security,"Yes, what are the plans? I too would like to know. ---; What are the plans for the tools available in Picard 2.9.2 or GATK3.7 that are not in GATK4 alpha? Is the plan eventually to port everything to GATK4? Or are some being permanently sent out to pasture?. I have specifically noticed as missing:; - CollectVariantCallingMetrics; - SetNmMdAndUqTags; - the -gvcf option for ValidateVariants. This Issue was generated from your [forums] ; [forums]: http://gatkforums.broadinstitute.org/gatk/discussion/9736/gatk4-status-of-some-picard-gatk3-7-tools-missing-from-alpha/p1",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3084:375,Validat,ValidateVariants,375,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3084,1,['Validat'],['ValidateVariants']
Security,[Echo] bq query audit [VS-1396] (#8847),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8854:16,audit,audit,16,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8854,1,['audit'],['audit']
Security,"[info] WorkflowManagerActor Starting workflow 968be82c-eef3-4bdb-a1ab-3d4e2ca70674; [2020-07-14 05:09:30,69] [info] WorkflowManagerActor Successfully started WorkflowActor-968be82c-eef3-4bdb-a1ab-3d4e2ca70674; [2020-07-14 05:09:30,69] [info] Retrieved 1 workflows from the WorkflowStoreActor; [2020-07-14 05:09:30,72] [info] WorkflowStoreHeartbeatWriteActor configured to flush with batch size 10000 and process rate 2 minutes.; [2020-07-14 05:09:30,83] [info] MaterializeWorkflowDescriptorActor [968be82c]: Parsing workflow as WDL 1.0; [2020-07-14 05:09:31,60] [info] MaterializeWorkflowDescriptorActor [968be82c]: Call-to-Backend assignments: ValidateBamsWf.ValidateBAM -> Local; [2020-07-14 05:09:31,82] [warn] Local [968be82c]: Key/s [memory, disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.; [2020-07-14 05:09:35,38] [info] Not triggering log of token queue status. Effective log interval = None; [2020-07-14 05:09:37,15] [info] WorkflowExecutionActor-968be82c-eef3-4bdb-a1ab-3d4e2ca70674 [968be82c]: Starting ValidateBamsWf.ValidateBAM; [2020-07-14 05:09:37,39] [info] Assigned new job execution tokens to the following groups: 968be82c: 1; [2020-07-14 05:09:41,61] [warn] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: Unrecognized runtime attribute keys: disks, memory; [2020-07-14 05:09:41,71] [info] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: /gatk/gatk \; ValidateSamFile \; --INPUT /cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/inputs/-1942028726/test.bam \; --OUTPUT test.validation_.txt \; --MODE SUMMARY; [2020-07-14 05:09:41,76] [info] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: executing: # make sure there is no preexisting Docker CID file; rm -f /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execut",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6710:4371,Validat,ValidateBamsWf,4371,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710,1,['Validat'],['ValidateBamsWf']
Security,"\ ; ; ASEReadCounter \\ ; ; \-L scattered.interval\_list \\ ; ; \-R Homo\_sapiens\_assembly19.fasta \\ ; ; \-V 1000G\_phase1.snps.high\_confidence.b37.vcf.gz \\ ; ; \-I downsample\_10k.bam \\ ; ; \-O output.txt --verbosity INFO. c) Entire error log:. 19:13:25.991 INFO NativeLibraryLoader - Loading libgkl\_compression.so from jar:file:/broad/software/free/Linux/redhat\_7\_x86\_64/pkgs/gatk\_4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl\_compression.so. Jun 14, 2021 7:13:26 PM shaded.cloud\_nio.com.google.auth.oauth2.DefaultCredentialsProvider warnAboutProblematicCredentials. WARNING: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a ""quota exceeded"" or ""API not enabled"" error. For more information about service accounts, see [https://cloud.google.com/docs/authentication/](https://cloud.google.com/docs/authentication/). 19:13:26.217 INFO ASEReadCounter - ------------------------------------------------------------. 19:13:26.218 INFO ASEReadCounter - The Genome Analysis Toolkit (GATK) v4.1.8.1. 19:13:26.218 INFO ASEReadCounter - For support and documentation go to [https://software.broadinstitute.org/gatk/](https://software.broadinstitute.org/gatk/). 19:13:26.219 INFO ASEReadCounter - Executing as [cbao@uger-c009.broadinstitute.org](mailto:cbao@uger-c009.broadinstitute.org) on Linux v3.10.0-1160.15.2.el7.x86\_64 amd64. 19:13:26.219 INFO ASEReadCounter - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0\_181-b13. 19:13:26.219 INFO ASEReadCounter - Start Date/Time: June 14, 2021 7:13:25 PM UTC. 19:13:26.219 INFO ASEReadCounter - ------------------------------------------------------------. 19:13:26.219 INFO ASEReadCounter - ------------------------------------------------------------. 19:13:26.220 INFO ASEReadCounter - HTSJDK Version: 2.23.0. 19:",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7327:2114,authenticat,authentication,2114,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7327,1,['authenticat'],['authentication']
Security,"] Running with database db.url = jdbc:hsqldb:mem:f10b64bd-d8ca-4428-917b-311fca24c372;shutdown=false;hsqldb.tx=mvcc; [2020-07-14 05:09:29,36] [info] Running migration RenameWorkflowOptionsInMetadata with a read batch size of 100000 and a write batch size of 100000; [2020-07-14 05:09:29,37] [info] [RenameWorkflowOptionsInMetadata] 100%; [2020-07-14 05:09:29,47] [info] Running with database db.url = jdbc:hsqldb:mem:e337a356-2f0c-4389-92c5-255465180f24;shutdown=false;hsqldb.tx=mvcc; [2020-07-14 05:09:29,89] [info] Slf4jLogger started; [2020-07-14 05:09:30,10] [info] Workflow heartbeat configuration:; {; ""cromwellId"" : ""cromid-ca5c695"",; ""heartbeatInterval"" : ""2 minutes"",; ""ttl"" : ""10 minutes"",; ""failureShutdownDuration"" : ""5 minutes"",; ""writeBatchSize"" : 10000,; ""writeThreshold"" : 10000; }; [2020-07-14 05:09:30,23] [info] Metadata summary refreshing every 1 second.; [2020-07-14 05:09:30,23] [warn] 'docker.hash-lookup.gcr-api-queries-per-100-seconds' is being deprecated, use 'docker.hash-lookup.gcr.throttle' instead (see reference.conf); [2020-07-14 05:09:30,25] [info] CallCacheWriteActor configured to flush with batch size 100 and process rate 3 seconds.; [2020-07-14 05:09:30,26] [info] KvWriteActor configured to flush with batch size 200 and process rate 5 seconds.; [2020-07-14 05:09:30,26] [info] WriteMetadataActor configured to flush with batch size 200 and process rate 5 seconds.; [2020-07-14 05:09:30,36] [info] JobExecutionTokenDispenser - Distribution rate: 50 per 1 seconds.; [2020-07-14 05:09:30,46] [info] SingleWorkflowRunnerActor: Version 51; [2020-07-14 05:09:30,48] [info] SingleWorkflowRunnerActor: Submitting workflow; [2020-07-14 05:09:30,55] [info] Unspecified type (Unspecified version) workflow 968be82c-eef3-4bdb-a1ab-3d4e2ca70674 submitted; [2020-07-14 05:09:30,66] [info] SingleWorkflowRunnerActor: Workflow submitted 968be82c-eef3-4bdb-a1ab-3d4e2ca70674; [2020-07-14 05:09:30,67] [info] 1 new workflows fetched by cromid-ca5c695: 968be82c-eef3-4bdb-a1ab-3d",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6710:2263,hash,hash-lookup,2263,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710,1,['hash'],['hash-lookup']
Security,_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 18:35:26.517 INFO MarkDuplicatesSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 18:35:26.517 INFO MarkDuplicatesSpark - Deflater: IntelDeflater; 18:35:26.517 INFO MarkDuplicatesSpark - Inflater: IntelInflater; 18:35:26.517 INFO MarkDuplicatesSpark - GCS max retries/reopens: 20; 18:35:26.517 INFO MarkDuplicatesSpark - Requester pays: disabled; 18:35:26.517 INFO MarkDuplicatesSpark - Initializing engine; 18:35:26.517 INFO MarkDuplicatesSpark - Done initializing engine; WARNING: An illegal reflective access operation has occurred; WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/user/wup/miniconda3/envs/gatk/share/gatk4-4.1.8.1-0/gatk-package-4.1.8.1-local.jar) to method java.nio.Bits.unaligned(); WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform; WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations; WARNING: All illegal access operations will be denied in a future release; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; 20/10/08 18:35:27 INFO SparkContext: Running Spark version 2.4.5; 18:35:27.640 WARN NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 20/10/08 18:35:27 INFO SparkContext: Submitted application: MarkDuplicatesSpark; 20/10/08 18:35:27 INFO SecurityManager: Changing view acls to: wup; 20/10/08 18:35:27 INFO SecurityManager: Changing modify acls to: wup; 20/10/08 18:35:27 INFO SecurityManager: Changing view acls groups to: ; 20/10/08 18:35:27 INFO SecurityManager: Changing modify acls groups to: ; 20/10/08 18:35:27 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(wup); groups with view permissions: Set(); users with modify permissions: Set(wup); groups with modify permissions: Set(); 20/10/08 18:35:28 INFO Utils: Suc,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6875:2317,access,access,2317,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6875,3,['access'],['access']
Security,"_CLASSPATH=$($HADOOP_HOME/bin/hadoop classpath). TEST_DIR=""hdfs://cromwellhadooptest:8020/user/hadoop/gatk/small""; COMMON_DIR=""hdfs://cromwellhadooptest:8020/user/hadoop/gatk/common""; INPUT_DIR=""$TEST_DIR/input""; OUTPUT_DIR=""$TEST_DIR/output"". input_bam=""$INPUT_DIR/small_CEUTrio.HiSeq.WGS.b37.NA12878.20.21.bam""; output_vcf_basename=""$OUTPUT_DIR/CEUTrio.HiSeq.WGS.b37.NA12878.20.21"". ref_fasta=""$COMMON_DIR/human_g1k_v37.20.21.fasta""; known_sites=""$COMMON_DIR/dbsnp_138.b37.20.21.vcf"". gatk ReadsPipelineSpark \; -R ${ref_fasta} \; -I ${input_bam} \; -O ${output_vcf_basename}.vcf \; --known-sites ${known_sites} \; -pairHMM AVX_LOGLESS_CACHING \; --spark-verbosity DEBUG \; -- --spark-runner SPARK --spark-master yarn-cluster \; # --conf 'spark.submit.deployMode=cluster'; ```. #### Expected behavior. ReadsPipelineSpark should be able to resolve the hdfs file path: `hdfs://cromwellhadooptest:8020/user/hadoop/gatk/common/human_g1k_v37.20.21.fasta`. #### Actual behavior; The tool tries to access: `file:///user/hadoop/gatk/common/human_g1k_v37.20.21.fasta` even when the input is: `hdfs://cromwellhadooptest:8020/user/hadoop/gatk/common/human_g1k_v37.20.21.fasta`. Verified that the file is accesible through hdfs:; ```; (gatk) root@2e738717b9c1:/gatk/mnt# $HADOOP_HOME/bin/hdfs dfs -ls hdfs://cromwellhadooptest:8020/user/hadoop/gatk/common/human_g1k_v37.20.21.fasta; -rw-r--r-- 3 hadoop supergroup 113008112 2020-07-29 15:54 hdfs://cromwellhadooptest:8020/user/hadoop/gatk/common/human_g1k_v37.20.21.fasta; ```; When I specify input as: `hdfs://cromwellhadooptest/user/hadoop/gatk/common/human_g1k_v37.20.21.fasta`, (i.e. without the port) I get the same error. **Stack trace for this**:; ```; ***********************************************************************; A USER ERROR has occurred: The specified fasta file (file:///user/hadoop/gatk/common/human_g1k_v37.20.21.fasta) does not exist.; ***********************************************************************; org.broadinstitute.hellbe",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6730:1653,access,access,1653,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6730,1,['access'],['access']
Security,"_SIZE : 131072; 17:43:53.163 INFO ValidateVariants - Defaults.REFERENCE_FASTA : null; 17:43:53.163 INFO ValidateVariants - Defaults.SAM_FLAG_FIELD_FORMAT : DECIMAL; 17:43:53.163 INFO ValidateVariants - Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 17:43:53.163 INFO ValidateVariants - Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 17:43:53.163 INFO ValidateVariants - Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 17:43:53.163 INFO ValidateVariants - Defaults.USE_CRAM_REF_DOWNLOAD : false; 17:43:53.163 INFO ValidateVariants - Deflater IntelDeflater; 17:43:53.163 INFO ValidateVariants - Inflater IntelInflater; 17:43:53.163 INFO ValidateVariants - Initializing engine; 17:43:53.270 INFO FeatureManager - Using codec VCFCodec to read file file:///Users/louisb/Workspace/gatk/src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleGood.vcf; 17:43:53.287 INFO FeatureManager - Using codec VCFCodec to read file file:///Users/louisb/Workspace/gatk/src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleGood.vcf; 17:43:53.291 WARN IndexUtils - Feature file ""/Users/louisb/Workspace/gatk/src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleGood.vcf"" appears to contain no sequence dictionary. Attempting to retrieve a sequence dictionary from the associated index file; 17:43:53.293 INFO ValidateVariants - Done initializing engine; 17:43:53.294 INFO ProgressMeter - Starting traversal; 17:43:53.294 INFO ProgressMeter - Current Locus Elapsed Minutes Records Processed Records/Minute; 17:43:53.302 INFO ValidateVariants - Shutting down engine; [March 21, 2017 5:43:53 PM EDT] org.broadinstitute.hellbender.tools.walkers.variantutils.ValidateVariants done. Elapsed time: 0.00 minutes.; Runtime.totalMemory()=194510848; java.lang.IllegalArgumentException: Illegal base [] seen in the allele; 	at htsjdk.variant.variantcontext.Allele.create(Allele.java:231); 	at htsjd",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2509:3541,Validat,ValidateVariants,3541,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2509,2,"['Validat', 'validat']","['ValidateVariants', 'validationExampleGood']"
Security,"_TEST_PROJECT and HELLBENDER_JSON_SERVICE_ACCOUNT_KEY must be set or the GCS hadoop connector will not be configured properly; 12:33:52.162 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/share/FGI2017B/pub/gatk-4.1.0.0/gatk-package-4.1.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; 12:33:53.793 INFO CreateReadCountPanelOfNormals - ------------------------------------------------------------; 12:33:53.794 INFO CreateReadCountPanelOfNormals - The Genome Analysis Toolkit (GATK) v4.1.0.0; 12:33:53.794 INFO CreateReadCountPanelOfNormals - For support and documentation go to https://software.broadinstitute.org/gatk/; 12:33:53.797 INFO CreateReadCountPanelOfNormals - Initializing engine; 12:33:53.797 INFO CreateReadCountPanelOfNormals - Done initializing engine; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; 19/02/18 12:33:53 INFO SparkContext: Running Spark version 2.2.0; WARNING: An illegal reflective access operation has occurred; WARNING: Illegal reflective access by org.apache.hadoop.security.authentication.util.KerberosUtil (file:/share/FGI2017B/pub/gatk-4.1.0.0/gatk-package-4.1.0.0-local.jar) to method sun.security.krb5.Config.getInstance(); WARNING: Please consider reporting this to the maintainers of org.apache.hadoop.security.authentication.util.KerberosUtil; WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations; WARNING: All illegal access operations will be denied in a future release; 12:33:54.187 WARN NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 12:33:54.263 INFO CreateReadCountPanelOfNormals - Shutting down engine; [February 18, 2019 at 12:33:54 PM CST] org.broadinstitute.hellbender.tools.copynumber.CreateReadCountPanelOfNormals done. Elapsed time: 0.04 minutes.; Runtime.totalMemory()=2147483648; Exception in thread ""main"" java.lang.ExceptionInInitializerError; 	at or",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5686:1424,access,access,1424,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5686,2,['access'],['access']
Security,_async_io_write_tribble=false -Dsamjdk.compression_level=2 --conf spark.kryoserializer.buffer.max=512m --conf spark.yarn.executor.memoryOverhead=600 /root/gatk-4.0.7.0/gatk-package-4.0.7.0-spark.jar PrintReadsSpark -I ../6484_snippet.bam -O ../output.bam --spark-master spark://10.0.0.21:7077; SLF4J: Class path contains multiple SLF4J bindings.; SLF4J: Found binding in [jar:file:/usr/hdp/2.6.3.40-13/spark2/jars/slf4j-log4j12-1.7.16.jar!/org/slf4j/impl/StaticLoggerBinder.class]; SLF4J: Found binding in [jar:file:/usr/hdp/2.6.3.40-13/spark_llap/spark-llap-assembly-1.0.0.2.6.3.40-13.jar!/org/slf4j/impl/StaticLoggerBinder.class]; SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.; SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]; java.lang.NoClassDefFoundError: org/apache/logging/log4j/core/appender/AbstractAppender; at java.lang.ClassLoader.defineClass1(Native Method); at java.lang.ClassLoader.defineClass(ClassLoader.java:763); at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142); at java.net.URLClassLoader.defineClass(URLClassLoader.java:467); at java.net.URLClassLoader.access$100(URLClassLoader.java:73); at java.net.URLClassLoader$1.run(URLClassLoader.java:368); at java.net.URLClassLoader$1.run(URLClassLoader.java:362); at java.security.AccessController.doPrivileged(Native Method); at java.net.URLClassLoader.findClass(URLClassLoader.java:361); at java.lang.ClassLoader.loadClass(ClassLoader.java:424); at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:349); at java.lang.ClassLoader.loadClass(ClassLoader.java:411); at java.lang.ClassLoader.loadClass(ClassLoader.java:357); at org.apache.logging.log4j.core.config.plugins.util.PluginRegistry.decodeCacheFiles(PluginRegistry.java:181); at org.apache.logging.log4j.core.config.plugins.util.PluginRegistry.loadFromMainClassLoader(PluginRegistry.java:119); at org.apache.logging.log4j.core.config.plugins.util.PluginManager.collectPlugins(PluginManager.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5126:2581,secur,security,2581,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5126,1,['secur'],['security']
Security,_nio_fixes; 10:56:25.360 WARN GermlineCNVCaller -. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. Warning: GermlineCNVCaller is a BETA tool and is not yet ready for use in production. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. 10:56:25.361 INFO GermlineCNVCaller - Initializing engine; 10:56:54.347 INFO GermlineCNVCaller - Done initializing engine; log4j:WARN No appenders could be found for logger (org.broadinstitute.hdf5.HDF5Library).; log4j:WARN Please initialize the log4j system properly.; log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.; 10:56:55.287 INFO GermlineCNVCaller - Retrieving intervals from first read-count file (hdf5/grexome0426.hdf5)...; 10:56:55.384 INFO GermlineCNVCaller - No GC-content annotations for intervals found; explicit GC-bias correction will not be performed...; 10:56:55.482 INFO GermlineCNVCaller - Running the tool in the COHORT mode...; 10:56:55.485 INFO GermlineCNVCaller - Validating and aggregating data from input read-count files...; 10:56:55.511 INFO GermlineCNVCaller - Aggregating read-count file hdf5/grexome0426.hdf5 (1 / 387); 10:56:55.812 INFO GermlineCNVCaller - Aggregating read-count file hdf5/grexome0342.hdf5 (2 / 387); 10:56:56.274 INFO GermlineCNVCaller - Aggregating read-count file hdf5/grexome0316.hdf5 (3 / 387); 10:56:56.635 INFO GermlineCNVCaller - Aggregating read-count file hdf5/grexome0338.hdf5 (4 / 387); 10:56:57.092 INFO GermlineCNVCaller - Aggregating read-count file hdf5/grexome0360.hdf5 (5 / 387); 10:56:57.728 INFO GermlineCNVCaller - Aggregating read-count file hdf5/grexome0384.hdf5 (6 / 387); 10:56:58.144 INFO GermlineCNVCaller - Aggregating read-count file hdf5/grexome0213.hdf5 (7 / 387); 10:56:58.681 INFO GermlineCNVCaller - Aggregating read-count file hdf5/grexome0347.hdf5 (8 / 387); 10:56:59.192 INFO GermlineCNVCaller - Aggregating read-count file hdf5/grexome0125.hdf5 (9 / 387); 10:56:59.643 INFO GermlineCNVCaller - Aggregating read-count ,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5053:3460,Validat,Validating,3460,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5053,1,['Validat'],['Validating']
Security,"`CloudStorageReadChannel.create()` appears to do a GCS access outside of the retry mechanism in `CloudStorageReadChannel.read()`. It calls the constructor, which calls `CloudStorageReadChannel.fetchSize()`, which does a `gcsStorage.get(file)` followed by a `getSize()`. . We are seeing 503 failures specifically from the GCS access in `CloudStorageReadChannel.fetchSize()`:. ```; com.google.cloud.storage.StorageException: 503 Service Unavailable; at com.google.cloud.storage.spi.v1.HttpStorageRpc.translate(HttpStorageRpc.java:189); at com.google.cloud.storage.spi.v1.HttpStorageRpc.get(HttpStorageRpc.java:335); at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:191); at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:188); at shaded.cloud_nio.com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:94); at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:54); at com.google.cloud.storage.StorageImpl.get(StorageImpl.java:188); at com.google.cloud.storage.StorageImpl.get(StorageImpl.java:202); at com.google.cloud.storage.contrib.nio.CloudStorageReadChannel.fetchSize(CloudStorageReadChannel.java:234); at com.google.cloud.storage.contrib.nio.CloudStorageReadChannel.<init>(CloudStorageReadChannel.java:78); at com.google.cloud.storage.contrib.nio.CloudStorageReadChannel.create(CloudStorageReadChannel.java:68); at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.newReadChannel(CloudStorageFileSystemProvider.java:304); at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.newByteChannel(CloudStorageFileSystemProvider.java:265); at java.nio.file.Files.newByteChannel(Files.java:361); at java.nio.file.Files.newByteChannel(Files.java:407); at htsjdk.samtools.seekablestream.SeekablePathStream.<init>(SeekablePathStream.java:41); at htsjdk.samtools.seekablestream.SeekableStreamFactory$DefaultSeekableStreamFactory.getStreamFor(SeekableStreamFactory.java:101); at htsjdk.tribble.readers.Ta",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3253:55,access,access,55,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3253,2,['access'],['access']
Security,`DataSourceUtils` contains string constants for fields in the config file (e.g. `CONFIG_FILE_FIELD_NAME_NAME`). These should be rolled into an enum together. This will facilitate file validation by enabling them to be iterated over automatically using the enum's built in methods.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5465:184,validat,validation,184,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5465,1,['validat'],['validation']
Security,"`GATKReadFilterPluginDescriptor.getAllInstances()` returns only the filters provided by the user, but I expect it to return the default ones. I know that they are added to the merged filter in `getMergedReadFilter`, but this does not allow to retrieve it as a list. In addition, there is no way to access the default filters provided. I suggest to move the code to merge into the same list the default and the user-provided filters to `getAllInstances()` and use that list in the `getMergedReadFilter`. ## EDITED:; The contract of `getAllInstances()` says that it should not include the default ones, so I propose a new specific method for retrieval.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2362:298,access,access,298,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2362,1,['access'],['access']
Security,"`GATKTool` uses stricter sequence dictionary validation settings for CRAM vs. reference than for non-CRAM vs. reference:. ```; if ( hasCramInput() ) {; // Use stricter validation for CRAM vs. the reference; SequenceDictionaryUtils.validateCRAMDictionaryAgainstReference(refDict, readDict);; }; else {; // Use standard validation settings for non-CRAM reads input vs. the reference; SequenceDictionaryUtils.validateDictionaries(""reference"", refDict, ""reads"", readDict);; }; ```. `GATKSparkTool.validateToolInputs()` should be patched to do the same, AFTER https://github.com/broadinstitute/gatk/issues/966 is done and cram support is in a usable state.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1179:45,validat,validation,45,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1179,6,['validat'],"['validateCRAMDictionaryAgainstReference', 'validateDictionaries', 'validateToolInputs', 'validation']"
Security,"`HashedListTargetCollection` sorts targets by `IntervalUtils.LEXICOGRAPHICAL_ORDER_COMPARATOR` i.e. ASCII order. Any tool that uses this class to store its targets outputs chromosomes in the order 1, 10, 11 . . . 19, 2, 20, 21, 22, 3 . . .",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1754:1,Hash,HashedListTargetCollection,1,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1754,1,['Hash'],['HashedListTargetCollection']
Security,`LoadReadsFromFileFn` has a `ValidationStringency` argument that is currently ignored. This line needs to be changed to pass in a customized SamReaderFactory that respects validation . ```; ReadsDataSource bam = new ReadsDataSource(c.element());; ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/745:29,Validat,ValidationStringency,29,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/745,2,"['Validat', 'validat']","['ValidationStringency', 'validation']"
Security,"`ValidateVariants` performs several checks that go above and beyond what the VCF spec requires for VCF files (e.g. throwing an exception if a variant has an alt allele but has a genotype of hom ref [as found by this user](https://gatk.broadinstitute.org/hc/en-us/community/posts/360061452132-GATK4-RNAseq-short-variant-discovery-SNPs-Indels-)). This is good - it helps catch logic errors in our and others' pipelines. . However, we should add a flag to `ValidateVariants` that will cause it to validate solely based on the VCF spec and not the more strict guidelines.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6553:1,Validat,ValidateVariants,1,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6553,3,"['Validat', 'validat']","['ValidateVariants', 'validate']"
Security,"`ValidateVariants` requires a large amount of memory (>16Gb) to validate a GVCF when another GVCF is used as the interval list. This is not the case if a regular interval list is used instead. This comes up in the production `ReblockGVCFs` pipeline since we validate the reblocked GVCF using the input (unreblocked) GVCF as the interval list to validate over (with `-L`). For now we can just use larger memory machines to run this tool, but it is confusing to me why using a ~4Gb GVCF as an interval list would cause such a large increase in memory requirement.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8608:1,Validat,ValidateVariants,1,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8608,4,"['Validat', 'validat']","['ValidateVariants', 'validate']"
Security,"`VariantWalker` and `VariantContext` do not do variant validation at parse-time. This causes awkward errors on invalid files like the one found here:; https://gatkforums.broadinstitute.org/gatk/discussion/23809/oncotator-for-build-hg38. It would be best if there was a way to properly validate the variants before parsing them. `ValidateVariants` currently doesn't properly work when given default options (#5862). When #5862 is fixed, this may be ignored - I think validating at run-time when iterating over variants may add too much overhead.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5867:55,validat,validation,55,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5867,4,"['Validat', 'validat']","['ValidateVariants', 'validate', 'validating', 'validation']"
Security,"`ah_var_store` edition: Allows hard-filtering based on a maximum number of alt alleles [VS-1334], as well as fixing GATK Docker image building to use image IDs rather than git hashes [VS-1357]. Integration test _mostly_ successful [here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/5d021859-5971-4fd7-8451-086c224fdb00). `GvsQuickstartIntegration` failed with:. ```; The bytes observed (89733530) for 'ExtractFilterTask.GvsCreateFilterSet.BigQuery Query Scanned' differ from those expected (85119360); FAIL!!! The relative difference between these is 0.0514208, which is greater than the allowed tolerance (0.05); ```. Successful tieout run [here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/04b840f9-9779-48d6-8faa-4425d67ddadb). [VS-1334]: https://broadworkbench.atlassian.net/browse/VS-1334?atlOrigin=eyJpIjoiNWRkNTljNzYxNjVmNDY3MDlhMDU5Y2ZhYzA5YTRkZjUiLCJwIjoiZ2l0aHViLWNvbS1KU1cifQ; [VS-1357]: https://broadworkbench.atlassian.net/browse/VS-1357?atlOrigin=eyJpIjoiNWRkNTljNzYxNjVmNDY3MDlhMDU5Y2ZhYzA5YTRkZjUiLCJwIjoiZ2l0aHViLWNvbS1KU1cifQ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8806:176,hash,hashes,176,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8806,1,['hash'],['hashes']
Security,"`mapred.max.split.size` is currently hardcoded to 10485760 in ReadsSparkSource. It should be exposed as a parameter that can be set at the command line since different values are better for different tools. It's a deprecated property, so it should probably be replaced with the new `mapreduce.input.fileinputformat.split.maxsize` instead.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1064:93,expose,exposed,93,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1064,1,['expose'],['exposed']
Security,`serializeToVcfString` should not be be in the interface for Funcotation (see `Funcotation.java`). That should be the job of the VCFOutputRenderer to sanitize any strings. A Funcotation should not care whether it is being rendered to a VCF or MAF. It's poor separation of concerns.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4797:150,sanitiz,sanitize,150,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4797,1,['sanitiz'],['sanitize']
Security,"a:1336); at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:912); at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:912); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1899); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1899); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); at org.apache.spark.scheduler.Task.run(Task.scala:86); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748); 00:11:09.632 WARN TaskSetManager:66 - Lost task 15.0 in stage 1.0 (TID 519, localhost): java.lang.IllegalStateException: Duplicate key [B@4e233a3c; at java.util.stream.Collectors.lambda$throwingMerger$0(Collectors.java:133); at java.util.HashMap.merge(HashMap.java:1253); at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1320); at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.PairHMMLikelihoodCalculationEngine.buildGapContinuationPenalties(PairHMMLikelihoodCalculat; ionEngine.java:304); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.PairHMMLikelihoodCalculationEngine.computeReadLikelihoods(PairHMMLikelihoodCalculationEngi; ne.java:253); at org.broadinstitute.hellbe",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3018:5516,Hash,HashMap,5516,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3018,1,['Hash'],['HashMap']
Security,accept(ForEachOps.java:183) ; at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195) ; at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195) ; at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1655) ; at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484) ; at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474) ; at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150) ; at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173) ; at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234) ; at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:497) ; at org.broadinstitute.hellbender.tools.funcotator.FilterFuncotations.lambda$getMatchingFilters$2(FilterFuncotations.java:192) ; at java.base/java.util.HashMap$Values.forEach(HashMap.java:976) ; at org.broadinstitute.hellbender.tools.funcotator.FilterFuncotations.getMatchingFilters(FilterFuncotations.java:191) ; at org.broadinstitute.hellbender.tools.funcotator.FilterFuncotations.secondPassApply(FilterFuncotations.java:174) ; at org.broadinstitute.hellbender.engine.TwoPassVariantWalker.nthPassApply(TwoPassVariantWalker.java:19) ; at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverse$0(MultiplePassVariantWalker.java:40) ; at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverseVariants$1(MultiplePassVariantWalker.java:77) ; at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183) ; at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:177) ; at java.base/java.util.Iterator.forEachRemaining(Iterator.java:133) ; at java.base/java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801) ; at java.base/java.util.stream,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7504:5820,Hash,HashMap,5820,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7504,1,['Hash'],['HashMap']
Security,"actually investigate the formatting error. Unfortunately my formatting error isn't the same as reported in the other post. I have 105 error in which the 1st alternative allele is a spanning deletion and the 2nd (and 3rd) is either an indel or snp. It's true that the 2nd and 3rd allele is actually not found in my samples. I even have 7 occurances in which the 1st allele (spanning deletion) has allele frequency 1.00. my code is the following for GenotypeGVCFs:. java -Xms32G -Xmx32G -jar ${gatk4} GenotypeGVCFs -R ${ref} -V ${pipeline}/${name}\_v4.1.6.0.g.vcf.gz -O ${vcf}/${name}\_v4.1.6.0.vcf.gz -L ${pipeline}/${name}\_intervals.list 2> ${log}/${name}\_v4.1.6.0\_genotype.log. for ValidateVariants:. java -Xms10G -Xmx10G -jar ${gatk4} ValidateVariants -R ${ref} -V ${name}\_v4.1.6.0.vcf.gz -L ${pipeline}/${name}\_intervals.list --warn-on-errors 2> ${log}/${name}\_v4.1.6.0\_genotype\_valivar.log. the warning in ValidateVariants and the site look like this:. 14:12:15.126 WARN ValidateVariants - \*\*\*\*\* Input 1st\_v4.1.6.0.vcf.gz fails strict validation of type ALL: one or more of the ALT allele(s) for the record at position chr\_1:1088200 are not observed at all in the sample genotypes \*\*\*\*\* ; ; chr\_1 1088200 . T \*,TAAAAAAAAAAAA 64.39 . AC=8,0;AF=0.667,0.00;AN=12;DP=118;ExcessHet=3.0103;FS=0.000;InbreedingCoeff=0.4286;MLEAC=7,7;MLEAF=0.583,0.583;MQ=58.73;QD=32.19;SOR=2.303 GT:AD:DP:GQ:PL ./.:9,0,0:9:.:0,0,0,0,0,0 0/0:9,0,0:9:0:0,0,113,0,113,113 ./.:10,0,0:10:.:0,0,0,0,0,0 ./.:5,0,0:5:.:0,0,0,0,0,0 1/1:0,0,1:1:0:225,15,0,15,0,0 ./.:0,0,0:0:.:0,0,0,0,0,0 ./.:12,0,0:12:.:0,0,0,0,0,0 ./.:8,0,0:8:.:0,0,0,0,0,0 0/0:3,0,0:3:0:0,0,43,0,43,43 ./.:7,0,0:7:.:0,0,0,0,0,0 ./.:1,0,0:1:.:0,0,0,0,0,0 ./.:0,0,0:0:.:0,0,0,0,0,0 ./.:3,0,0:3:.:0,0,0,0,0,0 ./.:7,0,0:7:.:0,0,0,0,0,0 1/1:0,0,0:0:0:45,3,0,3,0,0 ./.:0,0,0 1/1:0,0,1:1:0:45,3,0,3,0,0 1/1:0,0,0:0:0:267,18,0,18,0,0 ./.:9,0,0:9:.:0,0,0,0,0,0 ; . The exactly the same happens when I run GenotypeGVCFs in --include-non-variant-site",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6630:1905,Validat,ValidateVariants,1905,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6630,1,['Validat'],['ValidateVariants']
Security,add IBM. @frank-y-liu please review (I can't assign to you because you need write access for that),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1766:82,access,access,82,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1766,1,['access'],['access']
Security,add logging and validate vat to echo callset branch,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8770:16,validat,validate,16,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8770,1,['validat'],['validate']
Security,added option for ValidateBasicSomaticShortMutations to output a vcf,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4999:17,Validat,ValidateBasicSomaticShortMutations,17,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4999,1,['Validat'],['ValidateBasicSomaticShortMutations']
Security,adding git hash dependent version number,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/196:11,hash,hash,11,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/196,1,['hash'],['hash']
Security,adds arg validation to make sure margin is non-negative in SimpleInte…,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3794:9,validat,validation,9,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3794,1,['validat'],['validation']
Security,"adinstitute/gsa-unstable/issues/1053#issuecomment-222214083). Still a thing. No work has been done here AFAIK. ---. @vdauwera commented on [Mon Nov 14 2016](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-260465013). This seems like fairly low-hanging fruit -- @ronlevine . ---. @ronlevine commented on [Wed Nov 23 2016](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-262613152). @ldgauthier Shouldn't a locus without genotypes bypass `AC` validation, given it's defined as: `Allele count in genotypes, for each ALT allele, in the same order as listed`?. ---. @ldgauthier commented on [Wed Nov 23 2016](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-262613997). Agreed. ---. @ronlevine commented on [Thu Nov 24 2016](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-262635204). The change should be a lot simpler than proposed. The code can validate the number of alleles before it checks for the presence of genotypes in [VariantContext#validateChromosomeCounts](https://github.com/samtools/htsjdk/blob/master/src/main/java/htsjdk/variant/variantcontext/VariantContext.java#L1236). . ---. @ldgauthier commented on [Mon Nov 28 2016](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-263277972). Sorry, I needed to refresh my memory. I actually don't want to bypass AC validation for variants without genotypes, but I think you already figured that out. My proposal was more general, but you're right -- AC and AF should always have the same count as alt alleles and we don't need to check the header for that. When this came up (a year and a half ago!) we were thinking about validating all the info field annotations. ---. @ronlevine commented on [Mon Nov 28 2016](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-263280085). That's exactly what I did in https://github.com/samtools/htsjdk/pull/759. I can expand this to all INFO field annotations. ---. @ld",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2507:5843,validat,validate,5843,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2507,2,['validat'],"['validate', 'validateChromosomeCounts']"
Security,ain.java:275); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:755); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:119); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.lang.IllegalArgumentException: two input alignments' overlap on read consumes completely one of them.	1_1097_chrUn_JTFH01000492v1_decoy:501-1597_+_1097M6H_60_1_1092_O	483_612_chr17:26962677-26962806_-_482S130M491S_60_-1_281_S; 	at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:681); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.prototype.ContigAlignmentsModifier.removeOverlap(ContigAlignmentsModifier.java:36); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.prototype.AssemblyContigAlignmentSignatureClassifier.lambda$processContigsWithTwoAlignments$e28aa838$1(AssemblyContigAlignmentSignatureClassifier.java:114); 	at org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction$1.apply(JavaPairRDD.scala:1040); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:462); 	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); 	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); 	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at org.apache.spark.util.collection.ExternalSor,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4141:13118,validat,validateArg,13118,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4141,1,['validat'],['validateArg']
Security,"alArgumentException` if a reference isn't provided. . It should be a `UserException`. I don't know but I think there may be modes that don't require the reference, so it may need to give a smart error message. ```; gatk-launch ValidateVariants --variant src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleGood.vcf; Using GATK wrapper script /Users/louisb/Workspace/gatk/build/install/gatk/bin/gatk; Running:; /Users/louisb/Workspace/gatk/build/install/gatk/bin/gatk ValidateVariants --variant src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleGood.vcf; 17:43:53.119 INFO NativeLibraryLoader - Loading libgkl_compression.dylib from jar:file:/Users/louisb/Workspace/gatk/build/install/gatk/lib/gkl-0.4.1.jar!/com/intel/gkl/native/libgkl_compression.dylib; [March 21, 2017 5:43:53 PM EDT] org.broadinstitute.hellbender.tools.walkers.variantutils.ValidateVariants --variant src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleGood.vcf --doNotValidateFilteredRecords false --warnOnErrors false --interval_set_rule UNION --interval_padding 0 --interval_exclusion_padding 0 --readValidationStringency SILENT --secondsBetweenProgressUpdates 10.0 --disableSequenceDictionaryValidation false --createOutputBamIndex true --createOutputBamMD5 false --createOutputVariantIndex true --createOutputVariantMD5 false --lenient false --addOutputSAMProgramRecord true --cloudPrefetchBuffer 40 --cloudIndexPrefetchBuffer -1 --disableBamIndexCaching false --help false --version false --showHidden false --verbosity INFO --QUIET false --use_jdk_deflater false --use_jdk_inflater false --disableToolDefaultReadFilters false; [March 21, 2017 5:43:53 PM EDT] Executing as louisb@WMD2A-31E on Mac OS X 10.11.6 x86_64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_112-b16; Version: Version:4.alpha.2-189-g724fbd0-SNAPSHOT; 17:43:53.162 INFO ValidateVariants - Defaults.BUFFER_SIZE : 131072; 17:",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2509:967,Validat,ValidateVariants,967,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2509,3,"['Validat', 'validat']","['ValidateVariants', 'validationExampleGood']"
Security,"allow me to look at individual shards running ExtractTask if I ran GvsExtractCallsetPgenMerged. Job Manager would be an alternative for this, but it seems to be pretty much unusable for even moderately-sized jobs.); 4. Run GvsExtractCallset on the newly created cohort, making sure to use the same parameters, including scatter count. This will generate VCF files that we can use to compare to the PGEN files created during the previous step for validation.; 5. Run GvsExtractCallsetPgenMerged with the same parameters used to run GvsExtractCallsetPgen in Step 3. This will use call-caching for the extract steps and then merge the PGEN files by chromosome. (Running it this way is maybe not the ideal way to do this, but it's what I've been doing for reasons described in the parenthetical in Step 3).; 6. Create list files, by file type, containing the gs:// URIs for the .pgen, .psam, and .pvar.zst files created in Step 3, along with the .vcf.gz files created in Step 4. Upload them to the workspace to use for validation.; 7. Run ComparePgenAndVcfScatter using the file lists as inputs. If there are any differences, it will output files that contain those differences. If there are no diff files generated, the files match. ComparePgenAndVcfScatter is a workflow I wrote that converts a list of .pgen, .psam, and .pvar.zst files generated by GvsExtractCallsetPgen into .vcf.gz files and then compares those files to a list of .vcf.gz files generated by GvsExtractCallset. . It ignores basically everything except genotypes, because PGENs do not store all the other fields and annotations that the VCFs might have. It will also skip over any sites in the VCFs with >254 alleles because those will not be present in the PGEN files. Any differences are written to diff files, in the form of the differing lines in the VCFs being compared. The code for this comparison tool lives [here](https://github.com/KevinCLydon/pgen_vcf_comparator) in a repo I created under my GitHub account. (I didn't crea",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8708:11597,validat,validation,11597,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8708,1,['validat'],['validation']
Security,amesystem.concatInt(FSNamesystem.java:2257); > at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.concat(FSNamesystem.java:2219); > at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.concat(NameNodeRpcServer.java:829); > at org.apache.hadoop.hdfs.server.namenode.AuthorizationProviderProxyClientProtocol.concat(AuthorizationProviderProxyClientProtocol.java:285); > at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.concat(ClientNamenodeProtocolServerSideTranslatorPB.java:580); > at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java); > at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:617); > at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1073); > at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2278); > at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2274); > at java.security.AccessController.doPrivileged(Native Method); > at javax.security.auth.Subject.doAs(Subject.java:422); > at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1924); > at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2272); > ; > org.broadinstitute.hellbender.exceptions.UserException$CouldNotCreateOutputFile: Couldn't write file hdfs://cloudera08/gatk-test2/WES2019-022_S4_out.vcf because writing failed with exception concat: target file /gatk-test2/WES2019-022_S4_out.vcf.parts/output is empty; > at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.concatInternal(FSNamesystem.java:2303); > at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.concatInt(FSNamesystem.java:2257). #### Steps to reproduce; The user's command line was. > nohup /opt/gatk/gatk-4.1.4.0/gatk ReadsPipelineSpark --spark-runner SPARK --spark-master yarn --spark-submit-command spark2-submit -I hdfs://cloudera08/gatk-test2/WES2019-022_S4.bam -O hdfs://cloudera08/gatk-test2/WES2019-022_S4_o,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6218:1831,Access,AccessController,1831,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6218,1,['Access'],['AccessController']
Security,an exception. * What went wrong:; Execution failed for task ':gatkTabComplete'.; > Javadoc generation failed. Generated Javadoc options file (useful for troubleshooting): '/vsc-hard-mounts/leuven-data/304/vsc30484/git/gatk/build/tmp/gatkTabComplete/javadoc.options'. * Try:; Run with --info or --debug option to get more log output. * Exception is:; org.gradle.api.tasks.TaskExecutionException: Execution failed for task ':gatkTabComplete'.; at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.executeActions(ExecuteActionsTaskExecuter.java:69); at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.execute(ExecuteActionsTaskExecuter.java:46); at org.gradle.api.internal.tasks.execution.PostExecutionAnalysisTaskExecuter.execute(PostExecutionAnalysisTaskExecuter.java:35); at org.gradle.api.internal.tasks.execution.SkipUpToDateTaskExecuter.execute(SkipUpToDateTaskExecuter.java:64); at org.gradle.api.internal.tasks.execution.ValidatingTaskExecuter.execute(ValidatingTaskExecuter.java:58); at org.gradle.api.internal.tasks.execution.SkipEmptySourceFilesTaskExecuter.execute(SkipEmptySourceFilesTaskExecuter.java:52); at org.gradle.api.internal.tasks.execution.SkipTaskWithNoActionsExecuter.execute(SkipTaskWithNoActionsExecuter.java:52); at org.gradle.api.internal.tasks.execution.SkipOnlyIfTaskExecuter.execute(SkipOnlyIfTaskExecuter.java:53); at org.gradle.api.internal.tasks.execution.ExecuteAtMostOnceTaskExecuter.execute(ExecuteAtMostOnceTaskExecuter.java:43); at org.gradle.execution.taskgraph.DefaultTaskGraphExecuter$EventFiringTaskWorker.execute(DefaultTaskGraphExecuter.java:233); at org.gradle.execution.taskgraph.DefaultTaskGraphExecuter$EventFiringTaskWorker.execute(DefaultTaskGraphExecuter.java:215); at org.gradle.execution.taskgraph.AbstractTaskPlanExecutor$TaskExecutorWorker.processTask(AbstractTaskPlanExecutor.java:74); at org.gradle.execution.taskgraph.AbstractTaskPlanExecutor$TaskExecutorWorker.run(AbstractTaskPlanExecutor.java:55); at org.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4155:1536,Validat,ValidatingTaskExecuter,1536,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4155,1,['Validat'],['ValidatingTaskExecuter']
Security,"anager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).; 10:33:06.427 INFO ResourceUtils - ==============================================================; 10:33:06.427 INFO ResourceUtils - No custom resources configured for spark.driver.; 10:33:06.428 INFO ResourceUtils - ==============================================================; 10:33:06.428 INFO SparkContext - Submitted application: SortSamSpark; 10:33:06.446 INFO ResourceProfile - Default ResourceProfile created, executor resources: Map(memoryOverhead -> name: memoryOverhead, amount: 600, script: , vendor: , cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0); 10:33:06.454 INFO ResourceProfile - Limiting resource is cpu; 10:33:06.455 INFO ResourceProfileManager - Added ResourceProfile id: 0; 10:33:06.500 INFO SecurityManager - Changing view acls to: root; 10:33:06.501 INFO SecurityManager - Changing modify acls to: root; 10:33:06.501 INFO SecurityManager - Changing view acls groups to:; 10:33:06.502 INFO SecurityManager - Changing modify acls groups to:; 10:33:06.502 INFO SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); groups with view permissions: Set(); users with modify permissions: Set(root); groups with modify permissions: Set(); 10:33:06.755 INFO Utils - Successfully started service 'sparkDriver' on port 34861.; 10:33:06.784 INFO SparkEnv - Registering MapOutputTracker; 10:33:06.815 INFO SparkEnv - Registering BlockManagerMaster; 10:33:06.827 INFO BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information; 10:33:06.828 INFO BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up; 10:33:06.831 INFO SparkEnv - Registering BlockManagerMasterHeartbeat; 10:33:06.846 INFO DiskBlockManage",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8949:41780,Secur,SecurityManager,41780,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8949,1,['Secur'],['SecurityManager']
Security,ang.NoSuchMethodError: scala.collection.Seq.aggregate(Ljava/lang/Object;Lscala/Function2;Lscala/Function2;)Ljava/lang/Object;; at org.bdgenomics.adam.models.NonoverlappingRegions.mergeRegions(NonoverlappingRegions.scala:75); at org.bdgenomics.adam.models.NonoverlappingRegions.<init>(NonoverlappingRegions.scala:55); at org.bdgenomics.adam.models.NonoverlappingRegions$.apply(NonoverlappingRegions.scala:169); at org.bdgenomics.adam.util.TwoBitRecord$.apply(TwoBitFile.scala:193); at org.bdgenomics.adam.util.TwoBitFile$$anonfun$6.apply(TwoBitFile.scala:70); at org.bdgenomics.adam.util.TwoBitFile$$anonfun$6.apply(TwoBitFile.scala:70); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.immutable.HashMap$HashMap1.foreach(HashMap.scala:221); at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428); at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428); at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); at scala.collection.AbstractTraversable.map(Traversable.scala:104); at org.bdgenomics.adam.util.TwoBitFile.<init>(TwoBitFile.scala:70); at org.broadinstitute.hellbender.engine.spark.datasources.ReferenceTwoBitSource.<init>(ReferenceTwoBitSource.java:43); at org.broadinstitute.hellbender.engine.datasources.ReferenceMultiSource.<init>(ReferenceMultiSource.java:41); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.initializeReference(GATKSparkTool.java:353); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.initializeToolInputs(GATKSparkTool.java:320); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:311); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:38); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:108); at or,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2073:1217,Hash,HashMap,1217,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2073,2,['Hash'],"['HashMap', 'HashTrieMap']"
Security,"ants - Executing as zepengmu@midway2-login1.rcc.local on Linux v3.10.0-1127.8.2.el7.x86_64 amd64; 19:53:34.607 INFO ValidateVariants - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_45-b14; 19:53:34.607 INFO ValidateVariants - Start Date/Time: October 25, 2020 7:53:34 PM CDT; 19:53:34.607 INFO ValidateVariants - ------------------------------------------------------------; 19:53:34.607 INFO ValidateVariants - ------------------------------------------------------------; 19:53:34.607 INFO ValidateVariants - HTSJDK Version: 2.22.0; 19:53:34.607 INFO ValidateVariants - Picard Version: 2.22.8; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 19:53:34.608 INFO ValidateVariants - Deflater: IntelDeflater; 19:53:34.608 INFO ValidateVariants - Inflater: IntelInflater; 19:53:34.608 INFO ValidateVariants - GCS max retries/reopens: 20; 19:53:34.608 INFO ValidateVariants - Requester pays: disabled; 19:53:34.608 INFO ValidateVariants - Initializing engine; 19:53:35.169 INFO FeatureManager - Using codec VCFCodec to read file file://chr1-22.phased.rename.reheader.vcf.gz; 19:53:35.594 INFO ValidateVariants - Done initializing engine; 19:53:35.594 WARN ValidateVariants - IDS validation cannot be done because no DBSNP file was provided; 19:53:35.594 WARN ValidateVariants - Other possible validations will still be performed; 19:53:35.594 INFO ProgressMeter - Starting traversal; 19:53:35.595 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 19:53:35.660 INFO ValidateVariants - Shutting down engine; [October 25, 2020 7:53:35 PM CDT] org.broadinstitute.hellbender.tools.walkers.variantutils.ValidateVariants done. Elapsed time: 0.02 minutes.; Run",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6911:2403,Validat,ValidateVariants,2403,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6911,1,['Validat'],['ValidateVariants']
Security,"as a Selenocysteine edit. Look for the Selenocysteine; feature for the position of this on the genome; - cds_end_NF: the coding region end could not be confirmed; - cds_start_NF: the coding region start could not be confirmed; - mRNA_end_NF: the mRNA end could not be confirmed; - mRNA_start_NF: the mRNA start could not be confirmed.; - basic: the transcript is part of the gencode basic geneset. Comments. Lines may be commented out by the addition of a single # character at the start. These; lines should be ignored by your parser. Pragmas/Metadata. GTF files can contain meta-data. In the case of experimental meta-data these are ; noted by a #!. Those which are stable are noted by a ##. Meta data is a single key,; a space and then the value. Current meta data keys are:. * genome-build - Build identifier of the assembly e.g. GRCh37.p11; * genome-version - Version of this assembly e.g. GRCh37; * genome-date - The date of this assembly's release e.g. 2009-02; * genome-build-accession - The accession and source of this accession e.g. NCBI:GCA_000001405.14; * genebuild-last-updated - The date of the last genebuild update e.g. 2013-09. ------------------; Example GTF output; ------------------. #!genome-build GRCh38; 11 ensembl_havana gene 5422111 5423206 . + . gene_id ""ENSG00000167360""; gene_version ""4""; gene_name ""OR51Q1""; gene_source ""ensembl_havana""; gene_biotype ""protein_coding"";; 11 ensembl_havana transcript 5422111 5423206 . + . gene_id ""ENSG00000167360""; gene_version ""4""; transcript_id ""ENST00000300778""; transcript_version ""4""; gene_name ""OR51Q1""; gene_source ""ensembl_havana""; gene_biotype ""protein_coding""; transcript_name ""OR51Q1-001""; transcript_source ""ensembl_havana""; transcript_biotype ""protein_coding""; tag ""CCDS""; ccds_id ""CCDS31381"";; 11 ensembl_havana exon 5422111 5423206 . + . gene_id ""ENSG00000167360""; gene_version ""4""; transcript_id ""ENST00000300778""; transcript_version ""4""; exon_number ""1""; gene_name ""OR51Q1""; gene_source ""ensembl_havana""; gene_biotype """,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6488:6108,access,accession,6108,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6488,3,['access'],['accession']
Security,ass file major version 55; 	at org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:166); 	at org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:148); 	at org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:136); 	at org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:237); 	at org.apache.spark.util.ClosureCleaner$.getClassReader(ClosureCleaner.scala:49); 	at org.apache.spark.util.FieldAccessFinder$$anon$3$$anonfun$visitMethodInsn$2.apply(ClosureCleaner.scala:517); 	at org.apache.spark.util.FieldAccessFinder$$anon$3$$anonfun$visitMethodInsn$2.apply(ClosureCleaner.scala:500); 	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733); 	at scala.collection.mutable.HashMap$$anon$1$$anonfun$foreach$2.apply(HashMap.scala:134); 	at scala.collection.mutable.HashMap$$anon$1$$anonfun$foreach$2.apply(HashMap.scala:134); 	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236); 	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40); 	at scala.collection.mutable.HashMap$$anon$1.foreach(HashMap.scala:134); 	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732); 	at org.apache.spark.util.FieldAccessFinder$$anon$3.visitMethodInsn(ClosureCleaner.scala:500); 	at org.apache.xbean.asm6.ClassReader.readCode(ClassReader.java:2175); 	at org.apache.xbean.asm6.ClassReader.readMethod(ClassReader.java:1238); 	at org.apache.xbean.asm6.ClassReader.accept(ClassReader.java:631); 	at org.apache.xbean.asm6.ClassReader.accept(ClassReader.java:355); 	at org.apache.spark.util.ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$14.apply(ClosureCleaner.scala:307); 	at org.apache.spark.util.ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$14.apply(ClosureCleaner.scala:306); 	at scala.collection.immutable.List.foreach(List.scala:392); 	at org.apache.spark.util.ClosureCleaner$.org$apache$spark$util$ClosureCleaner$$clean(ClosureCleaner.scala:306),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7035:7009,Hash,HashMap,7009,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7035,1,['Hash'],['HashMap']
Security,at org.broadinstitute.hellbender.tools.HaplotypeCallerSpark.runTool(HaplotypeCallerSpark.java:115); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:353); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:38); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:116); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:179); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:198); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:121); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:142); at org.broadinstitute.hellbender.Main.main(Main.java:220); Caused by: java.lang.IllegalStateException: Duplicate key [B@4e233a3c; at java.util.stream.Collectors.lambda$throwingMerger$0(Collectors.java:133); at java.util.HashMap.merge(HashMap.java:1253); at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1320); at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.PairHMMLikelihoodCalculationEngine.buildGapContinuationPenalties(PairHMMLikelihoodCalculat; ionEngine.java:304); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.PairHMMLikelihoodCalculationEngine.computeReadLikelihoods(PairHMMLikelihoodCalculationEngi; ne.java:253); at org.broadinstitute.hellbe,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3018:16848,Hash,HashMap,16848,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3018,1,['Hash'],['HashMap']
Security,atk-package-4.0.7.0-spark.jar PrintReadsSpark -I ../6484_snippet.bam -O ../output.bam --spark-master spark://10.0.0.21:7077; SLF4J: Class path contains multiple SLF4J bindings.; SLF4J: Found binding in [jar:file:/usr/hdp/2.6.3.40-13/spark2/jars/slf4j-log4j12-1.7.16.jar!/org/slf4j/impl/StaticLoggerBinder.class]; SLF4J: Found binding in [jar:file:/usr/hdp/2.6.3.40-13/spark_llap/spark-llap-assembly-1.0.0.2.6.3.40-13.jar!/org/slf4j/impl/StaticLoggerBinder.class]; SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.; SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]; java.lang.NoClassDefFoundError: org/apache/logging/log4j/core/appender/AbstractAppender; at java.lang.ClassLoader.defineClass1(Native Method); at java.lang.ClassLoader.defineClass(ClassLoader.java:763); at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142); at java.net.URLClassLoader.defineClass(URLClassLoader.java:467); at java.net.URLClassLoader.access$100(URLClassLoader.java:73); at java.net.URLClassLoader$1.run(URLClassLoader.java:368); at java.net.URLClassLoader$1.run(URLClassLoader.java:362); at java.security.AccessController.doPrivileged(Native Method); at java.net.URLClassLoader.findClass(URLClassLoader.java:361); at java.lang.ClassLoader.loadClass(ClassLoader.java:424); at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:349); at java.lang.ClassLoader.loadClass(ClassLoader.java:411); at java.lang.ClassLoader.loadClass(ClassLoader.java:357); at org.apache.logging.log4j.core.config.plugins.util.PluginRegistry.decodeCacheFiles(PluginRegistry.java:181); at org.apache.logging.log4j.core.config.plugins.util.PluginRegistry.loadFromMainClassLoader(PluginRegistry.java:119); at org.apache.logging.log4j.core.config.plugins.util.PluginManager.collectPlugins(PluginManager.java:132); at org.apache.logging.log4j.core.pattern.PatternParser.<init>(PatternParser.java:131); at org.apache.logging.log4j.core.pattern.PatternParser.<init>(PatternP,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5126:2741,access,access,2741,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5126,1,['access'],['access']
Security,audit use of ReferenceSequenceFile and replace with ReferenceUtils.loadFastaDictionary(),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5180:0,audit,audit,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5180,1,['audit'],['audit']
Security,aults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : false; 18:30:54.424 INFO BwaAndMarkDuplicatesPipelineSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 18:30:54.424 INFO BwaAndMarkDuplicatesPipelineSpark - Deflater: IntelDeflater; 18:30:54.424 INFO BwaAndMarkDuplicatesPipelineSpark - Inflater: IntelInflater; 18:30:54.424 INFO BwaAndMarkDuplicatesPipelineSpark - GCS max retries/reopens: 20; 18:30:54.424 INFO BwaAndMarkDuplicatesPipelineSpark - Using google-cloud-java patch c035098b5e62cb4fe9155eff07ce88449a361f5d from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 18:30:54.424 INFO BwaAndMarkDuplicatesPipelineSpark - Initializing engine; 18:30:54.424 INFO BwaAndMarkDuplicatesPipelineSpark - Done initializing engine; 18/01/09 18:30:54 INFO spark.SparkContext: Running Spark version 2.2.0.cloudera1; 18/01/09 18:30:54 INFO spark.SparkContext: Submitted application: BwaAndMarkDuplicatesPipelineSpark; 18/01/09 18:30:54 INFO spark.SecurityManager: Changing view acls to: sun; 18/01/09 18:30:54 INFO spark.SecurityManager: Changing modify acls to: sun; 18/01/09 18:30:54 INFO spark.SecurityManager: Changing view acls groups to: ; 18/01/09 18:30:54 INFO spark.SecurityManager: Changing modify acls groups to: ; 18/01/09 18:30:54 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(sun); groups with view permissions: Set(); users with modify permissions: Set(sun); groups with modify permissions: Set(); 18/01/09 18:30:55 INFO util.Utils: Successfully started service 'sparkDriver' on port 38793.; 18/01/09 18:30:55 INFO spark.SparkEnv: Registering MapOutputTracker; 18/01/09 18:30:55 INFO spark.SparkEnv: Registering BlockManagerMaster; 18/01/09 18:30:55 INFO storage.BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information; 18/01/09 18:30:55 INFO storage.BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up; 18/01/09 18:30:55 INFO sto,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4112:5369,Secur,SecurityManager,5369,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4112,1,['Secur'],['SecurityManager']
Security,"aults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 16:51:57.770 INFO SparkGenomeReadCounts - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 16:51:57.770 INFO SparkGenomeReadCounts - Deflater: IntelDeflater; 16:51:57.770 INFO SparkGenomeReadCounts - Inflater: IntelInflater; 16:51:57.770 INFO SparkGenomeReadCounts - Initializing engine; 16:51:57.770 INFO SparkGenomeReadCounts - Done initializing engine; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; 17/07/21 16:51:58 INFO SparkContext: Running Spark version 2.0.2; 17/07/21 16:51:58 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 17/07/21 16:51:58 INFO SecurityManager: Changing view acls to: ameyner2; 17/07/21 16:51:58 INFO SecurityManager: Changing modify acls to: ameyner2; 17/07/21 16:51:58 INFO SecurityManager: Changing view acls groups to: ; 17/07/21 16:51:58 INFO SecurityManager: Changing modify acls groups to: ; 17/07/21 16:51:58 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(ameyner2); groups with view permissions: Set(); users with modify permissions: Set(ameyner2); groups with modify permissions: Set(); 17/07/21 16:51:58 INFO Utils: Successfully started service 'sparkDriver' on port 43815.; 17/07/21 16:51:58 INFO SparkEnv: Registering MapOutputTracker; 17/07/21 16:51:58 INFO SparkEnv: Registering BlockManagerMaster; 17/07/21 16:51:58 INFO DiskBlockManager: Created local directory at /tmp/ameyner2/blockmgr-d8bbd2bc-8366-4b98-a238-2d51da1689d1; 17/07/21 16:51:58 INFO MemoryStore: MemoryStore started with capacity 15.8 GB; 17/07/21 16:51:58 INFO SparkEnv: Registering OutputCommitCoordinator; 17/07/21 16:51:58 INFO Utils: Successfully started service 'SparkUI' on port 4040.; 17/07/21 16:51:58 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://192.41.105.80:4040; 17/07/21 16:51:58 INFO Executor: Starting executor ID driver o",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3360:3126,Secur,SecurityManager,3126,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3360,7,"['Secur', 'authenticat']","['SecurityManager', 'authentication']"
Security,bam \; --output gatk.split.bam \; > split.log 2>&1; ```. A tiny BAM file illustrating the problem is attached (it is gzipped to allow Github upload).; [100I_rna.bam.gz](https://github.com/broadinstitute/gatk/files/2456955/100I_rna.bam.gz). #### Actual behavior; Here is the stacktrace:; ```; ***********************************************************************. A USER ERROR has occurred: Badly formed genome unclippedLoc: Parameters to GenomeLocParser are incorrect:The stop position 3146412 is less than start 3146413 in contig chr20. ***********************************************************************; org.broadinstitute.hellbender.exceptions.UserException$MalformedGenomeLoc: Badly formed genome unclippedLoc: Parameters to GenomeLocParser are incorrect:The stop position 3146412 is less than start 3146413 in contig chr20; at org.broadinstitute.hellbender.utils.GenomeLocParser.vglHelper(GenomeLocParser.java:280); at org.broadinstitute.hellbender.utils.GenomeLocParser.validateGenomeLoc(GenomeLocParser.java:226); at org.broadinstitute.hellbender.utils.GenomeLocParser.createGenomeLoc(GenomeLocParser.java:185); at org.broadinstitute.hellbender.utils.GenomeLocParser.createGenomeLoc(GenomeLocParser.java:169); at org.broadinstitute.hellbender.utils.GenomeLocParser.createGenomeLoc(GenomeLocParser.java:150); at org.broadinstitute.hellbender.tools.walkers.rnaseq.OverhangFixingManager$SplitRead.setRead(OverhangFixingManager.java:402); at org.broadinstitute.hellbender.tools.walkers.rnaseq.OverhangFixingManager$SplitRead.<init>(OverhangFixingManager.java:396); at org.broadinstitute.hellbender.tools.walkers.rnaseq.OverhangFixingManager.getSplitRead(OverhangFixingManager.java:467); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.Collections$2.tryAdvance(Collections.java:4717); at java.util.Collections$2.forEachRemaining(Collections.java:4725); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.A,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5293:2265,validat,validateGenomeLoc,2265,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5293,1,['validat'],['validateGenomeLoc']
Security,"bgkl_compression.so from jar:file:/home/zepengmu/tools/gatk-4.1.8.0/gatk-package-4.1.8.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Oct 25, 2020 7:53:34 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 19:53:34.606 INFO ValidateVariants - ------------------------------------------------------------; 19:53:34.606 INFO ValidateVariants - The Genome Analysis Toolkit (GATK) v4.1.8.0; 19:53:34.606 INFO ValidateVariants - For support and documentation go to https://software.broadinstitute.org/gatk/; 19:53:34.607 INFO ValidateVariants - Executing as zepengmu@midway2-login1.rcc.local on Linux v3.10.0-1127.8.2.el7.x86_64 amd64; 19:53:34.607 INFO ValidateVariants - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_45-b14; 19:53:34.607 INFO ValidateVariants - Start Date/Time: October 25, 2020 7:53:34 PM CDT; 19:53:34.607 INFO ValidateVariants - ------------------------------------------------------------; 19:53:34.607 INFO ValidateVariants - ------------------------------------------------------------; 19:53:34.607 INFO ValidateVariants - HTSJDK Version: 2.22.0; 19:53:34.607 INFO ValidateVariants - Picard Version: 2.22.8; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 19:53:34.608 INFO ValidateVariants - Deflater: IntelDeflater; 19:53:34.608 INFO ValidateVariants - Inflater: IntelInflater; 19:53:34.608 INFO ValidateVariants - GCS max retries/reopens: 20; 19:53:34.608 INFO ValidateVariants - Requester pays: disabled; 19:53:34.608 INFO ValidateVariants - Initializing engine; 19:53:35.169 INFO FeatureManager - Using codec VCFCodec to read file file",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6911:1728,Validat,ValidateVariants,1728,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6911,1,['Validat'],['ValidateVariants']
Security,"ble technical artifacts (false positves); ## gnomad, gnomad_index: optional database of known germline variants (see http://gnomad.broadinstitute.org/downloads); ## variants_for_contamination, variants_for_contamination_index: VCF of common variants with allele frequencies fo calculating contamination; ##; ## ** Secondary resources ** (for optional tasks); ## onco_ds_tar_gz, default_config_file: Oncotator datasources and config file; ## sequencing_center, sequence_source: metadata for Oncotator; ##; ## Outputs :; ## - One VCF file and its index with primary filtering applied; secondary filtering and functional annotation if requested.; ##; ## Cromwell version support ; ## - Successfully tested on v27; ##; ## LICENSING : ; ## This script is released under the WDL source code license (BSD-3) (see LICENSE in ; ## https://github.com/broadinstitute/wdl). Note however that the programs it calls may ; ## be subject to different licenses. Users are responsible for checking that they are; ## authorized to run all programs before running this script. Please see the docker ; ## pages at https://hub.docker.com/r/broadinstitute/* for detailed licensing information ; ## pertaining to the included programs. workflow Mutect2 {; # Runtime; String gatk4_jar; File picard_jar; String m2_docker; String oncotator_docker; Int preemptible_attempts; # Workflow options; Int scatter_count; File? intervals ; Array[String] artifact_modes; String? m2_extra_args; String? m2_extra_filtering_args; Boolean is_run_orientation_bias_filter; Boolean is_run_oncotator; # Primary inputs ; File ref_fasta; File ref_fasta_index; File ref_dict; File tumor_bam; File tumor_bam_index; String tumor_sample_name; File? normal_bam; File? normal_bam_index; String? normal_sample_name; # Primary resources; File? pon; File? pon_index; File? gnomad; File? gnomad_index; File? variants_for_contamination; File? variants_for_contamination_index; # Secondary resources / inputs; File? onco_ds_tar_gz; File? default_config_file; ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3341:3101,authoriz,authorized,3101,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3341,1,['authoriz'],['authorized']
Security,bq query audit [VS-1396],MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8847:9,audit,audit,9,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8847,1,['audit'],['audit']
Security,"bs per interval, store the data from StratificationManager, and then restore/aggregate it, we could execute VariantEval/VariantQC scatter/gathered. Here is the proposal:; ; - This assumes my PR to separate VariantEvalEngine has been merged.; - In StratificationManager, create a SerializedStratificationState class. This class is responsible for gathering the relevant state of StratificationManager and would get serialized to disk using Jackson.; - StratificationManager would have a saveToDisk(), and a new constructor that accepts the Path to a serialized SerializedStratificationState object. The implementation of saving/restoring would basically be private to StratificationManager.; - In VariantEvalEngine, make a public method for saveToDisk(), which saves StratificationManager and any potential other needed information to disk, serializing with Jackson.; - StratificationManager already has a concept of combineStrats() and Combiner. This needs to be fully implemented across the VariantEval classes; however, I propose to build off this to allow VariantEvaluators and VariantStratifiers to be combined. ; - If the above works, then it is possible to take N serialized SerializedStratificationState objects, restore and combine to create one StratificationManager that represents the data from across the genome.; - With the above steps, the core capabilities I need should be present. As far as how that's exposed in existing GATK tools, I dont have strong opinions. If you want this exposed in VariantEval, I'm happy to make an new argument for --save-state-to-disk-only, which would save the result of VariantEval's interation to a serialized file and skip the reports. To be useful, we need a companion walker to ""MergeVariantEvals"", which takes N serialized files, loads/aggregates and makes the actual report. Does anyone have thoughts or concerns on this proposal? Is this something you think you'd accept as a PR to GATK/VariantEvalEngine/StratificationManager? Thanks in advance.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7030:3164,expose,exposed,3164,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7030,2,['expose'],['exposed']
Security,build_docker script should fail early if gcloud isn't authenticated,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5353:54,authenticat,authenticated,54,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5353,1,['authenticat'],['authenticated']
Security,"build_docker.sh creates unzippedJar and testsJar, but it does not remove them and it fails as a result in subsequent runs. . I ran ./build_socker.sh -e <GIT LOG HASH> and I got the error message ; mv: rename ./build/bundle-files-collected to ./unzippedJar/bundle-files-collected: Directory not empty. Only after removing unzippedJar and testJar could I build the image again successfully.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5369:161,HASH,HASH,161,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5369,1,['HASH'],['HASH']
Security,came up in recent profiling - hashCode computation on KMer was very inefficient and wasteful in String creation . @lbergelson can you review?,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1620:30,hash,hashCode,30,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1620,1,['hash'],['hashCode']
Security,came up in review of #614. ; Because of sequence dict validation we needed to hardwire bogus contig lengths in the tests. This issue is about how to resolve this - keep validation and not having to lie about the lengths (and ideally not having to commit the whole reference into the repository).,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/690:54,validat,validation,54,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/690,2,['validat'],['validation']
Security,came up on profiling - computing the hashcode over and over is expensive to we precompute it. @lbergelson please review,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1625:37,hash,hashcode,37,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1625,1,['hash'],['hashcode']
Security,"catesSpark) that running with an input in the form ""CountReadsSpark -I gs://my-bucket-dir/my-file.bam."" The tool crashes with the following unhelpful stacktraces:. ```; java.io.IOException: Error getting access token from metadata server at: http://metadata/computeMetadata/v1/instance/service-accounts/default/token; 	at com.google.cloud.hadoop.util.CredentialFactory.getCredentialFromMetadataServiceAccount(CredentialFactory.java:208); 	at com.google.cloud.hadoop.util.CredentialConfiguration.getCredential(CredentialConfiguration.java:70); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.configure(GoogleHadoopFileSystemBase.java:1825); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.initialize(GoogleHadoopFileSystemBase.java:1012); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.initialize(GoogleHadoopFileSystemBase.java:975); 	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2653); 	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:92); 	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2687); 	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2669); 	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:371); 	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:295); 	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.setInputPaths(FileInputFormat.java:500); 	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.setInputPaths(FileInputFormat.java:469); 	at org.apache.spark.SparkContext$$anonfun$newAPIHadoopFile$2.apply(SparkContext.scala:1084); 	at org.apache.spark.SparkContext$$anonfun$newAPIHadoopFile$2.apply(SparkContext.scala:1072); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); 	at org.apache.spark.SparkContext.withScope(SparkContext.scala:679); 	at org.apache.spark.SparkContext.newAPIHadoopFile(SparkContext.scala:1072); 	at org.apa",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4369:1068,access,access,1068,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4369,1,['access'],['access']
Security,cePipeline.forEach(ReferencePipeline.java:485); at org.broadinstitute.hellbender.engine.MultiVariantWalker.traverse(MultiVariantWalker.java:136); at org.broadinstitute.hellbender.engine.MultiVariantWalkerGroupedOnStart.traverse(MultiVariantWalkerGroupedOnStart.java:165); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1095); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289); Caused by: java.lang.IllegalStateException: Padded span must contain active span.; at org.broadinstitute.hellbender.utils.Utils.validate(Utils.java:814); at org.broadinstitute.hellbender.engine.AssemblyRegion.<init>(AssemblyRegion.java:109); at org.broadinstitute.hellbender.engine.AssemblyRegion.<init>(AssemblyRegion.java:85); at org.broadinstitute.hellbender.engine.AssemblyRegion.<init>(AssemblyRegion.java:120); at org.broadinstitute.hellbender.tools.walkers.realignmentfilter.FilterAlignmentArtifacts.makeAssemblyRegionFromVariantReads(FilterAlignmentArtifacts.java:280); at org.broadinstitute.hellbender.tools.walkers.realignmentfilter.FilterAlignmentArtifacts.apply(FilterAlignmentArtifacts.java:212); at org.broadinstitute.hellbender.engine.MultiVariantWalkerGroupedOnStart.apply(MultiVariantWalkerGroupedOnStart.java:133); at org.broadinstitute.hellbender.engine.MultiVariantWalkerGroupedOnStart.apply(MultiVariantWalkerGroupedOnStart.java:108); at org.broadinstitute.hellbender.engine.MultiVariantWalker.lambda$traverse$1(MultiVariantWalker.java:139); ... 21 more; ```. #### Steps to reproduce; _Tell us how to reproduce this,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8221:12552,validat,validate,12552,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8221,1,['validat'],['validate']
Security,"ch info header line, call on each VCFInfoHeaderLine getCount(vc) to get the expected number of info annotation entries; - Compare the expected number with a count based on vc.getAttribute(currentVCFinfoHeaderLine.getID()), which will require some additional parsing because it returns an Object; - (Bonus points if you use the isFixedCount() and getCount() functions on the VCF info header line to simplify annotations that aren't according to the number of alt alleles); ### Test data. /humgen/gsa-hpprojects/dev/gauthier/scratch/supportingMultiA.vcf; Should fail AC/AF validation at ; `1 768589 . A C,G 76 PASS AC=1;AF=0.00047;AN=2120`; See results using:. ```; use VCFtools; vcf-validator /humgen/gsa-hpprojects/dev/gauthier/scratch/supportingMultiA.vcf; ```. which outputs:; `INFO field at 1:768589 .. INFO tag [AC=1] expected different number of values (expected 2, found 1),INFO tag [AF=0.00047] expected different number of values (expected 2, found 1)`; ### Notes. Currently, all the validation modes call out to HTSJDK. Do we want to put the new functionality there as well?. ---. @yfarjoun commented on [Thu Jul 16 2015](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-122130280). I think that it is very appropriate to validate in htsjdk. On Thu, Jul 16, 2015 at 4:05 PM, ldgauthier notifications@github.com; wrote:. > Currently ValidateVariants relies on genotypes to transitively check that; > each alt allele occurs in at least one sample and that the AC adds up.; > However, this can fail on sites-only files because there are no genotypes.; > We should use the definition of the info annotations in the header to check; > how many entries each should have.; > Outline; > - Add a new validation type for info-field counts to enum and to; > switch statement; > - Grab info headers from input VCF with something like; > GATKVCFUtils.getVCFHeadersFromRods(getToolkit(),; > variantCollection.variants.getName()) and VCFHeader::getInfoHeaderLines; > - In the map() f",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2507:1753,validat,validation,1753,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2507,1,['validat'],['validation']
Security,change shards `hashCode` to fix bad distribution to partitions. fix NPE. adding uri's change from distinct to aggregate. reduce shard size by half,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/937:15,hash,hashCode,15,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/937,1,['hash'],['hashCode']
Security,cker image fails. #### Steps to reproduce. (base) fleharty@wm3b9-dfa docker % docker run -it broadinstitute/gatk:4.2.2.0; Unable to find image 'broadinstitute/gatk:4.2.2.0' locally; 4.2.2.0: Pulling from broadinstitute/gatk; a7fe112a8303: Already exists ; Digest: sha256:32175c3c7c1fb9f5bd6650183c9c5cf26fb822dddb0cad0123d48c33124b6065; Status: Downloaded newer image for broadinstitute/gatk:4.2.2.0; (gatk) root@bc90fdaf700c:/gatk# ; (gatk) root@bc90fdaf700c:/gatk# ; (gatk) root@bc90fdaf700c:/gatk# apt-get update; Get:1 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]; Get:2 http://archive.ubuntu.com/ubuntu bionic InRelease [242 kB] ; Get:3 http://security.ubuntu.com/ubuntu bionic-security/multiverse amd64 Packages [26.7 kB] ; Get:4 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [543 kB] ; Get:5 http://packages.cloud.google.com/apt cloud-sdk-bionic InRelease [6786 B] ; Get:6 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1426 kB] ; Err:5 http://packages.cloud.google.com/apt cloud-sdk-bionic InRelease ; The following signatures couldn't be verified because the public key is not available: NO_PUBKEY FEEA9169307EA071 NO_PUBKEY 8B57C5C2836F4BEB; Get:7 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2295 kB] ; Get:8 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB] ; Get:9 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB] ; Get:10 http://archive.ubuntu.com/ubuntu bionic/restricted amd64 Packages [13.5 kB] ; Get:11 http://archive.ubuntu.com/ubuntu bionic/multiverse amd64 Packages [186 kB]; Get:12 http://archive.ubuntu.com/ubuntu bionic/universe amd64 Packages [11.3 MB] ; Get:13 http://archive.ubuntu.com/ubuntu bionic/main amd64 Packages [1344 kB] ; Get:14 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2200 kB]; Get:15 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 Packages [34.4 kB]; Get:16 http:,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7447:1182,secur,security,1182,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7447,1,['secur'],['security']
Security,conda3/envs/gatk/share/gatk4-4.1.8.1-0/gatk-package-4.1.8.1-local.jar) to method java.nio.Bits.unaligned(); WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform; WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations; WARNING: All illegal access operations will be denied in a future release; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; 20/10/08 18:35:27 INFO SparkContext: Running Spark version 2.4.5; 18:35:27.640 WARN NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 20/10/08 18:35:27 INFO SparkContext: Submitted application: MarkDuplicatesSpark; 20/10/08 18:35:27 INFO SecurityManager: Changing view acls to: wup; 20/10/08 18:35:27 INFO SecurityManager: Changing modify acls to: wup; 20/10/08 18:35:27 INFO SecurityManager: Changing view acls groups to: ; 20/10/08 18:35:27 INFO SecurityManager: Changing modify acls groups to: ; 20/10/08 18:35:27 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(wup); groups with view permissions: Set(); users with modify permissions: Set(wup); groups with modify permissions: Set(); 20/10/08 18:35:28 INFO Utils: Successfully started service 'sparkDriver' on port 44712.; 20/10/08 18:35:28 INFO SparkEnv: Registering MapOutputTracker; 20/10/08 18:35:28 INFO SparkEnv: Registering BlockManagerMaster; 20/10/08 18:35:28 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information; 20/10/08 18:35:28 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up; 20/10/08 18:35:28 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-50a111b1-9241-4bc8-b711-cdb6d7054e70; 20/10/08 18:35:28 INFO MemoryStore: MemoryStore started with capacity 17.8 GB; 20/10/08 18:35:28 INFO SparkEnv: Registering OutputCommitCoordinator; 20/1,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6875:2863,Secur,SecurityManager,2863,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6875,7,"['Secur', 'authenticat']","['SecurityManager', 'authentication']"
Security,"connector will not be configured properly; 12:33:52.162 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/share/FGI2017B/pub/gatk-4.1.0.0/gatk-package-4.1.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; 12:33:53.793 INFO CreateReadCountPanelOfNormals - ------------------------------------------------------------; 12:33:53.794 INFO CreateReadCountPanelOfNormals - The Genome Analysis Toolkit (GATK) v4.1.0.0; 12:33:53.794 INFO CreateReadCountPanelOfNormals - For support and documentation go to https://software.broadinstitute.org/gatk/; 12:33:53.797 INFO CreateReadCountPanelOfNormals - Initializing engine; 12:33:53.797 INFO CreateReadCountPanelOfNormals - Done initializing engine; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; 19/02/18 12:33:53 INFO SparkContext: Running Spark version 2.2.0; WARNING: An illegal reflective access operation has occurred; WARNING: Illegal reflective access by org.apache.hadoop.security.authentication.util.KerberosUtil (file:/share/FGI2017B/pub/gatk-4.1.0.0/gatk-package-4.1.0.0-local.jar) to method sun.security.krb5.Config.getInstance(); WARNING: Please consider reporting this to the maintainers of org.apache.hadoop.security.authentication.util.KerberosUtil; WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations; WARNING: All illegal access operations will be denied in a future release; 12:33:54.187 WARN NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 12:33:54.263 INFO CreateReadCountPanelOfNormals - Shutting down engine; [February 18, 2019 at 12:33:54 PM CST] org.broadinstitute.hellbender.tools.copynumber.CreateReadCountPanelOfNormals done. Elapsed time: 0.04 minutes.; Runtime.totalMemory()=2147483648; Exception in thread ""main"" java.lang.ExceptionInInitializerError; 	at org.apache.spark.SparkConf.validateSettings(SparkConf.scala:546); 	at org.apache.spark",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5686:1520,authenticat,authentication,1520,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5686,1,['authenticat'],['authentication']
Security,"cords false --warnOnErrors false --interval_set_rule UNION --interval_padding 0 --interval_exclusion_padding 0 --readValidationStringency SILENT --secondsBetweenProgressUpdates 10.0 --disableSequenceDictionaryValidation false --createOutputBamIndex true --createOutputBamMD5 false --createOutputVariantIndex true --createOutputVariantMD5 false --lenient false --addOutputSAMProgramRecord true --cloudPrefetchBuffer 40 --cloudIndexPrefetchBuffer -1 --disableBamIndexCaching false --help false --version false --showHidden false --verbosity INFO --QUIET false --use_jdk_deflater false --use_jdk_inflater false --disableToolDefaultReadFilters false; [March 21, 2017 5:43:53 PM EDT] Executing as louisb@WMD2A-31E on Mac OS X 10.11.6 x86_64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_112-b16; Version: Version:4.alpha.2-189-g724fbd0-SNAPSHOT; 17:43:53.162 INFO ValidateVariants - Defaults.BUFFER_SIZE : 131072; 17:43:53.162 INFO ValidateVariants - Defaults.COMPRESSION_LEVEL : 1; 17:43:53.162 INFO ValidateVariants - Defaults.CREATE_INDEX : false; 17:43:53.163 INFO ValidateVariants - Defaults.CREATE_MD5 : false; 17:43:53.163 INFO ValidateVariants - Defaults.CUSTOM_READER_FACTORY :; 17:43:53.163 INFO ValidateVariants - Defaults.EBI_REFERENCE_SERVICE_URL_MASK : http://www.ebi.ac.uk/ena/cram/md5/%s; 17:43:53.163 INFO ValidateVariants - Defaults.NON_ZERO_BUFFER_SIZE : 131072; 17:43:53.163 INFO ValidateVariants - Defaults.REFERENCE_FASTA : null; 17:43:53.163 INFO ValidateVariants - Defaults.SAM_FLAG_FIELD_FORMAT : DECIMAL; 17:43:53.163 INFO ValidateVariants - Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 17:43:53.163 INFO ValidateVariants - Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 17:43:53.163 INFO ValidateVariants - Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 17:43:53.163 INFO ValidateVariants - Defaults.USE_CRAM_REF_DOWNLOAD : false; 17:43:53.163 INFO ValidateVariants - Deflater IntelDeflater; 17:43:53.163 INFO ValidateVariants - Inflater IntelInflater; 17:43:53.163 INFO Valid",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2509:2116,Validat,ValidateVariants,2116,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2509,1,['Validat'],['ValidateVariants']
Security,cram dictionary validation should print the missing contigs,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1289:16,validat,validation,16,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1289,1,['validat'],['validation']
Security,cutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745); Caused by: javax.net.ssl.SSLHandshakeException: Remote host closed connection during handshake; 	at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:992); 	at sun.security.ssl.SSLSocketImpl.performInitialHandshake(SSLSocketImpl.java:1375); 	at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1403); 	at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1387); 	at sun.net.www.protocol.https.HttpsClient.afterConnect(HttpsClient.java:559); 	at sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.connect(AbstractDelegateHttpsURLConnection.java:185); 	at sun.net.www.protocol.https.HttpsURLConnectionImpl.connect(HttpsURLConnectionImpl.java:153); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:93); 	at shaded.cloud_nio.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:972); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeMedia(AbstractGoogleClientRequest.java:380); 	at shaded.cloud_nio.com.google.api.services.storage.Storage$Objects$Get.executeMedia(Storage.java:5130); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.read(HttpStorageRpc.java:491); 	... 12 more; Caused by: java.io.EOFException: SSL peer shut down incorrectly; 	at sun.security.ssl.InputRecord.read(InputRecord.java:505); 	at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:973); 	... 25 more; ```; The error seems to appear after `org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImport done. Elapsed time: 19.15 minutes.` is logged which is surprising.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2685:7810,secur,security,7810,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2685,2,['secur'],['security']
Security,"d.interval\_list \\ ; ; \-R Homo\_sapiens\_assembly19.fasta \\ ; ; \-V 1000G\_phase1.snps.high\_confidence.b37.vcf.gz \\ ; ; \-I downsample\_10k.bam \\ ; ; \-O output.txt --verbosity INFO. c) Entire error log:. 19:13:25.991 INFO NativeLibraryLoader - Loading libgkl\_compression.so from jar:file:/broad/software/free/Linux/redhat\_7\_x86\_64/pkgs/gatk\_4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl\_compression.so. Jun 14, 2021 7:13:26 PM shaded.cloud\_nio.com.google.auth.oauth2.DefaultCredentialsProvider warnAboutProblematicCredentials. WARNING: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a ""quota exceeded"" or ""API not enabled"" error. For more information about service accounts, see [https://cloud.google.com/docs/authentication/](https://cloud.google.com/docs/authentication/). 19:13:26.217 INFO ASEReadCounter - ------------------------------------------------------------. 19:13:26.218 INFO ASEReadCounter - The Genome Analysis Toolkit (GATK) v4.1.8.1. 19:13:26.218 INFO ASEReadCounter - For support and documentation go to [https://software.broadinstitute.org/gatk/](https://software.broadinstitute.org/gatk/). 19:13:26.219 INFO ASEReadCounter - Executing as [cbao@uger-c009.broadinstitute.org](mailto:cbao@uger-c009.broadinstitute.org) on Linux v3.10.0-1160.15.2.el7.x86\_64 amd64. 19:13:26.219 INFO ASEReadCounter - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0\_181-b13. 19:13:26.219 INFO ASEReadCounter - Start Date/Time: June 14, 2021 7:13:25 PM UTC. 19:13:26.219 INFO ASEReadCounter - ------------------------------------------------------------. 19:13:26.219 INFO ASEReadCounter - ------------------------------------------------------------. 19:13:26.220 INFO ASEReadCounter - HTSJDK Version: 2.23.0. 19:13:26.220 INFO ASEReadCounter - Picard V",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7327:2161,authenticat,authentication,2161,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7327,1,['authenticat'],['authentication']
Security,"d4e2ca70674 submitted; [2020-07-14 05:09:30,66] [info] SingleWorkflowRunnerActor: Workflow submitted 968be82c-eef3-4bdb-a1ab-3d4e2ca70674; [2020-07-14 05:09:30,67] [info] 1 new workflows fetched by cromid-ca5c695: 968be82c-eef3-4bdb-a1ab-3d4e2ca70674; [2020-07-14 05:09:30,68] [info] WorkflowManagerActor Starting workflow 968be82c-eef3-4bdb-a1ab-3d4e2ca70674; [2020-07-14 05:09:30,69] [info] WorkflowManagerActor Successfully started WorkflowActor-968be82c-eef3-4bdb-a1ab-3d4e2ca70674; [2020-07-14 05:09:30,69] [info] Retrieved 1 workflows from the WorkflowStoreActor; [2020-07-14 05:09:30,72] [info] WorkflowStoreHeartbeatWriteActor configured to flush with batch size 10000 and process rate 2 minutes.; [2020-07-14 05:09:30,83] [info] MaterializeWorkflowDescriptorActor [968be82c]: Parsing workflow as WDL 1.0; [2020-07-14 05:09:31,60] [info] MaterializeWorkflowDescriptorActor [968be82c]: Call-to-Backend assignments: ValidateBamsWf.ValidateBAM -> Local; [2020-07-14 05:09:31,82] [warn] Local [968be82c]: Key/s [memory, disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.; [2020-07-14 05:09:35,38] [info] Not triggering log of token queue status. Effective log interval = None; [2020-07-14 05:09:37,15] [info] WorkflowExecutionActor-968be82c-eef3-4bdb-a1ab-3d4e2ca70674 [968be82c]: Starting ValidateBamsWf.ValidateBAM; [2020-07-14 05:09:37,39] [info] Assigned new job execution tokens to the following groups: 968be82c: 1; [2020-07-14 05:09:41,61] [warn] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: Unrecognized runtime attribute keys: disks, memory; [2020-07-14 05:09:41,71] [info] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: /gatk/gatk \; ValidateSamFile \; --INPUT /cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/inputs/-1942028726/test.bam \; --OUTPUT test.validation_.txt \; --MODE SUMMARY; [2020-07-14 05:09:41,76] [inf",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6710:3966,Validat,ValidateBAM,3966,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710,1,['Validat'],['ValidateBAM']
Security,"dPrefetchBuffer 40 --cloudIndexPrefetchBuffer -1 --disableBamIndexCaching false --help false --version false --showHidden false --verbosity INFO --QUIET false --use_jdk_deflater false --use_jdk_inflater false --disableToolDefaultReadFilters false; [March 21, 2017 5:43:53 PM EDT] Executing as louisb@WMD2A-31E on Mac OS X 10.11.6 x86_64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_112-b16; Version: Version:4.alpha.2-189-g724fbd0-SNAPSHOT; 17:43:53.162 INFO ValidateVariants - Defaults.BUFFER_SIZE : 131072; 17:43:53.162 INFO ValidateVariants - Defaults.COMPRESSION_LEVEL : 1; 17:43:53.162 INFO ValidateVariants - Defaults.CREATE_INDEX : false; 17:43:53.163 INFO ValidateVariants - Defaults.CREATE_MD5 : false; 17:43:53.163 INFO ValidateVariants - Defaults.CUSTOM_READER_FACTORY :; 17:43:53.163 INFO ValidateVariants - Defaults.EBI_REFERENCE_SERVICE_URL_MASK : http://www.ebi.ac.uk/ena/cram/md5/%s; 17:43:53.163 INFO ValidateVariants - Defaults.NON_ZERO_BUFFER_SIZE : 131072; 17:43:53.163 INFO ValidateVariants - Defaults.REFERENCE_FASTA : null; 17:43:53.163 INFO ValidateVariants - Defaults.SAM_FLAG_FIELD_FORMAT : DECIMAL; 17:43:53.163 INFO ValidateVariants - Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 17:43:53.163 INFO ValidateVariants - Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 17:43:53.163 INFO ValidateVariants - Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 17:43:53.163 INFO ValidateVariants - Defaults.USE_CRAM_REF_DOWNLOAD : false; 17:43:53.163 INFO ValidateVariants - Deflater IntelDeflater; 17:43:53.163 INFO ValidateVariants - Inflater IntelInflater; 17:43:53.163 INFO ValidateVariants - Initializing engine; 17:43:53.270 INFO FeatureManager - Using codec VCFCodec to read file file:///Users/louisb/Workspace/gatk/src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleGood.vcf; 17:43:53.287 INFO FeatureManager - Using codec VCFCodec to read file file:///Users/louisb/Workspace/gatk/src/test/resources/org/broadinstitute/hellbende",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2509:2515,Validat,ValidateVariants,2515,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2509,1,['Validat'],['ValidateVariants']
Security,"dateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0:/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0:delegated \; broadinstitute/gatk@sha256:18146e79d06787483310e5de666502090a480e10ac0fad06a36a5e7a5c9bb1dc /cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/script. # get the return code (working even if the container was detached); rc=$(docker wait cat /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/docker_cid). # remove the container after waiting; docker rm cat /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/docker_cid. # return exit code; exit $rc; [2020-07-14 05:09:45,29] [info] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: job id: 243; [2020-07-14 05:09:45,29] [info] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: Status change from - to Done; [2020-07-14 05:09:46,38] [info] WorkflowManagerActor Workflow 968be82c-eef3-4bdb-a1ab-3d4e2ca70674 failed (during ExecutingWorkflowState): Job ValidateBamsWf.ValidateBAM:0:1 exited with return code -1 which has not been declared as a valid return code. See 'continueOnReturnCode' runtime attribute for more details.; Check the content of stderr for potential additional information: /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/stderr.; Could not retrieve content: Could not read from /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/stderr: /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/stderr; [2020-07-14 05:09:46,38] [info] WorkflowManagerActor",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6710:6584,Validat,ValidateBAM,6584,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710,1,['Validat'],['ValidateBAM']
Security,"dateVariants - Defaults.USE_CRAM_REF_DOWNLOAD : false; 17:43:53.163 INFO ValidateVariants - Deflater IntelDeflater; 17:43:53.163 INFO ValidateVariants - Inflater IntelInflater; 17:43:53.163 INFO ValidateVariants - Initializing engine; 17:43:53.270 INFO FeatureManager - Using codec VCFCodec to read file file:///Users/louisb/Workspace/gatk/src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleGood.vcf; 17:43:53.287 INFO FeatureManager - Using codec VCFCodec to read file file:///Users/louisb/Workspace/gatk/src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleGood.vcf; 17:43:53.291 WARN IndexUtils - Feature file ""/Users/louisb/Workspace/gatk/src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleGood.vcf"" appears to contain no sequence dictionary. Attempting to retrieve a sequence dictionary from the associated index file; 17:43:53.293 INFO ValidateVariants - Done initializing engine; 17:43:53.294 INFO ProgressMeter - Starting traversal; 17:43:53.294 INFO ProgressMeter - Current Locus Elapsed Minutes Records Processed Records/Minute; 17:43:53.302 INFO ValidateVariants - Shutting down engine; [March 21, 2017 5:43:53 PM EDT] org.broadinstitute.hellbender.tools.walkers.variantutils.ValidateVariants done. Elapsed time: 0.00 minutes.; Runtime.totalMemory()=194510848; java.lang.IllegalArgumentException: Illegal base [] seen in the allele; 	at htsjdk.variant.variantcontext.Allele.create(Allele.java:231); 	at htsjdk.variant.variantcontext.Allele.create(Allele.java:374); 	at org.broadinstitute.hellbender.tools.walkers.variantutils.ValidateVariants.apply(ValidateVariants.java:181); 	at org.broadinstitute.hellbender.engine.VariantWalkerBase.lambda$traverse$0(VariantWalkerBase.java:104); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.I",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2509:3904,Validat,ValidateVariants,3904,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2509,1,['Validat'],['ValidateVariants']
Security,"dbSNP build, it throws this error:. \[Fri Jul 23 13:25:03 CEST 2021\] picard.vcf.CollectVariantCallingMetrics done. Elapsed time: 70.55 minutes. Runtime.totalMemory()=1623195648. To get help, see [http://broadinstitute.github.io/picard/index.html#GettingHelp](http://broadinstitute.github.io/picard/index.html#GettingHelp). java.lang.NullPointerException: Cannot invoke ""htsjdk.samtools.SAMSequenceRecord.getSequenceLength()"" because the return value of ""htsjdk.samtools.SAMSequenceDictionary.getSequence(String)"" is null. at picard.util.DbSnpBitSetUtil.loadVcf(DbSnpBitSetUtil.java:163). at picard.util.DbSnpBitSetUtil.createSnpAndIndelBitSets(DbSnpBitSetUtil.java:131). at picard.vcf.CollectVariantCallingMetrics.doWork(CollectVariantCallingMetrics.java:101). at picard.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:308). at org.broadinstitute.hellbender.cmdline.PicardCommandLineProgramExecutor.instanceMain(PicardCommandLineProgramExecutor.java:37). at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160). at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203). at org.broadinstitute.hellbender.Main.main(Main.java:289). As a bit of a background, I am trying to use the latest dbSNP release (build 155, GRCh38, GCF\_000001405.39) and have tried using GATK version 4.1.9.0 and the latest 4.2.0.0, both having the same problem. To prepare the dbSNP file for use with the best practices workflow, I renamed the NCBI chromosome accession numbers  to UCSC style names using bcftools annotate, updated the vcf headers using UpdateVcfSequenceDictionary, and indexed the file using IndexFeatureFile. The dbSNP file worked well with both HaplotypeCaller and GenotypeGVCFs, with the rsids overlapping perfectly with those obtained when using the dbSNP resource bundle version. Any help with this would be greatly appreciated!<br><br><i>(created from <a href='https://broadinstitute.zendesk.com/agent/tickets/171466'>Zendesk ticket #171466</a>)<br>gz#171466</i>",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7383:2426,access,accession,2426,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7383,1,['access'],['accession']
Security,"dependency-name=commons-io:commons-io&package-manager=gradle&previous-version=2.7&new-version=2.14.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself); You can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/broadinstitute/gatk/network/alerts). </details>",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/9003:2021,secur,security,2021,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/9003,2,"['Secur', 'secur']","['Security', 'security']"
Security,"derLine) or similar; add a test to VariantContextUnitTest.java; 2) After change 1) is merged, update ValidateVariants accordingly to use the new function and add a test to its integration tests. ---. @vdauwera commented on [Fri May 27 2016](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-222213763). @ldgauthier is this still a thing? (in the sense of not having been addressed in htsjdk). ---. @ldgauthier commented on [Fri May 27 2016](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-222214083). Still a thing. No work has been done here AFAIK. ---. @vdauwera commented on [Mon Nov 14 2016](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-260465013). This seems like fairly low-hanging fruit -- @ronlevine . ---. @ronlevine commented on [Wed Nov 23 2016](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-262613152). @ldgauthier Shouldn't a locus without genotypes bypass `AC` validation, given it's defined as: `Allele count in genotypes, for each ALT allele, in the same order as listed`?. ---. @ldgauthier commented on [Wed Nov 23 2016](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-262613997). Agreed. ---. @ronlevine commented on [Thu Nov 24 2016](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-262635204). The change should be a lot simpler than proposed. The code can validate the number of alleles before it checks for the presence of genotypes in [VariantContext#validateChromosomeCounts](https://github.com/samtools/htsjdk/blob/master/src/main/java/htsjdk/variant/variantcontext/VariantContext.java#L1236). . ---. @ldgauthier commented on [Mon Nov 28 2016](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-263277972). Sorry, I needed to refresh my memory. I actually don't want to bypass AC validation for variants without genotypes, but I think you already figured that out. My proposal was more general, but you're rig",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2507:5394,validat,validation,5394,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2507,1,['validat'],['validation']
Security,"directly, view it on GitHub; > https://github.com/broadinstitute/gsa-unstable/issues/1438#issuecomment-260495927,; > or mute the thread; > https://github.com/notifications/unsubscribe-auth/ACnk0uvegvUmCq7_G7U2PSuTpvIYl0wQks5q-Ox0gaJpZM4JNjE-; > . ---. @vdauwera commented on [Mon Nov 14 2016](https://github.com/broadinstitute/gsa-unstable/issues/1438#issuecomment-260519118). So, would adding a toggle be acceptable? And more importantly, can we make stringent validation default, with the option to not blow up on silly exome files? Will production accept that?. ---. @yfarjoun commented on [Tue Nov 15 2016](https://github.com/broadinstitute/gsa-unstable/issues/1438#issuecomment-260617185). let me talk with production to see if we can post-facto change the exome; file... On Mon, Nov 14, 2016 at 8:27 PM, Geraldine Van der Auwera <; notifications@github.com> wrote:. > So, would adding a toggle be acceptable? And more importantly, can we make; > stringent validation default, with the option to not blow up on silly exome; > files? Will production accept that?; > ; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > https://github.com/broadinstitute/gsa-unstable/issues/1438#issuecomment-260519118,; > or mute the thread; > https://github.com/notifications/unsubscribe-auth/ACnk0tUTNAAyuk3m_2cJ8j_3KYroaqB1ks5q-QpsgaJpZM4JNjE-; > . ---. @vdauwera commented on [Mon Mar 20 2017](https://github.com/broadinstitute/gsa-unstable/issues/1438#issuecomment-287821154). Any update on this, @yfarjoun ?. ---. @yfarjoun commented on [Mon Mar 20 2017](https://github.com/broadinstitute/gsa-unstable/issues/1438#issuecomment-287826525). I think we will only fix the interval list when we move exomes to; hg38....so, no. On Mon, Mar 20, 2017 at 12:45 PM, Geraldine Van der Auwera <; notifications@github.com> wrote:. > Any update on this, @yfarjoun <https://github.com/yfarjoun> ?; >; > —; > You are receiving this because you were mentioned.; >",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2520:3059,validat,validation,3059,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2520,1,['validat'],['validation']
Security,dockstore testing: move validate vat inputs,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7449:24,validat,validate,24,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7449,1,['validat'],['validate']
Security,"ds an artificial break at 1000 bins and screws up the scaling:. ![cr-ss](https://user-images.githubusercontent.com/11076296/51122629-417be180-17e8-11e9-9a8f-e17a5d0563f5.png). To fix this, I implemented minibatch slice sampling as described in http://proceedings.mlr.press/v33/dubois14.pdf. This uses early stopping of sampling as determined by a simple statistical test to perform approximate sampling of the posterior in a way that is more well behaved:. ![cr-mb](https://user-images.githubusercontent.com/11076296/51122680-61aba080-17e8-11e9-992a-f756a267d0ce.png). Note that the scaling levels off for larger segments, but the approximation can be made exact by taking the appropriate parameter to zero (here, this parameter is set to 0.1). However, since subsampling parameters were not exposed in the old code, I have not exposed the parameters for the approximation here. We can do this in a future PR if desired. Changing these parameters can affect runtime and results, but I've set them to reasonable values for now. The implementation involved 1) creating an abstract class to extract some common functionality shared with the old batch SliceSampler (which is now no longer used in production code), 2) implementing the MinibatchSliceSampler as described in the above reference, and 3) adding some hash-based caching functionality to both the batch/minibatch implementations, as well as to the allele-fraction likelihood calculations (see related discussion in #2860). I also made a few miscellaneous improvements to code style, etc. This is a relatively sizable change and can rather dramatically change the number of segments remaining after smoothing, etc. (although primarily on small scales and probably well within the noise). I will rerun the TCGA SNP array evaluations to make sure there are no negative effects on performance from this change or those introduced in #5556. @LeeTL1220 should also run some tests. The branch might require some further tweaking based on the results.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5575:2024,hash,hash-based,2024,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5575,1,['hash'],['hash-based']
Security,"e ""/Users/louisb/Workspace/gatk/src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleGood.vcf"" appears to contain no sequence dictionary. Attempting to retrieve a sequence dictionary from the associated index file; 17:43:53.293 INFO ValidateVariants - Done initializing engine; 17:43:53.294 INFO ProgressMeter - Starting traversal; 17:43:53.294 INFO ProgressMeter - Current Locus Elapsed Minutes Records Processed Records/Minute; 17:43:53.302 INFO ValidateVariants - Shutting down engine; [March 21, 2017 5:43:53 PM EDT] org.broadinstitute.hellbender.tools.walkers.variantutils.ValidateVariants done. Elapsed time: 0.00 minutes.; Runtime.totalMemory()=194510848; java.lang.IllegalArgumentException: Illegal base [] seen in the allele; 	at htsjdk.variant.variantcontext.Allele.create(Allele.java:231); 	at htsjdk.variant.variantcontext.Allele.create(Allele.java:374); 	at org.broadinstitute.hellbender.tools.walkers.variantutils.ValidateVariants.apply(ValidateVariants.java:181); 	at org.broadinstitute.hellbender.engine.VariantWalkerBase.lambda$traverse$0(VariantWalkerBase.java:104); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); 	at org.broadinstitute.hellbender.engine.VariantWalkerBase.traverse(VariantWalkerBase.j",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2509:4622,Validat,ValidateVariants,4622,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2509,1,['Validat'],['ValidateVariants']
Security,"e adopt a new default branch name and retire the use of 'master'.*. The use of 'master' as the default branch is quickly tipping into the realm of being archaic, and present the image of being increasingly tone deaf. 'main' is the commonly accepted replacement on GitHub, but I'm stopping short of suggesting the replacement name, just asking ""please retire master"". . ### 'master has a specific technical meaning' . It does. And is also an example of structural racism, which; > refers to the complex interactions of large scale societal systems, practices, ideologies, and programs that produce and and perpetuate inequities for racial minorities. The key aspect of structural or systematic racism is that these macro-level mechanisms operate independent of the intentions and actions of individuals, so that even if individual racism is not present, the adverse conditions and inequalities for racial minorities will continue to exist - [Gee & Ford, 2011](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4306458/). _And if you just felt as if you were accused of being a racist, please re-read the above definition again_ I'm addressing the bureaucracy ( which I can not realistically effect much change with, but some of you can).; ; Ultimately, a fair number of people are to varying degrees uncomfortable or threatened by this trope. And on these merits alone are a good reason to ditch master. [The process is straight forward and documentation abounds](https://www.git-tower.com/learn/git/faq/git-rename-master-to-main), [there are even tools to help automate the conversion](https://github.com/dsyer/main-branch-switch). But it will take time, and is not the most exciting work in the world. . Perhaps it's a sticky change as part of all major releases, or otherwise planned for? So, that's my vote, if I were to be asked to vote that is. And, if there are detailed plans in place to make this change, horray! Link them here, and now you have a(nother?) nice honeypot for this topic. John Major",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7621:1884,threat,threatened,1884,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7621,1,['threat'],['threatened']
Security,"e canonicalized/masked kmers. The result is a Collection<long[]> variable, which is then converted to either a PSKmerSet (Hopscotch set) or PSKmerBloomFilter, depending on the desired false positive probability. . The PSKmerSet/BloomFilter classes are basically wrappers for LargeLongHopscotchSet and LongBloomFilter, respectively. They both inherit PSKmerCollection, which provides a contains() function for querying new kmers for set membership and makes loading the kmers for filtering more convenient. These classes also store the kmer size, mask, and false positive probability. They also handle canonicalization/masking on queried kmers. **PathSeqFilterSpark tool**. Input:; 1) Input BAM; 2) Host kmer set file (optional); 3) Host reference bwa image (optional). Output:; 1) BAM containing paired reads that still have mates; 2) BAM containing unpaired reads / reads whose mates were filtered out; 3) Metrics file containing read counts and elapsed wall time at each step (optional). Filtering steps performed on each read:; - If the user sets the --isHostAligned, the read will first be filtered if it is aligned sufficiently well ; - Alignment info is stripped; - A series of quality filters (same as in the previous version of this tool); - Kmerized and filtered out if at least a threshold number of kmers are in the host set (default 1); - Aligned to the host reference and filtered if it maps sufficiently well; - Sequence duplicates are removed. Other:; -Fixed bugginess in very large LongBloomFilters by changing a size variable from int to long. ; - Also realized we can't get away with using just 1 hash function in the Bloom filter. Before, I was using a single 64-bit hash and splitting it into 2 32-bit hashes, then using the hash1 + i*hash2 trick to generate each hash value. I don't think we can do this now because we allow for tables of size >2 billion bits in a single filter, so we need 2 64-bit hashes to use the trick.; -A couple of utility functions have been moved around",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3115:2256,hash,hash,2256,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3115,5,['hash'],"['hash', 'hashes']"
Security,"e for info-field counts to enum and to; > switch statement; > - Grab info headers from input VCF with something like; > GATKVCFUtils.getVCFHeadersFromRods(getToolkit(),; > variantCollection.variants.getName()) and VCFHeader::getInfoHeaderLines; > - In the map() function, for each info header line, call on each; > VCFInfoHeaderLine getCount(vc) to get the expected number of info; > annotation entries; > - Compare the expected number with a count based on; > vc.getAttribute(currentVCFinfoHeaderLine.getID()), which will require some; > additional parsing because it returns an Object; > - (Bonus points if you use the isFixedCount() and getCount() functions; > on the VCF info header line to simplify annotations that aren't according; > to the number of alt alleles); > ; > Test data; > ; > /humgen/gsa-hpprojects/dev/gauthier/scratch/supportingMultiA.vcf; > Should fail AC/AF validation at; > 1 768589 . A C,G 76 PASS AC=1;AF=0.00047;AN=2120; > See results using:; > ; > use VCFtools; > vcf-validator /humgen/gsa-hpprojects/dev/gauthier/scratch/supportingMultiA.vcf; > ; > which outputs:; > INFO field at 1:768589 .. INFO tag [AC=1] expected different number of; > values (expected 2, found 1),INFO tag [AF=0.00047] expected different; > number of values (expected 2, found 1); > Notes; > ; > Currently, all the validation modes call out to HTSJDK. Do we want to put; > the new functionality there as well?; > ; > —; > Reply to this email directly or view it on GitHub; > https://github.com/broadinstitute/gsa-unstable/issues/1053. ---. @ldgauthier commented on [Fri Jul 17 2015](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-122308040). Today I learned that the way we currently build GATK, you can't point to a local htsjdk jar anymore, so this task will be two-fold:; 1) Make a PR to htsjdk with a new function in the VariantContext class for validateInfoFieldCounts(VCFInfoHeaderLine headerLine) or similar; add a test to VariantContextUnitTest.java; 2) After chang",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2507:3494,validat,validator,3494,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2507,1,['validat'],['validator']
Security,"e running on Google Compute Engine.; 19:53:34.606 INFO ValidateVariants - ------------------------------------------------------------; 19:53:34.606 INFO ValidateVariants - The Genome Analysis Toolkit (GATK) v4.1.8.0; 19:53:34.606 INFO ValidateVariants - For support and documentation go to https://software.broadinstitute.org/gatk/; 19:53:34.607 INFO ValidateVariants - Executing as zepengmu@midway2-login1.rcc.local on Linux v3.10.0-1127.8.2.el7.x86_64 amd64; 19:53:34.607 INFO ValidateVariants - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_45-b14; 19:53:34.607 INFO ValidateVariants - Start Date/Time: October 25, 2020 7:53:34 PM CDT; 19:53:34.607 INFO ValidateVariants - ------------------------------------------------------------; 19:53:34.607 INFO ValidateVariants - ------------------------------------------------------------; 19:53:34.607 INFO ValidateVariants - HTSJDK Version: 2.22.0; 19:53:34.607 INFO ValidateVariants - Picard Version: 2.22.8; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 19:53:34.608 INFO ValidateVariants - Deflater: IntelDeflater; 19:53:34.608 INFO ValidateVariants - Inflater: IntelInflater; 19:53:34.608 INFO ValidateVariants - GCS max retries/reopens: 20; 19:53:34.608 INFO ValidateVariants - Requester pays: disabled; 19:53:34.608 INFO ValidateVariants - Initializing engine; 19:53:35.169 INFO FeatureManager - Using codec VCFCodec to read file file://chr1-22.phased.rename.reheader.vcf.gz; 19:53:35.594 INFO ValidateVariants - Done initializing engine; 19:53:35.594 WARN ValidateVariants - IDS validation cannot be done because no DBSNP file was provided; 19:53:35.594 WARN ValidateVariants - Other possible validations will still be perfor",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6911:2048,Validat,ValidateVariants,2048,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6911,1,['Validat'],['ValidateVariants']
Security,"e running on Google Compute Engine.; [Sun Jul 26 10:20:35 EDT 2020] Executing as farrell@scc-hadoop.bu.edu on Linux 3.10.0-1062.12.1.el7.x86_64 amd64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_121-b13; Deflater: Intel; Inflater: Intel; Provider GCS is available; Picard version: Version:4.1.7.0; INFO 2020-07-26 10:20:35 LiftoverVcf Loading up the target reference genome.; INFO 2020-07-26 10:20:56 LiftoverVcf Lifting variants over and sorting (not yet writing the output file.); [Sun Jul 26 10:20:56 EDT 2020] picard.vcf.LiftoverVcf done. Elapsed time: 0.36 minutes.; Runtime.totalMemory()=5861015552; To get help, see http://broadinstitute.github.io/picard/index.html#GettingHelp; htsjdk.tribble.TribbleException: Badly formed variant context at location chr1:596697; getEnd() was 596797 but this VariantContext contains an END key with value 532177; at htsjdk.variant.variantcontext.VariantContext.validateStop(VariantContext.java:1401); at htsjdk.variant.variantcontext.VariantContext.validate(VariantContext.java:1383); at htsjdk.variant.variantcontext.VariantContext.<init>(VariantContext.java:489); at htsjdk.variant.variantcontext.VariantContextBuilder.make(VariantContextBuilder.java:647); at htsjdk.variant.variantcontext.VariantContextBuilder.make(VariantContextBuilder.java:638); at picard.util.LiftoverUtils.liftVariant(LiftoverUtils.java:92); at picard.vcf.LiftoverVcf.doWork(LiftoverVcf.java:426); at picard.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:305); at org.broadinstitute.hellbender.cmdline.PicardCommandLineProgramExecutor.instanceMain(PicardCommandLineProgramExecutor.java:25); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:163); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:206); at org.broadinstitute.hellbender.Main.main(Main.java:292). ```. #### Steps to reproduce. Download vcf from here:. ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/AshkenazimTrio/analysis/NIST_SVs_Integration_v0.6/HG002_SVs_Tier1_v0.6.vcf.gz",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6725:3148,validat,validate,3148,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6725,1,['validat'],['validate']
Security,"e.AssemblyRegionWalker.traverse(AssemblyRegionWalker.java:173); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1085); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289); Using GATK jar /root/gatk.jar defined in environment variable GATK_LOCAL_JAR; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx3000m -jar /root/gatk.jar Mutect2 -R gs://genomics-public-data/resources/broad/hg38/v0/Homo_sapiens_assembly38.fasta -I gs://cclebams/hg38_wes/CDS-ce3y1s.hg38.bam -tumor HAP1_1 --germline-resource gs://gatk-best-practices/somatic-hg38/af-only-gnomad.hg38.vcf.gz -pon gs://gatk-best-practices/somatic-hg38/1000g_pon.hg38.vcf.gz -L gs://fc-secure-76d1542e-1c49-4411-8268-e41e92f9f311/729d209c-0ef4-409f-b3af-2e84ff45ee36/omics_mutect2/16911ef5-efb2-4e12-86f2-f3d5a54b28c0/call-mutect2/Mutect2/4e4a27e2-6c57-40e9-8ddc-1024bdcc50c1/call-SplitIntervals/glob-0fc990c5ca95eebc97c4c204e3e303e1/0000-scattered.interval_list -O output.vcf.gz --f1r2-tar-gz f1r2.tar.gz --genotype-germline-sites true --genotype-pon-sites true --emit-ref-confidence GVCF --gcs-project-for-requester-pays broad-firecloud-ccle; ```. #### Steps to reproduce. running the same pipeline as described in previous issues: #7492. But I have added ""--genotype-germline-sites true --genotype-pon-sites true --emit-ref-confidence GVCF"" as additional args. the rest of the arguments are defaults/basic from the mutect2.wdl pipeline.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7849:7714,secur,secure-,7714,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7849,1,['secur'],['secure-']
Security,e.cloud.storage.contrib.nio.CloudStorageReadChannel.<init>(CloudStorageReadChannel.java:72); at com.google.cloud.storage.contrib.nio.CloudStorageReadChannel.create(CloudStorageReadChannel.java:62); at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.newReadChannel(CloudStorageFileSystemProvider.java:268); at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.newByteChannel(CloudStorageFileSystemProvider.java:229); at java.nio.file.Files.newByteChannel(Files.java:361); at java.nio.file.Files.newByteChannel(Files.java:407); at java.nio.file.spi.FileSystemProvider.newInputStream(FileSystemProvider.java:384); at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.newInputStream(CloudStorageFileSystemProvider.java:348); at java.nio.file.Files.newInputStream(Files.java:152); at org.broadinstitute.hellbender.utils.nio.GcsNioIntegrationTest.openPublicFile(GcsNioIntegrationTest.java:33); Caused by:; java.io.IOException: Error getting access token for service account: ; at shaded.cloud-nio.com.google.auth.oauth2.ServiceAccountCredentials.refreshAccessToken(ServiceAccountCredentials.java:319); at shaded.cloud-nio.com.google.auth.oauth2.OAuth2Credentials.refresh(OAuth2Credentials.java:149); at shaded.cloud-nio.com.google.auth.oauth2.OAuth2Credentials.getRequestMetadata(OAuth2Credentials.java:135); at shaded.cloud-nio.com.google.auth.http.HttpCredentialsAdapter.initialize(HttpCredentialsAdapter.java:96); at com.google.cloud.HttpTransportOptions$1.initialize(HttpTransportOptions.java:149); at shaded.cloud-nio.com.google.api.client.http.HttpRequestFactory.buildRequest(HttpRequestFactory.java:93); at shaded.cloud-nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.buildHttpRequest(AbstractGoogleClientRequest.java:300); at shaded.cloud-nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419); at shaded.cloud-nio.com.google.api.client.googlea,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2514:2067,access,access,2067,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2514,1,['access'],['access']
Security,"e.com/apt cloud-sdk-bionic InRelease [6786 B] ; Get:6 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1426 kB] ; Err:5 http://packages.cloud.google.com/apt cloud-sdk-bionic InRelease ; The following signatures couldn't be verified because the public key is not available: NO_PUBKEY FEEA9169307EA071 NO_PUBKEY 8B57C5C2836F4BEB; Get:7 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2295 kB] ; Get:8 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB] ; Get:9 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB] ; Get:10 http://archive.ubuntu.com/ubuntu bionic/restricted amd64 Packages [13.5 kB] ; Get:11 http://archive.ubuntu.com/ubuntu bionic/multiverse amd64 Packages [186 kB]; Get:12 http://archive.ubuntu.com/ubuntu bionic/universe amd64 Packages [11.3 MB] ; Get:13 http://archive.ubuntu.com/ubuntu bionic/main amd64 Packages [1344 kB] ; Get:14 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2200 kB]; Get:15 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 Packages [34.4 kB]; Get:16 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [575 kB]; Get:17 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2731 kB]; Get:18 http://archive.ubuntu.com/ubuntu bionic-backports/universe amd64 Packages [11.4 kB]; Get:19 http://archive.ubuntu.com/ubuntu bionic-backports/main amd64 Packages [11.3 kB]; Reading package lists... Done ; W: GPG error: http://packages.cloud.google.com/apt cloud-sdk-bionic InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY FEEA9169307EA071 NO_PUBKEY 8B57C5C2836F4BEB; E: The repository 'http://packages.cloud.google.com/apt cloud-sdk-bionic InRelease' is not signed.; N: Updating from such a repository can't be done securely, and is therefore disabled by default.; N: See apt-secure(8) manpage for repository creation and user configuration details.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7447:2954,secur,securely,2954,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7447,2,['secur'],"['secure', 'securely']"
Security,"e82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/script. # get the return code (working even if the container was detached); rc=$(docker wait cat /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/docker_cid). # remove the container after waiting; docker rm cat /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/docker_cid. # return exit code; exit $rc; [2020-07-14 05:09:45,29] [info] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: job id: 243; [2020-07-14 05:09:45,29] [info] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: Status change from - to Done; [2020-07-14 05:09:46,38] [info] WorkflowManagerActor Workflow 968be82c-eef3-4bdb-a1ab-3d4e2ca70674 failed (during ExecutingWorkflowState): Job ValidateBamsWf.ValidateBAM:0:1 exited with return code -1 which has not been declared as a valid return code. See 'continueOnReturnCode' runtime attribute for more details.; Check the content of stderr for potential additional information: /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/stderr.; Could not retrieve content: Could not read from /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/stderr: /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/stderr; [2020-07-14 05:09:46,38] [info] WorkflowManagerActor WorkflowActor-968be82c-eef3-4bdb-a1ab-3d4e2ca70674 is in a terminal state: WorkflowFailedState; [2020-07-14 05:09:51,97] [info] SingleWorkflowRunnerActor workflow finished with status 'Failed'.; [2020-07-14 05:09:55,28] [info] Workflow polling stopped; [2020-07-14 05:09:55,30] [info] 0 workflows released by cromid",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6710:6916,Validat,ValidateBAM,6916,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710,1,['Validat'],['ValidateBAM']
Security,"e; [January 12, 2021 at 3:50:33 PM EST] org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSpark done. Elapsed time: 0.06 minutes.; Runtime.totalMemory()=1065353216; java.lang.IllegalArgumentException: Unsupported class file major version 55; 	at org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:166); 	at org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:148); 	at org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:136); 	at org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:237); 	at org.apache.spark.util.ClosureCleaner$.getClassReader(ClosureCleaner.scala:49); 	at org.apache.spark.util.FieldAccessFinder$$anon$3$$anonfun$visitMethodInsn$2.apply(ClosureCleaner.scala:517); 	at org.apache.spark.util.FieldAccessFinder$$anon$3$$anonfun$visitMethodInsn$2.apply(ClosureCleaner.scala:500); 	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733); 	at scala.collection.mutable.HashMap$$anon$1$$anonfun$foreach$2.apply(HashMap.scala:134); 	at scala.collection.mutable.HashMap$$anon$1$$anonfun$foreach$2.apply(HashMap.scala:134); 	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236); 	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40); 	at scala.collection.mutable.HashMap$$anon$1.foreach(HashMap.scala:134); 	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732); 	at org.apache.spark.util.FieldAccessFinder$$anon$3.visitMethodInsn(ClosureCleaner.scala:500); 	at org.apache.xbean.asm6.ClassReader.readCode(ClassReader.java:2175); 	at org.apache.xbean.asm6.ClassReader.readMethod(ClassReader.java:1238); 	at org.apache.xbean.asm6.ClassReader.accept(ClassReader.java:631); 	at org.apache.xbean.asm6.ClassReader.accept(ClassReader.java:355); 	at org.apache.spark.util.ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$14.apply(ClosureCleaner.scala:307); 	at org.apache.spark.util.ClosureCleaner$$anonfun$org$ap",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7035:6749,Hash,HashMap,6749,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7035,1,['Hash'],['HashMap']
Security,"eManagers; 18/01/09 18:30:58 INFO yarn.Client: Verifying our application has not requested more than the maximum memory capability of the cluster (18432 MB per container); 18/01/09 18:30:58 INFO yarn.Client: Will allocate AM container, with 896 MB memory including 384 MB overhead; 18/01/09 18:30:58 INFO yarn.Client: Setting up container launch context for our AM; 18/01/09 18:30:58 INFO yarn.Client: Setting up the launch environment for our AM container; 18/01/09 18:30:58 INFO yarn.Client: Preparing resources for our AM container; 18/01/09 18:30:59 INFO yarn.Client: Uploading resource file:/tmp/sun/spark-5a3e539e-2e2b-4da2-b218-2bda166bd4c0/__spark_conf__7100950787185363106.zip -> hdfs://tele-1:8020/user/sun/.sparkStaging/application_1515493209401_0001/__spark_conf__.zip; 18/01/09 18:31:00 INFO spark.SecurityManager: Changing view acls to: sun; 18/01/09 18:31:00 INFO spark.SecurityManager: Changing modify acls to: sun; 18/01/09 18:31:00 INFO spark.SecurityManager: Changing view acls groups to: ; 18/01/09 18:31:00 INFO spark.SecurityManager: Changing modify acls groups to: ; 18/01/09 18:31:00 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(sun); groups with view permissions: Set(); users with modify permissions: Set(sun); groups with modify permissions: Set(); 18/01/09 18:31:00 INFO yarn.Client: Submitting application application_1515493209401_0001 to ResourceManager; 18/01/09 18:31:00 INFO impl.YarnClientImpl: Submitted application application_1515493209401_0001; 18/01/09 18:31:00 INFO cluster.SchedulerExtensionServices: Starting Yarn extension services with app application_1515493209401_0001 and attemptId None; 18/01/09 18:31:01 INFO yarn.Client: Application report for application_1515493209401_0001 (state: ACCEPTED); 18/01/09 18:31:01 INFO yarn.Client: ; 	 client token: N/A; 	 diagnostics: N/A; 	 ApplicationMaster host: N/A; 	 ApplicationMaster RPC port: -1; 	 queue: root.users.sun; 	 start ti",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4112:11947,Secur,SecurityManager,11947,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4112,1,['Secur'],['SecurityManager']
Security,"eReadCounts - Deflater: IntelDeflater; 20:08:45.223 INFO DenoiseReadCounts - Inflater: IntelInflater; 20:08:45.223 INFO DenoiseReadCounts - GCS max retries/reopens: 20; 20:08:45.223 INFO DenoiseReadCounts - Using google-cloud-java patch 6d11bef1c81f885c26b2b56c8616b7a705171e4f from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 20:08:45.223 INFO DenoiseReadCounts - Initializing engine; 20:08:45.223 INFO DenoiseReadCounts - Done initializing engine; log4j:WARN No appenders could be found for logger (org.broadinstitute.hdf5.HDF5Library).; log4j:WARN Please initialize the log4j system properly.; log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.; 20:08:45.300 INFO DenoiseReadCounts - Reading read-counts file (BT1813.counts.hdf5)...; HDF5-DIAG: Error detected in HDF5 (1.8.14) thread 0:; #000: /mnt/scr1/abyrne/HDFJava-platypus-2.11/native/HDF5-prefix/src/HDF5/src/H5F.c line 604 in H5Fopen(): unable to open file; major: File accessibilty; minor: Unable to open file; #001: /mnt/scr1/abyrne/HDFJava-platypus-2.11/native/HDF5-prefix/src/HDF5/src/H5Fint.c line 1085 in H5F_open(): unable to read superblock; major: File accessibilty; minor: Read failed; #002: /mnt/scr1/abyrne/HDFJava-platypus-2.11/native/HDF5-prefix/src/HDF5/src/H5Fsuper.c line 277 in H5F_super_read(): file signature not found; major: File accessibilty; minor: Not an HDF5 file; 20:08:49.800 INFO DenoiseReadCounts - Shutting down engine; [May 18, 2021 8:08:49 PM EDT] org.broadinstitute.hellbender.tools.copynumber.DenoiseReadCounts done. Elapsed time: 0.08 minutes.; Runtime.totalMemory()=1789919232; org.broadinstitute.hdf5.HDF5LibException: exception when opening '/hpf/largeprojects/tabori/projects/bmmrd/CNA_project/gatk_cna/gatk/analysis/lgg/cnvponC2.pon.hdf5' with READ_ONLY mode: Not an HDF5 file; at org.broadinstitute.hdf5.HDF5File.open(HDF5File.java:490); at org.broadinstitute.hdf5.HDF5File.<init>(HDF5File.java:82); at org.broadinstitute.hdf5.HDF5File.<init",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7258:4104,access,accessibilty,4104,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7258,1,['access'],['accessibilty']
Security,eTaskExecuter.execute(ExecuteAtMostOnceTaskExecuter.java:43); at org.gradle.execution.taskgraph.DefaultTaskGraphExecuter$EventFiringTaskWorker.execute(DefaultTaskGraphExecuter.java:233); at org.gradle.execution.taskgraph.DefaultTaskGraphExecuter$EventFiringTaskWorker.execute(DefaultTaskGraphExecuter.java:215); at org.gradle.execution.taskgraph.AbstractTaskPlanExecutor$TaskExecutorWorker.processTask(AbstractTaskPlanExecutor.java:74); at org.gradle.execution.taskgraph.AbstractTaskPlanExecutor$TaskExecutorWorker.run(AbstractTaskPlanExecutor.java:55); at org.gradle.execution.taskgraph.DefaultTaskPlanExecutor.process(DefaultTaskPlanExecutor.java:32); at org.gradle.execution.taskgraph.DefaultTaskGraphExecuter.execute(DefaultTaskGraphExecuter.java:113); at org.gradle.execution.SelectedTaskExecutionAction.execute(SelectedTaskExecutionAction.java:37); at org.gradle.execution.DefaultBuildExecuter.execute(DefaultBuildExecuter.java:37); at org.gradle.execution.DefaultBuildExecuter.access$000(DefaultBuildExecuter.java:23); at org.gradle.execution.DefaultBuildExecuter$1.proceed(DefaultBuildExecuter.java:43); at org.gradle.execution.DryRunBuildExecutionAction.execute(DryRunBuildExecutionAction.java:32); at org.gradle.execution.DefaultBuildExecuter.execute(DefaultBuildExecuter.java:37); at org.gradle.execution.DefaultBuildExecuter.execute(DefaultBuildExecuter.java:30); at org.gradle.initialization.DefaultGradleLauncher$4.run(DefaultGradleLauncher.java:186); at org.gradle.internal.Factories$1.create(Factories.java:22); at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:91); at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:53); at org.gradle.initialization.DefaultGradleLauncher.doBuildStages(DefaultGradleLauncher.java:183); at org.gradle.initialization.DefaultGradleLauncher.access$200(DefaultGradleLauncher.java:33); at org.gradle.initialization.DefaultGradleLauncher$1.create(DefaultG,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4155:2967,access,access,2967,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4155,2,['access'],['access']
Security,"e_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx30g -jar /gpfs/data/lab/bin/gatk/gatk-package-4.4.0.0-local.jar FilterAlignmentArtifacts -R /gpfs/data/lab/reference-files/hg38-gatk/Homo_sapiens_assembly38.fasta -V 60603-bulk.filtered.vcf.gz -I /gpfs/data/lab/projects/Mini/analysis/STR/60603-bulk_results/60603-bulk.cram --bwa-mem-index-image /gpfs/data/lab/reference-files/hg38-gatk/Homo_sapiens_assembly38.fasta.img -O 60603-bulk.filtered.FAA.vcf.gz; ```. Error:; ```; 11:02:16.087 INFO ProgressMeter - chrX:144247387 619.0 145000 234.3; 11:05:08.297 WARN IntelInflater - Zero Bytes Written : 0; 12:29:39.297 INFO FilterAlignmentArtifacts - Shutting down engine; [August 15, 2023 at 12:29:39 PM EDT] org.broadinstitute.hellbender.tools.walkers.realignmentfilter.FilterAlignmentArtifacts done. Elapsed time: 710.24 minutes.; Runtime.totalMemory()=4345298944; java.lang.IllegalStateException: Padded span must contain active span.; at org.broadinstitute.hellbender.utils.Utils.validate(Utils.java:814); at org.broadinstitute.hellbender.engine.AssemblyRegion.<init>(AssemblyRegion.java:109); at org.broadinstitute.hellbender.engine.AssemblyRegion.<init>(AssemblyRegion.java:85); at org.broadinstitute.hellbender.engine.AssemblyRegion.<init>(AssemblyRegion.java:120); at org.broadinstitute.hellbender.tools.walkers.realignmentfilter.FilterAlignmentArtifacts.makeAssemblyRegionFromVariantReads(FilterAlignmentArtifacts.java:280); at org.broadinstitute.hellbender.tools.walkers.realignmentfilter.FilterAlignmentArtifacts.apply(FilterAlignmentArtifacts.java:212); at org.broadinstitute.hellbender.engine.MultiVariantWalkerGroupedOnStart.apply(MultiVariantWalkerGroupedOnStart.java:133); at org.broadinstitute.hellbender.engine.MultiVariantWalkerGroupedOnStart.afterTraverse(MultiVariantWalkerGroupedOnStart.java:193); at org.broadinstitute.hellbender.engine.MultiVariantWalkerGroupedOnStart.traverse(MultiVariantWalkerGroupedOnStart.java:166); at org.broadinstitute.hellbender.engine.GATKTo",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8476:1183,validat,validate,1183,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8476,1,['validat'],['validate']
Security,e_tribble=false -Dsamjdk.compression_level=2 --conf spark.kryoserializer.buffer.max=512m --conf spark.yarn.executor.memoryOverhead=600 /root/gatk-4.0.7.0/gatk-package-4.0.7.0-spark.jar PrintReadsSpark -I ../6484_snippet.bam -O ../output.bam --spark-master spark://10.0.0.21:7077; SLF4J: Class path contains multiple SLF4J bindings.; SLF4J: Found binding in [jar:file:/usr/hdp/2.6.3.40-13/spark2/jars/slf4j-log4j12-1.7.16.jar!/org/slf4j/impl/StaticLoggerBinder.class]; SLF4J: Found binding in [jar:file:/usr/hdp/2.6.3.40-13/spark_llap/spark-llap-assembly-1.0.0.2.6.3.40-13.jar!/org/slf4j/impl/StaticLoggerBinder.class]; SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.; SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]; java.lang.NoClassDefFoundError: org/apache/logging/log4j/core/appender/AbstractAppender; at java.lang.ClassLoader.defineClass1(Native Method); at java.lang.ClassLoader.defineClass(ClassLoader.java:763); at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142); at java.net.URLClassLoader.defineClass(URLClassLoader.java:467); at java.net.URLClassLoader.access$100(URLClassLoader.java:73); at java.net.URLClassLoader$1.run(URLClassLoader.java:368); at java.net.URLClassLoader$1.run(URLClassLoader.java:362); at java.security.AccessController.doPrivileged(Native Method); at java.net.URLClassLoader.findClass(URLClassLoader.java:361); at java.lang.ClassLoader.loadClass(ClassLoader.java:424); at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:349); at java.lang.ClassLoader.loadClass(ClassLoader.java:411); at java.lang.ClassLoader.loadClass(ClassLoader.java:357); at org.apache.logging.log4j.core.config.plugins.util.PluginRegistry.decodeCacheFiles(PluginRegistry.java:181); at org.apache.logging.log4j.core.config.plugins.util.PluginRegistry.loadFromMainClassLoader(PluginRegistry.java:119); at org.apache.logging.log4j.core.config.plugins.util.PluginManager.collectPlugins(PluginManager.java:132); at,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5126:2590,Secur,SecureClassLoader,2590,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5126,1,['Secur'],['SecureClassLoader']
Security,eadChannel.java:125); 	at com.google.cloud.storage.contrib.nio.CloudStorageReadChannel.read(CloudStorageReadChannel.java:109); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher$WorkUnit.call(SeekableByteChannelPrefetcher.java:131); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher$WorkUnit.call(SeekableByteChannelPrefetcher.java:104); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745); Caused by: javax.net.ssl.SSLHandshakeException: Remote host closed connection during handshake; 	at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:992); 	at sun.security.ssl.SSLSocketImpl.performInitialHandshake(SSLSocketImpl.java:1375); 	at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1403); 	at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1387); 	at sun.net.www.protocol.https.HttpsClient.afterConnect(HttpsClient.java:559); 	at sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.connect(AbstractDelegateHttpsURLConnection.java:185); 	at sun.net.www.protocol.https.HttpsURLConnectionImpl.connect(HttpsURLConnectionImpl.java:153); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:93); 	at shaded.cloud_nio.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:972); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeMedia(AbstractGoogleClientRequest.java:380); 	at shaded.c,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2685:6542,secur,security,6542,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2685,1,['secur'],['security']
Security,"ed.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 19:53:34.606 INFO ValidateVariants - ------------------------------------------------------------; 19:53:34.606 INFO ValidateVariants - The Genome Analysis Toolkit (GATK) v4.1.8.0; 19:53:34.606 INFO ValidateVariants - For support and documentation go to https://software.broadinstitute.org/gatk/; 19:53:34.607 INFO ValidateVariants - Executing as zepengmu@midway2-login1.rcc.local on Linux v3.10.0-1127.8.2.el7.x86_64 amd64; 19:53:34.607 INFO ValidateVariants - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_45-b14; 19:53:34.607 INFO ValidateVariants - Start Date/Time: October 25, 2020 7:53:34 PM CDT; 19:53:34.607 INFO ValidateVariants - ------------------------------------------------------------; 19:53:34.607 INFO ValidateVariants - ------------------------------------------------------------; 19:53:34.607 INFO ValidateVariants - HTSJDK Version: 2.22.0; 19:53:34.607 INFO ValidateVariants - Picard Version: 2.22.8; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 19:53:34.608 INFO ValidateVariants - Deflater: IntelDeflater; 19:53:34.608 INFO ValidateVariants - Inflater: IntelInflater; 19:53:34.608 INFO ValidateVariants - GCS max retries/reopens: 20; 19:53:34.608 INFO ValidateVariants - Requester pays: disabled; 19:53:34.608 INFO ValidateVariants - Initializing engine; 19:53:35.169 INFO FeatureManager - Using codec VCFCodec to read file file://chr1-22.phased.rename.reheader.vcf.gz; 19:53:35.594 INFO ValidateVariants - Done initializing engine; 19:53:35.594 WARN ValidateVariants - IDS validation cannot be done",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6911:1926,Validat,ValidateVariants,1926,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6911,1,['Validat'],['ValidateVariants']
Security,ee http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.; 21:06:12.479 INFO FeatureManager - Using codec IntervalListCodec to read file file:///paedyl01/disk1/louisshe/work/NGS/wdl/test_workflow_cnv/germline/cromwell-executions/CNVGuts/-947966988/Homo_sapiens_assembly38.bed.preprocessed.filtered.scattered.0154.interval_list; 21:06:12.640 DEBUG FeatureDataSource - Cache statistics for FeatureInput /paedyl01/disk1/louisshe/work/NGS/wdl/test_workflow_cnv/germline/cromwell-executions/CNVGermlineCohort8/Homo_sapiens_assembly38.bed.preprocessed.filtered.scattered.0154.interval_list:/paedyl01/disk1/louisshe/work/NGS/wdl/test_workflow_cnv/germline/cromwell-executions/CNVGermli947966988/Homo_sapiens_assembly38.bed.preprocessed.filtered.scattered.0154.interval_list:; 21:06:12.640 DEBUG FeatureCache - Cache hit rate was 0.00% (0 out of 0 total queries); 21:06:12.645 INFO IntervalArgumentCollection - Processing 4999155 bp from intervals; 21:06:12.656 INFO GermlineCNVCaller - Reading and validating annotated intervals...; 21:06:18.914 WARN GermlineCNVCaller - Sequence dictionary in annotated-intervals file does not match the master sequence dictionary.; 21:06:19.130 INFO GermlineCNVCaller - GC-content annotations for intervals found; explicit GC-bias correction will be performed...; 21:06:19.200 INFO GermlineCNVCaller - Running the tool in COHORT mode...; 21:06:19.200 INFO GermlineCNVCaller - Validating and aggregating data from input read-count files...; 21:07:11.897 DEBUG ScriptExecutor - Executing:; 21:07:11.897 DEBUG ScriptExecutor - python; 21:07:11.897 DEBUG ScriptExecutor - /paedyl01/disk1/louisshe/tmp/gatk/cohort_denoising_calling.418897092082188314.py; 21:07:11.897 DEBUG ScriptExecutor - --ploidy_calls_path=/paedyl01/disk1/louisshe/work/NGS/wdl/test_workflow_cnv/germline/cromwell-executions/CNVGermlineCohortWorkflow/d53c0a; 21:07:11.897 DEBUG ScriptExecutor - --output_calls_path=/paedyl01/disk1/louisshe/out/NMD/batch1_2023/batch1_all/cnv/cohort_calls/batc,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8952:6615,validat,validating,6615,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8952,1,['validat'],['validating']
Security,"egions within the reference,; > and therefore will have fine mapping quality even though they are artifacts.; >; > There are published ""decoy genomes"" -- essentially pseudo-contigs of; > regions missing from the reference, and mapping with BWA in memory to; > *those* might be very helpful.; >; > So, we need to: 1) get our hands on a decoy genome that will play nicely; > with BWA, and 2) talk to the SV team.; >; > —; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk-protected/issues/844#issuecomment-296515266>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AGRhdCJQob4WqdwDN0R8jvbNGT1l0vSCks5rzBOmgaJpZM4Lb8pz>; > .; >. ---. @davidbenjamin commented on [Wed May 03 2017](https://github.com/broadinstitute/gatk-protected/issues/844#issuecomment-298946022). Copying comments from closed issue #993. Instead of running an aligner in memory, let's first try preprocessing an alignability (to the ref + decoy) resource file. Then we can simply query this file at each called variant. > ENCODE used a kmer size of 36 bp, which is seriously obsolete and will tend to underestimate alignability. However, the GEM program (paper here: http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0030377 and binary here: http://algorithms.cnag.cat/wiki/The_GEM_library#Documentation and blog post on how to run it here: http://blog.kokocinski.net/index.php/sequence-mappability-alignability?blog=2) was used by ENCODE to produce this track and we can easily produce it ourselves with any kmer size and any mismatch threshold. > Furthermore, once we make this track we can store this track in memory eg as a `HashedListTargetCollection` and therefore we can query it for every read to get an annotation for the number of uniquely mappable reads (up to some error tolerance). > One more thing: we can also query based on the start position of each read's mate.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2930:5486,Hash,HashedListTargetCollection,5486,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2930,1,['Hash'],['HashedListTargetCollection']
Security,eline_app/Apps/GATK/gatk-4.1.9.0/gatk-package-4.1.9.0-local.jar) to method java.nio.Bits.unaligned(); WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform; WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations; WARNING: All illegal access operations will be denied in a future release; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; 21/01/12 15:50:31 INFO SparkContext: Running Spark version 2.4.5; 21/01/12 15:50:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 21/01/12 15:50:31 INFO SparkContext: Submitted application: MarkDuplicatesSpark; 21/01/12 15:50:31 INFO SecurityManager: Changing view acls to: root; 21/01/12 15:50:31 INFO SecurityManager: Changing modify acls to: root; 21/01/12 15:50:31 INFO SecurityManager: Changing view acls groups to: ; 21/01/12 15:50:31 INFO SecurityManager: Changing modify acls groups to: ; 21/01/12 15:50:31 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); groups with view permissions: Set(); users with modify permissions: Set(root); groups with modify permissions: Set(); 21/01/12 15:50:31 INFO Utils: Successfully started service 'sparkDriver' on port 36657.; 21/01/12 15:50:31 INFO SparkEnv: Registering MapOutputTracker; 21/01/12 15:50:31 INFO SparkEnv: Registering BlockManagerMaster; 21/01/12 15:50:31 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information; 21/01/12 15:50:31 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up; 21/01/12 15:50:31 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-273b4c87-579e-4d57-81de-aa47a79634bb; 21/01/12 15:50:31 INFO MemoryStore: MemoryStore started with capacity 9.2 GB; 21/01/12 15:50:31 INFO SparkEnv: Registering OutputCommitCoordinator; 21/,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7035:1101,Secur,SecurityManager,1101,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7035,7,"['Secur', 'authenticat']","['SecurityManager', 'authentication']"
Security,"ellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289); ```. The user mentioned that this didn't happen on GATK 4.1, so I've been comparing both versions of the code. It turns out that the implementation of ""GenotypingEngine.java"" has changed since then, and after some digging, I noticed that the issue is that the newer versions have uninitialized instances of the class ""OneShotLogger"". The fix is simple, I've added the change myself and built GATK again. The user reports that the issue is gone. Just add the following code inside the constructor method:. ``` ; protected GenotypingEngine(final Config configuration,; final SampleList samples,; final boolean doAlleleSpecificCalcs) {; this.configuration = Utils.nonNull(configuration, ""the configuration cannot be null"");; Utils.validate(!samples.asListOfSamples().isEmpty(), ""the sample list cannot be null or empty"");; this.samples = samples;; this.doAlleleSpecificCalcs = doAlleleSpecificCalcs;; logger = LogManager.getLogger(getClass());; this.oneShotLogger = new OneShotLogger(logger); // <------ ADD THIS LINE; numberOfGenomes = this.samples.numberOfSamples() * configuration.genotypeArgs.samplePloidy;; alleleFrequencyCalculator = AlleleFrequencyCalculator.makeCalculator(configuration.genotypeArgs);; }; ```. #### Steps to reproduce; See description, but I can't provide the exact inputs used for it. #### Expected behavior; The null pointer exception shouldn't occur, there should be a warning only. #### Actual behavior; Program crashes with null pointer exception for high enough values of ploidy.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8158:3863,validat,validate,3863,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8158,1,['validat'],['validate']
Security,ellbender/tools/splitNCigarReadsSnippet.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/split_reads.bam; src/test/resources/org/broadinstitute/hellbender/tools/split_reads.cram; src/test/resources/org/broadinstitute/hellbender/tools/split_reads.dict; src/test/resources/org/broadinstitute/hellbender/tools/split_reads.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/split_reads_missing_lib.bam; src/test/resources/org/broadinstitute/hellbender/tools/split_reads_missing_lib.cram; src/test/resources/org/broadinstitute/hellbender/tools/split_reads_missing_lib.dict; src/test/resources/org/broadinstitute/hellbender/tools/split_reads_missing_lib.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/split_reads_missing_lib.sam; src/test/resources/org/broadinstitute/hellbender/tools/split_reads.sam; src/test/resources/org/broadinstitute/hellbender/tools/validation/marked.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.bam; src/test/resources/org/broadinstitute/hellbender/tools/validation/picard.marked.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.bam; src/test/resources/org/broadinstitute/hellbender/tools/validation/single.read.bai; src/test/resources/org/broadinstitute/hellbender/tools/valid.cram.crai; src/test/resources/org/broadinstitute/hellbender/tools/valid.dict; src/test/resources/org/broadinstitute/hellbender/tools/valid.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/VQSR/VQSR.AStest.indels.recal.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/VQSR/VQSR.AStest.input.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/VQSR/VQSR.AStest.postSNPinput.HACKEDhg38header.vcf.gz.tbi; src/test/resources/org/broadinstitute/hellbender/tools/VQSR/VQSR.AStest.postSNPinput.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/VQSR/VQSR.AStest.snps.recal.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/VQSR/VQSR.mixedTest.input.vcf.idx; src/test/resources/org/broadinstitute/hel,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3905:45664,validat,validation,45664,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905,1,['validat'],['validation']
Security,emBase.java:2185); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.configure(GoogleHadoopFileSystemBase.java:1832); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.initialize(GoogleHadoopFileSystemBase.java:1013); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.initialize(GoogleHadoopFileSystemBase.java:976); 	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2812); 	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:100); 	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2849); 	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2831); 	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:389); 	at org.apache.hadoop.fs.FileSystem$1.run(FileSystem.java:171); 	at org.apache.hadoop.fs.FileSystem$1.run(FileSystem.java:168); 	at java.base/java.security.AccessController.doPrivileged(Native Method); 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423); 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1836); 	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:168); 	at org.genomicsdb.reader.GenomicsDBQueryStream.jniGenomicsDBInit(Native Method); 	at org.genomicsdb.reader.GenomicsDBQueryStream.<init>(GenomicsDBQueryStream.java:209); 	at org.genomicsdb.reader.GenomicsDBQueryStream.<init>(GenomicsDBQueryStream.java:182); 	at org.genomicsdb.reader.GenomicsDBQueryStream.<init>(GenomicsDBQueryStream.java:91); 	at org.genomicsdb.reader.GenomicsDBFeatureReader.generateHeadersForQuery(GenomicsDBFeatureReader.java:176); 	at org.genomicsdb.reader.GenomicsDBFeatureReader.<init>(GenomicsDBFeatureReader.java:80); 	at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImportIntegrationTest.getGenomicsDBFeatureReader(GenomicsDBImportIntegrationTest.java:926); 	at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImportIntegrationTest.checkGenomicsDBAgainstExpected(GenomicsDBImportIntegrationTest.java:550); 	at org.broadinstitu,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6522:1696,secur,security,1696,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6522,1,['secur'],['security']
Security,emory including 384 MB overhead; 18/01/09 18:30:58 INFO yarn.Client: Setting up container launch context for our AM; 18/01/09 18:30:58 INFO yarn.Client: Setting up the launch environment for our AM container; 18/01/09 18:30:58 INFO yarn.Client: Preparing resources for our AM container; 18/01/09 18:30:59 INFO yarn.Client: Uploading resource file:/tmp/sun/spark-5a3e539e-2e2b-4da2-b218-2bda166bd4c0/__spark_conf__7100950787185363106.zip -> hdfs://tele-1:8020/user/sun/.sparkStaging/application_1515493209401_0001/__spark_conf__.zip; 18/01/09 18:31:00 INFO spark.SecurityManager: Changing view acls to: sun; 18/01/09 18:31:00 INFO spark.SecurityManager: Changing modify acls to: sun; 18/01/09 18:31:00 INFO spark.SecurityManager: Changing view acls groups to: ; 18/01/09 18:31:00 INFO spark.SecurityManager: Changing modify acls groups to: ; 18/01/09 18:31:00 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(sun); groups with view permissions: Set(); users with modify permissions: Set(sun); groups with modify permissions: Set(); 18/01/09 18:31:00 INFO yarn.Client: Submitting application application_1515493209401_0001 to ResourceManager; 18/01/09 18:31:00 INFO impl.YarnClientImpl: Submitted application application_1515493209401_0001; 18/01/09 18:31:00 INFO cluster.SchedulerExtensionServices: Starting Yarn extension services with app application_1515493209401_0001 and attemptId None; 18/01/09 18:31:01 INFO yarn.Client: Application report for application_1515493209401_0001 (state: ACCEPTED); 18/01/09 18:31:01 INFO yarn.Client: ; 	 client token: N/A; 	 diagnostics: N/A; 	 ApplicationMaster host: N/A; 	 ApplicationMaster RPC port: -1; 	 queue: root.users.sun; 	 start time: 1515493860237; 	 final status: UNDEFINED; 	 tracking URL: http://tele-1:8088/proxy/application_1515493209401_0001/; 	 user: sun; 18/01/09 18:31:02 INFO yarn.Client: Application report for application_1515493209401_0001 (state: ACCEPTED); 18/01/09,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4112:12105,Secur,SecurityManager,12105,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4112,3,"['Secur', 'authenticat']","['SecurityManager', 'authentication']"
Security,"en't according to the number of alt alleles); ### Test data. /humgen/gsa-hpprojects/dev/gauthier/scratch/supportingMultiA.vcf; Should fail AC/AF validation at ; `1 768589 . A C,G 76 PASS AC=1;AF=0.00047;AN=2120`; See results using:. ```; use VCFtools; vcf-validator /humgen/gsa-hpprojects/dev/gauthier/scratch/supportingMultiA.vcf; ```. which outputs:; `INFO field at 1:768589 .. INFO tag [AC=1] expected different number of values (expected 2, found 1),INFO tag [AF=0.00047] expected different number of values (expected 2, found 1)`; ### Notes. Currently, all the validation modes call out to HTSJDK. Do we want to put the new functionality there as well?. ---. @yfarjoun commented on [Thu Jul 16 2015](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-122130280). I think that it is very appropriate to validate in htsjdk. On Thu, Jul 16, 2015 at 4:05 PM, ldgauthier notifications@github.com; wrote:. > Currently ValidateVariants relies on genotypes to transitively check that; > each alt allele occurs in at least one sample and that the AC adds up.; > However, this can fail on sites-only files because there are no genotypes.; > We should use the definition of the info annotations in the header to check; > how many entries each should have.; > Outline; > - Add a new validation type for info-field counts to enum and to; > switch statement; > - Grab info headers from input VCF with something like; > GATKVCFUtils.getVCFHeadersFromRods(getToolkit(),; > variantCollection.variants.getName()) and VCFHeader::getInfoHeaderLines; > - In the map() function, for each info header line, call on each; > VCFInfoHeaderLine getCount(vc) to get the expected number of info; > annotation entries; > - Compare the expected number with a count based on; > vc.getAttribute(currentVCFinfoHeaderLine.getID()), which will require some; > additional parsing because it returns an Object; > - (Bonus points if you use the isFixedCount() and getCount() functions; > on the VCF info header li",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2507:2125,Validat,ValidateVariants,2125,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2507,1,['Validat'],['ValidateVariants']
Security,en; 443301511749-compute@developer.gserviceaccount.com does not have storage.objects.get access to broad-jg-dev-11k-call-set/JointGenotyping/0cb36821-b8bf-4e6d-a352-07b101f6b7d1/call-ApplyRecalibration/shard-1734/GMKF_Seidman_CHD_WGS_904.filtered.1734.vcf.gz.; 	at java.util.concurrent.FutureTask.report(FutureTask.java:122); 	at java.util.concurrent.FutureTask.get(FutureTask.java:192); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher$WorkUnit.getBuf(SeekableByteChannelPrefetcher.java:136); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher.fetch(SeekableByteChannelPrefetcher.java:255); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher.read(SeekableByteChannelPrefetcher.java:300); 	... 10 more; Caused by: com.google.cloud.storage.StorageException: 403 Forbidden; 443301511749-compute@developer.gserviceaccount.com does not have storage.objects.get access to broad-jg-dev-11k-call-set/JointGenotyping/0cb36821-b8bf-4e6d-a352-07b101f6b7d1/call-ApplyRecalibration/shard-1734/GMKF_Seidman_CHD_WGS_904.filtered.1734.vcf.gz.; 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.translate(HttpStorageRpc.java:189); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.read(HttpStorageRpc.java:526); 	at com.google.cloud.storage.BlobReadChannel$1.call(BlobReadChannel.java:127); 	at com.google.cloud.storage.BlobReadChannel$1.call(BlobReadChannel.java:124); 	at shaded.cloud_nio.com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:94); 	at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:54); 	at com.google.cloud.storage.BlobReadChannel.read(BlobReadChannel.java:124); 	at com.google.cloud.storage.contrib.nio.CloudStorageReadChannel.read(CloudStorageReadChannel.java:114); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher$WorkUnit.call(SeekableByteChannelPrefetcher.java:131); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher$WorkUni,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3735:3476,access,access,3476,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3735,1,['access'],['access']
Security,"engine; 17:43:53.270 INFO FeatureManager - Using codec VCFCodec to read file file:///Users/louisb/Workspace/gatk/src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleGood.vcf; 17:43:53.287 INFO FeatureManager - Using codec VCFCodec to read file file:///Users/louisb/Workspace/gatk/src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleGood.vcf; 17:43:53.291 WARN IndexUtils - Feature file ""/Users/louisb/Workspace/gatk/src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleGood.vcf"" appears to contain no sequence dictionary. Attempting to retrieve a sequence dictionary from the associated index file; 17:43:53.293 INFO ValidateVariants - Done initializing engine; 17:43:53.294 INFO ProgressMeter - Starting traversal; 17:43:53.294 INFO ProgressMeter - Current Locus Elapsed Minutes Records Processed Records/Minute; 17:43:53.302 INFO ValidateVariants - Shutting down engine; [March 21, 2017 5:43:53 PM EDT] org.broadinstitute.hellbender.tools.walkers.variantutils.ValidateVariants done. Elapsed time: 0.00 minutes.; Runtime.totalMemory()=194510848; java.lang.IllegalArgumentException: Illegal base [] seen in the allele; 	at htsjdk.variant.variantcontext.Allele.create(Allele.java:231); 	at htsjdk.variant.variantcontext.Allele.create(Allele.java:374); 	at org.broadinstitute.hellbender.tools.walkers.variantutils.ValidateVariants.apply(ValidateVariants.java:181); 	at org.broadinstitute.hellbender.engine.VariantWalkerBase.lambda$traverse$0(VariantWalkerBase.java:104); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.str",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2509:4119,Validat,ValidateVariants,4119,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2509,1,['Validat'],['ValidateVariants']
Security,"enotypeGVCFs \; 	-R 128_Mmul_10.fasta \; 	--variant gendb:///home/exacloud/gscratch/prime-seq/cachedData/16b9ede7-6db8-103a-9262-f8f3fc86a851/WGS_Feb22_1852.gdb \; 	-O /home/exacloud/gscratch/prime-seq/workDir/1bb5295c-6ec5-103a-8692-f8f3fc86cd3f/Job1.work/WGS_pre-mGAPv2.3_1852.vcf.gz \; 	--annotate-with-num-discovered-alleles \; 	-stand-call-conf 30 \; 	--max-alternate-alleles 6 \; 	--force-output-intervals mmul10.WGS-WXS.whitelist.v2.3.sort.merge.bed \; 	-L 1:1-3714165 \; 	--only-output-calls-starting-in-intervals \; 	--genomicsdb-shared-posixfs-optimizations; ```. and the exception:. ```; Exception in thread ""main"" java.lang.NoClassDefFoundError: org/broadinstitute/hellbender/relocated/com/google/common/base/Function; 	at org.broadinstitute.hellbender.Main.<clinit>(Main.java:45); Caused by: java.lang.ClassNotFoundException: org.broadinstitute.hellbender.relocated.com.google.common.base.Function; 	at java.net.URLClassLoader$1.run(URLClassLoader.java:370); 	at java.net.URLClassLoader$1.run(URLClassLoader.java:362); 	at java.security.AccessController.doPrivileged(Native Method); 	at java.net.URLClassLoader.findClass(URLClassLoader.java:361); 	at java.lang.ClassLoader.loadClass(ClassLoader.java:424); 	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331); 	at java.lang.ClassLoader.loadClass(ClassLoader.java:357); 	... 1 more; Caused by: java.util.zip.ZipException: invalid LOC header (bad signature); 	at java.util.zip.ZipFile.read(Native Method); 	at java.util.zip.ZipFile.access$1400(ZipFile.java:60); 	at java.util.zip.ZipFile$ZipFileInputStream.read(ZipFile.java:716); 	at java.util.zip.ZipFile$ZipFileInflaterInputStream.fill(ZipFile.java:419); 	at java.util.zip.InflaterInputStream.read(InflaterInputStream.java:158); 	at sun.misc.Resource.getBytes(Resource.java:124); 	at java.net.URLClassLoader.defineClass(URLClassLoader.java:462); 	at java.net.URLClassLoader.access$100(URLClassLoader.java:73); 	at java.net.URLClassLoader$1.run(URLClassLoader.java:368). ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7675:1632,secur,security,1632,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7675,4,"['Access', 'access', 'secur']","['AccessController', 'access', 'security']"
Security,"ent with the command:; ```; conda env create -n gatk -f scripts/gatkcondaenv.yml; ```; This currently fails with the following message (at least on MacOS):; ```; Requirement 'build/gatkPythonPackageArchive.zip' looks like a filename, but the file does not exist; Processing ./build/gatkPythonPackageArchive.zip; Exception:; Traceback (most recent call last):; File ""/Users/markw/anaconda/envs/gatk/lib/python3.6/site-packages/pip/basecommand.py"", line 215, in main; status = self.run(options, args); File ""/Users/markw/anaconda/envs/gatk/lib/python3.6/site-packages/pip/commands/install.py"", line 335, in run; wb.build(autobuilding=True); File ""/Users/markw/anaconda/envs/gatk/lib/python3.6/site-packages/pip/wheel.py"", line 749, in build; self.requirement_set.prepare_files(self.finder); File ""/Users/markw/anaconda/envs/gatk/lib/python3.6/site-packages/pip/req/req_set.py"", line 380, in prepare_files; ignore_dependencies=self.ignore_dependencies)); File ""/Users/markw/anaconda/envs/gatk/lib/python3.6/site-packages/pip/req/req_set.py"", line 620, in _prepare_file; session=self.session, hashes=hashes); File ""/Users/markw/anaconda/envs/gatk/lib/python3.6/site-packages/pip/download.py"", line 809, in unpack_url; unpack_file_url(link, location, download_dir, hashes=hashes); File ""/Users/markw/anaconda/envs/gatk/lib/python3.6/site-packages/pip/download.py"", line 715, in unpack_file_url; unpack_file(from_path, location, content_type, link); File ""/Users/markw/anaconda/envs/gatk/lib/python3.6/site-packages/pip/utils/__init__.py"", line 599, in unpack_file; flatten=not filename.endswith('.whl'); File ""/Users/markw/anaconda/envs/gatk/lib/python3.6/site-packages/pip/utils/__init__.py"", line 482, in unzip_file; zipfp = open(filename, 'rb'); FileNotFoundError: [Errno 2] No such file or directory: '/Users/markw/IdeaProjects/gatk/scripts/build/gatkPythonPackageArchive.zip'; ```; Moving gatkcondaenv.yml to the GATK root solves the issue. We can either change the yml location or modify the readme.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4741:1148,hash,hashes,1148,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4741,4,['hash'],['hashes']
Security,ent: Uploading resource file:/tmp/spark-28ab5ef4-82d1-425e-879f-5056e9b51e43/__spark_libs__7655440475844189559.zip -> hdfs://192.168.0.104:9000/user/jacky/.sparkStaging/application_1603353714322_0004/__spark_libs__7655440475844189559.zip; 20/10/22 12:02:31 INFO yarn.Client: Uploading resource file:/home/jacky/Exec/gatk/build/libs/gatk-spark.jar -> hdfs://192.168.0.104:9000/user/jacky/.sparkStaging/application_1603353714322_0004/gatk-spark.jar; 20/10/22 12:02:33 INFO yarn.Client: Uploading resource file:/tmp/spark-28ab5ef4-82d1-425e-879f-5056e9b51e43/__spark_conf__3248804172036151699.zip -> hdfs://192.168.0.104:9000/user/jacky/.sparkStaging/application_1603353714322_0004/__spark_conf__.zip; 20/10/22 12:02:33 INFO spark.SecurityManager: Changing view acls to: jacky; 20/10/22 12:02:33 INFO spark.SecurityManager: Changing modify acls to: jacky; 20/10/22 12:02:33 INFO spark.SecurityManager: Changing view acls groups to: ; 20/10/22 12:02:33 INFO spark.SecurityManager: Changing modify acls groups to: ; 20/10/22 12:02:33 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(jacky); groups with view permissions: Set(); users with modify permissions: Set(jacky); groups with modify permissions: Set(); 20/10/22 12:02:33 INFO yarn.Client: Submitting application application_1603353714322_0004 to ResourceManager; 20/10/22 12:02:33 INFO impl.YarnClientImpl: Submitted application application_1603353714322_0004; 20/10/22 12:02:34 INFO yarn.Client: Application report for application_1603353714322_0004 (state: ACCEPTED); 20/10/22 12:02:34 INFO yarn.Client: ; 	 client token: N/A; 	 diagnostics: N/A; 	 ApplicationMaster host: N/A; 	 ApplicationMaster RPC port: -1; 	 queue: default; 	 start time: 1603360953394; 	 final status: UNDEFINED; 	 tracking URL: http://jacky:8088/proxy/application_1603353714322_0004/; 	 user: jacky; 20/10/22 12:02:35 INFO yarn.Client: Application report for application_1603353714322_0004 (state: AC,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6906:3481,Secur,SecurityManager,3481,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6906,1,['Secur'],['SecurityManager']
Security,"epare, factored out sample name (#7288); - Remove training sites only param from ExtractFeatures broadinstitute/dsp-spec-ops#261; - add param for mem for indels (#7282); - Ah prepare localize option (#7299); - Export sites only vcf STEP 1-- 317 add AC, AN, AF to the final VCF (#7279); - AoU GVS Cohort Extract wdl (#7242); - reliability (#7310); - bump to include FT tag filtering (#7316); - First pass at a Terra QuickStart (#7267); - Ah fix timestamp query (#7319); - 313 Cleanup Extract Cohort params (#7293); - bump bq storage version. See GVS-332 (#7330); - Variant Store extraction - Add VCF size to output (#7329); - add WARP-style scattering to SNPsVariantRecalibrator in GvsCreateFilterSet (#7320); - added ref ranges support (#7337); - 318 Sites only filtered vcf then annotate wdl (#7305); - Replace service_account_json (file) with service_account_json_path (string) to allow call-caching (#7347); - Parallelize create filterset by breaking out the 3 filter set file creation/loads into separate tasks (#7342); - Create WDL to validate VAT and add first test (#7352); - Add task for VAT validation #3 (#7360); - Add task for VAT validation #4 (#7363); - Instructions on how to download BQ Metadata and visualize results (#7359); - don't mix contigs, rightsize memory (#7361); - Add custom annotations as ac an af (#7351); - Add task for VAT validation #8 & 9 (#7364); - added bcftools, upgraded gcloud version (#7369); - fix wdl (#7378); - Update .dockstore.yml; - Add VAT validation rule #5 [VS-16] (#7365); - Add VAT validation rule #7 [VS-14] and validation rule #6 [VS-15] (#7379); - Batching of samples for create import TSVs (#7382); - Add VAT validation rule #2 [VS-19] (#7374); - Create VAT scripts directory (#7386); - fixing SA change from file to string (#7371); - add extract_subpop script (#7387); - Add is_loaded column to sample_info and logic to populate after ingest [VS-158] (#7389); - Add Gnomad subpopulation info into the VAT (#7381); - implement GVS ID assignment (#",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8248:15969,validat,validate,15969,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8248,8,['validat'],"['validate', 'validation']"
Security,eq.1mb.1RG.sg4.table.gz; src/test/resources/org/broadinstitute/hellbender/tools/HiSeq.1mb.1RG.sg5.table.gz; src/test/resources/org/broadinstitute/hellbender/tools/Homo_sapiens_assembly18.10k_lines.dict; src/test/resources/org/broadinstitute/hellbender/tools/Homo_sapiens_assembly18.10k_lines.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/mutect/dream/vcfs/dream3-chr20.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/mutect/dream/vcfs/sample_1.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/mutect/dream/vcfs/sample_2.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/mutect/dream/vcfs/sample_3.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/mutect/dream/vcfs/sample_4.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/mutect/na12878-chr20-consumes-zero-reference-bases.bai; src/test/resources/org/broadinstitute/hellbender/tools/mutect/repeated_reads.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/mutect/validation/nearby_indels.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/NA12878.rg_subset.chr1.recal_data.table.gz; src/test/resources/org/broadinstitute/hellbender/tools/NA12878.rg_subset.chrY_Plus.recal_data.table.gz; src/test/resources/org/broadinstitute/hellbender/tools/originalQuals.chr1.1-1K.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/print_reads.chr1only.dict; src/test/resources/org/broadinstitute/hellbender/tools/print_reads.chr1only.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/print_reads.dict; src/test/resources/org/broadinstitute/hellbender/tools/print_reads.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/print_reads.intervals; src/test/resources/org/broadinstitute/hellbender/tools/print_reads_sorted.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/print_reads.sorted.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/print_reads.sorted.chr1_1.bam.bai; ,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3905:39469,validat,validation,39469,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905,1,['validat'],['validation']
Security,"er container); 17/10/11 14:19:12 INFO yarn.Client: Will allocate AM container, with 896 MB memory including 384 MB overhead; 17/10/11 14:19:12 INFO yarn.Client: Setting up container launch context for our AM; 17/10/11 14:19:12 INFO yarn.Client: Setting up the launch environment for our AM container; 17/10/11 14:19:12 INFO yarn.Client: Preparing resources for our AM container; 17/10/11 14:19:12 INFO gcs.GoogleHadoopFileSystemBase: GHFS version: 1.6.1-hadoop2; 17/10/11 14:19:12 INFO yarn.Client: Uploading resource file:/tmp/hdfs/spark-8c88439f-dcb0-48b2-86f3-fc82cef4c438/__spark_conf__8945422067005652415.zip -> hdfs://mg:8020/user/hdfs/.sparkStaging/application_1507683879816_0006/__spark_conf__8945422067005652415.zip; 17/10/11 14:19:13 INFO spark.SecurityManager: Changing view acls to: hdfs; 17/10/11 14:19:13 INFO spark.SecurityManager: Changing modify acls to: hdfs; 17/10/11 14:19:13 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(hdfs); users with modify permissions: Set(hdfs); 17/10/11 14:19:13 INFO yarn.Client: Submitting application 6 to ResourceManager; 17/10/11 14:19:13 INFO impl.YarnClientImpl: Submitted application application_1507683879816_0006; 17/10/11 14:19:14 INFO yarn.Client: Application report for application_1507683879816_0006 (state: ACCEPTED); 17/10/11 14:19:14 INFO yarn.Client: ; 	 client token: N/A; 	 diagnostics: N/A; 	 ApplicationMaster host: N/A; 	 ApplicationMaster RPC port: -1; 	 queue: root.users.hdfs; 	 start time: 1507702753100; 	 final status: UNDEFINED; 	 tracking URL: http://mg:8088/proxy/application_1507683879816_0006/; 	 user: hdfs; 17/10/11 14:19:15 INFO yarn.Client: Application report for application_1507683879816_0006 (state: ACCEPTED); 17/10/11 14:19:15 INFO cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as NettyRpcEndpointRef(null); 17/10/11 14:19:15 INFO cluster.YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686:6305,Secur,SecurityManager,6305,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686,3,"['Secur', 'authenticat']","['SecurityManager', 'authentication']"
Security,"er of query methods in GoogleGenomicsReadAdapter adapter; throw if the corresponding field is not present in the underlying read. For some; of these there are guard methods you can call to avoid this (see for example; the changes in ReadUtils.java), but for some of the others I'm not sure how to; usefully query the state without already knowing the answer, ie.:. -isSupplementaryAlignment; -isSecondaryAlignment,; -failsVendorQualityCheck; -isDuplicate; -mateIsReverseStrand. To have fidelity with SAMRecord.getSAMString , we need to be able to query these; (as does ReadUtils.getFlags, which has a similar problem, but I changed that to; use guard methods to prevent throwing). In a couple of cases I had to change; the Read adapter to not throw. We need to figure out if this kind; of change is ok. or what the alternative is. 2) This is incidental to this PR, but there are a few inconsistencies between how; GenomicsConverter.makeSAMRecord and ReadUtils compute derived state values, ie. flags.; I can work around these in the getSAMString tests (I'm using Read->SAMRecord; conversions to validate the tests), but the underlying format conversions; are inconsistent. Should we align them ?. For example, GenomicsConverter sets the firstInPair flag on the SAMRecord if readNumber==0,; even if numberOfReads==1, whereas the ReadUtils/GoogleReadAdapter requires readNumber==0; and numberOfReads==2. Likewise the unmapped flag is determined differently: Genomics converter: (http://google-genomics.readthedocs.org/en/latest/migrating_tips.html):; final boolean unmapped = (read.getAlignment() == null || ; read.getAlignment().getPosition() == null || ; read.getAlignment().getPosition().getPosition() == null);; ReadUtils:; private boolean positionIsUnmapped( final Position position ) {; return position == null ||; position.getReferenceName() == null || position.getReferenceName().equals(SAMRecord.NO_ALIGNMENT_REFERENCE_NAME) ||; position.getPosition() == null || position.getPosition() < 0;; }",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/871:1160,validat,validate,1160,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/871,1,['validat'],['validate']
Security,"er.vcf.gz -R ../../../../index/hg19.fa.gz; 19:53:34.379 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/zepengmu/tools/gatk-4.1.8.0/gatk-package-4.1.8.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Oct 25, 2020 7:53:34 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 19:53:34.606 INFO ValidateVariants - ------------------------------------------------------------; 19:53:34.606 INFO ValidateVariants - The Genome Analysis Toolkit (GATK) v4.1.8.0; 19:53:34.606 INFO ValidateVariants - For support and documentation go to https://software.broadinstitute.org/gatk/; 19:53:34.607 INFO ValidateVariants - Executing as zepengmu@midway2-login1.rcc.local on Linux v3.10.0-1127.8.2.el7.x86_64 amd64; 19:53:34.607 INFO ValidateVariants - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_45-b14; 19:53:34.607 INFO ValidateVariants - Start Date/Time: October 25, 2020 7:53:34 PM CDT; 19:53:34.607 INFO ValidateVariants - ------------------------------------------------------------; 19:53:34.607 INFO ValidateVariants - ------------------------------------------------------------; 19:53:34.607 INFO ValidateVariants - HTSJDK Version: 2.22.0; 19:53:34.607 INFO ValidateVariants - Picard Version: 2.22.8; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 19:53:34.608 INFO ValidateVariants - Deflater: IntelDeflater; 19:53:34.608 INFO ValidateVariants - Inflater: IntelInflater; 19:53:34.608 INFO ValidateVariants - GCS max retries/reopens: 20; 19:53:34.608 INFO ValidateVariants - Requester pays: disabled; 19:53:34.608 INFO ValidateVariants - I",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6911:1641,Validat,ValidateVariants,1641,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6911,1,['Validat'],['ValidateVariants']
Security,"er: IntelDeflater; 10:33:37.513 INFO Mutect2 - Inflater: IntelInflater; 10:33:37.514 INFO Mutect2 - GCS max retries/reopens: 20; 10:33:37.514 INFO Mutect2 - Requester pays: disabled; 10:33:37.514 INFO Mutect2 - Initializing engine; 10:33:37.874 INFO Mutect2 - Shutting down engine; [August 28, 2019 at 10:33:37 AM GMT] org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2 done. Elapsed time: 0.05 minutes.; Runtime.totalMemory()=161480704; java.lang.NullPointerException; at org.broadinstitute.hellbender.utils.SequenceDictionaryUtils.getContigNames(SequenceDictionaryUtils.java:463); at org.broadinstitute.hellbender.utils.SequenceDictionaryUtils.getCommonContigsByName(SequenceDictionaryUtils.java:457); at org.broadinstitute.hellbender.utils.SequenceDictionaryUtils.compareDictionaries(SequenceDictionaryUtils.java:234); at org.broadinstitute.hellbender.utils.SequenceDictionaryUtils.validateDictionaries(SequenceDictionaryUtils.java:150); at org.broadinstitute.hellbender.utils.SequenceDictionaryUtils.validateDictionaries(SequenceDictionaryUtils.java:98); at org.broadinstitute.hellbender.engine.GATKTool.validateSequenceDictionaries(GATKTool.java:769); at org.broadinstitute.hellbender.engine.GATKTool.onStartup(GATKTool.java:711); at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.onStartup(AssemblyRegionWalker.java:161); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:137); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:162); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:205); at org.broadinstitute.hellbender.Main.main(Main.java:291). This Issue was generated from your [forums] ; [forums]: https://gatkforums.broadinstitute.org/gatk/discussion/comment/60577#Comment_60577",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6142:3501,validat,validateDictionaries,3501,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6142,2,['validat'],"['validateDictionaries', 'validateSequenceDictionaries']"
Security,erException` instead. ```; ./gatk-launch BwaSpark -I hdfs://sn1:8020/user/$USER/gatk/CEUTrio.HiSeq.WEx.b37.NA12892.readnamesort.bam -R hdfs://sn1:8020/user/$USER/gatk/human_g1k_v37.fasta -O hdfs://sn1:8020/user/$USER/gatk/CEUTrio.HiSeq.WEx.b37.NA12892.readnamesort.bam -- --sparkRunner SPARK --sparkMaster spark://sn1:7077 --driver-memory 8G --num-executors 4 --executor-cores 9 --executor-memory 27g; ```. ```; java.lang.NullPointerException; at org.broadinstitute.hellbender.utils.SequenceDictionaryUtils.getContigNames(SequenceDictionaryUtils.java:464); at org.broadinstitute.hellbender.utils.SequenceDictionaryUtils.getCommonContigsByName(SequenceDictionaryUtils.java:458); at org.broadinstitute.hellbender.utils.SequenceDictionaryUtils.compareDictionaries(SequenceDictionaryUtils.java:234); at org.broadinstitute.hellbender.utils.SequenceDictionaryUtils.validateDictionaries(SequenceDictionaryUtils.java:150); at org.broadinstitute.hellbender.utils.SequenceDictionaryUtils.validateDictionaries(SequenceDictionaryUtils.java:98); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.validateToolInputs(GATKSparkTool.java:402); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:312); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:38); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:108); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:166); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:185); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:76); at org.broadinstitute.hellbender.Main.main(Main.java:92); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAc,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2020:1012,validat,validateDictionaries,1012,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2020,1,['validat'],['validateDictionaries']
Security,"erator.scala:1336); at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:912); at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:912); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1899); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1899); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); at org.apache.spark.scheduler.Task.run(Task.scala:86); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748); 00:11:09.632 WARN TaskSetManager:66 - Lost task 15.0 in stage 1.0 (TID 519, localhost): java.lang.IllegalStateException: Duplicate key [B@4e233a3c; at java.util.stream.Collectors.lambda$throwingMerger$0(Collectors.java:133); at java.util.HashMap.merge(HashMap.java:1253); at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1320); at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.PairHMMLikelihoodCalculationEngine.buildGapContinuationPenalties(PairHMMLikelihoodCalculat; ionEngine.java:304); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.PairHMMLikelihoodCalculationEngine.computeReadLikelihoods(PairHMMLikelihoodCalculationEngi; ne.java:253); at org.broadinsti",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3018:5502,Hash,HashMap,5502,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3018,1,['Hash'],['HashMap']
Security,"erer.java:216); 	at org.broadinstitute.hellbender.tools.exome.FilterByOrientationBias.onTraversalSuccess(FilterByOrientationBias.java:168); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:781); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:115); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:170); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:189); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:122); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:143); 	at org.broadinstitute.hellbender.Main.main(Main.java:221); ```; and; ```; java.lang.IllegalStateException: Allele in genotype G* not in the variant context [C*, T]; 	at htsjdk.variant.variantcontext.VariantContext.validateGenotypes(VariantContext.java:1360); 	at htsjdk.variant.variantcontext.VariantContext.validate(VariantContext.java:1298); 	at htsjdk.variant.variantcontext.VariantContext.<init>(VariantContext.java:401); 	at htsjdk.variant.variantcontext.VariantContextBuilder.make(VariantContextBuilder.java:494); 	at htsjdk.variant.variantcontext.VariantContextBuilder.make(VariantContextBuilder.java:488); 	at org.broadinstitute.hellbender.tools.exome.orientationbiasvariantfilter.OrientationBiasFilterer.annotateVariantContextsWithFilterResults(OrientationBiasFilterer.java:216); 	at org.broadinstitute.hellbender.tools.exome.FilterByOrientationBias.onTraversalSuccess(FilterByOrientationBias.java:211); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:840); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:115); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:170); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:189); 	at org.br",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3291:2321,validat,validate,2321,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3291,1,['validat'],['validate']
Security,"error in which the 1st alternative allele is a spanning deletion and the 2nd (and 3rd) is either an indel or snp. It's true that the 2nd and 3rd allele is actually not found in my samples. I even have 7 occurances in which the 1st allele (spanning deletion) has allele frequency 1.00. my code is the following for GenotypeGVCFs:. java -Xms32G -Xmx32G -jar ${gatk4} GenotypeGVCFs -R ${ref} -V ${pipeline}/${name}\_v4.1.6.0.g.vcf.gz -O ${vcf}/${name}\_v4.1.6.0.vcf.gz -L ${pipeline}/${name}\_intervals.list 2> ${log}/${name}\_v4.1.6.0\_genotype.log. for ValidateVariants:. java -Xms10G -Xmx10G -jar ${gatk4} ValidateVariants -R ${ref} -V ${name}\_v4.1.6.0.vcf.gz -L ${pipeline}/${name}\_intervals.list --warn-on-errors 2> ${log}/${name}\_v4.1.6.0\_genotype\_valivar.log. the warning in ValidateVariants and the site look like this:. 14:12:15.126 WARN ValidateVariants - \*\*\*\*\* Input 1st\_v4.1.6.0.vcf.gz fails strict validation of type ALL: one or more of the ALT allele(s) for the record at position chr\_1:1088200 are not observed at all in the sample genotypes \*\*\*\*\* ; ; chr\_1 1088200 . T \*,TAAAAAAAAAAAA 64.39 . AC=8,0;AF=0.667,0.00;AN=12;DP=118;ExcessHet=3.0103;FS=0.000;InbreedingCoeff=0.4286;MLEAC=7,7;MLEAF=0.583,0.583;MQ=58.73;QD=32.19;SOR=2.303 GT:AD:DP:GQ:PL ./.:9,0,0:9:.:0,0,0,0,0,0 0/0:9,0,0:9:0:0,0,113,0,113,113 ./.:10,0,0:10:.:0,0,0,0,0,0 ./.:5,0,0:5:.:0,0,0,0,0,0 1/1:0,0,1:1:0:225,15,0,15,0,0 ./.:0,0,0:0:.:0,0,0,0,0,0 ./.:12,0,0:12:.:0,0,0,0,0,0 ./.:8,0,0:8:.:0,0,0,0,0,0 0/0:3,0,0:3:0:0,0,43,0,43,43 ./.:7,0,0:7:.:0,0,0,0,0,0 ./.:1,0,0:1:.:0,0,0,0,0,0 ./.:0,0,0:0:.:0,0,0,0,0,0 ./.:3,0,0:3:.:0,0,0,0,0,0 ./.:7,0,0:7:.:0,0,0,0,0,0 1/1:0,0,0:0:0:45,3,0,3,0,0 ./.:0,0,0 1/1:0,0,1:1:0:45,3,0,3,0,0 1/1:0,0,0:0:0:267,18,0,18,0,0 ./.:9,0,0:9:.:0,0,0,0,0,0 ; . The exactly the same happens when I run GenotypeGVCFs in --include-non-variant-sites and when I run GenotypeGVCFS and ValidateVariants in v4.1.7.0. In principle, these sites just take up space in the vcf, as the corr",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6630:1975,validat,validation,1975,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6630,1,['validat'],['validation']
Security,"error specified; 1 error; 1 warning; :compileJava FAILED; :compileJava (Thread[Daemon worker Thread 2,5,main]) completed. Took 4.116 secs. FAILURE: Build failed with an exception. * What went wrong:; Execution failed for task ':compileJava'.; > Compilation failed; see the compiler error output for details. * Try:; Run with --debug option to get more log output. * Exception is:; org.gradle.api.tasks.TaskExecutionException: Execution failed for task ':compileJava'.; at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.executeActions(ExecuteActionsTaskExecuter.java:69); at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.execute(ExecuteActionsTaskExecuter.java:46); at org.gradle.api.internal.tasks.execution.PostExecutionAnalysisTaskExecuter.execute(PostExecutionAnalysisTaskExecuter.java:35); at org.gradle.api.internal.tasks.execution.SkipUpToDateTaskExecuter.execute(SkipUpToDateTaskExecuter.java:64); at org.gradle.api.internal.tasks.execution.ValidatingTaskExecuter.execute(ValidatingTaskExecuter.java:58); at org.gradle.api.internal.tasks.execution.SkipEmptySourceFilesTaskExecuter.execute(SkipEmptySourceFilesTaskExecuter.java:52); at org.gradle.api.internal.tasks.execution.SkipTaskWithNoActionsExecuter.execute(SkipTaskWithNoActionsExecuter.java:52); at org.gradle.api.internal.tasks.execution.SkipOnlyIfTaskExecuter.execute(SkipOnlyIfTaskExecuter.java:53); at org.gradle.api.internal.tasks.execution.ExecuteAtMostOnceTaskExecuter.execute(ExecuteAtMostOnceTaskExecuter.java:43); at org.gradle.execution.taskgraph.DefaultTaskGraphExecuter$EventFiringTaskWorker.execute(DefaultTaskGraphExecuter.java:233); at org.gradle.execution.taskgraph.DefaultTaskGraphExecuter$EventFiringTaskWorker.execute(DefaultTaskGraphExecuter.java:215); at org.gradle.execution.taskgraph.AbstractTaskPlanExecutor$TaskExecutorWorker.processTask(AbstractTaskPlanExecutor.java:74); at org.gradle.execution.taskgraph.AbstractTaskPlanExecutor$TaskExecutorWorker.run(AbstractTaskPla",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4248:6010,Validat,ValidatingTaskExecuter,6010,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4248,1,['Validat'],['ValidatingTaskExecuter']
Security,"es); gatk SplitNCigarReads. ### Affected version(s); - gatk 4.2.6.1. ### Description ; I produced the bam files using STAR, and adjusted the MQ value to 60. I then used sambamba markdup to mark duplicate, then I proceeded to use SplitNCigarReads. The CPU load for SplitNCigarReads was very high and at certain times can spike up to 2400%. I tried limiting the cpu usage with commands like `-XX:ParallelGCThreads=1` and `-XX:ConcGCThreads=1`, but it doesn't seem to have an effect. (The cpu usage sometimes do stay at 100%) I also adjusted the MQ value in STAR to lessen the load in SplitNCigarReads. I also tried to increase the read size to reduce I/O time.; ![image](https://user-images.githubusercontent.com/106958825/175206165-08b28567-d671-45fa-b033-f20c4792edb7.png). #### Steps to reproduce; STAR; ```; STAR \; --genomeDir ${star_reference_path} \; --runThreadN 16 \; --readFilesIn ${file_1} ${file_2} \; --readFilesCommand ""gunzip -c"" \; --sjdbOverhang 149 \; --outSAMtype BAM SortedByCoordinate \; --outBAMsortingThreadN 16 \; --outSAMmultNmax 1 \; --outSAMmapqUnique 60 \; --outSAMattrRGline ID:${id} LB:RNASEQ SM:${sample_name} PL:ILLUMINA PU:${platform_unit} PM:${instrument_id} \; --limitBAMsortRAM 50000000000 \; --twopassMode Basic \; --outFileNamePrefix /rawdata/rnaseq/clean/bam/1.; ```. Mark Duplicate; ```; sambamba markdup \; -t 4 \; --tmpdir=/tmp \; --hash-table-size=262144 \; --overflow-list-size=67108864 \; /rawdata/rnaseq/clean/bam/1.Aligned.sortedByCoord.out.bam \; /rawdata/rnaseq/clean/bam/1.aligned.duplicate_marked.sorted.bam \; ```. SplitNCigarReads; ```; gatk --java-options ""-Djava.io.tmpdir=/tmp -Xmx20G -XX:ParallelGCThreads=1 -XX:ConcGCThreads=1"" SplitNCigarReads \; -R ${reference_path} \; --tmp-dir /tmp \; -I /rawdata/rnaseq/clean/bam/1.aligned.duplicate_marked.sorted.bam \; -O /rawdata/rnaseq/clean/bam_gatk/1.aligned.duplicate_marked.sorted.bam \; --create-output-bam-md5 TRUE \; --max-reads-in-memory 1000000 \; --skip-mapping-quality-transform TRUE \; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7914:1418,hash,hash-table-size,1418,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7914,1,['hash'],['hash-table-size']
Security,esources/org/broadinstitute/hellbender/tools/spark/sv/utils/SVContext.vcf.gz.tbi; src/test/resources/org/broadinstitute/hellbender/tools/splitNCigarReadsSnippet.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/split_reads.bam; src/test/resources/org/broadinstitute/hellbender/tools/split_reads.cram; src/test/resources/org/broadinstitute/hellbender/tools/split_reads.dict; src/test/resources/org/broadinstitute/hellbender/tools/split_reads.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/split_reads_missing_lib.bam; src/test/resources/org/broadinstitute/hellbender/tools/split_reads_missing_lib.cram; src/test/resources/org/broadinstitute/hellbender/tools/split_reads_missing_lib.dict; src/test/resources/org/broadinstitute/hellbender/tools/split_reads_missing_lib.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/split_reads_missing_lib.sam; src/test/resources/org/broadinstitute/hellbender/tools/split_reads.sam; src/test/resources/org/broadinstitute/hellbender/tools/validation/marked.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.bam; src/test/resources/org/broadinstitute/hellbender/tools/validation/picard.marked.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.bam; src/test/resources/org/broadinstitute/hellbender/tools/validation/single.read.bai; src/test/resources/org/broadinstitute/hellbender/tools/valid.cram.crai; src/test/resources/org/broadinstitute/hellbender/tools/valid.dict; src/test/resources/org/broadinstitute/hellbender/tools/valid.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/VQSR/VQSR.AStest.indels.recal.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/VQSR/VQSR.AStest.input.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/VQSR/VQSR.AStest.postSNPinput.HACKEDhg38header.vcf.gz.tbi; src/test/resources/org/broadinstitute/hellbender/tools/VQSR/VQSR.AStest.postSNPinput.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/VQSR/VQSR.AStest.snps.recal.vcf.idx; src/test/r,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3905:45543,validat,validation,45543,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905,1,['validat'],['validation']
Security,etryHelper.java:47); 	at com.google.cloud.storage.BlobReadChannel.read(BlobReadChannel.java:125); 	at com.google.cloud.storage.contrib.nio.CloudStorageReadChannel.read(CloudStorageReadChannel.java:109); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher$WorkUnit.call(SeekableByteChannelPrefetcher.java:131); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher$WorkUnit.call(SeekableByteChannelPrefetcher.java:104); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745); Caused by: javax.net.ssl.SSLHandshakeException: Remote host closed connection during handshake; 	at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:992); 	at sun.security.ssl.SSLSocketImpl.performInitialHandshake(SSLSocketImpl.java:1375); 	at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1403); 	at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1387); 	at sun.net.www.protocol.https.HttpsClient.afterConnect(HttpsClient.java:559); 	at sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.connect(AbstractDelegateHttpsURLConnection.java:185); 	at sun.net.www.protocol.https.HttpsURLConnectionImpl.connect(HttpsURLConnectionImpl.java:153); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:93); 	at shaded.cloud_nio.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:972); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleCl,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2685:6466,secur,security,6466,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2685,1,['secur'],['security']
Security,etryHelper.java:54); 	at com.google.cloud.storage.BlobReadChannel.read(BlobReadChannel.java:124); 	at com.google.cloud.storage.contrib.nio.CloudStorageReadChannel.read(CloudStorageReadChannel.java:114); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher$WorkUnit.call(SeekableByteChannelPrefetcher.java:131); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher$WorkUnit.call(SeekableByteChannelPrefetcher.java:104); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745); Caused by: java.net.UnknownHostException: www.googleapis.com; 	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184); 	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392); 	at java.net.Socket.connect(Socket.java:589); 	at sun.security.ssl.SSLSocketImpl.connect(SSLSocketImpl.java:668); 	at sun.net.NetworkClient.doConnect(NetworkClient.java:175); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:432); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:527); 	at sun.net.www.protocol.https.HttpsClient.<init>(HttpsClient.java:264); 	at sun.net.www.protocol.https.HttpsClient.New(HttpsClient.java:367); 	at sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.getNewHttpClient(AbstractDelegateHttpsURLConnection.java:191); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1138); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1032); 	at sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.connect(AbstractDelegateHttpsURLConnection.java:177); 	at sun.net.www.protocol.https.HttpsURLConnectionImpl.connect(HttpsURLConnectionImpl.java:153); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetH,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5094:6597,secur,security,6597,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5094,1,['secur'],['security']
Security,"eue; SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=121, target=bigquerystorage.googleapis.com:443} was not shutdown properly!!! ~*~*~*; Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.; java.lang.RuntimeException: ManagedChannel allocation site; 	at io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:93); 	at io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53); 	at io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44); 	at io.grpc.internal.ManagedChannelImplBuilder.build(ManagedChannelImplBuilder.java:615); 	at io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:261); 	at com.google.api.gax.grpc.InstantiatingGrpcChannelProvider.createSingleChannel(InstantiatingGrpcChannelProvider.java:360); 	at com.google.api.gax.grpc.InstantiatingGrpcChannelProvider.access$1800(InstantiatingGrpcChannelProvider.java:81); 	at com.google.api.gax.grpc.InstantiatingGrpcChannelProvider$1.createSingleChannel(InstantiatingGrpcChannelProvider.java:231); 	at com.google.api.gax.grpc.ChannelPool.create(ChannelPool.java:72); 	at com.google.api.gax.grpc.InstantiatingGrpcChannelProvider.createChannel(InstantiatingGrpcChannelProvider.java:241); 	at com.google.api.gax.grpc.InstantiatingGrpcChannelProvider.getTransportChannel(InstantiatingGrpcChannelProvider.java:219); 	at com.google.api.gax.rpc.ClientContext.create(ClientContext.java:199); 	at com.google.cloud.bigquery.storage.v1.stub.EnhancedBigQueryReadStub.create(EnhancedBigQueryReadStub.java:89); 	at com.google.cloud.bigquery.storage.v1.BigQueryReadClient.<init>(BigQueryReadClient.java:129); 	at com.google.cloud.bigquery.storage.v1.BigQueryReadClient.create(BigQueryReadClient.java:110); 	at com.google.cloud.bigquery.storage.v1.BigQueryReadClient.create(BigQueryReadClient.java:102); 	at org.broadinstitute.hellbender.utils.bigquery.St",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7583:1303,access,access,1303,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7583,1,['access'],['access']
Security,eup.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/qc/pileup/reads_data_source_test1.samtools.pileup.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/rnaseq/ASEReadCounter/NA12878.chr20_2444518_2637800.RNAseq.IMPROPER_PAIR.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/rnaseq/ASEReadCounter/NA12878.chr20_2444518_2637800.RNAseq.MultiContext.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/rnaseq/ASEReadCounter/NA12878.chr20_2444518_2637800.RNAseq.NON_REF.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/rnaseq/ASEReadCounter/NA12878.chr20_2444518_2637800.RNAseq.SYNONYMOUS_CODING.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/rnaseq/ASEReadCounter/NA12878.chr20_2444518_2637800.RNAseq.warnings.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/UnmarkDuplicates/allDuplicates.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/complexEvents_incompatibleDict.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/complexEvents_lexDict.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/complexEvents.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/gvcf.basepairResolution.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet_BAD_INCOMPLETE_REGION.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet.BAD_MISSING_NON_REF.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet.missingrefblock.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validati,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3905:60190,Validat,ValidateVariants,60190,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905,1,['Validat'],['ValidateVariants']
Security,execute(NetHttpRequest.java:93); 	at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:981); 	at com.google.cloud.hadoop.util.CredentialFactory$ComputeCredentialWithRetry.executeRefreshToken(CredentialFactory.java:158); 	at com.google.api.client.auth.oauth2.Credential.refreshToken(Credential.java:489); 	at com.google.cloud.hadoop.util.CredentialFactory.getCredentialFromMetadataServiceAccount(CredentialFactory.java:206); 	at com.google.cloud.hadoop.util.CredentialConfiguration.getCredential(CredentialConfiguration.java:70); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.configure(GoogleHadoopFileSystemBase.java:1825); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.initialize(GoogleHadoopFileSystemBase.java:1012); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.initialize(GoogleHadoopFileSystemBase.java:975); 	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2653); 	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:92); 	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2687); 	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2669); 	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:371); 	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:295); 	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.setInputPaths(FileInputFormat.java:500); 	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.setInputPaths(FileInputFormat.java:469); 	at org.apache.spark.SparkContext$$anonfun$newAPIHadoopFile$2.apply(SparkContext.scala:1084); 	at org.apache.spark.SparkContext$$anonfun$newAPIHadoopFile$2.apply(SparkContext.scala:1072); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); 	at org.apache.spark.SparkContext.withScope(SparkContext.scala:679); 	at org.apache.spark.SparkContext.newAPIHadoopFile(SparkContext.scala:1072); 	at org.apa,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4369:7498,access,access,7498,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4369,1,['access'],['access']
Security,executeUnparsed(AbstractGoogleClientRequest.java:419); at shaded.cloud-nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352); at shaded.cloud-nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.execute(AbstractGoogleClientRequest.java:469); at com.google.cloud.storage.spi.DefaultStorageRpc.get(DefaultStorageRpc.java:347); ... 17 more; Caused by:; java.net.SocketTimeoutException: Read timed out; at java.net.SocketInputStream.socketRead0(Native Method); at java.net.SocketInputStream.socketRead(SocketInputStream.java:116); at java.net.SocketInputStream.read(SocketInputStream.java:170); at java.net.SocketInputStream.read(SocketInputStream.java:141); at sun.security.ssl.InputRecord.readFully(InputRecord.java:465); at sun.security.ssl.InputRecord.read(InputRecord.java:503); at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:973); at sun.security.ssl.SSLSocketImpl.performInitialHandshake(SSLSocketImpl.java:1375); at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1403); at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1387); at sun.net.www.protocol.https.HttpsClient.afterConnect(HttpsClient.java:559); at sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.connect(AbstractDelegateHttpsURLConnection.java:185); at sun.net.www.protocol.http.HttpURLConnection.getOutputStream0(HttpURLConnection.java:1316); at sun.net.www.protocol.http.HttpURLConnection.getOutputStream(HttpURLConnection.java:1291); at sun.net.www.protocol.https.HttpsURLConnectionImpl.getOutputStream(HttpsURLConnectionImpl.java:250); at shaded.cloud-nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:77); at shaded.cloud-nio.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:972); at shaded.cloud-nio.com.google.auth.oauth2.ServiceAccountCredentials.refreshAccessToken(ServiceAccountCredentials.java:317); ... 27 more; ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2514:4009,secur,security,4009,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2514,2,['secur'],['security']
Security,"executing `gradle test -Dtest.single=ValidateVariantsIntegrationTest`; produces, among other things, this:. testBadID2_OKif_notInDBSNP(org.broadinstitute.hellbender.tools.walkers.ValidateVariantsIntegrationTest) produced standard out/err: [Wed Mar 18 21:15:38 EDT 2015] org.broadinstitute.hellbender.tools.walkers.variantutils.ValidateVariants --dbsnp **org.broadinstitute.hellbender.engine.FeatureInput@4c4054af** **--validationTypeToExclude [REF, ALLELES, CHR_COUNTS]**. Two problems:; 1) FeatureInput needs a meaningful toString; 2) the argument that is a list of enum values should be printed as multiples of 'validationTypeToExclude' each with a value (so that the commandline is copy-paste-able)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/318:37,Validat,ValidateVariantsIntegrationTest,37,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/318,5,"['Validat', 'validat']","['ValidateVariants', 'ValidateVariantsIntegrationTest', 'validationTypeToExclude']"
Security,expose DEFAULT_FEATURE_CACHE_LOOKAHEAD as a configurable option,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3489:0,expose,expose,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3489,1,['expose'],['expose']
Security,expose intervalMerging Argument in IntervalArguments,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/165:0,expose,expose,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/165,1,['expose'],['expose']
Security,"f --recal-file recalibration. cat sb-recalibrated-tiny.vcf; ##fileformat=VCFv4.2; ##FILTER=<ID=LOW_VQSLOD,Description=""VQSLOD < 0.0"">; ##FILTER=<ID=PASS,Description=""Site contains at least one allele that passes filters"">; ##GATKCommandLine=<ID=ApplyVQSR,CommandLine=""ApplyVQSR --recal-file /Users/vlad/tmp/sb/recalibration --output sb-recalibrated-tiny-renamed4.vcf --variant sb-good-tiny-renamed4.vcf --use-allele-specific-annotations false --ignore-all-filters false --exclude-filtered false --mode SNP --interval-set-rule UNION --interval-padding 0 --interval-exclusion-padding 0 --interval-merging-rule ALL --read-validation-stringency SILENT --seconds-between-progress-updates 10.0 --disable-sequence-dictionary-validation false --create-output-bam-index true --create-output-bam-md5 false --create-output-variant-index true --create-output-variant-md5 false --lenient false --add-output-sam-program-record true --add-output-vcf-command-line true --cloud-prefetch-buffer 40 --cloud-index-prefetch-buffer -1 --disable-bam-index-caching false --sites-only-vcf-output false --help false --version false --showHidden false --verbosity INFO --QUIET false --use-jdk-deflater false --use-jdk-inflater false --gcs-max-retries 20 --gcs-project-for-requester-pays --disable-tool-default-read-filters false"",Version=""4.1.9.0"",Date=""31 May 2021 12:07:54 PM"">; ##INFO=<ID=END,Number=1,Type=Integer,Description=""Stop position of the interval"">; ##INFO=<ID=NEGATIVE_TRAIN_SITE,Number=0,Type=Flag,Description=""This variant was used to build the negative training set of bad variants"">; ##INFO=<ID=POSITIVE_TRAIN_SITE,Number=0,Type=Flag,Description=""This variant was used to build the positive training set of good variants"">; ##INFO=<ID=SB,Number=1,Type=Float,Description=""Strand Bias"">; ##INFO=<ID=VQSLOD,Number=1,Type=Float,Description=""Log odds of being a true variant versus being false under the trained gaussian mixture model"">; ##INFO=<ID=culprit,Number=1,Type=String,Description=""The annotation which w",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7280:2401,validat,validation,2401,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7280,1,['validat'],['validation']
Security,"f.gz`) . The log issue looks very similar to that described here [#7162)](https://github.com/broadinstitute/gatk/issues/7162), but the *Problematic frame* information is different. ; As suggested in this issue [#5690](https://github.com/broadinstitute/gatk/issues/5690), the problem disappears when using gatk 4.1.3.0 on the same inputs. . log:; ```bash; 17:37:20.674 INFO ProgressMeter - chr20:43968267 10.6 44000 4132.2; 17:37:38.646 INFO ProgressMeter - chr22:22736335 10.9 45000 4110.5; 17:37:52.672 INFO ProgressMeter - chrX:7000139 11.2 46000 4113.9; 17:38:05.421 INFO ProgressMeter - chrX:26360893 11.4 47000 4125.0; 17:38:17.207 INFO ProgressMeter - chrX:44917184 11.6 48000 4141.4; 17:38:29.312 INFO ProgressMeter - chrX:77681733 11.8 49000 4155.3; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x00007fc0ccec5cdb, pid=15987, tid=15988; #; # JRE version: OpenJDK Runtime Environment (11.0.11+9) (build 11.0.11+9-Ubuntu-0ubuntu2.18.04); # Java VM: OpenJDK 64-Bit Server VM (11.0.11+9-Ubuntu-0ubuntu2.18.04, mixed mode, sharing, tiered, compressed oops, g1 gc, linux-amd64); # Problematic frame:; # C [libc.so.6+0x97cdb] cfree+0x31b; #; # Core dump will be written. Default location: Core dumps may be processed with ""/usr/share/apport/apport %p %s %c %d %P %E"" (or dumping to /home/kt/core.15987); #; # An error report file with more information is saved as:; # /home/kt/hs_err_pid15987.log; ```. #### Steps to reproduce; My commands:; ```bash; gatk --java-options ""-Xmx11g"" \; FilterAlignmentArtifacts \; -R GRCh38.no_alt_analysis_set.fa \; -V in.vcf.gz \; -I bamout.bam \; --bwa-mem-index-image Homo_sapiens_assembly38.fa.img \; --num-regular-contigs 194 \; --max-reasonable-fragment-length 2000 \; --drop-ratio 0.1 \; --indel-start-tolerance 8 \; -O out.vcf.gz; ```; I copied the input vcfs (small: test.cf.gz and initial: m2.vcf.gz), bamout and ""hs_err_pid.logs"" to `gs://iseq/kt/strange-bug/` ; I hope you can access them. ; Best,; Kasia",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7247:2633,access,access,2633,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7247,1,['access'],['access']
Security,fb822dddb0cad0123d48c33124b6065; Status: Downloaded newer image for broadinstitute/gatk:4.2.2.0; (gatk) root@bc90fdaf700c:/gatk# ; (gatk) root@bc90fdaf700c:/gatk# ; (gatk) root@bc90fdaf700c:/gatk# apt-get update; Get:1 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]; Get:2 http://archive.ubuntu.com/ubuntu bionic InRelease [242 kB] ; Get:3 http://security.ubuntu.com/ubuntu bionic-security/multiverse amd64 Packages [26.7 kB] ; Get:4 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [543 kB] ; Get:5 http://packages.cloud.google.com/apt cloud-sdk-bionic InRelease [6786 B] ; Get:6 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1426 kB] ; Err:5 http://packages.cloud.google.com/apt cloud-sdk-bionic InRelease ; The following signatures couldn't be verified because the public key is not available: NO_PUBKEY FEEA9169307EA071 NO_PUBKEY 8B57C5C2836F4BEB; Get:7 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2295 kB] ; Get:8 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB] ; Get:9 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB] ; Get:10 http://archive.ubuntu.com/ubuntu bionic/restricted amd64 Packages [13.5 kB] ; Get:11 http://archive.ubuntu.com/ubuntu bionic/multiverse amd64 Packages [186 kB]; Get:12 http://archive.ubuntu.com/ubuntu bionic/universe amd64 Packages [11.3 MB] ; Get:13 http://archive.ubuntu.com/ubuntu bionic/main amd64 Packages [1344 kB] ; Get:14 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2200 kB]; Get:15 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 Packages [34.4 kB]; Get:16 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [575 kB]; Get:17 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2731 kB]; Get:18 http://archive.ubuntu.com/ubuntu bionic-backports/universe amd64 Packages [11.4 kB]; Get:19 http://archive.ubuntu.com/ubuntu bionic,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7447:1488,secur,security,1488,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7447,1,['secur'],['security']
Security,fix for sequence dict validation on cram,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1275:22,validat,validation,22,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1275,1,['validat'],['validation']
Security,fix inefficient hashcode computation and added tests to 100%,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1620:16,hash,hashcode,16,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1620,1,['hash'],['hashcode']
Security,fix invalid certificate for gatk-jenkins,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2446:12,certificate,certificate,12,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2446,1,['certificate'],['certificate']
Security,fix issue with validatevariants when validatign a gvcf and a record is followed by a record that is fully encompassed by the first one. The interval math was off in this case,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3530:15,validat,validatevariants,15,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3530,2,['validat'],"['validatevariants', 'validatign']"
Security,fix the script to validate-reads-spark-pipeline,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1921:18,validat,validate-reads-spark-pipeline,18,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1921,1,['validat'],['validate-reads-spark-pipeline']
Security,fixes #1398 . @yfarjoun can you review? it's a super simple picard-style CLP for comparing quals between bams (needed for GATK4 validation of BQSR - may be useful for GoTC too (?)),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1415:128,validat,validation,128,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1415,1,['validat'],['validation']
Security,"fixes #1486 (code already existed, just needed to be exposed). I found a limitation in Hadoop-BAM (https://github.com/HadoopGenomics/Hadoop-BAM/issues/68) regarding reading blocked vcfs.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1496:53,expose,exposed,53,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1496,1,['expose'],['exposed']
Security,fixes #754. updating spark along side the dataflow jump; also updating other dependencies as well. changing GatkTestPipeline to downgrade a naming error to a warning; replacing calls to setName; replacing calls to setCoder with calls to withCoder when possible. hooking up the validation stringency for local files; fixes #745. disabling failing test and opening #774 to reenable it,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/775:277,validat,validation,277,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/775,1,['validat'],['validation']
Security,"fixes the issue where CommandLineExceptions produced no error message. added a public getUsage() method to CommandLineProgram; added a catch for these in instanceMain(), where the CommandLineProgram is in scope for printing the usage message; added a protected accessor getCommandLineParser to CommandLineProgram which guards against having an uninitialized CommandLineParser; moved the ""A USER ERROR HAS OCCURRED"" text out of the actual user exception and into the pretty printing",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2340:261,access,accessor,261,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2340,1,['access'],['accessor']
Security,"fo header line, call on each; > VCFInfoHeaderLine getCount(vc) to get the expected number of info; > annotation entries; > - Compare the expected number with a count based on; > vc.getAttribute(currentVCFinfoHeaderLine.getID()), which will require some; > additional parsing because it returns an Object; > - (Bonus points if you use the isFixedCount() and getCount() functions; > on the VCF info header line to simplify annotations that aren't according; > to the number of alt alleles); > ; > Test data; > ; > /humgen/gsa-hpprojects/dev/gauthier/scratch/supportingMultiA.vcf; > Should fail AC/AF validation at; > 1 768589 . A C,G 76 PASS AC=1;AF=0.00047;AN=2120; > See results using:; > ; > use VCFtools; > vcf-validator /humgen/gsa-hpprojects/dev/gauthier/scratch/supportingMultiA.vcf; > ; > which outputs:; > INFO field at 1:768589 .. INFO tag [AC=1] expected different number of; > values (expected 2, found 1),INFO tag [AF=0.00047] expected different; > number of values (expected 2, found 1); > Notes; > ; > Currently, all the validation modes call out to HTSJDK. Do we want to put; > the new functionality there as well?; > ; > —; > Reply to this email directly or view it on GitHub; > https://github.com/broadinstitute/gsa-unstable/issues/1053. ---. @ldgauthier commented on [Fri Jul 17 2015](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-122308040). Today I learned that the way we currently build GATK, you can't point to a local htsjdk jar anymore, so this task will be two-fold:; 1) Make a PR to htsjdk with a new function in the VariantContext class for validateInfoFieldCounts(VCFInfoHeaderLine headerLine) or similar; add a test to VariantContextUnitTest.java; 2) After change 1) is merged, update ValidateVariants accordingly to use the new function and add a test to its integration tests. ---. @vdauwera commented on [Fri May 27 2016](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-222213763). @ldgauthier is this still a thing? (i",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2507:3815,validat,validation,3815,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2507,1,['validat'],['validation']
Security,"g engine; 00:05:57.036 INFO ProgressMeter - Starting traversal; 00:05:57.036 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 00:07:26.967 WARN ReferenceConfidenceVariantContextMerger - Detected invalid annotations: When trying to merge variant contexts at location chr16:10185 the annotation AS_VarDP=59|115|0 was not a numerical value and was ignored; 00:07:26.967 WARN ReferenceConfidenceVariantContextMerger - Reducible annotation 'AS_VarDP' detected, add -G StandardAnnotation -G AS_StandardAnnotation to the command to annotate in the final VC with this annotation.; 00:07:26.991 INFO GenotypeGVCFs - Shutting down engine; GENOMICSDB_TIMER,GenomicsDB iterator next() timer,Wall-clock time(s),0.02938786500000001,Cpu time(s),0.029037034000000003; [August 25, 2021 12:07:27 AM EDT] org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs done. Elapsed time: 1.55 minutes.; Runtime.totalMemory()=1807745024; java.lang.NullPointerException; at java.util.HashMap.putMapEntries(HashMap.java:500); at java.util.HashMap.putAll(HashMap.java:784); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorEngine.combineAnnotations(VariantAnnotatorEngine.java:211); at org.broadinstitute.hellbender.tools.walkers.ReferenceConfidenceVariantContextMerger.mergeAttributes(ReferenceConfidenceVariantContextMerger.java:318); at org.broadinstitute.hellbender.tools.walkers.ReferenceConfidenceVariantContextMerger.merge(ReferenceConfidenceVariantContextMerger.java:142); at org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFsEngine.callRegion(GenotypeGVCFsEngine.java:130); at org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs.apply(GenotypeGVCFs.java:281); at org.broadinstitute.hellbender.engine.VariantLocusWalker.lambda$traverse$0(VariantLocusWalker.java:135); at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.stream.Ref",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7437:8033,Hash,HashMap,8033,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7437,1,['Hash'],['HashMap']
Security,g(ConfigurationUtil.java:39); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.createOptionsBuilderFromConfig(GoogleHadoopFileSystemBase.java:2185); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.configure(GoogleHadoopFileSystemBase.java:1832); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.initialize(GoogleHadoopFileSystemBase.java:1013); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.initialize(GoogleHadoopFileSystemBase.java:976); 	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2812); 	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:100); 	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2849); 	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2831); 	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:389); 	at org.apache.hadoop.fs.FileSystem$1.run(FileSystem.java:171); 	at org.apache.hadoop.fs.FileSystem$1.run(FileSystem.java:168); 	at java.base/java.security.AccessController.doPrivileged(Native Method); 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423); 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1836); 	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:168); 	at org.genomicsdb.reader.GenomicsDBQueryStream.jniGenomicsDBInit(Native Method); 	at org.genomicsdb.reader.GenomicsDBQueryStream.<init>(GenomicsDBQueryStream.java:209); 	at org.genomicsdb.reader.GenomicsDBQueryStream.<init>(GenomicsDBQueryStream.java:182); 	at org.genomicsdb.reader.GenomicsDBQueryStream.<init>(GenomicsDBQueryStream.java:91); 	at org.genomicsdb.reader.GenomicsDBFeatureReader.generateHeadersForQuery(GenomicsDBFeatureReader.java:176); 	at org.genomicsdb.reader.GenomicsDBFeatureReader.<init>(GenomicsDBFeatureReader.java:80); 	at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImportIntegrationTest.getGenomicsDBFeatureReader(GenomicsDBImportIntegrationTest.java:926); 	at org.broadinstitute.hellbender.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6522:1553,secur,security,1553,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6522,1,['secur'],['security']
Security,g.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53); 	at org.apache.spark.scheduler.Task.run(Task.scala:109); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); 18/10/17 19:23:59 ERROR Executor: Exception in task 518.0 in stage 0.0 (TID 518); java.io.FileNotFoundException: /home/data/WGS/F002/F002.sort.bam (Too many open files); 	at java.io.FileInputStream.open0(Native Method); 	at java.io.FileInputStream.open(FileInputStream.java:195); 	at java.io.FileInputStream.<init>(FileInputStream.java:138); 	at org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileInputStream.<init>(RawLocalFileSystem.java:106); 	at org.apache.hadoop.fs.RawLocalFileSystem.open(RawLocalFileSystem.java:202); 	at org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:349); 	at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:769); 	at org.seqdoop.hadoop_bam.util.WrapSeekable.openPath(WrapSeekable.java:60); 	at org.seqdoop.hadoop_bam.BAMRecordReader.initialize(BAMRecordReader.java:147); 	at org.seqdoop.hadoop_bam.BAMInputFormat.createRecordReader(BAMInputFormat.java:222); 	at org.seqdoop.hadoop_bam.AnySAMInputFormat.createRecordReader(AnySAMInputFormat.java:190); 	at org.apache.spark.rdd.NewHadoopRDD$$anon$1.liftedTree1$1(NewHadoopRDD.scala:187); 	at org.apache.spark.rdd.NewHadoopRDD$$anon$1.<init>(NewHadoopRDD.scala:186); 	at org.apache.spark.rdd.NewHadoopRDD.compute(NewHadoopRDD.scala:141); 	at org.apache.spark.rdd.NewHadoopRDD.compute(NewHadoopRDD.scala:70); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); 	a,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5316:5323,Checksum,ChecksumFileSystem,5323,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5316,1,['Checksum'],['ChecksumFileSystem']
Security,g/broadinstitute/hellbender/tools/walkers/ValidateVariants/gvcf.basepairResolution.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet_BAD_INCOMPLETE_REGION.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet.BAD_MISSING_NON_REF.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet.missingrefblock.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleBad3.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleBad.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleGood.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleRSIDonPositionNotInDBSNP.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationUnusedAllelesBugFix.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/validation/basicshortmutpileup/IS3.snv.indel.sv-vs-G15512.prenormal.sorted.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/validation/basicshortmutpileup/synthetic.challenge.set1.tumor-vs-synthetic.challenge.set1.normal-filtered.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/CalculateGenotypePosteriors/CEUtriMixedPloidyTest.vcf; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/CalculateGenotypePosteriors/CEUtrioPopPriorsTest_chr1.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/CalculateGenotypePosteriors/CEUtrioTest_chr1.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/Calculat,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3905:61487,Validat,ValidateVariants,61487,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905,2,"['Validat', 'validat']","['ValidateVariants', 'validationExampleRSIDonPositionNotInDBSNP']"
Security,"galArgumentException: beta must be greater than 0 but got -87566.7500301585; ```; ""this error only comes after the first pass of filtermutectCalls completed."". ValidateVarinats shows no errors when run on VCF.; ""The stats file was created by mutect2 for each shard and then joined with MergeMutectStats. Similar the read orientation model was built with the f1r2 files from all shards."". @davidbenjamin. --------------; Hi there,. I have a simulated dataset of related samples and currently running Mutect2 on it (10 tumor samples WGS with 130x); I managed to run everything through and now FilterMutectCalls crashes after the first pass through the variants with. ```; [October 1, 2019 12:16:16 PM UTC] org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls done. Elapsed time: 370.68 minutes.; Runtime.totalMemory()=20597702656; java.lang.IllegalArgumentException: beta must be greater than 0 but got -87566.7500301585; at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:724); at org.broadinstitute.hellbender.tools.walkers.readorientation.BetaDistributionShape.<init>(BetaDistributionShape.java:14); at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.BinomialCluster.getFuzzyBinomial(BinomialCluster.java:42); at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.BinomialCluster.learn(BinomialCluster.java:33); at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.lambda$learnAndClearAccumulatedData$7(SomaticClusteringModel.java:131); at org.broadinstitute.hellbender.utils.IndexRange.forEach(IndexRange.java:116); at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.learnAndClearAccumulatedData(SomaticClusteringModel.java:131); at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.learnParameters(Mutect2FilteringEngine.java:156); at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls.afterNthP",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6202:1042,validat,validateArg,1042,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6202,1,['validat'],['validateArg']
Security,"gatk --java-options ""-Xmx4g -DGATK_STACKTRACE_ON_USER_EXCEPTION=true"" BaseRecalibrator -I /mnt/fq2bam/sample1.markdup.sorted.bam \; -R /mnt/fq2bam/inputs/reference/files/Homo_sapiens_assembly38.fasta \; --known-sites /mnt/fq2bam/inputs/resources/files/Homo_sapiens_assembly38.known_indels.vcf.gz \; --known-sites /mnt/fq2bam/inputs/resources/files/Mills_and_1000G_gold_standard.indels.hg38.vcf.gz \; --known-sites /mnt/fq2bam/inputs/resources/files/Homo_sapiens_assembly38.dbsnp138.vcf.gz \; -L chr1 \; -DF MappingQualityNotZeroReadFilter \; -DF MappedReadFilter \; -O /mnt/fq2bam/sample1_BQSR001.recal_data.table. I got the following error. java.lang.IllegalStateException: No cigar elements left after removing leading and trailing deletions.; at org.broadinstitute.hellbender.utils.Utils.validate(Utils.java:814); at org.broadinstitute.hellbender.utils.read.CigarBuilder.make(CigarBuilder.java:138); at org.broadinstitute.hellbender.utils.read.CigarBuilder.make(CigarBuilder.java:143); at org.broadinstitute.hellbender.utils.recalibration.BaseRecalibrationEngine.consolidateCigar(BaseRecalibrationEngine.java:293); at org.broadinstitute.hellbender.transformers.ReadTransformer.lambda$andThen$f85d1091$1(ReadTransformer.java:20); at org.broadinstitute.hellbender.transformers.ReadTransformer.lambda$andThen$f85d1091$1(ReadTransformer.java:20); at org.broadinstitute.hellbender.transformers.ReadTransformer.lambda$andThen$f85d1091$1(ReadTransformer.java:20); at org.broadinstitute.hellbender.transformers.ReadTransformer.lambda$andThen$f85d1091$1(ReadTransformer.java:20); at org.broadinstitute.hellbender.utils.recalibration.BaseRecalibrationEngine.processRead(BaseRecalibrationEngine.java:118); at org.broadinstitute.hellbender.tools.walkers.bqsr.BaseRecalibrator.apply(BaseRecalibrator.java:189); at org.broadinstitute.hellbender.engine.ReadWalker.lambda$traverse$0(ReadWalker.java:100); at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183); at java.util.stream.ReferencePipe",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8523:791,validat,validate,791,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8523,1,['validat'],['validate']
Security,"gatk silently sets TMP_DIR globally readable/writable for all users. This is problematic for admins trying to maintain a secure multi-user environment. It would be better (imho) if gatk tests if TMP_DIR is writeable and errors out when it is not instead of just globally making it writeable by all users. src/main/java/org/broadinstitute/hellbender/cmdline/CommandLineProgram.java. for (final File f : TMP_DIR) {; // Intentionally not checking the return values, because it may be that the program does not; // need a tmp_dir. If this fails, the problem will be discovered downstream.; if (!f.exists()) f.mkdirs();; f.setReadable(true, false);; f.setWritable(true, false);",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4513:121,secur,secure,121,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4513,1,['secur'],['secure']
Security,"ge tested against the workflow (#8062); - VS-637 Address a couple of issues in SampleLoadStatus handling in GVSImportGenomes. (#8052); - Revert Alpinizing of apt dependent task [VS-688] (#8065); - Fix missing vat schema JSONs [VS-699] (#8072); - Fix integration expectations for fixed AD [VS-689] (#8066); - VS-698 Remove unnecessary columns from Call set statistics (#8073); - Fix Dockerfile nits that break 20.10.21 (#8078); - Nirvana 3.18.1 Docker images support [VS-661] (#8082); - Add option to not prepare __REF_DATA or __SAMPLES tables to Prepare [VS-697] (#8079); - ""build-base"" Docker image for faster variantstore image builds [VS-712] (#8085); - GVS / Hail VDS integration test [VS-639] (#8086); - Remove AI/AN from VDS docs [VS-726] (#8096); - Add flag for cost_observability table writing to support sub-cohort use case [VS-521] (#8093); - Document STS delivery process for VDS [VS-727] (#8101); - delete obsolete callset_QC directory and its contents [VS-318] (#8108); - doc link typo and add check for control samples in AVRO export (#8110); - Add defaults for scatter_count in GvsExtractCohortFromSampleNames [VS-496] (#8109); - Escape table names properly in ValidateVat WDL (#8116); - Vs 741 fix indefinite freeze in split intervals task when using exome data (#8113); - VAT Readme updates (#8090); - WDL and python scripts to use the VDS in the VAT (#8077); - VS-757 - Use JASIX to make sub-jsons of annotated output of Nirvana (#8133); - add note about permissions for P&S workflow to work (#8135); - VS-759 (and VS-760) (#8137); - VS-765. Scatter the RemoveDuplicates task. (#8144); - update delivery docs based on latest VDS delivery run [VS-770] (#8150); - Add monitoring to index vcf (#8151); - Make some noise when VDS validation succeeds (#8155); - Handle empty genes annotation file. (#8153); - Add escapes for otherwise problematic dataset / table names. (#8162); - New WDL to create VAT tsvs from previously generated BigQuery table. (#8165); - Treat withdrawn samples in ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8248:30901,Validat,ValidateVat,30901,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8248,2,['Validat'],['ValidateVat']
Security,"ge-4.0.0.0-local.jar HaplotypeCaller -L chr5 --reference genomes/ucsc_hg19.fasta --input NA12878_S1_md.bam --output hc_variants_7.vcf --bam-output realigned_slice_7.bam --max-reads-per-alignment-start 1000 --min-base-quality-score 0 --minimum-mapping-quality 0 --disable-read-filter MappingQualityReadFilter --disable-read-filter MappingQualityAvailableReadFilter --disable-read-filter NotSecondaryAlignmentReadFilter --disable-read-filter NotDuplicateReadFilter --disable-read-filter PassesVendorQualityCheckReadFilter --disable-read-filter NonZeroReferenceLengthAlignmentReadFilter --disable-read-filter GoodCigarReadFilter --disable-read-filter WellformedReadFilter`; [January 10, 2018 2:39:19 PM EST] org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCaller done. Elapsed time: 91.81 minutes.; Runtime.totalMemory()=7215251456; java.lang.IllegalArgumentException: Invalid interval. Contig:chr5 start:71357769 end:71357768; at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:687); at org.broadinstitute.hellbender.utils.SimpleInterval.validatePositions(SimpleInterval.java:61); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:37); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:49); at org.broadinstitute.hellbender.engine.AssemblyRegion.add(AssemblyRegion.java:335); at org.broadinstitute.hellbender.engine.AssemblyRegionIterator.fillNextAssemblyRegionWithReads(AssemblyRegionIterator.java:230); at org.broadinstitute.hellbender.engine.AssemblyRegionIterator.loadNextAssemblyRegion(AssemblyRegionIterator.java:194); at org.broadinstitute.hellbender.engine.AssemblyRegionIterator.next(AssemblyRegionIterator.java:135); at org.broadinstitute.hellbender.engine.AssemblyRegionIterator.next(AssemblyRegionIterator.java:34); at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.processReadShard(AssemblyRegionWalker.java:290); at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.tra",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4120:1267,validat,validateArg,1267,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4120,1,['validat'],['validateArg']
Security,"genotypes. We should use the definition of the info annotations in the header to check how many entries each should have.; ### Outline; - Add a new validation type for info-field counts to enum and to switch statement; - Grab info headers from input VCF with something like GATKVCFUtils.getVCFHeadersFromRods(getToolkit(), variantCollection.variants.getName()) and VCFHeader::getInfoHeaderLines; - In the map() function, for each info header line, call on each VCFInfoHeaderLine getCount(vc) to get the expected number of info annotation entries; - Compare the expected number with a count based on vc.getAttribute(currentVCFinfoHeaderLine.getID()), which will require some additional parsing because it returns an Object; - (Bonus points if you use the isFixedCount() and getCount() functions on the VCF info header line to simplify annotations that aren't according to the number of alt alleles); ### Test data. /humgen/gsa-hpprojects/dev/gauthier/scratch/supportingMultiA.vcf; Should fail AC/AF validation at ; `1 768589 . A C,G 76 PASS AC=1;AF=0.00047;AN=2120`; See results using:. ```; use VCFtools; vcf-validator /humgen/gsa-hpprojects/dev/gauthier/scratch/supportingMultiA.vcf; ```. which outputs:; `INFO field at 1:768589 .. INFO tag [AC=1] expected different number of values (expected 2, found 1),INFO tag [AF=0.00047] expected different number of values (expected 2, found 1)`; ### Notes. Currently, all the validation modes call out to HTSJDK. Do we want to put the new functionality there as well?. ---. @yfarjoun commented on [Thu Jul 16 2015](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-122130280). I think that it is very appropriate to validate in htsjdk. On Thu, Jul 16, 2015 at 4:05 PM, ldgauthier notifications@github.com; wrote:. > Currently ValidateVariants relies on genotypes to transitively check that; > each alt allele occurs in at least one sample and that the AC adds up.; > However, this can fail on sites-only files because there are no geno",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2507:1332,validat,validation,1332,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2507,1,['validat'],['validation']
Security,get gcloud authorization working on travis,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/444:11,authoriz,authorization,11,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/444,1,['authoriz'],['authorization']
Security,"gine; 19:10:31.451 INFO CalculateContamination - Shutting down engine; [March 6, 2022 7:10:31 PM CST] org.broadinstitute.hellbender.tools.walkers.contamination.CalculateContamination done. Elapsed time: 0.01 minutes.; Runtime.totalMemory()=2141192192; java.lang.IllegalArgumentException: there is no such column: contig; 	at org.broadinstitute.hellbender.utils.tsv.DataLine.columnIndex(DataLine.java:483); 	at org.broadinstitute.hellbender.utils.tsv.DataLine.get(DataLine.java:452); 	at org.broadinstitute.hellbender.utils.tsv.DataLine.get(DataLine.java:581); 	at org.broadinstitute.hellbender.tools.walkers.contamination.PileupSummary$PileupSummaryTableReader.createRecord(PileupSummary.java:193); 	at org.broadinstitute.hellbender.tools.walkers.contamination.PileupSummary$PileupSummaryTableReader.createRecord(PileupSummary.java:188); 	at org.broadinstitute.hellbender.utils.tsv.TableReader.fetchNextRecord(TableReader.java:364); 	at org.broadinstitute.hellbender.utils.tsv.TableReader.access$200(TableReader.java:99); 	at org.broadinstitute.hellbender.utils.tsv.TableReader$1.hasNext(TableReader.java:472); 	at java.util.Iterator.forEachRemaining(Iterator.java:115); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:566); 	at org.broadinstitute.hellbender.utils.tsv.TableReader.toList(TableReader.java:532); 	at org.broadinstitute.hellbender.tools.walkers.contamination.PileupSummary.readFromFile(PileupSummary.java:139); 	at org.broadinstitute.hellbender.tools.walkers.contamination.CalculateContamination.doWork(CalculateContamination.java:116); 	at org.broadinstitute.hell",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7707:3994,access,access,3994,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7707,1,['access'],['access']
Security,google-cloud-java: CloudStorageReadChannel.create() does a GCS access outside of the retry mechanism in CloudStorageReadChannel.read(),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3253:63,access,access,63,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3253,1,['access'],['access']
Security,google-cloud-nio 0.123.23: certain non-requester-pays accesses fail when --gcs-project-for-requester-pays is specified,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7716:54,access,accesses,54,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7716,1,['access'],['accesses']
Security,"gs://depmapomicsdata/1000g_pon.hg38.vcf.gz; 20:59:55.629 INFO Mutect2 - Shutting down engine; [October 4, 2021 8:59:55 PM GMT] org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2 done. Elapsed time: 0.12 minutes.; Runtime.totalMemory()=876609536; code: 403; message: pet-102022583875839491351@broad-firecloud-ccle.iam.gserviceaccount.com does not have storage.buckets.get access to the Google Cloud Storage bucket.; reason: forbidden; location: null; retryable: false; com.google.cloud.storage.StorageException: pet-102022583875839491351@broad-firecloud-ccle.iam.gserviceaccount.com does not have storage.buckets.get access to the Google Cloud Storage bucket.; at com.google.cloud.storage.spi.v1.HttpStorageRpc.translate(HttpStorageRpc.java:229); at com.google.cloud.storage.spi.v1.HttpStorageRpc.get(HttpStorageRpc.java:406); at com.google.cloud.storage.StorageImpl$4.call(StorageImpl.java:217); ...; ```. This happens while it runs the command:. ```; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx15500m\ ; -jar /root/gatk.jar Mutect2 -R gs://genomics-public-data/resources/broad/hg38/v0/Homo_sapiens_assembly38.fasta\ ; -I gs://cclebams/hg38_wes/CDS-00rz9N.hg38.bam -tumor BC1_HAEMATOPOIETIC_AND_LYMPHOID_TISSUE --germline-resource gs://gcp-public-data--gnomad/release/3.0/vcf/genomes/gnomad.genomes.r3.0.sites.vcf.bgz\ ; -pon gs://gatk-best-practices/somatic-hg38/1000g_pon.hg38.vcf.gz\ ; -L gs://fc-secure-d2a2d895-a7af-4117-bdc7-652d7d268324/7a157f4a-7d93-4a3e-aaf4-c41833463f5a/Mutect2/3be8ce8e-1075-4063-bc43-6f61e386c3f5/call-SplitIntervals/cacheCopy/glob-0fc990c5ca95eebc97c4c204e3e303e1/0000-scattered.interval_list\ ; -O output.vcf.gz --f1r2-tar-gz f1r2.tar.gz --gcs-project-for-requester-pays broad-firecloud-ccle; ```. But I gave read (both regular and legacy) access to gs://cclebams (this is a requester pays bucket). This was done on GATK 4.2.2 docker. Best,",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7492:2132,secur,secure-,2132,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7492,2,"['access', 'secur']","['access', 'secure-']"
Security,"h a stack trace:; ```; code: 401; message: Anonymous caller does not have storage.objects.get access to joel-cram/SAM24339124.cram.; reason: required; location: Authorization; retryable: false; com.google.cloud.storage.StorageException: Anonymous caller does not have storage.objects.get access to joel-cram/SAM24339124.cram.; at com.google.cloud.storage.spi.v1.HttpStorageRpc.translate(HttpStorageRpc.java:220); at com.google.cloud.storage.spi.v1.HttpStorageRpc.get(HttpStorageRpc.java:415); at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:198); at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:195); at shaded.cloud_nio.com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:89); at com.google.cloud.RetryHelper.run(RetryHelper.java:74); at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:51); at com.google.cloud.storage.StorageImpl.get(StorageImpl.java:195); at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.checkAccess(CloudStorageFileSystemProvider.java:673); at java.nio.file.Files.exists(Files.java:2385); at htsjdk.samtools.util.IOUtil.assertFileIsReadable(IOUtil.java:429); at org.broadinstitute.hellbender.engine.ReadsDataSource.<init>(ReadsDataSource.java:206); ```. ```; Caused by: shaded.cloud_nio.com.google.api.client.googleapis.json.GoogleJsonResponseException: 401 Unauthorized; {; ""code"" : 401,; ""errors"" : [ {; ""domain"" : ""global"",; ""location"" : ""Authorization"",; ""locationType"" : ""header"",; ""message"" : ""Anonymous caller does not have storage.objects.get access to joel-cram/SAM24339124.cram."",; ""reason"" : ""required""; } ],; ""message"" : ""Anonymous caller does not have storage.objects.get access to joel-cram/SAM24339124.cram.""; }; ```. ### Desired; Something like ""Unable to read gs://joel-cram/SAM24339124.cram due to permissions. Have you enabled Google Cloud Application Default Credentials by running 'gcloud auth application-default login'? See [this forum post] for details.""",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5468:1992,Authoriz,Authorization,1992,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5468,3,"['Authoriz', 'access']","['Authorization', 'access']"
Security,"h/supportingMultiA.vcf; > ; > which outputs:; > INFO field at 1:768589 .. INFO tag [AC=1] expected different number of; > values (expected 2, found 1),INFO tag [AF=0.00047] expected different; > number of values (expected 2, found 1); > Notes; > ; > Currently, all the validation modes call out to HTSJDK. Do we want to put; > the new functionality there as well?; > ; > —; > Reply to this email directly or view it on GitHub; > https://github.com/broadinstitute/gsa-unstable/issues/1053. ---. @ldgauthier commented on [Fri Jul 17 2015](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-122308040). Today I learned that the way we currently build GATK, you can't point to a local htsjdk jar anymore, so this task will be two-fold:; 1) Make a PR to htsjdk with a new function in the VariantContext class for validateInfoFieldCounts(VCFInfoHeaderLine headerLine) or similar; add a test to VariantContextUnitTest.java; 2) After change 1) is merged, update ValidateVariants accordingly to use the new function and add a test to its integration tests. ---. @vdauwera commented on [Fri May 27 2016](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-222213763). @ldgauthier is this still a thing? (in the sense of not having been addressed in htsjdk). ---. @ldgauthier commented on [Fri May 27 2016](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-222214083). Still a thing. No work has been done here AFAIK. ---. @vdauwera commented on [Mon Nov 14 2016](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-260465013). This seems like fairly low-hanging fruit -- @ronlevine . ---. @ronlevine commented on [Wed Nov 23 2016](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-262613152). @ldgauthier Shouldn't a locus without genotypes bypass `AC` validation, given it's defined as: `Allele count in genotypes, for each ALT allele, in the same order as listed`?. ---. @ldgauthier commented on [Wed No",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2507:4521,Validat,ValidateVariants,4521,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2507,1,['Validat'],['ValidateVariants']
Security,haded.cloud_nio.com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:92); 	at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:47); 	at com.google.cloud.storage.BlobReadChannel.read(BlobReadChannel.java:125); 	at com.google.cloud.storage.contrib.nio.CloudStorageReadChannel.read(CloudStorageReadChannel.java:109); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher$WorkUnit.call(SeekableByteChannelPrefetcher.java:131); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher$WorkUnit.call(SeekableByteChannelPrefetcher.java:104); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745); Caused by: javax.net.ssl.SSLHandshakeException: Remote host closed connection during handshake; 	at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:992); 	at sun.security.ssl.SSLSocketImpl.performInitialHandshake(SSLSocketImpl.java:1375); 	at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1403); 	at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1387); 	at sun.net.www.protocol.https.HttpsClient.afterConnect(HttpsClient.java:559); 	at sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.connect(AbstractDelegateHttpsURLConnection.java:185); 	at sun.net.www.protocol.https.HttpsURLConnectionImpl.connect(HttpsURLConnectionImpl.java:153); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:93); 	at shaded.cloud_nio.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:972); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.Abstra,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2685:6310,secur,security,6310,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2685,1,['secur'],['security']
Security,handle normal reads in validation sample in BasicSomaticValidator,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5322:23,validat,validation,23,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5322,1,['validat'],['validation']
Security,hashtable lookups are expensive in Kryo and they add up to 15% or more of runtime (top hotspot on Xprof). https://twitter.com/aphyr/status/478638361150636032. This PR turns off reference tracking in Kryo which speeds things up ~7.2mins vs 7.4mins on MarkDuplicatesSpark but it's a bit risky because I think it may result in an infinite loop for cyclic object graphs. We do not have any cyclic object graphs now and so it's fine. The PR is to open a convo about this.; @tomwhite @droazen @laserson wdyt?,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1734:0,hash,hashtable,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1734,1,['hash'],['hashtable']
Security,"have been written, a new file is created with the index at the top and the contents of the temporary .pgen file appended to it. When `WRITE_SEPARATE_INDEX` is selected, the index is instead written to a separate .pgi file. The default is `WRITE_AND_COPY`. #### max-alt-alleles; The PGEN format can only support up to 254 alt alleles per site. This argument allows you to specify a limit. The default is the max of 254. Any sites with more alt alleles than the specified max will not be written. #### lenient-ploidy-validation; PGEN is a bit quirky in that it requires samples to be diploid but has a special case for sex chromosomes, which are allowed to be haploid. By default, any attempt to write a record with an unsupported ploidy will result in an exception being thrown. If this flag is used, then ploidy failures will instead be logged and the records will be written as missing. #### writer-log-file; The C++ code in the PGEN writer in PGEN-JNI will log sites that exceed max-alt-alleles and with unsupported ploidy (if lenient-ploidy-validation is set) to the specified log file, if this argument is set. #### allow-empty-pgen; Empty PGEN files are not technically valid PGEN files. However, for parallel processing purposes, it is sometimes helpful to allow the creation of empty files when there are no variants to be written. The GvsExtractCallsetPgenMerged workflow relies on this. If this flag is set and no variants are written, an empty .pgen, .psam, and .pvar.zst file will be written in `onShutdown()`. By default (i.e. if this flag is not set), if there are no variants written, an exception will be thrown. . ### Part 3: GvsExtractCallsetPgenMerged; GvsExtractCallsetPgenMerged is a WDL workflow that calls ExtractCohortToPgen to extract data from GVS and write it to PGEN files, and then merges those PGEN files by chromosome. This workflow has 3 steps:. #### Step 1: GvsExtractCallsetPgen; This is a workflow based very closely on the GvsExtractCallset workflow (which is used f",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8708:5098,validat,validation,5098,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8708,1,['validat'],['validation']
Security,"he Y chromosome, but possibly in other places as well) due to changes between the two references. ; ; 12:37:55.679 INFO  ProgressMeter - Starting traversal ; ; 12:37:55.679 INFO  ProgressMeter -        Current Locus  Elapsed Minutes    Features Processed  Features/Minute ; ; 12:37:56.198 WARN  FuncotatorUtils - Reference allele is different than the reference coding sequence (strand: -, alt = G, ref G != T reference coding seq) @\[chr1:13839497\]!  Substituting given allele for sequence code (TTC->GTC) ; ; 12:37:56.213 INFO  FuncotateSegments - Shutting down engine ; ; \[February 9, 2022 12:37:56 PM EST\] org.broadinstitute.hellbender.tools.funcotator.FuncotateSegments done. Elapsed time: 0.24 minutes. ; ; Runtime.totalMemory()=3139436544 ; ; java.lang.IllegalArgumentException: Invalid interval. Contig:chr1 start:29534 end:14501 ; ;     at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:804) ; ;     at org.broadinstitute.hellbender.utils.SimpleInterval.validatePositions(SimpleInterval.java:59) ; ;     at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:35) ; ;     at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.segment.SegmentExonUtils.findInclusiveExonIndex(SegmentExonUtils.java:95) ; ;     at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.segment.SegmentExonUtils.determineSegmentExonPosition(SegmentExonUtils.java:63) ; ;     at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createSegmentFuncotations(GencodeFuncotationFactory.java:2938) ; ;     at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createSegmentFuncotations(GencodeFuncotationFactory.java:2914) ; ;     at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsOnSegment(GencodeFuncotationFactory.java:2866) ; ;     at org.broadinstitute.hellbender.tools.funcotator.DataSourceF",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7676:2483,validat,validatePositions,2483,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7676,1,['validat'],['validatePositions']
Security,"his version includes a fix for the issue we were seeing which required multiple pulls; removed the workaround (fixes #1404). The problem was that we were using an ssh git remote. git-lfs fails in this case because it can't authenticate. (unclear to me if this is a bug or not, I don't know if github requires authentication for ssh access to public repos). In versions <= 1.1.0 git-lfs was falling back to trying over an http connection. They removed this fallback mechanism in 1.1.1. See github/git-lfs#1090 for discussion.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1600:223,authenticat,authenticate,223,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1600,3,"['access', 'authenticat']","['access', 'authenticate', 'authentication']"
Security,"houghts for @samuelklee. For example, CollectFragmentCounts produces the following hybrid-type `@RG` line:. ![screenshot 2018-02-22 15 05 48](https://user-images.githubusercontent.com/11543866/36908820-66b90938-1e0a-11e8-8830-793ff3f71e96.png). ```; @RG ID:GATKCopyNumber SM:HCC1143_tumor; ```; Official format specifications are at https://samtools.github.io/hts-specs/. Let me briefly describe the #choices. ---; If we are to follow conventions used in the alignment world (SAM specs, for interval lists), then... We note data transformations using `@PG` program groups. These can be added successively to the same data file, given unique `@PG ID` fields, and collectively these lines showcase the history of data transformations for a dataset. The `@RG` group is reserved for lane level data and yes, does unify based on the sample or library. ---; If we examine VCFs, the convention is to use `#` hashtags to denote header rows (VCF specs). Double hashtags `##` denote all metadata lines and a single hashtag `#` denotes the line with the column labels. Here are some select rows from an M2 VCF header:; ```; ##fileformat=VCFv4.2; ##FILTER=<ID=artifact_in_normal,Description=""artifact_in_normal"">; ...; ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Allelic depths for the ref and alt alleles in the order listed"">; ...; ##GATKCommandLine=<ID=FilterMutectCalls,CommandLine=""FilterMutectCalls...; ...; ##GATKCommandLine=<ID=Mutect2,CommandLine=""Mutect2 --tumor-sample HCC1143_tumor ...; ...; ##INFO=<ID=TLOD,Number=A,Type=Float,Description=""Tumor LOD score"">; ##Mutect Version=2.1-beta; ##command=FilterByOrientationBias --output hcc1143_T_clean-filtered.vcf...; ...; ##contig=<ID=chr1,length=248956422>; ##contig=<ID=chr2,length=242193529>; ...; ##contig=<ID=HLA-DRB1*16:02:01,length=11005>; ##filtering_status=These calls have been filtered by FilterMutectCalls to label false positives with a list of failed filters and true positives with PASS.; ##normal_sample=HCC1143_normal; ##orientatio",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4481:963,hash,hashtags,963,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4481,2,['hash'],"['hashtag', 'hashtags']"
Security,"htsjdk versions older than 2.1.1 would remove NM and MD tags on bam->cram compression, and then automatically regenerate NM tags when reading cram. Starting with 2.1.1, in order to ensure lossless round-tripping, it no longer does either, and restores only the tags present in the compressed file . As a result, any cramfile read with 2.1.1+ that was generated with older htsjdk versions (or samtools) will fail validation due to missing NM tags. So this PR contains an updated cram file that contains NM tags for the SAMFileValidation tests.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1551:412,validat,validation,412,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1551,1,['validat'],['validation']
Security,https://gatk-jenkins.broadinstitute.org/ is currently giving a warning when you try to visit it. We need to fix it's certificate so that it doesn't give a scary warning. It says it expired several days ago. @davidbernick Could you look into this?,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2446:117,certificate,certificate,117,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2446,1,['certificate'],['certificate']
Security,"https://github.com/broadinstitute/gatk/blob/c6daf7dd02b866907fbfebad150baeb540c35bce/src/main/java/org/broadinstitute/hellbender/tools/walkers/sv/JointGermlineCNVSegmentation.java#L701. I'm running into a recurrent issue in JointGermlineCNVSegmentation, running after PostprocessGermlineCNVCalls in a gCNV pipeline. A number of batches are being merged in parallel - some of those succeed, some fail. It's not clear just yet if this is a deterministic failure, I'll re-run a few times and see if I can answer that. . ```text; org.broadinstitute.hellbender.exceptions.GATKException: Exception thrown at chrX:6383391 [VC SAMPLE_ID.segments.vcf.gz @ chrX:6383391-17732942 Q3076.53 of type=NO_VARIATION alleles=[N*] attr={END=17732942} GT=GT:CN:NP:QA:QS:QSE:QSS	0:1:581:1:3077:4:20 filters=. ... Caused by: java.lang.IllegalStateException: Encountered genotype with ploidy 1 but 2 alleles.; 	at org.broadinstitute.hellbender.utils.Utils.validate(Utils.java:814); 	at org.broadinstitute.hellbender.tools.walkers.sv.JointGermlineCNVSegmentation.correctGenotypePloidy(JointGermlineCNVSegmentation.java:701); 	at org.broadinstitute.hellbender.tools.walkers.sv.JointGermlineCNVSegmentation.prepareGenotype(JointGermlineCNVSegmentation.java:682); ```. The VCF row in question is . ```text; chrX	6383391	CNV_chrX_6383391_17732942	N	.	3076.53	.	END=17732942	GT:CN:NP:QA:QS:QSE:QSS	0:1:581:1:3077:4:20; ```. The characterisation of this row as `type=NO_VARIATION alleles=[N*]` seems... partially correct? There is no variation at this locus, but I'm not sure why alleles is `N*`. In this situation, as I read it, the first clause should be satisfied: 1 allele, and allele is no-call. Instead the variant process is dying in the else side of the condition. Could you clarify if I'm interpreting this correctly?. Relevant versioning:; ```; 13:18:38.320 INFO JointGermlineCNVSegmentation - ------------------------------------------------------------; 13:18:38.321 INFO JointGermlineCNVSegmentation - The Genome Analy",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8834:933,validat,validate,933,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8834,1,['validat'],['validate']
Security,"i,. Using GATK mutect2's wdl file on Terra (version 21 on agora) I keep getting the same error:; ""pet-102022583875839491351@broad-firecloud-ccle.iam.gserviceaccount.com does not have storage.buckets.get access to the Google Cloud Storage bucket"" . Here is part of the stacktrace : ; ```; 20:59:48.744 INFO Mutect2 - Inflater: IntelInflater; 20:59:48.744 INFO Mutect2 - GCS max retries/reopens: 20; 20:59:48.744 INFO Mutect2 - Requester pays: enabled. Billed to: broad-firecloud-ccle; 20:59:48.744 INFO Mutect2 - Initializing engine; 20:59:54.630 INFO FeatureManager - Using codec VCFCodec to read file gs://depmapomicsdata/1000g_pon.hg38.vcf.gz; 20:59:55.629 INFO Mutect2 - Shutting down engine; [October 4, 2021 8:59:55 PM GMT] org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2 done. Elapsed time: 0.12 minutes.; Runtime.totalMemory()=876609536; code: 403; message: pet-102022583875839491351@broad-firecloud-ccle.iam.gserviceaccount.com does not have storage.buckets.get access to the Google Cloud Storage bucket.; reason: forbidden; location: null; retryable: false; com.google.cloud.storage.StorageException: pet-102022583875839491351@broad-firecloud-ccle.iam.gserviceaccount.com does not have storage.buckets.get access to the Google Cloud Storage bucket.; at com.google.cloud.storage.spi.v1.HttpStorageRpc.translate(HttpStorageRpc.java:229); at com.google.cloud.storage.spi.v1.HttpStorageRpc.get(HttpStorageRpc.java:406); at com.google.cloud.storage.StorageImpl$4.call(StorageImpl.java:217); ...; ```. This happens while it runs the command:. ```; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx15500m\ ; -jar /root/gatk.jar Mutect2 -R gs://genomics-public-data/resources/broad/hg38/v0/Homo_sapiens_assembly38.fasta\ ; -I gs://cclebams/hg38_wes/CDS-00rz9N.hg38.bam -tumor BC1_HAEMATOPOIETIC_AND_LYMPHOID_TISSUE --germline-resource gs://gcp-public-data--gnomad/release/3",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7492:982,access,access,982,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7492,1,['access'],['access']
Security,"ializing engine. 07:33:16.008 INFO FeatureManager - Using codec VCFCodec to read file file:///nobackup/lnsingh/MTRNA/out/COVSUBJ_0121_1_N_HA_filtered.humanspliced.gvcf.gz. 07:33:16.053 INFO IntervalArgumentCollection - Processing 16569 bp from intervals. 07:33:16.059 INFO FilterMutectCalls - Done initializing engine. 07:33:16.157 INFO ProgressMeter - Starting traversal. 07:33:16.157 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute. 07:33:16.158 INFO FilterMutectCalls - Starting pass 0 through the variants. 07:33:17.341 INFO FilterMutectCalls - Finished pass 0 through the variants. 07:33:17.404 INFO FilterMutectCalls - Shutting down engine. [September 20, 2020 7:33:17 AM PDT] org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls done. Elapsed time: 0.04 minutes. Runtime.totalMemory()=1256194048. java.lang.IllegalArgumentException: alpha must be greater than 0 but got NaN. at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:727). at org.broadinstitute.hellbender.utils.param.ParamUtils.isPositive(ParamUtils.java:165). at org.broadinstitute.hellbender.tools.walkers.readorientation.BetaDistributionShape.<init>(BetaDistributionShape.java:13). at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.BinomialCluster.getFuzzyBinomial(BinomialCluster.java:43). at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.BinomialCluster.<init>(BinomialCluster.java:17). at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.initializeClusters(SomaticClusteringModel.java:184). at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.learnAndClearAccumulatedData(SomaticClusteringModel.java:325). at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.learnParameters(Mutect2FilteringEngine.java:153). at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls.afterNthPass(Filte",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6850:4600,validat,validateArg,4600,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6850,1,['validat'],['validateArg']
Security,"ility to tweak sample-every-Nth-variant parameter for SNP model creation (#8019); - add initial notebook copy pasta (#8008); - add sample_table_timestamp to GetNumSamplesLoaded (#8022); - Batched Avro export [VS-630] (#8020); - Updating references to old GATK for VS-620 (#8023); - VS-517 Use standard version of GetBQTableLastModifiedDatetime in GvsValidateVat (#8024); - Fix bug in GvsWithdrawSamples.wdl (#8026); - Ah 617 exposing the drop_state parameter to the GvsJointVariantCalling wdl used for beta (and internal customer) (#8032); - Expose maximum-training-variants VQSR parameter [VS-634] (#8029); - Callset statistics [VS-560] (#8018); - Check for withdrawn before exporting to AVRO files [VS-646] (#8039); - Small updates to GVS Integration WDL [VS-618] (#8042); - Rework Hail script generation [VS-616] (#8034); - Alpine based Variant Store Docker image [VS-648] (#8044); - update warp version (#7906); - Fail Avro extract and callset stats on bad filter name [VS-655] (#8046); - Vs 629 failure to retrieve job information during ingest (#8047); - Restore accidentally removed bcftools [VS-661] (#8051); - Allowing our pipeline to function with a sample size of one (#8055); - Vs 665 re create vcf for cd 68 po 52339 with ad padding fixed (#8057); - VS-665 and VS-620 updating code to use latest docker images containing Rori's AD calculation changes in extract (#8061); - updating the beta workflow to use the latest jar, representing the version of GATK George tested against the workflow (#8062); - VS-637 Address a couple of issues in SampleLoadStatus handling in GVSImportGenomes. (#8052); - Revert Alpinizing of apt dependent task [VS-688] (#8065); - Fix missing vat schema JSONs [VS-699] (#8072); - Fix integration expectations for fixed AD [VS-689] (#8066); - VS-698 Remove unnecessary columns from Call set statistics (#8073); - Fix Dockerfile nits that break 20.10.21 (#8078); - Nirvana 3.18.1 Docker images support [VS-661] (#8082); - Add option to not prepare __REF_DATA or __",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8248:28794,Expose,Expose,28794,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8248,2,['Expose'],['Expose']
Security,"ilter.OrientationBiasFilterer.annotateVariantContextsWithFilterResults(OrientationBiasFilterer.java:216); 	at org.broadinstitute.hellbender.tools.exome.FilterByOrientationBias.onTraversalSuccess(FilterByOrientationBias.java:168); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:781); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:115); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:170); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:189); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:122); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:143); 	at org.broadinstitute.hellbender.Main.main(Main.java:221); ```; and; ```; java.lang.IllegalStateException: Allele in genotype G* not in the variant context [C*, T]; 	at htsjdk.variant.variantcontext.VariantContext.validateGenotypes(VariantContext.java:1360); 	at htsjdk.variant.variantcontext.VariantContext.validate(VariantContext.java:1298); 	at htsjdk.variant.variantcontext.VariantContext.<init>(VariantContext.java:401); 	at htsjdk.variant.variantcontext.VariantContextBuilder.make(VariantContextBuilder.java:494); 	at htsjdk.variant.variantcontext.VariantContextBuilder.make(VariantContextBuilder.java:488); 	at org.broadinstitute.hellbender.tools.exome.orientationbiasvariantfilter.OrientationBiasFilterer.annotateVariantContextsWithFilterResults(OrientationBiasFilterer.java:216); 	at org.broadinstitute.hellbender.tools.exome.FilterByOrientationBias.onTraversalSuccess(FilterByOrientationBias.java:211); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:840); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:115); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:170); 	at org.broadinstitute.he",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3291:2227,validat,validateGenotypes,2227,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3291,1,['validat'],['validateGenotypes']
Security,"imVariants - Reference allele is too long (212) at position chr2_KI270894v1_alt:202602; skipping that record. Set --reference_window_stop >= 212 ; INFO 21:38:54,233 LeftAlignAndTrimVariants - Reference allele is too long (220) at position chr2_KI270894v1_alt:204859; skipping that record. Set --reference_window_stop >= 220 ; INFO 21:38:54,237 LeftAlignAndTrimVariants - Reference allele is too long (262) at position chr2_KI270894v1_alt:207863; skipping that record. Set --reference_window_stop >= 262 ; 0 variants were aligned; INFO 21:38:54,554 ProgressMeter - done 3.31246907E8 31.8 m 5.0 s 99.7% 31.8 m 5.0 s ; INFO 21:38:54,554 ProgressMeter - Total runtime 1905.29 secs, 31.75 min, 0.53 hours ; ------------------------------------------------------------------------------------------; Done. There were 4 WARN messages, the first 4 are repeated below.; WARN 17:39:57,688 IndexDictionaryUtils - Track variant doesn't have a sequence dictionary built in, skipping dictionary validation ; WARN 18:13:42,039 SimpleTimer - Clock drift of -1,503,348,737,016,211,299 - -1,503,346,772,578,127,937 = 1,964,438,083,362 nanoseconds detected, vs. max allowable drift of 5,000,000,000. Assuming checkpoint/restart event. ; WARN 20:14:18,043 SimpleTimer - Clock drift of -1,503,355,916,564,964,097 - -1,503,348,737,015,111,124 = 7,179,549,852,973 nanoseconds detected, vs. max allowable drift of 5,000,000,000. Assuming checkpoint/restart event. ; WARN 21:10:35,064 SimpleTimer - Clock drift of -1,503,359,203,412,549,926 - -1,503,355,916,564,817,209 = 3,286,847,732,717 nanoseconds detected, vs. max allowable drift of 5,000,000,000. Assuming checkpoint/restart event. ; ------------------------------------------------------------------------------------------; WMCF9-CB5:Mutect2 shlee$ ; ```. ### Notice the following line from above. > 0 variants were aligned. Also, it would be great if the tool, which appears to keep track of the lengths of reference alleles that are too long, could give me the **ma",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3487:7468,validat,validation,7468,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3487,1,['validat'],['validation']
Security,"ime.AbstractFunction0.apply$mcV$sp(AbstractFunction0.scala:12); 	at scala.App.$anonfun$main$1$adapted(App.scala:76); 	at scala.collection.immutable.List.foreach(List.scala:389); 	at scala.App.main(App.scala:76); 	at scala.App.main$(App.scala:74); 	at StudentAws$.main(StudentAws.scala:8); 	at StudentAws.main(StudentAws.scala); Exception in thread ""main"" java.lang.UnsatisfiedLinkError: org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Ljava/lang/String;I)Z; 	at org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Native Method); 	at org.apache.hadoop.io.nativeio.NativeIO$Windows.access(NativeIO.java:793); 	at org.apache.hadoop.fs.FileUtil.canRead(FileUtil.java:1249); 	at org.apache.hadoop.fs.FileUtil.list(FileUtil.java:1454); 	at org.apache.hadoop.fs.RawLocalFileSystem.listStatus(RawLocalFileSystem.java:601); 	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1972); 	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:2014); 	at org.apache.hadoop.fs.ChecksumFileSystem.listStatus(ChecksumFileSystem.java:761); 	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1972); 	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:2014); 	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.getAllCommittedTaskPaths(FileOutputCommitter.java:334); 	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitJobInternal(FileOutputCommitter.java:404); 	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitJob(FileOutputCommitter.java:377); 	at org.apache.parquet.hadoop.ParquetOutputCommitter.commitJob(ParquetOutputCommitter.java:48); 	at org.apache.spark.internal.io.HadoopMapReduceCommitProtocol.commitJob(HadoopMapReduceCommitProtocol.scala:192); 	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$writeAndCommit$3(FileFormatWriter.scala:275); 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12); 	at org.apache.spark.util.Utils$.timeTakenMs(Utils.scala:640); 	at o",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8587:8246,Checksum,ChecksumFileSystem,8246,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8587,1,['Checksum'],['ChecksumFileSystem']
Security,"in `BwaSparkEngine` the method `alignWithBwa` is like this. ```; public JavaRDD<GATKRead> alignWithBWA(final JavaSparkContext ctx, final JavaRDD<GATKRead> unalignedReads, final SAMFileHeader readsHeader) {; //Note: SparkContext is not serializable so we don't store it in the engine and set this property here. Setting it multiple times is fine.; // ensure reads in a pair fall in the same partition (input split), so they are processed together; ctx.hadoopConfiguration().setBoolean(BAMInputFormat.KEEP_PAIRED_READS_TOGETHER_PROPERTY, true);. final JavaRDD<Tuple2<ShortRead, ShortRead>> shortReadPairs = convertToUnalignedReadPairs(unalignedReads);; final JavaRDD<String> samLines = align(shortReadPairs);; final SAMLineParser samLineParser = new SAMLineParser(new DefaultSAMRecordFactory(), ValidationStringency.SILENT, readsHeader, null, null);; final Broadcast<SAMLineParser> samLineParserBroadcast = ctx.broadcast(samLineParser);; return samLines.map(r -> new SAMRecordToGATKReadAdapter(samLineParserBroadcast.getValue().parseLine(r)));; }; ```. note that the parser is distributed by broadcast and thus shared by all tasks in an executor. That's a race condition because the parser is mutable (eg the `fields` field in the coded that gets mutated for each decode call). https://github.com/broadinstitute/gatk/issues/2039 may be caused by this bug",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2050:793,Validat,ValidationStringency,793,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2050,1,['Validat'],['ValidationStringency']
Security,ineCNVCaller - . !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. Warning: GermlineCNVCaller is a BETA tool and is not yet ready for use in production. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. 21:54:28.627 INFO GermlineCNVCaller - Initializing engine; 21:54:31.994 INFO GermlineCNVCaller - Done initializing engine; log4j:WARN No appenders could be found for logger (org.broadinstitute.hdf5.HDF5Library).; log4j:WARN Please initialize the log4j system properly.; log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.; 21:54:33.457 INFO GermlineCNVCaller - Intervals specified...; 21:54:34.113 INFO IntervalArgumentCollection - Processing 10999816 bp from intervals; 21:54:34.145 INFO GermlineCNVCaller - No GC-content annotations for intervals found; explicit GC-bias correction will not be performed...; 21:54:34.217 INFO GermlineCNVCaller - Running the tool in the COHORT mode...; 21:54:34.217 INFO GermlineCNVCaller - Validating and aggregating data from input read-count files...; 21:54:34.241 INFO GermlineCNVCaller - Aggregating read-count file /home/shlee/gcnv/low_coverage_1k/HG00096.lc.soohee1k.hdf5 (1 / 24); 21:54:36.539 INFO GermlineCNVCaller - Aggregating read-count file /home/shlee/gcnv/low_coverage_1k/HG00268.lc.soohee1k.hdf5 (2 / 24); 21:54:37.967 INFO GermlineCNVCaller - Aggregating read-count file /home/shlee/gcnv/low_coverage_1k/HG00419.lc.soohee1k.hdf5 (3 / 24); 21:54:40.147 INFO GermlineCNVCaller - Aggregating read-count file /home/shlee/gcnv/low_coverage_1k/HG00759.lc.soohee1k.hdf5 (4 / 24); 21:54:41.782 INFO GermlineCNVCaller - Aggregating read-count file /home/shlee/gcnv/low_coverage_1k/HG01051.lc.soohee1k.hdf5 (5 / 24); 21:54:43.197 INFO GermlineCNVCaller - Aggregating read-count file /home/shlee/gcnv/low_coverage_1k/HG01112.lc.soohee1k.hdf5 (6 / 24); 21:54:45.169 INFO GermlineCNVCaller - Aggregating read-count file /home/shlee/gcnv/low_coverage_1k/HG01500.lc.soohee1k.hdf5 (7 / 24); 21:54:46.852 I,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4826:2913,Validat,Validating,2913,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4826,1,['Validat'],['Validating']
Security,"info annotations in the header to check; > how many entries each should have.; > Outline; > - Add a new validation type for info-field counts to enum and to; > switch statement; > - Grab info headers from input VCF with something like; > GATKVCFUtils.getVCFHeadersFromRods(getToolkit(),; > variantCollection.variants.getName()) and VCFHeader::getInfoHeaderLines; > - In the map() function, for each info header line, call on each; > VCFInfoHeaderLine getCount(vc) to get the expected number of info; > annotation entries; > - Compare the expected number with a count based on; > vc.getAttribute(currentVCFinfoHeaderLine.getID()), which will require some; > additional parsing because it returns an Object; > - (Bonus points if you use the isFixedCount() and getCount() functions; > on the VCF info header line to simplify annotations that aren't according; > to the number of alt alleles); > ; > Test data; > ; > /humgen/gsa-hpprojects/dev/gauthier/scratch/supportingMultiA.vcf; > Should fail AC/AF validation at; > 1 768589 . A C,G 76 PASS AC=1;AF=0.00047;AN=2120; > See results using:; > ; > use VCFtools; > vcf-validator /humgen/gsa-hpprojects/dev/gauthier/scratch/supportingMultiA.vcf; > ; > which outputs:; > INFO field at 1:768589 .. INFO tag [AC=1] expected different number of; > values (expected 2, found 1),INFO tag [AF=0.00047] expected different; > number of values (expected 2, found 1); > Notes; > ; > Currently, all the validation modes call out to HTSJDK. Do we want to put; > the new functionality there as well?; > ; > —; > Reply to this email directly or view it on GitHub; > https://github.com/broadinstitute/gsa-unstable/issues/1053. ---. @ldgauthier commented on [Fri Jul 17 2015](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-122308040). Today I learned that the way we currently build GATK, you can't point to a local htsjdk jar anymore, so this task will be two-fold:; 1) Make a PR to htsjdk with a new function in the VariantContext class for valid",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2507:3379,validat,validation,3379,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2507,1,['validat'],['validation']
Security,"ing false --help false --version false --showHidden false --verbosity INFO --QUIET false --use_jdk_deflater false --use_jdk_inflater false --disableToolDefaultReadFilters false; [March 21, 2017 5:43:53 PM EDT] Executing as louisb@WMD2A-31E on Mac OS X 10.11.6 x86_64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_112-b16; Version: Version:4.alpha.2-189-g724fbd0-SNAPSHOT; 17:43:53.162 INFO ValidateVariants - Defaults.BUFFER_SIZE : 131072; 17:43:53.162 INFO ValidateVariants - Defaults.COMPRESSION_LEVEL : 1; 17:43:53.162 INFO ValidateVariants - Defaults.CREATE_INDEX : false; 17:43:53.163 INFO ValidateVariants - Defaults.CREATE_MD5 : false; 17:43:53.163 INFO ValidateVariants - Defaults.CUSTOM_READER_FACTORY :; 17:43:53.163 INFO ValidateVariants - Defaults.EBI_REFERENCE_SERVICE_URL_MASK : http://www.ebi.ac.uk/ena/cram/md5/%s; 17:43:53.163 INFO ValidateVariants - Defaults.NON_ZERO_BUFFER_SIZE : 131072; 17:43:53.163 INFO ValidateVariants - Defaults.REFERENCE_FASTA : null; 17:43:53.163 INFO ValidateVariants - Defaults.SAM_FLAG_FIELD_FORMAT : DECIMAL; 17:43:53.163 INFO ValidateVariants - Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 17:43:53.163 INFO ValidateVariants - Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 17:43:53.163 INFO ValidateVariants - Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 17:43:53.163 INFO ValidateVariants - Defaults.USE_CRAM_REF_DOWNLOAD : false; 17:43:53.163 INFO ValidateVariants - Deflater IntelDeflater; 17:43:53.163 INFO ValidateVariants - Inflater IntelInflater; 17:43:53.163 INFO ValidateVariants - Initializing engine; 17:43:53.270 INFO FeatureManager - Using codec VCFCodec to read file file:///Users/louisb/Workspace/gatk/src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleGood.vcf; 17:43:53.287 INFO FeatureManager - Using codec VCFCodec to read file file:///Users/louisb/Workspace/gatk/src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleGood.vcf; 17:43:53.2",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2509:2585,Validat,ValidateVariants,2585,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2509,1,['Validat'],['ValidateVariants']
Security,"ining CachingIndexedFastaSequenceFile/overloads; - [ ] Update tools in the pathseq package (PathSeqBwaSpark, PathSeqScoreSpark) that do directory manipulation. [Edit] Somewhat tangentially, PathSeqBwaSpark currently rejects read inputs specified through `--inputs` and uses separate args to allow the user to identify inputs as paired or unpaired. Once this is using `GATKPathSpecifier` this could be changed to use ""--inputs"" annotated with tags instead. Might be a problem for WDL gen though (which doesn't support tags).; - [ ] Test utilities (createTempFile/Dir, etc. that return GATKPath); - [ ] Add a `toHadoopPath` method to `GATKPath` that returns a `org.apache.hadoop.fs.Path`.; - [ ] Change tools that generate multiple output files using a stem (SplitReads, etc) to use the `resolve` methods listed above once they're available.; - [ ] All usages of `PrintStream` should be replaced with `OutputStreamWriter` (code that requires printf-style formatting can use `write` with `String.format` instead of the `printf` methods). `PrintStream` doesn't propagate IOExceptions and instead requires calls to `checkError`, but almost all usages of `PrintStream` don't call it.; - [ ] Update `org.broadinstitute.hellbender.utils.report` (`GATKReport` and friends) to eliminate `File` references and `PrintStream` usages.; - [ ] Update `org.broadinstitute.hellbender.utils.recalibration` (`RecalUtils` and friends) to eliminate `File` references and `PrintStream` usages.; - [ ] Fix cases where we have a tool with a `File` that needs to be accessible to R code (determine if the code can handle non-local file paths). i.e.`VariantRecalibrator` TRANCHES_FILE.; - [ ] Fix cases where we have a tool with a `File` that needs to be accessible to Python (determine if the code can handle non-local file paths).; - [ ] `FeatureInput` should have all of it's String constructors removed, and only take GATKPath inputs. The constructor overloads that take tag Maps can be removed, and all call sites updated.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6610:2290,access,accessible,2290,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6610,2,['access'],['accessible']
Security,"institute.hellbender.engine.GATKTool.doWork(GATKTool.java:966); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); 	at org.broadinstitute.hellbender.Main.main(Main.java:289); ```; A second case involved `--alleles` input:; ```; 22	16464044	rs571268158	CCAGGTCT	C; 22	16464051	rs569099729	T	C; ```; and crashed similarly, with:; ```; java.lang.IllegalStateException: Allele in genotype CCAGGTCT* not in the variant context [T*, *, C]; 	at htsjdk.variant.variantcontext.VariantContext.validateGenotypes(VariantContext.java:1360); 	at htsjdk.variant.variantcontext.VariantContext.validate(VariantContext.java:1298); 	at htsjdk.variant.variantcontext.VariantContext.<init>(VariantContext.java:401); 	at htsjdk.variant.variantcontext.VariantContextBuilder.make(VariantContextBuilder.java:494); 	at htsjdk.variant.variantcontext.VariantContextBuilder.make(VariantContextBuilder.java:488); 	at org.broadinstitute.hellbender.utils.variant.GATKVariantContextUtils.simpleMerge(GATKVariantContextUtils.java:864); 	at org.broadinstitute.hellbender.utils.variant.GATKVariantContextUtils.simpleMerge(GATKVariantContextUtils.java:646); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.AssemblyBasedCallerUtils.makeMergedVariantContext(AssemblyBasedCallerUtils.java:221); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerGenotypingEngine.assignGenotypeLikelihoods(HaplotypeCallerGenotypingEngine.java:150); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerEngine.callRegion(HaplotypeCallerEngine.java:599); 	at org.broadinstitute.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5336:2898,validat,validate,2898,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5336,1,['validat'],['validate']
Security,institute.hellbender.utils.locusiterator.LocusIteratorByState.lazyLoadNextAlignmentContext(LocusIteratorByState.java:288); at org.broadinstitute.hellbender.utils.locusiterator.LocusIteratorByState.hasNext(LocusIteratorByState.java:225); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.AssemblyBasedCallerUtils.getPileupsOverReference(AssemblyBasedCallerUtils.java:443); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.ReferenceConfidenceModel.calculateRefConfidence(ReferenceConfidenceModel.java:195); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerEngine.callRegion(HaplotypeCallerEngine.java:645); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCaller.apply(HaplotypeCaller.java:212); at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.processReadShard(AssemblyRegionWalker.java:200); at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.traverse(AssemblyRegionWalker.java:173); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1048); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:163); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:206); at org.broadinstitute.hellbender.Main.main(Main.java:292); ```; This hypothesis is further evidenced by the fact that one user at least claims that their input file validates and that they couldn't find the problem reads by looking at the input files manually. We probably will want to look at an example file in the debugger to catch what is happening at this site. We have refactored a bunch of code adjacent to this function recently so its possible this is a recent regression.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6490:3006,validat,validates,3006,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6490,1,['validat'],['validates']
Security,"institute/gatk/issues/6553. However, it would be nice if you could actually investigate the formatting error. Unfortunately my formatting error isn't the same as reported in the other post. I have 105 error in which the 1st alternative allele is a spanning deletion and the 2nd (and 3rd) is either an indel or snp. It's true that the 2nd and 3rd allele is actually not found in my samples. I even have 7 occurances in which the 1st allele (spanning deletion) has allele frequency 1.00. my code is the following for GenotypeGVCFs:. java -Xms32G -Xmx32G -jar ${gatk4} GenotypeGVCFs -R ${ref} -V ${pipeline}/${name}\_v4.1.6.0.g.vcf.gz -O ${vcf}/${name}\_v4.1.6.0.vcf.gz -L ${pipeline}/${name}\_intervals.list 2> ${log}/${name}\_v4.1.6.0\_genotype.log. for ValidateVariants:. java -Xms10G -Xmx10G -jar ${gatk4} ValidateVariants -R ${ref} -V ${name}\_v4.1.6.0.vcf.gz -L ${pipeline}/${name}\_intervals.list --warn-on-errors 2> ${log}/${name}\_v4.1.6.0\_genotype\_valivar.log. the warning in ValidateVariants and the site look like this:. 14:12:15.126 WARN ValidateVariants - \*\*\*\*\* Input 1st\_v4.1.6.0.vcf.gz fails strict validation of type ALL: one or more of the ALT allele(s) for the record at position chr\_1:1088200 are not observed at all in the sample genotypes \*\*\*\*\* ; ; chr\_1 1088200 . T \*,TAAAAAAAAAAAA 64.39 . AC=8,0;AF=0.667,0.00;AN=12;DP=118;ExcessHet=3.0103;FS=0.000;InbreedingCoeff=0.4286;MLEAC=7,7;MLEAF=0.583,0.583;MQ=58.73;QD=32.19;SOR=2.303 GT:AD:DP:GQ:PL ./.:9,0,0:9:.:0,0,0,0,0,0 0/0:9,0,0:9:0:0,0,113,0,113,113 ./.:10,0,0:10:.:0,0,0,0,0,0 ./.:5,0,0:5:.:0,0,0,0,0,0 1/1:0,0,1:1:0:225,15,0,15,0,0 ./.:0,0,0:0:.:0,0,0,0,0,0 ./.:12,0,0:12:.:0,0,0,0,0,0 ./.:8,0,0:8:.:0,0,0,0,0,0 0/0:3,0,0:3:0:0,0,43,0,43,43 ./.:7,0,0:7:.:0,0,0,0,0,0 ./.:1,0,0:1:.:0,0,0,0,0,0 ./.:0,0,0:0:.:0,0,0,0,0,0 ./.:3,0,0:3:.:0,0,0,0,0,0 ./.:7,0,0:7:.:0,0,0,0,0,0 1/1:0,0,0:0:0:45,3,0,3,0,0 ./.:0,0,0 1/1:0,0,1:1:0:45,3,0,3,0,0 1/1:0,0,0:0:0:267,18,0,18,0,0 ./.:9,0,0:9:.:0,0,0,0,0,0 ; . The exactly the",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6630:1840,Validat,ValidateVariants,1840,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6630,1,['Validat'],['ValidateVariants']
Security,ion 2.16.3. $ git-lfs pull --include src/main/resources/large; No default remote. No remotes defined. Current time in UTC: ; 2018-04-20 20:10:32. ENV:; LocalWorkingDir=/scratch/var/tmp/portage/sci-biology/gatk-9999/work/gatk-9999; LocalGitDir=/scratch/var/tmp/portage/sci-biology/gatk-9999/work/gatk-9999/.git; LocalGitStorageDir=/scratch/var/tmp/portage/sci-biology/gatk-9999/work/gatk-9999/.git; LocalMediaDir=/scratch/var/tmp/portage/sci-biology/gatk-9999/work/gatk-9999/.git/lfs/objects; LocalReferenceDir=; TempDir=/scratch/var/tmp/portage/sci-biology/gatk-9999/work/gatk-9999/.git/lfs/tmp; ConcurrentTransfers=3; TusTransfers=false; BasicTransfersOnly=false; SkipDownloadErrors=false; FetchRecentAlways=false; FetchRecentRefsDays=7; FetchRecentCommitsDays=0; FetchRecentRefsIncludeRemotes=true; PruneOffsetDays=3; PruneVerifyRemoteAlways=false; PruneRemoteName=origin; LfsStorageDir=/scratch/var/tmp/portage/sci-biology/gatk-9999/work/gatk-9999/.git/lfs; AccessDownload=none; AccessUpload=none; DownloadTransfers=basic; UploadTransfers=basic. Client IP addresses:; xx.xx.xx.xx; xx.xx.xx.xx; xx.xx.xx.xx; portage$ ls -latr; total 188; -rw-r--r-- 1 portage portage 428 Apr 20 22:05 codecov.yml; -rwxr-xr-x 1 portage portage 5741 Apr 20 22:05 build_docker.sh; -rw-r--r-- 1 portage portage 32161 Apr 20 22:05 build.gradle; -rw-r--r-- 1 portage portage 37502 Apr 20 22:05 README.md; -rw-r--r-- 1 portage portage 1502 Apr 20 22:05 LICENSE.TXT; -rw-r--r-- 1 portage portage 1555 Apr 20 22:05 Dockerfile; -rw-r--r-- 1 portage portage 1128 Apr 20 22:05 AUTHORS; -rw-r--r-- 1 portage portage 8237 Apr 20 22:05 .travis.yml; -rw-r--r-- 1 portage portage 395 Apr 20 22:05 .gitignore; -rw-r--r-- 1 portage portage 128 Apr 20 22:05 .gitattributes; -rw-r--r-- 1 portage portage 142 Apr 20 22:05 .dockerignore; drwxr-xr-x 2 portage portage 4096 Apr 20 22:05 resources_for_CI; drwxr-xr-x 2 portage portage 4096 Apr 20 22:05 hooks; -rwxr-xr-x 1 portage portage 5242 Apr 20 22:05 gradlew; drwxr-xr-x 3 portage port,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4687:16348,Access,AccessDownload,16348,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4687,2,['Access'],"['AccessDownload', 'AccessUpload']"
Security,"ion for variants without genotypes, but I think you already figured that out. My proposal was more general, but you're right -- AC and AF should always have the same count as alt alleles and we don't need to check the header for that. When this came up (a year and a half ago!) we were thinking about validating all the info field annotations. ---. @ronlevine commented on [Mon Nov 28 2016](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-263280085). That's exactly what I did in https://github.com/samtools/htsjdk/pull/759. I can expand this to all INFO field annotations. ---. @ldgauthier commented on [Tue Dec 06 2016](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-265221057). Expanding to all INFO annotations would be wonderful, but that can be a separate issue. ---. @ronlevine commented on [Tue Dec 06 2016](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-265223581). That's not the only one, @magicDGS requested validating the `AF` values (which can be a separate issue). . ---. @vdauwera commented on [Tue Dec 06 2016](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-265226356). I think this one requires some additional discussion, so let's hold off for now -- it's not essential for 3.7 and we can't wait any longer to release. ---. @vdauwera commented on [Mon Mar 20 2017](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-287824654). @ldgauthier Would it be ok to kick this down the road to whenever ValidateVariants gets ported to GATK4?. ---. @ldgauthier commented on [Tue Mar 21 2017](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-288223822). Yeah, this isn't critical for any production pipelines - pass that buck. On Mar 20, 2017 12:56 PM, ""Geraldine Van der Auwera"" <; notifications@github.com> wrote:. > @ldgauthier <https://github.com/ldgauthier> Would it be ok to kick this; > down the road to whenever ValidateVariants gets ported t",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2507:7293,validat,validating,7293,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2507,1,['validat'],['validating']
Security,"ired by the VCF spec, but this provides a much more flexible interface for other similar niche applications, like genotyping individuals with other known aneuploidies. The global `-ploidy` flag will still provide the background default (or the built-in ploidy of 2 for humans), but the user input value will supersede these in overlapping regions. Note that the overlap is checked against the active region, meaning variants near the boundary of the `--ploidy-regions` file may end up with GT fields having ploidy slightly differently than expected, for example if your custom region overlaps a given active region but the variant ends up being written to a location outside that interval. In this case the ploidy from the user input would be used rather than any other default. # Implementation Details. The key idea is to allow `HaplotypeCallerEngine` to initialize multiple genotyping engines based on the `--ploidy-regions` input. The intervals are first parsed to check for positive integer ploidy values, and then used to create hashmaps of ploidy -> genotyper. The engine uses two types of genotypers: one for active region determination and one for doing the actual genotyping. Both admit a ploidy paramter passed via `hcArgs`. This PR modifies the `HaplotypeCallerArgumentCollection` class to include a method for creating copies of this object with differing ploidy amounts. These then get fed to the constructors of the appropriate genotyper classes, which are organized into two hashmaps. In every situation where one of these genotypers is used, we instead begin the scope by calling a ""get local genotyper"" method that performs the logic of checking whether the region of interest overlaps any of the user-provided regions, and then selects the appropriate `localEngine` genotyper for the task, ensuring the user-provided ploidy supersedes any other defaults. # A Note on Dependency. The flexibility of using either .bed or .interval_list files to specify this information depends on [th",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8464:1372,hash,hashmaps,1372,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8464,1,['hash'],['hashmaps']
Security,"isn't match. The error log looks like below. Exception in thread ""main"" java.lang.NoSuchMethodError: scala.collection.Seq.aggregate(Ljava/lang/Object;Lscala/Function2;Lscala/Function2;)Ljava/lang/Object;; at org.bdgenomics.adam.models.NonoverlappingRegions.mergeRegions(NonoverlappingRegions.scala:75); at org.bdgenomics.adam.models.NonoverlappingRegions.<init>(NonoverlappingRegions.scala:55); at org.bdgenomics.adam.models.NonoverlappingRegions$.apply(NonoverlappingRegions.scala:169); at org.bdgenomics.adam.util.TwoBitRecord$.apply(TwoBitFile.scala:193); at org.bdgenomics.adam.util.TwoBitFile$$anonfun$6.apply(TwoBitFile.scala:70); at org.bdgenomics.adam.util.TwoBitFile$$anonfun$6.apply(TwoBitFile.scala:70); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.immutable.HashMap$HashMap1.foreach(HashMap.scala:221); at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428); at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428); at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); at scala.collection.AbstractTraversable.map(Traversable.scala:104); at org.bdgenomics.adam.util.TwoBitFile.<init>(TwoBitFile.scala:70); at org.broadinstitute.hellbender.engine.spark.datasources.ReferenceTwoBitSource.<init>(ReferenceTwoBitSource.java:43); at org.broadinstitute.hellbender.engine.datasources.ReferenceMultiSource.<init>(ReferenceMultiSource.java:41); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.initializeReference(GATKSparkTool.java:353); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.initializeToolInputs(GATKSparkTool.java:320); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:311); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:38); at org.broadinstitute.hel",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2073:1139,Hash,HashMap,1139,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2073,2,['Hash'],"['HashMap', 'HashTrieMap']"
Security,it(DirectRetryingExecutor.java:92); 	at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:47); 	at com.google.cloud.storage.BlobReadChannel.read(BlobReadChannel.java:125); 	at com.google.cloud.storage.contrib.nio.CloudStorageReadChannel.read(CloudStorageReadChannel.java:109); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher$WorkUnit.call(SeekableByteChannelPrefetcher.java:131); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher$WorkUnit.call(SeekableByteChannelPrefetcher.java:104); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745); Caused by: javax.net.ssl.SSLHandshakeException: Remote host closed connection during handshake; 	at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:992); 	at sun.security.ssl.SSLSocketImpl.performInitialHandshake(SSLSocketImpl.java:1375); 	at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1403); 	at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1387); 	at sun.net.www.protocol.https.HttpsClient.afterConnect(HttpsClient.java:559); 	at sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.connect(AbstractDelegateHttpsURLConnection.java:185); 	at sun.net.www.protocol.https.HttpsURLConnectionImpl.connect(HttpsURLConnectionImpl.java:153); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:93); 	at shaded.cloud_nio.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:972); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2685:6381,secur,security,6381,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2685,1,['secur'],['security']
Security,"it(DirectRetryingExecutor.java:94); 	at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:54); 	at com.google.cloud.storage.StorageImpl.get(StorageImpl.java:188); 	at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.checkAccess(CloudStorageFileSystemProvider.java:614); 	... 15 more; Caused by: shaded.cloud_nio.com.google.api.client.googleapis.json.GoogleJsonResponseException: 403 Forbidden; {; ""code"" : 403,; ""errors"" : [ {; ""domain"" : ""global"",; ""message"" : ""443301511749-compute@developer.gserviceaccount.com does not have storage.objects.get access to fc-50c768b1-a285-4c95-8d8c-8ce209f1fda8/744139c5-3371-4a67-a2c8-e054e46f814f/ReblockGVCF/601ea396-b6cf-4baa-95c7-83e88b92c194/call-GenotypeGVCF/09C97227.c9cd4496-b4ed-4686-babd-177c66168178.vcf.gz.tbi."",; ""reason"" : ""forbidden""; } ],; ""message"" : ""443301511749-compute@developer.gserviceaccount.com does not have storage.objects.get access to fc-50c768b1-a285-4c95-8d8c-8ce209f1fda8/744139c5-3371-4a67-a2c8-e054e46f814f/ReblockGVCF/601ea396-b6cf-4baa-95c7-83e88b92c194/call-GenotypeGVCF/09C97227.c9cd4496-b4ed-4686-babd-177c66168178.vcf.gz.tbi.""; }; 	at shaded.cloud_nio.com.google.api.client.googleapis.json.GoogleJsonResponseException.from(GoogleJsonResponseException.java:145); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:113); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:40); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest$1.interceptResponse(AbstractGoogleClientRequest.java:321); 	at shaded.cloud_nio.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1056); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419); 	at shaded.cloud_ni",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4592:4145,access,access,4145,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4592,1,['access'],['access']
Security,"ithout --rm flag (will remove later); docker run \; --cidfile /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/docker_cid \; -i \; \; --entrypoint /bin/bash \; -v /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0:/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0:delegated \; broadinstitute/gatk@sha256:18146e79d06787483310e5de666502090a480e10ac0fad06a36a5e7a5c9bb1dc /cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/script. # get the return code (working even if the container was detached); rc=$(docker wait cat /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/docker_cid). # remove the container after waiting; docker rm cat /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/docker_cid. # return exit code; exit $rc; [2020-07-14 05:09:45,29] [info] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: job id: 243; [2020-07-14 05:09:45,29] [info] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: Status change from - to Done; [2020-07-14 05:09:46,38] [info] WorkflowManagerActor Workflow 968be82c-eef3-4bdb-a1ab-3d4e2ca70674 failed (during ExecutingWorkflowState): Job ValidateBamsWf.ValidateBAM:0:1 exited with return code -1 which has not been declared as a valid return code. See 'continueOnReturnCode' runtime attribute for more details.; Check the content of stderr for potential additional information: /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/stderr.; Could not retrieve content: Could not read from /gatk/my_data/tools/cromwell-execution",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6710:6360,Validat,ValidateBamsWf,6360,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710,2,['Validat'],"['ValidateBAM', 'ValidateBamsWf']"
Security,"jars, because it increases entropy on the distribution & support side of things. I would much prefer to see this resolved by project development branches. With the possibility of making project-specific nightly builds off of those branches, to enable pointing people to hot fixes for a specific toolset without taking in whatever else is going on in other projects. ---. @droazen commented on [Fri Apr 29 2016](https://github.com/broadinstitute/gatk-protected/issues/473#issuecomment-215757315). Alright, to give an overview of where this stands, we have several options on the table for solving this problem:; 1. Split the GATK into even more repos (a CNV-only repo, a HaplotypeCaller repo) that are versioned separately. GATK release X would then consist of CNV version Y, HaplotypeCaller version Z, gatk-public version P, etc. This is probably the most ""correct"" solution from a software engineering perspective, but might be a nightmare to work with.; 2. Have the ability to release jars with a subset of the tools exposed to the user (eg., CNV-only jars). Geraldine hates this one, and it does seem like a bad idea to have these incomplete jars floating out in the wild.; 3. Everyone develops on separate branches, and merges to master only when everything in a branch is ""release-ready"". In this scenario master itself is always (theoretically, at least) ready for release. This solves the original problem of release of some tools being blocked by others, but creates some other problems: last-minute merge conflicts across dev teams, large amounts of code being held back for months while it undergoes testing, harder to share code across groups, more complex git workflows for everyone.; 4. Everyone is free to merge development versions of tools to master (as is currently the case), and most of the time we try to release everything in the GATK together. On rare occasions when, eg., CNV needs a release now and HC is not ready, we create a branch off of the last tagged release, cherry-pic",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2851:3486,expose,exposed,3486,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2851,1,['expose'],['exposed']
Security,java:205); at org.broadinstitute.hellbender.tools.HaplotypeCallerSpark.runTool(HaplotypeCallerSpark.java:115); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:353); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:38); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:116); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:179); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:198); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:121); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:142); at org.broadinstitute.hellbender.Main.main(Main.java:220); Caused by: java.lang.IllegalStateException: Duplicate key [B@4e233a3c; at java.util.stream.Collectors.lambda$throwingMerger$0(Collectors.java:133); at java.util.HashMap.merge(HashMap.java:1253); at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1320); at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.PairHMMLikelihoodCalculationEngine.buildGapContinuationPenalties(PairHMMLikelihoodCalculat; ionEngine.java:304); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.PairHMMLikelihoodCalculationEngine.computeReadLikelihoods(PairHMMLikelihoodCalculationEngi; ne.java:253); at org.broadinsti,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3018:16834,Hash,HashMap,16834,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3018,1,['Hash'],['HashMap']
Security,java:2219); > at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.concat(NameNodeRpcServer.java:829); > at org.apache.hadoop.hdfs.server.namenode.AuthorizationProviderProxyClientProtocol.concat(AuthorizationProviderProxyClientProtocol.java:285); > at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.concat(ClientNamenodeProtocolServerSideTranslatorPB.java:580); > at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java); > at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:617); > at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1073); > at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2278); > at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2274); > at java.security.AccessController.doPrivileged(Native Method); > at javax.security.auth.Subject.doAs(Subject.java:422); > at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1924); > at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2272); > ; > org.broadinstitute.hellbender.exceptions.UserException$CouldNotCreateOutputFile: Couldn't write file hdfs://cloudera08/gatk-test2/WES2019-022_S4_out.vcf because writing failed with exception concat: target file /gatk-test2/WES2019-022_S4_out.vcf.parts/output is empty; > at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.concatInternal(FSNamesystem.java:2303); > at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.concatInt(FSNamesystem.java:2257). #### Steps to reproduce; The user's command line was. > nohup /opt/gatk/gatk-4.1.4.0/gatk ReadsPipelineSpark --spark-runner SPARK --spark-master yarn --spark-submit-command spark2-submit -I hdfs://cloudera08/gatk-test2/WES2019-022_S4.bam -O hdfs://cloudera08/gatk-test2/WES2019-022_S4_out.vcf -R hdfs://cloudera08/gatk-test1/ucsc.hg19.fasta --known-sites hdfs://cloudera08/gatk-test1/dbsnp_150_hg19.vcf.gz --,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6218:1957,secur,security,1957,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6218,1,['secur'],['security']
Security,java:300); at java.util.Spliterators$1Adapter.hasNext(Spliterators.java:681); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:149); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53); at org.apache.spark.scheduler.Task.run(Task.scala:99); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); Caused by: java.lang.IllegalArgumentException: Invalid interval. Contig:chrUn_JTFH01000312v1_decoy start:0 end:0; at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:687); at org.broadinstitute.hellbender.utils.SimpleInterval.validatePositions(SimpleInterval.java:61); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:37); at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.NovelAdjacencyReferenceLocations$BreakpointsInference.getLeftJustifiedBreakpoints(NovelAdjacencyReferenceLocations.java:86); at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.NovelAdjacencyReferenceLocations.leftJustifyBreakpoints(NovelAdjacencyReferenceLocations.java:301); at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.NovelAdjacencyReferenceLocations.<init>(NovelAdjacencyReferenceLocations.java:46); ... 18 more. 8/02/23 23:06:24 INFO storage.BlockManagerMaster: BlockManagerMaster stopped; 18/02/23 23:06:24 INFO scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 18/02/23 23:06:24 INFO spark.SparkContext: Successfully stopped SparkC,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4458:3386,validat,validateArg,3386,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4458,1,['validat'],['validateArg']
Security,java:300); at java.util.Spliterators$1Adapter.hasNext(Spliterators.java:681); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:149); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53); at org.apache.spark.scheduler.Task.run(Task.scala:99); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); Caused by: java.lang.IllegalArgumentException: Invalid interval. Contig:chrUn_JTFH01000312v1_decoy start:0 end:0; at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:687); at org.broadinstitute.hellbender.utils.SimpleInterval.validatePositions(SimpleInterval.java:61); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:37); at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.NovelAdjacencyReferenceLocations$BreakpointsInference.getLeftJustifiedBreakpoints(NovelAdjacencyReferenceLocations.java:86); at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.NovelAdjacencyReferenceLocations.leftJustifyBreakpoints(NovelAdjacencyReferenceLocations.java:301); at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.NovelAdjacencyReferenceLocations.<init>(NovelAdjacencyReferenceLocations.java:46); ... 18 more. Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1435); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1423); at org.apache.spa,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4458:7065,validat,validateArg,7065,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4458,1,['validat'],['validateArg']
Security,java:300); at java.util.Spliterators$1Adapter.hasNext(Spliterators.java:681); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:149); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53); at org.apache.spark.scheduler.Task.run(Task.scala:99); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); Caused by: java.lang.IllegalArgumentException: Invalid interval. Contig:chrUn_JTFH01000312v1_decoy start:0 end:0; at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:687); at org.broadinstitute.hellbender.utils.SimpleInterval.validatePositions(SimpleInterval.java:61); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:37); at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.NovelAdjacencyReferenceLocations$BreakpointsInference.getLeftJustifiedBreakpoints(NovelAdjacencyReferenceLocations.java:86); at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.NovelAdjacencyReferenceLocations.leftJustifyBreakpoints(NovelAdjacencyReferenceLocations.java:301); at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.NovelAdjacencyReferenceLocations.<init>(NovelAdjacencyReferenceLocations.java:46); ... 18 more; 18/02/23 23:06:24 INFO util.ShutdownHookManager: Shutdown hook called; 18/02/23 23:06:24 INFO util.ShutdownHookManager: Deleting directory /restricted/projectnb/casa/wgs.hg38/sv/gatk.sv/tmp/farrell/spark-94fa6743-3d29-4748-b8f8-d13a52dfed31; ```. The command line is:. ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4458:13857,validat,validateArg,13857,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4458,1,['validat'],['validateArg']
Security,"joun is willing to help.; > ; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > https://github.com/broadinstitute/gsa-unstable/issues/1489#issuecomment-252247496,; > or mute the thread; > https://github.com/notifications/unsubscribe-auth/ACnk0lAsJd9NECpPP0JYVp2ziDhga0B9ks5qxkRUgaJpZM4KQT_3; > . ---. @vdauwera commented on [Wed Oct 26 2016](https://github.com/broadinstitute/gsa-unstable/issues/1489#issuecomment-256499771). Writing pipeline-help now and cc'ing everyone involved in this thread. Will try to get some kind of protocol set up for debugging things that happen in the cloud pipeline, because I expect this will happen again. But if it gets too complicated we could also mock up some fake records that would reproduce this. It seems to me that shouldn't be too hard. . ---. @vdauwera commented on [Mon Nov 14 2016](https://github.com/broadinstitute/gsa-unstable/issues/1489#issuecomment-260498705). I need to ping Daniel on getting access to the files. ---. @ronlevine commented on [Thu Jan 26 2017](https://github.com/broadinstitute/gsa-unstable/issues/1489#issuecomment-275576931). @vdauwera Can you get the data? I can take a look a this issue. ---. @vdauwera commented on [Thu Jan 26 2017](https://github.com/broadinstitute/gsa-unstable/issues/1489#issuecomment-275578721). Oh, they gave me access to the files but I never took the next step of figuring out which files are relevant. There are twenty thousand samples... I'm not sure what is the best way to approach this. ---. @ldgauthier commented on [Wed Mar 01 2017](https://github.com/broadinstitute/gsa-unstable/issues/1489#issuecomment-283365248). It would be too computationally expensive and just generally painful to get; that dropped allele. I'd suggest making a unit test with some fake data.; You'll need two positions: one upstream with a deletion to generate the *; and one for the SNP. I think the dropped allele was a 1bp deletion at the; same position t",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2959:2982,access,access,2982,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2959,1,['access'],['access']
Security,"king each executor to shut down; 19/04/08 19:03:28 INFO SchedulerExtensionServices: Stopping SchedulerExtensionServices; (serviceOption=None,; services=List(),; started=false); 19/04/08 19:03:28 INFO YarnClientSchedulerBackend: Stopped; 19/04/08 19:03:28 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 19/04/08 19:03:28 INFO MemoryStore: MemoryStore cleared; 19/04/08 19:03:28 INFO BlockManager: BlockManager stopped; 19/04/08 19:03:28 INFO BlockManagerMaster: BlockManagerMaster stopped; 19/04/08 19:03:28 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 19/04/08 19:03:28 INFO SparkContext: Successfully stopped SparkContext; 19:03:28.389 INFO HaplotypeCallerSpark - Shutting down engine; [April 8, 2019 7:03:28 PM UTC] org.broadinstitute.hellbender.tools.HaplotypeCallerSpark done. Elapsed time: 1.75 minutes.; Runtime.totalMemory()=941096960; Exception in thread ""main"" java.lang.StackOverflowError; 	at java.util.HashMap.putMapEntries(HashMap.java:501); 	at java.util.HashMap.<init>(HashMap.java:490); 	at com.esotericsoftware.kryo.Generics.<init>(Generics.java:47); 	at com.esotericsoftware.kryo.serializers.FieldSerializerGenericsUtil.buildGenericsScope(FieldSerializerGenericsUtil.java:116); 	at com.esotericsoftware.kryo.serializers.FieldSerializerGenericsUtil.newCachedFieldOfGenericType(FieldSerializerGenericsUtil.java:225); 	at com.esotericsoftware.kryo.serializers.FieldSerializer.newCachedField(FieldSerializer.java:368); 	at com.esotericsoftware.kryo.serializers.FieldSerializer.createCachedFields(FieldSerializer.java:331); 	at com.esotericsoftware.kryo.serializers.FieldSerializer.rebuildCachedFields(FieldSerializer.java:261); 	at com.esotericsoftware.kryo.serializers.FieldSerializer.rebuildCachedFields(FieldSerializer.java:182); 	at com.esotericsoftware.kryo.serializers.FieldSerializer.write(FieldSerializer.java:508); 	at com.esotericsoftware.kryo.Kryo.writeObject(Kryo.java:552); 	at com.esoterics",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5869:18424,Hash,HashMap,18424,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5869,1,['Hash'],['HashMap']
Security,"king from the original JAR. . The JAVA file where I added the most helpful statements was in CommandLineProgram.java which is actually in ""gatk"" repo (not ""gatk-protected"" repo). If I look at a LOG, I can see ""EAS"" my initials and see c40e75b which appears to be a more recent commit compared to 3a2bb0d. ```; EAS in main!!!!; EAS to call instanceMain second....; EAS to call instanceMain first....; 17:28:40.295 INFO SparkGenomeReadCounts - EAS ABOUT TO CALL instanceMainPostParseArgs in instanceMain in clp.java ; 17:28:40.396 INFO IntelGKLUtils - Trying to load Intel GKL library from:; 	jar:file:/cromwell_root/fc-7ac504fc-7fe4-4bc1-89d3-7f16317b8ff4/eddie.jar!/com/intel/gkl/native/libIntelGKL.so; 17:28:40.498 INFO IntelGKLUtils - Intel GKL library loaded from classpath.; [December 1, 2016 5:28:40 PM UTC] org.broadinstitute.hellbender.tools.genome.SparkGenomeReadCounts --binsize 5000 --outputFile this.entity_id.coverage.tsv --reference Homo_sapiens_assembly19.fasta --input firecloud-tcga-open-access/tutorial/bams/C835.HCC1143_BL.4.bam --keepXYMT false --readValidationStringency SILENT --interval_set_rule UNION --interval_padding 0 --interval_exclusion_padding 0 --bamPartitionSize 0 --disableSequenceDictionaryValidation false --shardedOutput false --numReducers 0 --sparkMaster local[*] --help false --version false --verbosity INFO --QUIET false --use_jdk_deflater false --disableAllReadFilters false; [December 1, 2016 5:28:40 PM UTC] Executing as root@71bfa07f6996 on Linux 3.16.0-0.bpo.4-amd64 amd64; OpenJDK 64-Bit Server VM 1.8.0_111-8u111-b14-2~bpo8+1-b14; Version: Version:c40e75b-SNAPSHOT; 17:28:40.501 INFO SparkGenomeReadCounts - Defaults.BUFFER_SIZE : 131072; ```. ---. @eddiebroad commented on [Wed Dec 07 2016](https://github.com/broadinstitute/gatk-protected/issues/806#issuecomment-265470147). I want to mention in my case, all the reference files were present (fasta, fai, dict) BUT the dict was in a different directory and NOT in the same directory as the other two ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2922:5232,access,access,5232,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2922,1,['access'],['access']
Security,"ks in advance!. ```; gatk ValidateVariants -V ../../data/geno/phased/chr1-22.phased.rename.reheader.vcf.gz -R ../../../../index/hg19.fa.gz; Using GATK jar ~/tools/gatk-4.1.8.0/gatk-package-4.1.8.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /home/zepengmu/tools/gatk-4.1.8.0/gatk-package-4.1.8.0-local.jar ValidateVariants -V ../../data/geno/phased/chr1-22.phased.rename.reheader.vcf.gz -R ../../../../index/hg19.fa.gz; 19:53:34.379 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/zepengmu/tools/gatk-4.1.8.0/gatk-package-4.1.8.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Oct 25, 2020 7:53:34 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 19:53:34.606 INFO ValidateVariants - ------------------------------------------------------------; 19:53:34.606 INFO ValidateVariants - The Genome Analysis Toolkit (GATK) v4.1.8.0; 19:53:34.606 INFO ValidateVariants - For support and documentation go to https://software.broadinstitute.org/gatk/; 19:53:34.607 INFO ValidateVariants - Executing as zepengmu@midway2-login1.rcc.local on Linux v3.10.0-1127.8.2.el7.x86_64 amd64; 19:53:34.607 INFO ValidateVariants - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_45-b14; 19:53:34.607 INFO ValidateVariants - Start Date/Time: October 25, 2020 7:53:34 PM CDT; 19:53:34.607 INFO ValidateVariants - ------------------------------------------------------------; 19:53:34.607 INFO ValidateVariants - ------------------------------------------------------------; 19:53:34.607 INFO ValidateVariants - HTSJDK Version: 2.22.0; 19:53:34.607 INFO ValidateVariants - Picard Version: 2.22.8; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 19:53:34.608 INFO ValidateVariants - HTSJDK Default",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6911:1116,Validat,ValidateVariants,1116,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6911,1,['Validat'],['ValidateVariants']
Security,"l or two that use `PythonScriptExecutor` to call into a Python machine-learning library, and do an assessment of maintainability, etc. `PythonScriptExecutor` will come with an attached set of conditions for its use, intended to address the most serious issues raised by the engine and support teams with having Python code in the GATK. We should document these conditions in the docs for `PythonScriptExecutor` when it's implemented:. 1. All tools that use `PythonScriptExecutor` must have a Java-based front-end, with standard GATK (barclay-based) arguments. We put a lot of development effort into our arg parser and into striving for user-interface consistency across tools, and cannot afford to duplicate this effort in Python. Geraldine (CC'd) and the rest of the support team can back me up on this one!. 2. An honest effort should be made to minimize the amount of code written in Python -- as much of each tool's work as possible should be done in Java. In particular, reading/writing final inputs and outputs should happen in Java. This is important for a number of reasons, including the engine team's goal of ensuring universal GCS support, consistent Google authentication handling, etc. Again, we really don't want to have to duplicate that work in Python, or for the tools that call into Python to be inconsistent with the rest of the toolkit. 3. All dependencies (Python and native) of Python libraries used will be clearly documented, and included in the default GATK docker image. I don't think I need to explain why this one is important :) . 4. Before we go any further down this path, we prototype one or two tools using `PythonScriptExecutor`, and do a fair assessment of maintainability and other concerns of the engine/support teams, such as whether it will even be possible to package all dependencies without conflicts. 5. Engine team will continue to search for Java-based solutions while this evaluation is ongoing, but this proposal at least unblocks the CNV team for now.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3501:1352,authenticat,authentication,1352,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3501,1,['authenticat'],['authentication']
Security,"l000209_random, chr21_gl000210_random, chrUn_gl000211, chrUn_gl000212, chrUn_gl000213, chrUn_gl000214, chrUn_gl000215, chrUn_gl000216, chrUn_gl000217, chrUn_gl000218, chrUn_gl000219, chrUn_gl000220, chrUn_gl000221, chrUn_gl000222, chrUn_gl000223, chrUn_gl000224, chrUn_gl000225, chrUn_gl000226, chrUn_gl000227, chrUn_gl000228, chrUn_gl000229, chrUn_gl000230, chrUn_gl000231, chrUn_gl000232, chrUn_gl000233, chrUn_gl000234, chrUn_gl000235, chrUn_gl000236, chrUn_gl000237, chrUn_gl000238, chrUn_gl000239, chrUn_gl000240, chrUn_gl000241, chrUn_gl000242, chrUn_gl000243, chrUn_gl000244, chrUn_gl000245, chrUn_gl000246, chrUn_gl000247, chrUn_gl000248, chrUn_gl000249]; reads contigs = []; 	at org.broadinstitute.hellbender.utils.SequenceDictionaryUtils.validateDictionaries(SequenceDictionaryUtils.java:163); 	at org.broadinstitute.hellbender.utils.SequenceDictionaryUtils.validateDictionaries(SequenceDictionaryUtils.java:98); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.validateToolInputs(GATKSparkTool.java:469); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:361); 	at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:38); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:119); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:176); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:195); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:131); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:152); 	at org.broadinstitute.hellbender.Main.main(Main.java:233); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	a",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4112:34855,validat,validateToolInputs,34855,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4112,1,['validat'],['validateToolInputs']
Security,"l_padding 0 --interval_exclusion_padding 0 --readValidationStringency SILENT --secondsBetweenProgressUpdates 10.0 --disableSequenceDictionaryValidation false --createOutputBamIndex true --createOutputBamMD5 false --createOutputVariantIndex true --createOutputVariantMD5 false --lenient false --addOutputSAMProgramRecord true --cloudPrefetchBuffer 40 --cloudIndexPrefetchBuffer -1 --disableBamIndexCaching false --help false --version false --showHidden false --verbosity INFO --QUIET false --use_jdk_deflater false --use_jdk_inflater false --disableToolDefaultReadFilters false; [March 21, 2017 5:43:53 PM EDT] Executing as louisb@WMD2A-31E on Mac OS X 10.11.6 x86_64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_112-b16; Version: Version:4.alpha.2-189-g724fbd0-SNAPSHOT; 17:43:53.162 INFO ValidateVariants - Defaults.BUFFER_SIZE : 131072; 17:43:53.162 INFO ValidateVariants - Defaults.COMPRESSION_LEVEL : 1; 17:43:53.162 INFO ValidateVariants - Defaults.CREATE_INDEX : false; 17:43:53.163 INFO ValidateVariants - Defaults.CREATE_MD5 : false; 17:43:53.163 INFO ValidateVariants - Defaults.CUSTOM_READER_FACTORY :; 17:43:53.163 INFO ValidateVariants - Defaults.EBI_REFERENCE_SERVICE_URL_MASK : http://www.ebi.ac.uk/ena/cram/md5/%s; 17:43:53.163 INFO ValidateVariants - Defaults.NON_ZERO_BUFFER_SIZE : 131072; 17:43:53.163 INFO ValidateVariants - Defaults.REFERENCE_FASTA : null; 17:43:53.163 INFO ValidateVariants - Defaults.SAM_FLAG_FIELD_FORMAT : DECIMAL; 17:43:53.163 INFO ValidateVariants - Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 17:43:53.163 INFO ValidateVariants - Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 17:43:53.163 INFO ValidateVariants - Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 17:43:53.163 INFO ValidateVariants - Defaults.USE_CRAM_REF_DOWNLOAD : false; 17:43:53.163 INFO ValidateVariants - Deflater IntelDeflater; 17:43:53.163 INFO ValidateVariants - Inflater IntelInflater; 17:43:53.163 INFO ValidateVariants - Initializing engine; 17:43:53.270 INFO FeatureManager ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2509:2184,Validat,ValidateVariants,2184,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2509,1,['Validat'],['ValidateVariants']
Security,lassReader.java:166); 	at org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:148); 	at org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:136); 	at org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:237); 	at org.apache.spark.util.ClosureCleaner$.getClassReader(ClosureCleaner.scala:49); 	at org.apache.spark.util.FieldAccessFinder$$anon$3$$anonfun$visitMethodInsn$2.apply(ClosureCleaner.scala:517); 	at org.apache.spark.util.FieldAccessFinder$$anon$3$$anonfun$visitMethodInsn$2.apply(ClosureCleaner.scala:500); 	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733); 	at scala.collection.mutable.HashMap$$anon$1$$anonfun$foreach$2.apply(HashMap.scala:134); 	at scala.collection.mutable.HashMap$$anon$1$$anonfun$foreach$2.apply(HashMap.scala:134); 	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236); 	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40); 	at scala.collection.mutable.HashMap$$anon$1.foreach(HashMap.scala:134); 	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732); 	at org.apache.spark.util.FieldAccessFinder$$anon$3.visitMethodInsn(ClosureCleaner.scala:500); 	at org.apache.xbean.asm6.ClassReader.readCode(ClassReader.java:2175); 	at org.apache.xbean.asm6.ClassReader.readMethod(ClassReader.java:1238); 	at org.apache.xbean.asm6.ClassReader.accept(ClassReader.java:631); 	at org.apache.xbean.asm6.ClassReader.accept(ClassReader.java:355); 	at org.apache.spark.util.ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$14.apply(ClosureCleaner.scala:307); 	at org.apache.spark.util.ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$14.apply(ClosureCleaner.scala:306); 	at scala.collection.immutable.List.foreach(List.scala:392); 	at org.apache.spark.util.ClosureCleaner$.org$apache$spark$util$ClosureCleaner$$clean(ClosureCleaner.scala:306); 	at org.apache.spark.util.ClosureCleaner$.clean(ClosureCleaner.scala:16,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7035:7078,Hash,HashMap,7078,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7035,1,['Hash'],['HashMap']
Security,"lbender.engine.AssemblyRegionWalker.traverse(AssemblyRegionWalker.java:267); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:966); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); 	at org.broadinstitute.hellbender.Main.main(Main.java:289); ```; A second case involved `--alleles` input:; ```; 22	16464044	rs571268158	CCAGGTCT	C; 22	16464051	rs569099729	T	C; ```; and crashed similarly, with:; ```; java.lang.IllegalStateException: Allele in genotype CCAGGTCT* not in the variant context [T*, *, C]; 	at htsjdk.variant.variantcontext.VariantContext.validateGenotypes(VariantContext.java:1360); 	at htsjdk.variant.variantcontext.VariantContext.validate(VariantContext.java:1298); 	at htsjdk.variant.variantcontext.VariantContext.<init>(VariantContext.java:401); 	at htsjdk.variant.variantcontext.VariantContextBuilder.make(VariantContextBuilder.java:494); 	at htsjdk.variant.variantcontext.VariantContextBuilder.make(VariantContextBuilder.java:488); 	at org.broadinstitute.hellbender.utils.variant.GATKVariantContextUtils.simpleMerge(GATKVariantContextUtils.java:864); 	at org.broadinstitute.hellbender.utils.variant.GATKVariantContextUtils.simpleMerge(GATKVariantContextUtils.java:646); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.AssemblyBasedCallerUtils.makeMergedVariantContext(AssemblyBasedCallerUtils.java:221); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerGenotypingEngine.assignGenotypeLikelihoods(HaplotypeCallerGenotypingEngine.java:150); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5336:2804,validat,validateGenotypes,2804,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5336,1,['validat'],['validateGenotypes']
Security,leapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419); at shaded.cloud-nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352); at shaded.cloud-nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.execute(AbstractGoogleClientRequest.java:469); at com.google.cloud.storage.spi.DefaultStorageRpc.get(DefaultStorageRpc.java:347); ... 17 more; Caused by:; java.net.SocketTimeoutException: Read timed out; at java.net.SocketInputStream.socketRead0(Native Method); at java.net.SocketInputStream.socketRead(SocketInputStream.java:116); at java.net.SocketInputStream.read(SocketInputStream.java:170); at java.net.SocketInputStream.read(SocketInputStream.java:141); at sun.security.ssl.InputRecord.readFully(InputRecord.java:465); at sun.security.ssl.InputRecord.read(InputRecord.java:503); at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:973); at sun.security.ssl.SSLSocketImpl.performInitialHandshake(SSLSocketImpl.java:1375); at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1403); at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1387); at sun.net.www.protocol.https.HttpsClient.afterConnect(HttpsClient.java:559); at sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.connect(AbstractDelegateHttpsURLConnection.java:185); at sun.net.www.protocol.http.HttpURLConnection.getOutputStream0(HttpURLConnection.java:1316); at sun.net.www.protocol.http.HttpURLConnection.getOutputStream(HttpURLConnection.java:1291); at sun.net.www.protocol.https.HttpsURLConnectionImpl.getOutputStream(HttpsURLConnectionImpl.java:250); at shaded.cloud-nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:77); at shaded.cloud-nio.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:972); at shaded.cloud-nio.com.google.auth.oauth2.ServiceAccountCredentials.refreshAccessToken(ServiceAcc,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2514:3925,secur,security,3925,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2514,1,['secur'],['security']
Security,lection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:149); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53); at org.apache.spark.scheduler.Task.run(Task.scala:99); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); Caused by: java.lang.IllegalArgumentException: Invalid interval. Contig:chrUn_JTFH01000312v1_decoy start:0 end:0; at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:687); at org.broadinstitute.hellbender.utils.SimpleInterval.validatePositions(SimpleInterval.java:61); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:37); at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.NovelAdjacencyReferenceLocations$BreakpointsInference.getLeftJustifiedBreakpoints(NovelAdjacencyReferenceLocations.java:86); at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.NovelAdjacencyReferenceLocations.leftJustifyBreakpoints(NovelAdjacencyReferenceLocations.java:301); at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.NovelAdjacencyReferenceLocations.<init>(NovelAdjacencyReferenceLocations.java:46); ... 18 more. 8/02/23 23:06:24 INFO storage.BlockManagerMaster: BlockManagerMaster stopped; 18/02/23 23:06:24 INFO scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 18/02/23 23:06:24 INFO spark.SparkContext: Successfully stopped SparkContext; 23:06:24.240 INFO StructuralVariationDiscoveryPipelineSpark - Shutting down engine;,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4458:3469,validat,validatePositions,3469,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4458,1,['validat'],['validatePositions']
Security,lection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:149); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53); at org.apache.spark.scheduler.Task.run(Task.scala:99); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); Caused by: java.lang.IllegalArgumentException: Invalid interval. Contig:chrUn_JTFH01000312v1_decoy start:0 end:0; at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:687); at org.broadinstitute.hellbender.utils.SimpleInterval.validatePositions(SimpleInterval.java:61); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:37); at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.NovelAdjacencyReferenceLocations$BreakpointsInference.getLeftJustifiedBreakpoints(NovelAdjacencyReferenceLocations.java:86); at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.NovelAdjacencyReferenceLocations.leftJustifyBreakpoints(NovelAdjacencyReferenceLocations.java:301); at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.NovelAdjacencyReferenceLocations.<init>(NovelAdjacencyReferenceLocations.java:46); ... 18 more. Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1435); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1423); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1422); at scala.co,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4458:7148,validat,validatePositions,7148,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4458,1,['validat'],['validatePositions']
Security,"lection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:149); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53); at org.apache.spark.scheduler.Task.run(Task.scala:99); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); Caused by: java.lang.IllegalArgumentException: Invalid interval. Contig:chrUn_JTFH01000312v1_decoy start:0 end:0; at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:687); at org.broadinstitute.hellbender.utils.SimpleInterval.validatePositions(SimpleInterval.java:61); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:37); at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.NovelAdjacencyReferenceLocations$BreakpointsInference.getLeftJustifiedBreakpoints(NovelAdjacencyReferenceLocations.java:86); at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.NovelAdjacencyReferenceLocations.leftJustifyBreakpoints(NovelAdjacencyReferenceLocations.java:301); at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.NovelAdjacencyReferenceLocations.<init>(NovelAdjacencyReferenceLocations.java:46); ... 18 more; 18/02/23 23:06:24 INFO util.ShutdownHookManager: Shutdown hook called; 18/02/23 23:06:24 INFO util.ShutdownHookManager: Deleting directory /restricted/projectnb/casa/wgs.hg38/sv/gatk.sv/tmp/farrell/spark-94fa6743-3d29-4748-b8f8-d13a52dfed31; ```. The command line is:. ```; gatk --java-options ""-Djava.io.tmpdir=tmp"" StructuralVariationDiscoveryPipelineSpark \; -",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4458:13940,validat,validatePositions,13940,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4458,1,['validat'],['validatePositions']
Security,"lem:. ```; chr1	10027	.	A	C,G	.	PASS	.	GT:AD:AF:DP	1/2:0,5,5:0.500,0.500:10; ```. vs. ```; chr1	10027	.	A	C,G	.	PASS	.	GT:AD:DP	1/2:0,5,5:10; ```. The output for GATK 4.1.4.1 or when the AF field is removed looks like this:; ```; chr1	10027	.	A	C	.	PASS	.	GT:AD:DP	./.:0,5:10; chr1	10027	.	A	G	.	PASS	.	GT:AD:DP	./.:0,5:10; ```. #### Steps to reproduce; ```; $gatk/gatk LeftAlignAndTrimVariants -R $reference --split-multi-allelics -V test.input.vcf -O test.output.vcf; ```. #### Expected behavior; LeftAlignAndTrimVariants should be able to split multiallelic records in a VCF to two separate records as in GATK version 4.1.4.1. The AF field is removed from the 4.1.4.1 output, however. #### Actual behavior; GATK fails at a multiallelic record with the following error (GATK 4.2.0.0):; ```; java.lang.IllegalArgumentException: the range size cannot be negative; 	at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:798); 	at org.broadinstitute.hellbender.utils.IndexRange.validate(IndexRange.java:107); 	at org.broadinstitute.hellbender.utils.IndexRange.<init>(IndexRange.java:67); 	at org.broadinstitute.hellbender.utils.variant.GATKVariantContextUtils.splitASSBTable(GATKVariantContextUtils.java:1533); 	at org.broadinstitute.hellbender.utils.variant.GATKVariantContextUtils.splitSomaticVariantContextToBiallelics(GATKVariantContextUtils.java:1501); 	at org.broadinstitute.hellbender.tools.walkers.variantutils.LeftAlignAndTrimVariants.apply(LeftAlignAndTrimVariants.java:225); 	at org.broadinstitute.hellbender.engine.VariantWalker.lambda$traverse$0(VariantWalker.java:104); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$Ite",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7211:1543,validat,validate,1543,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7211,1,['validat'],['validate']
Security,"lfs pull (#7806); - Document AoU SOP (up to the VAT) [VS-63] (#7807); - Incident VS 365 clinvar classification fix (#7769); - VS-390. Add precision and sensitivity wdl (#7813); - Quickstart based integration test [VS-357] (#7812); - 365 vat python testing additions (#7756); - VS 396 clinvar grabs too many values (#7823); - Added a test to validate WDLs in the scripts directory. (#7826) (#7829); - VAT Performance / Reliability Improvements (#7828); - VAT naming conventions [VS-410] (#7827); - Rc remove ad from vat (#7832); - bugfix, we were trying to grep a binary file (#7837); - Cleanup scripts/variantstore [VS-414] (#7834); - Merge VAT TSV files into single bgzipped file [VS-304] (#7848); - Handle fully and partially loaded samples [VS-262] [VS-258] (#7843); - Ingest Error Handling Fixes [VS-261] (#7841); - First cut at a python notebook to validate inputs. (#7845); - Compute filter scatter [VS-392] (#7852); - remove withdrawn req (#7844); - Improve import error message [VS-437] (#7855); - Fix Input Validation python notebook (#7853); - Add VAT Validation check that aa_change and exon_number are consistently set. (#7850); - Ingest 10K [VS-344] (#7860); - X/Y chromosome reweighting for better extract shard runtime balance [VS-389] (#7868); - VET Ingest Validation / Allow Ingest of non-VQSR'ed data (#7870); - Fix AoU workflow bugs (#7874); - Curate input arrays to skip already ingested sample data [VS-246] (#7862); - KM upload GVS product sheet (#7883); - Default extract scatter width [VS-415] (#7878); - Volatile tasks review [VS-447] (#7880); - Update Quickstart Integration for X/Y scaling changes [VS-464] (#7881); - clean up dockstore; - Rc vs 63 vat sop documentation (#7879); - Fix up FQ and race condition issues with volatile tasks work [VS-478] (#7888); - Use gvs-internal project in integration test (#7901); - Add cost observability BQ table [VS-441] (#7891); - Add preliminary labels to queries [VS-381] (#7902); - Workflow compute costs [VS-472] (#7905); - Fix bu",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8248:24617,Validat,Validation,24617,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8248,4,['Validat'],['Validation']
Security,licatesSpark done. Elapsed time: 0.06 minutes.; Runtime.totalMemory()=1065353216; java.lang.IllegalArgumentException: Unsupported class file major version 55; 	at org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:166); 	at org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:148); 	at org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:136); 	at org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:237); 	at org.apache.spark.util.ClosureCleaner$.getClassReader(ClosureCleaner.scala:49); 	at org.apache.spark.util.FieldAccessFinder$$anon$3$$anonfun$visitMethodInsn$2.apply(ClosureCleaner.scala:517); 	at org.apache.spark.util.FieldAccessFinder$$anon$3$$anonfun$visitMethodInsn$2.apply(ClosureCleaner.scala:500); 	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733); 	at scala.collection.mutable.HashMap$$anon$1$$anonfun$foreach$2.apply(HashMap.scala:134); 	at scala.collection.mutable.HashMap$$anon$1$$anonfun$foreach$2.apply(HashMap.scala:134); 	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236); 	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40); 	at scala.collection.mutable.HashMap$$anon$1.foreach(HashMap.scala:134); 	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732); 	at org.apache.spark.util.FieldAccessFinder$$anon$3.visitMethodInsn(ClosureCleaner.scala:500); 	at org.apache.xbean.asm6.ClassReader.readCode(ClassReader.java:2175); 	at org.apache.xbean.asm6.ClassReader.readMethod(ClassReader.java:1238); 	at org.apache.xbean.asm6.ClassReader.accept(ClassReader.java:631); 	at org.apache.xbean.asm6.ClassReader.accept(ClassReader.java:355); 	at org.apache.spark.util.ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$14.apply(ClosureCleaner.scala:307); 	at org.apache.spark.util.ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$14.apply(ClosureCleaner.scala:306); 	at scala.collection.immutable.List.fore,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7035:6880,Hash,HashMap,6880,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7035,1,['Hash'],['HashMap']
Security,lication_1603353714322_0004/__spark_libs__7655440475844189559.zip; 20/10/22 12:02:31 INFO yarn.Client: Uploading resource file:/home/jacky/Exec/gatk/build/libs/gatk-spark.jar -> hdfs://192.168.0.104:9000/user/jacky/.sparkStaging/application_1603353714322_0004/gatk-spark.jar; 20/10/22 12:02:33 INFO yarn.Client: Uploading resource file:/tmp/spark-28ab5ef4-82d1-425e-879f-5056e9b51e43/__spark_conf__3248804172036151699.zip -> hdfs://192.168.0.104:9000/user/jacky/.sparkStaging/application_1603353714322_0004/__spark_conf__.zip; 20/10/22 12:02:33 INFO spark.SecurityManager: Changing view acls to: jacky; 20/10/22 12:02:33 INFO spark.SecurityManager: Changing modify acls to: jacky; 20/10/22 12:02:33 INFO spark.SecurityManager: Changing view acls groups to: ; 20/10/22 12:02:33 INFO spark.SecurityManager: Changing modify acls groups to: ; 20/10/22 12:02:33 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(jacky); groups with view permissions: Set(); users with modify permissions: Set(jacky); groups with modify permissions: Set(); 20/10/22 12:02:33 INFO yarn.Client: Submitting application application_1603353714322_0004 to ResourceManager; 20/10/22 12:02:33 INFO impl.YarnClientImpl: Submitted application application_1603353714322_0004; 20/10/22 12:02:34 INFO yarn.Client: Application report for application_1603353714322_0004 (state: ACCEPTED); 20/10/22 12:02:34 INFO yarn.Client: ; 	 client token: N/A; 	 diagnostics: N/A; 	 ApplicationMaster host: N/A; 	 ApplicationMaster RPC port: -1; 	 queue: default; 	 start time: 1603360953394; 	 final status: UNDEFINED; 	 tracking URL: http://jacky:8088/proxy/application_1603353714322_0004/; 	 user: jacky; 20/10/22 12:02:35 INFO yarn.Client: Application report for application_1603353714322_0004 (state: ACCEPTED); 20/10/22 12:02:36 INFO yarn.Client: Application report for application_1603353714322_0004 (state: ACCEPTED); 20/10/22 12:02:37 INFO yarn.Client: Application report ,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6906:3561,Secur,SecurityManager,3561,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6906,3,"['Secur', 'authenticat']","['SecurityManager', 'authentication']"
Security,lientRequest.java:300); at shaded.cloud-nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419); at shaded.cloud-nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352); at shaded.cloud-nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.execute(AbstractGoogleClientRequest.java:469); at com.google.cloud.storage.spi.DefaultStorageRpc.get(DefaultStorageRpc.java:347); ... 17 more; Caused by:; java.net.SocketTimeoutException: Read timed out; at java.net.SocketInputStream.socketRead0(Native Method); at java.net.SocketInputStream.socketRead(SocketInputStream.java:116); at java.net.SocketInputStream.read(SocketInputStream.java:170); at java.net.SocketInputStream.read(SocketInputStream.java:141); at sun.security.ssl.InputRecord.readFully(InputRecord.java:465); at sun.security.ssl.InputRecord.read(InputRecord.java:503); at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:973); at sun.security.ssl.SSLSocketImpl.performInitialHandshake(SSLSocketImpl.java:1375); at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1403); at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1387); at sun.net.www.protocol.https.HttpsClient.afterConnect(HttpsClient.java:559); at sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.connect(AbstractDelegateHttpsURLConnection.java:185); at sun.net.www.protocol.http.HttpURLConnection.getOutputStream0(HttpURLConnection.java:1316); at sun.net.www.protocol.http.HttpURLConnection.getOutputStream(HttpURLConnection.java:1291); at sun.net.www.protocol.https.HttpsURLConnectionImpl.getOutputStream(HttpsURLConnectionImpl.java:250); at shaded.cloud-nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:77); at shaded.cloud-nio.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:972); at shaded.cloud-nio.com.goog,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2514:3855,secur,security,3855,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2514,1,['secur'],['security']
Security,"linked hash set, linked hash map",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1844:7,hash,hash,7,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1844,2,['hash'],['hash']
Security,litIntervals		6/5/2017	https://github.com/broadinstitute/gatk-protected/blob/ec40da398e4185fa8fb0c62453304e8315f8f4e1/src/main/java/org/broadinstitute/hellbender/tools/walkers/SplitIntervals.java	scripts/mutect2_wdl/mutect2.wdl	https://github.com/broadinstitute/gatk/pull/3032	yes	Default value: INTERVAL_SUBDIVISION. warn users to be careful when dividing lengthy genomic intervals. Perhaps it would be wise to specify the workflow in which this tool would be used. Something for the second pass.; 44	GetPileupSummaries	beta; helper tool for CalculateContamination	6/5/2017	https://github.com/broadinstitute/gatk-protected/blob/2bf35790393332da5414b42ec6dca813fcc63202/src/main/java/org/broadinstitute/hellbender/tools/walkers/contamination/GetPileupSummaries.java	scripts/mutect2_wdl/mutect2.wdl	https://github.com/broadinstitute/gatk/pull/3006	yes	; 33	AnnotateVcfWithBamDepth	internal (DB)	5/30	https://github.com/broadinstitute/gatk-protected/blob/e6278def94038d76339d0fd95ce2badb3bc44a22/src/main/java/org/broadinstitute/hellbender/tools/walkers/validation/AnnotateVcfWithBamDepth.java	scripts/mutect2_wdl/unsupported/hapmap_sensitivity_truth.wdl	https://github.com/broadinstitute/gatk-protected/pull/1131	yes	; 34	AnnotateVcfWithExpectedAlleleFraction	internal (DB)	5/30	https://github.com/broadinstitute/gatk-protected/blob/e6278def94038d76339d0fd95ce2badb3bc44a22/src/main/java/org/broadinstitute/hellbender/tools/walkers/validation/AnnotateVcfWithExpectedAlleleFraction.java	scripts/mutect2_wdl/unsupported/hapmap_sensitivity_truth.wdl	https://github.com/broadinstitute/gatk-protected/pull/1131	yes	; 37	CalculateMixingFractions	internal (DB)	5/30	https://github.com/broadinstitute/gatk-protected/blob/e6278def94038d76339d0fd95ce2badb3bc44a22/src/main/java/org/broadinstitute/hellbender/tools/walkers/validation/CalculateMixingFractions.java	scripts/mutect2_wdl/unsupported/hapmap_sensitivity_truth.wdl	https://github.com/broadinstitute/gatk-protected/pull/1131	yes	; 47	RemoveNearbyIndels	i,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3055:12697,validat,validation,12697,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3055,1,['validat'],['validation']
Security,"lling all running tasks in stage 2: Stage finished; 23/11/16 12:09:10 INFO DAGScheduler: Job 2 finished: parquet at StudentAws.scala:36, took 10.369237 s; 23/11/16 12:09:10 INFO FileFormatWriter: Start to commit write Job b17a4b92-9ee1-46cc-858a-08ed0b22fb8b.; 23/11/16 12:09:10 ERROR FileFormatWriter: Aborting job b17a4b92-9ee1-46cc-858a-08ed0b22fb8b.; java.lang.UnsatisfiedLinkError: org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Ljava/lang/String;I)Z; 	at org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Native Method); 	at org.apache.hadoop.io.nativeio.NativeIO$Windows.access(NativeIO.java:793); 	at org.apache.hadoop.fs.FileUtil.canRead(FileUtil.java:1249); 	at org.apache.hadoop.fs.FileUtil.list(FileUtil.java:1454); 	at org.apache.hadoop.fs.RawLocalFileSystem.listStatus(RawLocalFileSystem.java:601); 	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1972); 	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:2014); 	at org.apache.hadoop.fs.ChecksumFileSystem.listStatus(ChecksumFileSystem.java:761); 	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1972); 	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:2014); 	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.getAllCommittedTaskPaths(FileOutputCommitter.java:334); 	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitJobInternal(FileOutputCommitter.java:404); 	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitJob(FileOutputCommitter.java:377); 	at org.apache.parquet.hadoop.ParquetOutputCommitter.commitJob(ParquetOutputCommitter.java:48); 	at org.apache.spark.internal.io.HadoopMapReduceCommitProtocol.commitJob(HadoopMapReduceCommitProtocol.scala:192); 	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$writeAndCommit$3(FileFormatWriter.scala:275); 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12); 	at org.apache.spark.util.Utils$.timeTakenMs(Utils.scala:640); 	at o",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8587:2603,Checksum,ChecksumFileSystem,2603,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8587,1,['Checksum'],['ChecksumFileSystem']
Security,"lpha.2-189-g724fbd0-SNAPSHOT; 17:43:53.162 INFO ValidateVariants - Defaults.BUFFER_SIZE : 131072; 17:43:53.162 INFO ValidateVariants - Defaults.COMPRESSION_LEVEL : 1; 17:43:53.162 INFO ValidateVariants - Defaults.CREATE_INDEX : false; 17:43:53.163 INFO ValidateVariants - Defaults.CREATE_MD5 : false; 17:43:53.163 INFO ValidateVariants - Defaults.CUSTOM_READER_FACTORY :; 17:43:53.163 INFO ValidateVariants - Defaults.EBI_REFERENCE_SERVICE_URL_MASK : http://www.ebi.ac.uk/ena/cram/md5/%s; 17:43:53.163 INFO ValidateVariants - Defaults.NON_ZERO_BUFFER_SIZE : 131072; 17:43:53.163 INFO ValidateVariants - Defaults.REFERENCE_FASTA : null; 17:43:53.163 INFO ValidateVariants - Defaults.SAM_FLAG_FIELD_FORMAT : DECIMAL; 17:43:53.163 INFO ValidateVariants - Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 17:43:53.163 INFO ValidateVariants - Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 17:43:53.163 INFO ValidateVariants - Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 17:43:53.163 INFO ValidateVariants - Defaults.USE_CRAM_REF_DOWNLOAD : false; 17:43:53.163 INFO ValidateVariants - Deflater IntelDeflater; 17:43:53.163 INFO ValidateVariants - Inflater IntelInflater; 17:43:53.163 INFO ValidateVariants - Initializing engine; 17:43:53.270 INFO FeatureManager - Using codec VCFCodec to read file file:///Users/louisb/Workspace/gatk/src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleGood.vcf; 17:43:53.287 INFO FeatureManager - Using codec VCFCodec to read file file:///Users/louisb/Workspace/gatk/src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleGood.vcf; 17:43:53.291 WARN IndexUtils - Feature file ""/Users/louisb/Workspace/gatk/src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleGood.vcf"" appears to contain no sequence dictionary. Attempting to retrieve a sequence dictionary from the associated index file; 17:43:53.293 INFO ValidateVariants - Done init",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2509:2922,Validat,ValidateVariants,2922,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2509,1,['Validat'],['ValidateVariants']
Security,lse; 18:30:54.424 INFO BwaAndMarkDuplicatesPipelineSpark - Deflater: IntelDeflater; 18:30:54.424 INFO BwaAndMarkDuplicatesPipelineSpark - Inflater: IntelInflater; 18:30:54.424 INFO BwaAndMarkDuplicatesPipelineSpark - GCS max retries/reopens: 20; 18:30:54.424 INFO BwaAndMarkDuplicatesPipelineSpark - Using google-cloud-java patch c035098b5e62cb4fe9155eff07ce88449a361f5d from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 18:30:54.424 INFO BwaAndMarkDuplicatesPipelineSpark - Initializing engine; 18:30:54.424 INFO BwaAndMarkDuplicatesPipelineSpark - Done initializing engine; 18/01/09 18:30:54 INFO spark.SparkContext: Running Spark version 2.2.0.cloudera1; 18/01/09 18:30:54 INFO spark.SparkContext: Submitted application: BwaAndMarkDuplicatesPipelineSpark; 18/01/09 18:30:54 INFO spark.SecurityManager: Changing view acls to: sun; 18/01/09 18:30:54 INFO spark.SecurityManager: Changing modify acls to: sun; 18/01/09 18:30:54 INFO spark.SecurityManager: Changing view acls groups to: ; 18/01/09 18:30:54 INFO spark.SecurityManager: Changing modify acls groups to: ; 18/01/09 18:30:54 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(sun); groups with view permissions: Set(); users with modify permissions: Set(sun); groups with modify permissions: Set(); 18/01/09 18:30:55 INFO util.Utils: Successfully started service 'sparkDriver' on port 38793.; 18/01/09 18:30:55 INFO spark.SparkEnv: Registering MapOutputTracker; 18/01/09 18:30:55 INFO spark.SparkEnv: Registering BlockManagerMaster; 18/01/09 18:30:55 INFO storage.BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information; 18/01/09 18:30:55 INFO storage.BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up; 18/01/09 18:30:55 INFO storage.DiskBlockManager: Created local directory at /tmp/sun/blockmgr-b03058dc-763a-449c-bd05-18f3304c01ea; 18/01/09 18:30:55 INFO memory.MemoryStore: Mem,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4112:5519,Secur,SecurityManager,5519,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4112,1,['Secur'],['SecurityManager']
Security,"lters false; [March 21, 2017 5:43:53 PM EDT] Executing as louisb@WMD2A-31E on Mac OS X 10.11.6 x86_64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_112-b16; Version: Version:4.alpha.2-189-g724fbd0-SNAPSHOT; 17:43:53.162 INFO ValidateVariants - Defaults.BUFFER_SIZE : 131072; 17:43:53.162 INFO ValidateVariants - Defaults.COMPRESSION_LEVEL : 1; 17:43:53.162 INFO ValidateVariants - Defaults.CREATE_INDEX : false; 17:43:53.163 INFO ValidateVariants - Defaults.CREATE_MD5 : false; 17:43:53.163 INFO ValidateVariants - Defaults.CUSTOM_READER_FACTORY :; 17:43:53.163 INFO ValidateVariants - Defaults.EBI_REFERENCE_SERVICE_URL_MASK : http://www.ebi.ac.uk/ena/cram/md5/%s; 17:43:53.163 INFO ValidateVariants - Defaults.NON_ZERO_BUFFER_SIZE : 131072; 17:43:53.163 INFO ValidateVariants - Defaults.REFERENCE_FASTA : null; 17:43:53.163 INFO ValidateVariants - Defaults.SAM_FLAG_FIELD_FORMAT : DECIMAL; 17:43:53.163 INFO ValidateVariants - Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 17:43:53.163 INFO ValidateVariants - Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 17:43:53.163 INFO ValidateVariants - Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 17:43:53.163 INFO ValidateVariants - Defaults.USE_CRAM_REF_DOWNLOAD : false; 17:43:53.163 INFO ValidateVariants - Deflater IntelDeflater; 17:43:53.163 INFO ValidateVariants - Inflater IntelInflater; 17:43:53.163 INFO ValidateVariants - Initializing engine; 17:43:53.270 INFO FeatureManager - Using codec VCFCodec to read file file:///Users/louisb/Workspace/gatk/src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleGood.vcf; 17:43:53.287 INFO FeatureManager - Using codec VCFCodec to read file file:///Users/louisb/Workspace/gatk/src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleGood.vcf; 17:43:53.291 WARN IndexUtils - Feature file ""/Users/louisb/Workspace/gatk/src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleGood",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2509:2750,Validat,ValidateVariants,2750,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2509,1,['Validat'],['ValidateVariants']
Security,ltiIntervalLocalReadShard.iterator(MultiIntervalLocalReadShard.java:134); 	at org.broadinstitute.hellbender.engine.AssemblyRegionIterator.<init>(AssemblyRegionIterator.java:86); 	at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.processReadShard(AssemblyRegionWalker.java:188); 	at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.traverse(AssemblyRegionWalker.java:173); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1085); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); 	at org.broadinstitute.hellbender.Main.main(Main.java:289); ```. #### Steps to reproduce; The error occurs when running a command: ; ```; gatk Mutect2 -R /home/genome/gatk.hg38/Homo_sapiens_assembly38.fasta -L panel_collapsed.bed -I bam/tumour_recalibrated.bam -I bam/normal_recalibrated.bam -tumor tumour -normal normal -germline-resource /home/genome/gatk.hg38/af-only-gnomad.hg38.vcf.gz -pon /home/genome/pon/PON_B1.vcf --genotype-pon-sites --f1r2-tar-gz results/learnOrientation/tumour_lo.tar.gz -O results/Mutect2/tumour.s.vcf.gz -bamout bam/tumour.mutect2.bam --disable-read-filter MateOnSameContigOrNoMappedMateReadFilter --af-of-alleles-not-in-resource 0.000001; ```. #### Expected behavior; Mutect2 producing outputs. #### Actual behavior; Full log: ; [Mutect2_error.txt](https://github.com/broadinstitute/gatk/files/8772744/Mutect2_error.txt). ---. I would be grateful if you could help me to investigate the cause of this error. I couldn't find any clues when googling it and tried `picard ValidateSamFile` but it returns no errors or warnings. Many thanks!,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7872:3181,Validat,ValidateSamFile,3181,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7872,1,['Validat'],['ValidateSamFile']
Security,"ly$mcV$sp(AbstractFunction0.scala:12); 	at scala.App.$anonfun$main$1$adapted(App.scala:76); 	at scala.collection.immutable.List.foreach(List.scala:389); 	at scala.App.main(App.scala:76); 	at scala.App.main$(App.scala:74); 	at StudentAws$.main(StudentAws.scala:8); 	at StudentAws.main(StudentAws.scala); Exception in thread ""main"" java.lang.UnsatisfiedLinkError: org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Ljava/lang/String;I)Z; 	at org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Native Method); 	at org.apache.hadoop.io.nativeio.NativeIO$Windows.access(NativeIO.java:793); 	at org.apache.hadoop.fs.FileUtil.canRead(FileUtil.java:1249); 	at org.apache.hadoop.fs.FileUtil.list(FileUtil.java:1454); 	at org.apache.hadoop.fs.RawLocalFileSystem.listStatus(RawLocalFileSystem.java:601); 	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1972); 	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:2014); 	at org.apache.hadoop.fs.ChecksumFileSystem.listStatus(ChecksumFileSystem.java:761); 	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1972); 	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:2014); 	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.getAllCommittedTaskPaths(FileOutputCommitter.java:334); 	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitJobInternal(FileOutputCommitter.java:404); 	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitJob(FileOutputCommitter.java:377); 	at org.apache.parquet.hadoop.ParquetOutputCommitter.commitJob(ParquetOutputCommitter.java:48); 	at org.apache.spark.internal.io.HadoopMapReduceCommitProtocol.commitJob(HadoopMapReduceCommitProtocol.scala:192); 	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$writeAndCommit$3(FileFormatWriter.scala:275); 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12); 	at org.apache.spark.util.Utils$.timeTakenMs(Utils.scala:640); 	at org.apache.spark.sql.exec",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8587:8276,Checksum,ChecksumFileSystem,8276,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8587,1,['Checksum'],['ChecksumFileSystem']
Security,making the version number depend on the git hash using a gradle git plugin from https://github.com/ajoberstar/gradle-git. It seems like the top gradle-git integration library. There are lots of pre-baked things in it to help with releases and such that we can grow into.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/196:44,hash,hash,44,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/196,1,['hash'],['hash']
Security,manage_sv_pipeline checks version from gatk-spark.jar and compares it; to the current git hash (to ensure the correct version is run). Newer; gatk versions had a slightly different file name format and caused; errors parsing the hash. This updates the hash check and produces; more comprehensible error messages when it fails. Resolves: #3593,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3595:90,hash,hash,90,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3595,3,['hash'],['hash']
Security,"mand line argument is highly dubious.) . It's possible that apache code does something similar to fully decoding that could affect performance. All that is to say that we cannot achieve performance improvement with our original blueprint simply because this expensive ""fullyDecode"" operation seems to be a mythical operation that is never used in reality. So while I could not speed up SelectVariants, I cleaned up the code and added the following new arguments:. * `--select-genotype`: with this new genotype-specific JEXL argument, we support filtering by genotype fields like 'GQ > 0', where the behavior in the multi-sample case is 'GQ > 0' in at least one sample. I have not added the ability to do 'GQ > 0 for all samples' but it should be a simple (but not easy…) exercise in boolean operations.; * `applyJexlFiltersBeforeFilteringGenotypes`: if set to true, we do the JEXL checking before we subset by samples. In my tests, performance improvement from this option was very modest. Subsetting a ~3k 1kg SV vcf to a single sample was about 30 seconds faster (out of ~20 min total run time) than the default. I kept it in the PR because I thought some user might find it useful, but I wouldn't be opposed to removing it. Tests needed:; - [x] Filter by genotypes with a new flag --genotype-select, with the default behavior being 'passes if at least one sample passes' ; - [x] Multiple --select expressions should be combined with logical-or; - [x] Test string annotations (e.g. ALGORITHM == 'depth'); - [x] Jexl involving with logical-and (e.g. AC > 0 && AF > 0.01); - [x] Access genotypes directly e.g. vc.getsample('NA12878'); - [x] DP > 0 as --genotype-select and as --select; - [x] Combine --select and --select-genotypes; - [x] Code path that uses ""fully-decode""; - [x] Failing cases (reference genotype fields in --select and vice versa); - [x] `--applyJexlFiltersBeforeFilteringGenotypes.` Does this actually give us performance advantage? ; - [x] Add a test for `select-random-fraction`",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8092:3012,Access,Access,3012,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8092,1,['Access'],['Access']
Security,"mblyRegionWalker.traverse(AssemblyRegionWalker.java:267); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:966); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); 	at org.broadinstitute.hellbender.Main.main(Main.java:289); ```; The second case included the following `--alleles` input:; ```; 22	16464044	rs571268158	CCAGGTCT	C; 22	16464051	rs569099729	T	C; ```; and it crashed similarly, with:; ```; java.lang.IllegalStateException: Allele in genotype CCAGGTCT* not in the variant context [T*, *, C]; 	at htsjdk.variant.variantcontext.VariantContext.validateGenotypes(VariantContext.java:1360); 	at htsjdk.variant.variantcontext.VariantContext.validate(VariantContext.java:1298); 	at htsjdk.variant.variantcontext.VariantContext.<init>(VariantContext.java:401); 	at htsjdk.variant.variantcontext.VariantContextBuilder.make(VariantContextBuilder.java:494); 	at htsjdk.variant.variantcontext.VariantContextBuilder.make(VariantContextBuilder.java:488); 	at org.broadinstitute.hellbender.utils.variant.GATKVariantContextUtils.simpleMerge(GATKVariantContextUtils.java:864); 	at org.broadinstitute.hellbender.utils.variant.GATKVariantContextUtils.simpleMerge(GATKVariantContextUtils.java:646); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.AssemblyBasedCallerUtils.makeMergedVariantContext(AssemblyBasedCallerUtils.java:221); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerGenotypingEngine.assignGenotypeLikelihoods(HaplotypeCallerGenotypingEngine.java:150); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5337:2848,validat,validateGenotypes,2848,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5337,1,['validat'],['validateGenotypes']
Security,"mentations of copy-ratio, allele-fraction, and ""multidimensional"" (joint) segmentation. All implementations are pretty boilerplate; they simply partition by contig and then call out to KernelSegmenter. Note that there is some logic in multidimensional segmentation that only uses the first het in each copy-ratio interval and if any are available, and imputes the alt-allele fraction to 0.5 if not.; -Makes sense for @mbabadi to review this, since he reviewed the KernelSegmenter PR. Added modeling classes and tests for ModelSegments CNV pipeline.; -Most of this code is copied from the old MCMC code. However, I've done some overall code cleanup and refactoring, especially to remove some overextraction of methods in the allele-fraction likelihoods (see #2860). I also added downsampling and scaling of likelihoods to cut down on runtime. Tests have been simplified and rewritten to use simulated data.; -@LeeTL1220 do you think you could take a look?. Added ModelSegments CLI.; -Mostly control flow to handle optional inputs and validation, but there is some ugly and not well documented code that essentially does the GetHetCoverage step. We'll refactor later, I filed #3915.; -@asmirnov239 can review. This is lower priority than the gCNV VCF writing. Deleted gCNV WDL and Cromwell tests.; -Trivial to review. Added WDL and Cromwell tests for ModelSegments CNV pipeline.; -This includes the cost optimizations from @meganshand and @jsotobroad (sorry guys, I wasn't sure how to track your contributions while fixing up commits!) I also added tests for both GC/no-GC pair workflows.; -@MartonKN should review to gain familiarity with the WDL. Note that this WDL has already been through many revisions from @meganshand, @jsotobroad, and @LeeTL1220, so hopefully there shouldn't be too much for you to find serious fault with. Note that I punted on adding MultidimensionalKernelSegmenterUnitTest and ModelSegmentsIntegrationTest. Filed #3916. Closes #2858. (FINALLY!); Closes #3825.; Closes #3661.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3913:1600,validat,validation,1600,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3913,1,['validat'],['validation']
Security,"methods.internal, executor 48): java.lang.IllegalArgumentException: Unexpected CIGAR format with deletion neighboring clipping; cigar elements are: [1190M, 4D, 53M, 2I, 26M, 2I, 31M, 2D, 1450S]; 	at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:681); 	at org.broadinstitute.hellbender.tools.spark.sv.utils.SvCigarUtils.validateCigar(SvCigarUtils.java:134); 	at org.broadinstitute.hellbender.tools.spark.sv.utils.SvCigarUtils.getUnclippedReadLength(SvCigarUtils.java:161); 	at org.broadinstitute.hellbender.tools.spark.sv.utils.SvCigarUtils.computeAssociatedDistOnRead(SvCigarUtils.java:330); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.alignment.AlignmentInterval.readIntervalAlignedToRefSpan(AlignmentInterval.java:634); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.CpxVariantDetector.extractAltHaplotypeSeq(CpxVariantDetector.java:852); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.CpxVariantDetector.access$300(CpxVariantDetector.java:47); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.CpxVariantDetector$AnnotatedContig.annotate(CpxVariantDetector.java:194); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.CpxVariantDetector$AnnotatedContig.<init>(CpxVariantDetector.java:132); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.CpxVariantDetector.lambda$inferSvAndWriteVCF$14707a88$1(CpxVariantDetector.java:60); 	at org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction$1.apply(JavaPairRDD.scala:1040); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at scala.collection.Iterator$class.foreach(Iterator.scala:893); 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); 	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59); 	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104); 	at scala.collect",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4260:5745,access,access,5745,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4260,1,['access'],['access']
Security,"micsdb.GenomicsDBImport.getFeatureReadersSerially(GenomicsDBImport.java:602); 	at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImport.traverse(GenomicsDBImport.java:490); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:893); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:136); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:179); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:198); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:153); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:195); 	at org.broadinstitute.hellbender.Main.main(Main.java:277); Caused by: com.google.cloud.storage.StorageException: 443301511749-compute@developer.gserviceaccount.com does not have storage.objects.get access to fc-50c768b1-a285-4c95-8d8c-8ce209f1fda8/744139c5-3371-4a67-a2c8-e054e46f814f/ReblockGVCF/601ea396-b6cf-4baa-95c7-83e88b92c194/call-GenotypeGVCF/09C97227.c9cd4496-b4ed-4686-babd-177c66168178.vcf.gz.tbi.; 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.translate(HttpStorageRpc.java:189); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.get(HttpStorageRpc.java:335); 	at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:191); 	at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:188); 	at shaded.cloud_nio.com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:94); 	at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:54); 	at com.google.cloud.storage.StorageImpl.get(StorageImpl.java:188); 	at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.checkAccess(CloudStorageFileSystemProvider.java:614); 	... 15 more; Caused by: shaded.cloud_nio.com.google.api.client.googleapis.json.GoogleJsonResponseException: 403 Forbidden; {; ""code"" : 403,; ""errors"" : [ {; ""domain"" : ""global"",; """,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4592:2625,access,access,2625,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4592,1,['access'],['access']
Security,"mment-262613152). @ldgauthier Shouldn't a locus without genotypes bypass `AC` validation, given it's defined as: `Allele count in genotypes, for each ALT allele, in the same order as listed`?. ---. @ldgauthier commented on [Wed Nov 23 2016](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-262613997). Agreed. ---. @ronlevine commented on [Thu Nov 24 2016](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-262635204). The change should be a lot simpler than proposed. The code can validate the number of alleles before it checks for the presence of genotypes in [VariantContext#validateChromosomeCounts](https://github.com/samtools/htsjdk/blob/master/src/main/java/htsjdk/variant/variantcontext/VariantContext.java#L1236). . ---. @ldgauthier commented on [Mon Nov 28 2016](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-263277972). Sorry, I needed to refresh my memory. I actually don't want to bypass AC validation for variants without genotypes, but I think you already figured that out. My proposal was more general, but you're right -- AC and AF should always have the same count as alt alleles and we don't need to check the header for that. When this came up (a year and a half ago!) we were thinking about validating all the info field annotations. ---. @ronlevine commented on [Mon Nov 28 2016](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-263280085). That's exactly what I did in https://github.com/samtools/htsjdk/pull/759. I can expand this to all INFO field annotations. ---. @ldgauthier commented on [Tue Dec 06 2016](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-265221057). Expanding to all INFO annotations would be wonderful, but that can be a separate issue. ---. @ronlevine commented on [Tue Dec 06 2016](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-265223581). That's not the only one, @magicDGS requested validating the `AF` val",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2507:6292,validat,validation,6292,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2507,1,['validat'],['validation']
Security,ms.markduplicates.MarkDuplicatesSpark done. Elapsed time: 0.06 minutes.; Runtime.totalMemory()=1065353216; java.lang.IllegalArgumentException: Unsupported class file major version 55; 	at org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:166); 	at org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:148); 	at org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:136); 	at org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:237); 	at org.apache.spark.util.ClosureCleaner$.getClassReader(ClosureCleaner.scala:49); 	at org.apache.spark.util.FieldAccessFinder$$anon$3$$anonfun$visitMethodInsn$2.apply(ClosureCleaner.scala:517); 	at org.apache.spark.util.FieldAccessFinder$$anon$3$$anonfun$visitMethodInsn$2.apply(ClosureCleaner.scala:500); 	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733); 	at scala.collection.mutable.HashMap$$anon$1$$anonfun$foreach$2.apply(HashMap.scala:134); 	at scala.collection.mutable.HashMap$$anon$1$$anonfun$foreach$2.apply(HashMap.scala:134); 	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236); 	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40); 	at scala.collection.mutable.HashMap$$anon$1.foreach(HashMap.scala:134); 	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732); 	at org.apache.spark.util.FieldAccessFinder$$anon$3.visitMethodInsn(ClosureCleaner.scala:500); 	at org.apache.xbean.asm6.ClassReader.readCode(ClassReader.java:2175); 	at org.apache.xbean.asm6.ClassReader.readMethod(ClassReader.java:1238); 	at org.apache.xbean.asm6.ClassReader.accept(ClassReader.java:631); 	at org.apache.xbean.asm6.ClassReader.accept(ClassReader.java:355); 	at org.apache.spark.util.ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$14.apply(ClosureCleaner.scala:307); 	at org.apache.spark.util.ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$14.apply(ClosureCleaner.scala:306); 	at scala.collec,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7035:6839,Hash,HashMap,6839,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7035,1,['Hash'],['HashMap']
Security,mutect2 expose param,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8447:8,expose,expose,8,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8447,1,['expose'],['expose']
Security,"n [Wed Oct 19 2016](https://github.com/broadinstitute/gatk-protected/issues/751). Things that we discussed with @samuelklee that can be done to aid it:. -I think that all files we generate for individual case samples---""ReadCountCollection"" files for coverage profiles, ""AllelicCountCollection"" files for het pulldowns, and segment files---should contain the sample name as metadata in a header comment with a common tag (e.g., #sampleName = ...). Currently, these sample names are stored in column headers, in the fields of a SAMPLE column, or not at all, depending on the type of file. This would drastically simplify the use of the SampleNameFinder class, which would basically only contain a single method to parse this header comment and return the name. -CLIs that generate a file from an input BAM (CalculateTargetCoverage, GetHetCoverage, etc.) should take the sample name from that BAM by default. Since these are the first steps in our workflows, we could also optionally allow the user to specify a sample name different from that in the BAM. -Subsequent CLIs should then take the sample name from the header comment. -CLIs that take multiple non-BAM input files should check for consistency of the sample names as part of the argument validation step. -CLIs that output the sample name in plots should derive these from the header comment. -For files that contain data from multiple samples (e.g., the output of CombineReadCounts), we can probably leave the sample names in the column headers, but it would be nice to output the type of data stored in a header comment as well (e.g., PCOV or RAW). At some point I think we should restrict to RAW output only, see https://github.com/broadinstitute/gatk-protected/issues/615. -Entity names specified by the input file for the WDLs can be separate from the BAM sample names by default. However, if we do allow the user to optionally specify sample names as described in the first bullet point, we can set up the WDL to pass the entity names.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2910:1271,validat,validation,1271,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2910,1,['validat'],['validation']
Security,"n stage 2: Stage finished; 23/11/16 12:09:10 INFO DAGScheduler: Job 2 finished: parquet at StudentAws.scala:36, took 10.369237 s; 23/11/16 12:09:10 INFO FileFormatWriter: Start to commit write Job b17a4b92-9ee1-46cc-858a-08ed0b22fb8b.; 23/11/16 12:09:10 ERROR FileFormatWriter: Aborting job b17a4b92-9ee1-46cc-858a-08ed0b22fb8b.; java.lang.UnsatisfiedLinkError: org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Ljava/lang/String;I)Z; 	at org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Native Method); 	at org.apache.hadoop.io.nativeio.NativeIO$Windows.access(NativeIO.java:793); 	at org.apache.hadoop.fs.FileUtil.canRead(FileUtil.java:1249); 	at org.apache.hadoop.fs.FileUtil.list(FileUtil.java:1454); 	at org.apache.hadoop.fs.RawLocalFileSystem.listStatus(RawLocalFileSystem.java:601); 	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1972); 	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:2014); 	at org.apache.hadoop.fs.ChecksumFileSystem.listStatus(ChecksumFileSystem.java:761); 	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1972); 	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:2014); 	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.getAllCommittedTaskPaths(FileOutputCommitter.java:334); 	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitJobInternal(FileOutputCommitter.java:404); 	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitJob(FileOutputCommitter.java:377); 	at org.apache.parquet.hadoop.ParquetOutputCommitter.commitJob(ParquetOutputCommitter.java:48); 	at org.apache.spark.internal.io.HadoopMapReduceCommitProtocol.commitJob(HadoopMapReduceCommitProtocol.scala:192); 	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$writeAndCommit$3(FileFormatWriter.scala:275); 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12); 	at org.apache.spark.util.Utils$.timeTakenMs(Utils.scala:640); 	at org.apache.spark.sql.exec",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8587:2633,Checksum,ChecksumFileSystem,2633,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8587,1,['Checksum'],['ChecksumFileSystem']
Security,"naryValidation false --createOutputBamIndex true --createOutputBamMD5 false --createOutputVariantIndex true --createOutputVariantMD5 false --lenient false --addOutputSAMProgramRecord true --cloudPrefetchBuffer 40 --cloudIndexPrefetchBuffer -1 --disableBamIndexCaching false --help false --version false --showHidden false --verbosity INFO --QUIET false --use_jdk_deflater false --use_jdk_inflater false --disableToolDefaultReadFilters false; [March 21, 2017 5:43:53 PM EDT] Executing as louisb@WMD2A-31E on Mac OS X 10.11.6 x86_64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_112-b16; Version: Version:4.alpha.2-189-g724fbd0-SNAPSHOT; 17:43:53.162 INFO ValidateVariants - Defaults.BUFFER_SIZE : 131072; 17:43:53.162 INFO ValidateVariants - Defaults.COMPRESSION_LEVEL : 1; 17:43:53.162 INFO ValidateVariants - Defaults.CREATE_INDEX : false; 17:43:53.163 INFO ValidateVariants - Defaults.CREATE_MD5 : false; 17:43:53.163 INFO ValidateVariants - Defaults.CUSTOM_READER_FACTORY :; 17:43:53.163 INFO ValidateVariants - Defaults.EBI_REFERENCE_SERVICE_URL_MASK : http://www.ebi.ac.uk/ena/cram/md5/%s; 17:43:53.163 INFO ValidateVariants - Defaults.NON_ZERO_BUFFER_SIZE : 131072; 17:43:53.163 INFO ValidateVariants - Defaults.REFERENCE_FASTA : null; 17:43:53.163 INFO ValidateVariants - Defaults.SAM_FLAG_FIELD_FORMAT : DECIMAL; 17:43:53.163 INFO ValidateVariants - Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 17:43:53.163 INFO ValidateVariants - Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 17:43:53.163 INFO ValidateVariants - Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 17:43:53.163 INFO ValidateVariants - Defaults.USE_CRAM_REF_DOWNLOAD : false; 17:43:53.163 INFO ValidateVariants - Deflater IntelDeflater; 17:43:53.163 INFO ValidateVariants - Inflater IntelInflater; 17:43:53.163 INFO ValidateVariants - Initializing engine; 17:43:53.270 INFO FeatureManager - Using codec VCFCodec to read file file:///Users/louisb/Workspace/gatk/src/test/resources/org/broadinstitute/hellbender/tools/walkers/Va",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2509:2321,Validat,ValidateVariants,2321,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2509,1,['Validat'],['ValidateVariants']
Security,"nch SparkGenomeReadCounts -I hdfs://scc/user/farrell/adsp/bams/SRR990385.bam -o SRR990385.ReadCounts -R /restricted/projectnb/genpro/bundle/2.8/b37/human_g1k_v37.fasta --verbosity ERROR -- --sparkRunner SPARK --sparkMaster yarn --num-executors 1 --executor-memory 4G --executor-cores 3`. [December 3, 2017 2:56:35 PM EST] org.broadinstitute.hellbender.tools.genome.SparkGenomeReadCounts done. Elapsed time: 0.57 minutes.; Runtime.totalMemory()=982515712; org.apache.spark.SparkException: Job aborted due to stage failure: Task 12 in stage 0.0 failed 4 times, most recent failure: Lost task 12.3 in stage 0.0 (TID 14, scc-q09.scc.bu.edu, executor 1): java.lang.IllegalArgumentException: **Wrong FS: hdfs://scc:8020/user/farrell/adsp/bams/SRR990385.bai, expected: hdfs://scc**; at org.apache.hadoop.fs.FileSystem.checkPath(FileSystem.java:645); at org.apache.hadoop.hdfs.DistributedFileSystem.getPathName(DistributedFileSystem.java:193); at org.apache.hadoop.hdfs.DistributedFileSystem.access$000(DistributedFileSystem.java:105); at org.apache.hadoop.hdfs.DistributedFileSystem$3.doCall(DistributedFileSystem.java:302); at org.apache.hadoop.hdfs.DistributedFileSystem$3.doCall(DistributedFileSystem.java:298); at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81); at org.apache.hadoop.hdfs.DistributedFileSystem.open(DistributedFileSystem.java:298); at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:766); at org.seqdoop.hadoop_bam.util.WrapSeekable.openPath(WrapSeekable.java:60); at org.seqdoop.hadoop_bam.BAMRecordReader.initialize(BAMRecordReader.java:142); at org.seqdoop.hadoop_bam.BAMInputFormat.createRecordReader(BAMInputFormat.java:121); at org.seqdoop.hadoop_bam.AnySAMInputFormat.createRecordReader(AnySAMInputFormat.java:190); at org.apache.spark.rdd.NewHadoopRDD$$anon$1.liftedTree1$1(NewHadoopRDD.scala:178); at org.apache.spark.rdd.NewHadoopRDD$$anon$1.<init>(NewHadoopRDD.scala:177); at org.apache.spark.rdd.NewHadoopRDD.compute(NewHadoopRDD.scal",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3909:1390,access,access,1390,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3909,1,['access'],['access']
Security,"ncy SILENT --secondsBetweenProgressUpdates 10.0 --disableSequenceDictionaryValidation false --createOutputBamIndex true --createOutputBamMD5 false --createOutputVariantIndex true --createOutputVariantMD5 false --lenient false --addOutputSAMProgramRecord true --cloudPrefetchBuffer 40 --cloudIndexPrefetchBuffer -1 --disableBamIndexCaching false --help false --version false --showHidden false --verbosity INFO --QUIET false --use_jdk_deflater false --use_jdk_inflater false --disableToolDefaultReadFilters false; [March 21, 2017 5:43:53 PM EDT] Executing as louisb@WMD2A-31E on Mac OS X 10.11.6 x86_64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_112-b16; Version: Version:4.alpha.2-189-g724fbd0-SNAPSHOT; 17:43:53.162 INFO ValidateVariants - Defaults.BUFFER_SIZE : 131072; 17:43:53.162 INFO ValidateVariants - Defaults.COMPRESSION_LEVEL : 1; 17:43:53.162 INFO ValidateVariants - Defaults.CREATE_INDEX : false; 17:43:53.163 INFO ValidateVariants - Defaults.CREATE_MD5 : false; 17:43:53.163 INFO ValidateVariants - Defaults.CUSTOM_READER_FACTORY :; 17:43:53.163 INFO ValidateVariants - Defaults.EBI_REFERENCE_SERVICE_URL_MASK : http://www.ebi.ac.uk/ena/cram/md5/%s; 17:43:53.163 INFO ValidateVariants - Defaults.NON_ZERO_BUFFER_SIZE : 131072; 17:43:53.163 INFO ValidateVariants - Defaults.REFERENCE_FASTA : null; 17:43:53.163 INFO ValidateVariants - Defaults.SAM_FLAG_FIELD_FORMAT : DECIMAL; 17:43:53.163 INFO ValidateVariants - Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 17:43:53.163 INFO ValidateVariants - Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 17:43:53.163 INFO ValidateVariants - Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 17:43:53.163 INFO ValidateVariants - Defaults.USE_CRAM_REF_DOWNLOAD : false; 17:43:53.163 INFO ValidateVariants - Deflater IntelDeflater; 17:43:53.163 INFO ValidateVariants - Inflater IntelInflater; 17:43:53.163 INFO ValidateVariants - Initializing engine; 17:43:53.270 INFO FeatureManager - Using codec VCFCodec to read file file:///Users/louisb/Workspace",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2509:2250,Validat,ValidateVariants,2250,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2509,1,['Validat'],['ValidateVariants']
Security,"ne file; PrintReads Print reads in the SAM/BAM/CRAM file; ReorderSam Reorders reads in a SAM/BAM file to match ordering in reference; ReplaceSamHeader Replace the SAMFileHeader in a SAM/BAM file with the given header; RevertBaseQualityScores Revert Quality Scores in a SAM/BAM/CRAM file; RevertOriginalBaseQualitiesAndAddMateCigar Reverts the original base qualities and adds the mate cigar tag to read-group BAMs; RevertSam Reverts SAM/BAM files to a previous state; SamFormatConverter Convert a SAM/BAM/CRAM file to a SAM/BAM/CRAM file; SamToFastq Converts a SAM/BAM file into a FASTQ; SortSam Sorts a SAM/BAM/CRAM file; SplitNCigarReads Split Reads with N in Cigar; SplitReads Outputs reads from a SAM/BAM/CRAM by read group, sample and library name; UnmarkDuplicates Unmark duplicates in a SAM/BAM/CRAM file; ValidateSamFile Validates a SAM/BAM/CRAM file. --------------------------------------------------------------------------------------; Spark Validation tools: Tools written in Spark to compare aspects of two different files; CompareBaseQualitiesSpark Diff qs of the BAMs; CompareDuplicatesSpark Compares two BAMs for duplicates. --------------------------------------------------------------------------------------; Spark pipelines: Pipelines that combine tools and use Apache Spark for scaling out (experimental); BQSRPipelineSpark Both steps of BQSR (BaseRecalibrator and ApplyBQSR) on Spark; ReadsPipelineSpark Takes aligned reads (likely from BWA) and runs MarkDuplicates and BQSR. The final result is analysis-ready reads. --------------------------------------------------------------------------------------; Spark tools: Tools that use Apache Spark for scaling out (experimental); ApplyBQSRSpark ApplyBQSR on Spark; BaseRecalibratorSpark BaseRecalibrator on Spark; BaseRecalibratorSparkSharded BaseRecalibrator on Spark (experimental sharded implementation); CollectBaseDistributionByCycleSpark CollectBaseDistributionByCycle on Spark; CollectQualityYieldMetricsSpark CollectQua",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1669:6431,Validat,Validation,6431,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1669,1,['Validat'],['Validation']
Security,"ne; - Add a new validation type for info-field counts to enum and to switch statement; - Grab info headers from input VCF with something like GATKVCFUtils.getVCFHeadersFromRods(getToolkit(), variantCollection.variants.getName()) and VCFHeader::getInfoHeaderLines; - In the map() function, for each info header line, call on each VCFInfoHeaderLine getCount(vc) to get the expected number of info annotation entries; - Compare the expected number with a count based on vc.getAttribute(currentVCFinfoHeaderLine.getID()), which will require some additional parsing because it returns an Object; - (Bonus points if you use the isFixedCount() and getCount() functions on the VCF info header line to simplify annotations that aren't according to the number of alt alleles); ### Test data. /humgen/gsa-hpprojects/dev/gauthier/scratch/supportingMultiA.vcf; Should fail AC/AF validation at ; `1 768589 . A C,G 76 PASS AC=1;AF=0.00047;AN=2120`; See results using:. ```; use VCFtools; vcf-validator /humgen/gsa-hpprojects/dev/gauthier/scratch/supportingMultiA.vcf; ```. which outputs:; `INFO field at 1:768589 .. INFO tag [AC=1] expected different number of values (expected 2, found 1),INFO tag [AF=0.00047] expected different number of values (expected 2, found 1)`; ### Notes. Currently, all the validation modes call out to HTSJDK. Do we want to put the new functionality there as well?. ---. @yfarjoun commented on [Thu Jul 16 2015](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-122130280). I think that it is very appropriate to validate in htsjdk. On Thu, Jul 16, 2015 at 4:05 PM, ldgauthier notifications@github.com; wrote:. > Currently ValidateVariants relies on genotypes to transitively check that; > each alt allele occurs in at least one sample and that the AC adds up.; > However, this can fail on sites-only files because there are no genotypes.; > We should use the definition of the info annotations in the header to check; > how many entries each should have.; > Outlin",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2507:1443,validat,validator,1443,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2507,1,['validat'],['validator']
Security,"ntigPloidy - Initializing engine; 08:48:45.931 DEBUG ScriptExecutor - Executing:; 08:48:45.931 DEBUG ScriptExecutor - python; 08:48:45.932 DEBUG ScriptExecutor - -c; 08:48:45.932 DEBUG ScriptExecutor - import gcnvkernel. WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.; /home/ec2-user/miniconda3/envs/gatk/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.; from ._conv import register_converters as _register_converters; 08:48:50.351 DEBUG ScriptExecutor - Result: 0; 08:48:50.351 INFO DetermineGermlineContigPloidy - Done initializing engine; 08:48:50.352 INFO DetermineGermlineContigPloidy - Shutting down engine; [October 17, 2019 8:48:50 AM UTC] org.broadinstitute.hellbender.tools.copynumber.DetermineGermlineContigPloidy done. Elapsed time: 0.08 minutes.; Runtime.totalMemory()=597164032; java.lang.IllegalArgumentException: List of input read-count files cannot contain duplicates.; at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:725); at org.broadinstitute.hellbender.tools.copynumber.DetermineGermlineContigPloidy.validateArguments(DetermineGermlineContigPloidy.java:304); at org.broadinstitute.hellbender.tools.copynumber.DetermineGermlineContigPloidy.doWork(DetermineGermlineContigPloidy.java:277); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:163); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:206); at org.broadinstitute.hellbender.Main.main(Main.java:292). Kindly help me in fixing the issue",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6217:7088,validat,validateArg,7088,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6217,2,['validat'],"['validateArg', 'validateArguments']"
Security,"nts - Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 17:43:53.163 INFO ValidateVariants - Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 17:43:53.163 INFO ValidateVariants - Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 17:43:53.163 INFO ValidateVariants - Defaults.USE_CRAM_REF_DOWNLOAD : false; 17:43:53.163 INFO ValidateVariants - Deflater IntelDeflater; 17:43:53.163 INFO ValidateVariants - Inflater IntelInflater; 17:43:53.163 INFO ValidateVariants - Initializing engine; 17:43:53.270 INFO FeatureManager - Using codec VCFCodec to read file file:///Users/louisb/Workspace/gatk/src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleGood.vcf; 17:43:53.287 INFO FeatureManager - Using codec VCFCodec to read file file:///Users/louisb/Workspace/gatk/src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleGood.vcf; 17:43:53.291 WARN IndexUtils - Feature file ""/Users/louisb/Workspace/gatk/src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleGood.vcf"" appears to contain no sequence dictionary. Attempting to retrieve a sequence dictionary from the associated index file; 17:43:53.293 INFO ValidateVariants - Done initializing engine; 17:43:53.294 INFO ProgressMeter - Starting traversal; 17:43:53.294 INFO ProgressMeter - Current Locus Elapsed Minutes Records Processed Records/Minute; 17:43:53.302 INFO ValidateVariants - Shutting down engine; [March 21, 2017 5:43:53 PM EDT] org.broadinstitute.hellbender.tools.walkers.variantutils.ValidateVariants done. Elapsed time: 0.00 minutes.; Runtime.totalMemory()=194510848; java.lang.IllegalArgumentException: Illegal base [] seen in the allele; 	at htsjdk.variant.variantcontext.Allele.create(Allele.java:231); 	at htsjdk.variant.variantcontext.Allele.create(Allele.java:374); 	at org.broadinstitute.hellbender.tools.walkers.variantutils.ValidateVariants.apply(ValidateVariants.java:181); 	at org.broadinstitute.hellb",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2509:3722,Validat,ValidateVariants,3722,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2509,2,"['Validat', 'validat']","['ValidateVariants', 'validationExampleGood']"
Security,"nts were underestimated. . For example, the copy-ratio posterior widths should scale with the inverse square root of the number of copy-ratio bins in each segment. However, subsampling yields an artificial break at 1000 bins and screws up the scaling:. ![cr-ss](https://user-images.githubusercontent.com/11076296/51122629-417be180-17e8-11e9-9a8f-e17a5d0563f5.png). To fix this, I implemented minibatch slice sampling as described in http://proceedings.mlr.press/v33/dubois14.pdf. This uses early stopping of sampling as determined by a simple statistical test to perform approximate sampling of the posterior in a way that is more well behaved:. ![cr-mb](https://user-images.githubusercontent.com/11076296/51122680-61aba080-17e8-11e9-992a-f756a267d0ce.png). Note that the scaling levels off for larger segments, but the approximation can be made exact by taking the appropriate parameter to zero (here, this parameter is set to 0.1). However, since subsampling parameters were not exposed in the old code, I have not exposed the parameters for the approximation here. We can do this in a future PR if desired. Changing these parameters can affect runtime and results, but I've set them to reasonable values for now. The implementation involved 1) creating an abstract class to extract some common functionality shared with the old batch SliceSampler (which is now no longer used in production code), 2) implementing the MinibatchSliceSampler as described in the above reference, and 3) adding some hash-based caching functionality to both the batch/minibatch implementations, as well as to the allele-fraction likelihood calculations (see related discussion in #2860). I also made a few miscellaneous improvements to code style, etc. This is a relatively sizable change and can rather dramatically change the number of segments remaining after smoothing, etc. (although primarily on small scales and probably well within the noise). I will rerun the TCGA SNP array evaluations to make sure there are ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5575:1507,expose,exposed,1507,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5575,2,['expose'],['exposed']
Security,"number of canine WGS. It is formatted as a VCF with no sample information:; ```; chr1 240 . TG T 464.40 PASS AC=4;AF=0.011;AN=332;BaseQRankSum=0.674;ClippingRankSum=0;DP=14798;ExcessHet=0.0026;FS=5.63;InbreedingCoeff=-0.005;MLEAC=14;MLEAF=0.017;MQ=7.49;MQRankSum=-0.967;QD=22.11;ReadPosRankSum=0.967;SOR=3.18; ```. The VCF for variants for contamination is a subset of this VCF, with only biallelic SNPs with AF between 0.01 and 0.2. Initially, it was formatted the same as the above file. As part of debugging, I tried removing everything from the INFO field of the variants for contamination file, except allele frequency, and I tried using that simplified VCF both for the germline resource and the variants for contamination file. This seemed to fix the index out of bounds error, but the job then failed at the filtering step, with the following error:. ```; java.lang.IllegalArgumentException: log10p: Log10-probability must be 0 or less; 	at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:724); 	at org.broadinstitute.hellbender.utils.MathUtils.log10BinomialProbability(MathUtils.java:934); 	at org.broadinstitute.hellbender.utils.MathUtils.binomialProbability(MathUtils.java:927); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ContaminationFilter.calculateErrorProbability(ContaminationFilter.java:56); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2VariantFilter.errorProbability(Mutect2VariantFilter.java:15); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.lambda$new$1(ErrorProbabilities.java:19); 	at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1321); 	at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at jav",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6098:5142,validat,validateArg,5142,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6098,1,['validat'],['validateArg']
Security,"of time working with Mutect2 in the past year (I've built a whole workflow centered around this tool). But, while I recognize that the internal reassembly feature leads to ""best-in-class"" results in terms of calling variants, for my purposes it generally just creates headaches since it makes interpreting (certain) calls and verifying (certain) base-level behaviors/expectations very difficult (even when looking at the bamout and assembly logs). Moreover, while we know our alignment process isn't perfect, we think it's appropriate for our purposes, and we would gladly accept the loss of a few calls to be able to have more control over the expected behaviors. With that, I purpose a ""--skip-assembly"" flag that would cause the Mutect2/HaplotypeCaller engine to use the original alignment information to determine the haplotypes. . All that said, I imagine this could be a niche feature request, so I've spent some time digging through the source code trying to see if there could be a quick fix that could be made available to whatever group of developers would want this. It seemed like there could be another conditional branched added here (https://github.com/broadinstitute/gatk/blob/9ff3f8b180c063a3fa67dae129b0cbd04012448e/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/ReadThreadingAssembler.java#L159) to build a `resultSet` based on a non-assembly based approach. However, I'm not certain how using the original alignment information would affect the statistics employed for genotyping the candidate haplotypes, so I'm starting to back off implementing a custom fix and hoping the experts can help (or at least explain to me why this feature is not currently possible OR if there is a way that I can access this behavior that I'm missing). Thank you for the consideration. **(TL;DR)**; Introduce a `--skip-assembly` option that would cause the Mutect2/HaplotypeCaller engine to use the original alignment information to determine the haplotypes.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7064:1886,access,access,1886,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7064,1,['access'],['access']
Security,"ok well this was a draft, but Miguel got here first, so.....; do we want to just shut this all down and skip Validate VDS?. https://app.terra.bio/#workspaces/gvs-dev/GVS%20Quickstart%20v3%20cremer/job_history/91bc9190-d623-4ce6-8184-b20e5cb622e5. ok I hate this pr---I dont think it makes sense to have a VDS validation script that only produces a VDS if the VDS matches the VCF--that makes it very hard to debug. https://app.terra.bio/#workspaces/gvs-dev/GVS%20Quickstart%20v3%20cremer/job_history/c27c9bbe-6a01-4639-bdf9-14b00d5dc252",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8343:109,Validat,Validate,109,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8343,2,"['Validat', 'validat']","['Validate', 'validation']"
Security,"ols.github.io/hts-specs/VCFv4.2.pdf) doesn't actually say what format should the SB field be, so overriding it seems to be a bug in htsjdk?. #### Steps to reproduce; ```; cat sb-good-tiny.vcf; ##fileformat=VCFv4.2; ##INFO=<ID=SB,Number=.,Type=Integer,Description="""">; ##contig=<ID=chr1,length=248956422,assembly=GRCh38>; #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO; chr1	10146	.	AC	A	.	.	SB=5,2,18,29. gatk ApplyVQSR -O sb-recalibrated-tiny.vcf -V sb-good-tiny.vcf --recal-file recalibration. cat sb-recalibrated-tiny.vcf; ##fileformat=VCFv4.2; ##FILTER=<ID=LOW_VQSLOD,Description=""VQSLOD < 0.0"">; ##FILTER=<ID=PASS,Description=""Site contains at least one allele that passes filters"">; ##GATKCommandLine=<ID=ApplyVQSR,CommandLine=""ApplyVQSR --recal-file /Users/vlad/tmp/sb/recalibration --output sb-recalibrated-tiny-renamed4.vcf --variant sb-good-tiny-renamed4.vcf --use-allele-specific-annotations false --ignore-all-filters false --exclude-filtered false --mode SNP --interval-set-rule UNION --interval-padding 0 --interval-exclusion-padding 0 --interval-merging-rule ALL --read-validation-stringency SILENT --seconds-between-progress-updates 10.0 --disable-sequence-dictionary-validation false --create-output-bam-index true --create-output-bam-md5 false --create-output-variant-index true --create-output-variant-md5 false --lenient false --add-output-sam-program-record true --add-output-vcf-command-line true --cloud-prefetch-buffer 40 --cloud-index-prefetch-buffer -1 --disable-bam-index-caching false --sites-only-vcf-output false --help false --version false --showHidden false --verbosity INFO --QUIET false --use-jdk-deflater false --use-jdk-inflater false --gcs-max-retries 20 --gcs-project-for-requester-pays --disable-tool-default-read-filters false"",Version=""4.1.9.0"",Date=""31 May 2021 12:07:54 PM"">; ##INFO=<ID=END,Number=1,Type=Integer,Description=""Stop position of the interval"">; ##INFO=<ID=NEGATIVE_TRAIN_SITE,Number=0,Type=Flag,Description=""This variant was used to build the negative",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7280:2302,validat,validation-stringency,2302,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7280,1,['validat'],['validation-stringency']
Security,"om jar:file:/share/FGI2017B/pub/gatk-4.1.0.0/gatk-package-4.1.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; 12:33:53.793 INFO CreateReadCountPanelOfNormals - ------------------------------------------------------------; 12:33:53.794 INFO CreateReadCountPanelOfNormals - The Genome Analysis Toolkit (GATK) v4.1.0.0; 12:33:53.794 INFO CreateReadCountPanelOfNormals - For support and documentation go to https://software.broadinstitute.org/gatk/; 12:33:53.797 INFO CreateReadCountPanelOfNormals - Initializing engine; 12:33:53.797 INFO CreateReadCountPanelOfNormals - Done initializing engine; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; 19/02/18 12:33:53 INFO SparkContext: Running Spark version 2.2.0; WARNING: An illegal reflective access operation has occurred; WARNING: Illegal reflective access by org.apache.hadoop.security.authentication.util.KerberosUtil (file:/share/FGI2017B/pub/gatk-4.1.0.0/gatk-package-4.1.0.0-local.jar) to method sun.security.krb5.Config.getInstance(); WARNING: Please consider reporting this to the maintainers of org.apache.hadoop.security.authentication.util.KerberosUtil; WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations; WARNING: All illegal access operations will be denied in a future release; 12:33:54.187 WARN NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 12:33:54.263 INFO CreateReadCountPanelOfNormals - Shutting down engine; [February 18, 2019 at 12:33:54 PM CST] org.broadinstitute.hellbender.tools.copynumber.CreateReadCountPanelOfNormals done. Elapsed time: 0.04 minutes.; Runtime.totalMemory()=2147483648; Exception in thread ""main"" java.lang.ExceptionInInitializerError; 	at org.apache.spark.SparkConf.validateSettings(SparkConf.scala:546); 	at org.apache.spark.SparkContext.<init>(SparkContext.scala:373); 	at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContex",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5686:1638,secur,security,1638,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5686,1,['secur'],['security']
Security,"ome additional parsing because it returns an Object; - (Bonus points if you use the isFixedCount() and getCount() functions on the VCF info header line to simplify annotations that aren't according to the number of alt alleles); ### Test data. /humgen/gsa-hpprojects/dev/gauthier/scratch/supportingMultiA.vcf; Should fail AC/AF validation at ; `1 768589 . A C,G 76 PASS AC=1;AF=0.00047;AN=2120`; See results using:. ```; use VCFtools; vcf-validator /humgen/gsa-hpprojects/dev/gauthier/scratch/supportingMultiA.vcf; ```. which outputs:; `INFO field at 1:768589 .. INFO tag [AC=1] expected different number of values (expected 2, found 1),INFO tag [AF=0.00047] expected different number of values (expected 2, found 1)`; ### Notes. Currently, all the validation modes call out to HTSJDK. Do we want to put the new functionality there as well?. ---. @yfarjoun commented on [Thu Jul 16 2015](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-122130280). I think that it is very appropriate to validate in htsjdk. On Thu, Jul 16, 2015 at 4:05 PM, ldgauthier notifications@github.com; wrote:. > Currently ValidateVariants relies on genotypes to transitively check that; > each alt allele occurs in at least one sample and that the AC adds up.; > However, this can fail on sites-only files because there are no genotypes.; > We should use the definition of the info annotations in the header to check; > how many entries each should have.; > Outline; > - Add a new validation type for info-field counts to enum and to; > switch statement; > - Grab info headers from input VCF with something like; > GATKVCFUtils.getVCFHeadersFromRods(getToolkit(),; > variantCollection.variants.getName()) and VCFHeader::getInfoHeaderLines; > - In the map() function, for each info header line, call on each; > VCFInfoHeaderLine getCount(vc) to get the expected number of info; > annotation entries; > - Compare the expected number with a count based on; > vc.getAttribute(currentVCFinfoHeaderLine.getID",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2507:2015,validat,validate,2015,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2507,1,['validat'],['validate']
Security,"on/4e3bd06b-3018-4c94-ac98-feb78b924d1f/call-FilterFuncotations/shard-0/inputs/1333115969/104566-001-001.filtered.vcf.funcotated.vcf.gz \ ; --output 104566-001-001.filtered.vcf.filtered.vcf.gz \ ; --ref-version hg38 \ ; --allele-frequency-data-source gnomad --lenient true; ; ; ; ; . However, the command fails with the error message below:. ; ; ; ; [October 14, 2021 at 12:20:24 PM CEST] org.broadinstitute.hellbender.tools.funcotator.FilterFuncotations done. Elapsed time: 16.57 minutes. ; Runtime.totalMemory()=1134559232 ; java.lang.IllegalStateException: Duplicate key Gencode\_34\_annotationTranscript (attempted merging values ENST00000450305.2 and ENST00000456328.2) ; at java.base/java.util.stream.Collectors.duplicateKeyException(Collectors.java:133) ; at java.base/java.util.stream.Collectors.lambda$uniqKeysMapAccumulator$1(Collectors.java:180) ; at java.base/java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169) ; at java.base/java.util.HashMap$KeySpliterator.forEachRemaining(HashMap.java:1603) ; at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484) ; at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474) ; at java.base/java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:913) ; at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234) ; at java.base/java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:578) ; at org.broadinstitute.hellbender.tools.funcotator.filtrationRules.AlleleFrequencyUtils.lambda$buildMaxMafRule$1(AlleleFrequencyUtils.java:30) ; at org.broadinstitute.hellbender.tools.funcotator.filtrationRules.FuncotationFilter.lambda$checkFilter$0(FuncotationFilter.java:48) ; at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195) ; at java.base/java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:948) ; at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.ja",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7504:2438,Hash,HashMap,2438,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7504,1,['Hash'],['HashMap']
Security,"onActor [968be82cValidateBamsWf.ValidateBAM:0:1]: Unrecognized runtime attribute keys: disks, memory; [2020-07-14 05:09:41,71] [info] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: /gatk/gatk \; ValidateSamFile \; --INPUT /cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/inputs/-1942028726/test.bam \; --OUTPUT test.validation_.txt \; --MODE SUMMARY; [2020-07-14 05:09:41,76] [info] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: executing: # make sure there is no preexisting Docker CID file; rm -f /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/docker_cid; # run as in the original configuration without --rm flag (will remove later); docker run \; --cidfile /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/docker_cid \; -i \; \; --entrypoint /bin/bash \; -v /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0:/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0:delegated \; broadinstitute/gatk@sha256:18146e79d06787483310e5de666502090a480e10ac0fad06a36a5e7a5c9bb1dc /cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/script. # get the return code (working even if the container was detached); rc=$(docker wait cat /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/docker_cid). # remove the container after waiting; docker rm cat /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/docker_cid. # return exit code; exit $rc; [2020-07-14 05:09:45,29] [info] BackgroundConfigAsyncJobExecutionActor [968be8",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6710:5095,Validat,ValidateBAM,5095,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710,11,['Validat'],"['ValidateBAM', 'ValidateBamsWf']"
Security,onUtil.java:39); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.createOptionsBuilderFromConfig(GoogleHadoopFileSystemBase.java:2185); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.configure(GoogleHadoopFileSystemBase.java:1832); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.initialize(GoogleHadoopFileSystemBase.java:1013); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.initialize(GoogleHadoopFileSystemBase.java:976); 	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2812); 	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:100); 	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2849); 	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2831); 	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:389); 	at org.apache.hadoop.fs.FileSystem$1.run(FileSystem.java:171); 	at org.apache.hadoop.fs.FileSystem$1.run(FileSystem.java:168); 	at java.base/java.security.AccessController.doPrivileged(Native Method); 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423); 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1836); 	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:168); 	at org.genomicsdb.reader.GenomicsDBQueryStream.jniGenomicsDBInit(Native Method); 	at org.genomicsdb.reader.GenomicsDBQueryStream.<init>(GenomicsDBQueryStream.java:209); 	at org.genomicsdb.reader.GenomicsDBQueryStream.<init>(GenomicsDBQueryStream.java:182); 	at org.genomicsdb.reader.GenomicsDBQueryStream.<init>(GenomicsDBQueryStream.java:91); 	at org.genomicsdb.reader.GenomicsDBFeatureReader.generateHeadersForQuery(GenomicsDBFeatureReader.java:176); 	at org.genomicsdb.reader.GenomicsDBFeatureReader.<init>(GenomicsDBFeatureReader.java:80); 	at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImportIntegrationTest.getGenomicsDBFeatureReader(GenomicsDBImportIntegrationTest.java:926); 	at org.broadinstitute.hellbender.tools.genomic,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6522:1562,Access,AccessController,1562,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6522,1,['Access'],['AccessController']
Security,once #3480 is in and #3447 is in @magicDGS requested that we should expose DEFAULT_FEATURE_CACHE_LOOKAHEAD as a configurable option,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3489:68,expose,expose,68,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3489,1,['expose'],['expose']
Security,"ons=[] invertselect=false excludeNonVariants=false excludeFiltered=false preserveAlleles=false removeUnusedAlternates=false restrictAllelesTo=ALL keepOriginalAC=false keepOriginalDP=false mendelianViolation=false invertMendelianViolation=false mendelianViolationQualThreshold=0.0 select_random_fraction=0.0 remove_fraction_genotypes=0.0 selectTypeToInclude=[] selectTypeToExclude=[] keepIDs=null excludeIDs=null fullyDecode=false justRead=false maxIndelSize=2147483647 minIndelSize=0 maxFilteredGenotypes=2147483647 minFilteredGenotypes=0 maxFractionFilteredGenotypes=1.0 minFractionFilteredGenotypes=0.0 setFilteredGtToNocall=false ALLOW_NONOVERLAPPING_COMMAND_LINE_SAMPLES=false filter_reads_with_N_cigar=false filter_mismatching_base_and_quals=false filter_bases_not_stored=false"">; ```. The BAM header lines look something like this (may have changed slightly in more recent versions):. ```; @PG	ID:GATK IndelRealigner	VN:1.2-573-g821421d	CL:knownAlleles=[(RodBinding name=knownAlleles source=/humgen/gsa-hpprojects/GATK/data/Comparisons/Validated/dbSNP/dbsnp_132_b37.leftAligned.vcf), (RodBinding name=knownAlleles2 source=/humgen/1kg/processing/official_release/phase1/projectConsensus/ALL.wgs.projectConsensus_v2b.20101123.snps.sites.vcf), (RodBinding name=knownAlleles3 source=/humgen/gsa-hpprojects/GATK/data/Comparisons/Unvalidated/AFR+EUR+ASN+1KG.dindel_august_release_merged_pilot1.20110126.sites.vcf)] LODThresholdForCleaning=5.0 consensusDeterminationModel=USE_READS entropyThreshold=0.15 maxReadsInMemory=150000 maxIsizeForMovement=3000 maxPositionalMoveAllowed=200 maxConsensuses=30 maxReadsForConsensuses=120 maxReadsForRealignment=20000 noOriginalAlignmentTags=false nWayOut=null generate_nWayOut_md5s=false check_early=false noPGTag=false keepPGTags=false indelsFileForDebugging=null statisticsFileForDebugging=null SNPsFileForDebugging=null; ```. We don't need to replicate the formatting of these -- we can just have the raw command line as a String for both headers, along with ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2269:3429,Validat,Validated,3429,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2269,1,['Validat'],['Validated']
Security,"ools (GenomicsDBImport, GatherVcfs). Sometimes we get this as the only response from GATK when this happens. ```; ***********************************************************************. A USER ERROR has occurred: Couldn't read file. Error was: Failure while waiting for FeatureReader to initialize with exception: com.google.cloud.storage.StorageException: 403 Forbidden; 443301511749-compute@developer.gserviceaccount.com does not have storage.objects.get access to broad-gotc-prod-storage/pipeline/G101956/gvcfs/DDP_ATCP_42_1.4afb46bb-4009-47c4-9aa0-407e92de0db8.g.vcf.gz. ***********************************************************************; ```. and other times we get a nice stacktrace for this issue. ```; java.lang.RuntimeException: java.util.concurrent.ExecutionException: com.google.cloud.storage.StorageException: 403 Forbidden; 443301511749-compute@developer.gserviceaccount.com does not have storage.objects.get access to broad-jg-dev-11k-call-set/JointGenotyping/0cb36821-b8bf-4e6d-a352-07b101f6b7d1/call-ApplyRecalibration/shard-1734/GMKF_Seidman_CHD_WGS_904.filtered.1734.vcf.gz.; 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher.read(SeekableByteChannelPrefetcher.java:309); 	at htsjdk.samtools.seekablestream.SeekablePathStream.read(SeekablePathStream.java:86); 	at htsjdk.samtools.util.IOUtil.transferByStream(IOUtil.java:141); 	at org.broadinstitute.hellbender.tools.GatherVcfsCloud.gatherWithBlockCopying(GatherVcfsCloud.java:394); 	at org.broadinstitute.hellbender.tools.GatherVcfsCloud.doWork(GatherVcfsCloud.java:143); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:119); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:176); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:195); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:137); 	at org.broadinstitute.hellbender",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3735:1277,access,access,1277,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3735,1,['access'],['access']
Security,opFileSystemBase.createOptionsBuilderFromConfig(GoogleHadoopFileSystemBase.java:2185); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.configure(GoogleHadoopFileSystemBase.java:1832); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.initialize(GoogleHadoopFileSystemBase.java:1013); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.initialize(GoogleHadoopFileSystemBase.java:976); 	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2812); 	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:100); 	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2849); 	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2831); 	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:389); 	at org.apache.hadoop.fs.FileSystem$1.run(FileSystem.java:171); 	at org.apache.hadoop.fs.FileSystem$1.run(FileSystem.java:168); 	at java.base/java.security.AccessController.doPrivileged(Native Method); 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423); 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1836); 	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:168); 	at org.genomicsdb.reader.GenomicsDBQueryStream.jniGenomicsDBInit(Native Method); 	at org.genomicsdb.reader.GenomicsDBQueryStream.<init>(GenomicsDBQueryStream.java:209); 	at org.genomicsdb.reader.GenomicsDBQueryStream.<init>(GenomicsDBQueryStream.java:182); 	at org.genomicsdb.reader.GenomicsDBQueryStream.<init>(GenomicsDBQueryStream.java:91); 	at org.genomicsdb.reader.GenomicsDBFeatureReader.generateHeadersForQuery(GenomicsDBFeatureReader.java:176); 	at org.genomicsdb.reader.GenomicsDBFeatureReader.<init>(GenomicsDBFeatureReader.java:80); 	at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImportIntegrationTest.getGenomicsDBFeatureReader(GenomicsDBImportIntegrationTest.java:926); 	at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImportIntegrationTest.checkGenomicsDBAgainstExpe,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6522:1628,secur,security,1628,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6522,1,['secur'],['security']
Security,"orMetricsUpdate(34,WrappedArray()); 18/01/12 20:38:37 ERROR org.apache.spark.scheduler.LiveListenerBus: SparkListenerBus has already stopped! Dropping event SparkListenerExecutorMetricsUpdate(60,WrappedArray()); 20:38:37.897 INFO StructuralVariationDiscoveryPipelineSpark - Shutting down engine; [January 12, 2018 8:38:37 PM UTC] org.broadinstitute.hellbender.tools.spark.sv.StructuralVariationDiscoveryPipelineSpark done. Elapsed time: 42.74 minutes.; Runtime.totalMemory()=16692805632; org.apache.spark.SparkException: Job aborted due to stage failure: Task 284 in stage 25.0 failed 4 times, most recent failure: Lost task 284.3 in stage 25.0 (TID 43224, cw-test-w-6.c.broad-dsde-methods.internal, executor 7): java.lang.IllegalArgumentException: two input alignments' overlap on read consumes completely one of them.	1_1097_chrUn_JTFH01000492v1_decoy:501-1597_+_1097M6H_60_1_1092_O	483_612_chr17:26962677-26962806_-_482S130M491S_60_-1_281_S; 	at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:681); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.prototype.ContigAlignmentsModifier.removeOverlap(ContigAlignmentsModifier.java:36); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.prototype.AssemblyContigAlignmentSignatureClassifier.lambda$processContigsWithTwoAlignments$e28aa838$1(AssemblyContigAlignmentSignatureClassifier.java:114); 	at org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction$1.apply(JavaPairRDD.scala:1040); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:462); 	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); 	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); 	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at org.apache.spark.util.collection.ExternalSor",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4141:6681,validat,validateArg,6681,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4141,1,['validat'],['validateArg']
Security,org/broadinstitute/hellbender/tools/walkers/rnaseq/ASEReadCounter/NA12878.chr20_2444518_2637800.RNAseq.NON_REF.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/rnaseq/ASEReadCounter/NA12878.chr20_2444518_2637800.RNAseq.SYNONYMOUS_CODING.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/rnaseq/ASEReadCounter/NA12878.chr20_2444518_2637800.RNAseq.warnings.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/UnmarkDuplicates/allDuplicates.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/complexEvents_incompatibleDict.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/complexEvents_lexDict.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/complexEvents.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/gvcf.basepairResolution.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet_BAD_INCOMPLETE_REGION.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet.BAD_MISSING_NON_REF.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet.missingrefblock.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleBad3.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleBad.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleGood.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleRSIDonPositionNotInDBSNP.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walker,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3905:60637,Validat,ValidateVariants,60637,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905,1,['Validat'],['ValidateVariants']
Security,"ormatter - Java HotSpot(TM) 64-Bit Server VM 1.8.0_111-b14 ; INFO 17:39:56,368 HelpFormatter - Program Args: -T LeftAlignAndTrimVariants -R /Users/shlee/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V zeta_af-only-gnomad_Hg19toGRCh38.vcf.gz -o eta_af-only-gnomad_Hg19toGRCh38.vcf.gz ; INFO 17:39:56,373 HelpFormatter - Executing as shlee@WMCF9-CB5 on Mac OS X 10.11.6 x86_64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_111-b14. ; INFO 17:39:56,374 HelpFormatter - Date/Time: 2017/08/22 17:39:56 ; INFO 17:39:56,374 HelpFormatter - -------------------------------------------------------------------------------- ; INFO 17:39:56,374 HelpFormatter - -------------------------------------------------------------------------------- ; INFO 17:39:56,385 GenomeAnalysisEngine - Strictness is SILENT ; INFO 17:39:57,377 GenomeAnalysisEngine - Downsampling Settings: Method: BY_SAMPLE, Target Coverage: 1000 ; WARN 17:39:57,688 IndexDictionaryUtils - Track variant doesn't have a sequence dictionary built in, skipping dictionary validation ; INFO 17:39:58,497 GenomeAnalysisEngine - Preparing for traversal ; INFO 17:39:58,502 GenomeAnalysisEngine - Done preparing for traversal ; INFO 17:39:58,503 ProgressMeter - [INITIALIZATION COMPLETE; STARTING PROCESSING] ; INFO 17:39:58,503 ProgressMeter - | processed | time | per 1M | | total | remaining ; INFO 17:39:58,503 ProgressMeter - Location | sites | elapsed | sites | completed | runtime | runtime ; INFO 17:39:58,692 LeftAlignAndTrimVariants - Reference allele is too long (245) at position chr1:10146; skipping that record. Set --reference_window_stop >= 245 ; INFO 17:39:58,697 LeftAlignAndTrimVariants - Reference allele is too long (225) at position chr1:10178; skipping that record. Set --reference_window_stop >= 225 ; INFO 17:39:58,700 LeftAlignAndTrimVariants - Reference allele is too long (221) at position chr1:10213; skipping that record. Set --reference_window_stop >= 221 ; INFO 17:39:58,700 LeftAlignAndTrimVariants - Reference allele is",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3487:3198,validat,validation,3198,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3487,1,['validat'],['validation']
Security,"ou, please let me know if you think anyone else should look at this. This issue is created from a forum bug report (https://gatkforums.broadinstitute.org/gatk/discussion/24511/error-in-readspipelinespark-version-4-1-4/p1). More information can be requested if necessary. Stack trace copied below:; > A USER ERROR has occurred: Couldn't write file hdfs://cloudera08/gatk-test2/WES2019-022_S4_out.vcf because writing failed with exception concat: target file /gatk-test2/WES2019-022_S4_out.vcf.parts/output is empty; > at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.concatInternal(FSNamesystem.java:2303); > at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.concatInt(FSNamesystem.java:2257); > at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.concat(FSNamesystem.java:2219); > at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.concat(NameNodeRpcServer.java:829); > at org.apache.hadoop.hdfs.server.namenode.AuthorizationProviderProxyClientProtocol.concat(AuthorizationProviderProxyClientProtocol.java:285); > at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.concat(ClientNamenodeProtocolServerSideTranslatorPB.java:580); > at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java); > at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:617); > at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1073); > at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2278); > at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2274); > at java.security.AccessController.doPrivileged(Native Method); > at javax.security.auth.Subject.doAs(Subject.java:422); > at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1924); > at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2272); > ; > org.broadinstitute.hellbender.exceptions.UserException$CouldNotCreateOutputFile: Cou",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6218:1163,Authoriz,AuthorizationProviderProxyClientProtocol,1163,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6218,1,['Authoriz'],['AuthorizationProviderProxyClientProtocol']
Security,"oups in a SAM/BAM/CRAM file with a single new read group; ApplyBQSR Applies the BQSR table to the input SAM/BAM/CRAM; BaseRecalibrator Generates recalibration table for BQSR; BuildBamIndex Generates a BAM index (.bai) file; CalculateReadGroupChecksum Creates a hash code based on the read groups (RG) in the SAM/BAM/CRAM header; CleanSam Cleans the provided SAM/BAM/CRAM, soft-clipping beyond-end-of-reference alignments and setting MAPQ to 0 for unmapped reads; ClipReads Clip reads in a SAM/BAM/CRAM file; CompareBaseQualities Compares base qualities of two input SAM/BAM/CRAM files; CompareSAMs Compares two input SAM/BAM/CRAM files; CountBases Count bases in a SAM/BAM/CRAM file; CountReads Count reads in a SAM/BAM/CRAM file; DownsampleSam Down-sample a SAM/BAM file to retain a random subset of the reads; EstimateLibraryComplexity Estimates library complexity from the sequence of read pairs; ExampleReadWalkerWithReference Print reads with reference context; ExampleReadWalkerWithVariants Print reads with overlapping variants; FastqToSam Converts a fastq file to an unaligned SAM/BAM file; FilterReads Creates a new SAM/BAM/CRAM file by including or excluding aligned reads; FixMateInformation Ensure that all mate-pair information is in sync between each read and its mate pair; FixMisencodedBaseQualityReads Fix Illumina base quality scores in a SAM/BAM/CRAM file; FlagStat A reimplementation of the 'samtools flagstat' subcommand; GatherBQSRReports Gathers scattered BQSR recalibration reports into a single file; GatherBamFiles Concatenates one or more BAM files together as efficiently as possible; LeftAlignIndels Left-aligns indels from reads in a SAM/BAM/CRAM file; MarkDuplicates Examines aligned records in the supplied SAM/BAM/CRAM file to locate duplicate molecules.; MergeBamAlignment Merges alignment data from a SAM/BAM with data in an unmapped SAM/BAM/CRAM file; MergeSamFiles Merges multiple SAM/BAM files into one file; PrintReads Print reads in the SAM/BAM/CRAM file; Reor",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1669:3800,hash,hash,3800,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1669,1,['hash'],['hash']
Security,"pPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748). I don't understand why if the command is the same:; ```; $GATK_PATH BwaAndMarkDuplicatesPipelineSpark --bam-partition-size 64000000 or 4000000 \; --input hdfs://namenode:8020/$dir_prepro$ubam \; --reference hdfs://namenode:8020/hg19-ucsc/ucsc.hg19.2bit \; --bwa-mem-index-image /reference_image/ucsc.hg19.fasta.img \; --disable-sequence-dictionary-validation true \; --output hdfs://namenode:8020/$dir_prepro$output -- \; --spark-runner SPARK --spark-master spark://$SPARK_MASTER_HOST:7077 \; --driver-memory 20g --executor-cores 4 --executor-memory 8g; ```. Furthermore I have this problem with this version v4.0.4.0-23-g6e1cc8c-SNAPSHOT. > mark duplicate records objects corresponding to read with name, this could be the result of readnames spanning more than one partition; 	at org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSpark.lambda$null$0(MarkDuplicatesSpark.java:109); 	at java.util.HashMap.merge(HashMap.java:1253); 	at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1320); 	at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.R",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4820:6506,validat,validation,6506,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4820,1,['validat'],['validation']
Security,"pdated based on them... I think that best way to move forward here is:; 1. Lift up that maximum number of Genotypes to output PLs based on the ploidy parameter (I think the limit was quite modest perhaps as low as 20).; 2. Implement the alt. allele `culling` or `collapsing` that I mention above in HaplotypeCaller already. ; 3. Implement the alt. allele `re-culling` or `re-collapsing` in GVCF (VCF as well?) merging tools such as CombineGVCFs/GenotypeGVCFs.; 4. Regenotyping and QUAL recalculating tools would need to make sure that PLs less input are handled appropriately, not sure what would happen now if some of the inputs lack PLs... (an Exception?) ; - For example QUAL could be approximated as the max of the input Quals, and QD as the average? ; - Or simple lift them blank?. So it would a bit of work I would say... 3 of the old PTs worth. ---. @vdauwera commented on [Thu May 14 2015](https://github.com/broadinstitute/gsa-unstable/issues/855#issuecomment-102235192). Recording test case while sanitizing: . The files are located here: . ```; gsa1:/humgen/gsa-scr1/schandra/GenotypeGVCFs_LargePloidyAndLargeAlleles; ```. The command I ran:. ```; java -jar /humgen/gsa-hpprojects/GATK/private_unstable_builds/GenomeAnalysisTK_latest_unstable.jar \; -T GenotypeGVCFs \; -R /humgen/gsa-scr1/schandra/GenotypeGVCFs_LargePloidyAndLargeAlleles/45S_Jacobsen_rearranged.fa \; -V /humgen/gsa-scr1/schandra/GenotypeGVCFs_LargePloidyAndLargeAlleles/Input_ploidy.list \; -o Sheila.GenotypeGVCFs.vcf; ```. Which produces:. ```; ##### ERROR MESSAGE: the combination of ploidy (19) and number of alleles (21) results in a very large number of genotypes (> 2147483647). You need to limit ploidy or the number of alternative alleles to analyze this locus; ```. ---. @chandrans commented on [Wed Jan 20 2016](https://github.com/broadinstitute/gsa-unstable/issues/855#issuecomment-173357206). @davidbenjamin Hi David. Have you had a chance to look at this?. ---. @davidbenjamin commented on [Sat Jan 23 201",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2955:3413,sanitiz,sanitizing,3413,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2955,1,['sanitiz'],['sanitizing']
Security,"peline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); 	at org.broadinstitute.hellbender.engine.ReadWalker.traverse(ReadWalker.java:94); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1039); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:162); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:205); 	at org.broadinstitute.hellbender.Main.main(Main.java:291). My GATK version is :GATK4.1.2.0; My command is:; /data/home/wuly/soft/GATK4/gatk-4.1.2.0/gatk --java-options ""-Xmx20G -Djava.io.tmpdir=./"" BaseRecalibrator -R /data/home/wuly/source/Homo_sapiens_assembly38.fasta \; -I M1.bam \; --known-sites /data/home/wuly/source/hapmap_3.3.hg38.vcf.gz \; --known-sites /data/home/wuly/source/dbsnp_146.hg38.vcf.gz \; --known-sites /data/home/wuly/source/Mills_and_1000G_gold_standard.indels.hg38.vcf.gz \; --known-sites /data/home/wuly/source/1000G_phase1.snps.high_confidence.hg38.vcf.gz \; -O M1_recal.table; Then I run the ValidateSamFile to check the BAM file,this is the command : ; /data/home/wuly/soft/GATK4/gatk-4.1.2.0/gatk --java-options ""-Xmx20G -Djava.io.tmpdir=./"" ValidateSamFile -I M1.bam. And the result is: No errors found; I also tried to use the BAM file before I merge them to run BaseRecalibrator and ValidateSamFile, but I got the same result.Can anybody tell me how solve this problem?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5968:11938,Validat,ValidateSamFile,11938,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5968,3,['Validat'],['ValidateSamFile']
Security,pileup.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/rnaseq/ASEReadCounter/NA12878.chr20_2444518_2637800.RNAseq.IMPROPER_PAIR.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/rnaseq/ASEReadCounter/NA12878.chr20_2444518_2637800.RNAseq.MultiContext.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/rnaseq/ASEReadCounter/NA12878.chr20_2444518_2637800.RNAseq.NON_REF.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/rnaseq/ASEReadCounter/NA12878.chr20_2444518_2637800.RNAseq.SYNONYMOUS_CODING.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/rnaseq/ASEReadCounter/NA12878.chr20_2444518_2637800.RNAseq.warnings.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/UnmarkDuplicates/allDuplicates.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/complexEvents_incompatibleDict.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/complexEvents_lexDict.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/complexEvents.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/gvcf.basepairResolution.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet_BAD_INCOMPLETE_REGION.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet.BAD_MISSING_NON_REF.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet.missingrefblock.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleBad3.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExa,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3905:60310,Validat,ValidateVariants,60310,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905,1,['Validat'],['ValidateVariants']
Security,ples.MendelianViolation.updateViolations(MendelianViolation.java:122) at org.broadinstitute.hellbender.utils.samples.MendelianViolation.countFamilyViolations(MendelianViolation.java:148) at org.broadinstitute.hellbender.tools.walkers.varianteval.evaluators.MendelianViolationEvaluator.update1(MendelianViolationEvaluator.java:122) at org.broadinstitute.hellbender.tools.walkers.varianteval.util.EvaluationContext.apply(EvaluationContext.java:74) at org.broadinstitute.hellbender.tools.walkers.varianteval.VariantEval.processComp(VariantEval.java:596) at org.broadinstitute.hellbender.tools.walkers.varianteval.VariantEval.doApply(VariantEval.java:562) at org.broadinstitute.hellbender.tools.walkers.varianteval.VariantEval$PositionAggregator.callDoApply(VariantEval.java:497) at org.broadinstitute.hellbender.tools.walkers.varianteval.VariantEval$PositionAggregator.addVariant(VariantEval.java:478) at org.broadinstitute.hellbender.tools.walkers.varianteval.VariantEval$PositionAggregator.access$100(VariantEval.java:469) at org.broadinstitute.hellbender.tools.walkers.varianteval.VariantEval.apply(VariantEval.java:511) at org.broadinstitute.hellbender.engine.MultiVariantWalker.lambda$traverse$1(MultiVariantWalker.java:120) at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184) at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193) at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175) at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193) at java.util.Iterator.forEachRemaining(Iterator.java:116) at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801) at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481) at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471) at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151) at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174) at,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7304:5099,access,access,5099,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7304,1,['access'],['access']
Security,port ValidateVariants,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/46:5,Validat,ValidateVariants,5,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/46,1,['Validat'],['ValidateVariants']
Security,"port and documentation go to https://software.broadinstitute.org/gatk/; 19:53:34.607 INFO ValidateVariants - Executing as zepengmu@midway2-login1.rcc.local on Linux v3.10.0-1127.8.2.el7.x86_64 amd64; 19:53:34.607 INFO ValidateVariants - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_45-b14; 19:53:34.607 INFO ValidateVariants - Start Date/Time: October 25, 2020 7:53:34 PM CDT; 19:53:34.607 INFO ValidateVariants - ------------------------------------------------------------; 19:53:34.607 INFO ValidateVariants - ------------------------------------------------------------; 19:53:34.607 INFO ValidateVariants - HTSJDK Version: 2.22.0; 19:53:34.607 INFO ValidateVariants - Picard Version: 2.22.8; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 19:53:34.608 INFO ValidateVariants - Deflater: IntelDeflater; 19:53:34.608 INFO ValidateVariants - Inflater: IntelInflater; 19:53:34.608 INFO ValidateVariants - GCS max retries/reopens: 20; 19:53:34.608 INFO ValidateVariants - Requester pays: disabled; 19:53:34.608 INFO ValidateVariants - Initializing engine; 19:53:35.169 INFO FeatureManager - Using codec VCFCodec to read file file://chr1-22.phased.rename.reheader.vcf.gz; 19:53:35.594 INFO ValidateVariants - Done initializing engine; 19:53:35.594 WARN ValidateVariants - IDS validation cannot be done because no DBSNP file was provided; 19:53:35.594 WARN ValidateVariants - Other possible validations will still be performed; 19:53:35.594 INFO ProgressMeter - Starting traversal; 19:53:35.595 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 19:53:35.660 INFO ValidateVariants - Shutting down engine; [October 25, 2020 7:53:35 PM CDT] org.broadi",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6911:2310,Validat,ValidateVariants,2310,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6911,1,['Validat'],['ValidateVariants']
Security,"ports:; - 8334:50070; volumes:; - /data0/reference/hg19-ucsc/:/reference/hg19-ucsc/; - /data0/output/:/output/; - /data/ngs/:/ngs/; datanode:; image: bde2020/hadoop-datanode:2.0.0-hadoop2.7.4-java8; networks:; - workbench; volumes:; - datanode:/hadoop/dfs/data; environment:; SERVICE_PRECONDITION: ""namenode:50070""; # depends_on:; # - namenode; env_file:; - ./hadoop.env; deploy:; mode: global; restart_policy:; condition: on-failure; labels:; traefik.docker.network: workbench; traefik.port: 50075. volumes:; datanode:; namenode:. networks:; workbench:; external: true; ```; the datanodes and namenode and spark master and workers are all working.; My hardware resources are:; 16 core and 1Tb memory ssd and 56Gb ram for 3 machines. I have this problem when I launch the version(GATK) v4.0.4.0 but not with this version v4.0.2.0-4-gb59d863-SNAPSHOT:. >java.lang.IllegalStateException: Duplicate key -1; 	at java.util.stream.Collectors.lambda$throwingMerger$0(Collectors.java:133); 	at java.util.HashMap.merge(HashMap.java:1253); 	at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1320); 	at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 	at org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSpark.lambda$mark$2142e97f$1(MarkDuplicatesSpark.java:82); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$10$1.apply(JavaRDDLike.scala:319); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$1",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4820:3691,Hash,HashMap,3691,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4820,1,['Hash'],['HashMap']
Security,precompute hashcode in MultiDeBruijnVertex and added a bunch of tests,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1625:11,hash,hashcode,11,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1625,1,['hash'],['hashcode']
Security,prevent accidental toString call during validation,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3478:40,validat,validation,40,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3478,1,['validat'],['validation']
Security,prevent sequence dictionary validation when aligning reads,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4308:28,validat,validation,28,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4308,1,['validat'],['validation']
Security,"previously, tools that align reads required you to manually disable sequence dictionary validation; if you didn't, they would fail because the unaligned bam didn't have the required sequence dictionary. extracting out a SequenceDictionaryValidationArgumentCollection and providing a method for GATKSparkTools to configure it; ReadsPipeline couldn't easily make use of this, so instead it overrides the method that does validation. BwaSpark / BwaAndMarkDuplicatesPipelineSpark now do not require or allow dictionary validation; fixes #4131",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4308:88,validat,validation,88,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4308,3,['validat'],['validation']
Security,"ps://github.com/broadinstitute/gsa-unstable/issues/1489#issuecomment-256499771). Writing pipeline-help now and cc'ing everyone involved in this thread. Will try to get some kind of protocol set up for debugging things that happen in the cloud pipeline, because I expect this will happen again. But if it gets too complicated we could also mock up some fake records that would reproduce this. It seems to me that shouldn't be too hard. . ---. @vdauwera commented on [Mon Nov 14 2016](https://github.com/broadinstitute/gsa-unstable/issues/1489#issuecomment-260498705). I need to ping Daniel on getting access to the files. ---. @ronlevine commented on [Thu Jan 26 2017](https://github.com/broadinstitute/gsa-unstable/issues/1489#issuecomment-275576931). @vdauwera Can you get the data? I can take a look a this issue. ---. @vdauwera commented on [Thu Jan 26 2017](https://github.com/broadinstitute/gsa-unstable/issues/1489#issuecomment-275578721). Oh, they gave me access to the files but I never took the next step of figuring out which files are relevant. There are twenty thousand samples... I'm not sure what is the best way to approach this. ---. @ldgauthier commented on [Wed Mar 01 2017](https://github.com/broadinstitute/gsa-unstable/issues/1489#issuecomment-283365248). It would be too computationally expensive and just generally painful to get; that dropped allele. I'd suggest making a unit test with some fake data.; You'll need two positions: one upstream with a deletion to generate the *; and one for the SNP. I think the dropped allele was a 1bp deletion at the; same position that generated the representation with the extra base at the; end. Give that one a really low quality in its gvcf so it gets dropped.; PLs don't really matter as long as they jive with the quals and aren't hom; ref. You can just grab numbers from any other valid vcf. I think you can do; it with three samples: one with the upstream deletion and *, one with the; AC SNP and one with the low quality deletion.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2959:3345,access,access,3345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2959,1,['access'],['access']
Security,"questing a new application from cluster with 2 NodeManagers; 17/10/11 14:19:12 INFO yarn.Client: Verifying our application has not requested more than the maximum memory capability of the cluster (164726 MB per container); 17/10/11 14:19:12 INFO yarn.Client: Will allocate AM container, with 896 MB memory including 384 MB overhead; 17/10/11 14:19:12 INFO yarn.Client: Setting up container launch context for our AM; 17/10/11 14:19:12 INFO yarn.Client: Setting up the launch environment for our AM container; 17/10/11 14:19:12 INFO yarn.Client: Preparing resources for our AM container; 17/10/11 14:19:12 INFO gcs.GoogleHadoopFileSystemBase: GHFS version: 1.6.1-hadoop2; 17/10/11 14:19:12 INFO yarn.Client: Uploading resource file:/tmp/hdfs/spark-8c88439f-dcb0-48b2-86f3-fc82cef4c438/__spark_conf__8945422067005652415.zip -> hdfs://mg:8020/user/hdfs/.sparkStaging/application_1507683879816_0006/__spark_conf__8945422067005652415.zip; 17/10/11 14:19:13 INFO spark.SecurityManager: Changing view acls to: hdfs; 17/10/11 14:19:13 INFO spark.SecurityManager: Changing modify acls to: hdfs; 17/10/11 14:19:13 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(hdfs); users with modify permissions: Set(hdfs); 17/10/11 14:19:13 INFO yarn.Client: Submitting application 6 to ResourceManager; 17/10/11 14:19:13 INFO impl.YarnClientImpl: Submitted application application_1507683879816_0006; 17/10/11 14:19:14 INFO yarn.Client: Application report for application_1507683879816_0006 (state: ACCEPTED); 17/10/11 14:19:14 INFO yarn.Client: ; 	 client token: N/A; 	 diagnostics: N/A; 	 ApplicationMaster host: N/A; 	 ApplicationMaster RPC port: -1; 	 queue: root.users.hdfs; 	 start time: 1507702753100; 	 final status: UNDEFINED; 	 tracking URL: http://mg:8088/proxy/application_1507683879816_0006/; 	 user: hdfs; 17/10/11 14:19:15 INFO yarn.Client: Application report for application_1507683879816_0006 (state: ACCEPTED); 17/10/11 14:19:15 IN",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686:6153,Secur,SecurityManager,6153,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686,1,['Secur'],['SecurityManager']
Security,"r [968be82cValidateBamsWf.ValidateBAM:0:1]: job id: 243; [2020-07-14 05:09:45,29] [info] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: Status change from - to Done; [2020-07-14 05:09:46,38] [info] WorkflowManagerActor Workflow 968be82c-eef3-4bdb-a1ab-3d4e2ca70674 failed (during ExecutingWorkflowState): Job ValidateBamsWf.ValidateBAM:0:1 exited with return code -1 which has not been declared as a valid return code. See 'continueOnReturnCode' runtime attribute for more details.; Check the content of stderr for potential additional information: /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/stderr.; Could not retrieve content: Could not read from /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/stderr: /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/stderr; [2020-07-14 05:09:46,38] [info] WorkflowManagerActor WorkflowActor-968be82c-eef3-4bdb-a1ab-3d4e2ca70674 is in a terminal state: WorkflowFailedState; [2020-07-14 05:09:51,97] [info] SingleWorkflowRunnerActor workflow finished with status 'Failed'.; [2020-07-14 05:09:55,28] [info] Workflow polling stopped; [2020-07-14 05:09:55,30] [info] 0 workflows released by cromid-ca5c695; [2020-07-14 05:09:55,30] [info] Shutting down WorkflowStoreActor - Timeout = 5 seconds; [2020-07-14 05:09:55,30] [info] Shutting down WorkflowLogCopyRouter - Timeout = 5 seconds; [2020-07-14 05:09:55,30] [info] Shutting down JobExecutionTokenDispenser - Timeout = 5 seconds; [2020-07-14 05:09:55,31] [info] JobExecutionTokenDispenser stopped; [2020-07-14 05:09:55,31] [info] Aborting all running workflows.; [2020-07-14 05:09:55,31] [info] WorkflowStoreActor stopped; [2020-07-14 05:09:55,31] [info] WorkflowLogCopyRouter stopped; [2020-07-14 05:09:55,31] [info] Shutting down Workflow",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6710:7365,Validat,ValidateBamsWf,7365,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710,4,['Validat'],"['ValidateBAM', 'ValidateBamsWf']"
Security,"r log: ; gsutil cat gs://broad-jg-dev-cromwell-execution/JointGenotyping/6918095f-ca06-4883-bcb5-f5c2e343bb6d/call-ImportGVCFs/shard-0/ImportGVCFs-0-stderr.log. Using GATK jar /usr/gitc/gatk-package-4.beta.6-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -Xmx4g -Xms4g -jar /usr/gitc/gatk-package-4.beta.6-local.jar GenomicsDBImport --genomicsDBWorkspace genomicsdb --batchSize 50 -L chr1:1-391754 --sampleNameMap /cromwell_root/broad-jg-dev-storage/freimer_dutch_fin_wgs_v1/v1/sample_map --readerThreads 5 -ip 500; Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/cromwell_root/tmp.H9t5pC; [December 14, 2017 7:41:30 PM UTC] GenomicsDBImport --genomicsDBWorkspace genomicsdb --batchSize 50 --sampleNameMap /cromwell_root/broad-jg-dev-storage/freimer_dutch_fin_wgs_v1/v1/sample_map --readerThreads 5 --intervals chr1:1-391754 --interval_padding 500 --genomicsDBSegmentSize 1048576 --genomicsDBVCFBufferSize 16384 --overwriteExistingGenomicsDBWorkspace false --consolidate false --validateSampleNameMap false --interval_set_rule UNION --interval_exclusion_padding 0 --interval_merging_rule ALL --readValidationStringency SILENT --secondsBetweenProgressUpdates 10.0 --disableSequenceDictionaryValidation false --createOutputBamIndex true --createOutputBamMD5 false --createOutputVariantIndex true --createOutputVariantMD5 false --lenient false --addOutputSAMProgramRecord true --addOutputVCFCommandLine true --cloudPrefetchBuffer 0 --cloudIndexPrefetchBuffer 0 --disableBamIndexCaching false --help false --version false --showHidden false --verbosity INFO --QUIET false --use_jdk_deflater false --use_jdk_inflater false --gcs_max_retries 20 --disableToolDefaultReadFilters false; [December 14, 2017 7:41:30 PM UTC] Executing as root@7ca892f01ff3 on Linux 4.9.0-0.bpo.3-amd64 amd64; OpenJDK 64-Bit Server VM 1.8.0_111-8u111-b14-2~bpo8+1-b14; Version: 4.beta.6; [December 14, ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3979:1550,validat,validateSampleNameMap,1550,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3979,1,['validat'],['validateSampleNameMap']
Security,r the second pass.; 44	GetPileupSummaries	beta; helper tool for CalculateContamination	6/5/2017	https://github.com/broadinstitute/gatk-protected/blob/2bf35790393332da5414b42ec6dca813fcc63202/src/main/java/org/broadinstitute/hellbender/tools/walkers/contamination/GetPileupSummaries.java	scripts/mutect2_wdl/mutect2.wdl	https://github.com/broadinstitute/gatk/pull/3006	yes	; 33	AnnotateVcfWithBamDepth	internal (DB)	5/30	https://github.com/broadinstitute/gatk-protected/blob/e6278def94038d76339d0fd95ce2badb3bc44a22/src/main/java/org/broadinstitute/hellbender/tools/walkers/validation/AnnotateVcfWithBamDepth.java	scripts/mutect2_wdl/unsupported/hapmap_sensitivity_truth.wdl	https://github.com/broadinstitute/gatk-protected/pull/1131	yes	; 34	AnnotateVcfWithExpectedAlleleFraction	internal (DB)	5/30	https://github.com/broadinstitute/gatk-protected/blob/e6278def94038d76339d0fd95ce2badb3bc44a22/src/main/java/org/broadinstitute/hellbender/tools/walkers/validation/AnnotateVcfWithExpectedAlleleFraction.java	scripts/mutect2_wdl/unsupported/hapmap_sensitivity_truth.wdl	https://github.com/broadinstitute/gatk-protected/pull/1131	yes	; 37	CalculateMixingFractions	internal (DB)	5/30	https://github.com/broadinstitute/gatk-protected/blob/e6278def94038d76339d0fd95ce2badb3bc44a22/src/main/java/org/broadinstitute/hellbender/tools/walkers/validation/CalculateMixingFractions.java	scripts/mutect2_wdl/unsupported/hapmap_sensitivity_truth.wdl	https://github.com/broadinstitute/gatk-protected/pull/1131	yes	; 47	RemoveNearbyIndels	internal (DB)	5/30	https://github.com/broadinstitute/gatk-protected/blob/e6278def94038d76339d0fd95ce2badb3bc44a22/src/main/java/org/broadinstitute/hellbender/tools/walkers/validation/RemoveNearbyIndels.java	scripts/mutect2_wdl/unsupported/hapmap_sensitivity_truth.wdl	https://github.com/broadinstitute/gatk-protected/pull/1131	yes		; ```. This is also at <https://docs.google.com/a/broadinstitute.org/spreadsheets/d/15xviLwYUjU82MtYwxxPINiJAkovmaHpRGhqkghiEATQ/edit?usp=sharing>.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3055:13456,validat,validation,13456,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3055,2,['validat'],['validation']
Security,"r-mixed-ploidy-samples/p1); ----------; I'm attempting to call variants on whole genomes for about 500 illumina paired-end samples with varying ploidy (haploid to tetraploid). I'm running a fairly standard uBam to GVCF pipeline with HaplotypeCaller passed the ploidy information (1,2,3, or 4) in -ERC GVCF mode. I then try to collect the GVCFs using GenomicsDBImport in a batch size of 50 and use GenotypeGVCFs on the combined database. My interval list that is passed to GenomicsDBImport is just each chromosome on a separate line. I'm using GATK v4.1.1.0<br />; <br />; Command:<br />; ```<br />; ${GATK_DIR}/gatk GenomicsDBImport \<br />; --java-options ""-Xmx110g -Xms110g"" \<br />; -R ${REF} \<br />; --variant ${FILE_LIST} \<br />; -L ${SCRIPT_DIR}/GATK_Style_Interval.list \<br />; --genomicsdb-workspace-path ${WORK_DIR}/GenomicsDB_20190912 \<br />; --batch-size 50 \<br />; --tmp-dir=${WORK_DIR}/<br />; ```<br />; <br />; GenomicsDBImport appears to run without error, but only shows progress for the first 6000 bp before moving onto the next batch. When I run select variants on the created database, I only get variants up to position 6716 in the first interval. When I try to run GenotypeGVCF on it, I get a strange error:<br />; htsjdk.tribble.TribbleException: Invalid block size -1570639203<br />; <br />; My first assumption is that one of the gvcf's is malformed from HaplotypeCaller failing after the first 6000 bp, but I've verified that the gvcfs have all completed and have 'validated' them with ValidateVariants using GATK v4.1.3.0. When I grep for the particular position in the sample's gvcfs I don't find anything out of the ordinary. I would use CombineGVCFs, but it fails due to trying to combine mixed ploidies. <br />; <br />; Any ideas on troubleshooting or experience with problems like this?. This Issue was generated from your [forums] ; [forums]: https://gatkforums.broadinstitute.org/gatk/discussion/24446/genomicsdbimport-not-completing-for-mixed-ploidy-samples/p1",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6275:4509,validat,validated,4509,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6275,2,"['Validat', 'validat']","['ValidateVariants', 'validated']"
Security,"r.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.yarn.ApplicationMaster$$anon$4.run(ApplicationMaster.scala:721) ; ```. When I specify input as: `hdfs:///user/hadoop/gatk/common/human_g1k_v37.20.21.fasta`, the tool tries to access `hdfs://cromwellhadooptest:-1/user/hadoop/gatk/common/human_g1k_v37.20.21.fasta`. **Stack trace for this:**; ```; java.lang.IllegalArgumentException: Wrong FS: hdfs://cromwellhadooptest:-1/user/hadoop/gatk/common/human_g1k_v37.20.21.fasta, expected: hdfs://cromwellhadooptest; at org.apache.hadoop.fs.FileSystem.checkPath(FileSystem.java:776); at org.apache.hadoop.hdfs.DistributedFileSystem.getPathName(DistributedFileSystem.java:247); at org.apache.hadoop.hdfs.DistributedFileSystem$29.doCall(DistributedFileSystem.java:1725); at org.apache.hadoop.hdfs.DistributedFileSystem$29.doCall(DistributedFileSystem.java:1722); at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81); at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1737); at org.apache.hadoop.fs.FileSystem.exists(FileSystem.java:1729); at hdfs.jsr203.HadoopFileSystem.checkAccess(HadoopFileSystem.java:937); at hdfs.jsr203.HadoopFileSystemProvider.checkAccess(HadoopFileSystemProvider",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6730:4906,access,access,4906,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6730,1,['access'],['access']
Security,"r.engine.GATKTool.doWork(GATKTool.java:966); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); 	at org.broadinstitute.hellbender.Main.main(Main.java:289); ```; The second case included the following `--alleles` input:; ```; 22	16464044	rs571268158	CCAGGTCT	C; 22	16464051	rs569099729	T	C; ```; and it crashed similarly, with:; ```; java.lang.IllegalStateException: Allele in genotype CCAGGTCT* not in the variant context [T*, *, C]; 	at htsjdk.variant.variantcontext.VariantContext.validateGenotypes(VariantContext.java:1360); 	at htsjdk.variant.variantcontext.VariantContext.validate(VariantContext.java:1298); 	at htsjdk.variant.variantcontext.VariantContext.<init>(VariantContext.java:401); 	at htsjdk.variant.variantcontext.VariantContextBuilder.make(VariantContextBuilder.java:494); 	at htsjdk.variant.variantcontext.VariantContextBuilder.make(VariantContextBuilder.java:488); 	at org.broadinstitute.hellbender.utils.variant.GATKVariantContextUtils.simpleMerge(GATKVariantContextUtils.java:864); 	at org.broadinstitute.hellbender.utils.variant.GATKVariantContextUtils.simpleMerge(GATKVariantContextUtils.java:646); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.AssemblyBasedCallerUtils.makeMergedVariantContext(AssemblyBasedCallerUtils.java:221); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerGenotypingEngine.assignGenotypeLikelihoods(HaplotypeCallerGenotypingEngine.java:150); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerEngine.callRegion(HaplotypeCallerEngine.java:599); 	at org.broadinstitute.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5337:2942,validat,validate,2942,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5337,1,['validat'],['validate']
Security,"r.java:617); 	at java.lang.Thread.run(Thread.java:748). I don't understand why if the command is the same:; ```; $GATK_PATH BwaAndMarkDuplicatesPipelineSpark --bam-partition-size 64000000 or 4000000 \; --input hdfs://namenode:8020/$dir_prepro$ubam \; --reference hdfs://namenode:8020/hg19-ucsc/ucsc.hg19.2bit \; --bwa-mem-index-image /reference_image/ucsc.hg19.fasta.img \; --disable-sequence-dictionary-validation true \; --output hdfs://namenode:8020/$dir_prepro$output -- \; --spark-runner SPARK --spark-master spark://$SPARK_MASTER_HOST:7077 \; --driver-memory 20g --executor-cores 4 --executor-memory 8g; ```. Furthermore I have this problem with this version v4.0.4.0-23-g6e1cc8c-SNAPSHOT. > mark duplicate records objects corresponding to read with name, this could be the result of readnames spanning more than one partition; 	at org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSpark.lambda$null$0(MarkDuplicatesSpark.java:109); 	at java.util.HashMap.merge(HashMap.java:1253); 	at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1320); 	at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 	at org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSpark.lambda$mark$62928560$1(MarkDuplicatesSpark.java:109); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$10$1.apply(JavaRDDLike.scala:319); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$10$1.apply(",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4820:7101,Hash,HashMap,7101,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4820,1,['Hash'],['HashMap']
Security,r20_2444518_2637800.RNAseq.IMPROPER_PAIR.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/rnaseq/ASEReadCounter/NA12878.chr20_2444518_2637800.RNAseq.MultiContext.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/rnaseq/ASEReadCounter/NA12878.chr20_2444518_2637800.RNAseq.NON_REF.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/rnaseq/ASEReadCounter/NA12878.chr20_2444518_2637800.RNAseq.SYNONYMOUS_CODING.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/rnaseq/ASEReadCounter/NA12878.chr20_2444518_2637800.RNAseq.warnings.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/UnmarkDuplicates/allDuplicates.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/complexEvents_incompatibleDict.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/complexEvents_lexDict.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/complexEvents.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/gvcf.basepairResolution.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet_BAD_INCOMPLETE_REGION.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet.BAD_MISSING_NON_REF.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet.missingrefblock.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleBad3.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleBad.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validation,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3905:60421,Validat,ValidateVariants,60421,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905,1,['Validat'],['ValidateVariants']
Security,r: IntelDeflater; 13:19:28.985 INFO PathSeqPipelineSpark - Inflater: IntelInflater; 13:19:28.985 INFO PathSeqPipelineSpark - GCS max retries/reopens: 20; 13:19:28.985 INFO PathSeqPipelineSpark - Requester pays: disabled; 13:19:28.985 INFO PathSeqPipelineSpark - Initializing engine; 13:19:28.985 INFO PathSeqPipelineSpark - Done initializing engine; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; 23/05/23 13:19:29 INFO SparkContext: Running Spark version 2.4.5; 23/05/23 13:19:29 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 23/05/23 13:19:29 INFO SparkContext: Submitted application: PathSeqPipelineSpark; 23/05/23 13:19:29 INFO SecurityManager: Changing view acls to: singlecellproject; 23/05/23 13:19:29 INFO SecurityManager: Changing modify acls to: singlecellproject; 23/05/23 13:19:29 INFO SecurityManager: Changing view acls groups to: ; 23/05/23 13:19:29 INFO SecurityManager: Changing modify acls groups to: ; 23/05/23 13:19:29 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(singlecellproject); groups with view permissions: Set(); users with modify permissions: Set(singlecellproject); groups with modify permissions: Set(); 23/05/23 13:19:29 INFO Utils: Successfully started service 'sparkDriver' on port 40471.; 23/05/23 13:19:29 INFO SparkEnv: Registering MapOutputTracker; 23/05/23 13:19:29 INFO SparkEnv: Registering BlockManagerMaster; 23/05/23 13:19:29 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information; 23/05/23 13:19:29 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up; 23/05/23 13:19:29 INFO DiskBlockManager: Created local directory at pathseq/tmp/blockmgr-11fec4b1-0808-4f7e-9ab9-a87799853aee; 23/05/23 13:19:29 INFO MemoryStore: MemoryStore started with capacity 399.8 GB; 23/05/23 13:19:29 INFO SparkEnv: Regis,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8339:3771,Secur,SecurityManager,3771,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8339,7,"['Secur', 'authenticat']","['SecurityManager', 'authentication']"
Security,"rageRpc.translate(HttpStorageRpc.java:189); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.get(HttpStorageRpc.java:335); 	at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:191); 	at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:188); 	at shaded.cloud_nio.com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:94); 	at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:54); 	at com.google.cloud.storage.StorageImpl.get(StorageImpl.java:188); 	at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.checkAccess(CloudStorageFileSystemProvider.java:614); 	... 15 more; Caused by: shaded.cloud_nio.com.google.api.client.googleapis.json.GoogleJsonResponseException: 403 Forbidden; {; ""code"" : 403,; ""errors"" : [ {; ""domain"" : ""global"",; ""message"" : ""443301511749-compute@developer.gserviceaccount.com does not have storage.objects.get access to fc-50c768b1-a285-4c95-8d8c-8ce209f1fda8/744139c5-3371-4a67-a2c8-e054e46f814f/ReblockGVCF/601ea396-b6cf-4baa-95c7-83e88b92c194/call-GenotypeGVCF/09C97227.c9cd4496-b4ed-4686-babd-177c66168178.vcf.gz.tbi."",; ""reason"" : ""forbidden""; } ],; ""message"" : ""443301511749-compute@developer.gserviceaccount.com does not have storage.objects.get access to fc-50c768b1-a285-4c95-8d8c-8ce209f1fda8/744139c5-3371-4a67-a2c8-e054e46f814f/ReblockGVCF/601ea396-b6cf-4baa-95c7-83e88b92c194/call-GenotypeGVCF/09C97227.c9cd4496-b4ed-4686-babd-177c66168178.vcf.gz.tbi.""; }; 	at shaded.cloud_nio.com.google.api.client.googleapis.json.GoogleJsonResponseException.from(GoogleJsonResponseException.java:145); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:113); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:40); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.A",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4592:3802,access,access,3802,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4592,1,['access'],['access']
Security,"raversal; 00:05:57.036 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 00:07:26.967 WARN ReferenceConfidenceVariantContextMerger - Detected invalid annotations: When trying to merge variant contexts at location chr16:10185 the annotation AS_VarDP=59|115|0 was not a numerical value and was ignored; 00:07:26.967 WARN ReferenceConfidenceVariantContextMerger - Reducible annotation 'AS_VarDP' detected, add -G StandardAnnotation -G AS_StandardAnnotation to the command to annotate in the final VC with this annotation.; 00:07:26.991 INFO GenotypeGVCFs - Shutting down engine; GENOMICSDB_TIMER,GenomicsDB iterator next() timer,Wall-clock time(s),0.02938786500000001,Cpu time(s),0.029037034000000003; [August 25, 2021 12:07:27 AM EDT] org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs done. Elapsed time: 1.55 minutes.; Runtime.totalMemory()=1807745024; java.lang.NullPointerException; at java.util.HashMap.putMapEntries(HashMap.java:500); at java.util.HashMap.putAll(HashMap.java:784); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorEngine.combineAnnotations(VariantAnnotatorEngine.java:211); at org.broadinstitute.hellbender.tools.walkers.ReferenceConfidenceVariantContextMerger.mergeAttributes(ReferenceConfidenceVariantContextMerger.java:318); at org.broadinstitute.hellbender.tools.walkers.ReferenceConfidenceVariantContextMerger.merge(ReferenceConfidenceVariantContextMerger.java:142); at org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFsEngine.callRegion(GenotypeGVCFsEngine.java:130); at org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs.apply(GenotypeGVCFs.java:281); at org.broadinstitute.hellbender.engine.VariantLocusWalker.lambda$traverse$0(VariantLocusWalker.java:135); at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175);",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7437:8087,Hash,HashMap,8087,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7437,1,['Hash'],['HashMap']
Security,"rd-0:delegated \; broadinstitute/gatk@sha256:18146e79d06787483310e5de666502090a480e10ac0fad06a36a5e7a5c9bb1dc /cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/script. # get the return code (working even if the container was detached); rc=$(docker wait cat /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/docker_cid). # remove the container after waiting; docker rm cat /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/docker_cid. # return exit code; exit $rc; [2020-07-14 05:09:45,29] [info] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: job id: 243; [2020-07-14 05:09:45,29] [info] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: Status change from - to Done; [2020-07-14 05:09:46,38] [info] WorkflowManagerActor Workflow 968be82c-eef3-4bdb-a1ab-3d4e2ca70674 failed (during ExecutingWorkflowState): Job ValidateBamsWf.ValidateBAM:0:1 exited with return code -1 which has not been declared as a valid return code. See 'continueOnReturnCode' runtime attribute for more details.; Check the content of stderr for potential additional information: /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/stderr.; Could not retrieve content: Could not read from /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/stderr: /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/stderr; [2020-07-14 05:09:46,38] [info] WorkflowManagerActor WorkflowActor-968be82c-eef3-4bdb-a1ab-3d4e2ca70674 is in a terminal state: WorkflowFailedState; [2020-07-14 05:09:51,97] [info] SingleWorkflowRunnerActor workflow fi",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6710:6710,Validat,ValidateBAM,6710,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710,2,['Validat'],"['ValidateBAM', 'ValidateBamsWf']"
Security,reading CRAM on Spark needs a way to relax validation stringency,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1261:43,validat,validation,43,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1261,1,['validat'],['validation']
Security,"rect.github.com/protocolbuffers/protobuf/issues/18375"">#18375</a>)</li>; <li><a href=""https://github.com/protocolbuffers/protobuf/commit/8a60b6527a976cfd0028153da3ad8e4ed280e0de""><code>8a60b65</code></a> Merge pull request <a href=""https://redirect.github.com/protocolbuffers/protobuf/issues/17704"">#17704</a> from protocolbuffers/cp-segv</li>; <li><a href=""https://github.com/protocolbuffers/protobuf/commit/94a26630e362a4771b5ec80eac49f494988ca408""><code>94a2663</code></a> Fixed a SEGV when deep copying a non-reified sub-message.</li>; <li>Additional commits viewable in <a href=""https://github.com/protocolbuffers/protobuf/compare/v3.23.4...v3.25.5"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=com.google.protobuf:protobuf-java&package-manager=gradle&previous-version=3.23.4&new-version=3.25.5)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/9004:2712,secur,security-vulnerabilities,2712,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/9004,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,reduced memory consumption: identified by profiling HC. ; - added a bunch of tests while I was there. note: the equals/hashcode changes are just for clean code - no perf improvements. @lbergelson can you have a look?,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1892:119,hash,hashcode,119,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1892,1,['hash'],['hashcode']
Security,remove BAQ from BQSR (and validate results),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1557:26,validat,validate,26,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1557,1,['validat'],['validate']
Security,"rencePipeline.java:175); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); 	at org.broadinstitute.hellbender.engine.VariantWalkerBase.traverse(VariantWalkerBase.java:107); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:994); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:135); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:180); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:199); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); 	at org.broadinstitute.hellbender.Main.main(Main.java:289). I don't really know how to fix it. ValidateVariants gives no errors, and I am able to perform variant selection, e.g.:. gatk-4.0.5.1/gatk SelectVariants -R data/genome.fasta -V variants/6753_12-15-2015_first_pass_raw.vcf -select 'vc.getGenotype(""6753_12-15-2015"").getAD().1/vc.getGenotype(""6753_12-15-2015"").getDP() > 0.9 ' -output variants/6753_12-15-2015_first_pass_filtered.vcf. with no problems. Insights would be gratefully appreciated.; Thanks!; Gavin. This Issue was generated from your [forums] ; [forums]: https://gatkforums.broadinstitute.org/gatk/discussion/12223/java-lang-numberformatexception-when-trying-to-perform-variantfiltration/p1",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4921:7443,Validat,ValidateVariants,7443,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4921,1,['Validat'],['ValidateVariants']
Security,resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet.BAD_MISSING_NON_REF.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet.missingrefblock.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleBad3.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleBad.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleGood.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleRSIDonPositionNotInDBSNP.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationUnusedAllelesBugFix.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/validation/basicshortmutpileup/IS3.snv.indel.sv-vs-G15512.prenormal.sorted.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/validation/basicshortmutpileup/synthetic.challenge.set1.tumor-vs-synthetic.challenge.set1.normal-filtered.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/CalculateGenotypePosteriors/CEUtriMixedPloidyTest.vcf; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/CalculateGenotypePosteriors/CEUtrioPopPriorsTest_chr1.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/CalculateGenotypePosteriors/CEUtrioTest_chr1.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/CalculateGenotypePosteriors/expectedCGP_testFamilyPriors_chr1.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/CalculateGenotypePosteriors/expectedCGP_testFamilyPriors.vcf; src/test/resources/org/broadinstitute,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3905:61737,validat,validation,61737,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905,1,['validat'],['validation']
Security,rhaps it would be wise to specify the workflow in which this tool would be used. Something for the second pass.; 44	GetPileupSummaries	beta; helper tool for CalculateContamination	6/5/2017	https://github.com/broadinstitute/gatk-protected/blob/2bf35790393332da5414b42ec6dca813fcc63202/src/main/java/org/broadinstitute/hellbender/tools/walkers/contamination/GetPileupSummaries.java	scripts/mutect2_wdl/mutect2.wdl	https://github.com/broadinstitute/gatk/pull/3006	yes	; 33	AnnotateVcfWithBamDepth	internal (DB)	5/30	https://github.com/broadinstitute/gatk-protected/blob/e6278def94038d76339d0fd95ce2badb3bc44a22/src/main/java/org/broadinstitute/hellbender/tools/walkers/validation/AnnotateVcfWithBamDepth.java	scripts/mutect2_wdl/unsupported/hapmap_sensitivity_truth.wdl	https://github.com/broadinstitute/gatk-protected/pull/1131	yes	; 34	AnnotateVcfWithExpectedAlleleFraction	internal (DB)	5/30	https://github.com/broadinstitute/gatk-protected/blob/e6278def94038d76339d0fd95ce2badb3bc44a22/src/main/java/org/broadinstitute/hellbender/tools/walkers/validation/AnnotateVcfWithExpectedAlleleFraction.java	scripts/mutect2_wdl/unsupported/hapmap_sensitivity_truth.wdl	https://github.com/broadinstitute/gatk-protected/pull/1131	yes	; 37	CalculateMixingFractions	internal (DB)	5/30	https://github.com/broadinstitute/gatk-protected/blob/e6278def94038d76339d0fd95ce2badb3bc44a22/src/main/java/org/broadinstitute/hellbender/tools/walkers/validation/CalculateMixingFractions.java	scripts/mutect2_wdl/unsupported/hapmap_sensitivity_truth.wdl	https://github.com/broadinstitute/gatk-protected/pull/1131	yes	; 47	RemoveNearbyIndels	internal (DB)	5/30	https://github.com/broadinstitute/gatk-protected/blob/e6278def94038d76339d0fd95ce2badb3bc44a22/src/main/java/org/broadinstitute/hellbender/tools/walkers/validation/RemoveNearbyIndels.java	scripts/mutect2_wdl/unsupported/hapmap_sensitivity_truth.wdl	https://github.com/broadinstitute/gatk-protected/pull/1131	yes		; ```. This is also at <https://docs.google.com/a/broad,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3055:13076,validat,validation,13076,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3055,1,['validat'],['validation']
Security,"riant src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleGood.vcf --doNotValidateFilteredRecords false --warnOnErrors false --interval_set_rule UNION --interval_padding 0 --interval_exclusion_padding 0 --readValidationStringency SILENT --secondsBetweenProgressUpdates 10.0 --disableSequenceDictionaryValidation false --createOutputBamIndex true --createOutputBamMD5 false --createOutputVariantIndex true --createOutputVariantMD5 false --lenient false --addOutputSAMProgramRecord true --cloudPrefetchBuffer 40 --cloudIndexPrefetchBuffer -1 --disableBamIndexCaching false --help false --version false --showHidden false --verbosity INFO --QUIET false --use_jdk_deflater false --use_jdk_inflater false --disableToolDefaultReadFilters false; [March 21, 2017 5:43:53 PM EDT] Executing as louisb@WMD2A-31E on Mac OS X 10.11.6 x86_64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_112-b16; Version: Version:4.alpha.2-189-g724fbd0-SNAPSHOT; 17:43:53.162 INFO ValidateVariants - Defaults.BUFFER_SIZE : 131072; 17:43:53.162 INFO ValidateVariants - Defaults.COMPRESSION_LEVEL : 1; 17:43:53.162 INFO ValidateVariants - Defaults.CREATE_INDEX : false; 17:43:53.163 INFO ValidateVariants - Defaults.CREATE_MD5 : false; 17:43:53.163 INFO ValidateVariants - Defaults.CUSTOM_READER_FACTORY :; 17:43:53.163 INFO ValidateVariants - Defaults.EBI_REFERENCE_SERVICE_URL_MASK : http://www.ebi.ac.uk/ena/cram/md5/%s; 17:43:53.163 INFO ValidateVariants - Defaults.NON_ZERO_BUFFER_SIZE : 131072; 17:43:53.163 INFO ValidateVariants - Defaults.REFERENCE_FASTA : null; 17:43:53.163 INFO ValidateVariants - Defaults.SAM_FLAG_FIELD_FORMAT : DECIMAL; 17:43:53.163 INFO ValidateVariants - Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 17:43:53.163 INFO ValidateVariants - Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 17:43:53.163 INFO ValidateVariants - Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 17:43:53.163 INFO ValidateVariants - Defaults.USE_CRAM_REF_DOWNLOAD : false; 17:43:53",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2509:1979,Validat,ValidateVariants,1979,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2509,1,['Validat'],['ValidateVariants']
Security,"riants - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_45-b14; 19:53:34.607 INFO ValidateVariants - Start Date/Time: October 25, 2020 7:53:34 PM CDT; 19:53:34.607 INFO ValidateVariants - ------------------------------------------------------------; 19:53:34.607 INFO ValidateVariants - ------------------------------------------------------------; 19:53:34.607 INFO ValidateVariants - HTSJDK Version: 2.22.0; 19:53:34.607 INFO ValidateVariants - Picard Version: 2.22.8; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 19:53:34.608 INFO ValidateVariants - Deflater: IntelDeflater; 19:53:34.608 INFO ValidateVariants - Inflater: IntelInflater; 19:53:34.608 INFO ValidateVariants - GCS max retries/reopens: 20; 19:53:34.608 INFO ValidateVariants - Requester pays: disabled; 19:53:34.608 INFO ValidateVariants - Initializing engine; 19:53:35.169 INFO FeatureManager - Using codec VCFCodec to read file file://chr1-22.phased.rename.reheader.vcf.gz; 19:53:35.594 INFO ValidateVariants - Done initializing engine; 19:53:35.594 WARN ValidateVariants - IDS validation cannot be done because no DBSNP file was provided; 19:53:35.594 WARN ValidateVariants - Other possible validations will still be performed; 19:53:35.594 INFO ProgressMeter - Starting traversal; 19:53:35.595 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 19:53:35.660 INFO ValidateVariants - Shutting down engine; [October 25, 2020 7:53:35 PM CDT] org.broadinstitute.hellbender.tools.walkers.variantutils.ValidateVariants done. Elapsed time: 0.02 minutes.; Runtime.totalMemory()=2114453504; java.lang.ArrayIndexOutOfBoundsException: -87; 	at org.broadinstitute.hellbender.utils.BaseUtil",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6911:2527,Validat,ValidateVariants,2527,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6911,1,['Validat'],['ValidateVariants']
Security,"riationDiscoveryPipelineSpark - BND_INV55: 230; 17:21:06.648 INFO StructuralVariationDiscoveryPipelineSpark - DEL: 4488; 17:21:06.648 INFO StructuralVariationDiscoveryPipelineSpark - DUP: 1355; 17:21:06.648 INFO StructuralVariationDiscoveryPipelineSpark - INS: 1675; 17:21:06.648 INFO StructuralVariationDiscoveryPipelineSpark - INV: 0; 17:21:06.648 INFO StructuralVariationDiscoveryPipelineSpark - DUP_INV: 0; 17:21:06.648 INFO StructuralVariationDiscoveryPipelineSpark - CPX: 0; 18/01/25 17:21:07 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 29.0 in stage 61.0 (TID 60915, cwhelan-hg00514-1-cram-samtools-bam-feature-w-1.c.broad-dsde-methods.internal, executor 48): java.lang.IllegalArgumentException: Unexpected CIGAR format with deletion neighboring clipping; cigar elements are: [1190M, 4D, 53M, 2I, 26M, 2I, 31M, 2D, 1450S]; 	at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:681); 	at org.broadinstitute.hellbender.tools.spark.sv.utils.SvCigarUtils.validateCigar(SvCigarUtils.java:134); 	at org.broadinstitute.hellbender.tools.spark.sv.utils.SvCigarUtils.getUnclippedReadLength(SvCigarUtils.java:161); 	at org.broadinstitute.hellbender.tools.spark.sv.utils.SvCigarUtils.computeAssociatedDistOnRead(SvCigarUtils.java:330); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.alignment.AlignmentInterval.readIntervalAlignedToRefSpan(AlignmentInterval.java:634); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.CpxVariantDetector.extractAltHaplotypeSeq(CpxVariantDetector.java:852); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.CpxVariantDetector.access$300(CpxVariantDetector.java:47); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.CpxVariantDetector$AnnotatedContig.annotate(CpxVariantDetector.java:194); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.CpxVariantDetector$AnnotatedContig.<init>(CpxVariantDetector.java:132); 	at org.broadinstitute.hellbender.tools.spa",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4260:5098,validat,validateCigar,5098,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4260,1,['validat'],['validateCigar']
Security,rker.DefaultWorkerProcess.waitForStop(DefaultWorkerProcess.java:190); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.process.internal.worker.DefaultWorkerProcessBuilder$MemoryRequestingWorkerProcess.waitForStop(DefaultWorkerProcessBuilder.java:228); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.testing.worker.ForkingTestClassProcessor.stop(ForkingTestClassProcessor.java:122); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.testing.processors.RestartEveryNTestClassProcessor.endBatch(RestartEveryNTestClassProcessor.java:63); 11:54:40.437 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.testing.processors.RestartEveryNTestClassProcessor.stop(RestartEveryNTestClassProcessor.java:57); 11:54:40.437 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35); 11:54:40.437 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 11:54:40.437 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.dispatch.FailureHandlingDispatch.dispatch(FailureHandlingDispatch.java:29); 11:54:40.437 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.dispatch.AsyncDispatch.dispatchMessages(AsyncDispatch.java:132); 11:54:40.437 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.dispatch.AsyncDispatch.access$000(AsyncDispatch.java:33); 11:54:40.437 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.dispatch.AsyncDispatch$1.run(AsyncDispatch.java:72); 11:54:40.437 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	... 2 more,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2802:15663,access,access,15663,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2802,1,['access'],['access']
Security,rnal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.taskgraph.AbstractTaskPlanExecutor$TaskExecutorWorker.run(AbstractTaskPlanExecutor.java:58); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.taskgraph.DefaultTaskPlanExecutor.process(DefaultTaskPlanExecutor.java:32); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.taskgraph.DefaultTaskGraphExecuter.execute(DefaultTaskGraphExecuter.java:113); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.SelectedTaskExecutionAction.execute(SelectedTaskExecutionAction.java:37); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.DefaultBuildExecuter.execute(DefaultBuildExecuter.java:37); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.DefaultBuildExecuter.access$000(DefaultBuildExecuter.java:23); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.DefaultBuildExecuter$1.proceed(DefaultBuildExecuter.java:43); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.DryRunBuildExecutionAction.execute(DryRunBuildExecutionAction.java:32); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.DefaultBuildExecuter.execute(DefaultBuildExecuter.java:37); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.DefaultBuildExecuter.execute(DefaultBuildExecuter.java:30); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.initialization.DefaultGradleLauncher$RunTasksAction.execute(DefaultGradleLauncher.java:230); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.initialization.DefaultGradleL,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2802:4980,access,access,4980,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2802,1,['access'],['access']
Security,"roadinstitute.hellbender.Main.runCommandLineProgram(Main.java:162); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:205); at org.broadinstitute.hellbender.Main.main(Main.java:291); Caused by: htsjdk.tribble.TribbleException$MalformedFeatureFile: Unable to parse header with error: Duplicate key 0, for input source: cadd.config; at htsjdk.tribble.TribbleIndexedFeatureReader.readHeader(TribbleIndexedFeatureReader.java:263); at htsjdk.tribble.TribbleIndexedFeatureReader.&lt;init&gt;(TribbleIndexedFeatureReader.java:102); at htsjdk.tribble.TribbleIndexedFeatureReader.&lt;init&gt;(TribbleIndexedFeatureReader.java:127); at htsjdk.tribble.AbstractFeatureReader.getFeatureReader(AbstractFeatureReader.java:120); at org.broadinstitute.hellbender.engine.FeatureDataSource.getTribbleFeatureReader(FeatureDataSource.java:350); ... 14 more; Caused by: java.lang.IllegalStateException: Duplicate key 0; at java.util.stream.Collectors.lambda$throwingMerger$0(Collectors.java:133); at java.util.HashMap.merge(HashMap.java:1254); at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1320); at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); at java.util.stream.IntPipeline$4$1.accept(IntPipeline.java:250); at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110); at java.util.Spliterator$OfInt.forEachRemaining(Spliterator.java:693); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:566); at org.broadinstitute.hellbender.utils.codecs.xsvLocatableTable.XsvLocatableTableCodec.readActualHeader(XsvLocatableTableCodec.java:341); at org.broadinstitute.hellbender.utils.codecs.xsvLocatableTable.XsvLocatableTableCodec",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6223:2732,Hash,HashMap,2732,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6223,1,['Hash'],['HashMap']
Security,roadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet.missingrefblock.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleBad3.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleBad.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleGood.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleRSIDonPositionNotInDBSNP.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationUnusedAllelesBugFix.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/validation/basicshortmutpileup/IS3.snv.indel.sv-vs-G15512.prenormal.sorted.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/validation/basicshortmutpileup/synthetic.challenge.set1.tumor-vs-synthetic.challenge.set1.normal-filtered.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/CalculateGenotypePosteriors/CEUtriMixedPloidyTest.vcf; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/CalculateGenotypePosteriors/CEUtrioPopPriorsTest_chr1.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/CalculateGenotypePosteriors/CEUtrioTest_chr1.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/CalculateGenotypePosteriors/expectedCGP_testFamilyPriors_chr1.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/CalculateGenotypePosteriors/expectedCGP_testFamilyPriors.vcf; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/CalculateGenotypePosteriors/expectedCGP_testSingleParentFamily_chr1.vcf.idx; src/test/resources/org/broadinstit,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3905:61884,validat,validation,61884,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905,1,['validat'],['validation']
Security,ror: scala.collection.Seq.aggregate(Ljava/lang/Object;Lscala/Function2;Lscala/Function2;)Ljava/lang/Object;; at org.bdgenomics.adam.models.NonoverlappingRegions.mergeRegions(NonoverlappingRegions.scala:75); at org.bdgenomics.adam.models.NonoverlappingRegions.<init>(NonoverlappingRegions.scala:55); at org.bdgenomics.adam.models.NonoverlappingRegions$.apply(NonoverlappingRegions.scala:169); at org.bdgenomics.adam.util.TwoBitRecord$.apply(TwoBitFile.scala:193); at org.bdgenomics.adam.util.TwoBitFile$$anonfun$6.apply(TwoBitFile.scala:70); at org.bdgenomics.adam.util.TwoBitFile$$anonfun$6.apply(TwoBitFile.scala:70); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.immutable.HashMap$HashMap1.foreach(HashMap.scala:221); at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428); at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428); at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); at scala.collection.AbstractTraversable.map(Traversable.scala:104); at org.bdgenomics.adam.util.TwoBitFile.<init>(TwoBitFile.scala:70); at org.broadinstitute.hellbender.engine.spark.datasources.ReferenceTwoBitSource.<init>(ReferenceTwoBitSource.java:43); at org.broadinstitute.hellbender.engine.datasources.ReferenceMultiSource.<init>(ReferenceMultiSource.java:41); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.initializeReference(GATKSparkTool.java:353); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.initializeToolInputs(GATKSparkTool.java:320); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:311); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:38); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:108); at org.broadinstitute.h,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2073:1245,Hash,HashMap,1245,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2073,1,['Hash'],['HashMap']
Security,"roxy: Connecting to ResourceManager at tele-1/192.168.1.4:8032; 18/01/09 18:30:57 INFO yarn.Client: Requesting a new application from cluster with 4 NodeManagers; 18/01/09 18:30:58 INFO yarn.Client: Verifying our application has not requested more than the maximum memory capability of the cluster (18432 MB per container); 18/01/09 18:30:58 INFO yarn.Client: Will allocate AM container, with 896 MB memory including 384 MB overhead; 18/01/09 18:30:58 INFO yarn.Client: Setting up container launch context for our AM; 18/01/09 18:30:58 INFO yarn.Client: Setting up the launch environment for our AM container; 18/01/09 18:30:58 INFO yarn.Client: Preparing resources for our AM container; 18/01/09 18:30:59 INFO yarn.Client: Uploading resource file:/tmp/sun/spark-5a3e539e-2e2b-4da2-b218-2bda166bd4c0/__spark_conf__7100950787185363106.zip -> hdfs://tele-1:8020/user/sun/.sparkStaging/application_1515493209401_0001/__spark_conf__.zip; 18/01/09 18:31:00 INFO spark.SecurityManager: Changing view acls to: sun; 18/01/09 18:31:00 INFO spark.SecurityManager: Changing modify acls to: sun; 18/01/09 18:31:00 INFO spark.SecurityManager: Changing view acls groups to: ; 18/01/09 18:31:00 INFO spark.SecurityManager: Changing modify acls groups to: ; 18/01/09 18:31:00 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(sun); groups with view permissions: Set(); users with modify permissions: Set(sun); groups with modify permissions: Set(); 18/01/09 18:31:00 INFO yarn.Client: Submitting application application_1515493209401_0001 to ResourceManager; 18/01/09 18:31:00 INFO impl.YarnClientImpl: Submitted application application_1515493209401_0001; 18/01/09 18:31:00 INFO cluster.SchedulerExtensionServices: Starting Yarn extension services with app application_1515493209401_0001 and attemptId None; 18/01/09 18:31:01 INFO yarn.Client: Application report for application_1515493209401_0001 (state: ACCEPTED); 18/01/09 18:31:01 INFO yarn",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4112:11797,Secur,SecurityManager,11797,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4112,1,['Secur'],['SecurityManager']
Security,"rror log looks like below. Exception in thread ""main"" java.lang.NoSuchMethodError: scala.collection.Seq.aggregate(Ljava/lang/Object;Lscala/Function2;Lscala/Function2;)Ljava/lang/Object;; at org.bdgenomics.adam.models.NonoverlappingRegions.mergeRegions(NonoverlappingRegions.scala:75); at org.bdgenomics.adam.models.NonoverlappingRegions.<init>(NonoverlappingRegions.scala:55); at org.bdgenomics.adam.models.NonoverlappingRegions$.apply(NonoverlappingRegions.scala:169); at org.bdgenomics.adam.util.TwoBitRecord$.apply(TwoBitFile.scala:193); at org.bdgenomics.adam.util.TwoBitFile$$anonfun$6.apply(TwoBitFile.scala:70); at org.bdgenomics.adam.util.TwoBitFile$$anonfun$6.apply(TwoBitFile.scala:70); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.immutable.HashMap$HashMap1.foreach(HashMap.scala:221); at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428); at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428); at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); at scala.collection.AbstractTraversable.map(Traversable.scala:104); at org.bdgenomics.adam.util.TwoBitFile.<init>(TwoBitFile.scala:70); at org.broadinstitute.hellbender.engine.spark.datasources.ReferenceTwoBitSource.<init>(ReferenceTwoBitSource.java:43); at org.broadinstitute.hellbender.engine.datasources.ReferenceMultiSource.<init>(ReferenceMultiSource.java:41); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.initializeReference(GATKSparkTool.java:353); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.initializeToolInputs(GATKSparkTool.java:320); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:311); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:38); at org.broadinstitute.hellbender.cmdline.Co",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2073:1167,Hash,HashMap,1167,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2073,1,['Hash'],['HashMap']
Security,running RevertBaseQualityScores from Version:4.alpha-70-g10d9ec1-SNAPSHOT on /seq/picard_aggregation/G77386/NA12878/v1/NA12878.bam. ```; java.lang.IllegalArgumentException: end must be >= start. start:13984870 end:13984869; at org.broadinstitute.hellbender.utils.SimpleInterval.validatePositions(SimpleInterval.java:61); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:33); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:45); at org.broadinstitute.hellbender.engine.ReadWalker.lambda$traverse$18(ReadWalker.java:79); at org.broadinstitute.hellbender.engine.ReadWalker$$Lambda$45/1492875057.accept(Unknown Source); at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183); at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); at java.util.Iterator.forEachRemaining(Iterator.java:116); at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:512); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:502); at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150); at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); at org.broadinstitute.hellbender.engine.ReadWalker.traverse(ReadWalker.java:78); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:448); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:98); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:146); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:165); ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1473:278,validat,validatePositions,278,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1473,1,['validat'],['validatePositions']
Security,"running wgs1 with current code in master, we get the following stack trace:. Caused by: java.lang.IllegalArgumentException: Invalid interval. Contig:chrUn_JTFH01001938v1_decoy start:0 end:0; 	at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:686); 	at org.broadinstitute.hellbender.utils.SimpleInterval.validatePositions(SimpleInterval.java:60); 	at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:36); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.NovelAdjacencyReferenceLocations$BreakpointsInference.getLeftJustifiedBreakpoints(NovelAdjacencyReferenceLocations.java:78); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.NovelAdjacencyReferenceLocations.leftJustifyBreakpoints(NovelAdjacencyReferenceLocations.java:293); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.NovelAdjacencyReferenceLocations.<init>(NovelAdjacencyReferenceLocations.java:42); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.DiscoverVariantsFromContigAlignmentsSAMSpark.lambda$discoverNovelAdjacencyFromChimericAlignments$7(DiscoverVariantsFromContigAlignmentsSAMSpark.java:409); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.ArrayList$ArrayListSpliterator.tryAdvance(ArrayList.java:1351); 	at java.util.stream.StreamSpliterators$WrappingSpliterator.lambda$initPartialTraversalState$0(StreamSpliterators.java:294); 	at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.fillBuffer(StreamSpliterators.java:206); 	at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.doAdvance(StreamSpliterators.java:161); 	at java.util.stream.StreamSpliterators$WrappingSpliterator.tryAdvance(StreamSpliterators.java:300); 	at java.util.Spliterators$1Adapter.hasNext(Spliterators.java:681); 	at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); 	at org.apache.spark.shuffle.sor",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3874:237,validat,validateArg,237,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3874,2,['validat'],"['validateArg', 'validatePositions']"
Security,"runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 19:53:34.606 INFO ValidateVariants - ------------------------------------------------------------; 19:53:34.606 INFO ValidateVariants - The Genome Analysis Toolkit (GATK) v4.1.8.0; 19:53:34.606 INFO ValidateVariants - For support and documentation go to https://software.broadinstitute.org/gatk/; 19:53:34.607 INFO ValidateVariants - Executing as zepengmu@midway2-login1.rcc.local on Linux v3.10.0-1127.8.2.el7.x86_64 amd64; 19:53:34.607 INFO ValidateVariants - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_45-b14; 19:53:34.607 INFO ValidateVariants - Start Date/Time: October 25, 2020 7:53:34 PM CDT; 19:53:34.607 INFO ValidateVariants - ------------------------------------------------------------; 19:53:34.607 INFO ValidateVariants - ------------------------------------------------------------; 19:53:34.607 INFO ValidateVariants - HTSJDK Version: 2.22.0; 19:53:34.607 INFO ValidateVariants - Picard Version: 2.22.8; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 19:53:34.608 INFO ValidateVariants - Deflater: IntelDeflater; 19:53:34.608 INFO ValidateVariants - Inflater: IntelInflater; 19:53:34.608 INFO ValidateVariants - GCS max retries/reopens: 20; 19:53:34.608 INFO ValidateVariants - Requester pays: disabled; 19:53:34.608 INFO ValidateVariants - Initializing engine; 19:53:35.169 INFO FeatureManager - Using codec VCFCodec to read file file://chr1-22.phased.rename.reheader.vcf.gz; 19:53:35.594 INFO ValidateVariants - Done initializing engine; 19:53:35.594 WARN ValidateVariants - IDS validation cannot be done because no DBSNP file was provided; 19:53:35.594 WARN Valida",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6911:1987,Validat,ValidateVariants,1987,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6911,1,['Validat'],['ValidateVariants']
Security,"rvice-account gatktestjenkins@broad-gatk-test.iam.gserviceaccount.com --key-file /scratch/testservice.json --project broad-gatk-test; ./gatk-launch MarkDuplicatesSpark \; --shardedOutput true \; -O /scratch/tmp.md.bam \; --numReducers 0 \; --apiKey $APIKEY \; -I $bamIn \; -- \; --sparkRunner GCS \; --driver-memory 8G \; --cluster $CLUSTERNAME \; --executor-cores 3 \; --executor-memory 25G \; --conf spark.yarn.executor.memoryOverhead=2500""; ```. Fails with:. ```; Exception in thread ""main"" java.lang.NoClassDefFoundError: org/apache/spark/Logging; at java.lang.ClassLoader.defineClass1(Native Method); at java.lang.ClassLoader.defineClass(ClassLoader.java:763); at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142); at java.net.URLClassLoader.defineClass(URLClassLoader.java:467); at java.net.URLClassLoader.access$100(URLClassLoader.java:73); at java.net.URLClassLoader$1.run(URLClassLoader.java:368); at java.net.URLClassLoader$1.run(URLClassLoader.java:362); at java.security.AccessController.doPrivileged(Native Method); at java.net.URLClassLoader.findClass(URLClassLoader.java:361); at java.lang.ClassLoader.loadClass(ClassLoader.java:424); at org.apache.spark.util.ChildFirstURLClassLoader.loadClass(MutableURLClassLoader.scala:52); at java.lang.ClassLoader.loadClass(ClassLoader.java:357); at org.bdgenomics.adam.serialization.ADAMKryoRegistrator.registerClasses(ADAMKryoRegistrator.scala:85); at org.broadinstitute.hellbender.engine.spark.GATKRegistrator.registerClasses(GATKRegistrator.java:74); at org.apache.spark.serializer.KryoSerializer$$anonfun$newKryo$6.apply(KryoSerializer.scala:125); at org.apache.spark.serializer.KryoSerializer$$anonfun$newKryo$6.apply(KryoSerializer.scala:125); at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186); at org.apache.spark.serializer.KryoSerializer.newKryo(KryoSerializer.scala:125); at org.apache.spark.serializer.KryoS",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2183:1123,secur,security,1123,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2183,1,['secur'],['security']
Security,"s - The Genome Analysis Toolkit (GATK) v4.1.8.0; 19:53:34.606 INFO ValidateVariants - For support and documentation go to https://software.broadinstitute.org/gatk/; 19:53:34.607 INFO ValidateVariants - Executing as zepengmu@midway2-login1.rcc.local on Linux v3.10.0-1127.8.2.el7.x86_64 amd64; 19:53:34.607 INFO ValidateVariants - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_45-b14; 19:53:34.607 INFO ValidateVariants - Start Date/Time: October 25, 2020 7:53:34 PM CDT; 19:53:34.607 INFO ValidateVariants - ------------------------------------------------------------; 19:53:34.607 INFO ValidateVariants - ------------------------------------------------------------; 19:53:34.607 INFO ValidateVariants - HTSJDK Version: 2.22.0; 19:53:34.607 INFO ValidateVariants - Picard Version: 2.22.8; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 19:53:34.608 INFO ValidateVariants - Deflater: IntelDeflater; 19:53:34.608 INFO ValidateVariants - Inflater: IntelInflater; 19:53:34.608 INFO ValidateVariants - GCS max retries/reopens: 20; 19:53:34.608 INFO ValidateVariants - Requester pays: disabled; 19:53:34.608 INFO ValidateVariants - Initializing engine; 19:53:35.169 INFO FeatureManager - Using codec VCFCodec to read file file://chr1-22.phased.rename.reheader.vcf.gz; 19:53:35.594 INFO ValidateVariants - Done initializing engine; 19:53:35.594 WARN ValidateVariants - IDS validation cannot be done because no DBSNP file was provided; 19:53:35.594 WARN ValidateVariants - Other possible validations will still be performed; 19:53:35.594 INFO ProgressMeter - Starting traversal; 19:53:35.595 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 19:53:35.6",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6911:2217,Validat,ValidateVariants,2217,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6911,1,['Validat'],['ValidateVariants']
Security,"s users pulling from all docker repos (regardless of the tier for the owner of the repository being pulled from). This might or might not affect us since it looks like travis is pulling from our GCR repo for builds but we should be mindful of workflows that might rely on pulling hundreds of docker images from docker-hub through anonymous web VMs:; ```; On Monday, November 2, 2020 at 9am Pacific Standard Time, Docker will begin enforcing rate limits on container pulls for Anonymous and Free users. Anonymous (unauthenticated) users will be limited to 100 container image pulls every six hours, and Free (authenticated) users will be limited to 200 container image pulls every six hours, when enforcement is fully implemented. Docker Pro and Team subscribers can pull container images from Docker Hub without restriction, as long as the quantities are not excessive or abusive.; In addition, we are pausing enforcement of the changes to our image-retention policies until mid-2021, when we anticipate incorporating them into usage-based pricing. Two months ago, we announced an update to Docker image-retention policies. As originally stated, this change, which was set to take effect on November 1, 2020, would result in the deletion of images for free Docker account users after six months of inactivity. Today's announcement means Docker will not enforce image expiration on November 1, 2020.; ```; This is farther clarified on their FAQ https://www.docker.com/pricing/resource-consumption-updates:; ```; Rate limits for Docker image pulls are based on the account type of the user requesting the image - not the account type of the image’s owner. These are defined on the pricing page.; The highest entitlement a user has, based on their personal account and any orgs they belong to, will be used. Unauthenticated pull requests are “anonymous” and will be rate limited based on IP address rather than user ID. For more information on authenticating image pulls, please see this docs page.; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6922:1998,authenticat,authenticating,1998,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6922,1,['authenticat'],['authenticating']
Security,"s) or class(es); _Tool/class name(s), special parameters?_. ### Affected version(s); - [x] Latest public release version 4.2.2.0. ### Description . Running apt-get inside docker image fails. #### Steps to reproduce. (base) fleharty@wm3b9-dfa docker % docker run -it broadinstitute/gatk:4.2.2.0; Unable to find image 'broadinstitute/gatk:4.2.2.0' locally; 4.2.2.0: Pulling from broadinstitute/gatk; a7fe112a8303: Already exists ; Digest: sha256:32175c3c7c1fb9f5bd6650183c9c5cf26fb822dddb0cad0123d48c33124b6065; Status: Downloaded newer image for broadinstitute/gatk:4.2.2.0; (gatk) root@bc90fdaf700c:/gatk# ; (gatk) root@bc90fdaf700c:/gatk# ; (gatk) root@bc90fdaf700c:/gatk# apt-get update; Get:1 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]; Get:2 http://archive.ubuntu.com/ubuntu bionic InRelease [242 kB] ; Get:3 http://security.ubuntu.com/ubuntu bionic-security/multiverse amd64 Packages [26.7 kB] ; Get:4 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [543 kB] ; Get:5 http://packages.cloud.google.com/apt cloud-sdk-bionic InRelease [6786 B] ; Get:6 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1426 kB] ; Err:5 http://packages.cloud.google.com/apt cloud-sdk-bionic InRelease ; The following signatures couldn't be verified because the public key is not available: NO_PUBKEY FEEA9169307EA071 NO_PUBKEY 8B57C5C2836F4BEB; Get:7 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2295 kB] ; Get:8 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB] ; Get:9 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB] ; Get:10 http://archive.ubuntu.com/ubuntu bionic/restricted amd64 Packages [13.5 kB] ; Get:11 http://archive.ubuntu.com/ubuntu bionic/multiverse amd64 Packages [186 kB]; Get:12 http://archive.ubuntu.com/ubuntu bionic/universe amd64 Packages [11.3 MB] ; Get:13 http://archive.ubuntu.com/ubuntu bionic/main amd64 Packages [1344 kB] ; Get:14 http://archiv",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7447:1008,secur,security,1008,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7447,1,['secur'],['security']
Security,s.java:183) ; at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195) ; at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195) ; at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1655) ; at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484) ; at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474) ; at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150) ; at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173) ; at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234) ; at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:497) ; at org.broadinstitute.hellbender.tools.funcotator.FilterFuncotations.lambda$getMatchingFilters$2(FilterFuncotations.java:192) ; at java.base/java.util.HashMap$Values.forEach(HashMap.java:976) ; at org.broadinstitute.hellbender.tools.funcotator.FilterFuncotations.getMatchingFilters(FilterFuncotations.java:191) ; at org.broadinstitute.hellbender.tools.funcotator.FilterFuncotations.secondPassApply(FilterFuncotations.java:174) ; at org.broadinstitute.hellbender.engine.TwoPassVariantWalker.nthPassApply(TwoPassVariantWalker.java:19) ; at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverse$0(MultiplePassVariantWalker.java:40) ; at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverseVariants$1(MultiplePassVariantWalker.java:77) ; at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183) ; at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:177) ; at java.base/java.util.Iterator.forEachRemaining(Iterator.java:133) ; at java.base/java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801) ; at java.base/java.util.stream.AbstractPipeli,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7504:5843,Hash,HashMap,5843,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7504,1,['Hash'],['HashMap']
Security,s/org/broadinstitute/hellbender/tools/walkers/rnaseq/ASEReadCounter/NA12878.chr20_2444518_2637800.RNAseq.SYNONYMOUS_CODING.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/rnaseq/ASEReadCounter/NA12878.chr20_2444518_2637800.RNAseq.warnings.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/UnmarkDuplicates/allDuplicates.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/complexEvents_incompatibleDict.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/complexEvents_lexDict.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/complexEvents.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/gvcf.basepairResolution.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet_BAD_INCOMPLETE_REGION.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet.BAD_MISSING_NON_REF.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet.missingrefblock.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleBad3.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleBad.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleGood.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleRSIDonPositionNotInDBSNP.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationUnusedAllelesBugFix.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/validation/basic,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3905:60774,Validat,ValidateVariants,60774,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905,1,['Validat'],['ValidateVariants']
Security,"scala:893); at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); at org.apache.spark.storage.BlockManager.reportAllBlocks(BlockManager.scala:217); at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:236); at org.apache.spark.executor.Executor.org$apache$spark$executor$Executor$$reportHeartBeat(Executor.scala:522); at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply$mcV$sp(Executor.scala:547); at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply(Executor.scala:547); at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply(Executor.scala:547); at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1953); at org.apache.spark.executor.Executor$$anon$1.run(Executor.scala:547); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308); at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180); at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); 18/03/09 09:22:08 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 18/03/09 09:22:08 INFO SparkContext: Successfully stopped SparkContext; 09:22:08.389 INFO BaseRecalibratorSpark - Shutting down engine; [March 9, 2018 9:22:08 AM UTC] org.broadinstitute.hellbender.tools.spark.BaseRecalibratorSpark done. Elapsed time: 61.53 minutes.; Runtime.totalMemory()=16815489024; org.apache.spark.SparkException: Job aborted due to stage failure: Task 8 in stage 0.0 failed 1 times, most recent failure: Lost task 8.0 in stage 0.0 (TID 8, localhost): ExecutorLostFailure (executor driver exited caused by one ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4515:2107,access,access,2107,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4515,1,['access'],['access']
Security,"se reference name = *.; at htsjdk.samtools.SAMUtils.processValidationErrors(SAMUtils.java:439); at htsjdk.samtools.BAMFileReader$BAMFileIterator.advance(BAMFileReader.java:643); at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:628); at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:598); at htsjdk.samtools.SamReader$AssertingIterator.next(SamReader.java:544); at htsjdk.samtools.SamReader$AssertingIterator.next(SamReader.java:518); at htsjdk.samtools.util.PeekIterator.peek(PeekIterator.java:67); at htsjdk.samtools.SecondaryOrSupplementarySkippingIterator.skipAnyNotprimary(SecondaryOrSupplementarySkippingIterator.java:36); at htsjdk.samtools.SecondaryOrSupplementarySkippingIterator.advance(SecondaryOrSupplementarySkippingIterator.java:31); at org.broadinstitute.hellbender.utils.read.SamComparison.compareCoordinateSortedAlignments(SamComparison.java:111); at org.broadinstitute.hellbender.utils.read.SamComparison.compareAlignments(SamComparison.java:68); at org.broadinstitute.hellbender.utils.read.SamComparison.<init>(SamComparison.java:44); at org.broadinstitute.hellbender.tools.picard.sam.CompareSAMs.doWork(CompareSAMs.java:34); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:94); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:144); at org.broadinstitute.hellbender.cmdline.PicardCommandLineProgram.instanceMain(PicardCommandLineProgram.java:51); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:77); at org.broadinstitute.hellbender.Main.main(Main.java:92); ```. Same command on original picard passes validation (though claims the bam is different from itself: https://github.com/broadinstitute/picard/issues/160). Note to whoever fixes this: once this is fixed, re-enable code in BaseRecalibratorIntegrationTest.java. ```; //IntegrationTestSpec.compareBamFiles(actualHiSeqBam_recalibrated, expectedHiSeqBam_recalibrated);; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/419:2194,validat,validation,2194,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/419,1,['validat'],['validation']
Security,"se; 19:53:34.608 INFO ValidateVariants - Deflater: IntelDeflater; 19:53:34.608 INFO ValidateVariants - Inflater: IntelInflater; 19:53:34.608 INFO ValidateVariants - GCS max retries/reopens: 20; 19:53:34.608 INFO ValidateVariants - Requester pays: disabled; 19:53:34.608 INFO ValidateVariants - Initializing engine; 19:53:35.169 INFO FeatureManager - Using codec VCFCodec to read file file://chr1-22.phased.rename.reheader.vcf.gz; 19:53:35.594 INFO ValidateVariants - Done initializing engine; 19:53:35.594 WARN ValidateVariants - IDS validation cannot be done because no DBSNP file was provided; 19:53:35.594 WARN ValidateVariants - Other possible validations will still be performed; 19:53:35.594 INFO ProgressMeter - Starting traversal; 19:53:35.595 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 19:53:35.660 INFO ValidateVariants - Shutting down engine; [October 25, 2020 7:53:35 PM CDT] org.broadinstitute.hellbender.tools.walkers.variantutils.ValidateVariants done. Elapsed time: 0.02 minutes.; Runtime.totalMemory()=2114453504; java.lang.ArrayIndexOutOfBoundsException: -87; 	at org.broadinstitute.hellbender.utils.BaseUtils.convertIUPACtoN(BaseUtils.java:123); 	at org.broadinstitute.hellbender.utils.fasta.CachingIndexedFastaSequenceFile.getSubsequenceAt(CachingIndexedFastaSequenceFile.java:340); 	at org.broadinstitute.hellbender.engine.ReferenceFileSource.queryAndPrefetch(ReferenceFileSource.java:78); 	at org.broadinstitute.hellbender.engine.ReferenceDataSource.queryAndPrefetch(ReferenceDataSource.java:64); 	at org.broadinstitute.hellbender.engine.ReferenceContext.getBases(ReferenceContext.java:197); 	at org.broadinstitute.hellbender.tools.walkers.variantutils.ValidateVariants.apply(ValidateVariants.java:236); 	at org.broadinstitute.hellbender.engine.VariantWalker.lambda$traverse$0(VariantWalker.java:104); 	at org.broadinstitute.hellbender.engine.VariantWalker$$Lambda$76/1710491273.accept(Unknown Source); 	at java.util.stream.ForEachOps",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6911:3370,Validat,ValidateVariants,3370,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6911,1,['Validat'],['ValidateVariants']
Security,"seq-format-validation/validate-bam.inputs.json; [2020-07-14 05:09:22,78] [info] Running with database db.url = jdbc:hsqldb:mem:f10b64bd-d8ca-4428-917b-311fca24c372;shutdown=false;hsqldb.tx=mvcc; [2020-07-14 05:09:29,36] [info] Running migration RenameWorkflowOptionsInMetadata with a read batch size of 100000 and a write batch size of 100000; [2020-07-14 05:09:29,37] [info] [RenameWorkflowOptionsInMetadata] 100%; [2020-07-14 05:09:29,47] [info] Running with database db.url = jdbc:hsqldb:mem:e337a356-2f0c-4389-92c5-255465180f24;shutdown=false;hsqldb.tx=mvcc; [2020-07-14 05:09:29,89] [info] Slf4jLogger started; [2020-07-14 05:09:30,10] [info] Workflow heartbeat configuration:; {; ""cromwellId"" : ""cromid-ca5c695"",; ""heartbeatInterval"" : ""2 minutes"",; ""ttl"" : ""10 minutes"",; ""failureShutdownDuration"" : ""5 minutes"",; ""writeBatchSize"" : 10000,; ""writeThreshold"" : 10000; }; [2020-07-14 05:09:30,23] [info] Metadata summary refreshing every 1 second.; [2020-07-14 05:09:30,23] [warn] 'docker.hash-lookup.gcr-api-queries-per-100-seconds' is being deprecated, use 'docker.hash-lookup.gcr.throttle' instead (see reference.conf); [2020-07-14 05:09:30,25] [info] CallCacheWriteActor configured to flush with batch size 100 and process rate 3 seconds.; [2020-07-14 05:09:30,26] [info] KvWriteActor configured to flush with batch size 200 and process rate 5 seconds.; [2020-07-14 05:09:30,26] [info] WriteMetadataActor configured to flush with batch size 200 and process rate 5 seconds.; [2020-07-14 05:09:30,36] [info] JobExecutionTokenDispenser - Distribution rate: 50 per 1 seconds.; [2020-07-14 05:09:30,46] [info] SingleWorkflowRunnerActor: Version 51; [2020-07-14 05:09:30,48] [info] SingleWorkflowRunnerActor: Submitting workflow; [2020-07-14 05:09:30,55] [info] Unspecified type (Unspecified version) workflow 968be82c-eef3-4bdb-a1ab-3d4e2ca70674 submitted; [2020-07-14 05:09:30,66] [info] SingleWorkflowRunnerActor: Workflow submitted 968be82c-eef3-4bdb-a1ab-3d4e2ca70674; [2020-07-14 05:09:30,67",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6710:2185,hash,hash-lookup,2185,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710,1,['hash'],['hash-lookup']
Security,seq.warnings.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/UnmarkDuplicates/allDuplicates.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/complexEvents_incompatibleDict.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/complexEvents_lexDict.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/complexEvents.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/gvcf.basepairResolution.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet_BAD_INCOMPLETE_REGION.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet.BAD_MISSING_NON_REF.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet.missingrefblock.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleBad3.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleBad.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleGood.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleRSIDonPositionNotInDBSNP.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationUnusedAllelesBugFix.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/validation/basicshortmutpileup/IS3.snv.indel.sv-vs-G15512.prenormal.sorted.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/validation/basicshortmutpileup/synthetic.challenge.set1.tumor-vs-synthetic.challenge.set1.normal-filtered.vcf.idx; src/,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3905:61024,Validat,ValidateVariants,61024,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905,1,['Validat'],['ValidateVariants']
Security,skip hashtable lookup in Kryo,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1734:5,hash,hashtable,5,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1734,1,['hash'],['hashtable']
Security,spark validation tests fail,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1922:6,validat,validation,6,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1922,1,['validat'],['validation']
Security,spark.driver.maxResultSize=0 --conf spark.executor.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 --conf spark.driver.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 --conf spark.kryoserializer.buffer.max=512m --conf spark.yarn.executor.memoryOverhead=600 --driver-memory 15g --executor-cores 2 --executor-memory 8g /gatk/build/libs/gatk-spark.jar BwaAndMarkDuplicatesPipelineSpark --bam-partition-size 64000000 --input hdfs://namenode:8020/PREPROCESSING/PFC_0028_SW_CGTACG_R_fastqtosam.bam --reference hdfs://namenode:8020/hg19-ucsc/ucsc.hg19.2bit --bwa-mem-index-image /reference_image/ucsc.hg19.fasta.img --disable-sequence-dictionary-validation true --output hdfs://namenode:8020/PREPROCESSING/PFC_0028_SW_CGTACG_R_dedup_reads.bam --spark-master spark://973f3a3a3407:7077; 13:47:29.376 WARN SparkContextFactory - Environment variables HELLBENDER_TEST_PROJECT and HELLBENDER_JSON_SERVICE_ACCOUNT_KEY must be set or the GCS hadoop connector will not be configured properly; 13:47:29.548 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/gatk/build/libs/gatk-spark.jar!/com/intel/gkl/native/libgkl_compression.so; 13:47:29.831 INFO BwaAndMarkDuplicatesPipelineSpark - ------------------------------------------------------------; 13:47:29.831 INFO BwaAndMarkDuplicatesPipelineSpark - The Genome Analysis Toolkit (GATK) v4.0.4.0-23-g6e1cc8c-SNAPSHOT; 13:47:29.831 INFO BwaAndMarkDuplicatesPipelineSpark - For support and documentation go to https://software.broadinstitute.org/gatk/; 13:47:29.832 INFO BwaAndMarkDuplicatesPipelineSpark - Executing as root@973f3a3a3407 on Linux v4.4.0-124-generic amd64; 13:47:29.832 INFO BwaAndMarkDuplicatesPipe,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4820:18212,validat,validation,18212,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4820,1,['validat'],['validation']
Security,"specops issue #273: https://github.com/broadinstitute/dsp-spec-ops/issues/273. - renamed `ngs_cohort_extract.py` -> `create_cohort_extract_data_table.py`; - run the script in a WDL (GvsPrepareCallset.wdl); - use a custom docker - include script for creating and pushing this docker to gcr.io; - enable running as a SA - this has been tested in Terra and works as expected. if using a dataset that requires SA access and the user does not provide a working SA key, they get this error: `User does not have bigquery.jobs.create permission in project specops-variantstore-sa-tests.`",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7200:409,access,access,409,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7200,1,['access'],['access']
Security,"ssue mentioned [here](https://broadinstitute.slack.com/archives/CJRLP6ZSA/p1699026273329339)).; 2. Use that list as an input to GvsPrepareRangesCallset to create a cohort of test data in a separate BigQuery dataset (aou-genomics-curation-prod.klydon_pgen_extract_test).; 3. Run GvsExtractCallsetPgen on the newly created cohort. (I would just run GvsExtractCallsetPgenMerged, but I like using Workflow Dashboard to monitor how the job is going and dig into it if there are any failures. Workflow Dashboard doesn't seem to let you dig into individual tasks for workflows with sub-workflows, so it wouldn't allow me to look at individual shards running ExtractTask if I ran GvsExtractCallsetPgenMerged. Job Manager would be an alternative for this, but it seems to be pretty much unusable for even moderately-sized jobs.); 4. Run GvsExtractCallset on the newly created cohort, making sure to use the same parameters, including scatter count. This will generate VCF files that we can use to compare to the PGEN files created during the previous step for validation.; 5. Run GvsExtractCallsetPgenMerged with the same parameters used to run GvsExtractCallsetPgen in Step 3. This will use call-caching for the extract steps and then merge the PGEN files by chromosome. (Running it this way is maybe not the ideal way to do this, but it's what I've been doing for reasons described in the parenthetical in Step 3).; 6. Create list files, by file type, containing the gs:// URIs for the .pgen, .psam, and .pvar.zst files created in Step 3, along with the .vcf.gz files created in Step 4. Upload them to the workspace to use for validation.; 7. Run ComparePgenAndVcfScatter using the file lists as inputs. If there are any differences, it will output files that contain those differences. If there are no diff files generated, the files match. ComparePgenAndVcfScatter is a workflow I wrote that converts a list of .pgen, .psam, and .pvar.zst files generated by GvsExtractCallsetPgen into .vcf.gz files and the",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8708:11028,validat,validation,11028,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8708,1,['validat'],['validation']
Security,"statistics on local copy ratio posteriors as well in `GermlineCNVCallerIntegrationTest`; - [ ] unit tests for `ComputableGraphStructure`; - [ ] unit tests for `ImmutableComputableGraph`; - [ ] unit tests for ensuring that ICG nodes are treated as immutable and not modified by mistake; - [ ] unit tests for `CoverageModelEMWorkspaceMathUtils`; - [ ] unit tests for `CoverageModelParameters` (reading/writing); - [ ] unit tests for `CoverageModelSparkUtils`; - [ ] the issue with Spark tests and custom serializers (gCNV Spark tests are currently disabled). **Discussion about gCNV ICG unit tests (May 1st, 2017):**; It is possible to automate the test for ComputableNodeFunctions. One initializes the parents to random values, calls the function, and checks whether it has had any side effects on the parents. One must make a random-data-provider-of-some-sort for each parent node because the parent INDArrays have different shapes. For other functions in CoverageModelEMComputeBlock and CoverageModelEMWorkspace that query ICG nodes -- one needs to create a firewall. One can elevate all such functions to classes that essentially behave functionally, (ICGNodeProvider, List<NodeKey>, extra arguments) -> output, as opposed to writing vanilla member functions such as CoverageModelEMComputeBlock.getBiasLatentPosteriorDataUnregularized, etc. Then we can write automated unit tests for these classes. Another approach is to write a thin ImmutableNDArray interface that blocks access to all mutators and returns instances of ImmutableNDArray when a matrix view is extracted (e.g. via INDArray.get(...)). This is also quite non-trivial and requires intimate familiarity with Nd4j codebase. Perhaps one could write an immutable DataBuffer for Nd4j. Finally, there might be a brute-force approach: substitute all in-plane operations such as muli and addi with mul and add, and in-place transformations such as Transforms.log(INDArray, boolean duplicate) with Transforms.log(INDArray, true), run gCNV, and",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2929:1596,firewall,firewall,1596,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2929,1,['firewall'],['firewall']
Security,stitute.hellbender.Main.runCommandLineProgram(Main.java:131); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:152); at org.broadinstitute.hellbender.Main.main(Main.java:233); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:736); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.lang.IllegalArgumentException: observedValue must be non-negative; at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:681); at org.broadinstitute.hellbender.tools.spark.utils.IntHistogram.addObservation(IntHistogram.java:50); at org.broadinstitute.hellbender.tools.spark.sv.evidence.ReadMetadata$LibraryRawStatistics.addRead(ReadMetadata.java:367); at org.broadinstitute.hellbender.tools.spark.sv.evidence.ReadMetadata$PartitionStatistics.<init>(ReadMetadata.java:431); at org.broadinstitute.hellbender.tools.spark.sv.evidence.ReadMetadata.lambda$new$1dcab782$1(ReadMetadata.java:57); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:152); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:152); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:785); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:785); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3462:6105,validat,validateArg,6105,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3462,1,['validat'],['validateArg']
Security,stop using 32 bit key hash on travis,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5214:22,hash,hash,22,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5214,1,['hash'],['hash']
Security,stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); 	at org.broadinstitute.hellbender.engine.TwoPassReadWalker.traverseReads(TwoPassReadWalker.java:60); 	at org.broadinstitute.hellbender.engine.TwoPassReadWalker.traverse(TwoPassReadWalker.java:42); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:979); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:137); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:182); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:201); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); 	at org.broadinstitute.hellbender.Main.main(Main.java:289); ```. Command:; ```; ./gatk/gatk \; SplitNCigarReads \; --reference $REF \; --input test3.bam \; --output output.bam \; --verbosity DEBUG \; > split.log 2>&1; ```; Running ValidateSamFile does not reveal anything suspicious and visual inspection of the reads also appears to be fine. This Issue was generated from your [forums] ; [forums]: https://gatkforums.broadinstitute.org/gatk/discussion/12801/exception-in-splitncigarreads/p1,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5230:3099,Validat,ValidateSamFile,3099,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5230,1,['Validat'],['ValidateSamFile']
Security,"successful run; https://app.terra.bio/#workspaces/gvs-dev/GVS%20Quickstart%20v3%20cremer/job_history/cb0d2b70-64e8-455c-955e-a960db264804. Look at this beaut!!!; <img width=""1163"" alt=""Screenshot 2023-09-21 at 1 47 06 PM"" src=""https://github.com/broadinstitute/gatk/assets/6863459/c5b39555-e78e-4e54-b91f-3e1702086fb2"">. And we can add an autoscaling policy (currently here with a yaml that I shoved in the workspace bucket ahead of time---in the future we will want this to be a param or at least hashed out with Hail). <img width=""1144"" alt=""Screenshot 2023-09-22 at 1 36 07 PM"" src=""https://github.com/broadinstitute/gatk/assets/6863459/b9bf05ac-1a98-42cc-a117-24f6940bd764"">. And link to said policy (remember the ""="" sign!!!!). <img width=""1389"" alt=""Screenshot 2023-09-25 at 1 42 37 PM"" src=""https://github.com/broadinstitute/gatk/assets/6863459/5ed3e472-e4f8-4ed7-8dac-aeb917575c86"">",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8524:498,hash,hashed,498,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8524,1,['hash'],['hashed']
Security,switch away from calling hashCode directly on enums,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4621:25,hash,hashCode,25,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4621,1,['hash'],['hashCode']
Security,"t requested more than the maximum memory capability of the cluster (18432 MB per container); 18/01/09 18:30:58 INFO yarn.Client: Will allocate AM container, with 896 MB memory including 384 MB overhead; 18/01/09 18:30:58 INFO yarn.Client: Setting up container launch context for our AM; 18/01/09 18:30:58 INFO yarn.Client: Setting up the launch environment for our AM container; 18/01/09 18:30:58 INFO yarn.Client: Preparing resources for our AM container; 18/01/09 18:30:59 INFO yarn.Client: Uploading resource file:/tmp/sun/spark-5a3e539e-2e2b-4da2-b218-2bda166bd4c0/__spark_conf__7100950787185363106.zip -> hdfs://tele-1:8020/user/sun/.sparkStaging/application_1515493209401_0001/__spark_conf__.zip; 18/01/09 18:31:00 INFO spark.SecurityManager: Changing view acls to: sun; 18/01/09 18:31:00 INFO spark.SecurityManager: Changing modify acls to: sun; 18/01/09 18:31:00 INFO spark.SecurityManager: Changing view acls groups to: ; 18/01/09 18:31:00 INFO spark.SecurityManager: Changing modify acls groups to: ; 18/01/09 18:31:00 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(sun); groups with view permissions: Set(); users with modify permissions: Set(sun); groups with modify permissions: Set(); 18/01/09 18:31:00 INFO yarn.Client: Submitting application application_1515493209401_0001 to ResourceManager; 18/01/09 18:31:00 INFO impl.YarnClientImpl: Submitted application application_1515493209401_0001; 18/01/09 18:31:00 INFO cluster.SchedulerExtensionServices: Starting Yarn extension services with app application_1515493209401_0001 and attemptId None; 18/01/09 18:31:01 INFO yarn.Client: Application report for application_1515493209401_0001 (state: ACCEPTED); 18/01/09 18:31:01 INFO yarn.Client: ; 	 client token: N/A; 	 diagnostics: N/A; 	 ApplicationMaster host: N/A; 	 ApplicationMaster RPC port: -1; 	 queue: root.users.sun; 	 start time: 1515493860237; 	 final status: UNDEFINED; 	 tracking URL: http://tele-1:808",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4112:12025,Secur,SecurityManager,12025,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4112,1,['Secur'],['SecurityManager']
Security,"t this you'd see. ```; org.apache.spark.SparkException: Job aborted due to stage failure: Task 45 in stage 9.0 failed 8 times, most recent failure: Lost task 45.7 in stage 9.0 (TID 734, shuang-svdps-ceu-w-1.c.broad-dsde-methods.internal, executor 2): java.nio.file.FileSystemNotFoundException: Provider ""gs"" not installed; 	at java.nio.file.Paths.get(Paths.java:147); 	at org.broadinstitute.hellbender.engine.spark.datasources.ReferenceFileSparkSource.getReferencePath(ReferenceFileSparkSource.java:53); 	at org.broadinstitute.hellbender.engine.spark.datasources.ReferenceFileSparkSource.getReferenceBases(ReferenceFileSparkSource.java:60); 	at org.broadinstitute.hellbender.engine.spark.datasources.ReferenceMultiSparkSource.getReferenceBases(ReferenceMultiSparkSource.java:89); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.BreakEndVariantType.getRefBaseString(BreakEndVariantType.java:89); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.BreakEndVariantType.access$200(BreakEndVariantType.java:20); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.BreakEndVariantType$InterChromosomeBreakend.<init>(BreakEndVariantType.java:253); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.BreakEndVariantType$InterChromosomeBreakend.getOrderedMates(BreakEndVariantType.java:261); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.NovelAdjacencyAndAltHaplotype.toSimpleOrBNDTypes(NovelAdjacencyAndAltHaplotype.java:246); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.SimpleNovelAdjacencyInterpreter.inferType(SimpleNovelAdjacencyInterpreter.java:129); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.SimpleNovelAdjacencyInterpreter.lambda$inferTypeFromSingleContigSimpleChimera$24ddc343$1(SimpleNovelAdjacencyInterpreter.java:107); 	at org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(JavaPairRDD.scala:1043); 	at org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6070:1066,access,access,1066,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6070,1,['access'],['access']
Security,t/resources/org/broadinstitute/hellbender/tools/split_reads.cram; src/test/resources/org/broadinstitute/hellbender/tools/split_reads.dict; src/test/resources/org/broadinstitute/hellbender/tools/split_reads.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/split_reads_missing_lib.bam; src/test/resources/org/broadinstitute/hellbender/tools/split_reads_missing_lib.cram; src/test/resources/org/broadinstitute/hellbender/tools/split_reads_missing_lib.dict; src/test/resources/org/broadinstitute/hellbender/tools/split_reads_missing_lib.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/split_reads_missing_lib.sam; src/test/resources/org/broadinstitute/hellbender/tools/split_reads.sam; src/test/resources/org/broadinstitute/hellbender/tools/validation/marked.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.bam; src/test/resources/org/broadinstitute/hellbender/tools/validation/picard.marked.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.bam; src/test/resources/org/broadinstitute/hellbender/tools/validation/single.read.bai; src/test/resources/org/broadinstitute/hellbender/tools/valid.cram.crai; src/test/resources/org/broadinstitute/hellbender/tools/valid.dict; src/test/resources/org/broadinstitute/hellbender/tools/valid.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/VQSR/VQSR.AStest.indels.recal.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/VQSR/VQSR.AStest.input.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/VQSR/VQSR.AStest.postSNPinput.HACKEDhg38header.vcf.gz.tbi; src/test/resources/org/broadinstitute/hellbender/tools/VQSR/VQSR.AStest.postSNPinput.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/VQSR/VQSR.AStest.snps.recal.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/VQSR/VQSR.mixedTest.input.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/VQSR/VQSR.mixedTest.recal.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/annotator/allele,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3905:45792,validat,validation,45792,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905,1,['validat'],['validation']
Security,"tator - Built for Spark Version: 3.3.1; 16:36:22.397 INFO Funcotator - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 16:36:22.397 INFO Funcotator - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 16:36:22.398 INFO Funcotator - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 16:36:22.398 INFO Funcotator - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 16:36:22.398 INFO Funcotator - Deflater: IntelDeflater; 16:36:22.398 INFO Funcotator - Inflater: IntelInflater; 16:36:22.399 INFO Funcotator - GCS max retries/reopens: 20; 16:36:22.399 INFO Funcotator - Requester pays: disabled; 16:36:22.399 INFO Funcotator - Initializing engine; 16:36:22.624 INFO FeatureManager - Using codec VCFCodec to read file file:///home/ppshah/shared/CAS_MOSAIC/mutect/mrn_2507919/WES/KShaw-ROPR0004-DNA-229761-WX01-T_HMCKJDSX2-4-ATTGGCTC/KShaw-ROPR0004-DNA-229761-WX01-T_HMCKJDSX2-4-ATTGGCTC_filtered.vcf.gz; 16:36:22.842 INFO Funcotator - Done initializing engine; 16:36:22.842 INFO Funcotator - Validating sequence dictionaries...; 16:36:22.856 INFO Funcotator - Processing user transcripts/defaults/overrides...; 16:36:22.857 INFO Funcotator - Initializing data sources...; 16:36:22.859 INFO DataSourceUtils - Initializing data sources from directory: /home/ppshah/shared/pipelines/mutect/funcotator_dataSources.v1.7.20200521s; 16:36:22.871 INFO DataSourceUtils - Data sources version: 1.7.2020429s; 16:36:22.871 INFO DataSourceUtils - Data sources source: ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/funcotator/funcotator_dataSources.v1.7.20200429s.tar.gz; 16:36:22.871 INFO DataSourceUtils - Data sources alternate source: gs://broad-public-datasets/funcotator/funcotator_dataSources.v1.7.20200429s.tar.gz; 16:36:22.891 INFO Funcotator - Shutting down engine; [January 10, 2024 at 4:36:22 PM GMT] org.broadinstitute.hellbender.tools.funcotator.Funcotator done. Elapsed time: 0.01 minutes.; Runtime.totalMemory()=285212672; ***************************************************************",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8647:3780,Validat,Validating,3780,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8647,1,['Validat'],['Validating']
Security,te(DefaultBuildExecuter.java:37); at org.gradle.execution.DefaultBuildExecuter.access$000(DefaultBuildExecuter.java:23); at org.gradle.execution.DefaultBuildExecuter$1.proceed(DefaultBuildExecuter.java:43); at org.gradle.execution.DryRunBuildExecutionAction.execute(DryRunBuildExecutionAction.java:32); at org.gradle.execution.DefaultBuildExecuter.execute(DefaultBuildExecuter.java:37); at org.gradle.execution.DefaultBuildExecuter.execute(DefaultBuildExecuter.java:30); at org.gradle.initialization.DefaultGradleLauncher$4.run(DefaultGradleLauncher.java:186); at org.gradle.internal.Factories$1.create(Factories.java:22); at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:91); at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:53); at org.gradle.initialization.DefaultGradleLauncher.doBuildStages(DefaultGradleLauncher.java:183); at org.gradle.initialization.DefaultGradleLauncher.access$200(DefaultGradleLauncher.java:33); at org.gradle.initialization.DefaultGradleLauncher$1.create(DefaultGradleLauncher.java:112); at org.gradle.initialization.DefaultGradleLauncher$1.create(DefaultGradleLauncher.java:106); at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:91); at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:63); at org.gradle.initialization.DefaultGradleLauncher.doBuild(DefaultGradleLauncher.java:106); at org.gradle.initialization.DefaultGradleLauncher.run(DefaultGradleLauncher.java:92); at org.gradle.launcher.exec.GradleBuildController.run(GradleBuildController.java:66); at org.gradle.tooling.internal.provider.ExecuteBuildActionRunner.run(ExecuteBuildActionRunner.java:28); at org.gradle.launcher.exec.ChainingBuildActionRunner.run(ChainingBuildActionRunner.java:35); at org.gradle.launcher.exec.InProcessBuildActionExecuter.execute(InProcessBuildActionExecuter.java:41); at org.gr,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4155:3872,access,access,3872,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4155,2,['access'],['access']
Security,"te.hellbender.Main.runCommandLineProgram(Main.java:162); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:205); at org.broadinstitute.hellbender.Main.main(Main.java:291); Caused by: htsjdk.tribble.TribbleException$MalformedFeatureFile: Unable to parse header with error: Duplicate key 0, for input source: cadd.config; at htsjdk.tribble.TribbleIndexedFeatureReader.readHeader(TribbleIndexedFeatureReader.java:263); at htsjdk.tribble.TribbleIndexedFeatureReader.&lt;init&gt;(TribbleIndexedFeatureReader.java:102); at htsjdk.tribble.TribbleIndexedFeatureReader.&lt;init&gt;(TribbleIndexedFeatureReader.java:127); at htsjdk.tribble.AbstractFeatureReader.getFeatureReader(AbstractFeatureReader.java:120); at org.broadinstitute.hellbender.engine.FeatureDataSource.getTribbleFeatureReader(FeatureDataSource.java:350); ... 14 more; Caused by: java.lang.IllegalStateException: Duplicate key 0; at java.util.stream.Collectors.lambda$throwingMerger$0(Collectors.java:133); at java.util.HashMap.merge(HashMap.java:1254); at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1320); at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); at java.util.stream.IntPipeline$4$1.accept(IntPipeline.java:250); at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110); at java.util.Spliterator$OfInt.forEachRemaining(Spliterator.java:693); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:566); at org.broadinstitute.hellbender.utils.codecs.xsvLocatableTable.XsvLocatableTableCodec.readActualHeader(XsvLocatableTableCodec.java:341); at org.broadinstitute.hellbender.utils.codecs.xsvLocatableTable.XsvLocatableTableCodec.readActual",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6223:2746,Hash,HashMap,2746,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6223,1,['Hash'],['HashMap']
Security,te/gatk:4.2.2.0' locally; 4.2.2.0: Pulling from broadinstitute/gatk; a7fe112a8303: Already exists ; Digest: sha256:32175c3c7c1fb9f5bd6650183c9c5cf26fb822dddb0cad0123d48c33124b6065; Status: Downloaded newer image for broadinstitute/gatk:4.2.2.0; (gatk) root@bc90fdaf700c:/gatk# ; (gatk) root@bc90fdaf700c:/gatk# ; (gatk) root@bc90fdaf700c:/gatk# apt-get update; Get:1 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]; Get:2 http://archive.ubuntu.com/ubuntu bionic InRelease [242 kB] ; Get:3 http://security.ubuntu.com/ubuntu bionic-security/multiverse amd64 Packages [26.7 kB] ; Get:4 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [543 kB] ; Get:5 http://packages.cloud.google.com/apt cloud-sdk-bionic InRelease [6786 B] ; Get:6 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1426 kB] ; Err:5 http://packages.cloud.google.com/apt cloud-sdk-bionic InRelease ; The following signatures couldn't be verified because the public key is not available: NO_PUBKEY FEEA9169307EA071 NO_PUBKEY 8B57C5C2836F4BEB; Get:7 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2295 kB] ; Get:8 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB] ; Get:9 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB] ; Get:10 http://archive.ubuntu.com/ubuntu bionic/restricted amd64 Packages [13.5 kB] ; Get:11 http://archive.ubuntu.com/ubuntu bionic/multiverse amd64 Packages [186 kB]; Get:12 http://archive.ubuntu.com/ubuntu bionic/universe amd64 Packages [11.3 MB] ; Get:13 http://archive.ubuntu.com/ubuntu bionic/main amd64 Packages [1344 kB] ; Get:14 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2200 kB]; Get:15 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 Packages [34.4 kB]; Get:16 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [575 kB]; Get:17 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7447:1454,secur,security,1454,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7447,1,['secur'],['security']
Security,"te@developer.gserviceaccount.com does not have storage.objects.get access to fc-50c768b1-a285-4c95-8d8c-8ce209f1fda8/744139c5-3371-4a67-a2c8-e054e46f814f/ReblockGVCF/601ea396-b6cf-4baa-95c7-83e88b92c194/call-GenotypeGVCF/09C97227.c9cd4496-b4ed-4686-babd-177c66168178.vcf.gz.tbi."",; ""reason"" : ""forbidden""; } ],; ""message"" : ""443301511749-compute@developer.gserviceaccount.com does not have storage.objects.get access to fc-50c768b1-a285-4c95-8d8c-8ce209f1fda8/744139c5-3371-4a67-a2c8-e054e46f814f/ReblockGVCF/601ea396-b6cf-4baa-95c7-83e88b92c194/call-GenotypeGVCF/09C97227.c9cd4496-b4ed-4686-babd-177c66168178.vcf.gz.tbi.""; }; 	at shaded.cloud_nio.com.google.api.client.googleapis.json.GoogleJsonResponseException.from(GoogleJsonResponseException.java:145); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:113); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:40); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest$1.interceptResponse(AbstractGoogleClientRequest.java:321); 	at shaded.cloud_nio.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1056); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.execute(AbstractGoogleClientRequest.java:469); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.get(HttpStorageRpc.java:333); 	... 21 more; ```; The latter is more verbose than I need, but having that message from the 403 was key (since I needed the service account name to give it access.)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4592:5727,access,access,5727,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4592,1,['access'],['access']
Security,"teBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/docker_cid). # remove the container after waiting; docker rm cat /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/docker_cid. # return exit code; exit $rc; [2020-07-14 05:09:45,29] [info] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: job id: 243; [2020-07-14 05:09:45,29] [info] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: Status change from - to Done; [2020-07-14 05:09:46,38] [info] WorkflowManagerActor Workflow 968be82c-eef3-4bdb-a1ab-3d4e2ca70674 failed (during ExecutingWorkflowState): Job ValidateBamsWf.ValidateBAM:0:1 exited with return code -1 which has not been declared as a valid return code. See 'continueOnReturnCode' runtime attribute for more details.; Check the content of stderr for potential additional information: /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/stderr.; Could not retrieve content: Could not read from /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/stderr: /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/stderr; [2020-07-14 05:09:46,38] [info] WorkflowManagerActor WorkflowActor-968be82c-eef3-4bdb-a1ab-3d4e2ca70674 is in a terminal state: WorkflowFailedState; [2020-07-14 05:09:51,97] [info] SingleWorkflowRunnerActor workflow finished with status 'Failed'.; [2020-07-14 05:09:55,28] [info] Workflow polling stopped; [2020-07-14 05:09:55,30] [info] 0 workflows released by cromid-ca5c695; [2020-07-14 05:09:55,30] [info] Shutting down WorkflowStoreActor - Timeout = 5 seconds; [2020-07-14 05:09:55,30] [info] Shutting down WorkflowLogCopyRouter - Timeout = 5 seconds; [2020-07-14 05:09:55,3",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6710:7181,Validat,ValidateBamsWf,7181,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710,2,['Validat'],"['ValidateBAM', 'ValidateBamsWf']"
Security,ter; 18:30:54.424 INFO BwaAndMarkDuplicatesPipelineSpark - Inflater: IntelInflater; 18:30:54.424 INFO BwaAndMarkDuplicatesPipelineSpark - GCS max retries/reopens: 20; 18:30:54.424 INFO BwaAndMarkDuplicatesPipelineSpark - Using google-cloud-java patch c035098b5e62cb4fe9155eff07ce88449a361f5d from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 18:30:54.424 INFO BwaAndMarkDuplicatesPipelineSpark - Initializing engine; 18:30:54.424 INFO BwaAndMarkDuplicatesPipelineSpark - Done initializing engine; 18/01/09 18:30:54 INFO spark.SparkContext: Running Spark version 2.2.0.cloudera1; 18/01/09 18:30:54 INFO spark.SparkContext: Submitted application: BwaAndMarkDuplicatesPipelineSpark; 18/01/09 18:30:54 INFO spark.SecurityManager: Changing view acls to: sun; 18/01/09 18:30:54 INFO spark.SecurityManager: Changing modify acls to: sun; 18/01/09 18:30:54 INFO spark.SecurityManager: Changing view acls groups to: ; 18/01/09 18:30:54 INFO spark.SecurityManager: Changing modify acls groups to: ; 18/01/09 18:30:54 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(sun); groups with view permissions: Set(); users with modify permissions: Set(sun); groups with modify permissions: Set(); 18/01/09 18:30:55 INFO util.Utils: Successfully started service 'sparkDriver' on port 38793.; 18/01/09 18:30:55 INFO spark.SparkEnv: Registering MapOutputTracker; 18/01/09 18:30:55 INFO spark.SparkEnv: Registering BlockManagerMaster; 18/01/09 18:30:55 INFO storage.BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information; 18/01/09 18:30:55 INFO storage.BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up; 18/01/09 18:30:55 INFO storage.DiskBlockManager: Created local directory at /tmp/sun/blockmgr-b03058dc-763a-449c-bd05-18f3304c01ea; 18/01/09 18:30:55 INFO memory.MemoryStore: MemoryStore started with capacity 2004.6 MB; 18/01/09 18:30:55 INFO spark.SparkEnv,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4112:5597,Secur,SecurityManager,5597,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4112,1,['Secur'],['SecurityManager']
Security,"ternal:8020/user/hadoop/.sparkStaging/application_1554748821802_0005/hive-site.xml; 19/04/08 19:01:48 INFO Client: Uploading resource file:/mnt/tmp/spark-ada67a34-2db0-488c-adf5-7e4607fe989f/__spark_conf__2453357125414211656.zip -> hdfs://ip-xx.xx.xx.xx.ec2.internal:8020/user/hadoop/.sparkStaging/application_1554748821802_0005/__spark_conf__.zip; 19/04/08 19:01:48 INFO SecurityManager: Changing view acls to: hadoop; 19/04/08 19:01:48 INFO SecurityManager: Changing modify acls to: hadoop; 19/04/08 19:01:48 INFO SecurityManager: Changing view acls groups to: ; 19/04/08 19:01:48 INFO SecurityManager: Changing modify acls groups to: ; 19/04/08 19:01:48 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(hadoop); groups with view permissions: Set(); users with modify permissions: Set(hadoop); groups with modify permissions: Set(); 19/04/08 19:01:48 INFO Client: Submitting application application_1554748821802_0005 to ResourceManager; 19/04/08 19:01:48 INFO YarnClientImpl: Submitted application application_1554748821802_0005; 19/04/08 19:01:48 INFO SchedulerExtensionServices: Starting Yarn extension services with app application_1554748821802_0005 and attemptId None; 19/04/08 19:01:49 INFO Client: Application report for application_1554748821802_0005 (state: ACCEPTED); 19/04/08 19:01:49 INFO Client: ; 	 client token: N/A; 	 diagnostics: AM container is launched, waiting for AM container to Register with RM; 	 ApplicationMaster host: N/A; 	 ApplicationMaster RPC port: -1; 	 queue: default; 	 start time: 1554750108216; 	 final status: UNDEFINED; 	 tracking URL: http://ip-xx.xx.xx.xx.ec2.internal:20888/proxy/application_1554748821802_0005/; 	 user: hadoop; 19/04/08 19:01:50 INFO Client: Application report for application_1554748821802_0005 (state: ACCEPTED); 19/04/08 19:01:51 INFO YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -> ip-xx.xx.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5869:7925,Secur,SecurityManager,7925,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5869,7,"['Secur', 'authenticat']","['SecurityManager', 'authentication']"
Security,"terval_exclusion_padding 0 --bamPartitionSize 0 --shardedOutput false --numReducers 0 --sparkMaster local[*] --help false --version false --showHidden false --QUIET false --use_jdk_deflater false --use_jdk_inflater false; [August 22, 2017 6:54:35 PM UTC] Executing as root@d6d410d4b1c7 on Linux 4.9.0-0.bpo.3-amd64 amd64; OpenJDK 64-Bit Server VM 1.8.0_131-8u131-b11-0ubuntu1.16.04.2-b11; Version: 4.beta.3-SNAPSHOT; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; 17/08/22 18:54:38 INFO SparkContext: Running Spark version 2.0.2; 17/08/22 18:54:39 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 17/08/22 18:54:40 INFO SecurityManager: Changing view acls to: root; 17/08/22 18:54:40 INFO SecurityManager: Changing modify acls to: root; 17/08/22 18:54:40 INFO SecurityManager: Changing view acls groups to: ; 17/08/22 18:54:40 INFO SecurityManager: Changing modify acls groups to: ; 17/08/22 18:54:40 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); groups with view permissions: Set(); users with modify permissions: Set(root); groups with modify permissions: Set(); 17/08/22 18:54:41 INFO Utils: Successfully started service 'sparkDriver' on port 45651.; 17/08/22 18:54:41 INFO SparkEnv: Registering MapOutputTracker; 17/08/22 18:54:41 INFO SparkEnv: Registering BlockManagerMaster; 17/08/22 18:54:41 INFO DiskBlockManager: Created local directory at /cromwell_root/tmp.5EEmH0/root/blockmgr-84cc8cba-fa27-4b62-a6f6-1c10377ddc86; 17/08/22 18:54:41 INFO MemoryStore: MemoryStore started with capacity 4.1 GB; 17/08/22 18:54:41 INFO SparkEnv: Registering OutputCommitCoordinator; 17/08/22 18:54:42 INFO Utils: Successfully started service 'SparkUI' on port 4040.; 17/08/22 18:54:42 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://172.17.0.2:4040; 17/08/22 18:54:42 INFO Executor: Starting executor ID dri",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3492:1525,Secur,SecurityManager,1525,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3492,7,"['Secur', 'authenticat']","['SecurityManager', 'authentication']"
Security,"test BAMs (e.g., src/test/resources/large/cnv_somatic_workflows_test_files/HCC1143-t1-chr20-downsampled.deduplicated.bam), since these BAMs have been used in the past to consistently generate test files for other tools in the ModelSegments and GermlineCNVCaller pipelines. However, these original test files contained insufficient data to activate the changes found in #7649, even had exact-match tests been present. I thus took some old HCC1143T 100% WES data that I had and snippeted it to chr20. I've confirmed that the added tests with these files would've picked up the regression of log10factorial seen in #7649 for all relevant modes (i.e., all those that take in the allele counts as input, since that regression only affected allele-fraction MCMC sampling). Tests take maybe an additional minute to run and there was about ~12MB of additional large resources checked in, but I didn't try too hard to bring either down. I also added some early-fail parameter validation to check that the minimum total allele count in the case sample is zero in matched-normal mode. There are actually some open questions in my mind as to what the best behavior should be here, but given some of the discussion in #6499 and possible plans for using joint segmentation to do filtering of germline events, I think it's best to enforce that all het sites coming out of the genotyping step are the same across all samples. Recall that we added this parameter in #5556 because some users were running matched normals with much lower depth than their cases. This meant that many normal sites fell below the default threshold of 30 counts and were thus not pulled from the case, even though the latter had much higher depth. It's conceivable that there will be some use cases for which we might want to relax this and allow a non-zero case threshold; for example, if the case is low depth and there's significant noise in the allele fractions, which would affect the segmentation. But for now, I just added a suggest",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7652:1516,validat,validation,1516,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7652,1,['validat'],['validation']
Security,test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/complexEvents_lexDict.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/complexEvents.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/gvcf.basepairResolution.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet_BAD_INCOMPLETE_REGION.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet.BAD_MISSING_NON_REF.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet.missingrefblock.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleBad3.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleBad.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleGood.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleRSIDonPositionNotInDBSNP.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationUnusedAllelesBugFix.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/validation/basicshortmutpileup/IS3.snv.indel.sv-vs-G15512.prenormal.sorted.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/validation/basicshortmutpileup/synthetic.challenge.set1.tumor-vs-synthetic.challenge.set1.normal-filtered.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/CalculateGenotypePosteriors/CEUtriMixedPloidyTest.vcf; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/CalculateGenotypePosteriors/CEUtrioPopPriorsT,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3905:61266,Validat,ValidateVariants,61266,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905,2,"['Validat', 'validat']","['ValidateVariants', 'validationExampleBad']"
Security,tests that write bam/cram files need to validate that the right format is written,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1269:40,validat,validate,40,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1269,1,['validat'],['validate']
Security,"the HMM gap open/gap close penalties as well as the necessary changes to the PairHMM loading code in order to adjust the model appropriately.; - Support for using the DragstrParams and flat SNP priors to compute genotype posteriors and the support for using them in the selection of genotypes as well as for computing the QUAL score. ; - Base Quality Dropout (BQD) model which penalizes variants with low average base quality scores among genotyped reads and reads that were otherwise excluded from the genotyper. A number of additional arguments to expose internal behaviors in the readThreadingAssembler and HaplotypeCaller have been made in order to support threading more lowBQ reads through to the genotyper. ; - Foreign Read Detection (FRD) model which uses an adjusted mapping quality score as well as read strandedness information to penalize reads that are likely to have originated from somewhere else on the genome. A number of additional arguments and behaviors have been exposed in order to preserve lower mapping quality reads in the HaplotypeCaller in service.; - Dynamic Read Disqualification, allows for longer/lower base quality reads to be less likely to be rejected by eliminating the hard cap on quality scores and further adjusting the limit based on the average base quality for bases in the read. . Design decisions that I would direct the reviewers attention to as they correspond to potentially dangerous/controversial changes:; - Because FRD/BQD require low quality ends to be included in the models for genotyping, I have added the option to softclipLowQualityEnds (as opposed to their current treatment which involves hardclipping). This has resulted in a lot of code revolving around handling soft reads and making sure that the correct bases get used in the correct places, which often manifests as simply re-clipping the soft-clipped bases where necessary. This might seem expensive but low quality ends are fairly rare and consequently this has a negligible effect on ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6634:1341,expose,exposed,1341,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6634,1,['expose'],['exposed']
Security,"the dev-oriented material such as coding conventions etc should be moved to a separate wiki page.; The main readme should have examples of how to install it, how to validate the installation and how run it locally, on spark cluster and on the cloud. Candidate for alpha",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1049:165,validat,validate,165,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1049,1,['validat'],['validate']
Security,"the first commit is the fix, the second is a deliberate test failure so we can validate that the fix works when the tests fail",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5108:79,validat,validate,79,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5108,1,['validat'],['validate']
Security,"the invalid reads strikes back - i got this when running the ReadsPipelineSpark on qurynamesorted file `hdfs:///user/akiezun/data/CEUTrio.HiSeq.WEx.b37.NA12892.readnamesort.bam`:. ```; Job aborted due to stage failure: Task 47 in stage 2.0 failed 4 times, most recent failure: Lost task 47.3 in stage 2.0 (TID 680, dataflow05.broadinstitute.org): java.lang.IllegalArgumentException: ; Invalid interval. Contig:20 start:62720124 end:62720123; at org.broadinstitute.hellbender.utils.SimpleInterval.validatePositions(SimpleInterval.java:59); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:34); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:46); at org.broadinstitute.hellbender.engine.spark.BroadcastJoinReadsWithVariants.lambda$join$3d1c3858$1(BroadcastJoinReadsWithVariants.java:27); at org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(JavaPairRDD.scala:1030); at org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(JavaPairRDD.scala:1030); at scala.collection.Iterator$$anon$11.next(Iterator.scala:328); at scala.collection.Iterator$$anon$11.next(Iterator.scala:328); at scala.collection.Iterator$$anon$11.next(Iterator.scala:328); at scala.collection.convert.Wrappers$IteratorWrapper.next(Wrappers.scala:30); at org.broadinstitute.hellbender.tools.spark.transforms.BaseRecalibratorSparkFn.lambda$apply$26a6df3e$1(BaseRecalibratorSparkFn.java:28); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:156); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:156); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$17.apply(RDD.scala:706); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$17.apply(RDD.scala:706); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:297); at org.apache.spark.rdd.RDD.iterat",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1560:496,validat,validatePositions,496,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1560,1,['validat'],['validatePositions']
Security,"there is one bug commented out in ValidateSamFileIntegrationTest. The issue is https://github.com/samtools/htsjdk/issues/369, the fix is in https://github.com/samtools/htsjdk/pull/368. SamFileValidator throws NPE on a CRAM file with an invalid sort order. Once that fix is available we can uncomment the test.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1138:34,Validat,ValidateSamFileIntegrationTest,34,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1138,1,['Validat'],['ValidateSamFileIntegrationTest']
Security,"there was some not nice code in IntervalsSkipList (using Hashtables (sic! we had Hashtables in 2016), declaring things as ArrayList, verbose comparators etc). This is a small cleanup",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1698:57,Hash,Hashtables,57,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1698,2,['Hash'],['Hashtables']
Security,they seem to have changed the gcloud cli to use --key-file instead of; --key in authentication. this was causing travis to fail on the cloud tests,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2248:80,authenticat,authentication,80,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2248,1,['authenticat'],['authentication']
Security,this happens on the branch for https://github.com/broadinstitute/gatk/pull/1630 (which uses async IO for tests to mimic non-test usage). This bug is either due to or exposed by asynchronous tribble reading. more logs https://travis-ci.org/broadinstitute/gatk/jobs/118507152. test results; https://storage.googleapis.com/hellbender/test/build_reports/5109.2/tests/classes/org.broadinstitute.hellbender.tools.walkers.filters.VariantFiltrationIntegrationTest.html#testClusteredSnps. ```; java.lang.RuntimeException: htsjdk.tribble.TribbleException: Exception encountered in worker thread.; at org.broadinstitute.hellbender.utils.test.IntegrationTestSpec.executeTest(IntegrationTestSpec.java:153); at org.broadinstitute.hellbender.utils.test.IntegrationTestSpec.executeTest(IntegrationTestSpec.java:126); at org.broadinstitute.hellbender.utils.test.IntegrationTestSpec.executeTest(IntegrationTestSpec.java:108); at org.broadinstitute.hellbender.tools.walkers.filters.VariantFiltrationIntegrationTest.testClusteredSnps(VariantFiltrationIntegrationTest.java:36); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:497); at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); at org.testng.internal.Invoker.invokeMethod(Invoker.java:639); at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:821); at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1131); at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); at org.testng.TestRunner.privateRun(TestRunner.java:773); at org.testng.TestRunner.run(TestRunner.java:623); at org.testng.SuiteRunner.runTest(SuiteRunner.java:357); at org.testng.SuiteRunner.runSequentiall,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1638:166,expose,exposed,166,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1638,1,['expose'],['exposed']
Security,"this is a script which can be used after running gradle installDist to run spark jobs; it can be used identically to ths build/install/bin/gatk script, but has extra features for dealing with spark. running a spark tool and supplying the option --sparkTarget with LOCAL, CLUSTER, or GCS has special behavior; LOCAL will run the tool in the in memory spark runner; CLUSTER along with an appropriate --sparkMaster will run on an accessible spark cluster using spark-submit; arguments to spark-submit may be specified before the arguments to GATK by separating them with a --; GCS will submit jobs to google dataproc using gcloud; common arguments for spark submit will be adapted to match the gcloud formating; this will fail if gcloud isn't installed. if GATK_GCS_STAGING is specified, the jar will be uploaded and cached in the specified bucket for rapid re-use. input files will not be autouploaded to the cloud. --dry-run may be specified before the --, this will only print the commands that will be run instead of actually running them. Adding DataProcArgumentReplace simple tool to convert spark-submit args into gcloud args.; This conversion is not guarenteed to translate all spark command line options to matching gcloud ones.; If you find options that are not translated or are miss-translated please file an issue.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1211:427,access,accessible,427,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1211,1,['access'],['accessible']
Security,"thub.com/broadinstitute/gatk-protected/issues/149). Plots required to choose some of the parameters use along the pipeline:; To have an idea how they look like and how they would be used you can refer to XHMM tutorial:; https://atgu.mgh.harvard.edu/xhmm/tutorial.shtml. These can be totally in R and you may choose to reuse XHMM original code make reference to the appropriate license; they are quite simple so probably it is not necessary:; - min and max average sample coverage (to filter extreme samples).; - Plot a histogram of the average sample target coverage to choose this cut-offs. ; - min and max std dev. coverage across targets per sample (to filter extreme targets).; - Plot another histogram but in this case of the std .dev target coverage.; - min and max average and std. dev target coverage (to filter extreme targets); - Basically the ""transpose of the two plots above so that we can filter extreme targets:; - Histogram of the mean coverage per target across samples; - Histogram of the std. dev coverage per target across samples.; - Principal components variance explained plot.; - Y is the variance explained by the component (~ eigen value).; - X is the component index where 0 is the first component and i is the ith component.; Consequently this graph is monotonic decreasing.; - Would be nice to get the component vs covariate plot to find out whether we are getting rid ; of known biases like GC content but this one may take a bit more time an might not be necessary for now in practice. . The first few plots could be done by a script that takes in a read counts file.; The principal components one may access the .pon file directly perhaps using a cran package to read hdf5 files. Otherwise you might need to write a simple tool to extract those variances from the .pon. ---. @samuelklee commented on [Wed Aug 17 2016](https://github.com/broadinstitute/gatk-protected/issues/149#issuecomment-240525897). The new germline CNV tool should have some plotting capabilities.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2826:1682,access,access,1682,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2826,1,['access'],['access']
Security,"tig names of chromosomes. This tool supports two of those chromosome code options: `chrM` and `MT`, which correspond to hg38 and hg19 contig naming, respectively. This argument is required. #### write-mode; The PGEN writer defined in PGEN-JNI defines two different write modes. When `WRITE_AND_COPY` is selected, a temporary .pgen file is created and written to during the running of the tool, and then once all records have been written, a new file is created with the index at the top and the contents of the temporary .pgen file appended to it. When `WRITE_SEPARATE_INDEX` is selected, the index is instead written to a separate .pgi file. The default is `WRITE_AND_COPY`. #### max-alt-alleles; The PGEN format can only support up to 254 alt alleles per site. This argument allows you to specify a limit. The default is the max of 254. Any sites with more alt alleles than the specified max will not be written. #### lenient-ploidy-validation; PGEN is a bit quirky in that it requires samples to be diploid but has a special case for sex chromosomes, which are allowed to be haploid. By default, any attempt to write a record with an unsupported ploidy will result in an exception being thrown. If this flag is used, then ploidy failures will instead be logged and the records will be written as missing. #### writer-log-file; The C++ code in the PGEN writer in PGEN-JNI will log sites that exceed max-alt-alleles and with unsupported ploidy (if lenient-ploidy-validation is set) to the specified log file, if this argument is set. #### allow-empty-pgen; Empty PGEN files are not technically valid PGEN files. However, for parallel processing purposes, it is sometimes helpful to allow the creation of empty files when there are no variants to be written. The GvsExtractCallsetPgenMerged workflow relies on this. If this flag is set and no variants are written, an empty .pgen, .psam, and .pvar.zst file will be written in `onShutdown()`. By default (i.e. if this flag is not set), if there are no",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8708:4569,validat,validation,4569,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8708,1,['validat'],['validation']
Security,til.java:141); 	at org.broadinstitute.hellbender.tools.GatherVcfsCloud.gatherWithBlockCopying(GatherVcfsCloud.java:394); 	at org.broadinstitute.hellbender.tools.GatherVcfsCloud.doWork(GatherVcfsCloud.java:143); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:119); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:176); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:195); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:137); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:158); 	at org.broadinstitute.hellbender.Main.main(Main.java:239); Caused by: java.util.concurrent.ExecutionException: com.google.cloud.storage.StorageException: 403 Forbidden; 443301511749-compute@developer.gserviceaccount.com does not have storage.objects.get access to broad-jg-dev-11k-call-set/JointGenotyping/0cb36821-b8bf-4e6d-a352-07b101f6b7d1/call-ApplyRecalibration/shard-1734/GMKF_Seidman_CHD_WGS_904.filtered.1734.vcf.gz.; 	at java.util.concurrent.FutureTask.report(FutureTask.java:122); 	at java.util.concurrent.FutureTask.get(FutureTask.java:192); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher$WorkUnit.getBuf(SeekableByteChannelPrefetcher.java:136); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher.fetch(SeekableByteChannelPrefetcher.java:255); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher.read(SeekableByteChannelPrefetcher.java:300); 	... 10 more; Caused by: com.google.cloud.storage.StorageException: 403 Forbidden; 443301511749-compute@developer.gserviceaccount.com does not have storage.objects.get access to broad-jg-dev-11k-call-set/JointGenotyping/0cb36821-b8bf-4e6d-a352-07b101f6b7d1/call-ApplyRecalibration/shard-1734/GMKF_Seidman_CHD_WGS_904.filtered.1734.vcf.gz.; 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.translate(H,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3735:2637,access,access,2637,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3735,1,['access'],['access']
Security,"tions/AnnotationFiltration/4e3bd06b-3018-4c94-ac98-feb78b924d1f/call-FilterFuncotations/shard-0/inputs/1333115969/104566-001-001.filtered.vcf.funcotated.vcf.gz \ ; --output 104566-001-001.filtered.vcf.filtered.vcf.gz \ ; --ref-version hg38 \ ; --allele-frequency-data-source gnomad --lenient true; ; ; ; ; . However, the command fails with the error message below:. ; ; ; ; [October 14, 2021 at 12:20:24 PM CEST] org.broadinstitute.hellbender.tools.funcotator.FilterFuncotations done. Elapsed time: 16.57 minutes. ; Runtime.totalMemory()=1134559232 ; java.lang.IllegalStateException: Duplicate key Gencode\_34\_annotationTranscript (attempted merging values ENST00000450305.2 and ENST00000456328.2) ; at java.base/java.util.stream.Collectors.duplicateKeyException(Collectors.java:133) ; at java.base/java.util.stream.Collectors.lambda$uniqKeysMapAccumulator$1(Collectors.java:180) ; at java.base/java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169) ; at java.base/java.util.HashMap$KeySpliterator.forEachRemaining(HashMap.java:1603) ; at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484) ; at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474) ; at java.base/java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:913) ; at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234) ; at java.base/java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:578) ; at org.broadinstitute.hellbender.tools.funcotator.filtrationRules.AlleleFrequencyUtils.lambda$buildMaxMafRule$1(AlleleFrequencyUtils.java:30) ; at org.broadinstitute.hellbender.tools.funcotator.filtrationRules.FuncotationFilter.lambda$checkFilter$0(FuncotationFilter.java:48) ; at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195) ; at java.base/java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:948) ; at java.base/java.util.stream.AbstractPipeline.copy",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7504:2398,Hash,HashMap,2398,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7504,1,['Hash'],['HashMap']
Security,"to validate inputs. (#7845); - Compute filter scatter [VS-392] (#7852); - remove withdrawn req (#7844); - Improve import error message [VS-437] (#7855); - Fix Input Validation python notebook (#7853); - Add VAT Validation check that aa_change and exon_number are consistently set. (#7850); - Ingest 10K [VS-344] (#7860); - X/Y chromosome reweighting for better extract shard runtime balance [VS-389] (#7868); - VET Ingest Validation / Allow Ingest of non-VQSR'ed data (#7870); - Fix AoU workflow bugs (#7874); - Curate input arrays to skip already ingested sample data [VS-246] (#7862); - KM upload GVS product sheet (#7883); - Default extract scatter width [VS-415] (#7878); - Volatile tasks review [VS-447] (#7880); - Update Quickstart Integration for X/Y scaling changes [VS-464] (#7881); - clean up dockstore; - Rc vs 63 vat sop documentation (#7879); - Fix up FQ and race condition issues with volatile tasks work [VS-478] (#7888); - Use gvs-internal project in integration test (#7901); - Add cost observability BQ table [VS-441] (#7891); - Add preliminary labels to queries [VS-381] (#7902); - Workflow compute costs [VS-472] (#7905); - Fix bug and update images (#7912); - VS 483 Beta user wdl (#7894); - Core storage model cost [VS-473] (#7913); - Update Quickstart & Integration to use re-blocked v2 gVCFs [VS-491] (#7924); - KM GVS documentation (#7903); - Track BigQuery costs of GVS python VS-480 (#7915); - Read cost observability table [VS-475] (#7923); - Fix Race Condition, Add Support for Extract by Array of Sample Names (ie from a Sample Set) (#7917); - Rightsize import batches [VS-486] (#7925); - [AoU DRC] Support uppercase site_ids for reblocking (#7929); - Populate cost metadata for GATK tasks. (#7919); - remove accidentally added input (#7931); - VS_492 - Beta User Jar release (#7934); - Cost WDL should throw on FISS API errors [VS-518] (#7942); - Fix bad check for missing workflow name [VS-520] (#7943); - Remove usage of service account from GvsValidateVAT.wdl (#7937",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8248:24874,Validat,Validation,24874,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8248,2,['Validat'],['Validation']
Security,tools that expect unaligned reads shouldn't validate the sequence dictionary,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4131:44,validat,validate,44,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4131,1,['validat'],['validate']
Security,tools/walkers/rnaseq/ASEReadCounter/NA12878.chr20_2444518_2637800.RNAseq.MultiContext.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/rnaseq/ASEReadCounter/NA12878.chr20_2444518_2637800.RNAseq.NON_REF.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/rnaseq/ASEReadCounter/NA12878.chr20_2444518_2637800.RNAseq.SYNONYMOUS_CODING.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/rnaseq/ASEReadCounter/NA12878.chr20_2444518_2637800.RNAseq.warnings.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/UnmarkDuplicates/allDuplicates.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/complexEvents_incompatibleDict.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/complexEvents_lexDict.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/complexEvents.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/gvcf.basepairResolution.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet_BAD_INCOMPLETE_REGION.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet.BAD_MISSING_NON_REF.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet.missingrefblock.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleBad3.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleBad.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleGood.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVarian,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3905:60524,Validat,ValidateVariants,60524,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905,1,['Validat'],['ValidateVariants']
Security,"tor to shut down; 19/04/08 19:03:28 INFO SchedulerExtensionServices: Stopping SchedulerExtensionServices; (serviceOption=None,; services=List(),; started=false); 19/04/08 19:03:28 INFO YarnClientSchedulerBackend: Stopped; 19/04/08 19:03:28 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 19/04/08 19:03:28 INFO MemoryStore: MemoryStore cleared; 19/04/08 19:03:28 INFO BlockManager: BlockManager stopped; 19/04/08 19:03:28 INFO BlockManagerMaster: BlockManagerMaster stopped; 19/04/08 19:03:28 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 19/04/08 19:03:28 INFO SparkContext: Successfully stopped SparkContext; 19:03:28.389 INFO HaplotypeCallerSpark - Shutting down engine; [April 8, 2019 7:03:28 PM UTC] org.broadinstitute.hellbender.tools.HaplotypeCallerSpark done. Elapsed time: 1.75 minutes.; Runtime.totalMemory()=941096960; Exception in thread ""main"" java.lang.StackOverflowError; 	at java.util.HashMap.putMapEntries(HashMap.java:501); 	at java.util.HashMap.<init>(HashMap.java:490); 	at com.esotericsoftware.kryo.Generics.<init>(Generics.java:47); 	at com.esotericsoftware.kryo.serializers.FieldSerializerGenericsUtil.buildGenericsScope(FieldSerializerGenericsUtil.java:116); 	at com.esotericsoftware.kryo.serializers.FieldSerializerGenericsUtil.newCachedFieldOfGenericType(FieldSerializerGenericsUtil.java:225); 	at com.esotericsoftware.kryo.serializers.FieldSerializer.newCachedField(FieldSerializer.java:368); 	at com.esotericsoftware.kryo.serializers.FieldSerializer.createCachedFields(FieldSerializer.java:331); 	at com.esotericsoftware.kryo.serializers.FieldSerializer.rebuildCachedFields(FieldSerializer.java:261); 	at com.esotericsoftware.kryo.serializers.FieldSerializer.rebuildCachedFields(FieldSerializer.java:182); 	at com.esotericsoftware.kryo.serializers.FieldSerializer.write(FieldSerializer.java:508); 	at com.esotericsoftware.kryo.Kryo.writeObject(Kryo.java:552); 	at com.esotericsoftware.kryo.se",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5869:18446,Hash,HashMap,18446,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5869,1,['Hash'],['HashMap']
Security,"torSparkFn.java:38); 	at org.broadinstitute.hellbender.tools.spark.BaseRecalibratorSpark.runTool(BaseRecalibratorSpark.java:132); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:528); 	at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:30); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:138); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:162); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:205); 	at org.broadinstitute.hellbender.Main.main(Main.java:291)`; **Caused by: java.lang.IllegalArgumentException: Table1 1,3 not equal to 88,3**; 	`at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:724); 	at org.broadinstitute.hellbender.utils.recalibration.RecalUtils.combineTables(RecalUtils.java:560); 	at org.broadinstitute.hellbender.utils.recalibration.RecalibrationTables.combine(RecalibrationTables.java:144); 	at org.broadinstitute.hellbender.utils.recalibration.RecalibrationTables.inPlaceCombine(RecalibrationTables.java:178); 	at org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(JavaPairRDD.scala:1037); 	at scala.collection.TraversableOnce$$anonfun$foldLeft$1.apply(TraversableOnce.scala:157); 	at scala.collection.TraversableOnce$$anonfun$foldLeft$1.apply(TraversableOnce.scala:157); 	at scala.collection.Iterator$class.foreach(Iterator.scala:893); 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); 	at scala.collection.TraversableOnce$class.foldLeft(TraversableOnce.scala:157); 	at scala.collection.AbstractIterator.foldLeft(Iterator.scala:1336); 	at scala.collection.TraversableOnce$class.aggregate(TraversableOnce.scala:214); ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5854:4697,validat,validateArg,4697,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5854,1,['validat'],['validateArg']
Security,totalMemory()=1065353216; java.lang.IllegalArgumentException: Unsupported class file major version 55; 	at org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:166); 	at org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:148); 	at org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:136); 	at org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:237); 	at org.apache.spark.util.ClosureCleaner$.getClassReader(ClosureCleaner.scala:49); 	at org.apache.spark.util.FieldAccessFinder$$anon$3$$anonfun$visitMethodInsn$2.apply(ClosureCleaner.scala:517); 	at org.apache.spark.util.FieldAccessFinder$$anon$3$$anonfun$visitMethodInsn$2.apply(ClosureCleaner.scala:500); 	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733); 	at scala.collection.mutable.HashMap$$anon$1$$anonfun$foreach$2.apply(HashMap.scala:134); 	at scala.collection.mutable.HashMap$$anon$1$$anonfun$foreach$2.apply(HashMap.scala:134); 	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236); 	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40); 	at scala.collection.mutable.HashMap$$anon$1.foreach(HashMap.scala:134); 	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732); 	at org.apache.spark.util.FieldAccessFinder$$anon$3.visitMethodInsn(ClosureCleaner.scala:500); 	at org.apache.xbean.asm6.ClassReader.readCode(ClassReader.java:2175); 	at org.apache.xbean.asm6.ClassReader.readMethod(ClassReader.java:1238); 	at org.apache.xbean.asm6.ClassReader.accept(ClassReader.java:631); 	at org.apache.xbean.asm6.ClassReader.accept(ClassReader.java:355); 	at org.apache.spark.util.ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$14.apply(ClosureCleaner.scala:307); 	at org.apache.spark.util.ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$14.apply(ClosureCleaner.scala:306); 	at scala.collection.immutable.List.foreach(List.scala:392); 	at org.apache.spark.util.ClosureCl,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7035:6929,Hash,HashTable,6929,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7035,1,['Hash'],['HashTable']
Security,"trandBiasBySample - Annotation will not be calculated, genotype is not called or alleleLikelihoodMap is null; 00:10:41.089 WARN DepthPerSampleHC - Annotation will not be calculated, genotype is not called or alleleLikelihoodMap is null; 00:10:41.089 WARN StrandBiasBySample - Annotation will not be calculated, genotype is not called or alleleLikelihoodMap is null; 00:10:45.460 WARN DepthPerSampleHC - Annotation will not be calculated, genotype is not called or alleleLikelihoodMap is null; 00:10:45.460 WARN StrandBiasBySample - Annotation will not be calculated, genotype is not called or alleleLikelihoodMap is null; 00:11:09.609 WARN TaskMemoryManager:381 - leak 166.6 MB memory from org.apache.spark.util.collection.ExternalAppendOnlyMap@60a3c432; 00:11:09.611 ERROR Executor:91 - Exception in task 15.0 in stage 1.0 (TID 519); java.lang.IllegalStateException: Duplicate key [B@4e233a3c; at java.util.stream.Collectors.lambda$throwingMerger$0(Collectors.java:133); at java.util.HashMap.merge(HashMap.java:1253); at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1320); at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.PairHMMLikelihoodCalculationEngine.buildGapContinuationPenalties(PairHMMLikelihoodCalculat; ionEngine.java:304); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.PairHMMLikelihoodCalculationEngine.computeReadLikelihoods(PairHMMLikelihoodCalculationEngi; ne.java:253); at org.broadinstitute.hellbe",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3018:1454,Hash,HashMap,1454,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3018,1,['Hash'],['HashMap']
Security,"ts and custom serializers (gCNV Spark tests are currently disabled). **Discussion about gCNV ICG unit tests (May 1st, 2017):**; It is possible to automate the test for ComputableNodeFunctions. One initializes the parents to random values, calls the function, and checks whether it has had any side effects on the parents. One must make a random-data-provider-of-some-sort for each parent node because the parent INDArrays have different shapes. For other functions in CoverageModelEMComputeBlock and CoverageModelEMWorkspace that query ICG nodes -- one needs to create a firewall. One can elevate all such functions to classes that essentially behave functionally, (ICGNodeProvider, List<NodeKey>, extra arguments) -> output, as opposed to writing vanilla member functions such as CoverageModelEMComputeBlock.getBiasLatentPosteriorDataUnregularized, etc. Then we can write automated unit tests for these classes. Another approach is to write a thin ImmutableNDArray interface that blocks access to all mutators and returns instances of ImmutableNDArray when a matrix view is extracted (e.g. via INDArray.get(...)). This is also quite non-trivial and requires intimate familiarity with Nd4j codebase. Perhaps one could write an immutable DataBuffer for Nd4j. Finally, there might be a brute-force approach: substitute all in-plane operations such as muli and addi with mul and add, and in-place transformations such as Transforms.log(INDArray, boolean duplicate) with Transforms.log(INDArray, true), run gCNV, and require identical results. This is the easiest approach. This was my approach during the development. First, I wrote every function without in-place operations, ran the code, optimized the function with in-place ops, ran the code again, assert. If we can automate this sort of thing, it is the easiest way out. For the time being, I annotate all functions that can potentially mutate the ICG with @QueriesICG to finally decide how we'd like to proceed. I also made a TODO for writing suc",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2929:2013,access,access,2013,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2929,1,['access'],['access']
Security,"ts.CREATE_INDEX : false; 17:43:53.163 INFO ValidateVariants - Defaults.CREATE_MD5 : false; 17:43:53.163 INFO ValidateVariants - Defaults.CUSTOM_READER_FACTORY :; 17:43:53.163 INFO ValidateVariants - Defaults.EBI_REFERENCE_SERVICE_URL_MASK : http://www.ebi.ac.uk/ena/cram/md5/%s; 17:43:53.163 INFO ValidateVariants - Defaults.NON_ZERO_BUFFER_SIZE : 131072; 17:43:53.163 INFO ValidateVariants - Defaults.REFERENCE_FASTA : null; 17:43:53.163 INFO ValidateVariants - Defaults.SAM_FLAG_FIELD_FORMAT : DECIMAL; 17:43:53.163 INFO ValidateVariants - Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 17:43:53.163 INFO ValidateVariants - Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 17:43:53.163 INFO ValidateVariants - Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 17:43:53.163 INFO ValidateVariants - Defaults.USE_CRAM_REF_DOWNLOAD : false; 17:43:53.163 INFO ValidateVariants - Deflater IntelDeflater; 17:43:53.163 INFO ValidateVariants - Inflater IntelInflater; 17:43:53.163 INFO ValidateVariants - Initializing engine; 17:43:53.270 INFO FeatureManager - Using codec VCFCodec to read file file:///Users/louisb/Workspace/gatk/src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleGood.vcf; 17:43:53.287 INFO FeatureManager - Using codec VCFCodec to read file file:///Users/louisb/Workspace/gatk/src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleGood.vcf; 17:43:53.291 WARN IndexUtils - Feature file ""/Users/louisb/Workspace/gatk/src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleGood.vcf"" appears to contain no sequence dictionary. Attempting to retrieve a sequence dictionary from the associated index file; 17:43:53.293 INFO ValidateVariants - Done initializing engine; 17:43:53.294 INFO ProgressMeter - Starting traversal; 17:43:53.294 INFO ProgressMeter - Current Locus Elapsed Minutes Records Processed Records/Minute; 17:43:53.302 INFO ValidateVariants - Shu",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2509:3121,Validat,ValidateVariants,3121,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2509,1,['Validat'],['ValidateVariants']
Security,tute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet_BAD_INCOMPLETE_REGION.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet.BAD_MISSING_NON_REF.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet.missingrefblock.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleBad3.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleBad.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleGood.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleRSIDonPositionNotInDBSNP.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationUnusedAllelesBugFix.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/validation/basicshortmutpileup/IS3.snv.indel.sv-vs-G15512.prenormal.sorted.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/validation/basicshortmutpileup/synthetic.challenge.set1.tumor-vs-synthetic.challenge.set1.normal-filtered.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/CalculateGenotypePosteriors/CEUtriMixedPloidyTest.vcf; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/CalculateGenotypePosteriors/CEUtrioPopPriorsTest_chr1.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/CalculateGenotypePosteriors/CEUtrioTest_chr1.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/CalculateGenotypePosteriors/expectedCGP_testFamilyPriors_chr1.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3905:61618,Validat,ValidateVariants,61618,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905,2,"['Validat', 'validat']","['ValidateVariants', 'validationUnusedAllelesBugFix']"
Security,uisshe/work/NGS/wdl/test_workflow_cnv/germline/cromwell-executions/CNVGermlineCohort8/Homo_sapiens_assembly38.bed.preprocessed.filtered.scattered.0154.interval_list:/paedyl01/disk1/louisshe/work/NGS/wdl/test_workflow_cnv/germline/cromwell-executions/CNVGermli947966988/Homo_sapiens_assembly38.bed.preprocessed.filtered.scattered.0154.interval_list:; 21:06:12.640 DEBUG FeatureCache - Cache hit rate was 0.00% (0 out of 0 total queries); 21:06:12.645 INFO IntervalArgumentCollection - Processing 4999155 bp from intervals; 21:06:12.656 INFO GermlineCNVCaller - Reading and validating annotated intervals...; 21:06:18.914 WARN GermlineCNVCaller - Sequence dictionary in annotated-intervals file does not match the master sequence dictionary.; 21:06:19.130 INFO GermlineCNVCaller - GC-content annotations for intervals found; explicit GC-bias correction will be performed...; 21:06:19.200 INFO GermlineCNVCaller - Running the tool in COHORT mode...; 21:06:19.200 INFO GermlineCNVCaller - Validating and aggregating data from input read-count files...; 21:07:11.897 DEBUG ScriptExecutor - Executing:; 21:07:11.897 DEBUG ScriptExecutor - python; 21:07:11.897 DEBUG ScriptExecutor - /paedyl01/disk1/louisshe/tmp/gatk/cohort_denoising_calling.418897092082188314.py; 21:07:11.897 DEBUG ScriptExecutor - --ploidy_calls_path=/paedyl01/disk1/louisshe/work/NGS/wdl/test_workflow_cnv/germline/cromwell-executions/CNVGermlineCohortWorkflow/d53c0a; 21:07:11.897 DEBUG ScriptExecutor - --output_calls_path=/paedyl01/disk1/louisshe/out/NMD/batch1_2023/batch1_all/cnv/cohort_calls/batch1_all-calls; 21:07:11.897 DEBUG ScriptExecutor - --output_tracking_path=/paedyl01/disk1/louisshe/out/NMD/batch1_2023/batch1_all/cnv/cohort_calls/batch1_all-tracking; 21:07:11.897 DEBUG ScriptExecutor - --random_seed=1984; 21:07:11.897 DEBUG ScriptExecutor - --modeling_interval_list=/paedyl01/disk1/louisshe/tmp/gatk/intervals6744296186531223263.tsv; 21:07:11.897 DEBUG ScriptExecutor - --output_model_path=/paedyl01/disk1/louisshe/o,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8952:7028,Validat,Validating,7028,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8952,1,['Validat'],['Validating']
Security,ultiple SLF4J bindings.; SLF4J: Found binding in [jar:file:/usr/hdp/2.6.3.40-13/spark2/jars/slf4j-log4j12-1.7.16.jar!/org/slf4j/impl/StaticLoggerBinder.class]; SLF4J: Found binding in [jar:file:/usr/hdp/2.6.3.40-13/spark_llap/spark-llap-assembly-1.0.0.2.6.3.40-13.jar!/org/slf4j/impl/StaticLoggerBinder.class]; SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.; SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]; java.lang.NoClassDefFoundError: org/apache/logging/log4j/core/appender/AbstractAppender; at java.lang.ClassLoader.defineClass1(Native Method); at java.lang.ClassLoader.defineClass(ClassLoader.java:763); at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142); at java.net.URLClassLoader.defineClass(URLClassLoader.java:467); at java.net.URLClassLoader.access$100(URLClassLoader.java:73); at java.net.URLClassLoader$1.run(URLClassLoader.java:368); at java.net.URLClassLoader$1.run(URLClassLoader.java:362); at java.security.AccessController.doPrivileged(Native Method); at java.net.URLClassLoader.findClass(URLClassLoader.java:361); at java.lang.ClassLoader.loadClass(ClassLoader.java:424); at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:349); at java.lang.ClassLoader.loadClass(ClassLoader.java:411); at java.lang.ClassLoader.loadClass(ClassLoader.java:357); at org.apache.logging.log4j.core.config.plugins.util.PluginRegistry.decodeCacheFiles(PluginRegistry.java:181); at org.apache.logging.log4j.core.config.plugins.util.PluginRegistry.loadFromMainClassLoader(PluginRegistry.java:119); at org.apache.logging.log4j.core.config.plugins.util.PluginManager.collectPlugins(PluginManager.java:132); at org.apache.logging.log4j.core.pattern.PatternParser.<init>(PatternParser.java:131); at org.apache.logging.log4j.core.pattern.PatternParser.<init>(PatternParser.java:112); at org.apache.logging.log4j.core.layout.PatternLayout.createPatternParser(PatternLayout.java:220); at org.apache.logging.log4j.core.layou,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5126:2903,secur,security,2903,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5126,1,['secur'],['security']
Security,"un(Executor.scala:274); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748). 00:11:09.634 ERROR TaskSetManager:70 - Task 15 in stage 1.0 failed 1 times; aborting job; 00:11:09.810 WARN TaskSetManager:66 - Lost task 33.0 in stage 1.0 (TID 528, localhost): TaskKilled (killed intentionally); 00:11:24.786 INFO HaplotypeCallerSpark - Shutting down engine; [May 26, 2017 12:11:24 AM UTC] org.broadinstitute.hellbender.tools.HaplotypeCallerSpark done. Elapsed time: 10.58 minutes.; Runtime.totalMemory()=16622026752; org.apache.spark.SparkException: Job aborted due to stage failure: Task 15 in stage 1.0 failed 1 times, most recent failure: Lost task 15.0 in stage 1.0 (TID 519; , localhost): java.lang.IllegalStateException: Duplicate key [B@4e233a3c; at java.util.stream.Collectors.lambda$throwingMerger$0(Collectors.java:133); at java.util.HashMap.merge(HashMap.java:1253); at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1320); at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.PairHMMLikelihoodCalculationEngine.buildGapContinuationPenalties(PairHMMLikelihoodCalculat; ionEngine.java:304); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.PairHMMLikelihoodCalculationEngine.computeReadLikelihoods(PairHMMLikelihoodCalculationEngi; ne.java:253); at org.broadinsti",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3018:9943,Hash,HashMap,9943,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3018,1,['Hash'],['HashMap']
Security,"unMain$1(SparkSubmit.scala:198); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:228); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:137); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.nio.file.FileSystemNotFoundException: Provider ""gs"" not installed; 	at java.nio.file.Paths.get(Paths.java:147); 	at org.broadinstitute.hellbender.engine.spark.datasources.ReferenceFileSparkSource.getReferencePath(ReferenceFileSparkSource.java:53); 	at org.broadinstitute.hellbender.engine.spark.datasources.ReferenceFileSparkSource.getReferenceBases(ReferenceFileSparkSource.java:60); 	at org.broadinstitute.hellbender.engine.spark.datasources.ReferenceMultiSparkSource.getReferenceBases(ReferenceMultiSparkSource.java:89); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.BreakEndVariantType.getRefBaseString(BreakEndVariantType.java:89); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.BreakEndVariantType.access$200(BreakEndVariantType.java:20); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.BreakEndVariantType$InterChromosomeBreakend.<init>(BreakEndVariantType.java:253); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.BreakEndVariantType$InterChromosomeBreakend.getOrderedMates(BreakEndVariantType.java:261); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.NovelAdjacencyAndAltHaplotype.toSimpleOrBNDTypes(NovelAdjacencyAndAltHaplotype.java:246); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.SimpleNovelAdjacencyInterpreter.inferType(SimpleNovelAdjacencyInterpreter.java:129); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.SimpleNovelAdjacencyInterpreter.lambda$inferTypeFromSingleContigSimpleChimera$24ddc343$1(SimpleNovelAdjacencyInterpreter.java:107); 	at org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(JavaPairRDD.scala:1043); 	at org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6070:8743,access,access,8743,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6070,1,['access'],['access']
Security,"unity/posts/360056339072-Mutect2-Need-one-or-two-reads-to-construct-a-fragment. --. The command I used below is able to generate the .vcf output along with its index and stats file, but my snakemake run fails to complete due to exit status (3 instead of 0). I wonder if below error is caused by trying to split the runs by chromosome and setting improper interval padding. Thank you for your time. ------------------------------------------------------------------------------------------------------------------------------------. a) GATK version used. _The Genome Analysis Toolkit (GATK) v4.1.4.1_. b) Exact GATK commands used. _/usr/bin/time -v gatk --java-options ""-Xmx10G"" Mutect2 -R ../reference/indices\_010920/GRCh38.d1.vd1.fa -L chr4.bed -I chr4.bam --max-mnp-distance 0 --interval-padding 100 -O chr4.vcf.gz_. c) The entire error log if applicable. _java.lang.IllegalArgumentException: Need one or two reads to construct a fragment_ ; _at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:725)_ ; _at org.broadinstitute.hellbender.utils.read.Fragment.create(Fragment.java:43)_ ; _at org.broadinstitute.hellbender.utils.read.Fragment.createAndAvoidFailure(Fragment.java:58)_ ; _at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193)_ ; _at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1376)_ ; _at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481)_ ; _at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471)_ ; _at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708)_ ; _at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)_ ; _at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499)_ ; _at org.broadinstitute.hellbender.utils.genotyper.AlleleLikelihoods.groupEvidence(AlleleLikelihoods.java:589)_ ; _at org.broadinstitute.hellbender.tools.walkers.mutect.SomaticGenotypingEngine.callMutations(SomaticGenotypingEngine.java",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6419:1130,validat,validateArg,1130,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6419,1,['validat'],['validateArg']
Security,"unter generatd only header in output file. Here I enclosed my command and stderr log. Please help me to check it. Thank you!. If you are seeing an error, please provide(REQUIRED) : ; ; a) GATK version used: 4.1.8.1 ; ; b) Exact command used:. java -Xmx8000m -Djava.io.tmpdir=/broad/hptmp/cbao \\ ; ; \-jar ${path2gatk}/gatk-package-4.1.8.1-local.jar \\ ; ; ASEReadCounter \\ ; ; \-L scattered.interval\_list \\ ; ; \-R Homo\_sapiens\_assembly19.fasta \\ ; ; \-V 1000G\_phase1.snps.high\_confidence.b37.vcf.gz \\ ; ; \-I downsample\_10k.bam \\ ; ; \-O output.txt --verbosity INFO. c) Entire error log:. 19:13:25.991 INFO NativeLibraryLoader - Loading libgkl\_compression.so from jar:file:/broad/software/free/Linux/redhat\_7\_x86\_64/pkgs/gatk\_4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl\_compression.so. Jun 14, 2021 7:13:26 PM shaded.cloud\_nio.com.google.auth.oauth2.DefaultCredentialsProvider warnAboutProblematicCredentials. WARNING: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a ""quota exceeded"" or ""API not enabled"" error. For more information about service accounts, see [https://cloud.google.com/docs/authentication/](https://cloud.google.com/docs/authentication/). 19:13:26.217 INFO ASEReadCounter - ------------------------------------------------------------. 19:13:26.218 INFO ASEReadCounter - The Genome Analysis Toolkit (GATK) v4.1.8.1. 19:13:26.218 INFO ASEReadCounter - For support and documentation go to [https://software.broadinstitute.org/gatk/](https://software.broadinstitute.org/gatk/). 19:13:26.219 INFO ASEReadCounter - Executing as [cbao@uger-c009.broadinstitute.org](mailto:cbao@uger-c009.broadinstitute.org) on Linux v3.10.0-1160.15.2.el7.x86\_64 amd64. 19:13:26.219 INFO ASEReadCounter - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7327:1758,authenticat,authenticated,1758,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7327,1,['authenticat'],['authenticated']
Security,"unter to call allelic read counts on 1000 genome reference. But, I found ASEReadCounter generatd only header in output file. Here I enclosed my command and stderr log. Please help me to check it. Thank you!. If you are seeing an error, please provide(REQUIRED) :; a) GATK version used: 4.1.8.1; b) Exact command used:. java -Xmx8000m -Djava.io.tmpdir=/broad/hptmp/cbao \; -jar ${path2gatk}/gatk-package-4.1.8.1-local.jar \; ASEReadCounter \; -L scattered.interval_list \; -R Homo_sapiens_assembly19.fasta \; -V 1000G_phase1.snps.high_confidence.b37.vcf.gz \; -I downsample_10k.bam \; -O output.txt --verbosity INFO . c) Entire error log:; 19:13:25.991 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/broad/software/free/Linux/redhat_7_x86_64/pkgs/gatk_4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Jun 14, 2021 7:13:26 PM shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider warnAboutProblematicCredentials; WARNING: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a ""quota exceeded"" or ""API not enabled"" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/.; 19:13:26.217 INFO ASEReadCounter - ------------------------------------------------------------; 19:13:26.218 INFO ASEReadCounter - The Genome Analysis Toolkit (GATK) v4.1.8.1; 19:13:26.218 INFO ASEReadCounter - For support and documentation go to https://software.broadinstitute.org/gatk/; 19:13:26.219 INFO ASEReadCounter - Executing as cbao@uger-c009.broadinstitute.org on Linux v3.10.0-1160.15.2.el7.x86_64 amd64; 19:13:26.219 INFO ASEReadCounter - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_181-b13; 19:13:26.219 INFO ASEReadCounter - Start Date/Time: June 14, 2021 7:13:25 PM UTC; 19:13:26.219 IN",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7314:1034,authenticat,authenticated,1034,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7314,1,['authenticat'],['authenticated']
Security,urces/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/complexEvents_incompatibleDict.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/complexEvents_lexDict.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/complexEvents.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/gvcf.basepairResolution.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet_BAD_INCOMPLETE_REGION.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet.BAD_MISSING_NON_REF.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet.missingrefblock.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleBad3.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleBad.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleGood.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleRSIDonPositionNotInDBSNP.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationUnusedAllelesBugFix.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/validation/basicshortmutpileup/IS3.snv.indel.sv-vs-G15512.prenormal.sorted.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/validation/basicshortmutpileup/synthetic.challenge.set1.tumor-vs-synthetic.challenge.set1.normal-filtered.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/CalculateGenotypePosteriors/CEUtriMixedPloidyTest.vcf; src/test/re,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3905:61155,Validat,ValidateVariants,61155,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905,1,['Validat'],['ValidateVariants']
Security,"ush with batch size 10000 and process rate 2 minutes.; [2020-07-14 05:09:30,83] [info] MaterializeWorkflowDescriptorActor [968be82c]: Parsing workflow as WDL 1.0; [2020-07-14 05:09:31,60] [info] MaterializeWorkflowDescriptorActor [968be82c]: Call-to-Backend assignments: ValidateBamsWf.ValidateBAM -> Local; [2020-07-14 05:09:31,82] [warn] Local [968be82c]: Key/s [memory, disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.; [2020-07-14 05:09:35,38] [info] Not triggering log of token queue status. Effective log interval = None; [2020-07-14 05:09:37,15] [info] WorkflowExecutionActor-968be82c-eef3-4bdb-a1ab-3d4e2ca70674 [968be82c]: Starting ValidateBamsWf.ValidateBAM; [2020-07-14 05:09:37,39] [info] Assigned new job execution tokens to the following groups: 968be82c: 1; [2020-07-14 05:09:41,61] [warn] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: Unrecognized runtime attribute keys: disks, memory; [2020-07-14 05:09:41,71] [info] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: /gatk/gatk \; ValidateSamFile \; --INPUT /cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/inputs/-1942028726/test.bam \; --OUTPUT test.validation_.txt \; --MODE SUMMARY; [2020-07-14 05:09:41,76] [info] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: executing: # make sure there is no preexisting Docker CID file; rm -f /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/docker_cid; # run as in the original configuration without --rm flag (will remove later); docker run \; --cidfile /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/docker_cid \; -i \; \; --entrypoint /bin/bash \; -v /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6710:4598,Validat,ValidateBAM,4598,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710,1,['Validat'],['ValidateBAM']
Security,"using full (even sites-only) VCFs for BQSR is heavy, especially in spark, when we broadcast them. They can go > 10GB in size. Really, it's just a few million positions, so we could compress it hugely: say we have 4 million variants to consider (common sites) - that's just 4M*32bits = 16 MB. . This would require creating a special format for this (or finding an existing one that works for this case). note that need to represent indel positions (with start and end, which complicates things) too but they are much less common (1 in 10 compared to snps). Or maybe Using a BloomFilter is the way to go. For a 10^-3 probability of failure and 4 million entries we only need ~7MB of size with 10 hash functions",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1407:694,hash,hash,694,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1407,1,['hash'],['hash']
Security,"ute/gsa-unstable/issues/1053#issuecomment-262613997). Agreed. ---. @ronlevine commented on [Thu Nov 24 2016](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-262635204). The change should be a lot simpler than proposed. The code can validate the number of alleles before it checks for the presence of genotypes in [VariantContext#validateChromosomeCounts](https://github.com/samtools/htsjdk/blob/master/src/main/java/htsjdk/variant/variantcontext/VariantContext.java#L1236). . ---. @ldgauthier commented on [Mon Nov 28 2016](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-263277972). Sorry, I needed to refresh my memory. I actually don't want to bypass AC validation for variants without genotypes, but I think you already figured that out. My proposal was more general, but you're right -- AC and AF should always have the same count as alt alleles and we don't need to check the header for that. When this came up (a year and a half ago!) we were thinking about validating all the info field annotations. ---. @ronlevine commented on [Mon Nov 28 2016](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-263280085). That's exactly what I did in https://github.com/samtools/htsjdk/pull/759. I can expand this to all INFO field annotations. ---. @ldgauthier commented on [Tue Dec 06 2016](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-265221057). Expanding to all INFO annotations would be wonderful, but that can be a separate issue. ---. @ronlevine commented on [Tue Dec 06 2016](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-265223581). That's not the only one, @magicDGS requested validating the `AF` values (which can be a separate issue). . ---. @vdauwera commented on [Tue Dec 06 2016](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-265226356). I think this one requires some additional discussion, so let's hold off for now -- it's not essential f",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2507:6600,validat,validating,6600,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2507,1,['validat'],['validating']
Security,"uthier/scratch/supportingMultiA.vcf; > Should fail AC/AF validation at; > 1 768589 . A C,G 76 PASS AC=1;AF=0.00047;AN=2120; > See results using:; > ; > use VCFtools; > vcf-validator /humgen/gsa-hpprojects/dev/gauthier/scratch/supportingMultiA.vcf; > ; > which outputs:; > INFO field at 1:768589 .. INFO tag [AC=1] expected different number of; > values (expected 2, found 1),INFO tag [AF=0.00047] expected different; > number of values (expected 2, found 1); > Notes; > ; > Currently, all the validation modes call out to HTSJDK. Do we want to put; > the new functionality there as well?; > ; > —; > Reply to this email directly or view it on GitHub; > https://github.com/broadinstitute/gsa-unstable/issues/1053. ---. @ldgauthier commented on [Fri Jul 17 2015](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-122308040). Today I learned that the way we currently build GATK, you can't point to a local htsjdk jar anymore, so this task will be two-fold:; 1) Make a PR to htsjdk with a new function in the VariantContext class for validateInfoFieldCounts(VCFInfoHeaderLine headerLine) or similar; add a test to VariantContextUnitTest.java; 2) After change 1) is merged, update ValidateVariants accordingly to use the new function and add a test to its integration tests. ---. @vdauwera commented on [Fri May 27 2016](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-222213763). @ldgauthier is this still a thing? (in the sense of not having been addressed in htsjdk). ---. @ldgauthier commented on [Fri May 27 2016](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-222214083). Still a thing. No work has been done here AFAIK. ---. @vdauwera commented on [Mon Nov 14 2016](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-260465013). This seems like fairly low-hanging fruit -- @ronlevine . ---. @ronlevine commented on [Wed Nov 23 2016](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2507:4375,validat,validateInfoFieldCounts,4375,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2507,1,['validat'],['validateInfoFieldCounts']
Security,"utputStream.java:415); at htsjdk.samtools.util.BlockCompressedOutputStream.write(BlockCompressedOutputStream.java:305); at htsjdk.samtools.util.BinaryCodec.writeBytes(BinaryCodec.java:220); at htsjdk.samtools.util.BinaryCodec.writeBytes(BinaryCodec.java:212); at htsjdk.samtools.BAMRecordCodec.encode(BAMRecordCodec.java:168); at htsjdk.samtools.BAMFileWriter.writeAlignment(BAMFileWriter.java:134); ... 12 more; Caused by: java.io.IOException: Stale file handle; at java.base/sun.nio.ch.FileDispatcherImpl.write0(Native Method); at java.base/sun.nio.ch.FileDispatcherImpl.write(FileDispatcherImpl.java:62); at java.base/sun.nio.ch.IOUtil.writeFromNativeBuffer(IOUtil.java:115); at java.base/sun.nio.ch.IOUtil.write(IOUtil.java:80); at java.base/sun.nio.ch.FileChannelImpl.write(FileChannelImpl.java:280); at java.base/java.nio.channels.Channels.writeFullyImpl(Channels.java:74); at java.base/java.nio.channels.Channels.writeFully(Channels.java:97); at java.base/java.nio.channels.Channels.access$000(Channels.java:62); at java.base/java.nio.channels.Channels$1.write(Channels.java:172); at java.base/java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:81); at java.base/java.io.BufferedOutputStream.write(BufferedOutputStream.java:127); at htsjdk.samtools.util.BinaryCodec.writeBytes(BinaryCodec.java:220). Error type2:. gatk --java-options ""-Xmx32G -XX:ParallelGCThreads=8 -Djava.io.tmpdir=/group/zhougrp2/dguan/tmp"" SplitNCigarReads --spark-runner LOCAL -I 10_mkdup/SAMN05828173_mkdup.bam -R /group/zhougrp2/dguan/00_ref/Gallus_gallus.GRCg6a.dna.toplevel.fa -L /group/zhougrp2/dguan/00_ref/chicken_chr.list -O 11_cigar/SAMN05828173_cigar.bam --create-output-bam-index true --max-reads-in-memory 5000. 00:01:27.003 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/dguan/anaconda3/envs/Chicken_GTEx/share/gatk4-4.1.9.0-0/gatk-package-4.1.9.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Feb 21, 2021 12:01:27 AM shaded.cloud_nio.com.google.auth.o",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7091:61510,access,access,61510,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7091,1,['access'],['access']
Security,"utputVariantMD5 false --lenient false --addOutputSAMProgramRecord true --cloudPrefetchBuffer 40 --cloudIndexPrefetchBuffer -1 --disableBamIndexCaching false --help false --version false --showHidden false --verbosity INFO --QUIET false --use_jdk_deflater false --use_jdk_inflater false --disableToolDefaultReadFilters false; [March 21, 2017 5:43:53 PM EDT] Executing as louisb@WMD2A-31E on Mac OS X 10.11.6 x86_64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_112-b16; Version: Version:4.alpha.2-189-g724fbd0-SNAPSHOT; 17:43:53.162 INFO ValidateVariants - Defaults.BUFFER_SIZE : 131072; 17:43:53.162 INFO ValidateVariants - Defaults.COMPRESSION_LEVEL : 1; 17:43:53.162 INFO ValidateVariants - Defaults.CREATE_INDEX : false; 17:43:53.163 INFO ValidateVariants - Defaults.CREATE_MD5 : false; 17:43:53.163 INFO ValidateVariants - Defaults.CUSTOM_READER_FACTORY :; 17:43:53.163 INFO ValidateVariants - Defaults.EBI_REFERENCE_SERVICE_URL_MASK : http://www.ebi.ac.uk/ena/cram/md5/%s; 17:43:53.163 INFO ValidateVariants - Defaults.NON_ZERO_BUFFER_SIZE : 131072; 17:43:53.163 INFO ValidateVariants - Defaults.REFERENCE_FASTA : null; 17:43:53.163 INFO ValidateVariants - Defaults.SAM_FLAG_FIELD_FORMAT : DECIMAL; 17:43:53.163 INFO ValidateVariants - Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 17:43:53.163 INFO ValidateVariants - Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 17:43:53.163 INFO ValidateVariants - Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 17:43:53.163 INFO ValidateVariants - Defaults.USE_CRAM_REF_DOWNLOAD : false; 17:43:53.163 INFO ValidateVariants - Deflater IntelDeflater; 17:43:53.163 INFO ValidateVariants - Inflater IntelInflater; 17:43:53.163 INFO ValidateVariants - Initializing engine; 17:43:53.270 INFO FeatureManager - Using codec VCFCodec to read file file:///Users/louisb/Workspace/gatk/src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleGood.vcf; 17:43:53.287 INFO FeatureManager - Using codec VCFCodec to read file file:/",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2509:2438,Validat,ValidateVariants,2438,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2509,1,['Validat'],['ValidateVariants']
Security,validatevariants -gvcf fix,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3530:0,validat,validatevariants,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3530,1,['validat'],['validatevariants']
Security,"vol002/COVID/GenomicDB/tmp/tmpint00 --include-non-variant-sites false --merge-input-intervals false --input-is-somatic false --tumor-lod-to-emit 3.5 --allele-fraction-error 0.001 --keep-combined-raw-annotations false --annotate-with-num-discovered-alleles false --heterozygosity 0.001 --indel-heterozygosity 1.25E-4 --heterozygosity-stdev 0.01 --standard-min-confidence-threshold-for-calling 30.0 --max-alternate-alleles 6 --max-genotype-count 1024 --sample-ploidy 2 --num-reference-samples-if-no-call 0 --genomicsdb-use-bcf-codec false --genomicsdb-shared-posixfs-optimizations false --only-output-calls-starting-in-intervals false --interval-set-rule UNION --interval-padding 0 --interval-exclusion-padding 0 --interval-merging-rule ALL --read-validation-stringency SILENT --seconds-between-progress-updates 10.0 --disable-sequence-dictionary-validation false --create-output-bam-index true --create-output-bam-md5 false --create-output-variant-index true --create-output-variant-md5 false --lenient false --add-output-sam-program-record true --add-output-vcf-command-line true --cloud-prefetch-buffer 40 --cloud-index-prefetch-buffer -1 --disable-bam-index-caching false --sites-only-vcf-output false --help false --version false --showHidden false --verbosity INFO --QUIET false --use-jdk-deflater false --use-jdk-inflater false --gcs-max-retries 20 --gcs-project-for-requester-pays --disable-tool-default-read-filters false --disable-tool-default-annotations false --enable-all-annotations false --allow-old-rms-mapping-quality-annotation-data false"",Version=""4.1.9.0"",Date=""5 f<E9>vrier 2021 10:42:27 CET""`. Please note the `f<E9>vrier` at the end when the file is read with `less` on an UTF-8 system. #### Steps to reproduce. Run `gatk GenotypeGVCFs` with a french locale when the `date` command produces a line with an accent (in February, August or December). #### Expected behavior; The output file's encoding should be UTF-8. #### Actual behavior; The output file's encoding is ISO-8859-1.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7081:1526,validat,validation,1526,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7081,1,['validat'],['validation']
Security,"where after clipping an alignment (M -> S, e.g. for yielding sequence from one chimeric alignment to an overlapping one), a whole alignment block is clipped away and exposes a neighboring I/D operation. -------. If one is interested in the detail, the following assembly contig, when the 1st alignment yields 28 overlapping bases to the 2nd alignment, demonstrates the above edge case; ```; asm004994:tig00000	0	chr2	128791173	60	1190M4D53M2I26M2I31M2D28M1422S	*	0	0	GCTGGCCGGCCCTTCAGGCCACTCGTGCTCTCAGCCAGGCAGTTGCTCCAATAAAGTCCAGGGCCAGCCCTGCCAGGGCCTCAGCCCCACACCTCGGGGAGTGCTGCTCCCAGCTCCCACTCTGCCCTGCTCTCTGCCCTGTGCCTCTGCCTCCCGGCAGGGCTCCCCCCACACATGGAATGAATGCTTCTCTGGCATACTCTGATTTCACCGCAGCCACAGCCGCCTTTCTAGAATGGAAGTCTGAGTACATCAGCGACTCTCCTCACTGGGCCTTTGTCAGGCGGCCTTGCCAGTCCACCTCTTGTCGTGACCTGCCTTGCAGCGTCCGAAGCCAAATATGCTGTGCCTCCTCCTTTTGCCAGGATATTCCTGCTGCTGCCTGGAGATCCTCTTCACCCTTCACCTGGTGGAGAAGCCTTCTCAGCCCCACCAGCGGTCTCCAAACCCAGCCAAGGACTCAGAGTGTGGGGCCTGAAGGAGGGGCTCTCAGCAAAGCCTTCCTGGATGAAGGGGCTCATCCTCTGCATTGCATGGTGAGAAAAAGGCCCAGAAAGGTGAGCAGGAGATGCTAAACCCCGTCACCCACGCACCAGTCCCACCCGAACGGGGTGCCGTCCACTCTCTCACCCCTATGACGACATCTGAGATCCCGTGTTGAGTTGGTCGGCTTCCTCAGATTGCCTTCTCCCCTGCCAGCCCCAGACCCTGCGGGTGTGGAGCGGGAGCCCAGGAAGCAAACCTCAGCAGCCCTGTGTGGGGACAGGGAGGCCACTCTGCAGAGGACCGCTGAGCTGTCTCCATTGTGGTTTAGGAACTGCCCAGGTAAGGAGCCCTGGTGGATGCTGAGCAGGGGTTCCAGGCAGGGGAGCGGCATGAACCAAGGCCACAGGTGGACCTGGGGAACTGGAGATGCTCCCTGTGGGGGAAGCAAAAGTGAACAGATCATAATAAAGAAGCAAGAGCTCTGTGCCCAGTCATGCAAGGAGACCACAGGGTCACATCGCAGGAGACAGCAGGGGATGCATAACAGGGGGAACATGACCCCGCGCGTGCACTCACATCCGCACAGTGTCTCACACACACATCCACACACAGTGTCTCACACAAAGACCTCTCACACACACACATCCACACACAGTGTCTCTCACACACACACCTCACACACATGCACAGTGTCACACACATCTCACTCACACACAGTGTCACACACACATGCACACACAGTGTCTCTCACACACACCTCTCTCACACACACGCACACACAGTGTCACACACACATGCACACACAACCCTCACACATCCACAGTGTCTCACACACACATCCACACACAGTGTCTCTCACAAAGACCTCTCACACACACACATCCACACACATGCACAGTGTCACACACATCTCACACACGCACAGTGTCTCACACACACATGCACACACAACACCTCACACATCCACACAGTGTCTCACACACACACATCCACACACAGTCTCACACACATCTCTCACACACACGCACACATGGTGTCACACACACAT",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4262:166,expose,exposes,166,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4262,1,['expose'],['exposes']
Security,"will still provide the background default (or the built-in ploidy of 2 for humans), but the user input value will supersede these in overlapping regions. Note that the overlap is checked against the active region, meaning variants near the boundary of the `--ploidy-regions` file may end up with GT fields having ploidy slightly differently than expected, for example if your custom region overlaps a given active region but the variant ends up being written to a location outside that interval. In this case the ploidy from the user input would be used rather than any other default. # Implementation Details. The key idea is to allow `HaplotypeCallerEngine` to initialize multiple genotyping engines based on the `--ploidy-regions` input. The intervals are first parsed to check for positive integer ploidy values, and then used to create hashmaps of ploidy -> genotyper. The engine uses two types of genotypers: one for active region determination and one for doing the actual genotyping. Both admit a ploidy paramter passed via `hcArgs`. This PR modifies the `HaplotypeCallerArgumentCollection` class to include a method for creating copies of this object with differing ploidy amounts. These then get fed to the constructors of the appropriate genotyper classes, which are organized into two hashmaps. In every situation where one of these genotypers is used, we instead begin the scope by calling a ""get local genotyper"" method that performs the logic of checking whether the region of interest overlaps any of the user-provided regions, and then selects the appropriate `localEngine` genotyper for the task, ensuring the user-provided ploidy supersedes any other defaults. # A Note on Dependency. The flexibility of using either .bed or .interval_list files to specify this information depends on [this](https://github.com/samtools/htsjdk/pull/1680) PR in htsjdk being made into a full release, and then bumping the dependency of GATK. The code in this PR would not compile until this happens.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8464:1828,hash,hashmaps,1828,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8464,1,['hash'],['hashmaps']
Security,"xUtils - Feature file ""/Users/louisb/Workspace/gatk/src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleGood.vcf"" appears to contain no sequence dictionary. Attempting to retrieve a sequence dictionary from the associated index file; 17:43:53.293 INFO ValidateVariants - Done initializing engine; 17:43:53.294 INFO ProgressMeter - Starting traversal; 17:43:53.294 INFO ProgressMeter - Current Locus Elapsed Minutes Records Processed Records/Minute; 17:43:53.302 INFO ValidateVariants - Shutting down engine; [March 21, 2017 5:43:53 PM EDT] org.broadinstitute.hellbender.tools.walkers.variantutils.ValidateVariants done. Elapsed time: 0.00 minutes.; Runtime.totalMemory()=194510848; java.lang.IllegalArgumentException: Illegal base [] seen in the allele; 	at htsjdk.variant.variantcontext.Allele.create(Allele.java:231); 	at htsjdk.variant.variantcontext.Allele.create(Allele.java:374); 	at org.broadinstitute.hellbender.tools.walkers.variantutils.ValidateVariants.apply(ValidateVariants.java:181); 	at org.broadinstitute.hellbender.engine.VariantWalkerBase.lambda$traverse$0(VariantWalkerBase.java:104); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); 	at org.broadinstitute.hellbender.engine.VariantWalkerBase.traverse",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2509:4599,Validat,ValidateVariants,4599,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2509,1,['Validat'],['ValidateVariants']
Security,"xisting Docker CID file; rm -f /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/docker_cid; # run as in the original configuration without --rm flag (will remove later); docker run \; --cidfile /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/docker_cid \; -i \; \; --entrypoint /bin/bash \; -v /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0:/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0:delegated \; broadinstitute/gatk@sha256:18146e79d06787483310e5de666502090a480e10ac0fad06a36a5e7a5c9bb1dc /cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/script. # get the return code (working even if the container was detached); rc=$(docker wait cat /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/docker_cid). # remove the container after waiting; docker rm cat /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/docker_cid. # return exit code; exit $rc; [2020-07-14 05:09:45,29] [info] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: job id: 243; [2020-07-14 05:09:45,29] [info] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: Status change from - to Done; [2020-07-14 05:09:46,38] [info] WorkflowManagerActor Workflow 968be82c-eef3-4bdb-a1ab-3d4e2ca70674 failed (during ExecutingWorkflowState): Job ValidateBamsWf.ValidateBAM:0:1 exited with return code -1 which has not been declared as a valid return code. See 'continueOnReturnCode' runtime attribute for more details.; Check the content of stderr for potential additional information: /gatk/my_dat",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6710:6168,Validat,ValidateBamsWf,6168,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710,2,['Validat'],"['ValidateBAM', 'ValidateBamsWf']"
Security,"xtensionServices: Stopping SchedulerExtensionServices; (serviceOption=None,; services=List(),; started=false); 19/04/08 19:03:28 INFO YarnClientSchedulerBackend: Stopped; 19/04/08 19:03:28 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 19/04/08 19:03:28 INFO MemoryStore: MemoryStore cleared; 19/04/08 19:03:28 INFO BlockManager: BlockManager stopped; 19/04/08 19:03:28 INFO BlockManagerMaster: BlockManagerMaster stopped; 19/04/08 19:03:28 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 19/04/08 19:03:28 INFO SparkContext: Successfully stopped SparkContext; 19:03:28.389 INFO HaplotypeCallerSpark - Shutting down engine; [April 8, 2019 7:03:28 PM UTC] org.broadinstitute.hellbender.tools.HaplotypeCallerSpark done. Elapsed time: 1.75 minutes.; Runtime.totalMemory()=941096960; Exception in thread ""main"" java.lang.StackOverflowError; 	at java.util.HashMap.putMapEntries(HashMap.java:501); 	at java.util.HashMap.<init>(HashMap.java:490); 	at com.esotericsoftware.kryo.Generics.<init>(Generics.java:47); 	at com.esotericsoftware.kryo.serializers.FieldSerializerGenericsUtil.buildGenericsScope(FieldSerializerGenericsUtil.java:116); 	at com.esotericsoftware.kryo.serializers.FieldSerializerGenericsUtil.newCachedFieldOfGenericType(FieldSerializerGenericsUtil.java:225); 	at com.esotericsoftware.kryo.serializers.FieldSerializer.newCachedField(FieldSerializer.java:368); 	at com.esotericsoftware.kryo.serializers.FieldSerializer.createCachedFields(FieldSerializer.java:331); 	at com.esotericsoftware.kryo.serializers.FieldSerializer.rebuildCachedFields(FieldSerializer.java:261); 	at com.esotericsoftware.kryo.serializers.FieldSerializer.rebuildCachedFields(FieldSerializer.java:182); 	at com.esotericsoftware.kryo.serializers.FieldSerializer.write(FieldSerializer.java:508); 	at com.esotericsoftware.kryo.Kryo.writeObject(Kryo.java:552); 	at com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectField.java:80); 	a",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5869:18494,Hash,HashMap,18494,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5869,1,['Hash'],['HashMap']
Security,yHelper.java:54); 	at com.google.cloud.storage.BlobReadChannel.read(BlobReadChannel.java:124); 	at com.google.cloud.storage.contrib.nio.CloudStorageReadChannel.read(CloudStorageReadChannel.java:114); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher$WorkUnit.call(SeekableByteChannelPrefetcher.java:131); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher$WorkUnit.call(SeekableByteChannelPrefetcher.java:104); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745); Caused by: shaded.cloud_nio.com.google.api.client.googleapis.json.GoogleJsonResponseException: 403 Forbidden; 443301511749-compute@developer.gserviceaccount.com does not have storage.objects.get access to broad-jg-dev-11k-call-set/JointGenotyping/0cb36821-b8bf-4e6d-a352-07b101f6b7d1/call-ApplyRecalibration/shard-1734/GMKF_Seidman_CHD_WGS_904.filtered.1734.vcf.gz.; 	at shaded.cloud_nio.com.google.api.client.googleapis.json.GoogleJsonResponseException.from(GoogleJsonResponseException.java:145); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:113); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:40); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest$1.interceptResponse(AbstractGoogleClientRequest.java:321); 	at shaded.cloud_nio.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1056); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419); 	at shaded.cloud_nio.com.google.api.client.googleapis.ser,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3735:5067,access,access,5067,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3735,1,['access'],['access']
Security,"ync_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /home/zepengmu/tools/gatk-4.1.8.0/gatk-package-4.1.8.0-local.jar ValidateVariants -V ../../data/geno/phased/chr1-22.phased.rename.reheader.vcf.gz -R ../../../../index/hg19.fa.gz; 19:53:34.379 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/zepengmu/tools/gatk-4.1.8.0/gatk-package-4.1.8.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Oct 25, 2020 7:53:34 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 19:53:34.606 INFO ValidateVariants - ------------------------------------------------------------; 19:53:34.606 INFO ValidateVariants - The Genome Analysis Toolkit (GATK) v4.1.8.0; 19:53:34.606 INFO ValidateVariants - For support and documentation go to https://software.broadinstitute.org/gatk/; 19:53:34.607 INFO ValidateVariants - Executing as zepengmu@midway2-login1.rcc.local on Linux v3.10.0-1127.8.2.el7.x86_64 amd64; 19:53:34.607 INFO ValidateVariants - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_45-b14; 19:53:34.607 INFO ValidateVariants - Start Date/Time: October 25, 2020 7:53:34 PM CDT; 19:53:34.607 INFO ValidateVariants - ------------------------------------------------------------; 19:53:34.607 INFO ValidateVariants - ------------------------------------------------------------; 19:53:34.607 INFO ValidateVariants - HTSJDK Version: 2.22.0; 19:53:34.607 INFO ValidateVariants - Picard Version: 2.22.8; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 19:53:34.608 INFO ValidateVariants - Deflater: Intel",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6911:1413,Validat,ValidateVariants,1413,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6911,1,['Validat'],['ValidateVariants']
Security,"|0	0|0	0|0	0|0	0|0	0|1	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0; ```; Running `$HOME/gatk-4.0.11.0/gatk --java-options ""-Xmx4g"" HaplotypeCaller -R $HOME/GRCh37files/hs37d5.fa -I /mnt/fast/test.bam -O test.out.vcf.gz -L 22 --genotyping-mode GENOTYPE_GIVEN_ALLELES --alleles test.vcf.gz`, the resulting error is:; ```; java.lang.IllegalStateException: Allele in genotype GGTTTGTTT not in the variant context [GGTTTGTTT*, GGTTTGTTTGTTT, GGTTTGTTTGTTTGTTT, G]; at htsjdk.variant.variantcontext.VariantContext.validateGenotypes(VariantContext.java:1360); at htsjdk.variant.variantcontext.VariantContext.validate(VariantContext.java:1298); at htsjdk.variant.variantcontext.VariantContext.<init>(VariantContext.java:401); at htsjdk.variant.variantcontext.VariantContextBuilder.make(VariantContextBuilder.java:494); at htsjdk.variant.variantcontext.VariantContextBuilder.make(VariantContextBuilder.java:488); at org.broadinstitute.hellbender.utils.variant.GATKVariantContextUtils.simpleMerge(GATKVariantContextUtils.java:864); at org.broadinstitute.hellbender.utils.variant.GATKVariantContextUtils.simpleMerge(GATKVariantContextUtils.java:646); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.AssemblyBasedCallerUtils.makeMergedVariantContext(AssemblyBasedCallerUtils.java:228); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerGenotypingEngine.assignGenotypeLikelihoods(HaplotypeCallerGenotypingEngine.java:157); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.Haplotype",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5355:41186,validat,validateGenotypes,41186,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5355,1,['validat'],['validateGenotypes']
Security,"} ValidateVariants -R ${ref} -V ${name}\_v4.1.6.0.vcf.gz -L ${pipeline}/${name}\_intervals.list --warn-on-errors 2> ${log}/${name}\_v4.1.6.0\_genotype\_valivar.log. the warning in ValidateVariants and the site look like this:. 14:12:15.126 WARN ValidateVariants - \*\*\*\*\* Input 1st\_v4.1.6.0.vcf.gz fails strict validation of type ALL: one or more of the ALT allele(s) for the record at position chr\_1:1088200 are not observed at all in the sample genotypes \*\*\*\*\* ; ; chr\_1 1088200 . T \*,TAAAAAAAAAAAA 64.39 . AC=8,0;AF=0.667,0.00;AN=12;DP=118;ExcessHet=3.0103;FS=0.000;InbreedingCoeff=0.4286;MLEAC=7,7;MLEAF=0.583,0.583;MQ=58.73;QD=32.19;SOR=2.303 GT:AD:DP:GQ:PL ./.:9,0,0:9:.:0,0,0,0,0,0 0/0:9,0,0:9:0:0,0,113,0,113,113 ./.:10,0,0:10:.:0,0,0,0,0,0 ./.:5,0,0:5:.:0,0,0,0,0,0 1/1:0,0,1:1:0:225,15,0,15,0,0 ./.:0,0,0:0:.:0,0,0,0,0,0 ./.:12,0,0:12:.:0,0,0,0,0,0 ./.:8,0,0:8:.:0,0,0,0,0,0 0/0:3,0,0:3:0:0,0,43,0,43,43 ./.:7,0,0:7:.:0,0,0,0,0,0 ./.:1,0,0:1:.:0,0,0,0,0,0 ./.:0,0,0:0:.:0,0,0,0,0,0 ./.:3,0,0:3:.:0,0,0,0,0,0 ./.:7,0,0:7:.:0,0,0,0,0,0 1/1:0,0,0:0:0:45,3,0,3,0,0 ./.:0,0,0 1/1:0,0,1:1:0:45,3,0,3,0,0 1/1:0,0,0:0:0:267,18,0,18,0,0 ./.:9,0,0:9:.:0,0,0,0,0,0 ; . The exactly the same happens when I run GenotypeGVCFs in --include-non-variant-sites and when I run GenotypeGVCFS and ValidateVariants in v4.1.7.0. In principle, these sites just take up space in the vcf, as the correct behaviour of GenotypeGVCFS should result in the removal of ALT allele 2 and 3, which leads to the site not being called, as the spanning deletion is covered when it's called on the first base. I'm hoping that they disappear when I filter, but if not it's for me still a manageable amount to remove by hand even though that's not ideal. I just want to alert you to the weird behaviour, that I'm experiencing. I hope you can do something with my post and thanks in advance,<br><br><i>(created from <a href='https://broadinstitute.zendesk.com/agent/tickets/5803'>Zendesk ticket #5803</a>)<br>gz#5803</i>",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6630:2958,Validat,ValidateVariants,2958,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6630,1,['Validat'],['ValidateVariants']
Security,"~~The `ALL_TRANSCRIPTS` output from Funcotator is not properly parsed by the built-in parsing methods for the funcotations.~~. ~~This should be fixed so that these parsing methods will work without producing an error.~~. -----------. It turns out that at least for `ClinVar_VCF_CLNVI`, hashes aren't being properly cleaned (i.e. URL encoded) before writing to the VCF fields. This is bad, because hash is our delimiter for `ALL_TRANSCRIPTS` mode.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5671:286,hash,hashes,286,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5671,2,['hash'],"['hash', 'hashes']"
Security,"… ""abstract"" keyword to classes that are not instantiated. Classes that can be neither final nor abstract include: UserException, GATKException, GenomeLoc, HashedListExonCollection, LocusIteratorByStateBaseTest, ReadClipper, OverhangFixingManager, BasicInputParser",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/512:156,Hash,HashedListExonCollection,156,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/512,1,['Hash'],['HashedListExonCollection']
Security,… over the VCF index if its better. Handle sequence interval validation when no sequence length is available. Fixes https://github.com/broadinstitute/gatk/issues/1999 and the downstream genomeLoc parser validation fallout.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2091:61,validat,validation,61,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2091,2,['validat'],['validation']
Security,"…group for the contig alignments. To do downstream stuff like correlate breakpoints in copy number calls that are in VCF format, and perhaps eventually put a genotype column in our output VCF, it would be helpful to keep track of the sample name. This PR tries to help do that by 1) validating that input read groups contain reads from only one sample, 2) extracting the sample name for future use, and 3) putting a constructed read group in our aligned assemblies output file that contains the sample name, and tagging all of the alignment records in that file with the read group id. . As part of testing this I added an expected aligned contigs file test to `FindBreakpointEvidenceSparkIntegrationTest`.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3726:283,validat,validating,283,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3726,1,['validat'],['validating']
Testability,"	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|1	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0; ```; Running `$HOME/gatk-4.0.11.0/gatk --java-options ""-Xmx4g"" HaplotypeCaller -R $HOME/GRCh37files/hs37d5.fa -I /mnt/fast/test.bam -O test.out.vcf.gz -L 22 --genotyping-mode GENOTYPE_GIVEN_ALLELES --alleles test.vcf.gz`, the resulting error is:; ```; java.lang.IllegalStateException: Allele in genotype GGTTTGTTT not in the variant context [GGTTTGTTT*, GGTTTGTTTGTTT, GGTTTGTTTGTTTGTTT, G]; at htsjdk.variant.variantcontext.VariantContext.validateGenotypes(VariantContext.java:1360); at htsjdk.variant.variantcontext.VariantContext.validate(VariantContext.java:1298); at htsjdk.variant.variantcontext.VariantContext.<init>(VariantContext.java:401); at htsjdk.variant.variantcontext.VariantContextBuilder.make(VariantContextBuilder.java:494); at htsjdk.variant.variantcontext.VariantContextBuilder.make(VariantContextBuilder.java:488); at org.broadinstitute.hellbender.utils.variant.GATKVariantContextUtils.simpleMerge(GATKVariantContextUtils.java:864); at org.broadinstitute.hellbender.utils.variant.GATKVariantContextUtils.simpleMerge(GATKVariantContextUtils.java:646); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5355:40881,test,test,40881,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5355,1,['test'],['test']
Testability,	at org.broadinstitute.hellbender.CommandLineProgramTest.runCommandLine(CommandLineProgramTest.java:32); 	at org.broadinstitute.hellbender.utils.test.CommandLineProgramTester.runCommandLine(CommandLineProgramTester.java:97); 	at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2IntegrationTest.testTumorNormal(Mutect2IntegrationTest.java:237); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:497); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:108); 	at org.testng.internal.Invoker.invokeMethod(Invoker.java:661); 	at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:869); 	at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1193); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:126); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:109); 	at org.testng.TestRunner.privateRun(TestRunner.java:744); 	at org.testng.TestRunner.run(TestRunner.java:602); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:380); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:375); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:340); 	at org.testng.SuiteRunner.run(SuiteRunner.java:289); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1301); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1226); 	at org.testng.TestNG.runSuites(TestNG.java:1144); 	at org.testng.TestNG.run(TestNG.java:1115); 	at org.testng.IDEARemoteTestNG.run(IDEARemoteTestNG.java:72); 	at org.testng.RemoteTestNGStarter.main(RemoteTestNGStarter.java:123); ```. #### Steps to reproduce; These are the arguments I used (t,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5036:3795,Test,TestMethodWorker,3795,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5036,1,['Test'],['TestMethodWorker']
Testability,"	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:162); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:205); 	at org.broadinstitute.hellbender.Main.main(Main.java:291); Using GATK jar /usr/local/apps/GATK/4.1.2.0/gatk-package-4.1.2.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /usr/local/apps/GATK/4.1.2.0/gatk-package-4.1.2.0-local.jar DetermineGermlineContigPloidy -L /data/gatk_users1/0-Project/1-gCNV-Lung/z-bak/z-2019-10-26-1-Test-gCNV/9-Ref_Interval/2-Filter_Interval/22.preprocessed.Filtered.interval_list --interval-merging-rule OVERLAPPING_ONLY -I /data/gatk_users1/0-Project/1-gCNV-Lung/z-bak/z-2019-10-26-1-Test-gCNV/1-Input/3-BAM-ReadCount/22.SC349574.bam.csv -I /data/gatk_users1/0-Project/1-gCNV-Lung/z-bak/z-2019-10-26-1-Test-gCNV/1-Input/3-BAM-ReadCount/22.SC349575.bam.csv -I /data/gatk_users1/0-Project/1-gCNV-Lung/z-bak/z-2019-10-26-1-Test-gCNV/1-Input/3-BAM-ReadCount/22.SC349488.bam.csv -I /data/gatk_users1/0-Project/1-gCNV-Lung/z-bak/z-2019-10-26-1-Test-gCNV/1-Input/3-BAM-ReadCount/22.SC349489.bam.csv --contig-ploidy-priors /data/gatk_users1/0-Project/1-gCNV-Lung/z-bak/z-2019-10-26-1-Test-gCNV/9-Ref_Interval/3-contig_ploidy_priors/22.contig_ploidy_priors.csv --output /data/gatk_users1/0-Project/1-gCNV-Lung/z-bak/z-2019-10-26-1-Test-gCNV/2-Output/1-Contig-Ploidy/22.Contig_Ploidy_Dir --output-prefix ploidy --verbosity DEBUG. .............................................................(BUG 002)..........................................................; Stderr: Traceback (most recent call last):; File ""/tmp/segment_gcnv_calls.3402406683372415608.py"", line 9, in <module>; import gcnvkernel; File ""/usr/local/Anaconda/envs_app/gatk/4.1.2.0/lib/python3.6/site-packages/gcnvkernel/__init__.py",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6235:8714,Test,Test-gCNV,8714,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6235,1,['Test'],['Test-gCNV']
Testability,	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:163); 	at org.broadinstitute.hellbender.Main.instanceMain(Main.java:149); 	at org.broadinstitute.hellbender.Main.instanceMain(Main.java:190); 	at org.broadinstitute.hellbender.tools.walkers.vqsr.CNNVariantPipelineTest.testTrainingReadModel(CNNVariantPipelineTest.java:85); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:133); 	at org.testng.internal.TestInvoker.invokeMethod(TestInvoker.java:584); 	at org.testng.internal.TestInvoker.invokeTestMethod(TestInvoker.java:172); 	at org.testng.internal.MethodRunner.runInSequence(MethodRunner.java:46); 	at org.testng.internal.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:804); 	at org.testng.internal.TestInvoker.invokeTestMethods(TestInvoker.java:145); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:128); 	at java.util.ArrayList.forEach(ArrayList.java:1257); 	at org.testng.TestRunner.privateRun(TestRunner.java:770); 	at org.testng.TestRunner.run(TestRunner.java:591); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:402); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:396); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:355); 	at org.testng.SuiteRunner.run(SuiteRunner.java:304); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:53); 	at org.testng.SuiteRunnerWo,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6307:3083,Test,TestInvoker,3083,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6307,1,['Test'],['TestInvoker']
Testability, 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); 	at org.broadinstitute.hellbender.engine.VariantWalkerBase.traverse(VariantWalkerBase.java:108); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:893); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:136); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:179); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:198); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:152); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:195); 	at org.broadinstitute.hellbender.Main.main(Main.java:275); Caused by: org.sqlite.SQLiteException: [SQLITE_IOERR_LOCK] I/O error in the advisory file locking logic (disk I/O error); 	at org.sqlite.core.DB.newSQLException(DB.java:909); 	at org.sqlite.core.DB.newSQLException(DB.java:921); 	at org.sqlite.core.DB.throwex(DB.java:886); 	at org.sqlite.core.NativeDB.prepare_utf8(Native Method); 	at org.sqlite.core.NativeDB.prepare(NativeDB.java:127); 	at org.sqlite.core.DB.prepare(DB.java:227); 	at org.sqlite.jdbc3.JDBC3Statement.executeQuery(JDBC3Statement.java:81); 	at org.broadinstitute.hellbender.tools.funcotator.dataSources.cosmic.CosmicFuncotationFactory.createFuncotations(CosmicFuncotationFactory.java:215); 	... 21 more. ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4413:2347,log,logic,2347,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4413,1,['log'],['logic']
Testability, 	at org.broadinstitute.hellbender.Main.instanceMain(Main.java:148); 	at org.broadinstitute.hellbender.Main.instanceMain(Main.java:189); 	at org.broadinstitute.hellbender.CommandLineProgramTest.runCommandLine(CommandLineProgramTest.java:27); 	at org.broadinstitute.hellbender.tools.spark.pipelines.ReadsPipelineSparkIntegrationTest.testReadsPipelineSpark(ReadsPipelineSparkIntegrationTest.java:125); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:108); 	at org.testng.internal.Invoker.invokeMethod(Invoker.java:661); 	at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:869); 	at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1193); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:126); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:109); 	at org.testng.TestRunner.privateRun(TestRunner.java:744); 	at org.testng.TestRunner.run(TestRunner.java:602); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:380); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:375); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:340); 	at org.testng.SuiteRunner.run(SuiteRunner.java:289); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1301); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1226); 	at org.testng.TestNG.runSuites(TestNG.java:1144); 	at org.testng.TestNG.run(TestNG.java:1115); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:129); 	at org.gradle.api.internal.tas,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5680:8407,test,testng,8407,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5680,1,['test'],['testng']
Testability, 	at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:193); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:156); 	at org.broadinstitute.hellbender.testutils.VariantContextTestUtils.readEntireVCFIntoMemory(VariantContextTestUtils.java:67); 	at org.broadinstitute.hellbender.tools.funcotator.vcfOutput.VcfOutputRendererUnitTest.testExclusionListOverridesManualDefaultAnnotations(VcfOutputRendererUnitTest.java:40); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:133); 	at org.testng.internal.TestInvoker.invokeMethod(TestInvoker.java:584); 	at org.testng.internal.TestInvoker.invokeTestMethod(TestInvoker.java:172); 	at org.testng.internal.MethodRunner.runInSequence(MethodRunner.java:46); 	at org.testng.internal.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:804); 	at org.testng.internal.TestInvoker.invokeTestMethods(TestInvoker.java:145); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:128); 	at java.util.ArrayList.forEach(ArrayList.java:1257); 	at org.testng.TestRunner.privateRun(TestRunner.java:770); 	at org.testng.TestRunner.run(TestRunner.java:591); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:402); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:396); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:355); 	at org.testng.SuiteRunner.run(SuiteRunner.java:304); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:53); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:96); 	at org.testng.TestNG.runSuitesSequen,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6748:2410,Test,TestInvoker,2410,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6748,1,['Test'],['TestInvoker']
Testability, 	at org.broadinstitute.hellbender.tools.spark.pipelines.ReadsPipelineSparkIntegrationTest.testReadsPipelineSpark(ReadsPipelineSparkIntegrationTest.java:125); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:108); 	at org.testng.internal.Invoker.invokeMethod(Invoker.java:661); 	at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:869); 	at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1193); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:126); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:109); 	at org.testng.TestRunner.privateRun(TestRunner.java:744); 	at org.testng.TestRunner.run(TestRunner.java:602); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:380); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:375); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:340); 	at org.testng.SuiteRunner.run(SuiteRunner.java:289); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1301); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1226); 	at org.testng.TestNG.runSuites(TestNG.java:1144); 	at org.testng.TestNG.run(TestNG.java:1115); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:129); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:88); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Nati,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5680:8648,Test,TestRunner,8648,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5680,1,['Test'],['TestRunner']
Testability," 	at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2IntegrationTest.testTumorNormal(Mutect2IntegrationTest.java:237); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:497); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:108); 	at org.testng.internal.Invoker.invokeMethod(Invoker.java:661); 	at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:869); 	at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1193); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:126); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:109); 	at org.testng.TestRunner.privateRun(TestRunner.java:744); 	at org.testng.TestRunner.run(TestRunner.java:602); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:380); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:375); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:340); 	at org.testng.SuiteRunner.run(SuiteRunner.java:289); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1301); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1226); 	at org.testng.TestNG.runSuites(TestNG.java:1144); 	at org.testng.TestNG.run(TestNG.java:1115); 	at org.testng.IDEARemoteTestNG.run(IDEARemoteTestNG.java:72); 	at org.testng.RemoteTestNGStarter.main(RemoteTestNGStarter.java:123); ```. #### Steps to reproduce; These are the arguments I used (the input bam is on the file system):. ```; final String[] args = {; ""-I"", ""/humgen/gsa-hpprojects/dev/mshand/SpecOps/Mitochondria/Filtering/IGV/198489_vs_811158/sorted.mt.1.bam"",; ""-"" + M2ArgumentCollection.TUMOR_SAMPLE_SHOR",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5036:4015,test,testng,4015,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5036,1,['test'],['testng']
Testability, 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:133); 	at org.testng.internal.TestInvoker.invokeMethod(TestInvoker.java:584); 	at org.testng.internal.TestInvoker.invokeTestMethod(TestInvoker.java:172); 	at org.testng.internal.MethodRunner.runInSequence(MethodRunner.java:46); 	at org.testng.internal.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:804); 	at org.testng.internal.TestInvoker.invokeTestMethods(TestInvoker.java:145); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:128); 	at java.util.ArrayList.forEach(ArrayList.java:1257); 	at org.testng.TestRunner.privateRun(TestRunner.java:770); 	at org.testng.TestRunner.run(TestRunner.java:591); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:402); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:396); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:355); 	at org.testng.SuiteRunner.run(SuiteRunner.java:304); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:53); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:96); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1180); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1102); 	at org.testng.TestNG.runSuites(TestNG.java:1032); 	at org.testng.TestNG.run(TestNG.java:1000); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:141); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:90); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteT,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6748:2894,test,testng,2894,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6748,2,['test'],['testng']
Testability," ""console"".; log4j:ERROR A ""org.apache.log4j.FileAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by ; log4j:ERROR [sun.misc.Launcher$AppClassLoader@7506e922] whereas object of type ; log4j:ERROR ""org.apache.log4j.FileAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@28c4711c].; log4j:ERROR Could not instantiate appender named ""file"".; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by ; log4j:ERROR [sun.misc.Launcher$AppClassLoader@7506e922] whereas object of type ; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@28c4711c].; log4j:ERROR Could not instantiate appender named ""console"".; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; log4j:WARN No appenders could be found for logger (org.apache.spark.SparkContext).; log4j:WARN Please initialize the log4j system properly.; log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.; ```. By backtracking, the problem goes away at commit d827adc81266c788482c9cb4f119f2e3c1e152b8. Since spark-submmit was broken after 8af8bcc920ee5f393562e3e632d9ccd4acd9a638, the bug could be anywhere between commit 8af8bcc920ee5f393562e3e632d9ccd4acd9a638 and d25894b3bc80e450210cf8a9124c4171e65f3717. The log4j.property file is below:; ```; # Set everything to be logged to the console; log4j.rootCategory=WARN,console; log4j.appender.console=org.apache.log4j.ConsoleAppender; log4j.appender.console.target=System.out; log4j.appender.console.layout=org.apache.log4j.PatternLayout; log4j.appender.console.layout.ConversionPattern=%d{yy/MM/dd HH:mm:ss} %p %c{1}: %m%n. log4j.appender.file=org.apache.log4j.FileAppender; log4j.appender.file.file=/tmp/logs/spark/log4j-block_manager-output.txt; log",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2734:1585,log,logger,1585,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2734,1,['log'],['logger']
Testability," ### Description ; In 7% of 8M variants in a 9 sample variant calling there is a discordance at least once between the GT and PGT field of a sample. The discordance between the GT and PGT fields can be found in the GVCF files created by the HaplotypeCaller and in the multi-sample VCF created by GenomicsDBImport. . This issue and pullrequest might be related, but have not been updated since March. ; https://github.com/broadinstitute/gatk/issues/5727; https://github.com/broadinstitute/gatk/pull/5772. I also already created this post on the forum. ; https://gatkforums.broadinstitute.org/gatk/discussion/24465/how-can-a-homozygous-reference-0-0-genotype-gt-have-a-heterozygous-phased-genotype-pgt-of-0-1#latest. Just thought it might help to (also) ask here, for me and other people who encounter this issue. . #### Steps to reproduce. Run the script below on any multi-sample VCF file created by GenomicsDBImport. ; The GT and PGT discordance is already in the GVCF files. But I did not test this script on any GVCF file. . The most important bit of the script is this comparison between the allele sets of the GT and PGT field. ; ```; if gt_allele_set == {0} and pgt_allele_set == {0,1}:; variant_with_phase_homref_to_het_issue = True; if gt_allele_set == {2} and pgt_allele_set == {1}:; variant_with_phase_hom22_to_hom11_issue = True; elif gt_allele_set == {0,2} and pgt_allele_set == {0,1}:; variant_with_phase_het02_to_het01_issue = True; ```. ```; from cyvcf2 import VCF, Writer. path = ""/DA_1458/VSDA_1458-gatk-haplotype-joint-annotated.bcf""; output_path_hom_ref_to_het = ""/DA_1458/hom_gt_het_phase_issue/hom_gt_het_phase_issue_homref_to_het.vcf""; output_path_hom22_to_hom11 = ""/DA_1458/hom_gt_het_phase_issue/hom_gt_het_phase_issue_hom22_to_hom11.vcf""; output_path_het02_to_het01 = ""/DA_1458/hom_gt_het_phase_issue/hom_gt_het_phase_issue_het02_to_het01.vcf""; output_path_other = ""/DA_1458/hom_gt_het_phase_issue/hom_gt_het_phase_issue_other.vcf"". writer_hom_ref_to_het = Writer(output_path_",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6220:1134,test,test,1134,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6220,1,['test'],['test']
Testability, (150742 bp); 23:44:43.167 DEBUG GenomeLocParser - chrUn_KI270752v1 (27745 bp); 23:44:43.167 DEBUG GenomeLocParser - chrUn_KI270753v1 (62944 bp); 23:44:43.167 DEBUG GenomeLocParser - chrUn_KI270754v1 (40191 bp); 23:44:43.167 DEBUG GenomeLocParser - chrUn_KI270755v1 (36723 bp); 23:44:43.167 DEBUG GenomeLocParser - chrUn_KI270756v1 (79590 bp); 23:44:43.167 DEBUG GenomeLocParser - chrUn_KI270757v1 (71251 bp); 23:44:43.167 DEBUG GenomeLocParser - chrUn_GL000214v1 (137718 bp); 23:44:43.167 DEBUG GenomeLocParser - chrUn_KI270742v1 (186739 bp); 23:44:43.167 DEBUG GenomeLocParser - chrUn_GL000216v2 (176608 bp); 23:44:43.167 DEBUG GenomeLocParser - chrUn_GL000218v1 (161147 bp); 23:44:43.167 DEBUG GenomeLocParser - chrEBV (171823 bp); 23:44:43.173 INFO GermlineCNVCaller - Aggregating read-count file /gpfs/hpc/home/lijc/xiangxud/project/test/NGS_WES_test/4_tools_vcf/gatk4/info/counts/V300033254_96.tsv (1 / 3); 23:44:43.345 INFO GermlineCNVCaller - Aggregating read-count file /gpfs/hpc/home/lijc/xiangxud/project/test/NGS_WES_test/4_tools_vcf/gatk4/info/counts/V300033256_95.tsv (2 / 3); 23:44:43.521 INFO GermlineCNVCaller - Aggregating read-count file /gpfs/hpc/home/lijc/xiangxud/project/test/NGS_WES_test/4_tools_vcf/gatk4/info/counts/V300033254_97.tsv (3 / 3); 23:44:43.683 DEBUG ScriptExecutor - Executing:; 23:44:43.683 DEBUG ScriptExecutor - python; 23:44:43.683 DEBUG ScriptExecutor - /tmp/cohort_denoising_calling.6786136740079319091.py; 23:44:43.683 DEBUG ScriptExecutor - --ploidy_calls_path=/gpfs/hpc/home/lijc/xiangxud/project/test/NGS_WES_test/4_tools_vcf/gatk4/info/ploidy/ploidy-calls; 23:44:43.683 DEBUG ScriptExecutor - --output_calls_path=/gpfs/hpc/home/lijc/xiangxud/project/test/NGS_WES_test/4_tools_vcf/gatk4/info/cohort_all/cohort_30-calls; 23:44:43.683 DEBUG ScriptExecutor - --output_tracking_path=/gpfs/hpc/home/lijc/xiangxud/project/test/NGS_WES_test/4_tools_vcf/gatk4/info/cohort_all/cohort_30-tracking; 23:44:43.683 DEBUG ScriptExecutor - --random_seed=1984; 23:44:43,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8938:33558,test,test,33558,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8938,1,['test'],['test']
Testability," (build 1.8.0_242-8u242-b08-0ubuntu3~18.04-b08); # Java VM: OpenJDK 64-Bit Server VM (25.242-b08 mixed mode linux-amd64 compressed oops); # Problematic frame:; # C [libgkl_smithwaterman5951765478004985534.so+0x132d] smithWatermanBackTrack(dnaSeqPair*, int, int, int, int, int*, int)+0x1bd; #; # Failed to write core dump. Core dumps have been disabled. To enable core dumping, try ""ulimit -c unlimited"" before starting Java again; #; # An error report file with more information is saved as:; # /home/gatk/hs_err_pid849.log; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; # The crash happened outside the Java Virtual Machine in native code.; # See problematic frame for where to report the bug.; #; ```. **RELEVANT FILES**; [hs_err_pid100.log](https://github.com/broadinstitute/gatk/files/6203288/hs_err_pid100.log); [hs_err_pid164.log](https://github.com/broadinstitute/gatk/files/6203289/hs_err_pid164.log); [hs_err_pid274.log](https://github.com/broadinstitute/gatk/files/6203290/hs_err_pid274.log); [hs_err_pid400.log](https://github.com/broadinstitute/gatk/files/6203291/hs_err_pid400.log); [hs_err_pid482.log](https://github.com/broadinstitute/gatk/files/6203292/hs_err_pid482.log); [hs_err_pid711.log](https://github.com/broadinstitute/gatk/files/6203293/hs_err_pid711.log); [hs_err_pid735.log](https://github.com/broadinstitute/gatk/files/6203294/hs_err_pid735.log); [hs_err_pid801.log](https://github.com/broadinstitute/gatk/files/6203295/hs_err_pid801.log); [hs_err_pid825.log](https://github.com/broadinstitute/gatk/files/6203296/hs_err_pid825.log); [hs_err_pid849.log](https://github.com/broadinstitute/gatk/files/6203297/hs_err_pid849.log); [otherFiles.zip](https://github.com/broadinstitute/gatk/files/6203305/otherFiles.zip); [in2510-8.orientationFilter.vcf.txt](https://github.com/broadinstitute/gatk/files/6203356/in2510-8.orientationFilter.vcf.txt); *VCF extension appended with .txt to satisfy GitHub's upload requir",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7162:6668,log,log,6668,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7162,1,['log'],['log']
Testability," (build 11.0.11+9-Ubuntu-0ubuntu2.20.04, mixed mode, sharing). Command:. gatk GermlineCNVCaller \\ ; ; \--run-mode COHORT \\ ; ; \-L Twist\_Exome\_Target\_hg38\_preprocessed\_annotated\_gc-filtered.interval\_list \\ ; ; \-imr OVERLAPPING\_ONLY \\ ; ; \--contig-ploidy-calls ploidy-calls \\ ; ; \--annotated-intervals Twist\_Exome\_Target\_hg38\_preprocessed\_annotated.interval\_list \\ ; ; \-I 13-20.counts.hd5 \\ ; ; \-I 722.counts.hd5 \\ ; ; \-I D19047.counts.hd5 \\ ; ; \-I F24F1.counts.hd5 \\ ; ; \-I NS.counts.hd5 \\ ; ; \-I TBC039.counts.hd5 \\ ; ; \-I VP.counts.hd5 \\ ; ; \-I WES002.counts.hd5 \\ ; ; \-I WES02.counts.hd5 \\ ; ; \-I 17062-T1-.counts.hd5 \\ ; ; \-I 18001-M1-.counts.hd5 \\ ; ; \-I 516.counts.hd5 \\ ; ; \-I 533.counts.hd5 \\ ; ; \-I NBH.counts.hd5 \\ ; ; \-I ADN492.counts.hd5 \\ ; ; \-I WES607.counts.hd5 \\ ; ; \--class-coherence-length 1000.0 \\ ; ; \--cnv-coherence-length 1000.0 \\ ; ; \--enable-bias-factors true \\ ; ; \--interval-psi-scale 1.0E-6 \\ ; ; \--log-mean-bias-standard-deviation 0.01 \\ ; ; \--sample-psi-scale 1.0E-6 \\ ; ; \--output cohort16 \\ ; ; \--output-prefix cohort16 \\ ; ; \--verbosity DEBUG \\ ; ; \--java-options '-DGATK\_STACKTRACE\_ON\_USER\_EXCEPTION=true'. Error:. java.lang.IllegalArgumentException: Prefix string ""NS"" too short: length must be at least 3 ; ; at java.base/java.io.File.createTempFile(File.java:2104) ; ; at org.broadinstitute.hellbender.utils.io.IOUtils.createTempFileInDirectory(IOUtils.java:685) ; ; at org.broadinstitute.hellbender.utils.io.IOUtils.createTempFile(IOUtils.java:666) ; ; at org.broadinstitute.hellbender.tools.copynumber.GermlineCNVCaller.lambda$writeIntervalSubsetReadCountFiles$1(GermlineCNVCaller.java:430) ; ; at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183) ; ; at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195) ; ; at java.base/java.util.stream.IntPipeline$1$1.accept(IntPipeline.java:180) ; ; at java.base/java.util.stream.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7591:2061,log,log-mean-bias-standard-deviation,2061,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7591,1,['log'],['log-mean-bias-standard-deviation']
Testability," - ------------------------------------------------------------------------------------; INFO 14:49:42,883 HelpFormatter - The Genome Analysis Toolkit (GATK) v3.8-1-0-gf15c1c3ef, Compiled 2018/02/19 05:43:50; INFO 14:49:42,884 HelpFormatter - Copyright (c) 2010-2016 The Broad Institute; INFO 14:49:42,884 HelpFormatter - For support and documentation go to https://software.broadinstitute.org/gatk; INFO 14:49:42,884 HelpFormatter - [Sat Oct 09 14:49:42 CST 2021] Executing on Linux 2.6.32-696.el6.x86_64 amd64; INFO 14:49:42,884 HelpFormatter - Java HotSpot(TM) 64-Bit Server VM 1.8.0_11-b12; INFO 14:49:42,889 HelpFormatter - Program Args: -T HaplotypeCaller -R /share/Onc_Soft_DB/database/capsmart/hg19/hg19_20210805/hg19.rm_CRLF2_P2RY8.fix_PRSS1_MUC16.fasta -I /share/Onc_RD_Pipeline/OncDir/zhuangll/210927-commercial-tissue-zhangaiyuan/germline/Z19W06700-F1WA/2.Realign/Z19W06700-F1WA.bam -L /share/Onc_Soft_DB/database/capsmart/bed/gene102.snpindel.capsmart.bed -U -o /share/Onc_RD_Pipeline/OncDir/yanhs/test/GATK/Z19W06700-F1WA.HaplotypeCaller.raw.vcf -stand_call_conf 50 -A RMSMappingQuality -A BaseCounts; INFO 14:49:42,892 HelpFormatter - Executing as yanhs3941@compute-0-76 on Linux 2.6.32-696.el6.x86_64 amd64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_11-b12.; INFO 14:49:42,892 HelpFormatter - Date/Time: 2021/10/09 14:49:42; INFO 14:49:42,892 HelpFormatter - ------------------------------------------------------------------------------------; INFO 14:49:42,892 HelpFormatter - ------------------------------------------------------------------------------------; INFO 14:49:42,922 NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/share/Onc_Soft_DB/software/GATK3.8/GenomeAnalysisTK.jar!/com/intel/gkl/native/libgkl_compression.so; INFO 14:49:42,957 GenomeAnalysisEngine - Deflater: IntelDeflater; INFO 14:49:42,958 GenomeAnalysisEngine - Inflater: IntelInflater; INFO 14:49:42,958 GenomeAnalysisEngine - Strictness is SILENT; INFO 14:49:43,125 GenomeAnalysisEngine - ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7499:1075,test,test,1075,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7499,1,['test'],['test']
Testability," - HTSJDK Version: 2.23.0. 16:17:05.844 INFO HaplotypeCaller - Picard Version: 2.22.8. 16:17:05.844 INFO HaplotypeCaller - HTSJDK Defaults.COMPRESSION_LEVEL : 2. 16:17:05.844 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false. 16:17:05.844 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true. 16:17:05.844 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false. 16:17:05.844 INFO HaplotypeCaller - Deflater: JdkDeflater. 16:17:05.844 INFO HaplotypeCaller - Inflater: JdkInflater. 16:17:05.844 INFO HaplotypeCaller - GCS max retries/reopens: 20. 16:17:05.844 INFO HaplotypeCaller - Requester pays: disabled. 16:17:05.845 INFO HaplotypeCaller - Initializing engine. 16:17:05.928 WARN IntelDeflaterFactory - IntelInflater is not supported, using Java.util.zip.Inflater. 16:17:05.932 WARN IntelDeflaterFactory - IntelInflater is not supported, using Java.util.zip.Inflater. 16:17:06.503 INFO FeatureManager - Using codec VCFCodec to read file file:///home/robert/test/snps.vcf. 16:17:06.539 INFO IntervalArgumentCollection - Processing 61464 bp from intervals. 16:17:06.551 INFO HaplotypeCaller - Done initializing engine. 16:17:06.573 INFO HaplotypeCallerEngine - Disabling physical phasing, which is supported only for reference-model confidence output. 16:17:06.588 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/home/robert/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_utils.so. 16:17:06.589 **WARN** NativeLibraryLoader - Unable to load libgkl_utils.so from native/libgkl_utils.so (/tmp/libgkl_utils347167544598047196.so: /tmp/libgkl_utils347167544598047196.so: cannot open shared object file: No such file or directory (Possible cause: can't load AMD 64-bit .so on a Power PC 64 LE-bit platform)). 16:17:06.589 **WARN** IntelPairHmm - Intel GKL Utils not loaded. 16:17:06.589 INFO PairHMM - OpenMP multi-threaded AVX-accelerated native PairHMM implementation is not supported",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6794:3718,test,test,3718,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6794,1,['test'],['test']
Testability," - [x] Latest master branch as of [2/6/2020]. ### Description ; There are minimal/inconsistent checks that variants added to vcfWriters are correctly ordered (an issue with htsjdk I think). This leads to an insidious bug, where a sorted vcf can be fed through SelectVariants, and depending on the flavor of output vcf, either crash, or succeed but output an incorrectly sorted vcf. The issue is that in some circumstances SelectVariants will trim alleles to their minimal representation, which can change the location of a variant record, and thus reorder them. However, SelectVariants does nothing to account for the potential order change. Since vcfWriter implementations in htsjdk seem to do minimal/inconsistent checks on the order of variants being added to them, this may write out an incorrectly sorted vcf, or throw an exception, depending on the flavor of vcfWriter. . #### Steps to reproduce; With attached (zipped because github) vcf, run ; `gatk SelectVariants -V test.input.vcf -sn SAMPLE_01 -O test.output.vcf`; Tool will succeed, but output vcf will be incorrectly sorted. Somehow, this incorrectly sorted vcf will also be accompanied by an index! Though if you try to run `IndexFeatureFile` on the output vcf separately, it will fail. . run ; `gatk SelectVariants -V test.input.vcf -sn SAMPLE_01 -O test.output.vcf.gz`; tool will throw exception w/ stack trace:; ```; java.lang.IllegalArgumentException: Features added out of order: previous (TabixFeature{referenceIndex=0, start=17148456, end=17148456, featureStartFilePosition=2460, featureEndFilePosition=-1}) > next (TabixFeature{referenceIndex=0, start=17148447, end=17148457, featureStartFilePosition=2509, featureEndFilePosition=-1}); 	at htsjdk.tribble.index.tabix.TabixIndexCreator.addFeature(TabixIndexCreator.java:89); 	at htsjdk.variant.variantcontext.writer.IndexingVariantContextWriter.add(IndexingVariantContextWriter.java:203); 	at htsjdk.variant.variantcontext.writer.VCFWriter.add(VCFWriter.java:242); 	at org.broadi",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6443:1204,test,test,1204,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6443,1,['test'],['test']
Testability," --allosomal-contig chrY --autosomal-ref-copy-number 2 --contig-ploidy-calls DetermineGermlineContigPloidy/DetermineGermlineContigPloidy-calls/ --sample-index 6 --output-genotyped-intervals intervals/genotyped-intervals-SAMPLE_6.vcf.gz --output-genotyped-segments segments/genotyped-segments-SAMPLE_6.vcf.gz --output-denoised-copy-ratios ratios/denoised-copy-ratios-SAMPLE_6.tsv --sequence-dictionary hg19_min_oldM.fa.dict. #PostprocessGermlineCNVCalls_joint. 23:45:30.659 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/gatk/gatk-package-4.3.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; 23:45:31.000 INFO PostprocessGermlineCNVCalls - ------------------------------------------------------------; 23:45:31.001 INFO PostprocessGermlineCNVCalls - The Genome Analysis Toolkit (GATK) v4.3.0.0; 23:45:31.001 INFO PostprocessGermlineCNVCalls - For support and documentation go to https://software.broadinstitute.org/gatk/; 23:45:31.002 INFO PostprocessGermlineCNVCalls - Executing as testardqu@chu-lyon.fr@ge95142-vm1 on Linux v5.18.0-0.bpo.1-amd64 amd64; 23:45:31.002 INFO PostprocessGermlineCNVCalls - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_242-8u242-b08-0ubuntu3~18.04-b08; 23:45:31.002 INFO PostprocessGermlineCNVCalls - Start Date/Time: December 5, 2022 11:45:30 PM GMT; 23:45:31.002 INFO PostprocessGermlineCNVCalls - ------------------------------------------------------------; 23:45:31.002 INFO PostprocessGermlineCNVCalls - ------------------------------------------------------------; 23:45:31.003 INFO PostprocessGermlineCNVCalls - HTSJDK Version: 3.0.1; 23:45:31.003 INFO PostprocessGermlineCNVCalls - Picard Version: 2.27.5; 23:45:31.003 INFO PostprocessGermlineCNVCalls - Built for Spark Version: 2.4.5; 23:45:31.003 INFO PostprocessGermlineCNVCalls - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 23:45:31.003 INFO PostprocessGermlineCNVCalls - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 23:45:31.003 INFO PostprocessGermlineCNVCalls - HTS",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8183:7689,test,testardqu,7689,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8183,1,['test'],['testardqu']
Testability," --input snippet.bam \; --output snippet.vcf \; -R hg19/hg19.fa \; --bam-output assembly.bam \; -L chr1:68896800-68896900 \; --ploidy 2 \; --min-pruning 2 \; --min-dangling-branch-length 2 \; --pcr-indel-model CONSERVATIVE ; ```. Then I get only a single variant reported in the region (the 9bp deletion):. ```; #CHROM POS ID REF ALT QUAL FILTER INFO FORMAT test-sample; chr1 68896832 . CTTTAGTTTT C 1597.60 . AC=1;AF=0.500;AN=2;BaseQRankSum=0.000;DP=122;ExcessHet=3.0103;FS=0.000;MLEAC=1;MLEAF=0.500;MQ=60.00;MQRankSum=0.000;QD=14.52;ReadPosRankSum=1.341;SOR=0.350 GT:AD:DP:GQ:PL 0/1:67,43:110:99:1605,0,2683; ```. If i run to generate a gvcf then things get more interesting:. ```; gatk HaplotypeCaller \; --input snippet.bam \; --output snippet.g.vcf \; -R hg19/hg19.fa \; -ERC GVCF \; --bam-output assembly.bam \; -L chr1:68896800-68896900 \; --ploidy 2 \; --min-pruning 2 \; --min-dangling-branch-length 2 \; --pcr-indel-model CONSERVATIVE ; ```. yields:. ```; #CHROM POS ID REF ALT QUAL FILTER INFO FORMAT test-sample; chr1 68896800 . G <NON_REF> . . END=68896831 GT:DP:GQ:MIN_DP:PL 0/0:118:99:107:0,120,1800; chr1 68896832 . CTTTAGTTTT C,<NON_REF> 1597.60 . BaseQRankSum... GT:AD:DP:GQ:PL:SB 0/1:67,43,0:110:99:1605,0,2683,1807,2813,4620:67,0,43,0; chr1 68896841 . T *,TCC,<NON_REF> 344.02 . DP=110;Exces... GT:GQ:PL ./.:99:0,0,0,0,0,0,0,0,0,0; chr1 68896842 . G <NON_REF> . . END=68896899 GT:DP:GQ:MIN_DP:PL 0/0:71:99:41:0,99,1485; ```. I.e. a record is emitted for the insertion but the genotype is `./.` with a quality of 99, 0s for all the PLs and the other per-sample annotations we'd expect on a variant record missing. I suspect the problem has something to do with the fact that the deletion and insertion are in cis and the insertion's anchor base is within the deletion. I'm not even sure how one would represent this as a pair of variants. I think ideally this would be emitted as a single variant with `REF=CTTTAGTTTT` and `ALT=CCC`. #### Steps to reproduce; Use the command lines ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6538:2028,test,test-sample,2028,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6538,1,['test'],['test-sample']
Testability," 15:25:31 MarkDuplicates Will retain up to 116589493 data points before spilling to disk.; [Wed Jul 03 15:25:35 CEST 2024] picard.sam.markduplicates.MarkDuplicates done. Elapsed time: 0.07 minutes.; Runtime.totalMemory()=6861881344; To get help, see http://broadinstitute.github.io/picard/index.html#GettingHelp; Exception in thread ""main"" java.lang.NullPointerException: Cannot invoke ""htsjdk.samtools.SAMReadGroupRecord.getReadGroupId()"" because the return value of ""htsjdk.samtools.SAMRecord.getReadGroup()"" is null; at picard.sam.markduplicates.MarkDuplicates.buildSortedReadEndLists(MarkDuplicates.java:558); at picard.sam.markduplicates.MarkDuplicates.doWork(MarkDuplicates.java:270); at picard.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:281); at picard.cmdline.PicardCommandLine.instanceMain(PicardCommandLine.java:105); at picard.cmdline.PicardCommandLine.main(PicardCommandLine.java:115); ```; or from gatk; ```; gatk MarkDuplicates I=WA02_i5-537_i7-98_S11819_L004.bam O=test.dup.bam M=marked_dup_metrics.txt; Using GATK jar /opt/gatk-4.6.0.0/gatk-package-4.6.0.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /opt/gatk-4.6.0.0/gatk-package-4.6.0.0-local.jar MarkDuplicates I=WA02_i5-537_i7-98_S11819_L004.bam O=test.dup.bam M=marked_dup_metrics.txt; INFO 2024-07-03 15:26:21 MarkDuplicates. ********** NOTE: Picard's command line syntax is changing.; **********; ********** For more information, please see:; **********; https://github.com/broadinstitute/picard/wiki/Command-Line-Syntax-Transition-For-Users-(Pre-Transition); **********; ********** The command line looks like this in the new syntax:; **********; ********** MarkDuplicates -I WA02_i5-537_i7-98_S11819_L004.bam -O test.dup.bam -M marked_dup_metrics.txt; **********. 15:26:21.393 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/opt/gatk-4.6.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8904:5177,test,test,5177,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8904,1,['test'],['test']
Testability," 2.21.2; 09:54:54.732 INFO HaplotypeCaller - Picard Version: 2.21.9; 09:54:54.732 INFO HaplotypeCaller - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 09:54:54.732 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 09:54:54.732 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 09:54:54.732 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 09:54:54.732 INFO HaplotypeCaller - Deflater: IntelDeflater; 09:54:54.732 INFO HaplotypeCaller - Inflater: IntelInflater; 09:54:54.732 INFO HaplotypeCaller - GCS max retries/reopens: 20; 09:54:54.732 INFO HaplotypeCaller - Requester pays: disabled; 09:54:54.732 INFO HaplotypeCaller - Initializing engine; 09:55:05.747 INFO HaplotypeCaller - Shutting down engine; [September 11, 2020 9:55:05 AM CEST] org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCaller done. Elapsed time: 0.19 minutes.; Runtime.totalMemory()=5152178176; ***********************************************************************. A USER ERROR has occurred: Fasta dict file file:///home/averdier/test/dna-seq-pipeline/Triticum_aestivum_Claire_EIv1.1.dict for reference file:///home/averdier/test/dna-seq-pipeline/Triticum_aestivum_Claire_EIv1.1.fa.gz does not exist.; Please see http://gatkforums.broadinstitute.org/discussion/1601/how-can-i-prepare-a-fasta-file-to-use-as-reference for help creating it. ***********************************************************************; Set the system property GATK_STACKTRACE_ON_USER_EXCEPTION (--java-options '-DGATK_STACKTRACE_ON_USER_EXCEPTION=true') to print the stack trace. Command 'java -Xmx100G -jar /opt/gatk/gatk-package-4.1.7.0-local.jar HaplotypeCaller -R Triticum_aestivum_Claire_EIv1.1.fa.gz --sequence-dictionary Triticum_aestivum_Claire_EIv1.1.fa.gz.dict -I ClaireTest_MD.bam -O ClaireTest_MD_NoInter; vals_Output.vcf --stand-call-conf 10 --native-pair-hmm-threads 30' failed with 512. ```. I'm using the local gatk of version 4.1.7.0",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6808:2720,test,test,2720,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6808,2,['test'],['test']
Testability," </pre>. It seems that GenomicsDBImport crash after finishing 1 batch for large chromosomes. For example, here I simultaneously run for chr1-12 (not finished yet). For chr5-12, file size of 1 batch is less than 40GB and they successfully finished import batch 1 and running for batch 2 or 3. Thus, the file size for chr5-12 are 59GB now. However, for chr1-4, they just crash in batch 1 for very long time without any error. I have check the memory usage and there is still >35GB free memory for the compute node of each chromosome. Please see the followings for detail:. File size for all chromosomes, the GenomicsDB for chr1-4 is smaller:; <pre>[hcaoad@login-0 GenomicsDB]> du -h --max-depth=1; 59G ./chr10; 59G ./chr6; 50G ./chr2; 59G ./chr12; 59G ./chr9; 59G ./chr5; 59G ./chr7; 48G ./chr1; 59G ./chr11; 59G ./chr8; 40G ./chr4; 41G ./chr3; 647G .; </pre>. Files in GenomicsDB of chr1 batch 1. As you can see, no update for the database since Apr 20 13:34, while current time is Apr 21.; <pre>[hcaoad@login-0 .__6f46d0f3-86b3-4e38-92be-9a912291df0c139544093255424_1618555702611]> pwd; /home/hcaoad/scratch/Han/WGS/HK_WGS_5X/GenomicsDB/chr1/1$1$249250621/.__6f46d0f3-86b3-4e38-92be-9a912291df0c139544093255424_1618555702611; [hcaoad@login-0 .__6f46d0f3-86b3-4e38-92be-9a912291df0c139544093255424_1618555702611]> date; Wed Apr 21 11:09:46 HKT 2021; [hcaoad@login-0 .__6f46d0f3-86b3-4e38-92be-9a912291df0c139544093255424_1618555702611]> ll -h; total 48G; -rwx------ 1 hcaoad boip 260M Apr 20 13:34 AD.tdb; -rwx------ 1 hcaoad boip 203M Apr 20 13:34 AD_var.tdb; -rwx------ 1 hcaoad boip 304M Apr 20 13:34 ALT.tdb; -rwx------ 1 hcaoad boip 146M Apr 20 13:34 ALT_var.tdb; -rwx------ 1 hcaoad boip 353M Apr 20 13:34 BaseQRankSum.tdb; -rwx------ 1 hcaoad boip 7.3G Apr 20 13:34 __coords.tdb; -rwx------ 1 hcaoad boip 132M Apr 20 13:34 DB.tdb; -rwx------ 1 hcaoad boip 3.4G Apr 20 13:34 DP_FORMAT.tdb; -rwx------ 1 hcaoad boip 295M Apr 20 13:34 DP.tdb; -rwx------ 1 hcaoad boip 8.1G Apr 20 13:34 END.tdb; -r",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7218:1493,log,login-,1493,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7218,1,['log'],['login-']
Testability," Affected version(s); - [ ] Latest public release version [version?]; 4.6.0.0 GATK and Picard 3.2.0; - [ ] Latest master branch as of [date of test?]; 3 Jul 2023. ### Description ; _Describe the problem below. Provide **screenshots** , **stacktrace** , **logs** where appropriate._; I'm trying to use gatk for finding snps in exome capture project. I get an error when trying to use MarkDuplicates - I tried using it from picard and from gatk. The screen output is:; ```; picard MarkDuplicates I=WA02_i5-537_i7-98_S11819_L004.bam O=test.dup.bam M=marked_dup_metrics.txt; INFO 2024-07-03 15:25:31 MarkDuplicates. ********** NOTE: Picard's command line syntax is changing.; **********; ********** For more information, please see:; **********; https://github.com/broadinstitute/picard/wiki/Command-Line-Syntax-Transition-For-Users-(Pre-Transition); **********; ********** The command line looks like this in the new syntax:; **********; ********** MarkDuplicates -I WA02_i5-537_i7-98_S11819_L004.bam -O test.dup.bam -M marked_dup_metrics.txt; **********. 15:25:31.262 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/opt/picard/build/libs/picard.jar!/com/intel/gkl/native/libgkl_compression.so; [Wed Jul 03 15:25:31 CEST 2024] MarkDuplicates INPUT=[WA02_i5-537_i7-98_S11819_L004.bam] OUTPUT=test.dup.bam METRICS_FILE=marked_dup_metrics.txt MAX_SEQUENCES_FOR_DISK_READ_ENDS_MAP=50000 MAX_FILE_HANDLES_FOR_READ_ENDS_MAP=8000 SORTING_COLLECTION_SIZE_RATIO=0.25 TAG_DUPLICATE_SET_MEMBERS=false REMOVE_SEQUENCING_DUPLICATES=false TAGGING_POLICY=DontTag CLEAR_DT=true DUPLEX_UMI=false FLOW_MODE=false FLOW_DUP_STRATEGY=FLOW_QUALITY_SUM_STRATEGY USE_END_IN_UNPAIRED_READS=false USE_UNPAIRED_CLIPPED_END=false UNPAIRED_END_UNCERTAINTY=0 UNPAIRED_START_UNCERTAINTY=0 FLOW_SKIP_FIRST_N_FLOWS=0 FLOW_Q_IS_KNOWN_END=false FLOW_EFFECTIVE_QUALITY_THRESHOLD=15 ADD_PG_TAG_TO_READS=true REMOVE_DUPLICATES=false ASSUME_SORTED=false DUPLICATE_SCORING_STRATEGY=SUM_OF_BASE_QUALITIES PROGRAM_RECORD_",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8904:2281,test,test,2281,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8904,1,['test'],['test']
Testability," CustomTool`, but also with public tools. Only if `--use_jdk_deflater true` is provided, it works. . The log is the following (there is no other log):. ```; 14:57:19.102 INFO IntelGKLUtils - Trying to load Intel GKL library from:; jar:file:/Users/daniel/workspaces/gatk4test/build/libs/shadowJar-0.0.1-SNAPSHOT-all.jar!/com/intel/gkl/native/libIntelGKL.dylib; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGILL (0x4) at pc=0x0000000128c014d0, pid=31197, tid=5891; #; # JRE version: Java(TM) SE Runtime Environment (8.0_60-b27) (build 1.8.0_60-b27); # Java VM: Java HotSpot(TM) 64-Bit Server VM (25.60-b23 mixed mode bsd-amd64 compressed oops); # Problematic frame:; # C [libIntelGKL8818190486223479934.dylib+0xe4d0] _ZN7ContextIfEC2Ev+0x30; #; # Core dump written. Default location: /cores/core or core.31197; #; # An error report file with more information is saved as:; # /Users/daniel/workspaces/gatk4test/hs_err_pid31197.log; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; # The crash happened outside the Java Virtual Machine in native code.; # See problematic frame for where to report the bug.; #; Abort trap: 6 (core dumped); ```. To fix it, I tried by excluding `com.intel.gkl` from GATK and add it as a dependency to my program, but it blows up anyway. In addition, I tried a sample program to load the PairHMM fastest implementation by `PairHMM.Implementation.FASTEST_AVAILABLE.makeNewHMM()`, and it also blows up. If I remove completely the dependency in my shadow jar, the command line blows up because the gkl `IntelDeflaterFactory` is not found. I guess that the error in the library is GKL-related, but in the case of the GATK framework I would like to have a way of using the library without assuming that the final user will have support for the native code or not. Could this be done? I prefer not to remove the faster code by intel because I know that some users will benefit from it.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1985:1170,log,log,1170,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1985,1,['log'],['log']
Testability," Description ; I want to use Funcotator to annotate the VCF file given by Illumina TruSight Oncology 500 pipeline. But when I run the command above, it throws out an error, seems something related with malformat. I check my VCF file and think it should be OK. So I wonder if you can kindly tell me how to fix this bug?; The ERROR is:; `Using GATK jar /home/shiyang/softwares/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /home/shiyang/softwares/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar Funcotator --variant /home/shiyang/Project/BGB900_101/TSO_result/TSO_somatic_vcf/112-0005-0031-B1_L1.UP12.tmb.tsv.tso.somatic.vcf --reference /storage01/ref_genome/hg19/bwa/ucsc.hg19.fasta --ref-version hg19 --data-sources-path /home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s --output /home/shiyang/Project/BGB900_101/TSO_result/test.maf --output-file-format MAF; 15:41:48.793 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/shiyang/softwares/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Aug 19, 2020 3:41:49 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 15:41:49.028 INFO Funcotator - ------------------------------------------------------------; 15:41:49.028 INFO Funcotator - The Genome Analysis Toolkit (GATK) v4.1.8.1; 15:41:49.028 INFO Funcotator - For support and documentation go to https://software.broadinstitute.org/gatk/; 15:41:49.028 INFO Funcotator - Executing as shiyang@r740 on Linux v3.10.0-957.el7.x86_64 amd64; 15:41:49.028 INFO Funcotator - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_252-b09; 15:41:49.028 INFO Funcotator - Start Date/Time: August 19, 2020 3:41:48 PM CST; 15:41:49.029",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6758:2516,test,test,2516,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6758,1,['test'],['test']
Testability," FastaAlternateReferenceMaker tool. . A new parameter `--keep-contig-names` is added. . New optional behavior is to set contig names as ; `>originalcontigname description`. Here is my small local test and its result. **VCF**; ```; ##fileformat=VCFv4.2; ##FILTER=<ID=PASS,Description=""All filters passed"">; ##FORMAT=<ID=GT,Number=1,Type=String,Description=""GT"">; ##contig=<ID=chr17,length=83257441>; #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	Sample; chr17	1	.	N	A	100	PASS	.	GT	1/1; ```; **Original Fasta**; ```; >chr17; NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN; NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN; NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN; NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN; NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN; NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN; NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN; NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN; NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN; ```. **New Fasta with new optional behavior**; ```; >chr17 chr17:1-83257441; ANNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN; NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN; NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN; NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN; NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN; NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN; NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN; NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN; NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN; ```. **Sequence dictionary created for the new Fasta.**. ```; @HD	VN:1.0	SO:unsorted; @SQ	SN:chr17	LN:83257441	M5:8127f7ddcacb7afb1a6277cdd629fdcd	UR:file:///path/to/chr17_mod2.fasta; ```. Default value is false therefore original behavior is kept. Should not hurt any current tests.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8865:2077,test,tests,2077,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8865,1,['test'],['tests']
Testability, GenomeLocParser - chrEBV (171823 bp); 23:44:43.173 INFO GermlineCNVCaller - Aggregating read-count file /gpfs/hpc/home/lijc/xiangxud/project/test/NGS_WES_test/4_tools_vcf/gatk4/info/counts/V300033254_96.tsv (1 / 3); 23:44:43.345 INFO GermlineCNVCaller - Aggregating read-count file /gpfs/hpc/home/lijc/xiangxud/project/test/NGS_WES_test/4_tools_vcf/gatk4/info/counts/V300033256_95.tsv (2 / 3); 23:44:43.521 INFO GermlineCNVCaller - Aggregating read-count file /gpfs/hpc/home/lijc/xiangxud/project/test/NGS_WES_test/4_tools_vcf/gatk4/info/counts/V300033254_97.tsv (3 / 3); 23:44:43.683 DEBUG ScriptExecutor - Executing:; 23:44:43.683 DEBUG ScriptExecutor - python; 23:44:43.683 DEBUG ScriptExecutor - /tmp/cohort_denoising_calling.6786136740079319091.py; 23:44:43.683 DEBUG ScriptExecutor - --ploidy_calls_path=/gpfs/hpc/home/lijc/xiangxud/project/test/NGS_WES_test/4_tools_vcf/gatk4/info/ploidy/ploidy-calls; 23:44:43.683 DEBUG ScriptExecutor - --output_calls_path=/gpfs/hpc/home/lijc/xiangxud/project/test/NGS_WES_test/4_tools_vcf/gatk4/info/cohort_all/cohort_30-calls; 23:44:43.683 DEBUG ScriptExecutor - --output_tracking_path=/gpfs/hpc/home/lijc/xiangxud/project/test/NGS_WES_test/4_tools_vcf/gatk4/info/cohort_all/cohort_30-tracking; 23:44:43.683 DEBUG ScriptExecutor - --random_seed=1984; 23:44:43.683 DEBUG ScriptExecutor - --modeling_interval_list=/tmp/intervals15539986661449841065.tsv; 23:44:43.684 DEBUG ScriptExecutor - --output_model_path=/gpfs/hpc/home/lijc/xiangxud/project/test/NGS_WES_test/4_tools_vcf/gatk4/info/cohort_all/cohort_30-model; 23:44:43.684 DEBUG ScriptExecutor - --enable_explicit_gc_bias_modeling=True; 23:44:43.684 DEBUG ScriptExecutor - --read_count_tsv_files; 23:44:43.684 DEBUG ScriptExecutor - /tmp/V300033254_96.rc5147399438960401577.tsv; 23:44:43.684 DEBUG ScriptExecutor - /tmp/V300033256_95.rc16057077786486760637.tsv; 23:44:43.684 DEBUG ScriptExecutor - /tmp/V300033254_97.rc18322117796550461836.tsv; 23:44:43.684 DEBUG ScriptExecutor - --psi_s_scale=1.0000,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8938:34241,test,test,34241,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8938,1,['test'],['test']
Testability," I am able to run this step is by running it through the docker image you provide. That, however, is not ideal for our setup. Any idea as to what I may try to be able to run it directly?. GATK version:. Using GATK jar /home/analyst/anaconda3/envs/snakemake\_env/share/gatk4-4.2.5.0-0/gatk-package-4.2.5.0-local.jar ; ; Running: ; ;     java -Dsamjdk.use\_async\_io\_read\_samtools=false -Dsamjdk.use\_async\_io\_write\_samtools=true -Dsamjdk.use\_async\_io\_write\_tribble=false -Dsamjdk.compression\_level=2 -jar /home/analyst/anaconda3/envs/snakemake\_env/share/gatk4-4.2.5.0-0/gatk-package-4.2.5.0-local.jar --version ; ; The Genome Analysis Toolkit (GATK) v4.2.5.0 ; ; HTSJDK Version: 2.24.1 ; ; Picard Version: 2.25.4. Exact command:. gatk CNNScoreVariants -I 73318\_WES\_hg19\_recalibrated.sorted.bam -V 73318\_80\_IDTv1.vcf.gz -R /media/analyst/Data/Reference\_data/hg19.fa -O /media/analyst/Data/73318\_CNNScore\_test.vcf.gz -tensor-type read\_tensor > /media/analyst/Data/CNNScoreVariants.log. Entire console output:. Running: ; ;     java -Dsamjdk.use\_async\_io\_read\_samtools=false -Dsamjdk.use\_async\_io\_write\_samtools=true -Dsamjdk.use\_async\_io\_write\_tribble=false -Dsamjdk.compression\_level=2 -jar /home/analyst/anaconda3/envs/snakemake\_env/share/gatk4-4.2.5.0-0/gatk-package-4.2.5.0-local.jar CNNScoreVariants -I 73318\_WES\_hg19\_recalibrated.sorted.bam -V 73318\_80\_IDTv1.vcf.gz -R /media/analyst/Data/Reference\_data/hg19.fa -O /media/analyst/Data/73318\_CNNScore\_test.vcf.gz -tensor-type read\_tensor ; ; 11:17:58.509 INFO  NativeLibraryLoader - Loading libgkl\_compression.so from jar:file:/home/analyst/anaconda3/envs/snakemake\_env/share/gatk4-4.2.5.0-0/gatk-package-4.2.5.0-local.jar!/com/intel/gkl/native/libgkl\_compression.so ; ; Apr 25, 2022 11:17:58 AM shaded.cloud\_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine ; ; INFO: Failed to detect whether we are running on Google Compute Engine. ; ; 11:17:58.668 INFO  CNNScoreVariants -",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7811:1850,log,log,1850,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7811,1,['log'],['log']
Testability," I don't know how much you cleaned up the GATK4 version. We refactored all the engine stuff shared with `HaplotypeCaller` to be very distinct from the somatic genotyping logic, so the only complexity would be in local assembly and PairHMM. Which could be significant, of course. > We would also want to make sure that we only implement this optimization if that SNP is the only SNP on the haplotype. . .Although we've seen that the graph traversal frequently breaks phasing. The specific case I had in mind is when you have a bubble or something more complex in the graph, followed by a stretch of reference (i.e. all haplotypes have nothing going on here), followed (or not) by more activity. It seems reasonable in that case to chop each active area into its own haplotype(s), which is equivalent to pinning the ref-only area to be ref-only in PairHMM. I believe but could be wrong that in a case like this our assembly would not respect phasing between the two active areas anyway, so we lose nothing. By the way, I should clarify that the idea is not to truncate the `ActiveRegion`, but rather to break it into a few small haplotypes semi-intelligently *after* building the whole deBruijn graph. It could well be that my optimism is ill-founded. Nonetheless, having a quick-and-dirty mode would be very useful for the following purposes where you need to run M2 a lot and don't need perfection:. * making an M2 panel of normals; * making true positives + false positives training data sets for artifact classifiers; * testing changes. ---. @ldgauthier commented on [Mon Mar 06 2017](https://github.com/broadinstitute/gatk-protected/issues/909#issuecomment-284502170). ""Quick and dirty"" would be useful for testing changes, but the PoN and training sets shouldn't be recreated very often so there's less savings. I hate to leverage the fact that we break phasing to optimize things because I dream of a future where HaplotypeCaller actually calls haplotypes (as you've already added an issue for).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2945:3001,test,testing,3001,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2945,2,['test'],['testing']
Testability," I run GenotypeGVCFs with 222 samples I get the error: A USER ERROR has occurred: Couldn't create GenomicsDBFeatureReader. The GATK version used is gatk-4.4.0.0 and the command used is the following:. python2.7 /home/administrator/tool/gatk-4.4.0.0/gatk --java-options ""-Xmx4g"" GenotypeGVCFs -R /mnt/nas/Stefano/Cashmere/Reference_Genome/GCF_001704415.1_ARS1_genomic.fna -V gendb://my_database -O /mnt/nas2/Stefano/Cashmere/joint_variant_calling/222_goats.vcf.gz. attaches below also the complete program log. and the content of my callset.json file. Any idea about that?. Thank you very much. Stefano. REQUIRED for all errors and issues:; a) GATK version used: gatk-4.4.0.0; b) Exact command used: python2.7 /home/administrator/tool/gatk-4.4.0.0/gatk --java-options ""-Xmx4g"" GenotypeGVCFs -R /mnt/nas/Stefano/Cashmere/Reference_Genome/GCF_001704415.1_ARS1_genomic.fna -V gendb://my_database -O /mnt/nas2/Stefano/Cashmere/joint_variant_calling/222_goats_fatte_con_GenomicsDBImport.vcf.gz. c) Entire program log:. (base) administrator@srv2-napolioni:/mnt/nas2/Stefano/Cashmere/joint_variant_calling$ python2.7 /home/administrator/tool/gatk-4.4.0.0/gatk --java-options ""-Xmx4g"" GenotypeGVCFs -R /mnt/nas/Stefano/Cashmere/Reference_Genome/GCF_001704415.1_ARS1_genomic.fna -V gendb://my_database -O /mnt/nas2/Stefano/Cashmere/joint_variant_calling/222_goats.vcf.gz; Using GATK jar /home/administrator/tool/gatk-4.4.0.0/gatk-package-4.4.0.0-local.jar; Running:;     java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx4g -jar /home/administrator/tool/gatk-4.4.0.0/gatk-package-4.4.0.0-local.jar GenotypeGVCFs -R /mnt/nas/Stefano/Cashmere/Reference_Genome/GCF_001704415.1_ARS1_genomic.fna -V gendb://my_database -O /mnt/nas2/Stefano/Cashmere/joint_variant_calling/222_goats.vcf.gz; 12:01:18.521 INFO  NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/administrator/tool/ga",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8709:1555,log,log,1555,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8709,1,['log'],['log']
Testability," INFO --QUIET false --use_jdk_deflater false --use_jdk_inflater false --gcs_max_retries 20 --disableToolDefaultReadFilters false; [October 3, 2017 5:27:51 AM UTC] Executing as centos@master.novalocal on Linux 3.10.0-514.10.2.el7.x86_64 amd64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_131-b11; Version: 4.beta.5; 05:27:52.642 INFO PrintReadsSpark - HTSJDK Defaults.COMPRESSION_LEVEL : 1; 05:27:52.642 INFO PrintReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 05:27:52.642 INFO PrintReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : false; 05:27:52.642 INFO PrintReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 05:27:52.642 INFO PrintReadsSpark - Deflater: IntelDeflater; 05:27:52.642 INFO PrintReadsSpark - Inflater: IntelInflater; 05:27:52.643 INFO PrintReadsSpark - GCS max retries/reopens: 20; 05:27:52.643 INFO PrintReadsSpark - Using google-cloud-java patch c035098b5e62cb4fe9155eff07ce88449a361f5d from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 05:27:52.643 INFO PrintReadsSpark - Initializing engine; 05:27:52.643 INFO PrintReadsSpark - Done initializing engine; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@dcf3e99] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@61df66b6].; log4j:ERROR Could not instantiate appender named ""console"".; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; log4j:WARN No appenders could be found for logger (org.apache.spark.SparkContext).; log4j:WARN Please initialize the log4j system properly.; log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.; ```; I can run command using the spark-shell but somehow GATK4 fails. Any idea?. thank you very much",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3651:3997,log,logger,3997,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3651,2,['log'],"['logger', 'logging']"
Testability," INFO GenomicsDBImport - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 10:19:39.337 INFO GenomicsDBImport - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 10:19:39.337 INFO GenomicsDBImport - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 10:19:39.337 INFO GenomicsDBImport - Deflater: IntelDeflater; 10:19:39.337 INFO GenomicsDBImport - Inflater: IntelInflater; 10:19:39.337 INFO GenomicsDBImport - GCS max retries/reopens: 20; 10:19:39.338 INFO GenomicsDBImport - Requester pays: disabled; 10:19:39.338 INFO GenomicsDBImport - Initializing engine; 10:19:39.489 INFO IntervalArgumentCollection - Processing 100 bp from intervals; 10:19:39.490 INFO GenomicsDBImport - Done initializing engine; 10:19:39.948 INFO GenomicsDBLibLoader - GenomicsDB native library version : 1.4.4-ce4e1b9; 10:19:39.951 INFO GenomicsDBImport - Vid Map JSON file will be written to /home/test/Software/gatk-4.4.0.0/test/./02/vidmap.json; 10:19:39.951 INFO GenomicsDBImport - Callset Map JSON file will be written to /home/test/Software/gatk-4.4.0.0/test/./02/callset.json; 10:19:39.951 INFO GenomicsDBImport - Complete VCF Header will be written to /home/test/Software/gatk-4.4.0.0/test/./02/vcfheader.vcf; 10:19:39.951 INFO GenomicsDBImport - Importing to workspace - /home/test/Software/gatk-4.4.0.0/test/./02; 10:19:40.060 INFO GenomicsDBImport - Importing batch 1 with 2 samples; 10:19:40.075 INFO GenomicsDBImport - Shutting down engine; org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImport done. Elapsed time: 0.01 minutes.; Runtime.totalMemory()=285212672; java.lang.NumberFormatException: For input string: ""G""; 	at java.base/java.lang.NumberFormatException.forInputString(NumberFormatException.java:67); 	at java.base/java.lang.Integer.parseInt(Integer.java:668); 	at java.base/java.lang.Integer.parseInt(Integer.java:786); 	at htsjdk.tribble.readers.TabixReader.getIntv(TabixReader.java:337); 	at htsjdk.tribble.readers.TabixReader.access$500(TabixReader.java:48); 	at htsjd",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8517:2621,test,test,2621,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8517,1,['test'],['test']
Testability," Instructions. The github issue tracker is for bug reports, feature requests, and API documentation requests. General questions about how to use the GATK, how to interpret the output, etc. should be asked on the [official support forum](http://gatkforums.broadinstitute.org/gatk).; - Search the existing github issues to see if your issue (or something similar) has already been reported. If the issue already exists, you may comment there to inquire about the progress.; - Determine whether your issue is a **bug report**, a **feature request**, or a **documentation request** (for tool/class javadoc only -- for forum docs please post there); - Consider if your ""issue"" is better addressed on the GATK forum: http://gatkforums.broadinstitute.org/gatk Post there if you have questions about expected tool behavior, output format, unexpected results, or generally any question that does not fit into the categories above; - Use a **concise** yet **descriptive** title; - Choose the corresponding template block below and fill it in, replacing or deleting text in italics (surrounded by `_`) as appropriate; - Delete the other template blocks and this header. ----. ## Feature request. ### Tool(s) or class(es) involved. VariantRecalibrator. ### Description. VariantRecalibrator automatically runs the generated Rscript to produce recalibration plots. This is usually good and convenient, but it requires that all *R* dependencies must be installed in the same environment in the current running GATK environment. This is not necessarily the case for sandbox-based package managers e.g. docker or conda. A viable fix on the user's side is to include R dependencies with GATK in e.g. docker or conda. But I think I would prefer if my packages were as independent of each other as possible. It would be great if **VariantRecalibrator had an option to write but not run the Rscript for recalibration plots.** Then, the user can call the Rscript in an appropriate e.g. R conda environment or docker image.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7697:1553,sandbox,sandbox-based,1553,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7697,1,['sandbox'],['sandbox-based']
Testability, Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); 	at org.testng.internal.Invoker.invokeMethod(Invoker.java:639); 	at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:821); 	at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1131); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); 	at org.testng.TestRunner.privateRun(TestRunner.java:773); 	at org.testng.TestRunner.run(TestRunner.java:623); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:357); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:352); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:310); 	at org.testng.SuiteRunner.run(SuiteRunner.java:259); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1185); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1110); 	at org.testng.TestNG.run(TestNG.java:1018); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:129); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:88); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.internal.di,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2349:4888,test,testng,4888,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2349,1,['test'],['testng']
Testability," QUAL FILTER INFO FORMAT sample; 13 32911888 . A G 177.64 . AC=1;AF=0.500;AN=2;BaseQRankSum=0.086;DP=21;ExcessHet=3.0103;FS=1.719;MLEAC=1;MLEAF=0.500;MQ=60.00;MQRankSum=0.000;QD=8.46;ReadPosRankSum=0.475;SOR=0.368 GT:AD:DP:GQ:PL 0/1:13,8:21:99:185,0,339; 13 32913055 . A G 402.06 . AC=2;AF=1.00;AN=2;DP=15;ExcessHet=3.0103;FS=0.000;MLEAC=2;MLEAF=1.00;MQ=60.00;QD=26.80;SOR=1.112 GT:AD:DP:GQ:PL 1/1:0,15:15:45:416,45,0; 13 32915005 . G C 378.06 . AC=2;AF=1.00;AN=2;DP=13;ExcessHet=3.0103;FS=0.000;MLEAC=2;MLEAF=1.00;MQ=60.00;QD=29.08;SOR=1.179 GT:AD:DP:GQ:PL 1/1:0,13:13:39:392,39,0; 13 32929232 . A G 168.64 . AC=1;AF=0.500;AN=2;BaseQRankSum=1.335;DP=16;ExcessHet=3.0103;FS=0.000;MLEAC=1;MLEAF=0.500;MQ=60.00;MQRankSum=0.000;QD=15.33;ReadPosRankSum=-1.442;SOR=0.446 GT:AD:DP:GQ:PL 0/1:5,6:11:99:176,0,121; 13 32929387 . T C 209.02 . AC=2;AF=1.00;AN=2;DP=7;ExcessHet=3.0103;FS=0.000;MLEAC=2;MLEAF=1.00;MQ=60.00;QD=29.86;SOR=1.609 GT:AD:DP:GQ:PL 1/1:0,7:7:21:223,21,0; ```. Execution log:; ```; Using GATK jar /gatk/gatk-package-4.2.2.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /gatk/gatk-package-4.2.2.0-local.jar HaplotypeCaller --input sample.bam --annotation OrientationBiasReadCounts --intervals b37.chr13.bed --reference hs37d5.fa --output sample.vcf.gz; 03:56:44.380 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/gatk/gatk-package-4.2.2.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Jan 06, 2023 3:56:44 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 03:56:44.703 INFO HaplotypeCaller - ------------------------------------------------------------; 03:56:44.704 INFO HaplotypeCaller - The Genome Analysis Toolkit (GATK) v4.2.2.0; 03:56:44.704 INFO HaplotypeCaller - For support and documentation",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8149:2105,log,log,2105,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8149,1,['log'],['log']
Testability," QUALapprox and other features (#7146); - Job Add labels to BQ operations from GATK (Issues-199) (#7115); - parse map to list to avoid brackets and spaces in vcf output (#7168); - #259 Inline schema for importgenomes.wdl (#7171); - Created AvroFileReader and unittest, Update ExtractCohort and ExtractCohortEngine (#7174); - #224 Import WDL: handle 15 TB /table /day import limit (#7167); - #260 filter out AS_QD, SOR, FS from cohort extract VCF (#7173); - Full scientific validation via end to end comparison of filtered results between WARP and BQ (#7179); - Cherry pick of commits to fix GATK tests from master (#7183); - ExtractCohort supports -XL exclusion and follows intervals, other optimizations (#7181); - ExtractFeatures supports -XL exclusion and follows intervals, other optimizations (#7184); - change 0/0 GQ0 sites to nocalls (#7190); - updated (#7195); - Rename ""metadata"" table to ""sample_info"" table, fix vet schema (#7196); - Allow users to specify VQSLOD sensitivity and apply threshold in ExtractCohort (#7194); - Calculate and Store site-level QCs (#7197); - Filter Failing QC Sites from Extract (#7201); - WDLize GvsPrepareCallset (briefly known as CreateCohortTable) (#7200); - default drop_state to 60, but allow NONE as input (#7206); - SA support and consistent naming for all GVS WDLs (#7205); - fix GvsExtractCallset inputs file (#7210); - add clustering to tables (#7207); - add vqsr cutoffs to GvsExtractCallset wdl; clean up dockstore yml (#7209); - Avro test (#7192); - Enable call caching of TSV generation in GvsImportGenomes (#7226); - 266 Clean up ExtractCohort -- remove query mode param (#7227); - 288 Add an excess alleles param (#7221); - take sample name as a param (#7236); - How to run GIAB comparisons (#7237); - Update GvsCreateFilterSet.wdl (#7239); - Use GatherVcfsCloud in GvsCreateFilterSet.wdl (#7241); - parameterize TTL with defaults, reduce memory allocation (#7244); - Addressing OOM in CohortExtract (#7245); - make outputs optional, change case",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8248:12833,test,tests,12833,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8248,4,['test'],"['test', 'tests']"
Testability," SNP sites where a deletion was not called, since we still assign the haplotype to ""spanning deletion"" if there was a deletion at that site. . For indels however this can cause some extra false positives at sites like this one (the left variant under the deletion in the gatk track):; <img width=""1616"" alt=""Screen Shot 2020-07-14 at 4 09 47 PM"" src=""https://user-images.githubusercontent.com/16102845/87471543-86a2ee80-c5ec-11ea-9cdd-8acf1beb8c14.png"">; <img width=""178"" alt=""Screen Shot 2020-07-14 at 4 10 45 PM"" src=""https://user-images.githubusercontent.com/16102845/87471596-9de1dc00-c5ec-11ea-9d4c-786e114d57d3.png"">; This is a messy site that is perhaps complicated by representation issues but we can see that GATK emitted an extra insertion underlying the longer event (which was marked as homozygous in the truth set). Following the same logic as above we can see DRAGEN did not make the call because it assigned all of the likelihoods for the longer deletion to the reference when compared against the shorter insertion underlying it which outweighed the event, whereas in GATK the likelihood from that longer event was assigned to the spanning deletion allele. Since there was little evidence for the reference at this site the insertion ended up being called. This particular pattern can also occur because there are differing lengths of deletions at a site that is anchored on the right, causing noise when calling the events independently from eachother (whereas we might not have called them independently if they were anchored from the left and thus started on the same base). Generally this pattern of differing haplotype allele assignments has a particularly pronounced effect in low complexity regions where it is highly likely there are apparent deletions relative to the reference in the data and can result in significant differences in calling. . Right now there is a tradeoff (when running DRAGEN-GATK mode) for running `--disable-spanning-event-genotyping` in GATK. Given th",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6707:2851,log,logic,2851,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6707,1,['log'],['logic']
Testability," The PCR error model applied pre-pairHMM does not seem to always do the right thing. . This is explained in class TandemRepeatFinder JavaDoc (soon to be merged in). Moreover the code responsible to detect STR repeats seems rather inefficient doing multiple passes on the read bases for each position on the read when it seems that it must be possible to accomplish the same just doing at most one pass per possible STR length. This task is to fix the PCR artifact modeling issues evaluating whether there is at least no a drop in calling accuracy all. Also try to make the code more efficient. ---. @ldgauthier commented on [Tue Jul 21 2015](https://github.com/broadinstitute/gsa-unstable/issues/1064#issuecomment-123431158). @yfarjoun and I just added a Palantir issue for this this morning -- should the analysis wait until you're done updating the code?. ---. @vruano commented on [Tue Jul 21 2015](https://github.com/broadinstitute/gsa-unstable/issues/1064#issuecomment-123431971). Just waiting for test to pass...; So you knew about this issue already?. ---. @ldgauthier commented on [Tue Jul 21 2015](https://github.com/broadinstitute/gsa-unstable/issues/1064#issuecomment-123432816). We were talking about it because the PCR-free option doesn't get used in production (on PCR-free data) and we didn't know how much difference it actually makes. ---. @vruano commented on [Tue Jul 21 2015](https://github.com/broadinstitute/gsa-unstable/issues/1064#issuecomment-123481297). Merged. ; I think that you can go ahead with the analysis and I would borrow your set up to see if the eventual code update improves things for PCR-plus. . ---. @vruano commented on [Tue Jul 21 2015](https://github.com/broadinstitute/gsa-unstable/issues/1064#issuecomment-123481614). Sorry for the confusion, that merge doesn't solve this issue but one one related to the comp. performance of the existing code. . ---. @eitanbanks commented on [Tue Jul 21 2015](https://github.com/broadinstitute/gsa-unstable/issues/1064#",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2915:1205,test,test,1205,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2915,1,['test'],['test']
Testability," [VS-472] (#7905); - Fix bug and update images (#7912); - VS 483 Beta user wdl (#7894); - Core storage model cost [VS-473] (#7913); - Update Quickstart & Integration to use re-blocked v2 gVCFs [VS-491] (#7924); - KM GVS documentation (#7903); - Track BigQuery costs of GVS python VS-480 (#7915); - Read cost observability table [VS-475] (#7923); - Fix Race Condition, Add Support for Extract by Array of Sample Names (ie from a Sample Set) (#7917); - Rightsize import batches [VS-486] (#7925); - [AoU DRC] Support uppercase site_ids for reblocking (#7929); - Populate cost metadata for GATK tasks. (#7919); - remove accidentally added input (#7931); - VS_492 - Beta User Jar release (#7934); - Cost WDL should throw on FISS API errors [VS-518] (#7942); - Fix bad check for missing workflow name [VS-520] (#7943); - Remove usage of service account from GvsValidateVAT.wdl (#7937); - refactoring for testablity (#7946); - More import retries [VS-532] (#7953); - A few last doc changes (#7927); - WDL to extract a single callset cost (BQ only, not Terra) (#7940); - Temporarily swap in Corretto for Temurin as we can't download Temurin. (#7969); - GL-548 - Update CreateVat code to handle samples that do not contain all population groups. (#7965); - Restore Temurin 11 [VS-570] (#7972); - Add table size check to quickstart integration test [VS-501] (#7970); - Consolidate various docs for AoU callset generation into one to rule them all [VS-553] (#7971); - VS-567. Removing usage of ServiceAccount from CreateVat related WDLs (#7974); - WDL to extract Avro files for Hail import [VS-579] (#7981); - Removed usage of service account from WDLs (#7985); - Document steps for GVS cleanup for base use case [VS-586] (#7989); - Change backticks to single quotes in several error messages - causing shell to attempt to execute. (#7995); - VS-598 - Minor update to AoU Documentation. (#7994); - Allow for incremental addition of data to alt_allele [VS-52] (#7993); - Minor AoU Documentation Update (#7999); -",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8248:26473,test,testablity,26473,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8248,2,['test'],['testablity']
Testability," [hs_err_pid100.log](https://github.com/broadinstitute/gatk/files/6203288/hs_err_pid100.log); [hs_err_pid164.log](https://github.com/broadinstitute/gatk/files/6203289/hs_err_pid164.log); [hs_err_pid274.log](https://github.com/broadinstitute/gatk/files/6203290/hs_err_pid274.log); [hs_err_pid400.log](https://github.com/broadinstitute/gatk/files/6203291/hs_err_pid400.log); [hs_err_pid482.log](https://github.com/broadinstitute/gatk/files/6203292/hs_err_pid482.log); [hs_err_pid711.log](https://github.com/broadinstitute/gatk/files/6203293/hs_err_pid711.log); [hs_err_pid735.log](https://github.com/broadinstitute/gatk/files/6203294/hs_err_pid735.log); [hs_err_pid801.log](https://github.com/broadinstitute/gatk/files/6203295/hs_err_pid801.log); [hs_err_pid825.log](https://github.com/broadinstitute/gatk/files/6203296/hs_err_pid825.log); [hs_err_pid849.log](https://github.com/broadinstitute/gatk/files/6203297/hs_err_pid849.log); [otherFiles.zip](https://github.com/broadinstitute/gatk/files/6203305/otherFiles.zip); [in2510-8.orientationFilter.vcf.txt](https://github.com/broadinstitute/gatk/files/6203356/in2510-8.orientationFilter.vcf.txt); *VCF extension appended with .txt to satisfy GitHub's upload requirements*. #### Expected behavior; Worked on 7 other files generated with the same pipeline. . #### Actual behavior; Unsure why this last one is causing a segfault. The VCF included is not the whole VCF submitted originally. I went cutting out lines from the original until I could isolate it down to a minimal set required to reproduce the crash (I included all of the crash logs generated in case it can help). I was expecting to find a single line or maybe two that were required to reproduce this issue, but that range appears to be needed. Eliminating either the first or last line from the range will make the program work again. Did not attempt to remove lines from the middle of the range yet to see if they're necessary to cause the fault, but it's 2am and I should probably sleep.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7162:8052,log,logs,8052,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7162,1,['log'],['logs']
Testability," addressed on the GATK forum: http://gatkforums.broadinstitute.org/gatk Post there if you have questions about expected tool behavior, output format, unexpected results, or generally any question that does not fit into the categories above; - Use a **concise** yet **descriptive** title; - Choose the corresponding template block below and fill it in, replacing or deleting text in italics (surrounded by `_`) as appropriate; - Delete the other template blocks and this header. ----. ## Bug Report. ### Affected tool(s) or class(es); _Tool/class name(s), special parameters?_; GenotypeGVCFs, /public2/home/gaoshibin/software/gatk-4.4.0.0/gatk --java-options ""-Xmx160g -Djava.io.tmpdir=./tmp_fat"" GenotypeGVCFs -R /public2/home/gaoshibin/B73_REF/Zea_mays.AGPv4.dna.toplevel.fa -V gendb://./CHR9_gvcf_database -G StandardAnnotation -L 9:1-5000000 -O ./test.vcf.gz --genomicsdb-shared-posixfs-optimizations true; ### Affected version(s); - [ 4.1.9.0-4.4.0.0] Latest public release version [version?]; - [ ] Latest master branch as of [date of test?]. ### Description ; _Describe the problem below. Provide **screenshots** , **stacktrace** , **logs** where appropriate._; The ParaStor file system suffers from low CPU operating efficiency and extremely slow read and write speeds. If I test it on my own mobile hard drive, it's normal. The file format of my mobile hard disk is EXT4; #### Steps to reproduce; _Tell us how to reproduce this issue. If possible, include command lines that reproduce the problem. (The support team may follow up to ask you to upload data to reproduce the issue.)_; /public2/home/gaoshibin/software/gatk-4.4.0.0/gatk --java-options ""-Xmx160g -Djava.io.tmpdir=./tmp_fat"" GenotypeGVCFs -R /public2/home/gaoshibin/B73_REF/Zea_mays.AGPv4.dna.toplevel.fa -V gendb://./CHR9_gvcf_database -G StandardAnnotation -L 9:1-5000000 -O ./test.vcf.gz --genomicsdb-shared-posixfs-optimizations true; #### Expected behavior; _Tell us what should happen_; The ParaStor file system suffers from",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8546:1724,test,test,1724,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8546,1,['test'],['test']
Testability," also tried latest gatk version4.2.2.0, same result. Java version is ``` OpenJDK Runtime Environment (build 1.8.0_252-b09) ```; ```; /gatk-4.0.11.0/gatk --java-options ""-Xmx4G"" HaplotypeCaller \; -R GRCh38.p2.fa \; -I RT4_STD.bam \; -ERC GVCF \; -L chr16 \; -O RT4_STD.g.vcf \; -new-qual; ```; - Error message is also different; - First one is :; ```; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x00002aaad9f1e54a, pid=7818, tid=0x00002aaaabdce700; #; # JRE version: Java(TM) SE Runtime Environment (8.0_111-b14) (build 1.8.0_111-b14); # Java VM: Java HotSpot(TM) 64-Bit Server VM (25.111-b14 mixed mode linux-amd64 compressed oops); # Problematic frame:; # C [libgkl_pairhmm_omp1890484777463615571.so+0x6954a] double compute_full_prob_avxd<double>(testcase*)+0x34a; #; # Core dump written. Default location: core or core.7818; #; # An error report file with more information is saved as:; # hs_err_pid7818.log; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; # The crash happened outside the Java Virtual Machine in native code.; # See problematic frame for where to report the bug.; ```. -Second one is ; ```; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x00000035dfe84364, pid=160107, tid=0x00002aaaabdce700; #; # JRE version: Java(TM) SE Runtime Environment (8.0_111-b14) (build 1.8.0_111-b14); # Java VM: Java HotSpot(TM) 64-Bit Server VM (25.111-b14 mixed mode linux-amd64 ); # Problematic frame:; # C [libc.so.6+0x84364]; #; # Core dump written. Default location: core or core.160107; #; # An error report file with more information is saved as:; # hs_err_pid160107.log; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; # The crash happened outside the Java Virtual Machine in native code.; # See problematic frame for where to report the bug. ```. Could this be a bug ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7515:1159,log,log,1159,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7515,1,['log'],['log']
Testability, at org.apache.logging.log4j.core.config.plugins.util.PluginRegistry.decodeCacheFiles(PluginRegistry.java:181); at org.apache.logging.log4j.core.config.plugins.util.PluginRegistry.loadFromMainClassLoader(PluginRegistry.java:119); at org.apache.logging.log4j.core.config.plugins.util.PluginManager.collectPlugins(PluginManager.java:132); at org.apache.logging.log4j.core.pattern.PatternParser.<init>(PatternParser.java:131); at org.apache.logging.log4j.core.pattern.PatternParser.<init>(PatternParser.java:112); at org.apache.logging.log4j.core.layout.PatternLayout.createPatternParser(PatternLayout.java:220); at org.apache.logging.log4j.core.layout.PatternLayout.<init>(PatternLayout.java:138); at org.apache.logging.log4j.core.layout.PatternLayout.<init>(PatternLayout.java:57); at org.apache.logging.log4j.core.layout.PatternLayout$Builder.build(PatternLayout.java:446); at org.apache.logging.log4j.core.config.AbstractConfiguration.setToDefault(AbstractConfiguration.java:518); at org.apache.logging.log4j.core.config.DefaultConfiguration.<init>(DefaultConfiguration.java:49); at org.apache.logging.log4j.core.LoggerContext.<init>(LoggerContext.java:75); at org.apache.logging.log4j.core.selector.ClassLoaderContextSelector.createContext(ClassLoaderContextSelector.java:171); at org.apache.logging.log4j.core.selector.ClassLoaderContextSelector.locateContext(ClassLoaderContextSelector.java:145); at org.apache.logging.log4j.core.selector.ClassLoaderContextSelector.getContext(ClassLoaderContextSelector.java:70); at org.apache.logging.log4j.core.selector.ClassLoaderContextSelector.getContext(ClassLoaderContextSelector.java:57); at org.apache.logging.log4j.core.impl.Log4jContextFactory.getContext(Log4jContextFactory.java:140); at org.apache.logging.log4j.core.impl.Log4jContextFactory.getContext(Log4jContextFactory.java:41); at org.apache.logging.log4j.LogManager.getContext(LogManager.java:182); at org.apache.logging.log4j.LogManager.getLogger(LogManager.java:455); at org.broadinstitute.h,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5126:4256,log,logging,4256,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5126,1,['log'],['logging']
Testability," be supported by this environment), it's a difficult task:; > 1. The goal is to update Python from 3.6 to 3.10+, since Terra now requires the latter for officially supported images.; > 2. However, gCNV relies on the PyMC3 package. PyMC3 3.1 is currently used in GATK master. 3.1 was released in 2017, not long before our release of gCNV in 2018, but it's very old now.; > 3. The latest version of Python that is supported by PyMC3 3.1 in conda is Python 3.6.; > 4. @asmirnov239 has a draft PR (#8094) that updates PyMC3 to 3.5 and Python to 3.7, which clearly still falls short of Python 3.10+. This PR also updated some gCNV code to make it compatible with PyMC3 3.5. (It also removed TensorFlow and added PyTorch.); > 5. @asmirnov239 also merged a PR that added tests for numerical reproducibility of GermlineCNVCaller in cohort mode in #7889.; > 6. The earliest version of PyMC that supports Python 3.10+ is PyMC 4, released in 2022.; > 7. However, PyMC 4 introduces API changes, which will also require additional gCNV code changes and numerical testing.; > 8. These API changes are because the underlying computational backend for PyMC was updated from Theano (think of this as an old alternative to TensorFlow) to Aesara.; > 9. Since then, PyMC 5.9 has been released and the underlying backend has been updated again, from Aesara to PyTensor.; > 10. So if we are going to update the environment to support Python 3.10+, it probably makes sense to go all the way to PyMC 5.9. I've made some strides in this PR; as of [6b08f3a](https://github.com/broadinstitute/gatk/pull/8561/commits/6b08f3af205cb9af1f5c63a0786f9a5a52cd78c1), I've made enough updates to accommodate API changes so that cohort-mode inference for both GermlineCNVCaller and DetermineGermlineContigPloidy runs successfully under Python 3.10 and PyMC 5.9.0---although note that 5.9.1 has been released in the interim!. However, our work has just begun. Results now produced in the numerical tests mentioned above are quite far off ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8561:1242,test,testing,1242,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8561,1,['test'],['testing']
Testability, because the virtual machine instance does not have permission scopes specified. It is possible to skip checking for Compute Engine metadata by specifying the environment variable NO_GCE_CHECK=true.; at com.google.cloud.storage.spi.v1.HttpStorageRpc.translate(HttpStorageRpc.java:227); at com.google.cloud.storage.spi.v1.HttpStorageRpc.get(HttpStorageRpc.java:438); at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:239); at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:236); at shaded.cloud_nio.com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:105); at com.google.cloud.RetryHelper.run(RetryHelper.java:76); at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:50); at com.google.cloud.storage.StorageImpl.get(StorageImpl.java:235); at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.checkAccess(CloudStorageFileSystemProvider.java:687); at java.nio.file.Files.exists(Files.java:2385); at htsjdk.samtools.util.IOUtil.assertFileIsReadable(IOUtil.java:404); at org.broadinstitute.hellbender.engine.ReadsDataSource.<init>(ReadsDataSource.java:206); at org.broadinstitute.hellbender.engine.ReadsDataSource.<init>(ReadsDataSource.java:162); at org.broadinstitute.hellbender.engine.GATKTool.initializeReads(GATKTool.java:391); at org.broadinstitute.hellbender.engine.GATKTool.onStartup(GATKTool.java:640); at org.broadinstitute.hellbender.engine.ReadWalker.onStartup(ReadWalker.java:50); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:136); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:162); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:205); at org.broadinstitute.hellbender.Main.main(Main.java:291); ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5855:1997,assert,assertFileIsReadable,1997,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5855,1,['assert'],['assertFileIsReadable']
Testability," been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x00007ff7b7dfe32d, pid=849, tid=0x00007ff82e11d700; #; # JRE version: OpenJDK Runtime Environment (8.0_242-b08) (build 1.8.0_242-8u242-b08-0ubuntu3~18.04-b08); # Java VM: OpenJDK 64-Bit Server VM (25.242-b08 mixed mode linux-amd64 compressed oops); # Problematic frame:; # C [libgkl_smithwaterman5951765478004985534.so+0x132d] smithWatermanBackTrack(dnaSeqPair*, int, int, int, int, int*, int)+0x1bd; #; # Failed to write core dump. Core dumps have been disabled. To enable core dumping, try ""ulimit -c unlimited"" before starting Java again; #; # An error report file with more information is saved as:; # /home/gatk/hs_err_pid849.log; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; # The crash happened outside the Java Virtual Machine in native code.; # See problematic frame for where to report the bug.; #; ```. **RELEVANT FILES**; [hs_err_pid100.log](https://github.com/broadinstitute/gatk/files/6203288/hs_err_pid100.log); [hs_err_pid164.log](https://github.com/broadinstitute/gatk/files/6203289/hs_err_pid164.log); [hs_err_pid274.log](https://github.com/broadinstitute/gatk/files/6203290/hs_err_pid274.log); [hs_err_pid400.log](https://github.com/broadinstitute/gatk/files/6203291/hs_err_pid400.log); [hs_err_pid482.log](https://github.com/broadinstitute/gatk/files/6203292/hs_err_pid482.log); [hs_err_pid711.log](https://github.com/broadinstitute/gatk/files/6203293/hs_err_pid711.log); [hs_err_pid735.log](https://github.com/broadinstitute/gatk/files/6203294/hs_err_pid735.log); [hs_err_pid801.log](https://github.com/broadinstitute/gatk/files/6203295/hs_err_pid801.log); [hs_err_pid825.log](https://github.com/broadinstitute/gatk/files/6203296/hs_err_pid825.log); [hs_err_pid849.log](https://github.com/broadinstitute/gatk/files/6203297/hs_err_pid849.log); [otherFiles.zip](https://github.com/broadinstitute/gatk/files/6203305/otherFiles.zip); [in2510-",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7162:6482,log,log,6482,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7162,1,['log'],['log']
Testability," bug when variant ref allele doesn't match reference genome. - Fixed test cases for - strand indel cdna strings:; There is a bug in oncotator that was fixed in Funcotator involving cdna; strings for - strand indels. In Oncotator the positions reported are off by 1 (they; should be one less) and the base reported is also wrong.; This is now fixed. - Removed some old code that had been taken out of the main codepath. - Fixed a bug in how the gencode reference contexts are created.; - Fixed a bug in how the end points for the gencode annotations are; created. - Ref context field is now consistent for indels.; The reference context will give WINDOW bases before and after the; logical reference allele for a variant. This is NOT the allele in the; input VCF, but rather the allele that actually has changed. For; insertions, the logical allele is the SPACE BETWEEN TWO BASES (and; therefore the resulting string will always be 2xWINDOW bases long).; For deletions, the logical allele is the given ref allele without the; required preceding base. For MNPs the logical allele is the given ref; allele.; Updated some tests and test data to reflect this change. - Added a small HG38 regression test set. - Fixed a boundary bug with codon strings.; Now codon change strings have an alternate (correct) form for insertions; that involve the start codon on the - strand, and the stop codon on the; + strand. This form eliminates any overrun/out of bounds exceptions. - Fixed an issue involving variants that overrun the end of the coding sequence. - Added in additional required files for regression test gencode data source. - Added a helpful script and modified test data set to be correct. - Updated part of Gencode to prepare for fixing the exon boundary issue. - Updated FuncotatorIntegrationTests to use environment-variable paths; more safely. - Updated `FuncotatorUtils::getCodingSequenceChangeString` to use; base data types rather than those in `SequenceComparison`. - Refactored; `GencodeFunco",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5302:3807,log,logical,3807,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5302,1,['log'],['logical']
Testability," calculate 4 log gammas per het, so if you have 25,000 hets all the log gammas in the model likelihood take 1/100 of a second. . To get MLEs for each parameter (minor allele fractions, outlier probability etc) might require 100 evaluations each, so we're probably dealing with 10 seconds of log gammas per iteration to find the posterior mode. Getting a few hundred MCMC samples is probably more expensive but roughly comparable. These numbers are manageable but get expensive when we relearn the model at every iteration of segment merging. In my opinion it makes sense to come back to this issue after we have a new segmentation strategy. We'll see how pressing it is then. ---. @samuelklee commented on [Wed Jun 08 2016](https://github.com/broadinstitute/gatk-protected/issues/542#issuecomment-224786950). To clarify, I think this is primarily an issue for WGS, where we have ~1.5 million hets. From the logs in /dsde/working/lichtens/wgs/out_case_chip_wgs/acnv/*out it looks like finding the MLE takes ~10 minutes (which is roughly consistent with your estimate), but 200 MCMC iterations takes ~1 hr. Naive profiling of the AlleleFractionModeller tests suggests that around ~60% CPU is going toward log gammas, so if we can improve on this I think it might be an easy win. But we should perhaps profile more carefully. However, I agree that changing our segmentation is more pressing! Note that oversegmentation (typically 1000+ segments) hurts us by both by increasing the number of MAF parameters and by increasing the number of similar-segment merge iterations required to smooth things (looks like the WGS samples hit the limit of 25 merge iterations = ~25 hrs). Turning off refitting between iterations helps, perhaps at the cost of smoothness of the final result, but you're still looking at 2+ hours for the initial and final fit. Just to note, other possibilities for cutting down the runtime include trimming down the number of hets for WGS, changing similar-segment merging so that we ca",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2860:1653,log,logs,1653,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2860,1,['log'],['logs']
Testability," cannot vouch that this is the best way to do things) revealed 245Mb of files that are unused in master:. for ff in `find src/test/resources -name ""*""`; do file=`basename $ff`; git grep -l $file >/dev/null; rcode=$?; if [[ $rcode -ne 0 ]]; then echo $ff; fi; done. Note I didn't search in all branches, but I figure we can always recommit those files. Also, any index files, etc. should be retained if necessary. CNV team will delete their files, but I'll leave it up to engine and the other teams about how much we want to remove. src/test/resources/dbsnp_132.b36.excluding_sites_after_129.chr1_1k.vcf.idx; src/test/resources/empty.vcf.idx; src/test/resources/exampleFASTA.fasta.fai; src/test/resources/fastaWithoutDict.fasta.fai; src/test/resources/fastaWithoutFai.dict; src/test/resources/hg19micro.dict; src/test/resources/hg19micro.fasta.fai; src/test/resources/hg19mini.dict; src/test/resources/hg19mini.fasta.fai; src/test/resources/Homo_sapiens_assembly19_chr1_1M.dict; src/test/resources/Homo_sapiens_assembly19_chr1_1M.fasta.fai; src/test/resources/Homo_sapiens_assembly19.dbsnp135.chr1_1M.exome_intervals.vcf.idx; src/test/resources/HSA19.dbsnp135.chr1_1M.exome_intervals.modified.vcf.idx; src/test/resources/human_g1k_v37.chr17_1Mb.dict; src/test/resources/human_g1k_v37.chr17_1Mb.fasta.fai; src/test/resources/iupacFASTA.dict; src/test/resources/iupacFASTA.fasta.fai; src/test/resources/joint_calling.chr1_1M.1kg_samples.10samples.noINFO.vcf.idx; src/test/resources/large/1000G.phase3.broad.withGenotypes.chr20.10100000.vcf.idx; src/test/resources/large/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.cram.bai; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/bias_covariates_ARD_coefficients.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/mean_bias_covariates_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/mean_bias_covariates_norm2.tsv; src/test/resources/large/cn",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3905:1028,test,test,1028,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905,1,['test'],['test']
Testability," changes relevant to gatk -; * Allow changes for allele specific and other annotations to vid file via GenomicsDBImporter without hardcoding them in genomicsdb. See [GenomicsDB Fix 39](https://github.com/GenomicsDB/GenomicsDB/pull/39). Thanks @mlathara.; * [Fix](https://github.com/GenomicsDB/GenomicsDB/pull/54) for ; BUGreportGATK-07-19-19 reported by @bshifaw where a large ploidy + number of genotypes was leading to math overflow. The overflow is now caught and GenomicsDB stops enumerating genotypes for this case. Thanks @kgururaj.; * [Fix](https://github.com/GenomicsDB/GenomicsDB/pull/66) for missing libcurl in the native GenomicsDB library - Issue #6122 ; * [Fix](https://github.com/GenomicsDB/GenomicsDB/pull/67) to avoid crashing when vcfbufferstream from htslib happens to be invalid. This check was put in response to the [Forum Issue 59667](https://gatkforums.broadinstitute.org/gatk/discussion/comment/59667#Comment_59667). Note that the test vcfs [sample2](https://github.com/broadinstitute/gatk/tree/master/src/test/resources/org/broadinstitute/hellbender/tools/mutect/createpon/sample2.vcf), [sample3](https://github.com/broadinstitute/gatk/tree/master/src/test/resources/org/broadinstitute/hellbender/tools/mutect/createpon/sample3.vcf) and [sample4](https://github.com/broadinstitute/gatk/tree/master/src/test/resources/org/broadinstitute/hellbender/tools/mutect/createpon/sample4.vcf) had to be changed to be htslib compliant for importing and to run `org.broadinstitute.hellbender.tools.walkers.mutect.CreateSomaticPanelOfNormalsIntegrationTest` successfully.; * Allow for native GenomicsDBExceptions to be propagated as java IOExceptions to allow gatk to gracefully handle the exception by printing out relevant information. See [GenomicsDB Fix 68](https://github.com/GenomicsDB/GenomicsDB/pull/68).; * [Fix](https://github.com/GenomicsDB/GenomicsDB/pull/70) for issues using vid protobuf interface to pass vid information and there is more than one config. Thanks @mlathara.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6188:1043,test,test,1043,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6188,3,['test'],['test']
Testability," check that; > each alt allele occurs in at least one sample and that the AC adds up.; > However, this can fail on sites-only files because there are no genotypes.; > We should use the definition of the info annotations in the header to check; > how many entries each should have.; > Outline; > - Add a new validation type for info-field counts to enum and to; > switch statement; > - Grab info headers from input VCF with something like; > GATKVCFUtils.getVCFHeadersFromRods(getToolkit(),; > variantCollection.variants.getName()) and VCFHeader::getInfoHeaderLines; > - In the map() function, for each info header line, call on each; > VCFInfoHeaderLine getCount(vc) to get the expected number of info; > annotation entries; > - Compare the expected number with a count based on; > vc.getAttribute(currentVCFinfoHeaderLine.getID()), which will require some; > additional parsing because it returns an Object; > - (Bonus points if you use the isFixedCount() and getCount() functions; > on the VCF info header line to simplify annotations that aren't according; > to the number of alt alleles); > ; > Test data; > ; > /humgen/gsa-hpprojects/dev/gauthier/scratch/supportingMultiA.vcf; > Should fail AC/AF validation at; > 1 768589 . A C,G 76 PASS AC=1;AF=0.00047;AN=2120; > See results using:; > ; > use VCFtools; > vcf-validator /humgen/gsa-hpprojects/dev/gauthier/scratch/supportingMultiA.vcf; > ; > which outputs:; > INFO field at 1:768589 .. INFO tag [AC=1] expected different number of; > values (expected 2, found 1),INFO tag [AF=0.00047] expected different; > number of values (expected 2, found 1); > Notes; > ; > Currently, all the validation modes call out to HTSJDK. Do we want to put; > the new functionality there as well?; > ; > —; > Reply to this email directly or view it on GitHub; > https://github.com/broadinstitute/gsa-unstable/issues/1053. ---. @ldgauthier commented on [Fri Jul 17 2015](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-122308040). Today I le",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2507:3276,Test,Test,3276,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2507,1,['Test'],['Test']
Testability," cloud...requests like this need to; go through pipeline-help...sorry. Y. On Fri, Oct 7, 2016 at 9:08 AM, ldgauthier notifications@github.com wrote:. > I don't know what intermediates we save on the cloud but maybe @yfarjoun; > https://github.com/yfarjoun is willing to help.; > ; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > https://github.com/broadinstitute/gsa-unstable/issues/1489#issuecomment-252247496,; > or mute the thread; > https://github.com/notifications/unsubscribe-auth/ACnk0lAsJd9NECpPP0JYVp2ziDhga0B9ks5qxkRUgaJpZM4KQT_3; > . ---. @vdauwera commented on [Wed Oct 26 2016](https://github.com/broadinstitute/gsa-unstable/issues/1489#issuecomment-256499771). Writing pipeline-help now and cc'ing everyone involved in this thread. Will try to get some kind of protocol set up for debugging things that happen in the cloud pipeline, because I expect this will happen again. But if it gets too complicated we could also mock up some fake records that would reproduce this. It seems to me that shouldn't be too hard. . ---. @vdauwera commented on [Mon Nov 14 2016](https://github.com/broadinstitute/gsa-unstable/issues/1489#issuecomment-260498705). I need to ping Daniel on getting access to the files. ---. @ronlevine commented on [Thu Jan 26 2017](https://github.com/broadinstitute/gsa-unstable/issues/1489#issuecomment-275576931). @vdauwera Can you get the data? I can take a look a this issue. ---. @vdauwera commented on [Thu Jan 26 2017](https://github.com/broadinstitute/gsa-unstable/issues/1489#issuecomment-275578721). Oh, they gave me access to the files but I never took the next step of figuring out which files are relevant. There are twenty thousand samples... I'm not sure what is the best way to approach this. ---. @ldgauthier commented on [Wed Mar 01 2017](https://github.com/broadinstitute/gsa-unstable/issues/1489#issuecomment-283365248). It would be too computationally expensive and just generally pain",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2959:2721,mock,mock,2721,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2959,1,['mock'],['mock']
Testability," code, though I don't know how much you cleaned up the GATK4 version. We would also want to make sure that we only implement this optimization if that SNP is the only SNP on the haplotype. In cases where the haplotype has multiple SNPs and the phasing is poor, this could artificially inflate the likelihoods. Although we've seen that the graph traversal frequently breaks phasing then generating haplotypes anyway, so maybe I overestimate our current likelihood accuracy. Anyway, take my advice with a grain of salt. It's just some musings from a bored and somewhat sleep-deprived mom with a sleeping baby on her lap. ---. @davidbenjamin commented on [Fri Mar 03 2017](https://github.com/broadinstitute/gatk-protected/issues/909#issuecomment-284024760). > I think the main blocker in implementing it would be the complexity of the existing code, though I don't know how much you cleaned up the GATK4 version. We refactored all the engine stuff shared with `HaplotypeCaller` to be very distinct from the somatic genotyping logic, so the only complexity would be in local assembly and PairHMM. Which could be significant, of course. > We would also want to make sure that we only implement this optimization if that SNP is the only SNP on the haplotype. . .Although we've seen that the graph traversal frequently breaks phasing. The specific case I had in mind is when you have a bubble or something more complex in the graph, followed by a stretch of reference (i.e. all haplotypes have nothing going on here), followed (or not) by more activity. It seems reasonable in that case to chop each active area into its own haplotype(s), which is equivalent to pinning the ref-only area to be ref-only in PairHMM. I believe but could be wrong that in a case like this our assembly would not respect phasing between the two active areas anyway, so we lose nothing. By the way, I should clarify that the idea is not to truncate the `ActiveRegion`, but rather to break it into a few small haplotypes semi-intel",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2945:1649,log,logic,1649,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2945,1,['log'],['logic']
Testability," dataset / table names. (#8162); - New WDL to create VAT tsvs from previously generated BigQuery table. (#8165); - Treat withdrawn samples in sub-cohort prepare correctly [VS-772] (#8156); - Remove unused VAT Creation WDL (#8172); - Gg consistently use dataset name as input parameter (#8173); - AoU cleanup docs, round 1 [VS-671] (#8104); - VDS docs remove samples and correct GT [VS-807] (#8178); - [VS-693] Add support for VQSR Lite to GvsCreateFilterSet (#8157); - VAT Documentation Update Round 1 [VS-531]; - VS-530 VDS creation documentation for AoU (#8169); - Update beta docs to tell people not to use free credits (#8184); - VS-816 Keeping ingestion under quota (#8193); - CromwellOnAzure + Azure SQL DB + AAD first steps doc [VS-805] (#8191); - Edit and re-format VDS -> VAT doc [VS-821] (#8187); - VS-820 Incorporate code to stay under Google quotas for new accounts into beta workflow (#8200); - Update docs for Nirvana reference disk [VS-531] [VS-796] (#8170); - VS-694 - Extract Callset for VQSR Lite (#8182); - Updating docker image (#8210); - Document VCF generation [VS-795] (#8202); - Variants GATK Docker image building docs + script [VS-827] (#8207); - Update GATK jar used in GvsJointVariantCalling WDL (#8216); - Hello Azure SQL Database from Cromwell on Azure [VS-812] (#8220); - Remove what appear to be accidentally added files [VS-834] (#8225); - VS-815: Add Support for YNG to VQSR Lite (#8206); - Disentangle non-GVS code from GVS code [VS-834] (#8229); - VS-695. Updates to run Precision and Sensitivity on VQSR Lite (#8230); - Track avro export costs [VS-769] (#8236); - Add note that we deleted a VDS! (#8214); - Vs 822 Add documentation for the work that we did on the latest iteration of Delta (#8205); - Rc vs 822 gq0 documentation (#8240); - Add a test exclusion for gvs scripts; - testing if the exclusion works. [VS-16]: https://broadworkbench.atlassian.net/browse/VS-16?atlOrigin=eyJpIjoiNWRkNTljNzYxNjVmNDY3MDlhMDU5Y2ZhYzA5YTRkZjUiLCJwIjoiZ2l0aHViLWNvbS1KU1cifQ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8251:33367,test,test,33367,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8251,2,['test'],"['test', 'testing']"
Testability," existing github issues to see if your issue (or something similar) has already been reported. If the issue already exists, you may comment there to inquire about the progress.; - Determine whether your issue is a **bug report**, a **feature request**, or a **documentation request** (for tool/class javadoc only -- for forum docs please post there); - Consider if your ""issue"" is better addressed on the GATK forum: http://gatkforums.broadinstitute.org/gatk Post there if you have questions about expected tool behavior, output format, unexpected results, or generally any question that does not fit into the categories above; - Use a **concise** yet **descriptive** title; - Choose the corresponding template block below and fill it in, replacing or deleting text in italics (surrounded by `_`) as appropriate; - Delete the other template blocks and this header. ----; Thanks in advance!; ## Bug Report. ### Affected tool(s) or class(es); _Tool/class name(s), special parameters?_. ### Affected version(s); - [ ] Latest public release version [version?]; - [ ] Latest master branch as of [date of test?]. ### Description ; _Describe the problem below. Provide **screenshots** , **stacktrace** , **logs** where appropriate._. #### Steps to reproduce; _Tell us how to reproduce this issue. If possible, include command lines that reproduce the problem. (The support team may follow up to ask you to upload data to reproduce the issue.)_. #### Expected behavior; _Tell us what should happen_. #### Actual behavior; _Tell us what happens instead_. ----. ## Feature request. ### Tool(s) or class(es) involved; _Tool/class name(s), special parameters?_. ### Description; _Specify whether you want a modification of an existing behavior or addition of a new capability._; _Provide **examples**, **screenshots**, where appropriate._. ----. ## Documentation request. ### Tool(s) or class(es) involved; _Tool/class name(s), parameters?_. ### Description ; _Describe what needs to be added or modified._. ----",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6875:10413,test,test,10413,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6875,2,"['log', 'test']","['logs', 'test']"
Testability," folder. The index is there, but I don't know why the tool can't recognize it. Please help, thanks!; kh3@rgcaahauva08091 ~/Resources/genome_b37 $> ls -l genome.*; -rw-rw---- 1 kh3 kh3 784809415 Sep 16 10:16 genome.2bit; -rw-rw---- 1 kh3 kh3 3168829906 Feb 4 2014 genome.fa; -rw-r----- 1 kh3 kh3 106669 Sep 16 11:32 genome.fa.amb; -rw-r----- 1 kh3 kh3 3276 Sep 16 11:32 genome.fa.ann; -rw-r----- 1 kh3 kh3 3137454592 Sep 16 11:31 genome.fa.bwt; -rw-rw---- 1 kh3 kh3 2984 Feb 4 2014 genome.fa.fai; -rw-rw---- 1 kh3 kh3 2984 Sep 16 13:18 genome.fai; -rw-r----- 1 kh3 kh3 784363628 Sep 16 11:32 genome.fa.pac; -rw-r----- 1 kh3 kh3 1568727304 Sep 16 11:44 genome.fa.sa. Using GATK wrapper script /home/kh3/Softwares/gatk/build/install/gatk/bin/gatk; Running:; /home/kh3/Softwares/gatk/build/install/gatk/bin/gatk BwaAndMarkDuplicatesPipelineSpark -I /home/kh3/data/Illumina/GATK4/Platinum/TEST/test.spark.bam -R /home/kh3/Resources/genome_b37/ge; nome.2bit --disableSequenceDictionaryValidation true -t 16 -O /home/kh3/data/Illumina/GATK4/Platinum/TEST/test.spark.aligned.bam; 15:47:28.760 INFO IntelGKLUtils - Trying to load Intel GKL library from:; jar:file:/home/kh3/Softwares/gatk/build/install/gatk/lib/gkl-0.1.2.jar!/com/intel/gkl/native/libIntelGKL.so; 15:47:28.809 INFO IntelGKLUtils - Intel GKL library loaded from classpath.; [September 16, 2016 3:47:28 PM EDT] org.broadinstitute.hellbender.tools.spark.pipelines.BwaAndMarkDuplicatesPipelineSpark --threads 16 --output /home/kh3/data/Illumina/GATK4/Platinum/TEST/test.spark; .aligned.bam --reference /home/kh3/Resources/genome_b37/genome.2bit --input /home/kh3/data/Illumina/GATK4/Platinum/TEST/test.spark.bam --disableSequenceDictionaryValidation true --fixedChunkSiz; e 100000 --duplicates_scoring_strategy SUM_OF_BASE_QUALITIES --readValidationStringency SILENT --interval_set_rule UNION --interval_padding 0 --interval_exclusion_padding 0 --bamPartitionSize 0 --shardedO; utput false --numReducers 0 --sparkMaster local[*] --help false --ve",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2171:1081,TEST,TEST,1081,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2171,2,"['TEST', 'test']","['TEST', 'test']"
Testability," from the; GENE features, rather than the TRANSCRIPT features that contain each; variant. As a result, the order in which representative transcripts; were chosen was wrong. The TRANSCRIPT feature is now being used to; determine the Locus/Curation Level. - `TranscriptType` now determined by transcript annotation, not gene annotation; - Start/stop codon overlapping now corrected for preceding indel bases (is now correct for more cases).; - Changed algorithm for how 5'UTRs are determined. - Refactored how frameshift indels have codon change strings created. - Added in helper some scripts for testing funcotator. - Fixed how codon change strings are rendered to be consistent and more; correct. - Fixed Protein Change strings to be consistent and more; correct. - Implemented tests for CreateProteinChangeInfo; - Implemented tests for RenderProteinChangeString; - Implemented tests for IsIndelBetweenCodons; - Implemented tests for GetCodonChangeString. - Added a unit test for; testCreateGencodeFuncotationBuilderWithTrivialFieldsPopulated. - Fixed a bug when variant ref allele doesn't match reference genome. - Fixed test cases for - strand indel cdna strings:; There is a bug in oncotator that was fixed in Funcotator involving cdna; strings for - strand indels. In Oncotator the positions reported are off by 1 (they; should be one less) and the base reported is also wrong.; This is now fixed. - Removed some old code that had been taken out of the main codepath. - Fixed a bug in how the gencode reference contexts are created.; - Fixed a bug in how the end points for the gencode annotations are; created. - Ref context field is now consistent for indels.; The reference context will give WINDOW bases before and after the; logical reference allele for a variant. This is NOT the allele in the; input VCF, but rather the allele that actually has changed. For; insertions, the logical allele is the SPACE BETWEEN TWO BASES (and; therefore the resulting string will always be 2xWINDOW bases ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5302:2752,test,test,2752,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5302,2,['test'],"['test', 'testCreateGencodeFuncotationBuilderWithTrivialFieldsPopulated']"
Testability," less than 40GB and they successfully finished import batch 1 and running for batch 2 or 3. Thus, the file size for chr5-12 are 59GB now. However, for chr1-4, they just crash in batch 1 for very long time without any error. I have check the memory usage and there is still >35GB free memory for the compute node of each chromosome. Please see the followings for detail:. File size for all chromosomes, the GenomicsDB for chr1-4 is smaller:; <pre>[hcaoad@login-0 GenomicsDB]> du -h --max-depth=1; 59G ./chr10; 59G ./chr6; 50G ./chr2; 59G ./chr12; 59G ./chr9; 59G ./chr5; 59G ./chr7; 48G ./chr1; 59G ./chr11; 59G ./chr8; 40G ./chr4; 41G ./chr3; 647G .; </pre>. Files in GenomicsDB of chr1 batch 1. As you can see, no update for the database since Apr 20 13:34, while current time is Apr 21.; <pre>[hcaoad@login-0 .__6f46d0f3-86b3-4e38-92be-9a912291df0c139544093255424_1618555702611]> pwd; /home/hcaoad/scratch/Han/WGS/HK_WGS_5X/GenomicsDB/chr1/1$1$249250621/.__6f46d0f3-86b3-4e38-92be-9a912291df0c139544093255424_1618555702611; [hcaoad@login-0 .__6f46d0f3-86b3-4e38-92be-9a912291df0c139544093255424_1618555702611]> date; Wed Apr 21 11:09:46 HKT 2021; [hcaoad@login-0 .__6f46d0f3-86b3-4e38-92be-9a912291df0c139544093255424_1618555702611]> ll -h; total 48G; -rwx------ 1 hcaoad boip 260M Apr 20 13:34 AD.tdb; -rwx------ 1 hcaoad boip 203M Apr 20 13:34 AD_var.tdb; -rwx------ 1 hcaoad boip 304M Apr 20 13:34 ALT.tdb; -rwx------ 1 hcaoad boip 146M Apr 20 13:34 ALT_var.tdb; -rwx------ 1 hcaoad boip 353M Apr 20 13:34 BaseQRankSum.tdb; -rwx------ 1 hcaoad boip 7.3G Apr 20 13:34 __coords.tdb; -rwx------ 1 hcaoad boip 132M Apr 20 13:34 DB.tdb; -rwx------ 1 hcaoad boip 3.4G Apr 20 13:34 DP_FORMAT.tdb; -rwx------ 1 hcaoad boip 295M Apr 20 13:34 DP.tdb; -rwx------ 1 hcaoad boip 8.1G Apr 20 13:34 END.tdb; -rwx------ 1 hcaoad boip 223M Apr 20 13:34 ExcessHet.tdb; -rwx------ 1 hcaoad boip 158M Apr 20 13:34 FILTER.tdb; -rwx------ 1 hcaoad boip 0 Apr 20 13:34 FILTER_var.tdb; -rwx------ 1 hcaoad boip 3.7G Apr",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7218:1724,log,login-,1724,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7218,1,['log'],['login-']
Testability," long reads only (90x human wgs, min. read length>10kbp).; However, if the large BAM file contains short reads, it executes normally. #### Steps to reproduce; _Tell us how to reproduce this issue. If possible, include command lines that reproduce the problem. (The support team may follow up to ask you to upload data to reproduce the issue.)_. ```shell; sysctl -w vm.max_map_count=2147483642; gatk SortSamSpark \; --input HG002-NA24385-GM24385.bam \; --output HG002-NA24385-GM24385.sorted.bam \; --sort-order coordinate \; --java-options ""-XX:+UnlockDiagnosticVMOptions -XX:GCLockerRetryAllocationCount=96 -XX:+UseNUMA -XX:+UseZGC -Xmx1794G"" \; --tmp-dir . \; -- \; --spark-runner LOCAL --spark-master local[96] --conf spark.local.dir=./tmp --conf spark.port.maxRetries=61495; ```. #### Expected behavior; _Tell us what should happen_. Output a sorted BAM file. #### Actual behavior; _Tell us what happens instead_. `java.lang.OutOfMemoryError: Required array length ? is too large`. The last lines of the log file.; ```; 11:00:42.884 INFO BlockManagerInfo - Removed taskresult_15758 on 172.20.19.130:43279 in memory (size: 10.5 MiB, free: 1076.2 GiB); 11:00:42.888 INFO TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool; 11:00:42.902 INFO DAGScheduler - ResultStage 0 (sortByKey at SparkUtils.java:165) finished in 1652.742 s; 11:00:42.915 INFO DAGScheduler - Job 0 is finished. Cancelling potential speculative or zombie tasks for this job; 11:00:42.916 INFO TaskSchedulerImpl - Killing all running tasks in stage 0: Stage finished; 11:00:42.927 INFO DAGScheduler - Job 0 finished: sortByKey at SparkUtils.java:165, took 1653.133440 s; 11:00:49.975 INFO MemoryStore - Block broadcast_3 stored as values in memory (estimated size 2044.7 KiB, free 1076.2 GiB); 11:00:49.999 INFO MemoryStore - Block broadcast_3_piece0 stored as bytes in memory (estimated size 56.6 KiB, free 1076.2 GiB); 11:00:49.999 INFO BlockManagerInfo - Added broadcast_3_piece0 in memory on 172",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8949:1473,log,log,1473,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8949,1,['log'],['log']
Testability," more log output.; > Run with --scan to get full insights. * Get more help at https://help.gradle.org. BUILD FAILED in 17s; ```; However, I already install git-lfs; ```; git-lfs usr/; git-lfs usr/bin/; git-lfs usr/bin/git-lfs; git-lfs usr/share/; git-lfs usr/share/licenses/; git-lfs usr/share/licenses/git-lfs/; git-lfs usr/share/licenses/git-lfs/LICENSE; git-lfs usr/share/man/; git-lfs usr/share/man/man1/; git-lfs usr/share/man/man1/git-lfs-checkout.1.gz; git-lfs usr/share/man/man1/git-lfs-clean.1.gz; git-lfs usr/share/man/man1/git-lfs-clone.1.gz; git-lfs usr/share/man/man1/git-lfs-dedup.1.gz; git-lfs usr/share/man/man1/git-lfs-env.1.gz; git-lfs usr/share/man/man1/git-lfs-ext.1.gz; git-lfs usr/share/man/man1/git-lfs-fetch.1.gz; git-lfs usr/share/man/man1/git-lfs-filter-process.1.gz; git-lfs usr/share/man/man1/git-lfs-fsck.1.gz; git-lfs usr/share/man/man1/git-lfs-install.1.gz; git-lfs usr/share/man/man1/git-lfs-lock.1.gz; git-lfs usr/share/man/man1/git-lfs-locks.1.gz; git-lfs usr/share/man/man1/git-lfs-logs.1.gz; git-lfs usr/share/man/man1/git-lfs-ls-files.1.gz; git-lfs usr/share/man/man1/git-lfs-merge-driver.1.gz; git-lfs usr/share/man/man1/git-lfs-migrate.1.gz; git-lfs usr/share/man/man1/git-lfs-pointer.1.gz; git-lfs usr/share/man/man1/git-lfs-post-checkout.1.gz; git-lfs usr/share/man/man1/git-lfs-post-commit.1.gz; git-lfs usr/share/man/man1/git-lfs-post-merge.1.gz; git-lfs usr/share/man/man1/git-lfs-pre-push.1.gz; git-lfs usr/share/man/man1/git-lfs-prune.1.gz; git-lfs usr/share/man/man1/git-lfs-pull.1.gz; git-lfs usr/share/man/man1/git-lfs-push.1.gz; git-lfs usr/share/man/man1/git-lfs-smudge.1.gz; git-lfs usr/share/man/man1/git-lfs-standalone-file.1.gz; git-lfs usr/share/man/man1/git-lfs-status.1.gz; git-lfs usr/share/man/man1/git-lfs-track.1.gz; git-lfs usr/share/man/man1/git-lfs-uninstall.1.gz; git-lfs usr/share/man/man1/git-lfs-unlock.1.gz; git-lfs usr/share/man/man1/git-lfs-untrack.1.gz; git-lfs usr/share/man/man1/git-lfs-update.1.gz; git-lfs usr/share/man/man",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8320:2382,log,logs,2382,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8320,1,['log'],['logs']
Testability, name java.net.UnknownHostException: de2c81c88ddc: de2c81c88ddc: Temporary failure in name resolution; at java.net.InetAddress.getLocalHost(InetAddress.java:1506); at org.apache.logging.log4j.core.util.NetUtils.getLocalHostname(NetUtils.java:54); at org.apache.logging.log4j.core.LoggerContext.lambda$setConfiguration$0(LoggerContext.java:620); at java.util.concurrent.ConcurrentHashMap.computeIfAbsent(ConcurrentHashMap.java:1660); at org.apache.logging.log4j.core.LoggerContext.setConfiguration(LoggerContext.java:620); at org.apache.logging.log4j.core.LoggerContext.reconfigure(LoggerContext.java:699); at org.apache.logging.log4j.core.LoggerContext.reconfigure(LoggerContext.java:716); at org.apache.logging.log4j.core.LoggerContext.start(LoggerContext.java:270); at org.apache.logging.log4j.core.impl.Log4jContextFactory.getContext(Log4jContextFactory.java:155); at org.apache.logging.log4j.core.impl.Log4jContextFactory.getContext(Log4jContextFactory.java:47); at org.apache.logging.log4j.LogManager.getContext(LogManager.java:196); at org.apache.logging.log4j.LogManager.getLogger(LogManager.java:599); at org.broadinstitute.hellbender.utils.Utils.<clinit>(Utils.java:72); at org.broadinstitute.hellbender.Main.<clinit>(Main.java:45); Caused by: java.net.UnknownHostException: de2c81c88ddc: Temporary failure in name resolution; at java.net.Inet4AddressImpl.lookupAllHostAddr(Native Method); at java.net.InetAddress$2.lookupAllHostAddr(InetAddress.java:929); at java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1324); at java.net.InetAddress.getLocalHost(InetAddress.java:1501); ...13 more. The Genome Analysis Toolkit (GATK) v4.2.6.1; HTSJDK Version: 2.24.1; Picard Version: 2.27.1; Using GATK jar /gatk/gatk-package-4.2.6.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /gatk/gatk-package-4.2.6.1-local.jar -version; ```. This request ,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7983:1302,Log,LogManager,1302,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7983,1,['Log'],['LogManager']
Testability," occur.; 15:41:51.201 INFO DataSourceUtils - Resolved data source file path: file:///home/shiyang/softwares/gatk-4.1.8.1/gencode.v34lift37.pc_transcripts.fa -> file:///home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s/gencode/hg19/gencode.v34lift37.pc_transcripts.fa; 15:41:54.713 INFO DataSourceUtils - Resolved data source file path: file:///home/shiyang/softwares/gatk-4.1.8.1/simple_uniprot_Dec012014.tsv -> file:///home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s/simple_uniprot/hg19/simple_uniprot_Dec012014.tsv; 15:41:54.747 INFO DataSourceUtils - Resolved data source file path: file:///home/shiyang/softwares/gatk-4.1.8.1/gencode_xrefseq_v75_37.tsv -> file:///home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s/gencode_xrefseq/hg19/gencode_xrefseq_v75_37.tsv; 15:41:54.798 INFO Funcotator - Initializing Funcotator Engine...; 15:41:54.811 INFO Funcotator - Creating a MAF file for output: file:/home/shiyang/Project/BGB900_101/TSO_result/test.maf; 15:41:54.826 INFO ProgressMeter - Starting traversal; 15:41:54.827 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 15:41:54.853 INFO VcfFuncotationFactory - ClinVar_VCF 20180401 cache hits/total: 0/0; 15:41:54.854 INFO VcfFuncotationFactory - dbSNP 9606_b151 cache hits/total: 0/0; 15:41:54.860 INFO Funcotator - Shutting down engine; [August 19, 2020 3:41:54 PM CST] org.broadinstitute.hellbender.tools.funcotator.Funcotator done. Elapsed time: 0.10 minutes.; Runtime.totalMemory()=2588409856; htsjdk.tribble.TribbleException$MalformedFeatureFile: Error parsing LineIteratorImpl(SynchronousLineReader) at the first queried after chr1:2489658, for input source: file:///home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s/gencode/hg19/gencode.v34lift37.annotation.REORDERED.gtf; at htsjdk.tribble.TribbleIndexedFeatureReader$QueryIterator.readNextRecord(TribbleIndexedFe",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6758:19944,test,test,19944,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6758,1,['test'],['test']
Testability," on FSx for luster mount on ec2:; ; [root@ip-10-76-63-158 genomicsdb]# dd if=/dev/zero of=/gfb-dev-sv-fsx-results-us-east-2/cromwell-execution/GATKSVPipelineBatch/087bd722-5f51-43eb-a89e-70846a1da89f/call-GATKSVPipelinePhase1/GATKSVPipelinePhase1/38595c13-b874-4753-a554-81c09f6449f8/call-GatherBatchEvidence/GatherBatchEvidence/c8120761-6d9f-4bd3-b450-f528b7be817c/call-BAFFromGVCFs/BAFFromGVCFs/d5032666-9c09-4857-a8d7-41042927cf89/call-ImportGVCFs/shard-389/genomicsdb/test.img bs=1G count=5 oflag=dsync; 5+0 records in; 5+0 records out; 5368709120 bytes (5.4 GB) copied, 23.5143 s, 228 MB/s; [root@ip-10-76-63-158 genomicsdb]#. We also ran the jobs with strace enabled and we found that there are millions of FUTEX_WAIT_PRIVATE processes while we run the jobs for fsx writing as compared to just 26 when we write to EBS. # Local EBS writing strace log (Ran around 3.5 hrs); [root@ip-10-76-62-193 importvcf-job]# egrep ""FUTEX_WAIT_PRIVATE, 0, NULL"" ./local-write-logs/strace_local_writing.log | wc -l; 26. # FSx strace logs; # --reader-threads 5 (Ran around 7 hours); [root@ip-10-76-62-193 importvcf-job]# egrep ""FUTEX_WAIT_PRIVATE, 0, NULL"" ./fsx-write-logs/strace_fsx_writing.log | wc -l; 24378265. # --reader-threads 1; [root@ip-10-76-62-193 importvcf-job]# egrep ""FUTEX_WAIT_PRIVATE, 0, NULL"" ./strace_thread_1_fsx.txt | wc -l; 8745113. #--reader-threads 2; [root@ip-10-76-62-193 importvcf-job]# egrep ""FUTEX_WAIT_PRIVATE, 0, NULL"" ./strace_thread_2_fsx.txt | wc -l; 13946622. #--reader-threads 10; [root@ip-10-76-62-193 importvcf-job]# egrep ""FUTEX_WAIT_PRIVATE, 0, NULL"" ./strace_thread_10_fsx.txt | wc -l; 13535883; [root@ip-10-76-62-193 importvcf-job]#. The last 3 i.e. tests for thread 1, 2 and 10 were only executed for 20 mins and in those 20 minutes it only loaded around 220 MBs to the genomicsdb. Note that the above executions were done on different EC2 instances with 4 CPU and 30 GB memory (each running 1 job only at a given time). FSx executions were done one after the other. P",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7646:3632,log,log,3632,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7646,1,['log'],['log']
Testability," opened a bugreport to add a feature to ValidateVariants: https://github.com/broadinstitute/gatk/issues/6553. However, it would be nice if you could actually investigate the formatting error. Unfortunately my formatting error isn't the same as reported in the other post. I have 105 error in which the 1st alternative allele is a spanning deletion and the 2nd (and 3rd) is either an indel or snp. It's true that the 2nd and 3rd allele is actually not found in my samples. I even have 7 occurances in which the 1st allele (spanning deletion) has allele frequency 1.00. my code is the following for GenotypeGVCFs:. java -Xms32G -Xmx32G -jar ${gatk4} GenotypeGVCFs -R ${ref} -V ${pipeline}/${name}\_v4.1.6.0.g.vcf.gz -O ${vcf}/${name}\_v4.1.6.0.vcf.gz -L ${pipeline}/${name}\_intervals.list 2> ${log}/${name}\_v4.1.6.0\_genotype.log. for ValidateVariants:. java -Xms10G -Xmx10G -jar ${gatk4} ValidateVariants -R ${ref} -V ${name}\_v4.1.6.0.vcf.gz -L ${pipeline}/${name}\_intervals.list --warn-on-errors 2> ${log}/${name}\_v4.1.6.0\_genotype\_valivar.log. the warning in ValidateVariants and the site look like this:. 14:12:15.126 WARN ValidateVariants - \*\*\*\*\* Input 1st\_v4.1.6.0.vcf.gz fails strict validation of type ALL: one or more of the ALT allele(s) for the record at position chr\_1:1088200 are not observed at all in the sample genotypes \*\*\*\*\* ; ; chr\_1 1088200 . T \*,TAAAAAAAAAAAA 64.39 . AC=8,0;AF=0.667,0.00;AN=12;DP=118;ExcessHet=3.0103;FS=0.000;InbreedingCoeff=0.4286;MLEAC=7,7;MLEAF=0.583,0.583;MQ=58.73;QD=32.19;SOR=2.303 GT:AD:DP:GQ:PL ./.:9,0,0:9:.:0,0,0,0,0,0 0/0:9,0,0:9:0:0,0,113,0,113,113 ./.:10,0,0:10:.:0,0,0,0,0,0 ./.:5,0,0:5:.:0,0,0,0,0,0 1/1:0,0,1:1:0:225,15,0,15,0,0 ./.:0,0,0:0:.:0,0,0,0,0,0 ./.:12,0,0:12:.:0,0,0,0,0,0 ./.:8,0,0:8:.:0,0,0,0,0,0 0/0:3,0,0:3:0:0,0,43,0,43,43 ./.:7,0,0:7:.:0,0,0,0,0,0 ./.:1,0,0:1:.:0,0,0,0,0,0 ./.:0,0,0:0:.:0,0,0,0,0,0 ./.:3,0,0:3:.:0,0,0,0,0,0 ./.:7,0,0:7:.:0,0,0,0,0,0 1/1:0,0,0:0:0:45,3,0,3,0,0 ./.:0,0,0 1/1:0,0,1:1:0:45,3,0",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6630:1778,log,log,1778,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6630,1,['log'],['log']
Testability, org.broadinstitute.hellbender.tools.walkers.vqsr.CNNVariantPipelineTest.testTrainingReadModel(CNNVariantPipelineTest.java:85); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:133); 	at org.testng.internal.TestInvoker.invokeMethod(TestInvoker.java:584); 	at org.testng.internal.TestInvoker.invokeTestMethod(TestInvoker.java:172); 	at org.testng.internal.MethodRunner.runInSequence(MethodRunner.java:46); 	at org.testng.internal.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:804); 	at org.testng.internal.TestInvoker.invokeTestMethods(TestInvoker.java:145); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:128); 	at java.util.ArrayList.forEach(ArrayList.java:1257); 	at org.testng.TestRunner.privateRun(TestRunner.java:770); 	at org.testng.TestRunner.run(TestRunner.java:591); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:402); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:396); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:355); 	at org.testng.SuiteRunner.run(SuiteRunner.java:304); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:53); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:96); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1180); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1102); 	at org.testng.TestNG.runSuites(TestNG.java:1032); 	at org.testng.TestNG.run(TestNG.java:1000); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:141); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClass,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6307:3516,test,testng,3516,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6307,1,['test'],['testng']
Testability, org.broadinstitute.hellbender.utils.runtime.AsynchronousStreamWriterServiceUnitTest.testAsyncWriteInBatches(AsynchronousStreamWriterServiceUnitTest.java:35); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:108); 	at org.testng.internal.Invoker.invokeMethod(Invoker.java:661); 	at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:869); 	at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1193); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:126); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:109); 	at org.testng.TestRunner.privateRun(TestRunner.java:744); 	at org.testng.TestRunner.run(TestRunner.java:602); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:380); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:375); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:340); 	at org.testng.SuiteRunner.run(SuiteRunner.java:289); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1301); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1226); 	at org.testng.TestNG.runSuites(TestNG.java:1144); 	at org.testng.TestNG.run(TestNG.java:1115); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:129); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:88); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Nati,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4024:1474,Test,TestRunner,1474,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4024,1,['Test'],['TestRunner']
Testability, org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.StartBuildOrRespondWithBusy$1.run(StartBuildOrRespondWithBusy.java:50); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.DaemonStateCoordinator$1.run(DaemonStateCoordinator.java:297); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:63); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.concurrent.StoppableExecutorImpl$1.run(StoppableExecutorImpl.java:46); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] Caused by: org.gradle.process.internal.ExecException: Process 'Gradle Test Executor 1' finished with non-zero exit value 134; 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.process.internal.DefaultExecHandle$ExecResultImpl.assertNormalExitValue(DefaultExecHandle.java:369); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.process.internal.worker.DefaultWorkerProcess.waitForStop(DefaultWorkerProcess.java:190); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.process.internal.worker.DefaultWorkerProcessBuilder$MemoryRequestingWorkerProcess.waitForStop(DefaultWorkerProcessBuilder.java:228); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.testing.worker.ForkingTestClassProcessor.stop(ForkingTestClassProcessor.java:122); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.testing.processors.RestartEveryNTestClassProcessor.e,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2802:13580,Test,Test,13580,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2802,1,['Test'],['Test']
Testability, org.testng.Assert.assertEquals(Assert.java:372); 	at org.broadinstitute.hellbender.utils.test.IntegrationTestSpec.assertEqualTextFiles(IntegrationTestSpec.java:211); 	at org.broadinstitute.hellbender.utils.test.IntegrationTestSpec.assertEqualTextFiles(IntegrationTestSpec.java:190); 	at org.broadinstitute.hellbender.tools.examples.ExampleAssemblyRegionWalkerSparkIntegrationTest.testExampleAssemblyRegionWalker(ExampleAssemblyRegionWalkerSparkIntegrationTest.java:29); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); 	at org.testng.internal.Invoker.invokeMethod(Invoker.java:639); 	at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:821); 	at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1131); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); 	at org.testng.TestRunner.privateRun(TestRunner.java:773); 	at org.testng.TestRunner.run(TestRunner.java:623); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:357); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:352); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:310); 	at org.testng.SuiteRunner.run(SuiteRunner.java:259); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1185); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1110); 	at org.testng.TestNG.run(TestNG.java:1018); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:129); 	at org.grad,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2349:4362,test,testng,4362,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2349,1,['test'],['testng']
Testability, org.testng.internal.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:804); 	at org.testng.internal.TestInvoker.invokeTestMethods(TestInvoker.java:145); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:128); 	at java.util.ArrayList.forEach(ArrayList.java:1257); 	at org.testng.TestRunner.privateRun(TestRunner.java:770); 	at org.testng.TestRunner.run(TestRunner.java:591); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:402); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:396); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:355); 	at org.testng.SuiteRunner.run(SuiteRunner.java:304); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:53); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:96); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1180); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1102); 	at org.testng.TestNG.runSuites(TestNG.java:1032); 	at org.testng.TestNG.run(TestNG.java:1000); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:141); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:90); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:33); 	at or,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6748:3507,Test,TestNG,3507,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6748,2,['Test'],['TestNG']
Testability, org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); at org.testng.TestRunner.privateRun(TestRunner.java:773); at org.testng.TestRunner.run(TestRunner.java:623); at org.testng.SuiteRunner.runTest(SuiteRunner.java:357); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:352); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:310); at org.testng.SuiteRunner.run(SuiteRunner.java:259); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1185); at org.testng.TestNG.runSuitesLocally(TestNG.java:1110); at org.testng.TestNG.run(TestNG.java:1018); at org.testng.remote.RemoteTestNG.run(RemoteTestNG.java:111); at org.testng.remote.RemoteTestNG.initAndRun(RemoteTestNG.java:204); at org.testng.remote.RemoteTestNG.main(RemoteTestNG.java:175); at org.testng.RemoteTestNGStarter.main(RemoteTestNGStarter.java:125); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:483); at com.intellij.rt.execution.application.AppMain.main(AppMain.java:140); Caused by: java.lang.RuntimeException: java.lang.NoSuchMethodError: com.google.common.base.Stopwatch.createStarted()Lcom/google/common/base/Stopwatch;; at com.google.cloud.dataflow.sdk.Pipeline.run(Pipeline.java:166); at org.broadinstitute.hellbender.engine.dataflow.DataflowCommandLineProgram.runPipeline(DataflowCommandLineProgram.java:145); at org.broadinstitute.hellbender.engine.dataflow.DataflowCommandLineProgram.doWork(DataflowCommandLineProgram.java:107); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:98); at org.broadinsti,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/866:2421,test,testng,2421,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/866,1,['test'],['testng']
Testability, org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:128); 	at java.base/java.util.ArrayList.forEach(ArrayList.java:1540); 	at org.testng.TestRunner.privateRun(TestRunner.java:770); 	at org.testng.TestRunner.run(TestRunner.java:591); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:402); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:396); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:355); 	at org.testng.SuiteRunner.run(SuiteRunner.java:304); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:53); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:96); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1180); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1102); 	at org.testng.TestNG.runSuites(TestNG.java:1032); 	at org.testng.TestNG.run(TestNG.java:1000); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:141); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:90); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.base/java.lang.reflect.Method.invoke(Method.java:566); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:33); 	at org.gradle.internal.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:94); 	at com.sun.proxy.$Proxy5.stop(Unknown Source); 	at org.grad,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6745:3332,test,testng,3332,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6745,2,['test'],['testng']
Testability," pid=849, tid=0x00007ff82e11d700; #; # JRE version: OpenJDK Runtime Environment (8.0_242-b08) (build 1.8.0_242-8u242-b08-0ubuntu3~18.04-b08); # Java VM: OpenJDK 64-Bit Server VM (25.242-b08 mixed mode linux-amd64 compressed oops); # Problematic frame:; # C [libgkl_smithwaterman5951765478004985534.so+0x132d] smithWatermanBackTrack(dnaSeqPair*, int, int, int, int, int*, int)+0x1bd; #; # Failed to write core dump. Core dumps have been disabled. To enable core dumping, try ""ulimit -c unlimited"" before starting Java again; #; # An error report file with more information is saved as:; # /home/gatk/hs_err_pid849.log; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; # The crash happened outside the Java Virtual Machine in native code.; # See problematic frame for where to report the bug.; #; ```. **RELEVANT FILES**; [hs_err_pid100.log](https://github.com/broadinstitute/gatk/files/6203288/hs_err_pid100.log); [hs_err_pid164.log](https://github.com/broadinstitute/gatk/files/6203289/hs_err_pid164.log); [hs_err_pid274.log](https://github.com/broadinstitute/gatk/files/6203290/hs_err_pid274.log); [hs_err_pid400.log](https://github.com/broadinstitute/gatk/files/6203291/hs_err_pid400.log); [hs_err_pid482.log](https://github.com/broadinstitute/gatk/files/6203292/hs_err_pid482.log); [hs_err_pid711.log](https://github.com/broadinstitute/gatk/files/6203293/hs_err_pid711.log); [hs_err_pid735.log](https://github.com/broadinstitute/gatk/files/6203294/hs_err_pid735.log); [hs_err_pid801.log](https://github.com/broadinstitute/gatk/files/6203295/hs_err_pid801.log); [hs_err_pid825.log](https://github.com/broadinstitute/gatk/files/6203296/hs_err_pid825.log); [hs_err_pid849.log](https://github.com/broadinstitute/gatk/files/6203297/hs_err_pid849.log); [otherFiles.zip](https://github.com/broadinstitute/gatk/files/6203305/otherFiles.zip); [in2510-8.orientationFilter.vcf.txt](https://github.com/broadinstitute/gatk/files/6203356/in2510-8.or",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7162:6575,log,log,6575,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7162,1,['log'],['log']
Testability," read). You can find the failure below, but I also dug out the location of the failure with a proposed fix. ./gatk/src/main/java/org/broadinstitute/hellbender/utils/recalibration/covariates/ContextCovariate.java line 191 -->. ```; while (bases[currentNPenalty] != 'N') {; final int baseIndex = BaseUtils.simpleBaseToBaseIndex(bases[currentNPenalty]);; currentKey |= (baseIndex << offset);; offset -= 2;; currentNPenalty--;; }; ```. The current while loop allows the array index to become negative and walk right off the edge of the read. So a proposed fix is as follows (assuming it does not break the covariate logic) -->. ```; while (currentNPenalty > 0 && bases[currentNPenalty] != 'N') {; final int baseIndex = BaseUtils.simpleBaseToBaseIndex(bases[currentNPenalty]);; currentKey |= (baseIndex << offset);; offset -= 2;; currentNPenalty--;; }; ```. Minimal Command (test.bam attached - added txt extension just so site would let me attach it) -->. ```; gatk-launch BaseRecalibrator -I test.bam -O test.table -R GATK_Bundle_Build38/Homo_sapiens_assembly38.fasta --knownSites GATK_Bundle_Build38/dbsnp_146.hg38.vcf.gz; ```. Error message --> . ```; java.lang.ArrayIndexOutOfBoundsException: -1; 	at org.broadinstitute.hellbender.utils.recalibration.covariates.ContextCovariate.contextWith(ContextCovariate.java:191); 	at org.broadinstitute.hellbender.utils.recalibration.covariates.ContextCovariate.recordValues(ContextCovariate.java:68); 	at org.broadinstitute.hellbender.utils.recalibration.covariates.StandardCovariateList.recordAllValuesInStorage(StandardCovariateList.java:133); 	at org.broadinstitute.hellbender.utils.recalibration.RecalUtils.computeCovariates(RecalUtils.java:546); 	at org.broadinstitute.hellbender.utils.recalibration.RecalUtils.computeCovariates(RecalUtils.java:527); 	at org.broadinstitute.hellbender.utils.recalibration.BaseRecalibrationEngine.processRead(BaseRecalibrationEngine.java:136); 	at org.broadinstitute.hellbender.tools.walkers.bqsr.BaseRecalibrator.apply(Bas",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4005:1548,test,test,1548,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4005,1,['test'],['test']
Testability," report file with more information is saved as:; # /home/gatk/hs_err_pid849.log; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; # The crash happened outside the Java Virtual Machine in native code.; # See problematic frame for where to report the bug.; #; ```. **RELEVANT FILES**; [hs_err_pid100.log](https://github.com/broadinstitute/gatk/files/6203288/hs_err_pid100.log); [hs_err_pid164.log](https://github.com/broadinstitute/gatk/files/6203289/hs_err_pid164.log); [hs_err_pid274.log](https://github.com/broadinstitute/gatk/files/6203290/hs_err_pid274.log); [hs_err_pid400.log](https://github.com/broadinstitute/gatk/files/6203291/hs_err_pid400.log); [hs_err_pid482.log](https://github.com/broadinstitute/gatk/files/6203292/hs_err_pid482.log); [hs_err_pid711.log](https://github.com/broadinstitute/gatk/files/6203293/hs_err_pid711.log); [hs_err_pid735.log](https://github.com/broadinstitute/gatk/files/6203294/hs_err_pid735.log); [hs_err_pid801.log](https://github.com/broadinstitute/gatk/files/6203295/hs_err_pid801.log); [hs_err_pid825.log](https://github.com/broadinstitute/gatk/files/6203296/hs_err_pid825.log); [hs_err_pid849.log](https://github.com/broadinstitute/gatk/files/6203297/hs_err_pid849.log); [otherFiles.zip](https://github.com/broadinstitute/gatk/files/6203305/otherFiles.zip); [in2510-8.orientationFilter.vcf.txt](https://github.com/broadinstitute/gatk/files/6203356/in2510-8.orientationFilter.vcf.txt); *VCF extension appended with .txt to satisfy GitHub's upload requirements*. #### Expected behavior; Worked on 7 other files generated with the same pipeline. . #### Actual behavior; Unsure why this last one is causing a segfault. The VCF included is not the whole VCF submitted originally. I went cutting out lines from the original until I could isolate it down to a minimal set required to reproduce the crash (I included all of the crash logs generated in case it can help). I was expecting to find a single l",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7162:7112,log,log,7112,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7162,1,['log'],['log']
Testability," same result. Java version is ``` OpenJDK Runtime Environment (build 1.8.0_252-b09) ```; ```; /gatk-4.0.11.0/gatk --java-options ""-Xmx4G"" HaplotypeCaller \; -R GRCh38.p2.fa \; -I RT4_STD.bam \; -ERC GVCF \; -L chr16 \; -O RT4_STD.g.vcf \; -new-qual; ```; - Error message is also different; - First one is :; ```; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x00002aaad9f1e54a, pid=7818, tid=0x00002aaaabdce700; #; # JRE version: Java(TM) SE Runtime Environment (8.0_111-b14) (build 1.8.0_111-b14); # Java VM: Java HotSpot(TM) 64-Bit Server VM (25.111-b14 mixed mode linux-amd64 compressed oops); # Problematic frame:; # C [libgkl_pairhmm_omp1890484777463615571.so+0x6954a] double compute_full_prob_avxd<double>(testcase*)+0x34a; #; # Core dump written. Default location: core or core.7818; #; # An error report file with more information is saved as:; # hs_err_pid7818.log; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; # The crash happened outside the Java Virtual Machine in native code.; # See problematic frame for where to report the bug.; ```. -Second one is ; ```; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x00000035dfe84364, pid=160107, tid=0x00002aaaabdce700; #; # JRE version: Java(TM) SE Runtime Environment (8.0_111-b14) (build 1.8.0_111-b14); # Java VM: Java HotSpot(TM) 64-Bit Server VM (25.111-b14 mixed mode linux-amd64 ); # Problematic frame:; # C [libc.so.6+0x84364]; #; # Core dump written. Default location: core or core.160107; #; # An error report file with more information is saved as:; # hs_err_pid160107.log; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; # The crash happened outside the Java Virtual Machine in native code.; # See problematic frame for where to report the bug. ```. Could this be a bug of problem with my data?. Thanks, ; Wen",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7515:1937,log,log,1937,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7515,1,['log'],['log']
Testability," size (119 KB). The maximum recommended task size is 100 KB.; > Test: Test method testAllTargetsHDF5PoNCreationSpark[0](null, src/test/resources/org/broadinstitute/hellbender/tools/exome/create-pon-control-full.pcov)(org.broadinstitute.hellbender.tools.exome.CreatePanelOfNormalsIntegrationTest) produced standard out/err: 18:03:07.612 WARN TaskSetManager:70 - Stage 182 contains a task of very large size (119 KB). The maximum recommended task size is 100 KB.; > ; > ```; > 18:03:07.612 WARN TaskSetManager:70 - Stage 182 contains a task of very large size (119 KB). The maximum recommended task size is 100 KB.; > ```; > ; > #; > ; > # A fatal error has been detected by the Java Runtime Environment:; > ; > #; > ; > # SIGSEGV (0xb) at pc=0x000000010a5a9401, pid=2425, tid=8963; > ; > #; > ; > # JRE version: Java(TM) SE Runtime Environment (8.0_91-b14) (build 1.8.0_91-b14); > ; > # Java VM: Java HotSpot(TM) 64-Bit Server VM (25.91-b14 mixed mode bsd-amd64 compressed oops); > ; > # Problematic frame:; > ; > # V [libjvm.dylib+0x1a9401]; > ; > #; > ; > # Failed to write core dump. Core dumps have been disabled. To enable core dumping, try ""ulimit -c unlimited"" before starting Java again; > ; > #; > ; > # An error report file with more information is saved as:; > ; > # /Users/louisb/Workspace/gatk-protected/hs_err_pid2425.log; > ; > #; > ; > # If you would like to submit a bug report, please visit:; > ; > # http://bugreport.java.com/bugreport/crash.jsp; > ; > #; > ; > hs_err_pid2425.log.txt; > https://github.com/broadinstitute/gatk-protected/files/448383/hs_err_pid2425.log.txt; > ; > @yfarjoun https://github.com/yfarjoun Is this similar to the crash you; > saw a while back?; > ; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > https://github.com/broadinstitute/gatk-protected/issues/659, or mute; > the thread; > https://github.com/notifications/unsubscribe-auth/ACnk0h0xGA8ntZ_9wd53IUeIqTIfWye0ks5qlf_YgaJpZM4JyIZS; > .",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2883:3592,log,log,3592,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2883,3,['log'],['log']
Testability," spanned allele (`*`), and a genotype that references the spanned allele, but fail to emit the upstream spanning variant. This seems like a bug to me - either the spanning variant should be emitted _or_ the spanned allele should revert to a reference call. FWIW I have a sneaking suspicion that this is related to setting a non-zero value for `-stand-call-conf` (see #5793). My guess is that in one part of the code it determines the upstream variant _will_ be emitted so retains the allele as spanned, but then somewhere later the upstream variant is filtered out. ### Affected tool(s) or class(es); GenotypeGVCFs. ### Affected version(s); - [x] Latest public release version [4.1.2.0]; - [ ] Latest master branch as of [not tested]. ### Description ; Here's the example from the VCF in the attached zip file:. ```; #CHROM POS ID REF ALT QUAL FILTER INFO FORMAT test_sample; chr17 46806234 . TC T 148.64 . ... GT:AD:DP:F1R2:F2R1:GQ:PL 0/1:208,25:239:116,16:90,8:99:156,0,6824; chr17 46806237 . TTCTCTCTCTCTC TTCTC,* 1528.04 . ... GT:AD:DP:F1R2:F2R1:GQ:PL 1/2:3,60,33:174:1,29,20:1,21,11:99:3633,1088,2142,1538,0,3285; ```. You can see from this that a) the first variant does not have a spanned allele, implying that there cannot be a spanning event further upstream and b) the second variant has a spanned allele that is present in the `1/2` genotype. #### Steps to reproduce. The attached zip file contains a reduced test case with a 3-record gVCF and a 2-record VCF that exhibits the problem. To reproduce:. 1. Unzip the attached zip file; 2. Edit `command.sh` to put in the path to HG19; 3. Run `. command.sh` in the directory with the extracted files. #### Expected behavior; Either the spanning variant should be emitted, or the spanned allele should not be. #### Actual behavior; A spanned allele is emitted when there is no spanning variant!. ZIP file with test case: [spanned_allele_not_spanned.zip](https://github.com/broadinstitute/gatk/files/3374898/spanned_allele_not_spanned.zip). ----",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6031:1518,test,test,1518,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6031,2,['test'],['test']
Testability, src/test/resources/large/Homo_sapiens_assembly38.20.21.dict; src/test/resources/large/Homo_sapiens_assembly38.20.21.fasta.fai; src/test/resources/large/human_g1k_v37.20.21.fasta.amb; src/test/resources/large/human_g1k_v37.20.21.fasta.ann; src/test/resources/large/human_g1k_v37.20.21.fasta.bwt; src/test/resources/large/human_g1k_v37.20.21.fasta.pac; src/test/resources/large/human_g1k_v37.20.21.fasta.sa; src/test/resources/large/K-562.duplicateMarked.chr20.bai; src/test/resources/large/mutect/dream_synthetic_bams/normal_3.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/normal_4.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/normal.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/tumor_3.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/tumor_4.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/tumor.bam.bai; src/test/resources/large/NA12878.RNAseq.bai; src/test/resources/large/SVIntegrationTest.bam.bai; src/test/resources/large/very-small-gnomad.vcf.idx; src/test/resources/large/VQSR/ALL.wgs.indels_mills_devine_hg19_leftAligned_collapsed_double_hit.sites.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/combined.phase1.chr20.raw.indels.filtered.sites.1M-10M.vcf.idx; src/test/resources/large/VQSR/dbsnp_132_b37.leftAligned.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/expected/snpRecal.scattered.vcf.idx; src/test/resources/large/VQSR/expected/snpSampledRecal.vcf.idx; src/test/resources/large/VQSR/indelRecal.vcf.idx; src/test/resources/large/VQSR/Omni25_sites_1525_samples.b37.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/phase1.projectConsensus.chr20.1M-10M.raw.snps.vcf.idx; src/test/resources/large/VQSR/sites_r27_nr.b37_fwd.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/snpRecal.vcf.idx; src/test/resources/NA12878.chr17_69k_70k.dictFix.bam.bai; src/test/resources/NA12878.chr17_69k_70k.dictFix.cram.crai; src/test/resources/org/broadinstitute/hellbender/engine/ambiguityCodes.dict; src/test/resources/,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3905:7010,test,test,7010,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905,1,['test'],['test']
Testability, src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/segments/SM-74P35.seg; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/total_covariate_bias_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/total_unexplained_variance_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wgs_pon/model_final/bias_covariates_ARD_coefficients.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wgs_pon/model_final/mean_bias_covariates_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wgs_pon/model_final/mean_bias_covariates_norm2.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wgs_pon/model_final/target_specific_mean_log_bias.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wgs_pon/model_final/target_specific_unexplained_variance.tsv; src/test/resources/large/cnv/realistic-targets.tab; src/test/resources/large/cnv_somatic_workflows_test_files/ice_targets_sample-chr20.interval_list; src/test/resources/large/cnv_somatic_workflows_test_files/wes-do-gc.pon.hdf5; src/test/resources/large/cnv_somatic_workflows_test_files/wes-no-gc.pon.hdf5; src/test/resources/large/cnv/truncated-realistic-targets.tab; src/test/resources/large/dbsnp_138.b37.1.1-65M.vcf.idx; src/test/resources/large/dbsnp_138.b37.20.21.vcf.blockgz.gz.tbi; src/test/resources/large/expected.NA12878.RNAseq.splitNcigarReads.bai; src/test/resources/large/expected.NA12878.RNAseq.splitNcigarReads.doNotFixOverhangs.bai; src/test/resources/large/expected.NA12878.RNAseq.splitNcigarReads.maxBasesInOverhang5.bai; src/test/resources/large/expected.NA12878.RNAseq.splitNcigarReads.maxMismatchesInOverhang0.bai; src/test/resources/large/gencode.v19.LargeFile.gtf.idx; src/test/resources/large/gencode.v26.primary_assembly.annotation.XYZ.gtf.idx; src/test/resources/large/gvcfs/CEUTrio.20.21.gatk3.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3905:4622,test,test,4622,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905,1,['test'],['test']
Testability, src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/total_unexplained_variance_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wgs_pon/model_final/bias_covariates_ARD_coefficients.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wgs_pon/model_final/mean_bias_covariates_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wgs_pon/model_final/mean_bias_covariates_norm2.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wgs_pon/model_final/target_specific_mean_log_bias.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wgs_pon/model_final/target_specific_unexplained_variance.tsv; src/test/resources/large/cnv/realistic-targets.tab; src/test/resources/large/cnv_somatic_workflows_test_files/ice_targets_sample-chr20.interval_list; src/test/resources/large/cnv_somatic_workflows_test_files/wes-do-gc.pon.hdf5; src/test/resources/large/cnv_somatic_workflows_test_files/wes-no-gc.pon.hdf5; src/test/resources/large/cnv/truncated-realistic-targets.tab; src/test/resources/large/dbsnp_138.b37.1.1-65M.vcf.idx; src/test/resources/large/dbsnp_138.b37.20.21.vcf.blockgz.gz.tbi; src/test/resources/large/expected.NA12878.RNAseq.splitNcigarReads.bai; src/test/resources/large/expected.NA12878.RNAseq.splitNcigarReads.doNotFixOverhangs.bai; src/test/resources/large/expected.NA12878.RNAseq.splitNcigarReads.maxBasesInOverhang5.bai; src/test/resources/large/expected.NA12878.RNAseq.splitNcigarReads.maxMismatchesInOverhang0.bai; src/test/resources/large/gencode.v19.LargeFile.gtf.idx; src/test/resources/large/gencode.v26.primary_assembly.annotation.XYZ.gtf.idx; src/test/resources/large/gvcfs/CEUTrio.20.21.gatk3.4.g.vcf.idx; src/test/resources/large/gvcfs/combined.gatk3.7_30_ga4f720357.g.vcf.gz.tbi; src/test/resources/large/gvcfs/combined.gatk3.7.g.vcf.gz.tbi; src/test/resources/large/gvcfs/gatk3.7_30_ga4f720357.24_sample.21.g.vcf.idx; src/test/r,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3905:4850,test,test,4850,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905,1,['test'],['test']
Testability, src/test/resources/large/cnv_somatic_workflows_test_files/ice_targets_sample-chr20.interval_list; src/test/resources/large/cnv_somatic_workflows_test_files/wes-do-gc.pon.hdf5; src/test/resources/large/cnv_somatic_workflows_test_files/wes-no-gc.pon.hdf5; src/test/resources/large/cnv/truncated-realistic-targets.tab; src/test/resources/large/dbsnp_138.b37.1.1-65M.vcf.idx; src/test/resources/large/dbsnp_138.b37.20.21.vcf.blockgz.gz.tbi; src/test/resources/large/expected.NA12878.RNAseq.splitNcigarReads.bai; src/test/resources/large/expected.NA12878.RNAseq.splitNcigarReads.doNotFixOverhangs.bai; src/test/resources/large/expected.NA12878.RNAseq.splitNcigarReads.maxBasesInOverhang5.bai; src/test/resources/large/expected.NA12878.RNAseq.splitNcigarReads.maxMismatchesInOverhang0.bai; src/test/resources/large/gencode.v19.LargeFile.gtf.idx; src/test/resources/large/gencode.v26.primary_assembly.annotation.XYZ.gtf.idx; src/test/resources/large/gvcfs/CEUTrio.20.21.gatk3.4.g.vcf.idx; src/test/resources/large/gvcfs/combined.gatk3.7_30_ga4f720357.g.vcf.gz.tbi; src/test/resources/large/gvcfs/combined.gatk3.7.g.vcf.gz.tbi; src/test/resources/large/gvcfs/gatk3.7_30_ga4f720357.24_sample.21.g.vcf.idx; src/test/resources/large/gvcfs/HG00096.g.vcf.gz.tbi; src/test/resources/large/gvcfs/HG00268.g.vcf.gz.tbi; src/test/resources/large/gvcfs/NA19625.g.vcf.gz.tbi; src/test/resources/large/Homo_sapiens_assembly38.20.21.dict; src/test/resources/large/Homo_sapiens_assembly38.20.21.fasta.fai; src/test/resources/large/human_g1k_v37.20.21.fasta.amb; src/test/resources/large/human_g1k_v37.20.21.fasta.ann; src/test/resources/large/human_g1k_v37.20.21.fasta.bwt; src/test/resources/large/human_g1k_v37.20.21.fasta.pac; src/test/resources/large/human_g1k_v37.20.21.fasta.sa; src/test/resources/large/K-562.duplicateMarked.chr20.bai; src/test/resources/large/mutect/dream_synthetic_bams/normal_3.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/normal_4.bam.bai; src/test/resources/large/mutect/dream_,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3905:5656,test,test,5656,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905,1,['test'],['test']
Testability, src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m20k.NA12878.2inputs.recal.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m20k.NA12878.indels_context_size_4.recal.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m20k.NA12878.low_quality_tail_5.recal.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m20k.NA12878.mismatches_context_size_4.recal.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m20k.NA12878.quantizing_levels_6.recal.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m20k.NA12878.recal.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.HiSeq.1mb.1RG.2k_lines.alternate.recalibrated.DIQ.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.HiSeq.1mb.1RG.2k_lines.bqsr.qq-1.alternate.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.HiSeq.1mb.1RG.2k_lines.bqsr.qq6.alternate.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.MultiSite.reads.pipeline.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.MultiSite.reads.pipeline.cram.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/HiSeq.1mb.1RG.2k_lines.alternate_allaligned.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/HiSeq.1mb.1RG.2k_lines.alternate.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/HiSeq.1mb.1RG.2k_lines.alternate.recalibrated.DIQ.sharded.bam/part-r-00001.bam; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/HiSeq.1mb.1RG.2k_lines.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/human_b36_both.chr1_1k.dict; src/test/resources/org/broadinstitute/hellbender/too,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3905:20843,test,test,20843,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905,1,['test'],['test']
Testability, src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CR_WRITE_Q0S.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CT_15_X_CCCCC_XF.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CT_15_X_CCCCC_XF.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_20.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_20.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_2.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_2.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.X_CCCCC.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.X_CCCCC.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.XF.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.XF.tmp; src/test/resources/org/broadinstitute/hellbender/tools/copynumber/allelic/collect-allelic-counts-normal.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/copynumber/allelic/collect-allelic-counts-tumor.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/copynumber/collectfragmentcounts/collect-fragment-counts-NA12878.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/count_bases.cram.crai; src/test/resources/org/broadinstitute/hellbender/tools/count_bases.dict; src/test/resources/org/broadinstitute/hellbender/tools/count_bases.fasta,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3905:25539,test,test,25539,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905,1,['test'],['test']
Testability, src/test/resources/org/broadinstitute/hellbender/tools/exome/dupReadsMini.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-calls.vcf; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-calls.vcf.gz; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-calls.vcf.gz.tbi; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-targets.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-truth.vcf.gz; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/eval-truth.vcf.gz.tbi; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/gs-calls.vcf.gz; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-average-depth.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-average-fragment-depth.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-fragment-counts.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-base-calls.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-intervals_dups.bed; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-max-of-9.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-min-MQ-30.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-NA12778.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-NA12872.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-NA12878.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-NA12878.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-no-intervals.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-sampl,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3905:32246,test,test,32246,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905,1,['test'],['test']
Testability, src/test/resources/org/broadinstitute/hellbender/tools/haplotypecaller/expected.testVCFMode.gatk3.8-4-g7b0250253f.alleleSpecific.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/haplotypecaller/expected.testVCFMode.gatk3.8-4-g7b0250253.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/haplotypecaller/pretendTobeTetraPloidTetraAllelicSite.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/HiSeq.1mb.1RG.empty.table.gz; src/test/resources/org/broadinstitute/hellbender/tools/HiSeq.1mb.1RG.noSG.table.gz; src/test/resources/org/broadinstitute/hellbender/tools/HiSeq.1mb.1RG.sg1.table.gz; src/test/resources/org/broadinstitute/hellbender/tools/HiSeq.1mb.1RG.sg2.table.gz; src/test/resources/org/broadinstitute/hellbender/tools/HiSeq.1mb.1RG.sg3.table.gz; src/test/resources/org/broadinstitute/hellbender/tools/HiSeq.1mb.1RG.sg4.table.gz; src/test/resources/org/broadinstitute/hellbender/tools/HiSeq.1mb.1RG.sg5.table.gz; src/test/resources/org/broadinstitute/hellbender/tools/Homo_sapiens_assembly18.10k_lines.dict; src/test/resources/org/broadinstitute/hellbender/tools/Homo_sapiens_assembly18.10k_lines.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/mutect/dream/vcfs/dream3-chr20.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/mutect/dream/vcfs/sample_1.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/mutect/dream/vcfs/sample_2.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/mutect/dream/vcfs/sample_3.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/mutect/dream/vcfs/sample_4.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/mutect/na12878-chr20-consumes-zero-reference-bases.bai; src/test/resources/org/broadinstitute/hellbender/tools/mutect/repeated_reads.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/mutect/validation/nearby_indels.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/NA12878.rg_subset.chr1.recal_data.ta,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3905:38560,test,test,38560,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905,1,['test'],['test']
Testability, src/test/resources/org/broadinstitute/hellbender/tools/walkers/MarkDuplicatesGATK/optical_dupes.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/walkers/MarkDuplicatesGATK/optical_dupes_casava.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/walkers/MarkDuplicatesGATK/optical_dupes.dict; src/test/resources/org/broadinstitute/hellbender/tools/walkers/MarkDuplicatesGATK/optical_dupes.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/walkers/qc/pileup/reads_data_source_test1.samtools.baq.pileup.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/qc/pileup/reads_data_source_test1.samtools.pileup.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/rnaseq/ASEReadCounter/NA12878.chr20_2444518_2637800.RNAseq.IMPROPER_PAIR.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/rnaseq/ASEReadCounter/NA12878.chr20_2444518_2637800.RNAseq.MultiContext.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/rnaseq/ASEReadCounter/NA12878.chr20_2444518_2637800.RNAseq.NON_REF.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/rnaseq/ASEReadCounter/NA12878.chr20_2444518_2637800.RNAseq.SYNONYMOUS_CODING.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/rnaseq/ASEReadCounter/NA12878.chr20_2444518_2637800.RNAseq.warnings.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/UnmarkDuplicates/allDuplicates.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/complexEvents_incompatibleDict.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/complexEvents_lexDict.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/complexEvents.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/gvcf.basepairResolution.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/Val,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3905:59600,test,test,59600,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905,1,['test'],['test']
Testability, src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/SelectVariants/expected/testSelectVariants_DiscordanceNoSampleSpecified.vcf; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/SelectVariants/expected/testSelectVariants_FileWithoutInfoLineInHeaderWithOverride.vcf; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/SelectVariants/expected/testSelectVariants_SelectMultiAllelicExcludeNonVar.vcf; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/SelectVariants/filteringDepthInFormat.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/SelectVariants/haploid-multisample.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/SelectVariants/selectVariantsInfoField.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/SelectVariants/test.dup.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/SelectVariants/tetra-diploid.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/SelectVariants/tetraploid-multisample-sac.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/SelectVariants/tetraploid-multisample.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/SelectVariants/vcfexample2DiscordanceConcordance.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/SelectVariants/vcfexample2.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/UpdateVCFSequenceDictionary/exampleBAM.sam; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/UpdateVCFSequenceDictionary/exampleFASTA.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/VariantsToTable/expected.soap_gatk_annotated.AMD.table; src/test/resources/org/broadinstitute/hellbender/tools/wal,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3905:64880,test,test,64880,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905,1,['test'],['test']
Testability," strategies, while looking at the files I noticed that for a WGS run I obtained a stats file with a negative number:; [egrassi@occam biodiversa]>cat mutect/CRC1307LMO.vcf.gz.stats; statistic value; callable -1.538687311E9. Looking around about the meaning of the number I found https://gatkforums.broadinstitute.org/gatk/discussion/24496/regenerating-mutect2-stats-file, so I'm wondering if I should be worried by having a negative number of callable sites :/; What's more puzzling is that FilterMutectCalls after ran without any error. Before running mutect I used the usual best practices pipeline, then:; ; gatk Mutect2 -tumor CRC1307LMO -R /archive/home/egrassi/bit/task/annotations/dataset/gnomad/GRCh38.d1.vd1.fa -I align/realigned_CRC1307LMO.bam -O mutect/CRC1307LMO.vcf.gz --germline-resource /archive/home/egrassi/bit/task/annotations/dataset/gnomad/af-only-gnomad.hg38.vcf.gz --f1r2-tar-gz mutect/CRC1307LMO_f1r2.tar.gz --independent-mates 2> mutect/CRC1307LMO.vcf.gz.log; ; gatk CalculateContamination -I mutect/CRC1307LMO.pileup.table -O mutect/CRC1307LMO.contamination.table --tumor-segmentation mutect/CRC1307LMO.tum.seg 2> mutect/CRC1307LMO.contamination.table.log; ; gatk LearnReadOrientationModel -I mutect/CRC1307LMO_f1r2.tar.gz -O mutect/CRC1307LMO_read-orientation-model.tar.gz 2> mutect/CRC1307LMO_read-orientation-model.tar.gz.log; ; gatk FilterMutectCalls -V mutect/CRC1307LMO.vcf.gz -O mutect/CRC1307LMO.filtered.vcf.gz -R /archive/home/egrassi/bit/task/annotations/dataset/gnomad/GRCh38.d1.vd1.fa --stats mutect/CRC1307LMO.vcf.gz.stats --contamination-table mutect/CRC1307LMO.contamination.table --tumor-segmentation=mutect/CRC1307LMO.tum.seg --filtering-stats mutect/CRC1307LMO_filtering_stats.tsv --ob-priors mutect/CRC1307LMO_read-orientation-model.tar.gz 2> mutect/CRC1307LMO_filtering_stats.tsv.log; . This Issue was generated from your [forums] ; [forums]: https://gatkforums.broadinstitute.org/gatk/discussion/24633/mutect2-4-1-4-0-stats-file-with-a-negative-number/p1",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6302:1201,log,log,1201,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6302,4,['log'],['log']
Testability," strings to be consistent and more; correct. - Implemented tests for CreateProteinChangeInfo; - Implemented tests for RenderProteinChangeString; - Implemented tests for IsIndelBetweenCodons; - Implemented tests for GetCodonChangeString. - Added a unit test for; testCreateGencodeFuncotationBuilderWithTrivialFieldsPopulated. - Fixed a bug when variant ref allele doesn't match reference genome. - Fixed test cases for - strand indel cdna strings:; There is a bug in oncotator that was fixed in Funcotator involving cdna; strings for - strand indels. In Oncotator the positions reported are off by 1 (they; should be one less) and the base reported is also wrong.; This is now fixed. - Removed some old code that had been taken out of the main codepath. - Fixed a bug in how the gencode reference contexts are created.; - Fixed a bug in how the end points for the gencode annotations are; created. - Ref context field is now consistent for indels.; The reference context will give WINDOW bases before and after the; logical reference allele for a variant. This is NOT the allele in the; input VCF, but rather the allele that actually has changed. For; insertions, the logical allele is the SPACE BETWEEN TWO BASES (and; therefore the resulting string will always be 2xWINDOW bases long).; For deletions, the logical allele is the given ref allele without the; required preceding base. For MNPs the logical allele is the given ref; allele.; Updated some tests and test data to reflect this change. - Added a small HG38 regression test set. - Fixed a boundary bug with codon strings.; Now codon change strings have an alternate (correct) form for insertions; that involve the start codon on the - strand, and the stop codon on the; + strand. This form eliminates any overrun/out of bounds exceptions. - Fixed an issue involving variants that overrun the end of the coding sequence. - Added in additional required files for regression test gencode data source. - Added a helpful script and modified test ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5302:3515,log,logical,3515,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5302,1,['log'],['logical']
Testability," table creation and data loading in LoadData (#7056); - WIP; - tieout scripts; - notes files; - updated diff scripts; - fixed bug...; - add wdl and inputs file for warp pipeline; - reverting logging; - included top level WDL; - use gnarly with BQ extract cohort; - remove unused file; - cleaning up; - tidy; - tidy up before PR; - tidy up before PR; - PR comments; - merge conflict misfires; - added example SQL to create alt allele table from VET; - option to remove PLs; - fixed and enhanced unit test; - removing unused config, causing travis to fail; - add CreateVariantIngestFiles integration test (#7071); - add sampleName (instead of NULL) to error message (#7074); - Update To handle if no data error (#7084); - Memory improvement when writing missing positions to pet (#7098); - added support for loading QUALapprox into VET (#7101); - Add -m flag to gsutil step; add dockstore branch filters to facilitate development (#7104); - updates to ImportGenomes and LoadBigQueryData (#7112); - Add ngs to cohort extract Dockerfile; remove exception catching in extract python script (#7113); - remove problematic storage_location imports (#7119); - Reduce memory and CPU for CreateImportTsvs task, check for files before attempting load (#7121); - add -m flag to gsutil mv step (#7129); - ah_var_store : Add sample file argument to cohort extract (#7117); - Perform full WGS cohort extract scientific tieout for 35 ACMG59 samples (#7106); - Enable Read/Execution Project for BQ Queries (#7136); - ah - optional service account (#7140); - Add load lock file to prevent accidental re-loading of data to BQ (#7138); - #251 Address gvcf no-calls missing QUALapprox and other features (#7146); - Job Add labels to BQ operations from GATK (Issues-199) (#7115); - parse map to list to avoid brackets and spaces in vcf output (#7168); - #259 Inline schema for importgenomes.wdl (#7171); - Created AvroFileReader and unittest, Update ExtractCohort and ExtractCohortEngine (#7174); - #224 Import WDL: handle ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8248:10777,log,logging,10777,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8248,6,"['log', 'test']","['logging', 'test']"
Testability," the case that there???s a cycle skip, the read and reference flow signals will not be aligned, and therefore the score will be inaccurate.</li>; ^; ```. This test is skipped without any apparent reason:; ```; Running Test: Test method loadIndex(org.broadinstitute.hellbender.BwaMemIntegrationTest). Gradle suite > Gradle test > org.broadinstitute.hellbender.BwaMemIntegrationTest > loadIndex FAILED; java.lang.UnsatisfiedLinkError: 'boolean org.broadinstitute.hellbender.utils.bwa.BwaMemIndex.createReferenceIndex(java.lang.String, java.lang.String, java.lang.String)'; at org.broadinstitute.hellbender.utils.bwa.BwaMemIndex.createReferenceIndex(Native Method); at org.broadinstitute.hellbender.utils.bwa.BwaMemIndex.createIndexImageFromFastaFile(BwaMemIndex.java:227); at org.broadinstitute.hellbender.utils.bwa.BwaMemIndex.createIndexImageFromFastaFile(BwaMemIndex.java:196); at org.broadinstitute.hellbender.BwaMemIntegrationTest.loadIndex(BwaMemIntegrationTest.java:49); Running Test: Test method testChimericUnpairedMapping(org.broadinstitute.hellbender.BwaMemIntegrationTest). Gradle suite > Gradle test > org.broadinstitute.hellbender.BwaMemIntegrationTest > testChimericUnpairedMapping SKIPPED; Running Test: Test method testPerfectUnpairedMapping(org.broadinstitute.hellbender.BwaMemIntegrationTest). Gradle suite > Gradle test > org.broadinstitute.hellbender.BwaMemIntegrationTest > testPerfectUnpairedMapping SKIPPED; ```. This test fails because some JAR wasn't built:; ```; Running Test: Test method testPipeForPicardTools(org.broadinstitute.hellbender.engine.PipelineSupportIntegrationTest); Test: Test method testPipeForPicardTools(org.broadinstitute.hellbender.engine.PipelineSupportIntegrationTest) produced standard out/err: No local jar was found, please build one by running. Gradle suite > Gradle test > org.broadinstitute.hellbender.engine.PipelineSupportIntegrationTest > testPipeForPicardTools STANDARD_ERROR; No local jar was found, please build one by running; Test: Test m",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8940:2738,Test,Test,2738,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8940,3,"['Test', 'test']","['Test', 'testChimericUnpairedMapping']"
Testability," the tool, we generated the image index for whole genome by using the fasta file from GATK official ftp site, and uploaded the reference file to Hadoop HDFS. ``` bash; gatk-4.0.11.0/gatk BwaMemIndexImageCreator -I Homo_sapiens_assembly38.fasta -O Homo_sapiens_assembly38.fasta.img; ```. and then, we preprocess our pair end fastq files into unaligned ubam file as, ; ``` bash; java -jar picard.jar FastqToSam \; F1=R1.fastq.gz; F2=R2.fastq.gz; O=unaligned_reads.bam \; SM=sample001 \; PL=illumina \; RG=rg001; ```. For BwaSpark, we used,; ``` {bash}; ../gatk-4.0.11.0/gatk --java-options ""-Dgatk.spark.debug=true -XX:+PrintGCDetails"" BwaSpark -I hdfs://ns/user/root/test/unaligned_reads.bam -O hdfs://ns/user/root/test/test3.bam -R hdfs://ns/user/root/Homo_sapiens_assembly38.fasta --spark-runner SPARK --spark-master spark://master:7077 -- --num-executors 4 --driver-memory 4g --executor-cores 10 --executor-memory 20g; ```. For ReadsPipelineSpark, we used, ; ``` {bash}; time_gatk ""ReadsPipelineSpark --tmp-dir /tmp --align true -I hdfs://ns/user/root/test/unaligned_reads.bam -O hdfs://ns/user/root/test/test10.vcf -R hdfs://ns/user/root/Homo_sapiens_assembly38.fasta --known-sites hdfs://ns/user/root/Homo_sapiens_assembly38.dbsnp138.vcf -pairHMM AVX_LOGLESS_CACHING --max-reads-per-alignment-start 50"" 4 44 88g 12g; ```. #### Expected behavior; Both tool should end successfully without the specified error, and generated consistent result. #### Actual behavior; Both tool ends throwing out the same error, but the alignment ratio of the bam file from bwaspark is the same as the original bwa, and seems to be ok. The vcf variant number changes between each runs, and different from the result of stable non-spark official GATK 4 version. ``` bash; 2018-12-03 13:19:45 ERROR CoarseGrainedExecutorBackend:43 - RECEIVED SIGNAL TERM; ```. The vcf line number for several runs of the ReadsPipelineSpark,; ``` bash; 94488 test2.vcf.gz; 97426 test3.vcf.gz; 82279 test4.hg19.vcf.gz; 99403 test4.vcf.gz;",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5481:1694,test,test,1694,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5481,1,['test'],['test']
Testability," the user class path in order to get around the fact that our classes aren't in the system class loader. Here's an example program I wrote that can do it on the driver. . ``` java; package org.broadinstitute.hellbender.tools;. import org.apache.spark.api.java.JavaSparkContext;; import org.broadinstitute.barclay.argparser.CommandLineProgramProperties;; import org.broadinstitute.hellbender.cmdline.programgroups.SparkProgramGroup;; import org.broadinstitute.hellbender.engine.spark.GATKSparkTool;. import java.io.IOException;; import java.lang.reflect.Field;; import java.net.URI;; import java.net.URISyntaxException;; import java.nio.file.Files;; import java.nio.file.Path;; import java.nio.file.Paths;; import java.nio.file.spi.FileSystemProvider;; import java.util.ArrayList;; import java.util.List;; import java.util.ServiceLoader;. @CommandLineProgramProperties(summary = ""test"", oneLineSummary = ""testthing"", programGroup = SparkProgramGroup.class); public class TestGCS extends GATKSparkTool {; private static final long serialVersionUID = 1L;. @Override; protected void runTool(JavaSparkContext ctx) {; try {; modifyProviders();; } catch (IllegalAccessException | NoSuchFieldException e) {; throw new RuntimeException(""Couldn't reset FilesystemProviders"");; }; try {; final Path index = Paths.get(new URI(""gs://hellbender/test/build_reports/1626.1/tests/index.html""));; System.out.println(""Count:"" + Files.lines(index).count());; } catch (URISyntaxException | IOException e) {; throw new RuntimeException(""Couldn't read file"");; }; }; }. private void modifyProviders() throws IllegalAccessException, NoSuchFieldException {; final Field installedProviders = FileSystemProvider.class.getDeclaredField(""installedProviders"");; installedProviders.setAccessible(true);; installedProviders.set(null, loadInstalledProviders());; installedProviders.setAccessible(false);; }. //copied from FileSystemProvider, modified to use TestGCS.classLoader() instead of systemClassloader; private static List<File",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2312:1138,Test,TestGCS,1138,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2312,1,['Test'],['TestGCS']
Testability," to me that shouldn't be too hard. . ---. @vdauwera commented on [Mon Nov 14 2016](https://github.com/broadinstitute/gsa-unstable/issues/1489#issuecomment-260498705). I need to ping Daniel on getting access to the files. ---. @ronlevine commented on [Thu Jan 26 2017](https://github.com/broadinstitute/gsa-unstable/issues/1489#issuecomment-275576931). @vdauwera Can you get the data? I can take a look a this issue. ---. @vdauwera commented on [Thu Jan 26 2017](https://github.com/broadinstitute/gsa-unstable/issues/1489#issuecomment-275578721). Oh, they gave me access to the files but I never took the next step of figuring out which files are relevant. There are twenty thousand samples... I'm not sure what is the best way to approach this. ---. @ldgauthier commented on [Wed Mar 01 2017](https://github.com/broadinstitute/gsa-unstable/issues/1489#issuecomment-283365248). It would be too computationally expensive and just generally painful to get; that dropped allele. I'd suggest making a unit test with some fake data.; You'll need two positions: one upstream with a deletion to generate the *; and one for the SNP. I think the dropped allele was a 1bp deletion at the; same position that generated the representation with the extra base at the; end. Give that one a really low quality in its gvcf so it gets dropped.; PLs don't really matter as long as they jive with the quals and aren't hom; ref. You can just grab numbers from any other valid vcf. I think you can do; it with three samples: one with the upstream deletion and *, one with the; AC SNP and one with the low quality deletion. Other combinations will; probably also produce the same bug. There may be an even simpler way to reproduce the bug without the low; quality deletion but I suspect this will work. On Jan 26, 2017 10:02 PM, ""Geraldine Van der Auwera"" <; notifications@github.com> wrote:. Oh, they gave me access to the files but I never took the next step of; figuring out which files are relevant. There are twenty th",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2959:3783,test,test,3783,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2959,1,['test'],['test']
Testability, use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.; at org.reflections.vfs.Vfs.fromURL(Vfs.java:109); at org.reflections.vfs.Vfs.fromURL(Vfs.java:91); at org.reflections.Reflections.scan(Reflections.java:237); at org.reflections.Reflections.scan(Reflections.java:204); at org.reflections.Reflections.<init>(Reflections.java:129); at com.google.cloud.genomics.dataflow.utils.DataflowWorkarounds.registerGenomicsCoders(DataflowWorkarounds.java:90); at org.broadinstitute.hellbender.tools.dataflow.transforms.InsertSizeMetricsTransformUnitTest.testInsertSizeMetricsTransform(InsertSizeMetricsTransformUnitTest.java:49); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:497); at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); at org.testng.internal.Invoker.invokeMethod(Invoker.java:659); at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:845); at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1153); at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:125); at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); at org.testng.TestRunner.privateRun(TestRunner.java:771); at org.testng.TestRunner.run(TestRunner.java:621); at org.testng.SuiteRunner.runTest(SuiteRunner.java:357); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:352); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:310); at org.testng.SuiteRunner.run(SuiteRunner.java:259); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1199); at org.testng.TestNG.ru,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/609:1720,test,testng,1720,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/609,1,['test'],['testng']
Testability," writing happens during the `close()` command. This is necessary since it cannot actually render its output until all segments have been seen. This output renderer also relies heavily on specific funcotation fields being in the input `FuncotationMap`. Internally, the gene list output renderer uses the `SimpleTsvOutputRenderer` (see below) to do the actual writing.; - Introduces the `SimpleTsvOutputRenderer`. This output renderer is very flexible and renders a tab-separated text file based on several output rules. Formats are driven through config files. And developers can limit the output columns to ignore extraneous funcotation fields. Note that excluded fields are honored, regardless. If a configuration + parameter combination would result in this class producing an empty file, an exception is thrown. More notes are in the javadocs of the class.; - Currently, only the `GencodeFuncotationFactory` can actually funcotate segments. ; - Code base currently enforces only small mutations when running `Funcotator` (segs are funcotated as CANNOT_DETERMINE) and only segments when running `FuncotateSegments` (small mutations produce exception). This is enforced with flags in the code. The backend does not disallow a mixture for future use. This may prove important when funcotating CNVs from VCFs produced by tools other than `ModelSegments`.; - Added copy creation method for FuncotationMap based on Kryo. Also, added the necessary Kryo registrations. This induced a new unit test to enforce any concrete implementations of `Funcotation` to be Kryo serializable. The unit test does a recursive search of the funcotator package. For all concrete implementations, it tracks whether this unit test tests the serialization. If not, it fails. Instructions for developers is present as comments in the code. This is a bit fragile, especially for developers that are using GATK as a library; - See #5921 for tracking `FuncotateSegments` WDL development. Closes #4609 . Output formats may change.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5941:3141,test,test,3141,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5941,4,['test'],"['test', 'tests']"
Testability," yes, I know is still in beta but I’ve found these problems when I compared the outputs from Haplotypecaller in spark and in not Spark versions. For comparing these results I've used this tool [https://drive.google.com/file/d/1r2WHyiz5WqOIyY_EZ1VZt92wGlL19SE4/view?usp=sharing](url) and I've obtained these plots for sensitivity and specificity( The sensitivity is defined as the number of sites inwhich both sequencing and microarrays detected a deviation from the reference sequencedivided by the number of sites where a variant was detected by using the microarrays). **Spark**; Sensitivity; ![spark_sensitivity_hg19](https://user-images.githubusercontent.com/10074137/47148261-86b77280-d2d0-11e8-8b5a-9ecfef16d889.png); Specificity; ![sparkspecificityhg19](https://user-images.githubusercontent.com/10074137/47148277-933bcb00-d2d0-11e8-97eb-1adceb4e5ee2.png). **Local non Spark tool with GATK 2.7**; ![hg19local](https://user-images.githubusercontent.com/10074137/47148427-fcbbd980-d2d0-11e8-87d8-04ec20c1005d.png); furthermore I've executed the pipeline until BQSR in Spark version and after, I am focused just on Haplotypecaller because I've used this ""backwards"" approach and I've discovered that the pipeline is deterministic from the phase Variant Discovery, but don't in the phase of Preprocessing because when I've executed this phase more times, I've obtained results completely, this is the test with one single sample:; ![comparisons_pfc32](https://user-images.githubusercontent.com/10074137/47148552-49071980-d2d1-11e8-8b1c-aec468285699.png); furthermore when I've used the output from BQSR (executed in Spark) for execute of Haplotypecaller in local(not in Spark) and adapting this output for Haplotypecaller, I had to use the tool Samtools for sort the outputs and after this step the outputs are passed from average of 19 gigabytes to 13 gigabytes average for the all samples. I've opened this Issue because I would to help you with my experiments to improvement your tool.; thanks.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5323:1643,test,test,1643,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5323,1,['test'],['test']
Testability,"""""""""; gatk]# ./gradlew; Downloading https://services.gradle.org/distributions/gradle-3.1-bin.zip; ............................................; Download https://repo1.maven.org/maven2/commons-codec/commons-codec/1.6/commons-codec-1.6.jar; Executing: git lfs pull --include src/main/resources/large. FAILURE: Build failed with an exception. * Where:; Build file '/data/md1/zhouyajun/biotools/gatk/gatk/build.gradle' line: 102. * What went wrong:; A problem occurred evaluating root project 'gatk'.; > Execution of ""git lfs pull --include src/main/resources/large"" failed with exit code: 1. * Try:; Run with --stacktrace option to get the stack trace. Run with --info or --debug option to get more log output. BUILD FAILED; """"""; what should I do ?; How can I install GATK4 successful?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4669:696,log,log,696,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4669,1,['log'],['log']
Testability,"""; Failed to evaluate input 'extreme_sample_median_percentile' (reason 1 of 1): For input string: ""Float? (optional)""; 	at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.cromwell$engine$workflow$lifecycle$materialization$MaterializeWorkflowDescriptorActor$$workflowInitializationFailed(MaterializeWorkflowDescriptorActor.scala:235); 	at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anonfun$2.applyOrElse(MaterializeWorkflowDescriptorActor.scala:205); 	at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anonfun$2.applyOrElse(MaterializeWorkflowDescriptorActor.scala:200); 	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:38); 	at akka.actor.FSM.processEvent(FSM.scala:707); 	at akka.actor.FSM.processEvent$(FSM.scala:704); 	at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.akka$actor$LoggingFSM$$super$processEvent(MaterializeWorkflowDescriptorActor.scala:156); 	at akka.actor.LoggingFSM.processEvent(FSM.scala:847); 	at akka.actor.LoggingFSM.processEvent$(FSM.scala:829); 	at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.processEvent(MaterializeWorkflowDescriptorActor.scala:156); 	at akka.actor.FSM.akka$actor$FSM$$processMsg(FSM.scala:701); 	at akka.actor.FSM$$anonfun$receive$1.applyOrElse(FSM.scala:695); 	at akka.actor.Actor.aroundReceive(Actor.scala:539); 	at akka.actor.Actor.aroundReceive$(Actor.scala:537); 	at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.aroundReceive(MaterializeWorkflowDescriptorActor.scala:156); 	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:612); 	at akka.actor.ActorCell.invoke(ActorCell.scala:581); 	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:268); 	at akka.dispatch.Mailbox.run(Mailbox.scala:229); 	at akka.dispatch.Mailbox.exec(Mailbox.scala:241); 	at akka.dispatch.forkjoi",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6189:7593,Log,LoggingFSM,7593,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6189,1,['Log'],['LoggingFSM']
Testability,"""SNP"" issue and not-exactly-reproducible test results (see #1805) still under investigation. Changed API to input. Thanks for taking a look, @cwhelan!",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1704:41,test,test,41,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1704,1,['test'],['test']
Testability,"""cloud"" and ""bucket"" tests now run by default, in order to make progress for issue #751. Moved all existing tests to ""cloud_todo"" and ""bucket_todo"". The plan is to then move back the tests that work (but in a separate PR, to keep this clean and simple).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/819:21,test,tests,21,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/819,3,['test'],['tests']
Testability,"""cloud"" and ""bucket"" tests now run by default, in order to make progress for issue #751. Moved all existing tests to ""cloud_todo"" and ""bucket_todo"". The plan is to then move back the tests that work (but in a separate PR, to keep this clean and simple). This is a rebased and fixed version of #819.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/822:21,test,tests,21,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/822,3,['test'],['tests']
Testability,"""testthing"", programGroup = SparkProgramGroup.class); public class TestGCS extends GATKSparkTool {; private static final long serialVersionUID = 1L;. @Override; protected void runTool(JavaSparkContext ctx) {; try {; modifyProviders();; } catch (IllegalAccessException | NoSuchFieldException e) {; throw new RuntimeException(""Couldn't reset FilesystemProviders"");; }; try {; final Path index = Paths.get(new URI(""gs://hellbender/test/build_reports/1626.1/tests/index.html""));; System.out.println(""Count:"" + Files.lines(index).count());; } catch (URISyntaxException | IOException e) {; throw new RuntimeException(""Couldn't read file"");; }; }; }. private void modifyProviders() throws IllegalAccessException, NoSuchFieldException {; final Field installedProviders = FileSystemProvider.class.getDeclaredField(""installedProviders"");; installedProviders.setAccessible(true);; installedProviders.set(null, loadInstalledProviders());; installedProviders.setAccessible(false);; }. //copied from FileSystemProvider, modified to use TestGCS.classLoader() instead of systemClassloader; private static List<FileSystemProvider> loadInstalledProviders() {; List<FileSystemProvider> list = new ArrayList<FileSystemProvider>();. ServiceLoader<FileSystemProvider> sl = ServiceLoader; .load(FileSystemProvider.class, TestGCS.class.getClassLoader());. // ServiceConfigurationError may be throw here; for (FileSystemProvider provider: sl) {; String scheme = provider.getScheme();. // add to list if the provider is not ""file"" and isn't a duplicate; if (!scheme.equalsIgnoreCase(""file"")) {; boolean found = false;; for (FileSystemProvider p: list) {; if (p.getScheme().equalsIgnoreCase(scheme)) {; found = true;; break;; }; }; if (!found) {; list.add(provider);; }; }; }; return list;; }; }; ```. We'd have to add an initial action to GATKSparkTool that would run `modifyProviders` once on each executor which may be a bit of a trick on it's own. . If we decided to do this it would make sense to make `modifyProviders` use",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2312:2093,Test,TestGCS,2093,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2312,1,['Test'],['TestGCS']
Testability,"# Bug Report. ## Affected tool(s) or class(es); gatk `GenomicsDBImport ` `GenotypeGVCFs`; ## Affected version(s); The Genome Analysis Toolkit (GATK) v4.5.0.0; ## Description; Hi,; Here is my situation, I'm testing the feasibility of incremental GenomicsDB，I have total 400 samples to joint calling, I have no problem directly using `GenomicsDBImport `and `GenotypeGVCFs `for joint calling of all 400 samples. The configuration used is 4c32g for `GenomicsDBImport `and 2c16g for `GenotypeGVCFs`. But when I first built a GenomicsDB of 200 samples using `GenomicsDBImport `successfully, and then use GenomicsDB `--genomicsdb-update-workspace-path` increment 200 samples into the GenomicsDB , use this incremental imported GenomicsDB to `GenotypeGVCFs`. The error happend and report GENOMICSDB_TIMER,Exception in thread ""main"" java.lang.OutOfMemoryError: Java heap space; Here are my code; ```; gatk --java-options ""-Xms8000m -Xmx~{max_mem}m"" \; GenomicsDBImport \; --tmp-dir $PWD \; --genomicsdb-workspace-path ~{workspace_dir_name}~{prefix}.~{index} \; --batch-size 50 \; -L ~{intervals} \; --reader-threads 5 \; --merge-input-intervals \; --consolidate \; -V ~{sep = "" -V "" single_sample_gvcfs}. gatk --java-options ""-Xms8000m -Xmx~{max_mem}m"" \; GenomicsDBImport \; --tmp-dir $PWD \; --genomicsdb-update-workspace-path ~{workspace_dir_name} \; --batch-size 50 \; --reader-threads 5 \; --merge-input-intervals \; --consolidate \; -V ~{sep = "" -V "" single_sample_gvcfs}. gatk --java-options ""-Xms8000m -Xmx~{max_mem}m"" \; GenotypeGVCFs \; --tmp-dir $PWD \; -R ~{ref} \; -O ~{workspace_dir_name}.vcf.gz \; -G StandardAnnotation \; --only-output-calls-starting-in-intervals \; -V gendb://~{workspace_dir_name} \; -L ~{intervals} \; --merge-input-intervals \; -all-sites; ```; And I found that before report error the number of threads used by GATK increased, but the memory usage did not exceed the maximum limit of the server.; I also cheched `--max-alternate-alleles` and `--genomicsdb-max-alternate-al",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8777:206,test,testing,206,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8777,1,['test'],['testing']
Testability,"## Affected tool(s) or class(es); SoftClippedReadFilter. ### Affected version(s); 4.5.0.0. ### Description ; According to the filter's description, setting the `--soft-clipped-leading-trailing-ratio` to 0.9 should mean that reads will be filtered out if over 90% of their bases are soft-clipped at either the beginning or end. Therefore, a higher value indicates a more lenient filter, resulting in fewer reads being excluded. However, it seems that the current implementation retains reads with a ratio of 0.9 to 1.0 instead of excluding them, which is the opposite of what the description suggests. In practice, increasing the threshold from 0.3 to 0.6 and then to 0.9 results in more reads being filtered out, which is contrary to the expected behavior. #### Steps to reproduce; 1. Increase the threshold of `--soft-clipped-leading-trailing-ratio` from 0.3 to 0.6, and then to 0.9.; 2. Observe that more reads are being filtered out with higher thresholds. Refer to the attached log for detailed observations: [SoftClippedReadFilter_test.log](https://github.com/user-attachments/files/15935665/SoftClippedReadFilter_test.log). #### Expected behavior; Filter out reads where the ratio of soft-clipped bases to total bases exceeds the given threshold. For example, set the threshold to 0.9 and filter out reads with a ratio > 0.9. #### Actual behavior; Filter out reads where the ratio of soft-clipped bases to total bases is less than the given threshold. For example, set the threshold to 0.9 and filter out reads with a ratio < 0.9. #### Simple Solution Proposal; I believe the issue might be resolved by inverting the comparison operators in the relevant sections of the code. Specifically:. - Change the `>` to `<` in line 66 and line 95 of ; **`src/main/java/org/broadinstitute/hellbender/engine/filters/SoftClippedReadFilter.java`**. This change should make the `test()` function of the `ReadFilter` class return `false` when the ratio exceeds the threshold, aligning with the intended functi",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8887:998,log,log,998,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8887,1,['log'],['log']
Testability,"## Affected version(s); - [ ] Latest public release version [version?]; - [x] Latest master branch as of [2/6/2020]. ### Description ; There are minimal/inconsistent checks that variants added to vcfWriters are correctly ordered (an issue with htsjdk I think). This leads to an insidious bug, where a sorted vcf can be fed through SelectVariants, and depending on the flavor of output vcf, either crash, or succeed but output an incorrectly sorted vcf. The issue is that in some circumstances SelectVariants will trim alleles to their minimal representation, which can change the location of a variant record, and thus reorder them. However, SelectVariants does nothing to account for the potential order change. Since vcfWriter implementations in htsjdk seem to do minimal/inconsistent checks on the order of variants being added to them, this may write out an incorrectly sorted vcf, or throw an exception, depending on the flavor of vcfWriter. . #### Steps to reproduce; With attached (zipped because github) vcf, run ; `gatk SelectVariants -V test.input.vcf -sn SAMPLE_01 -O test.output.vcf`; Tool will succeed, but output vcf will be incorrectly sorted. Somehow, this incorrectly sorted vcf will also be accompanied by an index! Though if you try to run `IndexFeatureFile` on the output vcf separately, it will fail. . run ; `gatk SelectVariants -V test.input.vcf -sn SAMPLE_01 -O test.output.vcf.gz`; tool will throw exception w/ stack trace:; ```; java.lang.IllegalArgumentException: Features added out of order: previous (TabixFeature{referenceIndex=0, start=17148456, end=17148456, featureStartFilePosition=2460, featureEndFilePosition=-1}) > next (TabixFeature{referenceIndex=0, start=17148447, end=17148457, featureStartFilePosition=2509, featureEndFilePosition=-1}); 	at htsjdk.tribble.index.tabix.TabixIndexCreator.addFeature(TabixIndexCreator.java:89); 	at htsjdk.variant.variantcontext.writer.IndexingVariantContextWriter.add(IndexingVariantContextWriter.java:203); 	at htsjdk.variant.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6443:1172,test,test,1172,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6443,1,['test'],['test']
Testability,"## Bug Report. ### Affected class; AssemblyBasedCallerUtils. ### Affected version(s); - [x] Latest public release version 4.1.9.0; - [x] Latest master branch as of 10/10/2020. ### Description ; When adjusting the base quality of overlapping read pairs, the modifications are made in place. If the modified reads are later used in another active region, the results from the later active region will be changed by the earlier modification. We had previously fixed this issue in #4926. But it looks like the refactoring in https://github.com/broadinstitute/gatk/commit/1353e3201bb11e29039efd89359b0a4cfc11e5c0 reverted to the earlier behavior. `AssemblyBasedCallerUtilsUnitTest.testfinalizeRegion()` will fail due to this behavior if [line 67](https://github.com/broadinstitute/gatk/blob/master/src/test/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/AssemblyBasedCallerUtilsUnitTest.java#L67) is changed from:; ```; AssemblyBasedCallerUtils.finalizeRegion(activeRegion, false, false, minbq, header, sampleList, false);; ```; to:; ```; AssemblyBasedCallerUtils.finalizeRegion(activeRegion, false, false, minbq, header, sampleList, true);; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6882:676,test,testfinalizeRegion,676,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6882,2,['test'],"['test', 'testfinalizeRegion']"
Testability,"## Bug Report. ### Affected tool(s) or class(es). All Spark tools that takes parameter `-L`. ### Affected version(s); - [x] Latest public release version [4.0.4.0]; - [x] Latest master branch as of [2018-06-30]. ### Description . When running a Spark tool and passing in interval arguments via the standard `-L` argument, if the interval file (only BED file is tested) is stored in HDFS, we see errors like below. ```; org.broadinstitute.hellbender.exceptions.UserException$MalformedGenomeLoc: Badly formed genome unclippedLoc: Query interval ""hdfs://shuang-g94794-chmi-chmi3-wgs1-cram-bam-feature-m:8020/data/merged_commonFPDel.bed"" is not valid for this input.; 	at org.broadinstitute.hellbender.utils.GenomeLocParser.getUnambiguousInterval(GenomeLocParser.java:350); 	at org.broadinstitute.hellbender.utils.GenomeLocParser.parseGenomeLoc(GenomeLocParser.java:309); 	at org.broadinstitute.hellbender.utils.IntervalUtils.parseIntervalArguments(IntervalUtils.java:300); 	at org.broadinstitute.hellbender.utils.IntervalUtils.loadIntervals(IntervalUtils.java:226); 	at org.broadinstitute.hellbender.cmdline.argumentcollections.IntervalArgumentCollection.parseIntervals(IntervalArgumentCollection.java:174); 	at org.broadinstitute.hellbender.cmdline.argumentcollections.IntervalArgumentCollection.getTraversalParameters(IntervalArgumentCollection.java:155); 	at org.broadinstitute.hellbender.cmdline.argumentcollections.IntervalArgumentCollection.getIntervals(IntervalArgumentCollection.java:111); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.initializeIntervals(GATKSparkTool.java:514); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.initializeToolInputs(GATKSparkTool.java:451); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:439); 	at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:30); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLinePro",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4852:361,test,tested,361,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4852,1,['test'],['tested']
Testability,"## Bug Report. ### Affected tool(s) or class(es). FastaAlternateReferenceMaker. ### Affected version(s); - [x] Latest public release version 4.1.4.1; - [ ] Latest master branch as of [date of test?]. ### Description . A null pointer exception in . #### Steps to reproduce. We called variants with HaplotypeCaller & use resulting VCF with FastaAlternateReferenceMaker. See command below, but only reference fasta & HC vcf are given as input (no snp masking or interval list, though error also occurs when using interval list with multiple -L calls). #### Expected behavior. Alternate-adjusted reference file or at least a helpful error message. #### Actual behavior. ```; + latest-gatk/gatk-4.1.4.1/gatk FastaAlternateReferenceMaker -R /g/data/xe2/references/eucalyptus/emel_scott/Emelliodora_CSIROg1_SISH00000000.1.fasta -O consensus_sequences_gatk//CCA0704.fasta.tmp -V pergene_gatk/CCA0704/CCA0704.vcf.gz; Using GATK jar /g/data/xe2/users/stephen-rodgers/latest-gatk/gatk-4.1.4.1/gatk-package-4.1.4.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /g/data/xe2/users/stephen-rodgers/latest-gatk/gatk-4.1.4.1/gatk-package-4.1.4.1-local.jar FastaAlternateReferenceMaker -R /g/data/xe2/references/eucalyptus/emel_scott/Emelliodora_CSIROg1_SISH00000000.1.fasta -O consensus_sequences_gatk//CCA0704.fasta.tmp -V pergene_gatk/CCA0704/CCA0704.vcf.gz; 15:43:14.276 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/g/data/xe2/users/stephen-rodgers/latest-gatk/gatk-4.1.4.1/gatk-package-4.1.4.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Feb 03, 2020 3:43:15 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 15:43:15.230 INFO FastaAlternateReferenceMaker - ------------------------------------------------------------; 1",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6434:192,test,test,192,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6434,1,['test'],['test']
Testability,## Bug Report. ### Affected tool(s) or class(es). GermlineCNVCaller. ### Affected version(s). - [x] Latest public release version gatk 4.2.0.0; - [ ] Latest master branch as of [date of test?]. ### Description . The same set of hdf5 works fine with another annotated_intervals.tsv . the stack trace:; ```; 11:52:33.788 INFO GermlineCNVCaller - Aggregating read-count file /SCRATCH-BIRD/users/lindenbaum-p/work/NEXTFLOW/; 20210411.GRCh37.gatkcnv.brs/work/92/579e5a48aa9e52cd0e1df603266809/B00HOTD.counts.hdf5 (229 / 347); HDF5-DIAG: Error detected in HDF5 (1.8.14) thread 0:; #000: /mnt/scr1/abyrne/HDFJava-platypus-2.11/native/HDF5-prefix/src/HDF5/src/H5Dio.c line 173 in H5Dread(): can'; t read data; major: Dataset; minor: Read failed; #001: /mnt/scr1/abyrne/HDFJava-platypus-2.11/native/HDF5-prefix/src/HDF5/src/H5Dio.c line 550 in H5D__read(): ca; n't read data; major: Dataset; minor: Read failed; #002: /mnt/scr1/abyrne/HDFJava-platypus-2.11/native/HDF5-prefix/src/HDF5/src/H5Dcontig.c line 543 in H5D__contig; _read(): contiguous read failed; major: Dataset; minor: Read failed; #003: /mnt/scr1/abyrne/HDFJava-platypus-2.11/native/HDF5-prefix/src/HDF5/src/H5Dscatgath.c line 517 in H5D__scat; gath_read(): file gather failed; major: Low-level I/O; minor: Read failed; #004: /mnt/scr1/abyrne/HDFJava-platypus-2.11/native/HDF5-prefix/src/HDF5/src/H5Dscatgath.c line 253 in H5D__gath; er_file(): read error; major: Dataspace; minor: Read failed; #005: /mnt/scr1/abyrne/HDFJava-platypus-2.11/native/HDF5-prefix/src/HDF5/src/H5Dcontig.c line 873 in H5D__contig; _readvv(): can't perform vectorized sieve buffer read; major: Dataset; minor: Can't operate on object; #006: /mnt/scr1/abyrne/HDFJava-platypus-2.11/native/HDF5-prefix/src/HDF5/src/H5VM.c line 1457 in H5VM_opvv(): ca; n't perform operation; major: Internal error (too specific to document in detail); minor: Can't operate on object; #007: /mnt/scr1/abyrne/HDFJava-platypus-2.11/native/HDF5-prefix/src/HDF5/src/H5Dcontig.c line 696 in H5D_,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7202:186,test,test,186,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7202,1,['test'],['test']
Testability,## Bug Report. ### Affected tool(s) or class(es). HC java.lang.IllegalStateException: Padded span must contain active span. ### Affected version(s); - [X] Latest public release version [version?]; - [ ] Latest master branch as of [date of test?]. ### Description. ```; Runtime.totalMemory()=2494038016; java.lang.IllegalStateException: Padded span must contain active span.; at org.broadinstitute.hellbender.utils.Utils.validate(Utils.java:814); at org.broadinstitute.hellbender.engine.AssemblyRegion.<init>(AssemblyRegion.java:104); at org.broadinstitute.hellbender.engine.AssemblyRegion.<init>(AssemblyRegion.java:80); at org.broadinstitute.hellbender.utils.activityprofile.ActivityProfile.popNextReadyAssemblyRegion(ActivityProfile.java:332); at org.broadinstitute.hellbender.utils.activityprofile.ActivityProfile.popReadyAssemblyRegions(ActivityProfile.java:277); at org.broadinstitute.hellbender.engine.AssemblyRegionIterator.loadNextAssemblyRegion(AssemblyRegionIterator.java:159); at org.broadinstitute.hellbender.engine.AssemblyRegionIterator.next(AssemblyRegionIterator.java:112); at org.broadinstitute.hellbender.engine.AssemblyRegionIterator.next(AssemblyRegionIterator.java:35); at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.processReadShard(AssemblyRegionWalker.java:192); at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.traverse(AssemblyRegionWalker.java:173); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1058); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289); ```. ,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7289:239,test,test,239,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7289,1,['test'],['test']
Testability,"## Bug Report. ### Affected tool(s) or class(es). HaplotypeCaller. ### Affected version(s); - [x] Latest public release version (4.4.0.0, also 4.1.4.1); - [ ] Latest master branch as of [date of test?]. ### Description . I am using the HaplotypeCaller (GATK 4.4.0.0). When I look at the input BAM file in IGV, I expect the variant `NC_000015.9:g.48760182_48760185delinsGGGT`. However, HaplotypeCaller reports `NC_000015.9:g.48760182_48760185del` as well as an insertion `NC_000015.9:g.48760184_48760185insGGGT` (i.e. two distinct variants instead of a single indel). In the `bamout`, one can clearly see that the local realignment suggests the deletion + insertion and not the indel. ![image](https://user-images.githubusercontent.com/58295931/226553360-bff887ea-3823-44b7-bddb-46f70705c0b3.png). I understand that the local realignment is expected to improve variant calling and that his approach is battle-tested. I am thus not convinced this is a bug. However, the realignment/variant call is not obvious to the human eye - one would expect the indel instead. The variant seems like a clear heterozygous indel. I checked this [blog post](https://gatk.broadinstitute.org/hc/en-us/articles/360035891111-Expected-variant-at-a-specific-site-was-not-called): The bamout is as outlined above, the mapping + base quality seems fine (judging by IGV) and `--max-alternate-alleles` doesn't seem useful here (and indeed doesn't do anything to the result). I didn't got into kmer fiddling as suggested by the blog post. This is not a homopoly region. I also tested with 4.1.4.1 which only reports the deletion. The screenshot from above is from the 4.4.0.0 invocation. Here is the same situation for 4.1.4.1 (realignment is similar, `out.vcf` does not contain the insertion):. ![image](https://user-images.githubusercontent.com/58295931/226554045-0d9dd7e3-65ec-40ce-a6bd-74d73d4a2507.png). FYI, the variant lies on FBN1 / NM_000138.5 (rev strand). cDNA notation would be `NM_000138.5:c.4698_4701del` or `NM_000",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8253:195,test,test,195,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8253,2,['test'],"['test', 'tested']"
Testability,"## Bug Report. ### Affected tool(s) or class(es). MuTect2 for the test case, but any caller using the Reference Bases annotation and calling bases near the end of chromosomes. ### Affected version(s). This occurs with the latest release (4.0.8.1) and not with the previous (4.0.7.0). It appears to be related to the addition of the Orientation Bias filter (#4895) and assessing sequence context:. https://github.com/broadinstitute/gatk/pull/4895/files#diff-07e3c8c33f865c5b32b362afe50cfd86R48. ### Description . When identifying variants near the end of chromosome boundaries, MuTect2 fails with:; ```; java.lang.StringIndexOutOfBoundsException: String index out of range: 369; at java.lang.String.substring(String.java:1963); at org.broadinstitute.hellbender.tools.walkers.annotator.ReferenceBases.annotate(ReferenceBases.java:48); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorEngine.annotateContext(VariantAnnotatorEngine.java:270); at org.broadinstitute.hellbender.tools.walkers.mutect.SomaticGenotypingEngine.callMutations(SomaticGenotypingEngine.java:176); at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2Engine.callRegion(Mutect2Engine.java:211); at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2.apply(Mutect2.java:212); at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.processReadShard(AssemblyRegionWalker.java:291); at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.traverse(AssemblyRegionWalker.java:267); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:979); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:137); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:182); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:201); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.m",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5130:66,test,test,66,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5130,1,['test'],['test']
Testability,"## Bug Report. ### Affected tool(s) or class(es). Mutect2; `; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx130g -jar /gatk/gatk-package-4.1.8.1-local.jar Mutect2 -R /ucsc.hg19.fasta -I my.bam -L /test.bed --f1r2-tar-gz DD.f1r2.tar.gz --force-active --genotype-germline-sites --kmer-size 10 --kmer-size 20 --recover-all-dangling-branches --max-reads-per-alignment-start 0 --native-pair-hmm-threads 33 -O DD.vcf.gz; `. ### Affected version(s); Using GATK jar /gatk/gatk-package-4.1.8.1-local.jar. ### Description ; When bed is created with a reference genome that is not the same as the bam file, an null pointer can occurs. The error is not catched by GATK, and the error is difficult to understand. Here a discussion about it.; https://gatk.broadinstitute.org/hc/en-us/community/posts/360077477391-Haplotype-caller-fails-to-run-GATK-4-1-8-0-and-GATK-4-2-0-0-. The case below occurs when provided bed has been made with the wrong genome reference.; `; 14:25:55.254 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/gatk/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Oct 07, 2021 2:25:55 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 14:25:55.525 INFO Mutect2 - ------------------------------------------------------------; 14:25:55.525 INFO Mutect2 - The Genome Analysis Toolkit (GATK) v4.1.8.1; 14:25:55.525 INFO Mutect2 - For support and documentation go to https://software.broadinstitute.org/gatk/; 14:25:55.525 INFO Mutect2 - Executing as toto on Linux v5.4.123-1.el7.elrepo.x86_64 amd64; 14:25:55.525 INFO Mutect2 - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_242-8u242-b08-0ubuntu3~18.04-b08; 14:25:55.526 INFO Mutect2 - Start Date/Time: October 7, 2021 2:25:55 PM GMT; 14:25:55.526 INFO Mutect2 - -----",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7496:315,test,test,315,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7496,1,['test'],['test']
Testability,"## Bug Report. ### Affected tool(s) or class(es). The Genome Analysis Toolkit (GATK) v4.0.7.0. ### Description . I ran the command line below and get an oom error. I've got the same error when i set the heap memory larger using the param ""--java-option Xmx24g"" . This procedure only crashed when I tried to select INDEL. I've uploaded the vcf file for you to test. command line:; ```shell; disk/juntong/software/gatk-4.0.7.0/gatk SelectVariants -V /disk/juntong/huada/V300029595_results/mutect_outputs/V300029595.merged.vcf.gatk.somatic.vcf.gz -O /disk/juntong/huada/V300029595_results/mutect_outputs/V300029595.merged.vcf.gatk.somatic.vcf.gatk.somatic.indel.vcf.gz -select-type INDEL; ```. log:; ```; Using GATK jar /disk/juntong/software/gatk-4.0.7.0/gatk-package-4.0.7.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /disk/juntong/software/gatk-4.0.7.0/gatk-package-4.0.7.0-local.jar SelectVariants -V /disk/juntong/huada/V300029595_results/mutect_outputs/V300029595.merged.vcf.gatk.somatic.vcf.gz -O /disk/juntong/huada/V300029595_results/mutect_outputs/V300029595.merged.vcf.gatk.somatic.vcf.gatk.somatic.indel.vcf.gz -select-type INDEL; 05:06:54.800 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/disk/juntong/software/gatk-4.0.7.0/gatk-package-4.0.7.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; 05:06:55.409 INFO SelectVariants - ------------------------------------------------------------; 05:06:55.409 INFO SelectVariants - The Genome Analysis Toolkit (GATK) v4.0.7.0; 05:06:55.409 INFO SelectVariants - For support and documentation go to https://software.broadinstitute.org/gatk/; 05:06:55.410 INFO SelectVariants - Executing as juntong@train1 on Linux v3.10.0-1062.1.1.el7.x86_64 amd64; 05:06:55.410 INFO SelectVariants - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_222-b10; 05:06:55.410 INFO SelectVariants -",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6254:359,test,test,359,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6254,2,"['log', 'test']","['log', 'test']"
Testability,"## Bug Report. ### Affected tool(s) or class(es). ValidateVariants: `--fail-gvcf-on-overlap` / `-no-overlaps`. ### Affected version(s); - [x] Latest public release version: 4.2.6.1; - [ ] ~Latest master branch as of~ [did not test, but affected file hasn't changed since August 2021]. ### Description . If there are overlapping reference blocks when running ValidateVariants with the `-no-overlaps` option, a USER ERROR is outputted after the entire tool finishes running, as shown below:. ```; ***********************************************************************. A USER ERROR has occurred: This GVCF contained overlapping reference blocks. The first overlapping interval is [genomic coordinates here]. ***********************************************************************; ```. This error should be generally helpful, but it appears that the interval that is reported in the error message is the _last_ overlapping interval, not the _first_. I'm not super familiar with java, but I'm guessing that `firstOverlap` might be continuously replaced by `refInterval` if there are multiple overlaps, which is inconsistent with expected behavior. . Potentially relevant lines of code: ; - `-no-overlaps` argument description ([lines 192-201](; https://github.com/broadinstitute/gatk/blob/ca33bc953abfa7050b791f049285f5262675cf84/src/main/java/org/broadinstitute/hellbender/tools/walkers/variantutils/ValidateVariants.java#L192-L201)); - `firstOverlap = refInterval` ([line 275](https://github.com/broadinstitute/gatk/blob/ca33bc953abfa7050b791f049285f5262675cf84/src/main/java/org/broadinstitute/hellbender/tools/walkers/variantutils/ValidateVariants.java#L275)). #### Steps to reproduce. Running ValidateVariants with the `-no-overlaps` flag on a .g.vcf with overlapping intervals will cause this error. More specifically, we're running this within WARP's Exome Germline Single Sample v.3.1.7 WDL release. Our command is as follows:. ```; gatk --java-options ""-Xms6000m -Xmx6500m"" \; ValidateVariants ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8103:226,test,test,226,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8103,1,['test'],['test']
Testability,"## Bug Report. ### Affected tool(s) or class(es). VariantAnnotator ... but this is due to an old syntax update perhaps other docs in other tools are also affected. ### Affected version(s); - [X] Latest public release version [version?]; - [Presumptive] Latest master branch as of [date of test?]. ### Description . The argument ```--resource``` example(s) show a wrong syntax in regards to the location of the ""provider"" name ; ; #### Steps to reproduce; Google 'GATK VariantAnnotator'; the first or one of the first hits points to the current GATK doc on the tool. . #### Expected behavior. The example should read ```--resource:foo resource-file.vcf.gz```. #### Actual behavior. The example reads ```--resource foo:resource-file.vcf.gz```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8143:289,test,test,289,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8143,1,['test'],['test']
Testability,"## Bug Report. ### Affected tool(s) or class(es). `VariantFiltration` not working on `HaplotypeCaller` VCF. ### Affected version(s). > Using GATK jar /work/mtgraovac_lab/tools/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar. ### Description . Where a line of the VCF file looks like:. ```; ##source=HaplotypeCaller; #CHROM POS ID REF ALT QUAL FILTER INFO FORMAT MTG324; I 1355499 . A G 127.14 . AC=2;AF=1.00;AN=2;DP=4;ExcessHet=3.0103;FS=0.000;MLEAC=2;MLEAF=1.00;MQ=30.51;QD=31.79;SOR=1.609 GT:AD:DP:GQ:PL 1/1:0,4:4:12:141,12,0; ```; The following filter is applied:. ```; $ gatk VariantFiltration -R refs/c_elegans.PRJNA13758.WS265.genomic.fa -V VCFS/haplotypecaller.vcf -O test.vcf.gz --filter-expression ""MQ > 90.0"" --filter-name ""my_filters"". Using GATK jar /work/mtgraovac_lab/tools/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /work/mtgraovac_lab/tools/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar VariantFiltration -R refs/c_elegans.PRJNA13758.WS265.genomic.fa -V VCFS/haplotypecaller.vcf -O sanic.vcf.gz --filter-expression MQ > 90.0 --filter-name my_filters; 12:01:06.183 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/work/mtgraovac_lab/tools/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Nov 15, 2020 12:01:06 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 12:01:06.398 INFO VariantFiltration - ------------------------------------------------------------; 12:01:06.398 INFO VariantFiltration - The Genome Analysis Toolkit (GATK) v4.1.8.1; 12:01:06.398 INFO VariantFiltration - For support and documentation go to https://software.broadinstitute.org/gatk/; 12:01:06.398 INFO VariantFiltration - Executing as moldach@arc on Linux v3.10",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6960:671,test,test,671,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6960,1,['test'],['test']
Testability,"## Bug Report. ### Affected tool(s) or class(es): Mutect2. ### Affected version(s); gatk 4.2.5. ### Description ; Like most use cases, I acquired a high-confidence, ""consensus"" VCF from a large batch of samples, and I run force-calling on each individual sample again to:; (1) rescue rare variants.; (2) for variants that are not called in a sample, get the REF/ALT counts for them for downstream analysis. However, compared to the first pass (where Mutect2 is in simple germline calling mode), the second pass (force-calling) is extremely slow. Sorry I have not done any precise measurement, but the difference is quite significant. Given my use case, do you still recommend using force-calling? Or is there any alternative, more efficient method? I tried using bcftools call, but that tool has several issues as well such as omitting indels, not supporting multiallelic force-calling etc. #### Steps to reproduce. My command for force-calling is:; ```; ""gatk Mutect2 ""; ""-alleles {input.q_vcf} ""; ""-L {input.q_vcf} ""; ""--genotype-filtered-alleles ""; ""--max-reads-per-alignment-start {params.mrpas} ""; ""-R {params.REF} ""; ""-I {input.sc_bam} ""; ""-O {output.sc_vcf}; ""; ```. I can upload some BAMs for testing if needed. Thanks in advance!",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7825:1201,test,testing,1201,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7825,1,['test'],['testing']
Testability,"## Bug Report. ### Affected tool(s) or class(es); - `HaplotypeCaller` with the arguments `--max-mnp-distance 5`. ### Affected version(s); - gatk version 4.0.12.0. ### Description . For a genomes in a bottle reference sample, I have observed a genotype discordance as follows:. ref: `CA`; alleles: `CG` and `TG`. | Callset | Genotype |; | --- | --- |; | GIAB | `1/2` |; | Test | `0/2` |. As you can see, the test dataset improperly calls a reference allele (`CA`) when it should have called the first alternate instead. The GIAB callset has two phased records:; <details>; <summary> GIAB callset </summary>. ```; chr2 241815307 . C T 50 PASS platforms=3;platformnames=Illumina,CG,10X;datasets=4;datasetnames=HiSeqPE100x,CGnormal,10XChromium,HiSeqMatePair;callsets=6;callsetnames=HiSeqPE100xSentieon,CGnormal,HiSeqPE100xfreebayes,10XSentieonhaplo,HiSeqMatePairSentieon,HiSeqMatePairfreebayes;callable=CS_HiSeqPE100xSentieon_callable,CS_CGnormal_callable,CS_HiSeqPE100xfreebayes_callable,CS_10XSentieonhaplo_callable;filt=CS_CGnormal_filt GT:PS:DP:ADALL:AD:GQ 0|1:241815307_C_T:286:53,44:47,41:1082; chr2 241815308 . A G 50 PASS platforms=3;platformnames=Illumina,CG,10X;datasets=4;datasetnames=HiSeqPE100x,CGnormal,10XChromium,HiSeqMatePair;callsets=6;callsetnames=HiSeqPE100xSentieon,CGnormal,HiSeqPE100xfreebayes,10XSentieonhaplo,HiSeqMatePairSentieon,HiSeqMatePairfreebayes;callable=CS_HiSeqPE100xSentieon_callable,CS_CGnormal_callable,CS_HiSeqPE100xfreebayes_callable,CS_10XSentieonhaplo_callable;filt=CS_CGnormal_filt GT:PS:DP:ADALL:AD:GQ 1|1:241815307_C_T:287:0,98:0,89:1; ```; </details>. while the test callset has the following single record:. <details>; <summary> Test callset </summary>. ```; chr2 241815307 . CA TG 1756.77 PASS AC=1;AF=0.5;AN=2;BaseQRankSum=-0.802;ClippingRankSum=0.521;DP=85;ExcessHet=3.0103;FS=2.902;MLEAC=1;MLEAF=0.5;MQ=60.0;MQRankSum=0.0;QD=20.67;ReadPosRankSum=-1.858;SOR=0.571 GT:AD:DP:F1R2:F2R1:GQ:PL 0/1:37,48:85:16,25,0:21,23,0:99:1785,0,1406; ```; </details>. Next",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5696:371,Test,Test,371,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5696,2,"['Test', 'test']","['Test', 'test']"
Testability,"## Bug Report. ### Affected tool(s) or class(es); - gatk/scripts/cnv_wdl/germline/cnv_germline_case_workflow.wdl; - gatk/scripts/cnv_wdl/germline/cnv_getmline_cohort_workflow.wdl. ### Affected version(s); - **WDL** file from GATK latest release (4.2.5.0); - **GATK Docker** - latest (4.2.5.0). ### Description ; Accoridng to [GATK Germline CNV WDL instructions](https://github.com/broadinstitute/gatk/blob/master/scripts/cnv_wdl/germline/README.md), I ran cnv_getmline_cohort_workflow.wdl and got data to run cnv_germline_case_workflow.wdl. (contig_ploidy_model_tar file and 40 gcnv_model_tars files). Then I tried to run cnv_germline_case_workflow.wdl with one sample and got an error: ; ```; java.lang.IllegalArgumentException: The number of input call shards must match the number of input model shards.; 	at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:798); 	at org.broadinstitute.hellbender.tools.copynumber.PostprocessGermlineCNVCalls.validateArgum; ```. PostprocessGermlineCNVCalls only completes correctly if I use only one of the gcnv_model_tars files, but it only produces results for the iterval_list file that is included in the used gcnv_model_tars. #### Case mode files; [case.log](https://github.com/broadinstitute/gatk/files/8186658/case.log); [case-inputs.json.txt](https://github.com/broadinstitute/gatk/files/8186662/case-inputs.json.txt). #### Cohort mode files; [cohort.log](https://github.com/broadinstitute/gatk/files/8186665/cohort.log); [cohort-inputs.json.txt](https://github.com/broadinstitute/gatk/files/8186667/cohort-inputs.json.txt)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7706:1212,log,log,1212,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7706,4,['log'],['log']
Testability,"## Bug Report. ### Affected tool(s) or class(es); Any tool that uses log4j2 and is compiled in java11. ### Affected version(s); - [ X ] Latest master branch as of 20210707. ### Description ; Runing almost everything (anything that makes use of log4j2) I get an UnsuportedOperationException. For example:. ```; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx120g -XX:ParallelGCThreads=20 -jar /opt/gatk-4.2.0.0-42-g2fc3b65-SNAPSHOT/gatk-package-4.2.0.0-42-g2fc3b65-SNAPSHOT-local.jar HaplotypeCaller -R Reference/Cork_oak_ref.fasta -I 03-Mapping/05-Deduped-Sorted/S_B_10-deduped-sorted.bam -O 04-SNPcalling/01-HaplotypeCaller/S_B_10.raw.g.vcf --emit-ref-confidence GVCF; WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.; Exception in thread ""main"" java.lang.ExceptionInInitializerError; at org.broadinstitute.hellbender.Main.extractCommandLineProgram(Main.java:304); at org.broadinstitute.hellbender.Main.setupConfigAndExtractProgram(Main.java:180); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:202); at org.broadinstitute.hellbender.Main.main(Main.java:289); Caused by: java.lang.UnsupportedOperationException: No class provided, and an appropriate one cannot be found.; at org.apache.logging.log4j.LogManager.callerClass(LogManager.java:576); at org.apache.logging.log4j.LogManager.getLogger(LogManager.java:601); at org.apache.logging.log4j.LogManager.getLogger(LogManager.java:588); at org.broadinstitute.barclay.argparser.ClassFinder.<clinit>(ClassFinder.java:29); ... 4 more; ```. #### Steps to reproduce; Compile master with java11 and run ; `gatk CheckIlluminaDirectory --help`. #### Expected behavior; Normal execution. #### Actual behavior; UnsupportedOperationException",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7338:1361,log,logging,1361,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7338,9,"['Log', 'log']","['LogManager', 'logging']"
Testability,"## Bug Report. ### Affected tool(s) or class(es); BaseRecalibrator, `BaseRecalibrationEngine.calculateKnownSites`. ### Affected version(s); - public release version [tested on >=4.1? no idea how to check]. ### Description ; When running BaseRecalibrator, if a read begins with an insertion and the KnownSites file contains an interval that begins at that position, the bases will not be skipped as GetReadCoordinateForReferenceCoordinate returns the read coordinate after the insertion. To properly handle this case, in the line https://github.com/broadinstitute/gatk/blob/9bca5119e996886ee85ef6c890eba79ec5d6cfb1/src/main/java/org/broadinstitute/hellbender/utils/recalibration/BaseRecalibrationEngine.java#L340 ReadUtils.ClippingTail.LEFT_TAIL should be changed to ReadUtils.ClippingTail.RIGHT_TAIL. Making this substitution would ensure that the coordinate returned is always the leftmost coordinate when the read begins with an insertion, the desired effect for the start of the interval. #### Steps to reproduce; Use an alignment with a read that begins with an insertion and a BED that specifies an interval that begins at that position. For example, alignment file:; ```; @HD VN:1.6 SO:coordinate; @SQ SN:ref LN:10; @RG ID:foo SM:bar PU:baz PL:ILLUMINA; r001 0 ref 2 40 6I4M * 0 0 AAAAAAAAAA IIIIIIIIII RG:Z:foo; ```; and ref:; ```; >ref; AAAAAAAAAA; ```. and BED file; ```; ref 0 1; ref 1 2; ref 2 3; ref 3 4; ref 4 5; ref 5 6; ref 6 7; ref 7 8; ref 8 9; ref 9 10; ```; Then run BaseRecalibrator and look at the output:; `gatk BaseRecalibrator -I aln.bam -R ref.fa --known-sites sites.bed.gz -O recal.txt`. #### Expected behavior; The output tables should be empty, since every site in our reference (bases 1-10 inclusive) should be skipped. #### Actual behavior; The output tables include the 6 inserted bases, and the cycle covariate values confirm they are the 6 leading inserted bases:; ```; ReadGroup QualityScore CovariateValue CovariateName EventType EmpiricalQuality Observations Errors",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6385:166,test,tested,166,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6385,1,['test'],['tested']
Testability,"## Bug Report. ### Affected tool(s) or class(es); Build. ### Affected version(s); - [X] Latest public release version [version?]; - [ ] Latest master branch as of [date of test?]. ### Description ; ```; =======================<phase: build >============================; ===> Building for gatk-4.2.6.1_1. Welcome to Gradle 7.5.1!. Here are the highlights of this release:; - Support for Java 18; - Support for building with Groovy 4; - Much more responsive continuous builds; - Improved diagnostics for dependency resolution. For more details see https://docs.gradle.org/7.5.1/release-notes.html. Starting a Gradle Daemon (subsequent builds will be faster). FAILURE: Build failed with an exception. * Where:; Build file '/wrkdirs/usr/ports/biology/gatk/work/gatk-4.2.6.1/build.gradle' line: 15. * What went wrong:; Plugin [id: 'de.undercouch.download', version: '4.1.2'] was not found in any of the following sources:. - Gradle Core Plugins (plugin is not in 'org.gradle' namespace); - Plugin Repositories (could not resolve plugin artifact 'de.undercouch.download:de.undercouch.download.gradle.plugin:4.1.2'); Searched in the following repositories:; Gradle Central Plugin Repository; ```. #### Steps to reproduce; regular build. Version: 4.2.6.1; Java-17; FreeBSD 13.1",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7984:172,test,test,172,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7984,1,['test'],['test']
Testability,## Bug Report. ### Affected tool(s) or class(es); CalibrateDragstrModel. ### Affected version(s); Custom build: us.gcr.io/broad-dsde-methods/broad-gatk-snapshots/dragen_final_test_v2. ### Description ; An exception occurs on some AoU crams when running CalibrateDragstrModel; We have tried reindexing the cram.; This data is not public but @ahaessly can be a resource to help with debugging and testing. htsjdk.samtools.cram.CRAMException: Attempt to unmapped with non zero alignment start (0) or span (-2147483647); 	at htsjdk.samtools.cram.BAIEntry.<init>(BAIEntry.java:60); 	at htsjdk.samtools.cram.BAIEntry.<init>(BAIEntry.java:83); 	at htsjdk.samtools.cram.CRAIIndex.openCraiFileAsBaiStream(CRAIIndex.java:89); 	at htsjdk.samtools.SamIndexes.asBaiSeekableStreamOrNull(SamIndexes.java:91); 	at htsjdk.samtools.CRAMFileReader.initWithStreams(CRAMFileReader.java:202); 	at htsjdk.samtools.CRAMFileReader.<init>(CRAMFileReader.java:193); 	at htsjdk.samtools.SamReaderFactory$SamReaderFactoryImpl.open(SamReaderFactory.java:422); 	at htsjdk.samtools.SamReaderFactory.open(SamReaderFactory.java:105); 	at org.broadinstitute.hellbender.engine.ReadsPathDataSource.<init>(ReadsPathDataSource.java:245); 	at org.broadinstitute.hellbender.engine.ReadsPathDataSource.<init>(ReadsPathDataSource.java:181); 	at org.broadinstitute.hellbender.engine.GATKTool.initializeReads(GATKTool.java:459); 	at org.broadinstitute.hellbender.engine.GATKTool.onStartup(GATKTool.java:708); 	at org.broadinstitute.hellbender.tools.dragstr.CalibrateDragstrModel.onStartup(CalibrateDragstrModel.java:108); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:138); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); 	at org.broadinstitute.hell,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7152:395,test,testing,395,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7152,1,['test'],['testing']
Testability,"## Bug Report. ### Affected tool(s) or class(es); CombineGVCFs. ### Affected version(s); - [X] Latest public release version [4.2.5.0]; - [ ] Latest master branch as of [date of test?]. ### Description ; The auto-generated wdl for CombineGVCFs on dockstore won't work because it doesn't have any inputs for the indices of the input vcfs. This means GATK cannot access the vcf indices because they never get localized, so the workflow fails. . #### Steps to reproduce; Take any vcfs and run them through the workflow to get an error about missing indices. . #### Expected behavior; Including the indices in the task inputs will allow them to get localized along with the vcfs so GATK can operate normally. . #### Actual behavior; You get an error saying it requires index files to proceed.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7681:178,test,test,178,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7681,1,['test'],['test']
Testability,"## Bug Report. ### Affected tool(s) or class(es); Funcotator. ### Affected version(s); - [ ] v.4.1.3.0 using us.gcr.io/broad-gatk/gatk:4.1.3.0; - [ ] 11/22 failed in Terra. ### Description ; There is a bug in the logic with how Funcotator is handling this variant. It is a variant after ; chr14:24655355 ; **Stacktrace**; <img width=""1248"" alt=""Screen Shot 2019-11-27 at 4 37 31 PM"" src=""https://user-images.githubusercontent.com/13475639/69761316-026f2a00-1135-11ea-9b50-491f5b22971c.png"">. Jonn has the input files, log file, and WDL. #### Steps to reproduce; To reproduce this issue, all the inputs and full pipeline are listed in this[ Zendesk ticket 3847](https://broadinstitute.zendesk.com/agent/tickets/3847). Contact Tiffany for access. #### Expected behavior; The tool should handle this situation more gracefully?. #### Actual behavior; It fails with a java.lang.StringIndexOutOfBoundsException: String index out of range: 776. ----",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6289:213,log,logic,213,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6289,2,['log'],"['log', 'logic']"
Testability,"## Bug Report. ### Affected tool(s) or class(es); Funcotator. ### Affected version(s); - [x] Latest public release version [4.2.1.0]; - [ ] Latest master branch as of [date of test?]. ### Description ; When processing a VCF with tumor and matched normal into a MAF, the `Match_Norm_Seq_Allele1` and `Match_Norm_Seq_Allele2` fields are not populated. #### Steps to reproduce. `gatk --java-options -Xmx2048m Funcotator --data-sources-path /cromwell_root/datasources_dir --ref-version hg38 --output-file-format MAF -R /cromwell_root/getzlab-workflows-reference_files-oa/hg38/gdc/GRCh38.d1.vd1.fa -V` [`C3N-02729.vcf.gz`](https://github.com/broadinstitute/gatk/files/6977700/C3N-02729.vcf.gz) `-O C3N-02729.maf --annotation-default normal_barcode:C3N-02729_N --annotation-default tumor_barcode:C3N-02729_T --annotation-default Center:broadinstitute.org --annotation-default source:Unknown --transcript-selection-mode BEST_EFFECT`. (NOTE: reference files available at `gs://getzlab-workflows-reference_files-oa/hg38/gdc`). #### Expected behavior; `Match_Norm_Seq_Allele1` and `Match_Norm_Seq_Allele2` fields should be populated as appropriate based on the `GT` field for the matched normal in the VCF. #### Actual behavior; `Match_Norm_Seq_Allele1` and `Match_Norm_Seq_Allele2` are populated with `__UNKNOWN__`",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7408:176,test,test,176,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7408,1,['test'],['test']
Testability,## Bug Report. ### Affected tool(s) or class(es); Funcotator. ### Affected version(s); - [x] Latest public release version [version?]; - [x] Latest master branch as of [date of test?]. ### Description ; Funcotator appears to output an unnecessary extra tab at the end of each line. The change appears to have happened between gatk 4.1.4.0 and 4.1.6.0. #### Expected behavior; Output correct number of tabs corresponding to the number of column headers. #### Actual behavior; Outputs an extra tab.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6693:177,test,test,177,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6693,1,['test'],['test']
Testability,"## Bug Report. ### Affected tool(s) or class(es); Funcotator. ### Affected version(s); GATK 4.1.0.0. ### Description ; Funcotator does not perform any annotation on a minimal VCF with canonical cancer variants and returns the following error:. ```; 23:28:30.519 INFO Funcotator - Initializing Funcotator Engine...; 23:28:30.523 INFO Funcotator - Creating a VCF file for output: file:xxx/sandbox/idh.funcotated.vcf; 23:28:30.541 INFO ProgressMeter - Starting traversal; 23:28:30.541 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 23:28:30.652 INFO ProgressMeter - unmapped 0.0 15 8108.1; 23:28:30.652 INFO ProgressMeter - Traversal complete. Processed 15 total variants in 0.0 minutes.; 23:28:30.652 WARN Funcotator - ================================================================================; 23:28:30.652 WARN Funcotator - _ _ _ __ __ _ _ _ _; 23:28:30.652 WARN Funcotator - | || || | \ \ / /_ _ _ __ _ __ (_)_ __ __ _ | || || |; 23:28:30.652 WARN Funcotator - | || || | \ \ /\ / / _` | '__| '_ \| | '_ \ / _` | | || || |; 23:28:30.653 WARN Funcotator - |_||_||_| \ \V V / (_| | | | | | | | | | | (_| | |_||_||_|; 23:28:30.653 WARN Funcotator - (_)(_)(_) \_/\_/ \__,_|_| |_| |_|_|_| |_|\__, | (_)(_)(_); 23:28:30.653 WARN Funcotator - |___/; 23:28:30.653 WARN Funcotator - --------------------------------------------------------------------------------; 23:28:30.653 WARN Funcotator - Only IGRs were produced for this dataset. This STRONGLY indicates that this; 23:28:30.653 WARN Funcotator - run was misconfigured.; 23:28:30.653 WARN Funcotator - You MUST check your data sources to make sure they are correct for these data.; 23:28:30.653 WARN Funcotator - ================================================================================; ```. There is no reason to assume that there is any issue with the data sources or run parameters. They have worked fine using a different VCF that had completed INFO tags. #### Steps to reproduce; Run Funcotator",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5777:387,sandbox,sandbox,387,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5777,1,['sandbox'],['sandbox']
Testability,"## Bug Report. ### Affected tool(s) or class(es); Funcotator. ### Affected version(s); `master`. ### Description ; For example, the following two snippets are equivalent, but due to random ordering, the last two are switched and automated tests are failing, even though the code is untouched.; ```; .../MRPL55_ENST00000430433.1_SPLICE_SITE/C1orf35_ENST00000272139.4_FIVE_PRIME_FLANK/MRPL55_ENST00000465397.1_SPLICE_SITE/C1orf35_ENST00000472617.1_FIVE_PRIME_FLANK....; .../MRPL55_ENST00000430433.1_SPLICE_SITE/C1orf35_ENST00000272139.4_FIVE_PRIME_FLANK/C1orf35_ENST00000472617.1_FIVE_PRIME_FLANK/MRPL55_ENST00000465397.1_SPLICE_SITE...; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5927:239,test,tests,239,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5927,1,['test'],['tests']
Testability,"## Bug Report. ### Affected tool(s) or class(es); Funcotator. ### Affected version(s); gatk-4.1.8.0; funcotator_dataSources.v1.7.20200521s. ### Description . I am trying to use Funcotator to annotate the variants that I have already detected. Unfortunatelly, after a few seconds Funcotator stops with the error:. > java.lang.IllegalArgumentException: Unexpected value: lncRNA. I have no idea what is wrong and I did not find this error in the internet. Can it be a problem with JRE?. Full log below. #### Steps to reproduce. `~/programs/gatk-4.1.8.0/gatk Funcotator --variant filtered_variants/P1.vcf.gz --reference ~/resources/hg38_for_bwa/hs38DH.fa --ref-version hg38 --data-sources-path ~/resources/gatk/funcotator2/funcotator_dataSources.v1.7.20200521s --output filtered_variants/P1.avcf.gz --output-file-format VCF`. #### Expected behavior. Foncotator annotates my variants. #### Actual behavior. > (base) [pkus@master1 mutect_test]$ ~/programs/gatk-4.1.8.0/gatk Funcotator --variant filtered_variants/P1.vcf.gz --reference ~/resources/hg38_for_bwa/hs38DH.fa --ref-version hg38 --data-sources-path ~/resources/gatk/funcotator2/funcotator_dataSources.v1.7.20200521s --output filtered_variants/P1.avcf.gz --output-file-format VCF; > Using GATK jar /home/pkus/programs/gatk-4.1.8.0/gatk-package-4.1.8.0-local.jar; > Running:; > java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /home/pkus/programs/gatk-4.1.8.0/gatk-package-4.1.8.0-local.jar Funcotator --variant filtered_variants/P1.vcf.gz --reference /home/pkus/resources/hg38_for_bwa/hs38DH.fa --ref-version hg38 --data-sources-path /home/pkus/resources/gatk/funcotator2/funcotator_dataSources.v1.7.20200521s --output filtered_variants/P1.avcf.gz --output-file-format VCF; > 15:16:39.460 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/pkus/programs/gatk-4.1.8.0/gatk-package-4.1.8.0-local.jar!/com/int",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6708:489,log,log,489,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6708,1,['log'],['log']
Testability,"## Bug Report. ### Affected tool(s) or class(es); GATK 4.1.0.0 AnalyzeCovariates. ### Affected version(s); - [x] Latest public release version [version?]; - [ ] Latest master branch as of [date of test?]. ### Description ; The csv produced by AnalyzeCovariates is invalid. It doesn't escape commas in fields, resulting in an error in the R script. #### Steps to reproduce; If you have a comma in the readgroup in a BAM, this will happen. #### Expected behavior; It should produce valid csv files, and then be able to properly produce the plots. #### Actual behavior; Commas in read group names result in malformed (unescaped) csv where it's impossible to parse fields properly. This results in the following R script error:; ```; Error in read.table(file = file, header = header, sep = sep, quote = quote, :; more columns than column names; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5739:197,test,test,197,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5739,1,['test'],['test']
Testability,"## Bug Report. ### Affected tool(s) or class(es); GATK GenotypeGVCFs. ### Affected version(s); GATK 4.2.2.0. ### Description . When running GenotypeGVCFs,; 1. multiple warnings of **No valid combination operation found for INFO field** ; 2. AS_VarDP warnings:; ```; WARN ReferenceConfidenceVariantContextMerger - Detected invalid annotations: When trying to merge variant contexts at location chr16:10185 the annotation AS_VarDP=59|115|0 was not a numerical value and was ignored; WARN ReferenceConfidenceVariantContextMerger - Reducible annotation 'AS_VarDP' detected, add -G StandardAnnotation -G AS_StandardAnnotation to the command to annotate in the final VC with this annotation.; ```. 3. java.lang.NullPointerException occurs. ; 4. No variants output into VCF. This is the log:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx60g -jar /share/pkg.7/gatk/4.2.0.0/install/bin/gatk-package-4.2.0.0-local.jar GenotypeGVCFs -R /restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa -G StandardAnnotation -G AS_StandardAnnotation -V gendb:///restricted/projectnb/kageproj/gatk/genomicsdb/genomicsDB.chr16 -L chr16:1-105581 --use-new-qual-calculator --only-output-calls-starting-in-intervals TRUE --genomicsdb-shared-posixfs-optimizations TRUE --tmp-dir tmp -O chr16-1-105581.vcf.gz; 00:05:54.259 WARN GATKAnnotationPluginDescriptor - Redundant enabled annotation group (StandardAnnotation) is enabled for this tool by default; 00:05:54.319 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/share/pkg.7/gatk/4.2.0.0/install/bin/gatk-package-4.2.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Aug 25, 2021 12:05:54 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 00:05:54.582 INFO GenotypeGVCFs - -------------------",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7437:780,log,log,780,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7437,1,['log'],['log']
Testability,"## Bug Report. ### Affected tool(s) or class(es); GATK Haplotype caller. ### Affected version(s); - [x] Latest public release version [4.1.0.0]; - [ ] Latest master branch as of [date of test?]. The Genome Analysis Toolkit (GATK) v4.1.0.0; HTSJDK Version: 2.18.2; Picard Version: 2.18.25. ### Description ; HaplotypeCaller is outputting variants which have a no-call as the ALT, which breaks a bunch of downstream tools, this is new behavior in 4.1, AFAICT. ```; #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	s1564	s1741	s1851	s1852	s1862	s1901	s1912	s1971	s2017	s2021	s2026	s2056	s2100	s2102	s2104	s2122	s2124	s2151	s2157; 1	937796	.	T	.	179.65	.	AN=38;DP=31;MMQ=60;MQ=60.00	GT:AD:DP	0/0:0:0	0/0:0:0	0/0:4:4	0/0:0:0	0/0:1:1	0/0:1:1	0/0:0:0	0/0:0:0	0/0:2:2	0/0:0:0	0/0:1:1	0/0:3:3	0/0:1:1	0/0:8:8	0/0:1:1	0/0:0:0	0/0:2:2	0/0:7:7	0/0:0:0; ```. #### Steps to reproduce; I'm not doing anything special, so I suspect these variants should exist in other projects as well. I'm doing batch calling on several samples simultaneously; an example:. ```; unset JAVA_HOME && export PATH=/home/rdk4/local/share/bcbio/anaconda/bin:$PATH && gatk --java-options '-Xms4g -Xmx5000m -XX:+UseSerialGC -Djava.io.tmpdir=/n/data1/cores/bcbio/PIs/rudy_tanzi/tau-exome/tau-variants/work/bcbiotx/tmpTSg0hJ' HaplotypeCaller -R /n/app/bcbio/dev/genomes/Hsapiens/GRCh37/seq/GRCh37.fa --annotation MappingQualityRankSumTest --annotation MappingQualityZero --annotation QualByDepth --annotation ReadPosRankSumTest --annotation RMSMappingQuality --annotation BaseQualityRankSumTest --annotation FisherStrand --annotation MappingQuality --annotation DepthPerAlleleBySample --annotation Coverage -I /n/data1/cores/bcbio/PIs/rudy_tanzi/tau-exome/tau-variants/work/align/s2017/s2017-sort.bam -I /n/data1/cores/bcbio/PIs/rudy_tanzi/tau-exome/tau-variants/work/align/s2056/s2056-sort.bam -I /n/data1/cores/bcbio/PIs/rudy_tanzi/tau-exome/tau-variants/work/align/s2122/s2122-sort.bam -I /n/data1/cores/bcbio/PIs/rudy_tanzi/tau-exome/tau-var",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5650:187,test,test,187,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5650,1,['test'],['test']
Testability,"## Bug Report. ### Affected tool(s) or class(es); GATK v4.1.4.0 using FilterMutectCalls. ### Affected version(s); - [x] Latest public release version `4.1.4.0` installed from conda release `gatk4-4.1.4.0-1`; - [ ] Latest master branch as of [date of test?]. ### Description ; This issue reports the same error that is reported in #6237, but on the latest release, and in a mitochondrial calling setting. My command is:; ```bash; gatk FilterMutectCalls -V MT.vcf.gz\; -R human_g1k_v37.main.fasta\; -O MT.filtered.vcf.gz\; --stats MT.vcf.gz.stats\; --mitochondria-mode; ```. I get the following output to STDERR:; ```; 11:15:57.152 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/warkre/miniconda3/envs/gatk4.1.4.0/share/gatk4-4.1.4.0-1/gatk-package-4.1.4.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Nov 07, 2019 11:15:57 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 11:15:57.328 INFO FilterMutectCalls - ------------------------------------------------------------; 11:15:57.328 INFO FilterMutectCalls - The Genome Analysis Toolkit (GATK) v4.1.4.0; 11:15:57.328 INFO FilterMutectCalls - For support and documentation go to https://software.broadinstitute.org/gatk/; 11:15:57.328 INFO FilterMutectCalls - Executing as warkre@fuji on Linux v4.9.0-9-amd64 amd64; 11:15:57.328 INFO FilterMutectCalls - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_192-b01; 11:15:57.329 INFO FilterMutectCalls - Start Date/Time: November 7, 2019 11:15:57 AM CET; 11:15:57.329 INFO FilterMutectCalls - ------------------------------------------------------------; 11:15:57.329 INFO FilterMutectCalls - ------------------------------------------------------------; 11:15:57.329 INFO FilterMutectCalls - HTSJDK Version: 2.20.3; 11:15:57.329 INFO FilterMutectCalls - Picard Version: 2.21.1; 11:15:57.329 INFO FilterMutectCalls - HTSJDK Defaults.COMPRESSION_LEVEL : ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6255:250,test,test,250,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6255,1,['test'],['test']
Testability,"## Bug Report. ### Affected tool(s) or class(es); GATK version: 4.1.1.0-VariantRecalibrator-ApplyVQSR. ### Affected version(s); - [ ] Latest public release version [version?]; - [ ] Latest master branch as of [date of test?]. ### Description ; I am doing VQSR with gatk-VariantRecalibrator-ApplyVQSR, and i got some mistakes in the log file， and i dont konw what was wrong with my script,. #### Steps to reproduce; Below are my complete scripts:; java -Xmx3990m -Djava.io.tmpdir=/gss1/home/ldl20190322/a_haoxiaoshuai/JavaTmpDir -jar /gss1/home/ldl20190322/a_haoxiaoshuai/z_software/gatk/gatk-4.1.1.0/gatk-package-4.1.1.0-local.jar VariantRecalibrator -R Gmax_275_v2.0.fa --variant Ztem.gatk.vcf.gz --resource:hapmap,known=false,training=true,truth=true,prior=10.0 final.intersected.snp.vcf.gz -an QD -an MQ -an MQRankSum -an ReadPosRankSum -an FS -an SOR -an DP -mode SNP -O Ztem.gatk.snp.recal --tranches-file Ztem.gatk.snp.tranches --rscript-file Ztem.gatk.snp.plots.R -tranche 90.0 -tranche 92.0 -tranche 94.0 -tranche 96.0 -tranche 97.0 -tranche 98.0 -tranche 99.0 -tranche 99.9; java -Xmx3990m -Djava.io.tmpdir=/gss1/home/ldl20190322/a_haoxiaoshuai/JavaTmpDir -jar /gss1/home/ldl20190322/a_haoxiaoshuai/z_software/gatk/gatk-4.1.1.0/gatk-package-4.1.1.0-local.jar ApplyVQSR -R Gmax_275_v2.0.fa -V Ztem.gatk.vcf.gz --truth-sensitivity-filter-level 99.0 --tranches-file Ztem.gatk.snp.tranches --recal-file Ztem.gatk.snp.recal -mode SNP -O Ztem.gatk.snp.vcf.gz. #### Expected behavior; _Tell us what should happen_. #### Actual behavior; Below is the message of the mistakes and i just omitted some no use information in the log file:; .; .; .; 15:51:14.040 INFO VariantRecalibratorEngine - Evaluating full set of 3660 variants...; 15:51:15.156 INFO VariantRecalibratorEngine - Evaluating full set of 3660 variants...; 15:51:15.373 INFO VariantRecalibrator - Building FS x ReadPosRankSum plot...; 15:51:15.374 INFO VariantRecalibratorEngine - Evaluating full set of 3660 variants...; 15:51:16.493 INF",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6948:218,test,test,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6948,2,"['log', 'test']","['log', 'test']"
Testability,"## Bug Report. ### Affected tool(s) or class(es); GATKProtectedVariantContextUtils.chooseAlleleForRead(...). ### Affected version(s); Latest master branch as of [July 27, 2018]. ### Description ; This method has no facility for recognizing equivalent alleles in a read. For example:. Let's say we have a pileup with a single base insertion (of 'T') after an 'A' in a poly-T.; In IGV, the reads will all show the insertion right after the A.; However, if the caller said ref alt was AT --> ATT, then `chooseAlleleForRead` will miss the supporting alts in the validation normal, since it needed A --> AT. However, AT-->ATT and A --> AT are equivalent. See ValidateBasicSomaticShortMutationsIntegrationTest line ~151 for the corresponding TODO and a test case. #### Steps to reproduce; Leverage the existing test (`ValidateBasicSomaticShortMutationsIntegrationTest`) and change the gtNumAltReadsInValidationNormal to 1, instead of zero. #### Expected behavior; The test should pass. #### Actual behavior; The test will fail expecting zero.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5061:747,test,test,747,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5061,4,['test'],['test']
Testability,"## Bug Report. ### Affected tool(s) or class(es); GenomicsDBImport . ### Affected version(s); - [ ] Latest public release version [version?]; - [x] Latest master branch as of Apr 4, 2022. ### Description ; [E::faidx_adjust_position] The sequence ""chrX"" was not found; [E::faidx_adjust_position] The sequence ""chrX"" was not found; [E::faidx_adjust_position] The sequence ""chrX"" was not found; [E::faidx_adjust_position] The sequence ""chrX"" was not found. #### Steps to reproduce; Run the first test case for GnarlyGenotyperIntergrationTest::testUsingGenomicsDB() on the branch https://github.com/broadinstitute/gatk/pull/7750. The test contains the argument `--intervals chrX:1000000-5000000`, but I'm not sure why that would be an issue. The tool runs fine and the output is valid. #### Expected behavior; An informative warning or a single output of the existing warning. #### Actual behavior; Excessive logging",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7751:493,test,test,493,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7751,4,"['log', 'test']","['logging', 'test', 'testUsingGenomicsDB']"
Testability,"## Bug Report. ### Affected tool(s) or class(es); GenomicsDBImport. ### Affected version(s); - [ ] Latest public release version [4.2.5.0]. ### Description ; My gVCF files are block compressed and indexed, but the files have the file extension "".gvcf.gz"" rather than "".vcf.gz"". When I run `GenomicsDBImport` with `--bypass-feature-reader`, the "".gvcf.gz"" file cannot be recognized as a block compressed vcf file. The code of `GenomicsDBImport` validates if input is block compressed by checking if the file extension is "".vcf.gz"". ```; private static void assertVariantFileIsCompressedAndIndexed(final Path path) {; if (!path.toString().toLowerCase().endsWith(FileExtensions.COMPRESSED_VCF)) {; throw new UserException(""Input variant files must be block compressed vcfs when using "" +; BYPASS_FEATURE_READER + "", but "" + path.toString() + "" does not appear to be"");; }; Path indexPath = path.resolveSibling(path.getFileName() + FileExtensions.COMPRESSED_VCF_INDEX);; IOUtils.assertFileIsReadable(indexPath);; }; ```. I understand that this is an issue on my side because I did not name my gVCF files with the standard extension "".vcf.gz"". Is it possible to make this check less stringent in a future release? Maybe make any "".gz""/"".bgz"" file acceptable, or check the "".tbi"" index file to identify block compression (existing index typically means the file is block compressed and indexed). . Thank you. . ----",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7691:556,assert,assertVariantFileIsCompressedAndIndexed,556,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7691,2,['assert'],"['assertFileIsReadable', 'assertVariantFileIsCompressedAndIndexed']"
Testability,"## Bug Report. ### Affected tool(s) or class(es); GenomicsDBImport. ### Affected version(s); - [ ] Public release version 4.1.4.1 . ### Description ; Running GenomicsDBImport on an HPC cluster using SLURM, admin mentioned that the jobs are writing inefficiently to shared storage (@spikebike will follow up with HPC specifics and logs). . #### Steps to reproduce; ```; Using GATK jar /share/apps/gatk-4.1.4.1/gatk-package-4.1.4.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx60g -Xms60g -jar /share/apps/gatk-4.1.4.1/gatk-package-4.1.4.1-local.jar GenomicsDBImport --genomicsdb-workspace-path data/interim/combined_database_bpres/0004 --batch-size 50 --reader-threads 6 --sample-name-map data/processed/sample_map --intervals data/processed/scattered_intervals/0004-scattered.intervals --tmp-dir /scratch/sdturner/genomicsdbimport/0004; ```. #### Expected behavior; My understanding is that it may be more efficient to use a small buffer and write the final database in full. . #### Actual behavior; Again my (limited) understanding is that the tool is writing output multiple times and throwing out all but the last write. Here is an example of a log for a 2.6 Mb region and 295 samples: ; ; ```; 07:24:39.198 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/share/apps/gatk-4.1.4.1/gatk-package-4.1.4.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Feb 28, 2020 7:24:39 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 07:24:39.616 INFO GenomicsDBImport - ------------------------------------------------------------; 07:24:39.617 INFO GenomicsDBImport - The Genome Analysis Toolkit (GATK) v4.1.4.1; 07:24:39.617 INFO GenomicsDBImport - For support and documentation go to https://software.broadinstitute.org/ga",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6487:330,log,logs,330,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6487,1,['log'],['logs']
Testability,"## Bug Report. ### Affected tool(s) or class(es); GenotypeGVCFs 4.0.0.12. ### Affected version(s); - [ ] Latest public release version [version?]; - [ ] Latest master branch as of [date of test?]. ### Description ; I've run into a weird case where GenotypeGVCFs is doing something unexpected. I have a gVCF with the following entry in it:. ```; chr11 6637739 . ATTTTT A,AT,ATT,ATTT,ATTTT,ATTTTTT,<NON_REF> 565.73 . BaseQRankSum=-0.014;ClippingRankSum=0.508;DP=94;ExcessHet=3.0103;MLEAC=0,0,0,1,0,0,0;MLEAF=0,0,0,0.5,0,0,0;MQRankSum=0;RAW_MQandDP=338400,94;REF_BASES=GCCGGCCTGGATTTTTTTTTT;ReadPosRankSum=-0.812 GT:AD:DP:F1R2:F2R1:GQ:PL:SB 0/4:9,3,3,11,15,8,3,0:52:8,2,2,8,12,6,3,0:1,1,1,3,3,2,0,0:56:603,504,1526,335,1171,1118,56,661,640,608,0,362,313,183,335,336,500,389,187,171,527,655,864,622,277,169,466,1026,597,1101,953,645,465,625,861,1133:8,1,33,10; ```. It's a messy site for sure, an indel in a long homopolymer-T, but I think that's a separate issue. If I run the following on that gVCF:. ```; gatk GenotypeGVCFs \; -R hg19.fa -V test.g.vcf -O test.vcf \; -A ClippingRankSumTest -A Coverage -A ExcessHet -A FisherStrand \; -A MappingQualityRankSumTest -A OxoGReadCounts -A QualByDepth -A ReadPosRankSumTest \; -A ReferenceBases -A RMSMappingQuality -A StrandOddsRatio -A TandemRepeat \; -L chr11:6637730-6637750 \; -stand-call-conf 18.0 \; ```. then I get the following output to the VCF just like I'd expect:. ```; chr11 6637739 . ATT A 565.73 . AC=1;AF=0.500;AN=2;BaseQRankSum=-1.400e-02;ClippingRankSum=0.508;DP=94;ExcessHet=3.0103;FS=1.779;MLEAC=1;MLEAF=0.500;MQ=60.00;MQRankSum=0.00;QD=23.57;REF_BASES=GCCGGCCTGGATTTTTTTTTT;RPA=15,13;RU=T;ReadPosRankSum=-8.120e-01;SOR=0.386;STR GT:AD:DP:F1R2:F2R1:GQ:PL 0/1:9,15:52:8,2,2,8,12,6,3,0:1,1,1,3,3,2,0,0:99:603,0,335; ```. QUAL is unchanged since I'm genotyping a single-sample gVCF. However, if I raise my `-stand-call-conf` threshold to 19.0, GenotypeGVCFs no longer outputs any variants. 565.73 >> 19.0, so I'm confused as to why that var",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5793:189,test,test,189,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5793,1,['test'],['test']
Testability,"## Bug Report. ### Affected tool(s) or class(es); GenotypeGVCFs with --keep-combined-raw-annotations. ### Affected version(s); - [x] Latest public release version [version?]; - [ ] Latest master branch as of (not tested). ### Description ; @ldgauthier was kind enough to introduce the `--keep-combined-raw-annotations` option for us after the discussion in issue #5698, and we've been using it extensively. We recently noticed a problem that affects a small fraction of variants though. We're noticing this with `AS_SB_TABLE` but it probably applies to all annotations that are per-allele or per-alt allele. The problem is that when GenotypeGVCFs runs it may chose to output only a subset of the alleles present in the gVCF. When it does this it does not appear to update the annotations to remove the values for the removed alleles. This results in annotations with more values than there are alleles, and no safe/predictable way to interpret those annotations since you don't know the original ordering of alleles and which ones were removed when looking at the resulting VCF. This is happening, in my case, primarily at homopolymer sites and occasionally at STRs with larger repeat units. I've attached a zip file - [AS_SB_TABLE_bug.zip](https://github.com/broadinstitute/gatk/files/3357101/AS_SB_TABLE_bug.zip) - which contains a one-record gVCF, the command to generate the VCF and the resulting VCF, which should be sufficient to demonstrate the problem and reproduce it. Here's what an offending variant looks like:. ```; chr1 100366446 . GTT G 562.64 . AC=1;AF=0.500;AN=2;AS_SB_TABLE=19,6|16,6|4,0|2,2|1,1;...;REF_BASES=ATGTTTTTTTGTTTTTTTTTT;RPA=13,11;RU=T;ReadPosRankSum=-1.296e+00;SOR=0.534;STR GT:AD:DP:F1R2:F2R1:GQ:PL 0/1:25,22:57:19,16:4,4:99:570,0,819; ```. #### Steps to reproduce; See attached zip file. #### Expected behavior; All per-allele and per-alt-allele annotations should be subsetted to only the values for the alleles that are output in the resulting VCF. #### Actual behavi",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6029:213,test,tested,213,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6029,1,['test'],['tested']
Testability,"## Bug Report. ### Affected tool(s) or class(es); GenotypeGVCFs. ### Affected version(s); - [x] Latest public release version [version?]; - [x] Latest master branch as of [date of test?]. ### Description ; GenotypeGVCFs won't joint call DRAGEN mitochondrial data because of the DRAGEN somatic output format. We should be able to use the DRAGEN SQ in place of Mutect2's TLOD (see line 279 in GenotypeGVCFsEngine); Note that DRAGEN SQ is a Phred-scaled double. #### Steps to reproduce; DRAGEN somatic GVCF entries from version 3.8.4 look like:; chrM 1 . G <NON_REF> . weak_evidence END=1 GT:AD:DP:SQ:MIN_DP 0/0:112,1579:1691:0:1691. Run GenotypeGVCFs with -V to a file like that (reference GenotypeGVCFsIntegrationTest::testGenotypingForSomaticGVCFs() for more details); Must include `--input-is-somatic` as of now. #### Expected behavior; The task should run to completion, calculating a site quality store using the DRAGEN SQ value. #### Actual behavior; Error from AlleleFrequencyCalculator about not having PLs or GQ.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7840:180,test,test,180,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7840,2,['test'],"['test', 'testGenotypingForSomaticGVCFs']"
Testability,"## Bug Report. ### Affected tool(s) or class(es); GenotypeGVCFs. ### Affected version(s); GATK4.1.4.0. ### Description ; QUAL is 0 for hom_ref sites. We need detailed information for specific sites, whether or not those sites are mutated. But now these normal hom ref sites look like low qual sites. #### Steps to reproduce; gatk GenotypeGVCFs -R hg38.fa -V test.g.vcf.gz -O out.vcf -stand-call-conf 0 -all-sites -L chr1:14619-14643. #### Expected behavior; gatk-4.0.12.0; ```; #CHROM POS ID REF ALT QUAL FILTER INFO FORMAT AMCUGVCJTB; chr1 14619 . G . 70.23 . DP=15 GT:AD:DP:RGQ 0/0:15,0:15:42; chr1 14620 . C . 70.23 . DP=15 GT:AD:DP:RGQ 0/0:15,0:15:42; chr1 14621 . A . 76.23 . DP=16 GT:AD:DP:RGQ 0/0:16,0:16:48; chr1 14622 . G . 76.23 . DP=16 GT:AD:DP:RGQ 0/0:16,0:16:48; chr1 14623 . C . 76.23 . DP=16 GT:AD:DP:RGQ 0/0:16,0:16:48; chr1 14624 . T . 76.23 . DP=16 GT:AD:DP:RGQ 0/0:16,0:16:48; chr1 14625 . T . 76.23 . DP=16 GT:AD:DP:RGQ 0/0:16,0:16:48; chr1 14626 . G . 76.23 . DP=16 GT:AD:DP:RGQ 0/0:16,0:16:48; chr1 14627 . T . 76.23 . DP=16 GT:AD:DP:RGQ 0/0:16,0:16:48; chr1 14628 . C . 85.23 . DP=19 GT:AD:DP:RGQ 0/0:19,0:19:57; chr1 14629 . C . 85.23 . DP=19 GT:AD:DP:RGQ 0/0:19,0:19:57; chr1 14630 . T . 88.23 . DP=20 GT:AD:DP:RGQ 0/0:20,0:20:60; chr1 14631 . G . 88.23 . DP=20 GT:AD:DP:RGQ 0/0:20,0:20:60; chr1 14632 . G . 88.23 . DP=20 GT:AD:DP:RGQ 0/0:20,0:20:60; chr1 14633 . C . 85.23 . DP=20 GT:AD:DP:RGQ 0/0:20,0:20:57; chr1 14634 . T . 85.23 . DP=20 GT:AD:DP:RGQ 0/0:20,0:20:57; chr1 14635 . G . 85.23 . DP=20 GT:AD:DP:RGQ 0/0:20,0:20:57; chr1 14636 . T . 88.23 . DP=21 GT:AD:DP:RGQ 0/0:21,0:21:60; chr1 14637 . G . 88.23 . DP=21 GT:AD:DP:RGQ 0/0:21,0:21:60; chr1 14638 . T . 88.23 . DP=21 GT:AD:DP:RGQ 0/0:21,0:21:60; chr1 14639 . C . 88.23 . DP=21 GT:AD:DP:RGQ 0/0:21,0:21:60; chr1 14640 . C . 88.23 . DP=21 GT:AD:DP:RGQ 0/0:21,0:21:60; chr1 14641 . A . 88.23 . DP=21 GT:AD:DP:RGQ 0/0:21,0:21:60; chr1 14642 . T . 88.23 . DP=21 GT:AD:DP:RGQ 0/0:21,0:21:60; chr1 14643 . G . 100.23 .",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6309:358,test,test,358,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6309,1,['test'],['test']
Testability,"## Bug Report. ### Affected tool(s) or class(es); GermlineCNVCaller . ### Affected version(s); v4.0.4.0 and v4.0.11.0 tested with same result. ### Description ; ![screenshot 2018-11-02 14 50 17](https://user-images.githubusercontent.com/11543866/47934764-a8a71c80-deae-11e8-9f8f-c8a8b563d77a.png). ```; java.lang.IllegalArgumentException: Intervals for read-count file /home/shlee/gcnv/cvg/HG00096_chr20XY.hdf5 do not contain all specified intervals.; at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:724); at org.broadinstitute.hellbender.tools.copynumber.GermlineCNVCaller.writeIntervalSubsetReadCountFiles(GermlineCNVCaller.java:390); at org.broadinstitute.hellbender.tools.copynumber.GermlineCNVCaller.doWork(GermlineCNVCaller.java:285); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289); ```. Command runs fine sans `-XL` parameter. The contents of `-XL` are simply:. ![screenshot 2018-11-02 14 51 58](https://user-images.githubusercontent.com/11543866/47934827-e0ae5f80-deae-11e8-891e-473ec8420433.png). #### Expected behavior; It would be great to be able to iterate GermlineCNVCaller on coverage data while excluding various regions, e.g. centromeric regions, to test the impact of such regions on the denoising. Currently, the hypothetical workaround would be to collect coverage while excluding regions or to manually remove such intervals from the coverage data. Having to collect coverage once over all of the data is preferable to collecting coverage again and again over slightly variable regions.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5388:118,test,tested,118,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5388,2,['test'],"['test', 'tested']"
Testability,"## Bug Report. ### Affected tool(s) or class(es); GermlineCNVCaller. ### Affected version(s); - [x] Latest public release version [4.5.0.0]; - [x] Latest master branch as of [14.12.2023]. ### Description ; Very different results after update from 4.4.0.0 to 4.5.0.0. We updated test results after https://github.com/broadinstitute/gatk/issues/8619, but now we see big changes (especially in `segments` file). #### Steps to reproduce; Command list:; ```; /soft/gatk-4.5.0.0/gatk PreprocessIntervals -R /ref/GRCh38.d1.vd1/GRCh38.d1.vd1.fa --padding 0 -L chr1:10000-35000 -L chr22:198477-20003000 -imr OVERLAPPING_ONLY -O /outputs/gatk_intervals.interval_list. /soft/gatk-4.5.0.0/gatk AnnotateIntervals -L /outputs/gatk_intervals.interval_list -R /ref/GRCh38.d1.vd1/GRCh38.d1.vd1.fa -imr OVERLAPPING_ONLY -O /outputs/gatk_intervals.interval_list.annotated.tsv. /soft/gatk-4.5.0.0/gatk CollectReadCounts -I /inputs/E07002_normal_alignment.bam -R /ref/GRCh38.d1.vd1/GRCh38.d1.vd1.fa -L /outputs/gatk_intervals.interval_list --interval-merging-rule OVERLAPPING_ONLY -O /outputs/E07002_normal_alignment.bam.counts.hdf5; /soft/gatk-4.5.0.0/gatk CollectReadCounts -I /inputs/E07002_tumor_alignment.bam -R /ref/GRCh38.d1.vd1/GRCh38.d1.vd1.fa -L /outputs/gatk_intervals.interval_list --interval-merging-rule OVERLAPPING_ONLY -O /outputs/E07002_tumor_alignment.bam.counts.hdf5. /soft/gatk-4.5.0.0/gatk DetermineGermlineContigPloidy -L /outputs/gatk_intervals.interval_list --interval-merging-rule OVERLAPPING_ONLY --contig-ploidy-priors /outputs/a_valid_ploidy_priors_table.tsv.copy.tsv --output /outputs/COHORT_runDir --output-prefix COHORT --input /outputs/E07002_normal_alignment.bam.counts.hdf5 --input /outputs/E07002_tumor_alignment.bam.counts.hdf5. /soft/gatk-4.5.0.0/gatk GermlineCNVCaller --run-mode COHORT -L /outputs/gatk_intervals.interval_list --interval-merging-rule OVERLAPPING_ONLY --annotated-intervals /outputs/gatk_intervals.interval_list.annotated.tsv --contig-ploidy-calls /outputs/COHORT_run",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8628:278,test,test,278,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8628,1,['test'],['test']
Testability,"## Bug Report. ### Affected tool(s) or class(es); GnarlyGenotyper. ### Affected version(s); - [ ] Latest public release version [version?]; - [ ] Latest master branch as of [date of test?]; - [x] 4.2.3 - snapshot -> https://console.cloud.google.com/gcr/images/broad-dsde-methods/US/gatk_subset_dragen_allele_frac@sha256:f5e93bda2278f1c999bd9def027c6851eeb098736b47a93469c524863b46c21f/details. ### Description ; WDL joint genotyping using GnarlyGenotyper after ReblockGVCF (fixed on the snapshot above). #### Steps to reproduce; Joint Genotyper wdl pipeline with ""GatkJointGenotyping.useGnarlyGenotyper"": true , **samples from DRAGEN 3.8+**. #### Expected behavior; Complete the pipeline. #### Actual behavior; Failing with diploid error on Sexual Chromosomes. Hello again everyone.; First of all, thank you @ldgauthier to send us that snapshot docker. It kind of solved reblock problem. As feedback here, I tried with the newest GATK version (4.2.5) as it modified ReblockGVCF, but it didn`t work.; Anyway, I have another issue here...; While I was using only one or few chromosomes, the pipeline with reblock + gnarly was working fine. Once I added all chromosomes I started to get this type of error (GnarlyGenotyper):. ```; A USER ERROR has occurred: Bad input: This tool assumes diploid genotypes, but sample NA18668 has ploidy 1 at position chrY:2789135. or. A USER ERROR has occurred: Bad input: This tool assumes diploid genotypes, but sample NA14734 has ploidy 1 at position chrX:36667858. ```; I checked every failed log, and it's all related to the sexual chromosomes. Any thought/tip about that? ; ps.: From chr1 to chr22 it worked fine!",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7690:182,test,test,182,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7690,2,"['log', 'test']","['log', 'test']"
Testability,"## Bug Report. ### Affected tool(s) or class(es); HaplotypeCaller --output-mode EMIT_ALL_SITES. ### Affected version(s); - [x] Latest public release version [version?]; - [ ] Latest master branch as of [date of test?]. ### Description ; I'm trying to generate a VCF (not a gVCF) that contains calls spanning all the sites in my regions. Each region is small, and is more or less equivalent to a single variant. Ideally I'd use `GENOTYPE_GIVEN_ALLELES`, but I don't know the alleles, and in some cases the variant location is approximate (e.g. somewhere in _this_ 10bp window). I've been trying to use HaplotypeCaller to produce a VCF that contains calls covering my entire set of regions, but nothing seems to work. I started with just `--output-mode` and eventually ended up with:. ```; gatk HaplotypeCaller \; -R ref.fasta \; -L regions.interval_list \; --disable-optimizations \; --force-active \; --output-mode EMIT_ALL_SITES \; -I my.bam \; -O my.vcf.gz; ```. This does output considerably more records, including a lot of hom-ref records, but still nowhere near to the full set of bases within my regions. E.g. in one test this emits variants spanning 3,468bp which is way better than the ~120bp I get without those options, but nowhere near the 293,570bp with the regions I'm supplying. It would be great if `--output-mode EMIT_ALL_SITES` did as the documentation described, but if that's not possible, then perhaps that mode should simply be removed?. #### Steps to reproduce; Try calling a BAM file with HaplotypeCaller with a 100-1000bp region with `--output-mode EMIT_ALL_SITES`. #### Expected behavior; VCF should contain records spanning the entire input region. #### Actual behavior; VCF contains a minority of sites from the region.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6059:211,test,test,211,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6059,2,['test'],['test']
Testability,"## Bug Report. ### Affected tool(s) or class(es); HaplotypeCaller . ### Affected version(s); - [x] Latest public release version [4.1.6.0]; - [ ] Latest master branch (not tested). ### Description ; I have a sample that has a slightly complicated event in it that is getting miscalled. The easiest way to see it is probably with an IGV screenshot:. ![variant](https://user-images.githubusercontent.com/1609210/78403555-c6077b00-75b9-11ea-96f3-8f9ca6c25e86.png). BWA aligns the reads with a 7bp deletion followed by 2 mismatches, though am inclined to think of it as a 9bp deletion coupled with a 2bp insertion (or a swap of 9bp of reference for 2bp of novel sequence). The original alignments are in the top half of the IGV view. The bottom is the assembly BAM from running the HaplotypeCaller. From what I see the assembly is getting it right. . But the problem is that the event extraction/genotyping goes wrong. I've run it two ways. If I run to generate a called VCF directly using:. ```; gatk HaplotypeCaller \; --input snippet.bam \; --output snippet.vcf \; -R hg19/hg19.fa \; --bam-output assembly.bam \; -L chr1:68896800-68896900 \; --ploidy 2 \; --min-pruning 2 \; --min-dangling-branch-length 2 \; --pcr-indel-model CONSERVATIVE ; ```. Then I get only a single variant reported in the region (the 9bp deletion):. ```; #CHROM POS ID REF ALT QUAL FILTER INFO FORMAT test-sample; chr1 68896832 . CTTTAGTTTT C 1597.60 . AC=1;AF=0.500;AN=2;BaseQRankSum=0.000;DP=122;ExcessHet=3.0103;FS=0.000;MLEAC=1;MLEAF=0.500;MQ=60.00;MQRankSum=0.000;QD=14.52;ReadPosRankSum=1.341;SOR=0.350 GT:AD:DP:GQ:PL 0/1:67,43:110:99:1605,0,2683; ```. If i run to generate a gvcf then things get more interesting:. ```; gatk HaplotypeCaller \; --input snippet.bam \; --output snippet.g.vcf \; -R hg19/hg19.fa \; -ERC GVCF \; --bam-output assembly.bam \; -L chr1:68896800-68896900 \; --ploidy 2 \; --min-pruning 2 \; --min-dangling-branch-length 2 \; --pcr-indel-model CONSERVATIVE ; ```. yields:. ```; #CHROM POS ID REF A",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6538:172,test,tested,172,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6538,1,['test'],['tested']
Testability,"## Bug Report. ### Affected tool(s) or class(es); HaplotypeCaller 4.1 with -ERC GVCF. ### Affected version(s); - [x] Latest public release version [version?]; - [ ] Latest master branch as of [date of test?]. ### Description ; It would appear that variants covered by a spanning deletion are not output with phasing information even when surrounded by phased variants on either side. Since one of the alleles is covered by an upstream deletion phase is known, but the genotype itself is not phased and no phase set is attached. The following is a cut-down example from a gVCF:. ```; chr6 51618169 . GT G,<NON_REF> 948.60 . DP=94 GT:AD:DP:F1R2:F2R1:GQ:PGT:PID:PL:PS:SB 0|1:32,39,0:71:3,4,0:29,35,0:99:0|1:51618169_GT_G:956,0,808,1054,926,1980:51618169:3,29,4,35; chr6 51618170 . T *,G,<NON_REF> 776.01 . DP=92 GT:AD:DP:F1R2:F2R1:GQ:PL:SB 1/2:2,39,30,0:71:1,4,2,0:1,35,28,0:99:3533,786,723,1141,0,956,2837,916,1206,2757:1,1,6,63; chr6 51618171 . G <NON_REF> . . END=51618173 GT:DP:GQ:MIN_DP:PL 0/0:90:99:90:0,120,1800; chr6 51618174 . A G,<NON_REF> 1001.60 . DP=89 GT:AD:DP:F1R2:F2R1:GQ:PGT:PID:PL:PS:SB 0|1:33,41,0:74:3,4,0:30,37,0:99:0|1:51618169_GT_G:1009,0,803,1108,926,2034:51618169:3,30,4,37; ```. You can see that the SNP at 51618170 is flanked by phased variants at 51618169 and 51618174, but is output with unphased genotype and no `PS` (or `PID/PGT`). I'm not entirely sure if this is on purpose for some reason I don't understand, or simply an edge case in the phasing code that's handled incorrectly. #### Steps to reproduce; Run HC on reads with three variants, starting with a deletion, a variant spanned by the deletion and a variant just beyond the deletion. FWIW I've requested permission to share an example case from real data and am awaiting an answer. #### Expected behavior; I think the spanned variant should be output with phasing information, e.g. in the above case I would expect (abbreviated):. ```; chr6 51618169 . GT G,<NON_REF> ... GT:DP:PS 0|1:71:51618169; chr6 51618170 .",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5651:201,test,test,201,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5651,1,['test'],['test']
Testability,"## Bug Report. ### Affected tool(s) or class(es); HaplotypeCaller 4.1.1.0. ### Affected version(s); - [x] Latest public release version; - [x] Latest master branch as of 3/31/2019. ### Description ; It looks like PR #5840 did a lot of refactoring to the way F1R2/F2R1 annotations are computed. Along the way it looks like `OxoGReadCounts` was renamed to `OrientationBiasReadCounts`. This is, unfortunately for some, a non-backwards compatible change as any pipeline that uses `-A OxoGReadCounts` will now fail. I'm not sure if there's a deprecation mechanism for annotations that would inform users of this, and I'm not sure there's a whole lot to be done at this point. I'm logging this issue mainly so anyone else who runs into this will find the answer quickly. Might be nice to add a line to the 4.1.1.0 release notes though noting this change.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5848:675,log,logging,675,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5848,1,['log'],['logging']
Testability,"## Bug Report. ### Affected tool(s) or class(es); HaplotypeCaller GVCF mode. ### Affected version(s); GATK 4.1.8.0 . ### Description ; Discussed on the GATK forum: https://gatk.broadinstitute.org/hc/en-us/community/posts/360072760032-HaplotypeCaller-NullPointerException-Error. Command: ; `gatk --java-options ""-Xmx4g"" HaplotypeCaller -R hg19.fa.gz -I test.bam -O test.g.vcf.gz -ERC GVCF`. #### Stack Trace. ```; 17:08:11.229 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/zepengmu/tools/gatk-4.1.8.0/gatk-package-4.1.8.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Aug 27, 2020 5:08:12 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 17:08:12.021 INFO HaplotypeCaller - ------------------------------------------------------------; 17:08:12.028 INFO HaplotypeCaller - The Genome Analysis Toolkit (GATK) v4.1.8.0; 17:08:12.028 INFO HaplotypeCaller - For support and documentation go to https://software.broadinstitute.org/gatk/; 17:08:12.038 INFO HaplotypeCaller - Executing as zepengmu@midway2-0243.rcc.local on Linux v3.10.0-1127.8.2.el7.x86_64 amd64; 17:08:12.038 INFO HaplotypeCaller - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_45-b14; 17:08:12.039 INFO HaplotypeCaller - Start Date/Time: August 27, 2020 5:08:11 PM CDT; 17:08:12.039 INFO HaplotypeCaller - ------------------------------------------------------------; 17:08:12.039 INFO HaplotypeCaller - ------------------------------------------------------------; 17:08:12.039 INFO HaplotypeCaller - HTSJDK Version: 2.22.0; 17:08:12.039 INFO HaplotypeCaller - Picard Version: 2.22.8; 17:08:12.039 INFO HaplotypeCaller - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 17:08:12.040 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 17:08:12.040 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 17:08:12.040 INFO HaplotypeCal",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6783:352,test,test,352,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6783,2,['test'],['test']
Testability,"## Bug Report. ### Affected tool(s) or class(es); HaplotypeCaller `--annotation OrientationBiasReadCounts`. ### Affected version(s); - [ ] Latest public release version [4.3.0.0]; - [ ] 4.2.2.0. ### Description; When specifying OrientationBiasReadCounts, HaplotypeCaller adds the description of F1R2 and F2R1 to the header, but does not calculate them. This was observed in GATK 4.2.2.0 and also in a test with 4.3.0.0 (the latest at the moment of this issue).; ```; ##fileformat=VCFv4.2; ##FILTER=<ID=LowQual,Description=""Low quality"">; ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Allelic depths for the ref and alt alleles in the order listed"">; ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Approximate read depth (reads with MQ=255 or with bad mates are filtered)"">; ##FORMAT=<ID=F1R2,Number=R,Type=Integer,Description=""Count of reads in F1R2 pair orientation supporting each allele"">; ##FORMAT=<ID=F2R1,Number=R,Type=Integer,Description=""Count of reads in F2R1 pair orientation supporting each allele"">; ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Genotype Quality"">; ```. ```; #CHROM POS ID REF ALT QUAL FILTER INFO FORMAT sample; 13 32911888 . A G 177.64 . AC=1;AF=0.500;AN=2;BaseQRankSum=0.086;DP=21;ExcessHet=3.0103;FS=1.719;MLEAC=1;MLEAF=0.500;MQ=60.00;MQRankSum=0.000;QD=8.46;ReadPosRankSum=0.475;SOR=0.368 GT:AD:DP:GQ:PL 0/1:13,8:21:99:185,0,339; 13 32913055 . A G 402.06 . AC=2;AF=1.00;AN=2;DP=15;ExcessHet=3.0103;FS=0.000;MLEAC=2;MLEAF=1.00;MQ=60.00;QD=26.80;SOR=1.112 GT:AD:DP:GQ:PL 1/1:0,15:15:45:416,45,0; 13 32915005 . G C 378.06 . AC=2;AF=1.00;AN=2;DP=13;ExcessHet=3.0103;FS=0.000;MLEAC=2;MLEAF=1.00;MQ=60.00;QD=29.08;SOR=1.179 GT:AD:DP:GQ:PL 1/1:0,13:13:39:392,39,0; 13 32929232 . A G 168.64 . AC=1;AF=0.500;AN=2;BaseQRankSum=1.335;DP=16;ExcessHet=3.0103;FS=0.000;MLEAC=1;MLEAF=0.500;MQ=60.00;MQRankSum=0.000;QD=15.33;ReadPosRankSum=-1.442;SOR=0.446 GT:AD:DP:GQ:PL 0/1:5,6:11:99:176,0,121; 13 32929387 . T C 209.02 . AC=2;AF=1.00;AN=2;DP=7;ExcessHet=3.0103;FS=0.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8149:401,test,test,401,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8149,1,['test'],['test']
Testability,"## Bug Report. ### Affected tool(s) or class(es); HaplotypeCaller when emitting physical phasing. ### Affected version(s); - [x] Latest public release version [4.1.4.1]; - [ ] Latest master branch as of [n/a]. ### Description ; When there are three SNPs in close proximity with the first having a homozygous-alt genotype and the other two being hets that are in trans, the GATK incorrectly outputs genotypes and phasing indicating they are in cis. I haven't tested more broadly (e.g. with > 3 variants or with indels etc.) but my suspicion is that it is to do with the first variant in the phase set being homozygous. This was seen happening on real data from a real sample, but I have also been able to reproduce this with synthetic test data that I can attach here. #### Steps to reproduce; I've attached [phasing.zip](https://github.com/broadinstitute/gatk/files/4237216/phasing.zip) to this issue. It contains a BAM file of synthetic data where I've introduced two variant haplotypes at 50 locations each separated by about 1000 bases. My goal in doing this was just to have a number of different sequence contexts and variant alleles in case that affected anything. It also contains the resulting VCF from running this GATK command using 4.1.4.1:. ```; gatk HaplotypeCaller -I phasing.bam -O phasing.g.vcf -ERC GVCF \; -R hg19.fasta -L chr2:179390700-179672150; ```. While the BAM clearly shows the two hets as in trans with one another:; ![hom_with_in_trans_hets](https://user-images.githubusercontent.com/1609210/75055826-edcfd300-5492-11ea-8bb7-b3c492140797.png). The resulting variant calls are given as in-cis:. ```; chr2 179393825 . C A,<NON_REF> 2686.03 . DP=60;ExcessHet=3.0103;MLEAC=2,0;MLEAF=1.00,0.00;RAW_MQandDP=216000,60 GT:AD:DP:GQ:PGT:PID:PL:PS:SB 1|1:0,60,0:60:99:0|1:179393825_C_A:2700,181,0,2700,181,2700:179393825:0,0,60,0; chr2 179393826 . T <NON_REF> . . END=179393826 GT:DP:GQ:MIN_DP:PL 0/0:60:99:60:0,120,1800; chr2 179393827 . T G,<NON_REF> 1386.60 . BaseQRankSum=0.000;DP",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6463:458,test,tested,458,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6463,2,['test'],"['test', 'tested']"
Testability,"## Bug Report. ### Affected tool(s) or class(es); HaplotypeCaller with `--max-mnp-distance` filter. ### Affected version(s); - [x] Latest public release version [4.1.0.0]; - [ ] Latest master branch as of [date of test?]. ### Description ; I think there's a problem with the StrandOddsRatio (SOR) annotation and the `--map-mnp-distance` flag. I'm looking at a small region of NA24143 (one of the GIAB samples). There's a pair of SNPs in very close proximity. When called without the MNP output I get a pair of variants as follows (some info removed for clarity), coordinates are HG19:. ```; chr4 5743509 . C T 5903.03 . FS=0.000;QD=25.36;SOR=9.825 GT:AD:DP:GQ:PL 1/1:0,135:135:99:5917,406,0; chr4 5743512 . T C 2766.60 . FS=0.000;QD=21.12;SOR=0.983 GT:AD:DP:GQ:PL 0/1:57,74:131:99:2774,0,2060; ```. I'm trying to get permission to share the BAM over this region, but the key information is that every single read that spans or is in proximity to these variants is on the R strand. There is zero F strand coverage. This seems reasonable. It's a bit odd to me that the first SNP which is hom-var has a SOR value of 9.825, but it's homozygous so it's more or less irrelevant. Looking at the code, I think the problem here is that the code avoids divide-by-zero errors by adding pseudo-counts of `1.0` to the table, which for homozygous variants with no coverage on one strand creates a weird situation. I think it would be better to just detect if _all_ coverage is on one strand and short-circuit the calculation, but I digress. The real problem comes when running with `--max-mnp-distance 5`. Then I get this single variant:. ```; chr4 5743509 . CTAT TTAC,TTAT 5506.10 . FS=0.000;QD=25.36;SOR=9.750 GT:AD:DP:GQ:PL 1/2:0,74,56:130:99:5523,2213,2060,3016,0,2774; ```. Now I have a het variant with an SOR of 9.75. This seems really wrong to me - note how FS is 0.0. Again all coverage of all alleles is on one strand. And the het SNP that forms part of this MNP had an SOR of 0.983 when called independen",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5698:214,test,test,214,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5698,1,['test'],['test']
Testability,"## Bug Report. ### Affected tool(s) or class(es); HaplotypeCaller. ### Affected version(s); - [?] Latest public release version [version?]; - [x] Latest master branch as of Sept 10, 2019. ### Description ; Contamination estimate doesn't appear to be taken into account for reference blocks in GVCFs. #### Steps to reproduce; I'm looking at expected integration test results with uncontaminated (src/test/resources/org/broadinstitute/hellbender/tools/haplotypecaller/expected.CEUTrio.HiSeq.WGS.b37.NA12878.calls.20.10100000-10150000.vcf) vs. 15% contaminated (src/test/resources/org/broadinstitute/hellbender/tools/haplotypecaller/expected.CEUTrio.HiSeq.WGS.b37.NA12878.CONTAMINATED.WITH.HCC1143.NORMALS.15PCT.20.10100000-10150000.postIndelRefConfUpdate.g.vcf). #### Expected behavior; Contaminated calls should have lower depth because the reads are being downsampled (in a biased way) by the contamination fraction. #### Actual behavior; In the expected HC integration test results I'm seeing for 0 contamination; 20 10132770 . A <NON_REF> . . END=10132770 GT:DP:GQ:MIN_DP:PL 0/0:57:99:57:0,120,1800. For 15% contamination:; 20 10132770 . A <NON_REF> . . END=10132770 GT:DP:GQ:MIN_DP:PL 0/0:56:99:56:0,120,1800. The pileup has 55 (I'm not going down the rabbit hole of the bonus reads), so I would expect the contaminated GVCF to have < 55 DP. The variants look good in some places and less good in others. Looking through the code, I don't see anywhere the contamination estimate would be used for reference confidence. I suspect @davidbenjamin has been harboring a desire to update the contamination model anyway.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6152:361,test,test,361,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6152,4,['test'],['test']
Testability,"## Bug Report. ### Affected tool(s) or class(es); HaplotypeCaller. ### Affected version(s); - [x] Latest public release version [4.1.8.1]; - [ ] Latest master branch as of [date of test?]. ### Description ; I have a sample with a complex variant that could be modeled either as a 1bp deletion followed by a 2bp MNP, or more likely as a 3bp deletion followed by a 2bp insertion (or, if you will, the replacement of three reference bases with two other bases). The changes are clearly visible in the following screenshot. The top track is the aligned/deduped BAM, and the bottom track is the assembly BAM generated by HaplotypeCaller:. ![missing-insertion igv-screenshot](https://user-images.githubusercontent.com/1609210/93133361-516e5780-f694-11ea-9b7d-7aa71f5623cc.png). When I call this region to generate a gVCF I get some fairly strange output despite HC clearly reconstructing the haplotype correctly (some annotations removed for readability):. ```; #CHROM POS ID REF ALT QUAL FILTER INFO FORMAT test-sample; chr13 32953865 . T <NON_REF> . . END=32953884 GT:DP:GQ:MIN_DP:PL 0/0:204:99:196:0,120,1800; chr13 32953885 . AGTT A,<NON_REF> 3110.60 . DP=213;MLEAC=1,0;MLEAF=0.500,0.00 GT:AD:DP:GQ:PL:SB 0/1:108,82,0:1; chr13 32953888 . T *,TAA,<NON_REF> 585.02 . DP=205;MLEAC=0,0,2;MLEAF=NaN,NaN,1.00;RAW_MQandDP=738000,205 GT:GQ:PL ./.:99:0,0,0,0,0,0,0,0,0,0; chr13 32953889 . A <NON_REF> . . END=32953905 GT:DP:GQ:MIN_DP:PL 0/0:211:99:205:0,120,1800; ```. When this is genotyped by `GenotypeGVCFs` the only resulting variant is the 3bp deletion:. ```; #CHROM POS ID REF ALT QUAL FILTER INFO FORMAT test-sample; chr13 32953885 . AGTT A 3110.60 . AC=1;AF=0.500;AN=2;BaseQRankSum=0.00;DP=213;ExcessHet=3.0103;FS=2.544;MLEAC=1;MLEAF=0.500;MQ=60.00;MQRankSum=0.00;QD=16.37;ReadPosRankSum=-4.360e-01;SOR=0.506 GT:AD:DP:GQ:PL 0/1:108,82:190:99:3118,0,4288; ```. I've tried this with GATK 4.1.4.1, and also 4.1.7.0 and 4.1.8.1 and they all have the same issue (output above is from 4.1.8.1). I've also tried",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6817:181,test,test,181,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6817,2,['test'],"['test', 'test-sample']"
Testability,## Bug Report. ### Affected tool(s) or class(es); HaplotypeCaller. ### Affected version(s); - [x] Latest public release version [4.2.0.0]. ### Description ; HaplotypeCaller fails with the following java error:. ```*** Error in `java': munmap_chunk(): invalid pointer: 0x00007f1da5980f00 ***; ======= Backtrace: =========; /lib64/libc.so.6(+0x7f3e4)[0x7f1daaec73e4]; /var/tmp/rwilton/libgkl_smithwaterman14257239252565866950.so(_Z21runSWOnePairBT_avx512iiiiPhS_iiaPcPs+0x338)[0x7f05b3b50f48]; /var/tmp/rwilton/libgkl_smithwaterman14257239252565866950.so(Java_com_intel_gkl_smithwaterman_IntelSmithWaterman_alignNative+0xd8)```. #### Steps to reproduce; Using properly-aligned paired-end reads from GIAB reference sample HG002 (NA24385) with GRCh38.p12. Please see the attached log file for parameterization and stderr log:; [vcall.swbug.log](https://github.com/broadinstitute/gatk/files/6275740/vcall.swbug.log). #### Expected behavior; No error. #### Actual behavior; See above and attached log file. Thank you in advance for having a look at this!. Richard Wilton; Johns Hopkins University,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7187:776,log,log,776,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7187,5,['log'],['log']
Testability,"## Bug Report. ### Affected tool(s) or class(es); HaplotypeCaller. ### Affected version(s); gatk-package-4.1.9.0-33-g31df35b-SNAPSHOT-local.jar. ### Description . When run on the 30x 1000 genomes samples, I am getting this error. Not an issue on other crams we have. ```; /restricted/projectnb/genpro/github/gatk/gatk HaplotypeCaller -L chr22 -R /restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa -I cram/HG00096.final.cram -O test.g.vcf.gz; Using GATK jar /rprojectnb2/genpro/github/gatk/build/libs/gatk-package-4.1.9.0-33-g31df35b-SNAPSHOT-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /rprojectnb2/genpro/github/gatk/build/libs/gatk-package-4.1.9.0-33-g31df35b-SNAPSHOT-local.jar HaplotypeCaller -L chr22 -R /restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa -I cram/HG00096.final.cram -O test.g.vcf.gz; 14:39:56.283 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/rprojectnb2/genpro/github/gatk/build/libs/gatk-package-4.1.9.0-33-g31df35b-SNAPSHOT-local.jar!/com/intel/gkl/native/libgkl_compression.so; Feb 10, 2021 2:39:56 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 14:39:56.484 INFO HaplotypeCaller - ------------------------------------------------------------; 14:39:56.484 INFO HaplotypeCaller - The Genome Analysis Toolkit (GATK) v4.1.9.0-33-g31df35b-SNAPSHOT; 14:39:56.484 INFO HaplotypeCaller - For support and documentation go to https://software.broadinstitute.org/gatk/; 14:39:56.485 INFO HaplotypeCaller - Executing as farrell@scc-hadoop.bu.edu on Linux v3.10.0-1160.6.1.el7.x86_64 amd64; 14:39:56.485 INFO HaplotypeCaller - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_121-b13; 14:39:56.485 INFO HaplotypeCaller - Start Date/Time: February 10",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7076:450,test,test,450,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7076,2,['test'],['test']
Testability,"## Bug Report. ### Affected tool(s) or class(es); HaplotypeCaller/ActiveProfile. ### Affected version(s); - [ ] Latest public release version [4.3.0.0]. ### Description ; In function findEndOfRegion (line 355 in src/main/java/org/broadinstitute/hellbender/utils/activityprofile/ActivityProfile.java), it tries to determine the end of an active region. . The problem happens here, (at line 356); ![activeregion](https://user-images.githubusercontent.com/34263164/205565469-84900a73-1180-48e1-ba9f-f96c23d91e11.PNG); There could be an edge case where stateList.size() = maxRegionSize + getMaxProbPropagationDistance(), the function processes forward for further calculation. Hence the end of active region is determined immediately. However, the end of region is determined earlier than we expected. If by coincidence location at maxRegionSize is determined as minimum, region end is determined here. IBut wait a sec... If location at maxRegionSize+50 (which is NOT involved in current code in the ""if"" judgement at line 356) has an active score larger than 0, it rises the probability value at location maxRegionSize. . Now you should understand what I said. The state of location at maxRegionSize+50 is not updated when you accessed it. Let's assume ; maxRegionSize = 300 and point at location 350 has active value > 0. We trasverse the region to find the minimum point where we could cut the region and we found location at 300 in current logic. However, location 350 can acturally increase the probability at point 300 but this is not considered (or not updated) when making region end decision. #### Expected behavior; Simply use less or equal to at line 356 in the above image would fix this problem.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8118:1440,log,logic,1440,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8118,1,['log'],['logic']
Testability,"## Bug Report. ### Affected tool(s) or class(es); JointGermlineCNVSegmentation. ### Affected version(s); - [x] Latest public release version [v4.3.0.0]; - [ ] Latest master branch as of [date of test?]. ### Description ; I get the following exception when running JointGermlineCNVSegmentation on an exome trio dataset:. ```; [January 19, 2023 at 6:59:29 AM CET] org.broadinstitute.hellbender.tools.walkers.sv.JointGermlineCNVSegmentation done. Elapsed time: 0.82 minutes.; Runtime.totalMemory()=300941312; java.lang.IllegalStateException: Encountered genotype with ploidy 0 but 1 alleles.; at org.broadinstitute.hellbender.utils.Utils.validate(Utils.java:814); at org.broadinstitute.hellbender.tools.walkers.sv.JointGermlineCNVSegmentation.correctGenotypePloidy(JointGermlineCNVSegmentation.java:701); at org.broadinstitute.hellbender.tools.walkers.sv.JointGermlineCNVSegmentation.prepareGenotype(JointGermlineCNVSegmentation.java:682); at org.broadinstitute.hellbender.tools.walkers.sv.JointGermlineCNVSegmentation.lambda$createDepthOnlyFromGCNVWithOriginalGenotypes$4(JointGermlineCNVSegmentation.java:666); at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195); at java.base/java.util.ArrayList$Itr.forEachRemaining(ArrayList.java:1033); at java.base/java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484); at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474); at java.base/java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:913); at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.base/java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:578); at org.broadinstitute.hellbender.tools.walkers.sv.JointGermlineCNVSegmentation.createDepthOnlyFromGCNVWithOriginalGenotypes(JointGermlineCNVSegmentation.java:667); at org.broadinstitute.hellbender",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8164:195,test,test,195,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8164,1,['test'],['test']
Testability,"## Bug Report. ### Affected tool(s) or class(es); LeftAlignAndTrimVariants --split-multi-allelics. ### Affected version(s); Tested on versions 4.1.8.0, 4.1.9.0 and 4.2.0.0. ### Description ; GATK LeftAlignAndTrimVariants with option --split-multi-allelics crashes on multiallelic records on the versions tested. This does not occur with version 4.1.4.1 where the program manages to process and output the entire VCF. Upon further testing, it seems that the FORMAT field AF causes the problem as removing it from the following test record solves the problem:. ```; chr1	10027	.	A	C,G	.	PASS	.	GT:AD:AF:DP	1/2:0,5,5:0.500,0.500:10; ```. vs. ```; chr1	10027	.	A	C,G	.	PASS	.	GT:AD:DP	1/2:0,5,5:10; ```. The output for GATK 4.1.4.1 or when the AF field is removed looks like this:; ```; chr1	10027	.	A	C	.	PASS	.	GT:AD:DP	./.:0,5:10; chr1	10027	.	A	G	.	PASS	.	GT:AD:DP	./.:0,5:10; ```. #### Steps to reproduce; ```; $gatk/gatk LeftAlignAndTrimVariants -R $reference --split-multi-allelics -V test.input.vcf -O test.output.vcf; ```. #### Expected behavior; LeftAlignAndTrimVariants should be able to split multiallelic records in a VCF to two separate records as in GATK version 4.1.4.1. The AF field is removed from the 4.1.4.1 output, however. #### Actual behavior; GATK fails at a multiallelic record with the following error (GATK 4.2.0.0):; ```; java.lang.IllegalArgumentException: the range size cannot be negative; 	at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:798); 	at org.broadinstitute.hellbender.utils.IndexRange.validate(IndexRange.java:107); 	at org.broadinstitute.hellbender.utils.IndexRange.<init>(IndexRange.java:67); 	at org.broadinstitute.hellbender.utils.variant.GATKVariantContextUtils.splitASSBTable(GATKVariantContextUtils.java:1533); 	at org.broadinstitute.hellbender.utils.variant.GATKVariantContextUtils.splitSomaticVariantContextToBiallelics(GATKVariantContextUtils.java:1501); 	at org.broadinstitute.hellbender.tools.walkers.variantutils.LeftAlignAndTrimV",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7211:124,Test,Tested,124,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7211,5,"['Test', 'test']","['Tested', 'test', 'tested', 'testing']"
Testability,"## Bug Report. ### Affected tool(s) or class(es); LeftAlignAndTrimVariants. ### Affected version(s); I've only tested with v4.2.2.0. ### Description ; When running LeftAlignAndTrimVariants the program exited with a message that said:; ""A USER ERROR has occurred: Input files reference and features have incompatible contigs: No overlapping contigs found.; reference contigs = [chr1, chr2, chr3, chr4, chr5, chr6, chr7, chr8, chr9, chr10, chr11, chr12, chr13, chr14, chr15, chr16, chr17, chr18, chr19, chr20, chr21, chr22, chrX, chrY, chrM, chr1_KI270706v1_random, chr1_KI270707v1_random, chr1_KI270708v1_random, chr1_KI270709v1_random, chr1_KI270710v1_random, chr1_KI270711v1_random, chr1_KI270712v1_random, chr1_KI270713v1_random, chr1_KI270714v1_random, chr2_KI270715v1_random, chr2_KI270716v1_random, chr3_GL000221v1_random, chr4_GL000008v2_random, chr5_GL000208v1_random, chr9_KI270717v1_random, chr9_KI270718v1_random, chr9_KI270719v1_random, chr9_KI270720v1_random, chr11_KI270721v1_random, chr14_GL000009v2_random, chr14_GL000225v1_random, chr14_KI270722v1_random, chr14_GL000194v1_random, chr14_KI270723v1_random, chr14_KI270724v1_random, chr14_KI270725v1_random, chr14_KI270726v1_random, chr15_KI270727v1_random, chr16_KI270728v1_random, chr17_GL000205v2_random, chr17_KI270729v1_random, chr17_KI270730v1_random, chr22_KI270731v1_random, chr22_KI270732v1_random, chr22_KI270733v1_random, chr22_KI270734v1_random, chr22_KI270735v1_random, chr22_KI270736v1_random, chr22_KI270737v1_random, chr22_KI270738v1_random, chr22_KI270739v1_random, chrY_KI270740v1_random, chrUn_KI270302v1, chrUn_KI270304v1, chrUn_KI270303v1, chrUn_KI270305v1, chrUn_KI270322v1, chrUn_KI270320v1, chrUn_KI270310v1, chrUn_KI270316v1, chrUn_KI270315v1, chrUn_KI270312v1, chrUn_KI270311v1, chrUn_KI270317v1, chrUn_KI270412v1, chrUn_KI270411v1, chrUn_KI270414v1, chrUn_KI270419v1, chrUn_KI270418v1, chrUn_KI270420v1, chrUn_KI270424v1, chrUn_KI270417v1, chrUn_KI270422v1, chrUn_KI270423v1, chrUn_KI270425v1, chrUn_KI270429v1",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7538:111,test,tested,111,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7538,1,['test'],['tested']
Testability,"## Bug Report. ### Affected tool(s) or class(es); MarkDuplicatesSpark . ### Affected version(s); - Latest public release version [4.4.0.0]. ### Description . I am working on 40X human WGS data, running MarkDuplicatesSpark on the computation node of a cluster with 40 cores and 192GB RAM. MarkDuplicatesSpark usually hangs and never finish (even after few days) with log as below:. ```; 11:26:29.511 INFO FileOutputCommitter - File Output Committer Algorithm version is 1; 11:26:29.511 INFO FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false; 11:26:29.512 INFO FileOutputCommitter - File Output Committer Algorithm version is 1; 11:26:29.512 INFO FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false; 11:26:30.738 INFO FileOutputCommitter - File Output Committer Algorithm version is 1; 11:26:30.738 INFO FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false; 11:26:30.738 INFO FileOutputCommitter - File Output Committer Algorithm version is 1; 11:26:30.738 INFO FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false; 11:26:45.830 INFO FileOutputCommitter - File Output Committer Algorithm version is 1; 11:26:45.830 INFO FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false; 11:26:45.831 INFO FileOutputCommitter - File Output Committer Algorithm version is 1; 11:26:45.831 INFO FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false; 11:26:55.475 INFO FileOutputCommitter - File Output Committer Algorithm version is 1; 11:26:55.475 INFO FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folde",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8555:366,log,log,366,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8555,1,['log'],['log']
Testability,"## Bug Report. ### Affected tool(s) or class(es); MarkDuplicatesSpark. ### Affected version(s); - [ ] Latest public release version [version?]; 4.0.8.1; - [ ] Latest master branch as of [date of test?]; Sep 10, 2018. ### Description ; 18/09/08 10:32:49 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 6.0 (TID 515, localhost, executor 1, partition 0, NODE_LOCAL, 5270 bytes); 18/09/08 10:32:49 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 6.0 (TID 516, localhost, executor 2, partition 1, NODE_LOCAL, 5598 bytes); 18/09/08 10:32:49 INFO scheduler.TaskSetManager: Starting task 2.0 in stage 6.0 (TID 517, localhost, executor 1, partition 2, NODE_LOCAL, 5315 bytes); 18/09/08 10:32:49 INFO scheduler.TaskSetManager: Starting task 3.0 in stage 6.0 (TID 518, localhost, executor 2, partition 3, NODE_LOCAL, 5594 bytes); 18/09/08 10:32:49 INFO scheduler.TaskSetManager: Starting task 4.0 in stage 6.0 (TID 519, localhost, executor 1, partition 4, NODE_LOCAL, 5317 bytes); 18/09/08 10:32:49 INFO scheduler.TaskSetManager: Starting task 5.0 in stage 6.0 (TID 520, localhost, executor 2, partition 5, NODE_LOCAL, 5598 bytes); 18/09/08 10:32:49 INFO scheduler.TaskSetManager: Starting task 6.0 in stage 6.0 (TID 521, localhost, executor 1, partition 6, NODE_LOCAL, 5315 bytes); 18/09/08 10:32:49 INFO scheduler.TaskSetManager: Starting task 7.0 in stage 6.0 (TID 522, localhost, executor 2, partition 7, NODE_LOCAL, 5316 bytes); 18/09/08 10:32:49 INFO storage.BlockManagerInfo: Added broadcast_7_piece0 in memory on localhost:37617 (size: 59.2 KB, free: 2004.5 MB); 18/09/08 10:32:49 INFO storage.BlockManagerInfo: Added broadcast_7_piece0 in memory on localhost:45786 (size: 59.2 KB, free: 2004.5 MB); 18/09/08 10:32:50 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on localhost:37617 (size: 9.0 B, free: 2004.5 MB); 18/09/08 10:32:50 INFO scheduler.TaskSetManager: Starting task 8.0 in stage 6.0 (TID 523, localhost, executor 1, partition 8, NODE_LOCAL, 5604 bytes)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5169:195,test,test,195,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5169,1,['test'],['test']
Testability,"## Bug Report. ### Affected tool(s) or class(es); MergeVcfs (and potentially other Picard related tools). ### Affected version(s); - Latest public release version [4.1.7.0]. Here is my java version in case:; ```bash; $ java -version; openjdk version ""1.8.0_152-release""; OpenJDK Runtime Environment (build 1.8.0_152-release-1056-b12); OpenJDK 64-Bit Server VM (build 25.152-b12, mixed mode); ```. ### Description ; When the upstream path of the current directory contains a whitespace **and** the VCFs are stored in a directory 2 level deeper, the VCF is not found. The bug does not happen if:; * VCFs are located in current directory or in a subdirectory (level 1) from the current working directory (see reproducible steps below).; * VCFs have themselves whitespace in their filenames (see reproducible steps below). Here is a GATK stacktrace example:; ```java; Using GATK jar $HOME/local/pckg/python/miniconda3/envs/test/share/gatk4-4.1.7.0-0/gatk-package-4.1.7.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar $HOME/local/pckg/python/miniconda3/envs/test/share/gatk4-4.1.7.0-0/gatk-package-4.1.7.0-local.jar MergeVcfs -I data/calling/a.vcf.gz -I data/calling/b.vcf.gz -O c.vcf.gz; 23:25:05.033 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:$HOME/local/pckg/python/miniconda3/envs/test/share/gatk4-4.1.7.0-0/gatk-package-4.1.7.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; [Tue Jun 16 23:25:05 CDT 2020] MergeVcfs --INPUT data/calling/a.vcf.gz --INPUT data/calling/b.vcf.gz --OUTPUT c.vcf.gz --VERBOSITY INFO --QUIET false --VALIDATION_STRINGENCY STRICT --COMPRESSION_LEVEL 2 --MAX_RECORDS_IN_RAM 500000 --CREATE_INDEX true --CREATE_MD5_FILE false --GA4GH_CLIENT_SECRETS client_secrets.json --help false --version false --showHidden false --USE_JDK_DEFLATER false --USE_JDK_INFLATER false; Jun 16, 2020 11:25:05 PM shaded.c",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6664:919,test,test,919,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6664,1,['test'],['test']
Testability,"## Bug Report. ### Affected tool(s) or class(es); Mitochondria WDL. ### Affected version(s); - [x] Latest public release version [version?]; - [x] Latest master branch as of [date of test?]. ### Description ; Mitochondria WDL still has `--genotyping-mode` argument: https://github.com/broadinstitute/gatk/blob/master/scripts/mitochondria_m2_wdl/AlignAndCall.wdl#L420. This argument doesn't exist in GATK version 4.1.1.0 (which is the one that is currently being used in the mitochondria WDL), so this argument should be changed to the new force-call argument which was added in #6090",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6286:183,test,test,183,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6286,1,['test'],['test']
Testability,"## Bug Report. ### Affected tool(s) or class(es); Mutect2, HaplotypeCaller; ./gatk Mutect2 -I scripts/microbial/mtb/samples/D1CLVACXX.1.Solexa-125092.aligned.bam -R scripts/microbial/mtb/Mycobacterium_tuberculosis_H37Rv.fasta -O test.vcf --num-matching-bases-in-dangling-end-to-recover 1 --max-reads-per-alignment-start 75. ### Affected version(s); Latest master branch as of 2/18/21. ### Description ; java.lang.ArrayIndexOutOfBoundsException: Index 25 out of bounds for length 25; 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.readthreading.AbstractReadThreadingGraph.extendDanglingPathAgainstReference(AbstractReadThreadingGraph.java:913); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.readthreading.AbstractReadThreadingGraph.mergeDanglingHead(AbstractReadThreadingGraph.java:646); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.readthreading.AbstractReadThreadingGraph.recoverDanglingHead(AbstractReadThreadingGraph.java:542); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.readthreading.AbstractReadThreadingGraph.recoverDanglingHeads(AbstractReadThreadingGraph.java:447); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.readthreading.ReadThreadingAssembler.getAssemblyResult(ReadThreadingAssembler.java:685); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.readthreading.ReadThreadingAssembler.createGraph(ReadThreadingAssembler.java:664); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.readthreading.ReadThreadingAssembler.assemble(ReadThreadingAssembler.java:549); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.readthreading.ReadThreadingAssembler.assembleKmerGraphsAndHaplotypeCall(ReadThreadingAssembler.java:195); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.readthreading.ReadThreadingAssembler.runLocalAssembly(ReadThreadingAssembler.java:160); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.AssemblyBasedCallerUti",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7085:229,test,test,229,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7085,1,['test'],['test']
Testability,"## Bug Report. ### Affected tool(s) or class(es); Mutect2, multi-sample (2 samples) in Tumor-only mode. ### Affected version(s); - version 4.1.5.0, works fine on 4.1.4.1 and 4.1.4.0. ### Description ; Among my cohort of ~100 samples, mutect2 calling using reference genome hg38+alt+decoy (e.g. as provided in the gatk bundle) fails for one sample at a very specific location (chrUn_KI270748v1:61595-61748), returning an index out of range error. Slightly reducing the range removes the issue (e.g., calling on chrUn_KI270748v1:61596-61748), so it looks like an issue with the estimation of the number of repeats. This is not the most important location, but the error could affect more important calls for other people. The log is the following: ; ```gatk Mutect2 --java-options ""-Xmx15G"" -R /data/references/Homo_sapiens/GATK/hg38/Homo_sapiens_assembly38.fasta -I test1.bam -I test2.bam -O tests.vcf -L test_err.bed ; Using GATK jar /home/alcalan/.conda/mutect2-cd161e2f51ff2240ce6390abc942bbdd/share/gatk4-4.1.5.0-1/gatk-package-4.1.5.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx15G -jar /home/alcalan/.conda/mutect2-cd161e2f51ff2240ce6390abc942bbdd/share/gatk4-4.1.5.0-1/gatk-package-4.1.5.0-local.jar Mutect2 -R /data/references/Homo_sapiens/GATK/hg38/Homo_sapiens_assembly38.fasta -I test1.bam -I test2.bam -O tests.vcf -L test_err.bed; 10:34:24.578 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/alcalan/.conda/mutect2-cd161e2f51ff2240ce6390abc942bbdd/share/gatk4-4.1.5.0-1/gatk-package-4.1.5.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Mar 23, 2020 10:34:24 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 10:34:24.819 INFO Mutect2 - ---------------------------------------------------------",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6516:724,log,log,724,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6516,2,"['log', 'test']","['log', 'tests']"
Testability,"## Bug Report. ### Affected tool(s) or class(es); Mutect2. ### Affected version(s); - GATK v4.1.8.1. ### Description ; Hi, ; I am new to GATK so I hope this is not something trivial I overlooked. I called somatic variants using `Mutect2` (GATK v4.1.8.1) and wished to filter the results using `FilterMutectCalls`. I am running GATK via a docker container as described here: https://gatk.broadinstitute.org/hc/en-us/articles/360035889991--How-to-Run-GATK-in-a-Docker-container. ``` bash; ./gatk Mutect2 -I:tumor 1st.chr1.bam -I:normal 2nd.chr1.bam -O variants.vcf.gz --min-pruning 8 -R reference.chr1.fa; ```; I repeated this three times, the last time to make sure whether the .vcf.stats is being generated or not. This was a test run using the input filtered for chr1 using `samtools view -b`. I though this was the reason for getting the error message about Contig 2 not being present. ```bash; ...; 18:39:03.207 INFO ProgressMeter - 1:282722440 448.7 1529870 3409.8; 18:39:06.592 INFO VectorLoglessPairHMM - Time spent in setup for JNI call : 19.218222963000002; 18:39:06.592 INFO PairHMM - Total compute time in PairHMM computeLogLikelihoods() : 5376.604473962; 18:39:06.593 INFO SmithWatermanAligner - Total compute time in java Smith-Waterman : 12201.77 sec; 18:39:06.594 INFO Mutect2 - Shutting down engine; [August 25, 2020 6:39:06 PM GMT] org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2 done. Elapsed time: 448.75 minutes.; Runtime.totalMemory()=12349079552; ***********************************************************************. A USER ERROR has occurred: Contig 2 not present in the sequence dictionary [1]. ***********************************************************************; Set the system property GATK_STACKTRACE_ON_USER_EXCEPTION (--java-options '-DGATK_STACKTRACE_ON_USER_EXCEPTION=true') to print the stack trace.; ```; Is there any way of getting around this and generating .vcf.stats without repeating a lengthy variant calling `Mutect2`? Is this a problem introdu",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6768:726,test,test,726,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6768,1,['test'],['test']
Testability,"## Bug Report. ### Affected tool(s) or class(es); Mutect2. ### Affected version(s); - [x] Latest public release version [4.1.4.1]; - [ ] Latest master branch as of [date of test?]. ### Description ; Mutect2 occasionally writes lines including INFO tag `MPOS=-2147483648`. This doesn't look sensible for ""median distance from end of read"", and the specific value is disallowed in [section 1.3 of the VCF specification](https://samtools.github.io/hts-specs/VCFv4.3.pdf). I've had a quick look at the code, and think the dubious value may be generated in [ReadPosition::getValueForRead](https://github.com/broadinstitute/gatk/blob/946f39/src/main/java/org/broadinstitute/hellbender/tools/walkers/annotator/ReadPosition.java#L57) when the result from [ReadPosRankSumTest.getReadPosition](https://github.com/broadinstitute/gatk/blob/946f39/src/main/java/org/broadinstitute/hellbender/tools/walkers/annotator/ReadPosRankSumTest.java#L53) is cast to an `int`. Looking at that function, it can [return `INVALID_ELEMENT_FROM_READ`](https://github.com/broadinstitute/gatk/blob/946f39/src/main/java/org/broadinstitute/hellbender/tools/walkers/annotator/ReadPosRankSumTest.java#L62) which is [defined as `Double.NEGATIVE_INFINITY`](https://github.com/broadinstitute/gatk/blob/946f39/src/main/java/org/broadinstitute/hellbender/tools/walkers/annotator/RankSumTest.java#L23). According to the [java documentation](https://docs.oracle.com/javase/specs/jls/se7/html/jls-5.html#jls-5.1.3), casting NEGATIVE_INFINITY to int will result in a value of `INT_MIN`. (Disclaimer: I haven't tested this, so it may be completely wrong...). #### Steps to reproduce; See attached .zip file which includes a smallish bam file that shows the problem. I ran mutect2 on it in the Docker container for the latest GATK release:; ```sh; unzip mpos_issue.zip; cd mpos_issue; ../gatk Mutect2 --input input/small.bam --reference input/small.fa --output small.vcf; grep MPOS=- small.vcf; ```. #### Expected behavior; `MPOS` should have a se",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6342:173,test,test,173,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6342,1,['test'],['test']
Testability,"## Bug Report. ### Affected tool(s) or class(es); Mutect2. ### Affected version(s); - [x] Latest public release version: 4.0.11.0; - [ ] Latest master branch as of [date of test?]. ### Description ; The output vcf for a few samples looks like this:. ```; chrM 151 . CT TC . PASS DP=3420;ECNT=23;POP_AF=4.000e-03;P_CONTAM=0.00;TLOD=14304.21 GT:AD:AF:DP:F1R2:F2R1:MBQ:MFRL:MMQ:MPOS:ORIGINAL_CONTIG_MISMATCH:SA_MAP_AF:SA_POST_PROB:SB 0/1:27,3242:0.992:3269:13,1545:14,1697:30,30:317,335:60:26:0:0.990,0.990,0.992:0.045,0.015,0.940:9,18,1541,1701; chrM 152 . T C . chimeric_original_alignment DP=3358;ECNT=23;POP_AF=4.000e-03;P_CONTAM=0.00;TLOD=46.40 GT:AD:AF:DP:F1R2:F2R1:MBQ:MFRL:MMQ:MPOS:ORIGINAL_CONTIG_MISMATCH:PGT:PID:POTENTIAL_POLYMORPHIC_NUMT:SA_MAP_AF:SA_POST_PROB:SB 0/1:250,25:0.099:275:119,13:131,12:30,30:336,317:60:29:25:0|1:8660_C_T:true:0.091,0.061,0.091:2.722e-03,0.035,0.962:112,138,7,18; ```. ```; chrM 151 . CT TC . PASS DP=1867;ECNT=20;POP_AF=4.000e-03;P_CONTAM=0.00;TLOD=6145.34 GT:AD:AF:DP:F1R2:F2R1:MBQ:MFRL:MMQ:MPOS:ORIGINAL_CONTIG_MISMATCH:SA_MAP_AF:SA_POST_PROB:SB 0/1:13,1792:0.993:1805:7,879:6,913:30,30:441,442:60:39:0:0.990,0.990,0.993:0.026,0.024,0.950:5,8,745,1047; chrM 152 . T C . PASS DP=1847;ECNT=20;POP_AF=4.000e-03;P_CONTAM=0.00;TLOD=12.96 GT:AD:AF:DP:F1R2:F2R1:MBQ:MFRL:MMQ:MPOS:ORIGINAL_CONTIG_MISMATCH:SA_MAP_AF:SA_POST_PROB:SB 0/1:0,1755:0.999:1755:0,862:0,893:0,30:0,442:60:39:6:0.990,0.990,1.00:0.027,0.027,0.946:0,0,726,1029; ```. Note that site 152 is a T->C that is also captured in the MNP at site 151 CT->TC. In one case site 152 is filtered, but in the other it passes, but in both cases the MNP passes. . #### Steps to reproduce; @klaricch Could you please post the input BAMs into the Mutect task as well as the output VCFs from that task? Could you also post the ""script"" generated by Cromwell that will show what command Cromwell actually ran at this point? Thanks!. #### Expected behavior; I'm not sure what should happen in this case, but the two o",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5513:173,test,test,173,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5513,1,['test'],['test']
Testability,"## Bug Report. ### Affected tool(s) or class(es); Mutect2. ### Affected version(s); I test this problem in two versions, V4.1.4.1 and V4.3.0.0.They all have this problem. ### Description ; Following the recommendations of the 'Best Practice Workflows', I run mutect2 in the following command. java -jar -Djava.io.tmpdir=${tmpDir} -Xms2g -Xmx16g ; /mnt/bin/gatk-4.1.4.1/gatk-package-4.1.4.1-SNAPSHOT-local.jar Mutect2 ; --native-pair-hmm-threads 32 ; -R ${Fasta} ; -I ${cancer_bam} ; -I ${normal_bam}; --tumor-sample cancer --normal-sample normal ; -L ${all_chrome_bed}; --bam-output ${bam_output} ; -O ${vcf_output}. To improve parallelism, I try to split my all chrome bed to 25 files.Parallel running the flowing command brings me signficient performance improvement. java -jar -Djava.io.tmpdir=${tmpDir} -Xms2g -Xmx16g ; /mnt/bin/gatk-4.1.4.1/gatk-package-4.1.4.1-SNAPSHOT-local.jar Mutect2 ; --native-pair-hmm-threads 32 ; -R ${Fasta} ; -I ${cancer_bam} ; -I ${normal_bam}; --tumor-sample cancer --normal-sample normal ; -L ${chr1_bed}; --bam-output ${chr1_bam_output} ; -O ${chr1_vcf_output}. java -jar -Djava.io.tmpdir=${tmpDir} -Xms2g -Xmx16g ; /mnt/bin/gatk-4.1.4.1/gatk-package-4.1.4.1-SNAPSHOT-local.jar Mutect2 ; --native-pair-hmm-threads 32 ; -R ${Fasta} ; -I ${cancer_bam} ; -I ${normal_bam}; --tumor-sample cancer --normal-sample normal ; -L ${chr2_bed}; --bam-output ${chr2_bam_output} ; -O ${chr2_vcf_output}. But when I examined the vcf results produced by both modes of operation, I found consistency issues. #### Expected behavior; Let's focus on chromosome 2.I expect 100% consistency between the following two runs.; 1. The vcf file is obtained using a bed file containing only chromosome 2.; 2. Use bed file with all chromosomes to get all calling results, then filter to get chromesome 2 calling result. #### Actual behavior; 1. The first method above gives one more result than the second.; 2. There are 168 vcf results inconsistent, out of 1247 total.One of the inconsistencie",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8152:86,test,test,86,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8152,1,['test'],['test']
Testability,## Bug Report. ### Affected tool(s) or class(es); Mutect2. ### Affected version(s); Tested in 4.1.2 up to and including 4.1.5. ### Description ; Here's an IGV screenshot of a variant I found. One of the bases in the MNP is already a variant in the normal. ; https://drive.google.com/file/d/1YwfXH4LQQmhZ3wdi9HD1n6m3Up684DV5/view?usp=sharing. #### Steps to reproduce; My Mutect2 command was:. `gatk Mutect2; --reference genome.fa; -I normal.bam; -I tumor.bam; -normal normal; -tumor tumor; -L chr3:4300000-4400000; --annotation FisherStrand; --output output.vcf ; --bam-output output.bamout.bam ; --germline-resource af-only-gnomad.hg38.vcf.gz; --af-of-alleles-not-in-resource 0.0000025; --disable-read-filter MateOnSameContigOrNoMappedMateReadFilter; --panel-of-normals pon.vcf; --f1r2-tar-gz output.f1r2.tar.gz; --f1r2-max-depth 600; --dont-use-soft-clipped-bases true`. #### Expected behavior; This variant should just be called as a SNV at the first position. . #### Actual behavior; An MNP is called,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6476:84,Test,Tested,84,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6476,1,['Test'],['Tested']
Testability,"## Bug Report. ### Affected tool(s) or class(es); Mutect2. ### Affected version(s); gatk:4.1.4.1; ### Description ; Hello, I have an issue when i run Mutect2. Indeed it's seems to be a RAM issue (you will find 2 different log behind). To be aware of the context, I am using Mutect2 in production and in the new version which I use, approximately 1% of my Mutect2 failed. I first try to understand the log and it seems to me that the issue is due to memory management. Then I realized several test, by increasing both Java machine memory and docker job memory (10G) wich seems enough for mutect2 and my job was still failling. I also try to change CPU parameters but nothing change.; We did more test and try to run the same command with 2 others version of gatk (4.1.9.0 and 4.1.0.0). The job failed in 4.1.9.0 with the same log than 4.1.4.0 but the version 4.1.0.0 ran successfully. #### Steps to reproduce; you will find the command below. I'am not aware of the confidentiality about my input. If i can i will send it to you if needed.; `java -Xmx4000m -Xms4000m -XX:ParallelGCThreads=1 -XX:+AggressiveHeap -jar /usr/share/java/gatk-package-4.1.4.1-local.jar Mutect2 --smith-waterman FASTEST_AVAILABLE -I WES-T_S7_chr_1_bqsr.bam -I WGS-C_S12_chr_1_bqsr.bam -normal WGS-C -L 1 -O OUTPUT -R GRCh38.92.fa`; #### Expected behavior; _Tell us what should happen_. ### Description. > 10:29:22.302 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/usr/share/java/gatk-package-4.1.4.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Jan 06, 2021 10:29:22 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 10:29:22.407 INFO Mutect2 - ------------------------------------------------------------; 10:29:22.408 INFO Mutect2 - The Genome Analysis Toolkit (GATK) v4.1.4.1; 10:29:22.408 INFO Mutect2 - For support and documentation go to https://software.broadinstitute.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7032:222,log,log,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7032,5,"['log', 'test']","['log', 'test']"
Testability,"## Bug Report. ### Affected tool(s) or class(es); N/A. ### Affected version(s); - [ x] Latest public release version [4.5.0.0]; - [ ] Latest master branch as of [date of test?]. ### Description ; Dockerfile does not create unprivileged user account. #### Steps to reproduce; * git clone https://github.com/broadinstitute/gatk.git; * cd gatk; * git checkout 4.5.0.0; * docker build -t gatk .; * docker run ... #### Expected behavior; I'd expect the user to be in an unprivileged account in `/home/gatk` when the container is started. If there is a use case for enabling root (say for allowing system installs) this should be an option (config or a separate Dockerfile). #### Actual behavior; On `docker run` the user is root under `/gatk`. A container should not put the user in a root account upon startup. This is especially so in shared computing environments. I attempted to create a ""gatk"" account with `RUN useradd -d /home/gatk -ms /bin/bash gatk` (etc) in the Dockerfile but I get `Permission denied: '/root/.config/conda/.condarc'.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8856:170,test,test,170,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8856,1,['test'],['test']
Testability,## Bug Report. ### Affected tool(s) or class(es); ReadsPipelineSpark. ### Affected version(s); - [x] Latest public release version 4.1.0.0; - [ ] Latest master branch as of [date of test?]. ### Description . ```; java.lang.IllegalArgumentException: Interval NC_007605:1-171823 not within the bounds of a contig in the provided dictionary; 	at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:730); 	at org.broadinstitute.hellbender.engine.Shard.divideIntervalIntoShards(Shard.java:87); 	at org.broadinstitute.hellbender.engine.Shard.divideIntervalIntoShards(Shard.java:66); 	at org.broadinstitute.hellbender.tools.spark.pipelines.ReadsPipelineSpark.lambda$runTool$0(ReadsPipelineSpark.java:221); 	at java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:267); 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 	at org.broadinstitute.hellbender.tools.spark.pipelines.ReadsPipelineSpark.runTool(ReadsPipelineSpark.java:222); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:528); 	at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:30); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:138); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:162); 	at org.broadinsti,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5644:182,test,test,182,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5644,1,['test'],['test']
Testability,"## Bug Report. ### Affected tool(s) or class(es); Reblock | JointGenotype. ### Affected version(s); - [x] Latest public release version [version?]; - [ ] Latest master branch as of [date of test?]. ### Description ; We found a bug while running the latest JointGenotype pipeline (2.0.2). We are working with Dragen data (version 3.6.3); The error:. <details><summary>OPEN ERROR HERE</summary>; <p>. + gatk --java-options -Xms8g GenomicsDBImport --genomicsdb-workspace-path genomicsdb --batch-size 50 -L /tmp/scratch/cromwell-dragen-us-west-2/cromwell-execution/GatkJointGenotyping/7dd18ebe-29ca-47b1-b71a-56b99c362789/call-SplitIntervalList/glob-d928cd0f5fb17b6bd5e635f48c18ccfb/0073-scattered.interval_list --sample-name-map sample_name_map --reader-threads 5 --merge-input-intervals --consolidate; --; Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/tmp/scratch/cromwell-dragen-us-west-2/cromwell-execution/GatkJointGenotyping/7dd18ebe-29ca-47b1-b71a-56b99c362789/call-ImportGVCFs/shard-73/tmp.9a65c1fc; 18:46:55.750 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/gatk/gatk-package-4.2.3.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Dec 01, 2021 6:46:55 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 18:46:55.894 INFO GenomicsDBImport - ------------------------------------------------------------; 18:46:55.894 INFO GenomicsDBImport - The Genome Analysis Toolkit (GATK) v4.2.3.0; 18:46:55.895 INFO GenomicsDBImport - For support and documentation go to https://software.broadinstitute.org/gatk/; 18:46:55.895 INFO GenomicsDBImport - Executing as root@ip-10-10-156-13.us-west-2.compute.internal on Linux v4.14.243-185.433.amzn2.x86_64 amd64; 18:46:55.895 INFO GenomicsDBImport - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_242-8u242-b08-0ubuntu3~18.04-b08; 18:46:55.895 INFO GenomicsDBImport - Start Date/Time: December 1, 2021 6:46:55 PM GMT; 18",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7589:190,test,test,190,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7589,1,['test'],['test']
Testability,"## Bug Report. ### Affected tool(s) or class(es); ReblockGVCF. ### Affected version(s); - [x ] Latest public release version [version?] _**GATK 4.2.6.1**_; - [ ] Latest master branch as of [date of test?]. ### Description ; We ran ReblockGVCF in 549 samples with the newest GATK (4.2.6.1). 8 of them returned the error similar to the message below . `org.broadinstitute.hellbender.exceptions.GATKException: Exception thrown at chrM:1 [VC /tmp/scratch/prs-sabe-files/GRAR/2031812880_AJ.hard-filtered.gvcf.gz @ chrM:1 Q. of type=SYMBOLIC alleles=[G*, <NON_REF>] attr={END=1} GT=[[2031812880_AJ G*/G* DP 1691 AD 112,1579 {MIN_DP=1691, SQ=0}]] filters=weak_evidence`. and right below, we could find in all of them; `Caused by: org.broadinstitute.hellbender.exceptions.UserException$BadInput: Bad input: Homozygous reference genotypes must contain GQ or PL. Both are missing for hom ref genotype at chrM:1`. All the ""failed samples"" produced a broken output, in this case, missing the chrM (and the alt chr, such as HLA, chr1_alt etc)... It was weird because on WDL it returned as **_Success_** job... We need all the samples with a proper output to run the JointGenotype pipeline with the Reblocked Dragen samples output. #### Steps to reproduce; I'll share with you the chrM:1 from GVCF from a sample with no error; `chrM	1	.	G	<NON_REF>	.	PASS	END=72	GT:AD:DP:GQ:MIN_DP:PL:SPL:ICNT	0/0:2441,2:2443:99:1613:0,120,1800:0,255,255:40,13`. And now, the chrM:1 from a sample with the error; `chrM	1	.	G	<NON_REF>	.	weak_evidence	END=1	GT:AD:DP:SQ:MIN_DP	0/0:112,1579:1691:0:1691`. #### Expected behavior; No broken output. #### Actual behavior; Failing in a few samples, breaking the expected output.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7797:198,test,test,198,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7797,1,['test'],['test']
Testability,"## Bug Report. ### Affected tool(s) or class(es); SAMSequenceDictionary function in IndexUtils.java: https://github.com/broadinstitute/gatk/blob/master/src/main/java/org/broadinstitute/hellbender/utils/IndexUtils.java. ### Affected version(s); - [x] Latest public release version [version?]; - [x] Latest master branch as of [date of test?]. ### Description ; The SAMSequenceDictionary function always logs a warning when a file is passed in. Needs an if statement that validates whether or not the file is actually a sequence dictionary before logging the warning. #### Steps to reproduce; Run GATK's HaplotypeCaller with a --dbsnp option set, or just pass a sequence dictionary into the SAMSequenceDictionary function directly. #### Expected behavior; Should use the --dbsnp file that I pass in if valid, rather than log a warning and creating a separate sequence dictionary. #### Actual behavior; Logs a warning and instead tries to create a new sequence dictionary based on the index file it finds",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5692:334,test,test,334,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5692,5,"['Log', 'log', 'test']","['Logs', 'log', 'logging', 'logs', 'test']"
Testability,"## Bug Report. ### Affected tool(s) or class(es); SplitIntervals using `-MODE BALANCING_WITHOUT_INTERVAL_SUBDIVISION`. ### Affected version(s); Tested on: ; ```; The Genome Analysis Toolkit (GATK) v4.4.0.0; HTSJDK Version: 3.0.5; Picard Version: 3.0.0; ```. ### Description ; SplitIntervals does not produce the requested number of interval lists as specified by `--scatter-count`, even if it possible based on the input. It seems that SplitIntervals prioritizes equal interval list basepair size. See below for example. #### Steps to reproduce; Toy example:; genome.fa:; ```; >test; AGCTTTTCATTCTGACTGCAACGGGCAATATGTCTCTGTGTGGATTAAAAAAAGAGTCTCTGACAGCAGCTTCTGAACTG; GTTACCTGCCGTGAGTAAATTAAAATTTTATTGACTTAGGTCACTAAATACTTTAACCAATATAGGCATAGCGCACAGAC; AGATAAAAATTACAGAGTACACAACATCCATGAAACGCATTAGCACCACCATTACCACCACCATCACCACCACCATCACC; ```; intervals.list:; ```; test:1-5; test:7-10; test:15-20; test:25-30; test:30-35; test:40-45; test:50-55; test:60-65; test:70-75; test:76-80; test:82-88; test:90-96; test:98-102; test:105-130; test:136-139; test:145-159; test:160-220; ```; Command:; ```; gatk SplitIntervals -R genome.fa -L toy_intervals.list -O ./ --scatter-count 17 -mode BALANCING_WITHOUT_INTERVAL_SUBDIVISION --sequence-dictionary genome.dict --interval-merging-rule OVERLAPPING_ONLY; ```; This only produces 3 interval list files. If this is expected behavior, its not entirely clear from the documentation. #### Expected behavior; I have a list of 500 non-overlapping intervals (from ScatterIntervalsByNs) that I would like SplitIntervals to organize into 250 interval lists. I would expect that the tool would produce 250 list files. . #### Actual behavior; The tool only produces 12 interval list files. . ----",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8315:144,Test,Tested,144,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8315,19,"['Test', 'test']","['Tested', 'test']"
Testability,"## Bug Report. ### Affected tool(s) or class(es); VariantAnnotator -A ReferenceBases -A TandemRepeat. ### Affected version(s); - [x] Latest public release version [4.1.3]; - [ ] Latest master branch as of [date of test?]. ### Description ; VariantAnnotator doesn't seem to correctly generate annotations that are based off the reference. I've tried on a few different VCFs and with different genome builds, and get the same result every time. For `ReferenceBases` it seems to generate a string for each variant that is the ref allele, followed by `20-len(ref) * N`. E.g.:. ```; 1 118617 rs372912307 T C 50 PASS REF_BASES=TNNNNNNNNNNNNNNNNNNNN; 1 567239 rs78150957 CG C 50 PASS REF_BASES=CGNNNNNNNNNNNNNNNNNNN; ```. The STR annotations get their header lines added to the header, but not a single variant is flagged as an STR. I've tried processing the GIAB VCFs for NA12878 and NA24385 with the same results - even obvious STR variants are not flagged. I suspect this is related to the fact that REF_BASES isn't compute properly. #### Steps to reproduce; Take any decent size VCF without the above annotations (e.g. GIAB VCFs) and run something like:. gatk VariantAnnotator -V NA12878.vcf.gz -O NA12878.ann.vcf.gz -A TandemRepeat -A ReferenceBases -R hg38.fa",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6095:214,test,test,214,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6095,1,['test'],['test']
Testability,"## Bug Report. ### Affected tool(s) or class(es); VariantAnnotator. ### Affected version(s); - [x] Latest public release version 4.5.0.0; - [ ] Latest master branch as of [date of test?]. ### Description ; ```; Using GATK jar /directory_masked/programs/gatk-4.5.0.0/gatk-package-4.5.0.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -DGATK_STACKTRACE_ON_USER_EXCEPTION=true -jar /directory_masked/gatk-4.5.0.0/gatk-package-4.5.0.0-local.jar VariantAnnotator -I ../test.bam -V test.vcf -O test_2.vcf --reference /directory_masked/refs/hg19/ucsc.hg19.fasta --enable-all-annotations true -jdk-deflater true -jdk-inflater true; 14:02:45.344 INFO VariantAnnotator - ------------------------------------------------------------; 14:02:45.346 INFO VariantAnnotator - The Genome Analysis Toolkit (GATK) v4.5.0.0; 14:02:45.346 INFO VariantAnnotator - For support and documentation go to https://software.broadinstitute.org/gatk/; 14:02:45.346 INFO VariantAnnotator - Executing as username@hostname.local on Mac OS X v14.2 aarch64; 14:02:45.346 INFO VariantAnnotator - Java runtime: OpenJDK 64-Bit Server VM v17.0.10+0; 14:02:45.346 INFO VariantAnnotator - Start Date/Time: April 30, 2024 at 2:02:45 PM HKT; 14:02:45.346 INFO VariantAnnotator - ------------------------------------------------------------; 14:02:45.346 INFO VariantAnnotator - ------------------------------------------------------------; 14:02:45.347 INFO VariantAnnotator - HTSJDK Version: 4.1.0; 14:02:45.347 INFO VariantAnnotator - Picard Version: 3.1.1; 14:02:45.347 INFO VariantAnnotator - Built for Spark Version: 3.5.0; 14:02:45.348 INFO VariantAnnotator - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 14:02:45.348 INFO VariantAnnotator - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 14:02:45.348 INFO VariantAnnotator - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 14:02:45.348 INFO V",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8800:180,test,test,180,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8800,3,['test'],['test']
Testability,"## Bug Report. ### Affected tool(s) or class(es); VariantAnnotator. ### Affected version(s); - [x] Latest public release version [version?]; - [x] Latest master branch as of [date of test?]. ### Description . Throws an exception on a legal variant. java.lang.IllegalStateException: Allele in genotype G not in the variant context [G*, G, GT]; 	at htsjdk.variant.variantcontext.VariantContext$Validation.validateGenotypes(VariantContext.java:382); 	at htsjdk.variant.variantcontext.VariantContext$Validation.access$200(VariantContext.java:323); 	at htsjdk.variant.variantcontext.VariantContext$Validation$2.validate(VariantContext.java:331); 	at htsjdk.variant.variantcontext.VariantContext.lambda$validate$0(VariantContext.java:1384); 	at java.lang.Iterable.forEach(Iterable.java:75); 	at htsjdk.variant.variantcontext.VariantContext.validate(VariantContext.java:1384); 	at htsjdk.variant.variantcontext.VariantContext.<init>(VariantContext.java:489); 	at htsjdk.variant.variantcontext.VariantContextBuilder.make(VariantContextBuilder.java:647); 	at htsjdk.variant.variantcontext.VariantContextBuilder.make(VariantContextBuilder.java:638); 	at org.broadinstitute.hellbender.utils.variant.GATKVariantContextUtils.trimAlleles(GATKVariantContextUtils.java:1329); 	at org.broadinstitute.hellbender.utils.variant.GATKVariantContextUtils.trimAlleles(GATKVariantContextUtils.java:1285); 	at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorEngine.getMinRepresentationBiallelics(VariantAnnotatorEngine.java:499); 	at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorEngine.annotateExpressions(VariantAnnotatorEngine.java:440); 	at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorEngine.annotateContext(VariantAnnotatorEngine.java:285); 	at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotator.apply(VariantAnnotator.java:230); 	at org.broadinstitute.hellbender.engine.VariantWalker.lambda$traverse$0(VariantWalker.java:104); 	a",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6689:183,test,test,183,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6689,1,['test'],['test']
Testability,"## Bug Report. ### Affected tool(s) or class(es); VariantRecalibrator. ### Affected version(s); - [X] Latest public release version [4.5.0.0]; - [ ] Latest master branch as of [date of test?]. ### Description ; As of v1.3.0 the `scales` R package turns the use of deprecated values for the `space` parameter into a hard error, resulting in the VariantRecalibrator R-script terminating with the following message:. > The `space` argument of `pal_gradient_n()` only supports be ""Lab"" as of scales 0.3.0. This parameter is used repeatedly in the generated R-script via. ```R; scale_fill_gradient(high=""green"", low=""red"", space=""rgb""); ```. #### Steps to reproduce. ```shell; $ R --version; R version 4.1.2 (2021-11-01) -- ""Bird Hippie""; $ rm -rf ~/R; $ R; > install.packages(""ggplot2"", repos=""https://cloud.r-project.org/""); > packageVersion(""scales""); [1] ‘1.3.0’; > quit(); $ gatk --version; The Genome Analysis Toolkit (GATK) v4.5.0.0; HTSJDK Version: 4.1.0; Picard Version: 3.1.1; $ gatk VariantRecalibrator [arguments omitted for brevity]; org.broadinstitute.hellbender.utils.R.RScriptExecutorException: ; Rscript exited with 1; Command Line: Rscript -e tempLibDir = '/tmp/Rlib.9339186078473502558';source('/path/to/rscript.r');; Stdout: ; Stderr: Error:; ! The `space` argument of `pal_gradient_n()` only supports be ""Lab"" as; of scales 0.3.0.; Backtrace:; ▆; 1. ├─base::source(""/path/to/rscript.r""); 2. │ ├─base::withVisible(eval(ei, envir)); 3. │ └─base::eval(ei, envir); 4. │ └─base::eval(ei, envir); 5. └─ggplot2::scale_fill_gradient(high = ""green"", low = ""red"", space = ""rgb""); 6. ├─ggplot2::continuous_scale(...); 7. │ └─ggplot2::ggproto(...); 8. │ └─rlang::list2(...); 9. └─scales::seq_gradient_pal(low, high, space); 10. └─scales::pal_gradient_n(c(low, high), space = space); 11. └─lifecycle::deprecate_stop(""0.3.0"", ""pal_gradient_n(space = 'only supports be \""Lab\""')""); 12. └─lifecycle:::deprecate_stop0(msg); 13. └─rlang::cnd_signal(...); Execution halted; $ R; > install.packages(""remot",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8664:185,test,test,185,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8664,1,['test'],['test']
Testability,"## Bug Report. ### Affected tool(s) or class(es); VcfFuncotationFactoryUnitTest; SimpleKeyXsvFuncotationFactoryUnitTest; SimpleTsvOutputRendererUnitTest; VcfOutputRendererUnitTest; VariantOverlapAnnotaterUnitTest. ### Affected version(s). - [x] Latest master branch as of August 12, 2020. ### Description ; When running the entire unit test suite using; ```; ./gradlew test; ```; where the environment variable TEST_TYPE=unit. The same 371 tests will fail. The following stack trace gives an example of one of the failing tests:; ```; org.broadinstitute.hellbender.exceptions.GATKException: Unable to automatically instantiate codec org.broadinstitute.hellbender.utils.codecs.AnnotatedIntervalCodec; 	at org.broadinstitute.hellbender.engine.FeatureManager.getCandidateCodecsForFile(FeatureManager.java:508); 	at org.broadinstitute.hellbender.engine.FeatureManager.getCodecForFile(FeatureManager.java:455); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.getCodecForFeatureInput(FeatureDataSource.java:354); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.getFeatureReader(FeatureDataSource.java:334); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:282); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:238); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:206); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:193); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:156); 	at org.broadinstitute.hellbender.testutils.VariantContextTestUtils.readEntireVCFIntoMemory(VariantContextTestUtils.java:67); 	at org.broadinstitute.hellbender.tools.funcotator.vcfOutput.VcfOutputRendererUnitTest.testExclusionListOverridesManualDefaultAnnotations(VcfOutputRendererUnitTest.java:40); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorIm",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6748:336,test,test,336,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6748,4,['test'],"['test', 'tests']"
Testability,"## Bug Report. ### Affected tool(s) or class(es); _FilterAlignmentArtifacts_. ### Affected version(s); - [x] Latest public release version [4.1.4.1]. ### Description ; FilterAlignmentArtifacts consistently errors out with segmentation faults or IllegalArgumentExceptions. I've attached the log files for each of these errors below.; [invalid_interval.log](https://github.com/broadinstitute/gatk/files/4017907/invalid_interval.log); [seg_fault.log](https://github.com/broadinstitute/gatk/files/4017908/seg_fault.log). #### Steps to reproduce; The command to reproduce both errors is the same, and I have attached it below.; [realignment_filter.txt](https://github.com/broadinstitute/gatk/files/4017918/realignment_filter.txt); The BWA mem index I'm using is hg38, however the BAM that I am realigning from is hg19; thus, the reference argument is the hg19 fasta. I am happy to transfer zip files containing the other files need to reproduce this. Just let me know where to send them. #### Expected behavior; _FilterAlignmentArtifacts_. #### Actual behavior; _Errors_",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6344:290,log,log,290,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6344,5,['log'],['log']
Testability,## Bug Report. ### Affected tool(s) or class(es); _Funcotator_ _LocatableXsvFuncotationFactory_. ### Affected version(s); - [x] Latest master branch as of [date of test?]. ### Description ; The datasources (clinvar_hgmd in particular) contain multiple/overlapping entries for the same location. This causes too many funcotations to be added to a single variant for a single LocatableXsv data source. #### Expected behavior; For now Funcotator should just pick the first entry. Will need to discuss for what the correct behavior is.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4929:164,test,test,164,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4929,1,['test'],['test']
Testability,"## Bug Report. ### Affected tool(s) or class(es); _Funcotator_, _GencodeFuncotationFactory_. ### Affected version(s); - [x] Latest public release version [version?]; - [x] Latest master branch as of [date of test?]. ### Description ; The transcript position in Funcotator is always being populated as a single integer value. While this is correct for SNPs, it should be populated as a range - `<START_POS>_<END_POS>` for events spanning more than 1 base.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5375:208,test,test,208,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5375,1,['test'],['test']
Testability,## Bug Report. ### Affected tool(s) or class(es); _Funcotator_. ### Affected version(s); - [X] Latest master branch as of [20181001]. ### Description ; There appears to be an extra folder in the funcotator test datasources in `large`:. `large/funcotator/funcotator_dataSources/cancer_gene_census/hg19/hg38`; `large/funcotator/funcotator_dataSources/cancer_gene_census/hg38/hg38`. This should be removed.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5243:206,test,test,206,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5243,1,['test'],['test']
Testability,"## Bug Report. ### Affected tool(s) or class(es); _Funcotator_. ### Affected version(s); - [x] Latest public release version [version v4.1.4.1]; - [ ] Latest master branch as of [date of test?]. ### Description . Hi @jonn-smith , I saw you often address Funcotator related issues, so I thought this might be of interest to you. I ran funcotator on a vcf created by mutect2 from RNA-seq data. The vcf includes a large deletion in the GABARAP gene, and when Funcotator processes this annotation, it dies with an error about a query that extends past the end of a contig:. > htsjdk.samtools.SAMException: Query asks for data past end of contig. Query contig ENST00000571253.1|ENS; G00000170296.9|OTTHUMG00000102156.3|OTTHUMT00000440082.2|AC120057.8-003|GABARAP|837|UTR5:1-753|CDS:754-8; 37| start:1 stop:895 contigLength:837; at org.broadinstitute.hellbender.utils.fasta.CachingIndexedFastaSequenceFile.getSubsequenceAt(Ca; chingIndexedFastaSequenceFile.java:316); at org.broadinstitute.hellbender.engine.ReferenceFileSource.queryAndPrefetch(ReferenceFileSource; .java:78); at org.broadinstitute.hellbender.engine.ReferenceDataSource.queryAndPrefetch(ReferenceDataSource; .java:64); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.; getFivePrimeUtrSequenceFromTranscriptFasta(GencodeFuncotationFactory.java:744); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createUtrFuncotation(GencodeFuncotationFactory.java:1568); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createGencodeFuncotationOnSingleTranscript(GencodeFuncotationFactory.java:983); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsHelper(GencodeFuncotationFactory.java:805); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsHelper(GencodeFuncotationFactory.java:78",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6345:187,test,test,187,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6345,1,['test'],['test']
Testability,"## Bug Report. ### Affected tool(s) or class(es); _Funcotator_. ### Affected version(s); - [x] Latest public release version [version?]; - [x] Latest master branch as of [date of test?]. ### Description ; When annotating a VCF, if the VCF already contains funcotations Funcotator will add a new funcotator line to the header. This will cause the parser to fail because it will not be able to get the correct line from the header. This is a bit of a pathological case (I can't currently see a good reason to funcotate a VCF twice), but since this behavior is valid it should be accounted for. The primary issue is how to resolve the two funcotation sets. Ideally we would leave them both in and somehow version them (to preserve all the information). Alternatively we can append to the existing funcotation list. This second method will likely involve a lot of work and probably isn't worth it.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5368:179,test,test,179,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5368,1,['test'],['test']
Testability,"## Bug Report. ### Affected tool(s) or class(es); _GencodeFuncotationFactory_. ### Affected version(s); - [x] Latest public release version [version?]; - [x] Latest master branch as of [date of test?]. ### Description ; When a trouble transcript comes up for an allele pairl, `GencodeFuncotationFactory::createFuncotationsHelper` does not create a default annotation for the allele pair. This will cause the parsing of funcotations to fail because not all the alleles are represented in the funcotation list. See the `todo` in `GencodeFuncotationFactory::createFuncotationsHelper`.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5366:194,test,test,194,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5366,1,['test'],['test']
Testability,"## Bug Report. ### Affected tool(s) or class(es); _MarkDuplicatesSpark_. ### Affected version(s); - [ ] GATK version 4.1.9.0. ### Description ; Headers with another `@` character fail to create a valid bam using MarkDuplicatesSpark. The bam file is empty. But the header will work when using samtools markdup instead. The following example was found in one of many samples we found in ICGC datasets. Example header:; `@HWI-ST700660_163:1:1101:1243:1870#1@0/1`. Log:<br> (removed some content since it was too long); ```; 00:05 DEBUG: [kryo] Read: Object[]; 00:05 DEBUG: [kryo] Read: Object[]; 00:05 DEBUG: [kryo] Read: Object[]; 00:05 DEBUG: [kryo] Read: Object[]; 00:05 DEBUG: [kryo] Write: Object[]; 00:05 DEBUG: [kryo] Write: Object[]; 00:05 DEBUG: [kryo] Write: Object[]; ...; 01:22 DEBUG: [kryo] Read: CompressedMapStatus; 01:22 DEBUG: [kryo] Write: CompressedMapStatus; ...; 02:25 DEBUG: [kryo] Read: WrappedArray([]); 02:25 DEBUG: [kryo] Write: WrappedArray([]); 02:25 DEBUG: [kryo] Read: scala.Tuple3[]; 02:25 DEBUG: [kryo] Read: scala.Tuple3[]; 02:25 DEBUG: [kryo] Read: WrappedArray([]); 02:25 DEBUG: [kryo] Read: WrappedArray([]); 02:25 DEBUG: [kryo] Write: scala.Tuple3[]; ...; 02:42 DEBUG: [kryo] Write object reference 1941: HLA-A*24:152; 02:42 DEBUG: [kryo] Write object reference 1945: chrUn_JTFH01001224v1_decoy; 02:42 DEBUG: [kryo] Write object reference 1949: HLA-B*14:01:01; 02:42 DEBUG: [kryo] Write object reference 1953: chr5_GL949742v1_alt; ...; 02:42 DEBUG: [kryo] Write object reference 1942: SAMSequenceRecord(name=HLA-A*24:152,length=3176,dict_index=2919,assembly=null,alternate_names=[]); 02:42 DEBUG: [kryo] Write object reference 1946: SAMSequenceRecord(name=chrUn_JTFH01001224v1_decoy,length=1051,dict_index=2066,assembly=null,alternate_names=[]); 02:42 DEBUG: [kryo] Write object reference 1950: SAMSequenceRecord(name=HLA-B*14:01:01,length=3312,dict_index=2999,assembly=null,alternate_names=[]); 02:42 DEBUG: [kryo] Write object reference 1954: SAMSequenceRecord(name",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8134:461,Log,Log,461,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8134,1,['Log'],['Log']
Testability,"## Bug Report. ### Affected tool(s) or class(es); _Mutect2_. ### Affected version(s); - GATK 4.1.4.1. ### Description ; When running Mutect2 (from GATK v4.1.4.1) using the following command:. `gatk Mutect2 -R [path to grch37-1kg.fa] -I testcase.bam -O pon.vcf`. to create a PoN on NovaSeq WGS-data processed through the best practice pipeline (with the BQSR-steps run through the Spark-enabled tools, and bwa mem with -Y flag) I get the following error in multiple regions:. [Stacktrace](https://www.dropbox.com/s/d2n5zflj9u11oj8/stacktrace.png?dl=0). AFAIK this is related to the new code path introduced in #6240 and seem to be triggered when there are more than 2 reads supporting a fragment but all of them are either duplicate reads or supplemntary/secondary alignments. Any input is greatly appreciated. I guess a temporary fix is to use the --independent-mates flag (although haven't tried it yet -- how much worse mutation calling performance do one incur when using that flag?). #### Steps to reproduce; Use the following small test case .bam-file as input to the command specified above:. [Testcase](https://www.dropbox.com/s/hilcj3aj0jnjdmh/testcase.bam?dl=0). #### Expected behavior; Completion of mutect2 without Exception. #### Actual behavior; Early termination of the mutect2 run due to raising an exception when trying to create a fragment with no read data to back it up. ----",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6310:236,test,testcase,236,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6310,4,"['Test', 'test']","['Testcase', 'test', 'testcase']"
Testability,## Bug Report. ### Affected tool(s) or class(es); _Somatic CNV caller_. ### Affected version(s); - [ ] https://hub.docker.com/r/broadinstitute/gatk/. ### Description ; _I am following the steps outlined here: https://gatkforums.broadinstitute.org/gatk/discussion/11682 to generate copy number variation plots. When I execute the steps using the example data I am able to generate plots similar to example plots noted on the page. But the plots I generate using my own datafiles do not look as expected. . Main differences between example data and experimental data processing : ; 1. Reference genome : GRCh37 (instead of GRCh38 in example)_. #### Steps to reproduce; _1. Reference genome : GRCh37 (instead of GRCh38 in example); 2. WES sample_. #### Expected behavior; _Expected plot :; ![test denoisedLimit4](https://user-images.githubusercontent.com/17917521/67444546-66df1c80-f5be-11e9-8887-26f7b07717b8.png); _. #### Actual behavior; _; ![experimental_datafile_plot denoisedLimit4](https://user-images.githubusercontent.com/17917521/67444584-9726bb00-f5be-11e9-9a0f-4a68717a0fd5.png); _. ----,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6225:789,test,test,789,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6225,1,['test'],['test']
Testability,"## Bug Report. ### Affected tool(s) or class(es); _Tool/class name(s), special parameters?_. FilterAlignmentArtifacts. ### Affected version(s); - [x] Latest public release version [version?]; - [ ] Latest master branch as of [date of test?]. 4.3.0.0. ### Description ; _Describe the problem below. Provide **screenshots** , **stacktrace** , **logs** where appropriate._. ```; Using GATK jar /gatk-4.3.0.0/gatk-package-4.3.0.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -XX:+UseNUMA -jar /gatk-4.3.0.0/gatk-package-4.3.0.0-local.jar FilterAlignmentArtifacts -R /raid/bundle/hg38/Homo_sapiens_assembly38.fasta.gz -O WGS-NA12878.FilterAlignmentArtifacts.vcf --tmp-dir . -V WGS-NA12878.filtered.vcf -I WGS-NA12878.sorted.dedup.recal.bam --bwa-mem-index-image /raid/bundle/hg38/Homo_sapiens_assembly38.fasta.img; 11:24:09.761 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/gatk-4.3.0.0/gatk-package-4.3.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; 11:24:09.942 INFO FilterAlignmentArtifacts - ------------------------------------------------------------; 11:24:09.942 INFO FilterAlignmentArtifacts - The Genome Analysis Toolkit (GATK) v4.3.0.0; 11:24:09.943 INFO FilterAlignmentArtifacts - For support and documentation go to https://software.broadinstitute.org/gatk/; 11:24:09.943 INFO FilterAlignmentArtifacts - Executing as root@D52BV-2U on Linux v4.15.0-202-generic amd64; 11:24:09.943 INFO FilterAlignmentArtifacts - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_352-8u352-ga-1~18.04-b08; 11:24:09.943 INFO FilterAlignmentArtifacts - Start Date/Time: February 24, 2023 11:24:09 AM CST; 11:24:09.943 INFO FilterAlignmentArtifacts - ------------------------------------------------------------; 11:24:09.943 INFO FilterAlignmentArtifacts - ------------------------------------------------------------; 11:24:09.943 INFO Filter",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8221:234,test,test,234,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8221,2,"['log', 'test']","['logs', 'test']"
Testability,"## Bug Report. ### Affected tool(s) or class(es); _Tool/class name(s), special parameters?_. `SortSamSpark --sort-order coordinate`. ### Affected version(s); - [ ] Latest public release version [version?]; - [ ] Latest master branch as of [date of test?]. `4.4.0.0`. ### Description ; _Describe the problem below. Provide **screenshots** , **stacktrace** , **logs** where appropriate._. An error occurs when using SortSamSpark to sort the large BAM file that contain long reads only (90x human wgs, min. read length>10kbp).; However, if the large BAM file contains short reads, it executes normally. #### Steps to reproduce; _Tell us how to reproduce this issue. If possible, include command lines that reproduce the problem. (The support team may follow up to ask you to upload data to reproduce the issue.)_. ```shell; sysctl -w vm.max_map_count=2147483642; gatk SortSamSpark \; --input HG002-NA24385-GM24385.bam \; --output HG002-NA24385-GM24385.sorted.bam \; --sort-order coordinate \; --java-options ""-XX:+UnlockDiagnosticVMOptions -XX:GCLockerRetryAllocationCount=96 -XX:+UseNUMA -XX:+UseZGC -Xmx1794G"" \; --tmp-dir . \; -- \; --spark-runner LOCAL --spark-master local[96] --conf spark.local.dir=./tmp --conf spark.port.maxRetries=61495; ```. #### Expected behavior; _Tell us what should happen_. Output a sorted BAM file. #### Actual behavior; _Tell us what happens instead_. `java.lang.OutOfMemoryError: Required array length ? is too large`. The last lines of the log file.; ```; 11:00:42.884 INFO BlockManagerInfo - Removed taskresult_15758 on 172.20.19.130:43279 in memory (size: 10.5 MiB, free: 1076.2 GiB); 11:00:42.888 INFO TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool; 11:00:42.902 INFO DAGScheduler - ResultStage 0 (sortByKey at SparkUtils.java:165) finished in 1652.742 s; 11:00:42.915 INFO DAGScheduler - Job 0 is finished. Cancelling potential speculative or zombie tasks for this job; 11:00:42.916 INFO TaskSchedulerImpl - Killing all running ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8949:248,test,test,248,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8949,2,"['log', 'test']","['logs', 'test']"
Testability,"## Bug Report. ### Affected tool(s) or class(es); _Tool/class name(s), special parameters?_; Mutect2; ### Affected version(s); - [ ] 4.1.1.0. ### Description ; _Describe the problem below. Provide **screenshots** , **stacktrace** , **logs** where appropriate._; We have run mutect2 on the same sample using the same input crams, references, and intervals. The only discernible difference is the docker image used that we built. The difference between the first and second one is that the first one was built without samtools, the second one with samtools. The third is exactly the same as the second except it was re-built about a year or more later. Looking at a count of the `PASS` results based on each:. |Run type |var count|; |---------------------------|---------|; |docker no samtools | 8265 |; |docker yes samtools | 8283 |; |docker yes samtools rebuilt | 8273 |; |docker no samtools recently built | 8271 |. Out of curiosity, we tried building the docker again without samtools, so in theory, the only possible change is that when each docker is built, apt update is run. The differences are small, but is that expected? That with and without samtools, and if `apt` packages change, mutect2 could be influenced?. #### Steps to reproduce; _Tell us how to reproduce this issue. If possible, include command lines that reproduce the problem. (The support team may follow up to ask you to upload data to reproduce the issue.)_; I can't replicate scenario 1 in the table because it was built in 2019, so apt packages were different then.; Scenario 2 dockerPull: `docker pull kfdrc/gatk:4.1.1.0`; Scenario 3 dockerPull: `docker pull pgc-images.sbgenomics.com/d3b-bixu/gatk:4.1.1.0`; Scenario 4 dockerPull: `docker pull migbro/gatk:4.1.1.0L`. No samtools Dockerfile:; ```; FROM ubuntu:18.04; LABEL maintainer=""Miguel Brown (brownm28@email.chop.edu)"". ENV GATK4_VERSION 4.1.1.0. RUN apt update && apt install -y openjdk-8-jdk python wget unzip libgomp1; \; wget -q https://github.com/broadinstitute/g",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7269:234,log,logs,234,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7269,1,['log'],['logs']
Testability,"## Bug Report. ### Affected tool(s) or class(es); _Tool/class name(s), special parameters?_; Picard IlluminaBasecallsToSam and IlluminaBasecallsToFastq. ### Affected version(s); - [X] Latest public release version [4.2.0.0]; - [ ] Latest master branch as of [date of test?]. ### Description ; _Describe the problem below. Provide **screenshots** , **stacktrace** , **logs** where appropriate._; ""This bug has been fixed in Picard release https://github.com/broadinstitute/picard/releases/tag/2.25.4 - The version of gatk that you are using (4.2.0.0) was packaged with Picard https://github.com/broadinstitute/picard/releases/tag/2.25.0 in it (which has the bug)."" See [IlluminaBasecallsToSam and IlluminaBasecallsToFastq do not demultiplex NovaSeq barcoded reads](https://github.com/broadinstitute/picard/issues/1679) for details. The GATK release needs to be updated to contain Picard 2.25.4 or better. #### Steps to reproduce; _Tell us how to reproduce this issue. If possible, include command lines that reproduce the problem. (The support team may follow up to ask you to upload data to reproduce the issue.)_; Run tools with NovaSeq run directory as input and many dual index barcodes. #### Expected behavior; _Tell us what should happen_; Reads having each of the dual index barcodes should be demultiplexed to separate files. #### Actual behavior; _Tell us what happens instead_; Reads having each of the dual index barcodes are all in the UNKNOWN files. ----",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7254:267,test,test,267,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7254,2,"['log', 'test']","['logs', 'test']"
Testability,"## Bug Report. ### Affected tool(s) or class(es); _VariantEval, -O, --output_. ### Affected version(s); - [X] Latest public release version [4.1.0.0]; - [ ] Latest master branch as of [date of test?]. ### Description ; Program starts then terminates with error:; `***********************************************************************`; `A USER ERROR has occurred: Couldn't read file file:///[.....]/X034.eval.grp. Error was: It doesn't exist.`; `***********************************************************************`. Note: The error is not thrown, and VariantEval completes successfully, if a zero-byte file with the name passed with the `-o` or `--output` arguments is created before executing VariantEval; For this example: `touch X034.eval.grp`. #### Steps to reproduce; Command line:; `gatk VariantEval -R $ref -L autosomes.list --eval W034.raw.annotated.vcf.gz --dbsnp dbsnp.vcf.gz -O X034.eval.grp`. #### Expected behavior; Expect the program to create its own output file (as other GATK tools do). #### Actual behavior; Terminates with error (above). ----",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5674:193,test,test,193,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5674,1,['test'],['test']
Testability,"## Bug Report. ### Affected tool(s) or class(es); `Funcotator`. ### Affected version(s); GATK 4.1.0.0 release. ### Description ; Funcotator returns a `NullPointerException` when trying to output compressed VCF:. ```; 15:35:26.085 INFO Funcotator - Creating a VCF file for output: XXXX; 15:35:26.125 INFO ProgressMeter - Starting traversal; 15:35:26.125 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; log4j:WARN No appenders could be found for logger (org.broadinstitute.hellbender.tools.funcotator.dataSources.vcf.VcfFuncotationFactory).; log4j:WARN Please initialize the log4j system properly.; log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.; 15:35:26.328 INFO Funcotator - Shutting down engine; [February 15, 2019 3:35:26 PM EST] org.broadinstitute.hellbender.tools.funcotator.Funcotator done. Elapsed time: 0.18 minutes.; Runtime.totalMemory()=3391094784; java.lang.NullPointerException; at htsjdk.tribble.index.tabix.TabixIndexCreator.finalizeFeature(TabixIndexCreator.java:106); at htsjdk.tribble.index.tabix.TabixIndexCreator.finalizeIndex(TabixIndexCreator.java:129); at htsjdk.variant.variantcontext.writer.IndexingVariantContextWriter.close(IndexingVariantContextWriter.java:177); at htsjdk.variant.variantcontext.writer.VCFWriter.close(VCFWriter.java:231); at org.broadinstitute.hellbender.tools.funcotator.vcfOutput.VcfOutputRenderer.close(VcfOutputRenderer.java:137); at org.broadinstitute.hellbender.tools.funcotator.Funcotator.closeTool(Funcotator.java:883); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:970); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:138); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); at org.broadinstitute.hellbender.Main.runCommandLineProgra",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5683:483,log,logger,483,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5683,2,['log'],"['logger', 'logging']"
Testability,## Bug Report. ### Affected tool(s) or class(es); `GermlineCNVCaller`. ### Affected version(s); - [x] Latest public release version [`4.3.0.0` and `4.4.0.0`]. ### Description ; `GermlineCNVCaller` pipeline provide different results with same GATK version (`4.3.0.0`) on different base Ubuntu images (`18.04` and `22.04`). Test results of GATK version `4.3.0.0` and `4.4.0.0` are same on Ubuntu 22.04 - I assume there are no changes in `GermlineCNVCaller` between `4.3.0.0` and `4.4.0.0`. #### Steps to reproduce; Command list:; ```sh; /soft/gatk-4.3.0.0/gatk PreprocessIntervals -R /ref/GRCh38.d1.vd1/GRCh38.d1.vd1.fa --padding 0 -L chr1:10000-35000 -L chr22:198477-20003000 -imr OVERLAPPING_ONLY -O /outputs/gatk_intervals.interval_list. /soft/gatk-4.3.0.0/gatk AnnotateIntervals -L /outputs/gatk_intervals.interval_list -R /ref/GRCh38.d1.vd1/GRCh38.d1.vd1.fa -imr OVERLAPPING_ONLY -O /outputs/gatk_intervals.interval_list.annotated.tsv. /soft/gatk-4.3.0.0/gatk CollectReadCounts -I /inputs/E07002_normal_alignment.bam -R /ref/GRCh38.d1.vd1/GRCh38.d1.vd1.fa -L /outputs/gatk_intervals.interval_list --interval-merging-rule OVERLAPPING_ONLY -O /outputs/E07002_normal_alignment.bam.counts.hdf5; /soft/gatk-4.3.0.0/gatk CollectReadCounts -I /inputs/E07002_tumor_alignment.bam -R /ref/GRCh38.d1.vd1/GRCh38.d1.vd1.fa -L /outputs/gatk_intervals.interval_list --interval-merging-rule OVERLAPPING_ONLY -O /outputs/E07002_tumor_alignment.bam.counts.hdf5. /soft/gatk-4.3.0.0/gatk DetermineGermlineContigPloidy -L /outputs/gatk_intervals.interval_list --interval-merging-rule OVERLAPPING_ONLY --contig-ploidy-priors /outputs/a_valid_ploidy_priors_table.tsv.copy.tsv --output /outputs/COHORT_runDir --output-prefix COHORT --input /outputs/E07002_normal_alignment.bam.counts.hdf5 --input /outputs/E07002_tumor_alignment.bam.counts.hdf5. /soft/gatk-4.3.0.0/gatk GermlineCNVCaller --run-mode COHORT -L /outputs/gatk_intervals.interval_list --interval-merging-rule OVERLAPPING_ONLY --annotated-intervals /outputs/gat,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8619:322,Test,Test,322,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8619,1,['Test'],['Test']
Testability,"## Bug Report. ### Affected tool(s) or class(es); `Mutect2` and `FilterMutectCalls`. ### Affected version(s); GATK 4.1.0.0 release (though I suspect this was also in 4.0.x). ### Description ; M2 force-calling multi-allelic sites using GGA mode results in automatic `mappinq_quality` filter if one allele does not have any reads mapped, even if the other variant allele has good mapping quality. In my testing this happened when I force-called the following IDH1 mutations:. ```; #CHROM POS ID REF ALT QUAL FILTER INFO; 2 209113112 . C A . . .; 2 209113112 . C T . . .; ```. The first listed is the common IDH1 R132H variant and the second listed is the less common but equally pathogenic R132L variant. The purpose for force-calling both variants is that one wants to absolutely exclude the possibility of either variant at this site. In most my tests, variants would fail `FilterMutectCalls` because only one of the multi-allelic alleles would be present, eg. *(representative except of `Mutect2` + `FilterMutectCalls` output)*. ```; VAR 	2	209113112	.	C	A,T; FILTER	mapping_quality;read_position; INFO	MMQ=60,0,60; FORMAT	GT:AD 0/1/2:56,0,47; ```. Only in rare cases would the variant site `PASS`, and that's when there would be at least one variant read in the second allele, eg:. ```; VAR 	2	209113112	.	C	A,T; FILTER	PASS; INFO	MMQ=60,60,60; FORMAT	GT:AD 0/1/2:28,1,16; ```. #### Steps to reproduce; To reproduce this specific example you will need a BAM file with a C>T mutation at `2:209113112`, and no reads with an `A` at this position. You will then need to run M2 and `FilterMutectCalls` with `--genotyping-mode GENOTYPE_GIVEN_ALLELES --alleles ...` set to a VCF with both lines as shown in the description. #### Expected behavior; `FilterMutectCalls` should not apply a `mapping_quality` filter if one of the alleles would pass. Perhaps the mapping quality filter could ignore alleles with zero mapped reads, rather than assigning a MMQ of zero by default? *Note that this issue would also",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5695:401,test,testing,401,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5695,2,['test'],"['testing', 'tests']"
Testability,"## Bug Report. ### Affected tool(s) or class(es); `ParallelCopyGCSDirectoryIntoHDFSSpark`. ### Affected version(s); - [x] Latest public release version [version?]; - [x] Latest master branch as of [2019-05-13]. ### Description . `ParallelCopyGCSDirectoryIntoHDFSSpark` behaves in the following strange way:. * under __master/latest__ release, it __fails__ to copy a GCS ""directory"" containing __BAMs__; * under __master/latest__ release, it __successfully__ copies a GCS ""directory"" containing __reference__; * changing the nio lib version from 81 to 66 in `build.gradle`, it __successfully__ copies GCS ""directories"" containing __reference__ or __BAMs__; * see attached logs. #### Steps to reproduce. Both scripts referred to below need to be updated accordingly, but trivially. * from the master branch, run the attached `test.nio.ver.81.sh`. * branch out from master, change the literal `81` to `66` on line 69 in `build.gradle`, run the attached `test.nio.ver.66.sh`. #### Expected behavior. Files in the ""directories"" given in the gs path copied successfully. #### Actual behavior; Fail. See logs attached. -------------; [test.nio.paraCopyHDFSSpark.zip](https://github.com/broadinstitute/gatk/files/3174143/test.nio.paraCopyHDFSSpark.zip). UPDATE:; reuploaded attachment",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5935:671,log,logs,671,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5935,6,"['log', 'test']","['logs', 'test']"
Testability,"## Bug Report. ### Affected tool(s) or class(es); `PrintReadsSpark`. ### Affected version(s); - [x] Latest public release version [version?]; - [x] Latest master branch as of [date of test?]. ### Description . I first encountered this type of error in a prototype tool I'm writing, so to dig further about what's happening, I run our simplest Spark tool&mdash;`PrintReadsSpark`. `PrintReadsSpark` reports errors when intervals are specified in a BED file (see command given in the stack trace). * Scenario 1: run with a WGS bam and give intervals via `-L PATH_TO_BED_FILE`, error is reported; * Scenario 2: run with the WGS bam and give intervals via `-L chrX:[0-9]+-[0-9]+`, no error; * Scenario 3: run with bam that is shrunk from the WGS bam by including reads only in the union of intervals, then with `-L PATH_TO_BED_FILE`, no error; * Scenario 4: run with bam that is shrunk from the WGS bam by including reads only in the union of intervals, then with `-L chrX:[0-9]+-[0-9]+`, no error; * Scenario 5: download the shrunken bam to local machine and run `PrintReadsSpark` with `-L PATH_TO_BED_FILE`, no error. Stack trace from scenario 1:; ```; ./gatk PrintReadsSpark \; -I hdfs://shuang-small-m:8020/data/HG00512.cram.samtools1_9.bam \; -O hdfs://shuang-small-m:8020/results/temp.bam \; -L hdfs://shuang-small-m:8020/data/intervals.bed \; -- \; --spark-runner GCS \; --cluster shuang-small \; --project broad-dsde-methods. Using GATK jar /Users/shuang/GATK/gatk/build/libs/gatk-spark.jar; found cached jar: gs://broad-dsde-methods/shuang/tmp/gatk-jars/gatk-spark_5710525a8758807e46bbb660ac998e63.jar. Replacing spark-submit style args with dataproc style args. --cluster shuang-small --project broad-dsde-methods -> --cluster shuang-small --project broad-dsde-methods --properties spark.kryoserializer.buffer.max=512m,spark.driver.maxResultSize=0,spark.driver.userClassPathFirst=false,spark.io.compression.codec=lzf,spark.yarn.executor.memoryOverhead=600,spark.driver.extraJavaOptions=-DGATK_STA",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5051:184,test,test,184,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5051,1,['test'],['test']
Testability,"## Bug Report. ### Affected tool(s) or class(es); `SAMRecord` from `GATKRead`. ### Affected version(s); - [x] Latest master branch as of January 30, 2024. ### Description ; When I run a tool with a bam file as input, the following code will give me a null:; ```java; @Override; public void apply(GATKRead read, ReferenceContext referenceContext, FeatureContext featureContext) {. // Build sets of read IDs for each file.; final SAMRecord samRecord = read.convertToSAMRecord(getHeaderForReads());; final SAMFileSource fileSource = samRecord.getFileSource();; System.out.println(fileSource);; ```. Output:; (a long list of `null`). #### Steps to reproduce; Create a ReadWalker that takes in a bam file. Here is an integration test that will replicate the issue:. ```java; public class ReadConcordanceIntegrationTest extends CommandLineProgramTest {. @Test; public void testTwoCrams() throws IOException {; final File output = createTempFile(""testReadConcordanceOutputFile"", "".txt"");; final File input = new File(GATKBaseTest.largeFileTestDir, ""expected.K-562.splitNCigarReads.chr20.bam"");. final ArgumentsBuilder args = new ArgumentsBuilder();. args.addInput(input);; this.runCommandLine(args.getArgsArray());; }; }; ```. #### Expected behavior; Output should be the file used in the read data source (bam file) for each read. #### Actual behavior; I get nulls instead",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8671:724,test,test,724,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8671,4,"['Test', 'test']","['Test', 'test', 'testReadConcordanceOutputFile', 'testTwoCrams']"
Testability,"## Bug Report. ### Affected tool(s) or class(es); `org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.BreakpointsInference`, hence affecting the location of breakpoint output by the SV discovery pipeline. ### Affected version(s); - [x] Latest public release version [version?]; - [x] Latest master branch as of [date of test?]. ### Description . Micro-homology around breakpoints affects where we place breakpoints in the SV.; Take the simplest example of deletion; where (10A10G10A); ```; ......AAAAAAAAAAGGGGGGGGGGAAAAAAAAAA......; ```; becomes (10A); ```; ......AAAAAAAAAA......; ```; Here we have a homology of exactly 10A's.; When we detect the deletion by studying the alignment signature, the alt haplotype would have two alignments mapped to the reference, one ends just before the G-block, one starts just after the G-block, with the A-block on the alt haplotype mapped to two places.; We follow the left-align/left-justify convention, and place the POS 1-bp before the left most A (hence saying `10A10G` was deleted, as opposed to right-justify which would say `10G10A` deleted, in fact without the convention any contiguous substring of 20 bp long of `10A10G10A` would be correct). However, it can be imagined the homologous sequences flanking the G's are not exactly the same, or may not be the same length (small indels), and the alignments would contain small gaps in their CIGARs. By assuming the homologous sequence are of the same length, which is what we are doing now, we could get the breakpoint location wrong. This is generally not a serious problem, but when the accumulated gap sizes are large enough, we can end up too-far off. A similar issue is when inferring SVLEN for small tandem duplications, where we are assuming the extra copies have the same length. This is not always true and when the `DUP_SEQ_CIGARS` annotation is available, it should be easily fixable. When it is not available, one could use the difference between `SEQ_ALT_HAPLOTYPE` and END-POS",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4883:334,test,test,334,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4883,1,['test'],['test']
Testability,"## Bug Report. ### Affected tool(s) or class(es); gatk GenotypeGVCFs. ### Affected version(s); - [X] Latest public release version [GATK 4.1.9.0]; - [ ] Latest master branch as of [date of test?]. ### Description ; Files generated by 'gatk GenotypeGVCFs' with french locale in February (Février in french) August (Août) or December (Décembre) have ISO-8859-1 encoding instead of UTF-8 encoding. Indeed, the output files have this line:. `##GATKCommandLine=<ID=GenotypeGVCFs,CommandLine=""GenotypeGVCFs --output /volumes/vol002/COVID/GenomicDB/vcf/COVID.05022021.int00.vcf.gz --variant gendb://dbtot/int00 --reference /volumes/vol002/reference/human_g1k_v37.fasta --tmp-dir /volumes/vol002/COVID/GenomicDB/tmp/tmpint00 --include-non-variant-sites false --merge-input-intervals false --input-is-somatic false --tumor-lod-to-emit 3.5 --allele-fraction-error 0.001 --keep-combined-raw-annotations false --annotate-with-num-discovered-alleles false --heterozygosity 0.001 --indel-heterozygosity 1.25E-4 --heterozygosity-stdev 0.01 --standard-min-confidence-threshold-for-calling 30.0 --max-alternate-alleles 6 --max-genotype-count 1024 --sample-ploidy 2 --num-reference-samples-if-no-call 0 --genomicsdb-use-bcf-codec false --genomicsdb-shared-posixfs-optimizations false --only-output-calls-starting-in-intervals false --interval-set-rule UNION --interval-padding 0 --interval-exclusion-padding 0 --interval-merging-rule ALL --read-validation-stringency SILENT --seconds-between-progress-updates 10.0 --disable-sequence-dictionary-validation false --create-output-bam-index true --create-output-bam-md5 false --create-output-variant-index true --create-output-variant-md5 false --lenient false --add-output-sam-program-record true --add-output-vcf-command-line true --cloud-prefetch-buffer 40 --cloud-index-prefetch-buffer -1 --disable-bam-index-caching false --sites-only-vcf-output false --help false --version false --showHidden false --verbosity INFO --QUIET false --use-jdk-deflater false --use-jdk-in",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7081:189,test,test,189,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7081,1,['test'],['test']
Testability,"## Bug Report. ### Affected tool(s); Mutect2. ### Affected version(s); 3.6. ### Description ; The AF field of MuTect2 is unpredictable depending on the input interval. For example, if I run with `-L chr7:140452736-140453536`, I get this at one site:; `chr7	140453136	.	A	T	.	PASS	ECNT=1;HCNT=27;MAX_ED=.;MIN_ED=.;NLOD=239.30;TLOD=243.81	GT:AD:AF:ALT_F1R2:ALT_F2R1:FOXOG:QSS:REF_F1R2:REF_F2R1	0/1:1489,145:0.049:69:76:0.524:45565,4764:771:718	0/0:1094,0:0.00:0:0:.:34322,0:549:545`; But, if I run with `-L chr7:140452836-140453436`, I get this at the same site:; `chr7	140453136	.	A	T	.	PASS	ECNT=1;HCNT=15;MAX_ED=.;MIN_ED=.;NLOD=239.98;TLOD=245.96	GT:AD:AF:ALT_F1R2:ALT_F2R1:FOXOG:QSS:REF_F1R2:REF_F2R1	0/1:1489,144:0.092:69:75:0.521:45567,4730:770:719	0/0:1097,0:0.00:0:0:.:34389,0:551:546`; Notice the major difference in AF between the two runs. Side note, the AF does not equal the alt count / (alt count + ref count)?. #### Steps to reproduce; Test files here:; `/humgen/gsa-scr1/schandra/micknudsen_MuTect2AF/bugreport_AF`. Command for interval size of 600:; `java -jar /humgen/gsa-hpprojects/GATK/bin/current/GenomeAnalysisTK.jar -T MuTect2 -R /humgen/gsa-hpprojects/GATK/bundle/2.8/hg19/ucsc.hg19.fasta -I:normal /humgen/gsa-scr1/schandra/micknudsen_MuTect2AF/bugreport_AF/normal_chr7.12.bam -I:tumor /humgen/gsa-scr1/schandra/micknudsen_MuTect2AF/bugreport_AF/tumor_chr7.12.bam -o Sheila.MuTect2.vcf -L chr7:140452836-140453436. Command for interval size of 800:; `java -jar /humgen/gsa-hpprojects/GATK/bin/current/GenomeAnalysisTK.jar -T MuTect2 -R /humgen/gsa-hpprojects/GATK/bundle/2.8/hg19/ucsc.hg19.fasta -I:normal /humgen/gsa-scr1/schandra/micknudsen_MuTect2AF/bugreport_AF/normal_chr7.12.bam -I:tumor /humgen/gsa-scr1/schandra/micknudsen_MuTect2AF/bugreport_AF/tumor_chr7.12.bam -o Sheila.MuTect2.400.vcf -L chr7:140452736-140453536`. ----. This Issue was generated from your [forums] ; [forums]: http://gatkforums.broadinstitute.org/gatk/discussion/comment/33762#Comment_33762",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2295:949,Test,Test,949,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2295,1,['Test'],['Test']
Testability,"## Bug Report. ### Affected tool; CreateSomaticPanelOfNormals. ### Affected version; Tested on version 4.1.8.0 (likely commit 3e921c6, GenomicsDB 1.3.0 #6654). ### Description ; Panel of normals generated from version 4.1.8.0 has some ~28% less records (~52% less ALT alleles) than one created with 4.1.7.0 (tested at commit 9cc92e3) with all input data and arguments unchanged. The GenomicsDB version does not seem to matter as PoN created running CreateSomaticPanelOfNormals on 4.1.8.0 has the result is about the same regardless of whether GenomicsDBImport was run on 4.1.7.0 or 4.1.8.0. CreateSomaticPanelOfNormals on 4.1.7.0 fails to run on the new GenomicsDBs. |Mutect2|GenomicsDB|CreateSomaticPanelOfNormals|Output|; |---|---|---|---|; |4.1.7.0|4.1.7.0|4.1.7.0|100% alleles (reference)|; |4.1.8.0|4.1.8.0|4.1.7.0|expected error|; |4.1.7.0|4.1.7.0|4.1.8.0|48% alleles|; |4.1.8.0|4.1.8.0|4.1.8.0|48% alleles|. #### Steps to reproduce; The PoN was created with GRCh38, scattered over chromosomes. Mutect command:; ```; $gatk/gatk --java-options ""-Xmx4G"" Mutect2 \; 	-R $reference -L $chr \; 	-I $bam --max-mnp-distance 0 \; 	-O @out1@; ```. GenomicsDBImport command:; ```; $gatk/gatk --java-options ""-Xms8G -Xmx8G"" GenomicsDBImport \; 	-R $reference -L $chr \; 	--sample-name-map ${inputGenomicsDB.out1} \; 	--genomicsdb-workspace-path @folder1@; ```. CreateSomaticPanelOfNormals:; ```; $gatk/gatk --java-options ""-Xms8G"" CreateSomaticPanelOfNormals \; 	-R $reference -V gendb://@folder1@ -O @out1@ \; 	--germline-resource $gnomad \; 	--max-germline-probability 0.5; ```. #### Expected behavior; Based on description of the GenomicsDB 1.3.0 update, CreateSomaticPanelOfNormals is expected to behave similarly in 4.1.8.0 as before with the output PoN containing a similar number of variants. #### Actual behavior; 28% of PoN records (52% alleles) are missing in 4.1.8.0 compared to 4.1.7.0. Although all spanning deletions are dropped in the new version, they account for only a small portion of th",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6744:85,Test,Tested,85,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6744,2,"['Test', 'test']","['Tested', 'tested']"
Testability,"## Bug Report. ### Affected version(s); - Latest master branch as of 1/12/2022. ### Description ; When I tried to build from the github repo, I received the following error:. FAILURE: Build failed with an exception. * Where:; Build file '/gatk/build.gradle' line: 688. * What went wrong:; A problem occurred evaluating root project 'gatk'.; > Could not resolve all files for configuration ':runtimeClasspath'.; > Could not find biz.k11i:xgboost-predictor:0.3.0.; Searched in the following locations:; - https://repo.maven.apache.org/maven2/biz/k11i/xgboost-predictor/0.3.0/xgboost-predictor-0.3.0.pom; - https://broadinstitute.jfrog.io/broadinstitute/libs-snapshot/biz/k11i/xgboost-predictor/0.3.0/xgboost-predictor-0.3.0.pom; - https://oss.sonatype.org/content/repositories/snapshots/biz/k11i/xgboost-predictor/0.3.0/xgboost-predictor-0.3.0.pom; - file:/root/.m2/repository/biz/k11i/xgboost-predictor/0.3.0/xgboost-predictor-0.3.0.pom; Required by:; project :. * Try:; > Run with --stacktrace option to get the stack trace.; > Run with --info or --debug option to get more log output.; > Run with --scan to get full insights. * Get more help at https://help.gradle.org. #### Steps to reproduce; `git clone https://github.com/broadinstitute/gatk.git`; `cd gatk/`; `./gradlew bundle`",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7636:1074,log,log,1074,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7636,1,['log'],['log']
Testability,"## Bug Report. ### GermlineCNVCaller. ### Affected version(s); - [ ] (GATK) v4.2.1.0. ### Description ; Java exception raised when aggregating counts for samples with a name shorter than 3 characters. For example, in the pasted logs, it errors out when processing sample with interval read counts in `94.mkdup.sort.rg.tsv`. And I found removing the sample from the list of files would avoid the error. . ### Logs:. `; 06:49:05.526 INFO GermlineCNVCaller - Aggregating read-count file output/gCNV/bulkDNAseq_BGI/F20FTSAPHT0350_MUSyfqR/count_tsv/713.mkdup.sort.rg.tsv (40 / 323); 06:49:07.999 INFO GermlineCNVCaller - Aggregating read-count file output/gCNV/bulkDNAseq_BGI/F20FTSAPHT0350_MUSyfqR/count_tsv/252.mkdup.sort.rg.tsv (41 / 323); 06:49:10.433 INFO GermlineCNVCaller - Aggregating read-count file output/gCNV/bulkDNAseq_BGI/F20FTSAPHT0350_MUSyfqR/count_tsv/547.mkdup.sort.rg.tsv (42 / 323); 06:49:13.341 INFO GermlineCNVCaller - Aggregating read-count file output/gCNV/bulkDNAseq_BGI/F20FTSAPHT0350_MUSyfqR/count_tsv/154.mkdup.sort.rg.tsv (43 / 323); 06:49:15.782 INFO GermlineCNVCaller - Aggregating read-count file output/gCNV/bulkDNAseq_BGI/F20FTSAPHT0350_MUSyfqR/count_tsv/651.mkdup.sort.rg.tsv (44 / 323); 06:49:18.251 INFO GermlineCNVCaller - Aggregating read-count file output/gCNV/bulkDNAseq_BGI/F20FTSAPHT0350_MUSyfqR/count_tsv/94.mkdup.sort.rg.tsv (45 / 323); 06:49:20.605 INFO GermlineCNVCaller - Shutting down engine; [August 13, 2021 6:49:20 AM GMT] org.broadinstitute.hellbender.tools.copynumber.GermlineCNVCaller done. Elapsed time: 2.27 minutes.; Runtime.totalMemory()=2076049408; java.lang.IllegalArgumentException: Prefix string too short; at java.io.File.createTempFile(File.java:2001); at org.broadinstitute.hellbender.utils.io.IOUtils.createTempFileInDirectory(IOUtils.java:685); at org.broadinstitute.hellbender.utils.io.IOUtils.createTempFile(IOUtils.java:666); at org.broadinstitute.hellbender.tools.copynumber.GermlineCNVCaller.lambda$writeIntervalSubsetReadCountFiles$",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7410:228,log,logs,228,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7410,2,"['Log', 'log']","['Logs', 'logs']"
Testability,"## Bug Report. ### Tool; FilterAlignmentArtifacts. ### Affected version(s); 4.2.0.0 and 4.1.9.0, run from local jar or docker. ### Description ; FilterAlignmentArtifacts crushes repetitively in the same position of the input mutect2 vcf `m2.vcf.gz` (chrX:63457865). But, it finishes task successfully when only the last variant from the output file is present in the input vcf file. ; I cut the input vcf around the troublesome variant to reproduce the error on a smaller input and: ; 1. Error did not occur when the input was very small ; 2. FilterAlignmentArtifacts finished run at different variant (chrX:73769127) when analyzing the smaller input (`test.vcf.gz`) . The log issue looks very similar to that described here [#7162)](https://github.com/broadinstitute/gatk/issues/7162), but the *Problematic frame* information is different. ; As suggested in this issue [#5690](https://github.com/broadinstitute/gatk/issues/5690), the problem disappears when using gatk 4.1.3.0 on the same inputs. . log:; ```bash; 17:37:20.674 INFO ProgressMeter - chr20:43968267 10.6 44000 4132.2; 17:37:38.646 INFO ProgressMeter - chr22:22736335 10.9 45000 4110.5; 17:37:52.672 INFO ProgressMeter - chrX:7000139 11.2 46000 4113.9; 17:38:05.421 INFO ProgressMeter - chrX:26360893 11.4 47000 4125.0; 17:38:17.207 INFO ProgressMeter - chrX:44917184 11.6 48000 4141.4; 17:38:29.312 INFO ProgressMeter - chrX:77681733 11.8 49000 4155.3; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x00007fc0ccec5cdb, pid=15987, tid=15988; #; # JRE version: OpenJDK Runtime Environment (11.0.11+9) (build 11.0.11+9-Ubuntu-0ubuntu2.18.04); # Java VM: OpenJDK 64-Bit Server VM (11.0.11+9-Ubuntu-0ubuntu2.18.04, mixed mode, sharing, tiered, compressed oops, g1 gc, linux-amd64); # Problematic frame:; # C [libc.so.6+0x97cdb] cfree+0x31b; #; # Core dump will be written. Default location: Core dumps may be processed with ""/usr/share/apport/apport %p %s %c %d %P %E"" (or dumping to /home/k",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7247:653,test,test,653,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7247,2,"['log', 'test']","['log', 'test']"
Testability,"## Bug Report. Hi @jamesemery and @sooheelee ,. Thanks very much for looking into: https://github.com/broadinstitute/gatk/issues/5230. I am running into one additional error. Reads that contain an insert spanning the full length of the read are causing an exception in SplitNCigarReads. ### Affected tool(s) or class(es); SplitNCigarReads. ### Affected version(s); - Tested on 4.0.3.0 and also branch: je_splitNCigarReadsSplitError (gatk-4.0.10.0-4-gb0f0ab3). ### Description ; SplitNCigarReads gives an Exception when a read that is entirely an insertion is encountered. By contrast, HaplotypeCaller does not seem to have a problem with these reads. Example read:; ```; seq.1028598	163	chr20	3146413	60	100I	=	3146307	-106	CCAATAATTCGACCCTATAAATGATGACCTCCGTTATCGGAAGGGCACAGAACCGTCAGCCGCAACACCAGCAGCTGTAGGCCCTGCTGGGCGCGCTGGG	8;72442435768::8443224764768:84:7534457962;99:787;628:7557;::7:72878:7;:7;:8754;9:::87:8799:7:7:87::	YA:Z:chr20:3145675:600M138N208I599M	MC:Z:100M	PG:Z:MarkDuplicates	RG:Z:1	NH:i:1	HI:i:1	YM:i:0	nM:i:100	YO:Z:chr20:3146278:+:56S44M	MQ:i:60	AS:i:140	YX:i:49	mc:i:3146406	ms:i:2300; ```. #### Steps to reproduce; Command line:; ```; gatk \; --java-options '-DGATK_STACKTRACE_ON_USER_EXCEPTION=true' \; SplitNCigarReads \; --reference $REF \; --input 100I_rna.bam \; --output gatk.split.bam \; > split.log 2>&1; ```. A tiny BAM file illustrating the problem is attached (it is gzipped to allow Github upload).; [100I_rna.bam.gz](https://github.com/broadinstitute/gatk/files/2456955/100I_rna.bam.gz). #### Actual behavior; Here is the stacktrace:; ```; ***********************************************************************. A USER ERROR has occurred: Badly formed genome unclippedLoc: Parameters to GenomeLocParser are incorrect:The stop position 3146412 is less than start 3146413 in contig chr20. ***********************************************************************; org.broadinstitute.hellbender.exceptions.UserException$MalformedGenomeLoc: Badly formed genome unclippedLo",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5293:367,Test,Tested,367,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5293,1,['Test'],['Tested']
Testability,## Bug Report. In commit afc0e4. line 457:; return FastMath.log(x) - 0.5 / x - inv * ((1.0 / 12) + inv * (1.0 / 120 - inv / 252));. Is it should be:; return FastMath.log(x) - 0.5 / x - inv * ((1.0 / 12) - inv * (1.0 / 120 - inv / 252));,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6133:60,log,log,60,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6133,2,['log'],['log']
Testability,"## Bug Report. We're finding that in rare instances that `GenotypeGVCFs` can emit a variant with a spanned allele (`*`), and a genotype that references the spanned allele, but fail to emit the upstream spanning variant. This seems like a bug to me - either the spanning variant should be emitted _or_ the spanned allele should revert to a reference call. FWIW I have a sneaking suspicion that this is related to setting a non-zero value for `-stand-call-conf` (see #5793). My guess is that in one part of the code it determines the upstream variant _will_ be emitted so retains the allele as spanned, but then somewhere later the upstream variant is filtered out. ### Affected tool(s) or class(es); GenotypeGVCFs. ### Affected version(s); - [x] Latest public release version [4.1.2.0]; - [ ] Latest master branch as of [not tested]. ### Description ; Here's the example from the VCF in the attached zip file:. ```; #CHROM POS ID REF ALT QUAL FILTER INFO FORMAT test_sample; chr17 46806234 . TC T 148.64 . ... GT:AD:DP:F1R2:F2R1:GQ:PL 0/1:208,25:239:116,16:90,8:99:156,0,6824; chr17 46806237 . TTCTCTCTCTCTC TTCTC,* 1528.04 . ... GT:AD:DP:F1R2:F2R1:GQ:PL 1/2:3,60,33:174:1,29,20:1,21,11:99:3633,1088,2142,1538,0,3285; ```. You can see from this that a) the first variant does not have a spanned allele, implying that there cannot be a spanning event further upstream and b) the second variant has a spanned allele that is present in the `1/2` genotype. #### Steps to reproduce. The attached zip file contains a reduced test case with a 3-record gVCF and a 2-record VCF that exhibits the problem. To reproduce:. 1. Unzip the attached zip file; 2. Edit `command.sh` to put in the path to HG19; 3. Run `. command.sh` in the directory with the extracted files. #### Expected behavior; Either the spanning variant should be emitted, or the spanned allele should not be. #### Actual behavior; A spanned allele is emitted when there is no spanning variant!. ZIP file with test case: [spanned_allele_not_spanne",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6031:824,test,tested,824,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6031,1,['test'],['tested']
Testability,"## Bug Report. getBasesAndBaseQualitiesAlignedOneToOne behaves differently, in respect to the existence of SOFT_CLIP, on reads that contains and do not contain INDELS (due to optimised code path). When no INDELS present, it returns arrays of clipped length; When INDELS present, it returns arrays of unclipped length (with NUL bytes past actual unclipped content). ### Affected tool(s) or class(es); AlignmentUtils.getBasesAndBaseQualitiesAlignedOneToOne . ### Affected version(s); Latest. ### Description ; When adding a test case (see steps to reproduce):. expected [CGATCG] but found [ATCGAT\0\0",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8040:522,test,test,522,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8040,5,['test'],"['test', 'tests']"
Testability,"## Bug Report; 18:47:11.757 INFO Funcotator - Shutting down engine; [September 19, 2021 6:47:11 PM CST] org.broadinstitute.hellbender.tools; .funcotator.Funcotator done. Elapsed time: 0.13 minutes.; Runtime.totalMemory()=1885339648; **org.broadinstitute.hellbender.exceptions.GATKException: Unable to query; the database for geneName: WASH7P**; ....; at org.broadinstitute.hellbender.cmdline.CommandLineProgram.ins; tanceMainPostParseArgs(CommandLineProgram.java:192); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.ins; tanceMain(CommandLineProgram.java:211); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Mai; n.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289); **Caused by: org.sqlite.SQLiteException: [SQLITE_IOERR_LOCK] I/O error i; n the advisory file locking logic (disk I/O error)**; at org.sqlite.core.DB.newSQLException(DB.java:909); ### Affected version(s); GATK 4.1.9.0. ### Description ; GATK Funcotator [SQLITE_IOERR_LOCK] I/O error in the advisory file locking logic (disk I/O error). I downloaded the data-sources by ""gsutil cp gs://broad-public-datasets/funcotator/funcotator_dataSources.v1.7.20200521s.tar.gz ."". I can't find useful information for this error. Thank you. #### Steps to reproduce; Using GATK jar /lustre1/ruibinxi_pkuhpc/ljx/software/gatk-4.1.9.0/gatk-; package-4.1.9.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_i; o_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjd; k.compression_level=2 -jar /lustre1/ruibinxi_pkuhpc/ljx/software/gatk-4; .1.9.0/gatk-package-4.1.9.0-local.jar Funcotator -R /home/ruibinxi_pkuh; pc/lustre1/ljx/reference_genomes/hg38_bwa/hg38.fa -V /home/ruibinxi_pku; hpc/lustre1/ljx/data/raodn/WES/GATK/P14P_filtered.vcf.gz -O /home/ruibi; nxi_pkuhpc/lustre1/ljx/data/raodn/WES/GATK/P14P_filtered_funcotator.maf; --output-file-format MAF --data-sources-path /home/ruibinx",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7474:877,log,logic,877,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7474,1,['log'],['logic']
Testability,"## Bug Report; GenotypeGVCFs stuck indefinitely at ""Initializing engine"" step. ### Affected tool(s) or class(es); gatk GenotypeGVCFs; ### Affected version(s); GATK v4.1.4.1 (installed in a `conda` convironment from the bioconda channel), on a RHEL server 7.6 (Maipo). ### Description ; Following the recommended pipeline of HaplotypeCaller, GenomicsDBImport and then GenotypeGVCFs, the last command hangs indefinitely and from the log file, it seems like it doesn't get past the ""Initialize engine"" step. This is an example of the standard error stream (after the `GenotypeGVCFs` job reached 20 hours wall time and was killed) :; ```; 22:28:44.293 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/export/user/home/miniconda3/envs/aDNA/share/gatk4-4.1.4.1-1/gatk-package-4.1.4.1-local.; jar!/com/intel/gkl/native/libgkl_compression.so; Dec 17, 2020 10:28:44 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 22:28:44.639 INFO GenotypeGVCFs - ------------------------------------------------------------; 22:28:44.640 INFO GenotypeGVCFs - The Genome Analysis Toolkit (GATK) v4.1.4.1; 22:28:44.640 INFO GenotypeGVCFs - For support and documentation go to https://software.broadinstitute.org/gatk/; 22:28:44.640 INFO GenotypeGVCFs - Executing as user@gc-prd-hpcn002 on Linux v3.10.0-957.27.2.el7.x86_64 amd64; 22:28:44.640 INFO GenotypeGVCFs - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_192-b01; 22:28:44.640 INFO GenotypeGVCFs - Start Date/Time: December 17, 2020 10:28:44 PM AEST; 22:28:44.640 INFO GenotypeGVCFs - ------------------------------------------------------------; 22:28:44.640 INFO GenotypeGVCFs - ------------------------------------------------------------; 22:28:44.640 INFO GenotypeGVCFs - HTSJDK Version: 2.21.0; 22:28:44.640 INFO GenotypeGVCFs - Picard Version: 2.21.2; 22:28:44.640 INFO GenotypeGVCFs - HTSJDK Defaults.COMPRESSION_LEVEL : 2; ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7007:431,log,log,431,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7007,1,['log'],['log']
Testability,"## Bug Report; JDK8 is no longer available for the current stable Debian release (buster). Trying to run gatk with an OpenJDK11 install fails. I anticipate a WONTFIX since this is dependency related, but I figured it would be good to let people know. ### Affected tool(s) or class(es); GATKRead, probably others too. ### Affected version(s); - [x] Latest public release version [4.1.2.0]; - [ ] Latest master branch as of [didn't test]. ### Description ; ```; Exception in thread ""main"" java.lang.IncompatibleClassChangeError: Inconsistent constant pool data in classfile for class org/broadinstitute/hellbender/transformers/ReadTransformer. Method 'org.broadinstitute.hellbender.utils.read.GATKRead lambda$identity$d67512bf$1(org.broadinstitute.hellbender.utils.read.GATKRead)' at index 65 is CONSTANT_MethodRef and should be CONSTANT_InterfaceMethodRef; 	at org.broadinstitute.hellbender.transformers.ReadTransformer.identity(ReadTransformer.java:30); 	at org.broadinstitute.hellbender.engine.GATKTool.makePreReadFilterTransformer(GATKTool.java:345); 	at org.broadinstitute.hellbender.engine.GATKTool.getTransformedReadStream(GATKTool.java:374); 	at org.broadinstitute.hellbender.engine.ReadWalker.traverse(ReadWalker.java:93); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1039); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:162); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:205); 	at org.broadinstitute.hellbender.Main.main(Main.java:291); ```. This error seems related to the JRE version. You can still install JDK8 manually but that's not ideal for many users. #### Steps to reproduce; Run GATK on OpenJDK11. ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6053:430,test,test,430,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6053,1,['test'],['test']
Testability,"## Bug Report; when I run the MarkDuplicatesSpark, it throws me an error: basically it shows the spark engine stopped when run this function. ; the part of the error log is here:; WARNING: An illegal reflective access operation has occurred; WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/rnaseq_pipeline_app/Apps/GATK/gatk-4.1.9.0/gatk-package-4.1.9.0-local.jar) to method java.nio.Bits.unaligned(); WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform; WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations; WARNING: All illegal access operations will be denied in a future release; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; 21/01/12 15:50:31 INFO SparkContext: Running Spark version 2.4.5; 21/01/12 15:50:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 21/01/12 15:50:31 INFO SparkContext: Submitted application: MarkDuplicatesSpark; 21/01/12 15:50:31 INFO SecurityManager: Changing view acls to: root; 21/01/12 15:50:31 INFO SecurityManager: Changing modify acls to: root; 21/01/12 15:50:31 INFO SecurityManager: Changing view acls groups to: ; 21/01/12 15:50:31 INFO SecurityManager: Changing modify acls groups to: ; 21/01/12 15:50:31 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); groups with view permissions: Set(); users with modify permissions: Set(root); groups with modify permissions: Set(); 21/01/12 15:50:31 INFO Utils: Successfully started service 'sparkDriver' on port 36657.; 21/01/12 15:50:31 INFO SparkEnv: Registering MapOutputTracker; 21/01/12 15:50:31 INFO SparkEnv: Registering BlockManagerMaster; 21/01/12 15:50:31 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information; 21/01/12 15:50:31 INFO B",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7035:166,log,log,166,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7035,1,['log'],['log']
Testability,"## Description; A user wants to run Funcotator with a mouse sample but has an issue running IndexFeatureFile. The GencodeGTF parser is specific to human data. Funcotator could be useful for users with non-human data if there is a workaround for these errors. ### GATK Information; GATK 4.1.9.0; gatk IndexFeatureFile -I gencode.vM25.annotation.gtf; This request was created from a contribution made by T. Li on January 25, 2021 04:37 UTC. Link: [https://gatk.broadinstitute.org/hc/en-us/community/posts/360076815852-Error-Running-IndexFeatureFile-on-Ensembl-Mouse-GTF-file-](https://gatk.broadinstitute.org/hc/en-us/community/posts/360076815852-Error-Running-IndexFeatureFile-on-Ensembl-Mouse-GTF-file-). #### Error Log. ```; Using GATK jar /gatk/gatk-package-4.1.9.0-SNAPSHOT-local.jar ; ; Running: ; ; java -Dsamjdk.use\_async\_io\_read\_samtools=false -Dsamjdk.use\_async\_io\_write\_samtools=true -Dsamjdk.use\_async\_io\_write\_tribble=false -Dsamjdk.compression\_level=2 -jar /gatk/gatk-package-4.1.9.0-SNAPSHOT-local.jar IndexFeatureFile -I gencode/mm10/gencode.vM25.annotation.gtf ; ; 04:33:13.081 INFO NativeLibraryLoader - Loading libgkl\_compression.so from jar:file:/gatk/gatk-package-4.1.9.0-SNAPSHOT-local.jar!/com/intel/gkl/native/libgkl\_compression.so ; ; Jan 25, 2021 4:33:13 AM shaded.cloud\_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine ; ; INFO: Failed to detect whether we are running on Google Compute Engine. ; ; 04:33:13.195 INFO IndexFeatureFile - ------------------------------------------------------------ ; ; 04:33:13.195 INFO IndexFeatureFile - The Genome Analysis Toolkit (GATK) v4.1.9.0-SNAPSHOT ; ; 04:33:13.195 INFO IndexFeatureFile - For support and documentation go to [https://software.broadinstitute.org/gatk/](https://software.broadinstitute.org/gatk/) ; ; 04:33:13.195 INFO IndexFeatureFile - Executing as root@b4c480938d0d on Linux v5.4.0-1029-aws amd64 ; ; 04:33:13.195 INFO IndexFeatureFile - Java runtime: OpenJDK 64-Bit Server",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7054:716,Log,Log,716,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7054,1,['Log'],['Log']
Testability,"## Documentation request. ### Description ; I propose that installation of gcc be added to the instructions on the GATK Github README.md. If gcc is not installed, HaplotypeCaller complains that the AVX instruction set is not available, even when it is. It falls back to slower LOGLESS_CACHING PairHMM. The fault is missing libgomp1, which is a required dependency of gcc. Since this documentation request is related to a ""bug"" that comes about from not installing necessary libraries, I'll include the bug report format below, in case someone else searches for solutions to this problem, as suggested by @lbergelson. ### Affected tool(s) or class(es); _HaplotypeCaller_, or any other tool that uses _PairHMM_. ### Affected version(s); -I think all as of _2019-06-20_. I tested on release version _4.1.2.0_. #### Steps to reproduce; Run HaplotypeCaller from a released jar on an Ubuntu VM that supports the AVX instruction set. Critically, do *NOT* install gcc on the VM. Installing gcc fixes this problem. #### Expected behavior; If you install gcc, that results in the installation of libgomp1, which allows the Intel library to load and use AVX acceleration. You could probably install libgomp1 on its own, but I did not test that.; > 14:51:01.013 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/home/ubuntu/gatk-4.1.2.0/gatk-package-4.1.2.0-local.jar!/com/intel/gkl/native/libgkl_utils.so; > 14:51:01.015 INFO NativeLibraryLoader - Loading libgkl_pairhmm_omp.so from jar:file:/home/ubuntu/gatk-4.1.2.0/gatk-package-4.1.2.0-local.jar!/com/intel/gkl/native/libgkl_pairhmm_omp.so; > 14:51:01.053 INFO IntelPairHmm - Using CPU-supported AVX-512 instructions; > 14:51:01.053 INFO IntelPairHmm - Flush-to-zero (FTZ) is enabled when running PairHMM; > 14:51:01.054 INFO IntelPairHmm - Available threads: 16; > 14:51:01.054 INFO IntelPairHmm - Requested threads: 8; > 14:51:01.054 INFO PairHMM - Using the OpenMP multi-threaded AVX-accelerated native PairHMM implementation. #### Actual b",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6012:770,test,tested,770,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6012,1,['test'],['tested']
Testability,"## Documentation request. ### Description ; I was unable to successfully follow the R setup instructions required to run integration tests locally. I don't know whether this is a general concern regarding initial setup on Mac OS X High Sierra 10.13.6, or the problem is specific to my system. . #### R installation itself; Expected: `brew install R` would install R with all necessary core functionality.; Actual: `brew install R` installed a version of R without X11 support. The binary I downloaded from [CRAN](https://cran.r-project.org/bin/macosx/) had the proper support. #### R package installation; Expected `sudo Rscript scripts/docker/gatkbase/install_R_packages.R` would install the necessary packages for R scripts needed.; Actual: Failure to compile source packages, with an error like `clang: error: unsupported option '-fopenmp'`. I made some attempts to update my local `clang` but was unsuccessful. Instead, I installed the packages at the R prompt:; ```; $ R; > install.packages('ggplot2'); > install.packages('reshape'); > install.packages('gplots'); > install.packages('gridExtra'); > install.packages('gsalib'); > install.packages('data.table'); > quit(); ```. After doing so, my test run `TEST_TYPE=integration ./gradlew shadowJar test` succeeded.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5389:133,test,tests,133,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5389,3,['test'],"['test', 'tests']"
Testability,"## Documentation request. Incorrect statistical definition in the article [Calculation of PL and GQ by HaplotypeCaller and GenotypeGVCFs](https://gatk.broadinstitute.org/hc/en-us/articles/360035890451). The conditional probability in the definition of PL is backwards. ### Description . The article contains the following (between the lines):. ----. The basic formula for calculating PL is:. $$ PL = -10 * \log{P(Genotype | Data)} $$. where P(Genotype | Data) is the conditional probability of the Genotype given the sequence Data that we have observed. The process by which we determine the value of P(Genotype | Data) is described here. ----. The genotype likelihood _and, thus, PL values_ are actually P(Data|Genotype). ; P(Genotype|Data) is the _posterior_.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7577:407,log,log,407,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7577,1,['log'],['log']
Testability,"## Documentation request; Filing issue at the request of @samuelklee stemming from the discussion in https://github.com/broadinstitute/gatk/pull/5829. ### Tool(s) or class(es) involved; GermlineCNVCaller and related tools. . ### Description ; In particular, I am currently needing information for the gCNV tutorial writeup for the following parameters. What direction increases sensitivity?. - `--depth-correction-tau` has a default of 10000.0 (10K) and defines the precision of read-depth concordance with the global depth value.; - `--p-active` has a default of 1e-2 (0.01) and defines the expected probability of CNV events.; - `p-alt` has a default of 1e-6 (0.000001) and defines the prior probability of CNV states. . Here are some other parameters of particular interest and descriptions I worked on with help from @mwalker174 and @samuelklee:; - Decreasing `--class-coherence-length` from its default of 10,000bp to 1000bp decreases the expected length of contiguous segments. Factor for bin size when tuning. ; - Decreasing `--cnv-coherence-length` from its default 10,000bp to 1000bp decreases the expected length of CNV events. Factor for bin size when tuning. ; - Turning off `--enable-bias-factors` from the default `true` state to `false` turns off active discovery of learnable bias factors. This should always be on for targeted exome data and in general can be turned off for WGS data. ; - Decreasing `--interval-psi-scale` from its default of 0.001 to 1.0E-6 reduces the scale the tool considers normal in per-interval noise.; - Decreasing `--log-mean-bias-standard-deviation` from its default of 0.1 to 0.01 reduces what is considered normal noise in bias factors.; - Decreasing `--sample-psi-scale` from its default of 0.0001 to 1.0E-6 reduces the scale that is considered normal in sample-to-sample variance. . In general, all of the parameter descriptions could be friendlier. ----",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5850:1560,log,log-mean-bias-standard-deviation,1560,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5850,1,['log'],['log-mean-bias-standard-deviation']
Testability,"## Feature request / documentation request. ### Tool(s) or class(es) involved; Reading files from non-public GCS paths. ### Description; I did not have Application Default Credentials set up when I tried to read from a private bucket. This failed, as expected. Could we add a comment explaining that running `gcloud auth application-default login` is the necessary step to making this work? I didn't see anything on the forum about how to solve this. The solution was in the comments to #2394. ### Observed; GATK errored out with a stack trace:; ```; code: 401; message: Anonymous caller does not have storage.objects.get access to joel-cram/SAM24339124.cram.; reason: required; location: Authorization; retryable: false; com.google.cloud.storage.StorageException: Anonymous caller does not have storage.objects.get access to joel-cram/SAM24339124.cram.; at com.google.cloud.storage.spi.v1.HttpStorageRpc.translate(HttpStorageRpc.java:220); at com.google.cloud.storage.spi.v1.HttpStorageRpc.get(HttpStorageRpc.java:415); at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:198); at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:195); at shaded.cloud_nio.com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:89); at com.google.cloud.RetryHelper.run(RetryHelper.java:74); at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:51); at com.google.cloud.storage.StorageImpl.get(StorageImpl.java:195); at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.checkAccess(CloudStorageFileSystemProvider.java:673); at java.nio.file.Files.exists(Files.java:2385); at htsjdk.samtools.util.IOUtil.assertFileIsReadable(IOUtil.java:429); at org.broadinstitute.hellbender.engine.ReadsDataSource.<init>(ReadsDataSource.java:206); ```. ```; Caused by: shaded.cloud_nio.com.google.api.client.googleapis.json.GoogleJsonResponseException: 401 Unauthorized; {; ""code"" : 401,; ""errors"" : [ {; ""domain"" : ""global"",; ""location"" : ""Authoriza",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5468:341,log,login,341,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5468,1,['log'],['login']
Testability,"## Feature request. ### Description; I am using Splitintervals in a couple of spots in my somatic variant calling workflow to set up scatter parallelization. My problem is that some of my other tools require BEDs to operate correctly, and because GATK tools can use BED files as the interval (-L) parameter, I just default to using BED files. To do this, I run SplitIntervals and then IntervalListToBed, which works fine, but add a little (in my opinion) unneeded code, runtime, and logging. . To circumvent this, I was wondering if it would be possible to add a parameter to the SplitInterval tool for outputting BED files (or other formats, if other folks so desire that) instead of just interval_lists. I imagine it would make this tool all the more valuable in any bioinformaticist's toolbox, since it would allow convenient splitting of a number of common bioinformatics file formats.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6555:483,log,logging,483,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6555,1,['log'],['logging']
Testability,"## Feature request. ### Tool involved - GATK cnv_somatic_pair_workflow version 4.2.0.0; Link to main wdl - https://dockstore.org/workflows/github.com/broadinstitute/gatk/cnv_somatic_pair_workflow:4.2.0.0?tab=files. ### Description; Requesting for addition of a new feature called the `IndexFeatureFile` to be added as initial step in the `Funcotate_Segment` task of the `cnv_somatic_pair_workflow` wdl . **Detailed description:** ; An error was encountered while running the CNVSomaticPairWorkflow: `“A USER ERROR has occurred: Input /cromwell_root/fc-a21facc8-da03-4987-bb5b-dfadbfda2747/a923baec-ddd9-429a-b046-1f03c5ebda64/CNVSomaticPairWorkflow/42ba0311-ba93-4fdd-9b5e-bd7348c0ad42/call-CallCopyRatioSegmentsTumor/AMP-18-003-TIS.called.seg must support random access to enable traversal by intervals. If it's a file, please index it using the bundled tool IndexFeatureFile”`. - The FuncotateSegments task is asking an index file for the seg file, which is unusual to create an index for seg; - The same command from the cnv wdl was tested on-prem (Broad server using ish) by transferring all required files on-prem, this was done to replicate the error and find a solution without wasting compute money or resources on Terra; - To fix the issue, we initially ran Indexfilefeature tool (on-prem) for creating index file for the seg file, using the following command. ; `gatk IndexFeatureFile -I seg file`; - And then ran the main command `./gatk --java-options -Xmx2000m FuncotateSegments --data-sources-path data_sources_directory --ref-version hg19 --output-file-format SEG -R fasta_file_path --segments seg_file_path -O output_file_path/{basename}.seg.funcotated.tsv -L interval_list_path --transcript-selection-mode CANONICAL`. After this was complete, annotated file was generated correctly. In conclusion - the error identified is that `Indexfilefeature` tool had to be run as the first step. Requesting this change to be incorporated into `cnv_somatic_funcotate_seg_workflow.wdl`.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7294:1036,test,tested,1036,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7294,1,['test'],['tested']
Testability,"## Feature request. ### Tool(s) involved; VariantFiltration. ### Description; The tool throws a bunch of WARN messages when an annotation is missing a value. For example, when the RankSum annotations are not present in homozygous sites, the tool prints out a bunch of WARN messages that fill up the user's log file. Can this problematic WARN message be moved to be OneShotLogger?. This Issue was generated from your [forums] ; [forums]: https://gatkforums.broadinstitute.org/gatk/discussion/comment/42636#Comment_42636",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3828:306,log,log,306,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3828,1,['log'],['log']
Testability,"## Feature request. ### Tool(s) or class(es) involved. SV pipeline, Funcotator, etc. ### Description. In trying to build test data for SV, time and time again we face the problem of not being able to find actual desired events on the two chromosomes 20 and 21, hence end up having to painfully perform all kinds of coordinate hacks in order to have enough test coverage. It seems that the Funcotator team is also facing a similar issue. Therefore it will be great if the whole reference genome for HG38, and maybe HG19 as well, can be included in the tests, so that tool developers spend less time worrying about hassles in moving real events to chr20 and chr21. One of the potential downside is obvious: it increases the repo size and time for running tests (downloading a bigger file) on Travis.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5111:121,test,test,121,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5111,4,['test'],"['test', 'tests']"
Testability,"## Feature request. ### Tool(s) or class(es) involved; All WDL testing. ### Description; Currently, our WDL tests are not instrumented to look inside the outputs of a cromwell run. This stifles some WDL testing of differing parameters, since (for example) we cannot easily see if a file was created, such as a bamout.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6013:63,test,testing,63,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6013,3,['test'],"['testing', 'tests']"
Testability,"## Feature request. ### Tool(s) or class(es) involved; All WDL tests (Mutect2, CNV, Mitochondria pipeline, etc). ### Description; I'd like to be able to include tasks in GATK WDLs that use NIO (tasks with `String input_file` rather than `File input_file`). When I tried this with local git lfs files I got an error saying that the file could not be found (even though the file was being downloaded correctly). I then tried putting the file in `gs://hellbender/test/resources/large`, but when the tool tried to run on travis I got a permission error (see below). It would be great if the WDL tests all ran in the cloud since that's the main way we expect to run these WDLs. It would also be great it the local tests could account for NIO tasks (especially as we want to make more tasks use NIO in the future). ```; com.google.cloud.storage.StorageException: Error code 404 trying to get security access token from Compute Engine metadata for the default service account. This may be because the virtual machine instance does not have permission scopes specified. It is possible to skip checking for Compute Engine metadata by specifying the environment variable NO_GCE_CHECK=true.; at com.google.cloud.storage.spi.v1.HttpStorageRpc.translate(HttpStorageRpc.java:227); at com.google.cloud.storage.spi.v1.HttpStorageRpc.get(HttpStorageRpc.java:438); at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:239); at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:236); at shaded.cloud_nio.com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:105); at com.google.cloud.RetryHelper.run(RetryHelper.java:76); at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:50); at com.google.cloud.storage.StorageImpl.get(StorageImpl.java:235); at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.checkAccess(CloudStorageFileSystemProvider.java:687); at java.nio.file.Files.exists(Files.java:2385); at htsjdk.samtools.util.IOUtil.asse",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5855:63,test,tests,63,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5855,4,['test'],"['test', 'tests']"
Testability,"## Feature request. ### Tool(s) or class(es) involved; Docker container environment for FireCloud / GATK. ### Description. I started a FireCloud instance with a GATK example. It looks like although conda does seem to be correctly pulling TensorFlow from the Anaconda repository, TensorFlow is still not being enabled with Intel MKL-DNN (which would make TensorFlow much faster on CPU). To test this, you can start a notebook or python session and do:. `import tensorflow; print(tensorflow.pywrap_tensorflow.IsMklEnabled())`. If True, then MKL-DNN is enabled in TensorFlow. Currently, this is showing up as false. I'm wondering whether I could work with someone (possibly Sam @lucidtronix) to update the conda environment. Also, the compute instances on FireCloud are using older CPU hardware (AVX-2). Is there any way to update this to a Skylake or Cascade Lake instance (AVX-512/VNNI)?. Thanks.; -Tony",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6020:389,test,test,389,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6020,1,['test'],['test']
Testability,"## Feature request. ### Tool(s) or class(es) involved; HaplotypeCaller of GATK v4.2.0.0. ### Description; Hi, I'm using GATK to call variants in Aedes Aegypti samples.; My output is spammed with WARNINGs (see below). I wondered:; 1. If this was an issue, i.e. my samples have bad QC/Coverage? Or is it something expected? In particular, there is one sample that seems to generates much more warnings than the others, so that's why I thought it could be a coverage issue?; 2. Is there a way to deactivate these warnings, or print them only once?. ### Log example (only the first lines, the log is several gigs filled with these warnings); ```; 16:16:40.556 WARN DepthPerSampleHC - Annotation will not be calculated at position 1:18938 and possibly subsequent; genotype for sample TOTO is not called; 16:16:40.556 WARN StrandBiasBySample - Annotation will not be calculated at position 1:18938 and possibly subsequent; genotype for sample TOTO is not called; 16:16:40.568 WARN DepthPerSampleHC - Annotation will not be calculated at position 1:18946 and possibly subsequent; genotype for sample TOTO is not called; 16:16:40.568 WARN StrandBiasBySample - Annotation will not be calculated at position 1:18946 and possibly subsequent; genotype for sample TOTO is not called; 16:16:40.726 WARN DepthPerSampleHC - Annotation will not be calculated at position 1:19264 and possibly subsequent; genotype for sample TOTO is not called; 16:16:40.726 WARN StrandBiasBySample - Annotation will not be calculated at position 1:19264 and possibly subsequent; genotype for sample TOTO is not called; 16:16:42.644 WARN DepthPerSampleHC - Annotation will not be calculated at position 1:20675 and possibly subsequent; genotype for sample TOTO is not called; 16:16:42.644 WARN StrandBiasBySample - Annotation will not be calculated at position 1:20675 and possibly subsequent; genotype for sample TOTO is not called; 16:16:42.646 WARN DepthPerSampleHC - Annotation will not be calculated at position 1:20685 and possibl",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7344:550,Log,Log,550,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7344,2,"['Log', 'log']","['Log', 'log']"
Testability,"## Feature request. ### Tool(s) or class(es) involved; Mutect/HaplotypeCaller. ### Description. **(Background)**; I've spent a lot of time working with Mutect2 in the past year (I've built a whole workflow centered around this tool). But, while I recognize that the internal reassembly feature leads to ""best-in-class"" results in terms of calling variants, for my purposes it generally just creates headaches since it makes interpreting (certain) calls and verifying (certain) base-level behaviors/expectations very difficult (even when looking at the bamout and assembly logs). Moreover, while we know our alignment process isn't perfect, we think it's appropriate for our purposes, and we would gladly accept the loss of a few calls to be able to have more control over the expected behaviors. With that, I purpose a ""--skip-assembly"" flag that would cause the Mutect2/HaplotypeCaller engine to use the original alignment information to determine the haplotypes. . All that said, I imagine this could be a niche feature request, so I've spent some time digging through the source code trying to see if there could be a quick fix that could be made available to whatever group of developers would want this. It seemed like there could be another conditional branched added here (https://github.com/broadinstitute/gatk/blob/9ff3f8b180c063a3fa67dae129b0cbd04012448e/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/ReadThreadingAssembler.java#L159) to build a `resultSet` based on a non-assembly based approach. However, I'm not certain how using the original alignment information would affect the statistics employed for genotyping the candidate haplotypes, so I'm starting to back off implementing a custom fix and hoping the experts can help (or at least explain to me why this feature is not currently possible OR if there is a way that I can access this behavior that I'm missing). Thank you for the consideration. **(TL;DR)**; Introduce a `--skip-assembly`",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7064:572,log,logs,572,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7064,1,['log'],['logs']
Testability,"## Feature request. ### Tool(s) or class(es) involved; SelectVariants (all versions -- tested most recently with 4.0.9.0). ### Description; SelectVariants has an option for excluding specific sites by rsID, `--exclude-ids`. Currently the matching is done by exact string matching. The limitation is that if I have a site with two rsIDs (as appears in the 1000 Genomes dataset), I can't filter against just one of them. For example, if I want to exclude this site from 1000G participant HG00096 (because it makes my synthetic data generator choke, if you must know):. 3523879:16	68401338	rs554836707;rs56090907	CGTGCGCTGCT	CTGCT,C	100	PASS <snip>. I have to specify `--exclude-ids 'rs554836707;rs56090907'` in my SelectVariants command. I would like to be able to specify just `--exclude-ids rs554836707` or `--exclude-ids rs56090907` with the same result (the site is excluded). Right now if I do use just one like that, the site is not excluded because the pattern fails to match. The reason I want to be able to do that is because there are several other similar sites that I need to exclude, so I make an array of rsIDs to exclude, e.g. provide . ````; Array[String] = [; ""rs575450111"",; ""rs151266607"",; ""rs557010312"",; ""rs564559134"",; ""rs560466806"",; ""rs140802196"",; ""rs554836707"",; ""rs56090907""; ]; ````. as an input to my WDL, which handles it in the command block as . --exclude-ids ${sep=' --exclude-ids ' exclusionList}. Right now I have to use . ````; [; ""'rs575450111;rs151266607'"",; ""'rs557010312;rs564559134'"",; ""'rs560466806;rs140802196'"",; ""'rs554836707;rs56090907'""; ]; ````. which is stylistically ugly and would not cover cases where only one rsID is annotated for whatever reason.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5260:87,test,tested,87,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5260,1,['test'],['tested']
Testability,"## Feature request. ### Tool(s) or class(es) involved; _FindBreakpointEvidenceSpark_, _StructuralVariationDiscoveryPipelineSpark_, when using _XGBoostEvidenceFilter.java_. ### Description; The SV pipeline filters BreakpointEvidence based on BreakpointDensityFilter, or optionally XGBoostEvidenceFilter. The XGBoostEvidenceFilter uses a saved classifier model trained with Python code external to the GATK. This poses two main problems:; 1) The external Python code was designed for proof-of-principle and method development, not maintainability or ease of use. Additionally, GATK users and developers are assumed to be familiar with Java, not necessarily Python.; 2) The external Python code must share heterogeneous data with Java for unit/integration tests (supplying test BreakpointEvidence, expected classifier features, and expected classifier probabilities). Currently this is done via JSON files organized to (invertibly) store Pandas or Numpy objects. The resulting code to load these JSON files in on the Java side is complex.; These problems can be resolved by; 1) Replacing external python code by porting to an **experimental** tool in the GATK.; 2) Replacing JSON files with a serialization strategy currently supported by the GATK (e.g. Kryo). Additional benefits can be obtained by ensuring that the classifier-training subroutines are sufficiently general to speed development for other projects that may want to use boosted decision trees for classification.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4922:753,test,tests,753,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4922,2,['test'],"['test', 'tests']"
Testability,"## Feature request. ### Tool(s) or class(es) involved; _Funcotator tests_. ### Description; Now that the test data sources have been refactored, we need to go through and remove any extraneous data sources that are no longer necessary.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5350:105,test,test,105,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5350,1,['test'],['test']
Testability,## Feature request. ### Tool(s) or class(es) involved; _FuncotatorUtilsUnitTest::provideDataForTestGetAlignedRefAllele_. ### Description; Need to add test cases for the following: ; - tests with Strand.NEGATIVE!!!!; - tests with alt allele longer/shorter than ref allele!,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5351:150,test,test,150,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5351,3,['test'],"['test', 'tests']"
Testability,"## Feature request. ### Tool(s) or class(es) involved; _Funcotator_, _GencodeFuncotationFactoryUnitTest::testCreateFuncotations_. ### Description; The tests all assume `chr` is in contig names right now. This is wrong for the universal b37 reference that was put into the test baseline. However, our datasources are all hg19, so there is an evil mismatch. The horror of b37 vs hg19 raises it's ugly head once more. We need to instrument `GencodeFuncotationFactoryUnitTest::testCreateFuncotations` to allow for the mismatch.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5356:151,test,tests,151,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5356,3,['test'],"['test', 'testCreateFuncotations', 'tests']"
Testability,"## Feature request. ### Tool(s) or class(es) involved; _Funcotator_. ### Description. Need to add more indel test cases for HG38 for completeness. The set of test cases should be: . {3' and 5' UTRs, exons, introns, intronic and exonic splice sites, 3' and 5' flanks}; x; lengths in bases of {1,2,3,5} (maybe a subset of these, TBD); x; {PIK3CA, MUC16 transcripts, HLA/alternate contig targets}; X; {insertion, deletion}; x; {hg38}",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5223:109,test,test,109,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5223,2,['test'],['test']
Testability,"## Feature request. ### Tool(s) or class(es) involved; _org.broadinstitute.hellbender.engine.ProgressMeter_. ### Description; `ProgressMeter` does not currently let the user know how much longer to expect a tool to run on its data. . This can be computed by keeping a tally of the number of entries complete, how long they take, and how many there are in total. . The expected remaining time should then be logged with each log statement.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5179:407,log,logged,407,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5179,2,['log'],"['log', 'logged']"
Testability,"## Feature request. ### Tool(s) or class(es) involved; combine_tracks.wdl. ### Description; In order for outputs from GATK CNV to be usable by GISTIC2, we need to have a conversion step. Here is mostly un-tested WDL that should work:. ```; #UNSUPPORTED -- simple conversion of a merged & pruned seg file (from the CNV postprocessing workflow) to the GISTIC2 format.; # No column headers printed. Each column is:; #; #(1) Sample (sample name); #(2) Chromosome (chromosome number); #(3) Start Position (segment start position, in bases); #(4) End Position (segment end position, in bases); #(5) Num markers (number of markers in segment); #(6) Seg.CN (log2() -1 of copy number); #; # This has barely been tested; #; workflow ConvertMergedPrunedSegsToGistic2 {; File cnv_postprocessing_tumor_with_tracks_pruned_merged_seg; String docker; call Gistic2Convert {; input:; input_file = cnv_postprocessing_tumor_with_tracks_pruned_merged_seg,; docker = docker; }. output {; File cnv_postprocessing_tumor_with_tracks_pruned_merged_seg_gistic2 = Gistic2Convert.output_file_gistic2; }; }. task Gistic2Convert {; File input_file; String docker; String output_file = basename(input_file) + "".gistic2.seg"". command <<<; set -e; python <<EOF; import csv; input_file = ""${input_file}""; output_file = ""${output_file}"". """"""; The column headers are:. (1) Sample (sample name); (2) Chromosome (chromosome number); (3) Start Position (segment start position, in bases); (4) End Position (segment end position, in bases); (5) Num markers (number of markers in segment); (6) Seg.CN (log2() -1 of copy number); """""". if __name__ == ""__main__"":; with open(input_file, 'rb') as tsvinfp, open(output_file, 'wb') as tsvoutfp:; tsvin = csv.DictReader(tsvinfp, delimiter='\t'); tsvout = csv.writer(tsvoutfp, delimiter=""\t""); for r in tsvin:; int_ify_num_points = r[""NUM_POINTS_COPY_RATIO""].replace("".0"", """"); outrow = [r[""SAMPLE""], r[""Chromosome""], r[""Start""], r[""End""], int_ify_num_points, r[""MEAN_LOG2_COPY_RATIO""]]; print(outrow)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5283:205,test,tested,205,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5283,2,['test'],['tested']
Testability,"## Feature request. Since CombineVariants will not be ported, we need equivalent functionality to its ability to annotate ""set"", ie which callset(s) a site is present in. Here is an excerpt from a tutorial that describes this functionality in action:. ----. To find out which set each variant belongs to, we can use CombineVariants. CombineVariants has a way to annotate each site with which set the site belongs to. For example, if a site is in GIAB and failed hard filtering but passed VQSR, CombineVariants will annotate the site with set=G-filterInH-V. The ""filterIn"" flag before the filtering method tells us the site failed the filtering method, hence it was ""filtered"" in the set. java -jar GenomeAnalysisTK.jar \; 	-T CombineVariants \; 	-R ref/human_g1k_b37_20.fasta \; 	-V:G truth_dataset/NA12878.GIAB.vcf \; 	-V:H vcfs/NA12878.hard.filtered.vcf \; 	-V:V vcfs/NA12878.VQSR.filtered.vcf \; 	-o sandbox/NA12878.Combined.vcf . The set-annotated VCF looks like this:. ````; #CHROM POS ID REF ALT QUAL FILTER INFO FORMAT INTEGRATION NA12878; 20 61795 rs4814683 G T 2034.16 PASS AC=2;AF=0.500;AN=4;(...);set=Intersection​ ​ GT:AD:ADALL:DP :GQ:PL 0/1:218,205:172,169:769:99 0/1:30,30:.:60:99:1003,0,1027; ````. In this record, ""set=Intersection​"" indicates this record was present and unfiltered in all callsets considered. Here is a key of all the possible combinations for this 3-way venn:. | Meaning | Annotation |; |:-|:-|; | In GIAB only | G |; | In GIAB and failed VQSR only | G-H-filterInV |; | In GIAB and failed both hard filtering and VQSR | G-filterInH-filterInV |; | In GIAB and failed hard filtering only | G-filterInH-V |; | In GIAB and passed both hard filtering and VQSR | Intersection |; | Not in GIAB and failed VQSR only | H-filterInV |; | Not in GIAB and failed both hard filtering and VQSR | FilteredInAll |; | Not in GIAB and failed hard filtering only | filterInH-V |; | Not in GIAB and passed both hard filtering and VQSR | H-V |",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2489:903,sandbox,sandbox,903,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2489,1,['sandbox'],['sandbox']
Testability,"## System. * GATK4 a1eee32e84c21c2f265d248c5f47789ae0ba2b37; * Mac OS X 10.11.6 x86_64; * machdep.cpu.features: FPU VME DE PSE TSC MSR PAE MCE CX8 APIC SEP MTRR PGE MCA CMOV PAT PSE36 CLFSH DS ACPI MMX FXSR SSE SSE2 SS HTT TM PBE SSE3 DTES64 MON DSCPL VMX SMX EST TM2 SSSE3 CX16 TPR PDCM SSE4.1 SSE4.2 POPCNT; * machdep.cpu.extfeatures: SYSCALL XD EM64T LAHF RDTSCP TSCI; * java version ""1.8.0_60""; * Java(TM) SE Runtime Environment (build 1.8.0_60-b27); * Java HotSpot(TM) 64-Bit Server VM (build 25.60-b23, mixed mode). ## Error. When updating a downstream project with the latest master and running the integration/unit tests with gradle, it generates the following error. ```; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGILL (0x4) at pc=0x00000001236427f4, pid=4010, tid=20739; #; # JRE version: Java(TM) SE Runtime Environment (8.0_60-b27) (build 1.8.0_60-b27); # Java VM: Java HotSpot(TM) 64-Bit Server VM (25.60-b23 mixed mode bsd-amd64 compressed oops); # Problematic frame:; # C [libgkl_compression7227189416687158431.dylib+0x17f4] Java_com_intel_gkl_compression_IntelDeflater_resetNative+0x164; #; # Failed to write core dump. Core dumps have been disabled. To enable core dumping, try ""ulimit -c unlimited"" before starting Java again; #; # An error report file with more information is saved as:; # /Users/daniel/workspaces/ReadTools/hs_err_pid4010.log; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; # The crash happened outside the Java Virtual Machine in native code.; # See problematic frame for where to report the bug.; #; ```. Error report file: [hs_err_pid4010.log.txt](https://github.com/broadinstitute/gatk/files/1259963/hs_err_pid4010.log.txt). ## Forcing other GKL versions. * 0.5.2 (working); * 0.5.3 (failing); * 0.5.5 (failing); * 0.5.6 (failing); * 0.5.7 (failing); * 0.5.8 (failing)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3532:623,test,tests,623,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3532,4,"['log', 'test']","['log', 'tests']"
Testability,"## System; * Mac OS X 10.11.6 x86_64; * Java HotSpot(TM) 64-Bit Server VM 1.8.0_60-b27. ## Problem; I'm trying to update my project ([ReadTools](https://github.com/magicDGS/ReadTools)) to the latest version of GATK and this dependency throws the following error with some of my gradle tests and while running an uber-jar (using `--use_jdk_deflater false`):. ```; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGILL (0x4) at pc=0x000000011d925644, pid=7088, tid=20739; #; # JRE version: Java(TM) SE Runtime Environment (8.0_60-b27) (build 1.8.0_60-b27); # Java VM: Java HotSpot(TM) 64-Bit Server VM (25.60-b23 mixed mode bsd-amd64 compressed oops); # Problematic frame:; # C [libgkl_compression8215566221555962564.dylib+0x1644] Java_com_intel_gkl_compression_IntelDeflater_resetNative+0x164; #; # Failed to write core dump. Core dumps have been disabled. To enable core dumping, try ""ulimit -c unlimited"" before starting Java again; #; # An error report file with more information is saved as:; # /Users/daniel/workspaces/ReadTools/hs_err_pid7088.log; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; # The crash happened outside the Java Virtual Machine in native code.; # See problematic frame for where to report the bug.; #; ```. Find attached the log: [hs_err_pid7088.log.txt](https://github.com/broadinstitute/gatk/files/652421/hs_err_pid7088.log.txt)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2315:285,test,tests,285,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2315,5,"['log', 'test']","['log', 'tests']"
Testability,### **Addresses** ; https://github.com/broadinstitute/dsp-spec-ops/issues/192. ### **Commit Summary**; - Updated StorageAPIAvroReader.java; > - To handle the use case if no data is returned from BQ. ### **Tested**; - Updated BigQueryUtilsUnitTest.java; > - testQueryWithEmptyDatasetStorageAPI() function to test code changes,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7082:205,Test,Tested,205,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7082,9,"['Test', 'test']","['Tested', 'test', 'testQueryWithEmptyDatasetStorageAPI']"
Testability,"### **Addresses** ; https://github.com/broadinstitute/dsp-spec-ops/issues/199. ### **Commit Summary**. -Add labels to Sample list, Extract Cohort, and Extract features; - Edit Bigquery Utils Testing ; - Add labels as an input to a Bigquery functions ; - Created UID class for a unique identifier . ### **Output**; For Sample list, Extract Cohort and Extract features; ```; ""query"", ""Run_SampleTable_<UID>""; ""query"", ""extract_cohort_<UID>""; ""query"", ""extract_features_<UID>""; ```; Testing:; ```; ""test_query"", ""get_all_records_<UID>""; ""test_query"", ""test_where_clause_<UID>""; ""test_query"", ""test_batch_mode_<UID>""; ""test_query"", ""test_specified_execute_query_<UID>""; ""test_query"", ""test_storage_api_<UID>""; ""test_query"", ""test_storage_api_with_empty_dataset_<UID>"". ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7115:191,Test,Testing,191,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7115,2,['Test'],['Testing']
Testability,### **Addresses** ; https://github.com/broadinstitute/dsp-spec-ops/issues/246. ### **Commit Summary**; - Created AvroFileReader ; - Created a sampleAvroFile; - Update ExtractCohort and ExtractCohortEngine to accept a AvroFile. Testing:; Created a test for AvroFileReader,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7174:227,Test,Testing,227,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7174,2,"['Test', 'test']","['Testing', 'test']"
Testability,### **Addresses** ; https://github.com/broadinstitute/gatk/pull/7115. ### **Commit Summary**; -Created AvroFileReader; - Update ExtractCohort and ExtractCohortEngine to accept a AvroFile. Testing:; Created a test for AvroFileReader,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7127:188,Test,Testing,188,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7127,2,"['Test', 'test']","['Testing', 'test']"
Testability,"### Affected class(es); All test classes in GATK (and downstream projects) extending `BaseTest`. ### Affected version(s); - [x] Latest public release version; - [x] Latest master branch. ### Description ; The GATK toolkit assumes `US` locale (set in a `Main` static method), which in turn produces all the test files using the `US` locale; if the test suite is run in a different locale, it might fail unexpectedly. For example, if the locale has a comma-separated decimals instead of dot-separated, comparing the expected file output with `US` locale against the generated by the tests fail. . #### Expected behavior; `BaseTest` should set the locale in a `@BeforeSuite` method (or static method) to set the assumptions of the toolkit to all tests (also for downstream toolkits). #### Actual behavior; `BaseTest` picks default locale.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5012:28,test,test,28,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5012,5,['test'],"['test', 'tests']"
Testability,"### Affected tool(s) or class(es); Funcotator. ### Affected version(s); - [ ] Latest master branch as of June 7, 2018. ### Description ; Currently, the metadata for `GencodeFuncotation` will always be default, unknown for all fields. However, we know what each field is, so we could populate . This cannot be seen anywhere by a user, yet. However, future requirements will probably cause the metadata to be rendered into a VCF header or a MAF comment, so this should be populated. #### Expected behavior; The Gencode funcotations should not have unknown types and descriptions. This can be validated with an automated test. #### Actual behavior; The Gencode funcotations have unknown types and descriptions.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4857:618,test,test,618,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4857,1,['test'],['test']
Testability,"### Affected tool(s) or class(es); PostprocessGermlineCNVCalls . ### Affected version(s); - [X ] Latest public release version [4.3.0.0]. ### Description ; Hello, I am a regular user of the gCNV pipeline of GATK4. Since version GATK 4.2.0.0, you have introduced the germline CNV calling joint which I wanted to try and I encountered several problems. So I used, in order, the DetermineGermlineContigPloidy and GermlineCNVCaller tools (cutting my target into 8 bins) version 4.3.0.0 on a cohort of 540 patients. Then I used the PostProcessGermlineCaller tool to produce the VCF files for these patients. Next, I used the JointGermlineCNVSegmentation beta tool to produce a multisample VCF which I reused with PostProcessGermlineCaller to produce joined VCFs. The problem is that the time needed to produce each VCF file has been multiplied by 20 (on average 120 minutes compared to 6), which makes it difficult to use on large cohorts. Here is an extract of the logs, from a sample without, then with the --clustered-breakpoints option: ; #PostprocessGermlineCNVCalls. 14:23:53.500 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/gatk/gatk-package-4.3.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; 14:23:54.242 INFO PostprocessGermlineCNVCalls - ------------------------------------------------------------; 14:23:54.242 INFO PostprocessGermlineCNVCalls - The Genome Analysis Toolkit (GATK) v4.3.0.0; 14:23:54.242 INFO PostprocessGermlineCNVCalls - For support and documentation go to https://software.broadinstitute.org/gatk/; 14:23:54.262 INFO PostprocessGermlineCNVCalls - Executing as [tintest@dahu132.u-ga.fr](mailto:tintest@dahu132.u-ga.fr) on Linux v5.10.0-18-amd64 amd64; 14:23:54.262 INFO PostprocessGermlineCNVCalls - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_242-8u242-b08-0ubuntu3~18.04-b08; 14:23:54.263 INFO PostprocessGermlineCNVCalls - Start Date/Time: December 2, 2022 2:23:53 PM GMT; 14:23:54.263 INFO PostprocessGermlineCNVCalls - -----------",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8183:976,log,logs,976,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8183,1,['log'],['logs']
Testability,"### Bug Report. Hi, after installing the conda environment and running `conda activate gatk` without errors, I seem to still have a problem importing the gcnvkernel module. Is there a way I can install it through pip or what is something I may have done wrong? I already went over the README and standard documentation, and don't think I missed a step. ### Affected tool(s) or class(es); gvnvkernel, other expected modules. #### Expected behavior; Generate output file from my VCF. #### Actual behavior; ```; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -DGATK_STACKTRACE_ON_USER_EXCEPTION=true -jar /home/gamer456148/gatk-4.1.4.1/gatk-package-4.1.4.1-local.jar GermlineCNVCaller --input var.vcf --run-mode CASE --contig-ploidy-calls X/prefix-calls --output-prefix regular.vcf --output testfile.vcf; 21:21:12.277 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/gamer456148/gatk-4.1.4.1/gatk-package-4.1.4.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Feb 23, 2020 9:21:12 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 21:21:12.543 INFO GermlineCNVCaller - ------------------------------------------------------------; 21:21:12.544 INFO GermlineCNVCaller - The Genome Analysis Toolkit (GATK) v4.1.4.1; 21:21:12.544 INFO GermlineCNVCaller - For support and documentation go to https://software.broadinstitute.org/gatk/; 21:21:12.544 INFO GermlineCNVCaller - Executing as gamer456148@gamer456148-Inspiron-15-7579 on Linux v4.15.0-88-generic amd64; 21:21:12.544 INFO GermlineCNVCaller - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_191-b12; 21:21:12.544 INFO GermlineCNVCaller - Start Date/Time: February 23, 2020 9:21:12 PM EST; 21:21:12.544 INFO GermlineCNVCaller - -------------------------------------------",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6467:911,test,testfile,911,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6467,1,['test'],['testfile']
Testability,"### Instructions. ## Bug Report. ### Affected tool(s) or class(es); MarkDuplicatesSpark. ### Affected version(s); - [v ] Latest public release version [4.4.0.0]. ### Description ; Since switching to 4.4.0.0 we are experiencing an increased memory consumption of MarkDuplicatesSpark. We see it on large BAM/CRAM files, not tested on small files. #### Steps to reproduce; This command: ; ```; java -Xmx190g -jar /usr/gitc/GATK_ultima.jar MarkDuplicatesSpark \; --spark-master local[24] \; --input 019242_old.ua.aln.bam \; --output 019242_old.aligned.sorted.duplicates_marked.bam \; --create-output-bam-index true \; --spark-verbosity WARN \; --verbosity WARNING \; --flowbased; ```; required 90GB memory on 4.3.0.0. The input BAM is large: 270GB; However on the 4.4.0.0 it requires >160GB RAM. #### Expected behavior; The memory requirement is not expected to change ; #### Actual behavior; Significantly increased memory requirement",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8307:322,test,tested,322,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8307,1,['test'],['tested']
Testability,"### Instructions. ## Bug Report. Hi GATK team , I'm afraid I found an exception in gatk HC related to https://github.com/broadinstitute/gatk/issues/6516. ### Affected tool(s) or class(es). GATK HC v4.3.0.0 . ### Affected version(s); - [X] Latest public release version [version?]; - [ ] Latest master branch as of [date of test?]. ### Description . ```; + gatk --java-options '-Xmx5g -Djava.io.tmpdir=TMP' HaplotypeCaller -R /LAB-DATA/BiRD/resources/species/human/cng.fr/hs38me/hs38me_all_chr.fasta --minimum-mapping-quality 10 --sample-ploidy 2 --do-not-run-physical-phasing --alleles TMP/jeter.vcf.gz -L TMP/jeter.vcf.gz -I /SCRATCH-BIRD/users/lindenbaum-p/work/NEXTFLOW/20221123.hs38me.NTS299.ultrares/work/87/5fa0df303dc4f06212547353be621c/BAMS/cluster.aaaaaaacx.bam.list -O TMP/jeter2.vcf.gz Using GATK jar /LAB-DATA/BiRD/users/lindenbaum-p/packages/gatk/gatk-4.3.0.0/gatk-package-4.3.0.0-local.jar; Running: ; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx5g -Dj; ava.io.tmpdir=TMP -jar /LAB-DATA/BiRD/users/lindenbaum-p/packages/gatk/gatk-4.3.0.0/gatk-package-4.3.0.0-local.jar HaplotypeCaller -R /LAB-DATA/BiRD/resources/species/human/cng.fr/hs38me/hs38me_all_chr.fasta --minimum-mapping-quality 10 --sample-ploidy 2 --do-not-run-physical-phasing --alleles TMP/jeter.vcf.gz -L TMP/jeter.vcf.gz -I /SCRATCH-BIRD/users/lindenbaum-p/work/NEXTFLOW/20221123.hs38me.NTS299.ultrares/work/87/5fa0df303dc4f06212547353be621c/BAMS/cluster.aaaaaaacx.bam.list -O TMP/jeter2.vcf.gz; 18:15:19.107 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/LAB-DATA/BiRD/users/lindenbaum-p/packages/gatk/gatk-4.3.0.0/gatk-package-4.3.0.0-local.j; ar!/com/intel/gkl/native/libgkl_compression.so ; 18:15:21.727 INFO HaplotypeCaller - ------------------------------------------------------------ ; 18:15:21.728 INFO HaplotypeCaller - The Genome Analysis Toolkit (GATK) v4.3.0.0 ; 1",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8106:323,test,test,323,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8106,1,['test'],['test']
Testability,"### Instructions. ## Bug Report; ### Affected tool(s) or class(es); - tools: HaplotypeCaller perhaps Mutec. ; - classes: AlleleLikelihoods. ### Affected version(s); - [ X] Latest public release version [version?]; - [ X] Latest master branch as of [date of test?]. ### Description ; Right before calling annotators HC engine adds filtered reads as additional evidence in the AlleleLikelihoods instance that is passed down to the annotators. The code requests the new evidence to have 0.0 likelihoods so label them as uninformative. However due to an error in how the lk arrays are ""extended"" inside the AlleleLikelihoods these reads inherit past reads (removed) zombie likelihoods instead. Fix is easy. as simple as remove this enclosing ```if``` in AlleleLikelihoods, and simply executed its body; always:. ```; line 793:; if (initialLikelihood != 0.0) // the default array new value.; {; for (int a = 0; a < alleleCount; a++) {; Arrays.fill(sampleValues[a], sampleEvidenceCount, newSampleEvidenceCount, initialLikelihood);; }; }; ```. #### Steps to reproduce. Debug and active region with filtered reads. . #### Expected behavior. Those reads won't contribute to AD or DP. #### Actual behavior. They do contribute, at random, to those count annotations.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7153:257,test,test,257,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7153,1,['test'],['test']
Testability,"### Instructions. In one of the six samples that the DSP pipelines team ('lantern') uses for scientific testing, found bug in GATK 4.1.7.0's HaplotypeCaller. 'java.lang.IllegalArgumentException: evidence provided is not in sample'. Full stack trace below. This is found for Sample NA17-308, Shard 49.; https://cromwell.gotc-dev.broadinstitute.org/api/workflows/1/83938362-b9b5-49f3-a65d-715065d6eabd/metadata; Execution bucket is:; broad-gotc-dev-cromwell-execution (results will stay there for 30 days before being automatically cleaned up). ----. ## Bug Report. ### Affected tool(s) or class(es); HaplotypeCaller. ### Affected version(s); - 4.1.7.0. ### Description ; Stack trace:; java.lang.IllegalArgumentException: evidence provided is not in sample; 	at org.broadinstitute.hellbender.utils.genotyper.AlleleLikelihoods.lambda$removeEvidence$9(AlleleLikelihoods.java:1124); 	at java.util.stream.ReferencePipeline$4$1.accept(ReferencePipeline.java:210); 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:546); 	at java.util.stream.AbstractPipeline.evaluateToArrayNode(AbstractPipeline.java:260); 	at java.util.stream.IntPipeline.toArray(IntPipeline.java:504); 	at org.broadinstitute.hellbender.utils.genotyper.AlleleLikelihoods.removeEvidence(AlleleLikelihoods.java:1128); 	at org.broadinstitute.hellbender.utils.genotyper.AlleleLikelihoods.contaminationDownsampling(AlleleLikelihoods.java:315); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerGenotypingEngine.assignGenotypeLikelihoods(HaplotypeCallerGenotypingEngine.java:173); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerEngine.callRegion(HaplotypeCallerEngine.java:608); 	at org.broadinstitute.hellbender.tools.walkers",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6586:104,test,testing,104,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6586,1,['test'],['testing']
Testability,"### Instructions. The github issue tracker is for bug reports, feature requests, and API documentation requests. General questions about how to use the GATK, how to interpret the output, etc. should be asked on the [official support forum](http://gatkforums.broadinstitute.org/gatk).; - Search the existing github issues to see if your issue (or something similar) has already been reported. If the issue already exists, you may comment there to inquire about the progress.; - Determine whether your issue is a **bug report**, a **feature request**, or a **documentation request** (for tool/class javadoc only -- for forum docs please post there); - Consider if your ""issue"" is better addressed on the GATK forum: http://gatkforums.broadinstitute.org/gatk Post there if you have questions about expected tool behavior, output format, unexpected results, or generally any question that does not fit into the categories above; - Use a **concise** yet **descriptive** title; - Choose the corresponding template block below and fill it in, replacing or deleting text in italics (surrounded by `_`) as appropriate; - Delete the other template blocks and this header. ----. ## Bug Report. ### Affected tool(s) or class(es). FilterMutectCalls. ### Affected version(s); - [x] Latest public release version [version?]; - [x] Latest master branch as of [date of test?]. ### Description . If there is germline variant within one read length of a somatic variant, the clustered_events filter can filter out the somatic variant. Clustered events, intention is to filter out noisy sites that are likely artifactual, but should ignore contributions from neighboring germline sites.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6532:1352,test,test,1352,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6532,1,['test'],['test']
Testability,"### Instructions; I use PathSeqPipelineSpark to analyze 10x Visium spatial transcribed data.; I did not download the data from the database on the GATK official website. But I prepared the database according to the tutorial [https://gatk.broadinstitute.org/hc/en-us/articles/360035889911--How-to-Run-the-Pathseq-pipeline] by myself.; The analysis has no results, and I don't know the reason for the lack of results. ## software / environment / log file informations; Using GATK jar /mnt/icfs/work/singlecelldevelopment/software/gatk-4.3.0.0/gatk-package-4.3.0.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx750g -jar /mnt/icfs/work/singlecelldevelopment/software/gatk-4.3.0.0/gatk-package-4.3.0.0-local.jar PathSeqPipelineSpark --input CRC_16/outs/possorted_genome_bam.bam --filter-bwa-image hsa_GRCh38/genome.fa.img --kmer-file hsa_GRCh38/genome.hss --min-clipped-read-length 60 --microbe-dict 16SrRNA/bacteria.16SrRNA.dict --microbe-bwa-image 16SrRNA/bacteria.16SrRNA.fa.img --taxonomy-file 16SrRNA/16SrRNA.db --output pathseq/CRC_16.pathseq.complete.bam --scores-output pathseq/CRC_16.pathseq.complete.csv --is-host-aligned false --filter-duplicates false --min-score-identity .7 --tmp-dir pathseq/tmp; 13:19:23.776 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/mnt/icfs/work/singlecelldevelopment/software/gatk-4.3.0.0/gatk-package-4.3.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; 13:19:28.982 INFO PathSeqPipelineSpark - ------------------------------------------------------------; 13:19:28.982 INFO PathSeqPipelineSpark - The Genome Analysis Toolkit (GATK) v4.3.0.0; 13:19:28.982 INFO PathSeqPipelineSpark - For support and documentation go to https://software.broadinstitute.org/gatk/; 13:19:28.983 INFO PathSeqPipelineSpark - Executing as singlecellproject@d01.capitalbiotech.local on Linux v3.10.0-514.16.1.el7.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8339:444,log,log,444,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8339,1,['log'],['log']
Testability,"### Instructions; gatk --java-options ""-Xmx12G -Djava.io.tmpdir=/data/nws/WES/1align_out/200919_A00682_0446_AHCVMJDSXY/tmp -DGATK_STACKTRACE_ON_USER_EXCEPTION=true"" BaseRecalibrator -R /data/nws/WES/reference/Homo_sapiens_assembly38.fasta -I /data/nws/WES/1align_out/200919_A00682_0446_AHCVMJDSXY/Set12-3_L1_361361.sorted.marked.bam -O recal_data.table --known-sites /data/nws/WES/reference/dbsnp_146.hg38.vcf --known-sites /data/nws/WES/reference/1000G_phase1.snps.high_confidence.hg38.vcf --known-sites /data/nws/WES/reference/Mills_and_1000G_gold_standard.indels.hg38.vcf 1>/data/nws/WES/1align_out/200919_A00682_0446_AHCVMJDSXY/Set12-3_L1_361361.BaseRecalibrator.log 2>&1. Using GATK jar /usr/local/gatk-4.1.3.0/gatk-package-4.1.3.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx12G -Djava.io.tmpdir=/data/nws/WES/1align_out/200919_A00682_0446_AHCVMJDSXY/tmp -DGATK_STACKTRACE_ON_USER_EXCEPTION=true -jar /usr/local/gatk-4.1.3.0/gatk-package-4.1.3.0-local.jar BaseRecalibrator -R /data/nws/WES/reference/Homo_sapiens_assembly38.fasta -I /data/nws/WES/1align_out/200919_A00682_0446_AHCVMJDSXY/Set12-3_L1_361361.sorted.marked.bam -O recal_data.table --known-sites /data/nws/WES/reference/dbsnp_146.hg38.vcf --known-sites /data/nws/WES/reference/1000G_phase1.snps.high_confidence.hg38.vcf --known-sites /data/nws/WES/reference/Mills_and_1000G_gold_standard.indels.hg38.vcf; 15:45:57.013 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/usr/local/gatk-4.1.3.0/gatk-package-4.1.3.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; 15:46:12.281 INFO BaseRecalibrator - ------------------------------------------------------------; 15:46:12.282 INFO BaseRecalibrator - The Genome Analysis Toolkit (GATK) v4.1.3.0; 15:46:12.282 INFO BaseRecalibrator - For support and documentation go to https://software.broadinstitute.org/gatk/; 15:46:",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7031:667,log,log,667,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7031,1,['log'],['log']
Testability,### Instructions; it‘s my first time to run the pipline for RNA-seq data. ; the log of SplitNCigarReads makes me confused which said '00:39:03.278 WARN IntelInflater - Zero Bytes Written : 0' at below.; i don't know weather this step works will or just return the files same as last step？; maybe someone know what's happened，I'm very grateful for someone to help me answer this question！. 00:35:09.127 INFO ProgressMeter - 23:27354557 12.4 29918000 2404017.7; 00:35:19.176 INFO ProgressMeter - 23:39821286 12.6 30308000 2403016.1; 00:35:29.182 INFO ProgressMeter - unmapped 12.8 30712000 2403270.9; 00:35:39.184 INFO ProgressMeter - 25:18185455 12.9 31112000 2403222.6; 00:35:49.196 INFO ProgressMeter - 25:35485074 13.1 31463000 2399411.3; 00:35:59.205 INFO ProgressMeter - 26:15194951 13.3 31932000 2404584.5; 00:36:09.210 INFO ProgressMeter - 26:39796753 13.4 32325000 2403995.1; 00:36:19.234 INFO ProgressMeter - 27:19938980 13.6 33035000 2426647.2; 00:36:29.429 INFO ProgressMeter - 28:32806413 13.8 33417000 2424444.0; 00:36:39.586 INFO ProgressMeter - unmapped 14.0 33821000 2423984.0; 00:36:49.602 INFO ProgressMeter - 29:43615735 14.1 34294000 2428825.2; 00:36:59.630 INFO ProgressMeter - X:20297509 14.3 34746000 2432052.2; 00:37:09.635 INFO ProgressMeter - X:79368355 14.5 35002000 2421702.8; 00:37:19.744 INFO ProgressMeter - unmapped 14.6 35364000 2418555.7; 00:37:29.986 INFO ProgressMeter - MT:4752 14.8 36632000 2476365.0; 00:37:39.989 INFO ProgressMeter - MT:6105 15.0 37831000 2528917.2; 00:37:50.172 INFO ProgressMeter - MT:6537 15.1 38943000 2574051.7; 00:38:00.172 INFO ProgressMeter - MT:7097 15.3 40049000 2618311.9; 00:38:10.174 INFO ProgressMeter - MT:8432 15.5 41100000 2658052.2; 00:38:20.250 INFO ProgressMeter - MT:9258 15.6 42088000 2692704.3; 00:38:30.365 INFO ProgressMeter - MT:11181 15.8 43055000 2725181.1; 00:38:40.367 INFO ProgressMeter - MT:13120 16.0 44100000 2762177.2; 00:38:50.424 INFO ProgressMeter - MT:14886 16.1 45149000 2798500.4; 00:39:00.640 INFO Progr,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8126:80,log,log,80,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8126,1,['log'],['log']
Testability,"### SelectVariants could expand on their types (INDEL, SNP, MIXED, MNP, SYMBOLIC, NO_VARIATION) to include more types as follows:. - whether insertion or deletion as requested by user shis [here](http://gatkforums.broadinstitute.org/gatk/discussion/8988/how-to-select-insertion-or-deletion-from-a-indels-vcf-file#latest); - by star `*` allele as requested by user nkobmoo [here](http://gatkforums.broadinstitute.org/gatk/discussion/8977/how-to-filter-out-the-snps-with-deletion-allel#latest); - by AD values as requested by numerous users over the year I've been here and most recently by CanH [here](http://gatkforums.broadinstitute.org/gatk/discussion/9032/selectvariants-according-to-ad-values#latest). Also beware of something buggy described by user zzq [here](http://gatkforums.broadinstitute.org/gatk/discussion/8966/select-snp-and-reference-monomorphic-sites-from-a-large-callset#latest). I've asked them to reproduce the results using the latest version of GATK. It appears that the SYMBOLIC type, which I think must refer to the star allele, is not being recognized with v3.5-0-g36282e4. I don't have any such data to test this out with, otherwise, I'd report more on this issue. #### Current workarounds; Users are currently using AWK or JEXL to select their variants. JEXL documentation is [here](http://gatkforums.broadinstitute.org/gatk/discussion/1255/using-jexl-to-apply-hard-filters-or-select-variants-based-on-annotation-values).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2412:1128,test,test,1128,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2412,1,['test'],['test']
Testability,"### Summary ; A user wrote in to the forum regarding running FilterSamReads through GATK and the output bam file has formatting issues. After they sent in a bug report, I found that the exit code is getting written to the bam file, causing this issue. . This request was created from a contribution made by rcorbett on February 03, 2021 23:47 UTC. Link: [https://gatk.broadinstitute.org/hc/en-us/community/posts/360076905711-filterSamReads-stdout-format-error](https://gatk.broadinstitute.org/hc/en-us/community/posts/360076905711-filterSamReads-stdout-format-error). #### GATK Info; FilterSamReads 4.1.9.0 and 4.0.10.0; Command to stdout:; `gatk FilterSamReads -I subsampled.bam -O /dev/stdout --READ_LIST_FILE read_names.txt --FILTER excludeReadList --VALIDATION_STRINGENCY SILENT --QUIET > test_stdout.bam`; Log:; ```; Using GATK jar /gatk/gatk-package-4.1.9.0-SNAPSHOT-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /gatk/gatk-package-4.1.9.0-SNAPSHOT-local.jar FilterSamReads -I subsampled.bam -O /dev/stdout --READ_LIST_FILE read_names.txt --FILTER excludeReadList --VALIDATION_STRINGENCY SILENT --QUIET; 20:54:45.405 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/gatk/gatk-package-4.1.9.0-SNAPSHOT-local.jar!/com/intel/gkl/native/libgkl_compression.so; INFO	2021-02-12 20:54:45	FilterSamReads	Filtering [presorted=true] subsampled.bam -> OUTPUT=stdout [sortorder=coordinate]; INFO	2021-02-12 20:54:45	SAMFileWriterFactory	Unknown file extension, assuming BAM format when writing file: file:///dev/stdout; INFO	2021-02-12 20:54:45	FilterSamReads	6 SAMRecords written to stdout. ```; Check file:; `gunzip -c -d -f test_stdout.bam | head -n 5`; ```; Tool returned:; 0. ?[[lW?m?$?^?q???k????zg?x}?s???mE?ޖ?r#U???ԑ/Qm'܄dkUM???????zCBB?!*?V*?#; <Q!QU?; ```; Bam file using -0; `gunzip -c -d -f test_outbam.bam | head -n 5`; ```; BAM?2@",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7080:811,Log,Log,811,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7080,1,['Log'],['Log']
Testability,"### Updates; A record with SVTYPE=CTX and CPX_TYPE=CTX_INV was added to a recent GATK-SV VCF after manual curation. The following changes were made to be able to properly annotate this type of event.; * CPX_TYPE will be checked for CTX records, and if it is CTX_INV, the INV interval from CPX_INTERVALS will be added to the annotation segments.; * Additionally, instead of annotating two breakpoint intervals CHROM:POS-END and CHR2:END2-END2+1 for CTX events, we will now annotate 4 individual breakpoints to cover the case where END != POS+1. Those 4 breakpoints are CHROM:POS-POS, CHROM:END-END, CHR2:END2-END2, and CHR2:END2+1-END2+1.; * In the future, to be able to represent intervals on CHR2, POS2 may be added. SVAnnotate will need to be updated accordingly at that time. ### Testing; * Unit tests for CTX_INV added; * Unit tests for other CTX updated; * A one-line VCF was created to test the real-life example CTX_INV event that was curated, and it was annotated correctly",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8693:783,Test,Testing,783,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8693,4,"['Test', 'test']","['Testing', 'test', 'tests']"
Testability,### Updates; Some GATK-SV VCFs contain MEI deletions with ALT in the format <DEL:ME:ALU> or <DEL:ME>. This change will allow SVAnnotate to recognize and annotate those records as deletions. ### Testing; * Added unit test with MEI DEL; * Ran all unit and integration tests for SVAnnotate,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8125:194,Test,Testing,194,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8125,3,"['Test', 'test']","['Testing', 'test', 'tests']"
Testability,"###### | 100%; termcolor-1.1.0 | 8 KB | ########## | 100%; protobuf-3.11.2 | 635 KB | ########## | 100%; keras-applications-1 | 33 KB | ########## | 100%; readline-6.2 | 606 KB | ########## | 100%; libgfortran-ng-7.3.0 | 1006 KB | ########## | 100%; numpy-1.13.3 | 3.1 MB | ########## | 100%; ```. numpy-1.13.3 is corectly installed . but then . ```; Collecting numpy (from biopython==1.70->-r /root/gatk-4.1.4.0/condaenv.g1uyq0ce.requirements.txt (line 1)); Downloading https://files.pythonhosted.org/packages/62/20/4d43e141b5bc426ba38274933ef8e76e85c7adea2c321ecf9ebf7421cedf/numpy-1.18.1-cp36-cp36m-manylinux1_x86_64.whl (20.1MB); ```. that does . ```; Found existing installation: numpy 1.13.3; Uninstalling numpy-1.13.3:; Successfully uninstalled numpy-1.13.3; ```. this causes ```gatk DetermineGermlineContigPloidy ```; to exit with an error related to numpy.testing.decorators which is deprecated since numpy 1.15.0 see https://docs.scipy.org/doc/numpy-1.15.0/release.html. ```; Deprecations. Aliases of builtin pickle functions are deprecated, in favor of their unaliased pickle.<func> names:; numpy.loads; numpy.core.numeric.load; numpy.core.numeric.loads; numpy.ma.loads, numpy.ma.dumps; numpy.ma.load, numpy.ma.dump - these functions already failed on python 3 when called with a string.; Multidimensional indexing with anything but a tuple is deprecated. This means that the index list in ind = [slice(None), 0]; arr[ind] should be changed to a tuple, e.g., ind = [slice(None), 0]; arr[tuple(ind)] or arr[(slice(None), 0)]. That change is necessary to avoid ambiguity in expressions such as arr[[[0, 1], [0, 1]]], currently interpreted as arr[array([0, 1]), array([0, 1])], that will be interpreted as arr[array([[0, 1], [0, 1]])] in the future.; Imports from the following sub-modules are deprecated, they will be removed at some future date.; numpy.testing.utils; numpy.testing.decorators; numpy.testing.nosetester; numpy.testing.noseclasses; numpy.core.umath_tests; ````. regards. Eric",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6396:2573,test,testing,2573,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6396,4,['test'],['testing']
Testability,"#1629 @akiezun @droazen @lbergelson. Added a substring search to `SWPairwiseAlignment.align`to avoid running the full Smith-Waterman when the query is found in the reference without any indels. The performance benefit of this code will be data dependent. In the current HaplotypeCaller test, >80% of the Smith-Waterman calls are filtered by the substring search. Added tests to cover all of the overhang strategies. **Note:** The substring search only works for the `SOFTCLIP`and `IGNORE`overhang strategies. The `INDEL`and `LEADING_INDEL`can result in more complicated CIGAR strings. See the `SWPairwiseAlignmentUnitTest.testSubstringMatchIndelLong` and `SWPairwiseAlignmentUnitTest.testSubstringMatchLeadingIndelLong` tests for examples.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1677:286,test,test,286,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1677,5,['test'],"['test', 'testSubstringMatchIndelLong', 'testSubstringMatchLeadingIndelLong', 'tests']"
Testability,#2689 - Example code to mark fields that do not have a combination operation to avoid warnings such as 'No valid combination operation found for INFO field AN - the field will NOT be part of INFO fields in the generated VCF record'. We also have [GenomicsDB PR#85](https://github.com/GenomicsDB/GenomicsDB/pull/85) in the works that will log these types of messages only once per field.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6514:338,log,log,338,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6514,1,['log'],['log']
Testability,"#7359); - don't mix contigs, rightsize memory (#7361); - Add custom annotations as ac an af (#7351); - Add task for VAT validation #8 & 9 (#7364); - added bcftools, upgraded gcloud version (#7369); - fix wdl (#7378); - Update .dockstore.yml; - Add VAT validation rule #5 [VS-16] (#7365); - Add VAT validation rule #7 [VS-14] and validation rule #6 [VS-15] (#7379); - Batching of samples for create import TSVs (#7382); - Add VAT validation rule #2 [VS-19] (#7374); - Create VAT scripts directory (#7386); - fixing SA change from file to string (#7371); - add extract_subpop script (#7387); - Add is_loaded column to sample_info and logic to populate after ingest [VS-158] (#7389); - Add Gnomad subpopulation info into the VAT (#7381); - implement GVS ID assignment (#7355); - no longer loading sample info table in this wdl (#7407); - divide up creation/population of temp pet table [VS-48] (#7395); - Sample QC metrics (#7396); - update import for is_loaded (#7416); - fix partition end, add 1 (#7420); - Fixes to CreateFilterSet and ExtractCallset from 30K run (#7423); - Also changed file size from Int to Float in SumBytes task python (#7429); - Adding the subpopulation calculations to the VAT creation WDL (#7399); - 154 De obfuscate (#7435); - filter on gvs_ids for workflow (#7428); - update for assign ids and changes in import (#7439); - need to loop through sets when moving to done (#7440); - add option for create filter set to use sample_info with is_loaded (#7434); - remove dead branch (#7443); - Scaling the VAT -- switch the input to take in a file of vcf shard file names (#7446); - dockstore testing: move validate vat inputs (#7449); - Update GVS sample QC to support multiple callsets per datasset [VS-177] (#7451); - Update GvsImportGenomes.wdl (#7462); - Add extraction uuid BQ label to GvsPrepareCallstep from GvsExtractCohortFromSampleNames (#7458); - Add manifest summary file to GvsExtractCallset (#7457); - Create workflow to create and populate alt_allele table [VS-51] (",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8248:16795,log,logic,16795,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8248,4,"['log', 'test']","['logic', 'testing']"
Testability,"#7649, and because we are still awaiting coverage from pipeline-level/CARROT testing, I decided to go ahead and add these exact-match tests. This essentially freezes current ModelSegments behavior, which has been exactly stable since https://github.com/broadinstitute/gatk/pull/5814; that is, from sometime between 4.1.0.0/4.1.1.0 almost 3 years ago up to 4.2.4.1 today. Note that the original test files were generated from the test BAMs (e.g., src/test/resources/large/cnv_somatic_workflows_test_files/HCC1143-t1-chr20-downsampled.deduplicated.bam), since these BAMs have been used in the past to consistently generate test files for other tools in the ModelSegments and GermlineCNVCaller pipelines. However, these original test files contained insufficient data to activate the changes found in #7649, even had exact-match tests been present. I thus took some old HCC1143T 100% WES data that I had and snippeted it to chr20. I've confirmed that the added tests with these files would've picked up the regression of log10factorial seen in #7649 for all relevant modes (i.e., all those that take in the allele counts as input, since that regression only affected allele-fraction MCMC sampling). Tests take maybe an additional minute to run and there was about ~12MB of additional large resources checked in, but I didn't try too hard to bring either down. I also added some early-fail parameter validation to check that the minimum total allele count in the case sample is zero in matched-normal mode. There are actually some open questions in my mind as to what the best behavior should be here, but given some of the discussion in #6499 and possible plans for using joint segmentation to do filtering of germline events, I think it's best to enforce that all het sites coming out of the genotyping step are the same across all samples. Recall that we added this parameter in #5556 because some users were running matched normals with much lower depth than their cases. This meant that many normal ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7652:1078,test,tests,1078,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7652,1,['test'],['tests']
Testability,$ExecResultImpl.assertNormalExitValue(DefaultExecHandle.java:369); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.process.internal.worker.DefaultWorkerProcess.waitForStop(DefaultWorkerProcess.java:190); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.process.internal.worker.DefaultWorkerProcessBuilder$MemoryRequestingWorkerProcess.waitForStop(DefaultWorkerProcessBuilder.java:228); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.testing.worker.ForkingTestClassProcessor.stop(ForkingTestClassProcessor.java:122); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.testing.processors.RestartEveryNTestClassProcessor.endBatch(RestartEveryNTestClassProcessor.java:63); 11:54:40.437 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.testing.processors.RestartEveryNTestClassProcessor.stop(RestartEveryNTestClassProcessor.java:57); 11:54:40.437 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35); 11:54:40.437 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 11:54:40.437 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.dispatch.FailureHandlingDispatch.dispatch(FailureHandlingDispatch.java:29); 11:54:40.437 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.dispatch.AsyncDispatch.dispatchMessages(AsyncDispatch.java:132); 11:54:40.437 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.dispatch.AsyncDispatch.access$000(AsyncDispatch.java:33); 11:54:40.437 [ERROR] [org.gradle.internal.buildevents.BuildExcept,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2802:14759,test,testing,14759,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2802,1,['test'],['testing']
Testability,${GATK4_JAR} MarkDuplicatesSpark -I src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.bam -O tmp.junk.bam --METRICS_FILE=tmp.metrics -parallelism 1. samtools view tmp.junk.bam | less; and you'll see 1001995 ahead of 1001645; Offending records are at [20:1001995] and [20:1001645],MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1249:40,test,test,40,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1249,1,['test'],['test']
Testability,"'t seem to be a resource issue. The only difference appears to be the number of input gvcfs, which is still quite small (345 vs 80).  The number of reader threads for GenomicsDBImport has been hard-coded to 1 because these are exome sequences; scatter count = 10, batch size = 50, gather\_vcfs = false. GenomicsDBImport appears to succeed on all 10 shards but workflow execution fails with exactly the same c++ error, see below. REQUIRED for all errors and issues: ; ; a) GATK version used: v4.2.6.1. b) Exact command used:. java -Dconfig.file=/scratch.global/lee04110/config/sing-cache.conf -jar /home/pankrat2/public/bin/gatk4/cromwell-81.jar run -i /scratch.global/lee04110/config/jg.ca\_defects.json /home/pankrat2/public/bin/gatk4/warp/pipelines/broad/dna\_seq/germline/joint\_genotyping/JointGenotyping.wdl -o  <(echo '{""final\_workflow\_outputs\_dir"" : ""/scratch.global/lee04110/tmp\_jg"", ""use\_relative\_output\_paths"" : true, ""workflow-log-temporary"" : true}'). c) Entire program log: (too big to include the whole thing). (From main process stderr, picking from SplitInterval setting status to Done). \[2022-10-18 15:38:20,88\] \[info\] BackgroundConfigAsyncJobExecutionActor \[9743b28aJointGenotyping.SplitIntervalList:NA:1\]: Status change from WaitingForReturnCode to Done. \[2022-10-18 15:38:25,47\] \[info\] WorkflowExecutionActor-9743b28a-3819-49a7-8598-b0c5267647ee \[9743b28a\]: Starting JointGenotyping.ImportGVCFs (10 shards). \[2022-10-18 15:38:33,03\] \[info\] Assigned new job execution tokens to the following groups: 9743b28a: 10. \[2022-10-18 15:38:33,14\] \[warn\] BackgroundConfigAsyncJobExecutionActor \[9743b28aJointGenotyping.ImportGVCFs:3:1\]: Unrecognized runtime attribute keys: preemptible, bootDiskSizeGb, disks, cpu, memory. \[2022-10-18 15:38:33,14\] \[warn\] BackgroundConfigAsyncJobExecutionActor \[9743b28aJointGenotyping.ImportGVCFs:2:1\]: Unrecognized runtime attribute keys: preemptible, bootDiskSizeGb, disks, cpu, memory. \[2022-10-18 15:38:33,15\] \[warn",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8076:1970,log,log,1970,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8076,1,['log'],['log']
Testability,(DO NOT MERGE) Sl debug vector pair hmm test 2,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6658:40,test,test,40,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6658,1,['test'],['test']
Testability,"(HaplotypeCallerEngine.java:599); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCaller.apply(HaplotypeCaller.java:236); 	at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.processReadShard(AssemblyRegionWalker.java:291); 	at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.traverse(AssemblyRegionWalker.java:267); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:966); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); 	at org.broadinstitute.hellbender.Main.main(Main.java:289); ```. Based on the discussion around #4963 and the [test VCF](https://github.com/broadinstitute/gatk/blob/master/src/test/resources/org/broadinstitute/hellbender/tools/haplotypecaller/testGenotypeGivenAllelesMode_givenAlleles.vcf), I gather that this is intended to work without error. I was trying to figure out how these cases differed from the spanning deletion in the aforementioned test VCF. One thing I noticed was that these two problematic cases have the SNP at the very last base of the spanning deletion. I'm just speculating here, but maybe it is related to an off-by-one bug of some sort? . I am testing with v. 4.0.9.0.; I also tried with v. 4.0.5.1 which does not crash, but rather prints the warnings discussed in #4963:; `00:02:10.995 WARN HaplotypeCallerEngine - Multiple valid VCF records detected in the alleles input file at site 22:16137302-16137302, only considering the first record`; `00:03:08.220 WARN HaplotypeCallerEngine - Multiple valid VCF records detected in the alleles input file at site 22:16464051-16464051",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5336:4864,test,test,4864,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5336,1,['test'],['test']
Testability,(If this is not already possible -- we should test this),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4348:46,test,test,46,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4348,1,['test'],['test']
Testability,"(Linked to #7988); Feature additions (and integration tests) for CompareReferences tool, including:; * ability to run base-level comparison modes on specified sequences (not just detected mismatching sequences) using ""sequences-to-align"" option ; * changed wording for missing MD5 compatibility status ('COMPATIBLE' to 'MAYBE_COMPATIBLE,' or something similar) in compatibility tool ; * option to ignore case level differences in base level comparison modes . NOTE: integration test on using an equivalent sequences input file with more than one line (ie. specifying more than one sequences) not yet tested, and can probably do some refactoring to clean up the code for the equivalent sequence comparisons",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8163:54,test,tests,54,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8163,3,['test'],"['test', 'tested', 'tests']"
Testability,(PairRDDFunctions.scala:1203); 	at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1348); 	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13.apply(PairRDDFunctions.scala:1211); 	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13.apply(PairRDDFunctions.scala:1190); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); 	at org.apache.spark.scheduler.Task.run(Task.scala:86); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745). **This is the stack I get when the test completes but fails (note that the expected line count appears to not match the line count of the expected output file in the repo): **. java.lang.AssertionError: line counts expected [2629] but found [507]; 	at org.testng.Assert.fail(Assert.java:94); 	at org.testng.Assert.failNotEquals(Assert.java:496); 	at org.testng.Assert.assertEquals(Assert.java:125); 	at org.testng.Assert.assertEquals(Assert.java:372); 	at org.broadinstitute.hellbender.utils.test.IntegrationTestSpec.assertEqualTextFiles(IntegrationTestSpec.java:211); 	at org.broadinstitute.hellbender.utils.test.IntegrationTestSpec.assertEqualTextFiles(IntegrationTestSpec.java:190); 	at org.broadinstitute.hellbender.tools.examples.ExampleAssemblyRegionWalkerSparkIntegrationTest.testExampleAssemblyRegionWalker(ExampleAssemblyRegionWalkerSparkIntegrationTest.java:29); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMet,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2349:3150,Assert,AssertionError,3150,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2349,1,['Assert'],['AssertionError']
Testability,(SV) Add tests for AssemblyContigWithFineTunedAlignments,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4961:9,test,tests,9,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4961,1,['test'],['tests']
Testability,"(SV) consolidate logic in simple chimera inference, update how variants are represented in VCF emitted by new code path",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4663:17,log,logic,17,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4663,2,['log'],['logic']
Testability,(TestInvoker.java:804); 	at org.testng.internal.TestInvoker.invokeTestMethods(TestInvoker.java:145); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:128); 	at java.base/java.util.ArrayList.forEach(ArrayList.java:1540); 	at org.testng.TestRunner.privateRun(TestRunner.java:770); 	at org.testng.TestRunner.run(TestRunner.java:591); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:402); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:396); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:355); 	at org.testng.SuiteRunner.run(SuiteRunner.java:304); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:53); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:96); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1180); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1102); 	at org.testng.TestNG.runSuites(TestNG.java:1032); 	at org.testng.TestNG.run(TestNG.java:1000); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:141); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:90); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.base/java.lang.reflect.Method.invoke(Method.java:566); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6745:3141,Test,TestNG,3141,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6745,2,['Test'],['TestNG']
Testability,([0-9]+):([0-9]+).* OPTICAL_DUPLICATE_PIXEL_DISTANCE=100 VERBOSITY=INFO QUIET=false VALIDATION_STRINGENCY=STRICT COMPRESSION_LEVEL=5 MAX_RECORDS_IN_RAM=500000 CREATE_INDEX=false CREATE_MD5_FILE=false GA4GH_CLIENT_SECRETS=client_secrets.json; ## htsjdk.samtools.metrics.StringHeader; # Started on: Thu Oct 22 16:45:11 EDT 2015. ## METRICS CLASS picard.sam.DuplicationMetrics; LIBRARY UNPAIRED_READS_EXAMINED READ_PAIRS_EXAMINED UNMAPPED_READS UNPAIRED_READ_DUPLICATES READ_PAIR_DUPLICATES READ_PAIR_OPTICAL_DUPLICATES PERCENT_DUPLICATION ESTIMATED_LIBRARY_SIZE; Solexa-16399 0 0 0 0 0 0 ?; Solexa-16421 0 0 0 0 0 0 ?; Solexa-16410 0 0 0 0 0 0 ?; Solexa-16398 0 0 0 0 0 0 ?; Solexa-16420 0 0 0 0 0 0 ?; Solexa-16419 4 4 4 0 0 0 0; Solexa-16408 0 0 0 0 0 0 ?; Solexa-16416 2 2 2 0 0 0 0; Solexa-16426 0 0 0 0 0 0 ?; Solexa-16415 0 0 0 0 0 0 ?; Solexa-16404 3 9 3 0 2 0 0.190476 17; Solexa-16418 0 0 0 0 0 0 ?; Solexa-16407 0 0 0 0 0 0 ?; Solexa-16406 1 10 1 0 0 0 0; Solexa-16412 3 6 3 0 1 0 0.133333 15; Solexa-16423 0 0 0 0 0 0 ?; Solexa-16411 0 0 0 0 0 0 ?; Solexa-16422 0 0 0 0 0 0 ?; Solexa-16400 0 0 0 0 0 0 ?; Solexa-16425 0 0 0 0 0 0 ?; Solexa-16403 0 0 0 0 0 0 ?; Solexa-16414 0 0 0 0 0 0 ?; Solexa-16424 0 0 0 0 0 0 ?; Solexa-16402 0 0 0 0 0 0 ?; ```. The equivalent hellbender command . ```; hellbender MarkDuplicatesSpark --input src/test/resources/org/broadinstitute/hellbender/tools/picard/sam/MarkDuplicates/example.chr1.1-1K.unmarkedDups.bam --METRICS_FILE expected_duplicate_metrics.txt.spark --output out.bam.spark; ```. produces. ```; ## METRICS CLASS org.broadinstitute.hellbender.utils.read.markduplicates.DuplicationMetrics; LIBRARY UNPAIRED_READS_EXAMINED READ_PAIRS_EXAMINED UNMAPPED_READS UNPAIRED_READ_DUPLICATES READ_PAIR_DUPLICATES READ_PAIR_OPTICAL_DUPLICATES PERCENT_DUPLICATION ESTIMATED_LIBRARY_SIZE; Solexa-16416 2 2 2 0 0 0 0 0; Solexa-16404 3 9 3 0 2 0 0.190476 17; Solexa-16419 4 4 4 0 0 0 0 0; Solexa-16412 3 6 3 0 1 0 0.133333 15; Solexa-16406 1 10 1 0 0 0 0 0; ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1045:2299,test,test,2299,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1045,1,['test'],['test']
Testability,(also fixed a broken link in [Removing Samples from a VDS.md](https://github.com/broadinstitute/gatk/compare/ah_var_store...rsa_vs_749#diff-74ddd9f71eec0cc8080c093e76fbecdb3fa8b9d443e7071591b635e3d47afca5)). test run here: https://app.terra.bio/#workspaces/gvs-dev/RSA%20-%20GVS%20Quickstart%20V2%20/job_history/d2957947-0249-4197-9531-0b4203f2ea1c,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8110:208,test,test,208,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8110,1,['test'],['test']
Testability,(includes classes that are not supposed to be reviewed and added here only to compile and make tests pass. Those classes are being reviewed in other pull requests. I'll mark them on github),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/841:95,test,tests,95,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/841,1,['test'],['tests']
Testability,"(this is mainly relevant for Picard tools, which often have lots of log.info() calls). CommandLineProgram's VERBOSITY is set to INFO by default, which is reasonable when you're actually interacting with a tool, but quickly gets spammy when running unit tests. I propose injecting VERBOSITY=ERROR (the strictest setting) into CommandLineProgramTest to avoid this. This would fix https://github.com/broadinstitute/hellbender/issues/134",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/147:68,log,log,68,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/147,2,"['log', 'test']","['log', 'tests']"
Testability,"); 	at org.broadinstitute.hellbender.tools.walkers.vqsr.VariantRecalibratorEngine.generateModel(VariantRecalibratorEngine.java:43); 	at org.broadinstitute.hellbender.tools.walkers.vqsr.VariantRecalibrator.onTraversalSuccess(VariantRecalibrator.java:625); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:895); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:134); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:179); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:198); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); 	at org.broadinstitute.hellbender.Main.main(Main.java:289); ```. I believe this is derived from an error earlier in the log, since the `stderr` gives the same Java heap space error: ; ```; [2019-09-16 19:05:59,50] [error] WorkflowManagerActor Workflow 9f7a01a4-0632-4817-8622-aa51e520abf1 failed (during ExecutingWorkflowState): Job JointGenotyping.SNPsVariantRecalibratorClassic:NA:1 exited with return code 1 which has not been declared as a valid return code. See 'continueOnReturnCode' runtime attribute for more details.; Check the content of stderr for potential additional information: /path/to/stderr.; ```. I have read past issues (https://gatkforums.broadinstitute.org/gatk/discussion/23880/java-heap-space) regarding this that may suggest it is a bug. It has pointed me to increasing the available heap memory through the primary command of -Xmx. Is this the way to do it? ; ```; java -Xmx600G -Dconfig.file=' + re.sub('input.json', 'overrides.conf', input_json) + ' -jar ' + args.cromwell_path + ' run ' + re.sub('input.json', 'joint-discovery-gatk4.wdl', input_json) + ' -i ' + input_json; ```; where I substitute in the corresponding config, json, and wdl files. . Is 600G enough? Each vcf is ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6165:1781,log,log,1781,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6165,1,['log'],['log']
Testability,); at org.broadinstitute.hellbender.CommandLineProgramTest.runCommandLine(CommandLineProgramTest.java:65); at org.broadinstitute.hellbender.utils.test.testers.SamFileTester.runTest(SamFileTester.java:263); at org.broadinstitute.hellbender.utils.test.testers.AbstractMarkDuplicatesCommandLineProgramTest.testBulkFragmentsNoDuplicates(AbstractMarkDuplicatesCommandLineProgramTest.java:460); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:497); at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); at org.testng.internal.Invoker.invokeMethod(Invoker.java:639); at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:821); at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1131); at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); at org.testng.TestRunner.privateRun(TestRunner.java:773); at org.testng.TestRunner.run(TestRunner.java:623); at org.testng.SuiteRunner.runTest(SuiteRunner.java:357); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:352); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:310); at org.testng.SuiteRunner.run(SuiteRunner.java:259); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1185); at org.testng.TestNG.runSuitesLocally(TestNG.java:1110); at org.testng.TestNG.run(TestNG.java:1018); at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:133); at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:83); at ,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1768:3034,Test,TestMethodWorker,3034,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1768,1,['Test'],['TestMethodWorker']
Testability,"); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:166); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:185); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:76); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:83); at org.broadinstitute.hellbender.CommandLineProgramTest.runCommandLine(CommandLineProgramTest.java:76); at org.broadinstitute.hellbender.CommandLineProgramTest.runCommandLine(CommandLineProgramTest.java:80); at org.broadinstitute.hellbender.tools.genome.SparkGenomeReadCountsIntegrationTest.testSparkGenomeReadCounts(SparkGenomeReadCountsIntegrationTest.java:28). Caused by:; java.io.NotSerializableException: org.broadinstitute.hellbender.engine.TaggedInputFileArgument; Serialization stack:; - object not serializable (class: org.broadinstitute.hellbender.engine.TaggedInputFileArgument, value: /home/travis/build/broadinstitute/gatk-protected/src/test/resources/org/broadinstitute/hellbender/tools/genome/HCC1143_chr3_1K_11K.tiny.bam); - writeObject data (class: java.util.ArrayList); - object (class java.util.ArrayList, [/home/travis/build/broadinstitute/gatk-protected/src/test/resources/org/broadinstitute/hellbender/tools/genome/HCC1143_chr3_1K_11K.tiny.bam]); - field (class: org.broadinstitute.hellbender.cmdline.argumentcollections.OptionalReadInputArgumentCollection, name: readInputs, type: interface java.util.List); - object (class org.broadinstitute.hellbender.cmdline.argumentcollections.OptionalReadInputArgumentCollection, org.broadinstitute.hellbender.cmdline.argumentcollections.OptionalReadInputArgumentCollection@21d212c8); - field (class: org.broadinstitute.hellbender.engine.spark.GATKSparkTool, name: readArguments, type: class org.broadinstitute.hellbender.cmdline.argumentcollections.ReadInputArgumentCollection); - object (class org.broadinstitute.hellbender.tools.genome.SparkGenomeReadCounts, org.broadinstitute.hell",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2003:2679,test,test,2679,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2003,1,['test'],['test']
Testability,); at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:83); at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:497); at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35); at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); at org.gradle.messaging.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:32); at org.gradle.messaging.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:93); at com.sun.proxy.$Proxy2.stop(Unknown Source); at org.gradle.api.internal.tasks.testing.worker.TestWorker.stop(TestWorker.java:120); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:497); at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35); at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); at org.gradle.messaging.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:360); at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:54); at org.gradle.internal.concurrent.StoppableExecutorImpl$1.run(StoppableExecutorImpl.java:40); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1638:3546,test,testing,3546,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1638,2,['test'],['testing']
Testability,); at org.reflections.Reflections.scan(Reflections.java:204); at org.reflections.Reflections.<init>(Reflections.java:129); at com.google.cloud.genomics.dataflow.utils.DataflowWorkarounds.registerGenomicsCoders(DataflowWorkarounds.java:90); at org.broadinstitute.hellbender.tools.dataflow.transforms.InsertSizeMetricsTransformUnitTest.testInsertSizeMetricsTransform(InsertSizeMetricsTransformUnitTest.java:49); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:497); at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); at org.testng.internal.Invoker.invokeMethod(Invoker.java:659); at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:845); at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1153); at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:125); at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); at org.testng.TestRunner.privateRun(TestRunner.java:771); at org.testng.TestRunner.run(TestRunner.java:621); at org.testng.SuiteRunner.runTest(SuiteRunner.java:357); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:352); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:310); at org.testng.SuiteRunner.run(SuiteRunner.java:259); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1199); at org.testng.TestNG.runSuitesLocally(TestNG.java:1124); at org.testng.TestNG.run(TestNG.java:1032); at org.testng.remote.RemoteTestNG.run(RemoteTestNG.java:111); at org.testng.remote.RemoteTestNG.initAndRun(RemoteTestNG.java:204); at org.testng.remote.RemoteTestNG.main(RemoteTestNG.java:175); at org.testng.Remot,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/609:2011,test,testng,2011,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/609,1,['test'],['testng']
Testability,* A log message in SortSamSpark was using the wrong placeholder for inserting text so the message was printing; the literal characters %d instead inserting the correct value. Now it puts in a number.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6636:4,log,log,4,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6636,1,['log'],['log']
Testability,* Add new parameter to set filtered genotypes to no-calls to ExtractCohort; * Modified ExtractCohortEngine to optionally set genotypes that are filtered (FT flag set - at the genotype leve) to no-calls.; * Renamed VQSR Classic to 'VQSR'; * Renamed VQSR Lite to 'VETS'; * Updated VCF and pgen tests for code changes,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8797:292,test,tests,292,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8797,2,['test'],['tests']
Testability,"* Added liftover chain file creation script.; * Added WDLs and some arguments to lift over gnomAD; * Added chain file for b37->hg38 and arguments for liftover.; * Limited to 1000 records in memory.; * Added stack trace option to all wdls and sub tasks.; * Fixed output to be consistent with local files for indexing.; * Added timing information on wdls.; * Added a wdl/json to create a TSV from gnomAD allele freq data.; * Updated indexFeatureFile wdl, added params for run to index gnomAD.; * Added json file for indexing a large gnomad file.; * Fixed critical issues with NIO data sources.; * Updates to the test script to save output and point to full cloud data.; * Added some logging hooks to SeekableByteChannelPrefetcher. I haven't reviewed this since I made the changes to it to see what should stay, so it may need a fair bit of work.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5514:610,test,test,610,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5514,2,"['log', 'test']","['logging', 'test']"
Testability,"* Added new option --unfilteredBreakpointEvidenceDir; When set, this option dumps all evidence (even evidence that is; ultimately rejected) in an easy to parse text format. Some additional; info (cigarString, mappingQuality) is stored in ReadEvidence to output; information related to read quality.; * Updated option --readMetadata; When set, will additionaly output the map from contig number to contig; name. Added non-null ParitionBounds to readMetadata in; ReadMetadataTest::testEverything to prevent crash.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3691:479,test,testEverything,479,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3691,1,['test'],['testEverything']
Testability,"* Added support for annotating 5'/3' flanks via new FIVE_PRIME_FLANK and THREE_PRIME_FLANK funcotations. * Added --five-prime-flank-size and --three-prime-flank-size arguments to control the size of each flanking region. * Refactored datasource classes to allow for padded/custom queries to make this feature possible. * We now emit IGR funcotations in more cases (in particular, when a gene has no basic transcripts, and when the basic transcripts do not fully span a gene and the flank size is small). * Added comprehensive unit tests, and updated integration test data. Resolves #4771",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5403:531,test,tests,531,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5403,2,['test'],"['test', 'tests']"
Testability,"* Adding a new GATKTool level argument `--variant-output-interval-filtering-mode` which allows filtering output variants according to the input interval list. This replaces `--only-output-calls-starting-in-intervals` which was available in GenotypeGvcfs and GnarlyGenotyper. It works by adding a filtering decorator to the vcf writers created through `GATKTool.createVCFWriter`. ; There are several different filtering modes:; `STARTS_IN`, `ENDS_IN`, `OVERLAPS`, `CONTAINED`, and `ANYWHERE`. The default for tools is not to apply the decorator, but they may optionally change that behavior by overriding the new `getDefaultVariantOutputFilterMode`. `--variant-output-interval-filtering-mode STARTS_IN` is equivalent to the previous behavior of `--only-output-calls-starting-in-intervals true`. MockVcfWriter is now a testUtils class. The naming is a bit awkward so improvements would be helpful. This doesn't fix the weird behavior in HaplotypeCaller but does allow subsetting unique shards with SelectVariants and other variant outputting tools. We could adapt this to apply to bam outputs as well if that seems useful.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6388:794,Mock,MockVcfWriter,794,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6388,2,"['Mock', 'test']","['MockVcfWriter', 'testUtils']"
Testability,* Adding forkEvery 5 to cause the test jvm to be restarted every few test classes.; * This might fix a theoretical memory leak causing our builds to fail often. This might help?,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6093:34,test,test,34,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6093,2,['test'],['test']
Testability,"* Bump GKL version to 0.4.3 which addresses some GC and memory leak issues.; * Remove DEBUG verbosity setting in `IntelInflaterDeflaterIntegrationTest`, which caused subsequent tests to generate huge amounts of debug info and run out of memory on some systems. Resolves #2490 and resolves #2535.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2566:177,test,tests,177,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2566,1,['test'],['tests']
Testability,* Centralizes Docker image versioning to top-level WDLs; * Does away with GATK override jar in all cases except integration tests (override jar can still be specified during feature development and/or for emergencies); * Docker image versions can be captured as the inputs to tasks; * Freshens Variants Docker image. Integration run [here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/815ef8ea-8cfe-47b6-be80-54250d1f180b),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8457:124,test,tests,124,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8457,1,['test'],['tests']
Testability,* Change extract so that when we filter at the genotype level (with FT) the VCF header has the FT filter definition in the comment/unspecified field.; * Also minor renaming of ExtractCohort argument.; * Point to updated truth.; ; [Here's](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/94129da8-6faf-419b-ab75-a46c228b1bbe) an integration test run. Passing everything except ValidateVDS because `reference_data` not being written due to issues beyond my control.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8850:364,test,test,364,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8850,1,['test'],['test']
Testability,* Changing test results directory for the docker tests to match the test results directory from the non docker test.; * Awkward handling of this seems to have been resulting in different test output paths and causing the reporting bot to sometimes fail to report the correct file location,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8718:11,test,test,11,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8718,5,['test'],"['test', 'tests']"
Testability,"* Currently things are in a weird state, picard style interval lists are handled either as tribble files if they are named correctly as .interval_list; If they are named .intervals, .picard, or .list they are loaded with a different code path.; This unifies it so that picard files are only loaded as .interval_list and .intervals is always considered a Gatk style list. * This removes the work around for broken 0 length intervals that was put in place a long time ago. However, the workaround was effectively removed; for all .interval_list files in 4.1.3.0 when we started reading those through the tribble plugin. Either the broken files no longer are used or they; are misnamed as .intervals. * fix tests to deal correctly with .inverval_list vs .intervals",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6465:704,test,tests,704,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6465,1,['test'],['tests']
Testability,* Disabling SortSamSparkIntegrationTest.testSortBAMsSharded(); * This test is failing in master because of a disq bug.; * This should be re-enabled when https://github.com/broadinstitute/gatk/issues/5881 is fixed.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6635:40,test,testSortBAMsSharded,40,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6635,2,['test'],"['test', 'testSortBAMsSharded']"
Testability,* Have GvsCreateVATfromVDS.wdl take sites-only-vcf as an optional input.; * Added logic to allow/disallow CopyFile to overwrite. [Here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Quickstart%20v3%20ggrant/job_history/bb8906d4-7111-4fd1-a723-b5616b354c23) is a passing run using an existing sites-only VCF.; [Here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Quickstart%20v3%20ggrant/job_history/9c8be4d5-f707-4c54-bde5-18d9d23cde66) is a run where it tried to generate the sites-only VCF. Failing because of Echo issues with creating VDS.; [Here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/8f8cc493-b0ff-4d8c-8813-6c463dbf17c0) is an integration test. It's failing in ValidateVDS on two paths (the ones that create VDSes) since this is based off of EchoCallset branch - this is expected,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8866:82,log,logic,82,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8866,2,"['log', 'test']","['logic', 'test']"
Testability,* It turned out we weren't logging in to dockerhub on the wdl test cases in travis because I misunderstood how the DOCKER_TEST flag was used.; * Now we unconditionally authenticate to dockerhub in all test shards instead of trying to pick only the relevant ones.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7256:27,log,logging,27,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7256,3,"['log', 'test']","['logging', 'test']"
Testability,* Remove repo-specific files from `BaseTest` in favor of `TestResources` constants; * Remove `GenomeLocParser`initialization in `BaseTest` in favor of on-demand initialization in `TestResources` and getters for related objects. Closes #3029 ; Closes #2125,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3176:58,Test,TestResources,58,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3176,2,['Test'],['TestResources']
Testability,"* Should be runnable on-demand using a convenient mechanism (eg., reviewer types a command on a github PR). * Should be robust enough to provide confidence that a substantial change to a stable variant-calling tool is safe to merge. * Should cover performance as well as correctness. * Output may be a report that a human has to read (do not need automated pass/fail). * Implement for `HaplotypeCaller` and CNV tools first (with help of @LeeTL1220), then work with other teams to get test coverage for their tools.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4630:484,test,test,484,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4630,1,['test'],['test']
Testability,* SparkContextFactory no longer always emits a warning about the GCS connector environment variables.; This should now only occur when running tests and missing the necessary environment variables. I should have fixed this one a long time ago...,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5987:143,test,tests,143,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5987,1,['test'],['tests']
Testability,* This fixes an issue while installing gcloud on travis due to permissions in the root directories. @ldgauthier This should fix the issue you were seeing where test files weren't being uploaded.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7525:160,test,test,160,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7525,1,['test'],['test']
Testability,"* Updating htsjdk 2.18.1 -> 2.18.2; * Remove deprecated method use; * Changing IntervalUtilsUnitTest due to changes in IntervalList; * IntervalList now rejects certain invalid intervals that it previously didn't and throw IllegalArgumentException.; * This ends up changing which exceptions are thrown in some cases, updated some tests to accept both MalformedFile and MalforedGenomeLoc.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5585:329,test,tests,329,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5585,1,['test'],['tests']
Testability,"* VariantContexts from an assembled haplotype's EventMap, or found from pileups, that are really containers for a single alt allele, are explicitly marked as such. This way we don't have to keep tracing back the source of a biallelic variant context and putting in little comments about why it's safe to assume it has only one alt allele.; * Some methods that remove or add haplotypes based on alleles found in pileups have been made void methods of AssemblyResultSet, which to mind mind is the appropriate way to encapsulate transformations acting on that class.; * other random simplification of code surrounding pileup haplotypes. @jamesemery This is a warmup PR for DRAGEN stuff, a bit of housekeeping of code at the margins of partially determined haplotype logic.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8332:763,log,logic,763,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8332,1,['log'],['logic']
Testability,* When running recursive deletion file hooks we now catch all exceptions and log them at DEBUG level instead of letting them propagate.; * This should reduce confusion when test have deletion failures.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6125:77,log,log,77,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6125,2,"['log', 'test']","['log', 'test']"
Testability,* `JointVariantCalling` [does set](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/f3f98f0e-2a7f-460b-886f-3442551140a8) `tighter_gcp_quotas`.; * Integration tests [do not set](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/51213d40-7583-49f1-a101-1842180a6470) `tighter_gcp_quotas`.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8540:182,test,tests,182,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8540,1,['test'],['tests']
Testability,"* added a reference parameter to FeatureData source and FeatureManager methods; * genomicsDB requires a reference, previously this was being passed; through by hardcoding it in the required json files; * json files are now autogenerated by the importer tool, but the; reference wasn't being handled correctly. * updated the various walkers to pass the reference through if available. * gendb:// paths now point to the workspace directory instead of a; directory of jsons. * removed the ability to specify array, vidmap.json, and; callset.json paths in the importer tool since we now rely on the; structure and naming of the files when loading; moved some constants to GenomicsDBConstants. * updated GenomicsDBIntegration tests to use the new importer instead of a; prepackaged and very brittle set of json files. fixed a bug in GenomicsDBImporterIntegrationTests that made both tests; write to the same workspace",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2626:721,test,tests,721,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2626,2,['test'],['tests']
Testability,* adding back GenomicDBImportIntegrationTest.testYouCantWriteIntoAnExistingDirectory that was accidentally deleted; * fixing spacing issues introduced in the same pr; * removing unused parameter from internal method,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4175:45,test,testYouCantWriteIntoAnExistingDirectory,45,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4175,1,['test'],['testYouCantWriteIntoAnExistingDirectory']
Testability,"* changes to GenotypingEngine.calculateGenotypes in #2528 introduced a regression that caused IndexOutOfBoundsException; * fixes #2530 by preventing the exception and adding tests. @davidbenjamin Note that I also changed the condition from ""first alt allele is NON_REF"" to ""any alt allele is NON_REF"". This more accurately matches what the comment says, but let me know if you think it's not the right thing.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2531:174,test,tests,174,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2531,1,['test'],['tests']
Testability,"* changing GenotypeCounts to be doubles instead of ints, this is weird but it's how gatk3 is; * adding an additional boolean parameter to computeDiploidGenotypeCounts that controls rounding behavior; ExcessHet needs rounding on; InbreedingCoeff needs it off; * adding a new GenotypeUtilsUnitTest class; these tests are not exhaustive and leave most conditions untested; * updating InbreedingCoeffUnitTest with a test that checks that we match gatk3 output for a previously divergent case",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2546:309,test,tests,309,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2546,2,['test'],"['test', 'tests']"
Testability,* com.intel.gkl:gkl:0.8.8 -> 0.8.10. @droazen @kachulis Maybe we should update to the newest version and rerun the tests?,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8181:115,test,tests,115,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8181,1,['test'],['tests']
Testability,* creating utils to spin up a Dataproc cluster which will shut itself down after a brief interval of inactivity (10 minutes idle or 30 minutes total); * adding tests which spin up a cluster and run PrintReadsSpark on them; * updating gatk-launch to be aware of new GCLOUD_HOME environment variable. first round of #2298,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3767:160,test,tests,160,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3767,1,['test'],['tests']
Testability,* disables tests that use the now defunct google genomics reference API; * update BaseRecalibratorSparkIntegrationTest.testBQSRFailWithIncompatibleReference to not use the reference API; * fixes #4163; * these tests should be revisted and removed or replaced in #4166,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4178:11,test,tests,11,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4178,3,['test'],"['testBQSRFailWithIncompatibleReference', 'tests']"
Testability,* moved a log message about creating the python bundle during build so it only triggers when the python bundle is actually being built; * previously it was emitted on every build,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4147:10,log,log,10,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4147,1,['log'],['log']
Testability,* previously the docker build would unnecessarily pull the test files,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7727:59,test,test,59,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7727,1,['test'],['test']
Testability,"* this is currently broken, see https://github.com/broadinstitute/gatk/issues/4274; * add a check to HaplotypeCallerSpark and VariantSparkSink and throw a clear exception in this case; * added test for GVCF writing in VariantSparkSink which previously didn't exist; * added new UserException.UnimplementedFeature class; * closes https://github.com/broadinstitute/gatk/issues/4275",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4277:193,test,test,193,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4277,1,['test'],['test']
Testability,* updating Intel-GKL from 8.5 -> 8.6; * this is a very minor update that only changes a log message; * fixes https://github.com/broadinstitute/gatk/issues/5393,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5463:88,log,log,88,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5463,1,['log'],['log']
Testability,* updating htsjdk 2.16.1 -> 2.18.0; * the most noticable change is that we will now produce bam 1.6 instead; of 1.5; * some test files updated to have the new version since they were being; compared with exact match tests,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5424:124,test,test,124,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5424,2,['test'],"['test', 'tests']"
Testability,* updating tests because a toString changed in htsjdk and it's value is written directly into the outputs of some tools; * fix two trivial mistakes in ExampleVariantWalkerSpark that I noticed,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4401:11,test,tests,11,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4401,1,['test'],['tests']
Testability,"**;BQHIST=5,1,0,0,1,11,2,0,0,0,14,2,0,0,1,15,1,0,0,0,16,1,0,0,0,17,0,2,0,0,18,2,0,0,1,19,6,0,1,0,20,25,0,2,2,21,13,0,1,2,22,20,0,3,3,23,2,1,2,1,24,6,0,2,0,25,21,1,4,7,26,33,0,5,6,27,18,0,0,7,28,29,0,0,4,29,26,2,4,8,30,161,4,5,51,31,263,2,3,51,32,129,2,3,22,33,41,0,0,0,34,15,0,0,0,35,20,0,0,0,36,19,0,0,0,37,12,0,0,0,38,1,0,0,0,39,9,0,0,0,41,18,0,0,0,44,26,0,0,0;BaseQRankSum=-6.431;ClippingRankSum=-7.714;DP=1323;ECNT=1;FS=0.000;LikelihoodRankSum=-7.886;MBQ=31,30,26,30;MFRL=6590,6585,4819,6586;MMQ=60,60,60,60;MPOS=16,15,7;MQ=59.98;MQ0=0;MQRankSum=0.000;NALOD=0.569,1.49,1.49;NCC=0;NCount=0;NLOD=27.80,30.51,30.97;OCM=0;POPAF=6.00,6.00,6.00;REF\_BASES=GAACTTGCTTCTTTTTTTTGC;RPA=8,9,10,11;RU=T;ReadPosRankSum=5.751;SOR=1.152;STR;Samples=TCGA-NJ-A55R-01A-11R-A262-07;TLOD=284.47,51.82,3.50 GT:AD:AF:DP:F1R2:F2R1:SB 0/1/2/3:819,166,35,14:0.161,0.034,0.014:1034:365,76,17,4:440,87,17,8:16,803,6,209 0/0:103,1,0,0:0.017,8.250e-03,8.221e-03:104:50,1,0,0:52,0,0,0:26,77,0,1. The error log that FilterMutectCalls emited was listed below:. Using GATK jar /home/lqh/software/GATK-4.2.0.0/gatk-package-4.2.0.0-local.jar ; ; Running: ; ; java -Dsamjdk.use\_async\_io\_read\_samtools=false -Dsamjdk.use\_async\_io\_write\_samtools=true -Dsamjdk.use\_async\_io\_write\_tribble=false -Dsamjdk.compression\_level=2 -jar /home/lqh/software/GATK-4.2.0.0/gatk-package-4.2.0.0-local.jar FilterMutectCalls -R /public1/data/resources/ref\_genome/GRCh38/GRCh38.d1.vd1.fa -V somatic\_mutation/Mutect2/test.vcf.gz -O somatic\_mutation/FilterMutectCalls/test.vcf.gz ; ; 11:03:39.517 INFO NativeLibraryLoader - Loading libgkl\_compression.so from jar:file:/home/lqh/software/GATK-4.2.0.0/gatk-package-4.2.0.0-local.jar!/com/intel/gkl/native/libgkl\_compression.so ; ; Jun 04, 2021 11:03:49 AM shaded.cloud\_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine ; ; INFO: Failed to detect whether we are running on Google Compute Engine. ; ; 11:03:49.968 INFO FilterMutectCalls - --------------------------",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7298:2369,log,log,2369,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7298,1,['log'],['log']
Testability,"**Brief issue description:** ; When following the tutorial https://gatk.broadinstitute.org/hc/en-us/articles/360035531092--How-to-part-I-Sensitively-detect-copy-ratio-alterations-and-allelic-segments, the #4 Plot standardized and denoised copy ratios with PlotDenoisedCopyRatios have different results than the tutorial. Through the control vectors test, it seems that the samples that are used in step #2 to generate CNV PON used in the tutorial are different from the files stored in the tutorial.; **Results:**; Following steps 1 to 4, the resulting plots; ![hcc1143_T_clean denoised](https://github.com/broadinstitute/gatk/assets/89409924/3bce4382-5109-4c6e-b34d-1c6e365dcf62); ![hcc1143_T_clean denoisedLimit4](https://github.com/broadinstitute/gatk/assets/89409924/9d23987c-2747-43af-b72c-4e3754015531); The results have values However, the values in the tutorial are 0.134 and 0.125.; **Tests**; Using the files provided in the tutorial and script generated `cnvponC.pon.hdf5`, which seems to lead to this inconsistency result.; Using:; gatk --java-options ""-Xmx6500m"" CreateReadCountPanelOfNormals \; -I HG00133.alt_bwamem_GRCh38DH.20150826.GBR.exome.counts.hdf5 \; -I HG00733.alt_bwamem_GRCh38DH.20150826.PUR.exome.counts.hdf5 \; -I NA19654.alt_bwamem_GRCh38DH.20150826.MXL.exome.counts.hdf5 \; --minimum-interval-median-percentile 5.0 \; -O sandbox/cnvponC.pon.hdf5; **Files**; The script used to generate this result are attached. ; [gatk_tutorial11682_issue.zip](https://github.com/user-attachments/files/15930567/gatk_tutorial11682_issue.zip). Please help me understand this difference in reproducing the tutorial result. It will be extremely helpful for me to use the pipelines on our lab-generated data. Thank you very much!",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8884:349,test,test,349,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8884,3,"['Test', 'sandbox', 'test']","['Tests', 'sandbox', 'test']"
Testability,**DO NOT MERGE** assembly changes to test carrot,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7723:37,test,test,37,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7723,1,['test'],['test']
Testability,**DO NOT MERGE*** Test ForkPRs with Github actions,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7785:18,Test,Test,18,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7785,1,['Test'],['Test']
Testability,"**Initial integration of GKL**; - Removed native build related items from `build.gradle`; - Removed native code from src tree; - Refactored `PairHMM.java` and `VectorLoglessPairHMM.java` to use GKL; - Updated `VectorPairHMMUnitTest.java` to use GKL; - Added integration tests to `IntelDeflaterIntegrationTest.java`. **Notes**; - PairHMM has been tested in HaplotypeCaller and GVCF output is md5sum equivalent to the PairHMM currently in GATK; - PairHMM in GKL is still single threaded, but about **_1.4x faster**_ than existing PairHMM, due to fixing a performance issue in the native code; - Next steps are captured in #1903 #1946",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1935:270,test,tests,270,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1935,2,['test'],"['tested', 'tests']"
Testability,"**Summary**: ; A user reported `java.io.IOException: Stream closed` error with ApplyBQSRSpark. GATK 4.0.9.0 runs fine but when the user upgraded to gatk 4.1.1.0 version, they see his error. **User Report**:; I am getting the below error when running gatk-variant pipeline of bcbio. Bcbio using gatk 4.1.1.0 version. ; When I run ApplyBQSRSpark using GATK 4.0.9.0, it runs fine without any issues. Here is the command; **; gatk ApplyBQSRSpark --input test-sort.bam --output test-sort-recal.bam --bqsr-recal-file test-sort-recal.grp --static-quantized-quals 10 --static-quantized-quals 20 --static-quantized-quals 30 --spark-master local[8] --conf spark.local.dir=scratch/ --conf spark.driver.host=localhost --conf spark.network.timeout=800 --jdk-deflater --jdk-inflater**. Here is the error. [April 28, 2019 10:11:25 AM AST] org.broadinstitute.hellbender.tools.spark.ApplyBQSRSpark done. Elapsed time: 0.15 minutes.; Runtime.totalMemory()=874512384; **htsjdk.samtools.util.RuntimeIOException: java.io.IOException: Stream closed**; at htsjdk.samtools.IndexStreamBuffer.readFully(IndexStreamBuffer.java:23); at htsjdk.samtools.IndexStreamBuffer.readLong(IndexStreamBuffer.java:62); at htsjdk.samtools.AbstractBAMFileIndex.readLong(AbstractBAMFileIndex.java:436); at htsjdk.samtools.AbstractBAMFileIndex.query(AbstractBAMFileIndex.java:311); at htsjdk.samtools.CachingBAMFileIndex.getQueryResults(CachingBAMFileIndex.java:159); at htsjdk.samtools.BAMIndexMerger.processIndex(BAMIndexMerger.java:43); at htsjdk.samtools.BAMIndexMerger.processIndex(BAMIndexMerger.java:16); at org.disq_bio.disq.impl.file.IndexFileMerger.mergeParts(IndexFileMerger.java:90); at org.disq_bio.disq.impl.formats.bam.BamSink.save(BamSink.java:132); at org.disq_bio.disq.HtsjdkReadsRddStorage.write(HtsjdkReadsRddStorage.java:225); at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSink.writeReads(ReadsSparkSink.java:155); at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSink.writeReads(Rea",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5919:450,test,test-sort,450,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5919,3,['test'],"['test-sort', 'test-sort-recal']"
Testability,"**changes in this PR:**; - resolves specops issue #247 - ImportGenomes.wdl takes Array[File] from data table as vcf input; - refactor LoadBigQueryData.wdl back into ImportGenomes; - returns an error if the `bq load` step fails (workflow was silently succeeding when this step failed); - checks existence of tables using `bq show` rather than the csv file - this should still be safe against a race condition because of @ericsong 's refactoring to prevent the `CreateTables` step from being scattered; - run CreateTables at the start (don't wait for CreateImportTsvs); - does NOT use a preemptible VM for the LoadTables step, to minimize (though not eliminate) the possibility of loading a duplicate set of data (see specops issue #248 for further discussion). **testing:**; - these changes were tested in Terra, BQ outputs checked and verified",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7112:762,test,testing,762,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7112,2,['test'],"['tested', 'testing']"
Testability,"**feature request**, or a **documentation request** (for tool/class javadoc only -- for forum docs please post there); - Consider if your ""issue"" is better addressed on the GATK forum: http://gatkforums.broadinstitute.org/gatk Post there if you have questions about expected tool behavior, output format, unexpected results, or generally any question that does not fit into the categories above; - Use a **concise** yet **descriptive** title; - Choose the corresponding template block below and fill it in, replacing or deleting text in italics (surrounded by `_`) as appropriate; - Delete the other template blocks and this header. ----. ## Bug Report. ### Affected tool(s) or class(es); _Tool/class name(s), special parameters?_. After sourcing the tab-completion script, some tools shown cannot be run. Maybe they exist somewhere in an experimental dev version but are not bundled for public release?. ### Affected version(s); - [x ] Latest public release version [4.1.7.0]; - [ ] Latest master branch as of [date of test?]. ### Description ; _Describe the problem below. Provide **screenshots** , **stacktrace** , **logs** where appropriate._. After trying to tab complete the DepthOfCoverage, I saw a few tools not listed in the documentation. I tried running them and sure enough, there were errors:. `A USER ERROR has occurred: '*' is not a valid command.`; (* is one of the tools listed below). #### Steps to reproduce; _Tell us how to reproduce this issue. If possible, include command lines that reproduce the problem. (The support team may follow up to ask you to upload data to reproduce the issue.)_. ```; cd gatk-4.1.7.0; source gatk-completion.sh; ./gatk Depth<tab>; #>DepthOfCoverage DepthPerAlleleBySample DepthPerSampleHC; ./gatk DepthPerSampleHC -h; ...; ***********************************************************************; A USER ERROR has occurred: 'DepthPerSampleHC' is not a valid command.; ***********************************************************************; ./gatk Dep",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6615:1549,test,test,1549,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6615,1,['test'],['test']
Testability,"*, a **feature request**, or a **documentation request** (for tool/class javadoc only -- for forum docs please post there); - Consider if your ""issue"" is better addressed on the GATK forum: http://gatkforums.broadinstitute.org/gatk Post there if you have questions about expected tool behavior, output format, unexpected results, or generally any question that does not fit into the categories above; - Use a **concise** yet **descriptive** title; - Choose the corresponding template block below and fill it in, replacing or deleting text in italics (surrounded by `_`) as appropriate; - Delete the other template blocks and this header. ----. ## Bug Report. ### Affected tool(s) or class(es); _Tool/class name(s), special parameters?_; MarkDuplicates. ### Affected version(s); - [ ] Latest public release version [version?]; 4.6.0.0 GATK and Picard 3.2.0; - [ ] Latest master branch as of [date of test?]; 3 Jul 2023. ### Description ; _Describe the problem below. Provide **screenshots** , **stacktrace** , **logs** where appropriate._; I'm trying to use gatk for finding snps in exome capture project. I get an error when trying to use MarkDuplicates - I tried using it from picard and from gatk. The screen output is:; ```; picard MarkDuplicates I=WA02_i5-537_i7-98_S11819_L004.bam O=test.dup.bam M=marked_dup_metrics.txt; INFO 2024-07-03 15:25:31 MarkDuplicates. ********** NOTE: Picard's command line syntax is changing.; **********; ********** For more information, please see:; **********; https://github.com/broadinstitute/picard/wiki/Command-Line-Syntax-Transition-For-Users-(Pre-Transition); **********; ********** The command line looks like this in the new syntax:; **********; ********** MarkDuplicates -I WA02_i5-537_i7-98_S11819_L004.bam -O test.dup.bam -M marked_dup_metrics.txt; **********. 15:25:31.262 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/opt/picard/build/libs/picard.jar!/com/intel/gkl/native/libgkl_compression.so; [Wed Jul 03 15:25:31 CEST 202",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8904:1535,log,logs,1535,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8904,1,['log'],['logs']
Testability,"+ blaunch -no-wait -z hpcgenomicn24 /spark-1.6.2-bin-hadoop2.6//bin/spark-class org.apache.spark.deploy.worker.Worker spark://hpcgenomicn24:6311 -c 16; + echo --conf spark.executor.memory=2g --conf spark.driver.memory=2g --conf spark.local.dir=/gpfs/ngsdata/sparkcache --class org.broadinstitute.hellbender.Main /gpfs/software/spark/gatk4onspark.jar PrintReadsSpark -I /gpfs/home/tpathare/gatk/src/test/resources/NA12878.chr17_69k_70k.dictFix.bam -O /gpfs/home/tpathare/test/; --conf spark.executor.memory=2g --conf spark.driver.memory=2g --conf spark.local.dir=/gpfs/ngsdata/sparkcache --class org.broadinstitute.hellbender.Main /gpfs/software/spark/gatk4onspark.jar PrintReadsSpark -I /gpfs/home/tpathare/gatk/src/test/resources/NA12878.chr17_69k_70k.dictFix.bam -O /gpfs/home/tpathare/test/; + /spark-1.6.2-bin-hadoop2.6//bin/spark-submit --master spark://hpcgenomicn24:6311 --conf spark.executor.memory=2g --conf spark.driver.memory=2g --conf spark.local.dir=/gpfs/ngsdata/sparkcache --class org.broadinstitute.hellbender.Main /gpfs/software/spark/gatk4onspark.jar PrintReadsSpark -I /gpfs/home/tpathare/gatk/src/test/resources/NA12878.chr17_69k_70k.dictFix.bam -O /gpfs/home/tpathare/test/; 23:25:07.475 INFO IntelGKLUtils - Trying to load Intel GKL library from:; 	jar:file:/gpfs/software/spark/gatk4onspark.jar!/com/intel/gkl/native/libIntelGKL.so; 23:25:07.552 INFO IntelGKLUtils - Intel GKL library loaded from classpath.; [November 16, 2016 11:25:07 PM AST] org.broadinstitute.hellbender.tools.spark.pipelines.PrintReadsSpark --output /gpfs/home/tpathare/test/ --input /gpfs/home/tpathare/gatk/src/test/resources/NA12878.chr17_69k_70k.dictFix.bam --readValidationStringency SILENT --interval_set_rule UNION --interval_padding 0 --interval_exclusion_padding 0 --bamPartitionSize 0 --disableSequenceDictionaryValidation false --shardedOutput false --numReducers 0 --sparkMaster local[*] --help false --version false --verbosity INFO --QUIET false --use_jdk_deflater false --disableAllReadFilte",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2268:398,test,test,398,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2268,4,['test'],['test']
Testability,", in __init__; self.refresh(); File ""/usr/local/Anaconda/envs_app/gatk/4.1.2.0/lib/python3.6/site-packages/theano/gof/cmodule.py"", line 794, in refresh; files = os.listdir(root); FileNotFoundError: [Errno 2] No such file or directory: '/spin1/home/linux/gatk_users1/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-centos-7.5.1804-Core-x86_64-3.6.2-64/tmpmy0w17z3'; 00:34:39.396 DEBUG ScriptExecutor - Result: 1; 00:34:39.397 INFO DetermineGermlineContigPloidy - Shutting down engine; [October 27, 2019 12:34:39 AM EDT] org.broadinstitute.hellbender.tools.copynumber.DetermineGermlineContigPloidy done. Elapsed time: 0.66 minutes.; Runtime.totalMemory()=2151677952; org.broadinstitute.hellbender.utils.python.PythonScriptExecutorException: ; python exited with 1; Command Line: python /tmp/cohort_determine_ploidy_and_depth.3351404099122294482.py --sample_coverage_metadata=/tmp/samples-by-coverage-per-contig8898090777596224038.tsv --output_calls_path=/gpfs/gsfs7/users/gatk_users1/0-Project/1-gCNV-Lung/z-bak/z-2019-10-26-1-Test-gCNV/2-Output/1-Contig-Ploidy/22.Contig_Ploidy_Dir/ploidy-calls --mapping_error_rate=1.000000e-02 --psi_s_scale=1.000000e-04 --mean_bias_sd=1.000000e-02 --psi_j_scale=1.000000e-03 --learning_rate=5.000000e-02 --adamax_beta1=9.000000e-01 --adamax_beta2=9.990000e-01 --log_emission_samples_per_round=2000 --log_emission_sampling_rounds=100 --log_emission_sampling_median_rel_error=5.000000e-04 --max_advi_iter_first_epoch=1000 --max_advi_iter_subsequent_epochs=1000 --min_training_epochs=20 --max_training_epochs=100 --initial_temperature=2.000000e+00 --num_thermal_advi_iters=5000 --convergence_snr_averaging_window=5000 --convergence_snr_trigger_threshold=1.000000e-01 --convergence_snr_countdown_window=10 --max_calling_iters=1 --caller_update_convergence_threshold=1.000000e-03 --caller_internal_admixing_rate=7.500000e-01 --caller_external_admixing_rate=7.500000e-01 --disable_caller=false --disable_sampler=false --disable_annealing=false --interval_list=/tmp/in",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6235:5284,Test,Test-gCNV,5284,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6235,1,['Test'],['Test-gCNV']
Testability,",0.300,1|-2.000,1|;AS_RAW_MQ=14731200.000|828000.000|3600.000|0.000;AS_RAW_MQRankSum=|0.000,2|0.000,1|;AS_RAW_ReadPosRankSum=|0.300,1,1.900,1|0.100,1|;AS_SB_TABLE=1874,2218|112,118|0,1|0,0;BaseQRankSum=0.388;DP=39331;MQRankSum=0;RAW_MQandDP=16254000,4515;ReadPosRankSum=2.007 GT:AD:GQ:MIN_DP:SB:DP ./././././././././././././././././././.:.:9:1445:.:1628 ./././././././././././././././././././.:2150,118,1,0:99:.:979,1171,59,60:2269 ./././././././././././././././././././.:.:9:1867:.:2079 ./././././././././././././././././././.:.:9:1927:.:2216 ./././././././././././././././././././.:.:9:2056:.:2328 ./././././././././././././././././././.:.:9:2611:.:2992 ./././././././././././././././././././.:.:9:2547:.:2857 ./././././././././././././././././././.:.:9:1836:.:2175 ./././././././././././././././././././.:.:9:2334:.:2681 ./././././././././././././././././././.:.:9:1723:.:1966 ./././././././././././././././././././.:.:9:1790:.:2010 ./././././././././././././././././././.:1942,112,0,0:99:.:895,1047,53,59:2054 ./././././././././././././././././././.:.:9:1743:.:2058 ./././././././././././././././././././.:.:9:1937:.:2283 ./././././././././././././././././././.:.:9:1918:.:2244 ./././././././././././././././././././.:.:9:1743:.:1964 ./././././././././././././././././././.:.:9:2032:.:2290 ./././././././././././././././././././.:.:9:1748:.:1953 ./././././././././././././././././././.:.:9:1748:.:2037 ./././././././././././././././././././.:.:9:1811:.:2017; `. CombineGVCFs version of the site. `chr13 32339012 . A G,T,<NON_REF> . . BaseQRankSum=0.388;DP=39331;MQRankSum=0.00;RAW_MQandDP=16254000,4515;ReadPosRankSum=2.01 GT:AD:DP:GQ:MIN_DP:PL:SB ./././././././././././././././././././.:.:1628:9:1445:0,9,18,28,39,50,62,7..... (redacted..); `. GenomicsDB dump is lacking the PL field therefore final genotyped VCF is missing this variant. CombineGVCFs on the other hand has the proper PL field. ; Ploidy is 20 in these samples. . I asked user to send us snippets of those GVCF files for testing.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/9024:2370,test,testing,2370,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/9024,1,['test'],['testing']
Testability,",472:0,0,2,4; 20 10068167 . T *,<NON_REF> . . DP=28 GT:AD:DP:GQ:PL:SB ./.:0,4,0:6:53:735,102,53,507,108,472:0,0,2,4; 20 10068168 . A *,<NON_REF> . . DP=28 GT:AD:DP:GQ:PL:SB ./.:0,4,0:6:53:735,102,53,507,108,472:0,0,2,4; 20 10068169 . T *,<NON_REF> . . DP=28 GT:AD:DP:GQ:PL:SB ./.:0,4,0:6:53:735,102,53,507,108,472:0,0,2,4; 20 10068170 . A *,<NON_REF> . . DP=28 GT:AD:DP:GQ:PL:SB ./.:0,4,0:6:53:735,102,53,507,108,472:0,0,2,4; 20 10068171 . T *,<NON_REF> . . DP=28 GT:AD:DP:GQ:PL:SB ./.:0,4,0:6:53:735,102,53,507,108,472:0,0,2,4; 20 10068172 . G *,<NON_REF> . . DP=28 GT:AD:DP:GQ:PL:SB ./.:0,4,0:6:53:735,102,53,507,108,472:0,0,2,4; 20 10068173 . T *,<NON_REF> . . DP=28 GT:AD:DP:GQ:PL:SB ./.:0,4,0:6:53:735,102,53,507,108,472:0,0,2,4; 20 10068174 . A *,<NON_REF> . . DP=28 GT:AD:DP:GQ:PL:SB ./.:0,4,0:6:53:735,102,53,507,108,472:0,0,2,4; ```. GenomicsDBImport run like this:. ```; ./gatk GenomicsDBImport -R src/test/resources/large/human_g1k_v37.20.21.fasta -L 20 -V src/test/resources/org/broadinstitute/hellbender/tools/haplotypecaller/expected.testGVCFMode.gatk4.g.vcf -genomicsdb-workspace-path spanDelWorkspace; ./gatk SelectVariants -V gendb://spanDelWorkspace -R src/test/resources/large/human_g1k_v37.20.21.fasta -O test.g.vcf -L 20; ```. Returns the following output:. ```; 20 10068158 . GTGTATATATATA G,<NON_REF> . . BaseQRankSum=-6.520e-01;ClippingRankSum=0.00;DP=29;ExcessHet=3.01;MQRankSum=0.328;RAW_MQ=93364.00;ReadPosRankSum=-2.530e-0; 1 GT:AD:DP:GQ:PL:SB ./.:3,4,0:7:57:104,0,57,114,69,183:0,3,2,2; 20 10068159 . T *,<NON_REF> . . DP=29 GT:AD:DP:GQ:PL:SB ./.:3,4,0:7:57:104,0,57,114,69,183:0,3,2,2; 20 10068160 . GTATATATATATGTA G,*,<NON_REF> . . DP=28;ExcessHet=3.01;RAW_MQ=87005.00 GT:AD:DP:GQ:PL:SB ./.:0,2,4,0:6:53:735,162,131,102,0,53,507,174,108,472:0,0,; 2,4; 20 10068161 . T *,<NON_REF> . . DP=28 GT:AD:DP:GQ:PL:SB ./.:0,2,0:6:53:735,162,131,507,174,472:0,0,2,4; 20 10068162 . A *,<NON_REF> . . DP=28 GT:AD:DP:GQ:PL:SB ./.:0,2,0:6:53:735,162,131,507,174,472:0,0,2,4; 20 100681",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5160:3264,test,test,3264,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5160,1,['test'],['test']
Testability,",67] [info] 1 new workflows fetched by cromid-ca5c695: 968be82c-eef3-4bdb-a1ab-3d4e2ca70674; [2020-07-14 05:09:30,68] [info] WorkflowManagerActor Starting workflow 968be82c-eef3-4bdb-a1ab-3d4e2ca70674; [2020-07-14 05:09:30,69] [info] WorkflowManagerActor Successfully started WorkflowActor-968be82c-eef3-4bdb-a1ab-3d4e2ca70674; [2020-07-14 05:09:30,69] [info] Retrieved 1 workflows from the WorkflowStoreActor; [2020-07-14 05:09:30,72] [info] WorkflowStoreHeartbeatWriteActor configured to flush with batch size 10000 and process rate 2 minutes.; [2020-07-14 05:09:30,83] [info] MaterializeWorkflowDescriptorActor [968be82c]: Parsing workflow as WDL 1.0; [2020-07-14 05:09:31,60] [info] MaterializeWorkflowDescriptorActor [968be82c]: Call-to-Backend assignments: ValidateBamsWf.ValidateBAM -> Local; [2020-07-14 05:09:31,82] [warn] Local [968be82c]: Key/s [memory, disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.; [2020-07-14 05:09:35,38] [info] Not triggering log of token queue status. Effective log interval = None; [2020-07-14 05:09:37,15] [info] WorkflowExecutionActor-968be82c-eef3-4bdb-a1ab-3d4e2ca70674 [968be82c]: Starting ValidateBamsWf.ValidateBAM; [2020-07-14 05:09:37,39] [info] Assigned new job execution tokens to the following groups: 968be82c: 1; [2020-07-14 05:09:41,61] [warn] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: Unrecognized runtime attribute keys: disks, memory; [2020-07-14 05:09:41,71] [info] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: /gatk/gatk \; ValidateSamFile \; --INPUT /cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/inputs/-1942028726/test.bam \; --OUTPUT test.validation_.txt \; --MODE SUMMARY; [2020-07-14 05:09:41,76] [info] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: executing: # make sure there is no preexisting Docker CID file; rm -f /gatk/",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6710:4200,log,log,4200,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710,1,['log'],['log']
Testability,- Added `--min-num-bases-for-segment-funcotation` parameter to Funcotator.; This will allow for segments of length less than 150 bases to be; annotated if given at run time (defaults to 150 bases to preserve; previous behavior).; - Added miles of piping to support new parameter.; - Added test to ensure that the logic for this is adhered to in the; output renderer where the UserError was being thrown before; (GeneListOutputRenderer). Fixes #6575,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6577:289,test,test,289,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6577,2,"['log', 'test']","['logic', 'test']"
Testability,"- Added a ReadMe for the CNN workflow; - Added a input JSON for the Mutect2 workflow files located in gs:// buckets. The reason for this is to have any workflow listed in the Dockstore site have an accompanying JSON for users to test the workflow. Also, have a ReadMe with a description of the workflow.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6542:229,test,test,229,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6542,1,['test'],['test']
Testability,- Added code to populate `Match_Norm_Seq_Allele1` and 2.; - Added two samples to `regressionTestVariantSetHG38.vcf` file.; - Regenerated and validated expected outputs for large tests. Fixes #7408,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7422:178,test,tests,178,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7422,1,['test'],['tests']
Testability,"- Added the ability to have IUPAC bases in either the ref/alt alleles OR; in the reference when calculating the amino acid sequence. In this case, the code will no longer throw a user exception, but will log a warning and will produce `?` amino acids in the case that they cannot be decoded from the amino acid table. Currently this will happen any time an `N` or IUPAC base is in the region to be coded into amino acids.; - Added AminoAcid.UNDECODABLE as a placeholder for any unknown /; undecodable amino acid (such as in the case of an ambiguous IUPAC base). Fixes #6774",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6778:204,log,log,204,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6778,1,['log'],['log']
Testability,- Added the optional flag to run oncotator in the CNV WDL. This is not tested automatically in github.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3408:71,test,tested,71,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3408,1,['test'],['tested']
Testability,"- Adds size similarity criterion to SVConcordance and SVCluster tools. This is particularly useful for accurately matching smaller SVs that have a high degree of breakpoint uncertainty, in which case reciprocal overlap does not work well. PESR/mixed variant types must have size similarity, reciprocal overlap, and breakend window criteria met. Depth-only variants may have either size similarity + reciprocal overlap OR breakend window criteria met (or both).; - Rewrites some of the linkage logic to be simpler to read.; - Fixes a rare bug with `SortedMultiset` in `SVClusterEngine` that sometimes caused records with identical start positions to get lost.; - Removes null record attributes to avoid `.` INFO/FORMAT fields, which cause a parsing error with Integer types.; - Add check that the vcf header contigs are sorted in the same order.; - Retain FILTER and QUAL fields in output.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8257:493,log,logic,493,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8257,1,['log'],['logic']
Testability,"- Adds the “gatk” conda environment, with dependencies defined by the file scripts/gatkcondaenv.yml.; - Updates the docker image to include the activated conda environment.; - Adds a new entry to the travis test matrix for running tests that depend on Python and the conda environment.; - Adds a “python” test group. Any tests for tools or functionality that are dependent on Python should be put into this group. Tests in this group will be executed in a docker container on travis in the python build matrix entry only.; - The existing WDL tests are unchanged; so although they execute in the context of the docker container and conda environment, there are no tests (yet) that are actually dependent on the conda environment and run through cromwell.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3912:207,test,test,207,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3912,7,"['Test', 'test']","['Tests', 'test', 'tests']"
Testability,- ApplyBQSR adapted to fit into the Skeleton pipeline; - command-line version still works and passes tests (including cloud); - BaseRecalibrator's testPlottingWorkflow now passes,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/815:101,test,tests,101,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/815,2,['test'],"['testPlottingWorkflow', 'tests']"
Testability,- Attempts testing of docker,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2726:11,test,testing,11,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2726,1,['test'],['testing']
Testability,- CEUTrio.HiSeq.WGS.b37.ch20.4379150-4379157.bam is a very small input that triggers the bug.; - TestMath is a small demonstration of the underlying problem (order of operations changes the answer); - RecalDatum.java is updated to fix the problem; - BaseRecalibratorDataflowIntegrationTest runs the new code and confirms it's OK.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/878:97,Test,TestMath,97,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/878,1,['Test'],['TestMath']
Testability,"- Clarify tool documentation:; - Update `joint posteriors (JL)` to `joint posteriors (JP)`; - Remove statistical notes and provide link to GATK Article#11074 for background and math; - Consolidate Notes and Caveats sections; - Clarify at top the three different sources of priors and tool behavior regarding these; - Clarify for family priors the tool only considers trio groups; - Add Laura's comment that recent updates allow the tool to appropriately apply priors to indels; - Change logger.info to logger.warn for situation where trio pedigree file is incomplete; - Note that in this situation, in the absence of other refinement, the results are identical to the input",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5601:487,log,logger,487,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5601,2,['log'],['logger']
Testability,"- Complex (CPX) SV records no longer use `END2`/`CHR2` INFO fields and instead are defined by `CPX_INTERVALS` in addition to normal coordinates.; - Adds new class `SVCallRecord.ComplexEventInterval` for storing complex event intervals, which are associated with a particular SV type.; - SV clustering now takes into account CPX subtype and intervals, requiring intervals to match on type and interval similarity as defined by the clustering parameters (e.g. minimum reciprocal overlap).; - Improved reciprocal translocation (CTX) record handling. In particular, these records are now treated similarly to BNDs for clustering purposes.; - Added unit tests for new CPX cases.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8521:649,test,tests,649,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8521,1,['test'],['tests']
Testability,- Create a GATK4 Dockerfile; - Added a script to create the docker image for the GATK4 Dockerfile. This will create a staging directory if desired.; - Created a GATK Base Dockerfile that other GATK4 Dockerfiles can use in ``FROM``; - Added a script to create the GATK Base image; - Documentation; - Fixed unit tests that fail in the docker image.; - docker images based on OpenJDK 8. Closes #2457 ; Closes #2708 ; Closes #2700,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2709:310,test,tests,310,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2709,1,['test'],['tests']
Testability,"- Created FuncotationFactory as new base class for DataSourceFuncotationFactory; - Created ComputedFuncotationFactory class, inheriting from FuncotationFactory and acting as a base class for GCContentFuncotationFactory and ReferenceContextFuncotationFactory; - Extracted GC content calculation and reference context annotations from previous classes; - Created two new arguments for reference window size and gc content window size; - Created unit tests for GCContent- and ReferenceContextFuncotationFactories; - Regenerated validation files",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6033:448,test,tests,448,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6033,1,['test'],['tests']
Testability,"- DF_BaseRecalibrator tool, can be called from the command line. Same syntax as BaseRecalibrator.; - BaseRecalibrator's integration tests ported to this Dataflow version.; - Small changes to make types serializable.; - Note that this pull request is an intermediate step as it only works for local computations. (this depends on [PR#522](https://github.com/broadinstitute/hellbender/pull/522))",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/523:132,test,tests,132,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/523,1,['test'],['tests']
Testability,- Disable default read filter with arguments does not longer blows up but log a warning (fixes #2357); - Improved help message for read filter (fixes #2358 and #2398); - `--disableAllReadFilters` changed to `--disableToolDefaultReadFilters` and `isDisabledFilter()` honor this behavior (fixes #2361 and #2363); - Add test for exercise the path of logging a warning when disabling a not enabled filter (as proposed in #2377); - Disabling a non-existent read filter throws a `CommandLineException` (fixes #2397),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2401:74,log,log,74,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2401,3,"['log', 'test']","['log', 'logging', 'test']"
Testability,- Error that was missed in testing.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4045:27,test,testing,27,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4045,1,['test'],['testing']
Testability,- Extracted the order validation for GVCF files into a separate method and included; a check to reset the counter when a new contig is found. Contigs have to; occur in continuous blocks; validation for files in which contigs occur; alternatingly is not supported.; - Added a set of integration tests for GVCF files with two and three contigs. Fixes #6023,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6028:294,test,tests,294,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6028,1,['test'],['tests']
Testability,"- Fixed a NPE in the `problem` variant case, which is now resolved.; This was due to not filling out the dataSourceName field.; - Tested with b37 gnomAD matching against b37 variants with hg19 data; sources.; - Fixed some issues with the default problem variant annotations.; - Adding in per-data source cache settings.; - Fixing logger in DataSourceUtils. Fixes #5456",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5491:130,Test,Tested,130,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5491,2,"['Test', 'log']","['Tested', 'logger']"
Testability,"- Fixed automated test for that was being skipped. When re-enabled, it passed without code changes.; - Added automated test. Passed without any other code changes.; - Added documentation for blacklisting when running the PoN and case sample/pair workflows (as opposed to using the postprocessing combine_tracks.wdl).; - Added hard num het filter. This helps guard against oversegmentation skewing MAF estimates. For WGS, `10` is a reasonable value.; - Changed default maf threshold for calling balanced segments. The previous value was too sensitive.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5384:18,test,test,18,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5384,2,['test'],['test']
Testability,- Fixes #4880 ; - Adds test to catch this if it happens again. Offline I ran it against a large hg38 file and it succeeded.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4881:23,test,test,23,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4881,1,['test'],['test']
Testability,"- HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 02:55:32.063 INFO Funcotator - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 02:55:32.063 INFO Funcotator - Deflater: IntelDeflater; 02:55:32.063 INFO Funcotator - Inflater: IntelInflater; 02:55:32.063 INFO Funcotator - GCS max retries/reopens: 20; 02:55:32.063 INFO Funcotator - Using google-cloud-java patch 6d11bef1c81f885c26b2b56c8616b7a705171e4f from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 02:55:32.063 WARN Funcotator - . [1m[31m !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. Warning: Funcotator is a BETA tool and is not yet ready for use in production. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!![0m. 02:55:32.063 INFO Funcotator - Initializing engine; 02:55:32.318 INFO FeatureManager - Using codec VCFCodec to read file file:///export2/liuhw/wes_test/Mutect2_filter/K001137N_somatic_filtered.vcf.gz; 02:55:32.459 INFO Funcotator - Done initializing engine; log4j:WARN No appenders could be found for logger (org.broadinstitute.hellbender.tools.funcotator.dataSources.DataSourceUtils).; log4j:WARN Please initialize the log4j system properly.; log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.; 02:55:32.466 INFO Funcotator - Shutting down engine; [July 12, 2024 2:55:32 AM EDT] org.broadinstitute.hellbender.tools.funcotator.Funcotator done. Elapsed time: 0.01 minutes.; Runtime.totalMemory()=2148532224; ***********************************************************************. A USER ERROR has occurred: Bad input: ERROR in config file: file:///./software/gatk_Funcotator/funcotator_dataSources.v1.8.hg38.20230908s/gnomAD_exome/hg38/gnomAD_exome.config - src_file does not exist: /./software/gatk_Funcotator/funcotator_dataSources.v1.8.hg38.20230908s/gnomAD_exome/hg38/gs:/broad-public-datasets/funcotator/gnomAD_2.1_VCF_INFO_AF_Only/hg38/gnomad.exomes.r2.1.sites.liftoverToHg38.INFO_ANNOTATIONS_FIXED.vcf.gz. ****************",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8913:3104,log,logger,3104,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8913,1,['log'],['logger']
Testability,"- I sneaked in another change where I pass in a single file containing a list of input_vcfs instead of an array of input_vcfs. I made this because Terra couldn't save my inputs when I passed in 700 samples.; - Most of the logic was moved into `CreateTables`, including the determination for what files to load. It would have been cleaner to move all of the file loading logic into `LoadTable` but the current approach cuts down the on the number of `gsutil ls` calls made and more importantly, only spins up a shard if there are files to load.; - I pushed the logic into a separate workflow because I wanted to refactor it as two tasks and I couldn't find a way to get a Task to call another Task without wrapping it in a workflow.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7056:222,log,logic,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7056,3,['log'],['logic']
Testability,- M2 WDL has explicit optional parameter for a list of fields that should be excluded from the output.; - Both M2 WDL files are updated. Manually tested mutect2.wdl on local backend. Closes #5141,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5242:146,test,tested,146,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5242,1,['test'],['tested']
Testability,"- MAF is the output of Funcotator in M2 WDL. Closes #4935 ; - Updated mutect2.wdl manually tested locally and manually tested in FireCloud.; - Updated mutect2_nio.wdl manually tested in FireCloud.; - Updated automatic Cromwell WDL tests. Closes #4807 ; - Empty MAFs will be devoid of variants, not a file of 0 bytes. Closes #4937 ; - Fixed issue where multiple transcripts could be selected in edge cases, even when CANONICAL or BEST_EFFECT was selected. Closes #4952",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4941:91,test,tested,91,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4941,4,['test'],"['tested', 'tests']"
Testability,- Make test `public` so it can be run within IntelliJ.; - Make test clean up after itself.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8274:7,test,test,7,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8274,2,['test'],['test']
Testability,- Modified the files so that we can build libVectorLoglessPairHMM.so on Ubuntu/ppc64le platform; - Restored and modified the files for 128-bit vector that are on GATK3; - Added a new file to replace AVX with POWER8 vector instructions; - [Question] Is any unit test included in the repository to test the library?; - Confirmed that the library was built on Ubuntu 15.10/ppc64le. ```; ./gradlew installAll; :downloadGsaLibFile UP-TO-DATE; :extractIntelDeflater; :compileJava; :processResources; :classes; :compileVectorLoglessPairHMMSharedLibraryVectorLoglessPairHMMCpp; :linkVectorLoglessPairHMMSharedLibrary; :copySharedLib; :jar; :startScripts; :installDist; :sparkJar; :installSpark; :installAll. BUILD SUCCESSFUL; ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1748:261,test,test,261,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1748,2,['test'],['test']
Testability,- Move command line parser integration of read filters up to GATKTool (https://github.com/broadinstitute/gatk/issues/2175); - Added fromList method to ReadFilter and CountingReadFilter (https://github.com/broadinstitute/gatk/issues/2198); - Minor change/rationalization of naming and implementation of BQSR filter methods to match the rest of the framework; - Made a small change to the implementation of the base read filter class to improve clarity/testability; - Opportunistic removal of extraneous imports in unrelated classes,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2218:451,test,testability,451,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2218,1,['test'],['testability']
Testability,"- Moved tools to ""Metagenomics"" program group; - Updated tool docs; - Changed tool arguments to kebab-case; - Defined argument strings as static variables that are cross-referenced in integration tests",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3918:196,test,tests,196,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3918,1,['test'],['tests']
Testability,"- Now will detect variants on mitochondrial contigs and will use the; correct, alternate coding sequence to create protein change strings for; such variants.; - Added MT sequences to Gencode data source.; - Added tests for MT protein change strings.; - Now `FuncotatorUtils::getMitochondrialAminoAcidByCodon` has more; complete tests and handles special cases for known initiation site; differences by genus.; - Updated scripts to detect the directory in which the scripts are run.; - Added MT variants to integration tests.; - Added MT genes to gencode testing data source. Fixes #4863",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5361:213,test,tests,213,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5361,4,['test'],"['testing', 'tests']"
Testability,"- Refactored GencodeGtfCodec to enable parsing of ENSEMBL GTF files.; - Created AbstractGtfCodec and EnsemblGtfCodec.; - Updated Funcotator and Funcotation Factories to allow ENSEMBL-based; GTF files.; - Added an e. coli data sources folder, reference, VCF, and expected; data for testing.; - Added tests for ENSEMBL GTF files. Fixes #6180",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6477:281,test,testing,281,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6477,2,['test'],"['testing', 'tests']"
Testability,- Relaxes restrictions for allowed samples in SVConcordance: the tool can now accept eval/truth VCFs with arbitrary sample sets and will have genotype concordance metrics computed on the intersection of the sample sets. All available samples are still used for AF/AC annotations. Integration tests added for cases when the samples sets are overlapping but not equal.; - Small additional improvements for sites-only VCFs: concordance annotations will now be `.` instead of `NaN` for example. Integration test added for this case.; - Improved behavior for eval AF annotations: these will not be recalculated if they already exist.; - Improved behavior for truth AF annotations: these will now only be recalculated if they don't exist in the input truth VCF.; - Updated tool doc,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8211:292,test,tests,292,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8211,2,['test'],"['test', 'tests']"
Testability,- Remove some unused VCF header fields from ExtractFeatures; - Renamed VQSR Lite fields to their original naming (e.g. AS_VQS_SENS becomes CALIBRATION_SENSITIVITY). Passing integration test [here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Quickstart%20v3%20ggrant/job_history/67a00690-5b74-40fd-a0fb-5ab2b0407a4d) - uses updated truth. Example outputs can be found in [this](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Quickstart%20v3%20ggrant/job_history/22134bb6-e4b5-4252-b674-860a1168fb6c) Extract run.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8412:185,test,test,185,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8412,1,['test'],['test']
Testability,- Removed positive-negative training from TrainVariantAnnotationsModel along with associated integration and WDL tests.; - Added ability to run positive-unlabeled training by passing unlabeled annotations to a custom python backend (although no example backend or tests were added).; - Cleaned up some WDL arguments to allow distinct training and scoring python scripts.; - Removed the `useAlleleSpecificAnnotations` argument; we instead infer whether to run in allele-specific mode from the VCF header.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8131:113,test,tests,113,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8131,2,['test'],['tests']
Testability,"- The main change is the use of a reducible multi level collector; currently there is only one consumer which is InsertizeMetricsCollector.; - There is a long comment and diagram at the top of MetricsCollectorSpark that describes the roles and relationships of the various component classes that make up a collector. Its a good place to start to understand these changes.; - The Spark and walker versions of CollectInsertSizeMetrics now use the same MultiLevelCollectorReducible-derived implementation (InsertSizeCollector), and exactly the same tests and expected results.; - All of the CollectInsertSizeMetricsSpark code and corresponding unit tests from the previous implementation are removed in this PR.; - Fixes https://github.com/broadinstitute/gatk/issues/1512.; - Both CollectMultipleMetrics (Spark and walker) implementations include support and tests for external/custom collectors.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1959:546,test,tests,546,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1959,3,['test'],['tests']
Testability,- Tool creates histograms to reflect differences in the composition reference blocks in GVCF files; - Integration tests,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6802:114,test,tests,114,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6802,1,['test'],['tests']
Testability,- Unclear what is its purpose.; - added and modified tests.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3680:53,test,tests,53,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3680,1,['test'],['tests']
Testability,- Updated data sources to include variant sites for symbolic alleles.; - Fixed tests to be correct for new logic.; - Now has tests for symbollic alternate alleles and masked alleles. Fixes #5402,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5406:79,test,tests,79,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5406,3,"['log', 'test']","['logic', 'tests']"
Testability,- Use start position as end for purposes of sorting PE evidence; - Adds regression test to MultiFeatureWalker,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7835:83,test,test,83,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7835,1,['test'],['test']
Testability,"- User defined transcripts were being used as a filter rather than a priority order. The filtering step has been eliminated. Closes #4918 ; - Fixed previously unidentified issue where locus level ranking was being reversed. Updated tests. This was identified thanks to the thousands of tests in Funcotator (only one failed, but that was all it took).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4931:232,test,tests,232,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4931,2,['test'],['tests']
Testability,- Validating sequence dictionaries...; 14:24:34.550 INFO Funcotator - Processing user transcripts/defaults/overrides...; 14:24:34.551 INFO Funcotator - Initializing data sources...; 14:24:34.554 INFO DataSourceUtils - Initializing data sources from directory: funcotator_dataSources.v1.7.20200521g; 14:24:34.560 INFO DataSourceUtils - Data sources version: 1.7.2020521g; 14:24:34.560 INFO DataSourceUtils - Data sources source: ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/funcotator/funcotator_dataSources.v1.7.20200521g.tar.gz; 14:24:34.561 INFO DataSourceUtils - Data sources alternate source: gs://broad-public-datasets/funcotator/funcotator_dataSources.v1.7.20200521.tar.gz; 14:24:34.587 INFO DataSourceUtils - Resolved data source file path: file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/gencode.v34.annotation.REORDERED.gtf -> file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/funcotator_dataSources.v1.7.20200521g/gencode/hg38/gencode.v34.annotation.REORDERED.gtf; 14:24:34.591 INFO DataSourceUtils - Resolved data source file path: file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/gencode.v34.pc_transcripts.fa -> file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/funcotator_dataSources.v1.7.20200521g/gencode/hg38/gencode.v34.pc_transcripts.fa; 14:24:34.599 INFO DataSourceUtils - Resolved data source file path: file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/acmg59_test_cleaned.txt -> file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/funcotator_dataSources.v1.7.20200521g/acmg_rec/hg38/acmg59_te,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6926:4827,test,test,4827,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6926,1,['test'],['test']
Testability,- [ ] Sample-specific unexplained variance for all samples + quantile in the cohort; - [ ] HMM log likelihood + quantile in the cohort; - [ ] Bias factor loading quantiles in the cohort. This issues requires calculating and saving a number of summary statistics in the COHORT mode in conjunction with the coverage model parameters bundle.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4060:95,log,log,95,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4060,1,['log'],['log']
Testability,- [x] Mount the large files rather than copying into the docker image when running the tests.; - [x] Cleanup the build directory before publishing. We only need the jar.; - [ ] Remove native dependencies that are not required for the docker image.; - [ ] Uninstall gcc and clean the ubuntu image a bit.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2720:87,test,tests,87,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2720,1,['test'],['tests']
Testability,"- [x] Output bam instead of sam for assembly alignments; - [x] Instead of creating directory, new interpretation tool writes files (behavior consistent with current interpretation tool); - [x] Prefix with sample name for output files' names; - [x] Add `INSLEN` annotation when there's `INSSEQ`; - [x] Clarify the boundary between `AlignedContig` and `AssemblyContigWithFineTunedAlignments`; - [x] Increase test coverage for `AssemblyContigAlignmentsConfigPicker`. Up to date plans for more cleanups and improvements posted in #4111",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4562:406,test,test,406,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4562,1,['test'],['test']
Testability,"- `GvsImportGenomes.wdl` - renamed WDL, fixed issue with poorly returned bq load string; - `GvsCreateFilterSet.wdl` - renamed WDL, added SA support, fixed a lot of issues in ExtractFeatures tool surrounding permissions - BQ projectIDs are now being properly passed through, freq_table UDF defined in repo rather than in BQ; - `GvsPrepareCallset.wdl` (done in previous PR); - `GvsExtractCallset.wdl` - renamed WDL, added SA support; - SA testing README added. all 4 tested with SA in this Terra workspace: https://app.terra.bio/#workspaces/broad-dsp-spec-ops-fc/gvs_sa_testing; testing also without SA in this workspace: https://app.terra.bio/#workspaces/broad-dsp-spec-ops-fc/gvs_testing_no_sa",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7205:437,test,testing,437,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7205,3,['test'],"['tested', 'testing']"
Testability,- add missing null check for reads a whole block past EOF; - correct handling for seek just past EOF + read; - fix reuse of caching buffer when near EOF; - add tests that reproduce(d) the problems,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2387:160,test,tests,160,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2387,1,['test'],['tests']
Testability,- added GvsAssignIds to .dockstore.yaml; - added logic to GvsAssignIds to prevent bug from empty input; - updates to Quickstart README directions. Closes https://broadworkbench.atlassian.net/browse/VS-183,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7463:49,log,logic,49,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7463,1,['log'],['logic']
Testability,- also added it to the PGEN export WDL to analyze performance easier. test run of filter correction: https://app.terra.bio/#workspaces/gvs-dev/RSA%20-%20GVS%20Quickstart%20V2%20/job_history/f7de418a-05c7-4720-8dc9-a997b1cfd456; test run of PGEN extract: https://app.terra.bio/#workspaces/gvs-dev/RSA%20-%20GVS%20Quickstart%20V2%20/job_history/e2b2c875-4cfd-4cbe-879a-18fb91c1518e,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8954:70,test,test,70,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8954,2,['test'],['test']
Testability,"- error messages will now include all the missing arguments when applicable; - error messages should be more readable; old style:. ```; $ hellbender PrintReads; ***********************************************************************. A USER ERROR has occurred: Invalid command line: Argument output was missing: Argument 'output' is required. ***********************************************************************; ```. new style:. ```; $ hellbender PrintReads; ***********************************************************************. A USER ERROR has occurred:. Invalid command line:; required argument --input was not specified; required argument --output was not specified. Rerun with --help to see more information on available options. ***********************************************************************; ```; - fixed a bug in CommandLineParser; - collection arguments that had a mutual exclusion field would be reported as missing even if one of the mutex arguments was present; - adding tests for this case; - some refactoring on CommandLineParser. fixes #418. <!-- Reviewable:start -->. [<img src=""https://reviewable.io/review_button.png"" height=40 alt=""Review on Reviewable""/>](https://reviewable.io/reviews/broadinstitute/gatk/1144). <!-- Reviewable:end -->",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1144:999,test,tests,999,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1144,1,['test'],['tests']
Testability,- expanding unit tests to actually replicate the error if we have a regression.; - applied fix that sorts the output.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3795:17,test,tests,17,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3795,1,['test'],['tests']
Testability,- fixup for problem with fully specified `file:///` names that I introduced in #1450 ; - adding test for fully specified `file:///` url; - adding additional tests to `ReadSparkSink` for HDFS; - tests for writing to HDFS using `MiniDFSCluster`; - tests for overwriting existing HDFS paths; - fixed instance of Wrong FileSystem exception in `ReadSparkSink`; - refactored `ReadSparkSink` to remove duplication; - adding `MiniClusterUtils`; - revising existing code using `MiniDFSCluster` to go through `MiniClusterUtils`; - had to make the minicluster dependency a compile time instead of test dependency so downstream projects can make use of MiniClusterUtils.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1461:96,test,test,96,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1461,5,['test'],"['test', 'tests']"
Testability,"- improved baits count annotator (""lazy"" post processing); - included bait counts as a multiplicative bias in TargetCoverageSexGenotypeCalculator; - improved info and warn log messages in TargetCoverageSexGenotyper; - interval exclusion via CLI args for TargetCoverageSexGenotyper; - soft target filtering using masks; - more extensive unit/integration tests for TargetCoverageSexGenotyper; - integration test for annotate targets w/ bait counts; - missing test resource files from gatk-protected repo; - address PR review",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3183:172,log,log,172,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3183,4,"['log', 'test']","['log', 'test', 'tests']"
Testability,"- new ""lazy"" annotation mode in TargetAnnotator (a hack for generating annotations that can not be done with a state-less FeatureWalker); - baits count target annotation; - included bait count as a multiplicative bias in TargetCoverageSexGenotypeCalculator; - improved info and warn log messages in TargetCoverageSexGenotyper; - interval exclusion via CLI args for TargetCoverageSexGenotyper (PAR regions can not be blacklisted via CLI arguments); - soft target filtering using masks; - more extensive unit/integration tests for TargetCoverageSexGenotyper; - integration test for annotate targets w/ bait counts",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2813:283,log,log,283,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2813,3,"['log', 'test']","['log', 'test', 'tests']"
Testability,"- new version of BaseRecalibratorDataflow that fits into the skeleton framework; - new command-line BaseRecalibratorDataflow that uses the same code; - tests and test inputs for BaseRecalibrator. They pass, locally and on the cloud.; - fix for issue #791 via a new genomics-dataflow-java release; - smaller changes, like == -> .equals in SequenceDictionaryUtils and using getInstance() to follow the singleton pattern.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/812:152,test,tests,152,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/812,2,['test'],"['test', 'tests']"
Testability,- restore job stats collection to create_ranges_cohort_extract_data_table.py; - add writing of cost info to BigQuery table to create_ranges_cohort_extract_data_table.py and populate_alt_allele_table.py; - add task to GvsQuickstartIntegration.wdl that checks that expected cost data was written to BigQuery table; - tweaked schema for cost_observability table to include descriptions; ; Integration test run: https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/30a2d8ee-13dd-4829-b3a8-4e6a67409705; Closes https://broadworkbench.atlassian.net/browse/VS-480,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7915:398,test,test,398,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7915,1,['test'],['test']
Testability,"- reviewed and restricted the access modifiers of all ICG-related classes; - got rid of the functionality to hold on to old caches: whenever a cache goes out of date, the reference is immediately made null in the new ICG; - completely rewrote ComputableGraphStructure in a functional style; - got rid of unused and unnecessary methods; - Created an ImmutableComputableGraphUtils and factored out the builder and other common methods; - math equality asserts for NDArray; - unit tests for ComputableGraphStructure; - unit tests for ImmutableComputableGraph; - unit tests for ImmutableComputableGraphUtils; - CacheNode keys and tags have their own classes now for code clarity",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3034:450,assert,asserts,450,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3034,4,"['assert', 'test']","['asserts', 'tests']"
Testability,"- reviewed and restricted the access modifiers of all ICG-related classes; - got rid of the functionality to hold on to old caches: whenever a cache goes out of date, the reference is immediately made null in the new ICG; - completely rewrote ComputableGraphStructure in a functional style; - got rid of unused and unnecessary methods; - Created an ImmutableComputableGraphUtils and factored out the builder and other common methods; - math equality asserts for NDArray; - unit tests for ComputableGraphStructure; - unit tests for ImmutableComputableGraph; - unit tests for ImmutableComputableGraphUtils; - keys and tags have their own classes now",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3035:450,assert,asserts,450,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3035,4,"['assert', 'test']","['asserts', 'tests']"
Testability,- separates sample Avro output from other non-partitioned (filter tables) so that they can be in groups of 4000 samples each. Test run here: https://app.terra.bio/#workspaces/gvs-dev/RSA%20-%20GVS%20Quickstart%20V2%20/job_history/30321bb4-614b-4678-a124-12385deee37a,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8673:126,Test,Test,126,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8673,1,['Test'],['Test']
Testability,"- updated integration test (removed that argument so it defaults to the same thing); - tested that using ""NONE"" as an argument works",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7206:22,test,test,22,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7206,2,['test'],"['test', 'tested']"
Testability,"----------- ; ; 11:03:49.970 INFO FilterMutectCalls - HTSJDK Version: 2.24.0 ; ; 11:03:49.970 INFO FilterMutectCalls - Picard Version: 2.25.0 ; ; 11:03:49.970 INFO FilterMutectCalls - Built for Spark Version: 2.4.5 ; ; 11:03:49.970 INFO FilterMutectCalls - HTSJDK Defaults.COMPRESSION\_LEVEL : 2 ; ; 11:03:49.970 INFO FilterMutectCalls - HTSJDK Defaults.USE\_ASYNC\_IO\_READ\_FOR\_SAMTOOLS : false ; ; 11:03:49.970 INFO FilterMutectCalls - HTSJDK Defaults.USE\_ASYNC\_IO\_WRITE\_FOR\_SAMTOOLS : true ; ; 11:03:49.970 INFO FilterMutectCalls - HTSJDK Defaults.USE\_ASYNC\_IO\_WRITE\_FOR\_TRIBBLE : false ; ; 11:03:49.970 INFO FilterMutectCalls - Deflater: IntelDeflater ; ; 11:03:49.971 INFO FilterMutectCalls - Inflater: IntelInflater ; ; 11:03:49.971 INFO FilterMutectCalls - GCS max retries/reopens: 20 ; ; 11:03:49.971 INFO FilterMutectCalls - Requester pays: disabled ; ; 11:03:49.971 INFO FilterMutectCalls - Initializing engine ; ; 11:03:50.504 INFO FeatureManager - Using codec VCFCodec to read file file:///home/lqh/somatic\_mutation/Mutect2/test.vcf.gz ; ; 11:03:50.696 INFO FilterMutectCalls - Done initializing engine ; ; 11:03:50.840 INFO ProgressMeter - Starting traversal ; ; 11:03:50.840 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute ; ; 11:03:50.841 INFO FilterMutectCalls - Starting pass 0 through the variants ; ; 11:03:51.014 INFO FilterMutectCalls - Shutting down engine ; ; \[June 4, 2021 11:03:51 AM CST\] org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls done. Elapsed time: 0.19 minutes. ; ; Runtime.totalMemory()=625999872 ; ; java.lang.NumberFormatException: **For input string: ""167|35|14""** ; ; at java.lang.NumberFormatException.forInputString(NumberFormatException.java:65) ; ; at java.lang.Integer.parseInt(Integer.java:580) ; ; at java.lang.Integer.valueOf(Integer.java:766) ; ; at htsjdk.variant.variantcontext.CommonInfo.lambda$getAttributeAsIntList$1(CommonInfo.java:288) ; ; at java.util.stream.R",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7298:5223,test,test,5223,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7298,1,['test'],['test']
Testability,------------------------------------------------------ ; ; 23:01:23.928 INFO  SelectVariants - HTSJDK Version: 2.23.0 ; ; 23:01:23.929 INFO  SelectVariants - Picard Version: 2.23.3 ; ; 23:01:23.929 INFO  SelectVariants - HTSJDK Defaults.COMPRESSION\_LEVEL : 2 ; ; 23:01:23.929 INFO  SelectVariants - HTSJDK Defaults.USE\_ASYNC\_IO\_READ\_FOR\_SAMTOOLS : false ; ; 23:01:23.929 INFO  SelectVariants - HTSJDK Defaults.USE\_ASYNC\_IO\_WRITE\_FOR\_SAMTOOLS : true ; ; 23:01:23.929 INFO  SelectVariants - HTSJDK Defaults.USE\_ASYNC\_IO\_WRITE\_FOR\_TRIBBLE : false ; ; 23:01:23.930 INFO  SelectVariants - Deflater: IntelDeflater ; ; 23:01:23.930 INFO  SelectVariants - Inflater: IntelInflater ; ; 23:01:23.930 INFO  SelectVariants - GCS max retries/reopens: 20 ; ; 23:01:23.930 INFO  SelectVariants - Requester pays: disabled ; ; 23:01:23.930 INFO  SelectVariants - Initializing engine ; ; 23:01:25.939 INFO  GenomicsDBLibLoader - GenomicsDB native library version : 1.3.2-e18fa63 ; ; log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.lib.MutableMetricsFactory). ; ; log4j:WARN Please initialize the log4j system properly. ; ; log4j:WARN See [http://logging.apache.org/log4j/1.2/faq.html#noconfig](http://logging.apache.org/log4j/1.2/faq.html#noconfig) for more info. ; ; 23:01:39.847 info  NativeGenomicsDB - pid=4376 tid=4377 No valid combination operation found for INFO field AS\_InbreedingCoeff  - the field will NOT be part of INFO fields in the g ; ; enerated VCF records ; ; 23:01:39.847 info  NativeGenomicsDB - pid=4376 tid=4377 No valid combination operation found for INFO field AS\_QD  - the field will NOT be part of INFO fields in the generated VCF ; ; records ; ; 23:01:39.848 info  NativeGenomicsDB - pid=4376 tid=4377 No valid combination operation found for INFO field DS  - the field will NOT be part of INFO fields in the generated VCF rec ; ; ords ; ; 23:01:39.848 info  NativeGenomicsDB - pid=4376 tid=4377 No valid combination operation found for INFO fi,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7070:3562,log,logger,3562,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7070,1,['log'],['logger']
Testability,---------------------------------------------; 04:37:29.322 INFO GenomicsDBImport - ------------------------------------------------------------; 04:37:29.322 INFO GenomicsDBImport - HTSJDK Version: 2.16.1; 04:37:29.323 INFO GenomicsDBImport - Picard Version: 2.18.13; 04:37:29.323 INFO GenomicsDBImport - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 04:37:29.323 INFO GenomicsDBImport - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 04:37:29.324 INFO GenomicsDBImport - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 04:37:29.324 INFO GenomicsDBImport - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 04:37:29.324 INFO GenomicsDBImport - Deflater: IntelDeflater; 04:37:29.324 INFO GenomicsDBImport - Inflater: IntelInflater; 04:37:29.325 INFO GenomicsDBImport - GCS max retries/reopens: 20; 04:37:29.325 INFO GenomicsDBImport - Requester pays: disabled; 04:37:29.325 INFO GenomicsDBImport - Initializing engine; 04:37:29.993 INFO FeatureManager - Using codec BEDCodec to read file file:///cromwell_root/gatk-test-data/intervals/Broad.human.exome.scattered/Broad.human.exome.b37_1_nozero.bed; 04:37:30.330 INFO IntervalArgumentCollection - Processing 18455956 bp from intervals; 04:37:30.340 WARN GenomicsDBImport - A large number of intervals were specified. Using more than 100 intervals in a single import is not recommended and can cause performance to suffer. It is recommended that intervals be aggregated together.; 04:37:30.380 INFO GenomicsDBImport - Done initializing engine; Created workspace /cromwell_root/genomicsdb; 04:37:30.677 INFO GenomicsDBImport - Vid Map JSON file will be written to genomicsdb/vidmap.json; 04:37:30.677 INFO GenomicsDBImport - Callset Map JSON file will be written to genomicsdb/callset.json; 04:37:30.677 INFO GenomicsDBImport - Complete VCF Header will be written to genomicsdb/vcfheader.vcf; 04:37:30.678 INFO GenomicsDBImport - Importing to array - genomicsdb/genomicsdb_array; 04:37:30.680 INFO ProgressMeter - Starting traversal; 04:3,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5300:2446,test,test-data,2446,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5300,1,['test'],['test-data']
Testability,-------------------------------------; 23:45:26.825 INFO GenomicsDBImport - HTSJDK Version: 3.0.5; 23:45:26.825 INFO GenomicsDBImport - Picard Version: 3.0.0; 23:45:26.825 INFO GenomicsDBImport - Built for Spark Version: 3.3.1; 23:45:26.826 INFO GenomicsDBImport - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 23:45:26.826 INFO GenomicsDBImport - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 23:45:26.826 INFO GenomicsDBImport - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 23:45:26.826 INFO GenomicsDBImport - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 23:45:26.826 INFO GenomicsDBImport - Deflater: IntelDeflater; 23:45:26.827 INFO GenomicsDBImport - Inflater: IntelInflater; 23:45:26.827 INFO GenomicsDBImport - GCS max retries/reopens: 20; 23:45:26.827 INFO GenomicsDBImport - Requester pays: disabled; 23:45:26.827 INFO GenomicsDBImport - Initializing engine; 23:45:46.550 INFO FeatureManager - Using codec IntervalListCodec to read file file:///gpfs/gpfs_de6000/home/dalegre/projects/1000-Genomes/jointcalling-test/goast_workflows/JointCalling/test_samples-1000.1.4/results/germline/interval/temp_0882_of_2000/scattered.interval_list; 23:45:46.584 INFO IntervalArgumentCollection - Processing 1086188 bp from intervals; 23:45:46.586 INFO GenomicsDBImport - Done initializing engine; 23:45:47.489 INFO GenomicsDBLibLoader - GenomicsDB native library version : 1.4.4-ce4e1b9; 23:45:47.491 INFO GenomicsDBImport - Vid Map JSON file will be written to /gpfs/gpfs_de6000/home/dalegre/projects/1000-Genomes/jointcalling-test/goast_workflows/JointCalling/test_samples-1000.1.4/results/jointcalling/genomicsDB/temp_0882_of_2000_DB/vidmap.json; 23:45:47.491 INFO GenomicsDBImport - Callset Map JSON file will be written to /gpfs/gpfs_de6000/home/dalegre/projects/1000-Genomes/jointcalling-test/goast_workflows/JointCalling/test_samples-1000.1.4/results/jointcalling/genomicsDB/temp_0882_of_2000_DB/callset.json; 23:45:47.491 INFO GenomicsDBImport - Complete VCF Header will ,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8683:4211,test,test,4211,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8683,1,['test'],['test']
Testability,"------------------------------------; 04:59:43.046 INFO ApplyBQSR - HTSJDK Version: 2.23.0; 04:59:43.046 INFO ApplyBQSR - Picard Version: 2.23.3; 04:59:43.046 INFO ApplyBQSR - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 04:59:43.046 INFO ApplyBQSR - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 04:59:43.046 INFO ApplyBQSR - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 04:59:43.046 INFO ApplyBQSR - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 04:59:43.046 INFO ApplyBQSR - Deflater: IntelDeflater; 04:59:43.046 INFO ApplyBQSR - Inflater: IntelInflater; 04:59:43.046 INFO ApplyBQSR - GCS max retries/reopens: 20; 04:59:43.046 INFO ApplyBQSR - Requester pays: disabled; 04:59:43.047 INFO ApplyBQSR - Initializing engine; WARNING: BAM index file /scratch/ddo/markedsam/C18-436P.sort.rmdup.bam.bai is older than BAM /scratch/ddo/markedsam/C18-436P.sort.rmdup.bam; 04:59:43.556 INFO ApplyBQSR - Done initializing engine; 04:59:43.592 WARN ApplyBQSR - This tool has only been well tested on ILLUMINA-based sequencing data. For other data use at your own risk.; 04:59:43.592 INFO ProgressMeter - Starting traversal; 04:59:43.592 INFO ProgressMeter - Current Locus Elapsed Minutes Reads Processed Reads/Minute; 04:59:45.014 INFO ApplyBQSR - Shutting down engine; [November 8, 2021 at 4:59:45 a.m. PST] org.broadinstitute.hellbender.tools.walkers.bqsr.ApplyBQSR done. Elapsed time: 0.05 minutes.; Runtime.totalMemory()=557842432; java.lang.IllegalStateException: **The covariates table is missing ReadGroup V300019285_L2_ in RecalTable0**; 	at org.broadinstitute.hellbender.utils.Utils.validate(Utils.java:750); 	at org.broadinstitute.hellbender.utils.recalibration.covariates.ReadGroupCovariate.keyForReadGroup(ReadGroupCovariate.java:81); 	at org.broadinstitute.hellbender.utils.recalibration.covariates.ReadGroupCovariate.recordValues(ReadGroupCovariate.java:53); 	at org.broadinstitute.hellbender.utils.recalibration.covariates.StandardCovariateList.recordAllValuesInStorage(S",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7549:2917,test,tested,2917,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7549,1,['test'],['tested']
Testability,-----------------; 20:08:45.222 INFO DenoiseReadCounts - HTSJDK Version: 2.14.1; 20:08:45.223 INFO DenoiseReadCounts - Picard Version: 2.17.2; 20:08:45.223 INFO DenoiseReadCounts - HTSJDK Defaults.COMPRESSION_LEVEL : 1; 20:08:45.223 INFO DenoiseReadCounts - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 20:08:45.223 INFO DenoiseReadCounts - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 20:08:45.223 INFO DenoiseReadCounts - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 20:08:45.223 INFO DenoiseReadCounts - Deflater: IntelDeflater; 20:08:45.223 INFO DenoiseReadCounts - Inflater: IntelInflater; 20:08:45.223 INFO DenoiseReadCounts - GCS max retries/reopens: 20; 20:08:45.223 INFO DenoiseReadCounts - Using google-cloud-java patch 6d11bef1c81f885c26b2b56c8616b7a705171e4f from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 20:08:45.223 INFO DenoiseReadCounts - Initializing engine; 20:08:45.223 INFO DenoiseReadCounts - Done initializing engine; log4j:WARN No appenders could be found for logger (org.broadinstitute.hdf5.HDF5Library).; log4j:WARN Please initialize the log4j system properly.; log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.; 20:08:45.300 INFO DenoiseReadCounts - Reading read-counts file (BT1813.counts.hdf5)...; HDF5-DIAG: Error detected in HDF5 (1.8.14) thread 0:; #000: /mnt/scr1/abyrne/HDFJava-platypus-2.11/native/HDF5-prefix/src/HDF5/src/H5F.c line 604 in H5Fopen(): unable to open file; major: File accessibilty; minor: Unable to open file; #001: /mnt/scr1/abyrne/HDFJava-platypus-2.11/native/HDF5-prefix/src/HDF5/src/H5Fint.c line 1085 in H5F_open(): unable to read superblock; major: File accessibilty; minor: Read failed; #002: /mnt/scr1/abyrne/HDFJava-platypus-2.11/native/HDF5-prefix/src/HDF5/src/H5Fsuper.c line 277 in H5F_super_read(): file signature not found; major: File accessibilty; minor: Not an HDF5 file; 20:08:49.800 INFO DenoiseReadCounts - Shutting down engine; [May 1,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7258:3634,log,logger,3634,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7258,1,['log'],['logger']
Testability,"----. ## Bug Report. ### Affected tool(s) or class(es); - Tool/class name(s), special parameters: GenomicsDBImport. ### Affected version(s); - Version: gatk4-4.4.0.0-0. ### Description ; Hello,. I have been having an issue come up when utilizing `GenomicsDBImport`. This issue has happened when using a range of samples and shard counts (8 - 1000 samples, shard count of up to 2000). My current example is an attempt to joint call 1000 samples together. I will submit the jobs and 1-2 of the shards (of the ~100 concurrently running) will throw a `malloc(): unaligned tcache chunk detected`. When I resubmit that shard, it will usually rerun without a problem. Or if I kill all jobs and resubmit, a different shard will throw the malloc error. . I have run approximately 20 tests and I seem to get this failure 2/3 times. However, it only arises on the initial submission and not when additional jobs are submitted as previous shards complete. Please note that the 1000 samples have successfully been imported into the GenomicsDB but this error seems to persist somewhat randomly across multiple machines. . Thank you for your assistance! . #### Steps to reproduce. - Command used (omitting paths to 1000 samples for brevity) for one of the failed shards. ```; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx8g -jar /gpfs/gpfs_de6000/home/dalegre/miniconda3/envs/GOASTv4.0/share/gatk4-4.4.0.0-0/gatk-package-4.4.0.0-local.jar GenomicsDBImport -V [samples 1-1002] --genomicsdb-workspace-path results/jointcalling/genomicsDB/temp_0882_of_2000_DB --merge-input-intervals false --bypass-feature-reader --tmp-dir temp --max-num-intervals-to-import-in-parallel 10 --batch-size 50 --intervals results/germline/interval/temp_0882_of_2000/scattered.interval_list --genomicsdb-shared-posixfs-optimizations true; ```. #### Expected behavior; All shards are imported into the GenomicsDB successfu",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8683:774,test,tests,774,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8683,1,['test'],['tests']
Testability,----. ## Bug Report. ### Affected tool(s) or class(es); GenomicsDBImport. ### Affected version(s); - [X] Latest public release version [4.1.9.0]; - [ ] Latest master branch as of [date of test?]. ### Description ; [TileDB::FileSystem] Error: (write_to_file) Cannot write to file; File opening error; path=/storage/home/data/gendb/chr13/.__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/RAW_MQandDP.tdb; errno=122(Disk quota exceede; d); [TileDB::WriteState] Error: Cannot write segment to file.; [TileDB::FileSystem] Error: (write_to_file) Cannot write to file; File opening error; path=/storage/home/data/gendb/chr13/chr13$32310639$32310731/.__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/__book_keeping.tdb.gz; errno=122(Disk quota e; xceeded); [TileDB::utils] Error: (write_to_file_after_compression) Could not write compressed bytes to internal buffer; path=/storage/home/data/gendb/chr13/chr13$32310639$32310731/.__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/__book_keeping.tdb.gz; ; errno=122(Disk quota exceeded); [TileDB::BookKeeping] Error: Cannot finalize book-keeping; Failure to write to file /storage/home/data/gendb/chr13/chr13$32310639$32310731/.__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/__book_keeping.tdb.gz.; [TileDB::FileSystem] Error: (create_file) Failed to create file; path=/storage/home/data/gendb/chr13/chr13$32310639$32310731/__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/__tiledb_fragment.tdb; errno=122(Disk quota exceeded); [TileDB::utils] Error: (create_fragment_file) Failed to create fragment file; path=/storage/home/data/gendb/chr13/chr13$32310639$32310731/__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087; errno=122(Disk quota exceeded); 11:23:52.390 erro NativeGenomicsDB - pid=57964 tid=57984 VariantStorageManagerException exception : Error while finalizing TileDB array chr13$32310639$32310731; TileDB error message : [TileDB::WriteState] ,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6950:188,test,test,188,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6950,1,['test'],['test']
Testability,"----. ## Bug Report; Hi GATK team,. I've just been running some variant calling benchmarks on a set of bacterial isolates and I was trying to understand how GATK HaplotypeCaller chooses which reads to use in its analyses. From what I could tell within the code, HaplotypeCaller sets these default read filters:. *line ~336 `HaplotypeCallerEngine.java`*; ```; public static List<ReadFilter> makeStandardHCReadFilters() {; List<ReadFilter> filters = new ArrayList<>();; filters.add(new MappingQualityReadFilter(DEFAULT_READ_QUALITY_FILTER_THRESHOLD));; filters.add(ReadFilterLibrary.MAPPING_QUALITY_AVAILABLE);; filters.add(ReadFilterLibrary.MAPPED);; filters.add(ReadFilterLibrary.NOT_SECONDARY_ALIGNMENT);; filters.add(ReadFilterLibrary.NOT_DUPLICATE);; filters.add(ReadFilterLibrary.PASSES_VENDOR_QUALITY_CHECK);; filters.add(ReadFilterLibrary.NON_ZERO_REFERENCE_LENGTH_ALIGNMENT);; filters.add(ReadFilterLibrary.GOOD_CIGAR);; filters.add(new WellformedReadFilter());. return filters;; }; ```. And the `WellformedReadFilter` includes these filters:; ```; private void createFilter() {; final AlignmentAgreesWithHeaderReadFilter alignmentAgreesWithHeader = new AlignmentAgreesWithHeaderReadFilter(samHeader);. wellFormedFilter = ReadFilterLibrary.VALID_ALIGNMENT_START; .and(ReadFilterLibrary.VALID_ALIGNMENT_END); .and(alignmentAgreesWithHeader); .and(ReadFilterLibrary.HAS_READ_GROUP); .and(ReadFilterLibrary.HAS_MATCHING_BASES_AND_QUALS); .and(ReadFilterLibrary.READLENGTH_EQUALS_CIGARLENGTH); .and(ReadFilterLibrary.SEQ_IS_STORED); .and(ReadFilterLibrary.CIGAR_CONTAINS_NO_N_OPERATOR);; }; ```. These all seem sensible and consistent, but I was finding that when I would apply these filters to the output of other tools like samtools view, I'd get different number of reported reads compared to what seemed to be being discovered within HaplotypeCaller (via adding debug messages). For example, using this SRA sample: https://www.ncbi.nlm.nih.gov/sra/SRR12324251 and mapping the reads against thes",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7873:80,benchmark,benchmarks,80,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7873,1,['benchmark'],['benchmarks']
Testability,"----. ## Bug Report; Hi, I'm trying the CNV detection pipeline from GATK: https://gatk.broadinstitute.org/hc/en-us/categories/360002310591; However, when running the Determine Germline Contig Ploidy step, I stumble upon this error. Please guide me to solve this problem. ### Affected tool(s) or class(es); ```; gatk DetermineGermlineContigPloidy \; -L /home/nguyen/RB1/RB1.cohort.gc.filtered.interval_list \; --interval-merging-rule OVERLAPPING_ONLY \; -I ... (63 tsv files output from CollectReadCounts); ```. ### Affected version(s); - GATK 4.1.6.1; ### Description ; Full error log:; ```; Traceback (most recent call last):; File ""/tmp/cohort_determine_ploidy_and_depth.380621677219090732.py"", line 119, in <module>; ploidy_task.engage(); File ""/home/nguyen/anaconda3/envs/gatk/lib/python3.6/site-packages/gcnvkernel/tasks/inference_task_base.py"", line 339, in engage; converged_continuous = self._update_continuous_posteriors(); File ""/home/nguyen/anaconda3/envs/gatk/lib/python3.6/site-packages/gcnvkernel/tasks/inference_task_base.py"", line 395, in _update_continuous_posteriors; assert not np.isnan(loss), ""The optimization step for ELBO update returned a NaN""; AssertionError: The optimization step for ELBO update returned a NaN; 11:09:59.446 DEBUG ScriptExecutor - Result: 1; 11:09:59.447 INFO DetermineGermlineContigPloidy - Shutting down engine; [April 28, 2020 11:09:59 AM ICT] org.broadinstitute.hellbender.tools.copynumber.DetermineGermlineContigPloidy done. Elapsed time: 0.17 minutes.; Runtime.totalMemory()=623902720; org.broadinstitute.hellbender.utils.python.PythonScriptExecutorException: ; python exited with 1; Command Line: python /tmp/cohort_determine_ploidy_and_depth.380621677219090732.py --sample_coverage_metadata=/tmp/samples-by-coverage-per-contig8606344533091962323.tsv --output_calls_path=/home/nguyen/Exec/gatk-4.1.6.0/ploidy-calls --mapping_error_rate=1.000000e-02 --psi_s_scale=1.000000e-04 --mean_bias_sd=1.000000e-02 --psi_j_scale=1.000000e-03 --learning_rate=5.0",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6573:581,log,log,581,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6573,1,['log'],['log']
Testability,"----. ### Affected tool(s) or class(es); _Tool/class name(s), special parameters?_; CombineGVCFs. ### Affected version(s); - [ ] Latest public release version [version?] Yes; - [ ] Latest master branch as of [date of test?] singularity. ### Description ; _Describe the problem below. Provide **screenshots** , **stacktrace** , **logs** where appropriate._; I am trying to combine GVCFs for joint-calllings and I am using the latest singularity release of GATK. #### Steps to reproduce; _Tell us how to reproduce this issue. If possible, include command lines that reproduce the problem. (The support team may follow up to ask you to upload data to reproduce the issue.)_; I am trying to run GATK and CombineGVCF failed.; I am using the following code:; singularity exec /fs/scratch/PHS0338/appz/GVCF/gatk_latest.sif \; gatk CombineGVCFs -R /users/PHS0338/jpac1984/data/Autosome.fasta \; --variant PA113.vcf.gz --variant PA113corr.vcf.gz --variant PA112.vcf.gz --variant PA112corr.vcf.gz --variant IN33.vcf.gz\; --variant IN33corr.vcf.gz --variant AL82.vcf.gz \; -O test.vcf.gz; It has all the parameters as mentioned in the website: https://gatk.broadinstitute.org/hc/en-us/articles/360037593911-CombineGVCFs. #### Expected behavior; _Tell us what should happen_; According to the website (https://gatk.broadinstitute.org/hc/en-us/articles/360037593911-CombineGVCFs) about combineGVCF, it should have worked fine without any problems... I got the following error log:. 20:11:34.701 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/gatk/gatk-package-4.2.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Jun 13, 2021 8:11:35 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 20:11:35.527 INFO CombineGVCFs - ------------------------------------------------------------; 20:11:35.527 INFO CombineGVCFs - The Genome Analysis Toolkit (GATK) v4.2.0.0; 20:11:3",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7311:217,test,test,217,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7311,2,"['log', 'test']","['logs', 'test']"
Testability,"----; User Report; ----. We are also experiencing a problem wherein GATK 4.0.5.1 GenotypeGVCFs processes hang for many hours. . The last thing our processes logged was the same as reported here:; ```; 08:48:23.075 INFO GenotypeGVCFs - Shutting down engine; GENOMICSDB_TIMER,GenomicsDB iterator next() timer,Wall-clock time(s),0.044110324,Cpu time(s),0.026897973000000006; ```. This particular job ran for about 3m before outputting this line, then stayed running (but apparently doing nothing) for 8 hours before we killed it. . It is one of 1996 jobs that all did pretty much exactly the same thing in a similar time frame - in all cases these were the last two lines logged but GATK failed to terminate afterwards. At the same time, we did have about 8k jobs finish successfully and exit 0, so it appears that the rate at which this happens is (at least for our workload) is around 20%. Don't know yet whether or not this behaviour is deterministic. More on that later. . This Issue was generated from your [forums] ; [forums]: https://gatkforums.broadinstitute.org/gatk/discussion/comment/50019#Comment_50019",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4973:157,log,logged,157,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4973,2,['log'],['logged']
Testability,--adamax_beta2=9.990000e-01 --log_emission_samples_per_round=2000 --log_emission_sampling_rounds=100 --log_emission_sampling_median_rel_error=5.000000e-04 --max_advi_iter_first_epoch=1000 --max_advi_iter_subsequent_epochs=1000 --min_training_epochs=20 --max_training_epochs=100 --initial_temperature=2.000000e+00 --num_thermal_advi_iters=5000 --convergence_snr_averaging_window=5000 --convergence_snr_trigger_threshold=1.000000e-01 --convergence_snr_countdown_window=10 --max_calling_iters=1 --caller_update_convergence_threshold=1.000000e-03 --caller_internal_admixing_rate=7.500000e-01 --caller_external_admixing_rate=7.500000e-01 --disable_caller=false --disable_sampler=false --disable_annealing=false --interval_list=/tmp/intervals8430607484736018931.tsv --contig_ploidy_prior_table=/gpfs/gsfs7/users/gatk_users1/0-Project/1-gCNV-Lung/z-bak/z-2019-10-26-1-Test-gCNV/9-Ref_Interval/3-contig_ploidy_priors/22.contig_ploidy_priors.csv --output_model_path=/gpfs/gsfs7/users/gatk_users1/0-Project/1-gCNV-Lung/z-bak/z-2019-10-26-1-Test-gCNV/2-Output/1-Contig-Ploidy/22.Contig_Ploidy_Dir/ploidy-model; 	at org.broadinstitute.hellbender.utils.python.PythonExecutorBase.getScriptException(PythonExecutorBase.java:75); 	at org.broadinstitute.hellbender.utils.runtime.ScriptExecutor.executeCuratedArgs(ScriptExecutor.java:126); 	at org.broadinstitute.hellbender.utils.python.PythonScriptExecutor.executeArgs(PythonScriptExecutor.java:170); 	at org.broadinstitute.hellbender.utils.python.PythonScriptExecutor.executeScript(PythonScriptExecutor.java:151); 	at org.broadinstitute.hellbender.utils.python.PythonScriptExecutor.executeScript(PythonScriptExecutor.java:121); 	at org.broadinstitute.hellbender.tools.copynumber.DetermineGermlineContigPloidy.executeDeterminePloidyAndDepthPythonScript(DetermineGermlineContigPloidy.java:411); 	at org.broadinstitute.hellbender.tools.copynumber.DetermineGermlineContigPloidy.doWork(DetermineGermlineContigPloidy.java:288); 	at org.broadinstitute.hellbender.cmdline.Com,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6235:6556,Test,Test-gCNV,6556,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6235,1,['Test'],['Test-gCNV']
Testability,--assembly-complexity-reference-mode in AssemblyComplexity.java test missing,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7955:64,test,test,64,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7955,1,['test'],['test']
Testability,"--convergence_snr_countdown_window=10 --max_calling_iters=10 --caller_update_convergence_threshold=1.000000e-03 --caller_admixing_rate=7.500000e-01 --disable_caller=false --disable_sampler=false --disable_annealing=false; Stdout: 10:35:09.182 INFO cohort_denoising_calling - Loading 4 read counts file(s)...; 10:35:12.176 INFO gcnvkernel.io.io_metadata - Loading germline contig ploidy and global read depth metadata...; sample_names. Stderr: Traceback (most recent call last):; File ""/tmp/wujh/cohort_denoising_calling.7794651839449939395.py"", line 114, in <module>; n_st, sample_names, sample_metadata_collection); File ""/opt/NfsDir/BioDir/Anaconda3/lib/python3.6/site-packages/gcnvkernel/models/model_denoising_calling.py"", line 379, in __init__; sample_metadata_collection, sample_names, self.contig_list); File ""/opt/NfsDir/BioDir/Anaconda3/lib/python3.6/site-packages/gcnvkernel/models/model_denoising_calling.py"", line 586, in _get_baseline_copy_number_and_read_depth; ""Some samples do not have read depth metadata""; AssertionError: Some samples do not have read depth metadata. at org.broadinstitute.hellbender.utils.python.PythonExecutorBase.getScriptException(PythonExecutorBase.java:75); at org.broadinstitute.hellbender.utils.runtime.ScriptExecutor.executeCuratedArgs(ScriptExecutor.java:126); at org.broadinstitute.hellbender.utils.python.PythonScriptExecutor.executeArgs(PythonScriptExecutor.java:170); at org.broadinstitute.hellbender.utils.python.PythonScriptExecutor.executeScript(PythonScriptExecutor.java:151); at org.broadinstitute.hellbender.utils.python.PythonScriptExecutor.executeScript(PythonScriptExecutor.java:121); at org.broadinstitute.hellbender.tools.copynumber.GermlineCNVCaller.executeGermlineCNVCallerPythonScript(GermlineCNVCaller.java:416); at org.broadinstitute.hellbender.tools.copynumber.GermlineCNVCaller.doWork(GermlineCNVCaller.java:255); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:136); at org.broadinstitute.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4457:2721,Assert,AssertionError,2721,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4457,1,['Assert'],['AssertionError']
Testability,"-Add tests with an input cram and an output sam, bam, or cram with various intervals; provided to the -L argument, and check that we get the expected reads in the output; for each set of intervals. -Generalize CRAMReferenceIntegrationTest to CRAMSupportIntegrationTest, and centralize; cram test data in the engine package. Resolves #675",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/860:5,test,tests,5,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/860,2,['test'],"['test', 'tests']"
Testability,"-Added a ""large files"" directory to src/test/resoureces containing files managed; by ""git lfs"" rather than checked directly into the hellbender repository.; Updated setup instructions in README appropriately to reflect new requirement; for git lfs. -Added a bam with ~600,000 reads from chromosomes 20 and 21, as well as ~50000; unmapped reads. -Added a snippet of the b37 reference with all of chromosomes 20 and 21. -Added a DBSNP vcf containing variants overlapping the reads in the bam above.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/839:40,test,test,40,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/839,1,['test'],['test']
Testability,"-Adds start/end coordinate validation to `SVCallRecord`, checking contigs and positions against the sequence dictionary and their ordering.; -Adds some checks for invalid coordinates in places where `SimpleInterval.expandWithinContig()` can potentially return `null`.; -Addresses an issue where inter-chromosomal records' end positions were incorrectly disallowed from preceding the start position during record collapsing (despite being on a different contig).; -Deletes unused `SVCallRecordWithEvidence`. Includes regression tests.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7714:527,test,tests,527,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7714,1,['test'],['tests']
Testability,-Can now request arbitrary windows of reference bases for each read in AddContextDataToRead. -Wrote a reference window function for BQSR that retrieves for each read exactly the reference; bases required by the BQSR algorithm. -Comprehensive unit tests,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/789:247,test,tests,247,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/789,1,['test'],['tests']
Testability,-ERC BP_RESOLUTION mode in HaplotypeCaller needs an integration test,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6833:64,test,test,64,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6833,1,['test'],['test']
Testability,-Fixes broken input in somatic funcotator test; -Removes some unused resource variable defaults; -Adds `set -u` in some tasks,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6506:42,test,test,42,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6506,1,['test'],['test']
Testability,"-Ported the remaining pieces of the HaplotypeCaller and assembled them; into a runnable tool. Fixed many bugs in our ported code in the process; of doing so. -Extracted a separate ""engine"" that does all the work of the HC and is; separate from the runnable walker. -Added a new walker class, ReadWindowWalker, as a prospective replacement; for active region traversal. -Hooked up the native VECTOR_LOGLESS_CACHING PairHmm to the HaplotypeCaller,; and activated it by default (this speeds up performance by ~3x in my tests).; Also added a fallback mode when AVX is not present.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1567:516,test,tests,516,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1567,1,['test'],['tests']
Testability,"-Prints the current locus, the elapsed time, number of records processed,; and the rate at which records are being processed. -Hooked up for ReadWalkers, VariantWalkers, and IntervalWalkers. -A new command-line arg in GATKTool allows control over the frequency of; progress meter updates. -Tweaked the log4j output format to create more screen space for logger output. Resolves #974 (for alpha purposes)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1037:354,log,logger,354,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1037,1,['log'],['logger']
Testability,"-Published a jbwa snapshot to the Broad artifactory, which we now depend on; via gradle. This snapshot contains builds of the native jbwa code for both; Mac and Linux. -Added utility methods to NativeUtils to load this library at runtime,; and a test proving that it can be loaded successfully. Also switched; to the new NativeUtils methods for loading the PairHMM, and confirmed; that it loads successfully with the HaplotypeCaller in protected. -Included a gradle script to publish a new jbwa snapshot, should it; become necessary, along with instructions on how to do so. Resolves #1838",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1847:246,test,test,246,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1847,1,['test'],['test']
Testability,"-Reduce memory usage of AssemblyRegion traversal by an order of magnitude; by loading the reads for each shard more lazily. -Add a sharding mode that creates one shard per user interval (or per contig,; if there are no explicit intervals), and make it the default for both HaplotypeCaller; and Mutect2. -When determining active regions, only consider loci within the user's intervals (but; still include surrounding reads in the final region). This mimics GATK3.x behavior. -Serve up empty pileup objects for uncovered loci (this also mimics GATK3.x behavior).; The fact that we weren't doing this before was responsible for much of the remaining; difference vs. the GATK 3.x HaplotypeCaller. -Ported GATK 3 PR 1389 (use median rather than the second-best likelihood for the; NON_REF allele). -Ported a change to the ReferenceConfidenceModel from GATK3. -Fixed a bug in ReadLikelihoods that was causing ArrayIndexOutOfBoundsException. -Added special handling of RawMQ to HaplotypeCaller (mirrors the handling of RawMQ; from GenotypeGVCFs). -Added updated concordance test data generated with HaplotypeCaller 3.8-4-g7b0250253f. Resolves #1950; Resolves #3516; Resolves #3517; Resolves #3518; Resolves #3233; Resolves #2848",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3519:1067,test,test,1067,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3519,1,['test'],['test']
Testability,"-Require that the reference dictionary be a superset of the reads dictionary; only when there is at least one CRAM input. -When determining whether a superset relationship exists, do not take extended; attributes (like the sequence MD5) into account; only consider the contig names; and lengths. -Do not require common contigs to occur at the same absolute indices across; dictionaries (but do require that they occur in the same relative order).; Contig indices were an issue for GATK3, but since hellbender relies on contig; names for queries we can afford to disable this annoying check. If we later find; that we need to turn it back on, we can easily do so. -Updated tests appropriately:; -Added test cases showing that extended attributes are ignored when checking; for a superset. ```; -Added test cases for various combinations of the new boolean options; requireSuperset and checkContigIndices. -The existing integration test CRAMSupportIntegrationTest.testWrongRef(); shows that we throw when a CRAM is provided as input with a reference; that does not contain all of its contigs.; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/877:672,test,tests,672,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/877,5,['test'],"['test', 'testWrongRef', 'tests']"
Testability,"-b298-4324-8a8c-9f46f05708b5/call-GermlineCNVCallerCohortMode/shard-12910/inputs/1773956498/P0001010.b37.counts.hdf5 --contig-ploidy-calls contig-ploidy-calls-dir --interval-merging-rule OVERLAPPING_ONLY --output out --output-prefix csi_batch1-4_wes_gcnv_pon --verbosity DEBUG --p-alt 1e-6 --p-active 1e-2 --cnv-coherence-length 10000.0 --class-coherence-length 10000.0 --max-copy-number 5 --max-bias-factors 5 --mapping-error-rate 0.01 --interval-psi-scale 0.001 --sample-psi-scale 0.0001 --depth-correction-tau 10000.0 --log-mean-bias-standard-deviation 0.1 --init-ard-rel-unexplained-variance 0.1 --num-gc-bins 20 --gc-curve-standard-deviation 1.0 --copy-number-posterior-expectation-mode HYBRID --enable-bias-factors true --active-class-padding-hybrid-mode 50000 --learning-rate 0.05 --adamax-beta-1 0.9 --adamax-beta-2 0.99 --log-emission-samples-per-round 50 --log-emission-sampling-median-rel-error 0.005 --log-emission-sampling-rounds 10 --max-advi-iter-first-epoch 5000 --max-advi-iter-subsequent-epochs 100 --min-training-epochs 10 --max-training-epochs 100 --initial-temperature 2.0 --num-thermal-advi-iters 2500 --convergence-snr-averaging-window 500 --convergence-snr-trigger-threshold 0.1 --convergence-snr-countdown-window 10 --max-calling-iters 10 --caller-update-convergence-threshold 0.001 --caller-internal-admixing-rate 0.75 --caller-external-admixing-rate 1.00 --disable-annealing false. [2019-02-22 23:49:20,42] [info] WorkflowManagerActor WorkflowActor-098a389e-b298-4324-8a8c-9f46f05708b5 is in a terminal state: WorkflowFailedState; [2019-02-22 23:50:01,65] [info] SingleWorkflowRunnerActor workflow finished with status 'Failed'.; [2019-02-22 23:50:02,38] [info] Workflow polling stopped; [2019-02-22 23:50:02,48] [info] Shutting down WorkflowStoreActor - Timeout = 5 seconds; [2019-02-22 23:50:02,49] [info] Shutting down WorkflowLogCopyRouter - Timeout = 5 seconds; [2019-02-22 23:50:02,53] [info] Shutting down JobExecutionTokenDispenser - Timeout = 5 seconds; [2019-02-2",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5714:29847,log,log-emission-sampling-rounds,29847,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5714,1,['log'],['log-emission-sampling-rounds']
Testability,-biology/gatk-9999/work/gatk-9999/build.gradle:143); 22:05:55.985 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.groovy.scripts.internal.DefaultScriptRunnerFactory$ScriptRunnerImpl.run(DefaultScriptRunnerFactory.java:90); 22:05:55.986 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	... 58 more; 22:05:55.986 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] ; 22:05:55.986 [LIFECYCLE] [org.gradle.internal.buildevents.BuildResultLogger] ; 22:05:55.986 [LIFECYCLE] [org.gradle.internal.buildevents.BuildResultLogger] BUILD FAILED; 22:05:55.986 [LIFECYCLE] [org.gradle.internal.buildevents.BuildResultLogger] ; 22:05:55.987 [LIFECYCLE] [org.gradle.internal.buildevents.BuildResultLogger] Total time: 29.153 secs; ```. ```; root# su - portage; portage$ cd /scratch/var/tmp/portage/sci-biology/gatk-9999/work/gatk-9999/; portage$ git lfs pull --include src/main/resources/large; No default remote. Errors logged to /scratch/var/tmp/portage/sci-biology/gatk-9999/work/gatk-9999/.git/lfs/objects/logs/20180420T221032.955218097.log; Use `git lfs logs last` to view the log.; portage$ cat /scratch/var/tmp/portage/sci-biology/gatk-9999/work/gatk-9999/.git/lfs/objects/logs/20180420T221032.955218097.log; git-lfs/2.3.4 (GitHub; linux amd64; go 1.10); git version 2.16.3. $ git-lfs pull --include src/main/resources/large; No default remote. No remotes defined. Current time in UTC: ; 2018-04-20 20:10:32. ENV:; LocalWorkingDir=/scratch/var/tmp/portage/sci-biology/gatk-9999/work/gatk-9999; LocalGitDir=/scratch/var/tmp/portage/sci-biology/gatk-9999/work/gatk-9999/.git; LocalGitStorageDir=/scratch/var/tmp/portage/sci-biology/gatk-9999/work/gatk-9999/.git; LocalMediaDir=/scratch/var/tmp/portage/sci-biology/gatk-9999/work/gatk-9999/.git/lfs/objects; LocalReferenceDir=; TempDir=/scratch/var/tmp/portage/sci-biology/gatk-9999/work/gatk-9999/.git/lfs/tmp; ConcurrentTransfers=3; TusTransfers=false; BasicTransfersOnly=false; SkipDownloadErrors=,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4687:15038,log,logged,15038,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4687,1,['log'],['logged']
Testability,-bug-input.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/GenotypeGVCFs/CEUTrio.20.21.missingIndel.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/GenotypeGVCFs/chr21.bad.pl.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/GenotypeGVCFs/combined_genotype_gvcf_exception.nocall.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/GenotypeGVCFs/combined_genotype_gvcf_exception.original.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/GenotypeGVCFs/combine.single.sample.pipeline.1.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/GenotypeGVCFs/combine.single.sample.pipeline.2.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/GenotypeGVCFs/combine.single.sample.pipeline.3.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/GenotypeGVCFs/gvcf.basepairResolution.gvcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/GenotypeGVCFs/gvcfExample1.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/GenotypeGVCFs/leadingDeletion.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/GenotypeGVCFs/spanningDel.combined.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/GenotypeGVCFs/spanningDel.delOnly.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/GenotypeGVCFs/spanningDel.depr.delOnly.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/GenotypeGVCFs/testUpdatePGT.gvcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/MarkDuplicatesGATK/example.chr1.1-1K.markedDups.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/walkers/MarkDuplicatesGATK/example.chr1.1-1K.unmarkedDups.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/walkers/MarkDuplicatesGATK/example.chr1.1-1K.unmarkedDups.noDups.bam.bai; src/test/resources/org/broadinstitute/,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3905:57341,test,test,57341,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905,1,['test'],['test']
Testability,-counts-NA12878.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-no-intervals.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-sample-NA12878.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-test-targets.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-test-targets.tsv.idx; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-test-targets-wo-coords.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/germlinehmm/homo_sapiens_germline_HMM_priors.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/germlinehmm/TCGA_T_matrix_autosomal_bad.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/pon-input.tab; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/contig_annots_bad_autosomal_annot.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/contig_annots_bad_class.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/contig_annots_bad_missing_some_annots.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/ice_trunc_rcc.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/ice_trunc_sex_genotypes.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/ice_trunc_targets_some_missing.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/ice_trunc_targets.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/ice_trunc_targets_with_bait_counts.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/sex_genotyper_agilent_targets_trunc.tsv; src/test/resources/org/broadinstitute/hellbender/,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3905:33903,test,test,33903,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905,2,['test'],['test']
Testability,"-disable-optimizations \; --force-active -O out.vcf \; --reference /path/to/ucsc.hg19.fasta \; --minimum-mapping-quality <value>;; $ gatk --version; ...; The Genome Analysis Toolkit (GATK) v4.2.0.0; HTSJDK Version: 2.24.0; Picard Version: 2.25.0; ```. (I tried this `4.1.4.0`). `--minimum-mapping-quality 1`:; ```bash; chr7	145945238	.	A	G	7534.06	.	AC=2;AF=1.00;AN=2;DP=247;ExcessHet=3.0103;FS=0.000;MLEAC=2;MLEAF=1.00;MQ=58.06;QD=31.52;SOR=1.050	GT:AD:DP:GQ:PL	1/1:0,239:239:99:7548,716,0; ```. `--minimum-mapping-quality 20`:; ```bash; chr7	145945238	.	A	G	267.64	.	AC=1;AF=0.500;AN=2;BaseQRankSum=2.838;DP=14;ExcessHet=3.0103;FS=6.264;MLEAC=1;MLEAF=0.500;MQ=59.06;MQRankSum=0.000;QD=22.30;ReadPosRankSum=2.208;SOR=2.022	GT:AD:DP:GQ:PL	0/1:3,9:12:28:275,0,28; ```. `--minimum-mapping-quality 60`:; ```bash; chr7	145945238	.	A	G	7150.06	.	AC=2;AF=1.00;AN=2;DP=224;ExcessHet=3.0103;FS=0.000;MLEAC=2;MLEAF=1.00;MQ=60.00;QD=32.06;SOR=1.008	GT:AD:DP:GQ:PL	1/1:0,223:223:99:7164,668,0. ```. <details>; <summary>test.bam</summary>. ```; @HD	VN:1.6	SO:coordinate; @SQ	SN:chr1	LN:249250621; @SQ	SN:chr2	LN:243199373; @SQ	SN:chr3	LN:198022430; @SQ	SN:chr4	LN:191154276; @SQ	SN:chr5	LN:180915260; @SQ	SN:chr6	LN:171115067; @SQ	SN:chr7	LN:159138663; @SQ	SN:chr8	LN:146364022; @SQ	SN:chr9	LN:141213431; @SQ	SN:chr10	LN:135534747; @SQ	SN:chr11	LN:135006516; @SQ	SN:chr12	LN:133851895; @SQ	SN:chr13	LN:115169878; @SQ	SN:chr14	LN:107349540; @SQ	SN:chr15	LN:102531392; @SQ	SN:chr16	LN:90354753; @SQ	SN:chr17	LN:81195210; @SQ	SN:chr18	LN:78077248; @SQ	SN:chr19	LN:59128983; @SQ	SN:chr20	LN:63025520; @SQ	SN:chr21	LN:48129895; @SQ	SN:chr22	LN:51304566; @SQ	SN:chrX	LN:155270560; @SQ	SN:chrY	LN:59373566; @SQ	SN:chrM	LN:16571; @RG	ID:1	SM:Sample	LB:Sample	PU:na	PL:Illumina; @PG	PN:bwa	ID:bwa	CL:<redacted>; @PG	PN:MarkDuplicates	ID:MarkDuplicates	CL:<redacted>; q0	99	chr7	145945113	3	151M	=	145945249	287	AGAGATATAAGAGGTTGGGGCACGGAAATAAGGGATCGGGGCACAGAGATATAAGAGGCTGGGGCACGGAAATAAGGGATCGGGGCACAGAGATATAAGAGGCTGGGGCA",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7124:1681,test,test,1681,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7124,1,['test'],['test']
Testability,"-local.jar FastaAlternateReferenceMaker -R /g/data/xe2/references/eucalyptus/emel_scott/Emelliodora_CSIROg1_SISH00000000.1.fasta -O consensus_sequences_gatk//CCA0704.fasta.tmp -V pergene_gatk/CCA0704/CCA0704.vcf.gz; 15:43:14.276 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/g/data/xe2/users/stephen-rodgers/latest-gatk/gatk-4.1.4.1/gatk-package-4.1.4.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Feb 03, 2020 3:43:15 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 15:43:15.230 INFO FastaAlternateReferenceMaker - ------------------------------------------------------------; 15:43:15.230 INFO FastaAlternateReferenceMaker - The Genome Analysis Toolkit (GATK) v4.1.4.1; 15:43:15.230 INFO FastaAlternateReferenceMaker - For support and documentation go to https://software.broadinstitute.org/gatk/; 15:43:15.231 INFO FastaAlternateReferenceMaker - Executing as kdm801@gadi-login-01.gadi.nci.org.au on Linux v4.18.0-80.11.2.el8_0.x86_64 amd64; 15:43:15.240 INFO FastaAlternateReferenceMaker - Java runtime: OpenJDK 64-Bit Server VM v13+33; 15:43:15.240 INFO FastaAlternateReferenceMaker - Start Date/Time: 3 February 2020 at 3:43:14 pm AEDT; 15:43:15.240 INFO FastaAlternateReferenceMaker - ------------------------------------------------------------; 15:43:15.240 INFO FastaAlternateReferenceMaker - ------------------------------------------------------------; 15:43:15.241 INFO FastaAlternateReferenceMaker - HTSJDK Version: 2.21.0; 15:43:15.241 INFO FastaAlternateReferenceMaker - Picard Version: 2.21.2; 15:43:15.241 INFO FastaAlternateReferenceMaker - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 15:43:15.241 INFO FastaAlternateReferenceMaker - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 15:43:15.241 INFO FastaAlternateReferenceMaker - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 15:43:15.241 INFO FastaAlternateRefere",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6434:2296,log,login-,2296,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6434,1,['log'],['login-']
Testability,"-network none broadinstitute/gatk gatk -version. 2022-08-03 20:37:23,349 main ERROR Could not determine local host name java.net.UnknownHostException: de2c81c88ddc: de2c81c88ddc: Temporary failure in name resolution; at java.net.InetAddress.getLocalHost(InetAddress.java:1506); at org.apache.logging.log4j.core.util.NetUtils.getLocalHostname(NetUtils.java:54); at org.apache.logging.log4j.core.LoggerContext.lambda$setConfiguration$0(LoggerContext.java:620); at java.util.concurrent.ConcurrentHashMap.computeIfAbsent(ConcurrentHashMap.java:1660); at org.apache.logging.log4j.core.LoggerContext.setConfiguration(LoggerContext.java:620); at org.apache.logging.log4j.core.LoggerContext.reconfigure(LoggerContext.java:699); at org.apache.logging.log4j.core.LoggerContext.reconfigure(LoggerContext.java:716); at org.apache.logging.log4j.core.LoggerContext.start(LoggerContext.java:270); at org.apache.logging.log4j.core.impl.Log4jContextFactory.getContext(Log4jContextFactory.java:155); at org.apache.logging.log4j.core.impl.Log4jContextFactory.getContext(Log4jContextFactory.java:47); at org.apache.logging.log4j.LogManager.getContext(LogManager.java:196); at org.apache.logging.log4j.LogManager.getLogger(LogManager.java:599); at org.broadinstitute.hellbender.utils.Utils.<clinit>(Utils.java:72); at org.broadinstitute.hellbender.Main.<clinit>(Main.java:45); Caused by: java.net.UnknownHostException: de2c81c88ddc: Temporary failure in name resolution; at java.net.Inet4AddressImpl.lookupAllHostAddr(Native Method); at java.net.InetAddress$2.lookupAllHostAddr(InetAddress.java:929); at java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1324); at java.net.InetAddress.getLocalHost(InetAddress.java:1501); ...13 more. The Genome Analysis Toolkit (GATK) v4.2.6.1; HTSJDK Version: 2.24.1; Picard Version: 2.27.1; Using GATK jar /gatk/gatk-package-4.2.6.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_writ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7983:1189,log,logging,1189,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7983,1,['log'],['logging']
Testability,"-pays broad-dsde-methods; ; Child Process : java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx4g -Xms4g -jar /gatk/gatk-package-4.1.8.1-local.jar GenomicsDBImport --genomicsdb-workspace-path genomicsdb --batch-size 50 -L chrX:51630606-68003941 --sample-name-map inputs.list --reader-threads 5 -ip 500 --gcs-project-for-requester-pays broad-dsde-methods; ; The above command took approx. 3.5 hrs to run while writing to local mount of ec2 i.e. EBS volume.; The same command took 8+ hrs (still running as of this email) to run while writing to FSx for luster mount. And surprisingly through AWS Batch – EC2 as part of complete batch/pipeline, took 40+ hrs.; ; The files being read by this process are already cached into FSx as we have been using this same FSx for 5+ days now and these jobs already succeeded with 30-40 hrs of runtime.; ; While we were testing the below manual execution, nothing was running from batch or FSx perspective. Only the 2 manual jobs - one for writing it to local (EBS) and other for FSx. The FSx we are using is the scratch system type with 16.8 TB of space, which gives us a total throughput of 3.3 GB/s.; ; Below is the snapshot of batch 1 executions.; ; EBS Mount Run : Took a total of 1 hr in batch 1; ![EBS Mount Run Batch 1](https://user-images.githubusercontent.com/64221390/151032847-b0bfc418-c2c4-4d8f-a95a-ab0fc0b8eeee.png). FSX Mount Run : Took 2 hrs 11 mins in batch 1; ![FSX Run Batch 1](https://user-images.githubusercontent.com/64221390/151032872-2cae5890-ee5f-4122-b077-037ed4c38414.png). But when the “dd” command to test the write speeds for both the file systems, the FSx shows a much greater speed/performance.; ; Command : dd if=/dev/zero of=<Local/FSx>/test.img bs=1G count=5 oflag=dsync; ; Ran to write on local (ec2 EBS mount) :; ; root@6ece7fab91ec:/app# dd if=/dev/zero of=/app/test.img bs=1G count=5 oflag=dsync; 5+0 records in; 5",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7646:1485,test,testing,1485,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7646,1,['test'],['testing']
Testability,"-spark_7002d0551e84ddef0d74adf95dfee104.jar -- PrintVariantsSpark --V gs://hellbender/test/resources/large/gvcfs/gatk3.7_30_ga4f720357.24_sample.21.expected.vcf --output gs://hellbender-test-logs/test/staging/lb_staging/756f43e6-4663-49ce-8a8c-bf717b07a8c7.vcf --sparkMaster yarn; Job [dfac787d-19aa-4296-8078-c033cd9f440d] submitted.; Waiting for job output...; 19:43:09.678 WARN SparkContextFactory - Environment variables HELLBENDER_TEST_PROJECT and HELLBENDER_JSON_SERVICE_ACCOUNT_KEY must be set or the GCS hadoop connector will not be configured properly; 19:43:09.837 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/tmp/dfac787d-19aa-4296-8078-c033cd9f440d/gatk-package-4.beta.6-37-g0a135f8-SNAPSHOT-spark_7002d0551e84ddef0d74adf95dfee104.jar!/com/intel/gkl/native/libgkl_compression.so; [November 15, 2017 7:43:09 PM UTC] PrintVariantsSpark --output gs://hellbender-test-logs/test/staging/lb_staging/756f43e6-4663-49ce-8a8c-bf717b07a8c7.vcf --variant gs://hellbender/test/resources/large/gvcfs/gatk3.7_30_ga4f720357.24_sample.21.expected.vcf --sparkMaster yarn --variantShardSize 10000 --variantShardPadding 1000 --shuffle false --readValidationStringency SILENT --interval_set_rule UNION --interval_padding 0 --interval_exclusion_padding 0 --interval_merging_rule ALL --bamPartitionSize 0 --disableSequenceDictionaryValidation false --shardedOutput false --numReducers 0 --help false --version false --showHidden false --verbosity INFO --QUIET false --use_jdk_deflater false --use_jdk_inflater false --gcs_max_retries 20 --disableToolDefaultReadFilters false; [November 15, 2017 7:43:09 PM UTC] Executing as root@gatk-test-8875b999-b609-4a3f-86ea-973b929fe662-m on Linux 3.16.0-4-amd64 amd64; OpenJDK 64-Bit Server VM 1.8.0_131-8u131-b11-1~bpo8+1-b11; Version: 4.beta.6-37-g0a135f8-SNAPSHOT; 19:43:09.992 INFO PrintVariantsSpark - HTSJDK Defaults.COMPRESSION_LEVEL : 1; 19:43:09.992 INFO PrintVariantsSpark - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 19:",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3840:1920,test,test,1920,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3840,1,['test'],['test']
Testability,-truth.vcf.gz.tbi; src/test/resources/org/broadinstitute/hellbender/tools/exome/eval/gs-calls.vcf.gz; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-average-depth.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-average-fragment-depth.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-fragment-counts.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-base-calls.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-intervals_dups.bed; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-max-of-9.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-min-MQ-30.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-NA12778.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-NA12872.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-NA12878.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-NA12878.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-no-intervals.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-sample-NA12878.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-test-targets.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-test-targets.tsv.idx; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-test-targets-wo-coords.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/germlinehmm/homo_sapiens_germline_HMM_priors.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/germlinehmm/TCGA_T_matrix_autosomal_bad.tsv; src/test/resources/org/broadinstitute/h,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3905:32825,test,test,32825,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905,1,['test'],['test']
Testability,".	DP=626;ECNT=1;NLOD=88.13;N_ART_LOD=1.78;POP_AF=0.001;P_GERMLINE=-86.27;TLOD=4.57;	GT:AD:AF:F1R2:F2R1:MBQ:MFRL:MMQ:MPOS:SA_MAP_AF:SA_POST_PROB	0/0:323,3:0.035:172,3:151,0:41:141,254:60:27:.:.	0/1:264,3:0.038:127,1:137,2:41:124,7.97254e+06:60:27:0.01,0,0.011:0.001247,0.011,0.987; ```. **EDIT**: It appears that the int 7972545 is converted to 7.97254e+06 after I passed the vcf file through a custom filter, so not really a fault of gatk (apologies). Still '7.97254e+06' should be a valid float. Full stack trace:. ```; gatk FilterMutectCalls --variant gatk/TT001T03.snv.vcf.gz --output test.vcf.gz. Using GATK jar /home/db291g/applications/gatk/gatk-4.0.1.0/gatk-package-4.0.1.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -jar /home/db291g/applications/gatk/gatk-4.0.1.0/gatk-package-4.0.1.0-local.jar FilterMutectCalls --variant gatk/TT001T03.snv.vcf.gz --output test.vcf.gz; 10:10:10.424 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/db291g/applications/gatk/gatk-4.0.1.0/gatk-package-4.0.1.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; 10:10:10.528 INFO FilterMutectCalls - ------------------------------------------------------------; 10:10:10.528 INFO FilterMutectCalls - The Genome Analysis Toolkit (GATK) v4.0.1.0; 10:10:10.528 INFO FilterMutectCalls - For support and documentation go to https://software.broadinstitute.org/gatk/; 10:10:10.529 INFO FilterMutectCalls - Executing as db291g@login01 on Linux v2.6.32-431.23.3.el6.x86_64 amd64; 10:10:10.529 INFO FilterMutectCalls - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_121-b13; 10:10:10.529 INFO FilterMutectCalls - Start Date/Time: February 7, 2018 10:10:10 AM GMT; 10:10:10.529 INFO FilterMutectCalls - ------------------------------------------------------------; 10:10:10.529 INFO FilterMutectCalls - -----------------------------------------",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4363:1542,test,test,1542,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4363,1,['test'],['test']
Testability,". Note I didn't search in all branches, but I figure we can always recommit those files. Also, any index files, etc. should be retained if necessary. CNV team will delete their files, but I'll leave it up to engine and the other teams about how much we want to remove. src/test/resources/dbsnp_132.b36.excluding_sites_after_129.chr1_1k.vcf.idx; src/test/resources/empty.vcf.idx; src/test/resources/exampleFASTA.fasta.fai; src/test/resources/fastaWithoutDict.fasta.fai; src/test/resources/fastaWithoutFai.dict; src/test/resources/hg19micro.dict; src/test/resources/hg19micro.fasta.fai; src/test/resources/hg19mini.dict; src/test/resources/hg19mini.fasta.fai; src/test/resources/Homo_sapiens_assembly19_chr1_1M.dict; src/test/resources/Homo_sapiens_assembly19_chr1_1M.fasta.fai; src/test/resources/Homo_sapiens_assembly19.dbsnp135.chr1_1M.exome_intervals.vcf.idx; src/test/resources/HSA19.dbsnp135.chr1_1M.exome_intervals.modified.vcf.idx; src/test/resources/human_g1k_v37.chr17_1Mb.dict; src/test/resources/human_g1k_v37.chr17_1Mb.fasta.fai; src/test/resources/iupacFASTA.dict; src/test/resources/iupacFASTA.fasta.fai; src/test/resources/joint_calling.chr1_1M.1kg_samples.10samples.noINFO.vcf.idx; src/test/resources/large/1000G.phase3.broad.withGenotypes.chr20.10100000.vcf.idx; src/test/resources/large/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.cram.bai; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/bias_covariates_ARD_coefficients.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/mean_bias_covariates_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/mean_bias_covariates_norm2.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/target_specific_mean_log_bias.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/target_specific_unexplained_variance.tsv; src/test/resources/large/cnv_germline_wor",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3905:1300,test,test,1300,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905,1,['test'],['test']
Testability,". To enable core dumping, try ""ulimit -c unlimited"" before starting Java again; #; # An error report file with more information is saved as:; # /home/gatk/hs_err_pid849.log; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; # The crash happened outside the Java Virtual Machine in native code.; # See problematic frame for where to report the bug.; #; ```. **RELEVANT FILES**; [hs_err_pid100.log](https://github.com/broadinstitute/gatk/files/6203288/hs_err_pid100.log); [hs_err_pid164.log](https://github.com/broadinstitute/gatk/files/6203289/hs_err_pid164.log); [hs_err_pid274.log](https://github.com/broadinstitute/gatk/files/6203290/hs_err_pid274.log); [hs_err_pid400.log](https://github.com/broadinstitute/gatk/files/6203291/hs_err_pid400.log); [hs_err_pid482.log](https://github.com/broadinstitute/gatk/files/6203292/hs_err_pid482.log); [hs_err_pid711.log](https://github.com/broadinstitute/gatk/files/6203293/hs_err_pid711.log); [hs_err_pid735.log](https://github.com/broadinstitute/gatk/files/6203294/hs_err_pid735.log); [hs_err_pid801.log](https://github.com/broadinstitute/gatk/files/6203295/hs_err_pid801.log); [hs_err_pid825.log](https://github.com/broadinstitute/gatk/files/6203296/hs_err_pid825.log); [hs_err_pid849.log](https://github.com/broadinstitute/gatk/files/6203297/hs_err_pid849.log); [otherFiles.zip](https://github.com/broadinstitute/gatk/files/6203305/otherFiles.zip); [in2510-8.orientationFilter.vcf.txt](https://github.com/broadinstitute/gatk/files/6203356/in2510-8.orientationFilter.vcf.txt); *VCF extension appended with .txt to satisfy GitHub's upload requirements*. #### Expected behavior; Worked on 7 other files generated with the same pipeline. . #### Actual behavior; Unsure why this last one is causing a segfault. The VCF included is not the whole VCF submitted originally. I went cutting out lines from the original until I could isolate it down to a minimal set required to reproduce the crash (I incl",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7162:7019,log,log,7019,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7162,1,['log'],['log']
Testability,"... and this leads some users to believe that GATK has frozen (I've seen several such complaints on the forum). I use python `logger` to log INFO/WARN/DEBUG to `stdout` in `gcnvkernel`. At the moment, I do not pass GATK's log verbosity level to `gcnvkernel` (provisions for doing this is already in place -- it's just a one-liner fix to enable it). A simple strategy is to pipe python's stdout to JVM's, regardless of GATK's log level, and delegate the responsibility setting the log level in python scripts to python tool devs.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4629:126,log,logger,126,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4629,5,['log'],"['log', 'logger']"
Testability,... so we can use it in testing.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/75:24,test,testing,24,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/75,1,['test'],['testing']
Testability,"..... . 12:38:08.377 INFO KnownSitesCache - Number of variants read: 60200001; 12:38:09.341 INFO KnownSitesCache - Number of variants read: 60300001; 12:38:10.131 INFO KnownSitesCache - Number of variants read: 60400001; 12:38:10.940 INFO KnownSitesCache - Number of variants read: 60500001; 12:38:11.719 INFO KnownSitesCache - Number of variants read: 60600001; 12:38:12.568 INFO KnownSitesCache - Number of variants read: 60700001; 12:38:13.432 INFO KnownSitesCache - Number of variants read: 60800001; 12:38:14.137 INFO KnownSitesCache - Number of variants read: 60900001; 12:38:14.833 INFO KnownSitesCache - Number of variants read: 61000001; 12:39:23.200 INFO BaseRecalibrationEngine - The covariates being used here: ; 12:39:23.200 INFO BaseRecalibrationEngine - 	ReadGroupCovariate; ```; Based on the time stamps, the observation is that it took 10 min to read the KnowSites.vcf file (about 10GB), for the code which is a filtering and copy operation:. ```java; private static List<GATKVariant> wrapQueryResults(final Iterator<VariantContext> queryResults ) {; final List<GATKVariant> wrappedResults = new ArrayList<>();; long count = 0;; while ( queryResults.hasNext() ) {; if (count++ % 100000 == 0) {; log.info(""Number of variants read: "" + count);; }; wrappedResults.add(VariantContextVariantAdapter.sparkVariantAdapter(queryResults.next()));; }; return wrappedResults;; }. ```; Seems to me this is awfully slow. The vcf file resides on HDFS (with a 100Gbps switch and backed up by a NVMe storage with over 1GBps bandwidth). Assuming we can achieve a persistent 100MBps bandwidth (which IMO is quite modest), it would take 100 sec to fetch the file. Added the overhead, it should take only 2 to 3 minutes to finish this process. If it turns out that IO performance cannot be improved, I have the impression that knownSites file is relatively stable. Would it make sense to convert the KnownSites into an intermediate format which can be read much faster? Or smaller than the 2GB threshold?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4264:1959,log,log,1959,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4264,1,['log'],['log']
Testability,"...and test, naturally. Issue #3735 reports that transient errors can cause the auth server to return ""403 Forbidden"" and, in turn, cause us to fail. This PR attempts to work around this situation by retrying a few times on these errors.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3739:7,test,test,7,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3739,1,['test'],['test']
Testability,".00,0.200:0.011,0.053,0.936; chr7 65961067 . CAAA AAAA . base_quality;panel_of_normals;t_lod DP=178;ECNT=1;IN_PON;NLOD=15.64;N_ART_LOD=-8.858e-01;POP_AF=1.000e-03;P_GERMLINE=-1.452e+01;TLOD=3.82 GT:AD:AF:MBQ:MCL:MFRL:MMQ:MPOS:OBAM:OBAMRC:SA_MAP_AF:SA_POST_PROB 0/0:75,9:0.211:20,2:0,0:169,181:60,60:22,12:false:false 0/1:42,12:0.281:26,5:0,0:155,168:60,60:21,21:false:false:0.253,0.00,0.250:0.011,0.068,0.921; chr10 26536222 . GAAA AAAA . artifact_in_normal;base_quality;panel_of_normals DP=385;ECNT=1;IN_PON;NLOD=7.23;N_ART_LOD=2.38;POP_AF=1.000e-03;P_GERMLINE=-3.938e+00;TLOD=7.64 GT:AD:AF:MBQ:MCL:MFRL:MMQ:MPOS:OBAM:OBAMRC:SA_MAP_AF:SA_POST_PROB 0/0:75,18:0.241:14,6:0,0:169,221:60,60:21,18:false:false 0/1:187,45:0.241:19,8:0,0:134,190:60,60:24,17:false:false:0.111,0.00,0.108:9.821e-04,0.663,0.336; chr20 34445260 . GT TT . germline_risk;panel_of_normals DP=55;ECNT=1;IN_PON;NLOD=3.81;N_ART_LOD=-7.874e-01;POP_AF=6.812e-03;P_GERMLINE=-3.466e-01;TLOD=5.80 GT:AD:AF:MBQ:MCL:MFRL:MMQ:MPOS:OBAM:OBAMRC:SA_MAP_AF:SA_POST_PROB 0/0:13,0:0.186:35,0:0,0:265,0:60,0:30,0:false:false 0/1:28,6:0.188:21,19:0,0:161,168:60,60:20,23:false:false:0.263,0.00,0.263:0.010,0.100,0.890; ```. I select these from the callset with; ```; gatk-launch SelectVariants \; 	-V HCC1143-vs-HCC1143_BL-filtered.vcf \; 	-O other_waf_wpon.vcf.gz \; 	-xlSelectType SNP \; 	-xlSelectType INDEL; ```. The original BAMs and resource files from which these calls were made are as follows. Data are to GRCh38. - tumor `gs://shlee-dev/hcc/hcc1143_T_clean.bam` and `gs://shlee-dev/hcc/hcc1143_T_clean.bai`; - normal `gs://shlee-dev/hcc/ hcc1143_N_clean.bam` and `gs://shlee-dev/hcc/ hcc1143_N_clean.bai`; - 39 sample PoN generated with beta.1 jar `gs://knoblett/CreatePONFiles/log/output/pon.vcf.gz` and `gs://knoblett/CreatePONFiles/log/output/pon.vcf.gz.tbi`; - gnomad resource `gs://shlee-workshop/m2/resources-beta/theta_af-only-gnomad_grch38.vcf.gz` and `gs://shlee-workshop/m2/resources-beta/theta_af-only-gnomad_grch38.vcf.gz.tbi`",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3506:2875,log,log,2875,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3506,2,['log'],['log']
Testability,".04-b08; 14:25:55.526 INFO Mutect2 - Start Date/Time: October 7, 2021 2:25:55 PM GMT; 14:25:55.526 INFO Mutect2 - ------------------------------------------------------------; 14:25:55.526 INFO Mutect2 - ------------------------------------------------------------; 14:25:55.526 INFO Mutect2 - HTSJDK Version: 2.23.0; 14:25:55.526 INFO Mutect2 - Picard Version: 2.22.8; 14:25:55.526 INFO Mutect2 - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 14:25:55.526 INFO Mutect2 - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 14:25:55.527 INFO Mutect2 - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 14:25:55.527 INFO Mutect2 - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 14:25:55.527 INFO Mutect2 - Deflater: IntelDeflater; 14:25:55.527 INFO Mutect2 - Inflater: IntelInflater; 14:25:55.527 INFO Mutect2 - GCS max retries/reopens: 20; 14:25:55.527 INFO Mutect2 - Requester pays: disabled; 14:25:55.527 INFO Mutect2 - Initializing engine; 14:25:55.994 INFO FeatureManager - Using codec BEDCodec to read file file:///test.bed; 14:25:56.086 INFO IntervalArgumentCollection - Processing 3896357 bp from intervals; 14:25:56.115 INFO Mutect2 - Shutting down engine; [October 7, 2021 2:25:56 PM GMT] org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2 done. Elapsed time: 0.01 minutes.; Runtime.totalMemory()=2102919168; **java.lang.NullPointerException**; at java.util.ComparableTimSort.countRunAndMakeAscending(ComparableTimSort.java:325); at java.util.ComparableTimSort.sort(ComparableTimSort.java:202); at java.util.Arrays.sort(Arrays.java:1312); at java.util.Arrays.sort(Arrays.java:1506); at java.util.ArrayList.sort(ArrayList.java:1462); at java.util.Collections.sort(Collections.java:143); at org.broadinstitute.hellbender.utils.IntervalUtils.sortAndMergeIntervals(IntervalUtils.java:467); at org.broadinstitute.hellbender.utils.IntervalUtils.getIntervalsWithFlanks(IntervalUtils.java:965); at org.broadinstitute.hellbender.utils.IntervalUtils.getIntervalsWithFlanks(IntervalU",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7496:2914,test,test,2914,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7496,1,['test'],['test']
Testability,".086;DP=21;ExcessHet=3.0103;FS=1.719;MLEAC=1;MLEAF=0.500;MQ=60.00;MQRankSum=0.000;QD=8.46;ReadPosRankSum=0.475;SOR=0.368 GT:AD:DP:F1R2:F2R1:GQ:PL; 0/1:13,8:21:6,6:7,2:99:185,0,339; 13 32913055 . A G 402.03 . AC=2;AF=1.00;AN=2;DP=15;ExcessHet=3.0103;FS=0.000;MLEAC=2;MLEAF=1.00;MQ=60.00;QD=26.80;SOR=1.112 GT:AD:DP:F1R2:F2R1:GQ:PL 1/1:0,15:15:0,12:0,2:45:416,45,0; 13 32915005 . G C 378.02 . AC=2;AF=1.00;AN=2;DP=13;ExcessHet=3.0103;FS=0.000;MLEAC=2;MLEAF=1.00;MQ=60.00;QD=29.08;SOR=1.179 GT:AD:DP:F1R2:F2R1:GQ:PL 1/1:0,13:13:0,4:0,9:39:392,39,0; 13 32929232 . A G 168.60 . AC=1;AF=0.500;AN=2;BaseQRankSum=1.335;DP=11;ExcessHet=3.0103;FS=0.000;MLEAC=1;MLEAF=0.500;MQ=60.00;MQRankSum=0.000;QD=15.33;ReadPosRankSum=-1.442;SOR=0.446 GT:AD:DP:F1R2:F2R1:GQ:PL; 0/1:5,6:11:3,3:2,3:99:176,0,121; 13 32929387 . T C 208.98 . AC=2;AF=1.00;AN=2;DP=7;ExcessHet=3.0103;FS=0.000;MLEAC=2;MLEAF=1.00;MQ=60.00;QD=29.85;SOR=1.609 GT:AD:DP:F1R2:F2R1:GQ:PL 1/1:0,7:7:0,2:0,5:21:223,21,0; ```. Execution log:; ```; Using GATK jar /gatk/gatk-package-4.1.1.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /gatk/gatk-package-4.1.1.0-local.jar HaplotypeCaller --input sample.bam --annotation OrientationBiasReadCounts --intervals b37.chr13.bed --reference hs37d5.fa --output sample.vcf.gz; 03:58:32.017 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/gatk/gatk-package-4.1.1.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Jan 06, 2023 3:58:33 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 03:58:33.929 INFO HaplotypeCaller - ------------------------------------------------------------; 03:58:33.930 INFO HaplotypeCaller - The Genome Analysis Toolkit (GATK) v4.1.1.0; 03:58:33.930 INFO HaplotypeCaller - For support and documentation",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8149:8483,log,log,8483,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8149,1,['log'],['log']
Testability,.21.10m-10m100.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.10m-10m100.cram.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_132.b36.excluding_sites_after_129.chr1_1k.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_132.b37.excluding_sites_after_129.chr17_69k_70k.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_138.b37.20.10m-10m100.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_138.b37.21.10m-10m100.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_138.b37.excluding_sites_after_129.ch20.1m-1m1k.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.noMD.noBQSR.md.bqsr.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.postRecalibrated.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.recalibrated.DIQ.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m20k.NA12878.2inputs.recal.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m20k.NA12878.indels_context_size_4.recal.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m20k.NA12878.low_quality_tail_5.recal.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m20k.NA12878.mismatches_context_size_4.recal.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m20k.NA12878.quantizing_levels_6.recal.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m20k.NA12878.recal.txt; src/test/resources/org/broadinstitute/hellbender/tools/,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3905:19738,test,test,19738,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905,1,['test'],['test']
Testability,".7_30_ga4f720357.expected.vcf, 8536) FAILED; java.lang.AssertionError: different sizes 16940 vs 17070; at org.broadinstitute.hellbender.utils.test.VariantContextTestUtils.assertEqualVariants(VariantContextTestUtils.java:173); at org.broadinstitute.hellbender.tools.GatherVcfsIntegrationTest.testBlockGather(GatherVcfsIntegrationTest.java:103); Results: FAILURE (15 tests, 14 successes, 1 failures, 0 skipped); ```. The tool writes a vcf that, when read back in by GATK, appears to have fewer records than it should. The same test does NOT fail if you do ANY of the following:. * Edit `GatherVcfsIntegrationTest.testBlockGather()` to turn on the JDK deflater by changing `.addBooleanArgument(""use_jdk_deflater"", false);` to `.addBooleanArgument(""use_jdk_deflater"", true);`. * Keep the Intel deflater on, but edit `build.gradle` to change `samjdk.compression_level` to 1 or 2. (You'll also need to change the `Assert.assertEquals(System.getProperty(""samjdk.compression_level""), ""5"");` line in `GatherVcfsIntegrationTest.testBlockGather()` accordingly). * Edit the `getVcfsToShard` `DataProvider` in `GatherVcfsIntegrationTest` to change the failing `{LARGE_VCF, 8536}` test case to `{LARGE_VCF, 8535}`. This cuts the number of files that the vcf gets split into in half, and the test passes. * Comment out all but the last test case in the `getVcfsToShard` `DataProvider` in `GatherVcfsIntegrationTest`. This indicates that there is something stateful going on, since the test case does not fail if run in isolation. One additional bit of information: the test fails with the Intel deflater and compression levels 5 and 9, but with compression level 9 GATK is able to read many fewer records from the final output file than it does at compression level 5. As mentioned above, at compression levels 1 or 2 it's able to read all the records correctly. If you manually decompress the output file it appears to have all the correct records in all cases, so it's something wrong with the compression itself.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3117:1367,test,testBlockGather,1367,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3117,6,['test'],"['test', 'testBlockGather']"
Testability,".BwaMemIndex.createIndexImageFromFastaFile(BwaMemIndex.java:196); at org.broadinstitute.hellbender.BwaMemIntegrationTest.loadIndex(BwaMemIntegrationTest.java:49); Running Test: Test method testChimericUnpairedMapping(org.broadinstitute.hellbender.BwaMemIntegrationTest). Gradle suite > Gradle test > org.broadinstitute.hellbender.BwaMemIntegrationTest > testChimericUnpairedMapping SKIPPED; Running Test: Test method testPerfectUnpairedMapping(org.broadinstitute.hellbender.BwaMemIntegrationTest). Gradle suite > Gradle test > org.broadinstitute.hellbender.BwaMemIntegrationTest > testPerfectUnpairedMapping SKIPPED; ```. This test fails because some JAR wasn't built:; ```; Running Test: Test method testPipeForPicardTools(org.broadinstitute.hellbender.engine.PipelineSupportIntegrationTest); Test: Test method testPipeForPicardTools(org.broadinstitute.hellbender.engine.PipelineSupportIntegrationTest) produced standard out/err: No local jar was found, please build one by running. Gradle suite > Gradle test > org.broadinstitute.hellbender.engine.PipelineSupportIntegrationTest > testPipeForPicardTools STANDARD_ERROR; No local jar was found, please build one by running; Test: Test method testPipeForPicardTools(org.broadinstitute.hellbender.engine.PipelineSupportIntegrationTest) produced standard out/err:. Test: Test method testPipeForPicardTools(org.broadinstitute.hellbender.engine.PipelineSupportIntegrationTest) produced standard out/err: /disk-samsung/ports/biology/gatk/work/gatk-4.6.0.0/gradlew localJar. /disk-samsung/ports/biology/gatk/work/gatk-4.6.0.0/gradlew localJar; Test: Test method testPipeForPicardTools(org.broadinstitute.hellbender.engine.PipelineSupportIntegrationTest) produced standard out/err: or. or; Test: Test method testPipeForPicardTools(org.broadinstitute.hellbender.engine.PipelineSupportIntegrationTest) produced standard out/err: export GATK_LOCAL_JAR=<path_to_local_jar>. export GATK_LOCAL_JAR=<path_to_local_jar>; Test: Test method testPipeForPicardTools(org",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8940:3573,test,test,3573,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8940,1,['test'],['test']
Testability,".BwaMemIndex.createReferenceIndex(Native Method); at org.broadinstitute.hellbender.utils.bwa.BwaMemIndex.createIndexImageFromFastaFile(BwaMemIndex.java:227); at org.broadinstitute.hellbender.utils.bwa.BwaMemIndex.createIndexImageFromFastaFile(BwaMemIndex.java:196); at org.broadinstitute.hellbender.BwaMemIntegrationTest.loadIndex(BwaMemIntegrationTest.java:49); Running Test: Test method testChimericUnpairedMapping(org.broadinstitute.hellbender.BwaMemIntegrationTest). Gradle suite > Gradle test > org.broadinstitute.hellbender.BwaMemIntegrationTest > testChimericUnpairedMapping SKIPPED; Running Test: Test method testPerfectUnpairedMapping(org.broadinstitute.hellbender.BwaMemIntegrationTest). Gradle suite > Gradle test > org.broadinstitute.hellbender.BwaMemIntegrationTest > testPerfectUnpairedMapping SKIPPED; ```. This test fails because some JAR wasn't built:; ```; Running Test: Test method testPipeForPicardTools(org.broadinstitute.hellbender.engine.PipelineSupportIntegrationTest); Test: Test method testPipeForPicardTools(org.broadinstitute.hellbender.engine.PipelineSupportIntegrationTest) produced standard out/err: No local jar was found, please build one by running. Gradle suite > Gradle test > org.broadinstitute.hellbender.engine.PipelineSupportIntegrationTest > testPipeForPicardTools STANDARD_ERROR; No local jar was found, please build one by running; Test: Test method testPipeForPicardTools(org.broadinstitute.hellbender.engine.PipelineSupportIntegrationTest) produced standard out/err:. Test: Test method testPipeForPicardTools(org.broadinstitute.hellbender.engine.PipelineSupportIntegrationTest) produced standard out/err: /disk-samsung/ports/biology/gatk/work/gatk-4.6.0.0/gradlew localJar. /disk-samsung/ports/biology/gatk/work/gatk-4.6.0.0/gradlew localJar; Test: Test method testPipeForPicardTools(org.broadinstitute.hellbender.engine.PipelineSupportIntegrationTest) produced standard out/err: or. or; Test: Test method testPipeForPicardTools(org.broadinstitute.hellben",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8940:3361,Test,Test,3361,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8940,3,"['Test', 'test']","['Test', 'testPipeForPicardTools']"
Testability,.Invoker.invokeTestMethods(Invoker.java:1131); at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); at org.testng.TestRunner.privateRun(TestRunner.java:773); at org.testng.TestRunner.run(TestRunner.java:623); at org.testng.SuiteRunner.runTest(SuiteRunner.java:357); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:352); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:310); at org.testng.SuiteRunner.run(SuiteRunner.java:259); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1185); at org.testng.TestNG.runSuitesLocally(TestNG.java:1110); at org.testng.TestNG.run(TestNG.java:1018); at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:133); at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:83); at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:497); at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35); at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); at org.gradle.messaging.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:32); at org.gradle.messaging.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:93); at com.sun.proxy.$Proxy2.stop(Unknown Source); at org.gradle.api.internal.tasks.testing.worker.TestWorker.stop(TestWorker.ja,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1638:2586,test,testing,2586,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1638,2,['test'],['testing']
Testability,.Invoker.invokeTestMethods(Invoker.java:1193); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:126); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:109); 	at org.testng.TestRunner.privateRun(TestRunner.java:744); 	at org.testng.TestRunner.run(TestRunner.java:602); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:380); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:375); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:340); 	at org.testng.SuiteRunner.run(SuiteRunner.java:289); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1301); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1226); 	at org.testng.TestNG.runSuites(TestNG.java:1144); 	at org.testng.TestNG.run(TestNG.java:1115); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:129); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:88); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:32); 	at org.gradle.internal.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:93); 	at com.sun.proxy.$Proxy2.stop(Unknown Source); 	at o,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2797:2462,Test,TestNGTestClassProcessor,2462,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2797,3,['Test'],['TestNGTestClassProcessor']
Testability,.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:133); 	at org.testng.internal.TestInvoker.invokeMethod(TestInvoker.java:584); 	at org.testng.internal.TestInvoker.invokeTestMethod(TestInvoker.java:172); 	at org.testng.internal.MethodRunner.runInSequence(MethodRunner.java:46); 	at org.testng.internal.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:804); 	at org.testng.internal.TestInvoker.invokeTestMethods(TestInvoker.java:145); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:128); 	at java.util.ArrayList.forEach(ArrayList.java:1257); 	at org.testng.TestRunner.privateRun(TestRunner.java:770); 	at org.testng.TestRunner.run(TestRunner.java:591); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:402); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:396); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:355); 	at org.testng.SuiteRunner.run(SuiteRunner.java:304); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:53); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:96); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1180); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1102); 	at org.testng.TestNG.runSuites(TestNG.java:1032); 	at org.testng.TestNG.run(TestNG.java:1000); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:141); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:90); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Nati,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6748:2975,Test,TestRunner,2975,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6748,2,['Test'],['TestRunner']
Testability,.Reflections.scan(Reflections.java:204); at org.reflections.Reflections.<init>(Reflections.java:129); at com.google.cloud.genomics.dataflow.utils.DataflowWorkarounds.registerGenomicsCoders(DataflowWorkarounds.java:90); at org.broadinstitute.hellbender.tools.dataflow.transforms.InsertSizeMetricsTransformUnitTest.testInsertSizeMetricsTransform(InsertSizeMetricsTransformUnitTest.java:49); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:497); at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); at org.testng.internal.Invoker.invokeMethod(Invoker.java:659); at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:845); at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1153); at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:125); at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); at org.testng.TestRunner.privateRun(TestRunner.java:771); at org.testng.TestRunner.run(TestRunner.java:621); at org.testng.SuiteRunner.runTest(SuiteRunner.java:357); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:352); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:310); at org.testng.SuiteRunner.run(SuiteRunner.java:259); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1199); at org.testng.TestNG.runSuitesLocally(TestNG.java:1124); at org.testng.TestNG.run(TestNG.java:1032); at org.testng.remote.RemoteTestNG.run(RemoteTestNG.java:111); at org.testng.remote.RemoteTestNG.initAndRun(RemoteTestNG.java:204); at org.testng.remote.RemoteTestNG.main(RemoteTestNG.java:175); at org.testng.RemoteTestNGStarter.main(R,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/609:2027,Test,TestMethodWorker,2027,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/609,1,['Test'],['TestMethodWorker']
Testability,.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1348); 	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13.apply(PairRDDFunctions.scala:1211); 	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13.apply(PairRDDFunctions.scala:1190); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); 	at org.apache.spark.scheduler.Task.run(Task.scala:86); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745). **This is the stack I get when the test completes but fails (note that the expected line count appears to not match the line count of the expected output file in the repo): **. java.lang.AssertionError: line counts expected [2629] but found [507]; 	at org.testng.Assert.fail(Assert.java:94); 	at org.testng.Assert.failNotEquals(Assert.java:496); 	at org.testng.Assert.assertEquals(Assert.java:125); 	at org.testng.Assert.assertEquals(Assert.java:372); 	at org.broadinstitute.hellbender.utils.test.IntegrationTestSpec.assertEqualTextFiles(IntegrationTestSpec.java:211); 	at org.broadinstitute.hellbender.utils.test.IntegrationTestSpec.assertEqualTextFiles(IntegrationTestSpec.java:190); 	at org.broadinstitute.hellbender.tools.examples.ExampleAssemblyRegionWalkerSparkIntegrationTest.testExampleAssemblyRegionWalker(ExampleAssemblyRegionWalkerSparkIntegrationTest.java:29); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); 	,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2349:3219,test,testng,3219,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2349,1,['test'],['testng']
Testability,.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:83); at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:497); at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35); at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); at org.gradle.messaging.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:32); at org.gradle.messaging.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:93); at com.sun.proxy.$Proxy2.stop(Unknown Source); at org.gradle.api.internal.tasks.testing.worker.TestWorker.stop(TestWorker.java:120); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:497); at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35); at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); at org.gradle.messaging.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:360); at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:54); at org.gradle.internal.concurrent.StoppableExecutorImpl$1.run(StoppableExecutorImpl.java:40); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745);,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1638:3561,Test,TestWorker,3561,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1638,2,['Test'],['TestWorker']
Testability,.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectAlignmentSummaryMetrics/summary_alignment_bisulfite_test.sam; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectAlignmentSummaryMetrics/summary_alignment_stats_test2.sam; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectAlignmentSummaryMetrics/summary_alignment_stats_test.bam; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectAlignmentSummaryMetrics/summary_alignment_stats_test.cram; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectAlignmentSummaryMetrics/summary_alignment_stats_test.fasta.fai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectAlignmentSummaryMetrics/summary_alignment_stats_test_multiple.sam; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectAlignmentSummaryMetrics/summary_alignment_stats_test.sam; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectBaseDistributionByCycle/example_pfFail_reads.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectBaseDistributionByCycle/first5000a.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectBaseDistributionByCycle/originalQuals.chr1.1-1K.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectBaseDistributionByCycle/unmapped.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectBaseDistributionByCycle/valid.cram.crai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectBaseDistributionByCycle/valid.dict; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectBaseDistributionByCycle/valid.fasta.fai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectQualityYieldMetrics/collect_quality_yield_metrics.bam; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectQualityYieldMetrics/collect_qualit,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3905:13983,test,test,13983,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905,1,['test'],['test']
Testability,.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/QualityScoreDistribution/example_pfFail_reads.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/QualityScoreDistribution/first5000a.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/QualityScoreDistribution/originalQuals.chr1.1-1K.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/QualityScoreDistribution/unmapped.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/add_comments_to_bam.bam; src/test/resources/org/broadinstitute/hellbender/tools/add_comments_to_bam.sam; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.2.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.3.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.4.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.5.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.6.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.7.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.8.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.broken.1.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.broken.2.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.broken.3.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.broken.4.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.broken.5.txt; src/test/resources/org/broadin,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3905:16654,test,test,16654,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905,1,['test'],['test']
Testability,.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.noMD.noBQSR.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.noMD.noBQSR.cram.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.noMD.noBQSR.md.bqsr.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.ch20.4379150-4379157.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.10m-10m100.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.10m-10m100.cram.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_132.b36.excluding_sites_after_129.chr1_1k.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_132.b37.excluding_sites_after_129.chr17_69k_70k.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_138.b37.20.10m-10m100.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_138.b37.21.10m-10m100.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_138.b37.excluding_sites_after_129.ch20.1m-1m1k.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.noMD.noBQSR.md.bqsr.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.postRecalibrated.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.recalibrated.DIQ.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m20k.NA12878.2inputs.recal.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m20k.NA12878.indels_context_size_4.recal.txt; src/test/resources/org/bro,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3905:19147,test,test,19147,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905,1,['test'],['test']
Testability,.bai; src/test/resources/org/broadinstitute/hellbender/tools/copynumber/allelic/collect-allelic-counts-tumor.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/copynumber/collectfragmentcounts/collect-fragment-counts-NA12878.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/count_bases.cram.crai; src/test/resources/org/broadinstitute/hellbender/tools/count_bases.dict; src/test/resources/org/broadinstitute/hellbender/tools/count_bases.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/count_reads.cram.crai; src/test/resources/org/broadinstitute/hellbender/tools/count_reads.dict; src/test/resources/org/broadinstitute/hellbender/tools/count_reads.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/count_reads_sorted.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/count_reads_sorted.cram.crai; src/test/resources/org/broadinstitute/hellbender/tools/count_variants.blockgz.gz.tbi; src/test/resources/org/broadinstitute/hellbender/tools/count_variants_withSequenceDict.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/calling_combined_copy_number.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/calling_combined_read_counts.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/calling_sample_bias_latent.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/calling_sample_read_depth.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/calling_sample_sex_genotypes.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/learning_combined_copy_number.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/learning_combined_read_counts.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/learning_sample_bias_latent.tsv; src/test/resources/org/broadinstitute/hellbender/tools/,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3905:27063,test,test,27063,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905,1,['test'],['test']
Testability,.broadinstitute.hellbender.tools.walkers.filters.VariantFiltrationIntegrationTest.testClusteredSnps(VariantFiltrationIntegrationTest.java:36); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:497); at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); at org.testng.internal.Invoker.invokeMethod(Invoker.java:639); at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:821); at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1131); at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); at org.testng.TestRunner.privateRun(TestRunner.java:773); at org.testng.TestRunner.run(TestRunner.java:623); at org.testng.SuiteRunner.runTest(SuiteRunner.java:357); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:352); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:310); at org.testng.SuiteRunner.run(SuiteRunner.java:259); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1185); at org.testng.TestNG.runSuitesLocally(TestNG.java:1110); at org.testng.TestNG.run(TestNG.java:1018); at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:133); at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:83); at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62);,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1638:1911,test,testng,1911,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1638,1,['test'],['testng']
Testability,".broadinstitute.org/hc/en-us/community/posts/4409429876123--Did-not-inflate-expected-amount-Error). \--. Hi! I'm doing WGS analysis of a pedigree of three individuals using GATK 4.2.0.0. Everything went on well for the first individual. However, in the step of generating gvcf file from bam file, I encountered the error \[htsjdk.samtools.SAMFormatException: Did not inflate expected amount\] in the other two of the individuals. Please help me! Thank you in advance!. a) GATK version used:. GATK 4.2.0.0. b) Exact command used:. java -jar /home/ngs/biosoft/gatk-4.2.0.0/gatk-package-4.2.0.0-local.jar \\ ; ; HaplotypeCaller \\ ; ; \-R /media/ngs/NGS0/Database/RefSeq/Homo\_sapiens\_NCBI\_GRCh38Decoy/Homo\_sapiens/NCBI/GRCh38Decoy/Sequence/WholeGenomeFasta/NewIndex/genome.fa \\ ; ; \-I /media/ngs/BAM5T/WGS\_analysis/Data/9\_BQSRBam/Ped-San-3\_merged\_realigned\_bqsr.bam \\ ; ; \-ERC GVCF \\ ; ; \-O /media/ngs/BAM5T/WGS\_analysis/Data/10\_gvcf/Ped-San-3\_merged\_realigned\_bqsr.g.vcf. c) Entire error log:. 14:14:32.075 INFO NativeLibraryLoader - Loading libgkl\_compression.so from jar:file:/home/ngs/biosoft/gatk-4.2.0.0/gatk-package-4.2.0.0-local.jar!/com/intel/gkl/native/libgkl\_compression.so ; ; Nov 01, 2021 2:14:32 PM shaded.cloud\_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine ; ; INFO: Failed to detect whether we are running on Google Compute Engine. ; ; 14:14:32.573 INFO HaplotypeCaller - ------------------------------------------------------------ ; ; 14:14:32.573 INFO HaplotypeCaller - The Genome Analysis Toolkit (GATK) v4.2.0.0 ; ; 14:14:32.573 INFO HaplotypeCaller - For support and documentation go to [https://software.broadinstitute.org/gatk/](https://software.broadinstitute.org/gatk/) ; ; 14:14:32.573 INFO HaplotypeCaller - Executing as ngs@ngs-linux on Linux v5.8.0-59-generic amd64 ; ; 14:14:32.573 INFO HaplotypeCaller - Java runtime: OpenJDK 64-Bit Server VM v1.8.0\_292-8u292-b10-0ubuntu1~20.04-b10 ; ; 14:14:32.573 INFO HaplotypeCall",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7582:1393,log,log,1393,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7582,1,['log'],['log']
Testability,.cram.crai; src/test/resources/org/broadinstitute/hellbender/engine/ambiguityCodes.dict; src/test/resources/org/broadinstitute/hellbender/engine/ambiguityCodes.fasta.fai; src/test/resources/org/broadinstitute/hellbender/engine/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.10000000-10000020.with.unmapped.bam.bai; src/test/resources/org/broadinstitute/hellbender/engine/CEUTrio.HiSeq.WGS.b37.NA12878.snippet_with_unmapped.bam.bai; src/test/resources/org/broadinstitute/hellbender/engine/CEUTrio.HiSeq.WGS.b37.NA12878.snippet_with_unmapped.cram.crai; src/test/resources/org/broadinstitute/hellbender/engine/cramtestWrongRef.dict; src/test/resources/org/broadinstitute/hellbender/engine/cramtestWrongRef.fasta.fai; src/test/resources/org/broadinstitute/hellbender/engine/cram_with_bai_index.cram.bai; src/test/resources/org/broadinstitute/hellbender/engine/cram_with_crai_index.cram.crai; src/test/resources/org/broadinstitute/hellbender/engine/example_features.bed.idx; src/test/resources/org/broadinstitute/hellbender/engine/example_variants_noSequenceDict.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/example_variants_withSequenceDict.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/feature_data_source_test_gvcf.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/feature_data_source_test.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/feature_data_source_test_withSequenceDict.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/FeatureInput/vcfWithIndex.vcf; src/test/resources/org/broadinstitute/hellbender/engine/FeatureInput/vcfWithIndex.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/FeatureInput/vcfWithOutIndex.vcf; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_ReadWalkerGCSSupportIntegrationTest_bam_multiple_intervals.bai; src/test/resources/org/broadinstitute/hellbender/engine/GCSTests/expected_ReadWalkerGCSSupportIntegrationTest_bam_multiple_intervals_with_unmapped.b,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3905:8880,test,test,8880,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905,1,['test'],['test']
Testability,.google.cloud.storage.StorageOptions$Builder.build(StorageOptions.java:77); 	at com.google.cloud.storage.StorageOptions.getDefaultInstance(StorageOptions.java:121); 	at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.initStorage(CloudStorageFileSystemProvider.java:153); 	at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.getPath(CloudStorageFileSystemProvider.java:208); 	at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.getPath(CloudStorageFileSystemProvider.java:85); 	at java.nio.file.Paths.get(Paths.java:143); 	at org.broadinstitute.hellbender.utils.gcs.BucketUtilsTest.testNoIllegalArgumentException(BucketUtilsTest.java:38); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:108); 	at org.testng.internal.Invoker.invokeMethod(Invoker.java:661); 	at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:869); 	at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1193); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:126); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:109); 	at org.testng.TestRunner.privateRun(TestRunner.java:744); 	at org.testng.TestRunner.run(TestRunner.java:602); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:380); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:375); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:340); 	at org.testng.SuiteRunner.run(SuiteRunner.java:289); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1301); 	at org.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2707:1608,test,testng,1608,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2707,1,['test'],['testng']
Testability,.hellbender.tools.dataflow.pipelines.BaseRecalibratorDataflowIntegrationTest.testBQSRBucket(BaseRecalibratorDataflowIntegrationTest.java:176); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:483); at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); at org.testng.internal.Invoker.invokeMethod(Invoker.java:639); at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:821); at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1131); at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); at org.testng.TestRunner.privateRun(TestRunner.java:773); at org.testng.TestRunner.run(TestRunner.java:623); at org.testng.SuiteRunner.runTest(SuiteRunner.java:357); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:352); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:310); at org.testng.SuiteRunner.run(SuiteRunner.java:259); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1185); at org.testng.TestNG.runSuitesLocally(TestNG.java:1110); at org.testng.TestNG.run(TestNG.java:1018); at org.testng.remote.RemoteTestNG.run(RemoteTestNG.java:111); at org.testng.remote.RemoteTestNG.initAndRun(RemoteTestNG.java:204); at org.testng.remote.RemoteTestNG.main(RemoteTestNG.java:175); at org.testng.RemoteTestNGStarter.main(RemoteTestNGStarter.java:125); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAcc,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/866:1696,test,testng,1696,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/866,1,['test'],['testng']
Testability,.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/gvcfExample2.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/IntervalTest.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/NA12878.AS.chr20snippet.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/NA12892.AS.chr20snippet.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/spanningDel.1.copy.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/spanningDel.1.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/spanningDel.2.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/spanningDeletionRestrictToStartExpected.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/spanningDel.many.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/spanningDel.many.haploid.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/spanningDel.many.tetraploid.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/testAlleleSpecificAnnotationsNoGroup.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/testAlleleSpecificAnnotations.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/testBasepairResolutionInput.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/testBreakBandsArgumet.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/testMultipleSpanningDeletionsForOneSampleHaploid.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/testMultipleSpanningDeletionsForOneSampleTetraploid.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/testMultipl,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3905:50286,test,test,50286,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905,1,['test'],['test']
Testability,.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/testAlleleSpecificAnnotations.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/testBasepairResolutionInput.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/testBreakBandsArgumet.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/testMultipleSpanningDeletionsForOneSampleHaploid.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/testMultipleSpanningDeletionsForOneSampleTetraploid.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/testMultipleSpanningDeletionsForOneSample.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/testWrongReferenceBaseBugFix.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/tetraploid-gvcf-1.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/tetraploid-gvcf-2.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/tetraploid-gvcf-3.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/filters/VariantFiltration/expected/testVariantFiltration_testClusteredSnps.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/filters/VariantFiltration/expected/testVariantFiltration_testDeletions.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/filters/VariantFiltration/expected/testVariantFiltration_testFilter1.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/filters/VariantFiltration/expected/testVariantFiltration_testFilter2.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/filters/VariantFiltration/expected/testVariantFiltration_testFilteringDPfromFORMATAndFailMissing.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/filters/VariantFiltration/expected/,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3905:51585,test,test,51585,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905,1,['test'],['test']
Testability,.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/testBreakBandsArgumet.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/testMultipleSpanningDeletionsForOneSampleHaploid.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/testMultipleSpanningDeletionsForOneSampleTetraploid.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/testMultipleSpanningDeletionsForOneSample.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/testWrongReferenceBaseBugFix.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/tetraploid-gvcf-1.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/tetraploid-gvcf-2.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/tetraploid-gvcf-3.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/filters/VariantFiltration/expected/testVariantFiltration_testClusteredSnps.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/filters/VariantFiltration/expected/testVariantFiltration_testDeletions.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/filters/VariantFiltration/expected/testVariantFiltration_testFilter1.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/filters/VariantFiltration/expected/testVariantFiltration_testFilter2.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/filters/VariantFiltration/expected/testVariantFiltration_testFilteringDPfromFORMATAndFailMissing.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/filters/VariantFiltration/expected/testVariantFiltration_testFilteringDPfromFORMAT.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/filters/VariantFiltration/expected/testVariantFiltration_testFilteringDPfromINFO.vcf.idx; src/test/resources,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3905:51791,test,test,51791,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905,1,['test'],['test']
Testability,.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/filters/VariantFiltration/expected/testVariantFiltration_testFilterWithSeparateNames.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/filters/VariantFiltration/expected/testVariantFiltration_testGenotypeFilters1.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/filters/VariantFiltration/expected/testVariantFiltration_testGenotypeFilters2.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/filters/VariantFiltration/expected/testVariantFiltration_testInvertFilter.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/filters/VariantFiltration/expected/testVariantFiltration_testInvertGenotypeFilterExpression.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/filters/VariantFiltration/expected/testVariantFiltration_testInvertJexlFilter.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/filters/VariantFiltration/expected/testVariantFiltration_testInvertJexlGenotypeFilterExpression.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/filters/VariantFiltration/expected/testVariantFiltration_testMask1.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/filters/VariantFiltration/expected/testVariantFiltration_testMask2.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/filters/VariantFiltration/expected/testVariantFiltration_testMask3.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/filters/VariantFiltration/expected/testVariantFiltration_testMaskReversed.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/filters/VariantFiltration/expected/testVariantFiltration_testNoAction.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/filters/VariantFiltration/expected/testVariantFiltration_testSetFilteredGtoNocall.vcf.idx; src/test/resources/org/broadinstitute/hellbender/t,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3905:53911,test,test,53911,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905,1,['test'],['test']
Testability,.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); 	at org.testng.internal.Invoker.invokeMethod(Invoker.java:639); 	at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:821); 	at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1131); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); 	at org.testng.TestRunner.privateRun(TestRunner.java:773); 	at org.testng.TestRunner.run(TestRunner.java:623); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:357); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:352); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:310); 	at org.testng.SuiteRunner.run(SuiteRunner.java:259); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1185); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1110); 	at org.testng.TestNG.run(TestNG.java:1018); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:129); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:88); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.ja,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2349:5140,test,testng,5140,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2349,1,['test'],['testng']
Testability,.invoke(TestInvoker.java:804); 	at org.testng.internal.TestInvoker.invokeTestMethods(TestInvoker.java:145); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:128); 	at java.base/java.util.ArrayList.forEach(ArrayList.java:1540); 	at org.testng.TestRunner.privateRun(TestRunner.java:770); 	at org.testng.TestRunner.run(TestRunner.java:591); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:402); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:396); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:355); 	at org.testng.SuiteRunner.run(SuiteRunner.java:304); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:53); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:96); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1180); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1102); 	at org.testng.TestNG.runSuites(TestNG.java:1032); 	at org.testng.TestNG.run(TestNG.java:1000); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:141); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:90); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.base/java.lang.reflect.Method.invoke(Method.java:566); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDi,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6745:3134,test,testng,3134,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6745,2,['test'],['testng']
Testability,.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:483); at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); at org.testng.internal.Invoker.invokeMethod(Invoker.java:639); at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:821); at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1131); at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); at org.testng.TestRunner.privateRun(TestRunner.java:773); at org.testng.TestRunner.run(TestRunner.java:623); at org.testng.SuiteRunner.runTest(SuiteRunner.java:357); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:352); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:310); at org.testng.SuiteRunner.run(SuiteRunner.java:259); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1185); at org.testng.TestNG.runSuitesLocally(TestNG.java:1110); at org.testng.TestNG.run(TestNG.java:1018); at org.testng.remote.RemoteTestNG.run(RemoteTestNG.java:111); at org.testng.remote.RemoteTestNG.initAndRun(RemoteTestNG.java:204); at org.testng.remote.RemoteTestNG.main(RemoteTestNG.java:175); at org.testng.RemoteTestNGStarter.main(RemoteTestNGStarter.java:125); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:483); at com.intellij.rt.execution.application.AppMain.main(AppMain.java:140); Caused by: java.lang.RuntimeExceptio,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/866:1878,test,testng,1878,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/866,1,['test'],['testng']
Testability,.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:497); at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); at org.testng.internal.Invoker.invokeMethod(Invoker.java:639); at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:821); at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1131); at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); at org.testng.TestRunner.privateRun(TestRunner.java:773); at org.testng.TestRunner.run(TestRunner.java:623); at org.testng.SuiteRunner.runTest(SuiteRunner.java:357); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:352); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:310); at org.testng.SuiteRunner.run(SuiteRunner.java:259); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1185); at org.testng.TestNG.runSuitesLocally(TestNG.java:1110); at org.testng.TestNG.run(TestNG.java:1018); at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:133); at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:83); at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:497); at org.gradle.messaging.dispatch.Refle,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1638:2093,test,testng,2093,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1638,2,['test'],['testng']
Testability,".invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:497); at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); at org.testng.internal.Invoker.invokeMethod(Invoker.java:659); at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:845); at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1153); at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:125); at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); at org.testng.TestRunner.privateRun(TestRunner.java:771); at org.testng.TestRunner.run(TestRunner.java:621); at org.testng.SuiteRunner.runTest(SuiteRunner.java:357); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:352); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:310); at org.testng.SuiteRunner.run(SuiteRunner.java:259); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1199); at org.testng.TestNG.runSuitesLocally(TestNG.java:1124); at org.testng.TestNG.run(TestNG.java:1032); at org.testng.remote.RemoteTestNG.run(RemoteTestNG.java:111); at org.testng.remote.RemoteTestNG.initAndRun(RemoteTestNG.java:204); at org.testng.remote.RemoteTestNG.main(RemoteTestNG.java:175); at org.testng.RemoteTestNGStarter.main(RemoteTestNGStarter.java:125); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:497); at com.intellij.rt.execution.application.AppMain.main(AppMain.java:140). Jul 01, 2015 2:33:37 PM org.reflecti",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/609:2460,test,testng,2460,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/609,1,['test'],['testng']
Testability,.invokeTestMethod(TestInvoker.java:172); 	at org.testng.internal.MethodRunner.runInSequence(MethodRunner.java:46); 	at org.testng.internal.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:804); 	at org.testng.internal.TestInvoker.invokeTestMethods(TestInvoker.java:145); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:128); 	at java.base/java.util.ArrayList.forEach(ArrayList.java:1540); 	at org.testng.TestRunner.privateRun(TestRunner.java:770); 	at org.testng.TestRunner.run(TestRunner.java:591); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:402); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:396); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:355); 	at org.testng.SuiteRunner.run(SuiteRunner.java:304); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:53); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:96); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1180); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1102); 	at org.testng.TestNG.runSuites(TestNG.java:1032); 	at org.testng.TestNG.run(TestNG.java:1000); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:141); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:90); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.base/java.lang.reflect.Method.invoke(Method.java:566); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36); 	at org,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6745:2962,test,testng,2962,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6745,2,['test'],['testng']
Testability,.java:180); 	at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImportIntegrationTest.testCommandIncludedInOutputHeader(GenomicsDBImportIntegrationTest.java:422); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:108); 	at org.testng.internal.Invoker.invokeMethod(Invoker.java:661); 	at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:869); 	at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1193); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:126); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:109); 	at org.testng.TestRunner.privateRun(TestRunner.java:744); 	at org.testng.TestRunner.run(TestRunner.java:602); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:380); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:375); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:340); 	at org.testng.SuiteRunner.run(SuiteRunner.java:289); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1301); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1226); 	at org.testng.TestNG.runSuites(TestNG.java:1144); 	at org.testng.TestNG.run(TestNG.java:1115); 	at org.testng.IDEARemoteTestNG.run(IDEARemoteTestNG.java:72); 	at org.testng.RemoteTestNGStarter.main(RemoteTestNGStarter.java:123); Caused by: com.intel.genomicsdb.GenomicsDBException: Could not load genomicsdb native library; 	at com.intel.genomicsdb.GenomicsDBImporter.<clinit>(GenomicsDBImporter.java:72); 	... 37 more; ```. if you dig into it more you get down to the foll,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4062:2242,Test,TestRunner,2242,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4062,1,['Test'],['TestRunner']
Testability,".java:306). real 481m24.418s; user 581m54.752s; sys 2m49.965s. ```. This run did not complete successfully - the Exception caused it to fail prematurely. . Previously I had seen HaplotypeCaller run out of memory and fail in almost as much time, so I think this and the OOM error are related. The only difference in invocation was that with the OOM failure, I was running with the default for `--max-reads-per-alignment-start` (`50`). This also works just fine with that setting at 15. The failure seems to occur around the same place in the data each time (the end of `chr13`). At that point in the data, there is a very large pileup which is probably instigating this. Additionally, if I remove the `--linked-de-bruijn-graph` argument, this runs just fine with the default setting of `--max-reads-per-alignment-start`. I have a minimally reproductive dataset that I can share which reproduces the OOM error for sure (I'm 99% sure it reproduces this one as well). For the OOM failures, the final logs from HaplotypeCaller look like this:. ```; ./gatk HaplotypeCaller ...; ...; 15:56:23.205 INFO ProgressMeter - Pf3D7_13_v3:2603234 100.5 114070 1134.5; 15:56:33.443 INFO ProgressMeter - Pf3D7_13_v3:2661462 100.7 114420 1136.1; Dangling End recovery killed because of a loop (getReferencePathForwardFromKmer); 15:56:43.998 INFO ProgressMeter - Pf3D7_13_v3:2730055 100.9 114840 1138.3; 15:56:59.911 INFO ProgressMeter - Pf3D7_13_v3:2798281 101.2 115210 1139.0; 15:59:27.062 INFO ProgressMeter - Pf3D7_13_v3:2861780 103.6 115460 1114.4; Dangling End recovery killed because of a loop (getReferencePathForwardFromKmer); Dangling End recovery killed because of a loop (getReferencePathForwardFromKmer); 15:59:37.457 INFO ProgressMeter - Pf3D7_13_v3:2869697 103.8 115500 1112.9. real 671m24.770s; user 777m30.923s; sys 6m13.682s. $ echo $?; 247; ```. Here is my command-line invocation:; ```; ./gatk --java-options ""-Xmx100000m -Xms25000m"" \; HaplotypeCaller \; -R /juffowup2/malaria/references/PlasmoDB-61_",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8440:5050,log,logs,5050,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8440,1,['log'],['logs']
Testability,".java:36); at htsjdk.samtools.AsyncSAMFileWriter.synchronouslyWrite(AsyncSAMFileWriter.java:16); at htsjdk.samtools.util.AbstractAsyncWriter$WriterRunnable.run(AbstractAsyncWriter.java:117); at java.lang.Thread.run(Thread.java:745); Caused by: java.lang.ClassNotFoundException: org.xerial.snappy.LoadSnappy; at java.net.URLClassLoader.findClass(URLClassLoader.java:381); at java.lang.ClassLoader.loadClass(ClassLoader.java:424); at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331); at java.lang.ClassLoader.loadClass(ClassLoader.java:357); ... 11 more. We can find snappy-java in <INST_DIR>/build/install/gatk/lib/snappy-java-1.1.1.7.jar, but it does not have a LoadSnappy class. Renaming the snappy-java jar file so gatk cannot find it allows FastqToSam to run through. ---. @akiezun commented on [Thu Jun 30 2016](https://github.com/broadinstitute/gatk-protected/issues/587#issuecomment-229843043). thanks for the report. Can you provide the whole commandline you used?. ---. @huangk3 commented on [Thu Sep 15 2016](https://github.com/broadinstitute/gatk-protected/issues/587#issuecomment-247467619). Hi @akiezun I experience the same error when running gate-launch FastqToSam. My command line is:; ""./gatk_launch FastqToSam -SM ""test"" -F1 $fq1 -F2 $fq2 -O test.spark.sam -SO coordinate -R $ref --STRIP_UNPAIRED_MATE_NUMBER true --VALIDATION_STRINGENCY LENIENT -PL ILLUMINA --CREATE_INDEX true"". My Spark version is 2.0.0; Thanks!. ---. @lbergelson commented on [Mon Sep 19 2016](https://github.com/broadinstitute/gatk-protected/issues/587#issuecomment-248086238). @huangk3 Unfortunately Adam moved on to a different job so he's longer working on GATK. . I believe this is the same problem as https://github.com/broadinstitute/gatk/issues/2026 and has been patched in gatk public with https://github.com/broadinstitute/gatk/pull/2028. You might try using FastqToSam in the public repo, or wait and try a new version of protected that incorporates an updated gatk public (coming soon..)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2868:2780,test,test,2780,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2868,2,['test'],['test']
Testability,.java:43); at java.lang.reflect.Method.invoke(Method.java:483); at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); at org.testng.internal.Invoker.invokeMethod(Invoker.java:639); at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:821); at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1131); at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); at org.testng.TestRunner.privateRun(TestRunner.java:773); at org.testng.TestRunner.run(TestRunner.java:623); at org.testng.SuiteRunner.runTest(SuiteRunner.java:357); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:352); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:310); at org.testng.SuiteRunner.run(SuiteRunner.java:259); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1185); at org.testng.TestNG.runSuitesLocally(TestNG.java:1110); at org.testng.TestNG.run(TestNG.java:1018); at org.testng.remote.RemoteTestNG.run(RemoteTestNG.java:111); at org.testng.remote.RemoteTestNG.initAndRun(RemoteTestNG.java:204); at org.testng.remote.RemoteTestNG.main(RemoteTestNG.java:175); at org.testng.RemoteTestNGStarter.main(RemoteTestNGStarter.java:125); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:483); at com.intellij.rt.execution.application.AppMain.main(AppMain.java:140); Caused by: java.lang.RuntimeException: java.lang.NoSuchMethodError: com.google.common.base.Stopwatch.createStarted()Lcom/google/common/base/Stopwatch;; at com.google.cloud.dataflow.sdk.Pipeline.run(Pipeline.java:166); at o,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/866:2064,test,testng,2064,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/866,1,['test'],['testng']
Testability,.java:43); at java.lang.reflect.Method.invoke(Method.java:497); at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); at org.testng.internal.Invoker.invokeMethod(Invoker.java:639); at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:821); at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1131); at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); at org.testng.TestRunner.privateRun(TestRunner.java:773); at org.testng.TestRunner.run(TestRunner.java:623); at org.testng.SuiteRunner.runTest(SuiteRunner.java:357); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:352); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:310); at org.testng.SuiteRunner.run(SuiteRunner.java:259); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1185); at org.testng.TestNG.runSuitesLocally(TestNG.java:1110); at org.testng.TestNG.run(TestNG.java:1018); at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:133); at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:83); at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:497); at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35); at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); at org.gradle.messaging.dispatch.ContextClas,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1638:2279,test,testng,2279,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1638,2,['test'],['testng']
Testability,".java:43); at java.lang.reflect.Method.invoke(Method.java:497); at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); at org.testng.internal.Invoker.invokeMethod(Invoker.java:659); at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:845); at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1153); at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:125); at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); at org.testng.TestRunner.privateRun(TestRunner.java:771); at org.testng.TestRunner.run(TestRunner.java:621); at org.testng.SuiteRunner.runTest(SuiteRunner.java:357); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:352); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:310); at org.testng.SuiteRunner.run(SuiteRunner.java:259); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1199); at org.testng.TestNG.runSuitesLocally(TestNG.java:1124); at org.testng.TestNG.run(TestNG.java:1032); at org.testng.remote.RemoteTestNG.run(RemoteTestNG.java:111); at org.testng.remote.RemoteTestNG.initAndRun(RemoteTestNG.java:204); at org.testng.remote.RemoteTestNG.main(RemoteTestNG.java:175); at org.testng.RemoteTestNGStarter.main(RemoteTestNGStarter.java:125); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:497); at com.intellij.rt.execution.application.AppMain.main(AppMain.java:140). Jul 01, 2015 2:33:37 PM org.reflections.Reflections scan; ```. The fact that it doesn't show up for some users means its likely to be an environmental difference, possibly an underspecified dependency. @davidaadams I under",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/609:2646,test,testng,2646,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/609,1,['test'],['testng']
Testability,.java:467); at java.net.URLClassLoader.access$100(URLClassLoader.java:73); at java.net.URLClassLoader$1.run(URLClassLoader.java:368); at java.net.URLClassLoader$1.run(URLClassLoader.java:362); at java.security.AccessController.doPrivileged(Native Method); at java.net.URLClassLoader.findClass(URLClassLoader.java:361); at java.lang.ClassLoader.loadClass(ClassLoader.java:424); at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:349); at java.lang.ClassLoader.loadClass(ClassLoader.java:411); at java.lang.ClassLoader.loadClass(ClassLoader.java:357); at org.apache.logging.log4j.core.config.plugins.util.PluginRegistry.decodeCacheFiles(PluginRegistry.java:181); at org.apache.logging.log4j.core.config.plugins.util.PluginRegistry.loadFromMainClassLoader(PluginRegistry.java:119); at org.apache.logging.log4j.core.config.plugins.util.PluginManager.collectPlugins(PluginManager.java:132); at org.apache.logging.log4j.core.pattern.PatternParser.<init>(PatternParser.java:131); at org.apache.logging.log4j.core.pattern.PatternParser.<init>(PatternParser.java:112); at org.apache.logging.log4j.core.layout.PatternLayout.createPatternParser(PatternLayout.java:220); at org.apache.logging.log4j.core.layout.PatternLayout.<init>(PatternLayout.java:138); at org.apache.logging.log4j.core.layout.PatternLayout.<init>(PatternLayout.java:57); at org.apache.logging.log4j.core.layout.PatternLayout$Builder.build(PatternLayout.java:446); at org.apache.logging.log4j.core.config.AbstractConfiguration.setToDefault(AbstractConfiguration.java:518); at org.apache.logging.log4j.core.config.DefaultConfiguration.<init>(DefaultConfiguration.java:49); at org.apache.logging.log4j.core.LoggerContext.<init>(LoggerContext.java:75); at org.apache.logging.log4j.core.selector.ClassLoaderContextSelector.createContext(ClassLoaderContextSelector.java:171); at org.apache.logging.log4j.core.selector.ClassLoaderContextSelector.locateContext(ClassLoaderContextSelector.java:145); at org.apache.logging.log4j.core.selector,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5126:3698,log,logging,3698,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5126,1,['log'],['logging']
Testability,.java:496); 	at org.testng.Assert.assertEquals(Assert.java:125); 	at org.testng.Assert.assertEquals(Assert.java:372); 	at org.broadinstitute.hellbender.utils.test.IntegrationTestSpec.assertEqualTextFiles(IntegrationTestSpec.java:211); 	at org.broadinstitute.hellbender.utils.test.IntegrationTestSpec.assertEqualTextFiles(IntegrationTestSpec.java:190); 	at org.broadinstitute.hellbender.tools.examples.ExampleAssemblyRegionWalkerSparkIntegrationTest.testExampleAssemblyRegionWalker(ExampleAssemblyRegionWalkerSparkIntegrationTest.java:29); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); 	at org.testng.internal.Invoker.invokeMethod(Invoker.java:639); 	at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:821); 	at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1131); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); 	at org.testng.TestRunner.privateRun(TestRunner.java:773); 	at org.testng.TestRunner.run(TestRunner.java:623); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:357); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:352); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:310); 	at org.testng.SuiteRunner.run(SuiteRunner.java:259); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1185); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1110); 	at org.testng.TestNG.run(TestNG.java:1018); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClas,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2349:4294,test,testng,4294,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2349,1,['test'],['testng']
Testability,".jsp; # The crash happened outside the Java Virtual Machine in native code.; # See problematic frame for where to report the bug.; #; ```. **RELEVANT FILES**; [hs_err_pid100.log](https://github.com/broadinstitute/gatk/files/6203288/hs_err_pid100.log); [hs_err_pid164.log](https://github.com/broadinstitute/gatk/files/6203289/hs_err_pid164.log); [hs_err_pid274.log](https://github.com/broadinstitute/gatk/files/6203290/hs_err_pid274.log); [hs_err_pid400.log](https://github.com/broadinstitute/gatk/files/6203291/hs_err_pid400.log); [hs_err_pid482.log](https://github.com/broadinstitute/gatk/files/6203292/hs_err_pid482.log); [hs_err_pid711.log](https://github.com/broadinstitute/gatk/files/6203293/hs_err_pid711.log); [hs_err_pid735.log](https://github.com/broadinstitute/gatk/files/6203294/hs_err_pid735.log); [hs_err_pid801.log](https://github.com/broadinstitute/gatk/files/6203295/hs_err_pid801.log); [hs_err_pid825.log](https://github.com/broadinstitute/gatk/files/6203296/hs_err_pid825.log); [hs_err_pid849.log](https://github.com/broadinstitute/gatk/files/6203297/hs_err_pid849.log); [otherFiles.zip](https://github.com/broadinstitute/gatk/files/6203305/otherFiles.zip); [in2510-8.orientationFilter.vcf.txt](https://github.com/broadinstitute/gatk/files/6203356/in2510-8.orientationFilter.vcf.txt); *VCF extension appended with .txt to satisfy GitHub's upload requirements*. #### Expected behavior; Worked on 7 other files generated with the same pipeline. . #### Actual behavior; Unsure why this last one is causing a segfault. The VCF included is not the whole VCF submitted originally. I went cutting out lines from the original until I could isolate it down to a minimal set required to reproduce the crash (I included all of the crash logs generated in case it can help). I was expecting to find a single line or maybe two that were required to reproduce this issue, but that range appears to be needed. Eliminating either the first or last line from the range will make the program work agai",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7162:7298,log,log,7298,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7162,1,['log'],['log']
Testability,.lang.ClassLoader.loadClass(ClassLoader.java:411); at java.lang.ClassLoader.loadClass(ClassLoader.java:357); at org.apache.logging.log4j.core.config.plugins.util.PluginRegistry.decodeCacheFiles(PluginRegistry.java:181); at org.apache.logging.log4j.core.config.plugins.util.PluginRegistry.loadFromMainClassLoader(PluginRegistry.java:119); at org.apache.logging.log4j.core.config.plugins.util.PluginManager.collectPlugins(PluginManager.java:132); at org.apache.logging.log4j.core.pattern.PatternParser.<init>(PatternParser.java:131); at org.apache.logging.log4j.core.pattern.PatternParser.<init>(PatternParser.java:112); at org.apache.logging.log4j.core.layout.PatternLayout.createPatternParser(PatternLayout.java:220); at org.apache.logging.log4j.core.layout.PatternLayout.<init>(PatternLayout.java:138); at org.apache.logging.log4j.core.layout.PatternLayout.<init>(PatternLayout.java:57); at org.apache.logging.log4j.core.layout.PatternLayout$Builder.build(PatternLayout.java:446); at org.apache.logging.log4j.core.config.AbstractConfiguration.setToDefault(AbstractConfiguration.java:518); at org.apache.logging.log4j.core.config.DefaultConfiguration.<init>(DefaultConfiguration.java:49); at org.apache.logging.log4j.core.LoggerContext.<init>(LoggerContext.java:75); at org.apache.logging.log4j.core.selector.ClassLoaderContextSelector.createContext(ClassLoaderContextSelector.java:171); at org.apache.logging.log4j.core.selector.ClassLoaderContextSelector.locateContext(ClassLoaderContextSelector.java:145); at org.apache.logging.log4j.core.selector.ClassLoaderContextSelector.getContext(ClassLoaderContextSelector.java:70); at org.apache.logging.log4j.core.selector.ClassLoaderContextSelector.getContext(ClassLoaderContextSelector.java:57); at org.apache.logging.log4j.core.impl.Log4jContextFactory.getContext(Log4jContextFactory.java:140); at org.apache.logging.log4j.core.impl.Log4jContextFactory.getContext(Log4jContextFactory.java:41); at org.apache.logging.log4j.LogManager.getContext(LogManag,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5126:4148,log,logging,4148,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5126,1,['log'],['logging']
Testability,".lifecycle.materialization.MaterializeWorkflowDescriptorActor.aroundReceive(MaterializeWorkflowDescriptorActor.scala:156); 	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:612); 	at akka.actor.ActorCell.invoke(ActorCell.scala:581); 	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:268); 	at akka.dispatch.Mailbox.run(Mailbox.scala:229); 	at akka.dispatch.Mailbox.exec(Mailbox.scala:241); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107). [2019-10-01 02:53:03,81] [info] WorkflowManagerActor WorkflowActor-c55a06f3-abc1-4db1-8e0f-ea0303caab2c is in a terminal state: WorkflowFailedState; [2019-10-01 02:53:07,42] [info] Not triggering log of token queue status. Effective log interval = None; [2019-10-01 02:53:08,41] [info] SingleWorkflowRunnerActor workflow finished with status 'Failed'.; [2019-10-01 02:53:12,32] [info] Workflow polling stopped; [2019-10-01 02:53:12,33] [info] 0 workflows released by cromid-876ccf5; [2019-10-01 02:53:12,34] [info] Shutting down WorkflowStoreActor - Timeout = 5 seconds; [2019-10-01 02:53:12,34] [info] Shutting down WorkflowLogCopyRouter - Timeout = 5 seconds; [2019-10-01 02:53:12,34] [info] Shutting down JobExecutionTokenDispenser - Timeout = 5 seconds; [2019-10-01 02:53:12,34] [info] Aborting all running workflows.; [2019-10-01 02:53:12,34] [info] JobExecutionTokenDispenser stopped; [2019-10-01 02:53:12,35] [info] WorkflowStoreActor stopped; [2019-10-01 02:53:12,35] [info] WorkflowLogCopyRouter stopped; [2019-10-01 02:53:12,35] [info] Shutting down WorkflowManagerActor - Timeout = 3600 seconds; [2019-10-01 02:53:12,35] [info] WorkflowManagerActor All workflows finished; [2019-10-01 02:53:12,35] [info] WorkflowManagerActor stopped; [2019-10-01 02:53:12,65] [info] Connectio",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6189:9142,log,log,9142,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6189,1,['log'],['log']
Testability,.originalQuals.chr1.1-1K.bam.QT_10_CT_15_X_CCCCC.bai; src/test/resources/org/broadinstitute/hellbender/tools/expected.originalQuals.chr1.1-1K.bam.QT_10_CT_15_X_CCCCC.bam; src/test/resources/org/broadinstitute/hellbender/tools/expected.originalQuals.chr1.1-1K.bam.QT_10_CT_15_X_CCCCC.tmp; src/test/resources/org/broadinstitute/hellbender/tools/FixCallSetSampleOrdering/badlySorted1000-batch-size13.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/flag_stat.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/flag_stat.fasta; src/test/resources/org/broadinstitute/hellbender/tools/genome/HCC1143_chr22_27M_37M.tiny.bam; src/test/resources/org/broadinstitute/hellbender/tools/genome/HCC1143_chr22_27M_37M.tiny.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/genome/HCC1143_chr3_1K_11K.tiny.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/GenomicsDBImport/testHeaderContigLineSorting1.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/GenomicsDBImport/testHeaderContigLineSorting2.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/haplotypecaller/expected.testGVCFMode.3.8-4-g7b0250253f.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/haplotypecaller/expected.testGVCFMode.gatk3.5.alleleSpecific.g.vcf; src/test/resources/org/broadinstitute/hellbender/tools/haplotypecaller/expected.testGVCFMode.gatk3.5.g.vcf; src/test/resources/org/broadinstitute/hellbender/tools/haplotypecaller/expected.testGVCFMode.gatk3.8-4-g7b0250253f.alleleSpecific.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/haplotypecaller/expected.testVCFMode.gatk3.5.alleleSpecific.vcf; src/test/resources/org/broadinstitute/hellbender/tools/haplotypecaller/expected.testVCFMode.gatk3.5.vcf; src/test/resources/org/broadinstitute/hellbender/tools/haplotypecaller/expected.testVCFMode.gatk3.8-4-g7b0250253f.alleleSpecific.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/haplotypecaller/expected,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3905:36767,test,test,36767,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905,1,['test'],['test']
Testability,.piece.table.gz; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.noMD.noBQSR.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.noMD.noBQSR.cram.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.noMD.noBQSR.md.bqsr.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.ch20.4379150-4379157.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.10m-10m100.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.10m-10m100.cram.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_132.b36.excluding_sites_after_129.chr1_1k.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_132.b37.excluding_sites_after_129.chr17_69k_70k.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_138.b37.20.10m-10m100.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_138.b37.21.10m-10m100.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_138.b37.excluding_sites_after_129.ch20.1m-1m1k.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.noMD.noBQSR.md.bqsr.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.postRecalibrated.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.recalibrated.DIQ.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m20k.NA12878.2inputs.recal.txt; src/test/resources/org/broadinstitute/hellbender/,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3905:19024,test,test,19024,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905,1,['test'],['test']
Testability,.recal.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m20k.NA12878.indels_context_size_4.recal.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m20k.NA12878.low_quality_tail_5.recal.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m20k.NA12878.mismatches_context_size_4.recal.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m20k.NA12878.quantizing_levels_6.recal.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m20k.NA12878.recal.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.HiSeq.1mb.1RG.2k_lines.alternate.recalibrated.DIQ.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.HiSeq.1mb.1RG.2k_lines.bqsr.qq-1.alternate.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.HiSeq.1mb.1RG.2k_lines.bqsr.qq6.alternate.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.MultiSite.reads.pipeline.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.MultiSite.reads.pipeline.cram.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/HiSeq.1mb.1RG.2k_lines.alternate_allaligned.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/HiSeq.1mb.1RG.2k_lines.alternate.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/HiSeq.1mb.1RG.2k_lines.alternate.recalibrated.DIQ.sharded.bam/part-r-00001.bam; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/HiSeq.1mb.1RG.2k_lines.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/human_b36_both.chr1_1k.dict; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/human_b36_both.chr1_1k.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/NA12878.chr17_69k_7,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3905:20964,test,test,20964,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905,1,['test'],['test']
Testability,".reflect.Method.invoke(Method.java:497); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:108); 	at org.testng.internal.Invoker.invokeMethod(Invoker.java:661); 	at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:869); 	at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1193); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:126); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:109); 	at org.testng.TestRunner.privateRun(TestRunner.java:744); 	at org.testng.TestRunner.run(TestRunner.java:602); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:380); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:375); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:340); 	at org.testng.SuiteRunner.run(SuiteRunner.java:289); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1301); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1226); 	at org.testng.TestNG.runSuites(TestNG.java:1144); 	at org.testng.TestNG.run(TestNG.java:1115); 	at org.testng.IDEARemoteTestNG.run(IDEARemoteTestNG.java:72); 	at org.testng.RemoteTestNGStarter.main(RemoteTestNGStarter.java:123); ```. #### Steps to reproduce; These are the arguments I used (the input bam is on the file system):. ```; final String[] args = {; ""-I"", ""/humgen/gsa-hpprojects/dev/mshand/SpecOps/Mitochondria/Filtering/IGV/198489_vs_811158/sorted.mt.1.bam"",; ""-"" + M2ArgumentCollection.TUMOR_SAMPLE_SHORT_NAME, ""198489"",; ""-R"", ""/humgen/gsa-hpprojects/dev/mshand/SpecOps/Mitochondria/MitochondriaOnlyFastas/Homo_sapiens_assembly38.mt_only.fasta"",; ""-O"", outputVcf.getAbsolutePath(),; ""--max-reads-per-alignment-start"", ""0"",; ""-default-af"", ""0"",; ""--initial-tumor-lod"", ""0"",; ""--tumor-lod-to-emit"", ""0"",; ""--min-pruning"", ""10"",; ""--annotation"", ""StrandBiasBySample"",; //""--ignore-itr-a",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5036:4396,Test,TestNG,4396,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5036,1,['Test'],['TestNG']
Testability,.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:108); 	at org.testng.internal.Invoker.invokeMethod(Invoker.java:661); 	at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:869); 	at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1193); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:126); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:109); 	at org.testng.TestRunner.privateRun(TestRunner.java:744); 	at org.testng.TestRunner.run(TestRunner.java:602); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:380); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:375); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:340); 	at org.testng.SuiteRunner.run(SuiteRunner.java:289); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1301); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1226); 	at org.testng.TestNG.runSuites(TestNG.java:1144); 	at org.testng.TestNG.run(TestNG.java:1115); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:129); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:88); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.j,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2797:2177,Test,TestNG,2177,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2797,3,['Test'],['TestNG']
Testability,".reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:108); 	at org.testng.internal.Invoker.invokeMethod(Invoker.java:661); 	at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:869); 	at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1193); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:126); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:109); 	at org.testng.TestRunner.privateRun(TestRunner.java:744); 	at org.testng.TestRunner.run(TestRunner.java:602); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:380); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:375); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:340); 	at org.testng.SuiteRunner.run(SuiteRunner.java:289); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1301); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1226); 	at org.testng.TestNG.runSuites(TestNG.java:1144); 	at org.testng.TestNG.run(TestNG.java:1115); 	at org.testng.IDEARemoteTestNG.run(IDEARemoteTestNG.java:72); 	at org.testng.RemoteTestNGStarter.main(RemoteTestNGStarter.java:123); Caused by: com.intel.genomicsdb.GenomicsDBException: Could not load genomicsdb native library; 	at com.intel.genomicsdb.GenomicsDBImporter.<clinit>(GenomicsDBImporter.java:72); 	... 37 more; ```. if you dig into it more you get down to the following error:; ```; /private/var/folders/xt/vq7wz8955r1401mv8w0f4zf9qbfwzl/T/libtiledbgenomicsdb6159269479234619546.dylib: dlopen(/private/var/folders/xt/vq7wz8955r1401mv8w0f4zf9qbfwzl/T/libtiledbgenomicsdb6159269479234619546.dylib, 1): ; Library not loaded: /opt/local/lib/libuuid.16.dylib; Referenced from: /private/var/folders/xt/vq7wz8955r1401mv8w0f4zf9qbfwzl/T/libtiledbgenomicsdb6159269479234619546.dylib; Reason: image",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4062:2668,Test,TestNG,2668,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4062,1,['Test'],['TestNG']
Testability,".setPosition(SAMRecordToGATKReadAdapter.java:89); at org.broadinstitute.hellbender.utils.clipping.ClippingOp.applyHARDCLIP_BASES(ClippingOp.java:381); at org.broadinstitute.hellbender.utils.clipping.ClippingOp.apply(ClippingOp.java:73); at org.broadinstitute.hellbender.utils.clipping.ReadClipper.clipRead(ReadClipper.java:147); at org.broadinstitute.hellbender.utils.clipping.ReadClipper.clipRead(ReadClipper.java:128); at org.broadinstitute.hellbender.utils.clipping.ReadClipper.hardClipSoftClippedBases(ReadClipper.java:332); at org.broadinstitute.hellbender.utils.clipping.ReadClipper.hardClipSoftClippedBases(ReadClipper.java:335); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.AssemblyBasedCallerUtils.finalizeRegion(AssemblyBasedCallerUtils.java:84); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.AssemblyBasedCallerUtils.assembleReads(AssemblyBasedCallerUtils.java:238); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerEngine.callRegion(HaplotypeCallerEngine.java:478); at org.broadinstitute.hellbender.tools.HaplotypeCallerSpark.lambda$regionToVariants$580(HaplotypeCallerSpark.java:203) ; ```. At first glance this looks like a problem with unmapped reads, but these are filtered out by the tool. So it's more likely to be in the clipping logic. It's hard to diagnose since it doesn't say which read caused it, and it's slow to reproduce as it is running on a large input. Any thoughts @lbergelson, @droazen?. ---. @lbergelson commented on [Sat May 27 2017](https://github.com/broadinstitute/gatk-protected/issues/1091#issuecomment-304466112). @tomwhite Is it possible you could upload the bam file somewhere on google cloud along with the command line you used? It's not obvious to me where the error is being caused. It's painful to debug anything on a 160GB file, but I think we can probably do a binary search on the file and find the bad location pretty quickly. I.e. throw compute at the problem instead of human time...",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3013:1632,log,logic,1632,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3013,1,['log'],['logic']
Testability,.sites.1M-10M.vcf.idx; src/test/resources/large/VQSR/dbsnp_132_b37.leftAligned.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/expected/snpRecal.scattered.vcf.idx; src/test/resources/large/VQSR/expected/snpSampledRecal.vcf.idx; src/test/resources/large/VQSR/indelRecal.vcf.idx; src/test/resources/large/VQSR/Omni25_sites_1525_samples.b37.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/phase1.projectConsensus.chr20.1M-10M.raw.snps.vcf.idx; src/test/resources/large/VQSR/sites_r27_nr.b37_fwd.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/snpRecal.vcf.idx; src/test/resources/NA12878.chr17_69k_70k.dictFix.bam.bai; src/test/resources/NA12878.chr17_69k_70k.dictFix.cram.crai; src/test/resources/org/broadinstitute/hellbender/engine/ambiguityCodes.dict; src/test/resources/org/broadinstitute/hellbender/engine/ambiguityCodes.fasta.fai; src/test/resources/org/broadinstitute/hellbender/engine/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.10000000-10000020.with.unmapped.bam.bai; src/test/resources/org/broadinstitute/hellbender/engine/CEUTrio.HiSeq.WGS.b37.NA12878.snippet_with_unmapped.bam.bai; src/test/resources/org/broadinstitute/hellbender/engine/CEUTrio.HiSeq.WGS.b37.NA12878.snippet_with_unmapped.cram.crai; src/test/resources/org/broadinstitute/hellbender/engine/cramtestWrongRef.dict; src/test/resources/org/broadinstitute/hellbender/engine/cramtestWrongRef.fasta.fai; src/test/resources/org/broadinstitute/hellbender/engine/cram_with_bai_index.cram.bai; src/test/resources/org/broadinstitute/hellbender/engine/cram_with_crai_index.cram.crai; src/test/resources/org/broadinstitute/hellbender/engine/example_features.bed.idx; src/test/resources/org/broadinstitute/hellbender/engine/example_variants_noSequenceDict.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/example_variants_withSequenceDict.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/feature_data_source_test_gvcf.vcf.idx; src/test/resources/org/broadinstitute/hellbender/engine/feature_data_source_test.vcf,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3905:8225,test,test,8225,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905,1,['test'],['test']
Testability,".snappy' to force htsjdk to fallback to pure java. Longer term solution likely involves patches to htsjdk and possibly snappy itself. ```; ./gatk-launch SplitNCigarReads -I src/test/resources/large/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.bam -O out.bam -R src/test/resources/large/human_g1k_v37.20.21.fasta. Running:; /Users/louisb/Workspace/gatk/build/install/gatk/bin/gatk SplitNCigarReads -I src/test/resources/large/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.bam -O out.bam -R src/test/resources/large/human_g1k_v37.20.21.fasta; 15:31:00.516 INFO IntelGKLUtils - Trying to load Intel GKL library from:; jar:file:/Users/louisb/Workspace/gatk/build/install/gatk/lib/gkl-0.1.2.jar!/com/intel/gkl/native/libIntelGKL.dylib; 15:31:00.552 INFO IntelGKLUtils - Intel GKL library loaded from classpath.; [July 20, 2016 3:31:00 PM EDT] org.broadinstitute.hellbender.tools.walkers.rnaseq.SplitNCigarReads --output out.bam --input src/test/resources/large/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.bam --reference src/test/resources/large/human_g1k_v37.20.21.fasta --refactor_NDN_cigar_string false --maxReadsInMemory 150000 --maxMismatchesInOverhang 1 --maxBasesInOverhang 40 --doNotFixOverhangs false --disable_all_read_filters false --interval_set_rule UNION --interval_padding 0 --readValidationStringency SILENT --secondsBetweenProgressUpdates 10.0 --disableSequenceDictionaryValidation false --createOutputBamIndex true --createOutputBamMD5 false --addOutputSAMProgramRecord true --help false --version false --verbosity INFO --QUIET false --use_jdk_deflater false; [July 20, 2016 3:31:00 PM EDT] Executing as louisb@wm1b0-8ab on Mac OS X 10.10.5 x86_64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_91-b14; Version: Version:4.alpha.1-217-g3ff51ed-SNAPSHOT; 15:31:00.557 INFO SplitNCigarReads - Defaults.BUFFER_SIZE : 131072; 15:31:00.557 INFO SplitNCigarReads - Defaults.COMPRESSION_LEVEL : 1; 15:31:00.557 INFO SplitNCigarReads - Defaults.CREATE_INDEX : false; 15:31:00.557 INFO SplitNCigarReads - Defaults.CREATE_MD5 : fal",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2026:1155,test,test,1155,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2026,1,['test'],['test']
Testability,.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1348); 	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13.apply(PairRDDFunctions.scala:1211); 	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13.apply(PairRDDFunctions.scala:1190); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); 	at org.apache.spark.scheduler.Task.run(Task.scala:86); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745). **This is the stack I get when the test completes but fails (note that the expected line count appears to not match the line count of the expected output file in the repo): **. java.lang.AssertionError: line counts expected [2629] but found [507]; 	at org.testng.Assert.fail(Assert.java:94); 	at org.testng.Assert.failNotEquals(Assert.java:496); 	at org.testng.Assert.assertEquals(Assert.java:125); 	at org.testng.Assert.assertEquals(Assert.java:372); 	at org.broadinstitute.hellbender.utils.test.IntegrationTestSpec.assertEqualTextFiles(IntegrationTestSpec.java:211); 	at org.broadinstitute.hellbender.utils.test.IntegrationTestSpec.assertEqualTextFiles(IntegrationTestSpec.java:190); 	at org.broadinstitute.hellbender.tools.examples.ExampleAssemblyRegionWalkerSparkIntegrationTest.testExampleAssemblyRegionWalker(ExampleAssemblyRegionWalkerSparkIntegrationTest.java:29); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); 	at org.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2349:3226,Assert,Assert,3226,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2349,1,['Assert'],['Assert']
Testability,.splitNcigarReads.doNotFixOverhangs.bai; src/test/resources/large/expected.NA12878.RNAseq.splitNcigarReads.maxBasesInOverhang5.bai; src/test/resources/large/expected.NA12878.RNAseq.splitNcigarReads.maxMismatchesInOverhang0.bai; src/test/resources/large/gencode.v19.LargeFile.gtf.idx; src/test/resources/large/gencode.v26.primary_assembly.annotation.XYZ.gtf.idx; src/test/resources/large/gvcfs/CEUTrio.20.21.gatk3.4.g.vcf.idx; src/test/resources/large/gvcfs/combined.gatk3.7_30_ga4f720357.g.vcf.gz.tbi; src/test/resources/large/gvcfs/combined.gatk3.7.g.vcf.gz.tbi; src/test/resources/large/gvcfs/gatk3.7_30_ga4f720357.24_sample.21.g.vcf.idx; src/test/resources/large/gvcfs/HG00096.g.vcf.gz.tbi; src/test/resources/large/gvcfs/HG00268.g.vcf.gz.tbi; src/test/resources/large/gvcfs/NA19625.g.vcf.gz.tbi; src/test/resources/large/Homo_sapiens_assembly38.20.21.dict; src/test/resources/large/Homo_sapiens_assembly38.20.21.fasta.fai; src/test/resources/large/human_g1k_v37.20.21.fasta.amb; src/test/resources/large/human_g1k_v37.20.21.fasta.ann; src/test/resources/large/human_g1k_v37.20.21.fasta.bwt; src/test/resources/large/human_g1k_v37.20.21.fasta.pac; src/test/resources/large/human_g1k_v37.20.21.fasta.sa; src/test/resources/large/K-562.duplicateMarked.chr20.bai; src/test/resources/large/mutect/dream_synthetic_bams/normal_3.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/normal_4.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/normal.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/tumor_3.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/tumor_4.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/tumor.bam.bai; src/test/resources/large/NA12878.RNAseq.bai; src/test/resources/large/SVIntegrationTest.bam.bai; src/test/resources/large/very-small-gnomad.vcf.idx; src/test/resources/large/VQSR/ALL.wgs.indels_mills_devine_hg19_leftAligned_collapsed_double_hit.sites.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/combined.phase1.c,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3905:6213,test,test,6213,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905,1,['test'],['test']
Testability,.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:103); 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:827); 	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:65); 	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98); 	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:94); 	at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:512); 	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:104); 	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:512); 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:31); 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267); 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263); 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:31); 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:31); 	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:488); 	at org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:94); 	at org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:81); 	at org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:79); 	at org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:133); 	at org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:856); 	at org.apache.spark.sql.DataFrameWriter,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8587:5725,log,logical,5725,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8587,2,['log'],['logical']
Testability,.testExclusionListOverridesManualDefaultAnnotations(VcfOutputRendererUnitTest.java:40); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:133); 	at org.testng.internal.TestInvoker.invokeMethod(TestInvoker.java:584); 	at org.testng.internal.TestInvoker.invokeTestMethod(TestInvoker.java:172); 	at org.testng.internal.MethodRunner.runInSequence(MethodRunner.java:46); 	at org.testng.internal.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:804); 	at org.testng.internal.TestInvoker.invokeTestMethods(TestInvoker.java:145); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:128); 	at java.util.ArrayList.forEach(ArrayList.java:1257); 	at org.testng.TestRunner.privateRun(TestRunner.java:770); 	at org.testng.TestRunner.run(TestRunner.java:591); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:402); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:396); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:355); 	at org.testng.SuiteRunner.run(SuiteRunner.java:304); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:53); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:96); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1180); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1102); 	at org.testng.TestNG.runSuites(TestNG.java:1032); 	at org.testng.TestNG.run(TestNG.java:1000); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:141); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6748:2804,Test,TestMethodWorker,2804,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6748,1,['Test'],['TestMethodWorker']
Testability,.testng.internal.Invoker.invokeTestMethod(Invoker.java:821); at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1131); at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); at org.testng.TestRunner.privateRun(TestRunner.java:773); at org.testng.TestRunner.run(TestRunner.java:623); at org.testng.SuiteRunner.runTest(SuiteRunner.java:357); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:352); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:310); at org.testng.SuiteRunner.run(SuiteRunner.java:259); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1185); at org.testng.TestNG.runSuitesLocally(TestNG.java:1110); at org.testng.TestNG.run(TestNG.java:1018); at org.testng.remote.RemoteTestNG.run(RemoteTestNG.java:111); at org.testng.remote.RemoteTestNG.initAndRun(RemoteTestNG.java:204); at org.testng.remote.RemoteTestNG.main(RemoteTestNG.java:175); at org.testng.RemoteTestNGStarter.main(RemoteTestNGStarter.java:125); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:483); at com.intellij.rt.execution.application.AppMain.main(AppMain.java:140); Caused by: java.lang.RuntimeException: java.lang.NoSuchMethodError: com.google.common.base.Stopwatch.createStarted()Lcom/google/common/base/Stopwatch;; at com.google.cloud.dataflow.sdk.Pipeline.run(Pipeline.java:166); at org.broadinstitute.hellbender.engine.dataflow.DataflowCommandLineProgram.runPipeline(DataflowCommandLineProgram.java:145); at org.broadinstitute.hellbender.engine.dataflow.DataflowCommandLineProgram.doWork(DataflowCommandLineP,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/866:2289,test,testng,2289,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/866,1,['test'],['testng']
Testability,.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:128); 	at java.util.ArrayList.forEach(ArrayList.java:1257); 	at org.testng.TestRunner.privateRun(TestRunner.java:770); 	at org.testng.TestRunner.run(TestRunner.java:591); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:402); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:396); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:355); 	at org.testng.SuiteRunner.run(SuiteRunner.java:304); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:53); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:96); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1180); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1102); 	at org.testng.TestNG.runSuites(TestNG.java:1032); 	at org.testng.TestNG.run(TestNG.java:1000); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:141); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:90); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:33); 	at org.gradle.internal.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:94); 	at com.sun.proxy.$Proxy2.stop(Unknown Source); 	at o,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6748:3671,Test,TestNGTestClassProcessor,3671,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6748,2,['Test'],['TestNGTestClassProcessor']
Testability,.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/ice_trunc_rcc.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/ice_trunc_sex_genotypes.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/ice_trunc_targets_some_missing.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/ice_trunc_targets.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/ice_trunc_targets_with_bait_counts.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/sex_genotyper_agilent_targets_trunc.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/sex_genotypes_broadies_basic.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/sex_genotypes_broadies_extended.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/snps-basic-with-phase-posteriors.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/snps-full-with-phase-posteriors.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/snps-intermediate-with-phase-posteriors.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/snps-simplified-for-allelic-fraction-transformation.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/test_reference.dict; src/test/resources/org/broadinstitute/hellbender/tools/exome/test_reference.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/expected.originalQuals.chr1.1-1K.bam.QT_10_CT_15_X_CCCCC.bai; src/test/resources/org/broadinstitute/hellbender/tools/expected.originalQuals.chr1.1-1K.bam.QT_10_CT_15_X_CCCCC.bam; src/test/resources/org/broadinstitute/hellbender/tools/expected.originalQuals.chr1.1-1K.bam.QT_10_CT_15_X_CCCCC.tmp; src/test/resources/org/broadinstitute/hellbender/tools/FixCallSetSampleOrdering/badlySorted1000-batch-size13.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/flag_stat.bam.bai; src/test/r,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3905:35261,test,test,35261,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905,1,['test'],['test']
Testability,.utils.runtime.AsynchronousStreamWriterServiceUnitTest.testAsyncWriteInBatches(AsynchronousStreamWriterServiceUnitTest.java:35); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:108); 	at org.testng.internal.Invoker.invokeMethod(Invoker.java:661); 	at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:869); 	at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1193); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:126); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:109); 	at org.testng.TestRunner.privateRun(TestRunner.java:744); 	at org.testng.TestRunner.run(TestRunner.java:602); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:380); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:375); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:340); 	at org.testng.SuiteRunner.run(SuiteRunner.java:289); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1301); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1226); 	at org.testng.TestNG.runSuites(TestNG.java:1144); 	at org.testng.TestNG.run(TestNG.java:1115); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:129); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:88); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.Na,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4024:1504,test,testng,1504,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4024,1,['test'],['testng']
Testability,".vcf \\ ; ;   -L 0005-scattered.interval\_list \\ ; ;   -bamout results/wesep-229191-f.variants.bam \\ ; ;   -G StandardAnnotation -G StandardHCAnnotation \\ ; ;   --dragen-mode \\ ; ;   --dragstr-params-path /home/gvandeweyer/elprep\_streaming/results/wesep-229191-f.bam.params \\ ; ;   --native-pair-hmm-threads 2.   ; ; c) Entire program log:. (ELPREP) gvandeweyer@ngsvm-pipelines:~/elprep\_streaming/VariantCalling\_Test/scattered$ gatk --java-options ""-Djava.io.tmpdir=/tmp -Xmx3g"" HaplotypeCaller    -R /home/gvandeweyer/elprep\_streaming/reference/hg19.fasta    -I /home/gvandeweyer/elprep\_streaming/results/wesep- ; ; 229191-f.bam    -O results/wesep-229191-f.vcf    --alleles ../wesid-226998-m.haplotypecaller.final.vcf.gz -L 0005-scattered.interval\_list    -bamout results/wesep-229191-f.variants.bam    -G StandardAnnotation -G StandardHCAnnotation    --dragen-mode    --dragstr-params- ; ; path /home/gvandeweyer/elprep\_streaming/results/wesep-229191-f.bam.params 2>&1 | tee Runtime.log.txt ; ; Using GATK jar /home/gvandeweyer/miniconda3/envs/ELPREP/share/gatk4-4.2.5.0-0/gatk-package-4.2.5.0-local.jar ; ; Running: ; ;    java -Dsamjdk.use\_async\_io\_read\_samtools=false -Dsamjdk.use\_async\_io\_write\_samtools=true -Dsamjdk.use\_async\_io\_write\_tribble=false -Dsamjdk.compression\_level=2 -Djava.io.tmpdir=/tmp -Xmx3g -jar /home/gvandeweyer/miniconda3/envs/ELPREP/share/gatk4-4.2.5.0-0/gatk-packa ; ; ge-4.2.5.0-local.jar HaplotypeCaller -R /home/gvandeweyer/elprep\_streaming/reference/hg19.fasta -I /home/gvandeweyer/elprep\_streaming/results/wesep-229191-f.bam -O results/wesep-229191-f.vcf --alleles ../wesid-226998-m.haplotypecaller.final.vcf.gz -L 0005-scattered.inter ; ; val\_list -bamout results/wesep-229191-f.variants.bam -G StandardAnnotation -G StandardHCAnnotation --dragen-mode --dragstr-params-path /home/gvandeweyer/elprep\_streaming/results/wesep-229191-f.bam.params ; ; 22:06:39.332 WARN  GATKAnnotationPluginDescriptor - Redundant enabled annotation group (",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7741:3167,log,log,3167,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7741,1,['log'],['log']
Testability,.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/filters/VariantFiltration/expected/testVariantFiltration_testGenotypeFilters1.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/filters/VariantFiltration/expected/testVariantFiltration_testGenotypeFilters2.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/filters/VariantFiltration/expected/testVariantFiltration_testInvertFilter.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/filters/VariantFiltration/expected/testVariantFiltration_testInvertGenotypeFilterExpression.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/filters/VariantFiltration/expected/testVariantFiltration_testInvertJexlFilter.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/filters/VariantFiltration/expected/testVariantFiltration_testInvertJexlGenotypeFilterExpression.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/filters/VariantFiltration/expected/testVariantFiltration_testMask1.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/filters/VariantFiltration/expected/testVariantFiltration_testMask2.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/filters/VariantFiltration/expected/testVariantFiltration_testMask3.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/filters/VariantFiltration/expected/testVariantFiltration_testMaskReversed.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/filters/VariantFiltration/expected/testVariantFiltration_testNoAction.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/filters/VariantFiltration/expected/testVariantFiltration_testSetFilteredGtoNocall.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/filters/VariantFiltration/expected/testVariantFiltration_testSetVcfFilteredGtoNocall.vcf.idx; src/test/resources/org/broadinstitute/hellbende,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3905:54079,test,test,54079,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905,1,['test'],['test']
Testability,"//github.com/broadinstitute/hellbender/blob/c6b41e6da8c9ea3f03206a25ce4ad74312b154f0/src/test/java/org/broadinstitute/gatk/CommandLineProgramTest.java). I'm assuming this is because we have not settled on a way to `Assert` that outputs are similar after running a hellbender command line. This issue should resolve with a definition how far one should test before a pull request is accepted. After an arbitrary low level patch to the codebase, I believe the GATK [`MD5DB`](https://github.com/broadgsa/gatk/blob/3b67b448072e24c80779b2e1cbc9dcfcb5dce4cf/public/gatk-tools-public/src/test/java/org/broadinstitute/gatk/utils/MD5DB.java) and [`DiffEngine`](https://github.com/broadgsa/gatk/blob/3b67b448072e24c80779b2e1cbc9dcfcb5dce4cf/public/gatk-tools-public/src/main/java/org/broadinstitute/gatk/engine/walkers/diffengine/DiffEngine.java) are considered too hard to verify-and-update en masse. This limitation would also apply to external framework test utilities, such as TestNG's `FileAssert.assertLength()`. A 2009 discussion of file comparators is archived [here](http://stackoverflow.com/questions/466841/comparing-text-files-w-junit). Ultimately, I believe the biggest pain point with the `MD5DB` is that there does not exist a quick way to a) diagnose what has changed and b) to then update all hundreds of expected outputs. As in `DiffEngine`, we could define a way to regression test that only certain aspects of common file types aren't changing (exact number of reads in BAMs, or exact number of variants in BCF), or that values are falling within a certain range (number of quality scores all above 30 under 60), etc. As for updating results, instead of embedding the expected `MD5DB` outputs in a hundreds of java test files, one could also externalize _all_ of the expected outputs to another file (json, flat text, etc.) such that this singular sorted file for the entire test suite may be updated once. Or, we can decide that none of this is required at all and just delete `CommandLine",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/69:1082,assert,assertLength,1082,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/69,1,['assert'],['assertLength']
Testability,"/15305869/37785631-078c3fa8-2dd1-11e8-8bd1-3e8b1da36c8b.png); ![image](https://user-images.githubusercontent.com/15305869/37785638-0bc9f48e-2dd1-11e8-9aa1-47c77a5625aa.png); ![image](https://user-images.githubusercontent.com/15305869/37785656-19976c68-2dd1-11e8-802e-1893eb37cdd7.png); ![image](https://user-images.githubusercontent.com/15305869/37785664-1dcafa48-2dd1-11e8-832e-9d5fa0529653.png); ![image](https://user-images.githubusercontent.com/15305869/37785674-24d8d3dc-2dd1-11e8-8359-5dd266ca3947.png). Clearly, there is a strong correlation here. In particular, low mappability bins show two distinct modes: a mode at the coverage mode (~ 100 fragments/bin), and a mode that bifurcates to lower values. **I conjecture that the bimodality results from heterogeneity of mappability scores at different positions in the same bin. The bins are 1k wide and it is feasible that some positions are highly mappable and other positions are not. This conjecture can be tested by collecting coverage on smaller bins and to check whether the bimodality weakens. If it does, I suggest filtering based on read position, similar to Genome STRiP, as opposed to filtering bins.**. Also, there is little sample-to-sample variation in coverage-mappability scatter plots (as opposed to, let's say, GC). **Therefore, there is no reason to consider mappability as a bias covariate**. The mappability coverage bias can be captured by a cohort-wide mean bias. Finally, let us study the NB overdispersion of different samples for different contigs:; ![image](https://user-images.githubusercontent.com/15305869/37785938-c47b4e38-2dd1-11e8-85f5-6e82764afbde.png). There's a clear structure here: some samples have higher overdispersion than the others. This could be due to degraded samples, less even GC curve, different chemistry, etc. In any event, we can regress the residual variance $psi_sj$ (for sample s, contig j) with a linear model:. psi_sj ~ N(a_s * psi_j + b_s, \beta). Here's how the regression looks like",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4558:3245,test,tested,3245,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4558,1,['test'],['tested']
Testability,/BQSR/expected.HiSeq.1mb.1RG.2k_lines.alternate.recalibrated.DIQ.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.HiSeq.1mb.1RG.2k_lines.bqsr.qq-1.alternate.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.HiSeq.1mb.1RG.2k_lines.bqsr.qq6.alternate.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.MultiSite.reads.pipeline.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.MultiSite.reads.pipeline.cram.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/HiSeq.1mb.1RG.2k_lines.alternate_allaligned.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/HiSeq.1mb.1RG.2k_lines.alternate.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/HiSeq.1mb.1RG.2k_lines.alternate.recalibrated.DIQ.sharded.bam/part-r-00001.bam; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/HiSeq.1mb.1RG.2k_lines.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/human_b36_both.chr1_1k.dict; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/human_b36_both.chr1_1k.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/NA12878.chr17_69k_70k.dictFix.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/NA12878.oq.read_consumes_zero_ref_bases.chr20.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/na.bam; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/na.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/originalQuals.1kg.chr1.1-1K.1RG.dictFix.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/overlappingRead.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/solid.bam; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/solid.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/clippingReadsTest.withRG.hg19.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3905:21734,test,test,21734,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905,1,['test'],['test']
Testability,/CollectBaseDistributionByCycle/valid.dict; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectBaseDistributionByCycle/valid.fasta.fai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectQualityYieldMetrics/collect_quality_yield_metrics.bam; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectQualityYieldMetrics/collect_quality_yield_metrics.cram; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectQualityYieldMetrics/valid.cram.crai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectQualityYieldMetrics/valid.dict; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectQualityYieldMetrics/valid.fasta.fai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/MeanQualityByCycle/example_pfFail_reads.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/MeanQualityByCycle/first5000a.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/MeanQualityByCycle/unmapped.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/QualityScoreDistribution/example_pfFail_reads.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/QualityScoreDistribution/first5000a.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/QualityScoreDistribution/originalQuals.chr1.1-1K.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/QualityScoreDistribution/unmapped.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/add_comments_to_bam.bam; src/test/resources/org/broadinstitute/hellbender/tools/add_comments_to_bam.sam; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.2.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.3.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.4,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3905:15603,test,test,15603,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905,1,['test'],['test']
Testability,/NA12891.AS.chr20snippet.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/annotator/allelespecific/NA12892.AS.chr20snippet.g.unsorted.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/annotator/allelespecific/NA12892.AS.chr20snippet.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/annotator/allelespecific/NA12892.AS.InsertSizeRankSum.chr20snippet.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/annotator/allelespecific/NA12892.AS.MateRankSum.chr20snippet.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/annotator/allelespecific/NA12892.AS.MateRankSum.chr20snippet.withoutIndex.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/annotator/VariantAnnotatorEngine/one_entry_source.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/combine-gvcf-wrong-ref-input1.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/combine-gvcf-wrong-ref-input2.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/convertToBasePairResolution.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/gvcf.basepairResolution.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/gvcfExample1.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/gvcfExample2.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/IntervalTest.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/NA12878.AS.chr20snippet.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/NA12892.AS.chr20snippet.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/spanningDel.1.copy.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/spanningDel.1.g.vc,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3905:48898,test,test,48898,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905,1,['test'],['test']
Testability,"/PD_WES_50/cnv_calling/GATK_gCNV/infos/cohort_all/cohort_35-calls --calls-shard-path /data/xiangxd/project/test/PD_WES_50/cnv_calling/GATK_gCNV/infos/cohort_all/cohort_36-calls --calls-shard-path /data/xiangxd/project/test/PD_WES_50/cnv_calling/GATK_gCNV/infos/cohort_all/cohort_37-calls --calls-shard-path /data/xiangxd/project/test/PD_WES_50/cnv_calling/GATK_gCNV/infos/cohort_all/cohort_38-calls --calls-shard-path /data/xiangxd/project/test/PD_WES_50/cnv_calling/GATK_gCNV/infos/cohort_all/cohort_39-calls --calls-shard-path /data/xiangxd/project/test/PD_WES_50/cnv_calling/GATK_gCNV/infos/cohort_all/cohort_40-calls --calls-shard-path /data/xiangxd/project/test/PD_WES_50/cnv_calling/GATK_gCNV/infos/cohort_all/cohort_41-calls --calls-shard-path /data/xiangxd/project/test/PD_WES_50/cnv_calling/GATK_gCNV/infos/cohort_all/cohort_42-calls --calls-shard-path /data/xiangxd/project/test/PD_WES_50/cnv_calling/GATK_gCNV/infos/cohort_all/cohort_43-calls --calls-shard-path /data/xiangxd/project/test/PD_WES_50/cnv_calling/GATK_gCNV/infos/cohort_all/cohort_44-calls --calls-shard-path /data/xiangxd/project/test/PD_WES_50/cnv_calling/GATK_gCNV/infos/cohort_all/cohort_45-calls --contig-ploidy-calls /data/xiangxd/project/test/PD_WES_50/cnv_calling/GATK_gCNV/infos/ploidy/ploidy-calls --allosomal-contig chrX --allosomal-contig chrY --sample-index 1 --output-genotyped-intervals /data/xiangxd/project/test/PD_WES_50/cnv_calling/GATK_gCNV/infos/output/R18001345LU01-XG1009_combined_cohort.vcf --output-genotyped-segments /data/xiangxd/project/test/PD_WES_50/cnv_calling/GATK_gCNV/infos/output/R18001345LU01-XG1009_combined_segment_cohort.vcf --output-denoised-copy-ratios /data/xiangxd/project/test/PD_WES_50/cnv_calling/GATK_gCNV/infos/output/R18001345LU01-XG1009_combined_ratio.txt`. Here attach all my scattered interval list files, and I have confirmed all my scattered interval list are in the same dictionary order.; [scatter.zip](https://github.com/broadinstitute/gatk/files/14973582/scatter.zip)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8776:42982,test,test,42982,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8776,2,['test'],['test']
Testability,/PathSeqBuildKmers/exampleFASTA.hss; src/test/resources/org/broadinstitute/hellbender/tools/spark/pathseq/PathSeqBuildReferenceTaxonomy/genbank_test.dict; src/test/resources/org/broadinstitute/hellbender/tools/spark/pathseq/PathSeqBuildReferenceTaxonomy/genbank_test.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/spark/pathseq/PathSeqBuildReferenceTaxonomy/test.dict; src/test/resources/org/broadinstitute/hellbender/tools/spark/pathseq/PathSeqBuildReferenceTaxonomy/test.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/spark/pathseq/PathSeqPipelineSpark/e_coli_k12_mini.dict; src/test/resources/org/broadinstitute/hellbender/tools/spark/pathseq/PathSeqPipelineSpark/pipeline_output.bam.splitting-bai; src/test/resources/org/broadinstitute/hellbender/tools/spark/pathseq/PSBuildReferenceTaxonomyUtils/test.tar.gz; src/test/resources/org/broadinstitute/hellbender/tools/spark/pathseq/PSFilter/hg19mini_test_reads.bam; src/test/resources/org/broadinstitute/hellbender/tools/spark/pipelines/FlagStatSpark/flag_stat.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/spark/sv/evidence/FindBreakpointEvidenceSpark/SVBreakpointsTest.assembly.0; src/test/resources/org/broadinstitute/hellbender/tools/spark/sv/sga/RunSGAViaProcessBuilderOnSpark; src/test/resources/org/broadinstitute/hellbender/tools/spark/sv/sga/RunSGAViaProcessBuilderOnSpark/4.raw.fastq; src/test/resources/org/broadinstitute/hellbender/tools/spark/sv/sga/RunSGAViaProcessBuilderOnSpark/4.raw.pp.ec.fa; src/test/resources/org/broadinstitute/hellbender/tools/spark/sv/sga/RunSGAViaProcessBuilderOnSpark/4.raw.pp.ec.filter.pass.fa; src/test/resources/org/broadinstitute/hellbender/tools/spark/sv/sga/RunSGAViaProcessBuilderOnSpark/4.raw.pp.ec.filter.pass.merged.fa; src/test/resources/org/broadinstitute/hellbender/tools/spark/sv/sga/RunSGAViaProcessBuilderOnSpark/4.raw.pp.ec.filter.pass.merged.rmdup-contigs.fa; src/test/resources/org/broadinstitute/hellbender/tools/spark/sv/sga/RunSGA,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3905:42405,test,test,42405,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905,1,['test'],['test']
Testability,"/Users/droazen/src/hellbender/src/test/resources/large/gvcfs/combined.gatk3.7_30_ga4f720357.expected.vcf, 8536) FAILED; java.lang.AssertionError: different sizes 16940 vs 17070; at org.broadinstitute.hellbender.utils.test.VariantContextTestUtils.assertEqualVariants(VariantContextTestUtils.java:173); at org.broadinstitute.hellbender.tools.GatherVcfsIntegrationTest.testBlockGather(GatherVcfsIntegrationTest.java:103); Results: FAILURE (15 tests, 14 successes, 1 failures, 0 skipped); ```. The tool writes a vcf that, when read back in by GATK, appears to have fewer records than it should. The same test does NOT fail if you do ANY of the following:. * Edit `GatherVcfsIntegrationTest.testBlockGather()` to turn on the JDK deflater by changing `.addBooleanArgument(""use_jdk_deflater"", false);` to `.addBooleanArgument(""use_jdk_deflater"", true);`. * Keep the Intel deflater on, but edit `build.gradle` to change `samjdk.compression_level` to 1 or 2. (You'll also need to change the `Assert.assertEquals(System.getProperty(""samjdk.compression_level""), ""5"");` line in `GatherVcfsIntegrationTest.testBlockGather()` accordingly). * Edit the `getVcfsToShard` `DataProvider` in `GatherVcfsIntegrationTest` to change the failing `{LARGE_VCF, 8536}` test case to `{LARGE_VCF, 8535}`. This cuts the number of files that the vcf gets split into in half, and the test passes. * Comment out all but the last test case in the `getVcfsToShard` `DataProvider` in `GatherVcfsIntegrationTest`. This indicates that there is something stateful going on, since the test case does not fail if run in isolation. One additional bit of information: the test fails with the Intel deflater and compression levels 5 and 9, but with compression level 9 GATK is able to read many fewer records from the final output file than it does at compression level 5. As mentioned above, at compression levels 1 or 2 it's able to read all the records correctly. If you manually decompress the output file it appears to have all the correct",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3117:1264,assert,assertEquals,1264,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3117,1,['assert'],['assertEquals']
Testability,/VariantFiltration/vcfMask.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/GenotypeGVCFs/ad-bug-input.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/GenotypeGVCFs/CEUTrio.20.21.missingIndel.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/GenotypeGVCFs/chr21.bad.pl.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/GenotypeGVCFs/combined_genotype_gvcf_exception.nocall.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/GenotypeGVCFs/combined_genotype_gvcf_exception.original.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/GenotypeGVCFs/combine.single.sample.pipeline.1.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/GenotypeGVCFs/combine.single.sample.pipeline.2.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/GenotypeGVCFs/combine.single.sample.pipeline.3.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/GenotypeGVCFs/gvcf.basepairResolution.gvcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/GenotypeGVCFs/gvcfExample1.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/GenotypeGVCFs/leadingDeletion.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/GenotypeGVCFs/spanningDel.combined.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/GenotypeGVCFs/spanningDel.delOnly.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/GenotypeGVCFs/spanningDel.depr.delOnly.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/GenotypeGVCFs/testUpdatePGT.gvcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/MarkDuplicatesGATK/example.chr1.1-1K.markedDups.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/walkers/MarkDuplicatesGATK/example.chr1.1-1K.unmarkedDups.bam.bai; src/test/resources/org/broadinstitute/hellbender/too,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3905:57230,test,test,57230,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905,1,['test'],['test']
Testability,/broadinstitute/hellbender/tools/walkers/MarkDuplicatesGATK/example.chr1.1-1K.unmarkedDups.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/walkers/MarkDuplicatesGATK/example.chr1.1-1K.unmarkedDups.noDups.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/walkers/MarkDuplicatesGATK/markDups.test2reads.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/walkers/MarkDuplicatesGATK/merge2.sam; src/test/resources/org/broadinstitute/hellbender/tools/walkers/MarkDuplicatesGATK/merge3.sam; src/test/resources/org/broadinstitute/hellbender/tools/walkers/MarkDuplicatesGATK/optical_dupes.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/walkers/MarkDuplicatesGATK/optical_dupes_casava.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/walkers/MarkDuplicatesGATK/optical_dupes.dict; src/test/resources/org/broadinstitute/hellbender/tools/walkers/MarkDuplicatesGATK/optical_dupes.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/walkers/qc/pileup/reads_data_source_test1.samtools.baq.pileup.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/qc/pileup/reads_data_source_test1.samtools.pileup.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/rnaseq/ASEReadCounter/NA12878.chr20_2444518_2637800.RNAseq.IMPROPER_PAIR.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/rnaseq/ASEReadCounter/NA12878.chr20_2444518_2637800.RNAseq.MultiContext.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/rnaseq/ASEReadCounter/NA12878.chr20_2444518_2637800.RNAseq.NON_REF.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/rnaseq/ASEReadCounter/NA12878.chr20_2444518_2637800.RNAseq.SYNONYMOUS_CODING.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/rnaseq/ASEReadCounter/NA12878.chr20_2444518_2637800.RNAseq.warnings.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/UnmarkDuplicates/allDuplic,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3905:59071,test,test,59071,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905,1,['test'],['test']
Testability,/broadinstitute/hellbender/tools/walkers/MarkDuplicatesGATK/example.chr1.1-1K.unmarkedDups.noDups.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/walkers/MarkDuplicatesGATK/markDups.test2reads.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/walkers/MarkDuplicatesGATK/merge2.sam; src/test/resources/org/broadinstitute/hellbender/tools/walkers/MarkDuplicatesGATK/merge3.sam; src/test/resources/org/broadinstitute/hellbender/tools/walkers/MarkDuplicatesGATK/optical_dupes.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/walkers/MarkDuplicatesGATK/optical_dupes_casava.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/walkers/MarkDuplicatesGATK/optical_dupes.dict; src/test/resources/org/broadinstitute/hellbender/tools/walkers/MarkDuplicatesGATK/optical_dupes.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/walkers/qc/pileup/reads_data_source_test1.samtools.baq.pileup.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/qc/pileup/reads_data_source_test1.samtools.pileup.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/rnaseq/ASEReadCounter/NA12878.chr20_2444518_2637800.RNAseq.IMPROPER_PAIR.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/rnaseq/ASEReadCounter/NA12878.chr20_2444518_2637800.RNAseq.MultiContext.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/rnaseq/ASEReadCounter/NA12878.chr20_2444518_2637800.RNAseq.NON_REF.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/rnaseq/ASEReadCounter/NA12878.chr20_2444518_2637800.RNAseq.SYNONYMOUS_CODING.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/rnaseq/ASEReadCounter/NA12878.chr20_2444518_2637800.RNAseq.warnings.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/UnmarkDuplicates/allDuplicates.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/complexEvents_incompatibleDi,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3905:59193,test,test,59193,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905,1,['test'],['test']
Testability,/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/copy_ratio_Viterbi_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/log_likelihood_history.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/sample_bias_latent_posteriors.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/sample_log_likelihoods.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/sample_read_depth_posteriors.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/sample_specific_unexplained_variance.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/segments/SM-74NEG.seg; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/segments/SM-74P2T.seg; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/segments/SM-74P35.seg; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/total_covariate_bias_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/total_unexplained_variance_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wgs_pon/model_final/bias_covariates_ARD_coefficients.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wgs_pon/model_final/mean_bias_covariates_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wgs_pon/model_final/mean_bias_covariates_norm2.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wgs_pon/model_final/target_specific_mean_log_bias.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wgs_pon/model_final/target_specific_unexplained_variance.tsv; src/test/resources/large/cnv/realistic-targets.tab; src/test/resources/lar,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3905:3644,test,test,3644,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905,1,['test'],['test']
Testability,/combined_genotype_gvcf_exception.nocall.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/GenotypeGVCFs/combined_genotype_gvcf_exception.original.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/GenotypeGVCFs/combine.single.sample.pipeline.1.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/GenotypeGVCFs/combine.single.sample.pipeline.2.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/GenotypeGVCFs/combine.single.sample.pipeline.3.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/GenotypeGVCFs/gvcf.basepairResolution.gvcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/GenotypeGVCFs/gvcfExample1.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/GenotypeGVCFs/leadingDeletion.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/GenotypeGVCFs/spanningDel.combined.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/GenotypeGVCFs/spanningDel.delOnly.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/GenotypeGVCFs/spanningDel.depr.delOnly.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/GenotypeGVCFs/testUpdatePGT.gvcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/MarkDuplicatesGATK/example.chr1.1-1K.markedDups.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/walkers/MarkDuplicatesGATK/example.chr1.1-1K.unmarkedDups.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/walkers/MarkDuplicatesGATK/example.chr1.1-1K.unmarkedDups.noDups.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/walkers/MarkDuplicatesGATK/markDups.test2reads.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/walkers/MarkDuplicatesGATK/merge2.sam; src/test/resources/org/broadinstitute/hellbender/tools/walkers/MarkDuplicatesGATK/merge3.sam; src/test/resources/org/broadinstitute/hellbender/t,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3905:57653,test,test,57653,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905,1,['test'],['test']
Testability,/coveragemodel/learning_sample_read_depth.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/learning_sample_sex_genotypes.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_contig_anots.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_HMM_priors_table.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_model; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_model/mean_bias_covariates_matrix.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_model/target_specific_mean_log_bias.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_model/target_specific_unexplained_variance.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_targets.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/acnv-segments-from-allelic-integration.seg; src/test/resources/org/broadinstitute/hellbender/tools/exome/af-params-from-allelic-integration.af.param; src/test/resources/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldown-1.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldown-2.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldown-3.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldown-4.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/dupReadsMini.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-NA12778.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-NA12872.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-NA12878.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-c,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3905:29058,test,test,29058,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905,1,['test'],['test']
Testability,/exome/exome-read-counts-test-targets-wo-coords.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/germlinehmm/homo_sapiens_germline_HMM_priors.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/germlinehmm/TCGA_T_matrix_autosomal_bad.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/pon-input.tab; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/contig_annots_bad_autosomal_annot.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/contig_annots_bad_class.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/contig_annots_bad_missing_some_annots.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/ice_trunc_rcc.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/ice_trunc_sex_genotypes.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/ice_trunc_targets_some_missing.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/ice_trunc_targets.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/ice_trunc_targets_with_bait_counts.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/sex_genotyper_agilent_targets_trunc.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/sex_genotypes_broadies_basic.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/sex_genotypes_broadies_extended.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/snps-basic-with-phase-posteriors.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/snps-full-with-phase-posteriors.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/snps-intermediate-with-phase-posteriors.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/snps-simplified-for-allelic-fra,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3905:34507,test,test,34507,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905,1,['test'],['test']
Testability,/hellbender/tools/BQSR/solid.bam; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/solid.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/clippingReadsTest.withRG.hg19.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/clippingReadsTestCRAM.cram; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/clippingReadsTest.withRG.hg19.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTestCRAM.QT_10.cram; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTestCRAM.QT_10.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.CT_15_1115.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.CT_15_1115.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.CT_15.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.CT_15.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_0.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_0.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CR_SOFTCLIP_BASES.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CR_SOFTCLIP_BASES.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CR_WRITE_NS.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CR_WRITE_NS.tmp; src/test/resources/org/broadinstitute/hellbender/tools/Cl,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3905:23468,test,test,23468,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905,1,['test'],['test']
Testability,/hellbender/tools/valid.cram.crai; src/test/resources/org/broadinstitute/hellbender/tools/valid.dict; src/test/resources/org/broadinstitute/hellbender/tools/valid.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/VQSR/VQSR.AStest.indels.recal.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/VQSR/VQSR.AStest.input.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/VQSR/VQSR.AStest.postSNPinput.HACKEDhg38header.vcf.gz.tbi; src/test/resources/org/broadinstitute/hellbender/tools/VQSR/VQSR.AStest.postSNPinput.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/VQSR/VQSR.AStest.snps.recal.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/VQSR/VQSR.mixedTest.input.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/VQSR/VQSR.mixedTest.recal.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/annotator/allelespecific/CombineGVCFs.output.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/annotator/allelespecific/CombineGVCFs.output.withoutIndex.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/annotator/allelespecific/GenotypeGVCFs.output.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/annotator/allelespecific/HCOutputWithASAnnotation.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/annotator/allelespecific/NA12878.AS.chr20snippet.g.unindexed.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/annotator/allelespecific/NA12878.AS.chr20snippet.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/annotator/allelespecific/NA12878.AS.InsertSizeRankSum.chr20snippet.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/annotator/allelespecific/NA12878.AS.MateRankSum.chr20snippet.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/annotator/allelespecific/NA12878.AS.MateRankSum.chr20snippet.withoutIndex.vcf.idx; ,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3905:46813,test,test,46813,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905,1,['test'],['test']
Testability,/hellbender/tools/walkers/GenotypeGVCFs/spanningDel.delOnly.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/GenotypeGVCFs/spanningDel.depr.delOnly.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/GenotypeGVCFs/testUpdatePGT.gvcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/MarkDuplicatesGATK/example.chr1.1-1K.markedDups.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/walkers/MarkDuplicatesGATK/example.chr1.1-1K.unmarkedDups.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/walkers/MarkDuplicatesGATK/example.chr1.1-1K.unmarkedDups.noDups.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/walkers/MarkDuplicatesGATK/markDups.test2reads.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/walkers/MarkDuplicatesGATK/merge2.sam; src/test/resources/org/broadinstitute/hellbender/tools/walkers/MarkDuplicatesGATK/merge3.sam; src/test/resources/org/broadinstitute/hellbender/tools/walkers/MarkDuplicatesGATK/optical_dupes.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/walkers/MarkDuplicatesGATK/optical_dupes_casava.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/walkers/MarkDuplicatesGATK/optical_dupes.dict; src/test/resources/org/broadinstitute/hellbender/tools/walkers/MarkDuplicatesGATK/optical_dupes.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/walkers/qc/pileup/reads_data_source_test1.samtools.baq.pileup.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/qc/pileup/reads_data_source_test1.samtools.pileup.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/rnaseq/ASEReadCounter/NA12878.chr20_2444518_2637800.RNAseq.IMPROPER_PAIR.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/rnaseq/ASEReadCounter/NA12878.chr20_2444518_2637800.RNAseq.MultiContext.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/rnaseq/ASEReadCounter/NA1287,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3905:58645,test,test,58645,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905,1,['test'],['test']
Testability,/hellbender/tools/walkers/variantutils/CalculateGenotypePosteriors/threeMemberNonTrioTest_chr20.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/SelectVariants/261_S01_raw_variants_gvcf.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/SelectVariants/complexExample1.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/SelectVariants/diploid-multisample-sac.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/SelectVariants/expected/testSelectVariants_DiscordanceNoSampleSpecified.vcf; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/SelectVariants/expected/testSelectVariants_FileWithoutInfoLineInHeaderWithOverride.vcf; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/SelectVariants/expected/testSelectVariants_SelectMultiAllelicExcludeNonVar.vcf; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/SelectVariants/filteringDepthInFormat.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/SelectVariants/haploid-multisample.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/SelectVariants/selectVariantsInfoField.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/SelectVariants/test.dup.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/SelectVariants/tetra-diploid.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/SelectVariants/tetraploid-multisample-sac.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/SelectVariants/tetraploid-multisample.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/SelectVariants/vcfexample2DiscordanceConcordance.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/Sel,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3905:64404,test,test,64404,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905,1,['test'],['test']
Testability,/hg19micro.dict; src/test/resources/hg19micro.fasta.fai; src/test/resources/hg19mini.dict; src/test/resources/hg19mini.fasta.fai; src/test/resources/Homo_sapiens_assembly19_chr1_1M.dict; src/test/resources/Homo_sapiens_assembly19_chr1_1M.fasta.fai; src/test/resources/Homo_sapiens_assembly19.dbsnp135.chr1_1M.exome_intervals.vcf.idx; src/test/resources/HSA19.dbsnp135.chr1_1M.exome_intervals.modified.vcf.idx; src/test/resources/human_g1k_v37.chr17_1Mb.dict; src/test/resources/human_g1k_v37.chr17_1Mb.fasta.fai; src/test/resources/iupacFASTA.dict; src/test/resources/iupacFASTA.fasta.fai; src/test/resources/joint_calling.chr1_1M.1kg_samples.10samples.noINFO.vcf.idx; src/test/resources/large/1000G.phase3.broad.withGenotypes.chr20.10100000.vcf.idx; src/test/resources/large/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.cram.bai; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/bias_covariates_ARD_coefficients.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/mean_bias_covariates_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/mean_bias_covariates_norm2.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/target_specific_mean_log_bias.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/target_specific_unexplained_variance.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/bias_covariates_ARD_coefficients_history.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/copy_ratio_max_likelihood_estimate_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/copy_ratio_precision_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/copy_ratio_Viterbi_matrix.tsv; src/test/resources/large/cnv_germline_workflows_,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3905:1787,test,test,1787,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905,1,['test'],['test']
Testability,/hg38.fasta -O hdfs:///user/hadoop/output/testgatkvcf.vcf \; > -- \; > --spark-runner SPARK --spark-master yarn; Using GATK jar /home/hadoop/gatk/build/libs/gatk-spark.jar; Running:; /usr/lib/spark/bin/spark-submit --master yarn --conf spark.driver.userClassPathFirst=false --conf spark.io.compression.codec=lzf --conf spark.driver.maxResultSize=0 --conf spark.executor.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 --conf spark.driver.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 --conf spark.kryoserializer.buffer.max=512m --conf spark.yarn.executor.memoryOverhead=600 /home/hadoop/gatk/build/libs/gatk-spark.jar HaplotypeCallerSpark -I hdfs:///user/hadoop/testdata/TestData -R hdfs:///user/hadoop/reference/hg38.fasta -O hdfs:///user/hadoop/output/testgatkvcf.vcf --spark-master yarn; 19/04/08 19:01:40 WARN SparkConf: The configuration key 'spark.yarn.executor.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.executor.memoryOverhead' instead.; 19:01:43.413 WARN SparkContextFactory - Environment variables HELLBENDER_TEST_PROJECT and HELLBENDER_JSON_SERVICE_ACCOUNT_KEY must be set or the GCS hadoop connector will not be configured properly; 19:01:43.565 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/hadoop/gatk/build/libs/gatk-spark.jar!/com/intel/gkl/native/libgkl_compression.so; 19:01:43.728 INFO HaplotypeCallerSpark - ------------------------------------------------------------; 19:01:43.729 INFO HaplotypeCallerSpark - The Genome Analysis Toolkit (GATK) v4.1.1.0-10-g554a0e8-SNAPSHOT; 19:01:43.729 INFO HaplotypeCallerSpark - For support and document,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5869:1300,test,testdata,1300,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5869,2,"['Test', 'test']","['TestData', 'testdata']"
Testability,/inputs/wes_pon/posteriors_final/copy_ratio_max_likelihood_estimate_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/copy_ratio_precision_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/copy_ratio_Viterbi_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/log_likelihood_history.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/sample_bias_latent_posteriors.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/sample_log_likelihoods.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/sample_read_depth_posteriors.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/sample_specific_unexplained_variance.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/segments/SM-74NEG.seg; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/segments/SM-74P2T.seg; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/segments/SM-74P35.seg; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/total_covariate_bias_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/total_unexplained_variance_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wgs_pon/model_final/bias_covariates_ARD_coefficients.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wgs_pon/model_final/mean_bias_covariates_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wgs_pon/model_final/mean_bias_covariates_norm2.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wgs_pon/model_final/target_sp,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3905:3416,test,test,3416,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905,1,['test'],['test']
Testability,"/issues/1053). Currently ValidateVariants relies on genotypes to transitively check that each alt allele occurs in at least one sample and that the AC adds up. However, this can fail on sites-only files because there are no genotypes. We should use the definition of the info annotations in the header to check how many entries each should have.; ### Outline; - Add a new validation type for info-field counts to enum and to switch statement; - Grab info headers from input VCF with something like GATKVCFUtils.getVCFHeadersFromRods(getToolkit(), variantCollection.variants.getName()) and VCFHeader::getInfoHeaderLines; - In the map() function, for each info header line, call on each VCFInfoHeaderLine getCount(vc) to get the expected number of info annotation entries; - Compare the expected number with a count based on vc.getAttribute(currentVCFinfoHeaderLine.getID()), which will require some additional parsing because it returns an Object; - (Bonus points if you use the isFixedCount() and getCount() functions on the VCF info header line to simplify annotations that aren't according to the number of alt alleles); ### Test data. /humgen/gsa-hpprojects/dev/gauthier/scratch/supportingMultiA.vcf; Should fail AC/AF validation at ; `1 768589 . A C,G 76 PASS AC=1;AF=0.00047;AN=2120`; See results using:. ```; use VCFtools; vcf-validator /humgen/gsa-hpprojects/dev/gauthier/scratch/supportingMultiA.vcf; ```. which outputs:; `INFO field at 1:768589 .. INFO tag [AC=1] expected different number of values (expected 2, found 1),INFO tag [AF=0.00047] expected different number of values (expected 2, found 1)`; ### Notes. Currently, all the validation modes call out to HTSJDK. Do we want to put the new functionality there as well?. ---. @yfarjoun commented on [Thu Jul 16 2015](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-122130280). I think that it is very appropriate to validate in htsjdk. On Thu, Jul 16, 2015 at 4:05 PM, ldgauthier notifications@github.com; wrote:",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2507:1237,Test,Test,1237,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2507,1,['Test'],['Test']
Testability,/org/broadinstitute/hellbender/engine/spark/datasources/ReadsSparkSink/fragments_test; src/test/resources/org/broadinstitute/hellbender/engine/spark/datasources/ReadsSparkSink/fragments_test/part-r-00001; src/test/resources/org/broadinstitute/hellbender/engine/spark/datasources/ReadsSparkSink/fragments_test/part-r-00002; src/test/resources/org/broadinstitute/hellbender/engine/spark/datasources/ReadsSparkSink/fragments_test/part-r-00003; src/test/resources/org/broadinstitute/hellbender/engine/VariantWalkerTest_VariantsWithReads.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectAlignmentSummaryMetrics/summary_alignment_bisulfite_test.sam; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectAlignmentSummaryMetrics/summary_alignment_stats_test2.sam; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectAlignmentSummaryMetrics/summary_alignment_stats_test.bam; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectAlignmentSummaryMetrics/summary_alignment_stats_test.cram; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectAlignmentSummaryMetrics/summary_alignment_stats_test.fasta.fai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectAlignmentSummaryMetrics/summary_alignment_stats_test_multiple.sam; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectAlignmentSummaryMetrics/summary_alignment_stats_test.sam; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectBaseDistributionByCycle/example_pfFail_reads.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectBaseDistributionByCycle/first5000a.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectBaseDistributionByCycle/originalQuals.chr1.1-1K.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectBaseDistributionByCycle/unmapped.bam.bai; src/test/resources/org/broadinstitut,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3905:13443,test,test,13443,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905,1,['test'],['test']
Testability,/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.broken.3.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.broken.4.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.broken.5.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/bqsr.fakeSitesForTesting.b37.chr17.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/bqsr.fakeSitesForTesting.b37.chr20.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/bqsr.manyObservations.full.table.gz; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/bqsr.manyObservations.piece.table.gz; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.noMD.noBQSR.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.noMD.noBQSR.cram.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.noMD.noBQSR.md.bqsr.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.ch20.4379150-4379157.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.10m-10m100.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.10m-10m100.cram.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_132.b36.excluding_sites_after_129.chr1_1k.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_132.b37.excluding_sites_after_129.chr17_69k_70k.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_138.b37.20.10m-10m100.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_138.b37.21.10m-10m100.vcf.idx; ,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3905:18309,test,test,18309,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905,1,['test'],['test']
Testability,/org/broadinstitute/hellbender/tools/BQSR/HiSeq.1mb.1RG.2k_lines.alternate_allaligned.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/HiSeq.1mb.1RG.2k_lines.alternate.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/HiSeq.1mb.1RG.2k_lines.alternate.recalibrated.DIQ.sharded.bam/part-r-00001.bam; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/HiSeq.1mb.1RG.2k_lines.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/human_b36_both.chr1_1k.dict; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/human_b36_both.chr1_1k.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/NA12878.chr17_69k_70k.dictFix.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/NA12878.oq.read_consumes_zero_ref_bases.chr20.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/na.bam; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/na.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/originalQuals.1kg.chr1.1-1K.1RG.dictFix.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/overlappingRead.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/solid.bam; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/solid.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/clippingReadsTest.withRG.hg19.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/clippingReadsTestCRAM.cram; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/clippingReadsTest.withRG.hg19.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTestCRAM.QT_10.cram; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTestCRAM.QT_10.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.CT_15_1115.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3905:22271,test,test,22271,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905,1,['test'],['test']
Testability,/org/broadinstitute/hellbender/tools/copynumber/collectfragmentcounts/collect-fragment-counts-NA12878.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/count_bases.cram.crai; src/test/resources/org/broadinstitute/hellbender/tools/count_bases.dict; src/test/resources/org/broadinstitute/hellbender/tools/count_bases.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/count_reads.cram.crai; src/test/resources/org/broadinstitute/hellbender/tools/count_reads.dict; src/test/resources/org/broadinstitute/hellbender/tools/count_reads.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/count_reads_sorted.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/count_reads_sorted.cram.crai; src/test/resources/org/broadinstitute/hellbender/tools/count_variants.blockgz.gz.tbi; src/test/resources/org/broadinstitute/hellbender/tools/count_variants_withSequenceDict.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/calling_combined_copy_number.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/calling_combined_read_counts.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/calling_sample_bias_latent.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/calling_sample_read_depth.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/calling_sample_sex_genotypes.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/learning_combined_copy_number.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/learning_combined_read_counts.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/learning_sample_bias_latent.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/learning_sample_read_depth.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/learning_sample_sex_ge,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3905:27159,test,test,27159,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905,2,['test'],['test']
Testability,/org/broadinstitute/hellbender/tools/spark/sv/sga/RunSGAViaProcessBuilderOnSpark/9.raw.pp.ec.filter.pass.merged.rmdup.fa; src/test/resources/org/broadinstitute/hellbender/tools/spark/sv/sga/RunSGAViaProcessBuilderOnSpark/9.raw.pp.fq; src/test/resources/org/broadinstitute/hellbender/tools/spark/sv/utils/SVContext.vcf.gz.tbi; src/test/resources/org/broadinstitute/hellbender/tools/splitNCigarReadsSnippet.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/split_reads.bam; src/test/resources/org/broadinstitute/hellbender/tools/split_reads.cram; src/test/resources/org/broadinstitute/hellbender/tools/split_reads.dict; src/test/resources/org/broadinstitute/hellbender/tools/split_reads.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/split_reads_missing_lib.bam; src/test/resources/org/broadinstitute/hellbender/tools/split_reads_missing_lib.cram; src/test/resources/org/broadinstitute/hellbender/tools/split_reads_missing_lib.dict; src/test/resources/org/broadinstitute/hellbender/tools/split_reads_missing_lib.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/split_reads_missing_lib.sam; src/test/resources/org/broadinstitute/hellbender/tools/split_reads.sam; src/test/resources/org/broadinstitute/hellbender/tools/validation/marked.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.bam; src/test/resources/org/broadinstitute/hellbender/tools/validation/picard.marked.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.bam; src/test/resources/org/broadinstitute/hellbender/tools/validation/single.read.bai; src/test/resources/org/broadinstitute/hellbender/tools/valid.cram.crai; src/test/resources/org/broadinstitute/hellbender/tools/valid.dict; src/test/resources/org/broadinstitute/hellbender/tools/valid.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/VQSR/VQSR.AStest.indels.recal.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/VQSR/VQSR.AStest.input.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/VQSR/VQSR.AS,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3905:45246,test,test,45246,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905,1,['test'],['test']
Testability,/org/broadinstitute/hellbender/tools/walkers/annotator/VariantAnnotatorEngine/one_entry_source.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/combine-gvcf-wrong-ref-input1.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/combine-gvcf-wrong-ref-input2.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/convertToBasePairResolution.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/gvcf.basepairResolution.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/gvcfExample1.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/gvcfExample2.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/IntervalTest.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/NA12878.AS.chr20snippet.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/NA12892.AS.chr20snippet.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/spanningDel.1.copy.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/spanningDel.1.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/spanningDel.2.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/spanningDeletionRestrictToStartExpected.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/spanningDel.many.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/spanningDel.many.haploid.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/spanningDel.many.tetraploid.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/testAlleleSpecificAnnotationsNoGroup.vcf.idx; src/test/resources/org/broadinstitute/hellben,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3905:49640,test,test,49640,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905,1,['test'],['test']
Testability,/pool_sequence_nov2016/data/gVCF/pl_ZC_0035_chr26.raw.g.vcf --variant /usr/users/geibel/chicken/pool_sequence_nov2016/data/gVCF/pl_GV_0036_chr26.raw.g.vcf --variant /usr/users/geibel/chicken/pool_sequence_nov2016/data/gVCF/pl_CW_0037_chr26.raw.g.vcf --variant /usr/users/geibel/chicken/pool_sequence_nov2016/data/gVCF/pl_DL_0038_chr26.raw.g.vcf --variant /usr/users/geibel/chicken/pool_sequence_nov2016/data/gVCF/pl_KS_0039_chr26.raw.g.vcf --variant /usr/users/geibel/chicken/pool_sequence_nov2016/data/gVCF/pl_OF_0040_chr26.raw.g.vcf --variant /usr/users/geibel/chicken/pool_sequence_nov2016/data/gVCF/pl_WR_0041_chr26.raw.g.vcf --variant /usr/users/geibel/chicken/pool_sequence_nov2016/data/gVCF/pl_RI_0042_chr26.raw.g.vcf -nt 10 --max_genotype_count 1024 -L chr26 --dbsnp /usr/users/geibel/chicken/chickenrefgen/ENSEMBL_20170106/Gallus_gallus.updated.vcf -o /usr/users/geibel/chicken/pool_sequence_nov2016/data/rawVCF/IndandPool_chr26.raw.vcf ; ```. The user actually includes a shell script in the test data bundle called `JointGenotyping_chr26.sh`. ---; ### The error shows:; ```; ##### ERROR --; ##### ERROR stack trace ; java.lang.IllegalArgumentException: the number of genotypes is too large for ploidy 20 and allele 16: approx. 3247943160; 	at org.broadinstitute.gatk.tools.walkers.genotyper.GenotypeLikelihoodCalculators.getInstance(GenotypeLikelihoodCalculators.java:319); 	at org.broadinstitute.gatk.tools.walkers.variantutils.ReferenceConfidenceVariantContextMerger.mergeRefConfidenceGenotypes(ReferenceConfidenceVariantContextMerger.java:461); 	at org.broadinstitute.gatk.tools.walkers.variantutils.ReferenceConfidenceVariantContextMerger.merge(ReferenceConfidenceVariantContextMerger.java:164); 	at org.broadinstitute.gatk.tools.walkers.variantutils.GenotypeGVCFs.map(GenotypeGVCFs.java:302); 	at org.broadinstitute.gatk.tools.walkers.variantutils.GenotypeGVCFs.map(GenotypeGVCFs.java:135); 	at org.broadinstitute.gatk.engine.traversals.TraverseLociNano$TraverseLociMap.apply(TraverseL,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2946:9834,test,test,9834,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2946,1,['test'],['test']
Testability,/resources/large/K-562.duplicateMarked.chr20.bai; src/test/resources/large/mutect/dream_synthetic_bams/normal_3.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/normal_4.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/normal.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/tumor_3.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/tumor_4.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/tumor.bam.bai; src/test/resources/large/NA12878.RNAseq.bai; src/test/resources/large/SVIntegrationTest.bam.bai; src/test/resources/large/very-small-gnomad.vcf.idx; src/test/resources/large/VQSR/ALL.wgs.indels_mills_devine_hg19_leftAligned_collapsed_double_hit.sites.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/combined.phase1.chr20.raw.indels.filtered.sites.1M-10M.vcf.idx; src/test/resources/large/VQSR/dbsnp_132_b37.leftAligned.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/expected/snpRecal.scattered.vcf.idx; src/test/resources/large/VQSR/expected/snpSampledRecal.vcf.idx; src/test/resources/large/VQSR/indelRecal.vcf.idx; src/test/resources/large/VQSR/Omni25_sites_1525_samples.b37.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/phase1.projectConsensus.chr20.1M-10M.raw.snps.vcf.idx; src/test/resources/large/VQSR/sites_r27_nr.b37_fwd.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/snpRecal.vcf.idx; src/test/resources/NA12878.chr17_69k_70k.dictFix.bam.bai; src/test/resources/NA12878.chr17_69k_70k.dictFix.cram.crai; src/test/resources/org/broadinstitute/hellbender/engine/ambiguityCodes.dict; src/test/resources/org/broadinstitute/hellbender/engine/ambiguityCodes.fasta.fai; src/test/resources/org/broadinstitute/hellbender/engine/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.10000000-10000020.with.unmapped.bam.bai; src/test/resources/org/broadinstitute/hellbender/engine/CEUTrio.HiSeq.WGS.b37.NA12878.snippet_with_unmapped.bam.bai; src/test/resources/org/broadinstitute/hellbender/engine/CEUTrio.HiSeq.WGS.b37.NA12878.snippet_with_unm,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3905:7419,test,test,7419,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905,1,['test'],['test']
Testability,/resources/large/gencode.v26.primary_assembly.annotation.XYZ.gtf.idx; src/test/resources/large/gvcfs/CEUTrio.20.21.gatk3.4.g.vcf.idx; src/test/resources/large/gvcfs/combined.gatk3.7_30_ga4f720357.g.vcf.gz.tbi; src/test/resources/large/gvcfs/combined.gatk3.7.g.vcf.gz.tbi; src/test/resources/large/gvcfs/gatk3.7_30_ga4f720357.24_sample.21.g.vcf.idx; src/test/resources/large/gvcfs/HG00096.g.vcf.gz.tbi; src/test/resources/large/gvcfs/HG00268.g.vcf.gz.tbi; src/test/resources/large/gvcfs/NA19625.g.vcf.gz.tbi; src/test/resources/large/Homo_sapiens_assembly38.20.21.dict; src/test/resources/large/Homo_sapiens_assembly38.20.21.fasta.fai; src/test/resources/large/human_g1k_v37.20.21.fasta.amb; src/test/resources/large/human_g1k_v37.20.21.fasta.ann; src/test/resources/large/human_g1k_v37.20.21.fasta.bwt; src/test/resources/large/human_g1k_v37.20.21.fasta.pac; src/test/resources/large/human_g1k_v37.20.21.fasta.sa; src/test/resources/large/K-562.duplicateMarked.chr20.bai; src/test/resources/large/mutect/dream_synthetic_bams/normal_3.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/normal_4.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/normal.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/tumor_3.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/tumor_4.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/tumor.bam.bai; src/test/resources/large/NA12878.RNAseq.bai; src/test/resources/large/SVIntegrationTest.bam.bai; src/test/resources/large/very-small-gnomad.vcf.idx; src/test/resources/large/VQSR/ALL.wgs.indels_mills_devine_hg19_leftAligned_collapsed_double_hit.sites.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/combined.phase1.chr20.raw.indels.filtered.sites.1M-10M.vcf.idx; src/test/resources/large/VQSR/dbsnp_132_b37.leftAligned.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/expected/snpRecal.scattered.vcf.idx; src/test/resources/large/VQSR/expected/snpSampledRecal.vcf.idx; src/test/resources/large/VQSR/indelRecal,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3905:6494,test,test,6494,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905,1,['test'],['test']
Testability,/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/IntervalTest.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/NA12878.AS.chr20snippet.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/NA12892.AS.chr20snippet.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/spanningDel.1.copy.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/spanningDel.1.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/spanningDel.2.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/spanningDeletionRestrictToStartExpected.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/spanningDel.many.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/spanningDel.many.haploid.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/spanningDel.many.tetraploid.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/testAlleleSpecificAnnotationsNoGroup.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/testAlleleSpecificAnnotations.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/testBasepairResolutionInput.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/testBreakBandsArgumet.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/testMultipleSpanningDeletionsForOneSampleHaploid.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/testMultipleSpanningDeletionsForOneSampleTetraploid.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/testMultipleSpanningDeletionsForOneSample.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGV,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3905:50398,test,test,50398,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905,1,['test'],['test']
Testability,/resources/org/broadinstitute/hellbender/utils/IndexUtils/test_bed_for_index.bed.idx; src/test/resources/org/broadinstitute/hellbender/utils/IndexUtils/test_variants_for_index.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/utils/IndexUtils/test_variants_for_index.vcf.bgz.tbi; src/test/resources/org/broadinstitute/hellbender/utils/read/comparator_test_with_unmapped.bam.bai; src/test/resources/org/broadinstitute/hellbender/utils/read/ReadUtils/print_reads.fasta.fai; src/test/resources/org/broadinstitute/hellbender/utils/samples/SampleUtils/emptySamples.samples; src/test/resources/org/broadinstitute/hellbender/utils/samples/SampleUtils/overlapsWithSamples2.samples; src/test/resources/org/broadinstitute/hellbender/utils/samples/SampleUtils/samples1.samples; src/test/resources/org/broadinstitute/hellbender/utils/samples/SampleUtils/samples2.samples; src/test/resources/org/broadinstitute/hellbender/utils/SequenceDictionaryUtils/test2.dict; src/test/resources/org/broadinstitute/hellbender/utils/SequenceDictionaryUtils/test2.fasta.fai; src/test/resources/org/broadinstitute/hellbender/utils/SequenceDictionaryUtils/test2.intervals; src/test/resources/org/broadinstitute/hellbender/utils/SequenceDictionaryUtils/test2.sorted.bam.bai; src/test/resources/org/broadinstitute/hellbender/utils/SequenceDictionaryUtils/test2.vcf.idx; src/test/resources/org/broadinstitute/hellbender/utils/SequenceDictionaryUtils/test.dict; src/test/resources/org/broadinstitute/hellbender/utils/SequenceDictionaryUtils/test.fasta.fai; src/test/resources/org/broadinstitute/hellbender/utils/SequenceDictionaryUtils/test.sorted.bam.bai; src/test/resources/org/broadinstitute/hellbender/utils/SequenceDictionaryUtils/test_variants_for_index.vcf.bgz.tbi; src/test/resources/org/broadinstitute/hellbender/utils/SequenceDictionaryUtils/test.vcf.idx; src/test/resources/org/broadinstitute/hellbender/utils/test/SamAssertionUtilsUnitTest/file1.bam.bai; src/test/resources/problematicFASTA.dict; src/test/resourc,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3905:67681,test,test,67681,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905,1,['test'],['test']
Testability,/sga/RunSGAViaProcessBuilderOnSpark/4.raw.pp.ec.filter.pass.fa; src/test/resources/org/broadinstitute/hellbender/tools/spark/sv/sga/RunSGAViaProcessBuilderOnSpark/4.raw.pp.ec.filter.pass.merged.fa; src/test/resources/org/broadinstitute/hellbender/tools/spark/sv/sga/RunSGAViaProcessBuilderOnSpark/4.raw.pp.ec.filter.pass.merged.rmdup-contigs.fa; src/test/resources/org/broadinstitute/hellbender/tools/spark/sv/sga/RunSGAViaProcessBuilderOnSpark/4.raw.pp.ec.filter.pass.merged.rmdup.fa; src/test/resources/org/broadinstitute/hellbender/tools/spark/sv/sga/RunSGAViaProcessBuilderOnSpark/4.raw.pp.fq; src/test/resources/org/broadinstitute/hellbender/tools/spark/sv/sga/RunSGAViaProcessBuilderOnSpark/9.raw.fastq; src/test/resources/org/broadinstitute/hellbender/tools/spark/sv/sga/RunSGAViaProcessBuilderOnSpark/9.raw.pp.ec.fa; src/test/resources/org/broadinstitute/hellbender/tools/spark/sv/sga/RunSGAViaProcessBuilderOnSpark/9.raw.pp.ec.filter.pass.fa; src/test/resources/org/broadinstitute/hellbender/tools/spark/sv/sga/RunSGAViaProcessBuilderOnSpark/9.raw.pp.ec.filter.pass.merged.fa; src/test/resources/org/broadinstitute/hellbender/tools/spark/sv/sga/RunSGAViaProcessBuilderOnSpark/9.raw.pp.ec.filter.pass.merged.rmdup-contigs.fa; src/test/resources/org/broadinstitute/hellbender/tools/spark/sv/sga/RunSGAViaProcessBuilderOnSpark/9.raw.pp.ec.filter.pass.merged.rmdup.fa; src/test/resources/org/broadinstitute/hellbender/tools/spark/sv/sga/RunSGAViaProcessBuilderOnSpark/9.raw.pp.fq; src/test/resources/org/broadinstitute/hellbender/tools/spark/sv/utils/SVContext.vcf.gz.tbi; src/test/resources/org/broadinstitute/hellbender/tools/splitNCigarReadsSnippet.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/split_reads.bam; src/test/resources/org/broadinstitute/hellbender/tools/split_reads.cram; src/test/resources/org/broadinstitute/hellbender/tools/split_reads.dict; src/test/resources/org/broadinstitute/hellbender/tools/split_reads.fasta.fai; src/test/resources/org/broadinstitute/h,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3905:43982,test,test,43982,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905,1,['test'],['test']
Testability,/sim_model/target_specific_mean_log_bias.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_model/target_specific_unexplained_variance.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_targets.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/acnv-segments-from-allelic-integration.seg; src/test/resources/org/broadinstitute/hellbender/tools/exome/af-params-from-allelic-integration.af.param; src/test/resources/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldown-1.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldown-2.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldown-3.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldown-4.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/dupReadsMini.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-NA12778.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-NA12872.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-NA12878.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-NA12878.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-sample-NA12878.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/test_reference.dict; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/test_reference.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/exome/conversion/allelicbalancecaller/cell_line_full-sim-final.seg; src/test/resources/org/broadinstitute/hellbender/tools/exome/create-pon-some-targets.bed; src/test/resources,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3905:29647,test,test,29647,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905,1,['test'],['test']
Testability,"/sparkcache --class org.broadinstitute.hellbender.Main /gpfs/software/spark/gatk4onspark.jar PrintReadsSpark -I /gpfs/home/tpathare/gatk/src/test/resources/NA12878.chr17_69k_70k.dictFix.bam -O /gpfs/home/tpathare/test/; + /spark-1.6.2-bin-hadoop2.6//bin/spark-submit --master spark://hpcgenomicn24:6311 --conf spark.executor.memory=2g --conf spark.driver.memory=2g --conf spark.local.dir=/gpfs/ngsdata/sparkcache --class org.broadinstitute.hellbender.Main /gpfs/software/spark/gatk4onspark.jar PrintReadsSpark -I /gpfs/home/tpathare/gatk/src/test/resources/NA12878.chr17_69k_70k.dictFix.bam -O /gpfs/home/tpathare/test/; 23:25:07.475 INFO IntelGKLUtils - Trying to load Intel GKL library from:; 	jar:file:/gpfs/software/spark/gatk4onspark.jar!/com/intel/gkl/native/libIntelGKL.so; 23:25:07.552 INFO IntelGKLUtils - Intel GKL library loaded from classpath.; [November 16, 2016 11:25:07 PM AST] org.broadinstitute.hellbender.tools.spark.pipelines.PrintReadsSpark --output /gpfs/home/tpathare/test/ --input /gpfs/home/tpathare/gatk/src/test/resources/NA12878.chr17_69k_70k.dictFix.bam --readValidationStringency SILENT --interval_set_rule UNION --interval_padding 0 --interval_exclusion_padding 0 --bamPartitionSize 0 --disableSequenceDictionaryValidation false --shardedOutput false --numReducers 0 --sparkMaster local[*] --help false --version false --verbosity INFO --QUIET false --use_jdk_deflater false --disableAllReadFilters false; [November 16, 2016 11:25:07 PM AST] Executing as root@hpcgenomicn24 on Linux 2.6.32-358.el6.x86_64 amd64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_66-b17; Version: Version:4.alpha.2-98-g8fa5092-SNAPSHOT; 23:25:07.556 INFO PrintReadsSpark - Defaults.BUFFER_SIZE : 131072; 23:25:07.556 INFO PrintReadsSpark - Defaults.COMPRESSION_LEVEL : 5; 23:25:07.556 INFO PrintReadsSpark - Defaults.CREATE_INDEX : false; 23:25:07.556 INFO PrintReadsSpark - Defaults.CREATE_MD5 : false; 23:25:07.556 INFO PrintReadsSpark - Defaults.CUSTOM_READER_FACTORY : ; 23:25:07.556 INFO PrintR",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2268:1565,test,test,1565,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2268,2,['test'],['test']
Testability,/summary_alignment_stats_test2.sam; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectAlignmentSummaryMetrics/summary_alignment_stats_test.bam; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectAlignmentSummaryMetrics/summary_alignment_stats_test.cram; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectAlignmentSummaryMetrics/summary_alignment_stats_test.fasta.fai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectAlignmentSummaryMetrics/summary_alignment_stats_test_multiple.sam; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectAlignmentSummaryMetrics/summary_alignment_stats_test.sam; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectBaseDistributionByCycle/example_pfFail_reads.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectBaseDistributionByCycle/first5000a.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectBaseDistributionByCycle/originalQuals.chr1.1-1K.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectBaseDistributionByCycle/unmapped.bam.bai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectBaseDistributionByCycle/valid.cram.crai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectBaseDistributionByCycle/valid.dict; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectBaseDistributionByCycle/valid.fasta.fai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectQualityYieldMetrics/collect_quality_yield_metrics.bam; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectQualityYieldMetrics/collect_quality_yield_metrics.cram; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectQualityYieldMetrics/valid.cram.crai; src/test/resources/org/broadinstitute/hellbender/metrics/analysis/CollectQualityYieldMetrics/valid.dict;,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3905:14223,test,test,14223,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905,1,['test'],['test']
Testability,/test/PD_WES_50/cnv_calling/GATK_gCNV/infos/cohort_all/cohort_39-calls --calls-shard-path /data/xiangxd/project/test/PD_WES_50/cnv_calling/GATK_gCNV/infos/cohort_all/cohort_40-calls --calls-shard-path /data/xiangxd/project/test/PD_WES_50/cnv_calling/GATK_gCNV/infos/cohort_all/cohort_41-calls --calls-shard-path /data/xiangxd/project/test/PD_WES_50/cnv_calling/GATK_gCNV/infos/cohort_all/cohort_42-calls --calls-shard-path /data/xiangxd/project/test/PD_WES_50/cnv_calling/GATK_gCNV/infos/cohort_all/cohort_43-calls --calls-shard-path /data/xiangxd/project/test/PD_WES_50/cnv_calling/GATK_gCNV/infos/cohort_all/cohort_44-calls --calls-shard-path /data/xiangxd/project/test/PD_WES_50/cnv_calling/GATK_gCNV/infos/cohort_all/cohort_45-calls --calls-shard-path /data/xiangxd/project/test/PD_WES_50/cnv_calling/GATK_gCNV/infos/cohort_all/cohort_1-calls --calls-shard-path /data/xiangxd/project/test/PD_WES_50/cnv_calling/GATK_gCNV/infos/cohort_all/cohort_2-calls --calls-shard-path /data/xiangxd/project/test/PD_WES_50/cnv_calling/GATK_gCNV/infos/cohort_all/cohort_3-calls --calls-shard-path /data/xiangxd/project/test/PD_WES_50/cnv_calling/GATK_gCNV/infos/cohort_all/cohort_4-calls --calls-shard-path /data/xiangxd/project/test/PD_WES_50/cnv_calling/GATK_gCNV/infos/cohort_all/cohort_5-calls --calls-shard-path /data/xiangxd/project/test/PD_WES_50/cnv_calling/GATK_gCNV/infos/cohort_all/cohort_6-calls --calls-shard-path /data/xiangxd/project/test/PD_WES_50/cnv_calling/GATK_gCNV/infos/cohort_all/cohort_7-calls --calls-shard-path /data/xiangxd/project/test/PD_WES_50/cnv_calling/GATK_gCNV/infos/cohort_all/cohort_8-calls --calls-shard-path /data/xiangxd/project/test/PD_WES_50/cnv_calling/GATK_gCNV/infos/cohort_all/cohort_9-calls --calls-shard-path /data/xiangxd/project/test/PD_WES_50/cnv_calling/GATK_gCNV/infos/cohort_all/cohort_10-calls --calls-shard-path /data/xiangxd/project/test/PD_WES_50/cnv_calling/GATK_gCNV/infos/cohort_all/cohort_11-calls --calls-shard-path /data/xiangxd/project/test/PD_WES,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8776:37893,test,test,37893,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8776,1,['test'],['test']
Testability,/test/PD_WES_50/cnv_calling/GATK_gCNV/infos/cohort_all/cohort_39-model --model-shard-path /data/xiangxd/project/test/PD_WES_50/cnv_calling/GATK_gCNV/infos/cohort_all/cohort_40-model --model-shard-path /data/xiangxd/project/test/PD_WES_50/cnv_calling/GATK_gCNV/infos/cohort_all/cohort_41-model --model-shard-path /data/xiangxd/project/test/PD_WES_50/cnv_calling/GATK_gCNV/infos/cohort_all/cohort_42-model --model-shard-path /data/xiangxd/project/test/PD_WES_50/cnv_calling/GATK_gCNV/infos/cohort_all/cohort_43-model --model-shard-path /data/xiangxd/project/test/PD_WES_50/cnv_calling/GATK_gCNV/infos/cohort_all/cohort_44-model --model-shard-path /data/xiangxd/project/test/PD_WES_50/cnv_calling/GATK_gCNV/infos/cohort_all/cohort_45-model --calls-shard-path /data/xiangxd/project/test/PD_WES_50/cnv_calling/GATK_gCNV/infos/cohort_all/cohort_1-calls --calls-shard-path /data/xiangxd/project/test/PD_WES_50/cnv_calling/GATK_gCNV/infos/cohort_all/cohort_2-calls --calls-shard-path /data/xiangxd/project/test/PD_WES_50/cnv_calling/GATK_gCNV/infos/cohort_all/cohort_3-calls --calls-shard-path /data/xiangxd/project/test/PD_WES_50/cnv_calling/GATK_gCNV/infos/cohort_all/cohort_4-calls --calls-shard-path /data/xiangxd/project/test/PD_WES_50/cnv_calling/GATK_gCNV/infos/cohort_all/cohort_5-calls --calls-shard-path /data/xiangxd/project/test/PD_WES_50/cnv_calling/GATK_gCNV/infos/cohort_all/cohort_6-calls --calls-shard-path /data/xiangxd/project/test/PD_WES_50/cnv_calling/GATK_gCNV/infos/cohort_all/cohort_7-calls --calls-shard-path /data/xiangxd/project/test/PD_WES_50/cnv_calling/GATK_gCNV/infos/cohort_all/cohort_8-calls --calls-shard-path /data/xiangxd/project/test/PD_WES_50/cnv_calling/GATK_gCNV/infos/cohort_all/cohort_9-calls --calls-shard-path /data/xiangxd/project/test/PD_WES_50/cnv_calling/GATK_gCNV/infos/cohort_all/cohort_10-calls --calls-shard-path /data/xiangxd/project/test/PD_WES_50/cnv_calling/GATK_gCNV/infos/cohort_all/cohort_11-calls --calls-shard-path /data/xiangxd/project/test/PD_WES,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8776:13429,test,test,13429,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8776,2,['test'],['test']
Testability,/test/PD_WES_50/cnv_calling/GATK_gCNV/infos/cohort_all/cohort_39-model --model-shard-path /data/xiangxd/project/test/PD_WES_50/cnv_calling/GATK_gCNV/infos/cohort_all/cohort_40-model --model-shard-path /data/xiangxd/project/test/PD_WES_50/cnv_calling/GATK_gCNV/infos/cohort_all/cohort_41-model --model-shard-path /data/xiangxd/project/test/PD_WES_50/cnv_calling/GATK_gCNV/infos/cohort_all/cohort_42-model --model-shard-path /data/xiangxd/project/test/PD_WES_50/cnv_calling/GATK_gCNV/infos/cohort_all/cohort_43-model --model-shard-path /data/xiangxd/project/test/PD_WES_50/cnv_calling/GATK_gCNV/infos/cohort_all/cohort_44-model --model-shard-path /data/xiangxd/project/test/PD_WES_50/cnv_calling/GATK_gCNV/infos/cohort_all/cohort_45-model --model-shard-path /data/xiangxd/project/test/PD_WES_50/cnv_calling/GATK_gCNV/infos/cohort_all/cohort_1-model --model-shard-path /data/xiangxd/project/test/PD_WES_50/cnv_calling/GATK_gCNV/infos/cohort_all/cohort_2-model --model-shard-path /data/xiangxd/project/test/PD_WES_50/cnv_calling/GATK_gCNV/infos/cohort_all/cohort_3-model --model-shard-path /data/xiangxd/project/test/PD_WES_50/cnv_calling/GATK_gCNV/infos/cohort_all/cohort_4-model --model-shard-path /data/xiangxd/project/test/PD_WES_50/cnv_calling/GATK_gCNV/infos/cohort_all/cohort_5-model --model-shard-path /data/xiangxd/project/test/PD_WES_50/cnv_calling/GATK_gCNV/infos/cohort_all/cohort_6-model --model-shard-path /data/xiangxd/project/test/PD_WES_50/cnv_calling/GATK_gCNV/infos/cohort_all/cohort_7-model --model-shard-path /data/xiangxd/project/test/PD_WES_50/cnv_calling/GATK_gCNV/infos/cohort_all/cohort_8-model --model-shard-path /data/xiangxd/project/test/PD_WES_50/cnv_calling/GATK_gCNV/infos/cohort_all/cohort_9-model --model-shard-path /data/xiangxd/project/test/PD_WES_50/cnv_calling/GATK_gCNV/infos/cohort_all/cohort_10-model --model-shard-path /data/xiangxd/project/test/PD_WES_50/cnv_calling/GATK_gCNV/infos/cohort_all/cohort_11-model --model-shard-path /data/xiangxd/project/test/PD_WES,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8776:27921,test,test,27921,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8776,1,['test'],['test']
Testability,/test/PD_WES_50/cnv_calling/GATK_gCNV/infos/cohort_all/cohort_8-calls --calls-shard-path /data/xiangxd/project/test/PD_WES_50/cnv_calling/GATK_gCNV/infos/cohort_all/cohort_9-calls --calls-shard-path /data/xiangxd/project/test/PD_WES_50/cnv_calling/GATK_gCNV/infos/cohort_all/cohort_10-calls --calls-shard-path /data/xiangxd/project/test/PD_WES_50/cnv_calling/GATK_gCNV/infos/cohort_all/cohort_11-calls --calls-shard-path /data/xiangxd/project/test/PD_WES_50/cnv_calling/GATK_gCNV/infos/cohort_all/cohort_12-calls --calls-shard-path /data/xiangxd/project/test/PD_WES_50/cnv_calling/GATK_gCNV/infos/cohort_all/cohort_13-calls --calls-shard-path /data/xiangxd/project/test/PD_WES_50/cnv_calling/GATK_gCNV/infos/cohort_all/cohort_14-calls --calls-shard-path /data/xiangxd/project/test/PD_WES_50/cnv_calling/GATK_gCNV/infos/cohort_all/cohort_15-calls --calls-shard-path /data/xiangxd/project/test/PD_WES_50/cnv_calling/GATK_gCNV/infos/cohort_all/cohort_16-calls --calls-shard-path /data/xiangxd/project/test/PD_WES_50/cnv_calling/GATK_gCNV/infos/cohort_all/cohort_17-calls --calls-shard-path /data/xiangxd/project/test/PD_WES_50/cnv_calling/GATK_gCNV/infos/cohort_all/cohort_18-calls --calls-shard-path /data/xiangxd/project/test/PD_WES_50/cnv_calling/GATK_gCNV/infos/cohort_all/cohort_19-calls --calls-shard-path /data/xiangxd/project/test/PD_WES_50/cnv_calling/GATK_gCNV/infos/cohort_all/cohort_20-calls --calls-shard-path /data/xiangxd/project/test/PD_WES_50/cnv_calling/GATK_gCNV/infos/cohort_all/cohort_21-calls --calls-shard-path /data/xiangxd/project/test/PD_WES_50/cnv_calling/GATK_gCNV/infos/cohort_all/cohort_22-calls --calls-shard-path /data/xiangxd/project/test/PD_WES_50/cnv_calling/GATK_gCNV/infos/cohort_all/cohort_23-calls --calls-shard-path /data/xiangxd/project/test/PD_WES_50/cnv_calling/GATK_gCNV/infos/cohort_all/cohort_24-calls --calls-shard-path /data/xiangxd/project/test/PD_WES_50/cnv_calling/GATK_gCNV/infos/cohort_all/cohort_25-calls --calls-shard-path /data/xiangxd/project/test,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8776:14976,test,test,14976,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8776,3,['test'],['test']
Testability,/test/PD_WES_50/cnv_calling/GATK_gCNV/infos/cohort_all/cohort_8-model --model-shard-path /data/xiangxd/project/test/PD_WES_50/cnv_calling/GATK_gCNV/infos/cohort_all/cohort_9-model --model-shard-path /data/xiangxd/project/test/PD_WES_50/cnv_calling/GATK_gCNV/infos/cohort_all/cohort_10-model --model-shard-path /data/xiangxd/project/test/PD_WES_50/cnv_calling/GATK_gCNV/infos/cohort_all/cohort_11-model --model-shard-path /data/xiangxd/project/test/PD_WES_50/cnv_calling/GATK_gCNV/infos/cohort_all/cohort_12-model --model-shard-path /data/xiangxd/project/test/PD_WES_50/cnv_calling/GATK_gCNV/infos/cohort_all/cohort_13-model --model-shard-path /data/xiangxd/project/test/PD_WES_50/cnv_calling/GATK_gCNV/infos/cohort_all/cohort_14-model --model-shard-path /data/xiangxd/project/test/PD_WES_50/cnv_calling/GATK_gCNV/infos/cohort_all/cohort_15-model --model-shard-path /data/xiangxd/project/test/PD_WES_50/cnv_calling/GATK_gCNV/infos/cohort_all/cohort_16-model --model-shard-path /data/xiangxd/project/test/PD_WES_50/cnv_calling/GATK_gCNV/infos/cohort_all/cohort_17-model --model-shard-path /data/xiangxd/project/test/PD_WES_50/cnv_calling/GATK_gCNV/infos/cohort_all/cohort_18-model --model-shard-path /data/xiangxd/project/test/PD_WES_50/cnv_calling/GATK_gCNV/infos/cohort_all/cohort_19-model --model-shard-path /data/xiangxd/project/test/PD_WES_50/cnv_calling/GATK_gCNV/infos/cohort_all/cohort_20-model --model-shard-path /data/xiangxd/project/test/PD_WES_50/cnv_calling/GATK_gCNV/infos/cohort_all/cohort_21-model --model-shard-path /data/xiangxd/project/test/PD_WES_50/cnv_calling/GATK_gCNV/infos/cohort_all/cohort_22-model --model-shard-path /data/xiangxd/project/test/PD_WES_50/cnv_calling/GATK_gCNV/infos/cohort_all/cohort_23-model --model-shard-path /data/xiangxd/project/test/PD_WES_50/cnv_calling/GATK_gCNV/infos/cohort_all/cohort_24-model --model-shard-path /data/xiangxd/project/test/PD_WES_50/cnv_calling/GATK_gCNV/infos/cohort_all/cohort_25-model --model-shard-path /data/xiangxd/project/test,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8776:9990,test,test,9990,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8776,3,['test'],['test']
Testability,/test/resources/large/cnv_germline_workflows_test_files/inputs/wgs_pon/model_final/target_specific_mean_log_bias.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wgs_pon/model_final/target_specific_unexplained_variance.tsv; src/test/resources/large/cnv/realistic-targets.tab; src/test/resources/large/cnv_somatic_workflows_test_files/ice_targets_sample-chr20.interval_list; src/test/resources/large/cnv_somatic_workflows_test_files/wes-do-gc.pon.hdf5; src/test/resources/large/cnv_somatic_workflows_test_files/wes-no-gc.pon.hdf5; src/test/resources/large/cnv/truncated-realistic-targets.tab; src/test/resources/large/dbsnp_138.b37.1.1-65M.vcf.idx; src/test/resources/large/dbsnp_138.b37.20.21.vcf.blockgz.gz.tbi; src/test/resources/large/expected.NA12878.RNAseq.splitNcigarReads.bai; src/test/resources/large/expected.NA12878.RNAseq.splitNcigarReads.doNotFixOverhangs.bai; src/test/resources/large/expected.NA12878.RNAseq.splitNcigarReads.maxBasesInOverhang5.bai; src/test/resources/large/expected.NA12878.RNAseq.splitNcigarReads.maxMismatchesInOverhang0.bai; src/test/resources/large/gencode.v19.LargeFile.gtf.idx; src/test/resources/large/gencode.v26.primary_assembly.annotation.XYZ.gtf.idx; src/test/resources/large/gvcfs/CEUTrio.20.21.gatk3.4.g.vcf.idx; src/test/resources/large/gvcfs/combined.gatk3.7_30_ga4f720357.g.vcf.gz.tbi; src/test/resources/large/gvcfs/combined.gatk3.7.g.vcf.gz.tbi; src/test/resources/large/gvcfs/gatk3.7_30_ga4f720357.24_sample.21.g.vcf.idx; src/test/resources/large/gvcfs/HG00096.g.vcf.gz.tbi; src/test/resources/large/gvcfs/HG00268.g.vcf.gz.tbi; src/test/resources/large/gvcfs/NA19625.g.vcf.gz.tbi; src/test/resources/large/Homo_sapiens_assembly38.20.21.dict; src/test/resources/large/Homo_sapiens_assembly38.20.21.fasta.fai; src/test/resources/large/human_g1k_v37.20.21.fasta.amb; src/test/resources/large/human_g1k_v37.20.21.fasta.ann; src/test/resources/large/human_g1k_v37.20.21.fasta.bwt; src/test/resources/large/human_g1k_v37.20.21.fasta.p,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3905:5362,test,test,5362,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905,1,['test'],['test']
Testability,/test/resources/large/gvcfs/HG00268.g.vcf.gz.tbi; src/test/resources/large/gvcfs/NA19625.g.vcf.gz.tbi; src/test/resources/large/Homo_sapiens_assembly38.20.21.dict; src/test/resources/large/Homo_sapiens_assembly38.20.21.fasta.fai; src/test/resources/large/human_g1k_v37.20.21.fasta.amb; src/test/resources/large/human_g1k_v37.20.21.fasta.ann; src/test/resources/large/human_g1k_v37.20.21.fasta.bwt; src/test/resources/large/human_g1k_v37.20.21.fasta.pac; src/test/resources/large/human_g1k_v37.20.21.fasta.sa; src/test/resources/large/K-562.duplicateMarked.chr20.bai; src/test/resources/large/mutect/dream_synthetic_bams/normal_3.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/normal_4.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/normal.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/tumor_3.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/tumor_4.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/tumor.bam.bai; src/test/resources/large/NA12878.RNAseq.bai; src/test/resources/large/SVIntegrationTest.bam.bai; src/test/resources/large/very-small-gnomad.vcf.idx; src/test/resources/large/VQSR/ALL.wgs.indels_mills_devine_hg19_leftAligned_collapsed_double_hit.sites.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/combined.phase1.chr20.raw.indels.filtered.sites.1M-10M.vcf.idx; src/test/resources/large/VQSR/dbsnp_132_b37.leftAligned.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/expected/snpRecal.scattered.vcf.idx; src/test/resources/large/VQSR/expected/snpSampledRecal.vcf.idx; src/test/resources/large/VQSR/indelRecal.vcf.idx; src/test/resources/large/VQSR/Omni25_sites_1525_samples.b37.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/phase1.projectConsensus.chr20.1M-10M.raw.snps.vcf.idx; src/test/resources/large/VQSR/sites_r27_nr.b37_fwd.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/snpRecal.vcf.idx; src/test/resources/NA12878.chr17_69k_70k.dictFix.bam.bai; src/test/resources/NA12878.chr17_69k_70k.dictFix.cram.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3905:6913,test,test,6913,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905,1,['test'],['test']
Testability,/test/resources/org/broadinstitute/hellbender/tools/BQSR/HiSeq.1mb.1RG.2k_lines.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/human_b36_both.chr1_1k.dict; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/human_b36_both.chr1_1k.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/NA12878.chr17_69k_70k.dictFix.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/NA12878.oq.read_consumes_zero_ref_bases.chr20.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/na.bam; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/na.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/originalQuals.1kg.chr1.1-1K.1RG.dictFix.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/overlappingRead.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/solid.bam; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/solid.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/clippingReadsTest.withRG.hg19.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/clippingReadsTestCRAM.cram; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/clippingReadsTest.withRG.hg19.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTestCRAM.QT_10.cram; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTestCRAM.QT_10.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.CT_15_1115.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.CT_15_1115.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.CT_15.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.CT_15.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipRea,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3905:22611,test,test,22611,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905,1,['test'],['test']
Testability,/test/resources/org/broadinstitute/hellbender/tools/HiSeq.1mb.1RG.empty.table.gz; src/test/resources/org/broadinstitute/hellbender/tools/HiSeq.1mb.1RG.noSG.table.gz; src/test/resources/org/broadinstitute/hellbender/tools/HiSeq.1mb.1RG.sg1.table.gz; src/test/resources/org/broadinstitute/hellbender/tools/HiSeq.1mb.1RG.sg2.table.gz; src/test/resources/org/broadinstitute/hellbender/tools/HiSeq.1mb.1RG.sg3.table.gz; src/test/resources/org/broadinstitute/hellbender/tools/HiSeq.1mb.1RG.sg4.table.gz; src/test/resources/org/broadinstitute/hellbender/tools/HiSeq.1mb.1RG.sg5.table.gz; src/test/resources/org/broadinstitute/hellbender/tools/Homo_sapiens_assembly18.10k_lines.dict; src/test/resources/org/broadinstitute/hellbender/tools/Homo_sapiens_assembly18.10k_lines.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/mutect/dream/vcfs/dream3-chr20.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/mutect/dream/vcfs/sample_1.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/mutect/dream/vcfs/sample_2.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/mutect/dream/vcfs/sample_3.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/mutect/dream/vcfs/sample_4.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/mutect/na12878-chr20-consumes-zero-reference-bases.bai; src/test/resources/org/broadinstitute/hellbender/tools/mutect/repeated_reads.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/mutect/validation/nearby_indels.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/NA12878.rg_subset.chr1.recal_data.table.gz; src/test/resources/org/broadinstitute/hellbender/tools/NA12878.rg_subset.chrY_Plus.recal_data.table.gz; src/test/resources/org/broadinstitute/hellbender/tools/originalQuals.chr1.1-1K.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/print_reads.chr1only.dict; src/test/resources/org/broadinstitute/hellbender/tools/print_reads.chr1only.fasta.fai; src/test/reso,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3905:38941,test,test,38941,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905,1,['test'],['test']
Testability,/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/ice_trunc_sex_genotypes.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/ice_trunc_targets_some_missing.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/ice_trunc_targets.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/ice_trunc_targets_with_bait_counts.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/sex_genotyper_agilent_targets_trunc.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/sex_genotypes_broadies_basic.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/sex_genotypes_broadies_extended.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/snps-basic-with-phase-posteriors.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/snps-full-with-phase-posteriors.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/snps-intermediate-with-phase-posteriors.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/snps-simplified-for-allelic-fraction-transformation.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/test_reference.dict; src/test/resources/org/broadinstitute/hellbender/tools/exome/test_reference.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/expected.originalQuals.chr1.1-1K.bam.QT_10_CT_15_X_CCCCC.bai; src/test/resources/org/broadinstitute/hellbender/tools/expected.originalQuals.chr1.1-1K.bam.QT_10_CT_15_X_CCCCC.bam; src/test/resources/org/broadinstitute/hellbender/tools/expected.originalQuals.chr1.1-1K.bam.QT_10_CT_15_X_CCCCC.tmp; src/test/resources/org/broadinstitute/hellbender/tools/FixCallSetSampleOrdering/badlySorted1000-batch-size13.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/flag_stat.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/flag_stat.fasta; src/test/resources/org/broadinstitute/he,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3905:35359,test,test,35359,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905,1,['test'],['test']
Testability,/test/resources/org/broadinstitute/hellbender/tools/haplotypecaller/expected.testGVCFMode.gatk3.5.alleleSpecific.g.vcf; src/test/resources/org/broadinstitute/hellbender/tools/haplotypecaller/expected.testGVCFMode.gatk3.5.g.vcf; src/test/resources/org/broadinstitute/hellbender/tools/haplotypecaller/expected.testGVCFMode.gatk3.8-4-g7b0250253f.alleleSpecific.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/haplotypecaller/expected.testVCFMode.gatk3.5.alleleSpecific.vcf; src/test/resources/org/broadinstitute/hellbender/tools/haplotypecaller/expected.testVCFMode.gatk3.5.vcf; src/test/resources/org/broadinstitute/hellbender/tools/haplotypecaller/expected.testVCFMode.gatk3.8-4-g7b0250253f.alleleSpecific.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/haplotypecaller/expected.testVCFMode.gatk3.8-4-g7b0250253.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/haplotypecaller/pretendTobeTetraPloidTetraAllelicSite.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/HiSeq.1mb.1RG.empty.table.gz; src/test/resources/org/broadinstitute/hellbender/tools/HiSeq.1mb.1RG.noSG.table.gz; src/test/resources/org/broadinstitute/hellbender/tools/HiSeq.1mb.1RG.sg1.table.gz; src/test/resources/org/broadinstitute/hellbender/tools/HiSeq.1mb.1RG.sg2.table.gz; src/test/resources/org/broadinstitute/hellbender/tools/HiSeq.1mb.1RG.sg3.table.gz; src/test/resources/org/broadinstitute/hellbender/tools/HiSeq.1mb.1RG.sg4.table.gz; src/test/resources/org/broadinstitute/hellbender/tools/HiSeq.1mb.1RG.sg5.table.gz; src/test/resources/org/broadinstitute/hellbender/tools/Homo_sapiens_assembly18.10k_lines.dict; src/test/resources/org/broadinstitute/hellbender/tools/Homo_sapiens_assembly18.10k_lines.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/mutect/dream/vcfs/dream3-chr20.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/mutect/dream/vcfs/sample_1.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/mutect/d,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3905:37976,test,test,37976,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905,1,['test'],['test']
Testability,/test/resources/org/broadinstitute/hellbender/tools/validation/single.read.bai; src/test/resources/org/broadinstitute/hellbender/tools/valid.cram.crai; src/test/resources/org/broadinstitute/hellbender/tools/valid.dict; src/test/resources/org/broadinstitute/hellbender/tools/valid.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/VQSR/VQSR.AStest.indels.recal.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/VQSR/VQSR.AStest.input.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/VQSR/VQSR.AStest.postSNPinput.HACKEDhg38header.vcf.gz.tbi; src/test/resources/org/broadinstitute/hellbender/tools/VQSR/VQSR.AStest.postSNPinput.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/VQSR/VQSR.AStest.snps.recal.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/VQSR/VQSR.mixedTest.input.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/VQSR/VQSR.mixedTest.recal.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/annotator/allelespecific/CombineGVCFs.output.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/annotator/allelespecific/CombineGVCFs.output.withoutIndex.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/annotator/allelespecific/GenotypeGVCFs.output.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/annotator/allelespecific/HCOutputWithASAnnotation.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/annotator/allelespecific/NA12878.AS.chr20snippet.g.unindexed.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/annotator/allelespecific/NA12878.AS.chr20snippet.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/annotator/allelespecific/NA12878.AS.InsertSizeRankSum.chr20snippet.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/annotator/allelespecific/NA12878.AS.MateRankSum.chr20snippet.g.vcf.idx; src/test/resources/org/broadi,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3905:46696,test,test,46696,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905,1,['test'],['test']
Testability,/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/complexEvents.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/gvcf.basepairResolution.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet_BAD_INCOMPLETE_REGION.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet.BAD_MISSING_NON_REF.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet.missingrefblock.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleBad3.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleBad.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleGood.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleRSIDonPositionNotInDBSNP.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationUnusedAllelesBugFix.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/validation/basicshortmutpileup/IS3.snv.indel.sv-vs-G15512.prenormal.sorted.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/validation/basicshortmutpileup/synthetic.challenge.set1.tumor-vs-synthetic.challenge.set1.normal-filtered.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/CalculateGenotypePosteriors/CEUtriMixedPloidyTest.vcf; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/CalculateGenotypePosteriors/CEUtrioPopPriorsTest_chr1.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/CalculateGenotype,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3905:61317,test,test,61317,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905,1,['test'],['test']
Testability,/test/resources/org/broadinstitute/hellbender/tools/walkers/rnaseq/ASEReadCounter/NA12878.chr20_2444518_2637800.RNAseq.warnings.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/UnmarkDuplicates/allDuplicates.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/complexEvents_incompatibleDict.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/complexEvents_lexDict.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/complexEvents.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/gvcf.basepairResolution.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet_BAD_INCOMPLETE_REGION.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet.BAD_MISSING_NON_REF.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet.missingrefblock.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleBad3.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleBad.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleGood.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleRSIDonPositionNotInDBSNP.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationUnusedAllelesBugFix.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/validation/basicshortmutpileup/IS3.snv.indel.sv-vs-G15512.prenormal.sorted.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/vali,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3905:60850,test,test,60850,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905,1,['test'],['test']
Testability,/tests/classes/org.broadinstitute.hellbender.tools.walkers.filters.VariantFiltrationIntegrationTest.html#testClusteredSnps. ```; java.lang.RuntimeException: htsjdk.tribble.TribbleException: Exception encountered in worker thread.; at org.broadinstitute.hellbender.utils.test.IntegrationTestSpec.executeTest(IntegrationTestSpec.java:153); at org.broadinstitute.hellbender.utils.test.IntegrationTestSpec.executeTest(IntegrationTestSpec.java:126); at org.broadinstitute.hellbender.utils.test.IntegrationTestSpec.executeTest(IntegrationTestSpec.java:108); at org.broadinstitute.hellbender.tools.walkers.filters.VariantFiltrationIntegrationTest.testClusteredSnps(VariantFiltrationIntegrationTest.java:36); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:497); at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); at org.testng.internal.Invoker.invokeMethod(Invoker.java:639); at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:821); at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1131); at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); at org.testng.TestRunner.privateRun(TestRunner.java:773); at org.testng.TestRunner.run(TestRunner.java:623); at org.testng.SuiteRunner.runTest(SuiteRunner.java:357); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:352); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:310); at org.testng.SuiteRunner.run(SuiteRunner.java:259); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1185); at org.testng.TestNG.ru,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1638:1353,test,testng,1353,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1638,1,['test'],['testng']
Testability,/tools/ArtificallyContaminatedBams/contamination.case.3.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.4.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.5.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.6.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.7.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.8.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.broken.1.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.broken.2.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.broken.3.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.broken.4.txt; src/test/resources/org/broadinstitute/hellbender/tools/ArtificallyContaminatedBams/contamination.case.broken.5.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/bqsr.fakeSitesForTesting.b37.chr17.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/bqsr.fakeSitesForTesting.b37.chr20.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/bqsr.manyObservations.full.table.gz; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/bqsr.manyObservations.piece.table.gz; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.noMD.noBQSR.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.noMD.noBQSR.cram.bai; src/test/resources/org/broadinstitute/hellbender/t,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3905:17438,test,test,17438,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905,1,['test'],['test']
Testability,/tools/coveragemodel/calling_sample_sex_genotypes.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/learning_combined_copy_number.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/learning_combined_read_counts.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/learning_sample_bias_latent.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/learning_sample_read_depth.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/learning_sample_sex_genotypes.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_contig_anots.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_HMM_priors_table.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_model; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_model/mean_bias_covariates_matrix.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_model/target_specific_mean_log_bias.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_model/target_specific_unexplained_variance.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_targets.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/acnv-segments-from-allelic-integration.seg; src/test/resources/org/broadinstitute/hellbender/tools/exome/af-params-from-allelic-integration.af.param; src/test/resources/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldown-1.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldown-2.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldown-3.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldown-4.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/dupReadsMini.bam.bai; src/test/resources/org/broadinstitute,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3905:28632,test,test,28632,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905,1,['test'],['test']
Testability,/tools/coveragemodel/sim_model; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_model/mean_bias_covariates_matrix.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_model/target_specific_mean_log_bias.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_model/target_specific_unexplained_variance.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_targets.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/acnv-segments-from-allelic-integration.seg; src/test/resources/org/broadinstitute/hellbender/tools/exome/af-params-from-allelic-integration.af.param; src/test/resources/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldown-1.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldown-2.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldown-3.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldown-4.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/dupReadsMini.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-NA12778.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-NA12872.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-NA12878.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-NA12878.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-sample-NA12878.output; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/test_reference.dict; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/test_reference.fasta.fai; src/test/resources/,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3905:29446,test,test,29446,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905,2,['test'],"['test', 'test-pulldown-']"
Testability,/tools/exome/exome-read-counts-test-targets.tsv.idx; src/test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-test-targets-wo-coords.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/germlinehmm/homo_sapiens_germline_HMM_priors.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/germlinehmm/TCGA_T_matrix_autosomal_bad.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/pon-input.tab; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/contig_annots_bad_autosomal_annot.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/contig_annots_bad_class.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/contig_annots_bad_missing_some_annots.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/ice_trunc_rcc.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/ice_trunc_sex_genotypes.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/ice_trunc_targets_some_missing.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/ice_trunc_targets.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/ice_trunc_targets_with_bait_counts.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/sex_genotyper_agilent_targets_trunc.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/sex_genotypes_broadies_basic.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/sex_genotypes_broadies_extended.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/snps-basic-with-phase-posteriors.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/snps-full-with-phase-posteriors.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/snps-intermediate-with-phase-po,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3905:34404,test,test,34404,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905,1,['test'],['test']
Testability,/tools/flag_stat.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/flag_stat.fasta; src/test/resources/org/broadinstitute/hellbender/tools/genome/HCC1143_chr22_27M_37M.tiny.bam; src/test/resources/org/broadinstitute/hellbender/tools/genome/HCC1143_chr22_27M_37M.tiny.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/genome/HCC1143_chr3_1K_11K.tiny.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/GenomicsDBImport/testHeaderContigLineSorting1.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/GenomicsDBImport/testHeaderContigLineSorting2.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/haplotypecaller/expected.testGVCFMode.3.8-4-g7b0250253f.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/haplotypecaller/expected.testGVCFMode.gatk3.5.alleleSpecific.g.vcf; src/test/resources/org/broadinstitute/hellbender/tools/haplotypecaller/expected.testGVCFMode.gatk3.5.g.vcf; src/test/resources/org/broadinstitute/hellbender/tools/haplotypecaller/expected.testGVCFMode.gatk3.8-4-g7b0250253f.alleleSpecific.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/haplotypecaller/expected.testVCFMode.gatk3.5.alleleSpecific.vcf; src/test/resources/org/broadinstitute/hellbender/tools/haplotypecaller/expected.testVCFMode.gatk3.5.vcf; src/test/resources/org/broadinstitute/hellbender/tools/haplotypecaller/expected.testVCFMode.gatk3.8-4-g7b0250253f.alleleSpecific.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/haplotypecaller/expected.testVCFMode.gatk3.8-4-g7b0250253.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/haplotypecaller/pretendTobeTetraPloidTetraAllelicSite.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/HiSeq.1mb.1RG.empty.table.gz; src/test/resources/org/broadinstitute/hellbender/tools/HiSeq.1mb.1RG.noSG.table.gz; src/test/resources/org/broadinstitute/hellbender/tools/HiSeq.1mb.1RG.sg1.table.gz; src/test/resources/org/broadinstitute/hell,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3905:37232,test,test,37232,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905,1,['test'],['test']
Testability,/tools/walkers/CombineGVCFs/spanningDel.1.copy.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/spanningDel.1.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/spanningDel.2.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/spanningDeletionRestrictToStartExpected.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/spanningDel.many.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/spanningDel.many.haploid.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/spanningDel.many.tetraploid.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/testAlleleSpecificAnnotationsNoGroup.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/testAlleleSpecificAnnotations.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/testBasepairResolutionInput.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/testBreakBandsArgumet.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/testMultipleSpanningDeletionsForOneSampleHaploid.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/testMultipleSpanningDeletionsForOneSampleTetraploid.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/testMultipleSpanningDeletionsForOneSample.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/testWrongReferenceBaseBugFix.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/tetraploid-gvcf-1.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/tetraploid-gvcf-2.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/tetraploid-gvcf-3.vcf.idx; src/test/,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3905:50750,test,test,50750,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905,2,['test'],"['test', 'testBasepairResolutionInput']"
Testability,/tools/walkers/GenotypeGVCFs/gvcfExample1.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/GenotypeGVCFs/leadingDeletion.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/GenotypeGVCFs/spanningDel.combined.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/GenotypeGVCFs/spanningDel.delOnly.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/GenotypeGVCFs/spanningDel.depr.delOnly.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/GenotypeGVCFs/testUpdatePGT.gvcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/MarkDuplicatesGATK/example.chr1.1-1K.markedDups.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/walkers/MarkDuplicatesGATK/example.chr1.1-1K.unmarkedDups.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/walkers/MarkDuplicatesGATK/example.chr1.1-1K.unmarkedDups.noDups.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/walkers/MarkDuplicatesGATK/markDups.test2reads.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/walkers/MarkDuplicatesGATK/merge2.sam; src/test/resources/org/broadinstitute/hellbender/tools/walkers/MarkDuplicatesGATK/merge3.sam; src/test/resources/org/broadinstitute/hellbender/tools/walkers/MarkDuplicatesGATK/optical_dupes.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/walkers/MarkDuplicatesGATK/optical_dupes_casava.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/walkers/MarkDuplicatesGATK/optical_dupes.dict; src/test/resources/org/broadinstitute/hellbender/tools/walkers/MarkDuplicatesGATK/optical_dupes.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/walkers/qc/pileup/reads_data_source_test1.samtools.baq.pileup.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/qc/pileup/reads_data_source_test1.samtools.pileup.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/rnaseq/ASEReadC,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3905:58346,test,test,58346,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905,1,['test'],['test']
Testability,/tools/walkers/annotator/allelespecific/NA12892.AS.chr20snippet.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/annotator/allelespecific/NA12892.AS.InsertSizeRankSum.chr20snippet.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/annotator/allelespecific/NA12892.AS.MateRankSum.chr20snippet.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/annotator/allelespecific/NA12892.AS.MateRankSum.chr20snippet.withoutIndex.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/annotator/VariantAnnotatorEngine/one_entry_source.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/combine-gvcf-wrong-ref-input1.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/combine-gvcf-wrong-ref-input2.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/convertToBasePairResolution.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/gvcf.basepairResolution.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/gvcfExample1.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/gvcfExample2.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/IntervalTest.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/NA12878.AS.chr20snippet.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/NA12892.AS.chr20snippet.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/spanningDel.1.copy.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/spanningDel.1.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/spanningDel.2.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/spanningDeletionRestrictToStart,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3905:49126,test,test,49126,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905,1,['test'],['test']
Testability,/validation/marked.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.bam; src/test/resources/org/broadinstitute/hellbender/tools/validation/picard.marked.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.bam; src/test/resources/org/broadinstitute/hellbender/tools/validation/single.read.bai; src/test/resources/org/broadinstitute/hellbender/tools/valid.cram.crai; src/test/resources/org/broadinstitute/hellbender/tools/valid.dict; src/test/resources/org/broadinstitute/hellbender/tools/valid.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/VQSR/VQSR.AStest.indels.recal.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/VQSR/VQSR.AStest.input.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/VQSR/VQSR.AStest.postSNPinput.HACKEDhg38header.vcf.gz.tbi; src/test/resources/org/broadinstitute/hellbender/tools/VQSR/VQSR.AStest.postSNPinput.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/VQSR/VQSR.AStest.snps.recal.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/VQSR/VQSR.mixedTest.input.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/VQSR/VQSR.mixedTest.recal.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/annotator/allelespecific/CombineGVCFs.output.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/annotator/allelespecific/CombineGVCFs.output.withoutIndex.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/annotator/allelespecific/GenotypeGVCFs.output.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/annotator/allelespecific/HCOutputWithASAnnotation.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/annotator/allelespecific/NA12878.AS.chr20snippet.g.unindexed.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/annotator/allelespecific/NA12878.AS.chr20snippet.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/annotator/allelespecific/NA12878.AS.InsertSi,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3905:46516,test,test,46516,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905,1,['test'],['test']
Testability,/walkers/CombineGVCFs/spanningDel.1.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/spanningDel.2.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/spanningDeletionRestrictToStartExpected.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/spanningDel.many.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/spanningDel.many.haploid.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/spanningDel.many.tetraploid.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/testAlleleSpecificAnnotationsNoGroup.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/testAlleleSpecificAnnotations.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/testBasepairResolutionInput.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/testBreakBandsArgumet.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/testMultipleSpanningDeletionsForOneSampleHaploid.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/testMultipleSpanningDeletionsForOneSampleTetraploid.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/testMultipleSpanningDeletionsForOneSample.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/testWrongReferenceBaseBugFix.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/tetraploid-gvcf-1.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/tetraploid-gvcf-2.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/tetraploid-gvcf-3.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/filters/VariantFiltration/expected/testVariantFiltration,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3905:50863,test,test,50863,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905,2,['test'],"['test', 'testBreakBandsArgumet']"
Testability,/wes_pon/model_final/bias_covariates_ARD_coefficients.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/mean_bias_covariates_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/mean_bias_covariates_norm2.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/target_specific_mean_log_bias.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/target_specific_unexplained_variance.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/bias_covariates_ARD_coefficients_history.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/copy_ratio_max_likelihood_estimate_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/copy_ratio_precision_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/copy_ratio_Viterbi_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/log_likelihood_history.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/sample_bias_latent_posteriors.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/sample_log_likelihoods.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/sample_read_depth_posteriors.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/sample_specific_unexplained_variance.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/segments/SM-74NEG.seg; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/segments/SM-74P2T.seg; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3905:2672,test,test,2672,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905,1,['test'],['test']
Testability,/wes_pon/model_final/mean_bias_covariates_norm2.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/target_specific_mean_log_bias.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/target_specific_unexplained_variance.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/bias_covariates_ARD_coefficients_history.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/copy_ratio_max_likelihood_estimate_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/copy_ratio_precision_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/copy_ratio_Viterbi_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/log_likelihood_history.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/sample_bias_latent_posteriors.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/sample_log_likelihoods.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/sample_read_depth_posteriors.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/sample_specific_unexplained_variance.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/segments/SM-74NEG.seg; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/segments/SM-74P2T.seg; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/segments/SM-74P35.seg; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/total_covariate_bias_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_fina,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3905:2913,test,test,2913,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905,1,['test'],['test']
Testability,"0	0|1	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|1	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0; ```; Running `$HOME/gatk-4.0.11.0/gatk --java-options ""-Xmx4g"" HaplotypeCaller -R $HOME/GRCh37files/hs37d5.fa -I /mnt/fast/test.bam -O test.out.vcf.gz -L 22 --genotyping-mode GENOTYPE_GIVEN_ALLELES --alleles test.vcf.gz`, the resulting error is:; ```; java.lang.IllegalStateException: Allele in genotype GGTTTGTTT not in the variant context [GGTTTGTTT*, GGTTTGTTTGTTT, GGTTTGTTTGTTTGTTT, G]; at htsjdk.variant.variantcontext.VariantContext.validateGenotypes(VariantContext.java:1360); at htsjdk.variant.variantcontext.VariantContext.validate(VariantContext.java:1298); at htsjdk.variant.variantcontext.VariantContext.<init>(VariantContext.java:401); at htsjdk.variant.variantcontext.VariantContextBuilder.make(VariantContextBuilder.java:494); at htsjdk.variant.variantcontext.VariantContextBuilder.make(VariantContextBuilder.java:488); at org.broadinstitute.hellbender.utils.variant.GATKVariantContextUtils.simpleMerge(GATKVariantContextUtils.java:864); at org.broadinstitute.hellbender.utils.variant.GATKVariantContextUtils.simpleMerge(GATKVariantContextUtils.java:646); at org.broadinstitute.hellbender.tools.walkers",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5355:40869,test,test,40869,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5355,1,['test'],['test']
Testability,0); Caused by: org.gradle.api.GradleException: Javadoc generation failed. Generated Javadoc options file (useful for troubleshooting): '/vsc-hard-mounts/leuven-data/304/vsc30484/git/gatk/build/tmp/gatkTabComplete/javadoc.options'; at org.gradle.api.tasks.javadoc.internal.JavadocGenerator.execute(JavadocGenerator.java:58); at org.gradle.api.tasks.javadoc.internal.JavadocGenerator.execute(JavadocGenerator.java:31); at org.gradle.api.tasks.javadoc.Javadoc.executeExternalJavadoc(Javadoc.java:152); at org.gradle.api.tasks.javadoc.Javadoc.generate(Javadoc.java:140); at org.gradle.internal.reflect.JavaMethod.invoke(JavaMethod.java:75); at org.gradle.api.internal.project.taskfactory.DefaultTaskClassInfoStore$StandardTaskAction.doExecute(DefaultTaskClassInfoStore.java:136); at org.gradle.api.internal.project.taskfactory.DefaultTaskClassInfoStore$StandardTaskAction.execute(DefaultTaskClassInfoStore.java:129); at org.gradle.api.internal.project.taskfactory.DefaultTaskClassInfoStore$StandardTaskAction.execute(DefaultTaskClassInfoStore.java:118); at org.gradle.api.internal.AbstractTask$TaskActionWrapper.execute(AbstractTask.java:623); at org.gradle.api.internal.AbstractTask$TaskActionWrapper.execute(AbstractTask.java:606); at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.executeAction(ExecuteActionsTaskExecuter.java:80); at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.executeActions(ExecuteActionsTaskExecuter.java:61); ... 68 more; Caused by: org.gradle.process.internal.ExecException: Process 'command '/vsc-hard-mounts/leuven-apps/thinking/2015a/software/Java/1.8.0_144/bin/javadoc'' finished with non-zero exit value 1; at org.gradle.process.internal.DefaultExecHandle$ExecResultImpl.assertNormalExitValue(DefaultExecHandle.java:369); at org.gradle.process.internal.DefaultExecAction.execute(DefaultExecAction.java:31); at org.gradle.api.tasks.javadoc.internal.JavadocGenerator.execute(JavadocGenerator.java:53); ... 79 more. BUILD FAILED; ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4155:9752,assert,assertNormalExitValue,9752,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4155,1,['assert'],['assertNormalExitValue']
Testability,"0.100;MQ=60.00;MQRankSum=0.000;QD=0.46;ReadPosRankSum=-0.300;SOR=2.792 GT:AD:DP:GQ:PL 0/0/0/0/0/0/0/0/0/1:85,3:88:34:66,0,34,78,132,196,276,380,528,782,6199; contig00001 8244 . T C 43.68 . AC=1;AF=0.100;AN=10;BaseQRankSum=-0.838;ClippingRankSum=0.000;DP=80;FS=15.529;MLEAC=1;MLEAF=0.100;MQ=60.00;MQRankSum=0.000;QD=0.55;ReadPosRankSum=-1.716;SOR=2.783 GT:AD:DP:GQ:PL 0/0/0/0/0/0/0/0/0/1:77,3:80:31:69,0,31,71,119,178,251,347,482,716,5872; contig00001 8846 . C T 72.68 . AC=1;AF=0.100;AN=10;BaseQRankSum=0.659;ClippingRankSum=0.000;DP=88;FS=2.385;MLEAC=1;MLEAF=0.100;MQ=59.93;MQRankSum=0.273;QD=0.83;ReadPosRankSum=-4.696;SOR=1.102 GT:AD:DP:GQ:PL 0/0/0/0/0/0/0/0/0/1:84,4:88:31:98,0,31,72,124,186,264,366,510,759,3392; contig00001 9854 . A G 42.69 . AC=1;AF=0.100;AN=10;BaseQRankSum=0.463;ClippingRankSum=0.000;DP=79;FS=11.687;MLEAC=1;MLEAF=0.100;MQ=60.00;MQRankSum=0.000;QD=0.55;ReadPosRankSum=1.267;SOR=2.799 GT:AD:DP:GQ:PL 0/0/0/0/0/0/0/0/0/1:74,3:77:29:68,0,29,66,111,166,235,324,450,665,2970; contig00001 19796 . A G 34.70 . AC=1;AF=0.100;AN=10;BaseQRankSum=-2.543;ClippingRankSum=0.000;DP=66;FS=10.825;MLEAC=1;MLEAF=0.100;MQ=60.00;MQRankSum=0.000;QD=0.53;ReadPosRankSum=-0.600;SOR=0.829 GT:AD:DP:GQ:PL 0/0/0/0/0/0/0/0/0/1:63,3:66:23:60,0,23,54,93,140,199,275,384,572,2745; contig00001 20699 . T C 47.70 . AC=1;AF=0.100;AN=10;BaseQRankSum=0.326;ClippingRankSum=0.000;DP=66;FS=2.442;MLEAC=1;MLEAF=0.1; ```. When I run . ```gatk VariantFiltration -V GenomeA.rawSNPs.vcf -filter ""QD < 20.0"" --filter-name ""snp_def"" -O test.vcf```. or. ```gatk VariantFiltration -R ../GenomeA_contigs.fa -V GenomeA.rawSNPs.vcf -filter ""QD < 20.0"" --filter-name ""snp_def"" -O test.vcf```. I get the following error:. ```A USER ERROR has occurred: Invalid argument '>'.```. I tried to use different operators and style ```""""``` rather than ```''``` but the error is still the same.; I was hoping that there is a mistake in my code but it seems to be a bug to me.; I run on a HPC with a slurm managing system. ; Thank you",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6241:1804,test,test,1804,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6241,2,['test'],['test']
Testability,"00 KB. 18:03:07.612 WARN TaskSetManager:70 - Stage 182 contains a task of very large size (119 KB). The maximum recommended task size is 100 KB.; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x000000010a5a9401, pid=2425, tid=8963; #; # JRE version: Java(TM) SE Runtime Environment (8.0_91-b14) (build 1.8.0_91-b14); # Java VM: Java HotSpot(TM) 64-Bit Server VM (25.91-b14 mixed mode bsd-amd64 compressed oops); # Problematic frame:; # V [libjvm.dylib+0x1a9401]; #; # Failed to write core dump. Core dumps have been disabled. To enable core dumping, try ""ulimit -c unlimited"" before starting Java again; #; # An error report file with more information is saved as:; # /Users/louisb/Workspace/gatk-protected/hs_err_pid2425.log; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; #; ```. [hs_err_pid2425.log.txt](https://github.com/broadinstitute/gatk-protected/files/448383/hs_err_pid2425.log.txt). @yfarjoun Is this similar to the crash you saw a while back?. ---. @yfarjoun commented on [Wed Aug 31 2016](https://github.com/broadinstitute/gatk-protected/issues/659#issuecomment-243946864). no. this is different. On Wed, Aug 31, 2016 at 3:27 PM, Louis Bergelson notifications@github.com; wrote:. > I got a segfault while running CreatePanelOfNormalsIntegrationTest.; > Subsequent runs were unable to reproduce it.; > ; > 18:03:07.573 WARN TaskSetManager:70 - Stage 181 contains a task of very large size (119 KB). The maximum recommended task size is 100 KB.; > Test: Test method testAllTargetsHDF5PoNCreationSpark[0](null, src/test/resources/org/broadinstitute/hellbender/tools/exome/create-pon-control-full.pcov)(org.broadinstitute.hellbender.tools.exome.CreatePanelOfNormalsIntegrationTest) produced standard out/err: 18:03:07.612 WARN TaskSetManager:70 - Stage 182 contains a task of very large size (119 KB). The maximum recommended task size is 100 KB.; > ; > ```; > 18:03:07.612 WAR",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2883:1750,log,log,1750,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2883,1,['log'],['log']
Testability,00.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_138.b37.excluding_sites_after_129.ch20.1m-1m1k.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.noMD.noBQSR.md.bqsr.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.postRecalibrated.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.recalibrated.DIQ.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m20k.NA12878.2inputs.recal.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m20k.NA12878.indels_context_size_4.recal.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m20k.NA12878.low_quality_tail_5.recal.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m20k.NA12878.mismatches_context_size_4.recal.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m20k.NA12878.quantizing_levels_6.recal.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m20k.NA12878.recal.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.HiSeq.1mb.1RG.2k_lines.alternate.recalibrated.DIQ.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.HiSeq.1mb.1RG.2k_lines.bqsr.qq-1.alternate.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.HiSeq.1mb.1RG.2k_lines.bqsr.qq6.alternate.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.MultiSite.reads.pipeline.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.MultiSite.reads.pipeline.cram.bai; src/test/resources/org/broadinstitute/hell,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3905:20297,test,test,20297,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905,1,['test'],['test']
Testability,"0076845511-How-do-I-SelectVariants-from-GenomicsDB-stored-in-GCS-#community\_comment\_360014183291](https://gatk.broadinstitute.org/hc/en-us/community/posts/360076845511-How-do-I-SelectVariants-from-GenomicsDB-stored-in-GCS-#community_comment_360014183291). \--. Thank you, it has started to work with gendb.gs://. But now I think it does not run. I have only one sample stored into the database and I'm selecting only chr20:1-1000000 and it is running for more than 30 minutes. Is it expected?. I'm using a VM from GCE, in the same region as the GCS bucket. Using GATK jar /home/taniguti/gatk-4.1.9.0/gatk-package-4.1.9.0-local.jar ; ; ```; Running: ; ;    java -Dsamjdk.use\_async\_io\_read\_samtools=false -Dsamjdk.use\_async\_io\_write\_samtools=true -Dsamjdk.use\_async\_io\_write\_tribble=false -Dsamjdk.compression\_level=2 -Xmx10g -Xms5g - ; ; jar /home/taniguti/gatk-4.1.9.0/gatk-package-4.1.9.0-local.jar SelectVariants -R Homo\_sapiens\_assembly38.fasta -V gendb.gs://mybucket/genomicsdb -L chr20:1-1000000 -O teste. ; ; vcf.gz ; ; 23:01:23.595 INFO  NativeLibraryLoader - Loading libgkl\_compression.so from jar:file:/home/taniguti/gatk-4.1.9.0/gatk-package-4.1.9.0-local.jar!/com/intel/gkl/native/libgkl\_compres ; ; sion.so ; ; 23:01:23.914 INFO  SelectVariants - ------------------------------------------------------------ ; ; 23:01:23.915 INFO  SelectVariants - The Genome Analysis Toolkit (GATK) v4.1.9.0 ; ; 23:01:23.915 INFO  SelectVariants - For support and documentation go to [https://software.broadinstitute.org/gatk/](https://software.broadinstitute.org/gatk/) ; ; 23:01:23.918 INFO  SelectVariants - Executing as taniguti@phasing-shapeit4-taniguti on Linux v5.4.0-1036-gcp amd64 ; ; 23:01:23.918 INFO  SelectVariants - Java runtime: OpenJDK 64-Bit Server VM v11.0.9.1+1-Ubuntu-0ubuntu1.20.04 ; ; 23:01:23.919 INFO  SelectVariants - Start Date/Time: February 1, 2021 at 11:01:23 PM UTC ; ; 23:01:23.919 INFO  SelectVariants - --------------------------------------------------",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7070:1502,test,teste,1502,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7070,1,['test'],['teste']
Testability,"0190327_David_rampseq_Ehsan/data/samtools_sorted_out/SNPs_candidates.g.vcf; 09:28:39.708 INFO ProgressMeter - Starting traversal; 09:28:39.708 INFO ProgressMeter - Current Locus Elapsed Minutes Records Processed Records/Minute; =========This is the indexed chromosome ===================; 09:28:41.968 INFO ProgressMeter - **chr7B_part2:295520629** 0.0 925631 24596040.7. 09:28:41.968 INFO ProgressMeter - Traversal complete. Processed 925631 total records in 0.0 minutes.; 09:28:42.006 INFO IndexFeatureFile - Successfully wrote index to /storage/ppl/yifang/20190327/data/samtools_sorted_out/SNPs_candidates.g.vcf.idx; 09:28:42.006 INFO IndexFeatureFile - Shutting down engine; [May 6, 2019 9:28:42 CST AM] org.broadinstitute.hellbender.tools.IndexFeatureFile done. Elapsed time: 0.05 minutes.; Runtime.totalMemory()=2434269184). ```; This is my command line:; `java -DGATK_STACKTRACE_ON_USER_EXCEPTION=true -jar ${gatk4_jar} IndexFeatureFile --feature-file ${gvcf} --output ${gvcf}.idx 2>${LOGDIR}/index_candidates.log`. I tried this exact command line with another genome, which worked just fine with output progress report as following for a comparison of the multiple chromosomes processed:; ```; 12:50:38.871 INFO ProgressMeter - Starting traversal; 12:50:38.873 INFO ProgressMeter - Current Locus Elapsed Minutes Records Processed Records/Minute; 12:50:48.876 INFO ProgressMeter - N1:21408210 0.2 5669000 34010598.9; 12:50:58.876 INFO ProgressMeter - N2:13383863 0.3 11960000 35874618.8. ...... 12:55:58.884 INFO ProgressMeter - N19:50063133 5.3 208660000 39122405.2; 12:56:02.409 INFO ProgressMeter - N19:55994806 5.4 210940859 39119265.4; 12:56:02.409 INFO ProgressMeter - Traversal complete. Processed 210940859 total records in 5.4 minutes.; 12:56:02.429 INFO IndexFeatureFile - Successfully wrote index to /storage/ppl/yifang/20190225/data3/samtools_sorted_out/SNPs_candidates.g.vcf.idx; 12:56:02.429 INFO IndexFeatureFile - Shutting down engine; [April 25, 2019 12:56:02 PM CST] org.broad",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5917:4721,LOG,LOGDIR,4721,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5917,1,['LOG'],['LOGDIR']
Testability,"07, 2021 12:21 UTC. . Link: [https://gatk.broadinstitute.org/hc/en-us/community/posts/4403256366107--java-lang-ArrayIndexOutOfBoundsException-32772-while-running-GenotypeGVCFs](https://gatk.broadinstitute.org/hc/en-us/community/posts/4403256366107--java-lang-ArrayIndexOutOfBoundsException-32772-while-running-GenotypeGVCFs). \--. i don't get an error but the massge  java.lang.ArrayIndexOutOfBoundsException: 32772 ; ; i use : GATK version used: 4.2.0 ; ; b) Exact command used  this line for Geomics DBImport. gatk GenomicsDBImport -V MA1.g.vcf -V MA2.g.vcf -V MA3.g.vcf -V MH1.g.vcf -V MH2.g.vcf -V MH3.g.vcf -V F4\_1.g.vcf -V F4\_2.g.vcf -V F4\_3.g.vcf --genomicsdb-workspace-path my\_database1AB -L 1A -L 1B -L 2A -L 2B -L 3A -L 3B -L 4A -L 4B -L 5A -L 5B -L 6A -L 6B -L 7A -L 7B. and this for GenotypeGVCFs. gatk --java-options ""-Xmx12g -Xms12g"" GenotypeGVCFs -R Triticum\_dicoccoides.WEWSeq\_v.1.0.dna.toplevel.fa -V gendb://my\_database -O output.vcf.gz --new-qual --tmp-dir temp/. c) Entire error log:. Using GATK jar /home/alonzi/miniconda3/envs/rna-seq/share/gatk4-4.2.0.0-1/gatk-package-4.2.0.0-local.jar ; ; Running: ; ; java -Dsamjdk.use\_async\_io\_read\_samtools=false -Dsamjdk.use\_async\_io\_write\_samtools=true -Dsamjdk.use\_async\_io\_write\_tribble=false -Dsamjdk.compression\_level=2 -Xmx12g -Xms12g -jar /home/alonzi/miniconda3/envs/rna-seq/share/gatk4-4.2.0.0-1/gatk-package-4.2.0.0-local.jar GenotypeGVCFs -R Triticum\_dicoccoides.WEWSeq\_v.1.0.dna.toplevel.fa -V gendb://my\_database -O output.vcf.gz --new-qual --tmp-dir temp/ ; ; 14:28:22.448 INFO NativeLibraryLoader - Loading libgkl\_compression.so from jar:file:/home/alonzi/miniconda3/envs/rna-seq/share/gatk4-4.2.0.0-1/gatk-package-4.2.0.0-local.jar!/com/intel/gkl/native/libgkl\_compression.so ; ; Jul 07, 2021 2:28:22 PM shaded.cloud\_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine ; ; INFO: Failed to detect whether we are running on Google Compute Engine. ; ; 14:28:22.617 INFO Genoty",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7348:1561,log,log,1561,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7348,1,['log'],['log']
Testability,"0:01.719 INFO GermlineCNVCaller - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 10:20:01.719 INFO GermlineCNVCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 10:20:01.719 INFO GermlineCNVCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 10:20:01.719 INFO GermlineCNVCaller - Deflater: IntelDeflater; 10:20:01.719 INFO GermlineCNVCaller - Inflater: IntelInflater; 10:20:01.719 INFO GermlineCNVCaller - GCS max retries/reopens: 20; 10:20:01.719 INFO GermlineCNVCaller - Requester pays: disabled; 10:20:01.720 INFO GermlineCNVCaller - Initializing engine; 10:20:07.111 INFO GermlineCNVCaller - Done initializing engine; 10:20:07.207 INFO GermlineCNVCaller - Running the tool in CASE mode...; 10:20:07.207 INFO GermlineCNVCaller - Validating and aggregating data from input read-count files...; 10:20:07.231 INFO GermlineCNVCaller - Aggregating read-count file /media/Ergebnisse/0115-24_Masterpanel_NB501654_0623/0115-24_noProbe.hdf5 (1 / 1); log4j:WARN No appenders could be found for logger (org.broadinstitute.hdf5.HDF5Library).; log4j:WARN Please initialize the log4j system properly.; log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.; 10:20:25.874 INFO GermlineCNVCaller - Shutting down engine; [March 14, 2024 at 10:20:25 AM CET] org.broadinstitute.hellbender.tools.copynumber.GermlineCNVCaller done. Elapsed time: 0.40 minutes.; Runtime.totalMemory()=2147483648; org.broadinstitute.hellbender.utils.python.PythonScriptExecutorException:; python exited with 1; Command Line: python /media/Data/tmp/case_denoising_calling.3564509013495540802.py --ploidy_calls_path=/media/Ergebnisse/0115-24_Masterpanel_NB501654_0623/0115-24_DGCP_noProbe-calls --output_calls_path=/media/Ergebnisse/0115-24_Masterpanel_NB501654_0623/0115-24_GCNV_noProbe-calls --output_tracking_path=/media/Ergebnisse/0115-24_Masterpanel_NB501654_0623/0115-24_GCNV_noProbe-tracking --input_model_path=/media/Data/MasterV3/GCNV_noProbe-model --random_seed=198",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8740:3700,log,logger,3700,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8740,1,['log'],['logger']
Testability,"0:38:16.247 INFO MarkDuplicatesSpark - For support and documentation go to https://software.broadinstitute.org/gatk/; 10:38:16.247 INFO MarkDuplicatesSpark - Executing as hcaoad@hhnode-ib-16 on Linux v3.10.0-1062.el7.x86_64 amd64; 10:38:16.247 INFO MarkDuplicatesSpark - Java runtime: OpenJDK 64-Bit Server VM v17.0.8-internal+0-adhoc..src; 10:38:16.247 INFO MarkDuplicatesSpark - Start Date/Time: October 18, 2023 at 10:38:16 AM HKT; 10:38:16.247 INFO MarkDuplicatesSpark - ------------------------------------------------------------; 10:38:16.247 INFO MarkDuplicatesSpark - ------------------------------------------------------------; 10:38:16.248 INFO MarkDuplicatesSpark - HTSJDK Version: 3.0.5; 10:38:16.248 INFO MarkDuplicatesSpark - Picard Version: 3.0.0; 10:38:16.248 INFO MarkDuplicatesSpark - Built for Spark Version: 3.3.1; 10:38:16.249 INFO MarkDuplicatesSpark - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 10:38:16.249 INFO MarkDuplicatesSpark - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 10:38:16.249 INFO MarkDuplicatesSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 10:38:16.249 INFO MarkDuplicatesSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 10:38:16.249 INFO MarkDuplicatesSpark - Deflater: IntelDeflater; 10:38:16.249 INFO MarkDuplicatesSpark - Inflater: IntelInflater; 10:38:16.250 INFO MarkDuplicatesSpark - GCS max retries/reopens: 20; 10:38:16.250 INFO MarkDuplicatesSpark - Requester pays: disabled; 10:38:16.250 INFO MarkDuplicatesSpark - Initializing engine; 10:38:16.250 INFO MarkDuplicatesSpark - Done initializing engine; 10:38:17.179 INFO SparkContext - Running Spark version 3.3.0; ```. #### Steps to reproduce; The most wired thing is that this issue is very hard to reproduce. When running the command for hundreds of samples, this always happens to a few samples. However, if I re-submit my job for the failed sample, this error may just disappear. As the whole log file is too big, I can upload it later if need. Thanks.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8555:5530,log,log,5530,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8555,1,['log'],['log']
Testability,"0]. Here is my java version in case:; ```bash; $ java -version; openjdk version ""1.8.0_152-release""; OpenJDK Runtime Environment (build 1.8.0_152-release-1056-b12); OpenJDK 64-Bit Server VM (build 25.152-b12, mixed mode); ```. ### Description ; When the upstream path of the current directory contains a whitespace **and** the VCFs are stored in a directory 2 level deeper, the VCF is not found. The bug does not happen if:; * VCFs are located in current directory or in a subdirectory (level 1) from the current working directory (see reproducible steps below).; * VCFs have themselves whitespace in their filenames (see reproducible steps below). Here is a GATK stacktrace example:; ```java; Using GATK jar $HOME/local/pckg/python/miniconda3/envs/test/share/gatk4-4.1.7.0-0/gatk-package-4.1.7.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar $HOME/local/pckg/python/miniconda3/envs/test/share/gatk4-4.1.7.0-0/gatk-package-4.1.7.0-local.jar MergeVcfs -I data/calling/a.vcf.gz -I data/calling/b.vcf.gz -O c.vcf.gz; 23:25:05.033 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:$HOME/local/pckg/python/miniconda3/envs/test/share/gatk4-4.1.7.0-0/gatk-package-4.1.7.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; [Tue Jun 16 23:25:05 CDT 2020] MergeVcfs --INPUT data/calling/a.vcf.gz --INPUT data/calling/b.vcf.gz --OUTPUT c.vcf.gz --VERBOSITY INFO --QUIET false --VALIDATION_STRINGENCY STRICT --COMPRESSION_LEVEL 2 --MAX_RECORDS_IN_RAM 500000 --CREATE_INDEX true --CREATE_MD5_FILE false --GA4GH_CLIENT_SECRETS client_secrets.json --help false --version false --showHidden false --USE_JDK_DEFLATER false --USE_JDK_INFLATER false; Jun 16, 2020 11:25:05 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; [Tue Jun 16 23:",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6664:1193,test,test,1193,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6664,1,['test'],['test']
Testability,0_CT_15_X_CCCCC.bam; src/test/resources/org/broadinstitute/hellbender/tools/expected.originalQuals.chr1.1-1K.bam.QT_10_CT_15_X_CCCCC.tmp; src/test/resources/org/broadinstitute/hellbender/tools/FixCallSetSampleOrdering/badlySorted1000-batch-size13.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/flag_stat.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/flag_stat.fasta; src/test/resources/org/broadinstitute/hellbender/tools/genome/HCC1143_chr22_27M_37M.tiny.bam; src/test/resources/org/broadinstitute/hellbender/tools/genome/HCC1143_chr22_27M_37M.tiny.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/genome/HCC1143_chr3_1K_11K.tiny.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/GenomicsDBImport/testHeaderContigLineSorting1.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/GenomicsDBImport/testHeaderContigLineSorting2.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/haplotypecaller/expected.testGVCFMode.3.8-4-g7b0250253f.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/haplotypecaller/expected.testGVCFMode.gatk3.5.alleleSpecific.g.vcf; src/test/resources/org/broadinstitute/hellbender/tools/haplotypecaller/expected.testGVCFMode.gatk3.5.g.vcf; src/test/resources/org/broadinstitute/hellbender/tools/haplotypecaller/expected.testGVCFMode.gatk3.8-4-g7b0250253f.alleleSpecific.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/haplotypecaller/expected.testVCFMode.gatk3.5.alleleSpecific.vcf; src/test/resources/org/broadinstitute/hellbender/tools/haplotypecaller/expected.testVCFMode.gatk3.5.vcf; src/test/resources/org/broadinstitute/hellbender/tools/haplotypecaller/expected.testVCFMode.gatk3.8-4-g7b0250253f.alleleSpecific.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/haplotypecaller/expected.testVCFMode.gatk3.8-4-g7b0250253.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/haplotypecaller/pretendTobeTetraPloidTetraAllelicSite,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3905:36955,test,testGVCFMode,36955,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905,1,['test'],['testGVCFMode']
Testability,0snippet.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/annotator/allelespecific/NA12878.AS.MateRankSum.chr20snippet.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/annotator/allelespecific/NA12878.AS.MateRankSum.chr20snippet.withoutIndex.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/annotator/allelespecific/NA12891.AS.chr20snippet.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/annotator/allelespecific/NA12892.AS.chr20snippet.g.unsorted.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/annotator/allelespecific/NA12892.AS.chr20snippet.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/annotator/allelespecific/NA12892.AS.InsertSizeRankSum.chr20snippet.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/annotator/allelespecific/NA12892.AS.MateRankSum.chr20snippet.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/annotator/allelespecific/NA12892.AS.MateRankSum.chr20snippet.withoutIndex.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/annotator/VariantAnnotatorEngine/one_entry_source.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/combine-gvcf-wrong-ref-input1.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/combine-gvcf-wrong-ref-input2.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/convertToBasePairResolution.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/gvcf.basepairResolution.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/gvcfExample1.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/gvcfExample2.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/IntervalTest.vcf.idx; src/test/resources/org/broadinst,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3905:48515,test,test,48515,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905,1,['test'],['test']
Testability,"1 of 1): For input string: ""Float? (optional)""; 	at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.cromwell$engine$workflow$lifecycle$materialization$MaterializeWorkflowDescriptorActor$$workflowInitializationFailed(MaterializeWorkflowDescriptorActor.scala:235); 	at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anonfun$2.applyOrElse(MaterializeWorkflowDescriptorActor.scala:205); 	at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anonfun$2.applyOrElse(MaterializeWorkflowDescriptorActor.scala:200); 	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:38); 	at akka.actor.FSM.processEvent(FSM.scala:707); 	at akka.actor.FSM.processEvent$(FSM.scala:704); 	at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.akka$actor$LoggingFSM$$super$processEvent(MaterializeWorkflowDescriptorActor.scala:156); 	at akka.actor.LoggingFSM.processEvent(FSM.scala:847); 	at akka.actor.LoggingFSM.processEvent$(FSM.scala:829); 	at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.processEvent(MaterializeWorkflowDescriptorActor.scala:156); 	at akka.actor.FSM.akka$actor$FSM$$processMsg(FSM.scala:701); 	at akka.actor.FSM$$anonfun$receive$1.applyOrElse(FSM.scala:695); 	at akka.actor.Actor.aroundReceive(Actor.scala:539); 	at akka.actor.Actor.aroundReceive$(Actor.scala:537); 	at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.aroundReceive(MaterializeWorkflowDescriptorActor.scala:156); 	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:612); 	at akka.actor.ActorCell.invoke(ActorCell.scala:581); 	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:268); 	at akka.dispatch.Mailbox.run(Mailbox.scala:229); 	at akka.dispatch.Mailbox.exec(Mailbox.scala:241); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoi",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6189:7686,Log,LoggingFSM,7686,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6189,1,['Log'],['LoggingFSM']
Testability,"1) reads a kmer kill list (prepared by FindBadGenomicKmers),; 2) finds reads that support a notion of a breakpoint (split or discordant),; 3) kmerizes them for each breakpoint ignoring those kmers that are on the kill list, and then; 4) passes over all the reads again, pulling out those reads containing the breakpoint-supporting kmers.; 5) Finally, the reads to be assembled for each breakpoint are dumped into a FASTQ file.; FindBadGenomicKmers cleanup. More comments. Fewer magic values.; Added unit tests for Kmer class.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1434:504,test,tests,504,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1434,1,['test'],['tests']
Testability,1) removed a few dead classes: ; TestMath (subsumed by code in MathUtilsTests); AlignmentContext (had nothing more than what ReadPileup has); CsvInputParser (not used in picard not used in gatk). 2) created simple tests for the 'constants' classes - just checking that you can't make instances of them ; (fixed the code accordningly). 3) fixed ClassUtils + added tests to check that you cant make instances of classes without public constructors. 4) switched from JUnit assertArrayEquals to TestNG assertEquals for consistency with the rest of the code (we use TestNG everywhere). @lbergelson can you look at this?,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1513:33,Test,TestMath,33,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1513,7,"['Test', 'assert', 'test']","['TestMath', 'TestNG', 'assertArrayEquals', 'assertEquals', 'tests']"
Testability,"1. Add new arg `genomicsdb-shared-posixfs-optimizations` to help with shared posix filesystems like NFS and Lustre. This turns on `disable file locking` and for GenomicsDB import it minimizes writes to disks. The performance on some of the gatk datasets for the import of about 10 samples went from 23.72m to 6.34m on NFS which was comparable to importing to a local filesystem. Hopefully this helps with Issue #6487 and #6627. Also, fixes Issue #6519.; 2. This version of GenomicsDB also uses pre-compression filters for offset and compression files for new workspaces and genomicsdb arrays. The total sizes for a GenomicsDB workspace using the same dataset as above and the 10 samples went from 313MB to 170MB with no change in import and query times. Smaller GenomicsDB arrays also help with performance on distributed and cloud file systems.; 3. This version has added support to handle MNVs similar to deletions as described in Issue #6500. See [GenomicsDB PR 88](https://github.com/GenomicsDB/GenomicsDB/pull/88). Thanks @kgururaj.; 4. There is added support in the GenomicsDBImporter to have multiple contigs in the same GenomicsDB partition/array. This will hopefully help import times in cases where users have many thousands of contigs. See [GenomicsDB PR 91](https://github.com/GenomicsDB/GenomicsDB/pull/91). Changes will be needed from the gatk side to avail this support. Thanks @mlathara.; 5. Logging has been improved somewhat with the native C/C++ code using [spdlog](https://github.com/gabime/spdlog) and [fmt](https://github.com/fmtlib/fmt) and the Java layer using apache log4j and log4j.properties provided by the application. Also, info messages like `No valid combination operation found for INFO field AA - the field will NOT be part of INFO fields in the generated VCF records` will only be output once for the operation. Also see open PR #6514 for code to actually suppress these warnings for known fields.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6654:1408,Log,Logging,1408,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6654,1,['Log'],['Logging']
Testability,"1. User can define the number of Spark cores in gradle test by environmental variable GATK_TEST_SPARK_CORES. If the variable is not defined, or the value is bogus, will fall back to default of ""local[*]""; 2. Skip intelDeflator test on PPC platforms.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1776:55,test,test,55,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1776,2,['test'],['test']
Testability,1.fasta.amb; src/test/resources/large/human_g1k_v37.20.21.fasta.ann; src/test/resources/large/human_g1k_v37.20.21.fasta.bwt; src/test/resources/large/human_g1k_v37.20.21.fasta.pac; src/test/resources/large/human_g1k_v37.20.21.fasta.sa; src/test/resources/large/K-562.duplicateMarked.chr20.bai; src/test/resources/large/mutect/dream_synthetic_bams/normal_3.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/normal_4.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/normal.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/tumor_3.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/tumor_4.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/tumor.bam.bai; src/test/resources/large/NA12878.RNAseq.bai; src/test/resources/large/SVIntegrationTest.bam.bai; src/test/resources/large/very-small-gnomad.vcf.idx; src/test/resources/large/VQSR/ALL.wgs.indels_mills_devine_hg19_leftAligned_collapsed_double_hit.sites.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/combined.phase1.chr20.raw.indels.filtered.sites.1M-10M.vcf.idx; src/test/resources/large/VQSR/dbsnp_132_b37.leftAligned.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/expected/snpRecal.scattered.vcf.idx; src/test/resources/large/VQSR/expected/snpSampledRecal.vcf.idx; src/test/resources/large/VQSR/indelRecal.vcf.idx; src/test/resources/large/VQSR/Omni25_sites_1525_samples.b37.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/phase1.projectConsensus.chr20.1M-10M.raw.snps.vcf.idx; src/test/resources/large/VQSR/sites_r27_nr.b37_fwd.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/snpRecal.vcf.idx; src/test/resources/NA12878.chr17_69k_70k.dictFix.bam.bai; src/test/resources/NA12878.chr17_69k_70k.dictFix.cram.crai; src/test/resources/org/broadinstitute/hellbender/engine/ambiguityCodes.dict; src/test/resources/org/broadinstitute/hellbender/engine/ambiguityCodes.fasta.fai; src/test/resources/org/broadinstitute/hellbender/engine/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.10000000-1000002,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3905:7183,test,test,7183,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905,1,['test'],['test']
Testability,"1/Cosmic.db -> file:///home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s/cosmic/hg19/Cosmic.db; 15:41:51.190 INFO DataSourceUtils - Resolved data source file path: file:///home/shiyang/softwares/gatk-4.1.8.1/gencode.v34lift37.annotation.REORDERED.gtf -> file:///home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s/gencode/hg19/gencode.v34lift37.annotation.REORDERED.gtf; 15:41:51.190 INFO DataSourceUtils - Setting lookahead cache for data source: Gencode : 100000; 15:41:51.191 WARN GencodeGtfCodec - GENCODE GTF Header line 1 has a version number that is above maximum tested version (v 28) (given: 34): ##description: evidence-based annotation of the human genome (GRCh38), version 34 (Ensembl 100), mapped to GRCh37 with gencode-backmap Continuing, but errors may occur.; 15:41:51.192 WARN GencodeGtfCodec - GENCODE GTF Header line 1 has a version number that is above maximum tested version (v 28) (given: 34): ##description: evidence-based annotation of the human genome (GRCh38), version 34 (Ensembl 100), mapped to GRCh37 with gencode-backmap Continuing, but errors may occur.; 15:41:51.192 INFO FeatureManager - Using codec GencodeGtfCodec to read file file:///home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s/gencode/hg19/gencode.v34lift37.annotation.REORDERED.gtf; 15:41:51.193 WARN GencodeGtfCodec - GENCODE GTF Header line 1 has a version number that is above maximum tested version (v 28) (given: 34): ##description: evidence-based annotation of the human genome (GRCh38), version 34 (Ensembl 100), mapped to GRCh37 with gencode-backmap Continuing, but errors may occur.; 15:41:51.201 INFO DataSourceUtils - Resolved data source file path: file:///home/shiyang/softwares/gatk-4.1.8.1/gencode.v34lift37.pc_transcripts.fa -> file:///home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s/gencode/hg19/gencode.v34lift37.pc_transcripts.fa; 15:41:54.713 INFO Dat",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6758:18164,test,tested,18164,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6758,1,['test'],['tested']
Testability,"10068166 . A *,<NON_REF> . . DP=28 GT:AD:DP:GQ:PL:SB ./.:0,4,0:6:53:735,102,53,507,108,472:0,0,2,4; 20 10068167 . T *,<NON_REF> . . DP=28 GT:AD:DP:GQ:PL:SB ./.:0,4,0:6:53:735,102,53,507,108,472:0,0,2,4; 20 10068168 . A *,<NON_REF> . . DP=28 GT:AD:DP:GQ:PL:SB ./.:0,4,0:6:53:735,102,53,507,108,472:0,0,2,4; 20 10068169 . T *,<NON_REF> . . DP=28 GT:AD:DP:GQ:PL:SB ./.:0,4,0:6:53:735,102,53,507,108,472:0,0,2,4; 20 10068170 . A *,<NON_REF> . . DP=28 GT:AD:DP:GQ:PL:SB ./.:0,4,0:6:53:735,102,53,507,108,472:0,0,2,4; 20 10068171 . T *,<NON_REF> . . DP=28 GT:AD:DP:GQ:PL:SB ./.:0,4,0:6:53:735,102,53,507,108,472:0,0,2,4; 20 10068172 . G *,<NON_REF> . . DP=28 GT:AD:DP:GQ:PL:SB ./.:0,4,0:6:53:735,102,53,507,108,472:0,0,2,4; 20 10068173 . T *,<NON_REF> . . DP=28 GT:AD:DP:GQ:PL:SB ./.:0,4,0:6:53:735,102,53,507,108,472:0,0,2,4; 20 10068174 . A *,<NON_REF> . . DP=28 GT:AD:DP:GQ:PL:SB ./.:0,4,0:6:53:735,102,53,507,108,472:0,0,2,4; ```. GenomicsDBImport run like this:. ```; ./gatk GenomicsDBImport -R src/test/resources/large/human_g1k_v37.20.21.fasta -L 20 -V src/test/resources/org/broadinstitute/hellbender/tools/haplotypecaller/expected.testGVCFMode.gatk4.g.vcf -genomicsdb-workspace-path spanDelWorkspace; ./gatk SelectVariants -V gendb://spanDelWorkspace -R src/test/resources/large/human_g1k_v37.20.21.fasta -O test.g.vcf -L 20; ```. Returns the following output:. ```; 20 10068158 . GTGTATATATATA G,<NON_REF> . . BaseQRankSum=-6.520e-01;ClippingRankSum=0.00;DP=29;ExcessHet=3.01;MQRankSum=0.328;RAW_MQ=93364.00;ReadPosRankSum=-2.530e-0; 1 GT:AD:DP:GQ:PL:SB ./.:3,4,0:7:57:104,0,57,114,69,183:0,3,2,2; 20 10068159 . T *,<NON_REF> . . DP=29 GT:AD:DP:GQ:PL:SB ./.:3,4,0:7:57:104,0,57,114,69,183:0,3,2,2; 20 10068160 . GTATATATATATGTA G,*,<NON_REF> . . DP=28;ExcessHet=3.01;RAW_MQ=87005.00 GT:AD:DP:GQ:PL:SB ./.:0,2,4,0:6:53:735,162,131,102,0,53,507,174,108,472:0,0,; 2,4; 20 10068161 . T *,<NON_REF> . . DP=28 GT:AD:DP:GQ:PL:SB ./.:0,2,0:6:53:735,162,131,507,174,472:0,0,2,4; 20 10068162 . A *,<NON_REF>",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5160:3204,test,test,3204,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5160,1,['test'],['test']
Testability,"10068169 . T *,<NON_REF> . . DP=28 GT:AD:DP:GQ:PL:SB ./.:0,4,0:6:53:735,102,53,507,108,472:0,0,2,4; 20 10068170 . A *,<NON_REF> . . DP=28 GT:AD:DP:GQ:PL:SB ./.:0,4,0:6:53:735,102,53,507,108,472:0,0,2,4; 20 10068171 . T *,<NON_REF> . . DP=28 GT:AD:DP:GQ:PL:SB ./.:0,4,0:6:53:735,102,53,507,108,472:0,0,2,4; 20 10068172 . G *,<NON_REF> . . DP=28 GT:AD:DP:GQ:PL:SB ./.:0,4,0:6:53:735,102,53,507,108,472:0,0,2,4; 20 10068173 . T *,<NON_REF> . . DP=28 GT:AD:DP:GQ:PL:SB ./.:0,4,0:6:53:735,102,53,507,108,472:0,0,2,4; 20 10068174 . A *,<NON_REF> . . DP=28 GT:AD:DP:GQ:PL:SB ./.:0,4,0:6:53:735,102,53,507,108,472:0,0,2,4; ```. GenomicsDBImport run like this:. ```; ./gatk GenomicsDBImport -R src/test/resources/large/human_g1k_v37.20.21.fasta -L 20 -V src/test/resources/org/broadinstitute/hellbender/tools/haplotypecaller/expected.testGVCFMode.gatk4.g.vcf -genomicsdb-workspace-path spanDelWorkspace; ./gatk SelectVariants -V gendb://spanDelWorkspace -R src/test/resources/large/human_g1k_v37.20.21.fasta -O test.g.vcf -L 20; ```. Returns the following output:. ```; 20 10068158 . GTGTATATATATA G,<NON_REF> . . BaseQRankSum=-6.520e-01;ClippingRankSum=0.00;DP=29;ExcessHet=3.01;MQRankSum=0.328;RAW_MQ=93364.00;ReadPosRankSum=-2.530e-0; 1 GT:AD:DP:GQ:PL:SB ./.:3,4,0:7:57:104,0,57,114,69,183:0,3,2,2; 20 10068159 . T *,<NON_REF> . . DP=29 GT:AD:DP:GQ:PL:SB ./.:3,4,0:7:57:104,0,57,114,69,183:0,3,2,2; 20 10068160 . GTATATATATATGTA G,*,<NON_REF> . . DP=28;ExcessHet=3.01;RAW_MQ=87005.00 GT:AD:DP:GQ:PL:SB ./.:0,2,4,0:6:53:735,162,131,102,0,53,507,174,108,472:0,0,; 2,4; 20 10068161 . T *,<NON_REF> . . DP=28 GT:AD:DP:GQ:PL:SB ./.:0,2,0:6:53:735,162,131,507,174,472:0,0,2,4; 20 10068162 . A *,<NON_REF> . . DP=28 GT:AD:DP:GQ:PL:SB ./.:0,2,0:6:53:735,162,131,507,174,472:0,0,2,4; 20 10068163 . T *,<NON_REF> . . DP=28 GT:AD:DP:GQ:PL:SB ./.:0,2,0:6:53:735,162,131,507,174,472:0,0,2,4; 20 10068164 . A *,<NON_REF> . . DP=28 GT:AD:DP:GQ:PL:SB ./.:0,2,0:6:53:735,162,131,507,174,472:0,0,2,4; 20 10068165 . T *,<NON_",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5160:3517,test,test,3517,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5160,1,['test'],['test']
Testability,12878.RNAseq.splitNcigarReads.maxMismatchesInOverhang0.bai; src/test/resources/large/gencode.v19.LargeFile.gtf.idx; src/test/resources/large/gencode.v26.primary_assembly.annotation.XYZ.gtf.idx; src/test/resources/large/gvcfs/CEUTrio.20.21.gatk3.4.g.vcf.idx; src/test/resources/large/gvcfs/combined.gatk3.7_30_ga4f720357.g.vcf.gz.tbi; src/test/resources/large/gvcfs/combined.gatk3.7.g.vcf.gz.tbi; src/test/resources/large/gvcfs/gatk3.7_30_ga4f720357.24_sample.21.g.vcf.idx; src/test/resources/large/gvcfs/HG00096.g.vcf.gz.tbi; src/test/resources/large/gvcfs/HG00268.g.vcf.gz.tbi; src/test/resources/large/gvcfs/NA19625.g.vcf.gz.tbi; src/test/resources/large/Homo_sapiens_assembly38.20.21.dict; src/test/resources/large/Homo_sapiens_assembly38.20.21.fasta.fai; src/test/resources/large/human_g1k_v37.20.21.fasta.amb; src/test/resources/large/human_g1k_v37.20.21.fasta.ann; src/test/resources/large/human_g1k_v37.20.21.fasta.bwt; src/test/resources/large/human_g1k_v37.20.21.fasta.pac; src/test/resources/large/human_g1k_v37.20.21.fasta.sa; src/test/resources/large/K-562.duplicateMarked.chr20.bai; src/test/resources/large/mutect/dream_synthetic_bams/normal_3.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/normal_4.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/normal.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/tumor_3.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/tumor_4.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/tumor.bam.bai; src/test/resources/large/NA12878.RNAseq.bai; src/test/resources/large/SVIntegrationTest.bam.bai; src/test/resources/large/very-small-gnomad.vcf.idx; src/test/resources/large/VQSR/ALL.wgs.indels_mills_devine_hg19_leftAligned_collapsed_double_hit.sites.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/combined.phase1.chr20.raw.indels.filtered.sites.1M-10M.vcf.idx; src/test/resources/large/VQSR/dbsnp_132_b37.leftAligned.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/expected/snpReca,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3905:6381,test,test,6381,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905,1,['test'],['test']
Testability,"14427-Issue-when-running-BaseRecalibrator). \--. REQUIRED for all errors and issues: ; ; a) GATK version used:v4.2.6.1  ; ; b) Exact command used: see below ; ; c) Entire program log: see below ; ; **How can I assign a temp directory and won't get the bug?**. I always got error when I assigned the temp directory:. /data/xieduo/WES\_pipe/pipeline/bin/gatk-4.2.6.1/gatk --java-options ""-Xmx8G -Djava.io.tmpdir=/data/xieduo/Immun\_genomics/data/Łuksza\_2022\_Nature/shell/temp"" BaseRecalibrator -R /data/reference/gatk\_resource/Homo\_sapiens\_assembly38.fasta -I /data/xieduo/Immun\_genomics/data/Łuksza\_2022\_Nature/bam/PAAD11N.rmdup.bam --known-sites /data/xieduo/WES\_pipe/pipeline/gatk\_resource/dbsnp\_146.hg38.vcf.gz --known-sites /data/reference/gatk\_resource/1000G\_phase1.snps.high\_confidence.hg38.vcf.gz --known-sites /data/reference/gatk\_resource/Mills\_and\_1000G\_gold\_standard.indels.hg38.vcf.gz  -O /data/xieduo/Immun\_genomics/data/Łuksza\_2022\_Nature/bam/PAAD11N.recal\_data.test.table ; ; Using GATK jar /data/xieduo/WES\_pipe/pipeline/bin/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar ; ; Running: ; ;     java -Dsamjdk.use\_async\_io\_read\_samtools=false -Dsamjdk.use\_async\_io\_write\_samtools=true -Dsamjdk.use\_async\_io\_write\_tribble=false -Dsamjdk.compression\_level=2 -Xmx8G -Djava.io.tmpdir=/data/xieduo/Immun\_genomics/data/Łuksza\_2022\_Nature/shell/temp -jar /data/xieduo/WES\_pipe/pipeline/bin/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar BaseRecalibrator -R /data/reference/gatk\_resource/Homo\_sapiens\_assembly38.fasta -I /data/xieduo/Immun\_genomics/data/Łuksza\_2022\_Nature/bam/PAAD11N.rmdup.bam --known-sites /data/xieduo/WES\_pipe/pipeline/gatk\_resource/dbsnp\_146.hg38.vcf.gz --known-sites /data/reference/gatk\_resource/1000G\_phase1.snps.high\_confidence.hg38.vcf.gz --known-sites /data/reference/gatk\_resource/Mills\_and\_1000G\_gold\_standard.indels.hg38.vcf.gz -O /data/xieduo/Immun\_genomics/data/Łuksza\_2022\_Nature/bam/PAAD11N.recal\_data.test",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8005:1269,test,test,1269,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8005,1,['test'],['test']
Testability,"15307 . C T 50 PASS platforms=3;platformnames=Illumina,CG,10X;datasets=4;datasetnames=HiSeqPE100x,CGnormal,10XChromium,HiSeqMatePair;callsets=6;callsetnames=HiSeqPE100xSentieon,CGnormal,HiSeqPE100xfreebayes,10XSentieonhaplo,HiSeqMatePairSentieon,HiSeqMatePairfreebayes;callable=CS_HiSeqPE100xSentieon_callable,CS_CGnormal_callable,CS_HiSeqPE100xfreebayes_callable,CS_10XSentieonhaplo_callable;filt=CS_CGnormal_filt GT:PS:DP:ADALL:AD:GQ 0|1:241815307_C_T:286:53,44:47,41:1082; chr2 241815308 . A G 50 PASS platforms=3;platformnames=Illumina,CG,10X;datasets=4;datasetnames=HiSeqPE100x,CGnormal,10XChromium,HiSeqMatePair;callsets=6;callsetnames=HiSeqPE100xSentieon,CGnormal,HiSeqPE100xfreebayes,10XSentieonhaplo,HiSeqMatePairSentieon,HiSeqMatePairfreebayes;callable=CS_HiSeqPE100xSentieon_callable,CS_CGnormal_callable,CS_HiSeqPE100xfreebayes_callable,CS_10XSentieonhaplo_callable;filt=CS_CGnormal_filt GT:PS:DP:ADALL:AD:GQ 1|1:241815307_C_T:287:0,98:0,89:1; ```; </details>. while the test callset has the following single record:. <details>; <summary> Test callset </summary>. ```; chr2 241815307 . CA TG 1756.77 PASS AC=1;AF=0.5;AN=2;BaseQRankSum=-0.802;ClippingRankSum=0.521;DP=85;ExcessHet=3.0103;FS=2.902;MLEAC=1;MLEAF=0.5;MQ=60.0;MQRankSum=0.0;QD=20.67;ReadPosRankSum=-1.858;SOR=0.571 GT:AD:DP:F1R2:F2R1:GQ:PL 0/1:37,48:85:16,25,0:21,23,0:99:1785,0,1406; ```; </details>. Next, I looked at the reads from the haplotype assembly BAM supporting each of the three possible alleles in the test callset:. | Allele | # of reads |; | --- | --- |; | ref (`CA`) | 1 read |; | alt1 (`CG`) | 36 reads |; | alt 2 (`TG`) | 48 reads |. You can see the sum of the count of reads in the table is equal to the depth and sum of allelic depths in the VCF record. It is clear from the haplotype assembly BAM that the call should be `1/2` (`CG/TG`), but the finall call is `0/2` (`CA/TG`). . I then re-ran `HaplotypeCaller` without the `--max-mnp-distance 5` argument and got the variant call I expected, which matches",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5696:1604,test,test,1604,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5696,1,['test'],['test']
Testability,15_X_CCCCC.tmp; src/test/resources/org/broadinstitute/hellbender/tools/FixCallSetSampleOrdering/badlySorted1000-batch-size13.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/flag_stat.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/flag_stat.fasta; src/test/resources/org/broadinstitute/hellbender/tools/genome/HCC1143_chr22_27M_37M.tiny.bam; src/test/resources/org/broadinstitute/hellbender/tools/genome/HCC1143_chr22_27M_37M.tiny.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/genome/HCC1143_chr3_1K_11K.tiny.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/GenomicsDBImport/testHeaderContigLineSorting1.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/GenomicsDBImport/testHeaderContigLineSorting2.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/haplotypecaller/expected.testGVCFMode.3.8-4-g7b0250253f.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/haplotypecaller/expected.testGVCFMode.gatk3.5.alleleSpecific.g.vcf; src/test/resources/org/broadinstitute/hellbender/tools/haplotypecaller/expected.testGVCFMode.gatk3.5.g.vcf; src/test/resources/org/broadinstitute/hellbender/tools/haplotypecaller/expected.testGVCFMode.gatk3.8-4-g7b0250253f.alleleSpecific.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/haplotypecaller/expected.testVCFMode.gatk3.5.alleleSpecific.vcf; src/test/resources/org/broadinstitute/hellbender/tools/haplotypecaller/expected.testVCFMode.gatk3.5.vcf; src/test/resources/org/broadinstitute/hellbender/tools/haplotypecaller/expected.testVCFMode.gatk3.8-4-g7b0250253f.alleleSpecific.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/haplotypecaller/expected.testVCFMode.gatk3.8-4-g7b0250253.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/haplotypecaller/pretendTobeTetraPloidTetraAllelicSite.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/HiSeq.1mb.1RG.empty.table.gz; src/test/resources/org/broa,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3905:37077,test,testGVCFMode,37077,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905,1,['test'],['testGVCFMode']
Testability,163); 	at org.broadinstitute.hellbender.Main.instanceMain(Main.java:149); 	at org.broadinstitute.hellbender.Main.instanceMain(Main.java:190); 	at org.broadinstitute.hellbender.tools.walkers.vqsr.CNNVariantPipelineTest.testTrainingReadModel(CNNVariantPipelineTest.java:85); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:133); 	at org.testng.internal.TestInvoker.invokeMethod(TestInvoker.java:584); 	at org.testng.internal.TestInvoker.invokeTestMethod(TestInvoker.java:172); 	at org.testng.internal.MethodRunner.runInSequence(MethodRunner.java:46); 	at org.testng.internal.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:804); 	at org.testng.internal.TestInvoker.invokeTestMethods(TestInvoker.java:145); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:128); 	at java.util.ArrayList.forEach(ArrayList.java:1257); 	at org.testng.TestRunner.privateRun(TestRunner.java:770); 	at org.testng.TestRunner.run(TestRunner.java:591); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:402); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:396); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:355); 	at org.testng.SuiteRunner.run(SuiteRunner.java:304); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:53); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:96); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1180); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1102); 	at org.testng.TestNG.runSuites(TestNG.java:1032); 	at org.testng.TestNG.run(TestNG.java:1000); 	at org.gradle.api.internal.tasks.tes,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6307:3368,Test,TestInvoker,3368,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6307,1,['Test'],['TestInvoker']
Testability,167 DEBUG GenomeLocParser - chrUn_KI270749v1 (158759 bp); 23:44:43.167 DEBUG GenomeLocParser - chrUn_KI270750v1 (148850 bp); 23:44:43.167 DEBUG GenomeLocParser - chrUn_KI270751v1 (150742 bp); 23:44:43.167 DEBUG GenomeLocParser - chrUn_KI270752v1 (27745 bp); 23:44:43.167 DEBUG GenomeLocParser - chrUn_KI270753v1 (62944 bp); 23:44:43.167 DEBUG GenomeLocParser - chrUn_KI270754v1 (40191 bp); 23:44:43.167 DEBUG GenomeLocParser - chrUn_KI270755v1 (36723 bp); 23:44:43.167 DEBUG GenomeLocParser - chrUn_KI270756v1 (79590 bp); 23:44:43.167 DEBUG GenomeLocParser - chrUn_KI270757v1 (71251 bp); 23:44:43.167 DEBUG GenomeLocParser - chrUn_GL000214v1 (137718 bp); 23:44:43.167 DEBUG GenomeLocParser - chrUn_KI270742v1 (186739 bp); 23:44:43.167 DEBUG GenomeLocParser - chrUn_GL000216v2 (176608 bp); 23:44:43.167 DEBUG GenomeLocParser - chrUn_GL000218v1 (161147 bp); 23:44:43.167 DEBUG GenomeLocParser - chrEBV (171823 bp); 23:44:43.173 INFO GermlineCNVCaller - Aggregating read-count file /gpfs/hpc/home/lijc/xiangxud/project/test/NGS_WES_test/4_tools_vcf/gatk4/info/counts/V300033254_96.tsv (1 / 3); 23:44:43.345 INFO GermlineCNVCaller - Aggregating read-count file /gpfs/hpc/home/lijc/xiangxud/project/test/NGS_WES_test/4_tools_vcf/gatk4/info/counts/V300033256_95.tsv (2 / 3); 23:44:43.521 INFO GermlineCNVCaller - Aggregating read-count file /gpfs/hpc/home/lijc/xiangxud/project/test/NGS_WES_test/4_tools_vcf/gatk4/info/counts/V300033254_97.tsv (3 / 3); 23:44:43.683 DEBUG ScriptExecutor - Executing:; 23:44:43.683 DEBUG ScriptExecutor - python; 23:44:43.683 DEBUG ScriptExecutor - /tmp/cohort_denoising_calling.6786136740079319091.py; 23:44:43.683 DEBUG ScriptExecutor - --ploidy_calls_path=/gpfs/hpc/home/lijc/xiangxud/project/test/NGS_WES_test/4_tools_vcf/gatk4/info/ploidy/ploidy-calls; 23:44:43.683 DEBUG ScriptExecutor - --output_calls_path=/gpfs/hpc/home/lijc/xiangxud/project/test/NGS_WES_test/4_tools_vcf/gatk4/info/cohort_all/cohort_30-calls; 23:44:43.683 DEBUG ScriptExecutor - --output_tracking_,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8938:33380,test,test,33380,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8938,1,['test'],['test']
Testability,"16af50496640; 1. Make a cram file like this (in our src/test/resources/large):; `samtools view -C -T human_g1k_v37.20.21.fasta -o CEUTrio.HiSeq.WGS.b37.NA12878.20.21.cram CEUTrio.HiSeq.WGS.b37.NA12878.20.21.bam`; `samtools index CEUTrio.HiSeq.WGS.b37.NA12878.20.21.cram`; 2. run HC on it and compare with BAM:. ```; ./gatk-launch HaplotypeCaller -I ~/IdeaProjects/gatk/src/test/resources/large/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.cram -L 20:1-11000000 -R ~/IdeaProjects/gatk/src/test/resources/large/human_g1k_v37.20.21.fasta -O testa.cram.g.vcf -ERC GVCF --bamOutput testa.cram.outHC.bam; ```. time BAM : 0.7 minutes; time CRAM: 3.81 minutes. ---. @droazen commented on [Wed Apr 27 2016](https://github.com/broadinstitute/gatk-protected/issues/467#issuecomment-215194800). What if you run without `--bamOutput`? Is it still slow?. ---. @droazen commented on [Wed Apr 27 2016](https://github.com/broadinstitute/gatk-protected/issues/467#issuecomment-215202513). In addition to testing without `--bamOutput`, you should also try it with a `.bai` index on the cram, as @cmnbroad has identified issues with the current `.crai` support in htsjdk. ---. @akiezun commented on [Wed Apr 27 2016](https://github.com/broadinstitute/gatk-protected/issues/467#issuecomment-215214737). yes, still super slow without `--bamOutput`. ---. @akiezun commented on [Wed Apr 27 2016](https://github.com/broadinstitute/gatk-protected/issues/467#issuecomment-215216639). Should we blow up on crai and say it's unsupported for now? (better that than produce bogus results). Also, how do i make a bai file for a cram file?. ---. @droazen commented on [Wed Apr 27 2016](https://github.com/broadinstitute/gatk-protected/issues/467#issuecomment-215219095). @akiezun I defer to @cmnbroad on whether the issues with `crai` are bad enough to warrant such an approach. . You should be able to make a `bai` on the cram by running GATK `PrintReads` on it. ---. @cmnbroad commented on [Wed Apr 27 2016](https://github.com/broadinstitute",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2850:1111,test,testing,1111,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2850,1,['test'],['testing']
Testability,17_1Mb.fasta.fai; src/test/resources/iupacFASTA.dict; src/test/resources/iupacFASTA.fasta.fai; src/test/resources/joint_calling.chr1_1M.1kg_samples.10samples.noINFO.vcf.idx; src/test/resources/large/1000G.phase3.broad.withGenotypes.chr20.10100000.vcf.idx; src/test/resources/large/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.cram.bai; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/bias_covariates_ARD_coefficients.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/mean_bias_covariates_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/mean_bias_covariates_norm2.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/target_specific_mean_log_bias.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/model_final/target_specific_unexplained_variance.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/bias_covariates_ARD_coefficients_history.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/copy_ratio_max_likelihood_estimate_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/copy_ratio_precision_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/copy_ratio_Viterbi_matrix.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/log_likelihood_history.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/sample_bias_latent_posteriors.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/sample_log_likelihoods.tsv; src/test/resources/large/cnv_germline_workflows_test_files/inputs/wes_pon/posteriors_final/sample_read_depth_posteriors.tsv; src/test/resources/large/cnv_germline_workflows_test_f,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3905:2273,test,test,2273,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905,1,['test'],['test']
Testability,191); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:163); 	at org.broadinstitute.hellbender.Main.instanceMain(Main.java:149); 	at org.broadinstitute.hellbender.Main.instanceMain(Main.java:190); 	at org.broadinstitute.hellbender.tools.walkers.vqsr.CNNVariantPipelineTest.testTrainingReadModel(CNNVariantPipelineTest.java:85); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:133); 	at org.testng.internal.TestInvoker.invokeMethod(TestInvoker.java:584); 	at org.testng.internal.TestInvoker.invokeTestMethod(TestInvoker.java:172); 	at org.testng.internal.MethodRunner.runInSequence(MethodRunner.java:46); 	at org.testng.internal.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:804); 	at org.testng.internal.TestInvoker.invokeTestMethods(TestInvoker.java:145); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:128); 	at java.util.ArrayList.forEach(ArrayList.java:1257); 	at org.testng.TestRunner.privateRun(TestRunner.java:770); 	at org.testng.TestRunner.run(TestRunner.java:591); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:402); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:396); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:355); 	at org.testng.SuiteRunner.run(SuiteRunner.java:304); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:53); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:96); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1180); 	at org.tes,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6307:3190,test,testng,3190,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6307,1,['test'],['testng']
Testability,1:01:39.582 INFO ProgressMeter - 6:136884895 32.3 493710 15293.9; 11:01:49.601 INFO ProgressMeter - 6:137645024 32.4 496460 15299.9; 11:01:59.637 INFO ProgressMeter - 6:138403074 32.6 499180 15304.8; 11:02:09.707 INFO ProgressMeter - 6:139027372 32.8 501500 15297.3; 11:02:19.722 INFO ProgressMeter - 6:139763198 33.0 504200 15301.7; 11:02:29.730 INFO ProgressMeter - 6:140651241 33.1 507330 15319.2; 11:02:39.754 INFO ProgressMeter - 6:141519060 33.3 510390 15334.2; 11:02:49.770 INFO ProgressMeter - 6:142365895 33.5 513350 15346.2; 11:02:59.825 INFO ProgressMeter - 6:143095858 33.6 515950 15347.0; 11:03:09.839 INFO ProgressMeter - 6:143836224 33.8 518620 15350.2; 11:03:19.935 INFO ProgressMeter - 6:144523800 34.0 521100 15347.2; 11:03:29.954 INFO ProgressMeter - 6:145296272 34.1 523860 15353.0; 11:03:39.962 INFO ProgressMeter - 6:146107991 34.3 526730 15362.0; 11:03:49.985 INFO ProgressMeter - 6:146894128 34.5 529520 15368.5; 11:04:00.014 INFO ProgressMeter - 6:147667260 34.6 532290 15374.3; 11:04:10.038 INFO ProgressMeter - 6:148434247 34.8 535070 15380.4; 11:04:20.045 INFO ProgressMeter - 6:149146016 35.0 537680 15381.6; 11:04:30.067 INFO ProgressMeter - 6:149747499 35.1 539940 15372.8; 11:04:40.079 INFO ProgressMeter - 6:150367082 35.3 542250 15365.6; 11:04:50.105 INFO ProgressMeter - 6:151044177 35.5 544720 15362.9; 11:05:00.117 INFO ProgressMeter - 6:151680574 35.6 547110 15358.0; 11:05:10.177 INFO ProgressMeter - 6:152355153 35.8 549520 15353.4; 11:05:20.182 INFO ProgressMeter - 6:153064683 36.0 552080 15353.4; 11:05:30.185 INFO ProgressMeter - 6:153910522 36.1 555100 15366.1; 11:05:40.196 INFO ProgressMeter - 6:154615553 36.3 557700 15367.1; 11:05:50.234 INFO ProgressMeter - 6:155257622 36.5 560130 15363.2; 11:06:00.243 INFO ProgressMeter - 6:156087587 36.6 563090 15374.1; 11:06:10.286 INFO ProgressMeter - 6:156810430 36.8 565700 15375.1; free(): invalid size. Second log is the same but the issue at the end is the following one; `munmap_chunk(): invalid pointer`,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7032:19036,log,log,19036,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7032,1,['log'],['log']
Testability,"1:644:1:1; chr22	19895477	CNV_chr22_19895477_19901476	N	<DUP>	2.30	.	END=19901476	GT:CN:NP:QA:QS:QSE:QSS	./.:3:6:1:2:1:0; chr22	19901477	CNV_chr22_19901477_19946476	N	<DEL>	123.62	.	END=19946476	GT:CN:NP:QA:QS:QSE:QSS	1/1:0:45:0:124:1:1; chr22	19946477	CNV_chr22_19946477_19971476	N	<DUP>	6.86	.	END=19971476	GT:CN:NP:QA:QS:QSE:QSS	./.:3:25:0:7:2:1; chr22	19971477	CNV_chr22_19971477_20003000	N	<DEL>	198.68	.	END=20003000	GT:CN:NP:QA:QS:QSE:QSS	1/1:0:32:0:199:2:2. ```. #### Actual behavior. - `gatkgermlinecnvcaller_genotyped-intervals-COHORT_0.woTimestamp.vcf` (`##contig` cut from header and only first 5 `chr22` CNVs present). ```; ##fileformat=VCFv4.2; ##FORMAT=<ID=CN,Number=1,Type=Integer,Description=""Copy number maximum a posteriori value"">; ##FORMAT=<ID=CNLP,Number=.,Type=Integer,Description=""Copy number log posterior (in Phred-scale) rounded down"">; ##FORMAT=<ID=CNQ,Number=1,Type=Integer,Description=""Genotype call quality as the difference between the best and second best phred-scaled log posterior scores"">; ##FORMAT=<ID=GT,Number=1,Type=Integer,Description=""Genotype"">; ##INFO=<ID=END,Number=1,Type=Integer,Description=""End coordinate of the variant"">; ##contig=<ID=chr1,length=248956422,assembly=GRCh38.d1.vd1>; ...; ##contig=<ID=HPV-mSD2,length=7300,assembly=GRCh38.d1.vd1>; ##source=PostprocessGermlineCNVCalls; #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	E07002_normal; chr1	10000	CNV_chr1_10000_10999	N	<DEL>,<DUP>	.	.	END=10999	GT:CN:CNLP:CNQ	1:0:0,78,88,96,104,111:78; chr1	11000	CNV_chr1_11000_11999	N	<DEL>,<DUP>	.	.	END=11999	GT:CN:CNLP:CNQ	1:0:0,80,85,88,90,93:80; chr1	12000	CNV_chr1_12000_12999	N	<DEL>,<DUP>	.	.	END=12999	GT:CN:CNLP:CNQ	1:0:0,89,101,110,119,126:89; chr1	13000	CNV_chr1_13000_13999	N	<DEL>,<DUP>	.	.	END=13999	GT:CN:CNLP:CNQ	1:0:0,89,96,101,105,108:89; chr1	14000	CNV_chr1_14000_14999	N	<DEL>,<DUP>	.	.	END=14999	GT:CN:CNLP:CNQ	1:0:0,86,91,94,96,98:86; chr1	15000	CNV_chr1_15000_15999	N	<DEL>,<DUP>	.	.	END=15999	GT:CN:CNLP:CNQ	1:0:0,83,89,94,99,103:",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8619:19625,log,log,19625,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8619,2,['log'],['log']
Testability,2.544 DEBUG GenomeLocParser - chrUn_KI270752v1 (27745 bp); 23:44:42.545 DEBUG GenomeLocParser - chrUn_KI270753v1 (62944 bp); 23:44:42.545 DEBUG GenomeLocParser - chrUn_KI270754v1 (40191 bp); 23:44:42.545 DEBUG GenomeLocParser - chrUn_KI270755v1 (36723 bp); 23:44:42.545 DEBUG GenomeLocParser - chrUn_KI270756v1 (79590 bp); 23:44:42.545 DEBUG GenomeLocParser - chrUn_KI270757v1 (71251 bp); 23:44:42.545 DEBUG GenomeLocParser - chrUn_GL000214v1 (137718 bp); 23:44:42.545 DEBUG GenomeLocParser - chrUn_KI270742v1 (186739 bp); 23:44:42.545 DEBUG GenomeLocParser - chrUn_GL000216v2 (176608 bp); 23:44:42.545 DEBUG GenomeLocParser - chrUn_GL000218v1 (161147 bp); 23:44:42.545 DEBUG GenomeLocParser - chrEBV (171823 bp); 23:44:42.632 INFO FeatureManager - Using codec IntervalListCodec to read file file:///gpfs/hpc/home/lijc/xiangxud/project/test/NGS_WES_test/4_tools_vcf/gatk4/info/scatter/scatter_30.interval_list; 23:44:42.739 DEBUG FeatureDataSource - Cache statistics for FeatureInput /gpfs/hpc/home/lijc/xiangxud/project/test/NGS_WES_test/4_tools_vcf/gatk4/info/scatter/scatter_30.interval_list:/gpfs/hpc/home/lijc/xiangxud/project/test/NGS_WES_test/4_tools_vcf/gatk4/info/scatter/scatter_30.interval_list:; 23:44:42.740 DEBUG FeatureCache - Cache hit rate was 0.00% (0 out of 0 total queries); 23:44:42.743 INFO IntervalArgumentCollection - Processing 1022379 bp from intervals; 23:44:42.756 INFO GermlineCNVCaller - Reading and validating annotated intervals...; 23:44:43.119 INFO GermlineCNVCaller - GC-content annotations for intervals found; explicit GC-bias correction will be performed...; 23:44:43.160 INFO GermlineCNVCaller - Running the tool in COHORT mode...; 23:44:43.160 INFO GermlineCNVCaller - Validating and aggregating data from input read-count files...; 23:44:43.160 DEBUG GenomeLocParser - Prepared reference sequence contig dictionary; 23:44:43.160 DEBUG GenomeLocParser - chr1 (248956422 bp); 23:44:43.161 DEBUG GenomeLocParser - chr2 (242193529 bp); 23:44:43.161 DEBUG GenomeLoc,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8938:19556,test,test,19556,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8938,1,['test'],['test']
Testability,2.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.X_CCCCC.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.X_CCCCC.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.XF.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.XF.tmp; src/test/resources/org/broadinstitute/hellbender/tools/copynumber/allelic/collect-allelic-counts-normal.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/copynumber/allelic/collect-allelic-counts-tumor.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/copynumber/collectfragmentcounts/collect-fragment-counts-NA12878.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/count_bases.cram.crai; src/test/resources/org/broadinstitute/hellbender/tools/count_bases.dict; src/test/resources/org/broadinstitute/hellbender/tools/count_bases.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/count_reads.cram.crai; src/test/resources/org/broadinstitute/hellbender/tools/count_reads.dict; src/test/resources/org/broadinstitute/hellbender/tools/count_reads.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/count_reads_sorted.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/count_reads_sorted.cram.crai; src/test/resources/org/broadinstitute/hellbender/tools/count_variants.blockgz.gz.tbi; src/test/resources/org/broadinstitute/hellbender/tools/count_variants_withSequenceDict.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/calling_combined_copy_number.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/calling_combined_read_counts.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/calling_sample_bias_latent.ts,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3905:26502,test,test,26502,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905,1,['test'],['test']
Testability,20); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.ForwardClientInput$2.call(ForwardClientInput.java:74); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.ForwardClientInput$2.call(ForwardClientInput.java:72); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.util.Swapper.swap(Swapper.java:38); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.ForwardClientInput.execute(ForwardClientInput.java:72); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.LogAndCheckHealth.execute(LogAndCheckHealth.java:55); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.LogToClient.doBuild(LogToClient.java:60); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.BuildCommandOnly.execute(BuildCommandOnly.java:36); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.EstablishBuildEnvironment.doBuild(EstablishBuildEnvironment.java:72); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	a,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2802:11418,Log,LogAndCheckHealth,11418,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2802,1,['Log'],['LogAndCheckHealth']
Testability,20); 22:05:55.980 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.ForwardClientInput$2.call(ForwardClientInput.java:74); 22:05:55.980 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.ForwardClientInput$2.call(ForwardClientInput.java:72); 22:05:55.980 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.util.Swapper.swap(Swapper.java:38); 22:05:55.980 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.ForwardClientInput.execute(ForwardClientInput.java:72); 22:05:55.981 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); 22:05:55.982 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.LogAndCheckHealth.execute(LogAndCheckHealth.java:55); 22:05:55.982 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); 22:05:55.982 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.LogToClient.doBuild(LogToClient.java:60); 22:05:55.982 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.BuildCommandOnly.execute(BuildCommandOnly.java:36); 22:05:55.982 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); 22:05:55.983 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.EstablishBuildEnvironment.doBuild(EstablishBuildEnvironment.java:72); 22:05:55.983 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	a,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4687:10160,Log,LogAndCheckHealth,10160,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4687,1,['Log'],['LogAndCheckHealth']
Testability,210); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:163); 	at org.broadinstitute.hellbender.Main.instanceMain(Main.java:149); 	at org.broadinstitute.hellbender.Main.instanceMain(Main.java:190); 	at org.broadinstitute.hellbender.tools.walkers.vqsr.CNNVariantPipelineTest.testTrainingReadModel(CNNVariantPipelineTest.java:85); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:133); 	at org.testng.internal.TestInvoker.invokeMethod(TestInvoker.java:584); 	at org.testng.internal.TestInvoker.invokeTestMethod(TestInvoker.java:172); 	at org.testng.internal.MethodRunner.runInSequence(MethodRunner.java:46); 	at org.testng.internal.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:804); 	at org.testng.internal.TestInvoker.invokeTestMethods(TestInvoker.java:145); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:128); 	at java.util.ArrayList.forEach(ArrayList.java:1257); 	at org.testng.TestRunner.privateRun(TestRunner.java:770); 	at org.testng.TestRunner.run(TestRunner.java:591); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:402); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:396); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:355); 	at org.testng.SuiteRunner.run(SuiteRunner.java:304); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:53); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:96); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1180); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1102); 	at org.testng.TestNG.runSuites(TestNG.java:1032); 	at o,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6307:3280,Test,TestInvoker,3280,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6307,1,['Test'],['TestInvoker']
Testability,22); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:108); 	at org.testng.internal.Invoker.invokeMethod(Invoker.java:661); 	at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:869); 	at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1193); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:126); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:109); 	at org.testng.TestRunner.privateRun(TestRunner.java:744); 	at org.testng.TestRunner.run(TestRunner.java:602); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:380); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:375); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:340); 	at org.testng.SuiteRunner.run(SuiteRunner.java:289); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1301); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1226); 	at org.testng.TestNG.runSuites(TestNG.java:1144); 	at org.testng.TestNG.run(TestNG.java:1115); 	at org.testng.IDEARemoteTestNG.run(IDEARemoteTestNG.java:72); 	at org.testng.RemoteTestNGStarter.main(RemoteTestNGStarter.java:123); Caused by: com.intel.genomicsdb.GenomicsDBException: Could not load genomicsdb native library; 	at com.intel.genomicsdb.GenomicsDBImporter.<clinit>(GenomicsDBImporter.java:72); 	... 37 more; ```. if you dig into it more you get down to the following error:; ```; /private/var/folders/xt/vq7wz8955r1401mv8w0f4zf9qbfwzl/T/libtiledbgenomicsdb6159269479234619546.dylib: dlopen(/private/var/folders/xt/vq7wz8955r1401,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4062:2411,test,testng,2411,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4062,1,['test'],['testng']
Testability,"23:42:41.992 INFO GenomicsDBImport - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 23:42:41.992 INFO GenomicsDBImport - Deflater: IntelDeflater; 23:42:41.992 INFO GenomicsDBImport - Inflater: IntelInflater; 23:42:41.992 INFO GenomicsDBImport - GCS max retries/reopens: 20; 23:42:41.992 INFO GenomicsDBImport - Requester pays: disabled; 23:42:41.992 INFO GenomicsDBImport - Initializing engine; 23:42:44.099 INFO IntervalArgumentCollection - Processing 115639695 bp from intervals; 23:42:44.102 INFO GenomicsDBImport - Done initializing engine; 23:42:44.276 INFO GenomicsDBImport - Vid Map JSON file will be written to /home/WangBS/Analyses/vcf/test/chr02/vidmap.json; 23:42:44.276 INFO GenomicsDBImport - Callset Map JSON file will be written to /home/WangBS/Analyses/vcf/test/chr02/callset.json; 23:42:44.276 INFO GenomicsDBImport - Complete VCF Header will be written to /home/WangBS/Analyses/vcf/test/chr02/vcfheader.vcf; 23:42:44.276 INFO GenomicsDBImport - Importing to array - /home/WangBS/Analyses/vcf/test/chr02/genomicsdb_array; 23:42:44.276 INFO ProgressMeter - Starting traversal; 23:42:44.276 INFO ProgressMeter - Current Locus Elapsed Minutes Batches Processed Batches/Minute; 23:42:45.830 INFO GenomicsDBImport - Importing batch 1 with 63 samples; Buffer resized from 37294 bytes to 65464; Buffer resized from 37294 bytes to 65511; Buffer resized from 37293 bytes to 65539; Buffer resized from 37294 bytes to 65447; .....; .....; Buffer resized from 65538 bytes to 65539; Buffer resized from 65538 bytes to 65539; Buffer resized from 65538 bytes to 65539; 06:50:14.219 INFO ProgressMeter - Qrob_Chr02:1 427.5 1 0.0; 06:50:14.220 INFO GenomicsDBImport - Done importing batch 1/1; 06:50:14.221 INFO ProgressMeter - Qrob_Chr02:1 427.5 1 0.0; 06:50:14.229 INFO ProgressMeter - Traversal complete. Processed 1 total batches in 427.5 minutes.; 06:50:14.236 INFO GenomicsDBImport - Import completed!; 06:50:14.236 INFO GenomicsDBImport - Shutting down engine; [January 27, 2019 6:50:1",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5865:3249,test,test,3249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5865,1,['test'],['test']
Testability,24); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); 	at org.testng.TestRunner.privateRun(TestRunner.java:773); 	at org.testng.TestRunner.run(TestRunner.java:623); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:357); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:352); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:310); 	at org.testng.SuiteRunner.run(SuiteRunner.java:259); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1185); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1110); 	at org.testng.TestNG.run(TestNG.java:1018); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:129); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:88); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:32); 	at org.gradle.internal.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:93); 	at com.sun.proxy.$Proxy2.stop(Unknown Source); 	at org.gradle.api.internal.tasks.testing.worker.TestWorker.stop(TestWorker.java:120); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAcces,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2349:5502,test,testing,5502,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2349,1,['test'],['testing']
Testability,24); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:108); 	at org.testng.internal.Invoker.invokeMethod(Invoker.java:661); 	at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:869); 	at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1193); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:126); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:109); 	at org.testng.TestRunner.privateRun(TestRunner.java:744); 	at org.testng.TestRunner.run(TestRunner.java:602); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:380); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:375); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:340); 	at org.testng.SuiteRunner.run(SuiteRunner.java:289); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1301); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1226); 	at org.testng.TestNG.runSuites(TestNG.java:1144); 	at org.testng.TestNG.run(TestNG.java:1115); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:129); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:88); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(Delegat,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2797:1920,test,testng,1920,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2797,1,['test'],['testng']
Testability,25); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:108); 	at org.testng.internal.Invoker.invokeMethod(Invoker.java:661); 	at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:869); 	at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1193); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:126); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:109); 	at org.testng.TestRunner.privateRun(TestRunner.java:744); 	at org.testng.TestRunner.run(TestRunner.java:602); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:380); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:375); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:340); 	at org.testng.SuiteRunner.run(SuiteRunner.java:289); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1301); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1226); 	at org.testng.TestNG.runSuites(TestNG.java:1144); 	at org.testng.TestNG.run(TestNG.java:1115); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:129); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:88); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(Delegat,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5680:8802,test,testng,8802,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5680,1,['test'],['testng']
Testability,250253f.alleleSpecific.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/haplotypecaller/expected.testVCFMode.gatk3.5.alleleSpecific.vcf; src/test/resources/org/broadinstitute/hellbender/tools/haplotypecaller/expected.testVCFMode.gatk3.5.vcf; src/test/resources/org/broadinstitute/hellbender/tools/haplotypecaller/expected.testVCFMode.gatk3.8-4-g7b0250253f.alleleSpecific.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/haplotypecaller/expected.testVCFMode.gatk3.8-4-g7b0250253.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/haplotypecaller/pretendTobeTetraPloidTetraAllelicSite.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/HiSeq.1mb.1RG.empty.table.gz; src/test/resources/org/broadinstitute/hellbender/tools/HiSeq.1mb.1RG.noSG.table.gz; src/test/resources/org/broadinstitute/hellbender/tools/HiSeq.1mb.1RG.sg1.table.gz; src/test/resources/org/broadinstitute/hellbender/tools/HiSeq.1mb.1RG.sg2.table.gz; src/test/resources/org/broadinstitute/hellbender/tools/HiSeq.1mb.1RG.sg3.table.gz; src/test/resources/org/broadinstitute/hellbender/tools/HiSeq.1mb.1RG.sg4.table.gz; src/test/resources/org/broadinstitute/hellbender/tools/HiSeq.1mb.1RG.sg5.table.gz; src/test/resources/org/broadinstitute/hellbender/tools/Homo_sapiens_assembly18.10k_lines.dict; src/test/resources/org/broadinstitute/hellbender/tools/Homo_sapiens_assembly18.10k_lines.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/mutect/dream/vcfs/dream3-chr20.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/mutect/dream/vcfs/sample_1.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/mutect/dream/vcfs/sample_2.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/mutect/dream/vcfs/sample_3.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/mutect/dream/vcfs/sample_4.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/mutect/na12878-chr20-consumes-zero-reference-bases.bai; src/test/resour,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3905:38311,test,test,38311,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905,1,['test'],['test']
Testability,"26,30;MFRL=6590,6585,4819,6586;MMQ=60,60,60,60;MPOS=16,15,7;MQ=59.98;MQ0=0;MQRankSum=0.000;NALOD=0.569,1.49,1.49;NCC=0;NCount=0;NLOD=27.80,30.51,30.97;OCM=0;POPAF=6.00,6.00,6.00;REF\_BASES=GAACTTGCTTCTTTTTTTTGC;RPA=8,9,10,11;RU=T;ReadPosRankSum=5.751;SOR=1.152;STR;Samples=TCGA-NJ-A55R-01A-11R-A262-07;TLOD=284.47,51.82,3.50 GT:AD:AF:DP:F1R2:F2R1:SB 0/1/2/3:819,166,35,14:0.161,0.034,0.014:1034:365,76,17,4:440,87,17,8:16,803,6,209 0/0:103,1,0,0:0.017,8.250e-03,8.221e-03:104:50,1,0,0:52,0,0,0:26,77,0,1. The error log that FilterMutectCalls emited was listed below:. Using GATK jar /home/lqh/software/GATK-4.2.0.0/gatk-package-4.2.0.0-local.jar ; ; Running: ; ; java -Dsamjdk.use\_async\_io\_read\_samtools=false -Dsamjdk.use\_async\_io\_write\_samtools=true -Dsamjdk.use\_async\_io\_write\_tribble=false -Dsamjdk.compression\_level=2 -jar /home/lqh/software/GATK-4.2.0.0/gatk-package-4.2.0.0-local.jar FilterMutectCalls -R /public1/data/resources/ref\_genome/GRCh38/GRCh38.d1.vd1.fa -V somatic\_mutation/Mutect2/test.vcf.gz -O somatic\_mutation/FilterMutectCalls/test.vcf.gz ; ; 11:03:39.517 INFO NativeLibraryLoader - Loading libgkl\_compression.so from jar:file:/home/lqh/software/GATK-4.2.0.0/gatk-package-4.2.0.0-local.jar!/com/intel/gkl/native/libgkl\_compression.so ; ; Jun 04, 2021 11:03:49 AM shaded.cloud\_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine ; ; INFO: Failed to detect whether we are running on Google Compute Engine. ; ; 11:03:49.968 INFO FilterMutectCalls - ------------------------------------------------------------ ; ; 11:03:49.969 INFO FilterMutectCalls - The Genome Analysis Toolkit (GATK) v4.2.0.0 ; ; 11:03:49.969 INFO FilterMutectCalls - For support and documentation go to [https://software.broadinstitute.org/gatk/](https://software.broadinstitute.org/gatk/) ; ; 11:03:49.969 INFO FilterMutectCalls - Executing as lqh@master on Linux v5.6.14-1.el7.elrepo.x86\_64 amd64 ; ; 11:03:49.969 INFO FilterMutectCalls - Java runtime: Java HotSpot(",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7298:2868,test,test,2868,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7298,1,['test'],['test']
Testability,2878.indels_context_size_4.recal.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m20k.NA12878.low_quality_tail_5.recal.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m20k.NA12878.mismatches_context_size_4.recal.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m20k.NA12878.quantizing_levels_6.recal.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m20k.NA12878.recal.txt; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.HiSeq.1mb.1RG.2k_lines.alternate.recalibrated.DIQ.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.HiSeq.1mb.1RG.2k_lines.bqsr.qq-1.alternate.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.HiSeq.1mb.1RG.2k_lines.bqsr.qq6.alternate.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.MultiSite.reads.pipeline.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.MultiSite.reads.pipeline.cram.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/HiSeq.1mb.1RG.2k_lines.alternate_allaligned.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/HiSeq.1mb.1RG.2k_lines.alternate.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/HiSeq.1mb.1RG.2k_lines.alternate.recalibrated.DIQ.sharded.bam/part-r-00001.bam; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/HiSeq.1mb.1RG.2k_lines.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/human_b36_both.chr1_1k.dict; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/human_b36_both.chr1_1k.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/NA12878.chr17_69k_70k.dictFix.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/NA12878.oq.read_consumes_zero_ref_bases.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3905:21084,test,test,21084,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905,1,['test'],['test']
Testability,"2:45.346 INFO VariantAnnotator - ------------------------------------------------------------; 14:02:45.347 INFO VariantAnnotator - HTSJDK Version: 4.1.0; 14:02:45.347 INFO VariantAnnotator - Picard Version: 3.1.1; 14:02:45.347 INFO VariantAnnotator - Built for Spark Version: 3.5.0; 14:02:45.348 INFO VariantAnnotator - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 14:02:45.348 INFO VariantAnnotator - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 14:02:45.348 INFO VariantAnnotator - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 14:02:45.348 INFO VariantAnnotator - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 14:02:45.349 INFO VariantAnnotator - Deflater: JdkDeflater; 14:02:45.349 INFO VariantAnnotator - Inflater: JdkInflater; 14:02:45.349 INFO VariantAnnotator - GCS max retries/reopens: 20; 14:02:45.349 INFO VariantAnnotator - Requester pays: disabled; 14:02:45.349 INFO VariantAnnotator - Initializing engine; 14:02:45.425 INFO FeatureManager - Using codec VCFCodec to read file file:///directory_masked/test.vcf; 14:02:45.436 INFO VariantAnnotator - Done initializing engine; 14:02:45.459 INFO ProgressMeter - Starting traversal; 14:02:45.459 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 14:02:45.498 WARN VariantAnnotatorEngine - Jumbo genotype annotations requested but fragment likelihoods or haplotype likelihoods were not given.; 14:02:45.505 INFO VariantAnnotator - Shutting down engine; [April 30, 2024 at 2:02:45 PM HKT] org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotator done. Elapsed time: 0.00 minutes.; Runtime.totalMemory()=285212672; java.lang.IndexOutOfBoundsException: Index 1 out of bounds for length 1; at java.base/jdk.internal.util.Preconditions.outOfBounds(Preconditions.java:64); at java.base/jdk.internal.util.Preconditions.outOfBoundsCheckIndex(Preconditions.java:70); at java.base/jdk.internal.util.Preconditions.checkIndex(Preconditions.java:266); at java.base/java.util.Obje",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8800:2476,test,test,2476,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8800,1,['test'],['test']
Testability,"2:6:.:0|1:65074846_T_C:90,6,0,90,6,90:0,0,2,0 ./.:.:1:0:0:.:.:0,0,0,0,0,0; chr7 65074875 . C *,<NON_REF> . . DP=2 GT:AD:DP:GQ:MIN_DP:PGT:PID:PL:SB ./.:.:0:0:0:.:.:0,0,0,0,0,0 ./.:0,2,0:2:6:.:0|1:65074846_T_C:90,6,0,90,6,90:0,0,2,0 ./.:.:1:0:0:.:.:0,0,0,0,0,0; chr7 65074876 . G *,<NON_REF> . . DP=2 GT:AD:DP:GQ:MIN_DP:PGT:PID:PL:SB ./.:.:0:0:0:.:.:0,0,0,0,0,0 ./.:0,2,0:2:6:.:0|1:65074846_T_C:90,6,0,90,6,90:0,0,2,0 ./.:.:1:0:0:.:.:0,0,0,0,0,0; chr7 65074877 . T *,<NON_REF> . . DP=2 GT:AD:DP:GQ:MIN_DP:PGT:PID:PL:SB ./.:.:0:0:0:.:.:0,0,0,0,0,0 ./.:0,2,0:2:6:.:0|1:65074846_T_C:90,6,0,90,6,90:0,0,2,0 ./.:.:1:0:0:.:.:0,0,0,0,0,0; chr7 65074878 . G <NON_REF> . . END=65074923 GT:DP:GQ:MIN_DP:PL ./.:0:0:0:0,0,0 ./.:2:0:0:0,0,0 ./.:1:0:0:0,0,0 ./.:2:0:0:0,0,0 ./.:0:0:0:0,0,0 ./.:0:0:0:0,0,0 ./.:0:0:0:0,0,0 ./.:1:0:0:0,0,; ```; Where the second genotype column with the `65074846_T_C` tag is for NA12891, which is the sample that has the deletion. I suspect that the GATK engine logic is smart enough to look upstream since those genotyped get annotations. This is admittedly sort of an ambiguous case, but GDB certainly should be able to power through. The stack trace looks like this:; ```; Native frames: (J=compiled Java code, j=interpreted, Vv=VM code, C=native code); C [libtiledbgenomicsdb4636568691140868757.dylib+0x1a2cf] BroadCombinedGVCFOperator::handle_deletions(Variant&, VariantQueryConfig const&)+0xa7f; C [libtiledbgenomicsdb4636568691140868757.dylib+0x18f12] BroadCombinedGVCFOperator::operate(Variant&, VariantQueryConfig const&)+0x22; C [libtiledbgenomicsdb4636568691140868757.dylib+0x59d98] VariantQueryProcessor::handle_gvcf_ranges(std::__1::priority_queue<VariantCall*, std::__1::vector<VariantCall*, std::__1::allocator<VariantCall*> >, EndCmpVariantCallStruct>&, VariantQueryConfig const&, Variant&, SingleVariantOperatorBase&, long long&, long long, bool, unsigned long long&, GTProfileStats*) const+0xa8; C [libtiledbgenomicsdb4636568691140868757.dylib+0x5a8e2] VariantQueryPr",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5449:1889,log,logic,1889,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5449,1,['log'],['logic']
Testability,2k_lines.bqsr.qq6.alternate.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.MultiSite.reads.pipeline.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.MultiSite.reads.pipeline.cram.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/HiSeq.1mb.1RG.2k_lines.alternate_allaligned.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/HiSeq.1mb.1RG.2k_lines.alternate.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/HiSeq.1mb.1RG.2k_lines.alternate.recalibrated.DIQ.sharded.bam/part-r-00001.bam; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/HiSeq.1mb.1RG.2k_lines.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/human_b36_both.chr1_1k.dict; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/human_b36_both.chr1_1k.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/NA12878.chr17_69k_70k.dictFix.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/NA12878.oq.read_consumes_zero_ref_bases.chr20.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/na.bam; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/na.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/originalQuals.1kg.chr1.1-1K.1RG.dictFix.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/overlappingRead.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/solid.bam; src/test/resources/org/broadinstitute/hellbender/tools/BQSR/solid.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/clippingReadsTest.withRG.hg19.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/clippingReadsTestCRAM.cram; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/clippingReadsTest.withRG.hg19.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTestCRAM.QT_10.cram; src/test/resources/org/broadinstitute/hell,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3905:22016,test,test,22016,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905,1,['test'],['test']
Testability,"3 1568727304 Sep 16 11:44 genome.fa.sa. Using GATK wrapper script /home/kh3/Softwares/gatk/build/install/gatk/bin/gatk; Running:; /home/kh3/Softwares/gatk/build/install/gatk/bin/gatk BwaAndMarkDuplicatesPipelineSpark -I /home/kh3/data/Illumina/GATK4/Platinum/TEST/test.spark.bam -R /home/kh3/Resources/genome_b37/ge; nome.2bit --disableSequenceDictionaryValidation true -t 16 -O /home/kh3/data/Illumina/GATK4/Platinum/TEST/test.spark.aligned.bam; 15:47:28.760 INFO IntelGKLUtils - Trying to load Intel GKL library from:; jar:file:/home/kh3/Softwares/gatk/build/install/gatk/lib/gkl-0.1.2.jar!/com/intel/gkl/native/libIntelGKL.so; 15:47:28.809 INFO IntelGKLUtils - Intel GKL library loaded from classpath.; [September 16, 2016 3:47:28 PM EDT] org.broadinstitute.hellbender.tools.spark.pipelines.BwaAndMarkDuplicatesPipelineSpark --threads 16 --output /home/kh3/data/Illumina/GATK4/Platinum/TEST/test.spark; .aligned.bam --reference /home/kh3/Resources/genome_b37/genome.2bit --input /home/kh3/data/Illumina/GATK4/Platinum/TEST/test.spark.bam --disableSequenceDictionaryValidation true --fixedChunkSiz; e 100000 --duplicates_scoring_strategy SUM_OF_BASE_QUALITIES --readValidationStringency SILENT --interval_set_rule UNION --interval_padding 0 --interval_exclusion_padding 0 --bamPartitionSize 0 --shardedO; utput false --numReducers 0 --sparkMaster local[*] --help false --version false --verbosity INFO --QUIET false --use_jdk_deflater false --disableAllReadFilters false; [September 16, 2016 3:47:28 PM EDT] Executing as kh3@rgcaahauva08091.rgc.aws.com on Linux 3.13.0-91-generic amd64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_101-b13; Version: Version:4.alpha.; 2-45-ga30af5a-SNAPSHOT; 15:47:28.835 INFO BwaAndMarkDuplicatesPipelineSpark - Defaults.BUFFER_SIZE : 131072; 15:47:28.835 INFO BwaAndMarkDuplicatesPipelineSpark - Defaults.COMPRESSION_LEVEL : 1; 15:47:28.835 INFO BwaAndMarkDuplicatesPipelineSpark - Defaults.CREATE_INDEX : false; 15:47:28.835 INFO BwaAndMarkDuplicatesPipelineSpark - D",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2171:1684,TEST,TEST,1684,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2171,2,"['TEST', 'test']","['TEST', 'test']"
Testability,"3 tests fail, sometimes. They often pass on a rerun of the build. Here's one example. ```; org.broadinstitute.hellbender.tools.picard.illumina.IlluminaBasecallsToSamTest.testMultiplexedWithAlternateBarcodeName FAILED; java.lang.AssertionError: SAM file output differs from expected output expected [true] but found [false]; at org.testng.Assert.fail(Assert.java:94); at org.testng.Assert.failNotEquals(Assert.java:494); at org.testng.Assert.assertTrue(Assert.java:42); at org.broadinstitute.hellbender.utils.read.SamAssertionUtils.assertSamsEqual(SamAssertionUtils.java:27); at ; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/364:2,test,tests,2,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/364,14,"['Assert', 'assert', 'test']","['Assert', 'AssertionError', 'assertSamsEqual', 'assertTrue', 'testMultiplexedWithAlternateBarcodeName', 'testng', 'tests']"
Testability,3); at java.lang.reflect.Method.invoke(Method.java:483); at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); at org.testng.internal.Invoker.invokeMethod(Invoker.java:639); at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:821); at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1131); at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); at org.testng.TestRunner.privateRun(TestRunner.java:773); at org.testng.TestRunner.run(TestRunner.java:623); at org.testng.SuiteRunner.runTest(SuiteRunner.java:357); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:352); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:310); at org.testng.SuiteRunner.run(SuiteRunner.java:259); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1185); at org.testng.TestNG.runSuitesLocally(TestNG.java:1110); at org.testng.TestNG.run(TestNG.java:1018); at org.testng.remote.RemoteTestNG.run(RemoteTestNG.java:111); at org.testng.remote.RemoteTestNG.initAndRun(RemoteTestNG.java:204); at org.testng.remote.RemoteTestNG.main(RemoteTestNG.java:175); at org.testng.RemoteTestNGStarter.main(RemoteTestNGStarter.java:125); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:483); at com.intellij.rt.execution.application.AppMain.main(AppMain.java:140); Caused by: java.lang.RuntimeException: java.lang.NoSuchMethodError: com.google.common.base.Stopwatch.createStarted()Lcom/google/common/base/Stopwatch;; at com.google.cloud.dataflow.sdk.Pipeline.run(Pipeline.java:166); at org.broa,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/866:2071,Test,TestNG,2071,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/866,1,['Test'],['TestNG']
Testability,3); at java.lang.reflect.Method.invoke(Method.java:497); at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); at org.testng.internal.Invoker.invokeMethod(Invoker.java:639); at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:821); at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1131); at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); at org.testng.TestRunner.privateRun(TestRunner.java:773); at org.testng.TestRunner.run(TestRunner.java:623); at org.testng.SuiteRunner.runTest(SuiteRunner.java:357); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:352); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:310); at org.testng.SuiteRunner.run(SuiteRunner.java:259); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1185); at org.testng.TestNG.runSuitesLocally(TestNG.java:1110); at org.testng.TestNG.run(TestNG.java:1018); at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:133); at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:83); at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:497); at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35); at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); at org.gradle.messaging.dispatch.ContextClassLoader,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1638:2286,Test,TestNG,2286,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1638,2,['Test'],['TestNG']
Testability,"3); at java.lang.reflect.Method.invoke(Method.java:497); at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); at org.testng.internal.Invoker.invokeMethod(Invoker.java:659); at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:845); at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1153); at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:125); at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); at org.testng.TestRunner.privateRun(TestRunner.java:771); at org.testng.TestRunner.run(TestRunner.java:621); at org.testng.SuiteRunner.runTest(SuiteRunner.java:357); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:352); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:310); at org.testng.SuiteRunner.run(SuiteRunner.java:259); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1199); at org.testng.TestNG.runSuitesLocally(TestNG.java:1124); at org.testng.TestNG.run(TestNG.java:1032); at org.testng.remote.RemoteTestNG.run(RemoteTestNG.java:111); at org.testng.remote.RemoteTestNG.initAndRun(RemoteTestNG.java:204); at org.testng.remote.RemoteTestNG.main(RemoteTestNG.java:175); at org.testng.RemoteTestNGStarter.main(RemoteTestNGStarter.java:125); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:497); at com.intellij.rt.execution.application.AppMain.main(AppMain.java:140). Jul 01, 2015 2:33:37 PM org.reflections.Reflections scan; ```. The fact that it doesn't show up for some users means its likely to be an environmental difference, possibly an underspecified dependency. @davidaadams I understand t",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/609:2653,Test,TestNG,2653,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/609,1,['Test'],['TestNG']
Testability,"3); at org.broadinstitute.hellbender.utils.codecs.gtf.GencodeGtfFeature.<init>(GencodeGtfFeature.java:224); at org.broadinstitute.hellbender.utils.codecs.gtf.GencodeGtfExonFeature.<init>(GencodeGtfExonFeature.java:19); at org.broadinstitute.hellbender.utils.codecs.gtf.GencodeGtfExonFeature.create(GencodeGtfExonFeature.java:23); at org.broadinstitute.hellbender.utils.codecs.gtf.GencodeGtfFeature$FeatureType$4.create(GencodeGtfFeature.java:777); at org.broadinstitute.hellbender.utils.codecs.gtf.GencodeGtfFeature.create(GencodeGtfFeature.java:320); at org.broadinstitute.hellbender.utils.codecs.gtf.AbstractGtfCodec.decode(AbstractGtfCodec.java:138); at org.broadinstitute.hellbender.utils.codecs.gtf.AbstractGtfCodec.decode(AbstractGtfCodec.java:23); at htsjdk.tribble.TribbleIndexedFeatureReader$QueryIterator.readNextRecord(TribbleIndexedFeatureReader.java:501); ... 43 more; `; #### Steps to reproduce. [test.somatic.vcf.gz](https://github.com/broadinstitute/gatk/files/5094900/test.somatic.vcf.gz). I upload my VCF file here. The reference is hg19 downloaded from UCSC. The data sources is downloaded from funcotator official website (somatic). You can simply run this command to reproduce this error:; `gatk Funcotator --variant test.somatic.vcf --reference ucsc.hg19.fasta --ref-version hg19 --data-sources-path funcotator_dataSources.v1.7.20200521s --output test.maf --output-file-format MAF; `; #### Expected behavior; Successfully run and output a MAF file. #### Actual behavior; Throw out an error and an MAF file with only header; ----. ## Feature request. ### Tool(s) or class(es) involved; _Tool/class name(s), special parameters?_. ### Description; _Specify whether you want a modification of an existing behavior or addition of a new capability._; _Provide **examples**, **screenshots**, where appropriate._. ----. ## Documentation request. ### Tool(s) or class(es) involved; _Tool/class name(s), parameters?_. ### Description ; _Describe what needs to be added or modified._. ----",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6758:26359,test,test,26359,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6758,2,['test'],['test']
Testability,"3.601 INFO PostprocessGermlineCNVCalls - Analyzing shard 36 / 45...; 03:13:13.736 INFO PostprocessGermlineCNVCalls - Analyzing shard 37 / 45...; 03:13:13.884 INFO PostprocessGermlineCNVCalls - Analyzing shard 38 / 45...; 03:13:14.027 INFO PostprocessGermlineCNVCalls - Analyzing shard 39 / 45...; 03:13:14.156 INFO PostprocessGermlineCNVCalls - Analyzing shard 40 / 45...; 03:13:14.284 INFO PostprocessGermlineCNVCalls - Analyzing shard 41 / 45...; 03:13:14.385 INFO PostprocessGermlineCNVCalls - Analyzing shard 42 / 45...; 03:13:14.515 INFO PostprocessGermlineCNVCalls - Analyzing shard 43 / 45...; 03:13:14.652 INFO PostprocessGermlineCNVCalls - Analyzing shard 44 / 45...; 03:13:14.843 INFO PostprocessGermlineCNVCalls - Analyzing shard 45 / 45...; 03:13:15.144 INFO PostprocessGermlineCNVCalls - Generating segments...; 03:14:44.578 INFO PostprocessGermlineCNVCalls - Parsing Python output...; 03:14:44.593 INFO PostprocessGermlineCNVCalls - Writing segments VCF file to /data/xiangxd/project/test/PD_WES_50/cnv_calling/GATK_gCNV/infos/output/R18002110LU01-XG3351_combined_segment_cohort.vcf...; 03:14:46.272 INFO PostprocessGermlineCNVCalls - Generating denoised copy ratios...; 03:14:47.231 INFO PostprocessGermlineCNVCalls - Writing denoised copy ratios to /data/xiangxd/project/test/PD_WES_50/cnv_calling/GATK_gCNV/infos/output/R18002110LU01-XG3351_combined_ratio.txt...; 03:14:58.266 INFO PostprocessGermlineCNVCalls - PostprocessGermlineCNVCalls complete.; 03:14:58.268 INFO PostprocessGermlineCNVCalls - Shutting down engine; [April 15, 2024, 3:14:58 AM CST] org.broadinstitute.hellbender.tools.copynumber.PostprocessGermlineCNVCalls done. Elapsed time: 2.32 minutes.; Runtime.totalMemory()=1207959552; Using GATK jar /data/xiangxd/project/software/callers/gatk_4.4/gatk-package-4.4.0.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /data/xiangxd/pr",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8776:7088,test,test,7088,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8776,1,['test'],['test']
Testability,3.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/flag_stat.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/flag_stat.fasta; src/test/resources/org/broadinstitute/hellbender/tools/genome/HCC1143_chr22_27M_37M.tiny.bam; src/test/resources/org/broadinstitute/hellbender/tools/genome/HCC1143_chr22_27M_37M.tiny.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/genome/HCC1143_chr3_1K_11K.tiny.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/GenomicsDBImport/testHeaderContigLineSorting1.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/GenomicsDBImport/testHeaderContigLineSorting2.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/haplotypecaller/expected.testGVCFMode.3.8-4-g7b0250253f.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/haplotypecaller/expected.testGVCFMode.gatk3.5.alleleSpecific.g.vcf; src/test/resources/org/broadinstitute/hellbender/tools/haplotypecaller/expected.testGVCFMode.gatk3.5.g.vcf; src/test/resources/org/broadinstitute/hellbender/tools/haplotypecaller/expected.testGVCFMode.gatk3.8-4-g7b0250253f.alleleSpecific.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/haplotypecaller/expected.testVCFMode.gatk3.5.alleleSpecific.vcf; src/test/resources/org/broadinstitute/hellbender/tools/haplotypecaller/expected.testVCFMode.gatk3.5.vcf; src/test/resources/org/broadinstitute/hellbender/tools/haplotypecaller/expected.testVCFMode.gatk3.8-4-g7b0250253f.alleleSpecific.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/haplotypecaller/expected.testVCFMode.gatk3.8-4-g7b0250253.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/haplotypecaller/pretendTobeTetraPloidTetraAllelicSite.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/HiSeq.1mb.1RG.empty.table.gz; src/test/resources/org/broadinstitute/hellbender/tools/HiSeq.1mb.1RG.noSG.table.gz; src/test/resources/org/broadinstitute/hellbender/tools/HiSeq.1mb.1,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3905:37200,test,testGVCFMode,37200,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905,1,['test'],['testGVCFMode']
Testability,3.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleBad.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleGood.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleRSIDonPositionNotInDBSNP.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationUnusedAllelesBugFix.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/validation/basicshortmutpileup/IS3.snv.indel.sv-vs-G15512.prenormal.sorted.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/validation/basicshortmutpileup/synthetic.challenge.set1.tumor-vs-synthetic.challenge.set1.normal-filtered.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/CalculateGenotypePosteriors/CEUtriMixedPloidyTest.vcf; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/CalculateGenotypePosteriors/CEUtrioPopPriorsTest_chr1.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/CalculateGenotypePosteriors/CEUtrioTest_chr1.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/CalculateGenotypePosteriors/expectedCGP_testFamilyPriors_chr1.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/CalculateGenotypePosteriors/expectedCGP_testFamilyPriors.vcf; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/CalculateGenotypePosteriors/expectedCGP_testSingleParentFamily_chr1.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/CalculateGenotypePosteriors/expectedCGP_testSingleParentFamily.vcf; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/CalculateGenotypePosteriors/NA12878.Jan2013.haplotypeCaller.subset.indels.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tool,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3905:62134,test,test,62134,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905,1,['test'],['test']
Testability,"301 tests fail, 37 are skipped",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8940:4,test,tests,4,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8940,1,['test'],['tests']
Testability,"307_C_T:287:0,98:0,89:1; ```; </details>. while the test callset has the following single record:. <details>; <summary> Test callset </summary>. ```; chr2 241815307 . CA TG 1756.77 PASS AC=1;AF=0.5;AN=2;BaseQRankSum=-0.802;ClippingRankSum=0.521;DP=85;ExcessHet=3.0103;FS=2.902;MLEAC=1;MLEAF=0.5;MQ=60.0;MQRankSum=0.0;QD=20.67;ReadPosRankSum=-1.858;SOR=0.571 GT:AD:DP:F1R2:F2R1:GQ:PL 0/1:37,48:85:16,25,0:21,23,0:99:1785,0,1406; ```; </details>. Next, I looked at the reads from the haplotype assembly BAM supporting each of the three possible alleles in the test callset:. | Allele | # of reads |; | --- | --- |; | ref (`CA`) | 1 read |; | alt1 (`CG`) | 36 reads |; | alt 2 (`TG`) | 48 reads |. You can see the sum of the count of reads in the table is equal to the depth and sum of allelic depths in the VCF record. It is clear from the haplotype assembly BAM that the call should be `1/2` (`CG/TG`), but the finall call is `0/2` (`CA/TG`). . I then re-ran `HaplotypeCaller` without the `--max-mnp-distance 5` argument and got the variant call I expected, which matches the GIAB variant call:. <details>; <summary> Test callset without `--max-mnp-distance 5` </summary>. ```; chr2 241815307 . C T,<NON_REF> 1717.77 . BaseQRankSum=-1.137;ClippingRankSum=1.185;DP=83;ExcessHet=3.0103;MLEAC=1,0;MLEAF=0.500,0.00;MQRankSum=0.000;RAW_MQandDP=298800,83;ReadPosRankSum=-1.967 GT:AD:DP:F1R2:F2R1:GQ:PGT:PID:PL:PS:SB 0|1:36,47,0:83:15,24,0:21,23,0:99:0|1:241815307_C_T:1746,0,1375,1855,1516,3371:241815307:15,21,24,23; chr2 241815308 . A G,<NON_REF> 3429.77 . BaseQRankSum=0.293;ClippingRankSum=0.601;DP=83;ExcessHet=3.0103;MLEAC=2,0;MLEAF=1.00,0.00;MQRankSum=0.000;RAW_MQandDP=298800,83;ReadPosRankSum=-1.420 GT:AD:DP:F1R2:F2R1:GQ:PGT:PID:PL:PS:SB 1|1:1,82,0:83:1,38,0:0,44,0:99:0|1:241815307_C_T:3458,206,0,3461,246,3500:241815307:1,0,38,44; ```; </details>. I have a work-around where I can post-GATK join phased variants into an MNP, but it looks like there is a bug in this version of `HaplotypeCaller`.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5696:2668,Test,Test,2668,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5696,1,['Test'],['Test']
Testability,31); at org.apache.logging.log4j.core.pattern.PatternParser.<init>(PatternParser.java:112); at org.apache.logging.log4j.core.layout.PatternLayout.createPatternParser(PatternLayout.java:220); at org.apache.logging.log4j.core.layout.PatternLayout.<init>(PatternLayout.java:138); at org.apache.logging.log4j.core.layout.PatternLayout.<init>(PatternLayout.java:57); at org.apache.logging.log4j.core.layout.PatternLayout$Builder.build(PatternLayout.java:446); at org.apache.logging.log4j.core.config.AbstractConfiguration.setToDefault(AbstractConfiguration.java:518); at org.apache.logging.log4j.core.config.DefaultConfiguration.<init>(DefaultConfiguration.java:49); at org.apache.logging.log4j.core.LoggerContext.<init>(LoggerContext.java:75); at org.apache.logging.log4j.core.selector.ClassLoaderContextSelector.createContext(ClassLoaderContextSelector.java:171); at org.apache.logging.log4j.core.selector.ClassLoaderContextSelector.locateContext(ClassLoaderContextSelector.java:145); at org.apache.logging.log4j.core.selector.ClassLoaderContextSelector.getContext(ClassLoaderContextSelector.java:70); at org.apache.logging.log4j.core.selector.ClassLoaderContextSelector.getContext(ClassLoaderContextSelector.java:57); at org.apache.logging.log4j.core.impl.Log4jContextFactory.getContext(Log4jContextFactory.java:140); at org.apache.logging.log4j.core.impl.Log4jContextFactory.getContext(Log4jContextFactory.java:41); at org.apache.logging.log4j.LogManager.getContext(LogManager.java:182); at org.apache.logging.log4j.LogManager.getLogger(LogManager.java:455); at org.broadinstitute.hellbender.utils.Utils.<clinit>(Utils.java:77); at org.broadinstitute.hellbender.Main.<clinit>(Main.java:45); at java.lang.Class.forName0(Native Method); at java.lang.Class.forName(Class.java:348); at org.apache.spark.util.Utils$.classForName(Utils.scala:230); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:739); at org.apache.spark.deploy.SparkSubmit$.doRunMain$,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5126:4675,log,logging,4675,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5126,1,['log'],['logging']
Testability,"32693; Buffer resized from 32693bytes to 32738; Buffer resized from 32738bytes to 32741; Buffer resized from 32741bytes to 32756; Buffer resized from 32756bytes to 32768; Buffer resized from 32768bytes to 32769; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x00007f9935bac359, pid=8320, tid=0x00007f99881bf700; #; # JRE version: OpenJDK Runtime Environment (8.0_171-b10) (build 1.8.0_171-b10); # Java VM: OpenJDK 64-Bit Server VM (25.171-b10 mixed mode linux-amd64 compressed oops); # Problematic frame:; # C [libtiledbgenomicsdb1661720680664773125.so+0x155359] BufferVariantCell::set_cell(void const*)+0x99; #; # Failed to write core dump. Core dumps have been disabled. To enable core dumping, try ""ulimit -c unlimited"" before starting Java again; #; # An error report file with more information is saved as:; # /mnt/isilon/cbmi/variome/rathik/mendelian_rnaseq/gatk_output/CDL-164-04P/log/hs_err_pid8320.log; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; # The crash happened outside the Java Virtual Machine in native code.; # See problematic frame for where to report the bug.; #; ```. Then, I tried to enable core dumping:. ```; [rathik@reslnrefo01 CDL-164-04P]$ ulimit -c unlimited. [rathik@reslnrefo01 CDL-164-04P]$ gatk --java-options '-Xms454m -Xmx3181m -XX:+UseSerialGC -Djava.io.tmpdir=/mnt/isilon/cbmi/variome/rathik/mendelian_rnaseq/gatk_output/CDL-164-04P/joint/gatk-haplotype-joint/CDL-164-04P/1/bcbiotx/tmp1SAfjS' GenomicsDBImport --reader-threads 1 --genomicsdb-workspace-path CDL-164-04P-1_0_249250621_genomicsdb -L 1:1-249250621 --variant /mnt/isilon/cbmi/variome/rathik/mendelian_rnaseq/gatk_output/CDL-164-04P/variation/rnaseq/gatk-haplotype/Sample_1__CDL-164-04P-gatk-haplotype-annotated-rnaedit-annotated-gemini.vcf.gz; Using GATK jar /mnt/isilon/cbmi/variome/bin/bcbio-nextgen/bcbio/anaconda/share/gatk4-4.0.6.0-0/gatk-package-4.0.6.0-local.jar; Running:; java",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5045:5633,log,log,5633,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5045,1,['log'],['log']
Testability,35); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:108); 	at org.testng.internal.Invoker.invokeMethod(Invoker.java:661); 	at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:869); 	at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1193); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:126); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:109); 	at org.testng.TestRunner.privateRun(TestRunner.java:744); 	at org.testng.TestRunner.run(TestRunner.java:602); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:380); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:375); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:340); 	at org.testng.SuiteRunner.run(SuiteRunner.java:289); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1301); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1226); 	at org.testng.TestNG.runSuites(TestNG.java:1144); 	at org.testng.TestNG.run(TestNG.java:1115); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:129); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:88); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(Delegat,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4024:1628,test,testng,1628,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4024,1,['test'],['testng']
Testability,"353714322_0004 (state: ACCEPTED); 20/10/22 12:02:38 INFO yarn.Client: Application report for application_1603353714322_0004 (state: ACCEPTED); 20/10/22 12:02:39 INFO yarn.Client: Application report for application_1603353714322_0004 (state: ACCEPTED); 20/10/22 12:02:40 INFO yarn.Client: Application report for application_1603353714322_0004 (state: ACCEPTED); 20/10/22 12:02:41 INFO yarn.Client: Application report for application_1603353714322_0004 (state: ACCEPTED); 20/10/22 12:02:42 INFO yarn.Client: Application report for application_1603353714322_0004 (state: ACCEPTED); 20/10/22 12:02:43 INFO yarn.Client: Application report for application_1603353714322_0004 (state: ACCEPTED); 20/10/22 12:02:44 INFO yarn.Client: Application report for application_1603353714322_0004 (state: FAILED); 20/10/22 12:02:44 INFO yarn.Client: ; 	 client token: N/A; 	 diagnostics: Application application_1603353714322_0004 failed 2 times due to AM Container for appattempt_1603353714322_0004_000002 exited with exitCode: 13; For more detailed output, check application tracking page:http://jacky:8088/cluster/app/application_1603353714322_0004Then, click on links to logs of each attempt.; Diagnostics: Exception from container-launch.; Container id: container_1603353714322_0004_02_000001; Exit code: 13; Stack trace: ExitCodeException exitCode=13: ; 	at org.apache.hadoop.util.Shell.runCommand(Shell.java:545); 	at org.apache.hadoop.util.Shell.run(Shell.java:456); 	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:722); 	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:211); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecut",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6906:5870,log,logs,5870,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6906,1,['log'],['logs']
Testability,"36 INFO GenomicsDBImport - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 10:19:39.337 INFO GenomicsDBImport - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 10:19:39.337 INFO GenomicsDBImport - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 10:19:39.337 INFO GenomicsDBImport - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 10:19:39.337 INFO GenomicsDBImport - Deflater: IntelDeflater; 10:19:39.337 INFO GenomicsDBImport - Inflater: IntelInflater; 10:19:39.337 INFO GenomicsDBImport - GCS max retries/reopens: 20; 10:19:39.338 INFO GenomicsDBImport - Requester pays: disabled; 10:19:39.338 INFO GenomicsDBImport - Initializing engine; 10:19:39.489 INFO IntervalArgumentCollection - Processing 100 bp from intervals; 10:19:39.490 INFO GenomicsDBImport - Done initializing engine; 10:19:39.948 INFO GenomicsDBLibLoader - GenomicsDB native library version : 1.4.4-ce4e1b9; 10:19:39.951 INFO GenomicsDBImport - Vid Map JSON file will be written to /home/test/Software/gatk-4.4.0.0/test/./02/vidmap.json; 10:19:39.951 INFO GenomicsDBImport - Callset Map JSON file will be written to /home/test/Software/gatk-4.4.0.0/test/./02/callset.json; 10:19:39.951 INFO GenomicsDBImport - Complete VCF Header will be written to /home/test/Software/gatk-4.4.0.0/test/./02/vcfheader.vcf; 10:19:39.951 INFO GenomicsDBImport - Importing to workspace - /home/test/Software/gatk-4.4.0.0/test/./02; 10:19:40.060 INFO GenomicsDBImport - Importing batch 1 with 2 samples; 10:19:40.075 INFO GenomicsDBImport - Shutting down engine; org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImport done. Elapsed time: 0.01 minutes.; Runtime.totalMemory()=285212672; java.lang.NumberFormatException: For input string: ""G""; 	at java.base/java.lang.NumberFormatException.forInputString(NumberFormatException.java:67); 	at java.base/java.lang.Integer.parseInt(Integer.java:668); 	at java.base/java.lang.Integer.parseInt(Integer.java:786); 	at htsjdk.tribble.readers.TabixReader.getIntv(TabixReader.java:337); 	at",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8517:2514,test,test,2514,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8517,1,['test'],['test']
Testability,"362); 	at org.apache.spark.rdd.PairRDDFunctions.saveAsNewAPIHadoopDataset(PairRDDFunctions.scala:1084); 	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsNewAPIHadoopFile$2.apply$mcV$sp(PairRDDFunctions.scala:1003); 	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsNewAPIHadoopFile$2.apply(PairRDDFunctions.scala:994); 	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsNewAPIHadoopFile$2.apply(PairRDDFunctions.scala:994); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); 	at org.apache.spark.rdd.RDD.withScope(RDD.scala:362); 	at org.apache.spark.rdd.PairRDDFunctions.saveAsNewAPIHadoopFile(PairRDDFunctions.scala:994); 	at org.apache.spark.api.java.JavaPairRDD.saveAsNewAPIHadoopFile(JavaPairRDD.scala:823); 	at org.disq_bio.disq.impl.formats.sam.AnySamSinkMultiple.save(AnySamSinkMultiple.java:96); 	at org.disq_bio.disq.HtsjdkReadsRddStorage.write(HtsjdkReadsRddStorage.java:206); 	at org.broadinstitute.hellbender.engine.sp...; ```. here’s the command line; bamIn=gs://broad-gatk-test-jenkins-robust/CEUTrio.HiSeq.WEx.b37.NA12892.readnamesort.bam; refIn=gs://broad-gatk-test-jenkins-robust/human_g1k_v37.fasta; bamOut=gs://broad-gatk-test-jenkins-write-robust/CEUTrio.HiSeq.WEx.b37.NA12892.readnamesort.bam.md.bqsr; knownIn=gs://broad-gatk-test-jenkins-robust/dbsnp_138.b37.excluding_sites_after_129.vcf; vcfOut=gs://broad-gatk-test-jenkins-write-robust/CEUTrio.HiSeq.WEx.b37.NA12892.vcf; ./gatk ReadsPipelineSpark \; -I $bamIn \; -R $refIn \; --output-bam $bamOut \; -O $vcfOut \; --known-sites $knownIn \; --sharded-output true \; --emit-original-quals \; --duplicate-scoring-strategy SUM_OF_BASE_QUALITIES \; --num-reducers 0 \; -- \; --spark-runner GCS \; --cluster $CLUSTERNAME \; --driver-memory 8G \; --conf 'spark.yarn.executor.memoryOverhead=2000' \; --executor-memory 18g \; --executor-cores 6 \; --conf spark.yarn.executor.memoryOverhead=2000""",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5545:12889,test,test-jenkins-robust,12889,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5545,5,['test'],"['test-jenkins-robust', 'test-jenkins-write-robust']"
Testability,365 vat python testing additions,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7756:15,test,testing,15,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7756,1,['test'],['testing']
Testability,"37); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:497); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:108); 	at org.testng.internal.Invoker.invokeMethod(Invoker.java:661); 	at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:869); 	at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1193); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:126); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:109); 	at org.testng.TestRunner.privateRun(TestRunner.java:744); 	at org.testng.TestRunner.run(TestRunner.java:602); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:380); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:375); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:340); 	at org.testng.SuiteRunner.run(SuiteRunner.java:289); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1301); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1226); 	at org.testng.TestNG.runSuites(TestNG.java:1144); 	at org.testng.TestNG.run(TestNG.java:1115); 	at org.testng.IDEARemoteTestNG.run(IDEARemoteTestNG.java:72); 	at org.testng.RemoteTestNGStarter.main(RemoteTestNGStarter.java:123); ```. #### Steps to reproduce; These are the arguments I used (the input bam is on the file system):. ```; final String[] args = {; ""-I"", ""/humgen/gsa-hpprojects/dev/mshand/SpecOps/Mitochondria/Filtering/IGV/198489_vs_811158/sorted.mt.1.bam"",; ""-"" + M2ArgumentCollection.TUMOR_SAMPLE_SHORT_NAME, ""198489"",; ""-R"", ""/humgen/gsa-hpprojects/dev/mshand/SpecOps/Mitochondria/MitochondriaOnlyFastas/Homo_sapiens_assembl",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5036:4139,test,testng,4139,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5036,1,['test'],['testng']
Testability,38.20.21.dict; src/test/resources/large/Homo_sapiens_assembly38.20.21.fasta.fai; src/test/resources/large/human_g1k_v37.20.21.fasta.amb; src/test/resources/large/human_g1k_v37.20.21.fasta.ann; src/test/resources/large/human_g1k_v37.20.21.fasta.bwt; src/test/resources/large/human_g1k_v37.20.21.fasta.pac; src/test/resources/large/human_g1k_v37.20.21.fasta.sa; src/test/resources/large/K-562.duplicateMarked.chr20.bai; src/test/resources/large/mutect/dream_synthetic_bams/normal_3.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/normal_4.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/normal.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/tumor_3.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/tumor_4.bam.bai; src/test/resources/large/mutect/dream_synthetic_bams/tumor.bam.bai; src/test/resources/large/NA12878.RNAseq.bai; src/test/resources/large/SVIntegrationTest.bam.bai; src/test/resources/large/very-small-gnomad.vcf.idx; src/test/resources/large/VQSR/ALL.wgs.indels_mills_devine_hg19_leftAligned_collapsed_double_hit.sites.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/combined.phase1.chr20.raw.indels.filtered.sites.1M-10M.vcf.idx; src/test/resources/large/VQSR/dbsnp_132_b37.leftAligned.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/expected/snpRecal.scattered.vcf.idx; src/test/resources/large/VQSR/expected/snpSampledRecal.vcf.idx; src/test/resources/large/VQSR/indelRecal.vcf.idx; src/test/resources/large/VQSR/Omni25_sites_1525_samples.b37.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/phase1.projectConsensus.chr20.1M-10M.raw.snps.vcf.idx; src/test/resources/large/VQSR/sites_r27_nr.b37_fwd.20.1M-10M.vcf.idx; src/test/resources/large/VQSR/snpRecal.vcf.idx; src/test/resources/NA12878.chr17_69k_70k.dictFix.bam.bai; src/test/resources/NA12878.chr17_69k_70k.dictFix.cram.crai; src/test/resources/org/broadinstitute/hellbender/engine/ambiguityCodes.dict; src/test/resources/org/broadinstitute/hellbender/engine/ambiguityCo,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3905:7062,test,test,7062,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905,1,['test'],['test']
Testability,"4 05:09:31,60] [info] MaterializeWorkflowDescriptorActor [968be82c]: Call-to-Backend assignments: ValidateBamsWf.ValidateBAM -> Local; [2020-07-14 05:09:31,82] [warn] Local [968be82c]: Key/s [memory, disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.; [2020-07-14 05:09:35,38] [info] Not triggering log of token queue status. Effective log interval = None; [2020-07-14 05:09:37,15] [info] WorkflowExecutionActor-968be82c-eef3-4bdb-a1ab-3d4e2ca70674 [968be82c]: Starting ValidateBamsWf.ValidateBAM; [2020-07-14 05:09:37,39] [info] Assigned new job execution tokens to the following groups: 968be82c: 1; [2020-07-14 05:09:41,61] [warn] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: Unrecognized runtime attribute keys: disks, memory; [2020-07-14 05:09:41,71] [info] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: /gatk/gatk \; ValidateSamFile \; --INPUT /cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/inputs/-1942028726/test.bam \; --OUTPUT test.validation_.txt \; --MODE SUMMARY; [2020-07-14 05:09:41,76] [info] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: executing: # make sure there is no preexisting Docker CID file; rm -f /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/docker_cid; # run as in the original configuration without --rm flag (will remove later); docker run \; --cidfile /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/docker_cid \; -i \; \; --entrypoint /bin/bash \; -v /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0:/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0:delegated \; broadinstitute/gatk@sha",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6710:4939,test,test,4939,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710,1,['test'],['test']
Testability,"4 MLEAF.tdb; -rwx------ 1 hcaoad boip 80M Apr 20 13:34 MLEAF_var.tdb; -rwx------ 1 hcaoad boip 236M Apr 20 13:34 MQRankSum.tdb; -rwx------ 1 hcaoad boip 204M Apr 20 13:34 PGT.tdb; -rwx------ 1 hcaoad boip 6.8M Apr 20 13:34 PGT_var.tdb; -rwx------ 1 hcaoad boip 208M Apr 20 13:34 PID.tdb; -rwx------ 1 hcaoad boip 15M Apr 20 13:34 PID_var.tdb; -rwx------ 1 hcaoad boip 315M Apr 20 13:34 PL.tdb; -rwx------ 1 hcaoad boip 14G Apr 20 13:34 PL_var.tdb; -rwx------ 1 hcaoad boip 173M Apr 20 13:34 PS.tdb; -rwx------ 1 hcaoad boip 496M Apr 20 13:34 QUAL.tdb; -rwx------ 1 hcaoad boip 412M Apr 20 13:34 RAW_MQandDP.tdb; -rwx------ 1 hcaoad boip 358M Apr 20 13:34 ReadPosRankSum.tdb; -rwx------ 1 hcaoad boip 254M Apr 20 13:34 REF.tdb; -rwx------ 1 hcaoad boip 1.5G Apr 20 13:34 REF_var.tdb; -rwx------ 1 hcaoad boip 278M Apr 20 13:34 Samples.tdb; -rwx------ 1 hcaoad boip 256M Apr 20 13:34 Samples_var.tdb; -rwx------ 1 hcaoad boip 510M Apr 20 13:34 SB.tdb; </pre>; Log file for chr1, no error reported:; <pre>Using GATK jar /home/hcaoad/miniconda2/share/gatk4-4.2.0.0-0/gatk-package-4.2.0.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx80G -Xms80G -jar /home/hcaoad/miniconda2/share/gatk4-4.2.0.0-0/gatk-package-4.2.0.0-local.jar GenomicsDBImport --genomicsdb-workspace-path /scratch/PI/boip/Han/WGS/HK_WGS_5X/GenomicsDB//chr1 -L 1 --sample-name-map input/sample.map -R /scratch/PI/boip/Reference/Human_genome/GRCh37/hs37d5.fa --batch-size 400 --reader-threads 5; 14:48:08.923 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/hcaoad/miniconda2/share/gatk4-4.2.0.0-0/gatk-package-4.2.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Apr 16, 2021 2:48:09 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 14:48:09.08",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7218:4148,Log,Log,4148,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7218,1,['Log'],['Log']
Testability,41.992 INFO GenomicsDBImport - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 23:42:41.992 INFO GenomicsDBImport - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 23:42:41.992 INFO GenomicsDBImport - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 23:42:41.992 INFO GenomicsDBImport - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 23:42:41.992 INFO GenomicsDBImport - Deflater: IntelDeflater; 23:42:41.992 INFO GenomicsDBImport - Inflater: IntelInflater; 23:42:41.992 INFO GenomicsDBImport - GCS max retries/reopens: 20; 23:42:41.992 INFO GenomicsDBImport - Requester pays: disabled; 23:42:41.992 INFO GenomicsDBImport - Initializing engine; 23:42:44.099 INFO IntervalArgumentCollection - Processing 115639695 bp from intervals; 23:42:44.102 INFO GenomicsDBImport - Done initializing engine; 23:42:44.276 INFO GenomicsDBImport - Vid Map JSON file will be written to /home/WangBS/Analyses/vcf/test/chr02/vidmap.json; 23:42:44.276 INFO GenomicsDBImport - Callset Map JSON file will be written to /home/WangBS/Analyses/vcf/test/chr02/callset.json; 23:42:44.276 INFO GenomicsDBImport - Complete VCF Header will be written to /home/WangBS/Analyses/vcf/test/chr02/vcfheader.vcf; 23:42:44.276 INFO GenomicsDBImport - Importing to array - /home/WangBS/Analyses/vcf/test/chr02/genomicsdb_array; 23:42:44.276 INFO ProgressMeter - Starting traversal; 23:42:44.276 INFO ProgressMeter - Current Locus Elapsed Minutes Batches Processed Batches/Minute; 23:42:45.830 INFO GenomicsDBImport - Importing batch 1 with 63 samples; Buffer resized from 37294 bytes to 65464; Buffer resized from 37294 bytes to 65511; Buffer resized from 37293 bytes to 65539; Buffer resized from 37294 bytes to 65447; .....; .....; Buffer resized from 65538 bytes to 65539; Buffer resized from 65538 bytes to 65539; Buffer resized from 65538 bytes to 65539; 06:50:14.219 INFO ProgressMeter - Qrob_Chr02:1 427.5 1 0.0; 06:50:14.220 INFO GenomicsDBImport - Done importing batch 1/1; 06:50:14.221 INFO ProgressMeter - Qrob_Ch,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5865:3012,test,test,3012,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5865,1,['test'],['test']
Testability,"41:51.191 WARN GencodeGtfCodec - GENCODE GTF Header line 1 has a version number that is above maximum tested version (v 28) (given: 34): ##description: evidence-based annotation of the human genome (GRCh38), version 34 (Ensembl 100), mapped to GRCh37 with gencode-backmap Continuing, but errors may occur.; 15:41:51.192 WARN GencodeGtfCodec - GENCODE GTF Header line 1 has a version number that is above maximum tested version (v 28) (given: 34): ##description: evidence-based annotation of the human genome (GRCh38), version 34 (Ensembl 100), mapped to GRCh37 with gencode-backmap Continuing, but errors may occur.; 15:41:51.192 INFO FeatureManager - Using codec GencodeGtfCodec to read file file:///home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s/gencode/hg19/gencode.v34lift37.annotation.REORDERED.gtf; 15:41:51.193 WARN GencodeGtfCodec - GENCODE GTF Header line 1 has a version number that is above maximum tested version (v 28) (given: 34): ##description: evidence-based annotation of the human genome (GRCh38), version 34 (Ensembl 100), mapped to GRCh37 with gencode-backmap Continuing, but errors may occur.; 15:41:51.201 INFO DataSourceUtils - Resolved data source file path: file:///home/shiyang/softwares/gatk-4.1.8.1/gencode.v34lift37.pc_transcripts.fa -> file:///home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s/gencode/hg19/gencode.v34lift37.pc_transcripts.fa; 15:41:54.713 INFO DataSourceUtils - Resolved data source file path: file:///home/shiyang/softwares/gatk-4.1.8.1/simple_uniprot_Dec012014.tsv -> file:///home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s/simple_uniprot/hg19/simple_uniprot_Dec012014.tsv; 15:41:54.747 INFO DataSourceUtils - Resolved data source file path: file:///home/shiyang/softwares/gatk-4.1.8.1/gencode_xrefseq_v75_37.tsv -> file:///home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s/gencode_xrefseq/hg19/gencode_xrefseq",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6758:18699,test,tested,18699,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6758,1,['test'],['tested']
Testability,42); 	at org.broadinstitute.hellbender.Main.instanceMain(Main.java:183); 	at org.broadinstitute.hellbender.CommandLineProgramTest.runCommandLine(CommandLineProgramTest.java:32); 	at org.broadinstitute.hellbender.utils.test.CommandLineProgramTester.runCommandLine(CommandLineProgramTester.java:92); 	at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImportIntegrationTest.writeToGenomicsDB(GenomicsDBImportIntegrationTest.java:180); 	at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImportIntegrationTest.testCommandIncludedInOutputHeader(GenomicsDBImportIntegrationTest.java:422); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:108); 	at org.testng.internal.Invoker.invokeMethod(Invoker.java:661); 	at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:869); 	at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1193); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:126); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:109); 	at org.testng.TestRunner.privateRun(TestRunner.java:744); 	at org.testng.TestRunner.run(TestRunner.java:602); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:380); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:375); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:340); 	at org.testng.SuiteRunner.run(SuiteRunner.java:289); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1301); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1226); 	at org.testng.TestNG.runSuites(TestNG.java:,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4062:1814,test,testng,1814,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4062,1,['test'],['testng']
Testability,43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:133); 	at org.testng.internal.TestInvoker.invokeMethod(TestInvoker.java:584); 	at org.testng.internal.TestInvoker.invokeTestMethod(TestInvoker.java:172); 	at org.testng.internal.MethodRunner.runInSequence(MethodRunner.java:46); 	at org.testng.internal.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:804); 	at org.testng.internal.TestInvoker.invokeTestMethods(TestInvoker.java:145); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:128); 	at java.util.ArrayList.forEach(ArrayList.java:1257); 	at org.testng.TestRunner.privateRun(TestRunner.java:770); 	at org.testng.TestRunner.run(TestRunner.java:591); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:402); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:396); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:355); 	at org.testng.SuiteRunner.run(SuiteRunner.java:304); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:53); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:96); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1180); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1102); 	at org.testng.TestNG.runSuites(TestNG.java:1032); 	at org.testng.TestNG.run(TestNG.java:1000); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:141); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:90); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(Delegat,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6748:3129,test,testng,3129,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6748,2,['test'],['testng']
Testability,4j.core.layout.PatternLayout.createPatternParser(PatternLayout.java:220); at org.apache.logging.log4j.core.layout.PatternLayout.<init>(PatternLayout.java:138); at org.apache.logging.log4j.core.layout.PatternLayout.<init>(PatternLayout.java:57); at org.apache.logging.log4j.core.layout.PatternLayout$Builder.build(PatternLayout.java:446); at org.apache.logging.log4j.core.config.AbstractConfiguration.setToDefault(AbstractConfiguration.java:518); at org.apache.logging.log4j.core.config.DefaultConfiguration.<init>(DefaultConfiguration.java:49); at org.apache.logging.log4j.core.LoggerContext.<init>(LoggerContext.java:75); at org.apache.logging.log4j.core.selector.ClassLoaderContextSelector.createContext(ClassLoaderContextSelector.java:171); at org.apache.logging.log4j.core.selector.ClassLoaderContextSelector.locateContext(ClassLoaderContextSelector.java:145); at org.apache.logging.log4j.core.selector.ClassLoaderContextSelector.getContext(ClassLoaderContextSelector.java:70); at org.apache.logging.log4j.core.selector.ClassLoaderContextSelector.getContext(ClassLoaderContextSelector.java:57); at org.apache.logging.log4j.core.impl.Log4jContextFactory.getContext(Log4jContextFactory.java:140); at org.apache.logging.log4j.core.impl.Log4jContextFactory.getContext(Log4jContextFactory.java:41); at org.apache.logging.log4j.LogManager.getContext(LogManager.java:182); at org.apache.logging.log4j.LogManager.getLogger(LogManager.java:455); at org.broadinstitute.hellbender.utils.Utils.<clinit>(Utils.java:77); at org.broadinstitute.hellbender.Main.<clinit>(Main.java:45); at java.lang.Class.forName0(Native Method); at java.lang.Class.forName(Class.java:348); at org.apache.spark.util.Utils$.classForName(Utils.scala:230); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:739); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205); at org.apache.spark.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5126:4792,log,logging,4792,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5126,1,['log'],['logging']
Testability,5 DEBUG GenomeLocParser - chrUn_KI270754v1 (40191 bp); 23:44:42.545 DEBUG GenomeLocParser - chrUn_KI270755v1 (36723 bp); 23:44:42.545 DEBUG GenomeLocParser - chrUn_KI270756v1 (79590 bp); 23:44:42.545 DEBUG GenomeLocParser - chrUn_KI270757v1 (71251 bp); 23:44:42.545 DEBUG GenomeLocParser - chrUn_GL000214v1 (137718 bp); 23:44:42.545 DEBUG GenomeLocParser - chrUn_KI270742v1 (186739 bp); 23:44:42.545 DEBUG GenomeLocParser - chrUn_GL000216v2 (176608 bp); 23:44:42.545 DEBUG GenomeLocParser - chrUn_GL000218v1 (161147 bp); 23:44:42.545 DEBUG GenomeLocParser - chrEBV (171823 bp); 23:44:42.632 INFO FeatureManager - Using codec IntervalListCodec to read file file:///gpfs/hpc/home/lijc/xiangxud/project/test/NGS_WES_test/4_tools_vcf/gatk4/info/scatter/scatter_30.interval_list; 23:44:42.739 DEBUG FeatureDataSource - Cache statistics for FeatureInput /gpfs/hpc/home/lijc/xiangxud/project/test/NGS_WES_test/4_tools_vcf/gatk4/info/scatter/scatter_30.interval_list:/gpfs/hpc/home/lijc/xiangxud/project/test/NGS_WES_test/4_tools_vcf/gatk4/info/scatter/scatter_30.interval_list:; 23:44:42.740 DEBUG FeatureCache - Cache hit rate was 0.00% (0 out of 0 total queries); 23:44:42.743 INFO IntervalArgumentCollection - Processing 1022379 bp from intervals; 23:44:42.756 INFO GermlineCNVCaller - Reading and validating annotated intervals...; 23:44:43.119 INFO GermlineCNVCaller - GC-content annotations for intervals found; explicit GC-bias correction will be performed...; 23:44:43.160 INFO GermlineCNVCaller - Running the tool in COHORT mode...; 23:44:43.160 INFO GermlineCNVCaller - Validating and aggregating data from input read-count files...; 23:44:43.160 DEBUG GenomeLocParser - Prepared reference sequence contig dictionary; 23:44:43.160 DEBUG GenomeLocParser - chr1 (248956422 bp); 23:44:43.161 DEBUG GenomeLocParser - chr2 (242193529 bp); 23:44:43.161 DEBUG GenomeLocParser - chr3 (198295559 bp); 23:44:43.161 DEBUG GenomeLocParser - chr4 (190214555 bp); 23:44:43.161 DEBUG GenomeLocParser - chr5 (18153,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8938:19667,test,test,19667,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8938,1,['test'],['test']
Testability,"5 oflag=dsync; 5+0 records in; 5+0 records out; 5368709120 bytes (5.4 GB, 5.0 GiB) copied, 51.5764 s, 104 MB/s; root@6ece7fab91ec:/app#; ; ; Ran to write on FSx for luster mount on ec2:; ; [root@ip-10-76-63-158 genomicsdb]# dd if=/dev/zero of=/gfb-dev-sv-fsx-results-us-east-2/cromwell-execution/GATKSVPipelineBatch/087bd722-5f51-43eb-a89e-70846a1da89f/call-GATKSVPipelinePhase1/GATKSVPipelinePhase1/38595c13-b874-4753-a554-81c09f6449f8/call-GatherBatchEvidence/GatherBatchEvidence/c8120761-6d9f-4bd3-b450-f528b7be817c/call-BAFFromGVCFs/BAFFromGVCFs/d5032666-9c09-4857-a8d7-41042927cf89/call-ImportGVCFs/shard-389/genomicsdb/test.img bs=1G count=5 oflag=dsync; 5+0 records in; 5+0 records out; 5368709120 bytes (5.4 GB) copied, 23.5143 s, 228 MB/s; [root@ip-10-76-63-158 genomicsdb]#. We also ran the jobs with strace enabled and we found that there are millions of FUTEX_WAIT_PRIVATE processes while we run the jobs for fsx writing as compared to just 26 when we write to EBS. # Local EBS writing strace log (Ran around 3.5 hrs); [root@ip-10-76-62-193 importvcf-job]# egrep ""FUTEX_WAIT_PRIVATE, 0, NULL"" ./local-write-logs/strace_local_writing.log | wc -l; 26. # FSx strace logs; # --reader-threads 5 (Ran around 7 hours); [root@ip-10-76-62-193 importvcf-job]# egrep ""FUTEX_WAIT_PRIVATE, 0, NULL"" ./fsx-write-logs/strace_fsx_writing.log | wc -l; 24378265. # --reader-threads 1; [root@ip-10-76-62-193 importvcf-job]# egrep ""FUTEX_WAIT_PRIVATE, 0, NULL"" ./strace_thread_1_fsx.txt | wc -l; 8745113. #--reader-threads 2; [root@ip-10-76-62-193 importvcf-job]# egrep ""FUTEX_WAIT_PRIVATE, 0, NULL"" ./strace_thread_2_fsx.txt | wc -l; 13946622. #--reader-threads 10; [root@ip-10-76-62-193 importvcf-job]# egrep ""FUTEX_WAIT_PRIVATE, 0, NULL"" ./strace_thread_10_fsx.txt | wc -l; 13535883; [root@ip-10-76-62-193 importvcf-job]#. The last 3 i.e. tests for thread 1, 2 and 10 were only executed for 20 mins and in those 20 minutes it only loaded around 220 MBs to the genomicsdb. Note that the above executions we",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7646:3492,log,log,3492,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7646,1,['log'],['log']
Testability,5.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.CT_15_1115.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.CT_15.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.CT_15.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_0.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_0.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CR_SOFTCLIP_BASES.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CR_SOFTCLIP_BASES.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CR_WRITE_NS.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CR_WRITE_NS.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CR_WRITE_Q0S.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CR_WRITE_Q0S.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CT_15_X_CCCCC_XF.bam; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10_CT_15_X_CCCCC_XF.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_10.tmp; src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTest.withRG.hg19.QT_20.bam; src/test/resources/org/broadins,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3905:24192,test,test,24192,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905,1,['test'],['test']
Testability,5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/cohort.vcf.gz; 14:24:34.510 INFO Funcotator - Done initializing engine; 14:24:34.511 INFO Funcotator - Validating sequence dictionaries...; 14:24:34.550 INFO Funcotator - Processing user transcripts/defaults/overrides...; 14:24:34.551 INFO Funcotator - Initializing data sources...; 14:24:34.554 INFO DataSourceUtils - Initializing data sources from directory: funcotator_dataSources.v1.7.20200521g; 14:24:34.560 INFO DataSourceUtils - Data sources version: 1.7.2020521g; 14:24:34.560 INFO DataSourceUtils - Data sources source: ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/funcotator/funcotator_dataSources.v1.7.20200521g.tar.gz; 14:24:34.561 INFO DataSourceUtils - Data sources alternate source: gs://broad-public-datasets/funcotator/funcotator_dataSources.v1.7.20200521.tar.gz; 14:24:34.587 INFO DataSourceUtils - Resolved data source file path: file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/gencode.v34.annotation.REORDERED.gtf -> file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/funcotator_dataSources.v1.7.20200521g/gencode/hg38/gencode.v34.annotation.REORDERED.gtf; 14:24:34.591 INFO DataSourceUtils - Resolved data source file path: file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/gencode.v34.pc_transcripts.fa -> file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/funcotator_dataSources.v1.7.20200521g/gencode/hg38/gencode.v34.pc_transcripts.fa; 14:24:34.599 INFO DataSourceUtils - Resolved data source file path: file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/acmg59_test_cl,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6926:4658,test,test,4658,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6926,1,['test'],['test']
Testability,"54,225 HelpFormatter - [Tue Sep 08 10:47:54 WEST 2020] Executing on Mac OS X 10.15.6 x86_64 ; INFO 10:47:54,225 HelpFormatter - Java HotSpot(TM) 64-Bit Server VM 1.8.0_65-b17 ; INFO 10:47:54,229 HelpFormatter - Program Args: -T IndelRealigner -R /Users/mac/Desktop/NGS-/TriTrypDB-47_LmajorLV39c5_Genome.fasta -I /Users/mac/Desktop/NGS-/marked_duplicates42-pe.bam -targetIntervals /Users/mac/Desktop/NGS-/42-pe-realigner.intervals -o /Users/mac/Desktop/NGS-/42-pe-idelsrealigner.bam ; INFO 10:47:54,492 HelpFormatter - Executing as mac@MacBook-Air-de-mac.local on Mac OS X 10.15.6 x86_64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_65-b17. ; INFO 10:47:54,493 HelpFormatter - Date/Time: 2020/09/08 10:47:54 ; INFO 10:47:54,494 HelpFormatter - ---------------------------------------------------------------------------------- ; INFO 10:47:54,494 HelpFormatter - ---------------------------------------------------------------------------------- ; ERROR StatusLogger Unable to create class org.apache.logging.log4j.core.impl.Log4jContextFactory specified in jar:file:/Users/mac/Desktop/GenomeAnalysisTK-3.8-0-ge9d806836%204/GenomeAnalysisTK.jar!/META-INF/log4j-provider.properties; ERROR StatusLogger Log4j2 could not find a logging implementation. Please add log4j-core to the classpath. Using SimpleLogger to log to the console...; INFO 10:47:55,875 GenomeAnalysisEngine - Deflater: IntelDeflater ; INFO 10:47:55,876 GenomeAnalysisEngine - Inflater: IntelInflater ; INFO 10:47:55,876 GenomeAnalysisEngine - Strictness is SILENT ; INFO 10:47:56,246 GenomeAnalysisEngine - Downsampling Settings: No downsampling ; INFO 10:47:56,255 SAMDataSource$SAMReaders - Initializing SAMRecords in serial ; INFO 10:47:56,333 SAMDataSource$SAMReaders - Done initializing BAM readers: total time 0.07 ; ##### ERROR ------------------------------------------------------------------------------------------; ##### ERROR A USER ERROR has occurred (version 3.8-0-ge9d806836): ; ##### ERROR; ##### ERROR This means that one",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6798:1836,log,logging,1836,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6798,1,['log'],['logging']
Testability,54:28.626 INFO GermlineCNVCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 21:54:28.627 INFO GermlineCNVCaller - Deflater: IntelDeflater; 21:54:28.627 INFO GermlineCNVCaller - Inflater: IntelInflater; 21:54:28.627 INFO GermlineCNVCaller - GCS max retries/reopens: 20; 21:54:28.627 INFO GermlineCNVCaller - Using google-cloud-java patch 6d11bef1c81f885c26b2b56c8616b7a705171e4f from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 21:54:28.627 WARN GermlineCNVCaller - . !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. Warning: GermlineCNVCaller is a BETA tool and is not yet ready for use in production. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. 21:54:28.627 INFO GermlineCNVCaller - Initializing engine; 21:54:31.994 INFO GermlineCNVCaller - Done initializing engine; log4j:WARN No appenders could be found for logger (org.broadinstitute.hdf5.HDF5Library).; log4j:WARN Please initialize the log4j system properly.; log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.; 21:54:33.457 INFO GermlineCNVCaller - Intervals specified...; 21:54:34.113 INFO IntervalArgumentCollection - Processing 10999816 bp from intervals; 21:54:34.145 INFO GermlineCNVCaller - No GC-content annotations for intervals found; explicit GC-bias correction will not be performed...; 21:54:34.217 INFO GermlineCNVCaller - Running the tool in the COHORT mode...; 21:54:34.217 INFO GermlineCNVCaller - Validating and aggregating data from input read-count files...; 21:54:34.241 INFO GermlineCNVCaller - Aggregating read-count file /home/shlee/gcnv/low_coverage_1k/HG00096.lc.soohee1k.hdf5 (1 / 24); 21:54:36.539 INFO GermlineCNVCaller - Aggregating read-count file /home/shlee/gcnv/low_coverage_1k/HG00268.lc.soohee1k.hdf5 (2 / 24); 21:54:37.967 INFO GermlineCNVCaller - Aggregating read-count file /home/shlee/gcnv/low_coverage_1k/HG00419.lc.soohee1k.hdf5 (3 / 24); 21:54:40.147 INFO GermlineCNVCaller - Aggregating read-count,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4826:2447,log,logging,2447,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4826,1,['log'],['logging']
Testability,55.985 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.groovy.scripts.internal.DefaultScriptRunnerFactory$ScriptRunnerImpl.run(DefaultScriptRunnerFactory.java:90); 22:05:55.986 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	... 58 more; 22:05:55.986 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] ; 22:05:55.986 [LIFECYCLE] [org.gradle.internal.buildevents.BuildResultLogger] ; 22:05:55.986 [LIFECYCLE] [org.gradle.internal.buildevents.BuildResultLogger] BUILD FAILED; 22:05:55.986 [LIFECYCLE] [org.gradle.internal.buildevents.BuildResultLogger] ; 22:05:55.987 [LIFECYCLE] [org.gradle.internal.buildevents.BuildResultLogger] Total time: 29.153 secs; ```. ```; root# su - portage; portage$ cd /scratch/var/tmp/portage/sci-biology/gatk-9999/work/gatk-9999/; portage$ git lfs pull --include src/main/resources/large; No default remote. Errors logged to /scratch/var/tmp/portage/sci-biology/gatk-9999/work/gatk-9999/.git/lfs/objects/logs/20180420T221032.955218097.log; Use `git lfs logs last` to view the log.; portage$ cat /scratch/var/tmp/portage/sci-biology/gatk-9999/work/gatk-9999/.git/lfs/objects/logs/20180420T221032.955218097.log; git-lfs/2.3.4 (GitHub; linux amd64; go 1.10); git version 2.16.3. $ git-lfs pull --include src/main/resources/large; No default remote. No remotes defined. Current time in UTC: ; 2018-04-20 20:10:32. ENV:; LocalWorkingDir=/scratch/var/tmp/portage/sci-biology/gatk-9999/work/gatk-9999; LocalGitDir=/scratch/var/tmp/portage/sci-biology/gatk-9999/work/gatk-9999/.git; LocalGitStorageDir=/scratch/var/tmp/portage/sci-biology/gatk-9999/work/gatk-9999/.git; LocalMediaDir=/scratch/var/tmp/portage/sci-biology/gatk-9999/work/gatk-9999/.git/lfs/objects; LocalReferenceDir=; TempDir=/scratch/var/tmp/portage/sci-biology/gatk-9999/work/gatk-9999/.git/lfs/tmp; ConcurrentTransfers=3; TusTransfers=false; BasicTransfersOnly=false; SkipDownloadErrors=false; FetchRecentAlways=false; FetchRecentRefsDays=7; Fetc,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4687:15127,log,logs,15127,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4687,1,['log'],['logs']
Testability,587 INFO DataSourceUtils - Resolved data source file path: file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/gencode.v34.annotation.REORDERED.gtf -> file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/funcotator_dataSources.v1.7.20200521g/gencode/hg38/gencode.v34.annotation.REORDERED.gtf; 14:24:34.591 INFO DataSourceUtils - Resolved data source file path: file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/gencode.v34.pc_transcripts.fa -> file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/funcotator_dataSources.v1.7.20200521g/gencode/hg38/gencode.v34.pc_transcripts.fa; 14:24:34.599 INFO DataSourceUtils - Resolved data source file path: file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/acmg59_test_cleaned.txt -> file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/funcotator_dataSources.v1.7.20200521g/acmg_rec/hg38/acmg59_test_cleaned.txt; 14:24:34.608 INFO DataSourceUtils - Resolved data source file path: file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/clinvar_20180429_hg38.vcf -> file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/funcotator_dataSources.v1.7.20200521g/clinvar/hg38/clinvar_20180429_hg38.vcf; 14:24:34.614 INFO DataSourceUtils - Resolved data source file path: file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/LMM_Path_LP_VUS5-variants-6-12-18.sorted_liftover_b38,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6926:5554,test,test,5554,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6926,1,['test'],['test']
Testability,"5g -Xms85g"" GenomicsDBImport \\ ; ; \-R ${dir\_refdata}/b37\_human\_g1k\_v37\_decoy.fasta \\ ; ; \--sample-name-map ${dir\_CombineGVCFs}/S2\_cohort.sample\_map \\ ; ; \--genomicsdb-workspace-path ${dir\_CombineGVCFs}/temporary/tmp4 \\ ; ; \--TMP\_DIR ${dir\_CombineGVCFs}/temporary \\ ; ; \--intervals ${dir\_CombineGVCFs}/intervals/bed3\_tmp.intervals \\ ; ; \--reader-threads 5 \\ ; ; \--batch-size 50. **\[output\]**:. folders and files in; ====================. \--genomicsdb-workspace-path ${dir\_CombineGVCFs}/temporary/tmp4; ================================================================. callset.json ; ; genomicsdb\_array ; ; \_\_tiledb\_workspace.tdb ; ; vcfheader.vcf ; ; vidmap.json. **\[Tool\]: GenotypeGVCFs**. export TILEDB\_DISABLE\_FILE\_LOCKING=1. time ${dir\_tool\_gatk}/gatk --java-options ""-Xmx4g"" GenotypeGVCFs \\ ; ; \-R ${dir\_refdata}/b37\_human\_g1k\_v37\_decoy.fasta \\ ; ; \-V gendb://${dir\_GenomicsDBImport}/tmp4 \\ ; ; \-O ${dir\_GenotypeVCFs}/tmp4.vcf.gz. c) Entire error log:. Using GATK jar /home/projects/bin/gatk-4.0.3.0/gatk-package-4.0.3.0-local.jar ; ; Running: ; ; java -Dsamjdk.use\_async\_io\_read\_samtools=false ; ; \-Dsamjdk.use\_async\_io\_write\_samtools=true ; ; \-Dsamjdk.use\_async\_io\_write\_tribble=false ; ; \-Dsamjdk.compression\_level=2 ; ; \-Xmx4g -jar /home/projects/bin/gatk-4.0.3.0/gatk-package-4.0.3.0-local.jar ; ; GenotypeGVCFs -R /home/reference\_hg19/b37\_human\_g1k\_v37\_decoy.fasta ; ; \-V gendb:///home/WES-VCFQC/S2\_GenomicsDBImport/temporary/tmp4 ; ; \-O /home/WES-VCFQC/S2\_GenomicsDBImport/VCF/tmp4.vcf.gz ; ; 12:52:15.187 INFO NativeLibraryLoader - Loading libgkl\_compression.so from jar:file:/home/projects/bin/gatk-4.0.3.0/gatk-package-4.0.3.0-local.jar!/com/intel/gkl/native/libgkl\_compression.so ; ; 12:52:16.266 INFO GenotypeGVCFs - ------------------------------------------------------------ ; ; 12:52:16.267 INFO GenotypeGVCFs - The Genome Analysis Toolkit (GATK) v4.0.3.0 ; ; 12:52:16.267 INFO GenotypeGVCFs - For",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7442:1862,log,log,1862,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7442,1,['log'],['log']
Testability,6); 	at org.testng.internal.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:804); 	at org.testng.internal.TestInvoker.invokeTestMethods(TestInvoker.java:145); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:128); 	at java.util.ArrayList.forEach(ArrayList.java:1257); 	at org.testng.TestRunner.privateRun(TestRunner.java:770); 	at org.testng.TestRunner.run(TestRunner.java:591); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:402); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:396); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:355); 	at org.testng.SuiteRunner.run(SuiteRunner.java:304); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:53); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:96); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1180); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1102); 	at org.testng.TestNG.runSuites(TestNG.java:1032); 	at org.testng.TestNG.run(TestNG.java:1000); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:141); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:90); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:33);,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6748:3500,test,testng,3500,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6748,2,['test'],['testng']
Testability,6); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:128); 	at java.base/java.util.ArrayList.forEach(ArrayList.java:1540); 	at org.testng.TestRunner.privateRun(TestRunner.java:770); 	at org.testng.TestRunner.run(TestRunner.java:591); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:402); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:396); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:355); 	at org.testng.SuiteRunner.run(SuiteRunner.java:304); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:53); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:96); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1180); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1102); 	at org.testng.TestNG.runSuites(TestNG.java:1032); 	at org.testng.TestNG.run(TestNG.java:1000); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:141); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:90); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.base/java.lang.reflect.Method.invoke(Method.java:566); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:33); 	at org.gradle.internal.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:94); 	at com.sun.proxy.$Proxy5.stop(Unknown Source); 	at ,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6745:3324,test,testing,3324,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6745,2,['test'],['testing']
Testability,62c695472a59dfab47a87afe4f3/gencode.v34.pc_transcripts.fa -> file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/funcotator_dataSources.v1.7.20200521g/gencode/hg38/gencode.v34.pc_transcripts.fa; 14:24:34.599 INFO DataSourceUtils - Resolved data source file path: file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/acmg59_test_cleaned.txt -> file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/funcotator_dataSources.v1.7.20200521g/acmg_rec/hg38/acmg59_test_cleaned.txt; 14:24:34.608 INFO DataSourceUtils - Resolved data source file path: file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/clinvar_20180429_hg38.vcf -> file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/funcotator_dataSources.v1.7.20200521g/clinvar/hg38/clinvar_20180429_hg38.vcf; 14:24:34.614 INFO DataSourceUtils - Resolved data source file path: file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/LMM_Path_LP_VUS5-variants-6-12-18.sorted_liftover_b38.corrected.vcf -> file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/funcotator_dataSources.v1.7.20200521g/lmm_known/hg38/LMM_Path_LP_VUS5-variants-6-12-18.sorted_liftover_b38.corrected.vcf; 14:24:34.617 INFO DataSourceUtils - Resolved data source file path: file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/acmg_lof.tsv -> file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/funco,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6926:6142,test,test,6142,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6926,1,['test'],['test']
Testability,639); 	at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:821); 	at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1131); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); 	at org.testng.TestRunner.privateRun(TestRunner.java:773); 	at org.testng.TestRunner.run(TestRunner.java:623); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:357); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:352); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:310); 	at org.testng.SuiteRunner.run(SuiteRunner.java:259); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1185); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1110); 	at org.testng.TestNG.run(TestNG.java:1018); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:129); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:88); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:32); 	at org.gradle.internal.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:93); 	at com.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2349:5277,test,testng,5277,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2349,1,['test'],['testng']
Testability,639); at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:821); at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1131); at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); at org.testng.TestRunner.privateRun(TestRunner.java:773); at org.testng.TestRunner.run(TestRunner.java:623); at org.testng.SuiteRunner.runTest(SuiteRunner.java:357); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:352); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:310); at org.testng.SuiteRunner.run(SuiteRunner.java:259); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1185); at org.testng.TestNG.runSuitesLocally(TestNG.java:1110); at org.testng.TestNG.run(TestNG.java:1018); at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:133); at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:83); at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:497); at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35); at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); at org.gradle.messaging.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:32); at org.gradle.messaging.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:93); at com.sun.proxy.$Proxy2.stop(,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1638:2483,Test,TestNGTestClassProcessor,2483,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1638,2,['Test'],['TestNGTestClassProcessor']
Testability,"675 INFO FilterMutectCalls - Initializing engine; 11:30:15.870 INFO FeatureManager - Using codec VCFCodec to read file file:///tmp/tmp.8lRGFREUhm/mu.2.vcf; 11:30:15.883 INFO FilterMutectCalls - Done initializing engine; 11:30:15.929 INFO ProgressMeter - Starting traversal; 11:30:15.929 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 11:30:15.930 INFO FilterMutectCalls - Starting pass 0 through the variants; 11:30:15.958 INFO FilterMutectCalls - Finished pass 0 through the variants; 11:30:15.970 INFO FilterMutectCalls - Starting pass 1 through the variants; 11:30:15.974 INFO FilterMutectCalls - Shutting down engine; [November 7, 2019 11:30:15 AM CET] org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls done. Elapsed time: 0.01 minutes.; Runtime.totalMemory()=2252865536; java.lang.IllegalArgumentException: log10 p: Values must be non-infinite and non-NAN; 	at org.broadinstitute.hellbender.utils.NaturalLogUtils.logSumExp(NaturalLogUtils.java:84); 	at org.broadinstitute.hellbender.utils.NaturalLogUtils.normalizeLog(NaturalLogUtils.java:51); 	at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.clusterProbabilities(SomaticClusteringModel.java:203); 	at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.probabilityOfSequencingError(SomaticClusteringModel.java:96); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.TumorEvidenceFilter.calculateErrorProbability(TumorEvidenceFilter.java:27); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2VariantFilter.errorProbability(Mutect2VariantFilter.java:15); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.lambda$new$1(ErrorProbabilities.java:19); 	at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1321); 	at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); 	at java.util.ArrayList$ArrayListSpliterat",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6255:9801,log,logSumExp,9801,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6255,1,['log'],['logSumExp']
Testability,"687,idleTimeout=10800000,daemonOpts=-XX:MaxPermSize=256m,-XX:+HeapDumpOnOutOfMemoryError,-Xmx1024m,-Dfile.encoding=US-ASCII,-Duser.country=US,-Duser.language=en,-Duser.variant]}. Dispatching request Build{id=16e78f98-b0ed-404d-bf38-965d87be7924.1, currentDir=/home/axverdier/Tools/GATK4/git/gatk}.; Received result org.gradle.launcher.daemon.protocol.BuildStarted@5495333e from daemon DaemonInfo{pid=32687, address=[a73e45df-d609-43d0-9385-508a26a328d4 port:39221, addresses:[/0:0:0:0:0:0:0:1, /127.0.0.1]], state=Idle, lastBusy=1516787326803, context=DefaultDaemonContext[uid=7e8a7a6d-190b-445f-9873-f0329477e561,javaHome=/usr/lib/jvm/java-8-oracle,daemonRegistryDir=/home/axverdier/.gradle/daemon,pid=32687,idleTimeout=10800000,daemonOpts=-XX:MaxPermSize=256m,-XX:+HeapDumpOnOutOfMemoryError,-Xmx1024m,-Dfile.encoding=US-ASCII,-Duser.country=US,-Duser.language=en,-Duser.variant]} (build should be starting).; The client will now receive all logging from the daemon (pid: 32687). The daemon log file: /home/axverdier/.gradle/daemon/3.1/daemon-32687.out.log; Starting 7th build in daemon [uptime: 5 mins 24.778 secs, performance: 92%, GC rate: 0.11/s, tenured heap usage: 12% of 716.2 MB]; Executing build with daemon context: DefaultDaemonContext[uid=7e8a7a6d-190b-445f-9873-f0329477e561,javaHome=/usr/lib/jvm/java-8-oracle,daemonRegistryDir=/home/axverdier/.gradle/daemon,pid=32687,idleTimeout=10800000,daemonOpts=-XX:MaxPermSize=256m,-XX:+HeapDumpOnOutOfMemoryError,-Xmx1024m,-Dfile.encoding=US-ASCII,-Duser.country=US,-Duser.language=en,-Duser.variant]; Starting Build; Settings evaluated using settings file '/home/axverdier/Tools/GATK4/git/gatk/settings.gradle'.; Projects loaded. Root project using build file '/home/axverdier/Tools/GATK4/git/gatk/build.gradle'.; Included projects: [root project 'gatk']; Evaluating root project 'gatk' using build file '/home/axverdier/Tools/GATK4/git/gatk/build.gradle'.; build for version:4.0.0.0-32-gf700774-SNAPSHOT; All projects evaluated.; No tasks spe",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4248:1703,log,log,1703,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4248,1,['log'],['log']
