quality_attribute,sentence,source,author,repo,version,id,keyword,matched_word,match_idx,wiki,url,total_similar,target_keywords,target_matched_words
Safety,"Made types final. @tpoterba I think you should rebase GenotypeView on this and use the new accessors there. We shouldn't be trying to optimize the traversal of types or the field access code now. The way to optimize these things is to make the types compile-time objects (as they should be) and these accessors will become code generators that turn lookups into things like `byteOffsets` into a compile-time constant. At some point I think we should go ""full unsafe"" by using off-heap allocation and change the (region, offset) pair into a Long. However, this makes error checking harder. I'll think about when to do that. I still think getting rid of the triple in VSM is the right next step.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2093:459,unsafe,unsafe,459,https://hail.is,https://github.com/hail-is/hail/pull/2093,1,['unsafe'],['unsafe']
Safety,Make a safer implementation of this transformation. The best solution is probably a hash.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5377:7,safe,safer,7,https://hail.is,https://github.com/hail-is/hail/issues/5377,1,['safe'],['safer']
Safety,Make strings raw to avoid warnings,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4617:20,avoid,avoid,20,https://hail.is,https://github.com/hail-is/hail/pull/4617,1,['avoid'],['avoid']
Safety,"Makes elementsOffsetTable private, it's only used internally and by defensively making class members private we can reduce the cognitive complexity of our codebase. More importantly, avoid unnecessarily initializing the elementsOffsetTable array.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7617:183,avoid,avoid,183,https://hail.is,https://github.com/hail-is/hail/pull/7617,1,['avoid'],['avoid']
Safety,"Makes some further progress on simplifying the `PruneDeadFields` pass, with the primary goal of decoupling it from the details of the binding structure. The primary change is to `memoizeValueIR`. Before, it passed in only the requested type of the node, and returned and environment containing all free variables and their requested types. Any bound variables would then need to be removed, and the environments of all children then merged. This low-level manipulation of environments made it closely tied to the binding structure, essentially redundantly encoding everything in `Binds.scala`. Now we pass an environment down into the children, which maps variables to a mutable state tracking the requested type. Each `Ref` node unions the requested type at the reference with the state in the environment. This lets us use the general environment infrastructure. I didn't do an assertion directly comparing the old and new implementations, as I've done with some other pass rewrites. But `PruneDeadFields` has pretty good test coverage.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14509:544,redund,redundantly,544,https://hail.is,https://github.com/hail-is/hail/pull/14509,1,['redund'],['redundantly']
Safety,"Maximal independent set has had a bug/misfeature since https://github.com/hail-is/hail/pull/2975. That PR added an `hl.int64(...)` coercion around the tie_breaker function. This allowed users to pass tie_breakers that returned floating point numbers, but it *changed the meaning*. The sign of values with magnitude greater than or equal to one was preserved. All values in (-1, 1) were converted to 0, thus treating them as indistinguishable for the purposes of the MIS. This PR fixes this long standing bug and adds a simple test for that case. Supporting arbitrary numeric types is actually quite simple! The conversion from any Hail numeric type to float64 is sign-preserving (AFAIK), which is the only property we need to preserve the user's intended ordering. This change also introduces two mild, obvious performance improvements:; - Use one region for the entire MIS calculation, clearing for each invocation of tie_breaker (MIS is single-threaded); - Read the tie_breaker value using simple Region and type methods rather than allocating a new SafeRow each time the tie_breaker is invoked.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7729:1052,Safe,SafeRow,1052,https://hail.is,https://github.com/hail-is/hail/pull/7729,1,['Safe'],['SafeRow']
Safety,"Memory's local storage is a simple cache, so it is safe for k8s to; evict it from the node if the node is underutilized. https://github.com/kubernetes/autoscaler/blob/master/cluster-autoscaler/FAQ.md#what-types-of-pods-can-prevent-ca-from-removing-a-node",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10864:51,safe,safe,51,https://hail.is,https://github.com/hail-is/hail/pull/10864,1,['safe'],['safe']
Safety,"Merge of https://github.com/hail-is/hail/pull/12868 and https://github.com/hail-is/hail/pull/12867 because I expect each is likely to fail due to the other's error. ---. [qob] retry `storage.writer` and `storage.reader`; ; I do not think we frequently get errors in `storage.reader`, but I think `storage.writer` was; always flaky and we were protected by the `retryTransientErrors` on `createNoCompression`. My; change to fix requester pays delayed the error until either the first `write` or the `close`; which do not have a `retryTransientErrors` (and it is not obvious to me that it is safe to retry; a `flush`). ---. [qob] retry transient errors reading the results file. ---",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12869:590,safe,safe,590,https://hail.is,https://github.com/hail-is/hail/pull/12869,1,['safe'],['safe']
Safety,Minor fixes to avoid OrderedRDD => OrderedRDD2 conversion.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2326:15,avoid,avoid,15,https://hail.is,https://github.com/hail-is/hail/pull/2326,1,['avoid'],['avoid']
Safety,"Minrep (in split multi) throwing:; ```; hail.utils.java.FatalError: HailException: invalid allele ""GN"". Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 9 in stage 10.0 failed 20 times, most recent failure: Lost task 9.19 in stage 10.0 (TID 1997, exomes-w-1.c.broad-mpg-gnomad.internal, executor 15): is.hail.utils.HailException: invalid allele ""GN""; 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:6); 	at is.hail.utils.package$.fatal(package.scala:26); 	at is.hail.variant.AltAlleleMethods$.validate(AltAlleleMethods.scala:24); 	at is.hail.variant.AltAlleleMethods$.altAlleleType(AltAlleleMethods.scala:28); 	at is.hail.variant.AltAlleleMethods$.isStar(AltAlleleMethods.scala:73); 	at is.hail.variant.VariantMethods$$anonfun$minRep$1.apply(VariantMethods.scala:43); 	at is.hail.variant.VariantMethods$$anonfun$minRep$1.apply(VariantMethods.scala:43); 	at scala.collection.IndexedSeqOptimized$class.prefixLengthImpl(IndexedSeqOptimized.scala:38); 	at scala.collection.IndexedSeqOptimized$class.forall(IndexedSeqOptimized.scala:43); 	at scala.collection.mutable.WrappedArray.forall(WrappedArray.scala:35); 	at is.hail.variant.VariantMethods$.minRep(VariantMethods.scala:43); 	at is.hail.methods.SplitMultiPartitionContext$$anonfun$2.apply(SplitMulti.scala:196); 	at is.hail.methods.SplitMultiPartitionContext$$anonfun$2.apply(SplitMulti.scala:192); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at scala.collection.Iterator$class.foreach(Iterator.scala:893); 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); 	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59); 	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104); 	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48); 	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310); 	at scala.collection.AbstractIterator.to(Iterator.scala:1336); 	at scala.collection.Tra",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3480:160,abort,aborted,160,https://hail.is,https://github.com/hail-is/hail/issues/3480,1,['abort'],['aborted']
Safety,More parallelism timeouts strict local backend heap size,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13128:17,timeout,timeouts,17,https://hail.is,https://github.com/hail-is/hail/pull/13128,1,['timeout'],['timeouts']
Safety,"Moved sample and variant QC methods from VDS to their own objects, and call the object apply methods from elsewhere (tests and python). If we're happy with this model (following the hail2 api) I'll change everything else. Long chains of `vds.f().g().h()` will need to get broken up as. ```; var vdss = ...; vds = f(vds); vds = g(vds); vds = h(vds); ```. to avoid unnecessary nesting (and clarity).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2590:357,avoid,avoid,357,https://hail.is,https://github.com/hail-is/hail/pull/2590,1,['avoid'],['avoid']
Safety,"Moved the cheatsheets a few weeks ago, had to wait for a website update to safely take the old ones out of the repo. . For reference, new location is here: ; https://github.com/hail-is/hail/blob/master/hail/python/hail/docs/_static/cheatsheets/hail_tables_cheat_sheet.pdf; https://github.com/hail-is/hail/blob/master/hail/python/hail/docs/_static/cheatsheets/hail_matrix_tables_cheat_sheet.pdf",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8061:75,safe,safely,75,https://hail.is,https://github.com/hail-is/hail/pull/8061,1,['safe'],['safely']
Safety,NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:280); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:214); 	at java.lang.Thread.run(Thread.java:748)java.lang.AssertionError: assertion failed; 	at scala.Predef$.assert(Predef.scala:156); 	at is.hail.annotations.Region.loadInt(Region.scala:36); 	at is.hail.expr.types.TBinary$.loadLength(TBinary.scala:62); 	at is.hail.annotations.UnsafeRow$.readBinary(UnsafeRow.scala:128); 	at is.hail.annotations.UnsafeRow$.readString(UnsafeRow.scala:139); 	at is.hail.annotations.UnsafeRow$.readAltAllele(UnsafeRow.scala:152); 	at is.hail.annotations.UnsafeRow$.readArrayAltAllele(UnsafeRow.scala:164); 	at is.hail.annotations.UnsafeRow$.read(UnsafeRow.scala:210); 	at is.hail.annotations.UnsafeRow.get(UnsafeRow.scala:257); 	at is.hail.expr.FilterVariants$$anonfun$10.apply(Relational.scala:503); 	at is.hail.expr.FilterVariants$$anonfun$10.apply(Relational.scala:500); 	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:463); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$9$$anon$5.hasNext(OrderedRVD.scala:658); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$9$$anon$5.hasNext(OrderedRVD.scala:658); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$9$$anon$5.hasNext(OrderedRVD.scala:658); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at is.hail.sparkextras.OrderedRDD$$anonfun$apply$5$$anon$2.hasNext(OrderedRDD.scala:194); 	at,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2743:8074,Unsafe,UnsafeRow,8074,https://hail.is,https://github.com/hail-is/hail/issues/2743,1,['Unsafe'],['UnsafeRow']
Safety,Next time we make backwards incompatible changes we should avoid keying this table because it forces a sort now.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5128:59,avoid,avoid,59,https://hail.is,https://github.com/hail-is/hail/issues/5128,1,['avoid'],['avoid']
Safety,No detectable difference in performance:. ```; $ hail-bench compare /tmp/before.json /tmp/after2.json; Name Ratio Time 1 Time 2; ---- ----- ------ ------; matrix_table_decode_and_count 101.5% 4.216 4.278; ----------------------; Geometric mean: 101.5%; Simple mean: 101.5%; Median: 101.5%; ```,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7143:3,detect,detectable,3,https://hail.is,https://github.com/hail-is/hail/pull/7143,1,['detect'],['detectable']
Safety,"No one has complained about this yet, but I suspect there's a lurking issue in `linreg`. On line 75 of LinearRegression.scala, we create a writable region value using a context managed region. This region will be kept alive (in the garbage collection sense) by the context until the end of the Task (which I believe is the end of processing one partition). As such, `linreg` will generate a bunch of garbage. We close the child as soon as we know it is no longer used, thus saving memory use, at the cost of copying the results. In a future where we can reference-count regions then we could avoid the copy and simply return the writable region value. This future is not here yet.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3590:592,avoid,avoid,592,https://hail.is,https://github.com/hail-is/hail/pull/3590,1,['avoid'],['avoid']
Safety,"Notably:. * Add options for `gvcf_info_to_keep` and `gvcf_reference_entry_fields_to_keep` to control those parameters to `transform_gvcf`.; * Limit gvcf merge tasks to 150,000 partitions.; * Auto-detect `gvcf_reference_entry_fields_to_keep` if it is not provided. If any VDS argument is present, use the reference_data entry type, otherwise, compute it from the first gvcf.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10964:196,detect,detect,196,https://hail.is,https://github.com/hail-is/hail/pull/10964,1,['detect'],['detect']
Safety,"Note this PR replaces the previous [Feature/sas token merge](https://github.com/hail-is/hail/pull/12877) because the original PR branch got jacked up beyond repair. All the comments on the earlier PR are responded to there and addressed in the code for this one. This PR is to enable `hail-az/https` Azure file references to contain SAS tokens to enable bearer-auth style file access to Azure storage. Basic summary of the changes:; - Update `AzureAsyncFS` url parsing function to look for and separate out a SAS-token-like query string. Note: made fairly specific to SAS tokens - generic detection of query string syntax interferes with glob support and '?' characters in file names; - Added `generate_sas_token` convenience function to `AzureAsyncFS`. Adds new azure-mgmt-storage package requirement.; - Updated `AzureAsyncFS` to use `(account, container, credential)` tuple as internal `BlobServiceClient` cache key; - Updated `AzureAsyncFSURL` and `AzureFileListEntry` to track the token separately from the name, and extend the base classes to allow returning url with or without a token; - Update `RouterFS.ls` function and associated listfiles function to allow for trailing query strings during path traversal; - Update `AsyncFS.open_from` function to handle query-string urls in zero-length case; - Change to existing behavior: `LocalAsyncFSURL.__str__` no longer returns 'file:' prefix. Done to make `str()` output be appropriate for input to `fs` functions across all subclasses; - Updated `InputResource` to not include the SAS token as part of the destination file name; - Updated `inter_cloud/test_fs.py` to generically use query-string-friendly file path building functions to respect the new model, where it is no longer safe to extend URLs by just appending new segments with `+ ""/""` because there may be a query string, and added `'sas/azure-https'` test case to the fixture. Running tests for the SAS case requires some new test variables to allow the test code to generate SAS toke",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13140:589,detect,detection,589,https://hail.is,https://github.com/hail-is/hail/pull/13140,1,['detect'],['detection']
Safety,"Now that we are running with very small nodes, image-fetcher doesn't seem to provide all that much benefit. The intention is that caching through the memory service will ultimately prove better without having to run a daemonset. This also was running a whole daemon set for every PR namespace which meant a lot of our pods were redundant image-fetchers.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10272:328,redund,redundant,328,https://hail.is,https://github.com/hail-is/hail/pull/10272,1,['redund'],['redundant']
Safety,"Numerous times, I have sent REST credentials to a web endpoint. It is supremely annoying; to run around in circles wondering how your credentials got out of date. I think; this message is safe because the user really is a credentialed user, they just; used the wrong endpoint.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9131:188,safe,safe,188,https://hail.is,https://github.com/hail-is/hail/pull/9131,1,['safe'],['safe']
Safety,"OK, three issues:. 1. The TOKEN envvar needs to be defined.; 2. If statement indentation a bit confusing.; 3. Hail Batch in the default namespace rejects JAR URLs that are not under `$QUERY_STORAGE_URI/jars`, ergo we need to use QUERY_STORAGE_URI in the default namespace branch. The official JARs have a retention policy and are at the top level (rather than under a `/$(whoami)/`), so there is little risk of corrupting them.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12826:403,risk,risk,403,https://hail.is,https://github.com/hail-is/hail/pull/12826,1,['risk'],['risk']
Safety,"On views narrower than the height of the graph image + 100px, the slide box will overflow the adjacent install section. Fixed using inline style to avoid css caching issues until the build process is fixed.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8992:148,avoid,avoid,148,https://hail.is,https://github.com/hail-is/hail/pull/8992,1,['avoid'],['avoid']
Safety,"One more time, with feeling! (was: #10072). - [x] (@tpoterba) a1f3b2a5c9 add fails_service_backend; - [ ] (@tpoterba, @cseed) dc0bee7ce1 [hail] introduce and use mktemp and mktempd; - [ ] (@tpoterba) 4b663be367 [hail] make is.hail.expr.ir.functions threadsafe; - [ ] (@tpoterba) d3c1f0987c [hail] fix use of row requiredness in lowerDistributedSort; - [ ] (@catoverdrive) aab6ba98be [query-service] handle void-typed IRs in query-service; - [ ] (@catoverdrive) a1619cff36 [query-service] make user cache thread-safe; - [ ] (@tpoterba) c315fcb0b1 [query-service] bugfix: preserve globals through a shuffle; - [ ] (@catoverdrive) 912c21f709 [shuffler] log ShuffleCodecSpec anytime it is created; - [x] (@daniel-goldstein) c2495837e7 [scala-lsm] bugfix: least key may equal greatest key; - [x] (@daniel-goldstein) 5fb3db703e [services] discovered new transient error; - [x] (@daniel-goldstein) 9cd0999938 [shuffler] more assertions in ShuffleClient; - [x] (@daniel-goldstein) a71a3c9b8c [shuffler] bugfix: shuffler needs a HailContext to decode loci; - [x] (@daniel-goldstein) 41b06aeaa8 [query-service] move hail.jar earlier in Dockerfile; - [x] (@daniel-goldstein) 8df4029698 [query-service] permit pod scaling and remove cpu limit; - [ ] (@catoverdrive) 0354e1f557 [query-service] simplify socket handling; - [x] (@jigold) 6690a4decc [batch] teach JVMJob where to find the hail configuration files; - [x] (@daniel-goldstein) ae2e3d2996 [query-service] switch to services team approved logging; - [ ] (@tpoterba) b18f86e647 [query-service] query workers need a hail context; - [ ] (@daniel-goldstein, @catoverdrive) 6d5d0b68af [query-service] use a UNIX Domain Socket for Py-Scala communication; - [ ] (@daniel-goldstein, @catoverdrive) 0d42df8b08 [query-service] run tests against query service; - [x] (@jigold) f9d361e686 [query-service] aiohttp.ClientSession must be created in async code; - [ ] (@cseed) c35f2e10e3 [query-service][hail][build.yaml] address miscellaneous comments from cotton; - [x]",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10100:511,safe,safe,511,https://hail.is,https://github.com/hail-is/hail/pull/10100,1,['safe'],['safe']
Safety,"Originally #5355. Unfortunately, I had to squash commits to avoid bad rebasing conflicts, so I can't open the original PR.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5935:60,avoid,avoid,60,https://hail.is,https://github.com/hail-is/hail/pull/5935,1,['avoid'],['avoid']
Safety,"Our secret cache fails on ~1 in 10000 jobs. I observed this while running some; large scale tests which will soon become standard PR tests. In anticipation of this,; I fixed the k8s_cache. In particular, note how *everyone* who wins the lock tries to; remove it from the dictionary; however, only *one* task can do that successfully. The new code avoids locks entirely. It is a bit longer because I eagerly remove; out of date keys when I see them and use a future to notify all waiter simultaneouly. I also updated memory to use this cache for user credentials.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11040:347,avoid,avoids,347,https://hail.is,https://github.com/hail-is/hail/pull/11040,1,['avoid'],['avoids']
Safety,"PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI2NDVjMDg3ZS00NzIwLTRkZTgtYmI0NC00MWNkOTY0NTBmZjUiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjY0NWMwODdlLTQ3MjAtNGRlOC1iYjQ0LTQxY2Q5NjQ1MGZmNSJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/0ba777e1-bc27-41cc-aefa-0ed1a253829e?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/0ba777e1-bc27-41cc-aefa-0ed1a253829e?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""645c087e-4720-4de8-bb44-41cd96450ff5"",""prPublicId"":""645c087e-4720-4de8-bb44-41cd96450ff5"",""dependencies"":[{""name"":""aiohttp"",""from"":""3.8.6"",""to"":""3.9.2""}],""packageManager"":""pip"",""projectPublicId"":""0ba777e1-bc27-41cc-aefa-0ed1a253829e"",""projectUrl"":""https://app.snyk.io/org/danking/project/0ba777e1-bc27-41cc-aefa-0ed1a253829e?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-AIOHTTP-6209406"",""SNYK-PYTHON-AIOHTTP-6209407""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""pr-warning-shown"",""priorityScore""],""priorityScoreList"":[581,718],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Improper Limitation of a Pathname to a Restricted Directory (&#x27;Path Traversal&#x27;)](https://learn.snyk.io/lesson/directory-traversal/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14220:3803,remediat,remediationStrategy,3803,https://hail.is,https://github.com/hail-is/hail/pull/14220,1,['remediat'],['remediationStrategy']
Safety,"PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI3ZGRlNzcwZi0yMzMyLTQ5ZjktOWI1My05ZDY1OGJlOTVjMmQiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjdkZGU3NzBmLTIzMzItNDlmOS05YjUzLTlkNjU4YmU5NWMyZCJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/b72ce54d-5de3-48e5-a1d4-6f8967681a12?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/b72ce54d-5de3-48e5-a1d4-6f8967681a12?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""7dde770f-2332-49f9-9b53-9d658be95c2d"",""prPublicId"":""7dde770f-2332-49f9-9b53-9d658be95c2d"",""dependencies"":[{""name"":""aiohttp"",""from"":""3.8.6"",""to"":""3.9.2""}],""packageManager"":""pip"",""projectPublicId"":""b72ce54d-5de3-48e5-a1d4-6f8967681a12"",""projectUrl"":""https://app.snyk.io/org/danking/project/b72ce54d-5de3-48e5-a1d4-6f8967681a12?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-AIOHTTP-6209406"",""SNYK-PYTHON-AIOHTTP-6209407""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""pr-warning-shown"",""priorityScore""],""priorityScoreList"":[581,718],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Improper Limitation of a Pathname to a Restricted Directory (&#x27;Path Traversal&#x27;)](https://learn.snyk.io/lesson/directory-traversal/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14228:3751,remediat,remediationStrategy,3751,https://hail.is,https://github.com/hail-is/hail/pull/14228,1,['remediat'],['remediationStrategy']
Safety,"PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI5ZWNjYjQ0YS1jYWZiLTQ0OTgtYjU1NS02NDdmZjUwY2ExOTQiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjllY2NiNDRhLWNhZmItNDQ5OC1iNTU1LTY0N2ZmNTBjYTE5NCJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/fdd23464-9a67-49b8-8d9c-08502282c5fb?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/fdd23464-9a67-49b8-8d9c-08502282c5fb?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""9eccb44a-cafb-4498-b555-647ff50ca194"",""prPublicId"":""9eccb44a-cafb-4498-b555-647ff50ca194"",""dependencies"":[{""name"":""aiohttp"",""from"":""3.8.6"",""to"":""3.9.2""}],""packageManager"":""pip"",""projectPublicId"":""fdd23464-9a67-49b8-8d9c-08502282c5fb"",""projectUrl"":""https://app.snyk.io/org/danking/project/fdd23464-9a67-49b8-8d9c-08502282c5fb?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-AIOHTTP-6209406"",""SNYK-PYTHON-AIOHTTP-6209407""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""pr-warning-shown"",""priorityScore""],""priorityScoreList"":[581,718],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Improper Limitation of a Pathname to a Restricted Directory (&#x27;Path Traversal&#x27;)](https://learn.snyk.io/lesson/directory-traversal/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14225:3737,remediat,remediationStrategy,3737,https://hail.is,https://github.com/hail-is/hail/pull/14225,1,['remediat'],['remediationStrategy']
Safety,"PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJhZDFmMzFlYi1hYTcyLTQyMTYtOTgzNC01MDljMDdhOWFmNTMiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImFkMWYzMWViLWFhNzItNDIxNi05ODM0LTUwOWMwN2E5YWY1MyJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/fa47fca0-549b-41a3-8bf7-bcda4ca9a617?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/fa47fca0-549b-41a3-8bf7-bcda4ca9a617?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""ad1f31eb-aa72-4216-9834-509c07a9af53"",""prPublicId"":""ad1f31eb-aa72-4216-9834-509c07a9af53"",""dependencies"":[{""name"":""aiohttp"",""from"":""3.8.6"",""to"":""3.9.2""}],""packageManager"":""pip"",""projectPublicId"":""fa47fca0-549b-41a3-8bf7-bcda4ca9a617"",""projectUrl"":""https://app.snyk.io/org/danking/project/fa47fca0-549b-41a3-8bf7-bcda4ca9a617?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-AIOHTTP-6209406"",""SNYK-PYTHON-AIOHTTP-6209407""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""pr-warning-shown"",""priorityScore""],""priorityScoreList"":[581,718],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Improper Limitation of a Pathname to a Restricted Directory (&#x27;Path Traversal&#x27;)](https://learn.snyk.io/lesson/directory-traversal/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14227:3983,remediat,remediationStrategy,3983,https://hail.is,https://github.com/hail-is/hail/pull/14227,1,['remediat'],['remediationStrategy']
Safety,"PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJlMzQ0ZjYzNy00MjQwLTQxNmEtYjE2Yi1kODhmYjc2YTUwZmYiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImUzNDRmNjM3LTQyNDAtNDE2YS1iMTZiLWQ4OGZiNzZhNTBmZiJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/92d13c88-936f-40d3-b692-29e637c1a00c?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/92d13c88-936f-40d3-b692-29e637c1a00c?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""e344f637-4240-416a-b16b-d88fb76a50ff"",""prPublicId"":""e344f637-4240-416a-b16b-d88fb76a50ff"",""dependencies"":[{""name"":""aiohttp"",""from"":""3.8.6"",""to"":""3.9.2""}],""packageManager"":""pip"",""projectPublicId"":""92d13c88-936f-40d3-b692-29e637c1a00c"",""projectUrl"":""https://app.snyk.io/org/danking/project/92d13c88-936f-40d3-b692-29e637c1a00c?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-AIOHTTP-6209406"",""SNYK-PYTHON-AIOHTTP-6209407""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""pr-warning-shown"",""priorityScore""],""priorityScoreList"":[581,718],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Improper Limitation of a Pathname to a Restricted Directory (&#x27;Path Traversal&#x27;)](https://learn.snyk.io/lesson/directory-traversal/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14226:3728,remediat,remediationStrategy,3728,https://hail.is,https://github.com/hail-is/hail/pull/14226,1,['remediat'],['remediationStrategy']
Safety,PTypes 11: Remove unsafeInsert from Type,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4310:18,unsafe,unsafeInsert,18,https://hail.is,https://github.com/hail-is/hail/pull/4310,1,['unsafe'],['unsafeInsert']
Safety,PTypes 12: UnsafeRow and SafeRow take PTypes,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4312:11,Unsafe,UnsafeRow,11,https://hail.is,https://github.com/hail-is/hail/pull/4312,2,"['Safe', 'Unsafe']","['SafeRow', 'UnsafeRow']"
Safety,PTypes 6: Remove UnsafeOrdering from Type,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4278:17,Unsafe,UnsafeOrdering,17,https://hail.is,https://github.com/hail-is/hail/pull/4278,1,['Unsafe'],['UnsafeOrdering']
Safety,Pandas only releases [breaking changes in major versions](https://pandas.pydata.org/docs/development/policies.html). It seems safe; to be flexible on patch version. Just today I had an issue where I ran `pip install pandas` to; upgrade from an old pandas version and I landed on 1.1.5.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9819:126,safe,safe,126,https://hail.is,https://github.com/hail-is/hail/pull/9819,1,['safe'],['safe']
Safety,"Part of a refactoring effort. I need to break the model that a `TNDArray` is represented by an underlying `TStruct` and `TArray`. This adds an `UnsafeNDArray` Java representation, rather than the old model which was just to use`UnsafeRow` like it was a struct. . cc @tpoterba",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9854:144,Unsafe,UnsafeNDArray,144,https://hail.is,https://github.com/hail-is/hail/pull/9854,2,['Unsafe'],"['UnsafeNDArray', 'UnsafeRow']"
Safety,"Patrick -- can you give this a careful look over? Once we're happy with it, I'll redo the benchmarking as a last sanity check.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12629:113,sanity check,sanity check,113,https://hail.is,https://github.com/hail-is/hail/pull/12629,1,['sanity check'],['sanity check']
Safety,"Picking up where #13776 left off. CHANGELOG: improved speed of reading hail format datasets from disk. This PR speeds up decoding arrays in two main ways:; * instead of calling `arrayType.isElementDefined(array, i)` on every single array element, which expands to; ```scala; val b = aoff + lengthHeaderBytes + (i >> 3); !((Memory.loadByte(b) & (1 << (i & 7).toInt)) != 0); ```; process elements in groups of 64, and load the corresponding long of missing bits once; * once we have a whole long of missing bits, we can be smarter than branching on each bit. After flipping to get `presentBits`, we use the following psuedocode to extract the positions of the set bits, with time proportional to the number of set bits:; ```; while (presentBits != 0) {; val idx = java.lang.Long.numberOfTrailingZeroes(presentBits); // do something with idx; presentBits = presentBits & (presentBits - 1) // unsets the rightmost set bit; }; ```. To avoid needing to handle the last block of 64 elements differently, this PR changes the layout of `PCanonicalArray` to ensure the missing bits are always padded out to a multiple of 64 bits. They were already padded to a multiple of 32, and I don't expect this change to have much of an effect. But if needed, blocking by 32 elements instead had very similar performance in my benchmarks. I also experimented with unrolling loops. In the non-missing case, this is easy. In the missing case, I tried using `if (presentBits.bitCount >= 8)` to guard an unrolled inner loop. In both cases, unrolling was if anything slower. Dan observed benefit from unrolling, but that was combined with the first optimization above (not loading a bit from memory every element), which I beleive was the real source of improvement.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13787:930,avoid,avoid,930,https://hail.is,https://github.com/hail-is/hail/pull/13787,1,['avoid'],['avoid']
Safety,Please check whether you like the behavior I added where I raise a NotImplementedError if you try and use the local backend with `always_run` or `timeout`.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8258:146,timeout,timeout,146,https://hail.is,https://github.com/hail-is/hail/pull/8258,1,['timeout'],['timeout']
Safety,"Pool$.scoped(RegionPool.scala:17); 	at is.hail.backend.ExecuteContext$.scoped(ExecuteContext.scala:59); 	at is.hail.backend.spark.SparkBackend.withExecuteContext(SparkBackend.scala:339); 	at is.hail.backend.spark.SparkBackend.$anonfun$executeEncode$1(SparkBackend.scala:483); 	at is.hail.utils.ExecutionTimer$.time(ExecutionTimer.scala:52); 	at is.hail.backend.spark.SparkBackend.executeEncode(SparkBackend.scala:482); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:282); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:238); 	at java.lang.Thread.run(Thread.java:750). Hail version: 0.2.107-2387bb00ceee; Error summary: SparkException: Job aborted due to stage failure: Task 0 in stage 1.0 failed 4 times, most recent failure: Lost task 0.4 in stage 1.0 (TID 10) (all-of-us-1774-w-0.c.terra-vpc-sc-23dfb1a3.internal executor 7): ExecutorLostFailure (executor 7 exited caused by one of the running tasks) Reason: Container from a bad node: container_e01_1690206305672_0001_01_000007 on host: all-of-us-1774-w-0.c.terra-vpc-sc-23dfb1a3.internal. Exit status: 137. Diagnostics: [2023-07-24 13:52:49.515]Container killed on request. Exit code is 137; [2023-07-24 13:52:49.517]Container exited with a non-zero exit code 137. ; [2023-07-24 13:52:49.518]Killed by external signal; .; Driver stacktrace:; ```; [hail-20230724-1347-0.2.107-2387bb00ceee.log](https://github.com/hail-is/hail/files/12146671/hail-20230724-1347-0.2.107-2387bb00ceee.log)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13287:12228,abort,aborted,12228,https://hail.is,https://github.com/hail-is/hail/issues/13287,1,['abort'],['aborted']
Safety,Pytest sometimes uses a background thread to collect tests. That interacts badly; with asyncio. We avoid this by explicitly managing the event loop.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11933:99,avoid,avoid,99,https://hail.is,https://github.com/hail-is/hail/pull/11933,1,['avoid'],['avoid']
Safety,RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$25.apply(RDD.scala:820); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); 	at org.apache.spark.scheduler.Task.run(Task.scala:86); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.ap,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2743:4883,abort,abortStage,4883,https://hail.is,https://github.com/hail-is/hail/issues/2743,1,['abort'],['abortStage']
Safety,RDD.iterator(RDD.scala:283); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); at org.apache.spark.scheduler.Task.run(Task.scala:86); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1873); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1886); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1899); at org,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1275:4185,abort,abortStage,4185,https://hail.is,https://github.com/hail-is/hail/issues/1275,1,['abort'],['abortStage']
Safety,RDD.scala:287); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1658); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2022); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2043); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3040:7291,abort,abortStage,7291,https://hail.is,https://github.com/hail-is/hail/issues/3040,2,['abort'],['abortStage']
Safety,RR: https://github.com/hail-is/hail/issues/13261. Grouping asserts of distributed `BlockMatrix` queries via `BatchAssert` lead to repeated timeout failures during tests that used the batch-service backend.; This change removes all `BatchAssert`s from `test_linalg.py`. It uses `pytest.mark.parameterize` to gain parallelism in test execution from the test driver.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13348:139,timeout,timeout,139,https://hail.is,https://github.com/hail-is/hail/pull/13348,1,['timeout'],['timeout']
Safety,"Random hex strings, while valid, are a little dangerous to use as hostnames because some tools (Spark) could attempt to interpret an entirely numeric name as an IP address. This just avoids that danger entirely.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10679:183,avoid,avoids,183,https://hail.is,https://github.com/hail-is/hail/pull/10679,1,['avoid'],['avoids']
Safety,"Ready to look at. Assigning John because this code was related to NDArray. Purpose of this was to clean up the function a bit (some unnecessary assignments, code clarity), reduce the number of loops needed to detect a missing value. We don't need to check every bit O(N) to determine whether a value is missing. Instead, it is sufficient to check groups of at least 1 byte, and in the case that there are more than 64 values, groups of 8 bytes, or 1 byte. We could further improve this by removing the condition in the loop in favor of 2 loops (one over floor(nMissingBytes / 8), one over the remainder), but I think this gets us most of the benefit. We could also check for groups of 4 bytes (int) when groups of 8 bytes (long) are exhausted, but that doesn't really bring us much, since the major benefit comes from the largest batch group. I also factored out the checking function, because I will use this in upcasting.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7633:209,detect,detect,209,https://hail.is,https://github.com/hail-is/hail/pull/7633,1,['detect'],['detect']
Safety,"Ready to review once copy non-staged pr goes in. Left a few FIXME notes where signatures exist that rely entirely on region because of now-removed ptype regions. I elected to keep these as is to avoid complicating the review, but I think if we plan to keep such unused args around, we should document why. Related to: https://github.com/hail-is/hail/issues/7826",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7903:195,avoid,avoid,195,https://hail.is,https://github.com/hail-is/hail/pull/7903,1,['avoid'],['avoid']
Safety,"RecordV11(0/0:.:.:.:GP=1.0,0.0,0.0, 0/0:.:.:.:GP=1.0,0.0,0.0, 0/0:.:.:.:GP=1.0,0.0,0.0, 0/0:.:.:.:GP=1.0,0.0,0.0, 0/0:.:.:.:GP=1.0,0.0,0.0, 0/0:.:.:.:GP=1.0,0.0,0.0, 0/0:.:.:.:GP=1.0,0.0,0.0, 0/0:.:.:.:GP=1.0,0.0,0.0, 0/0:.:.:.:GP=1.0,0.0,0.0, 0/0:.:.:.:GP=1.0,0.0,0.0, 0/0:.:.:.:GP=1.0,0.0,0.0, 0/0:.:.:.:GP=1.0,0.0,0.0, 0/0:.:.:.:GP=1.0,0.0,0.0, 0/0:.:.:.:GP=1.0,0.0,0.0, 0/0:.:.:.:GP=0.99798583984375,0.00201416015625,0.0, 0/0:.:.:.:GP=1.0,0.0,0.0, 0/0:.:.:.:GP=1.0,0.0,0.0, 0/0:.:.:.:GP=1.0,0.0,0.0, 0/0:.:.:.:GP=1.0,0.0,0.0,. goes on for a while. field (class: scala.Tuple2, name: _2, type: class java.lang.Object); 	- object (class scala.Tuple2, ([rs149841286:10000179:AAAAAAAC:A,---],BgenRecordV11(0/0:.:.:.:GP=1.0,0.0,0.0, 0/0:.:.:.:GP=1.0,0.0,0.0,. keeps on going like above until remaining stack trace:. at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGSche",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2527:1718,abort,abortStage,1718,https://hail.is,https://github.com/hail-is/hail/issues/2527,1,['abort'],['abortStage']
Safety,"Records in the job_group_inst_coll_cancellable_resources table are dead once a; job group completes. We already compact records when a job group is cancelled. ; We are yet to do this for finished job groups. See the linked issue for a more ; detailed motivation. This change adds two background tasks:; 1. finds uncompacted groups of records for finished job groups and; compacts them by summing across the token field.; 2. finds compacted records for finished job groups and deletes them if; all associated resources are 0. The results of both tasks converge to a fixed point where the only remaining; records are for those jobs groups that are unfinished, cancelled or have; resources outstanding. I've taken care to optimise the underlying SQL queries as best as I can. Both; make heavy use of lateral joins to avoid explodes - the natural implementation; of both are prohibitively expensive. I've tested these tasks in a dev deploy where I created a number of batches and; observed that records from this table have indeed been compacted and destroyed; on completion. It's not immediately obvious to me how to automate testing for ; these. AFAICT, we lack any automated integration testing for these background ; tasks. Resolves: #14623",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14645:814,avoid,avoid,814,https://hail.is,https://github.com/hail-is/hail/pull/14645,1,['avoid'],['avoid']
Safety,"Refactors `Bindings` to return an object encoding the change to the environment (any new bindings, whether the agg/scan env is promoted, etc). This allows the deletion of `SegregatedBindingEnv`. Follow up work will use this to replace the other specializations of `GenericBindingEnv`, and to greatly simplify compiler passes, such as `NormalizeNames` and `PruneDeadFields`, which currently need to redundantly encode the binding structure of every node.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14496:398,redund,redundantly,398,https://hail.is,https://github.com/hail-is/hail/pull/14496,1,['redund'],['redundantly']
Safety,"Remaining is that found in Etypes, in the _buildSkip function. This is slightly tricky, because there is a place in the code where there is no corresponding PType, and the solution to fix that is a bit involved, or if straightforward, beyond my current understanding of ETypes. I made an issue here: https://github.com/hail-is/hail/issues/7701. Stacked on https://github.com/hail-is/hail/pull/7687. edit: I removed the ETypes issue, by creating a packBitsToBytes function on UnsafeUtils. We may not want this change however, because I think array packing may needs to be the same as the array implementation (I think readBytes fills the allocated memory with the InputBuffer's encoded missingness data, which needs same number of bytes as what is encoded), in which case that coupling becomes less clear if the utility function is on UnsafeUtils. I could move it back to PContainer, or may _buildSkip take a ptype. . There are other places where (n + 7) >>> 3 are used, so this seems pretty general, hence UnsafeUtils (where we have some other bitwise ops, happy to move elsewhere). PTuple is one.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7702:475,Unsafe,UnsafeUtils,475,https://hail.is,https://github.com/hail-is/hail/pull/7702,3,['Unsafe'],['UnsafeUtils']
Safety,"Remove the `Begin` node, as its behavior can now be represented by the `Let` node. Besides removing redundant nodes, this will also make the new ssa-style text representation simpler. The `Begin` node emmitter performed method splitting, emitting groups of 16 children in seperate methods. This preserves that behavior by doing a similar optimization in the `Let` emitter. This is a significant change in how we split generated code into methods, so we should watch out for how this affects things.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14068:100,redund,redundant,100,https://hail.is,https://github.com/hail-is/hail/pull/14068,1,['redund'],['redundant']
Safety,Removed an internal use of cond to avoid deprecation warnings,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9813:35,avoid,avoid,35,https://hail.is,https://github.com/hail-is/hail/pull/9813,1,['avoid'],['avoid']
Safety,Renamed agg->aggArgs in Interpret to avoid name collision.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6698:37,avoid,avoid,37,https://hail.is,https://github.com/hail-is/hail/pull/6698,1,['avoid'],['avoid']
Safety,Renamed type module to avoid clash with python builtin,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1625:23,avoid,avoid,23,https://hail.is,https://github.com/hail-is/hail/pull/1625,1,['avoid'],['avoid']
Safety,Reopening. Needed by https://github.com/hail-is/hail/pull/2097. Will address performance once Row is gone and we're full unsafe.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2098:121,unsafe,unsafe,121,https://hail.is,https://github.com/hail-is/hail/pull/2098,1,['unsafe'],['unsafe']
Safety,Reorganize & Code-ify UnsafeOrdering,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2519:22,Unsafe,UnsafeOrdering,22,https://hail.is,https://github.com/hail-is/hail/pull/2519,1,['Unsafe'],['UnsafeOrdering']
Safety,Replacement for #12120. Stacked on #12117. . The `foreign_key_checks=0` is necessary in order to avoid locking the entire table while copying the whole thing.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12193:97,avoid,avoid,97,https://hail.is,https://github.com/hail-is/hail/pull/12193,1,['avoid'],['avoid']
Safety,"Replaces https://github.com/hail-is/hail/pull/13260. - `test_spectral_moments` times out in a PR: (QoB) https://hail.zulipchat.com/#narrow/stream/127527-team/topic/timeouts/near/376698259, (spark) https://ci.hail.is/batches/7653376/jobs/74, (spark) https://ci.hail.is/batches/7653376/jobs/72, (spark) https://ci.hail.is/batches/7653376/jobs/62. I also backed local off to 4m even though it has no evidence of time outs. Seems simpler for Spark and local to be the same.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13278:164,timeout,timeouts,164,https://hail.is,https://github.com/hail-is/hail/pull/13278,1,['timeout'],['timeouts']
Safety,"Replicable bug:. ```; hail -b 0 importvcf src/test/resources/multipleChromosomes.vcf -n 10 exportvcf -o /tmp/out.vcf.bgz importvcf /tmp/out.vcf.bgz -n 10 count --genotypes. hail: count: caught exception: Job aborted due to stage failure: Task 4 in stage 0.0 failed 1 times, most recent failure: Lost task 4.0 in stage 0.0 (TID 4, localhost): htsjdk.samtools.SAMFormatException: Invalid GZIP header; at htsjdk.samtools.util.BlockGunzipper.unzipBlock(BlockGunzipper.java:72); at htsjdk.samtools.util.BlockCompressedInputStream.inflateBlock(BlockCompressedInputStream.java:410); at htsjdk.samtools.util.BlockCompressedInputStream.readBlock(BlockCompressedInputStream.java:392); at htsjdk.samtools.util.BlockCompressedInputStream.available(BlockCompressedInputStream.java:127); at org.seqdoop.hadoop_bam.util.BGZFSplitCompressionInputStream.readWithinBlock(BGZFSplitCompressionInputStream.java:81); at org.seqdoop.hadoop_bam.util.BGZFSplitCompressionInputStream.read(BGZFSplitCompressionInputStream.java:48); at java.io.InputStream.read(InputStream.java:101); at org.apache.hadoop.mapreduce.lib.input.CompressedSplitLineReader.fillBuffer(CompressedSplitLineReader.java:130); at org.apache.hadoop.util.LineReader.readDefaultLine(LineReader.java:216); at org.apache.hadoop.util.LineReader.readLine(LineReader.java:174); at org.apache.hadoop.mapreduce.lib.input.CompressedSplitLineReader.readLine(CompressedSplitLineReader.java:159); at org.apache.hadoop.mapred.LineRecordReader.<init>(LineRecordReader.java:134); at org.apache.hadoop.mapred.TextInputFormat.getRecordReader(TextInputFormat.java:67); at org.apache.spark.rdd.HadoopRDD$$anon$1.<init>(HadoopRDD.scala:239); at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:216); at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:101); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:297); at org.apache.spark.rdd.RDD.iterator(RDD.scala:264); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apac",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/566:208,abort,aborted,208,https://hail.is,https://github.com/hail-is/hail/issues/566,1,['abort'],['aborted']
Safety,"Replicable with the following:. ```; ds = hc.read('gs://future-variant-calling/future-pipeline/future.vds'); ds.filter_rows(ds.v.num_alleles() == 2).count_rows(); ```. ```; Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 66 in stage 2.0 failed 20 times, most recent failure: Lost task 66.19 in stage 2.0 (TID 2061, tim-debug-sw-h2hs.c.broad-ctsa.internal): java.lang.AssertionError: assertion failed; 	at scala.Predef$.assert(Predef.scala:156); 	at is.hail.annotations.Region.loadInt(Region.scala:36); 	at is.hail.expr.types.TBinary$.loadLength(TBinary.scala:62); 	at is.hail.annotations.UnsafeRow$.readBinary(UnsafeRow.scala:128); 	at is.hail.annotations.UnsafeRow$.readString(UnsafeRow.scala:139); 	at is.hail.annotations.UnsafeRow$.readAltAllele(UnsafeRow.scala:152); 	at is.hail.annotations.UnsafeRow$.readArrayAltAllele(UnsafeRow.scala:164); 	at is.hail.annotations.UnsafeRow$.read(UnsafeRow.scala:210); 	at is.hail.annotations.UnsafeRow.get(UnsafeRow.scala:257); 	at is.hail.expr.FilterVariants$$anonfun$10.apply(Relational.scala:428); 	at is.hail.expr.FilterVariants$$anonfun$10.apply(Relational.scala:425); 	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:463); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$9$$anon$5.hasNext(OrderedRVD.scala:694); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$9$$anon$5.hasNext(OrderedRVD.scala:694); 	at scala.collection.Iterator$class.foreach(Iterator.scala:893); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$9$$anon$5.foreach(OrderedRVD.scala:691); 	at is.hail.methods.SampleQC$$anonfun$results$1.apply(SampleQC.scala:170); 	at is.hail.methods.SampleQC$$anonfun$results$1.apply(SampleQC.scala:166); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:785); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:785); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPa",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2803:229,abort,aborted,229,https://hail.is,https://github.com/hail-is/hail/issues/2803,13,"['Unsafe', 'abort']","['UnsafeRow', 'aborted']"
Safety,Revert 8970 and Prevent Unsafe.copyMemory from being called with length 0,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9134:24,Unsafe,Unsafe,24,https://hail.is,https://github.com/hail-is/hail/pull/9134,1,['Unsafe'],['Unsafe']
Safety,Rewrite the staged aggregator interface to:; - allow primitive values in aggregator without associated region; - create Scala Region instance once and reuse by setting different underlying native Region object to avoid overhead of object creation. Also includes some interface changes to AggregatorState (formerly RVAState) to clean up the region dependencies.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6652:213,avoid,avoid,213,https://hail.is,https://github.com/hail-is/hail/pull/6652,1,['avoid'],['avoid']
Safety,"Right now, if we accidentally make a wheel too big, it breaks our deploy. Let's avoid this by checking that we never let wheel get too big.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11592:80,avoid,avoid,80,https://hail.is,https://github.com/hail-is/hail/pull/11592,1,['avoid'],['avoid']
Safety,"Rs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI1NDBhNTVlYS05Y2JkLTRlZWEtYmJmZi00ZWU2NjlhZWJmYWQiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjU0MGE1NWVhLTljYmQtNGVlYS1iYmZmLTRlZTY2OWFlYmZhZCJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/fa47fca0-549b-41a3-8bf7-bcda4ca9a617?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/fa47fca0-549b-41a3-8bf7-bcda4ca9a617?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""540a55ea-9cbd-4eea-bbff-4ee669aebfad"",""prPublicId"":""540a55ea-9cbd-4eea-bbff-4ee669aebfad"",""dependencies"":[{""name"":""jupyter-server"",""from"":""1.24.0"",""to"":""2.7.2""},{""name"":""setuptools"",""from"":""39.0.1"",""to"":""65.5.1""}],""packageManager"":""pip"",""projectPublicId"":""fa47fca0-549b-41a3-8bf7-bcda4ca9a617"",""projectUrl"":""https://app.snyk.io/org/danking/project/fa47fca0-549b-41a3-8bf7-bcda4ca9a617?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-JUPYTERSERVER-5862881"",""SNYK-PYTHON-JUPYTERSERVER-5862882"",""SNYK-PYTHON-SETUPTOOLS-3180412""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""pr-warning-shown""],""priorityScoreList"":[null,null,509],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Access Control Bypass](https://learn.snyk.io/lesson/broken-access-control/?loc&#x3D;fix-pr); 🦉 [Open Redirect](https://learn.snyk.io/lesson/open-redirect/?loc&#x3D;fix-pr); 🦉 [Regular Expression Denial of Service (ReDoS)](https://learn.snyk.io/lesson/redos/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13516:3979,remediat,remediationStrategy,3979,https://hail.is,https://github.com/hail-is/hail/pull/13516,1,['remediat'],['remediationStrategy']
Safety,"Rs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJhZWIyYjAwNS1lYjhhLTRiMzgtYjkwMS04YzRmNTY2OGM3ZDYiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImFlYjJiMDA1LWViOGEtNGIzOC1iOTAxLThjNGY1NjY4YzdkNiJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""aeb2b005-eb8a-4b38-b901-8c4f5668c7d6"",""prPublicId"":""aeb2b005-eb8a-4b38-b901-8c4f5668c7d6"",""dependencies"":[{""name"":""jupyter-server"",""from"":""1.24.0"",""to"":""2.7.2""},{""name"":""setuptools"",""from"":""39.0.1"",""to"":""65.5.1""}],""packageManager"":""pip"",""projectPublicId"":""20159ae6-a5aa-42fa-845a-c89f5bcbf999"",""projectUrl"":""https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-JUPYTERSERVER-5862881"",""SNYK-PYTHON-JUPYTERSERVER-5862882"",""SNYK-PYTHON-SETUPTOOLS-3180412""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""pr-warning-shown""],""priorityScoreList"":[null,null,509],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Access Control Bypass](https://learn.snyk.io/lesson/broken-access-control/?loc&#x3D;fix-pr); 🦉 [Open Redirect](https://learn.snyk.io/lesson/open-redirect/?loc&#x3D;fix-pr); 🦉 [Regular Expression Denial of Service (ReDoS)](https://learn.snyk.io/lesson/redos/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13517:3803,remediat,remediationStrategy,3803,https://hail.is,https://github.com/hail-is/hail/pull/13517,1,['remediat'],['remediationStrategy']
Safety,Ruchi and Sam need this functionality to avoid an unnecessary scan.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8706:41,avoid,avoid,41,https://hail.is,https://github.com/hail-is/hail/pull/8706,1,['avoid'],['avoid']
Safety,"Safe, On-Heap Annotations",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3353:0,Safe,Safe,0,https://hail.is,https://github.com/hail-is/hail/pull/3353,1,['Safe'],['Safe']
Safety,Safer language in Getting Started about Spark version.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1262:0,Safe,Safer,0,https://hail.is,https://github.com/hail-is/hail/pull/1262,1,['Safe'],['Safer']
Safety,Safer scans,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3921:0,Safe,Safer,0,https://hail.is,https://github.com/hail-is/hail/pull/3921,1,['Safe'],['Safer']
Safety,"Scala calls functions that match on the type to avoid boxing. This is; slightly better than allocating, but so much worse than plain array; operations. Benchmarks forthcoming.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9884:48,avoid,avoid,48,https://hail.is,https://github.com/hail-is/hail/pull/9884,1,['avoid'],['avoid']
Safety,"Security Impact: No exploits possible, but this does make us look slightly better, and removes a small risk of incorrect component re-use in the future.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14669:103,risk,risk,103,https://hail.is,https://github.com/hail-is/hail/pull/14669,1,['risk'],['risk']
Safety,See attached log. Error not clear:. `[Stage 0:==========> (596 + 168) / 2836]hail: write: caught exception: Job aborted.`. [hail.log.txt](https://github.com/broadinstitute/hail/files/269500/hail.log.txt),MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/391:112,abort,aborted,112,https://hail.is,https://github.com/hail-is/hail/issues/391,1,['abort'],['aborted']
Safety,"See for example, this PR test https://storage.googleapis.com/hail-ci-0-1/ci/28153fd91e1ab73e64144620ade2d1ca271f4d5a/8074a6697bbeb0dc0c4d71b27d8313ff83d2398e/job.log . I believe this is causing https://github.com/hail-is/hail/issues/5519. If you look carefully at that log, you'll see that read_timeout in `connectionpool.py` is 5. It is set by:. ```; read_timeout = timeout_obj.read_timeout; ```. timeout_obj, *should* be created by requests with the same timeout value for read and connect which I am confident (see api.py) is set to 60. Somebody somewhere in this (honestly very confusing) pile of calls is erasing our setting. I am worried there's something that modifies the timeout to have `total = True` which means it subtracts the time spent connecting from the read timeout.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5566:457,timeout,timeout,457,https://hail.is,https://github.com/hail-is/hail/issues/5566,3,['timeout'],['timeout']
Safety,"Seen in Azure:. ```; aiodocker.exceptions.DockerError: DockerError(500, 'Get \""https://mcr.microsoft.com/v2/azure-cli/manifests/sha256:068eaecb7abab2d5195a05a6c144c71e9ba1c532efc2912b3ea290d98fbeadb2\"": dial tcp 131.253.33.219:443: i/o timeout'); ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11488:236,timeout,timeout,236,https://hail.is,https://github.com/hail-is/hail/pull/11488,1,['timeout'],['timeout']
Safety,"Simply enables CORS from all domains. This would be insecure, but our endpoints are read-only operations on public GitHub resources, against a fixed list of users, there is no database to inject, and there are no cookies or local storage entries to steal. I think it's safe enough for the time being, but open to suggestions. Also expose /json endpoint to return all index.html data without rendering a page.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4945:269,safe,safe,269,https://hail.is,https://github.com/hail-is/hail/pull/4945,2,['safe'],['safe']
Safety,"Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""92bcf51f-c710-4a85-9af1-5ae170a8797a"",""prPublicId"":""92bcf51f-c710-4a85-9af1-5ae170a8797a"",""dependencies"":[{""name"":""certifi"",""from"":""2021.10.8"",""to"":""2023.7.22""},{""name"":""cryptography"",""from"":""3.3.2"",""to"":""41.0.5""},{""name"":""requests"",""from"":""2.27.1"",""to"":""2.31.0""}],""packageManager"":""pip"",""projectPublicId"":""c1c98f6a-57c6-4ecc-a329-3b744cab74bd"",""projectUrl"":""https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-CERTIFI-3164749"",""SNYK-PYTHON-CERTIFI-5805047"",""SNYK-PYTHON-CRYPTOGRAPHY-3172287"",""SNYK-PYTHON-CRYPTOGRAPHY-3314966"",""SNYK-PYTHON-CRYPTOGRAPHY-3315324"",""SNYK-PYTHON-CRYPTOGRAPHY-3315328"",""SNYK-PYTHON-CRYPTOGRAPHY-3315331"",""SNYK-PYTHON-CRYPTOGRAPHY-3315452"",""SNYK-PYTHON-CRYPTOGRAPHY-3315972"",""SNYK-PYTHON-CRYPTOGRAPHY-3315975"",""SNYK-PYTHON-CRYPTOGRAPHY-3316038"",""SNYK-PYTHON-CRYPTOGRAPHY-3316211"",""SNYK-PYTHON-CRYPTOGRAPHY-5663682"",""SNYK-PYTHON-CRYPTOGRAPHY-5777683"",""SNYK-PYTHON-CRYPTOGRAPHY-5813745"",""SNYK-PYTHON-CRYPTOGRAPHY-5813746"",""SNYK-PYTHON-CRYPTOGRAPHY-5813750"",""SNYK-PYTHON-CRYPTOGRAPHY-5914629"",""SNYK-PYTHON-CRYPTOGRAPHY-6036192"",""SNYK-PYTHON-REQUESTS-5595532""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""pr-warning-shown""],""priorityScoreList"":[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Use After Free](https://learn.snyk.io/lesson/use-after-free/?loc&#x3D;fix-pr); 🦉 [Access of Resource Using Incompatible Type (&#x27;Type Confusion&#x27;)](https://learn.snyk.io/lesson/type-confusion/?loc&#x3D;fix-pr); 🦉 [Denial of Service (DoS)](https://learn.snyk.io/lesson/redos/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13938:10029,remediat,remediationStrategy,10029,https://hail.is,https://github.com/hail-is/hail/pull/13938,1,['remediat'],['remediationStrategy']
Safety,"So I did:. hail-new-vep importvcf /user/satterst/DILI/DILI_controls.vcf.bgz repartition -n 100 splitmulti vep --config /psych/genetics_data/working/cseed/vep.properties write -o /user/satterst/DILI/DILI_split_vep.vds . It almost immediately advanced to the write, then it sat there having tasks fail for two hours, then it said:; [Stage 1:> (0 + 35) / 100]; hail: write: caught exception: org.apache.spark.SparkException: Job aborted. log here: /humgen/atgu1/fs03/satterst/hail.jobaborted.log",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/302:426,abort,aborted,426,https://hail.is,https://github.com/hail-is/hail/issues/302,1,['abort'],['aborted']
Safety,"So I'm of two minds here, and I don't quite know which to choose. Imagine we make an internal (service to service) request. It fails with a transient error like a timeout. What do we do?. Option 1. Retry. Option 2. Return a transient error 503 service unavailable to our client, and let them to decide what to do. I've implemented both options here: request_{retry, raise}_transient_errors. Which should I use in, for example, the auth decorators which hit the auth/userinfo endpoint?. I've chosen option 1 after bouncing back and forth a few times. I feel like retrying will give a better experience in the common case (a real transient error) and both will recover eventually in the case of a real outage. It appears that browsers don't retry 503 even with Retry-After header set. I'd want it to retry immediately or after a very short delay (1s). In the end, this is what convinced me we should retry. Currently CI uses option 1 when calling batch because it is hardcoded into the batch client. The signature of these functions match aiohttp.ClientSession.request. @danking I'm compelled by your concern that we have a potentially infinite loop of failures nobody will be notified about. I will follow up with another PR to add some logging to the request_retry function. Finally, I'm not quite sure why we're getting so many transient errors. I suspect some of it is gaps in k8s service handoffs, but I'm not sure.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7284:163,timeout,timeout,163,https://hail.is,https://github.com/hail-is/hail/pull/7284,2,"['recover', 'timeout']","['recover', 'timeout']"
Safety,"Some context: To make Batch feature additions safer, we now have infrastructure to turn off new components with checkboxes on the driver page. I forgot to add the text before the checkbox when I put it in last week.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13288:46,safe,safer,46,https://hail.is,https://github.com/hail-is/hail/pull/13288,1,['safe'],['safer']
Safety,"Sorry missed this in the initial PR. `os.environ` is global to the whole python session so setting it directly could inadvertently affect the environment for unrelated tests. There seems to be safe ways to do this using `monkeypatch` and whatever `CliRunner` is doing, but I decided just not to set it.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13457:193,safe,safe,193,https://hail.is,https://github.com/hail-is/hail/pull/13457,1,['safe'],['safe']
Safety,"Spark 3.3.0 uses log4j2. Note the ""2"". If you use the log4j1 programmatic reconfiguration system, you will break log4j2 for you and everyone else. The only way to recover from such a breakage is to use the log4j2 programmatic reconfiguration system. Changes in this PR:. 1. Include JVM output in error logs when the JVM crashes. This should help debugging of JVM crashing in production until the JVM logs are shown on a per-worker page. 2. JVMEntryway is now a real gradle project. I need to compile against log4j, and I didn't want to do that by hand with `javac`. Ignore gradlew, gradlew.bat, and gradle/wrapper, they're programmatically generated by gradle. 3. Add logging to JVMEntryway. JVMEntryway now logs its arguments into the QoB job log. I also log exceptions from the main thread or the cancel thread into the job log. We also flush the logs after the main thread completes, the cancel thread completes, and when the try-catch exits. This should ensure that regardless of what goes wrong (even if both threads fail to start) we at least see the arguments that the JVMEntryway received. 4. Use log4j2 programmatic reconfiguration after every job. This restores log4j2 to well enough working order that, *if you do not try to reconfigure it using log4j1 programmatic configuration*, logs will work. All old versions of Hail use log4j1 programmatic configuration. As a result, **all old versions of Hail will still have no logs**. However, new versions of Hail will log correctly even if an old version of Hail used the JVM before it. 5. `QoBAppender`. This is how we always should have done logging. A custom appender which we can flush and then redirect to a new file at our whim. I followed the log4j2 best practices for creating a new appender. All these annotations, factory methods, and managers are The Right Way, for better or worse. If we ever ban old versions of Hail from the cluster, then we can also eliminate the log4j2 reconfiguration. New versions of Hail work fine without an",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12941:163,recover,recover,163,https://hail.is,https://github.com/hail-is/hail/pull/12941,1,['recover'],['recover']
Safety,Spark executor heartbeat timeout during hl.king(),MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12290:25,timeout,timeout,25,https://hail.is,https://github.com/hail-is/hail/issues/12290,1,['timeout'],['timeout']
Safety,"Spicy meatball for you, @tpoterba. I hope I didn't step on your feet too much. read{_table} and write now read and write rows, stolen and tweaked up from tpoterba/unsafe-rowstore-2. (Nice work!) Parquet is gone. Not having to scan all the partitions feels so nice, and I'm just working on tiny examples on my laptop. Added RegionValueBuilder which is useful for ... building region-based values (values allocated in a MemoryBuffer). `import_vcf` uses it to produces `RegionValues`/`UnsafeRow`. I left in `UnsafeRowBuilder`, but it is not being used (except by the tests). We should port over the region => region optimization, and remove it. I feel like this could be used to write our own non-consing Parquet importer easily (that supports nested fields!) Also, our own VCF parser is now trivial to drop in, esp. for genotypes. Added UnsafeIndexedSeqAnnotation and pulling native complex types out of unsafe rows. Cleaned up read/writing VDS/KT metadata files. Got rid of `RowGenotype`, wrote `buildGenotypeExtractor` to be much better. I handled the serialization issue a slightly different way. See `BroadcastTypeTree`. Including your Kryo optimizations from unsafe-rowstore-2 would be good, too. It is still not as fast as 0.1, but generic and getting closer. This change has a lot of upside. Making things mutable now is trivial (just remove to `region.copy()` in `LoadVCF`, `ReadRowsRDD`, etc.) Tests spend a lot of time in methods that should eventually go away (e.g. `UnsafeRow.read`). The main problem is that the rowstore with naive encodings is about 4x larger (compressed) than the corresponding 0.1 VDS (profile225, 2.0GB => 7.8GB) and a huge amount of time is spent in LZ4 compression. I have a plan for this.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2074:163,unsafe,unsafe-rowstore-,163,https://hail.is,https://github.com/hail-is/hail/pull/2074,7,"['Unsafe', 'unsafe']","['UnsafeIndexedSeqAnnotation', 'UnsafeRow', 'UnsafeRowBuilder', 'unsafe', 'unsafe-rowstore-']"
Safety,Split the Hail query backends into separate file. One goal here is to have spark_backend.py the only file that imports pyspark. Also: Added init_service(). init() is for initialising with the Spark backend. init_service() is for initialising with the service backend. Don't import the backends unelss they are used. This will allow us to avoid importing pyspark (or even having it installed) when using the service backend.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8656:338,avoid,avoid,338,https://hail.is,https://github.com/hail-is/hail/pull/8656,1,['avoid'],['avoid']
Safety,"Stacked on #11240. Rewrite all `SSettable.store` implementations to take an `SValue`. With that, `SCode` and subclasses are safe to delete.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11241:124,safe,safe,124,https://hail.is,https://github.com/hail-is/hail/pull/11241,1,['safe'],['safe']
Safety,"Stacked on #11995 . This PR creates all of the new `aggregated_*_resources_by_date` tables that will be used for real time billing and making our billing queries fast and also populates them! It will probably run for ~7-8 hours (online migration) and add an estimated 200 GB to the database. It will take around 5-6 hours to populate the tables and the remainder of the time is doing an audit. I think we should whiteboard what is going on in person, but the general idea is as follows:; 1. Revert any previous work and set the trigger back to the original state (idempotent); 2. Find the latest complete or open batch id. We know that a complete batch will not have updates to the attempts table. This is extremely important because the next steps can be done in parallel rather than serially.; 3. Find offsets for complete batches up to the batch id from Step 1 in groups of 100 attempts; 4. Randomize the offsets and have a burn in period of 5000 to avoid the birthday problem where we populate the `aggregated_*_resources_by_date` tables.; 5. In 10-way parallelism (maxes out a 4 core database), randomly populate the tables for each chunk.; 6. From the last offset (original first running batch id), we sequentially process attempts in groups of 100. We take note of where we are at with tracking any updates to the attempts table (`attempts_time_msecs_diff`), populate the `aggregated_*_resources_by_date` tables, and then do a final catchup step where we apply any updates from `attempts_time_msecs_diff` for any attempts that we have already processed.; 7. Once we have reached the ""end"" of the attempts table, we lock all tables of interest especially the `attempts` table, and do one last final processing step before we add the new triggers that will auto-populate the `aggregated_*_resources_by_date` tables.; 8. Then we perform an audit and make sure things look correct. (I might need to change or eliminate the billing_project audit query because there are 5 batches with ~20 jobs that ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11996:953,avoid,avoid,953,https://hail.is,https://github.com/hail-is/hail/pull/11996,1,['avoid'],['avoid']
Safety,"Stacked on #12757. - This PR gets the ranges of existing rows from the attempt_resources, aggregated_*_resources_v2 tables in bunches of 100 and then migrates each bunch by triggering an after update trigger for those rows that haven't been migrated. The triggers were added in #12757. ; - There's an audit at the end to make sure the new v3 tables give the same answer as the old v2 tables with duplicate resources.; - We use the same trick with a burn-in period to avoid the birthday problem with deadlocks.; - I added a function that generates the where statements programmatically based on looking at the where statement from previous migrations where we wrote out the where statement by hand. I think this way is less error-prone than writing out the where statement for each table, but it might be harder to reason about. Let me know if this way is too confusing.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12761:467,avoid,avoid,467,https://hail.is,https://github.com/hail-is/hail/pull/12761,1,['avoid'],['avoid']
Safety,"Stacked on #13475. This PR renames the following tables to have job groups in the name instead of batches. Note that this PR needs to shutdown the batch deployment (offline migration). I'm not 100% sure this is necessary, but I want to avoid a case where MJC of the database migration job cannot happen thus deadlocking the system. ```sql; RENAME TABLE batch_attributes TO job_group_attributes,; batches_cancelled TO job_groups_cancelled,; batches_inst_coll_staging TO job_groups_inst_coll_staging, ; batch_inst_coll_cancellable_resources TO job_group_inst_coll_cancellable_resources, ; aggregated_batch_resources_v2 TO aggregated_job_group_resources_v2,; aggregated_batch_resources_v3 TO aggregated_job_group_resources_v3, ; batches_n_jobs_in_complete_states TO job_groups_n_jobs_in_complete_states;; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13810:236,avoid,avoid,236,https://hail.is,https://github.com/hail-is/hail/pull/13810,1,['avoid'],['avoid']
Safety,"Stacked on #9220. The region parameter to emit ostensibly means ""construct the value in this region"". But in many places `StagedRegionValueBuilder`s are constructed with the default region, which is the argument to the method being emitted into. This PR fixes all the uses in the emitter to build values in the right region. Most of the remaining users of the constructor with the default region are in tests, so I thought it safest to remove those constructors, and require explicitly passing the region to build into. Otherwise it's too easy to create memory leaks.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9181:426,safe,safest,426,https://hail.is,https://github.com/hail-is/hail/pull/9181,1,['safe'],['safest']
Safety,"Stacked on: https://github.com/hail-is/hail/pull/5414. UnsafeSuite.testCodec verifies this aggressively. I also turned the up the test count massively in hand testing and everything looks good. This should give a modest speed boost to writes, shuffles, anything that uses the encoder generally. Next up is staging the result from RegionValueAggregators.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5417:55,Unsafe,UnsafeSuite,55,https://hail.is,https://github.com/hail-is/hail/pull/5417,1,['Unsafe'],['UnsafeSuite']
Safety,"Stacked on: https://github.com/hail-is/hail/pull/5507. Drops one broadcast from my test dataset from 1.4MB => 300KB (5x). I think that corresponds to the parallelize for writeSplitSpecs, which is now constant (won't scale according to the number of inputs). The RDD actually doing the writing, the OriginUnionRDD, still scales linearly. I think that's inevitable unless we do the LightweightContextRVDDistributedArray thing I mentioned on Zulip since we necessarily allocate at least one RDD per input. It might still be possible to push the constants down. The point of this change is to avoid capturing the OriginUnionRDD partitions inside the map step. I did this essentially by turning OriginUnionRDD into a union with ""mapPartitionsWithOriginIndex"". I think it might be wroth trying to re-run it after this goes in. Between this one and the last one, there are some pretty big memory/broadcast savings here.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5509:589,avoid,avoid,589,https://hail.is,https://github.com/hail-is/hail/pull/5509,1,['avoid'],['avoid']
Safety,"Summary of changes:; - At the end of schedule, log total time and number of jobs scheduled.; - Only log database timing if total query took >20ms.; - Make sure context_manager is cleaned up in gear.Transaction.; - Limit workers to max 250 requests/s incoming to batch driver. I used an nginx limit to do this, but it is per pod, so I turned off autoscaling and increased CPU to roughly what I saw when 100K cores was hammering against a dead driver.; - Increase the worker exponential backoff from 30s to 2m. The main thing I was trying to address was the driver getting overloaded when trying to restart with a large standing cluster. It isn't totally clear why the cluster failed in the first place. I made a few other changes to mitigate the issue before adding the nginx limit, so I'm not 100% sure which combination of changes fixed the problem:. - I put a 60s timeout on the scheduler loop. This probably isn't necessary, although the scheduler does get bogged down if many of the instances it tries to schedule on are not responding. - I put a 10s timeout on mark_job_complete. - I put a maximum of 150 active mark_job_complete requests being processed, and returned service unavailable when the max was hit. I don't think this problem is completely solved. I think we want to keep the driver in the ~80% CPU load regime where everything is being processed quickly. I think we want to back off workers if, for example, mark_job_complete is taking more than 95%ile in the not overloaded case. I'm not sure who should do this, although it could be the batch-driver if internal-gateway is doing front-line throttling. Exiting in the overload case should be very cheap. We might want to prioritize mark_job_complete over the scheduler in that case, too. @danking I'd love to get some metrics for the scheduling loop: schedules/s, jobs/s, and time once this goes in. Should I switch to logging json to make that easier?",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8149:866,timeout,timeout,866,https://hail.is,https://github.com/hail-is/hail/pull/8149,2,['timeout'],['timeout']
Safety,"Summary;; I tried running hail with spark-submit and a .py script with a short pipeline to compare speed. Offending line:; ```; kt = vds_results.make_table('v = v', 'pval = va.pval').export(""output/test.txt""); ```; gives; ```; File ""<decorator-gen-93>"", line 2, in export; File ""/home/ludvig/Programs/hail/python/hail/java.py"", line 121, in handle_py4j; 'Error summary: %s' % (deepest, full, Env.hc().version, deepest)); hail.java.FatalError: SparkException: Job aborted due to stage failure: Task 0.0 in stage 5.0 (TID 1591) had a not serializable result: is.hail.io.bgen.BgenRecordV11$$anon$1; ```; ```; Serialization stack:; 	- object not serializable (class: is.hail.io.bgen.BgenRecordV11$$anon$1, value: BgenRecordV11(0/0:.:.:.:GP=1.0,0.0,0.0, 0/0:.:.:.:GP=1.0,0.0,0.0, 0/0:.:.:.:GP=1.0,0.0,0.0, 0/0:.:.:.:GP=1.0,0.0,0.0, 0/0:.:.:.:GP=1.0,0.0,0.0, 0/0:.:.:.:GP=1.0,0.0,0.0, 0/0:.:.:.:GP=1.0,0.0,0.0, 0/0:.:.:.:GP=1.0,0.0,0.0, 0/0:.:.:.:GP=1.0,0.0,0.0, 0/0:.:.:.:GP=1.0,0.0,0.0, 0/0:.:.:.:GP=1.0,0.0,0.0, 0/0:.:.:.:GP=1.0,0.0,0.0, 0/0:.:.:.:GP=1.0,0.0,0.0, 0/0:.:.:.:GP=1.0,0.0,0.0, 0/0:.:.:.:GP=0.99798583984375,0.00201416015625,0.0, 0/0:.:.:.:GP=1.0,0.0,0.0, 0/0:.:.:.:GP=1.0,0.0,0.0, 0/0:.:.:.:GP=1.0,0.0,0.0, 0/0:.:.:.:GP=1.0,0.0,0.0,. goes on for a while. field (class: scala.Tuple2, name: _2, type: class java.lang.Object); 	- object (class scala.Tuple2, ([rs149841286:10000179:AAAAAAAC:A,---],BgenRecordV11(0/0:.:.:.:GP=1.0,0.0,0.0, 0/0:.:.:.:GP=1.0,0.0,0.0,. keeps on going like above until remaining stack trace:. at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBu",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2527:463,abort,aborted,463,https://hail.is,https://github.com/hail-is/hail/issues/2527,1,['abort'],['aborted']
Safety,"Switch apiserver from flask to aiohttp. Mostly boilerplate, except calling into the JVM is blocking. Therefore, I execute JVM calls via a concurrent ThreadPoolExecutor with (a somewhat randomly selected) 16 threads. py4j is thread safe and executes each request on the server (Java) side in a separate thread: https://github.com/bartdag/py4j/blob/master/py4j-python/src/py4j/java_gateway.py#L898",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5624:231,safe,safe,231,https://hail.is,https://github.com/hail-is/hail/pull/5624,1,['safe'],['safe']
Safety,"Take a look at the docs for [`IPython.display.display`](https://ipython.readthedocs.io/en/stable/api/generated/IPython.display.html#IPython.display.display). I preserve the user's ability to specify a custom handler. The handler is no longer given a string but an object that has a sensible `__str__` and `__repr__`. Moreover, this object has a `_repr_html_` which Jupyter uses to display an HTML table. Detecting what frontend is being run is done by `IPython.display.display`. I use the `_Show` shim class to avoid having tables themselves print as HTML. I also check for terminal size and use that to pick `n` and `width`. Should `_hl_repr` live here?. Resolves #5663, #2847",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5666:404,Detect,Detecting,404,https://hail.is,https://github.com/hail-is/hail/pull/5666,2,"['Detect', 'avoid']","['Detecting', 'avoid']"
Safety,"TestNG Suite from JAR File Fails to Delete Temporary Copy of Suite File (Steven Jubb); Fixed: GITHUB-2818: Add configuration key for callback discrepancy behavior (Krishnan Mahadevan); Fixed: GITHUB-2819: Ability to retry a data provider in case of failures (Krishnan Mahadevan); Fixed: GITHUB-2308: StringIndexOutOfBoundsException in findClassesInPackage - Surefire/Maven - JDK 11 fails (Krishnan Mahadevan); Fixed: GITHUB:2788: TestResult.isSuccess() is TRUE when test fails due to expectedExceptions (Krishnan Mahadevan); Fixed: GITHUB-2800: Running Test Classes with Inherited <a href=""https://github.com/Factory""><code>@​Factory</code></a> and <a href=""https://github.com/DataProvider""><code>@​DataProvider</code></a> Annotated Non-Static Methods Fail (Krishnan Mahadevan); New: Ability to provide custom error message for assertThrows\expectThrows methods (Anatolii Yuzhakov); Fixed: GITHUB-2780: Use SpotBugs instead of abandoned FindBugs; Fixed: GITHUB-2801: JUnitReportReporter is too slow; Fixed: GITHUB-2807: buildStackTrace should be fail-safe (Sergey Chernov); Fixed: GITHUB-2830: TestHTMLReporter parameter toString should be fail-safe (Sergey Chernov); Fixed: GITHUB-2798: Parallel executions coupled with retry analyzer results in duplicate retry analyzer instances being created (Krishnan Mahadevan)</p>; <p>7.6.1; Fixed: GITHUB-2761: Exception: ERROR java.nio.file.NoSuchFileException: /tmp/testngXmlPathInJar-15086412835569336174 (Krishnan Mahadevan); 7.6.0; Fixed: GITHUB-2741: Show fully qualified name of the test instead of just the function name for better readability of test output.(Krishnan Mahadevan); Fixed: GITHUB-2725: Honour custom attribute values in TestNG default reports (Krishnan Mahadevan); Fixed: GITHUB-2726: <a href=""https://github.com/AfterClass""><code>@​AfterClass</code></a> config method is executed for EACH <a href=""https://github.com/Test""><code>@​Test</code></a> method when parallel == methods (Krishnan Mahadevan); Fixed: GITHUB-2752: TestListener i",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12665:12047,safe,safe,12047,https://hail.is,https://github.com/hail-is/hail/pull/12665,2,['safe'],['safe']
Safety,Tests are approximate but should be safe.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6769:36,safe,safe,36,https://hail.is,https://github.com/hail-is/hail/pull/6769,1,['safe'],['safe']
Safety,"The Artifact Registry is useful to avoid network egress costs for regions like Australia, where GCR doesn't provide local hosting. Partially addresses #9872.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9875:35,avoid,avoid,35,https://hail.is,https://github.com/hail-is/hail/pull/9875,1,['avoid'],['avoid']
Safety,"The Balding Nichols Model currently does a bunch of allocation per-variant. We can avoid a lot of this by using a random seed per-partition, instead of per-variant. Moreover, we should modify the interface of `Distribution` such that it reads:. ```scala; trait Distribution {; def setSeed(seed: Long); def sample(): Double; }; ```. And the implementations should rely directly on java.util.Random:; ```scala; class UniformDist(...) {; ...; private val rand = new java.util.Random(); def setSeed(seed: Long) {; rand.setSeed(seed); }; def sample(): Double = rand.nextDouble(minVal, maxVal); }; ```; etc. Then we can reformulate the balding nichols model with a `mapPartitions` that allocates one Distribution per partition and seeds it once. If all the partition seeds come from one master seed, then the entire process is deterministic, but only requires allocation and seeding per partition.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2314:83,avoid,avoid,83,https://hail.is,https://github.com/hail-is/hail/issues/2314,1,['avoid'],['avoid']
Safety,"The CountMentions implementation was totally wrong -- it hadn't been updated to use the binding environment. I think most of the usages of Mentions were technically correct as implemented, but this is much safer.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5740:206,safe,safer,206,https://hail.is,https://github.com/hail-is/hail/pull/5740,1,['safe'],['safer']
Safety,"The `BatchPoolExecutor` assumes, incorrectly, that the default number of CPUs for; a batch job is 1. This is not true in test and development environment. I avoid explicitly setting the value if it is `None`. This choice preserves the; default value in this environment. I set the thread limit to 1 if the CPU is `None`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9462:157,avoid,avoid,157,https://hail.is,https://github.com/hail-is/hail/pull/9462,1,['avoid'],['avoid']
Safety,"The `BlockingInputBuffer` allocates a somewhat large array of; bytes each time it is allocated. As such, it is important to avoid; allocating a `BlockingInputBuffer` for each row if each row is; significantly smaller than the buffer size. This change removes problematic methods from `RegionValue`, `RVD`,; and `CodecSpec` that have poor performance. In every case, a small; code change enables one allocation per-partition. This required the; implementation of `RestartableByteArrayInputStream` which is a thread-; unsafe version of `ByteArrayInputStream` that, crucially, can; be restarted with a new `Array[Byte]`. ---. I rebased this off of my shuffler branch. With this change on the shuffler branch (which otherwise didn't change Spark shuffles), I saw these benchmark results:; ```; # hailctl dev benchmark compare more-allocs.json fewer-allocs.json; Name Ratio Time 1 Time 2; ---- ----- ------ ------; shuffle__key_rows_by_mt 105.2% 25.528 26.860; shuffle__key_rows_by_4096_byte_rows 102.7% 1.052 1.081; shuffle__key_rows_by_65k_byte_rows 102.7% 19.311 19.832; shuffle__order_by_10m_int 47.0% 93.554 44.011; ----------------------; Geometric mean: 85.0%; Simple mean: 89.4%; Median: 102.7%; ```. The first benchmark is dominated by LZ4 calls in Kryo. The second and third benchmarks are dominated by the construction of the MT. I suspect this is due to unnecessary data copying (when Hail constructs an array of structs it creates the structs out of line and copies them into place).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7108:124,avoid,avoid,124,https://hail.is,https://github.com/hail-is/hail/pull/7108,2,"['avoid', 'unsafe']","['avoid', 'unsafe']"
Safety,"The `MatrixEntriesTable` lowering rule was broken. It fails when the input `MatrixTable` has multiple key fields, which appear out of order in the row struct. `MatrixEntriesTable` has to do an `TableAggregateByKey`, which makes a table with row type `Struct{keyFields..., aggResult}`. In particular, it rearranges the key fields to the key order. Then the later; ```scala; mapRows('row.dropFields(toExplode).insertStruct('row (toExplode),; ordering = Some(x.typ.rowType.fieldNames.toFastIndexedSeq))); ```; fails, because it tries to put the key fields back in their original order. I've fixed this by changing the above line to a `mapRows(makeStruct(...))`, but I don't see any good reason for the restriction that `InsertFields` must preserve the relative ordering of old fields. Another fix, which I prefer, is to change the typecheck rule for `InsertFields` to; ```scala; case x@InsertFields(old, fields, fieldOrder) =>; fieldOrder.foreach { fds =>; val fieldsMap = scala.collection.mutable.Map(; old.typ.asInstanceOf[TStruct].fields.map(f => f.name -> -f.typ): _*); fieldsMap ++= fields.map { case (name, ir) => name -> ir.typ }. assert(fds.forall { f =>; fieldsMap.get(f).forall(_ == -x.typ.fieldType(f)); }); assert(fds.length == x.typ.size); ```; As far as I can tell, code generation for `InsertFields` is safe for this relaxed typechecking. @tpoterba Can you weigh in on the `InsertFields` semantics?",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6882:1315,safe,safe,1315,https://hail.is,https://github.com/hail-is/hail/pull/6882,1,['safe'],['safe']
Safety,"The `assert(_ptype2 == null)` check in InferPType is breaking here on; certain complex pipelines in a way I don't want to debug. There's no IR sharing within the IR (see utility I added), but there; must be subtrees that are inferred multiple times in different Compile; calls. This is a safe stop-gap.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8031:288,safe,safe,288,https://hail.is,https://github.com/hail-is/hail/pull/8031,1,['safe'],['safe']
Safety,"The `distinct` is safe to remove since `ToDict` will do its own distinct. The only occasion when we'd want the distinct there is if we have tons of highly duplicated keys in `table`, which is very rare. Otherwise, removing the distinct and inserting an unkey will generate better IRs with fewer shuffles.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5274:18,safe,safe,18,https://hail.is,https://github.com/hail-is/hail/pull/5274,1,['safe'],['safe']
Safety,"The actual necessary fix is `history.pushState("""", document.title, loc.pathname + loc.search);` instead of `history.pushState("""", document.title, loc.pathname);`. Given the nervousness around JS and its use in docs (many imperative scripts interacting), I've decided to take a simpler approach that guarantees that Firefox will have behavior inconsistent with Chrome/Safari. In practice it isn't so bad (initially scrolls too far instead of starting at top of page). There may also be a chance that the browser's built-in scroll will act after the JS command, but there simply isn't a better way (besides setting a longer timeout), or the version that alters the url.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7385:622,timeout,timeout,622,https://hail.is,https://github.com/hail-is/hail/pull/7385,1,['timeout'],['timeout']
Safety,"The code as written doesn't seem to allow this to happen. Did someone else bind to that port? It looks like it can happen if an unhandled exception occurs during docker stop or delete, in which case we free the port even though the container might still have the port open. ```; Traceback (most recent call last):; File ""/usr/local/lib/python3.6/site-packages/batch/worker.py"", line 354, in run; start_container, self.container); File ""/usr/local/lib/python3.6/site-packages/batch/worker.py"", line 94, in wrapper; return await asyncio.wait_for(f(*args, **kwargs), timeout); File ""/usr/local/lib/python3.6/asyncio/tasks.py"", line 358, in wait_for; return fut.result(); File ""/usr/local/lib/python3.6/site-packages/batch/worker.py"", line 142, in start_container; return await container.start(); File ""/usr/local/lib/python3.6/site-packages/aiodocker/containers.py"", line 170, in start; data=kwargs,; File ""/usr/local/lib/python3.6/site-packages/aiodocker/docker.py"", line 291, in __aenter__; resp = await self._coro; File ""/usr/local/lib/python3.6/site-packages/aiodocker/docker.py"", line 206, in _do_query; raise DockerError(response.status, json.loads(what.decode(""utf8""))); aiodocker.exceptions.DockerError: DockerError(500, 'driver failed programming external connectivity on endpoint batch-20376-job-59-main (8a971634c54c03a1e7df1b4255814137c92e10d310b3d47a1fe6cb7432222ed0): Error starting userland proxy: listen tcp 0.0.0.0:46572: bind: address already in use'); ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8411:564,timeout,timeout,564,https://hail.is,https://github.com/hail-is/hail/issues/8411,1,['timeout'],['timeout']
Safety,"The comment in the code has most of the context. For auth checks, Envoy uses the same HTTP method as the original request, which confuses our aiohttp middleware which checks CSRF tokens on every `POST`. This broke Grafana because the grafana front-end POSTs queries to the backend, and those end up failing the auth check. We just don't need to check for CSRF in auth checks. This should be the only occurrence in our codebase where a safe endpoint can be reached with an unsafe HTTP method.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13646:435,safe,safe,435,https://hail.is,https://github.com/hail-is/hail/pull/13646,2,"['safe', 'unsafe']","['safe', 'unsafe']"
Safety,"The constructor to the VDS Combiner has this sanity check:; https://github.com/hail-is/hail/blob/3e0b2131eafa075e406d674c2d5e847c2f06f8cc/hail/python/hail/vds/combiner/variant_dataset_combiner.py#L226-L227. A complete combiner will not have any vdses or gvcfs present, so that sanity check will fail and the combiner will be rerun in its entirety. It is a valid state for a `VariantDatasetCombiner` to have no vdses or gvcfs (when it is done), and so the fix is straightforward, remove the sanity check. A similar one already exists in `new_combiner` and `VariantDatasetCombiner.__init__` isn't really part of the public interface. I'm undecided if we should add a different sanity check to `maybe_load_from_saved_path` to see if the final file is present if the combiner is done. Though better logging will be added to that function so that the message from the exception is logged.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14079:45,sanity check,sanity check,45,https://hail.is,https://github.com/hail-is/hail/issues/14079,4,['sanity check'],['sanity check']
Safety,"The current `filter_rows` is implemented as a transpose. Nik and Konrad are running into driver memory issues when doing `tree_matmul`, and one theory of mine is that making lots of `BlockMatrixTransposeRDD`'s is contributing to this. I'd like to make this change to avoid that in the future.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9373:267,avoid,avoid,267,https://hail.is,https://github.com/hail-is/hail/pull/9373,1,['avoid'],['avoid']
Safety,"The current main version of the Query Service uses a fresh class loader for every query. This means each driver job and worker job starts with uncompiled classes for any class in Hail. This change uses a shared class loader for all jobs with the same SHA. This enables use of previously JIT'ed Hail classes. This noticeably improves no-op performance from ~8 seconds to ~3 seconds. Most of that remaining 3 seconds is due to Query-on-Batch and Batch, not Query. Currently, Hail generates classes using a counter. When a driver or worker re-uses an old class loader, it would mistakenly re-use classes generated by a previous Hail Query-on-Batch job because they share the same name. This PR avoids that entirely by using a fresh class loader per job for *generated* classes. This PR parameterizes the entire Hail Query system by a class loader. This class loader is passed in from the initiator of the driver or worker job. We could, eventually, re-use class loaders:; - across jobs for a single batch; - across jobs for a single user; - across jobs for a single billing project; - across all jobs. I think the first three are somewhat uncontroversial but we need to fix the class naming problem. The fourth introduces a new security risk. I think we have a lot of performance to squeeze out of QoB before we need to take that step.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11212:691,avoid,avoids,691,https://hail.is,https://github.com/hail-is/hail/pull/11212,2,"['avoid', 'risk']","['avoids', 'risk']"
Safety,"The default OS for dataproc instances is based on debian8, which uses g++-4.9.x; That has a libstdc++ with an old-ABI implementation of std::list and std::string. To build; a libhail.so which can link against the default libstdc++ on g++-4.x systems, we need to; avoid the use of std::string inside libhail.so (but it's ok to use it in dynamic-generated code,; which will be built with a compiler which matches the libstdc++). This commit introduces a minimal hail::hstring and hail::hstringstream with the necessary; functionality for NativeModule.cpp. Since these don't have a std::hash, I also imported the source code for the (free and uncopyrighted); MurmurHash3, a fast high-quality (but non-crypto) hash function which can give a 128bit hash. ; This simplifies the calculation of the 80bit hash used for module-keys. In addition to using these prebuilt libraries, we also need to get g++ installed on the dataproc; master node, which could be done with ""sudo apt-get install build-essential"". But I'm not yet sure where; that initialization step needs to go.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4422:263,avoid,avoid,263,https://hail.is,https://github.com/hail-is/hail/pull/4422,1,['avoid'],['avoid']
Safety,The emptyDir is only used to communicate from the initcontainer to the; main container. The autoscaler can safely evict and reschedule Grafana; and the initcontainer will run again and generate the token as necessary.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12016:107,safe,safely,107,https://hail.is,https://github.com/hail-is/hail/pull/12016,1,['safe'],['safely']
Safety,"The fix is somewhat subtle and relies on PruneDeadFields, which is called (a) by the optimizer and (b) by the compiler, so this is safe. The important piece is that the process of upcasting strips requiredness. This isn't a great design, but I'm comfortable with it for now since I hope physical types will solve this in The Right Way™ before 0.2 release anyway. fixes #4134",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4265:131,safe,safe,131,https://hail.is,https://github.com/hail-is/hail/pull/4265,1,['safe'],['safe']
Safety,"The issue is we start billing for instances as soon as they're created with the API. However, if an instance is stuck in provisioning and never activates, we never update the start billing time to account for the lack of resource. This PR uses the `lastStartTimestamp` in the [Google REST API](https://cloud.google.com/compute/docs/reference/rest/v1/instances/get). This value is in RFC3339 format. I think this is the same format the timestamp in the activity logs, so I copied how we parse that value. If we delete the instance due to activation timeout, then we set the attempt start time to NULL so it's not billed. I couldn't find good documentation on this, but it seems like the `lastStartTimestamp` approximates what we care about for the purposes of checking for stuck workers. I checked it on an instance that was provisioning and the value was missing. Once the instance was in starting, the value was about 10 seconds after the `creationTimestamp`. . QUESTION: This does raise a question on whether we should be using the `lastStartTimestamp` when billing users if the difference is around 10 seconds. That will be a harder change, but is probably doable. We can't access the `lastStartTimestamp` through the metadata on the worker which would have been the easiest solution. We can get the compute client on the worker and access the `lastStartTimestamp` that way and set the job start time to the instance start time. I'd need to change the database for the attempts trigger to account for this. For the scenario where a job private job is cancelled while creating the instance, we would either need to make the additional API call or we just leave the time we created the instance. Thoughts?",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10069:548,timeout,timeout,548,https://hail.is,https://github.com/hail-is/hail/pull/10069,1,['timeout'],['timeout']
Safety,"The native libraries sometimes play tricks to squeeze out better; precision if the memory layout is amenable to it. This causes some; of our tests to fail, particularly those related to transposition.; We avoid extreme values which should keep us from encountering; situations where naive arithmetic produces Infinity.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2366:205,avoid,avoid,205,https://hail.is,https://github.com/hail-is/hail/pull/2366,1,['avoid'],['avoid']
Safety,"The new generic lines coerce code could produce a partitioner with unsafe values. Those unsafe values ended up in the Compile cache, which become invalid when owning region was cleared. This fixes the memory errors I was seeing when running with the local backend. It is possible it will fix (some?) of the errors you were investigating, @johnc1231.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8987:67,unsafe,unsafe,67,https://hail.is,https://github.com/hail-is/hail/pull/8987,2,['unsafe'],['unsafe']
Safety,"The original goal of this PR was avoiding `Try` when we are not using the restartability provided by semantic hashing because I strongly suspect it is related to the loss of stacktraces in exceptions. Unrelatedly, we realized the semantic hash PR changed the semantics of Query-on-Spark even when semantic hash is disabled: previously we would abort RDD writing on the first exception. In Hail 0.2.123 through 0.2.126, the semantics were changed to only crash *after* we already ran every other partition. Two bad scenarios of which I can think:. 1. Suppose the first partition fails due to OOM. We now waste time/money on the rest of the partitions even though we cannot possibly get a valid output. 2. Suppose every partition hits a permission error. Users should get that feedback after paying for O(1) partitions run, not O(N). I created two Backend paths: the normal `parallelizeAndComputeWithIndex` with its pre-0.2.123 semantics as well as `parallelizeAndComputeWithIndexReturnAllErrors` which, as the name says, returns errors instead of raising them. While making this change, I think I found two other bugs in the ""return all errors"" path, only one of which I addressed in this PR:. 1. I'm pretty sure semantic-hash-enabled QoB batch submission is broken because it uses the logical partition ids as job indices. Suppose there are 10,000 partitions, but we only need to compute 1, 100, and 1543. 0.2.126 would try to submit a batch of size 3 but whose job indices are 1, 100, and 1543. 2. Likewise, the Query-on-Spark path returns an invalid `SparkTaskContext.partitionId` which, at best, produces confusing partition filenames. I only fixed the former because it was simple to fix. I wasn't exactly sure what to do about the latter. We should fix that separately because the changes in this PR need to urgently land in the next release to avoid unexpected cost when one partition fails.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14085:33,avoid,avoiding,33,https://hail.is,https://github.com/hail-is/hail/pull/14085,3,"['abort', 'avoid']","['abort', 'avoid', 'avoiding']"
Safety,The overloading made development a huge headache. I think we should consider overloading more than ~2-way bad practice and try to avoid it.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8570:130,avoid,avoid,130,https://hail.is,https://github.com/hail-is/hail/pull/8570,1,['avoid'],['avoid']
Safety,"The previous formula, `(1/n) (sumsq - (2 * mean * sum) + (n * mean^2))` was weirdly redundant, since `mean * sum == n * mean^2`. This was added by #6728, which ported stats from Scala, but the weird formula did not come from the Scala implementation. I have no clue where this came from. The only reason for doing something like this might be for improved numerical stability, but that doesn't seem to be the case here. In fact, this current method of computing the variance (pre or post this pr) is known to be unstable when the mean is much larger than the stdev (as is easy to see: you're subtracting two nearly equal positive numbers). The Scala implementation used the spark `StatCounter`, which uses the more stable [Welford's algorithm](https://en.wikipedia.org/wiki/Algorithms_for_calculating_variance#Welford's_online_algorithm). We should probably fix any variance or stdev computation to use a stable method, which I think requires a dedicated stats aggregator that maintains count, mean, and variance in a smart way.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10132:84,redund,redundant,84,https://hail.is,https://github.com/hail-is/hail/pull/10132,1,['redund'],['redundant']
Safety,"The resulting rules are more succinct and correctly rely on file-system modification dependencies. - No use of `SPARK_HOME` and `PYTHONPATH`, and limited use of `PYSPARK_SUBMIT_ARGS`. Python tests now rely on the python package directly which handles correctly handles dependencies like `pyspark`. - There are also some phony targets for convenience: `jar`, `zip`, `pip-install`, `docs`, and `docs-no-test`. - Fix configuration of Spark version for the python package. The version is written by make into `python/spark_version` and read by `python/setup.py`. Many of the tests pass against 2.3.0, but there's some floating point value changes. - add breezeVersions for all currently released Spark versions greater than 2.2.0. - For developers, require python package `py` version 1.7.0 or later to allow `pytest` to test an installed package while loading the doctest expressions from the source code. (We could also determine where hail was installed and pass that path to pytest instead of `python/src`, but using the environment variable `PY_IGNORE_IMPORTMISMATCH` seems simple and safe enough). ---. ### Explainers. #### env_var.mk. This is a Makefile that is intended to be `include`d by other Makefiles. It defines a [multi-line variable](https://www.gnu.org/software/make/manual/html_node/Multi_002dLine.html) that [takes arguments](https://www.gnu.org/software/make/manual/html_node/Call-Function.html#Call-Function) (known in any reasonable language as a ""function""). It is intended to be used like this:. ```; VERSION = 30; $(eval $(call ENV_VAR,VERSION)). build: env/VERSION; build:; ... $(VERSION) ...; ```. Each time this Makefile is executed, at Makefile parse-time, `make` evaluates the `ifneq` to compare the current value of the variable to the previously used value (if any). If they differ, a phony (ergo always needs to be rebuilt) target is dynamically generated. That target will force a execution of any dependent targets, in the example above, it will force `build` to be exec",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5130:2422,safe,safe,2422,https://hail.is,https://github.com/hail-is/hail/pull/5130,1,['safe'],['safe']
Safety,The risk is that a container image will eventually be pushed; to the container registry allowing this container to proceed.; We do not rely on this behavior (modulo the eventual consistency; of GCR).,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6784:4,risk,risk,4,https://hail.is,https://github.com/hail-is/hail/pull/6784,1,['risk'],['risk']
Safety,"The stack trace reported:. ```; [Stage 7:> (0 + 132) / 194]Traceback (most recent call last):; File ""/tmp/b54eac62-9ebc-43ff-b49c-80cc77f89aa2/genomes_sites_vcf.py"", line 42, in <module>; sites_vds.write(tmp_vds); File ""/home/teamcity/TeamCityAgent2/work/591c293e3f6bfb1d/python/pyhail/dataset.py"", line 595, in write; File ""/tmp/b54eac62-9ebc-43ff-b49c-80cc77f89aa2/utils.py"", line 211, in run_command; cmd_args); File ""/usr/lib/spark/python/lib/py4j-0.10.3-src.zip/py4j/java_gateway.py"", line 1133, in __call__; File ""/usr/lib/spark/python/lib/pyspark.zip/pyspark/sql/utils.py"", line 63, in deco; for criterion, pop in criteria_pops:; File ""/usr/lib/spark/python/lib/py4j-0.10.3-src.zip/py4j/protocol.py"", line 319, in get_return_value; py4j.protocol.Py4JJavaError: An error occurred while calling o309.run.; : org.apache.spark.SparkException: Job aborted.; 	at org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand$$anonfun$run$1.apply$mcV$sp(InsertIntoHadoopFsRelationCommand.scala:149); 	at org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand$$anonfun$run$1.apply(InsertIntoHadoopFsRelationCommand.scala:115); 	at org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand$$anonfun$run$1.apply(InsertIntoHadoopFsRelationCommand.scala:115); 	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:57); 	at org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:115); 	at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:58); 	at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:56); 	at org.apache.spark.sql.execution.command.ExecutedCommandExec.doExecute(commands.scala:74); 	at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:115); 	at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(S",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1202:850,abort,aborted,850,https://hail.is,https://github.com/hail-is/hail/issues/1202,1,['abort'],['aborted']
Safety,"The test that lists batches timed out. The main problem is the limit in the aioclient used by the test_batch tests was passing a string rather than an integer. I assumed downstream the function was passing an integer. Therefore, we were doing this:. batch_id < ""137""; and not batch_id < 137. So the query was running forever and scanning all batches from the test user. I also was missing a tag annotation on the queries, but that was not causing the timeout.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13237:451,timeout,timeout,451,https://hail.is,https://github.com/hail-is/hail/pull/13237,1,['timeout'],['timeout']
Safety,The tests relying on Batch are getting slower because it takes a long time to download and build Docker images and we're putting more load on Batch. This will increase parallelism and reduce test failures due to timeouts.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9441:212,timeout,timeouts,212,https://hail.is,https://github.com/hail-is/hail/pull/9441,1,['timeout'],['timeouts']
Safety,"The tests use multiple threads which can race to download the references. This is a bit; of a blunt fix. In particular, this is not an asyncio-friendly lock (because I need; thread safety, which asyncio.Lock does not provide). In general, users should not try; to initialize hail multiple times in different coroutines in the same thread.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11949:181,safe,safety,181,https://hail.is,https://github.com/hail-is/hail/pull/11949,1,['safe'],['safety']
Safety,"The treatment of `ClientPayloadError` as a sometimes transient error was originally made in response to [an existing issue](https://github.com/aio-libs/aiohttp/issues/4581) in aiohttp that can cause transient errors on the client that are difficult to distinguish from a real broken server. What's in `main` matched exactly on the error message, but that error message has [since changed](https://github.com/aio-libs/aiohttp/commit/dc38630b168a169139974617d75e176530c91696) to include more information, breaking our transient error handling. This change relaxes the requirement of the error response string to fix transient error handling for our current version of `aiohttp`. I wish I had a better approach. `ClientPayloadError` can also be thrown in the case of malformed data, so I am reticent to treat it as always transient, but we could perhaps make it a `limited_retries_error` and avoid inspecting the error message.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14545:889,avoid,avoid,889,https://hail.is,https://github.com/hail-is/hail/pull/14545,1,['avoid'],['avoid']
Safety,"There are many things wrong here. The Hadoop configuration is not copied per HadoopRDD operation. Proof:. ```; >>> import hail as hl; >>> hl.init(min_block_size=0); >>> t = hl.import_table('test.tsv.bgz', impute=True, min_partitions=8); >>> t.n_partitions(); 8; >>> t = hl.import_table('test-bgz.tsv.gz', impute=True, min_partitions=8); >>> t.n_partitions(); 1; ```. where `test-bgz.tsv.gz` is a bgz in gz's clothing. This is compounded by the fact that SparkContext.hadoopFile is not invoked until TableIR.execute is run making HailContext.forceBGZ() completely ineffective. One option is turning on spark.hadoop.cloneConf, that appears to clone the Hadoop configuration (to avoid some multithreading issues) although the docs don't recommend it due to ""performance regressions"". I haven't tested it. The other option is stop using the Hadoop stuff so we can pass state into the file loaders. Doing that for text files/line splitting is a bit nasty, but it would mean we could properly fix this gz/bgz business once and for all (look at the GZ header to see if it is block gzip'ed).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3861:676,avoid,avoid,676,https://hail.is,https://github.com/hail-is/hail/issues/3861,1,['avoid'],['avoid']
Safety,There are two errors in the status returned by the worker: one is caught when executing the job and the other is when executing the container (such as uploading log to google storage or timeout error). We were only handling job-level errors correctly.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8784:186,timeout,timeout,186,https://hail.is,https://github.com/hail-is/hail/pull/8784,1,['timeout'],['timeout']
Safety,"There could be a webserver with reference datasets, and local installs that use hail-based pipelines (eg. seqr-hail prototype) can avoid downloading large files.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/840:131,avoid,avoid,131,https://hail.is,https://github.com/hail-is/hail/issues/840,1,['avoid'],['avoid']
Safety,"There is still work to do here, but it is now complete enough that InterpretSuite can be run properly on a minimal example. Current TODOs:; - [x] Add C++ emit; - [x] Add Python api (experimental, for now); - [x] Proper type checking in python? *yes, but no type inference*; - [ ] Test ALL failure pathways; - [x] Mismatched Number of args between `Loop` and matching `Recur`; - [x] Mismatched types of args between `Loop` and matching `Recur`; - [ ] Infinite loop detection; - [ ] Not tail recursive detection",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5228:464,detect,detection,464,https://hail.is,https://github.com/hail-is/hail/pull/5228,2,['detect'],['detection']
Safety,"There were two sources of deadlocks:. 1. The attempt resources were not inserted in the same order in the aggregated_*_resources tabes between the two triggers `attempt_resources_after_insert` and `attempts_after_update`. One had jobs -> batches -> billing projects and the other had billing_projects -> batches -> jobs. We also were inserting the resources in a different order in the two triggers. I solved the ordering issue by making sure we `INSERT MANY` the resources in alphabetical order. 2. Once I fixed (1), then the next set of errors were in `add_attempt`. We were locking the `instances_free_cores_mcpu` table only if the attempt didn't already exist. This was causing cryptic deadlock errors like this:. ```; ------------------------; LATEST DETECTED DEADLOCK; ------------------------; 2022-06-23 18:08:12 0x7f1807665700; *** (1) TRANSACTION:; TRANSACTION 1215034153, ACTIVE 0 sec starting index read; mysql tables in use 1, locked 1; LOCK WAIT 21 lock struct(s), heap size 1136, 12 row lock(s), undo log entries 5; MySQL thread id 962402, OS thread handle 139741222766336, query id 6809292838 10.32.5.50 jigold updating; UPDATE instances_free_cores_mcpu; SET free_cores_mcpu = free_cores_mcpu + cur_cores_mcpu; WHERE instances_free_cores_mcpu.name = in_instance_name; *** (1) WAITING FOR THIS LOCK TO BE GRANTED:; RECORD LOCKS space id 1578686 page no 3 n bits 72 index PRIMARY of table `jigold`.`instances_free_cores_mcpu` trx id 1215034153 lock_mode X locks rec but not gap waiting; Record lock, heap no 3 PHYSICAL RECORD: n_fields 4; compact format; info bits 0; 0: len 30; hex 62617463682d776f726b65722d6a69676f6c642d7374616e646172642d62; asc batch-worker-jigold-standard-b; (total 34 bytes);; 1: len 6; hex 0000486bf32c; asc Hk ,;;; 2: len 7; hex 600001287513cb; asc ` (u ;;; 3: len 4; hex 80002de6; asc - ;;. *** (2) TRANSACTION:; TRANSACTION 1215034156, ACTIVE 0 sec inserting; mysql tables in use 6, locked 6; 22 lock struct(s), heap size 1136, 13 row lock(s), undo log entries",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11959:756,DETECT,DETECTED,756,https://hail.is,https://github.com/hail-is/hail/pull/11959,1,['DETECT'],['DETECTED']
Safety,These are the exact same error:; ```; In [4]: import asyncio; ...: import concurrent; ...: asyncio.TimeoutError == concurrent.futures.TimeoutError; Out[4]: True; ```,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10946:99,Timeout,TimeoutError,99,https://hail.is,https://github.com/hail-is/hail/pull/10946,2,['Timeout'],['TimeoutError']
Safety,"These tests spin up a lot of non-preemptible Query Driver jobs. This makes these tests feel not really preemptible safe, as a preemption of the test job will end up submitting duplicate Query Drivers.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13004:115,safe,safe,115,https://hail.is,https://github.com/hail-is/hail/pull/13004,1,['safe'],['safe']
Safety,"These will be helpful when we support searching based on attributes in the Batch UI. Maybe calling it attributes would be better than tags to be consistent with k8s and batch? Also, when making this PR, I don't love the redundancy of the name argument on init and the name method for Tasks. I propose getting rid of the name method. Thoughts? . Stacked on #6277",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6278:220,redund,redundancy,220,https://hail.is,https://github.com/hail-is/hail/pull/6278,1,['redund'],['redundancy']
Safety,"This PR adds `utils/StackSafe.scala`, which contains generic tools for writing stack safe code. To illustrate its use, I've converted `NormalizeNames` and `RewriteBottomUp` to be stack safe. This approach optimizes for the minimal possible change to existing code to make it stack safe. I originally expected this to have mediocre performance, and designed this to have optimization opportunities--requiring more substantial rewrites--where we found it was necessary. In a follow up PR, I converted the IR parser to be stack safe. In benchmarking that, I'm not able to see any performance penalty (if anything, the stack safe version looks slightly faster, which is probably just noise). So it's possible this will perform well enough as is, but we can keep an eye on it as we convert more passes. The basic idea is to rewrite functions that can be called recursively (directly or indirectly through a path of mutually recursive functions) from `f: (...) => A` to `f: (...) => StackFrame[A]`. Where the former evaluates, executing all recursive calls, and then returns the `A` result, the later returns a description of the work to be done before making any recursive calls. The method `StackFrame[A].run(): A` executes that description in a non-recursive loop. `StackFrame` is a monad, implementing `map` and `flatMap`, which allows the `for` syntactic sugar to be used. When a method makes several recursive calls, this can be significantly more readable. The public api is small. There are the free functions; ```scala; def done[A](result: A): StackFrame[A]; def call[A](body: => StackFrame[A]): StackFrame[A]; ```; and the methods; ```scala; abstract class StackFrame[A] {; def flatMap[B](f: A => StackFrame[B]): StackFrame[B]; def map[B](f: A => B): StackFrame[B] = flatMap(a => Done(f(a))); def run(): A; }; ```; `done` is basically the return statement. `call` is very important: it wraps a recursive call in a thunk, so that returning a `StackFrame` doesn't require descending all the way to t",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9320:85,safe,safe,85,https://hail.is,https://github.com/hail-is/hail/pull/9320,5,['safe'],['safe']
Safety,"This PR adds infrastructure for unrealizable `PType`s and `PCode`s. My primary goal was finding the shortest path to enabling nested streams in EmitStream. The main changes are:; * Add `PUnrealizable` and `PUnrealizableCode`. These are traits in the `PType` and `PCode` hierarchies, respectively, that provide ""implementations"" (throw exceptions) for methods not supported on unrealizable types.; * Add `PStreamCode` and `PCanonicalStreamCode`. The latter just wraps a `Stream` from EmitStream.scala, but eventually these should be unified. I also added `PCanonicalStream`, mostly for consistency with the rest of the `PType` hierarchy. If you think the added noise isn't worth the consistency, I can get rid of the abstract classes.; * I added assertions to `TypeCheck` for all cases I could think of where a node could take a child of any type, but now will only work for realizable types.; * To support nested streams in the emitter, we need to be able to bind streams in the environment, e.g. to map over stream of streams. The easiest way I could see to enable this was to keep the environment an `Env[EmitValue]`, but to allow `EmitValue`s of unrealizable types. I added `EmitUnrealizableValue` which asserts that it is only used once. This does go against the concept that ""values are things that can safely be used multiple times""; I'm open to discussion on what the right design is.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8564:1308,safe,safely,1308,https://hail.is,https://github.com/hail-is/hail/pull/8564,1,['safe'],['safely']
Safety,"This PR adds support for Azure SAS tokens in QoB. A SAS token is basically a blob storage URI with a short-lived credential to access that resource appended as a URL query string. In such a scenario where the FS receives a blob URI with a SAS token, that token should be used instead of the latent credentials on the system. Most of the changes to the `AzureStorageFS.scala` are to parse out a SAS token from blob names. This change brings with it a couple caveats. Unfortunately it is not possible to truly disambiguate a SAS token from a glob pattern, or even just a normal blob filename. So we take what is probably a safe assumption and look to see if there exists a query-parameter style key-value pair after the last `?` in the blob name. If this is the case, we treat everything after the last `?` as a SAS token. If this condition is not satsified, we say there is no SAS token and treat the whole path as the blob name. This logic already exists in python, but I'm open to alternatives. Introducing SAS tokens also breaks the way globbing is currently implemented, where it is deemed safe to iteratively append components to the end of a blob URI string. I added an abstract type member to `FS` and instead of a `String` have `globWithPrefix` accept that associated URL type that can properly handle path updates. I'm unclear on the best way to do this w.r.t. the type system, and wasn't quite sure what to put as the associated type for `RouterFS`, which ideally would accept a union of the URL types for the filesystems that it wraps, so some guidance on that would be great if you have any.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13178:621,safe,safe,621,https://hail.is,https://github.com/hail-is/hail/pull/13178,2,['safe'],['safe']
Safety,This PR adds the ability to use `hl.literal` on numpy arrays. It also changes the behavior of `hl._ndarray` when called on a numpy ndarray so it just goes through literal to avoid creating an IR node for each element of tensor.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7209:174,avoid,avoid,174,https://hail.is,https://github.com/hail-is/hail/pull/7209,1,['avoid'],['avoid']
Safety,"This PR breaks ""fatal"" out into two functions, ""fatal"" and ""abort"". Fatal is for unexpected error handling, and produces a python stacktrace, but 'abort' is for handled, expected errors (like invalid method inputs) and does not generate a stack trace in python.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1552:60,abort,abort,60,https://hail.is,https://github.com/hail-is/hail/pull/1552,2,['abort'],['abort']
Safety,"This PR changes the semantics of TableMapRows in the IR and Table.select. They are now required to preserve the key ordering. In other words, applying TableMapRows to an ordered table can produce an ordered table without shuffling. I put an assert to verify that the produced OrderedRVD is really ordered, but that might be too expensive an assertion. Before, `newKey = None` meant ""keep the old key"", but that left no room to ask for the result to be unkeyed. Now `newKey` is just the key of the resulting table. If any partition key fields are modified, then even if the ordering is preserved, the result will need to be scanned to update the partition bounds. To avoid this scan when unnecessary, I added the `preservedKeyFields` parameter, which is the length of the prefix of key fields which are not modified. Thus, if the number of partition keys of the underlying OrderedRVD is less than or equal to `preservedKeyFields`, the partition bounds will remain valid. This feels pretty clunky, and I welcome better ideas. In particular, is there a way to compute this from the `newRow` IR? That's what I did on the Python side in `_select`, but it wasn't obvious to me how to do the same with the Scala IR.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3622:666,avoid,avoid,666,https://hail.is,https://github.com/hail-is/hail/pull/3622,1,['avoid'],['avoid']
Safety,"This PR fixes a problem where the database state for the instance didn't match the in-memory state for the instance. For example, in-memory the state was 'inactive' while in the database it was 'deleted'. We're not sure why that happens yet. There are 4 possible states: pending, active, inactive, deleted. Rather than failing when this happens (causing an infinite retry loop), we check the return code from the database and act accordingly. . For `deactivate`, the return code will be non-zero only if the instance is inactive or deleted. I thought about making the in-memory state match the state in the database explicitly, but I think it's safer to keep the current behavior where the in-memory state is ""inactive"". The state will be fixed to deleted when the callers of deactivate eventually call `mark_deleted`. Likewise, `mark_deleted` expects the state to be inactive. I thought about handling the case where the db is pending or active and the in-memory state is inactive and realized that could never happen. Therefore, I just assert the db state must be already deleted and update the state appropriately.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8254:645,safe,safer,645,https://hail.is,https://github.com/hail-is/hail/pull/8254,1,['safe'],['safer']
Safety,"This PR introduces `facet_wrap`, which will allow creating plots based on a specified facet. It also adds ; ` def _add_aesthetics_to_trace_args(self, trace_args, df):`; and; ` def _update_legend_trace_args(self, trace_args, legend_cache):`. two helper methods which let me clean up some of the redundant plotting work. A `legend_cache` was introduced to make sure we put traces that should have the same legend point in a `legendgroup` together. Without it, if I draw one red line in each of 4 different subplots created by a facet, then 4 entries appear in the legend.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11725:294,redund,redundant,294,https://hail.is,https://github.com/hail-is/hail/pull/11725,1,['redund'],['redundant']
Safety,"This PR introduces a generic pretty-printing package, which for now is only used in `ir.Pretty`. The primary motivation was to separate format specification from rendering, to simplify the formatting code, and make it easier to add multiple formatting options, including forms with line number references. Some nice properties of the new pretty-printer:; * Generic. Should be able to be used for all pretty-printing in hail scala code. This simplifies the codebase by making client pretty-printers easy to understand and modify, without getting bogged down in low-level details.; * Composable. Formatting specifications are trivially combinable, without needing to manually track context like the current indentation level, max line length, etc.; * Stack safe. Uses constant stack space.; * Uses constant heap space. Only keeps in memory text which might print in the current line, if it fits. (The pretty printer writes to a `java.io.Writer`, and I'm ignoring any heap space used by the writer.); * Lazy. If the number of lines to print is capped, doesn't scan more of the tree than is needed to print those lines.; * Produces more readable output, printing nodes on a single line where possible. As we work to increase visibility into the compiler, I think this will be very helpful. A formatted document is represented by the `Doc` type. This defines a `render` method, which takes three parameters to control the output:; * `width`: the maximum length of a line, including indentation; * `ribbonLength`: the maximum length of a line, not including indentation (too many characters on a line is hard to read, regardless of indentation); * `maxLines`: the maximum number of lines to print. There are only a few `Doc` constructors, which suffice to define all methods in the richer api contained in the `prettyPrint` package object.; * `Text(t: String)`; * `Line(ifFlat: String)`; * `Indent(i: Int, body: Doc)`; * `Concat(it: Iterable[Doc])`; * `Group(body: Doc)`. Ignoring `Group` for the moment, th",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9652:755,safe,safe,755,https://hail.is,https://github.com/hail-is/hail/pull/9652,1,['safe'],['safe']
Safety,"This PR is the first iteration of an AsyncFS-based copy interface. It adds RouterAsyncFS.copy. The goal of these changes is to establish the interface and behavior. I expect several follow-on PRs:. - Revise the original copy interface proposal and add to dev-docs.; - ~~Parallelizes the transfers concurrently with async and across multiple threads.~~; - ~~After parallizing, copy will involve a lot of paralellism. Throwing an exception on the first error will be very non-deterministic. Instead, copy will return a report that collects all the errors that were encountered in the course of copying, and summarizes how many files/bytes were copied.~~; - Use multi-process parallelism; - Avoid overwriting the destination if it exists and has a matching checksum (or size).; - ~~Introduce multi-part transfers~~; - add a post-pass for Google Storage to detect file-and-directory errors.; - Adds support for S3.; - Add `hailctl cp ...` (PR); - Use copy in Batch. After this goes in, these can mostly be developed in parallel. A few principles guided the implementation of copy: perform the minimal number of system calls or API requests per copy, and only do error checking when it doesn't involve additional FS operations. For example, it is too expensive to exhaustively check if we're creating a path that is a file and a directory in Google Storage. I considered doing additional and exhaustive checking for the actual copy arguments. For example, currently, `cp -T /path/to/file /path/to/dir` will not generate an error on Google Storage. In the end, I decided to go with the current behavior and I will add an option to do a postpass to check for file-and-dir paths. To achieve this, for each transfer, I simultaneously stat the destination (if needd) to determine if it is a file, directory or doesn't exist. For each source, I simultaneously try to copy it as a file and a directory. When copying each source, we don't need to know the type of the destination until after we've stat'ed the sour",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9822:688,Avoid,Avoid,688,https://hail.is,https://github.com/hail-is/hail/pull/9822,2,"['Avoid', 'detect']","['Avoid', 'detect']"
Safety,"This PR is to enable `hail-az;` file references to contain SAS tokens to enable bearer-auth style file access to Azure storage. Basic summary of the changes:; 	- Update `AzureAsyncFS` url parsing function to look for and separate out a SAS-token-like query string. Note: made fairly specific to SAS tokens - generic detection of query string syntax interferes with glob support and '?' characters in file names; 	- Added `generate_sas_token` convenience function to `AzureAsyncFS`. Adds new `azure-mgmt-storage` package requirement.; 	- Updated `AzureAsyncFS` to use `(account, credential)` tuple as internal `BlobServiceClient` cache key; 	- Updated `AzureAsyncFSURL` and `AzureFileListEntry` to track the token separately from the name, and extend the base classes to allow returning url with or without a token ; 	- Update `RouterFS.ls` function and associated `listfiles` function to allow for trailing query strings during path traversal ; 	- Change to existing behavior: `LocalAsyncFSURL.__str__`no longer returns 'file:' prefix. Done to make `str()` output be appropriate for input to `fs` functions across all subclasses; 	- Updated `inter_cloud/test_fs.py` to generically use query-string-friendly file path building functions; - Updated InputResource to not include the SAS token as part of the destination file name . `test_fs.py` has been updated to respect the new model, where it is no longer safe to extend URLs by just appending new segments with + ""/"" because there may be a query string. But actually running those tests for the SAS case will require some new test variables to allow the test code to generate SAS tokens (`build.yaml/test_hail_python_fs`): ; ```; export HAIL_TEST_AZURE_ACCOUNT=hailtest; export HAIL_TEST_AZURE_CONTAINER=hail-test-4nxei; # Required for SAS testing on Azure; export HAIL_TEST_AZURE_RESGRP=hailms02; export HAIL_TEST_AZURE_SUBID=12ab51c6-da79-4a99-8dec-3d2decc97343; ```; So the SAS case is disabled for now (`test_fs.py`):; ```; @pytest.fixture(param",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12877:316,detect,detection,316,https://hail.is,https://github.com/hail-is/hail/pull/12877,1,['detect'],['detection']
Safety,This PR makes docker calls idempotent and adds a timeout for docker calls in the retry function. I got the error codes to ignore from the older docker documentation at the bottom of each API call: https://docs.docker.com/engine/api/v1.30/#operation/ContainerDelete. FYI: @cseed since you had opinions on the timeout times,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8049:49,timeout,timeout,49,https://hail.is,https://github.com/hail-is/hail/pull/8049,2,['timeout'],['timeout']
Safety,"This PR makes the following changes:. 1. For some reason, I forgot `CompileAndEvaluate` exists, and was separately calling `Compile`, applying it, then doing `SafeRow.read` in two places. Ripped those out in favor of `CompileAndEvaluate`.; 2. When all segments are either already sorted or sufficiently small, I now sort and write out all the sufficiently small ones. Now I have a set of files that taken together fully represent the table, and I create a new `TableStage` by assembling those chunks into approximately evenly sized partitions.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11296:159,Safe,SafeRow,159,https://hail.is,https://github.com/hail-is/hail/pull/11296,1,['Safe'],['SafeRow']
Safety,"This PR removes the `as_array` parameter on `pca` and `hwe_normalized_pca`. The scores and loadings tables are constructed to always have a field of array type, mirroring the eigenvalues array. This simplifies the interface and makes pipeline (and PC indexing) behavior more predictable.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3280:275,predict,predictable,275,https://hail.is,https://github.com/hail-is/hail/pull/3280,1,['predict'],['predictable']
Safety,"This PR teaches most of our cluster how to exclusively speak HTTPS instead of; HTTP. The exceptions are:; - from batch-driver to batch workers; - from batch workers to internal-gateway; - to ukbb-rg; - from router to notebook workers; - letsencrypt (oh the irony). ## Changes from Original PR Proposal. ### Root Certificate. I added a secret to default named `ssl-config-hail-root` containing `hail-root-key.pem`, and `hail-root-cert.pem`. Every principal trusts this root. This root trusts every principal. This PR originally prevented clients from speaking to servers with certs they didn't trust. Now everyone trusts everyone. As long as the root key is not leaked this is OK. Only `create_certs` mounts this secret. The key is used to sign every certificate and the cert is included in each principal's incoming and outgoing trust lists. The root certificate and key are never re-created, so our deploys have no downtime and we avoid addressing the rotation problem. I removed all the trust specifications. A later PR will resolve rotation and mTLS. That PR will restore the trust specifications. I didn't change the structure of the secrets (they still have an incoming and outgoing trust list which only contains the root cert) because I need this structure for mTLS anyway. The original PR text follows. ---. ## HTTPS and TLS. HTTP is implemented on TCP/IP. HTTPS is also implemented on TCP/IP and differs; very mildly. After the socket is opened, a TLS [1] connection is established; over the socket. Thereafter, every HTTP message is encrypted and transported by; the TLS machinery. The HTTP protocol is unchanged. The default port fort HTTP is; 80 and the default port for HTTPS 443, however any port may be used. There are currently four versions of TLS, the latest is TLS 1.3. All versions of; SSL are considered insecure. The OpenSSL library implements TLS. There are other implementations, such as; LibreSSL, but they implement roughly the same interface as OpenSSL. The TLS protocol def",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8561:932,avoid,avoid,932,https://hail.is,https://github.com/hail-is/hail/pull/8561,1,['avoid'],['avoid']
Safety,"This PR:. 1. Fixes a mistake in deploy.sh so that files get written to predictable paths. I manually put a file in the hail-common bucket for the purposes of testing this PR. ; 2. Replaces `make_pip_versioned_docs` with `get_pip_versioned_docs`, a step that will usually just pull prerendered docs from `hail-common`, but if it's a deploy, it will pass along the docs that it gets from its input, `make-docs`. . The effect should be that as soon as this merges, tutorials will correctly render again.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11314:71,predict,predictable,71,https://hail.is,https://github.com/hail-is/hail/pull/11314,1,['predict'],['predictable']
Safety,This Region will get cleared by consumers. I introduced the zip primitive which is a safer way to; zip two RVDs because it does not rely on the user correctly; clearing the regions used by the left and right hand sides; of the zip. cc: @cseed,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3400:85,safe,safer,85,https://hail.is,https://github.com/hail-is/hail/pull/3400,1,['safe'],['safer']
Safety,"This adds SpillingCollectIterator which avoids holding more than 1000 aggregation results in memory at one time. We could do something that listens for GC events and spills data if there's high memory pressure. That seems a bit error prone and hard. The number of results kept in memory is a flag on the HailContext. In C++ we can design a system that is aware of its memory usage and adjusts memory allocated to scans accordingly. #### Implementation Notes. I had to add two new file operations to `FS` and `HadoopFS` because I need seekable file input streams. When we add non-hadoop `FS`'s we'll need to address the interface issue. When we overflow our in-memory buffer, we spill to a disk file. We use O(n_partitions / mem_limit) files. We stream through the files to `scanLeft`, to compute the globally valid scan state per partition. The stream writes its results to another file which must be on a cluster-visible file system (we use `HailContext.getTemporaryFile`). Finally, each partition reads that file and seeks to its scan state. I somewhat better solution would be to eagerly scan as results come in. I leave that as future work. #### Timings. Master 0.2.14-4da055db5a7b; ```; In [1]: %%time ; ...: ; ...: import hail as hl ; ...: ht = hl.utils.range_table(10000, n_partitions=10000) ; ...: ht = ht.annotate(rank = hl.scan.count())._force_count() ; CPU times: user 1.45 s, sys: 333 ms, total: 1.78 s; Wall time: 24.6 s; In [3]: %%time ; ...: ; ...: import hail as hl ; ...: ht = hl.utils.range_table(1000000, n_partitions=1000) ; ...: ht = ht.annotate(rank = hl.scan.count())._force_count() ; CPU times: user 6.23 ms, sys: 1.96 ms, total: 8.19 ms; Wall time: 1.33 s; ```; This branch; ```; In [1]: %%time ; ...: ; ...: import hail as hl ; ...: ht = hl.utils.range_table(10000, n_partitions=10000) ; ...: ht = ht.annotate(rank = hl.scan.count())._force_count() ; CPU times: user 1.36 s, sys: 297 ms, total: 1.66 s; Wall time: 27.3 s. In [2]: %%time ; ...: ; ...: import hail as hl ; ...:",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6345:40,avoid,avoids,40,https://hail.is,https://github.com/hail-is/hail/pull/6345,1,['avoid'],['avoids']
Safety,"This adds `SpillingCollectIterator` which avoids holding more than 1000 aggregation results in memory at one time. We could do something that [listens for GC events](https://stackoverflow.com/questions/30041332/a-useful-metric-for-determining-when-the-jvm-is-about-to-get-into-memory-gc-trou) and spills data if there's high memory pressure. That seems a bit error prone and hard. How should I pipe the size limit down to TableMapRows? The only workable solution I can think of is a HailContext setting. Maybe I should bite the bullet and respond to memory pressure? Either way this should get Laurent cooking with gas. Spilling ten local files and then reading them in is probably in the noise of timings. 🎉. Master 0.2.14-4da055db5a7b; ```ipython; In [1]: %%time ; ...: ; ...: import hail as hl ; ...: ht = hl.utils.range_table(10000, n_partitions=10000) ; ...: ht = ht.annotate(rank = hl.scan.count())._force_count() ; CPU times: user 1.45 s, sys: 333 ms, total: 1.78 s; Wall time: 24.6 s; In [3]: %%time ; ...: ; ...: import hail as hl ; ...: ht = hl.utils.range_table(1000000, n_partitions=1000) ; ...: ht = ht.annotate(rank = hl.scan.count())._force_count() ; CPU times: user 6.23 ms, sys: 1.96 ms, total: 8.19 ms; Wall time: 1.33 s; ```; This branch:; ```ipython; In [2]: %%time ; ...: ; ...: import hail as hl ; ...: ht = hl.utils.range_table(10000, n_partitions=10000) ; ...: ht = ht.annotate(rank = hl.scan.count())._force_count() ; CPU times: user 1.41 s, sys: 313 ms, total: 1.72 s; Wall time: 25.2 s. In [3]: %%time ; ...: ; ...: import hail as hl ; ...: ht = hl.utils.range_table(1000000, n_partitions=1000) ; ...: ht = ht.annotate(rank = hl.scan.count())._force_count() ; ...: ; ...: ; CPU times: user 4.72 ms, sys: 1.82 ms, total: 6.53 ms; Wall time: 1.41 s; ```. ---. Minor implementation note: I did the rigamarole with `runJob` because I wasn't sure that using `synchronized` in a constructor was kosher and I'm also generally weary of Scala's constructor syntax.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6306:42,avoid,avoids,42,https://hail.is,https://github.com/hail-is/hail/pull/6306,1,['avoid'],['avoids']
Safety,"This adds `SpillingCollectIterator` which avoids holding more than 1000 aggregation results in memory at one time. We could do something that listens for GC events and spills data if there's high memory pressure. That seems a bit error prone and hard. How should I pipe the size limit down to TableMapRows? I decided to make it a HailContext `flag` which means its not very user-visible, but Laurent can set it for now. In C++ we can design a system that is aware of its memory usage and adjusts memory allocated to scans accordingly. Spilling ten local files and then reading them in is probably in the noise of timings. 🎉. ---. ### Implementation Notes. I had to add two new file operations to the `RichHadoopConfiguration` because I need seekable file input streams. I don't like the names. I'm not sure what to do here. Hadoop really screws us with the seek-ability on compressed streams. The implementation is rather simple, it just maintains an array of the per-partition results. The index of the array corresponds to the partition index. The sparsity of that array is controlled by how often we spill. For an operation with a huge number of partitions that are often spilled (e.g. large number of partitions, each with a lot of data), we may want to use a `Map` instead of an `Array`. The use of `ObjectOutputStream` without a try-catch-finally block is non-standard. I was having trouble seeking to individual classes when I used one ObjectOutputStream to output each partition's array. There were these ""bad header"" messages. This seems to work. I don't close the OOS because I'm going to re-use the underlying output stream on the next partition. We use O(n_spills) files. ---. ### Timings. Master 0.2.14-4da055db5a7b; ```; In [1]: %%time ; ...: ; ...: import hail as hl ; ...: ht = hl.utils.range_table(10000, n_partitions=10000) ; ...: ht = ht.annotate(rank = hl.scan.count())._force_count() ; CPU times: user 1.45 s, sys: 333 ms, total: 1.78 s; Wall time: 24.6 s; In [3]: %%time ; ...: ;",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6333:42,avoid,avoids,42,https://hail.is,https://github.com/hail-is/hail/pull/6333,1,['avoid'],['avoids']
Safety,"This adds `partitionKeys` which partitions the keys into partitions containing as-near-to-equal-as-possible number of records. The partitions are represented by an array, `pb`, of keys of length `nPartitions + 1`. The partitions are taken to include records with keys in; ```; [pb(0), pb(1)); [pb(1), pb(2)); ...; [pb(nPartitions-1), pb(nPartitions)]; ```; Note that the last partition is inclusive of both end-points. I have two simple examples of the partitioning behavior at the top of `LSMSuite`. In these cases, the number of elements is so small that the LSM perfectly stored the distribution, so there is no approximation. `LSMSuite` also contains tests that use enough keys so as to force the LSM to not keep them all. When the LSM has more than 10,000 keys, it starts sampling. It flips a coin that is true with probability `10,000 / n_keys_seen`. As we see more keys, the probability that the next seen key is kept decreases. If we decide to keep a key, we uniformly randomly choose a key to evict. The above is not entirely true. In reality, we keep 9998 keys in an array and separately keep the greatest and the least. Those are the true greatest seen key and the true least seen key. The probabilities above are adjusted accordingly. If the sample of keys is unbiased, then we expect the partitions chosen to be roughly equal in number of records. ---. The TestNG changes are already in another PR, I'll rebase when that lands. I separately fixed a bug in KeyedCodecSpec wherein it incorrectly assumed the Key and Value types were the same. I also fixed a bug in that the LSM used non-thread-local regions. Regions are not thread safe and the Indeed LSM implementation uses many threads. In order to track every addition to the LSM, I made the Indeed LSM object private and made the Hail LSM class have the necessary methods.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8803:1643,safe,safe,1643,https://hail.is,https://github.com/hail-is/hail/pull/8803,1,['safe'],['safe']
Safety,"This adds an `svd` method to `hl.nd`, allowing us to take singular value decomposition of local ndarrays. This is a generally useful operation, but my primary reason for adding it is to avoid the need to call numpy's SVD as a substep of Annamira's new randomized PCA method. The interface is designed to match numpy exactly. . Note that this method uses the LAPACK method `dgesdd`, which is newer, faster version of `dgesvd`. As far as I can tell, there's never a reason to use `dgesvd`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9303:186,avoid,avoid,186,https://hail.is,https://github.com/hail-is/hail/pull/9303,1,['avoid'],['avoid']
Safety,"This adds the minimal resources to k8s to allow us to modify the gateway's configuration to include redirects for https://notebook.hail.is. Currently, that domain will timeout, but there should otherwise be no errors introduces to the k8s system. cc: @cseed",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4645:168,timeout,timeout,168,https://hail.is,https://github.com/hail-is/hail/pull/4645,2,['timeout'],['timeout']
Safety,"This aligns the auth styling with the new batch UI styling. Nothing has really changed about the structure of the pages. This one should be considerably easier than the batch overhaul, just three pages `/user`, `/users` and `/roles` (I think roles were added to auth but never fleshed out, we never use this page. But that's for another PR..). I manually checked that I didn't break any of the Batch pages after moving the utils file into web_common, but a sanity check on that would be great.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14586:457,sanity check,sanity check,457,https://hail.is,https://github.com/hail-is/hail/pull/14586,1,['sanity check'],['sanity check']
Safety,"This assertion was getting triggered by the ref `inner` in a perfectly correct IR of the form `StreamMap(inner, StreamGrouped(...), ...)`. There's no way to avoid the unrealizable ref when mapping over a nested stream, and I don't see why `extract` depends on this assertion.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9631:157,avoid,avoid,157,https://hail.is,https://github.com/hail-is/hail/pull/9631,1,['avoid'],['avoid']
Safety,This avoids confusing Docker cache behavior by baking the verison number into; the RUN command string.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10282:5,avoid,avoids,5,https://hail.is,https://github.com/hail-is/hail/pull/10282,1,['avoid'],['avoids']
Safety,"This avoids serializing to a String before writing, which; likely doubles the memory requirements.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1198:5,avoid,avoids,5,https://hail.is,https://github.com/hail-is/hail/pull/1198,1,['avoid'],['avoids']
Safety,"This basically involved two main things:. - converting the rangeBounds on OrderedRVDPartitioner from an UnsafeIndexedSeq to an IndexedSeq[Interval], which had the nice side effect of getting rid of the gross-looking `rangeBounds(i).asInstanceOf[Interval]` stuff everywhere. Since we're pulling everything into Annotation-land when we do comparisons against this, we were basically using rangeBounds in this way anyways. - implementing Annotation.copy as a fully safe copy that gets rid of all instances of UnsafeRow and UnsafeIndexedSeq. This is used for e.g. making the rangeBounds fully safe, and also for when we need to serialize an annotation that could potentially contain UnsafeRows. . I originally had implemented this as a separate method from the existing copy, but I think the only reason we call Annotation.copy() anyways is so that we can call collect() or otherwise serialize things, so I just removed the other version in favor of this. I implemented a way to manually serialize UnsafeRow and UnsafeIndexedSeq as byte arrays, but I think there's basically no reason we should be manually serializing UnsafeRows instead of just serializing the underlying region, so I took it back out.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3219:104,Unsafe,UnsafeIndexedSeq,104,https://hail.is,https://github.com/hail-is/hail/pull/3219,9,"['Unsafe', 'safe']","['UnsafeIndexedSeq', 'UnsafeRow', 'UnsafeRows', 'safe']"
Safety,"This both avoids an extra pass to find the failing rows as well as avoiding a an extra pass if the globals depend on non-global data. In particular, this pipeline would run the column aggregations four times (IMO, at most twice is OK):. ```; mt = hl.utils.range_matrix_table(2,2); mt = mt.annotate_entries(x = mt.row_idx * mt.col_idx); mt = mt.annotate_cols(mean_x = hl.agg.mean(mt.x)); mt = mt.annotate_entries(x = mt.x - mt.mean_x); mt._same(mt); ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13151:10,avoid,avoids,10,https://hail.is,https://github.com/hail-is/hail/pull/13151,2,['avoid'],"['avoiding', 'avoids']"
Safety,"This branch:; ```; In [2]: %timeit vds.split_multi().count(); 1 loop, best of 3: 18.2 s per loop; ```. Master:; ```; In [2]: %timeit vds.split_multi().count(); 1 loop, best of 3: 27.7 s per loop; ```. I predict the performance improvement will increase with large datasets.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1363:203,predict,predict,203,https://hail.is,https://github.com/hail-is/hail/pull/1363,1,['predict'],['predict']
Safety,This change allows batchces which fit in one bunch to be created in one; request instead of three. I found this saved a few hundred milliseconds; for batches with 1 job. This path is already well tested because most; of our test batches fit in one job. To be clear: all the savings here is from avoiding two round-trips to front-end.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11044:295,avoid,avoiding,295,https://hail.is,https://github.com/hail-is/hail/pull/11044,1,['avoid'],['avoiding']
Safety,"This change applies each currently-ignored `ruff` rule progressively; each commit applies one rule. The changes were applied manually to avoid known issues with the automatic fixes; for example, given the code; ```python; return (; is_container(t); or isinstance(t, tstruct); or isinstance(t, tunion); or isinstance(t, ttuple); or isinstance(t, tndarray); ); ```; the automatic fixes produce; ```python; return isinstance(t, (tndarray, tstruct, ttuple, tunion)); ```; instead of ; ```python; return is_container(t) or isinstance(t, (tstruct, tunion, ttuple, tndarray)); ```; where not only has the call to `is_container` been removed, but also the order of the `isinstance` comparisons has been changed, which has the potential to produce side effects (though in this case, I don’t think it does). Similarly, when eliminating assignments to unused variables, I left the right-hand side of the assignment intact in case of side effects, except where I myself wrote the code in question and know there are no side effects produced by it. See also https://github.com/hail-is/hail/pull/14150 and https://github.com/hail-is/hail/pull/14159.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14415:137,avoid,avoid,137,https://hail.is,https://github.com/hail-is/hail/pull/14415,1,['avoid'],['avoid']
Safety,"This change avoids computing the context twice (or, if head and tail are interleaved, an exponential number of times).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11781:12,avoid,avoids,12,https://hail.is,https://github.com/hail-is/hail/pull/11781,1,['avoid'],['avoids']
Safety,"This change brings the `facet_wrap` interface more in line with [the `ggplot2` implementation](https://ggplot2-book.org/facet.html#facet-wrap) by defaulting to show axes (with tick marks) for all facets, as well as providing `scales`, `nrow` and `ncol` arguments that the user can use to specify whether the scales should be the same across facets and how many rows or columns to use. It also updates the faceting code to avoid duplicating legend entries when [grouped legends](https://github.com/hail-is/hail/pull/12254) are used, and to disable interactivity accordingly. With this update, running this code:. ```python; import hail as hl; from hail.ggplot import aes, facet_wrap, geom_point, ggplot, vars; ht = hl.utils.range_table(10); ht = ht.annotate(squared=ht.idx ** 2); ht = ht.annotate(even=hl.if_else(ht.idx % 2 == 0, ""yes"", ""no"")); ht = ht.annotate(threeven=hl.if_else(ht.idx % 3 == 0, ""good"", ""bad"")); ht = ht.annotate(fourven=hl.if_else(ht.idx % 4 == 0, ""minor"", ""major"")); fig = (; ggplot(ht, aes(x=ht.idx, y=ht.squared)); + geom_point(aes(shape=ht.even, color=ht.threeven)); + facet_wrap(vars(ht.threeven, ht.fourven), nrow=1); ); fig.show(); ```. Produces the following plot:. <img width=""1283"" alt=""Screen Shot 2022-11-23 at 12 23 21"" src=""https://user-images.githubusercontent.com/84595986/203611376-682b98e7-2915-4e2c-8f1e-ef8c74b12907.png"">",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12497:422,avoid,avoid,422,https://hail.is,https://github.com/hail-is/hail/pull/12497,1,['avoid'],['avoid']
Safety,This change enforces that `String` accepting methods just convert to `URL` and do nothing more. All the logic is now in `URL` accepting methods. I think this is a bit easier to understand. It also avoids the `val url = XXXX.parseUrl(filename)` at the start of every method. I had to remove the type parameter because I would have needed a kind of existential types that I could not easily encode in Scala. I suspect there's a slight speed benefit because anywhere that we work with URLs we can avoid re-parsing them for each method call.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13650:197,avoid,avoids,197,https://hail.is,https://github.com/hail-is/hail/pull/13650,2,['avoid'],"['avoid', 'avoids']"
Safety,"This change exists as part of larger refactoring work. Herein, I've exchanged; hard-coded contextual strings passed to `ExecutionTimer.time` with implict; contexts, drawing inspiration from scalatest. These contexts are now supplied after entering functions like `Compile` and; `Emit` instead of before (see `ExecuteContext.time`). By sprinking calls to ; `time` throughout the codebase after entering functions, we obtain a nice trace; of the timings with `sourcecode.Enclosing`, minus the previous verbosity. See [1] for more information about what pre-built macros are available. We can; always build our own later. See comments in [pull request id] for example output.; Note that `ExectionTimer.time` still accepts a string to support uses like; `Optimise` and `LoweringPass` where those contexts are provided already.; It is also exception-safe now. This change exposed many similarities between the implementations of query; execution across all three backends. I've stopped short of full unification; which is a greater work, I've instead simplified and moved duplicated result; encoding into the various backend api implementations. More interesting changes are to `ExecuteContext`, which now supports; - `time`, as discussed above; - `local`, a generalisation for temporarily overriding properties of an ; `ExecuteContext` (inspired by [2]). While I've long wanted this for testing,; we were doing some questionable things when reporting timings back to python,; for which locally overriding the `timer` of a `ctx` has been very useful.; We also follow this pattern for local regions. [1] https://github.com/com-lihaoyi/sourcecode; [2] https://hackage.haskell.org/package/mtl-2.3.1/docs/Control-Monad-Reader.html#v:local",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14679:845,safe,safe,845,https://hail.is,https://github.com/hail-is/hail/pull/14679,1,['safe'],['safe']
Safety,"This change grew out of https://github.com/hail-is/hail/pull/13674.; The idea is simple - we shouldn't be appending code after control statements as such statements are redundant. That idea opened pandora's box, but now we're not generating and dropping dead code anymore. Main changes that rose form fixing fallout from adding assert in `Block.append`:; - Implement basic control-flow structures (if, while, for, switch) in `CodeBuilderLike` and remove the older implementations from `Code`.; - main difference is these are built from sequencing `Code` operations rather than being defined from LIR; - allows for a higher-level implementation that I think is simpler to read.; - Use the type-system to prevent foot-guns like `cb.ifx(cond, label.goto)`. Other changes:; - rename `ifx`, `forLoop` and `whileLoop` to just `if_`, `for_` and `while_`, respectively.; - Implement loops in-terms of one-another to remove code duplication.; - Fix logic for when to write IRs as some default value behaviour was broken when `HAIL_WRITE_IR_FILES` was set in tests",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13752:169,redund,redundant,169,https://hail.is,https://github.com/hail-is/hail/pull/13752,1,['redund'],['redundant']
Safety,"This change introduces timeouts to `benchmark run`. This makes it easier; to run benchmarks on old versions of Hail, which might have extremely; slow times for certain benchmarks (block matrix multiply, looking at you)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7214:23,timeout,timeouts,23,https://hail.is,https://github.com/hail-is/hail/pull/7214,1,['timeout'],['timeouts']
Safety,"This change is rather small actually. Instead of allocating a JVM-managed `Array[Byte]` we directly allocate memory with `Memory.malloc` which calls into `sun.misc.Unsafe`'s allocation functions. This gives us a non-managed (i.e. non-GC'ed) block of memory. We must free this memory. Regions created by `RVDContext`'s are handled by `ContextRDD`. `ContextRDD` uses Spark's `TaskContext.addTaskCompletionListener` to ensure memory is free'd when the task is finished. By virtue of returning pointers instead of offsets, this change converts every use of offset in the region value world to a use of a pointer. cc: @cseed",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3655:164,Unsafe,Unsafe,164,https://hail.is,https://github.com/hail-is/hail/pull/3655,1,['Unsafe'],['Unsafe']
Safety,This change is to ensure that the SKU we think is associated with a product doesn't change in case the human readable name changes to a different SKU. This was raised as a good safety feature by #13430,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13607:177,safe,safety,177,https://hail.is,https://github.com/hail-is/hail/pull/13607,1,['safe'],['safety']
Safety,"This change removes previous infrastructure for building generated C++; code. The previous infrastructure would write two files, a cpp file and; a makefile, then run make to build the shared object. This change gets rid of all that in favor of a pipe-fork-exec model,; using the ability of clang++/g++ to read from stdin via `-x <LANG>` and; `-` arguments. Some notes:. * We still invoke the shell to find JAVA_HOME if it is not defined. We; do this in a similar way to what we do in the makefiles.; * Because of the odd signatures of the `exec` family of functions, we; use a `const_cast` to discard the appropriate qualifiers. This is safe; because we only do it after forking, and only to exec, and never use; that data after the call to `execvp`.; * We ignore `SIGPIPE`, as it is raised when the process tries to write; to a pipe where the other end is closed. Not doing this could crash; hail, and means that the child process died before we wrote all of the; c++ source to the pipe, other error handling will catch what actually; went wrong, rather than being unable to write to the pipe.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6927:637,safe,safe,637,https://hail.is,https://github.com/hail-is/hail/pull/6927,1,['safe'],['safe']
Safety,"This commit introduces the SCode hierarchy. How are SCodes different; from PCodes? SCodes are what we want PCodes to be. They don't have; the methods `code / tcode`, which gives us a way to implement new; performance-improving types like SStackStruct with well-defined; boundaries around that functionality. Currently, the `asPCode` and `IEmitCode.typecast` methods break this; boundary, and I added these as a short-term mechanism to avoid another; very spicy meatball. This commit is entirely reorganizational, with no semantic changes; to the compiler.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9729:435,avoid,avoid,435,https://hail.is,https://github.com/hail-is/hail/pull/9729,1,['avoid'],['avoid']
Safety,This creates redundant bindings that interfere with our ability to apply certain simplification rules.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7720:13,redund,redundant,13,https://hail.is,https://github.com/hail-is/hail/pull/7720,1,['redund'],['redundant']
Safety,"This exposes functionality previously present in the private `hail.expr.functions._allele_ints` and `hail.expr.functions._num_allele_type`, used to avoid strings in the query when determining allele type. Implement AlleleType as a python [IntEnum]. Replace `_num_allele_type` with the now public `numeric_allele_type`. As a note to developers of hail, it is _unlikely_ that the enum values of AlleleType will change, but they are documented as though they could. CHANGELOG: Exposed previously internal `_num_allele_type` as `numeric_allele_type` and deprecated it. Add new `AlleleType` enumeration for users to be able to easily use the values returned by `numeric_allele_type`. [IntEnum]: https://docs.python.org/3/library/enum.html#enum.IntEnum",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14360:148,avoid,avoid,148,https://hail.is,https://github.com/hail-is/hail/pull/14360,1,['avoid'],['avoid']
Safety,"This gets ld_prune on the `get_1kg` data down to around 37s. That's still ~1000 times slower than plink.; ```; mt = hl.read_matrix_table('repartitioned.mt'); pruned_tbl = hl.ld_prune(mt.GT, r2 = 0.2, bp_window_size = 1000000, memory_per_core = 1000); pruned_tbl.write(""pruned_tbl.ht"", overwrite=True); ```. Performance Wins:; - local ld prune returns an unkeyed, unsorted dataset, and `ld_prune` collects the relatively small number of variants locally instead of trying to do table joins (I'm doing the broadcast join optimization manually); - avoid `key_by` (and thus sort) of output of MIS, again we do a broadcast join; - two unnecessary writes removed (at the cost of no debugging output); - `maximal_independent_set` no longer keys by, thus avoiding a sort. Minor Changes:. - I don't set env vars anymore, so I need an easy way to pip install hail, so I added a gradle task for that and an associated file that does almost the same thing as deploy.sh. you should complain and make me consolidate these two files. ---; ## Big Data Test. I'm running a test on profile225 right now. ---. resolves #4506",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5078:545,avoid,avoid,545,https://hail.is,https://github.com/hail-is/hail/pull/5078,2,['avoid'],"['avoid', 'avoiding']"
Safety,"This is a rebased update to the closed PR #3715. Updates:. - `locus_table` is now `locus_expr`, an expression on a table or matrix table. This is more flexible, and avoids unnatural requirements on key (rather than order). - uses `global_position` and requires/checks ascending order, rather than reordering within the method. Re-ordering, if non-trivial, would silently invalidate the results with respect to the row-order of the source. This also avoids a potentially unnecessary shuffle, and addresses the issue that contig order may not be alphabetical in the reference. - keeps the size of data collected close to the minimal data necessary (in particular, no collection of contigs). When `coord_expr` is not set, its an array of int. When `coord_expr` is set, its an array of (int, float). A tuple of arrays would be better, but directly collecting two arrays in order would require two actions with the current infrastructure since agg.collect() does not preserve order.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3873:165,avoid,avoids,165,https://hail.is,https://github.com/hail-is/hail/pull/3873,2,['avoid'],['avoids']
Safety,"This is a total overhaul of our docker images. Though very verbose, I tried to stick to these main tenets:. - Any docker image has exactly 1 layer in it (all the way down to ubuntu) that installs pip dependencies. This primarily aims to protect the cache for this particularly large layer and also avoids a later layer silently upgrading the version of a dependency installed in an earlier layer. This pairs nicely with the following goal; - We only ever use 1 version of a dependency across the monorepo. Liberal use of pip's [constraint files](https://pip.pypa.io/en/stable/user_guide/#constraints-files) to ensure that the dependencies for a service must be compatible with dependencies from hail. The `install-dev-dependencies` target which install all our pinned requirements files would tell you if there's any incompatible versions of transitive dependencies across the repo; - The image graph is shallow and images don't contain more than they need. In order to have a single layer with requirements and hail code on top, I moved the service images to just be based on hail-ubuntu. This shortens the critical path and therefore reduces total image building time by reducing the number of times our image data needs to be downloaded and re-uploaded to the registry. I also removed a lot of unnecessary cruft like gcloud in places it wasn't used anymore, some unused/unnecessary pip requirements, etc.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12578:298,avoid,avoids,298,https://hail.is,https://github.com/hail-is/hail/pull/12578,1,['avoid'],['avoids']
Safety,This is developer only and helpful primarily in dev deploy.; I think its safe as long as we trust hail devs not to; accidentally hit this endpoint.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8409:73,safe,safe,73,https://hail.is,https://github.com/hail-is/hail/pull/8409,1,['safe'],['safe']
Safety,This is part 1 in mitigating the extra rows in the billing tables with redundant resources with the same prices. I'm not sure how long it takes to drop a table of this size. Would prefer to merge in the morning in case there are any issues.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12710:71,redund,redundant,71,https://hail.is,https://github.com/hail-is/hail/pull/12710,1,['redund'],['redundant']
Safety,"This is runIfRequested deployment that simply has hail; and ipython installed. It facilitates developmnent of; services that interact with Hail Query (i.e. the Shuffler). I do this silly thing with a tar file because:; - I do not know the hail version (which is included in the wheel filename), so; - I am unable to copy it out with a variable name, and; - python refuses to install a wheel that does not have the version in the filename. I added `make update-hail-repl` to `hail/Makefile` which updates the hail wheel on the hail-repo without changing the pod or rebuilding the image. If the pod is restarted you lose your version, but the risk is worth the immense benefit of 5s deploys.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8194:641,risk,risk,641,https://hail.is,https://github.com/hail-is/hail/pull/8194,1,['risk'],['risk']
Safety,This lets us avoid crashes/ooms from rendering 90K intervals thousands of times. Stacked on #10517,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10518:13,avoid,avoid,13,https://hail.is,https://github.com/hail-is/hail/pull/10518,1,['avoid'],['avoid']
Safety,This might avoid command to long errors,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8470:11,avoid,avoid,11,https://hail.is,https://github.com/hail-is/hail/pull/8470,1,['avoid'],['avoid']
Safety,"This moves `self.activate` into a `wait_for` with a timeout. We use a tight try-except; around the activation code to provide a precise error message if activation fails. If activation succeeds, we enter the else branch which operates as before. If activation; times out we do not deactivate. This is OK, we probably did not activate. If we did activate,; batch will eventually find out.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8816:52,timeout,timeout,52,https://hail.is,https://github.com/hail-is/hail/pull/8816,1,['timeout'],['timeout']
Safety,"This overrides each vcf's header with a user provided one, and; overrides the vcfs' samples' names with a user provided list of lists. This is wildly unsafe. I don't like this code. However it seems that it; is the best way to proceed with data production for gnomAD v3. cc @cseed",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6043:150,unsafe,unsafe,150,https://hail.is,https://github.com/hail-is/hail/pull/6043,1,['unsafe'],['unsafe']
Safety,"This prevents decorators like `@rest_authenticated_users_only` from making an additional request to `auth` (which includes a database query for the `userinfo` endpoint) on every API request. I also realized that auth wasn't getting scraped by prometheus so I added the `grafanak8sapp` label to fix that. auth's `userinfo` endpoint should probably also have a cache, but it felt worth it to also implement it this way to avoid constant communication with the auth service from batch.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12122:420,avoid,avoid,420,https://hail.is,https://github.com/hail-is/hail/pull/12122,1,['avoid'],['avoid']
Safety,"This refactors the parser to use `BindingEnv`, which tracks the separate eval, agg, scan, and relational environments. This was motivated by the new randomness work, which needs to be able to rebind row and col references in both eval and agg scopes, which was breaking the parser. I don't like duplicating the (rather complicated) binding behavior of the nodes, but I couldn't find a way to avoid it without a much larger refactoring of the IR. So I tried to make the binding logic in the parser be as direct a copy of what is encoded in `Binds.scala` as possible. For example, relational nodes always pass `env.onlyRelational` to their children, which isn't necessary if we ensure that only relational bindings exist in environments passed to relational nodes, but it matches the logic in `Binds`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12289:392,avoid,avoid,392,https://hail.is,https://github.com/hail-is/hail/pull/12289,1,['avoid'],['avoid']
Safety,"This revamps the `batch.front_end` web pages to be a bit less cluttered and more usable. I brought in tailwindcss instead of using our existing sass. I mainly find it easier to work with but am fine porting it to sass if anyone feels strongly against changing css tools. In order to avoid overhauling all our HTML in one PR, I added a flag to the jinja context `use_tailwind` that is currently only on for the `batch` service. `layout.html` then uses this flag to determine which CSS and header it should use. If this gets to a state we're happy to merge, it should be a lot less work to bring over auth and CI and delete that flag.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14562:283,avoid,avoid,283,https://hail.is,https://github.com/hail-is/hail/pull/14562,1,['avoid'],['avoid']
Safety,This should help us avoid more confusing errors down the line since our workers are all running JDK 8 and cannot use JDK 11+ bytecode.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13734:20,avoid,avoid,20,https://hail.is,https://github.com/hail-is/hail/pull/13734,1,['avoid'],['avoid']
Safety,This should lighten the database load a bit by avoiding a couple joins and a CTE.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12651:47,avoid,avoiding,47,https://hail.is,https://github.com/hail-is/hail/pull/12651,1,['avoid'],['avoiding']
Safety,"This should make computing the loadings better, since it uses a checkpointed variants table instead of accidentally recomputing the incoming MatrixTable. Also made a change to avoid accidentally clobbering a field name if someone had a field named `idx`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10201:176,avoid,avoid,176,https://hail.is,https://github.com/hail-is/hail/pull/10201,1,['avoid'],['avoid']
Safety,"This test:. ```python3; p = Pipeline(backend=BatchBackend('https://batch.hail.is')); for _ in range(30000):; p.new_task().command('/bin/true'); p.run(); ```. Revealed a number of issues:; daniel king: Problems Found:; - [x] https://github.com/hail-is/hail/issues/6543 mysql can deadlock itself, requiring you to reissue the db request; - [x] https://github.com/hail-is/hail/issues/6545 of the 20760 pods that were successfully created before #6543 happened, about 800 could not get their logs due to not existing. That's a failure rate of ~4%. The number of failures continues to grow as I type this message (now up to 1280). I'm counting failures this way:; ```; k logs -l app=batch --tail=999999 | grep 'no logs for ' | sed -E 's/^.*no logs for ([^ ]+).*$/\1/' | sort -u | wc -l; ```; - the k8s request latency spiked to 3.47s max 0.6 s mean during this test and stayed elevated for 10 minutes.; - [ ] https://github.com/hail-is/hail/issues/6546 there was a lot of volume mount failures due to, apparently, the secrets, e.g.:; ```; 9m13s Warning FailedMount Pod Unable to mount volumes for pod ""batch-278-job-10258-a49a81_batch-pods(82ea5910-9ccb-11e9-ad88-42010a800049)"": timeout expired waiting for volumes to attach or mount for pod ""batch-pods""/""batch-278-job-10258-a49a81"". list of unmounted volumes=[gsa-key default-token-8h99c]. list of unattached volumes=[gsa-key default-token-8h99c]; ```; - [ ] https://github.com/hail-is/hail/issues/6548 batch takes 4 seconds to render the batch page with 20k jobs (the web browser displays it fine though), e.g. https://batch.hail.is/batches/278; - [ ] https://github.com/hail-is/hail/issues/6548 batch UI search is DOA with 20k jobs; - [ ] https://github.com/hail-is/hail/issues/6556 delete (and likely cancel) will timeout on large batches",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6547:1175,timeout,timeout,1175,https://hail.is,https://github.com/hail-is/hail/issues/6547,2,['timeout'],['timeout']
Safety,"This was to simplify the bytecode generated for unsafe memory access calls vs Scala objects. If there was an improvement, it was smaller than the benchmark measurement noise. Also added some object+offset variants.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2184:48,unsafe,unsafe,48,https://hail.is,https://github.com/hail-is/hail/pull/2184,1,['unsafe'],['unsafe']
Safety,This will avoid extra requests especially since most batches statuses; will not change (most batches are finished). The new function last_known_status() will make an HTTP request if and; only if the saved status is None.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9510:10,avoid,avoid,10,https://hail.is,https://github.com/hail-is/hail/pull/9510,1,['avoid'],['avoid']
Safety,"This will hopefully make it easier to develop QoB. Now, running `make -C hail install-for-qob NAMESPACE=default` will push a jar and configure hailctl to use that jar. So `make -C hail install-for-qob NAMESPACE=default && ipython` will drop you into an ipython session pointed at production where any hail queries reflects your local code. `make -C hail pytest-qob NAMESPACE=default PYTEST_ARGS='-k test_foo'` runs `test_foo` with any of your current changes. Things to note:; - Variables like `QUERY_STORAGE_URI` are lazy so this should hopefully not break any current usages of the file for non-developers; - You are at no risk of overwriting a release jar unless you specify `UPLOAD_RELEASE_JAR=true` in the make invocation.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12342:625,risk,risk,625,https://hail.is,https://github.com/hail-is/hail/pull/12342,1,['risk'],['risk']
Safety,"Tim, like we discussed, thanks for the suggestion. No login for workshop users, we skip auth0 altogether. Not quite as safe, but probably not a big deal provided https, a long-enough password. . I also removed the image picker, because it's I think more implementation detail than workshop users need (and it's not particularly styled). and uses ibg2019. cc @danking @cseed",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5556:119,safe,safe,119,https://hail.is,https://github.com/hail-is/hail/pull/5556,1,['safe'],['safe']
Safety,"Tim, when I run the following command I get the exception below. ~/hail/build/install/hail/bin/hail import -i ~/t2d/GoT2D.first10k.vcf filtervariants --keep -c ""true"" count. I get the following exception. ""[-80"" is not in the original vcf, so Cotton thinks it may be because htsjdk parses the info, then you converts them back to Strings, and then reparses them, so you might have trouble eating your own output. I'll share the vcf with you. I have no trouble filtering based on sample and interval lists, or doing qc or linreg. ```; Exception in thread ""main"" org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 0.0 failed 1 times, most recent failure: Lost task 1.0 in stage 0.0 (TID 1, localhost): java.lang.NumberFormatException: For input string: ""[-80""; at java.lang.NumberFormatException.forInputString(NumberFormatException.java:65); at java.lang.Integer.parseInt(Integer.java:580); at java.lang.Integer.parseInt(Integer.java:615); at scala.collection.immutable.StringLike$class.toInt(StringLike.scala:272); at scala.collection.immutable.StringOps.toInt(StringOps.scala:30); at org.broadinstitute.hail.methods.AnnotationValueString$$anonfun$toArrayInt$extension$1.apply(Filter.scala:18); at org.broadinstitute.hail.methods.AnnotationValueString$$anonfun$toArrayInt$extension$1.apply(Filter.scala:18); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:245); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:245); at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186); at scala.collection.TraversableLike$class.map(TraversableLike.scala:245); at scala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:186); at org.broadinstitute.hail.methods.AnnotationValueString$.toArrayInt$extension(Filter.scala:18); at __wrapper$1$c1aef7d48806473ea6c7fc7ceb61989c.__wrapper$1$c1aef7d48806473ea6c7fc7ceb61989c$$a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/120:598,abort,aborted,598,https://hail.is,https://github.com/hail-is/hail/issues/120,1,['abort'],['aborted']
Safety,To avoid `pymysql` packet sequence errors on long-running pods. See https://hail.zulipchat.com/#narrow/stream/300487-Hail-Batch-Dev/topic/PyMysql.20packet.20sequence.20errors/near/289668489 for context. #assign services,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12051:3,avoid,avoid,3,https://hail.is,https://github.com/hail-is/hail/pull/12051,1,['avoid'],['avoid']
Safety,"To avoid casting to PStruct (`representation.asInstanceOf[PStruct]`), which requires assumptions about the implementation of the complex type, and which thereby is inconsistent with the use of the abstract class (say PLocus) in the pattern match/argument. . Comes up in:. https://github.com/hail-is/hail/blob/e363f372c5418e0a0cd81ca0360677eaed5f8156/hail/src/main/scala/is/hail/expr/ir/BinarySearch.scala; https://github.com/hail-is/hail/blob/7c2f5fe6c0d066ee49eefc3729749012b66556f5/hail/src/main/scala/is/hail/annotations/UnsafeRow.scala; https://github.com/hail-is/hail/blob/8b2e4d202beaeb6b65d07dabc95355bb71634ba3/hail/src/main/scala/is/hail/expr/types/encoded/EBaseStruct.scala; https://github.com/hail-is/hail/blob/d25d49b34312bcf2180b316349dc723b3e094b4b/hail/src/main/scala/is/hail/expr/ir/functions/LocusFunctions.scala",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7746:3,avoid,avoid,3,https://hail.is,https://github.com/hail-is/hail/issues/7746,2,"['Unsafe', 'avoid']","['UnsafeRow', 'avoid']"
Safety,"To avoid classname serialization overhead, we should register all of our classes that are being serialized, with the most important being those which are RDD elements, until we are able to turn on `conf.set(""spark.kryo.registrationRequired"", ""true"")` without error. This will also catch places where we are serializing far more than we thought. Background here:; https://spark.apache.org/docs/latest/tuning.html#data-serialization. Only a small number of classes are registered by default:; https://github.com/apache/spark/blob/v1.4.0/core/src/main/scala/org/apache/spark/serializer/KryoSerializer.scala#L317. More background in first answer here:; http://stackoverflow.com/questions/31394140/require-kryo-serialization-in-spark-scala",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1022:3,avoid,avoid,3,https://hail.is,https://github.com/hail-is/hail/issues/1022,1,['avoid'],['avoid']
Safety,To avoid having to modify router/router.nginx.conf.in for internal.hail.is routes.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7364:3,avoid,avoid,3,https://hail.is,https://github.com/hail-is/hail/issues/7364,1,['avoid'],['avoid']
Safety,To avoid serializing results between JVM and Python,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4025:3,avoid,avoid,3,https://hail.is,https://github.com/hail-is/hail/issues/4025,1,['avoid'],['avoid']
Safety,To avoid this:. ```sh; + sleep 360; + true; + curl -sSL http://notebook/worker-image; curl: (7) Failed to connect to notebook port 80: Connection refused; ```. Since notebook is not currently running,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6481:3,avoid,avoid,3,https://hail.is,https://github.com/hail-is/hail/pull/6481,1,['avoid'],['avoid']
Safety,"To be merges AFTER jb_mendel_y. Here I have:; 1) added documentation for mendel errors; 2) modified the functions leading to the individual and family files so that the SNP count is recorded in addition to the total count. Talking to analysts, the SNP count is useful for QC because indels are so much more volatile. If analysts will typically want both, it seems better to avoid forcing them to run mendel errors twice (before and after filtering to SNPs). Adding the NSNP column in .imendel and .fmendel breaks the PLINK spec but only very gently: adding one additional (final) column. Once we have a better sense of users needs, we should break it completely to best suit them. I'd feel comfortable breaking up chr:pos:ref:alt into separate columns now if you think the time has come...calling that column SNP is especially confusing given that the variant may be an indel. Next up for mendel will be Issues #94 and #148",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/149:374,avoid,avoid,374,https://hail.is,https://github.com/hail-is/hail/pull/149,1,['avoid'],['avoid']
Safety,"To do this add an intermidiate abstract PartitionWriter,; SimplePartitionWriter, and extend it with TextTablePartitionWriter. SimplePartitionWriter manages the output stream for its subclasses. The; subclasses need to implement consumeElement, and optionally preConsume; and postConsume. TextTablePartitionWriter handles the delimiter delimited writing per; element item and the line delimited writing per element of the stream.; It will also optionally write the header if ExportType.PARALLEL_HEADER_IN_SHARD; has been requested. TextTableFinalizer is the 'MetadataWriter' (name change pending), for; TextTableWriter. That's where the header is written for; PARALLEL_SEPARATE_HEADER and CONCATENATED, and files are merged for; CONCATENATED. There are currently a few idosyncracies that don't replicate bug-for-bug; compatibility with the non-lowered version. 1. We avoid the use of fs.copyMerge, as such, we don't check for the; existence of the _SUCCESS file (even though we create it).; 2. ExportType.PARALLEL_COMPOSABLE is unsupported.; 3. We rely on the temporary file cleaner to clean up the files; created for CONCATENATED export, rather than deleting them; explicitly.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11323:866,avoid,avoid,866,https://hail.is,https://github.com/hail-is/hail/pull/11323,1,['avoid'],['avoid']
Safety,"To properly implement IR sets, I need to staged UnsafeOrdering's, or, at the very least, I need to be able to call them from `Code`-land. Since objects at IR-compile-time are not available at IR-run-time (without shipping them to the nodes and passing them as arguments, which I'd like to avoid), I must be able to call static methods, or have fully code-ified versions of every UnsafeOrdering used in the IR. Whenever possible, I tried to call static methods. In a few cases, I couldn't figure out how to make that work, so I had to reimplement the operation in `Code`. I also had to introduce `BindingCode[T]` which is a type alias for `(FunctionBuilder, StagedBitSet) => Code[T]`. The function builder is used to allocate new variables and the `StagedBitSet` is used to compactly store boolean values. I am also somewhat confused by the `missingGreatest` parameter which existed on the original `UnsafeOrdering`s (which I refactored while Code-ifying). cc: @cseed, I guess this parameter is only sensible on compound data? It seems like there should be a:. ```; def compare(r1: MemoryBuffer, o1: Long, m1: Boolean, r2: MemoryBuffer, o2: Long, m2: Boolean): Int; ```. which correctly applies the `missingGreatest` parameter.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2519:48,Unsafe,UnsafeOrdering,48,https://hail.is,https://github.com/hail-is/hail/pull/2519,4,"['Unsafe', 'avoid']","['UnsafeOrdering', 'avoid']"
Safety,"To replicate, replace the contents of `test_king.py::test_king_small` with:; ```; @fails_local_backend(); def test_king_small():; hl.init(idempotent=True) # Should be no error; hl.stop(); hl.init(idempotent=True) # Should be no error; hl.init(hl.spark_context(), idempotent=True) # Should be no error. plink_path = resource('balding-nichols-1024-variants-4-samples-3-populations'); mt = hl.import_plink(bed=f'{plink_path}.bed',; bim=f'{plink_path}.bim',; fam=f'{plink_path}.fam'); kinship = hl.king(mt.GT); assert_c_king_same_as_hail_king(; resource('balding-nichols-1024-variants-4-samples-3-populations.kin0'),; kinship); ```. Stack trace:; ```; E hail.utils.java.FatalError: IndexOutOfBoundsException: 0; E ; E Java stack trace:; E org.apache.spark.SparkException: Job aborted due to stage failure: Task 7 in stage 18.0 failed 1 times, most recent failure: Lost task 7.0 in stage 18.0 (TID 34, localhost, executor driver): java.lang.IndexOutOfBoundsException: 0; E 	at scala.collection.immutable.NumericRange.apply(NumericRange.scala:112); E 	at is.hail.linalg.BlockMatrixReadRowBlockedRDD$$anonfun$compute$9.apply(BlockMatrix.scala:2131); E 	at is.hail.linalg.BlockMatrixReadRowBlockedRDD$$anonfun$compute$9.apply(BlockMatrix.scala:2127); E 	at is.hail.sparkextras.ContextRDD$$anonfun$cmapPartitionsWithIndex$1$$anonfun$apply$18$$anonfun$apply$19.apply(ContextRDD.scala:259); E 	at is.hail.sparkextras.ContextRDD$$anonfun$cmapPartitionsWithIndex$1$$anonfun$apply$18$$anonfun$apply$19.apply(ContextRDD.scala:259); E 	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:435); E 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:441); E 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409); E 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:439); E 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409); E 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:439); E 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/9867:772,abort,aborted,772,https://hail.is,https://github.com/hail-is/hail/issues/9867,1,['abort'],['aborted']
Safety,"To report a bug, fill in the information below. . hail-0.2.70-4fcd186e31da; -----------------------------------------------------------------------------. After uploading vcfs, merging to mt, qcing and exporting back to vcf, the header was missing the filled out Description field for the FORMAT and INFO header lines. . Originally this.....; ```; ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Allelic depths for the ref and alt alleles in the order listed"">; ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Approximate read depth (reads with MQ=255 or with bad mates are filtered)"">; ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Genotype Quality"">; ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">; ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block"">; ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Normalized, Phred-scaled likelihoods for genotypes as defined in the VCF specification"">; ##FORMAT=<ID=PS,Number=1,Type=Integer,Description=""Phasing set (typically the position of the first variant in the set)"">; ##FORMAT=<ID=RGQ,Number=1,Type=Integer,Description=""Unconditional reference genotype confidence, encoded as a phred quality -10*log10 p(genotype call is wrong)"">; ##FORMAT=<ID=SB,Number=4,Type=Integer,Description=""Per-sample component statistics which comprise the Fisher's Exact Test to detect strand bias."">; ```. head header.norm.qc.txt. ```; ##hailversion=0.2.70-4fcd186e31da; ##FORMAT=<ID=AD,Number=.,Type=Integer,Description="""">; ##FORMAT=<ID=DP,Number=1,Type=Integer,Description="""">; ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description="""">; ##FORMAT=<ID=GT,Number=1,Type=String,Description="""">; ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description="""">; ##FORMAT=<ID=PL,Number=.,Type=Integer,Description="""">; ##FORMAT=<ID=PS,Number=1,Type=Integer,Description="""">; ##FORMAT=<ID=RGQ,Number=1,Type=Integer,Description="""">. ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/11093:1378,detect,detect,1378,https://hail.is,https://github.com/hail-is/hail/issues/11093,1,['detect'],['detect']
Safety,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: http://discuss.hail.is/. -------------------------------------------------------------------------------------------. ### Hail version: devel-63d60cc. ### What you did:. Tried to run ld_prune and pc_relate on 5000 WGS samples. ```; spark-submit --verbose --master yarn --deploy-mode client \; --num-executors 14 \; --executor-cores 6 \; --jars $JAR \; --conf spark.kryo.registrator=is.hail.kryo.HailKryoRegistrator \; --conf ""spark.driver.extraClassPath=$JAR"" \; --conf ""spark.executor.extraClassPath=$JAR"" \; --executor-memory 90G\; --driver-memory 80g\; --conf spark.yarn.executor.memoryOverhead=8000 \; --conf spark.network.timeout=600 \; --conf spark.executor.heartbeatInterval=120\; hc_prune.py; ```. Where hc_prune.py is:. ```; import matplotlib.pyplot as plt; import seaborn. import numpy as np; import pandas as pd; from collections import Counter; from math import log, isnan; from pprint import pprint; # hail; import hail as hl; import hail.expr.aggregators as agg; import hail.expr.functions. hl.init(default_reference='GRCh38'); print(""Read in PASS SNVs""); passed=hl.read_matrix_table('/project/casa/hail.ds/gatk.hc/gcad.5k.snv.vqsr.pass'); print(""Filtering Common Variants""); common=passed.filter_rows(passed.variant_qc.AF > 0.01).persist(); common.write('/project/casa/hail.ds/gatk.hc/gcad.5k.snv.vqsr.pass.common'); print(""Pruning LD Variants""); pruned =hl.ld_prune(common,30,r2=0.1, memory_per_core=2048); pruned.write('/project/casa/hail.ds/gatk.hc/gcad.5k.snv.vqsr.pruned'); print(""Sample 20% of variants for running PC-Relate""); pruned_subsample = pruned.sample_rows(0.2).persist(); print(""Running PC_Relate""); rel = hl.pc_relate(pruned_subsample.GT, 0.01, k=10); rel_df = rel.to_pandas(); rel_df.describe(); pprint(rel_df); rel_df.to_csv('gcad_5k.snv.rel.csv'); ```. ### What went wrong (all error messages here, including the full java stack trace):. Got a memor",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3463:744,timeout,timeout,744,https://hail.is,https://github.com/hail-is/hail/issues/3463,1,['timeout'],['timeout']
Safety,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: http://discuss.hail.is/. -------------------------------------------------------------------------------------------. ### Hail version:; Hail .2, Spark 2.2. ### What you did:; Error when I run one of several methods of MatrixTable (write(), count_rows(), etc). ### What went wrong (all error messages here, including the full java stack trace):; org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 1.0 failed 4 times, most recent failure: Lost task 1.3 in stage 1.0 (TID 23, ip-172-31-66-74.ec2.internal, executor 1): java.io.InvalidClassException: is.hail.expr.types.TInterval; local class incompatible: stream classdesc serialVersionUID = -1783603148272890463, local class serialVersionUID = 7653437602465004618",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4650:500,abort,aborted,500,https://hail.is,https://github.com/hail-is/hail/issues/4650,1,['abort'],['aborted']
Safety,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: http://discuss.hail.is/. -------------------------------------------------------------------------------------------. ### Hail version:; devel-92bbe4b. ### What you did:; I used `join` to combine two VDS. Empty sample schema, different variant schema, no overlapping samples, hardcalls. ### What went wrong (all error messages here, including the full java stack trace):; Got an AssertionError:; ```; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 5.0 failed 20 times, most recent failure: Lost task 0.19 in stage 5.0 (TID 677, mycluster3-w-1.c.ccdg-wgs.internal): java.lang.AssertionError: assertion failed; at scala.Predef$.assert(Predef.scala:156); at is.hail.annotations.Region.loadInt(Region.scala:36); at is.hail.expr.types.TContainer$.loadLength(TContainer.scala:9); at is.hail.expr.types.TContainer.loadLength(TContainer.scala:27); at is.hail.variant.MatrixTable$$anonfun$105$$anonfun$apply$58.apply(MatrixTable.scala:1702); at is.hail.variant.MatrixTable$$anonfun$105$$anonfun$apply$58.apply(MatrixTable.scala:1685); at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); at is.hail.rvd.OrderedRVD$$anonfun$apply$9$$anon$5.next(OrderedRVD.scala:661); at is.hail.rvd.OrderedRVD$$anonfun$apply$9$$anon$5.next(OrderedRVD.scala:655); ```. I can make it work by copying the variant annotation from one VDS to the other before calling `join`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2763:555,abort,aborted,555,https://hail.is,https://github.com/hail-is/hail/issues/2763,1,['abort'],['aborted']
Safety,"To reproduce:. ```; >>> import hail as hl; >>> hl._set_flags(cpp='true'); >>> mt = hl.read_table('gs://gnomad-public/release/2.1/ht/exomes/gnomad.exomes.r2.1.sites.ht'); >>> mt._force_count(); ```. gets:. ```; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x0000000113aae924, pid=29051, tid=0x0000000000004003; #; ```. This is on OSX. Smaller examples work fine with C++ on.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4816:238,detect,detected,238,https://hail.is,https://github.com/hail-is/hail/issues/4816,1,['detect'],['detected']
Safety,"Tried running ; `hail read -i file:///mnt/lustre/bavila/denovo/myrioux3.vep.vds exportvcf -o file:///mnt/lustre/bavila/denovo/myrioux3.vep.vcf`. got the following; ```; hail: info: running: read -i file:///mnt/lustre/bavila/denovo/myrioux3.vep.vds; [Stage 1:======================================================>(255 + 1) / 256]hail: info: running: exportvcf -o file:///mnt/lustre/bavila/denovo/myrioux3.vep.vcf; [Stage 2:=====> (2117 + 256) / 19042]hail: exportvcf: caught exception: org.apache.spark.SparkException: Job aborted due to stage failure: Task 2137 in stage 2.0 failed 4 times, most recent failure: Lost task 2137.3 in stage 2.0 (TID 3028, nid00013.urika.com): java.lang.IllegalArgumentException: Self-suppression not permitted; 	at java.lang.Throwable.addSuppressed(Throwable.java:1043); 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1219); 	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13.apply(PairRDDFunctions.scala:1116); 	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13.apply(PairRDDFunctions.scala:1095); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66); 	at org.apache.spark.scheduler.Task.run(Task.scala:88); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745); ```. Full error and log below:. [error.txt](https://github.com/hail-is/hail/files/652656/error.txt); [hail.log.txt](https://github.com/hail-is/hail/files/652665/hail.log.txt)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1185:523,abort,aborted,523,https://hail.is,https://github.com/hail-is/hail/issues/1185,1,['abort'],['aborted']
Safety,"Tried to load 1kg public VCF using newest version of hail:; ```; tgp = hl.import_vcf('gs://genomics-public-data/1000-genomes-phase-3/vcf-20150220/ALL.chr22.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf'); tgp.describe(); tgp.rows().show(); ```; Getting:; ```; hail.utils.java.FatalError: NoSuchElementException: key not found: GT. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 2.0 failed 20 times, most recent failure: Lost task 0.19 in stage 2.0 (TID 104, pca-w-1.c.daly-ibd.internal, executor 2): is.hail.utils.HailException: ALL.chr22.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf: caught java.util.NoSuchElementException: key not found: GT; offending line: 22	16050075	rs587697622	A	G	100	PASS	AC=1;AF=0.000199681;AN=...; 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:17); 	at is.hail.utils.package$.fatal(package.scala:26); 	at is.hail.utils.Context.wrapException(Context.scala:23); 	at is.hail.io.vcf.LoadVCF$$anonfun$parseLines$1$$anon$1.hasNext(LoadVCF.scala:761); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); 	at scala.collection.Iterator$$anon$1.hasNext(Iterator.scala:1004); 	at is.hail.rvd.OrderedRVD$$anon$2.hasNext(OrderedRVD.scala:413); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$10$$anon$3.hasNext(OrderedRVD.scala:815); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$10$$anon$3.hasNext(OrderedRVD.scala:815); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:389); 	at scal",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3467:403,abort,aborted,403,https://hail.is,https://github.com/hail-is/hail/issues/3467,1,['abort'],['aborted']
Safety,Try to avoid collecting twice in LDMatrix,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2009:7,avoid,avoid,7,https://hail.is,https://github.com/hail-is/hail/issues/2009,1,['avoid'],['avoid']
Safety,"Turns out we didn't support `--dry-run` on `dataproc connect`. I'm not totally satisfied with this, as the command that gets printed out isn't runnable, because it will lack quotes around the `--ssh-flag=-D 1000` part. I tried adding the quotes into the command, thinking it would work but just be redundant, but I couldn't get it to work. I suppose I could have the printing logic go through the list and replace that bit with a quoted version. Let me know what you think.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7128:298,redund,redundant,298,https://hail.is,https://github.com/hail-is/hail/pull/7128,1,['redund'],['redundant']
Safety,"Typically, a CSRF attack can occur when `evil.com` tricks a user into requesting a state-changing URL at `batch.hail.is`. We use CSRF tokens to protect against such attacks, but there is an additional defense-in-depth cookie attribute that we can use called [SameSite](https://cheatsheetseries.owasp.org/cheatsheets/Cross-Site_Request_Forgery_Prevention_Cheat_Sheet.html#samesite-cookie-attribute). The possible values for this attribute are:. - None => browser always sends this cookie in cross-site requests; - Strict => browser never sends this cookie in cross-site requests; - Lax => browser only sends this cookie in cross-site requests that use ""safe"" HTTP methods (GET, HEAD, OPTIONS). Both Lax and Strict protect against the most primitive forms of CSRF (a form on evil.com submitting a POST to batch.hail.is). Lax seems very reasonable, and still allows linking to, say, linking to jobs from Zulip's web app without the user needing to log in once they get there. Worth noting that this does not protect against [all forms of CSRF](https://datatracker.ietf.org/doc/html/draft-ietf-httpbis-rfc6265bis-02#section-5.3.7.1) attacks, so this does not replace CSRF tokens, just provides additional defense-in-depth.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13631:652,safe,safe,652,https://hail.is,https://github.com/hail-is/hail/pull/13631,1,['safe'],['safe']
Safety,"Unfortunately, as far as I can tell, swagger-codgen providss no way; to set a default timeout. Instead, I littered our code with explicit; timeout arguments to k8s API calls. The best documentation of this feature of swagger-codegen that I have; found is the PR that adds the feature:; https://github.com/swagger-api/swagger-codegen/pull/4173. cc: @cseed, we should do this any time we add new k8s API calls.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4811:86,timeout,timeout,86,https://hail.is,https://github.com/hail-is/hail/pull/4811,2,['timeout'],['timeout']
Safety,Unnecessarily specific (and crashes on UnsafeRow).,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2289:39,Unsafe,UnsafeRow,39,https://hail.is,https://github.com/hail-is/hail/pull/2289,1,['Unsafe'],['UnsafeRow']
Safety,Unsafe row,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1893:0,Unsafe,Unsafe,0,https://hail.is,https://github.com/hail-is/hail/pull/1893,1,['Unsafe'],['Unsafe']
Safety,"Until we have a mechanism to infer the correct timeout based on network conditions, this provides an escape hatch for users on flaky network connections such as wifi.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14206:47,timeout,timeout,47,https://hail.is,https://github.com/hail-is/hail/pull/14206,1,['timeout'],['timeout']
Safety,"Updates the requirements on [google-cloud-storage](https://github.com/googleapis/python-storage) to permit the latest version.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/googleapis/python-storage/releases"">google-cloud-storage's releases</a>.</em></p>; <blockquote>; <h2>v2.1.0</h2>; <h2><a href=""https://github.com/googleapis/python-storage/compare/v2.0.0...v2.1.0"">2.1.0</a> (2022-01-19)</h2>; <h3>Features</h3>; <ul>; <li>add turbo replication support and samples (<a href=""https://github-redirect.dependabot.com/googleapis/python-storage/issues/622"">#622</a>) (<a href=""https://github.com/googleapis/python-storage/commit/4dafc815470480ce9de7f0357e331d3fbd0ae9b7"">4dafc81</a>)</li>; <li>avoid authentication with storage emulator (<a href=""https://github-redirect.dependabot.com/googleapis/python-storage/issues/679"">#679</a>) (<a href=""https://github.com/googleapis/python-storage/commit/8789afaaa1b2bd6f03fae72e3d87ce004ec10129"">8789afa</a>)</li>; <li>remove python 3.6 support (<a href=""https://github-redirect.dependabot.com/googleapis/python-storage/issues/689"">#689</a>) (<a href=""https://github.com/googleapis/python-storage/commit/8aa4130ee068a1922161c8ca54a53a4a51d65ce0"">8aa4130</a>)</li>; </ul>; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/googleapis/python-storage/blob/main/CHANGELOG.md"">google-cloud-storage's changelog</a>.</em></p>; <blockquote>; <h2><a href=""https://github.com/googleapis/python-storage/compare/v2.0.0...v2.1.0"">2.1.0</a> (2022-01-19)</h2>; <h3>Features</h3>; <ul>; <li>add turbo replication support and samples (<a href=""https://github-redirect.dependabot.com/googleapis/python-storage/issues/622"">#622</a>) (<a href=""https://github.com/googleapis/python-storage/commit/4dafc815470480ce9de7f0357e331d3fbd0ae9b7"">4dafc81</a>)</li>; <li>avoid authentication with storage emulator (<a href=""https://github-redirect.dependabot.com/googleapis/p",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11520:742,avoid,avoid,742,https://hail.is,https://github.com/hail-is/hail/pull/11520,1,['avoid'],['avoid']
Safety,Use generative adversarial neural nets** to predict what the user meant to type,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2735:44,predict,predict,44,https://hail.is,https://github.com/hail-is/hail/pull/2735,1,['predict'],['predict']
Safety,Use in MatrixMapRows to avoid region value allocations.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3523:24,avoid,avoid,24,https://hail.is,https://github.com/hail-is/hail/pull/3523,1,['avoid'],['avoid']
Safety,"Uses method in line with PStruct, PTuple rewrite to avoid unimplemented def, at the cost of more lines of code.; * lazy in line with PStruct and PTuple fundamentalTypes, and also it doesn't seem right to have more than one fundamental type for a single instance of the class.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7751:52,avoid,avoid,52,https://hail.is,https://github.com/hail-is/hail/pull/7751,1,['avoid'],['avoid']
Safety,VCFCodec.parseVCFLine(AbstractVCFCodec.java:336); 	at htsjdk.variant.vcf.AbstractVCFCodec.decodeLine(AbstractVCFCodec.java:279); 	at htsjdk.variant.vcf.AbstractVCFCodec.decode(AbstractVCFCodec.java:257); 	at is.hail.io.vcf.LoadVCF$$anonfun$13.apply(LoadVCF.scala:850); 	at is.hail.io.vcf.LoadVCF$$anonfun$13.apply(LoadVCF.scala:849); 	at is.hail.io.vcf.LoadVCF$$anonfun$parseLines$1$$anon$1.hasNext(LoadVCF.scala:718); 	... 17 more. Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1658); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2022); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2043); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3015:3191,abort,abortStage,3191,https://hail.is,https://github.com/hail-is/hail/issues/3015,1,['abort'],['abortStage']
Safety,"VDS.write(VariantSampleMatrix.scala:1073); 	at org.broadinstitute.hail.driver.Write$.run(Write.scala:35); 	at org.broadinstitute.hail.driver.Write$.run(Write.scala:6); 	at org.broadinstitute.hail.driver.Command.runCommand(Command.scala:259); 	at org.broadinstitute.hail.driver.Command.run(Command.scala:264); 	at sun.reflect.GeneratedMethodAccessor54.invoke(Unknown Source); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:280); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:214); 	at java.lang.Thread.run(Thread.java:745); Caused by: org.apache.spark.SparkException: Job aborted due to stage failure: Task 35 in stage 7.0 failed 20 times, most recent failure: Lost task 35.19 in stage 7.0 (TID 6963, gnomad-prod-sw-m8lk.c.broad-mpg-gnomad.internal): org.apache.spark.SparkException: Task failed while writing rows; 	at org.apache.spark.sql.execution.datasources.DefaultWriterContainer.writeRows(WriterContainer.scala:261); 	at org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand$$anonfun$run$1$$anonfun$apply$mcV$sp$1.apply(InsertIntoHadoopFsRelationCommand.scala:143); 	at org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand$$anonfun$run$1$$anonfun$apply$mcV$sp$1.apply(InsertIntoHadoopFsRelationCommand.scala:143); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); 	at org.apache.spark.scheduler.Task.run(Task.scala:86); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.Thread",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1202:3871,abort,aborted,3871,https://hail.is,https://github.com/hail-is/hail/issues/1202,1,['abort'],['aborted']
Safety,"We already statically know the return type of a given expression in Python (without needing to consult the function registry), so there's no need to ask our function registry to re-derive that information. The change here adds a return type field to all of our Apply nodes, and changes the function registry to unify over `argTypes :+ retType` when looking up the correct function without attempting to infer what the return type needs to be. This will allow us to avoid registering a set of LocusFunctions and LiftoverFunctions per reference genome/liftover, since the return type does not need to be inferred and we can just treat them as any other function with type-specific information. This actually probably means we can remove all of the predefined functions from the (python) function registry, and just reserve that for user-defined functions. I haven't done that here for the sake of keeping this change pretty minimal, but I think it would be a reasonable thing to do.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6941:465,avoid,avoid,465,https://hail.is,https://github.com/hail-is/hail/pull/6941,1,['avoid'],['avoid']
Safety,"We always ensure that `cleanup` is run, but in order to ensure that `post_job_complete` is run we need to ensure we get through any computation in cleanup and `mark_complete` that could potentially hang. So we add timeouts to any yield points in those functions and broadly catch exceptions so we always continue in the cleanup/mark_complete process regardless of failure.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12944:214,timeout,timeouts,214,https://hail.is,https://github.com/hail-is/hail/pull/12944,1,['timeout'],['timeouts']
Safety,We can directly download the key and specify the repository. I used these instructions:; - https://wiki.debian.org/DebianRepository/UseThirdParty; - https://launchpad.net/~deadsnakes/+archive/ubuntu/ppa. This builds in like 2 minutes rather than 4. The frontend part avoids issues in downstream docker files where the installer might try to interact with the user. I noticed that some package was updated and now pulls in `tzdata` which asks you to select a timezone at install-time (if Debian frontend is interactive).,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10356:267,avoid,avoids,267,https://hail.is,https://github.com/hail-is/hail/pull/10356,1,['avoid'],['avoids']
Safety,"We currently have several hail sparse matrix tables that contain up to 10,000 aggregated gVCF files that we aggregated using run_combiner(). We are trying to merge these tables together with a script that makes use of your combine_gvcfs function that is defined in your experimental vcf combiner library. We have successfully succeeded in doing this for merging multiple sparse matrix table into a final table of around 18,000 gVCFs. We are now trying to do this for just under 110,00 gVCFs. The script runs for a while and seems to fail at the very end. Based on the logs, it looks like it is writing to output when it fails. We monitored our resources on google cloud and there is not an issue with cluster CPU or memory usage. We believe the problem stems from not having enough memory in the individual executors at this stage. We are currently using the default of:. spark.executor.memory=10117m; spark.executor.memoryOverhead=15175m. We would like to scale this up and re-run. Do you have any recommended settings for a job of this size?. For reference, below is the error message that we received. Thank you in advance.; ````; Hail version: 0.2.81-edeb70bc789c; Error summary: SparkException: Job aborted due to stage failure: Task 2476 in stage 0.0 failed 20 times, most recent failure: Lost task 2476.20 in stage 0.0 (TID 6571) (<clusterinfo>.internal executor 1128): ExecutorLostFailure (executor 1128 exited caused by one of the running tasks) Reason: Container from a bad node: container_1659731953912_0002_01_001691 on host: cluster-himem-w-0.c.gbsc-gcp-project.internal. Exit status: 143. Diagnostics: [2022-08-10 20:11:38.904]Container killed on request. Exit code is 143; [2022-08-10 20:11:38.904]Container exited with a non-zero exit code 143. ; [2022-08-10 20:11:38.905]Killed by external signal-; ````",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12083:1204,abort,aborted,1204,https://hail.is,https://github.com/hail-is/hail/issues/12083,1,['abort'],['aborted']
Safety,"We do not make guarantees about the exact contents of a folder after; a parallel export. We do guarantee that all data is in the folder; however, so we must make it speculation safe. We do so by adding a UUID; to each part file we write for in lowered text export.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11910:177,safe,safe,177,https://hail.is,https://github.com/hail-is/hail/pull/11910,1,['safe'],['safe']
Safety,"We generate these a lot as intermediates when we manually build service images. I think it should be pretty safe to ignore all of these, since I don't know of anything we need to check in with that extension.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9526:108,safe,safe,108,https://hail.is,https://github.com/hail-is/hail/pull/9526,1,['safe'],['safe']
Safety,We get a lot of errors about files that already exist. Hail commands are usually not retryable because there are file paths that might have been partly written to. This tightly scopes the retries to just the I/O. It also avoids keeping the output stream open for a long period of time.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13152:221,avoid,avoids,221,https://hail.is,https://github.com/hail-is/hail/pull/13152,1,['avoid'],['avoids']
Safety,"We had a couple PRs fail because the database reached its [max connections](https://portal.azure.com/#@haildev.onmicrosoft.com/resource/subscriptions/22cd45fe-f996-4c51-af67-ef329d977519/resourceGroups/haildev/providers/Microsoft.DBforMySQL/servers/db-393222c4/metrics). We should probably be resilient to this, but I figured we should be able to handle our normal PR load. I also checked GCP and their default is 4k. Azure sets its cap at 1250. I haven't applied any terraform since you've made your changes. Is that safe to do?",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11329:518,safe,safe,518,https://hail.is,https://github.com/hail-is/hail/pull/11329,1,['safe'],['safe']
Safety,"We have long had trouble with copying on flaky Internet connections. AFAIK, this is due to our very aggressive timeouts. This change permits the CLI to override the default timeout in `hailtop.aiotools.copy`. Setting this back to 600s should work on most flaky Internet connections. It works on my particularly bad home WiFi. The upload-docs target was old and broken so I deleted it. I did not change the upload-artifacts target because that is Google Cloud specific anyway. Main benefit is that these targets work in Azure now.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14138:111,timeout,timeouts,111,https://hail.is,https://github.com/hail-is/hail/pull/14138,2,['timeout'],"['timeout', 'timeouts']"
Safety,"We should probably make batch faster, but a quicker fix is to figure out what the timeout is set to 5 seconds and raise it. The default batch client timeout is 60 seconds. We should probably not send all the logs in response to list_jobs.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5519:82,timeout,timeout,82,https://hail.is,https://github.com/hail-is/hail/issues/5519,2,['timeout'],['timeout']
Safety,"We should use __init__ to initialize variables to avoid duplication. This requires changing the init methods to not do any work and have static methods that do the database calls, construct pods, etc.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5944:50,avoid,avoid,50,https://hail.is,https://github.com/hail-is/hail/issues/5944,1,['avoid'],['avoid']
Safety,"We use Q twice if someone wants to compute the loadings, so we want to save it to avoid redoing full QR.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10223:82,avoid,avoid,82,https://hail.is,https://github.com/hail-is/hail/pull/10223,1,['avoid'],['avoid']
Safety,"We use a readiness probe with a generous timeout to ensure the browser; loads the relevant files into a cache before any users see the website. This; slows deployment because we wait about 30s before sending any user traffic (in; the meantime, users will see 502s). On the bright side, after start-up, users will; always have a face experience, even if the pod was restarted since someone last; visited the site. I also codified some of the file update steps and clarified the README wrt Duncan's; GitHub repo.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8899:41,timeout,timeout,41,https://hail.is,https://github.com/hail-is/hail/pull/8899,1,['timeout'],['timeout']
Safety,"We're currently emitting the explicit node (without optimization!).; This design is incrementally better, and lets us do ptyping more easily. The right solution is to do generate a method as the node suggests, but; there are some issues to sort out here, like how to return a missing; value. We may need to return a (possibly null) pointer to an allocated; value, which could be inefficient. Pushing ptypes/requiredness fully; through the system would let us avoid this in many cases. Stacked on #8084, don't review until that goes in.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8085:459,avoid,avoid,459,https://hail.is,https://github.com/hail-is/hail/pull/8085,1,['avoid'],['avoid']
Safety,"We're currently emitting the explicit node (without optimization!).; This design is incrementally better, and lets us do ptyping more easily. The right solution is to do generate a method as the node suggests, but; there are some issues to sort out here, like how to return a missing; value. We may need to return a (possibly null) pointer to an allocated; value, which could be inefficient. Pushing ptypes/requiredness fully; through the system would let us avoid this in many cases. cc @catoverdrive",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8067:459,avoid,avoid,459,https://hail.is,https://github.com/hail-is/hail/pull/8067,1,['avoid'],['avoid']
Safety,"We've had to do a redeploy of our hail batch instance on Azure. This PR resolves/clarifies two issues we encountered. 1) Storage Account Name Uniqueness. Due to Azure's restrictions on storage account naming (mainly that names must be globally unique) the redeploy did not succeed. This is because the resource group name (we chose to reuse hail) is possible under a new subscription, but the generated storage account names were therefore identical to our previous stack. I've added in an argument called `storage_account_suffix` to account for this issue. It can be set to any arbitrary string that complies with Azure's storage account naming scheme in order to avoid naming conflicts in the future. While the option remains to simply choose a novel resource group name this is not enforced by Azure and anyone deploying a stack similarly named to someone else would not know until the `terraform apply` stage that the name would not work. 2) Mysql Flexible Server Zones. The only other issue is that the zone argument for the mysql flexible server is no longer always valid depending on your compute region. We needed to comment it out for a successful deploy in Australia East. The comment that has been added we hope will be helpful for others in future.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13058:665,avoid,avoid,665,https://hail.is,https://github.com/hail-is/hail/pull/13058,1,['avoid'],['avoid']
Safety,What might be the issue as I had an error reported while running:. hail importvcf /user/jkoskela/ibd/vcf/v30_ibd_exomes.vcf.bgz splitmulti \. > write -o /user/jkoskela/ibd/hail/v30_split_ibd.vds; > hail: info: running: importvcf /user/jkoskela/ibd/vcf/v30_ibd_exomes.vcf.bgz; > [Stage 0:====================================================>(4569 + 1) / 4570]hail: info: Coerced sorted dataset; > hail: info: running: splitmulti; > hail: info: running: write -o /user/jkoskela/ibd/hail/v30_split_ibd.vds; > [Stage 2:> (0 + 162) / 4570]hail: write: caught exception: org.apache.spark.SparkException: Job aborted. Log can be found in:. /humgen/atgu1/fs03/jkoskela/hail.log,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/913:602,abort,aborted,602,https://hail.is,https://github.com/hail-is/hail/issues/913,1,['abort'],['aborted']
Safety,"When a batch is closed the DAG is complete and we do not permit any new jobs to be added. This permits us to safely clean up any job garbage when a job's children are finished. (We don't do any of that right now, but this is necessary for that).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5232:109,safe,safely,109,https://hail.is,https://github.com/hail-is/hail/pull/5232,1,['safe'],['safely']
Safety,"While running mendel_errors:; ```; hail.utils.java.FatalError: ClassCastException: is.hail.codegen.generated.C71 cannot be cast to is.hail.asm4s.AsmFunction7. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 143 in stage 13.0 failed 20 times, most recent failure: Lost task 143.19 in stage 13.0 (TID 4198, exomes2-sw-k2p2.c.broad-mpg-gnomad.internal, executor 212): java.lang.ClassCastException: is.hail.codegen.generated.C71 cannot be cast to is.hail.asm4s.AsmFunction7; 	at is.hail.expr.MatrixFilterEntries$$anonfun$54.apply(Relational.scala:1752); 	at is.hail.expr.MatrixFilterEntries$$anonfun$54.apply(Relational.scala:1750); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:797); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:797); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); [...]; 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); 	at org.apache.spark.rdd.RDD.withScope(RDD.scala:362); 	at org.apache.spark.rdd.RDD.collect(RDD.scala:935); 	at is.hail.sparkextras.ContextRDD.collect(ContextRDD.scala:132); 	at is.hail.rvd.OrderedRVD$.getPartitionKeyInfo(OrderedRVD.scala:478); 	at is.hail.rvd.OrderedRVD$.getPartitionKeyInfo(OrderedRVD.scala:488); 	at is.hail.rvd.OrderedRVD$.coerce(OrderedRVD.scala:556); 	at is.hail.rvd.OrderedRVD$.coerce(OrderedRVD.scala:514); 	at is.hail.table.Table.toOrderedRVD(Table.scala:1152); 	at is.hail.table.Table.distinctByKey(Table.scala:540); 	at sun.reflect.Nati",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3446:215,abort,aborted,215,https://hail.is,https://github.com/hail-is/hail/issues/3446,1,['abort'],['aborted']
Safety,"Will merge cleanly when https://github.com/hail-is/hail/pull/3560 lands. I needed to remove `RegionValue.copy` and `Region.copy` because they necessarily create regions that aren't managed by an `RVDContext`. `RegionValue.copy` is only used in three places. . - `Table.toMatrixTable`: Here, I took the somewhat inefficient choice of creating `SafeRow`s. If `toMatrixTable` is a performance bottleneck, we might want to reconsider this. It's not totally obvious how to do this. I think I'd need to explicitly serialize/deserialize these values and modify `reduceByKey` to explicitly provide the `RVDContext`. Anyway, this works and I don't think it's _that_ slow. (I guess I should check that). - `OrderedRVD.localKeySort` & `LocalLDPrune.pruneLocal`: in both cases we need keep a handful of region values around per-partition. This does not lend itself to region-based-allocation. I solve this with two copies and a fresh region per value. Putting a value into `localKeySort`'s queue requires copying it into a fresh region. Taking a value out of the queue requires copying it into the consumer's region and closing/freeing the region it was living in. There fresh region is alive as long as the value is in the queue. I had to modify `RVDContext` to track `Region`s that get closed early. This seems a bit inefficient. Maybe I should track children as a `Set`?. cc: @cseed",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3579:343,Safe,SafeRow,343,https://hail.is,https://github.com/hail-is/hail/pull/3579,1,['Safe'],['SafeRow']
Safety,"Working on the safe memory allocator that checks if we are accessing invalid memory, it's catching this 0 pointer. . There are already tests that hit `TableWriter`, and this should result in no functionality change.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8970:15,safe,safe,15,https://hail.is,https://github.com/hail-is/hail/pull/8970,1,['safe'],['safe']
Safety,"Works pretty much like Read/Write, except serializes to/from a fixed number of byte array slots on the function object. Not *super* happy with this design, but I'm using it in the new TableMapRows implementation to avoid reading/writing all the aggregations to a file. (Broken out from #6580)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6646:215,avoid,avoid,215,https://hail.is,https://github.com/hail-is/hail/pull/6646,1,['avoid'],['avoid']
Safety,"Yet Another Terraform Refactoring PR, this creates two simple modules:; - A gcs_bucket module to remove the redundancy of resources that we have across the batch-logs, query and test bucket; - A ukbb module which sets up the ukbb k8s resources. While this technically would allow us to reuse this, say in azure, it's more an attempt to tease it apart from the google-specific infrastructure so that we wouldn't have to. In short, it would be nice to organize things such that deploying hail with or without the ukbb site is as simple as choosing to include or omit a terraform module.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10842:108,redund,redundancy,108,https://hail.is,https://github.com/hail-is/hail/pull/10842,1,['redund'],['redundancy']
Safety,[DB] Remove redundant f-strings and validate ints,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14669:12,redund,redundant,12,https://hail.is,https://github.com/hail-is/hail/pull/14669,1,['redund'],['redundant']
Safety,[WIP] Fix billing tables with redundant billing information,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12715:30,redund,redundant,30,https://hail.is,https://github.com/hail-is/hail/pull/12715,1,['redund'],['redundant']
Safety,[auth] avoid redirect loop on failed login,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12401:7,avoid,avoid,7,https://hail.is,https://github.com/hail-is/hail/pull/12401,1,['avoid'],['avoid']
Safety,[auth] give some more cpu to avoid scaling thrashing,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10104:29,avoid,avoid,29,https://hail.is,https://github.com/hail-is/hail/pull/10104,1,['avoid'],['avoid']
Safety,[azure] Add connection timeouts for Azure FS in both Python and Scala,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13344:23,timeout,timeouts,23,https://hail.is,https://github.com/hail-is/hail/pull/13344,1,['timeout'],['timeouts']
Safety,"[batch,ci] Add timeout parameter",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8160:15,timeout,timeout,15,https://hail.is,https://github.com/hail-is/hail/pull/8160,1,['timeout'],['timeout']
Safety,"[batch2] prefer native aiohttp interface to abort, jsonify",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7212:44,abort,abort,44,https://hail.is,https://github.com/hail-is/hail/pull/7212,1,['abort'],['abort']
Safety,[batch] Add pool_recycle parameter to database creation to avoid stale connections,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12051:59,avoid,avoid,59,https://hail.is,https://github.com/hail-is/hail/pull/12051,1,['avoid'],['avoid']
Safety,[batch] Add timeout to test_hail_services_java,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10098:12,timeout,timeout,12,https://hail.is,https://github.com/hail-is/hail/pull/10098,1,['timeout'],['timeout']
Safety,[batch] Add timeouts to ensure that post_job_complete is reached,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12944:12,timeout,timeouts,12,https://hail.is,https://github.com/hail-is/hail/pull/12944,1,['timeout'],['timeouts']
Safety,[batch] Avoid CI deadlocks based on zone,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10511:8,Avoid,Avoid,8,https://hail.is,https://github.com/hail-is/hail/pull/10511,1,['Avoid'],['Avoid']
Safety,[batch] Avoid calling add_attempt_resources in MJC if MJS succeeded,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12461:8,Avoid,Avoid,8,https://hail.is,https://github.com/hail-is/hail/pull/12461,1,['Avoid'],['Avoid']
Safety,[batch] Avoid computing billing project cost when not needed,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13210:8,Avoid,Avoid,8,https://hail.is,https://github.com/hail-is/hail/pull/13210,1,['Avoid'],['Avoid']
Safety,[batch] Cache tokens for job bunches on the driver to avoid db queries,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12023:54,avoid,avoid,54,https://hail.is,https://github.com/hail-is/hail/pull/12023,1,['avoid'],['avoid']
Safety,[batch] Delay waiting on batch completion to avoid unnecessary requests,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13181:45,avoid,avoid,45,https://hail.is,https://github.com/hail-is/hail/pull/13181,1,['avoid'],['avoid']
Safety,[batch] Increase timeout for disk wait operation,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10652:17,timeout,timeout,17,https://hail.is,https://github.com/hail-is/hail/pull/10652,1,['timeout'],['timeout']
Safety,[batch] Mitigate test failures by extending batch client timeout,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12709:57,timeout,timeout,57,https://hail.is,https://github.com/hail-is/hail/pull/12709,1,['timeout'],['timeout']
Safety,[batch] Reduce redundant SQL queries for mark_healthy,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11889:15,redund,redundant,15,https://hail.is,https://github.com/hail-is/hail/pull/11889,1,['redund'],['redundant']
Safety,[batch] Remove redundant env variable for internal gateway ip,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12005:15,redund,redundant,15,https://hail.is,https://github.com/hail-is/hail/pull/12005,1,['redund'],['redundant']
Safety,[batch] Up network allocation timeout to a minute,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13412:30,timeout,timeout,30,https://hail.is,https://github.com/hail-is/hail/pull/13412,1,['timeout'],['timeout']
Safety,[batch] Update docker client timeout transient error message,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11942:29,timeout,timeout,29,https://hail.is,https://github.com/hail-is/hail/pull/11942,1,['timeout'],['timeout']
Safety,[batch] Use a timeout for iptables instead of failing on contention,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10641:14,timeout,timeout,14,https://hail.is,https://github.com/hail-is/hail/pull/10641,1,['timeout'],['timeout']
Safety,[batch] Use code prefixes to detect vm states,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11393:29,detect,detect,29,https://hail.is,https://github.com/hail-is/hail/pull/11393,1,['detect'],['detect']
Safety,[batch] add bpe test for calling result after a timeout,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10760:48,timeout,timeout,48,https://hail.is,https://github.com/hail-is/hail/pull/10760,1,['timeout'],['timeout']
Safety,[batch] adjust Hail's cost structure to recover operating expenses,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13526:40,recover,recover,40,https://hail.is,https://github.com/hail-is/hail/issues/13526,1,['recover'],['recover']
Safety,[batch] avoid unnecessary locks,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10367:8,avoid,avoid,8,https://hail.is,https://github.com/hail-is/hail/pull/10367,1,['avoid'],['avoid']
Safety,[batch] avoid use of metadata server in regenie tests,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9390:8,avoid,avoid,8,https://hail.is,https://github.com/hail-is/hail/pull/9390,1,['avoid'],['avoid']
Safety,[batch] back off gpu timeout to 10 minutes,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13739:21,timeout,timeout,21,https://hail.is,https://github.com/hail-is/hail/pull/13739,1,['timeout'],['timeout']
Safety,[batch] downgrade gcsfuse to avoid gcsfuse bug,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12749:29,avoid,avoid,29,https://hail.is,https://github.com/hail-is/hail/pull/12749,1,['avoid'],['avoid']
Safety,[batch] fix scheduler -- schedule job timeout 1sec,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8022:38,timeout,timeout,38,https://hail.is,https://github.com/hail-is/hail/pull/8022,1,['timeout'],['timeout']
Safety,[batch] fix worker activate timeout,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8842:28,timeout,timeout,28,https://hail.is,https://github.com/hail-is/hail/pull/8842,1,['timeout'],['timeout']
Safety,[batch] make cpu and mem resource readers similar and avoid race,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13879:54,avoid,avoid,54,https://hail.is,https://github.com/hail-is/hail/pull/13879,1,['avoid'],['avoid']
Safety,[batch] make docker calls idempotent with a timeout,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8049:44,timeout,timeout,44,https://hail.is,https://github.com/hail-is/hail/pull/8049,1,['timeout'],['timeout']
Safety,[batch] remove redundant super class,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13541:15,redund,redundant,15,https://hail.is,https://github.com/hail-is/hail/pull/13541,1,['redund'],['redundant']
Safety,[batch] require YARL <1.6.0 which avoids bug,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9518:34,avoid,avoids,34,https://hail.is,https://github.com/hail-is/hail/pull/9518,1,['avoid'],['avoids']
Safety,[batch] shorten worker timeout,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7972:23,timeout,timeout,23,https://hail.is,https://github.com/hail-is/hail/pull/7972,1,['timeout'],['timeout']
Safety,[batch] timeout for worker activation,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8816:8,timeout,timeout,8,https://hail.is,https://github.com/hail-is/hail/pull/8816,1,['timeout'],['timeout']
Safety,[batch] timeouts,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5233:8,timeout,timeouts,8,https://hail.is,https://github.com/hail-is/hail/pull/5233,1,['timeout'],['timeouts']
Safety,[batch] upload logs after timeout occurs in worker,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8280:26,timeout,timeout,26,https://hail.is,https://github.com/hail-is/hail/pull/8280,1,['timeout'],['timeout']
Safety,[batch] use marketplace.gcr.io Ubuntu image to avoid Docker Hub rate limits warning,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9753:47,avoid,avoid,47,https://hail.is,https://github.com/hail-is/hail/pull/9753,1,['avoid'],['avoid']
Safety,[batch] use safe load in batch client,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5825:12,safe,safe,12,https://hail.is,https://github.com/hail-is/hail/pull/5825,1,['safe'],['safe']
Safety,[batch][azure] increase timeout for Azure,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12473:24,timeout,timeout,24,https://hail.is,https://github.com/hail-is/hail/pull/12473,1,['timeout'],['timeout']
Safety,[batch][azure] increase timeout for list deployments,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12472:24,timeout,timeout,24,https://hail.is,https://github.com/hail-is/hail/pull/12472,1,['timeout'],['timeout']
Safety,[batch][notebook] Ubiqutous use of timeouts,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4811:35,timeout,timeouts,35,https://hail.is,https://github.com/hail-is/hail/pull/4811,1,['timeout'],['timeouts']
Safety,[benchmark] Add timeout functionality.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7214:16,timeout,timeout,16,https://hail.is,https://github.com/hail-is/hail/pull/7214,1,['timeout'],['timeout']
Safety,[benchmark] Fix `make_ndarray_bench` to avoid optimizations that obvi…,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10717:40,avoid,avoid,40,https://hail.is,https://github.com/hail-is/hail/pull/10717,1,['avoid'],['avoid']
Safety,[build.yaml] Add timeout for cancel running batches step,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12054:17,timeout,timeout,17,https://hail.is,https://github.com/hail-is/hail/pull/12054,1,['timeout'],['timeout']
Safety,[build.yaml] cancel all running test batches after tests timeout/complete,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11679:57,timeout,timeout,57,https://hail.is,https://github.com/hail-is/hail/pull/11679,1,['timeout'],['timeout']
Safety,"[build] Add timeouts to test_{ci,batch,pipeline,dbuf}",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8164:12,timeout,timeouts,12,https://hail.is,https://github.com/hail-is/hail/pull/8164,1,['timeout'],['timeouts']
Safety,[build] rewrite kubectl secret copying to avoid deprecated --export flag,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9561:42,avoid,avoid,42,https://hail.is,https://github.com/hail-is/hail/pull/9561,1,['avoid'],['avoid']
Safety,[ci] Add timeout feature,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5745:9,timeout,timeout,9,https://hail.is,https://github.com/hail-is/hail/issues/5745,1,['timeout'],['timeout']
Safety,[ci] Allow GCP g2 test to timeout,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14435:26,timeout,timeout,26,https://hail.is,https://github.com/hail-is/hail/pull/14435,1,['timeout'],['timeout']
Safety,[ci] CI doesn't timeout any more?,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7761:16,timeout,timeout,16,https://hail.is,https://github.com/hail-is/hail/issues/7761,1,['timeout'],['timeout']
Safety,[ci] Recover from missing deploy jobs as well,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4683:5,Recover,Recover,5,https://hail.is,https://github.com/hail-is/hail/pull/4683,1,['Recover'],['Recover']
Safety,[ci] Remove redundancies between the two build_hail steps,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13038:12,redund,redundancies,12,https://hail.is,https://github.com/hail-is/hail/pull/13038,1,['redund'],['redundancies']
Safety,[ci] avoid sending unserializabale exceptions into web.json_response,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10402:5,avoid,avoid,5,https://hail.is,https://github.com/hail-is/hail/pull/10402,1,['avoid'],['avoid']
Safety,[ci] fix docker/requirements.txt to avoid incompatible lib versions,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10629:36,avoid,avoid,36,https://hail.is,https://github.com/hail-is/hail/pull/10629,1,['avoid'],['avoid']
Safety,[ci] hail_curl_image is redundant. kill it.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14490:24,redund,redundant,24,https://hail.is,https://github.com/hail-is/hail/pull/14490,1,['redund'],['redundant']
Safety,[ci] recover from deleted batches,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6406:5,recover,recover,5,https://hail.is,https://github.com/hail-is/hail/pull/6406,1,['recover'],['recover']
Safety,[combiner] Redesign combiner matrix reads to avoid interval duplication,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10517:45,avoid,avoid,45,https://hail.is,https://github.com/hail-is/hail/pull/10517,1,['avoid'],['avoid']
Safety,[compiler] fix stack safety bug in TypeCheck,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12704:21,safe,safety,21,https://hail.is,https://github.com/hail-is/hail/pull/12704,1,['safe'],['safety']
Safety,[compiler] make TypeCheck stack safe,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12606:32,safe,safe,32,https://hail.is,https://github.com/hail-is/hail/pull/12606,1,['safe'],['safe']
Safety,[copy] fix the TimeoutError and ServerDisconnected issues in copy,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11830:15,Timeout,TimeoutError,15,https://hail.is,https://github.com/hail-is/hail/pull/11830,1,['Timeout'],['TimeoutError']
Safety,[ggplot] avoid circularity in types,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12336:9,avoid,avoid,9,https://hail.is,https://github.com/hail-is/hail/pull/12336,1,['avoid'],['avoid']
Safety,[ggplot] avoid weird dataframe error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12337:9,avoid,avoid,9,https://hail.is,https://github.com/hail-is/hail/pull/12337,1,['avoid'],['avoid']
Safety,"[hail-ubuntu] avoid software-properties-common, a huge package",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10356:14,avoid,avoid,14,https://hail.is,https://github.com/hail-is/hail/pull/10356,1,['avoid'],['avoid']
Safety,"[hail/ptypes] PSet, PDict: better unsafeOrdering",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7752:34,unsafe,unsafeOrdering,34,https://hail.is,https://github.com/hail-is/hail/pull/7752,1,['unsafe'],['unsafeOrdering']
Safety,[hail/ptypes] Remove UnsafeOrdering from PArrayBackedContainer,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7737:21,Unsafe,UnsafeOrdering,21,https://hail.is,https://github.com/hail-is/hail/issues/7737,1,['Unsafe'],['UnsafeOrdering']
Safety,[hail/ptypes] Remove `unsafeStructInsert`,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8068:22,unsafe,unsafeStructInsert,22,https://hail.is,https://github.com/hail-is/hail/pull/8068,1,['unsafe'],['unsafeStructInsert']
Safety,"[hail/ptypes] lift rvd.rowPType/bind to variable, to avoid rvd serialization",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8134:53,avoid,avoid,53,https://hail.is,https://github.com/hail-is/hail/pull/8134,1,['avoid'],['avoid']
Safety,[hail/ptypes] remove region argument from unsafeOrdering methods,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7920:42,unsafe,unsafeOrdering,42,https://hail.is,https://github.com/hail-is/hail/issues/7920,1,['unsafe'],['unsafeOrdering']
Safety,[hail/ptypes] unsafeOrdering: require equality of ptypes,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8042:14,unsafe,unsafeOrdering,14,https://hail.is,https://github.com/hail-is/hail/pull/8042,1,['unsafe'],['unsafeOrdering']
Safety,[hail] Improve IR generated by VQC/SQC to avoid exponential blowup,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8032:42,avoid,avoid,42,https://hail.is,https://github.com/hail-is/hail/pull/8032,1,['avoid'],['avoid']
Safety,"[hail] Rewrite PType.subsetTo to avoid using `canonical`, which is wrong",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7870:33,avoid,avoid,33,https://hail.is,https://github.com/hail-is/hail/pull/7870,1,['avoid'],['avoid']
Safety,[hail] Set AzureFS timeout to 30s,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11883:19,timeout,timeout,19,https://hail.is,https://github.com/hail-is/hail/pull/11883,1,['timeout'],['timeout']
Safety,[hail] Write custom serializer for ApproxCDFCombiner to avoid issues,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7922:56,avoid,avoid,56,https://hail.is,https://github.com/hail-is/hail/pull/7922,1,['avoid'],['avoid']
Safety,[hail] avoid != in Makefile,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6891:7,avoid,avoid,7,https://hail.is,https://github.com/hail-is/hail/pull/6891,1,['avoid'],['avoid']
Safety,"[hail] change from ""polygenic risk score"" to ""polygenic score""",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8936:30,risk,risk,30,https://hail.is,https://github.com/hail-is/hail/pull/8936,1,['risk'],['risk']
Safety,[hail] improve unsafe row printed form,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8191:15,unsafe,unsafe,15,https://hail.is,https://github.com/hail-is/hail/pull/8191,1,['unsafe'],['unsafe']
Safety,[hail] makefile OS X safe,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7388:21,safe,safe,21,https://hail.is,https://github.com/hail-is/hail/pull/7388,1,['safe'],['safe']
Safety,"[hail] stop testing head, avoiding deprecation warning",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10082:26,avoid,avoiding,26,https://hail.is,https://github.com/hail-is/hail/pull/10082,1,['avoid'],['avoiding']
Safety,[hail][etc.] Update aiohttp version to avoid bug,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7078:39,avoid,avoid,39,https://hail.is,https://github.com/hail-is/hail/pull/7078,1,['avoid'],['avoid']
Safety,[hailctl dataproc] use a dataproc image that is log4j-safe,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11157:54,safe,safe,54,https://hail.is,https://github.com/hail-is/hail/pull/11157,1,['safe'],['safe']
Safety,[hailctl] change dev deploy timeout to 60s,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9933:28,timeout,timeout,28,https://hail.is,https://github.com/hail-is/hail/pull/9933,1,['timeout'],['timeout']
Safety,[hailctl] expose JSON unsafeDecode as a hailctl command,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6714:22,unsafe,unsafeDecode,22,https://hail.is,https://github.com/hail-is/hail/issues/6714,1,['unsafe'],['unsafeDecode']
Safety,[hailjwt] Unsafe decode,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5887:10,Unsafe,Unsafe,10,https://hail.is,https://github.com/hail-is/hail/pull/5887,1,['Unsafe'],['Unsafe']
Safety,[hailtop.batch] Fix docs for Job.timeout to include seconds,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11754:33,timeout,timeout,33,https://hail.is,https://github.com/hail-is/hail/pull/11754,1,['timeout'],['timeout']
Safety,[hailtop.batch] avoid serializing whole module in tests,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10317:16,avoid,avoid,16,https://hail.is,https://github.com/hail-is/hail/pull/10317,1,['avoid'],['avoid']
Safety,[hailtop] allow configuration of default HTTP timeout,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14206:46,timeout,timeout,46,https://hail.is,https://github.com/hail-is/hail/pull/14206,1,['timeout'],['timeout']
Safety,[hailtop] avoid code duplication in process.py,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10940:10,avoid,avoid,10,https://hail.is,https://github.com/hail-is/hail/pull/10940,1,['avoid'],['avoid']
Safety,[hailtop] avoid errors on rare transient errors,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13921:10,avoid,avoid,10,https://hail.is,https://github.com/hail-is/hail/pull/13921,1,['avoid'],['avoid']
Safety,[hailtop] safely use chunks,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12492:10,safe,safely,10,https://hail.is,https://github.com/hail-is/hail/pull/12492,1,['safe'],['safely']
Safety,[hailtop] treat asyncio.TimeoutError as transient,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7312:24,Timeout,TimeoutError,24,https://hail.is,https://github.com/hail-is/hail/pull/7312,1,['Timeout'],['TimeoutError']
Safety,[http] set project-wide default http timeout to 5 seconds,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9866:37,timeout,timeout,37,https://hail.is,https://github.com/hail-is/hail/pull/9866,1,['timeout'],['timeout']
Safety,[httpx] avoid subclassing aiohttp.ClientSession,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10939:8,avoid,avoid,8,https://hail.is,https://github.com/hail-is/hail/pull/10939,1,['avoid'],['avoid']
Safety,[httpx] use timeouts and remove footgun,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11770:12,timeout,timeouts,12,https://hail.is,https://github.com/hail-is/hail/pull/11770,1,['timeout'],['timeouts']
Safety,[httpx][Makefile][copier] add --timeout to copier; use in Makefile,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14138:32,timeout,timeout,32,https://hail.is,https://github.com/hail-is/hail/pull/14138,1,['timeout'],['timeout']
Safety,[k8s] update to avoid unsupported apiVersions,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13277:16,avoid,avoid,16,https://hail.is,https://github.com/hail-is/hail/pull/13277,1,['avoid'],['avoid']
Safety,[memory] ensure we timeout requests,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11924:19,timeout,timeout,19,https://hail.is,https://github.com/hail-is/hail/pull/11924,1,['timeout'],['timeout']
Safety,[memory] safe to evict,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10864:9,safe,safe,9,https://hail.is,https://github.com/hail-is/hail/pull/10864,1,['safe'],['safe']
Safety,[notebook] 2m timeout,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7281:14,timeout,timeout,14,https://hail.is,https://github.com/hail-is/hail/pull/7281,1,['timeout'],['timeout']
Safety,[notebook] Set 2500% target utilization to avoid rapid scale up,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12435:43,avoid,avoid,43,https://hail.is,https://github.com/hail-is/hail/pull/12435,1,['avoid'],['avoid']
Safety,[pip] Update jinja to avoid 3.1.3 vulnerability,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14532:22,avoid,avoid,22,https://hail.is,https://github.com/hail-is/hail/pull/14532,1,['avoid'],['avoid']
Safety,[pipeline] add timeout option,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8258:15,timeout,timeout,15,https://hail.is,https://github.com/hail-is/hail/pull/8258,1,['timeout'],['timeout']
Safety,[prometheus] update to 2.46.0 to attempt to avoid WAL issues,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13443:44,avoid,avoid,44,https://hail.is,https://github.com/hail-is/hail/pull/13443,1,['avoid'],['avoid']
Safety,[qob] back off timeout on test_joins_work_correctly,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13661:15,timeout,timeout,15,https://hail.is,https://github.com/hail-is/hail/pull/13661,1,['timeout'],['timeout']
Safety,[query/combiner] Fix MatrixMultiWrite to avoid metadata races,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9775:41,avoid,avoid,41,https://hail.is,https://github.com/hail-is/hail/pull/9775,1,['avoid'],['avoid']
Safety,[query/service] avoid round trip to compute StringTableReader type,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11768:16,avoid,avoid,16,https://hail.is,https://github.com/hail-is/hail/pull/11768,1,['avoid'],['avoid']
Safety,[query/service] change test to use a cloud-safe temp dir,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11590:43,safe,safe,43,https://hail.is,https://github.com/hail-is/hail/pull/11590,1,['safe'],['safe']
Safety,[query/vds combiner] Change sanity checks on combiner construction,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14087:28,sanity check,sanity checks,28,https://hail.is,https://github.com/hail-is/hail/pull/14087,1,['sanity check'],['sanity checks']
Safety,[query] Add EncodedLiteral node to avoid java serialization,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9487:35,avoid,avoid,35,https://hail.is,https://github.com/hail-is/hail/pull/9487,1,['avoid'],['avoid']
Safety,[query] Add typechecking rule to detect badly-placed void arguments,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9974:33,detect,detect,33,https://hail.is,https://github.com/hail-is/hail/pull/9974,1,['detect'],['detect']
Safety,[query] Avoid Class A Operations.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13450:8,Avoid,Avoid,8,https://hail.is,https://github.com/hail-is/hail/pull/13450,5,['Avoid'],['Avoid']
Safety,[query] Avoid py4j for python-backend interactions,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13797:8,Avoid,Avoid,8,https://hail.is,https://github.com/hail-is/hail/pull/13797,1,['Avoid'],['Avoid']
Safety,[query] Cache table coercers per driver JVM to avoid scans on every q…,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12099:47,avoid,avoid,47,https://hail.is,https://github.com/hail-is/hail/pull/12099,1,['avoid'],['avoid']
Safety,[query] Don't define unsafeOrdering on complexPType,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8913:21,unsafe,unsafeOrdering,21,https://hail.is,https://github.com/hail-is/hail/pull/8913,1,['unsafe'],['unsafeOrdering']
Safety,[query] Fix TableNativeWriter/TableRange to avoid generating O(N_partitions) IR,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10872:44,avoid,avoid,44,https://hail.is,https://github.com/hail-is/hail/pull/10872,1,['avoid'],['avoid']
Safety,[query] Fix column major test to avoid extra copying,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9768:33,avoid,avoid,33,https://hail.is,https://github.com/hail-is/hail/pull/9768,1,['avoid'],['avoid']
Safety,[query] Fix text partition writers to use UUIDs and avoid speculation…,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12415:52,avoid,avoid,52,https://hail.is,https://github.com/hail-is/hail/pull/12415,1,['avoid'],['avoid']
Safety,[query] Framework for making compiler passes stack safe,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9320:51,safe,safe,51,https://hail.is,https://github.com/hail-is/hail/pull/9320,1,['safe'],['safe']
Safety,[query] Make pc_relate benchmark faster to avoid timeouts,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9268:43,avoid,avoid,43,https://hail.is,https://github.com/hail-is/hail/pull/9268,2,"['avoid', 'timeout']","['avoid', 'timeouts']"
Safety,[query] Refactor PStruct to avoid abstract methods,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8528:28,avoid,avoid,28,https://hail.is,https://github.com/hail-is/hail/pull/8528,1,['avoid'],['avoid']
Safety,[query] Remove region argument from SafeRow.read,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8269:36,Safe,SafeRow,36,https://hail.is,https://github.com/hail-is/hail/pull/8269,1,['Safe'],['SafeRow']
Safety,[query] Remove unused and redundant requirements,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13988:26,redund,redundant,26,https://hail.is,https://github.com/hail-is/hail/pull/13988,1,['redund'],['redundant']
Safety,[query] Stack safe parser,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9332:14,safe,safe,14,https://hail.is,https://github.com/hail-is/hail/pull/9332,1,['safe'],['safe']
Safety,[query] Time safe row conversion,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9370:13,safe,safe,13,https://hail.is,https://github.com/hail-is/hail/pull/9370,1,['safe'],['safe']
Safety,[query] Turn BlockMatrixIR typs into lazy vals to avoid recomputing,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9363:50,avoid,avoid,50,https://hail.is,https://github.com/hail-is/hail/pull/9363,1,['avoid'],['avoid']
Safety,[query] a few more timeout relaxations or test splits,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13145:19,timeout,timeout,19,https://hail.is,https://github.com/hail-is/hail/pull/13145,1,['timeout'],['timeout']
Safety,[query] add timeouts and more logging,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9478:12,timeout,timeouts,12,https://hail.is,https://github.com/hail-is/hail/pull/9478,1,['timeout'],['timeouts']
Safety,[query] avoid broadcasting FS,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10942:8,avoid,avoid,8,https://hail.is,https://github.com/hail-is/hail/pull/10942,1,['avoid'],['avoid']
Safety,[query] avoid code explosion for trivial upcasts,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14232:8,avoid,avoid,8,https://hail.is,https://github.com/hail-is/hail/pull/14232,1,['avoid'],['avoid']
Safety,[query] avoid hanging the JVM in Dataproc,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13916:8,avoid,avoid,8,https://hail.is,https://github.com/hail-is/hail/pull/13916,1,['avoid'],['avoid']
Safety,[query] avoid index_bgen races in the tests,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12824:8,avoid,avoid,8,https://hail.is,https://github.com/hail-is/hail/pull/12824,1,['avoid'],['avoid']
Safety,[query] avoid orjson-caused segfault in py4j_backend.py,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14300:8,avoid,avoid,8,https://hail.is,https://github.com/hail-is/hail/pull/14300,1,['avoid'],['avoid']
Safety,[query] avoid rare test collection bug,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11933:8,avoid,avoid,8,https://hail.is,https://github.com/hail-is/hail/pull/11933,1,['avoid'],['avoid']
Safety,[query] avoid signed integer overlow in partition function,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13550:8,avoid,avoid,8,https://hail.is,https://github.com/hail-is/hail/pull/13550,1,['avoid'],['avoid']
Safety,"[query] back off spectral moments timeout for local, spark, and batch",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13278:34,timeout,timeout,34,https://hail.is,https://github.com/hail-is/hail/pull/13278,1,['timeout'],['timeout']
Safety,[query] back test_spectral_moments timeout off to 8 minutes,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13260:35,timeout,timeout,35,https://hail.is,https://github.com/hail-is/hail/pull/13260,1,['timeout'],['timeout']
Safety,[query] cache RVD specs to avoid lots of file reads,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12086:27,avoid,avoid,27,https://hail.is,https://github.com/hail-is/hail/pull/12086,1,['avoid'],['avoid']
Safety,[query] cleanup redundent MethodBuilders in Emit,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8449:16,redund,redundent,16,https://hail.is,https://github.com/hail-is/hail/pull/8449,1,['redund'],['redundent']
Safety,[query] freeze when necessary to avoid hashing issues,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12265:33,avoid,avoid,33,https://hail.is,https://github.com/hail-is/hail/pull/12265,1,['avoid'],['avoid']
Safety,[query] make debug_info non-Spark-safe,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10377:34,safe,safe,34,https://hail.is,https://github.com/hail-is/hail/pull/10377,1,['safe'],['safe']
Safety,"[query] split tests, faster test dataset, longer timeout for big test",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13147:49,timeout,timeout,49,https://hail.is,https://github.com/hail-is/hail/pull/13147,1,['timeout'],['timeout']
Safety,[query] use a 10 minute timeout,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9574:24,timeout,timeout,24,https://hail.is,https://github.com/hail-is/hail/pull/9574,1,['timeout'],['timeout']
Safety,[query][qob] Zstandard corrupted block detected when reading VDS out of GCS,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13409:39,detect,detected,39,https://hail.is,https://github.com/hail-is/hail/issues/13409,1,['detect'],['detected']
Safety,[spark_backend] avoid infinite recursion when initialization fails,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14199:16,avoid,avoid,16,https://hail.is,https://github.com/hail-is/hail/pull/14199,1,['avoid'],['avoid']
Safety,[sync.py] avoid infinite retry loop,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9858:10,avoid,avoid,10,https://hail.is,https://github.com/hail-is/hail/pull/9858,1,['avoid'],['avoid']
Safety,[sync.py] more improvements to avoid unnecessary extra reloadings,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10343:31,avoid,avoid,31,https://hail.is,https://github.com/hail-is/hail/pull/10343,1,['avoid'],['avoid']
Safety,[test_dataproc] set timeout to 2 hours,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11267:20,timeout,timeout,20,https://hail.is,https://github.com/hail-is/hail/pull/11267,1,['timeout'],['timeout']
Safety,[tests] Increase service backend test timeout to 600s,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13297:38,timeout,timeout,38,https://hail.is,https://github.com/hail-is/hail/pull/13297,1,['timeout'],['timeout']
Safety,[tests] test_skat should have default timeout of 10mins,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13320:38,timeout,timeout,38,https://hail.is,https://github.com/hail-is/hail/pull/13320,1,['timeout'],['timeout']
Safety,[utils] make sleep_and_backoff a bit more predictable,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10409:42,predict,predictable,42,https://hail.is,https://github.com/hail-is/hail/pull/10409,1,['predict'],['predictable']
Safety,[vds/combiner] Add sanity check on uniqueness of gvcf paths/sample names,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14207:19,sanity check,sanity check,19,https://hail.is,https://github.com/hail-is/hail/pull/14207,1,['sanity check'],['sanity check']
Safety,[website][build.yaml] use --no-same-owner to avoid uid issues in exte…,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11440:45,avoid,avoid,45,https://hail.is,https://github.com/hail-is/hail/pull/11440,1,['avoid'],['avoid']
Safety,"_</code> (<a href=""https://github-redirect.dependabot.com/aio-libs/async-timeout/issues/274"">#274</a>)</li>; <li><a href=""https://github.com/aio-libs/async-timeout/commit/8685c60dc0e82ee246fbe3d1aa272d1dfe57c24c""><code>8685c60</code></a> Bump mypy from 0.910 to 0.920 (<a href=""https://github-redirect.dependabot.com/aio-libs/async-timeout/issues/273"">#273</a>)</li>; <li><a href=""https://github.com/aio-libs/async-timeout/commit/f0a0914345b224448220aeb00d71e6a04a5d24bd""><code>f0a0914</code></a> Bump twine from 3.7.0 to 3.7.1 (<a href=""https://github-redirect.dependabot.com/aio-libs/async-timeout/issues/272"">#272</a>)</li>; <li><a href=""https://github.com/aio-libs/async-timeout/commit/e5c813173b8811b30f4a30eeba56fa8808ab15bb""><code>e5c8131</code></a> [pre-commit.ci] pre-commit autoupdate (<a href=""https://github-redirect.dependabot.com/aio-libs/async-timeout/issues/271"">#271</a>)</li>; <li><a href=""https://github.com/aio-libs/async-timeout/commit/c7e10db3d0965422122bef263fb36f6fd7572330""><code>c7e10db</code></a> Fix linter configs</li>; <li><a href=""https://github.com/aio-libs/async-timeout/commit/6af8bf421a799208b27d57c6bf69de0d998fedec""><code>6af8bf4</code></a> Bump pre-commit from 2.15 to 2.16.0 (<a href=""https://github-redirect.dependabot.com/aio-libs/async-timeout/issues/269"">#269</a>)</li>; <li><a href=""https://github.com/aio-libs/async-timeout/commit/c71bbb5b5d7330f6dabfde7a1adec30a4611c0be""><code>c71bbb5</code></a> Bump docutils from 0.18 to 0.18.1 (<a href=""https://github-redirect.dependabot.com/aio-libs/async-timeout/issues/266"">#266</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/aio-libs/async-timeout/compare/v3.0.1...v4.0.2"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=async-timeout&package-manager=pip&previous-version=3.0.1&new-version=4.0.2)](https://docs.github.com/en/github/managing-security-vulnerabilities",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11465:5555,timeout,timeout,5555,https://hail.is,https://github.com/hail-is/hail/pull/11465,1,['timeout'],['timeout']
Safety,"_From @cseed on October 22, 2015 13:56_. Andrea is running into some problems with the Estonian dataset in sampleqc:. ```; Exception in thread ""main"" org.apache.spark.SparkException: Job aborted due to stage failure: Total size of serialized results of 2689 tasks (2.0 GB) is bigger than spark.driver.maxResultSize (2.0 GB); ```. _Copied from original issue: cseed/hail#89_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/53:187,abort,aborted,187,https://hail.is,https://github.com/hail-is/hail/issues/53,1,['abort'],['aborted']
Safety,"_From @cseed on September 29, 2015 15:43_. Added gqbydp --plot option. Some issues to resolve:; - need to test; - installDir detection won't work with shadowJar; - handle case of output file in Hadoop or Hadoop URI. _Copied from original issue: cseed/hail#62_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/43:125,detect,detection,125,https://hail.is,https://github.com/hail-is/hail/issues/43,1,['detect'],['detection']
Safety,"_at(deadline)</code> (<a href=""https://github-redirect.dependabot.com/aio-libs/async-timeout/issues/117"">#117</a>)</p>; </li>; <li>; <p>Supported <code>timeout.deadline</code> and <code>timeout.expired</code> properties.</p>; </li>; <li>; <p>Drooped <code>timeout.remaining</code> property: it can be calculated as; <code>timeout.deadline - loop.time()</code></p>; </li>; <li>; <p>Dropped <code>timeout.timeout</code> property that returns a relative timeout based on the; timeout object creation time; the absolute <code>timeout.deadline</code> should be used; instead.</p>; </li>; <li>; <p>Added the deadline modification methods: <code>timeout.reject()</code>,; <code>timeout.shift(delay)</code>, <code>timeout.update(deadline)</code>.</p>; </li>; <li>; <p>Deprecated synchronous context manager usage</p>; </li>; </ul>; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/aio-libs/async-timeout/blob/master/CHANGES.rst"">async-timeout's changelog</a>.</em></p>; <blockquote>; <h1>4.0.2 (2021-12-20)</h1>; <h2>Misc</h2>; <ul>; <li><code>[#259](https://github.com/aio-libs/async-timeout/issues/259) &lt;https://github.com/aio-libs/async-timeout/issues/259&gt;</code><em>, <code>[#274](https://github.com/aio-libs/async-timeout/issues/274) &lt;https://github.com/aio-libs/async-timeout/issues/274&gt;</code></em></li>; </ul>; <h1>4.0.1 (2121-11-10)</h1>; <ul>; <li>; <p>Fix regression:</p>; <ol>; <li>; <p>Don't raise TimeoutError from timeout object that doesn't enter into async context; manager</p>; </li>; <li>; <p>Use call_soon() for raising TimeoutError if deadline is reached on entering into; async context manager</p>; </li>; </ol>; <p>(<a href=""https://github-redirect.dependabot.com/aio-libs/async-timeout/issues/258"">#258</a>)</p>; </li>; <li>; <p>Make <code>Timeout</code> class available in <code>__all__</code>.</p>; </li>; </ul>; <h1>4.0.0 (2021-11-01)</h1>; <ul>; <li>; <p>Implemented <code>timeout_at(deadline)</code> (",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11465:2097,timeout,timeout,2097,https://hail.is,https://github.com/hail-is/hail/pull/11465,1,['timeout'],['timeout']
Safety,"_missing(mt.fam.pat_id),; mt.GT.num_alt_alleles())),; meta={'group': 'adj'}). per_sample = per_sample.annotate(adj=adj_per_sample[per_sample.s]). mt = mt.annotate_rows(family_stats=mt.family_stats.append(family_stats_adj)); mt.write(); ```; ### What went wrong (all error messages here, including the full java stack trace):; ```; java.lang.AssertionError: assertion failed; 	at scala.Predef$.assert(Predef.scala:156); 	at is.hail.annotations.RegionValueBuilder.addRegionValue(RegionValueBuilder.scala:394); 	at is.hail.annotations.RegionValueBuilder.addField(RegionValueBuilder.scala:335); 	at is.hail.variant.MatrixTable$$anonfun$dropEntries$2.apply(MatrixTable.scala:1433); 	at is.hail.variant.MatrixTable$$anonfun$dropEntries$2.apply(MatrixTable.scala:1421); 	at is.hail.variant.MatrixTable$$anonfun$95$$anonfun$apply$60$$anonfun$apply$4.apply$mcV$sp(MatrixTable.scala:1723); 	at is.hail.expr.types.TStruct$$anonfun$unsafeInsert$1.apply(TStruct.scala:177); 	at is.hail.expr.types.TStruct$$anonfun$unsafeInsert$1.apply(TStruct.scala:177); 	at is.hail.expr.types.TStruct$$anonfun$unsafeInsert$2.apply(TStruct.scala:197); 	at is.hail.expr.types.TStruct$$anonfun$unsafeInsert$2.apply(TStruct.scala:186); 	at is.hail.variant.MatrixTable$$anonfun$95$$anonfun$apply$60.apply(MatrixTable.scala:1722); 	at is.hail.variant.MatrixTable$$anonfun$95$$anonfun$apply$60.apply(MatrixTable.scala:1718); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$6$$anon$5.next(OrderedRVD.scala:736); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$6$$anon$5.next(OrderedRVD.scala:730); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$6$$anon$5.next(OrderedRVD.scala:736); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$6$$anon$5.next(OrderedRVD.scala:730); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$6$$anon$5.next(OrderedRVD.scala:736); 	at is.hail.rvd",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3074:2000,unsafe,unsafeInsert,2000,https://hail.is,https://github.com/hail-is/hail/issues/3074,1,['unsafe'],['unsafeInsert']
Safety,"_per_month); ```. This works out to 143 USD to run a 10,000 VM cluster 24 hours a day for 30 days. I suspect our average VM count in a month is closer to 10 which is within the free tier (340 MiB). I; might be wrong abou the connections per vm per aggregation interval, but this is straightforward to; monitor once we have the logs. For a sense of the cost landscape, these are all free:. 1. 1000 VMs.; 2. 500 VMs, with a sampling rate of 1.; 3. 200 VMs, with a sampling rate of 1, with an interval of 5 minutes.; 4. 10 VMs, with a sampling rate of 1, with an interval of 30 seconds. It's all linear, so if we need to halve the interval we can either change the sampling rate, reasses; our expected number of VM-hours, or adjust the service fee accordingly. We can also assess the landscape of fees necessary to cover costs (ignoring the free 50 GiB):. 1. 15 minute intervals, 0.5 sampling rate, 100 expected connections per vm per interval: 0.0000008; USD per core per hour. 2. 30 second intervals, 1.0 sampling rate, 100 expected connections per vm per interval: 0.00005 USD; per core per hour. 2. 5 second intervals, 1.0 sampling rate, 100 expected connections per vm per interval: 0.0003 USD; per core per hour. 2. 5 second intervals, 1.0 sampling rate, 1000 expected connections per vm per interval (1000 unique; connections per second honestly seems to me quite remarkable performance): 0.003 USD per core per; hour. ```; USD_per_core_per_hour = bytes_per_hour / vms / 1024. / 1024 / 1024 * 0.5 / 16. print(USD_per_core_per_hour); ```. ---. # Conclusion. I think we're safe to enable this with the parameters in this PR (15 minute intervals, 50%; sampling). We can assess unknown parameters, like connections per vm, and get comfortable looking at; these logs. Security constraints or observability demands may push us towards desiring more logs. If that; occurs, we can assess the need for a new fee. Regardless, this fee appears to be small relative to; the current cost of preemptible cores.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12883:4862,safe,safe,4862,https://hail.is,https://github.com/hail-is/hail/pull/12883,1,['safe'],['safe']
Safety,"_rows(family_stats=mt.family_stats.append(family_stats_adj)); mt.write(); ```; ### What went wrong (all error messages here, including the full java stack trace):; ```; java.lang.AssertionError: assertion failed; 	at scala.Predef$.assert(Predef.scala:156); 	at is.hail.annotations.RegionValueBuilder.addRegionValue(RegionValueBuilder.scala:394); 	at is.hail.annotations.RegionValueBuilder.addField(RegionValueBuilder.scala:335); 	at is.hail.variant.MatrixTable$$anonfun$dropEntries$2.apply(MatrixTable.scala:1433); 	at is.hail.variant.MatrixTable$$anonfun$dropEntries$2.apply(MatrixTable.scala:1421); 	at is.hail.variant.MatrixTable$$anonfun$95$$anonfun$apply$60$$anonfun$apply$4.apply$mcV$sp(MatrixTable.scala:1723); 	at is.hail.expr.types.TStruct$$anonfun$unsafeInsert$1.apply(TStruct.scala:177); 	at is.hail.expr.types.TStruct$$anonfun$unsafeInsert$1.apply(TStruct.scala:177); 	at is.hail.expr.types.TStruct$$anonfun$unsafeInsert$2.apply(TStruct.scala:197); 	at is.hail.expr.types.TStruct$$anonfun$unsafeInsert$2.apply(TStruct.scala:186); 	at is.hail.variant.MatrixTable$$anonfun$95$$anonfun$apply$60.apply(MatrixTable.scala:1722); 	at is.hail.variant.MatrixTable$$anonfun$95$$anonfun$apply$60.apply(MatrixTable.scala:1718); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$6$$anon$5.next(OrderedRVD.scala:736); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$6$$anon$5.next(OrderedRVD.scala:730); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$6$$anon$5.next(OrderedRVD.scala:736); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$6$$anon$5.next(OrderedRVD.scala:730); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$6$$anon$5.next(OrderedRVD.scala:736); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$6$$anon$5.next(OrderedRVD.scala:730); 	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:462); 	at is.hail.rvd.OrderedRVD$$a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3074:2162,unsafe,unsafeInsert,2162,https://hail.is,https://github.com/hail-is/hail/issues/3074,1,['unsafe'],['unsafeInsert']
Safety,"_sample = per_sample.annotate(adj=adj_per_sample[per_sample.s]). mt = mt.annotate_rows(family_stats=mt.family_stats.append(family_stats_adj)); mt.write(); ```; ### What went wrong (all error messages here, including the full java stack trace):; ```; java.lang.AssertionError: assertion failed; 	at scala.Predef$.assert(Predef.scala:156); 	at is.hail.annotations.RegionValueBuilder.addRegionValue(RegionValueBuilder.scala:394); 	at is.hail.annotations.RegionValueBuilder.addField(RegionValueBuilder.scala:335); 	at is.hail.variant.MatrixTable$$anonfun$dropEntries$2.apply(MatrixTable.scala:1433); 	at is.hail.variant.MatrixTable$$anonfun$dropEntries$2.apply(MatrixTable.scala:1421); 	at is.hail.variant.MatrixTable$$anonfun$95$$anonfun$apply$60$$anonfun$apply$4.apply$mcV$sp(MatrixTable.scala:1723); 	at is.hail.expr.types.TStruct$$anonfun$unsafeInsert$1.apply(TStruct.scala:177); 	at is.hail.expr.types.TStruct$$anonfun$unsafeInsert$1.apply(TStruct.scala:177); 	at is.hail.expr.types.TStruct$$anonfun$unsafeInsert$2.apply(TStruct.scala:197); 	at is.hail.expr.types.TStruct$$anonfun$unsafeInsert$2.apply(TStruct.scala:186); 	at is.hail.variant.MatrixTable$$anonfun$95$$anonfun$apply$60.apply(MatrixTable.scala:1722); 	at is.hail.variant.MatrixTable$$anonfun$95$$anonfun$apply$60.apply(MatrixTable.scala:1718); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$6$$anon$5.next(OrderedRVD.scala:736); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$6$$anon$5.next(OrderedRVD.scala:730); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$6$$anon$5.next(OrderedRVD.scala:736); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$6$$anon$5.next(OrderedRVD.scala:730); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$6$$anon$5.next(OrderedRVD.scala:736); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$6$$anon$5.next(OrderedRVD.scala:730); 	at scala.collec",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3074:2081,unsafe,unsafeInsert,2081,https://hail.is,https://github.com/hail-is/hail/issues/3074,1,['unsafe'],['unsafeInsert']
Safety,"_traceback__ is not tb:; --> 769 raise value.with_traceback(tb); 770 raise value. File /opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py:703, in HTTPConnectionPool.urlopen(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw); 702 # Make the request on the httplib connection object.; --> 703 httplib_response = self._make_request(; 704 conn,; 705 method,; 706 url,; 707 timeout=timeout_obj,; 708 body=body,; 709 headers=headers,; 710 chunked=chunked,; 711 ); 713 # If we're going to release the connection in ``finally:``, then; 714 # the response doesn't need to know about the connection. Otherwise; 715 # it will also try to release it and we'll have a double-release; 716 # mess. File /opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py:449, in HTTPConnectionPool._make_request(self, conn, method, url, timeout, chunked, **httplib_request_kw); 445 except BaseException as e:; 446 # Remove the TypeError from the exception chain in; 447 # Python 3 (including for exceptions like SystemExit).; 448 # Otherwise it looks like a bug in the code.; --> 449 six.raise_from(e, None); 450 except (SocketTimeout, BaseSSLError, SocketError) as e:. File <string>:3, in raise_from(value, from_value). File /opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py:444, in HTTPConnectionPool._make_request(self, conn, method, url, timeout, chunked, **httplib_request_kw); 443 try:; --> 444 httplib_response = conn.getresponse(); 445 except BaseException as e:; 446 # Remove the TypeError from the exception chain in; 447 # Python 3 (including for exceptions like SystemExit).; 448 # Otherwise it looks like a bug in the code. File /opt/conda/lib/python3.10/http/client.py:1375, in HTTPConnection.getresponse(self); 1374 try:; -> 1375 response.begin(); 1376 except ConnectionError:. File /opt/conda/lib/python3.10/http/client.py:318, in HTTPResponse.begin(self); 317 while True:; --> 3",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13960:8508,timeout,timeout,8508,https://hail.is,https://github.com/hail-is/hail/issues/13960,1,['timeout'],['timeout']
Safety,"_where(; (hl.is_deletion(mt.alleles[0], mt.alleles[1])) & (mt.GT.is_hom_var()); ),; )) for interval_name in interval_names}. mt2 = mt.annotate_cols(**annotate_dict); return mt2; ```; ```; interval_table_dict = dict(; zip(interval_names, [hl.is_defined(interval_table[filtered_mt.locus]) for interval_table in interval_tables]); ); ```. ### Version. 0.2.126. ### Relevant log output. ```shell; ---------------------------------------------------------------------------; RemoteDisconnected Traceback (most recent call last); File /opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py:703, in HTTPConnectionPool.urlopen(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw); 702 # Make the request on the httplib connection object.; --> 703 httplib_response = self._make_request(; 704 conn,; 705 method,; 706 url,; 707 timeout=timeout_obj,; 708 body=body,; 709 headers=headers,; 710 chunked=chunked,; 711 ); 713 # If we're going to release the connection in ``finally:``, then; 714 # the response doesn't need to know about the connection. Otherwise; 715 # it will also try to release it and we'll have a double-release; 716 # mess. File /opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py:449, in HTTPConnectionPool._make_request(self, conn, method, url, timeout, chunked, **httplib_request_kw); 445 except BaseException as e:; 446 # Remove the TypeError from the exception chain in; 447 # Python 3 (including for exceptions like SystemExit).; 448 # Otherwise it looks like a bug in the code.; --> 449 six.raise_from(e, None); 450 except (SocketTimeout, BaseSSLError, SocketError) as e:. File <string>:3, in raise_from(value, from_value). File /opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py:444, in HTTPConnectionPool._make_request(self, conn, method, url, timeout, chunked, **httplib_request_kw); 443 try:; --> 444 httplib_response = conn.getresponse(); 445 except Ba",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13960:4133,timeout,timeout,4133,https://hail.is,https://github.com/hail-is/hail/issues/13960,1,['timeout'],['timeout']
Safety,"`; [Stage 3:> (0 + 140) / 415]Traceback (most recent call last):; File ""/restricted/projectnb/genpro/github/hail.qc/delly-qc.py"", line 35, in <module>; ds = hl.sample_qc(ds); File ""<decorator-gen-902>"", line 2, in sample_qc; File ""/restricted/projectnb/genpro/github/hail/python/hail/typecheck/check.py"", line 490, in _typecheck; return __orig_func__(*args_, **kwargs_); File ""/restricted/projectnb/genpro/github/hail/python/hail/methods/qc.py"", line 91, in sample_qc; return MatrixTable(Env.hail().methods.SampleQC.apply(require_biallelic(dataset, 'sample_qc')._jvds, name)); File ""/share/pkg/spark/2.2.0/install/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py"", line 1133, in __call__; File ""/restricted/projectnb/genpro/github/hail/python/hail/utils/java.py"", line 196, in deco; 'Error summary: %s' % (deepest, full, hail.__version__, deepest)) from None; hail.utils.java.FatalError: HailException: invalid allele ""<DEL>"". Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 2 in stage 3.0 failed 4 times, most recent failure: Lost task 2.3 in stage 3.0 (TID 160, scc-q01.scc.bu.edu, executor 4): is.hail.utils.HailException: invalid allele ""<DEL>""; at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:6); at is.hail.utils.package$.fatal(package.scala:26); at is.hail.variant.AltAlleleMethods$.validate(AltAlleleMethods.scala:24); at is.hail.variant.AltAlleleMethods$.altAlleleType(AltAlleleMethods.scala:29); at is.hail.methods.SampleQCCombiner$.alleleIndices(SampleQC.scala:44); at is.hail.methods.SampleQC$$anonfun$results$1$$anonfun$apply$1.apply(SampleQC.scala:178); at is.hail.methods.SampleQC$$anonfun$results$1$$anonfun$apply$1.apply(SampleQC.scala:175); at scala.collection.Iterator$class.foreach(Iterator.scala:893); at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); at is.hail.methods.SampleQC$$anonfun$results$1.apply(SampleQC.scala:175); at is.hail.methods.SampleQC$$anonfun$results$1.apply(SampleQC.scala:170); a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3413:1491,abort,aborted,1491,https://hail.is,https://github.com/hail-is/hail/issues/3413,1,['abort'],['aborted']
Safety,"`ArrayScan` is implemented in such a way that a scan on an empty array will read some uninitialized memory:. ```; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.2.23-7f06f94534d5; >>> hl.eval(hl.empty_array(hl.tint32).scan(lambda x,y: x + y, 0)); [0]; >>> hl.eval(hl.array([1, 2, 3]).scan(lambda x,y: x + y, 0)); [0, 1, 3, 6]; >>> hl.eval(hl.empty_array(hl.tint32).scan(lambda x,y: x + y, 0)); [643629112]; >>> hl.eval(hl.empty_array(hl.tarray(hl.tint32)).scan(lambda x,y: y, hl.empty_array(hl.tint32))); #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x000000010ef85ded, pid=49261, tid=0x0000000000009903; #; # JRE version: Java(TM) SE Runtime Environment (8.0_211-b12) (build 1.8.0_211-b12); # Java VM: Java HotSpot(TM) 64-Bit Server VM (25.211-b12 mixed mode bsd-amd64 compressed oops); # Problematic frame:; # V [libjvm.dylib+0x585ded]; #; # Failed to write core dump. Core dumps have been disabled. To enable core dumping, try ""ulimit -c unlimited"" before starting Java again; #; # An error report file with more information is saved as:; # /Users/mturner/Documents/hail/hail/python/hs_err_pid49261.log; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; #; ```. This is because `ArrayScan` claims to have `len+1` elements, where `len` is the length of the inner stream. However, it will only call the consumer continuation during the `addElements` loop of the inner stream. Thus, if the inner stream is empty, the consumer continuation is never called. So the resulting effect is that we return an initialized array with length 1.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7135:571,detect,detected,571,https://hail.is,https://github.com/hail-is/hail/issues/7135,1,['detect'],['detected']
Safety,"`BlockMatrix.from_entry_expr` is not in the style of our other conversion methods (e.g. (`un`)`localize_entries`, `entries`). We should deprecate it (does python have a way to officially do this? I'd like users to get warnings at least) and replace with `mt.GT.n_alt_alleles().to_block_matrix()`. Obviously this only works if the expression is row & column indexed. @tpoterba thoughts on this? I seem to really hate the `BlockMatrix.from_entry_expr` bit, but we've avoided putting relational methods on expressions.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5589:465,avoid,avoided,465,https://hail.is,https://github.com/hail-is/hail/issues/5589,1,['avoid'],['avoided']
Safety,`BlockMatrix.to_numpy` writes separate block files if the matrix size is too big to export in a single file on the leader. This caused a bug on the cluster because the workers were writing to their local filesystems and not Hadoop. This now actually writes and reads with a temp Hadoop path. Added an underscore parameter to the `to_numpy` method to force writing the block matrix out in blocks and added a sanity check in the cluster tests.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5686:407,sanity check,sanity check,407,https://hail.is,https://github.com/hail-is/hail/pull/5686,1,['sanity check'],['sanity check']
Safety,"`Instance.mark_healthy` tries to avoid a database call if the instance was marked healthy within the last five seconds. However, since `self._last_updated = now` is set *after* the database query, multiple invocations of `mark_healthy` can still race and execute the query. Since this is run every time we receive an MJC, we end up executing this query very often, instead of just once every five seconds per worker. Bringing the state checking / setting together into 1 synchronous block instead of split across an await fixed the issue. The `query_name` business is just adding prometheus monitoring to that query.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11889:33,avoid,avoid,33,https://hail.is,https://github.com/hail-is/hail/pull/11889,1,['avoid'],['avoid']
Safety,"`Mentions(ir, name)` is true if `name` is referenced by `ir`. Ergo, when it is false, there exist no references to it, so it's safe to give it some bogus value, like the `0` pointer. This was the last mile of improving Caitlin's pipeline and is obviated by the off-heap stuff. @jigold this is one of the things you requested me to break out.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3751:127,safe,safe,127,https://hail.is,https://github.com/hail-is/hail/pull/3751,1,['safe'],['safe']
Safety,"`OnDiskBTreeIndexToValue` can index the elements at the base of a BTree. The BGen BTree is a BTree on the byte-offsets of variants in the BGen file. In a following PR, I will use this class to filter the BGen file to a subset of variants, specified by their index. This kind of filtering happens at the level of bytes, it permits me to avoid decoding/decompressing any variants I don't need. Ideally, the index would also include the variant keys themselves. That would be a really nice extension of this work and would enable a more natural file-level filtering user experience. Aside: `IndexBTree` could use some TLC. I'm sort of making the minimal changes to get Caitlin cooking. Last night, I slipped into a rewrite and it's just too big a task to get right before Friday because I don't have any documentation of precisely what our btree file format is.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3794:336,avoid,avoid,336,https://hail.is,https://github.com/hail-is/hail/pull/3794,1,['avoid'],['avoid']
Safety,"`RegionValueBuilder` isn't serializable. Therefore, I had to initialize it for each seqop in `treeAggregate`. Is there a way to avoid this? @danking",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3418:128,avoid,avoid,128,https://hail.is,https://github.com/hail-is/hail/pull/3418,1,['avoid'],['avoid']
Safety,"```; # gsutil cat gs://hail-ci-0-1/ci/46808cb\*/038a6de7ce33b218b8d45160f224cae1feaf1c5a/job.log; failed to get container status {"""" """"}: rpc error: code = OutOfRange desc = EOF% . ```; The three most recent commits:. ```; * 6d17db60a - (23 minutes ago) add batch client timeouts, set timeout in ci (#4586) - Daniel King (HEAD -> fix-batch-client, hi/master, master); * 74d5e7560 - (23 minutes ago) fix a few issues with hl.plot.histogram (#4681) - Tim Poterba; * 038a6de7c - (45 minutes ago) refresh from batch (#4670) - Daniel King; ```. #4586 was never tested against 75d5e7560. This is bad. We can look at the log of statuses posted to GitHub:; ```; # curl -sSL api.github.com/repos/hail-is/hail/commits/46808cb224dbaa2d4fbae9f4fc90439e2eed8730/statuses | less; ```; [46808cb224dbaa2d4fbae9f4fc90439e2eed8730-statuses.txt](https://github.com/hail-is/hail/files/2531246/46808cb224dbaa2d4fbae9f4fc90439e2eed8730-statuses.txt). Before the merge status goes in we see this one:; ```; {; ""url"": ""https://api.github.com/repos/hail-is/hail/statuses/46808cb224dbaa2d4fbae9f4fc90439e2eed8730"",; ""avatar_url"": ""https://avatars2.githubusercontent.com/u/106194?v=4"",; ""id"": 5728320639,; ""node_id"": ""MDEzOlN0YXR1c0NvbnRleHQ1NzI4MzIwNjM5"",; ""state"": ""success"",; ""description"": ""successful build"",; ""target_url"": ""https://storage.googleapis.com/hail-ci-0-1/ci/46808cb224dbaa2d4fbae9f4fc90439e2eed8730/038a6de7ce33b218b8d45160f224cae1feaf1c5a/index.html"",; ""context"": ""hail-ci-0-1"",; ""created_at"": ""2018-10-30T18:51:09Z"",; ""updated_at"": ""2018-10-30T18:51:09Z"",; ""creator"": {; ""login"": ""danking"", ...; }; },; ```. and before that:. ```; {; ""url"": ""https://api.github.com/repos/hail-is/hail/statuses/46808cb224dbaa2d4fbae9f4fc90439e2eed8730"",; ""avatar_url"": ""https://avatars2.githubusercontent.com/u/106194?v=4"",; ""id"": 5728220065,; ""node_id"": ""MDEzOlN0YXR1c0NvbnRleHQ1NzI4MjIwMDY1"",; ""state"": ""pending"",; ""description"": ""build 38 pending. target: 038a6de7ce33"",; ""target_url"": null,; ""context"": ""hail-ci-0-1"",; ""cr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4685:271,timeout,timeouts,271,https://hail.is,https://github.com/hail-is/hail/issues/4685,2,['timeout'],"['timeout', 'timeouts']"
Safety,"```; # hailctl auth copy-paste-login LXTFDIXKJ6N4Q23G2Q53VQ7GDOGUTYUUWHQI7EZZ6XHLUKDUFZGQ==== ; Logged into namespace dking as dking.; ```; It is safe to reprint this token because it is not only expired but already used. Tokens live for 5 minutes and can be used only once. You can try logging in with that token (to dking's auth) to see for yourself. The user page now includes a button to retrieve a fresh copy-paste token:. ![Screen Shot 2020-04-15 at 11 35 20 PM](https://user-images.githubusercontent.com/106194/79411894-14315c80-7f72-11ea-9c94-e769919da09f.png). This sends you to a rather ugly page that includes a base32 encoded (dashes create word breaks which makes highlighting annoying, so I preferred base32 over base64) token. That token is good for 5 minutes. You copy that token and log in as above. ![Screen Shot 2020-04-19 at 4 16 27 PM](https://user-images.githubusercontent.com/106194/79698776-2b659800-8259-11ea-8697-ea41aa3a6c23.png)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8563:146,safe,safe,146,https://hail.is,https://github.com/hail-is/hail/pull/8563,1,['safe'],['safe']
Safety,"```; Traceback (most recent call last):; File ""/tmp/09d98b2f-4a41-4652-9eba-e319bfda2ca4/sandbox.py"", line 17, in <module>; pprint(hc.read('%s/variantqc/exacv2_rf.vds' % root, sites_only=True).filter_variants_intervals('gs://exac2/temp').head()); File ""/tmp/09d98b2f-4a41-4652-9eba-e319bfda2ca4/utils.py"", line 201, in head; return json.loads(self.variants_keytable().to_dataframe().toJSON().first()); File ""/usr/lib/spark/python/lib/pyspark.zip/pyspark/rdd.py"", line 1328, in first; File ""/usr/lib/spark/python/lib/pyspark.zip/pyspark/rdd.py"", line 1310, in take; File ""/usr/lib/spark/python/lib/pyspark.zip/pyspark/context.py"", line 933, in runJob; File ""/usr/lib/spark/python/lib/py4j-0.10.3-src.zip/py4j/java_gateway.py"", line 1133, in __call__; File ""/usr/lib/spark/python/lib/pyspark.zip/pyspark/sql/utils.py"", line 63, in deco; for criterion, pop in criteria_pops:; File ""/usr/lib/spark/python/lib/py4j-0.10.3-src.zip/py4j/protocol.py"", line 319, in get_return_value; py4j.protocol.Py4JJavaError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.runJob.; : org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 5.0 failed 20 times, most recent failure: Lost task 0.19 in stage 5.0 (TID 20022, exac-sw-3pdd.c.broad-mpg-gnomad.internal): java.lang.ClassCastException: scala.Tuple2 cannot be cast to org.apache.spark.sql.Row; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1311:1124,abort,aborted,1124,https://hail.is,https://github.com/hail-is/hail/issues/1311,1,['abort'],['aborted']
Safety,"```; Traceback (most recent call last):; File ""/usr/local/lib/python3.6/site-packages/batch/worker.py"", line 287, in run; name=f'batch-{self.job.batch_id}-job-{self.job.job_id}-{self.name}'); File ""/usr/local/lib/python3.6/site-packages/batch/worker.py"", line 91, in docker_call_retry; return await f(*args, **kwargs); File ""/usr/local/lib/python3.6/site-packages/aiodocker/containers.py"", line 48, in create; url, method=""POST"", data=config, params=kwargs; File ""/usr/local/lib/python3.6/site-packages/aiodocker/docker.py"", line 223, in _query_json; path, method, params=params, data=data, headers=headers, timeout=timeout; File ""/usr/local/lib/python3.6/site-packages/aiodocker/docker.py"", line 291, in __aenter__; resp = await self._coro; File ""/usr/local/lib/python3.6/site-packages/aiodocker/docker.py"", line 206, in _do_query; raise DockerError(response.status, json.loads(what.decode(""utf8""))); aiodocker.exceptions.DockerError: DockerError(404, 'No such image: gcr.io/hail-vdc/ci-utils:e9pnvtf1078g'); ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8201:608,timeout,timeout,608,https://hail.is,https://github.com/hail-is/hail/issues/8201,2,['timeout'],['timeout']
Safety,"```; Traceback (most recent call last):; File ""/usr/local/lib/python3.7/dist-packages/batch/worker/worker.py"", line 525, in run_until_done_or_deleted; return step.result(); File ""/usr/lib/python3.7/asyncio/futures.py"", line 181, in result; raise self._exception; File ""/usr/lib/python3.7/asyncio/tasks.py"", line 249, in __step; result = coro.send(None); File ""/usr/local/lib/python3.7/dist-packages/batch/worker/worker.py"", line 695, in _run; raise ContainerTimeoutError(f'timed out after {self.timeout}s'); ContainerTimeoutError: timed out after 5s; ```. ```; Traceback (most recent call last):; File ""/usr/local/lib/python3.7/dist-packages/batch/worker/worker.py"", line 2378, in run_job; await job.run(); File ""/usr/local/lib/python3.7/dist-packages/batch/worker/worker.py"", line 1695, in run; await self.mark_complete(); File ""/usr/local/lib/python3.7/dist-packages/batch/worker/worker.py"", line 1392, in mark_complete; json.dumps(full_status),; File ""/usr/local/lib/python3.7/dist-packages/hailtop/utils/utils.py"", line 722, in retry_transient_errors; return await f(*args, **kwargs); File ""/usr/local/lib/python3.7/dist-packages/batch/file_store.py"", line 76, in write_status_file; await self.fs.write(url, status.encode('utf-8')); File ""/usr/local/lib/python3.7/dist-packages/hailtop/aiotools/fs/fs.py"", line 208, in write; await retry_transient_errors(_write); File ""/usr/local/lib/python3.7/dist-packages/hailtop/utils/utils.py"", line 722, in retry_transient_errors; return await f(*args, **kwargs); File ""/usr/local/lib/python3.7/dist-packages/hailtop/aiotools/fs/fs.py"", line 205, in _write; async with await self.create(url, retry_writes=False) as f:; File ""/usr/local/lib/python3.7/dist-packages/hailtop/aiocloud/aiogoogle/client/storage_client.py"", line 543, in create; return await self._storage_client.insert_object(bucket, name, params=params); AttributeError: 'GoogleStorageAsyncFS' object has no attribute '_storage_client'; ```. ```; Traceback (most recent call last):; File ""/usr/l",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11686:495,timeout,timeout,495,https://hail.is,https://github.com/hail-is/hail/pull/11686,1,['timeout'],['timeout']
Safety,"```; Traceback (most recent call last):; File ""/usr/share/python-wheels/urllib3-1.22-py2.py3-none-any.whl/urllib3/response.py"", line 302, in _error_catcher; yield; File ""/usr/share/python-wheels/urllib3-1.22-py2.py3-none-any.whl/urllib3/response.py"", line 384, in read; data = self._fp.read(amt); File ""/usr/lib/python3.6/http/client.py"", line 459, in read; n = self.readinto(b); File ""/usr/lib/python3.6/http/client.py"", line 503, in readinto; n = self.fp.readinto(b); File ""/usr/lib/python3.6/socket.py"", line 586, in readinto; return self._sock.recv_into(b); File ""/usr/lib/python3.6/ssl.py"", line 1012, in recv_into; return self.read(nbytes, buffer); File ""/usr/lib/python3.6/ssl.py"", line 874, in read; return self._sslobj.read(len, buffer); File ""/usr/lib/python3.6/ssl.py"", line 631, in read; v = self._sslobj.read(len, buffer); socket.timeout: The read operation timed out. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/usr/lib/python3/dist-packages/pip/basecommand.py"", line 215, in main; status = self.run(options, args); File ""/usr/lib/python3/dist-packages/pip/commands/install.py"", line 342, in run; requirement_set.prepare_files(finder); File ""/usr/lib/python3/dist-packages/pip/req/req_set.py"", line 380, in prepare_files; ignore_dependencies=self.ignore_dependencies)); File ""/usr/lib/python3/dist-packages/pip/req/req_set.py"", line 620, in _prepare_file; session=self.session, hashes=hashes); File ""/usr/lib/python3/dist-packages/pip/download.py"", line 821, in unpack_url; hashes=hashes; File ""/usr/lib/python3/dist-packages/pip/download.py"", line 659, in unpack_http_url; hashes); File ""/usr/lib/python3/dist-packages/pip/download.py"", line 882, in _download_http_url; _download_url(resp, link, content_file, hashes); File ""/usr/lib/python3/dist-packages/pip/download.py"", line 603, in _download_url; hashes.check_against_chunks(downloaded_chunks); File ""/usr/lib/python3/dist-packages/pip/utils/hashes.py"", line 46, ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8390:843,timeout,timeout,843,https://hail.is,https://github.com/hail-is/hail/issues/8390,1,['timeout'],['timeout']
Safety,"```; Write out vds: gs://seqr-hail/datasets/GRCh38/1kg/1kg.liftover.vep.vds; [Stage 5:======================================================> (22 + 1) / 23]Traceback (most recent call last):; File ""/tmp/956b6743-f2ac-4bf6-a82e-20a431c52c1c/do_vep.py"", line 22, in <module>; vds.write(output_vds, overwrite=True); File ""<decorator-gen-90>"", line 2, in write; File ""/home/ec2-user/BuildAgent/work/c38e75e72b769a7c/python/hail/java.py"", line 113, in handle_py4j; hail.java.FatalError: AssertionError: assertion failed. Java stack trace:; org.apache.spark.SparkException: Job aborted.; 	at org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand$$anonfun$run$1.apply$mcV$sp(InsertIntoHadoopFsRelationCommand.scala:149); 	at org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand$$anonfun$run$1.apply(InsertIntoHadoopFsRelationCommand.scala:115); 	at org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand$$anonfun$run$1.apply(InsertIntoHadoopFsRelationCommand.scala:115); 	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:57); 	at org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:115); 	at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:58); 	at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:56); 	at org.apache.spark.sql.execution.command.ExecutedCommandExec.doExecute(commands.scala:74); 	at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:115); 	at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:115); 	at org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:136); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); 	at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:13",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1822:572,abort,aborted,572,https://hail.is,https://github.com/hail-is/hail/issues/1822,1,['abort'],['aborted']
Safety,```; def collectRowKeys(): Array[Annotation] = {; val rowKeyIdx = mv.typ.rowKeyFieldIdx. mv.rvd.toRows.map[Any] { r =>; Row.fromSeq(rowKeyIdx.map(r.get)); }; .collect(); }; ```. toRows calls `SafeRow`. WTF,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6236:192,Safe,SafeRow,192,https://hail.is,https://github.com/hail-is/hail/issues/6236,1,['Safe'],['SafeRow']
Safety,"```; dking@wmb16-359 # kubectl get pods -l app=site ; NAME READY STATUS RESTARTS AGE; site-deployment-584746fc8c-ldfpd 1/1 Running 0 1h; site-deployment-5b84fc86bf-k9jtr 0/1 Terminating 0 3m; site-deployment-5cdc5c7679-fwb97 0/1 ContainerCreating 0 5s; ```. warning from `kubectl describe pod site-deployment-5b84fc86bf-k9jtr`. ```; Warning FailedMount 47s kubelet, gke-cs-test-default-pool-ef886a34-5231 Unable to mount volumes for pod ""site-deployment-5b84fc86bf-k9jtr_default(e75ca5a2-c1b0-11e8-a2cb-42010a8000fa)"": timeout expired waiting for volumes to attach/mount for pod ""default""/""site-deployment-5b84fc86bf-k9jtr"". list of unattached/unmounted volumes=[letsencrypt-certs]; ```. `site-deployment-5cdc5c7679-fwb97` is still pulling the image, I anticipate it will have the same issue.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4452:519,timeout,timeout,519,https://hail.is,https://github.com/hail-is/hail/issues/4452,1,['timeout'],['timeout']
Safety,"```; gsutil cat gs://hail-ci-0-1/deploy/ef349a51016f\*/job-log; ```. the last few lines:. ```; + make push-batch; docker build -t batch .; time=""2018-09-26T00:14:20Z"" level=error msg=""failed to dial gRPC: cannot connect to the Docker daemon. Is 'docker daemon' running on this host?: dial unix /var/run/docker.sock: connect: permission denied""; Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Post http://%2Fvar%2Frun%2Fdocker.sock/v1.38/build?buildargs=%7B%7D&cachefrom=%5B%5D&cgroupparent=&cpuperiod=0&cpuquota=0&cpusetcpus=&cpusetmems=&cpushares=0&dockerfile=Dockerfile&labels=%7B%7D&memory=0&memswap=0&networkmode=default&rm=1&session=vhnl6wchhs00sgt8raa35j7m7&shmsize=0&t=batch&target=&ulimits=null&version=1: dial unix /var/run/docker.sock: connect: permission denied; time=""2018-09-26T00:14:20Z"" level=error msg=""Can't add file /hail/repo/batch/batch/server.py to tar: io: read/write on closed pipe""; Makefile:14: recipe for target 'build-batch' failed; make: *** [build-batch] Error 1; ```. this is failing all deploys of hail, which is safe, but it prevents our users from getting updates.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4443:1103,safe,safe,1103,https://hail.is,https://github.com/hail-is/hail/issues/4443,1,['safe'],['safe']
Safety,"```; hail read -i profile.vds annotatesamples tsv -i sampleInfo.tsv -t 'Age: Int, Health: Double' -r sa.info filtersamples --keep -c 'sa.info.Health > 0.2' linreg -y sa.info.Health -c 'sa.info.Age' -r va.linreg exportvariants -c 'Variant=v, Beta = va.linreg.beta, Pval = va.linreg.pval' -o linreg.tsv; ```. ```; [Stage 1:> (0 + 7) / 7]hail: exportvariants: caught exception: org.apache.spark.SparkException: Job aborted due to stage failure: Task 5 in stage 1.0 failed 1 times, most recent failure: Lost task 5.0 in stage 1.0 (TID 13, localhost): java.lang.ArrayIndexOutOfBoundsException: 357; at org.broadinstitute.hail.methods.LinRegBuilder$$anonfun$stats$1.apply$mcVI$sp(LinearRegression.scala:80); at org.broadinstitute.hail.methods.LinRegBuilder$$anonfun$stats$1.apply(LinearRegression.scala:80); at org.broadinstitute.hail.methods.LinRegBuilder$$anonfun$stats$1.apply(LinearRegression.scala:80); at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); at scala.collection.mutable.ArrayOps$ofInt.foreach(ArrayOps.scala:156); at org.broadinstitute.hail.methods.LinRegBuilder.stats(LinearRegression.scala:80); at org.broadinstitute.hail.methods.LinearRegression$$anonfun$apply$4.apply(LinearRegression.scala:130); at org.broadinstitute.hail.methods.LinearRegression$$anonfun$apply$4.apply(LinearRegression.scala:129); at org.apache.spark.rdd.PairRDDFunctions$$anonfun$mapValues$1$$anonfun$apply$41$$anonfun$apply$42.apply(PairRDDFunctions.scala:700); at org.apache.spark.rdd.PairRDDFunctions$$anonfun$mapValues$1$$anonfun$apply$41$$anonfun$apply$42.apply(PairRDDFunctions.scala:700); at scala.collection.Iterator$$anon$11.next(Iterator.scala:328); at scala.collection.Iterator$$anon$20.next(Iterator.scala:635); at scala.collection.Iterator$$anon$20.next(Iterator.scala:633); at scala.collection.Iterator$$anon$11.next(Iterator.scala:328); at scala.collection.Iterator$$anon$11.next(Iterator.scala:328); at scala.collection.Iterator$$anon$11.next(Iterator.scala:328); a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/336:412,abort,aborted,412,https://hail.is,https://github.com/hail-is/hail/issues/336,1,['abort'],['aborted']
Safety,"```; hail.utils.java.FatalError: AssertionError: assertion failed. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 567 in stage 86.0 failed 20 times, most recent failure: Lost task 567.19 in stage 86.0 (TID 59449, exomes-sw-73zg.c.broad-mpg-gnomad.internal, executor 41): java.lang.AssertionError: assertion failed; 	at scala.Predef$.assert(Predef.scala:156); 	at is.hail.annotations.RegionValueBuilder.addRegionValue(RegionValueBuilder.scala:417); 	at is.hail.annotations.RegionValueBuilder.addField(RegionValueBuilder.scala:345); 	at is.hail.annotations.RegionValueBuilder.addField(RegionValueBuilder.scala:351); 	at is.hail.expr.ir.MatrixAggregateColsByKey$$anonfun$33$$anonfun$apply$15.apply(MatrixIR.scala:1016); 	at is.hail.expr.ir.MatrixAggregateColsByKey$$anonfun$33$$anonfun$apply$15.apply(MatrixIR.scala:972); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$18$$anon$3.next(OrderedRVD.scala:1106); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$18$$anon$3.next(OrderedRVD.scala:1100); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$18$$anon$3.next(OrderedRVD.scala:1106); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$18$$anon$3.next(OrderedRVD.scala:1100); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$18$$anon$3.next(OrderedRVD.scala:1106); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$18$$anon$3.next(OrderedRVD.scala:1100); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at scala.collection.Iterator$class.foreach(Iterator.scala:89",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4263:123,abort,aborted,123,https://hail.is,https://github.com/hail-is/hail/issues/4263,1,['abort'],['aborted']
Safety,"```; ht.join(ht2, how='outer'); ```; results in:; ```; 2018-10-02 16:18:34 Hail: INFO: Table.join: renamed the following fields on the right to avoid name conflicts:; 'context' -> 'context_1'; 'ref' -> 'ref_1'; 'alt' -> 'alt_1'; 'methylation_level' -> 'methylation_level_1'; 'exome_coverage' -> 'exome_coverage_1'; ```; where those 5 are the keys, so obviously nothing actually got renamed. The join still works fine, but the warning is wrong",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4485:144,avoid,avoid,144,https://hail.is,https://github.com/hail-is/hail/issues/4485,1,['avoid'],['avoid']
Safety,"```; mu = mutation_ht.aggregate(hl.agg.group_by(; hl.struct(context=mutation_ht.context, ref=mutation_ht.ref, alt=mutation_ht.alt,; methylation_level=mutation_ht.methylation_level),; hl.agg.collect(mutation_ht.mu_snp))); ```; got:; ```; Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 1.0 failed 1 times, most recent failure: Lost task 1.0 in stage 1.0 (TID 11, localhost, executor driver): com.esotericsoftware.kryo.KryoException: sun.reflect.generics.reflectiveObjects.NotImplementedException; Serialization trace:; m (is.hail.annotations.aggregators.KeyedRegionValueAggregator); 	at com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectField.java:101); 	at com.esotericsoftware.kryo.serializers.FieldSerializer.write(FieldSerializer.java:518); 	at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:628); 	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.write(DefaultArraySerializers.java:366); 	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.write(DefaultArraySerializers.java:307); 	at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:628); 	at org.apache.spark.serializer.KryoSerializerInstance.serialize(KryoSerializer.scala:315); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:386); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); Caused by: sun.reflect.generics.reflectiveObjects.NotImplementedException; 	at is.hail.annotations.UnKryoSerializable$class.write(UnsafeRow.scala:15); 	at is.hail.annotations.UnsafeRow.write(UnsafeRow.scala:141); 	at com.esotericsoftware.kryo.serializers.DefaultSerializers$KryoSerializableSerializer.write(DefaultSerializers.java:505); 	at com.esotericsoftware.kryo.serializers.DefaultSerializers$KryoSerializa",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4215:293,abort,aborted,293,https://hail.is,https://github.com/hail-is/hail/issues/4215,1,['abort'],['aborted']
Safety,```Error summary: Error: Multiple ES-Hadoop versions detected in the classpath; please use only one; jar:file:/tmp/7a54aa23-f38b-40e4-8068-3ea48ee212a0/hail-annotateAlleles01.jar; jar:file:/usr/lib/spark/jars/hail-0.1-6e815ac3d973-Spark-2.0.2.jar; ```,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2272:53,detect,detected,53,https://hail.is,https://github.com/hail-is/hail/issues/2272,1,['detect'],['detected']
Safety,"`boundary` is safe because after `it.next()` is called, the previous; value is no longer needed. Fixes #8163",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8274:14,safe,safe,14,https://hail.is,https://github.com/hail-is/hail/pull/8274,1,['safe'],['safe']
Safety,"`curlylint` doesn't like logical blocks that produce incomplete html tags. This is the only instance in our codebase where we do that though. In either path of the if/else block we produce an open `a` tag and then close it out outside of the block. I reorganized it to avoid this and think it's actually more clear, and that creating open tags like this is a footgun to avoid since it's super easy not to close them (which we have had a lot).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10412:269,avoid,avoid,269,https://hail.is,https://github.com/hail-is/hail/pull/10412,2,['avoid'],['avoid']
Safety,`hailctl dataproc modify`'s `--update-hail-version` and `--wheel` arguments cannot be used together. Using argparse's [mutually exclusive group](https://docs.python.org/3/library/argparse.html#mutual-exclusion) to enforce that makes the usage/help text clearer. ```; usage: hailctl dataproc modify [-h] [--num-workers NUM_WORKERS]; [--num-preemptible-workers NUM_PREEMPTIBLE_WORKERS]; [--graceful-decommission-timeout GRACEFUL_DECOMMISSION_TIMEOUT]; [--max-idle MAX_IDLE] [--dry-run] [--zone ZONE]; [--update-hail-version | --wheel WHEEL]; name; ```,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8918:410,timeout,timeout,410,https://hail.is,https://github.com/hail-is/hail/pull/8918,1,['timeout'],['timeout']
Safety,"`hl.eval_expr(hl.literal([1,2,3])/hl.literal([1,2]))`. ```; FatalError: HailException: array index out of bounds: 2 / 2. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 36.0 failed 20 times, most recent failure: Lost task 0.19 in stage 36.0 (TID 55, exomes-w-1.c.broad-mpg-gnomad.internal, executor 3): is.hail.utils.HailException: array index out of bounds: 2 / 2; 	at is.hail.codegen.generated.C166.apply(Unknown Source); 	at is.hail.codegen.generated.C166.apply(Unknown Source); 	at is.hail.expr.TableMapRows$$anonfun$55$$anonfun$apply$29.apply(Relational.scala:1877); 	at is.hail.expr.TableMapRows$$anonfun$55$$anonfun$apply$29.apply(Relational.scala:1872); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at scala.collection.Iterator$class.foreach(Iterator.scala:893); 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); 	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59); 	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104); 	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48); 	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310); 	at scala.collection.AbstractIterator.to(Iterator.scala:1336); 	at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302); 	at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1336); 	at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289); 	at scala.collection.AbstractIte",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3653:177,abort,aborted,177,https://hail.is,https://github.com/hail-is/hail/issues/3653,1,['abort'],['aborted']
Safety,"`httpx.ClientSession` did not include the logic to set up the timeout. I do; not recall why I had a factory function distinct from the class itself. That; was a mistake. I leave the factory function because it is used prevasively.; However, now, allocating the class itself is also OK.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11770:62,timeout,timeout,62,https://hail.is,https://github.com/hail-is/hail/pull/11770,1,['timeout'],['timeout']
Safety,"`inttypes.h` is definitely needed for standards compliant usage of; printf format strings. The latter is safe, but should not be necessary; on recent C++ compilers with recent stdlibs. Compiling with a C++ compiler and a somewhat old version of glibc will; not provide PRIu64 and friends unless this macro is defined before; including `inttypes.h`. For more details see [1] with associated comments; and the related bug fix [2] which landed in glibc 2.18. [1] http://stackoverflow.com/questions/8132399/how-to-printf-uint64-t; [2] https://sourceware.org/bugzilla/show_bug.cgi?id=15366",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1330:105,safe,safe,105,https://hail.is,https://github.com/hail-is/hail/pull/1330,1,['safe'],['safe']
Safety,"`java.nio` avoids unnecessary copies. We suspect we may see a 2-3x improvement in Zstd decoding speed by passing it `ByteBuffer` instead of `Array[Byte]`. We also suspect there may be pervasive (but minor) improvements to Hail's I/O infrastructure. We should start with the egregious examples. Consider `AzureStorageFS.createNoCompression`'s [`OutputStream`](https://github.com/hail-is/hail/blob/main/hail/src/main/scala/is/hail/io/fs/AzureStorageFS.scala#L332-L342):; ```scala; val os: PositionedOutputStream = new FSPositionedOutputStream(4 * 1024 * 1024) {; private[this] val client: BlockBlobClient = blockBlobClient; private[this] val blobOutputStream = client.getBlobOutputStream(true). override def flush(): Unit = {; bb.flip(). if (bb.limit() > 0) {; blobOutputStream.write(bb.array(), 0, bb.limit()); }. bb.clear(); }; // ...; }; ```. Notice how we already have a `ByteBuffer` but we convert it to an array and send that to the OutputStream. Instead, we could just use the [`ByteChannel` methods of `BlockBlobClient`](https://learn.microsoft.com/en-us/java/api/com.azure.storage.blob.specialized.blockblobclient?view=azure-java-stable#com-azure-storage-blob-specialized-blockblobclient-openseekablebytechannelwrite(com-azure-storage-blob-options-blockblobseekablebytechannelwriteoptions)). The [read case also supports a channel](https://learn.microsoft.com/en-us/java/api/com.azure.storage.blob.specialized.blobclientbase?view=azure-java-stable#com-azure-storage-blob-specialized-blobclientbase-openseekablebytechannelread(com-azure-storage-blob-options-blobseekablebytechannelreadoptions-com-azure-core-util-context)). The next, more complicated problem, is the InputBuffer and OutputBuffer interfaces. These assume their sources/sinks are `java.io.InputStream` and `java.io.OutputStream`. Moreover, they too rely on and expose `Array[Byte]` interfaces (e.g. `readBytesArray` and the implementation of `StreamInputBuffer.readBytes`). Let's start with InputBuffer and the decoders and use de",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13840:11,avoid,avoids,11,https://hail.is,https://github.com/hail-is/hail/issues/13840,1,['avoid'],['avoids']
Safety,`orjson` 3.9.15 fixed the rare segfault that we saw in `3.9.11`. Besides just updating to latest patch and minor versions:. - Removed a redundant requirement of `orjson` in `gear/requirements.txt` -- it inherits `orjson` from hailtop; - Bokeh `3.4` made a breaking change w.r.t. the `circle` method on figures. I have restricted the bounds for `bokeh` to avoid this breaking change but will follow up with a PR that changes our usage of bokeh to follow the deprecation/upgrade advice and undo the bounds restriction,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14471:136,redund,redundant,136,https://hail.is,https://github.com/hail-is/hail/pull/14471,2,"['avoid', 'redund']","['avoid', 'redundant']"
Safety,"`orjson` is a perennial issue. We could (and probably should) set an upper limit pin that is compatible with most Broad-issued Macbooks. In the meantime, hopefully this doc improvement will help users avoid the issue themselves.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13099:201,avoid,avoid,201,https://hail.is,https://github.com/hail-is/hail/pull/13099,1,['avoid'],['avoid']
Safety,"a href=""https://github-redirect.dependabot.com/googleapis/python-storage/issues/703"">#703</a>) (<a href=""https://github.com/googleapis/python-storage/commit/bcde0ec619d7d303892bcc0863b7f977c79f7649"">bcde0ec</a>)</li>; </ul>; <h3>Bug Fixes</h3>; <ul>; <li>add user agent in python-storage when calling resumable media (<a href=""https://github.com/googleapis/python-storage/commit/c7bf615909a04f3bab3efb1047a9f4ba659bba19"">c7bf615</a>)</li>; <li><strong>deps:</strong> require google-api-core&gt;=1.31.5, &gt;=2.3.2 (<a href=""https://github-redirect.dependabot.com/googleapis/python-storage/issues/722"">#722</a>) (<a href=""https://github.com/googleapis/python-storage/commit/e9aab389f868799d4425133954bad4f1cbb85786"">e9aab38</a>)</li>; <li>Fix BlobReader handling of interleaved reads and seeks (<a href=""https://github-redirect.dependabot.com/googleapis/python-storage/issues/721"">#721</a>) (<a href=""https://github.com/googleapis/python-storage/commit/5d1cfd2050321481a3bc4acbe80537ea666506fa"">5d1cfd2</a>)</li>; <li>retry client side requests timeout (<a href=""https://github-redirect.dependabot.com/googleapis/python-storage/issues/727"">#727</a>) (<a href=""https://github.com/googleapis/python-storage/commit/e0b3b354d51e4be7c563d7f2f628a7139df842c0"">e0b3b35</a>)</li>; </ul>; <h3>Documentation</h3>; <ul>; <li>fixed download_blob_to_file example (<a href=""https://github-redirect.dependabot.com/googleapis/python-storage/issues/704"">#704</a>) (<a href=""https://github.com/googleapis/python-storage/commit/2c94d98ed21cc768cfa54fac3d734254fc4d8480"">2c94d98</a>)</li>; </ul>; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/googleapis/python-storage/blob/main/CHANGELOG.md"">google-cloud-storage's changelog</a>.</em></p>; <blockquote>; <h2><a href=""https://github.com/googleapis/python-storage/compare/v2.1.0...v2.2.0"">2.2.0</a> (2022-03-14)</h2>; <h3>Features</h3>; <ul>; <li>allow no project in client methods using storage emulato",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11578:1580,timeout,timeout,1580,https://hail.is,https://github.com/hail-is/hail/pull/11578,1,['timeout'],['timeout']
Safety,"a href=""https://github-redirect.dependabot.com/googleapis/python-storage/issues/703"">#703</a>) (<a href=""https://github.com/googleapis/python-storage/commit/bcde0ec619d7d303892bcc0863b7f977c79f7649"">bcde0ec</a>)</li>; </ul>; <h3>Bug Fixes</h3>; <ul>; <li>add user agent in python-storage when calling resumable media (<a href=""https://github.com/googleapis/python-storage/commit/c7bf615909a04f3bab3efb1047a9f4ba659bba19"">c7bf615</a>)</li>; <li><strong>deps:</strong> require google-api-core&gt;=1.31.5, &gt;=2.3.2 (<a href=""https://github-redirect.dependabot.com/googleapis/python-storage/issues/722"">#722</a>) (<a href=""https://github.com/googleapis/python-storage/commit/e9aab389f868799d4425133954bad4f1cbb85786"">e9aab38</a>)</li>; <li>Fix BlobReader handling of interleaved reads and seeks (<a href=""https://github-redirect.dependabot.com/googleapis/python-storage/issues/721"">#721</a>) (<a href=""https://github.com/googleapis/python-storage/commit/5d1cfd2050321481a3bc4acbe80537ea666506fa"">5d1cfd2</a>)</li>; <li>retry client side requests timeout (<a href=""https://github-redirect.dependabot.com/googleapis/python-storage/issues/727"">#727</a>) (<a href=""https://github.com/googleapis/python-storage/commit/e0b3b354d51e4be7c563d7f2f628a7139df842c0"">e0b3b35</a>)</li>; </ul>; <h3>Documentation</h3>; <ul>; <li>fixed download_blob_to_file example (<a href=""https://github-redirect.dependabot.com/googleapis/python-storage/issues/704"">#704</a>) (<a href=""https://github.com/googleapis/python-storage/commit/2c94d98ed21cc768cfa54fac3d734254fc4d8480"">2c94d98</a>)</li>; </ul>; <h2><a href=""https://github.com/googleapis/python-storage/compare/v2.0.0...v2.1.0"">2.1.0</a> (2022-01-19)</h2>; <h3>Features</h3>; <ul>; <li>add turbo replication support and samples (<a href=""https://github-redirect.dependabot.com/googleapis/python-storage/issues/622"">#622</a>) (<a href=""https://github.com/googleapis/python-storage/commit/4dafc815470480ce9de7f0357e331d3fbd0ae9b7"">4dafc81</a>)</li>; <li>avoid authenticati",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11578:3585,timeout,timeout,3585,https://hail.is,https://github.com/hail-is/hail/pull/11578,1,['timeout'],['timeout']
Safety,"a href=""https://github.com/googleapis/python-storage/commit/8789afaaa1b2bd6f03fae72e3d87ce004ec10129"">8789afa</a>)</li>; <li>remove python 3.6 support (<a href=""https://github-redirect.dependabot.com/googleapis/python-storage/issues/689"">#689</a>) (<a href=""https://github.com/googleapis/python-storage/commit/8aa4130ee068a1922161c8ca54a53a4a51d65ce0"">8aa4130</a>)</li>; </ul>; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/googleapis/python-storage/blob/main/CHANGELOG.md"">google-cloud-storage's changelog</a>.</em></p>; <blockquote>; <h2><a href=""https://github.com/googleapis/python-storage/compare/v2.0.0...v2.1.0"">2.1.0</a> (2022-01-19)</h2>; <h3>Features</h3>; <ul>; <li>add turbo replication support and samples (<a href=""https://github-redirect.dependabot.com/googleapis/python-storage/issues/622"">#622</a>) (<a href=""https://github.com/googleapis/python-storage/commit/4dafc815470480ce9de7f0357e331d3fbd0ae9b7"">4dafc81</a>)</li>; <li>avoid authentication with storage emulator (<a href=""https://github-redirect.dependabot.com/googleapis/python-storage/issues/679"">#679</a>) (<a href=""https://github.com/googleapis/python-storage/commit/8789afaaa1b2bd6f03fae72e3d87ce004ec10129"">8789afa</a>)</li>; <li>remove python 3.6 support (<a href=""https://github-redirect.dependabot.com/googleapis/python-storage/issues/689"">#689</a>) (<a href=""https://github.com/googleapis/python-storage/commit/8aa4130ee068a1922161c8ca54a53a4a51d65ce0"">8aa4130</a>)</li>; </ul>; <h2><a href=""https://github.com/googleapis/python-storage/compare/v1.44.0...v2.0.0"">2.0.0</a> (2022-01-12)</h2>; <h3>⚠ BREAKING CHANGES</h3>; <ul>; <li>Remove Python 2 support (<a href=""https://github-redirect.dependabot.com/googleapis/python-storage/issues/657"">#657</a>)</li>; </ul>; <h3>Features</h3>; <ul>; <li>Remove Python 2 support (<a href=""https://github-redirect.dependabot.com/googleapis/python-storage/issues/657"">#657</a>) (<a href=""https://github.com/goo",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11520:1897,avoid,avoid,1897,https://hail.is,https://github.com/hail-is/hail/pull/11520,1,['avoid'],['avoid']
Safety,a.collection.AbstractIterator.aggregate(Iterator.scala:1336); at org.apache.spark.rdd.RDD$$anonfun$aggregate$1$$anonfun$22.apply(RDD.scala:1113); at org.apache.spark.rdd.RDD$$anonfun$aggregate$1$$anonfun$22.apply(RDD.scala:1113); at org.apache.spark.SparkContext$$anonfun$33.apply(SparkContext.scala:2118); at org.apache.spark.SparkContext$$anonfun$33.apply(SparkContext.scala:2118); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:108); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3063:5291,abort,abortStage,5291,https://hail.is,https://github.com/hail-is/hail/issues/3063,2,['abort'],['abortStage']
Safety,"ach and found it; more work than the current approach. ---. My apologies for eliminating JVMProcess in this PR. It's an unrelated change which facilitated my; understanding of worker.py. I essentially inlined JVMProcess into JVMJob and eliminated any duplicative; code. ---. After making this change I restored the tests. Some tests had bitrotted. In the process of fixing; those tests, I found a few other bugs. Fixing these lower-level bugs unlocked a number of new; tests. One test (which was added since the service tests were removed) had to be marked as failing. Some; Hail operations rely on writing to the local file system. Implementing that properly in the Query; Worker will take some thought. Here are the bugs I fixed:. 1. Correct the error message raised when tests are run in a non-main thread (we look for this; message and start an event loop for Hail's async code because asyncio refuses to start an event; loop in a non-main thread). 2. Use a `SafeRow` to copy the globals data out of a Region and into durable, GC'ed objects. 3. Re-enable serialization of GoogleStorageFS (including its private key, which we really shouldn't; do; Tim is working on it), which was broken (presumably) when we changed Scala versions. The; `var` modifier ensures the name is compiled as a JVM field. 4. Correctly convert from a `Byte` to an `Int`. By default `Byte` to `Int` conversion (which is done; automatically when you return a `Byte` from a function whose return type is `Int`) is; sign-preserving. That means that the byte `0000 1111` is converted to the `Int` 15 and the byte; `1000 1111` is converted to the `Int` -113. The contract of; [`InputStream.read`](https://docs.oracle.com/javase/8/docs/api/java/io/InputStream.html#read--); is to return the unsigned integeral value of the next `Byte` or `-1` if we've reached the end of; the stream. `DataInputStream` treats any negative value as EOS which lead to perplexing EOSes; when reading data from GCS. 5. Retain the `gs://` protocol whe",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10314:2057,Safe,SafeRow,2057,https://hail.is,https://github.com/hail-is/hail/pull/10314,1,['Safe'],['SafeRow']
Safety,"add batch client timeouts, set timeout in ci",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4586:17,timeout,timeouts,17,https://hail.is,https://github.com/hail-is/hail/pull/4586,2,['timeout'],"['timeout', 'timeouts']"
Safety,added unsafe memcpy bytes to/from double,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2531:6,unsafe,unsafe,6,https://hail.is,https://github.com/hail-is/hail/pull/2531,1,['unsafe'],['unsafe']
Safety,"aj +</li>; <li>Mark Harfouche</li>; <li>Matti Picus</li>; <li>Panagiotis Zestanakis +</li>; <li>Peter Hawkins</li>; <li>Pradipta Ghosh</li>; <li>Ross Barnowski</li>; <li>Sayed Adel</li>; <li>Sebastian Berg</li>; <li>Syam Gadde +</li>; <li>dmbelov +</li>; <li>pkubaj +</li>; </ul>; <h2>Pull requests merged</h2>; <p>A total of 17 pull requests were merged for this release.</p>; <ul>; <li><a href=""https://redirect.github.com/numpy/numpy/pull/22965"">#22965</a>: MAINT: Update python 3.11-dev to 3.11.</li>; <li><a href=""https://redirect.github.com/numpy/numpy/pull/22966"">#22966</a>: DOC: Remove dangling deprecation warning</li>; <li><a href=""https://redirect.github.com/numpy/numpy/pull/22967"">#22967</a>: ENH: Detect CPU features on FreeBSD/powerpc64*</li>; <li><a href=""https://redirect.github.com/numpy/numpy/pull/22968"">#22968</a>: BUG: np.loadtxt cannot load text file with quoted fields separated...</li>; <li><a href=""https://redirect.github.com/numpy/numpy/pull/22969"">#22969</a>: TST: Add fixture to avoid issue with randomizing test order.</li>; <li><a href=""https://redirect.github.com/numpy/numpy/pull/22970"">#22970</a>: BUG: Fix fill violating read-only flag. (<a href=""https://redirect.github.com/numpy/numpy/issues/22959"">#22959</a>)</li>; <li><a href=""https://redirect.github.com/numpy/numpy/pull/22971"">#22971</a>: MAINT: Add additional information to missing scalar AttributeError</li>; <li><a href=""https://redirect.github.com/numpy/numpy/pull/22972"">#22972</a>: MAINT: Move export for scipy arm64 helper into main module</li>; <li><a href=""https://redirect.github.com/numpy/numpy/pull/22976"">#22976</a>: BUG, SIMD: Fix spurious invalid exception for sin/cos on arm64/clang</li>; <li><a href=""https://redirect.github.com/numpy/numpy/pull/22989"">#22989</a>: BUG: Ensure correct loop order in sin, cos, and arctan2</li>; <li><a href=""https://redirect.github.com/numpy/numpy/pull/23030"">#23030</a>: DOC: Add version added information for the strict parameter in...</li>; <li><a href=",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12898:1702,avoid,avoid,1702,https://hail.is,https://github.com/hail-is/hail/pull/12898,1,['avoid'],['avoid']
Safety,ala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); 	at scala.collection.AbstractTraversable.map(Traversable.scala:104); 	at org.json4s.Extraction$ClassInstanceBuilder.instantiate(Extraction.scala:546); 	at org.json4s.Extraction$ClassInstanceBuilder.result(Extraction.scala:597); 	at org.json4s.Extraction$$anonfun$extract$6.apply(Extraction.scala:400); 	at org.json4s.Extraction$$anonfun$extract$6.apply(Extraction.scala:392); 	at org.json4s.Extraction$.customOrElse(Extraction.scala:606); 	at org.json4s.Extraction$.extract(Extraction.scala:392); 	at org.json4s.Extraction$.extract(Extraction.scala:39); 	... 38 more. Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:2039); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:2027); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:2026); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2026); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:966); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:966); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:966); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2260); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2209); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGSche,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7044:12013,abort,abortStage,12013,https://hail.is,https://github.com/hail-is/hail/issues/7044,2,['abort'],['abortStage']
Safety,alculateConcordance.apply(CalculateConcordance.scala); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:280); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:214); 	at java.lang.Thread.run(Thread.java:748)java.lang.AssertionError: assertion failed; 	at scala.Predef$.assert(Predef.scala:156); 	at is.hail.annotations.Region.loadInt(Region.scala:36); 	at is.hail.expr.types.TBinary$.loadLength(TBinary.scala:62); 	at is.hail.annotations.UnsafeRow$.readBinary(UnsafeRow.scala:128); 	at is.hail.annotations.UnsafeRow$.readString(UnsafeRow.scala:139); 	at is.hail.annotations.UnsafeRow$.readAltAllele(UnsafeRow.scala:152); 	at is.hail.annotations.UnsafeRow$.readArrayAltAllele(UnsafeRow.scala:164); 	at is.hail.annotations.UnsafeRow$.read(UnsafeRow.scala:210); 	at is.hail.annotations.UnsafeRow.get(UnsafeRow.scala:257); 	at is.hail.expr.FilterVariants$$anonfun$10.apply(Relational.scala:503); 	at is.hail.expr.FilterVariants$$anonfun$10.apply(Relational.scala:500); 	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:463); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$9$$anon$5.hasNext(OrderedRVD.scala:658); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$9$$anon$5.hasNext(OrderedRVD.scala:658); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$9$$anon$5.hasNext(OrderedRVD.scala:658); 	at scala.collection.Itera,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2743:7938,Unsafe,UnsafeRow,7938,https://hail.is,https://github.com/hail-is/hail/issues/2743,1,['Unsafe'],['UnsafeRow']
Safety,alizer.write(FieldSerializer.java:518); 	at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:628); 	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.write(DefaultArraySerializers.java:366); 	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.write(DefaultArraySerializers.java:307); 	at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:628); 	at org.apache.spark.serializer.KryoSerializerInstance.serialize(KryoSerializer.scala:315); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:386); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); Caused by: sun.reflect.generics.reflectiveObjects.NotImplementedException; 	at is.hail.annotations.UnKryoSerializable$class.write(UnsafeRow.scala:15); 	at is.hail.annotations.UnsafeRow.write(UnsafeRow.scala:141); 	at com.esotericsoftware.kryo.serializers.DefaultSerializers$KryoSerializableSerializer.write(DefaultSerializers.java:505); 	at com.esotericsoftware.kryo.serializers.DefaultSerializers$KryoSerializableSerializer.write(DefaultSerializers.java:503); 	at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:628); 	at com.esotericsoftware.kryo.serializers.MapSerializer.write(MapSerializer.java:106); 	at com.esotericsoftware.kryo.serializers.MapSerializer.write(MapSerializer.java:39); 	at com.esotericsoftware.kryo.Kryo.writeObject(Kryo.java:552); 	at com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectField.java:80); 	... 10 more; Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1517); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1505); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortS,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4215:1765,Unsafe,UnsafeRow,1765,https://hail.is,https://github.com/hail-is/hail/issues/4215,1,['Unsafe'],['UnsafeRow']
Safety,"allbacks, polls for I/O,; schedules the resulting callbacks, and finally schedules; 'call_later' callbacks.; """"""; ; sched_count = len(self._scheduled); if (sched_count > _MIN_SCHEDULED_TIMER_HANDLES and; self._timer_cancelled_count / sched_count >; _MIN_CANCELLED_TIMER_HANDLES_FRACTION):; # Remove delayed calls that were cancelled if their number; # is too high; new_scheduled = []; for handle in self._scheduled:; if handle._cancelled:; handle._scheduled = False; else:; new_scheduled.append(handle); ; heapq.heapify(new_scheduled); self._scheduled = new_scheduled; self._timer_cancelled_count = 0; else:; # Remove delayed calls that were cancelled from head of queue.; while self._scheduled and self._scheduled[0]._cancelled:; self._timer_cancelled_count -= 1; handle = heapq.heappop(self._scheduled); handle._scheduled = False; ; timeout = None; if self._ready or self._stopping:; timeout = 0; elif self._scheduled:; # Compute the desired timeout.; when = self._scheduled[0]._when; timeout = min(max(0, when - self.time()), MAXIMUM_SELECT_TIMEOUT); ; event_list = self._selector.select(timeout); self._process_events(event_list); ; # Handle 'later' callbacks that are ready.; end_time = self.time() + self._clock_resolution; while self._scheduled:; handle = self._scheduled[0]; if handle._when >= end_time:; break; handle = heapq.heappop(self._scheduled); handle._scheduled = False; self._ready.append(handle); ; # This is the only place where callbacks are actually *called*.; # All other places just add them to ready.; # Note: We run all currently scheduled callbacks, but not any; # callbacks scheduled by callbacks run this time around --; # they will be run the next time (after another I/O poll).; # Use an idiom that is thread-safe without using locks.; ntodo = len(self._ready); for i in range(ntodo):; > handle = self._ready.popleft(); E IndexError: pop from an empty deque. /usr/lib/python3.9/asyncio/base_events.py:1890: IndexError; ```. ### Version. 0.2.126. ### Relevant log output",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13997:3477,timeout,timeout,3477,https://hail.is,https://github.com/hail-is/hail/issues/13997,1,['timeout'],['timeout']
Safety,"allbacks, polls for I/O,; schedules the resulting callbacks, and finally schedules; 'call_later' callbacks.; """"""; ; sched_count = len(self._scheduled); if (sched_count > _MIN_SCHEDULED_TIMER_HANDLES and; self._timer_cancelled_count / sched_count >; _MIN_CANCELLED_TIMER_HANDLES_FRACTION):; # Remove delayed calls that were cancelled if their number; # is too high; new_scheduled = []; for handle in self._scheduled:; if handle._cancelled:; handle._scheduled = False; else:; new_scheduled.append(handle); ; heapq.heapify(new_scheduled); self._scheduled = new_scheduled; self._timer_cancelled_count = 0; else:; # Remove delayed calls that were cancelled from head of queue.; while self._scheduled and self._scheduled[0]._cancelled:; self._timer_cancelled_count -= 1; handle = heapq.heappop(self._scheduled); handle._scheduled = False; ; timeout = None; if self._ready or self._stopping:; timeout = 0; elif self._scheduled:; # Compute the desired timeout.; when = self._scheduled[0]._when; timeout = min(max(0, when - self.time()), MAXIMUM_SELECT_TIMEOUT); ; if self._debug and timeout != 0:; t0 = self.time(); event_list = self._selector.select(timeout); dt = self.time() - t0; if dt >= 1.0:; level = logging.INFO; else:; level = logging.DEBUG; nevent = len(event_list); if timeout is None:; logger.log(level, 'poll took %.3f ms: %s events',; dt * 1e3, nevent); elif nevent:; logger.log(level,; 'poll %.3f ms took %.3f ms: %s events',; timeout * 1e3, dt * 1e3, nevent); elif dt >= 1.0:; logger.log(level,; 'poll %.3f ms took %.3f ms: timeout',; timeout * 1e3, dt * 1e3); else:; event_list = self._selector.select(timeout); self._process_events(event_list); ; # Handle 'later' callbacks that are ready.; end_time = self.time() + self._clock_resolution; while self._scheduled:; handle = self._scheduled[0]; if handle._when >= end_time:; break; handle = heapq.heappop(self._scheduled); handle._scheduled = False; self._ready.append(handle); ; # This is the only place where callbacks are actually *called*",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10705:2566,timeout,timeout,2566,https://hail.is,https://github.com/hail-is/hail/pull/10705,1,['timeout'],['timeout']
Safety,"als_to_index_meta=True,; File ""/hail-elasticsearch-pipelines/hail_scripts/v01/utils/elasticsearch_client.py"", line 142, in export_vds_to_elasticsearch; verbose=verbose); File ""/hail-elasticsearch-pipelines/hail_scripts/v01/utils/elasticsearch_client.py"", line 287, in export_kt_to_elasticsearch; kt.export_elasticsearch(self._host, int(self._port), index_name, index_type_name, block_size, config=elasticsearch_config); File ""<decorator-gen-143>"", line 2, in export_elasticsearch; File ""/hail/build/distributions/hail-python.zip/hail/java.py"", line 121, in handle_py4j; hail.java.FatalError: EsHadoopIllegalArgumentException: Unsupported/Unknown Elasticsearch version 6.0.0. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 12.0 failed 1 times, most recent failure: Lost task 0.0 in stage 12.0 (TID 20050, localhost): org.elasticsearch.hadoop.EsHadoopIllegalArgumentException: Cannot detect ES version - typically this happens if the network/Elasticsearch cluster is not accessible or when targeting a WAN/Cloud instance without the proper setting 'es.nodes.wan.only'; 	at org.elasticsearch.hadoop.rest.InitializationUtils.discoverEsVersion(InitializationUtils.java:247); 	at org.elasticsearch.hadoop.rest.RestService.createWriter(RestService.java:545); 	at org.elasticsearch.spark.rdd.EsRDDWriter.write(EsRDDWriter.scala:58); 	at org.elasticsearch.spark.rdd.EsSpark$$anonfun$doSaveToEs$1.apply(EsSpark.scala:102); 	at org.elasticsearch.spark.rdd.EsSpark$$anonfun$doSaveToEs$1.apply(EsSpark.scala:102); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); 	at org.apache.spark.scheduler.Task.run(Task.scala:86); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); Caused by: org.elasticsearch.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4138:1658,detect,detect,1658,https://hail.is,https://github.com/hail-is/hail/issues/4138,1,['detect'],['detect']
Safety,"alse>. def _run_once(self):; """"""Run one full iteration of the event loop.; ; This calls all currently ready callbacks, polls for I/O,; schedules the resulting callbacks, and finally schedules; 'call_later' callbacks.; """"""; ; sched_count = len(self._scheduled); if (sched_count > _MIN_SCHEDULED_TIMER_HANDLES and; self._timer_cancelled_count / sched_count >; _MIN_CANCELLED_TIMER_HANDLES_FRACTION):; # Remove delayed calls that were cancelled if their number; # is too high; new_scheduled = []; for handle in self._scheduled:; if handle._cancelled:; handle._scheduled = False; else:; new_scheduled.append(handle); ; heapq.heapify(new_scheduled); self._scheduled = new_scheduled; self._timer_cancelled_count = 0; else:; # Remove delayed calls that were cancelled from head of queue.; while self._scheduled and self._scheduled[0]._cancelled:; self._timer_cancelled_count -= 1; handle = heapq.heappop(self._scheduled); handle._scheduled = False; ; timeout = None; if self._ready or self._stopping:; timeout = 0; elif self._scheduled:; # Compute the desired timeout.; when = self._scheduled[0]._when; timeout = min(max(0, when - self.time()), MAXIMUM_SELECT_TIMEOUT); ; event_list = self._selector.select(timeout); self._process_events(event_list); ; # Handle 'later' callbacks that are ready.; end_time = self.time() + self._clock_resolution; while self._scheduled:; handle = self._scheduled[0]; if handle._when >= end_time:; break; handle = heapq.heappop(self._scheduled); handle._scheduled = False; self._ready.append(handle); ; # This is the only place where callbacks are actually *called*.; # All other places just add them to ready.; # Note: We run all currently scheduled callbacks, but not any; # callbacks scheduled by callbacks run this time around --; # they will be run the next time (after another I/O poll).; # Use an idiom that is thread-safe without using locks.; ntodo = len(self._ready); for i in range(ntodo):; > handle = self._ready.popleft(); E IndexError: pop from an empty deque. /u",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13997:3376,timeout,timeout,3376,https://hail.is,https://github.com/hail-is/hail/issues/13997,1,['timeout'],['timeout']
Safety,"alse>. def _run_once(self):; """"""Run one full iteration of the event loop.; ; This calls all currently ready callbacks, polls for I/O,; schedules the resulting callbacks, and finally schedules; 'call_later' callbacks.; """"""; ; sched_count = len(self._scheduled); if (sched_count > _MIN_SCHEDULED_TIMER_HANDLES and; self._timer_cancelled_count / sched_count >; _MIN_CANCELLED_TIMER_HANDLES_FRACTION):; # Remove delayed calls that were cancelled if their number; # is too high; new_scheduled = []; for handle in self._scheduled:; if handle._cancelled:; handle._scheduled = False; else:; new_scheduled.append(handle); ; heapq.heapify(new_scheduled); self._scheduled = new_scheduled; self._timer_cancelled_count = 0; else:; # Remove delayed calls that were cancelled from head of queue.; while self._scheduled and self._scheduled[0]._cancelled:; self._timer_cancelled_count -= 1; handle = heapq.heappop(self._scheduled); handle._scheduled = False; ; timeout = None; if self._ready or self._stopping:; timeout = 0; elif self._scheduled:; # Compute the desired timeout.; when = self._scheduled[0]._when; timeout = min(max(0, when - self.time()), MAXIMUM_SELECT_TIMEOUT); ; if self._debug and timeout != 0:; t0 = self.time(); event_list = self._selector.select(timeout); dt = self.time() - t0; if dt >= 1.0:; level = logging.INFO; else:; level = logging.DEBUG; nevent = len(event_list); if timeout is None:; logger.log(level, 'poll took %.3f ms: %s events',; dt * 1e3, nevent); elif nevent:; logger.log(level,; 'poll %.3f ms took %.3f ms: %s events',; timeout * 1e3, dt * 1e3, nevent); elif dt >= 1.0:; logger.log(level,; 'poll %.3f ms took %.3f ms: timeout',; timeout * 1e3, dt * 1e3); else:; event_list = self._selector.select(timeout); self._process_events(event_list); ; # Handle 'later' callbacks that are ready.; end_time = self.time() + self._clock_resolution; while self._scheduled:; handle = self._scheduled[0]; if handle._when >= end_time:; break; handle = heapq.heappop(self._scheduled); handle._sch",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10705:2465,timeout,timeout,2465,https://hail.is,https://github.com/hail-is/hail/pull/10705,1,['timeout'],['timeout']
Safety,"alse`, step 3 succeeds. ### What went wrong (all error messages here, including the full java stack trace):; ```; 2018-06-19 17:15:41 Hail: INFO: vep: annotated 2 variants; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/opt/hail/python/hail/typecheck/check.py"", line 547, in wrapper; return f(*args_, **kwargs_); File ""/opt/hail/python/hail/table.py"", line 1195, in show; print(self._show(n,width, truncate, types)); File ""/opt/hail/python/hail/table.py"", line 1198, in _show; return self._jt.showString(n, joption(truncate), types, width); File ""/opt/spark-2.2.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py"", line 1133, in __call__; File ""/opt/hail/python/hail/utils/java.py"", line 196, in deco; 'Error summary: %s' % (deepest, full, hail.__version__, deepest)) from None; hail.utils.java.FatalError: MatchError: [Ljava.lang.String;@7cd5fe91 (of class [Ljava.lang.String;). Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 11.0 failed 1 times, most recent failure: Lost task 0.0 in stage 11.0 (TID 11, localhost, executor driver): scala.MatchError: [Ljava.lang.String;@7cd5fe91 (of class [Ljava.lang.String;); 	at is.hail.annotations.RegionValueBuilder.addAnnotation(RegionValueBuilder.scala:489); 	at is.hail.methods.VEP$$anonfun$9$$anonfun$apply$4.apply(VEP.scala:350); 	at is.hail.methods.VEP$$anonfun$9$$anonfun$apply$4.apply(VEP.scala:345); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$16$$anon$3.next(OrderedRVD.scala:926); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$16$$anon$3.next(OrderedRVD.scala:920); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:462); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3790:1342,abort,aborted,1342,https://hail.is,https://github.com/hail-is/hail/issues/3790,1,['abort'],['aborted']
Safety,"ams, data=data, headers=headers, timeout=timeout; File ""/usr/local/lib/python3.7/site-packages/aiodocker/docker.py"", line 291, in __aenter__; resp = await self._coro; File ""/usr/local/lib/python3.7/site-packages/aiodocker/docker.py"", line 206, in _do_query; raise DockerError(response.status, json.loads(what.decode(""utf8""))); aiodocker.exceptions.DockerError: DockerError(404, 'no such image: gcr.io/hail-vdc/query:tfkm2kev7zcf: No such image: gcr.io/hail-vdc/query:tfkm2kev7zcf'). During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/usr/local/lib/python3.7/site-packages/batch/worker/worker.py"", line 372, in run; await self.ensure_image_is_pulled(); File ""/usr/local/lib/python3.7/site-packages/batch/worker/worker.py"", line 363, in ensure_image_is_pulled; docker.images.pull, self.image); File ""/usr/local/lib/python3.7/site-packages/batch/worker/worker.py"", line 111, in wrapper; return await asyncio.wait_for(f(*args, **kwargs), timeout); File ""/usr/local/lib/python3.7/asyncio/tasks.py"", line 442, in wait_for; return fut.result(); File ""/usr/local/lib/python3.7/asyncio/futures.py"", line 181, in result; raise self._exception; File ""/usr/local/lib/python3.7/asyncio/tasks.py"", line 249, in __step; result = coro.send(None); File ""/usr/local/lib/python3.7/site-packages/aiodocker/images.py"", line 104, in _handle_list; async with cm as response:; File ""/usr/local/lib/python3.7/site-packages/aiodocker/docker.py"", line 291, in __aenter__; resp = await self._coro; File ""/usr/local/lib/python3.7/site-packages/aiodocker/docker.py"", line 206, in _do_query; raise DockerError(response.status, json.loads(what.decode(""utf8""))); aiodocker.exceptions.DockerError: DockerError(500, ""unauthorized: You don't have the needed permissions to perform this operation, and you may have invalid credentials. To authenticate your request, follow the steps in: https://cloud.google.com/container-registry/docs/advanced-authentication""); ```. [1] The ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9902:3343,timeout,timeout,3343,https://hail.is,https://github.com/hail-is/hail/pull/9902,1,['timeout'],['timeout']
Safety,"an OS pipe; reader stream on Linux. (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/23131"">#23131</a>)</li>; </ul>; <h2>azure-storage-blob_12.10.0b4</h2>; <h2>12.10.0b4 (2022-02-24)</h2>; <h3>Features Added</h3>; <ul>; <li>Updated clients to support both SAS and OAuth together.</li>; <li>Updated OAuth implementation to use the AAD scope returned in a Bearer challenge.</li>; </ul>; <h3>Bugs Fixed</h3>; <ul>; <li>Addressed a few <code>mypy</code> typing hint errors.</li>; </ul>; <h2>azure-storage-blob_12.10.0b3</h2>; <h2>12.10.0b3 (2022-02-08)</h2>; <p>This version and all future versions will require Python 3.6+. Python 2.7 is no longer supported.</p>; <h3>Features Added</h3>; <ul>; <li>Added support for service version 2021-04-10.</li>; <li>Added support for <code>find_blobs_by_tags()</code> on a container.</li>; <li>Added support for <code>Find (f)</code> container SAS permission.</li>; </ul>; <h3>Bugs Fixed</h3>; <ul>; <li>Update <code>azure-core</code> dependency to avoid inconsistent dependencies from being installed.</li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/699acfe143cc0ca570de2d040c8ffcf7cb2a3c55""><code>699acfe</code></a> [Storage] Fix <code>detination_lease</code> type hint (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/23417"">#23417</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/5b6ff12ffbb3cc440bc73b4e714ec260ab0f03ac""><code>5b6ff12</code></a> [Storage] Update <code>rename_directory</code> lease param name (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/23411"">#23411</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/4513dbda0f23964a7690eee938f9fdaf91cf33b8""><code>4513dbd</code></a> [Storage] Fix duplicate type signatures in async (<a href=""https://github-redirect.dependabot.com/Azure/azure-",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11610:2470,avoid,avoid,2470,https://hail.is,https://github.com/hail-is/hail/pull/11610,1,['avoid'],['avoid']
Safety,"an be calculated as; <code>timeout.deadline - loop.time()</code></p>; </li>; <li>; <p>Dropped <code>timeout.timeout</code> property that returns a relative timeout based on the; timeout object creation time; the absolute <code>timeout.deadline</code> should be used; instead.</p>; </li>; <li>; <p>Added the deadline modification methods: <code>timeout.reject()</code>,; <code>timeout.shift(delay)</code>, <code>timeout.update(deadline)</code>.</p>; </li>; <li>; <p>Deprecated synchronous context manager usage</p>; </li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/aio-libs/async-timeout/commit/5128f7f4ff73b165579006a8336978efaeeca07a""><code>5128f7f</code></a> Fix CHANGES</li>; <li><a href=""https://github.com/aio-libs/async-timeout/commit/18e718a56f9def7dc40bb9ce3a2962a8fb0c883c""><code>18e718a</code></a> Bump to 4.0.2</li>; <li><a href=""https://github.com/aio-libs/async-timeout/commit/48d1c4ce923b1da75976d7e2a6ca9234b3092c16""><code>48d1c4c</code></a> Setup towncrier</li>; <li><a href=""https://github.com/aio-libs/async-timeout/commit/2ede7d73e55f8d1a2279d78861af0009d96219fb""><code>2ede7d7</code></a> Fix annotations on <code>__exit__</code> and <code>__aexit__</code> (<a href=""https://github-redirect.dependabot.com/aio-libs/async-timeout/issues/274"">#274</a>)</li>; <li><a href=""https://github.com/aio-libs/async-timeout/commit/8685c60dc0e82ee246fbe3d1aa272d1dfe57c24c""><code>8685c60</code></a> Bump mypy from 0.910 to 0.920 (<a href=""https://github-redirect.dependabot.com/aio-libs/async-timeout/issues/273"">#273</a>)</li>; <li><a href=""https://github.com/aio-libs/async-timeout/commit/f0a0914345b224448220aeb00d71e6a04a5d24bd""><code>f0a0914</code></a> Bump twine from 3.7.0 to 3.7.1 (<a href=""https://github-redirect.dependabot.com/aio-libs/async-timeout/issues/272"">#272</a>)</li>; <li><a href=""https://github.com/aio-libs/async-timeout/commit/e5c813173b8811b30f4a30eeba56fa8808ab15bb""><code>e5c8131</code></a> [pre-com",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11465:4321,timeout,timeout,4321,https://hail.is,https://github.com/hail-is/hail/pull/11465,1,['timeout'],['timeout']
Safety,"anager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:236); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:305); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:84); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748). Container exited with a non-zero exit code 134; ```; When I dig into the container logs, the stdout is empty on most, stderr is full of warnings, but no errors:; ```; 18/03/02 15:28:07 WARN com.google.cloud.hadoop.gcsio.GoogleCloudStorageReadChannel: Channel for 'gs://gnomad/coverage/hail-0.2/coverage/exomes/parts/part_partition1049.vds/entries/rows/parts/part-0095' is not open.; ```; But then one machine I logged into had:; ```; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x00007fa70eb59074, pid=4361, tid=0x00007fa707702700; #; # JRE version: OpenJDK Runtime Environment (8.0_131-b11) (build 1.8.0_131-8u131-b11-1~bpo8+1-b11); # Java VM: OpenJDK 64-Bit Server VM (25.131-b11 mixed mode linux-amd64 compressed oops); # Problematic frame:; # C [libconscrypt_openjdk_jni.so+0x43074]; [error occurred during error reporting (printing problematic frame), id 0xb]. # Failed to write core dump. Core dumps have been disabled. To enable core dumping, try ""ulimit -c unlimited"" before starting Java again; #; # An error report file with more information is saved as:; # /hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1519994715701_0001/container_1519994715701_0001_01_000558/hs_err_pid4361.log; # [ timer expired, abort... ]; ```; But said log file has no information. The job is finishing, just with a high (~50-100%) task failure rate.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3053:4228,detect,detected,4228,https://hail.is,https://github.com/hail-is/hail/issues/3053,2,"['abort', 'detect']","['abort', 'detected']"
Safety,"and propagate resources to docker build command. Without this, we can overload the node by running a bunch of build image jobs which tiny cpu allocations that invoke docker build which run unconstrained docker builds. This should resolve the docker timeout issue I saw. I allocated 2G per build job, and pass 1.5G of that to the docker build. Just guessing on that -- I'm not sure how to figure out how much memory a docker build required.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6246:249,timeout,timeout,249,https://hail.is,https://github.com/hail-is/hail/pull/6246,1,['timeout'],['timeout']
Safety,anonfun$mapPartitionsWithIndex$1$$anonfun$apply$25.apply(RDD.scala:820); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$25.apply(RDD.scala:820); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); 	at org.apache.spark.scheduler.Task.run(Task.scala:86); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGSche,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2743:4785,abort,abortStage,4785,https://hail.is,https://github.com/hail-is/hail/issues/2743,1,['abort'],['abortStage']
Safety,apPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGSche,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3235:5838,abort,abortStage,5838,https://hail.is,https://github.com/hail-is/hail/issues/3235,1,['abort'],['abortStage']
Safety,"apache.spark.unsafe.types.UTF8String, StringType, fromString, validateexternaltype(getexternalrowfield(validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 0, variant), StructField(contig,StringType,false), StructField(start,IntegerType,false), StructField(ref,StringType,false), StructField(altAlleles,ArrayType(StructType(StructField(ref,StringType,false), StructField(alt,StringType,false)),false),false)), 0, contig), StringType), true), start, validateexternaltype(getexternalrowfield(validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 0, variant), StructField(contig,StringType,false), StructField(start,IntegerType,false), StructField(ref,StringType,false), StructField(altAlleles,ArrayType(StructType(StructField(ref,StringType,false), StructField(alt,StringType,false)),false),false)), 1, start), IntegerType), ref, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, validateexternaltype(getexternalrowfield(validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 0, variant), StructField(contig,StringType,false), StructField(start,IntegerType,false), StructField(ref,StringType,false), StructField(altAlleles,ArrayType(StructType(StructField(ref,StringType,false), StructField(alt,StringType,false)),false),false)), 2, ref), StringType), true), altAlleles, mapobjects(MapObjects_loopValue8, MapObjects_loopIsNull9, ObjectType(class java.lang.Object), if (isnull(validateexternaltype(lambdavariable(MapObjects_loopValue8, MapObjects_loopIsNull9, ObjectType(class java.lang.Object)), StructField(ref,StringType,false), StructField(alt,StringType,false)))) null else named_struct(ref, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, validateexternaltype(getexternalrowfield(validateexternaltype(lambdavariable(MapObjects_l",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1260:8490,unsafe,unsafe,8490,https://hail.is,https://github.com/hail-is/hail/issues/1260,1,['unsafe'],['unsafe']
Safety,arn.app.container.log.dir=/var/log/hadoop-yarn/userlogs/application_1519994715701_0003/container_1519994715701_0003_01_000102 -XX:OnOutOfMemoryError='kill %p' org.apache.spark.executor.CoarseGrainedExecutorBackend --driver-url spark://CoarseGrainedScheduler@10.128.0.4:41843 --executor-id 99 --hostname exomes-sw-pxt3.c.broad-mpg-gnomad.internal --cores 4 --app-id application_1519994715701_0003 --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1519994715701_0003/container_1519994715701_0003_01_000102/__app__.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1519994715701_0003/container_1519994715701_0003_01_000102/hail.jar > /var/log/hadoop-yarn/userlogs/application_1519994715701_0003/container_1519994715701_0003_01_000102/stdout 2> /var/log/hadoop-yarn/userlogs/application_1519994715701_0003/container_1519994715701_0003_01_000102/stderr. Stack trace: ExitCodeException exitCode=134: /bin/bash: line 1: 6739 Aborted /usr/lib/jvm/java-8-openjdk-amd64/bin/java -server -Xmx11171m '-Xss4M' -Djava.io.tmpdir=/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1519994715701_0003/container_1519994715701_0003_01_000102/tmp '-Dspark.driver.port=41843' '-Dspark.rpc.message.maxSize=512' -Dspark.yarn.app.container.log.dir=/var/log/hadoop-yarn/userlogs/application_1519994715701_0003/container_1519994715701_0003_01_000102 -XX:OnOutOfMemoryError='kill %p' org.apache.spark.executor.CoarseGrainedExecutorBackend --driver-url spark://CoarseGrainedScheduler@10.128.0.4:41843 --executor-id 99 --hostname exomes-sw-pxt3.c.broad-mpg-gnomad.internal --cores 4 --app-id application_1519994715701_0003 --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1519994715701_0003/container_1519994715701_0003_01_000102/__app__.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1519994715701_0003/container_1519994715701_0003_01_000102/hail.jar > /var/log/had,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3053:1720,Abort,Aborted,1720,https://hail.is,https://github.com/hail-is/hail/issues/3053,1,['Abort'],['Aborted']
Safety,ask 55.0 in stage 3.0 (TID 1197); java.lang.NullPointerException; at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.GoogleCloudStorageFileSystem.mkdirs(GoogleCloudStorageFileSystem.java:515); at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.GoogleCloudStorageFileSystem.create(GoogleCloudStorageFileSystem.java:261); at com.google.cloud.hadoop.fs.gcs.GoogleHadoopOutputStream.createChannel(GoogleHadoopOutputStream.java:82); at com.google.cloud.hadoop.fs.gcs.GoogleHadoopOutputStream.<init>(GoogleHadoopOutputStream.java:74); at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.create(GoogleHadoopFileSystemBase.java:797); at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1067); at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1048); at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:937); at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:925); at is.hail.io.fs.HadoopFS.create(HadoopFS.scala:91); at is.hail.io.fs.HadoopFS.unsafeWriter(HadoopFS.scala:445); at is.hail.linalg.WriteBlocksRDD$$anonfun$63.apply(BlockMatrix.scala:1840); at is.hail.linalg.WriteBlocksRDD$$anonfun$63.apply(BlockMatrix.scala:1833); at scala.Array$.tabulate(Array.scala:331); at is.hail.linalg.WriteBlocksRDD.compute(BlockMatrix.scala:1833); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346); at org.apache.spark.rdd.RDD.iterator(RDD.scala:310); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90); at org.apache.spark.scheduler.Task.run(Task.scala:123); at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408); at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); at java.lang.Thread.run(Thread.java:748)```,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8239:1927,unsafe,unsafeWriter,1927,https://hail.is,https://github.com/hail-is/hail/issues/8239,1,['unsafe'],['unsafeWriter']
Safety,askRunner.$anonfun$run$3(Executor.scala:497); 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2254); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2203); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2202); 	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62); 	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2202); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1078); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1078); 	at scala.Option.foreach(Option.scala:407); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1078); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2441); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2383); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2372); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:868); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2202); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2223); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:22,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/10682:8408,abort,abortStage,8408,https://hail.is,https://github.com/hail-is/hail/issues/10682,1,['abort'],['abortStage']
Safety,askRunner.$anonfun$run$3(Executor.scala:498); 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:501); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:750). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2304); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2253); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2252); 	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62); 	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2252); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1124); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1124); 	at scala.Option.foreach(Option.scala:407); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1124); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2491); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2433); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2422); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:902); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2204); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2225); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:22,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12532:6276,abort,abortStage,6276,https://hail.is,https://github.com/hail-is/hail/issues/12532,1,['abort'],['abortStage']
Safety,"at is.hail.annotations.Region$.scoped(Region.scala:18); 	at is.hail.expr.ir.ExecuteContext$.scoped(ExecuteContext.scala:9); 	at is.hail.backend.Backend.execute(Backend.scala:56); 	at is.hail.backend.Backend.executeJSON(Backend.scala:62); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:282); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:238); 	at java.lang.Thread.run(Thread.java:745). org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 3.0 failed 1 times, most recent failure: Lost task 0.0 in stage 3.0 (TID 3, localhost, executor driver): is.hail.utils.HailException: Hail only supports 8-bit probabilities, found 16.; 	at is.hail.codegen.generated.C_bgen_rdd_decoder_13.apply(Unknown Source); 	at is.hail.codegen.generated.C_bgen_rdd_decoder_13.apply(Unknown Source); 	at is.hail.io.bgen.BgenRecordIteratorWithoutFilter.next(BgenRDD.scala:222); 	at is.hail.io.bgen.BgenRecordIteratorWithoutFilter.next(BgenRDD.scala:206); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:410); 	at scala.collection.TraversableOnce$FlattenOps$$anon$1.hasNext(TraversableOnce.scala:464); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:439); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:439); 	at scala.collection.Iterator$class.foreach(Iterator.scala:891); 	at scala.collection.AbstractIterator.foreach(Iterato",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8545:4072,abort,aborted,4072,https://hail.is,https://github.com/hail-is/hail/issues/8545,1,['abort'],['aborted']
Safety,"at is.hail.annotations.Region$.scoped(Region.scala:18); 	at is.hail.expr.ir.ExecuteContext$.scoped(ExecuteContext.scala:9); 	at is.hail.backend.Backend.execute(Backend.scala:77); 	at is.hail.backend.Backend.executeJSON(Backend.scala:96); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:282); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:238); 	at java.lang.Thread.run(Thread.java:748). org.apache.spark.SparkException: Job aborted due to stage failure: Task 40 in stage 7.0 failed 20 times, most recent failure: Lost task 40.19 in stage 7.0 (TID 3171, seqr-loading-cluster-sw-z91p.c.seqr-project.internal, executor 14): is.hail.utils.HailException: cannot set missing field for required type +PCStruct{info:PCStruct{ALLELEID:PInt32}}; 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:9); 	at is.hail.utils.package$.fatal(package.scala:74); 	at is.hail.annotations.RegionValueBuilder.setMissing(RegionValueBuilder.scala:210); 	at is.hail.rvd.RVD$$anonfun$24$$anonfun$apply$17.apply(RVD.scala:974); 	at is.hail.rvd.RVD$$anonfun$24$$anonfun$apply$17.apply(RVD.scala:967); 	at is.hail.utils.FlipbookIterator$$anon$5.<init>(FlipbookIterator.scala:176); 	at is.hail.utils.FlipbookIterator.map(FlipbookIterator.scala:174); 	at is.hail.utils.FlipbookIterator.map(FlipbookIterator.scala:145); 	at is.hail.rvd.RVD$$anonfun$24.apply(RVD.scala:967); 	at is.hail.rvd.RVD$$anonfun$24.apply(RVD.scala:963); 	at is.hail.rvd.KeyedRVD$$anonf",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8469:51092,abort,aborted,51092,https://hail.is,https://github.com/hail-is/hail/issues/8469,1,['abort'],['aborted']
Safety,at org.apache.spark.rdd.RDD.iterator(RDD.scala:310) at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52) at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346) at org.apache.spark.rdd.RDD.iterator(RDD.scala:310) at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90) at org.apache.spark.scheduler.Task.run(Task.scala:123) at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408) at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360) at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748); 			at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1891); 			at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1879); 			at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1878); 			at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 			at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 			at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1878); 			at org.apache.spark.scheduler.DAGScheduler.handleTaskCompletion(DAGScheduler.scala:1495); 			at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2109); 			at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2061); 			at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2050); 			at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49); 			at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:738); 			at org.apache.spark.SparkContext.runJob(SparkContext.scala:2061); 	,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8944:10991,abort,abortStage,10991,https://hail.is,https://github.com/hail-is/hail/issues/8944,1,['abort'],['abortStage']
Safety,"ates (including the; > VeriSign root certs that signed the public certs that gateway uses, different; > from the internal certs that our services use).; >; > In particular, note that the error says ""unable to get local issuer; > certificate."" That means that the local trust store lacks a certificate that; > trusts the remote server's certificate. In Dania's case, the default python on; > OS X lacks all certificates, so every remote server is untrusted. In notebook's; > case, ssl_client_session creates an SSL/TLS session that only trusts Hail; > internal services (in particular, it does not trust the certificates that; > gateway uses for incoming public traffic). The error also says that the server; > in question is workshop.hail.is which is a public domain (note the hail.is), so; > that traffic is going through the public gateway with its public certificates.; >; > ```; > # don't have dev credentials to connect through internal.hail.is; > ready_url = deploy_config.external_url(; > service,; > f'/instance/{notebook[""notebook_token""]}/?token={notebook[""jupyter_token""]}'); > try:; > async with ssl_client_session(; > timeout=aiohttp.ClientTimeout(total=1),; > headers=headers,; > cookies=cookies) as session:; > async with session.get(ready_url) as resp:; > ```. I also changed the names and functionality of the functions in tls. Now; `in_cluster_ssl_context` will error if there is no ssl configuration found; instead of silently (and confusingly) using an SSLContext suited for public; communication (and wrong for in-cluster communication). I added `get_context_specific_client_ssl_context` which should only be used in; publicly consumable tools (*never* in a service). This function allows the same; tool to be used inside and outside the cluster. It will load the correct certs; for your environment (it will load public certs if you're outside the cluster,; it will load in-cluster-only certs if you're in the cluster). I also added types to `tls.py` and fixed some type errors.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9120:1543,timeout,timeout,1543,https://hail.is,https://github.com/hail-is/hail/pull/9120,1,['timeout'],['timeout']
Safety,"ation obliquely notes that the username should be; `oauth2accesstoken`](https://cloud.google.com/container-registry/docs/advanced-authentication). I; use this only for retrieving a ""public gcr image"" which I fix in this PR to be images whose; ""repository"" [1] is one of these:; - gcr.io/PROJECT/query; - gcr.io/PROJECT/hail; - gcr.io/PROJECT/python-dill. A previous Shuffler PR taught worker.py to translate our `hailgenetics` Docker image names to; `gcr.io/PROJECT` image names. I had to move the docker-worker into a new Docker network which allows it to access the metadata server. I think this is safe because we trust our own code. From a relevant Docker worker log:. ```; Traceback (most recent call last):; File ""/usr/local/lib/python3.7/site-packages/batch/worker/worker.py"", line 359, in ensure_image_is_pulled; docker.images.get, self.image); File ""/usr/local/lib/python3.7/site-packages/batch/worker/worker.py"", line 111, in wrapper; return await asyncio.wait_for(f(*args, **kwargs), timeout); File ""/usr/local/lib/python3.7/asyncio/tasks.py"", line 442, in wait_for; return fut.result(); File ""/usr/local/lib/python3.7/asyncio/futures.py"", line 181, in result; raise self._exception; File ""/usr/local/lib/python3.7/asyncio/tasks.py"", line 249, in __step; result = coro.send(None); File ""/usr/local/lib/python3.7/site-packages/aiodocker/images.py"", line 46, in get; return await self.inspect(name); File ""/usr/local/lib/python3.7/site-packages/aiodocker/images.py"", line 36, in inspect; response = await self.docker._query_json(""images/{name}/json"".format(name=name)); File ""/usr/local/lib/python3.7/site-packages/aiodocker/docker.py"", line 223, in _query_json; path, method, params=params, data=data, headers=headers, timeout=timeout; File ""/usr/local/lib/python3.7/site-packages/aiodocker/docker.py"", line 291, in __aenter__; resp = await self._coro; File ""/usr/local/lib/python3.7/site-packages/aiodocker/docker.py"", line 206, in _do_query; raise DockerError(response.status, json.loads(",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9902:1647,timeout,timeout,1647,https://hail.is,https://github.com/hail-is/hail/pull/9902,1,['timeout'],['timeout']
Safety,"ature requests, please use the discussion forum: http://discuss.hail.is/. -------------------------------------------------------------------------------------------. ### Hail version: . current master. ### What you did:. Read in a giant table of phenotypes (~500k rows x ~3k columns). `; raw_phenos = hl.import_table('gs://phenotype_31063/ukb31063.raw_phenotypes.tsv.bgz',; key='eid', impute=True, types={'eid': hl.tstr}, missing='NA', min_partitions=100); raw_phenos.write('gs://armartin/disparities/ukbb_afr/ukb31063.raw_phenotypes.ht'); `; ### What went wrong (all error messages here, including the full java stack trace):. [Stage 1:> (0 + 100) / 100]Traceback (most recent call last):; File ""/tmp/0fdaf26ceb274d679f571483f658e509/run_prs_afr.py"", line 266, in <module>; main(args); File ""/tmp/0fdaf26ceb274d679f571483f658e509/run_prs_afr.py"", line 125, in main; raw_phenos.write('gs://armartin/disparities/ukbb_afr/ukb31063.raw_phenotypes.ht'); File ""<decorator-gen-652>"", line 2, in write; File ""/tmp/0fdaf26ceb274d679f571483f658e509/hail-devel-5dfbe2ec29f8.zip/hail/typecheck/check.py"", line 546, in wrapper; File ""/tmp/0fdaf26ceb274d679f571483f658e509/hail-devel-5dfbe2ec29f8.zip/hail/table.py"", line 1218, in write; File ""/usr/lib/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py"", line 1133, in __call__; File ""/tmp/0fdaf26ceb274d679f571483f658e509/hail-devel-5dfbe2ec29f8.zip/hail/utils/java.py"", line 210, in deco; hail.utils.java.FatalError: NumberFormatException: For input string: ""1001101010010110"". Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 46 in stage 1.0 failed 20 times, most recent failure: Lost task 46.19 in stage 1.0 (TID 1559, arm-sw-vq41.c.daly-ibd.internal, executor 6): is.hail.utils.HailException: ukb31063.raw_phenotypes.tsv.bgz: java.lang.NumberFormatException: could not convert ""1001101010010110"" to int32 in column ""10145-0.3""; offending line: 3314275 NA 1 NA NA NA NA NA 0 1959 31 NA NA 36 NA NA 98 NA N...",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4268:1650,abort,aborted,1650,https://hail.is,https://github.com/hail-is/hail/issues/4268,1,['abort'],['aborted']
Safety,"authlib-3.1.0-py2.py3-none-any.whl (147 kB); Installing collected packages: six, pyasn1, urllib3, rsa, pyparsing, pyasn1-modules, protobuf, idna, chardet, certifi, cachetools, requests, pytz, packaging, oauthlib, multidict, googleapis-common-protos, google-auth, yarl, typing-extensions, requests-oauthlib, MarkupSafe, google-api-core, attrs, async-timeout, wrapt, wcwidth, tornado, PyYAML, python-dateutil, py4j, ptyprocess, pillow, parso, numpy, Jinja2, ipython-genutils, google-resumable-media, google-cloud-core, google-auth-oauthlib, fsspec, decorator, aiohttp, traitlets, tqdm, tabulate, scipy, python-json-logger, pyspark, PyJWT, pygments, prompt-toolkit, pickleshare, pexpect, parsimonious, pandas, nest-asyncio, jedi, hurry.filesize, humanize, google-cloud-storage, gcsfs, dill, Deprecated, bokeh, backcall, asyncinit, aiohttp-session, ipython, hail; Successfully installed Deprecated-1.2.12 Jinja2-2.11.3 MarkupSafe-1.1.1 PyJWT-2.0.1 PyYAML-5.4.1 aiohttp-3.7.4 aiohttp-session-2.7.0 async-timeout-3.0.1 asyncinit-0.2.4 attrs-20.3.0 backcall-0.2.0 bokeh-1.4.0 cachetools-4.2.1 certifi-2020.12.5 chardet-3.0.4 decorator-4.4.2 dill-0.3.3 fsspec-0.8.7 gcsfs-0.7.2 google-api-core-1.26.1 google-auth-1.27.1 google-auth-oauthlib-0.4.3 google-cloud-core-1.6.0 google-cloud-storage-1.25.0 google-resumable-media-0.5.1 googleapis-common-protos-1.53.0 hail-0.2.64 humanize-1.0.0 hurry.filesize-0.9 idna-2.8 ipython-7.21.0 ipython-genutils-0.2.0 jedi-0.18.0 multidict-5.1.0 nest-asyncio-1.5.1 numpy-1.20.1 oauthlib-3.1.0 packaging-20.9 pandas-1.1.4 parsimonious-0.8.1 parso-0.8.1 pexpect-4.8.0 pickleshare-0.7.5 pillow-8.1.2 prompt-toolkit-3.0.17 protobuf-3.15.6 ptyprocess-0.7.0 py4j-0.10.7 pyasn1-0.4.8 pyasn1-modules-0.2.8 pygments-2.8.1 pyparsing-2.4.7 pyspark-2.4.1 python-dateutil-2.8.1 python-json-logger-0.1.11 pytz-2021.1 requests-2.22.0 requests-oauthlib-1.3.0 rsa-4.7.2 scipy-1.6.1 six-1.15.0 tabulate-0.8.3 tornado-6.1 tqdm-4.42.1 traitlets-5.0.5 typing-extensions-3.7.4.3 urllib3-1.25.11 ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/10197:8395,timeout,timeout-,8395,https://hail.is,https://github.com/hail-is/hail/issues/10197,1,['timeout'],['timeout-']
Safety,ava:1359) at io.netty.channel.AbstractChannelHandlerCtractChannelHandlerContext.java:348) at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935) at io.nettyectedKey(NioEventLoop.java:645) at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:580) at io.netty at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858) at io.netty.util.concurrent.Default; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1889); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1876); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1876); at org.apache.spark.scheduler.DAGScheduler.handleTaskCompletion(DAGScheduler.scala:1493); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2107); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2059); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2048); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:737); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2061); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2082); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2114); at org.apache.spark.internal.io.SparkHadoopWriter$.write(SparkHadoopWriter.scala:78); at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1.apply$mcV$sp(PairRDDFunctions.scala:1096); at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAs,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8106:24416,abort,abortStage,24416,https://hail.is,https://github.com/hail-is/hail/issues/8106,1,['abort'],['abortStage']
Safety,avoid copying data when not reading genotypes,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3783:0,avoid,avoid,0,https://hail.is,https://github.com/hail-is/hail/pull/3783,1,['avoid'],['avoid']
Safety,"avoid scan logic if not used; don't rv-ify globals if not needed. The following pipeline was sped up ~7%:. ```; t1 = hl.utils.range_table(100 * 1000 * 1000); t2 = t1.annotate(x = hl.rand_unif(0, 1)); t2.write('t2.ht', overwrite=True); ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4031:0,avoid,avoid,0,https://hail.is,https://github.com/hail-is/hail/pull/4031,1,['avoid'],['avoid']
Safety,avoid unneccesary scan in IndexBgen,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4434:0,avoid,avoid,0,https://hail.is,https://github.com/hail-is/hail/pull/4434,1,['avoid'],['avoid']
Safety,avoid unnecessary copying,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5145:0,avoid,avoid,0,https://hail.is,https://github.com/hail-is/hail/pull/5145,1,['avoid'],['avoid']
Safety,"ay in the common case of not needing the read to produce uids, we don't need to pollute the printed IR with large types.; * `hl.read_table` gets an option `_create_row_uids`, to allow for testing uids in python, and similarly for `hl.read_matrix_table`; * There are globally fixed default field names `TableReader.uidFieldName`, `MatrixReader.rowUIDFieldName`, and `MatrixReader.colUIDFieldName`. The full type of any `TableReader`/`MatrixReader` must contain these fields. If a consumer doesn't want uids, it just doesn't include them in the requested type. If it wants different field names, it must use a `TableRename`/`MatrixRename` node. This design ensures that the field pruner doesn't need any awareness of uids.; * An exception to this rule is if the written data already contains any of these special fields, in which case they are just read as usual. This ensures that a write/read in the middle of a pipeline can't change uid fields. We're making the assumption that these reserved field names are never used in user data, so if written data contains one of these fields, it must have been created by us, and so has the correct uid semantics. (Note that this was a late change, and I may have missed converting some readers to handle this case.); * The uids fields always come last in the row/col struct. Note that this requires some care when lowering MatrixTable, to make sure the row uid field comes after the entries field.; * `PartitionReader`s, on the other hand, must specify the name of their uid field. If this field is in the requested type, it will always be generated by the reader, even if the field already existed in the written data. It is now the responsibility of the consumer to choose the uid field name so as not to clobber an existing field.; * Added a trait `CountedIterator`, for iterators which keep track of a row index or file offset. The method `getCurIdx` should be called after `next()`, to get the corresponding index. This avoids having to allocate tuples.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12031:2191,avoid,avoids,2191,https://hail.is,https://github.com/hail-is/hail/pull/12031,1,['avoid'],['avoids']
Safety,"b.com/aio-libs/aiohttp) from 3.9.3 to 3.9.4.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/aio-libs/aiohttp/releases"">aiohttp's releases</a>.</em></p>; <blockquote>; <h2>3.9.4</h2>; <h2>Bug fixes</h2>; <ul>; <li>; <p>The asynchronous internals now set the underlying causes; when assigning exceptions to the future objects; -- by :user:<code>webknjaz</code>.</p>; <p><em>Related issues and pull requests on GitHub:</em>; <a href=""https://redirect.github.com/aio-libs/aiohttp/issues/8089"">#8089</a>.</p>; </li>; <li>; <p>Treated values of <code>Accept-Encoding</code> header as case-insensitive when checking; for gzip files -- by :user:<code>steverep</code>.</p>; <p><em>Related issues and pull requests on GitHub:</em>; <a href=""https://redirect.github.com/aio-libs/aiohttp/issues/8104"">#8104</a>.</p>; </li>; <li>; <p>Improved the DNS resolution performance on cache hit -- by :user:<code>bdraco</code>.</p>; <p>This is achieved by avoiding an :mod:<code>asyncio</code> task creation in this case.</p>; <p><em>Related issues and pull requests on GitHub:</em>; <a href=""https://redirect.github.com/aio-libs/aiohttp/issues/8163"">#8163</a>.</p>; </li>; <li>; <p>Changed the type annotations to allow <code>dict</code> on :meth:<code>aiohttp.MultipartWriter.append</code>,; :meth:<code>aiohttp.MultipartWriter.append_json</code> and; :meth:<code>aiohttp.MultipartWriter.append_form</code> -- by :user:<code>cakemanny</code></p>; <p><em>Related issues and pull requests on GitHub:</em>; <a href=""https://redirect.github.com/aio-libs/aiohttp/issues/7741"">#7741</a>.</p>; </li>; <li>; <p>Ensure websocket transport is closed when client does not close it; -- by :user:<code>bdraco</code>.</p>; <p>The transport could remain open if the client did not close it. This; change ensures the transport is closed when the client does not close; it.</p>; </li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summar",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14477:1011,avoid,avoiding,1011,https://hail.is,https://github.com/hail-is/hail/pull/14477,6,['avoid'],['avoiding']
Safety,"b169eb3285818ba1390ddf2771d897e6e""><code>aeb51cb</code></a> Merge branch 'main' into lcms</li>; <li><a href=""https://github.com/python-pillow/Pillow/commit/5beb0b66648db8b542bb5260eed79b25e33d643b""><code>5beb0b6</code></a> Update CHANGES.rst [ci skip]</li>; <li><a href=""https://github.com/python-pillow/Pillow/commit/cac6ffa7b399ea79b6239984d1307056a0b19af2""><code>cac6ffa</code></a> Merge pull request <a href=""https://redirect.github.com/python-pillow/Pillow/issues/7927"">#7927</a> from python-pillow/imagemath</li>; <li><a href=""https://github.com/python-pillow/Pillow/commit/f5eeeacf7539eaa0d93a677d7666bc7c142c8d1c""><code>f5eeeac</code></a> Name as 'options' in lambda_eval and unsafe_eval, but '_dict' in deprecated eval</li>; <li><a href=""https://github.com/python-pillow/Pillow/commit/facf3af93dabcbdd8cdbda8c3b50eefafa3bb04c""><code>facf3af</code></a> Added release notes</li>; <li><a href=""https://github.com/python-pillow/Pillow/commit/2a93aba5cfcf6e241ab4f9392c13e3b74032c061""><code>2a93aba</code></a> Use strncpy to avoid buffer overflow</li>; <li><a href=""https://github.com/python-pillow/Pillow/commit/a670597bc30e9d489656fc9d807170b8f3d7ca57""><code>a670597</code></a> Update CHANGES.rst [ci skip]</li>; <li>Additional commits viewable in <a href=""https://github.com/python-pillow/Pillow/compare/10.2.0...10.3.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pillow&package-manager=pip&previous-version=10.2.0&new-version=10.3.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</sum",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14439:14884,avoid,avoid,14884,https://hail.is,https://github.com/hail-is/hail/pull/14439,3,['avoid'],['avoid']
Safety,"back (most recent call last):\n File \""/usr/local/lib/python3.6/dist-packages/ci/ci.py\"", line 311, in update_loop\n await wb.update(app)\n File \""/usr/local/lib/python3.6/dist-packages/ci/github.py\"", line 518, in update\n await self._update(app)\n File \""/usr/local/lib/python3.6/dist-packages/ci/github.py\"", line 540, in _update\n await self._update_batch(batch_client)\n File \""/usr/local/lib/python3.6/dist-packages/ci/github.py\"", line 652, in _update_batch\n await self._update_deploy(batch_client)\n File \""/usr/local/lib/python3.6/dist-packages/ci/github.py\"", line 609, in _update_deploy\n 'target_branch': self.branch.short_str()\n File \""/usr/local/lib/python3.6/dist-packages/hailtop/batch_client/aioclient.py\"", line 476, in list_batches\n batches = await self._get('/api/v1alpha/batches', params=params)\n File \""/usr/local/lib/python3.6/dist-packages/hailtop/batch_client/aioclient.py\"", line 455, in _get\n self.url + path, params=params, headers=self._headers)\n File \""/usr/local/lib/python3.6/dist-packages/aiohttp/client.py\"", line 484, in _request\n timeout=real_timeout\n File \""/usr/local/lib/python3.6/dist-packages/aiohttp/connector.py\"", line 523, in connect\n proto = await self._create_connection(req, traces, timeout)\n File \""/usr/local/lib/python3.6/dist-packages/aiohttp/connector.py\"", line 859, in _create_connection\n req, traces, timeout)\n File \""/usr/local/lib/python3.6/dist-packages/aiohttp/connector.py\"", line 997, in _create_direct_connection\n raise last_exc\n File \""/usr/local/lib/python3.6/dist-packages/aiohttp/connector.py\"", line 979, in _create_direct_connection\n req=req, client_error=client_error)\n File \""/usr/local/lib/python3.6/dist-packages/aiohttp/connector.py\"", line 936, in _wrap_create_connection\n raise client_error(req.connection_key, exc) from exc\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host batch.default:80 ssl:None [Connection refused]""}; `. This happens every time CI is deployed, as far as I know.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7166:1746,timeout,timeout,1746,https://hail.is,https://github.com/hail-is/hail/issues/7166,3,['timeout'],['timeout']
Safety,"basically, it now looks at the partitioner for the MatrixValues of its children when it executes, and only shuffles if rvds are non-disjoint. It removes empty rvds and separates children into non-disjoint piles, shuffles those independently, and then concatenates them together in sorted order. (I'm not sure how this behaves relative to the old behavior (coerce everything together) when we have multiple shuffles that need to happen, but at least filtering out empty RVDs helps a lot in e.g. the split-multi case where none of the variants need to be moved.). I think the (a?) better optimization would be to add smarter partitioning so that we're adjusting partition bounds and not really shuffling under most circumstances, but I thought I'd PR this first since at least there's a warning in python about unioning non-disjoint datasets (where this will avoid the scan). I also added tests for MatrixUnionRows and pulled out one of the simplify rules; TableUnion does an unsorted union (I'm not sure this is actually correct behavior now if the tables have keys) and pulling the union outside of a MatrixRowsTable can cause the ordering to be wrong.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4043:857,avoid,avoid,857,https://hail.is,https://github.com/hail-is/hail/pull/4043,1,['avoid'],['avoid']
Safety,"batch log:. ```; {""levelname"": ""ERROR"", ""asctime"": ""2019-07-29 12:35:40,389"", ""filename"": ""batch.py"", ""funcNameAndLine"": ""polling_event_loop:1343"", ""message"": ""Could not poll due to exception: HTTPConnectionPool(host='10.32.16.16', port=5001): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ff2413b8470>: Failed to establish a new connection: [Errno 113] No route to host',))"", ""exc_info"": ""Traceback (most recent call last):\n File \""/usr/local/lib/python3.6/dist-packages/urllib3/connection.py\"", line 159, in _new_conn\n (self._dns_host, self.port), self.timeout, **extra_kw)\n File \""/usr/local/lib/python3.6/dist-packages/urllib3/util/connection.py\"", line 80, in create_connection\n raise err\n File \""/usr/local/lib/python3.6/dist-packages/urllib3/util/connection.py\"", line 70, in create_connection\n sock.connect(sa)\nOSError: [Errno 113] No route to host\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n File \""/usr/local/lib/python3.6/dist-packages/urllib3/connectionpool.py\"", line 600, in urlopen\n chunked=chunked)\n File \""/usr/local/lib/python3.6/dist-packages/urllib3/connectionpool.py\"", line 354, in _make_request\n conn.request(method, url, **httplib_request_kw)\n File \""/usr/lib/python3.6/http/client.py\"", line 1239, in request\n self._send_request(method, url, body, headers, encode_chunked)\n File \""/usr/lib/python3.6/http/client.py\"", line 1285, in _send_request\n self.endheaders(body, encode_chunked=encode_chunked)\n File \""/usr/lib/python3.6/http/client.py\"", line 1234, in endheaders\n self._send_output(message_body, encode_chunked=encode_chunked)\n File \""/usr/lib/python3.6/http/client.py\"", line 1026, in _send_output\n self.send(msg)\n File \""/usr/lib/python3.6/http/client.py\"", line 964, in send\n self.connect()\n File \""/usr/local/lib/python3.6/dist-packages/urllib3/connection.py\"", line 181, in connect\n conn = self._new_conn()\n ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6754:623,timeout,timeout,623,https://hail.is,https://github.com/hail-is/hail/issues/6754,1,['timeout'],['timeout']
Safety,"bc4acbe80537ea666506fa"">5d1cfd2</a>)</li>; <li>retry client side requests timeout (<a href=""https://github-redirect.dependabot.com/googleapis/python-storage/issues/727"">#727</a>) (<a href=""https://github.com/googleapis/python-storage/commit/e0b3b354d51e4be7c563d7f2f628a7139df842c0"">e0b3b35</a>)</li>; </ul>; <h3>Documentation</h3>; <ul>; <li>fixed download_blob_to_file example (<a href=""https://github-redirect.dependabot.com/googleapis/python-storage/issues/704"">#704</a>) (<a href=""https://github.com/googleapis/python-storage/commit/2c94d98ed21cc768cfa54fac3d734254fc4d8480"">2c94d98</a>)</li>; </ul>; <h2><a href=""https://github.com/googleapis/python-storage/compare/v2.0.0...v2.1.0"">2.1.0</a> (2022-01-19)</h2>; <h3>Features</h3>; <ul>; <li>add turbo replication support and samples (<a href=""https://github-redirect.dependabot.com/googleapis/python-storage/issues/622"">#622</a>) (<a href=""https://github.com/googleapis/python-storage/commit/4dafc815470480ce9de7f0357e331d3fbd0ae9b7"">4dafc81</a>)</li>; <li>avoid authentication with storage emulator (<a href=""https://github-redirect.dependabot.com/googleapis/python-storage/issues/679"">#679</a>) (<a href=""https://github.com/googleapis/python-storage/commit/8789afaaa1b2bd6f03fae72e3d87ce004ec10129"">8789afa</a>)</li>; <li>remove python 3.6 support (<a href=""https://github-redirect.dependabot.com/googleapis/python-storage/issues/689"">#689</a>) (<a href=""https://github.com/googleapis/python-storage/commit/8aa4130ee068a1922161c8ca54a53a4a51d65ce0"">8aa4130</a>)</li>; </ul>; <h2><a href=""https://github.com/googleapis/python-storage/compare/v1.44.0...v2.0.0"">2.0.0</a> (2022-01-12)</h2>; <h3>⚠ BREAKING CHANGES</h3>; <ul>; <li>Remove Python 2 support (<a href=""https://github-redirect.dependabot.com/googleapis/python-storage/issues/657"">#657</a>)</li>; </ul>; <h3>Features</h3>; <ul>; <li>Remove Python 2 support (<a href=""https://github-redirect.dependabot.com/googleapis/python-storage/issues/657"">#657</a>) (<a href=""https://github.com/goo",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11578:4524,avoid,avoid,4524,https://hail.is,https://github.com/hail-is/hail/pull/11578,1,['avoid'],['avoid']
Safety,"ble(); .flatten(); .select(['va.info.MQRankSum']); ); print(rf_kt.schema()). rf_df = rf_kt.to_dataframe(); rf_df.printSchema(); rf_df.show(); ```. And here is the output and stacktrace as it crashes when running `show()`:. ```; Struct {; `va.info.MQRankSum`: Double; }; root; |-- va.info.MQRankSum: double (nullable = true); Traceback (most recent call last):; File ""/tmp/db4d8e04-85c9-4eba-b0b3-4ade69200fd3/test.py"", line 60, in <module>; rf_df.show(); File ""/usr/lib/spark/python/lib/pyspark.zip/pyspark/sql/dataframe.py"", line 287, in show; File ""/usr/lib/spark/python/lib/py4j-0.10.3-src.zip/py4j/java_gateway.py"", line 1133, in __call__; File ""/usr/lib/spark/python/lib/pyspark.zip/pyspark/sql/utils.py"", line 63, in deco; for criterion, pop in criteria_pops:; File ""/usr/lib/spark/python/lib/py4j-0.10.3-src.zip/py4j/protocol.py"", line 319, in get_return_value; py4j.protocol.Py4JJavaError: An error occurred while calling o73.showString.; : org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 2.0 failed 20 times, most recent failure: Lost task 0.19 in stage 2.0 (TID 2520, gnomad-prod-sw-s89f.c.broad-mpg-gnomad.internal): java.lang.IndexOutOfBoundsException: 21; at scala.collection.mutable.ResizableArray$class.apply(ResizableArray.scala:43); at scala.collection.mutable.ArrayBuffer.apply(ArrayBuffer.scala:48); at is.hail.keytable.KeyTable$$anonfun$8$$anonfun$10.apply(KeyTable.scala:68); at is.hail.keytable.KeyTable$$anonfun$8$$anonfun$10.apply(KeyTable.scala:68); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); at scala.collection.AbstractTraversable.map(Traversable.scala:104); at is.hail.keytable.KeyT",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1275:1090,abort,aborted,1090,https://hail.is,https://github.com/hail-is/hail/issues/1275,1,['abort'],['aborted']
Safety,bleIterator.hasNext(InterruptibleIterator.scala:37); at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:199); at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:103); at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1517); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1505); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1504); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1504); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1732); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1687); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1676); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.s,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4780:9944,abort,abortStage,9944,https://hail.is,https://github.com/hail-is/hail/issues/4780,1,['abort'],['abortStage']
Safety,"boxed</code> argument and pytest-forked dependency.</li>; </ul>; <h2>Features</h2>; <ul>; <li>; <p><code>[#722](https://github.com/pytest-dev/pytest-xdist/issues/722) &lt;https://github.com/pytest-dev/pytest-xdist/issues/722&gt;</code>_: Full compatibility with pytest 7 - no deprecation warnings or use of legacy features.</p>; </li>; <li>; <p><code>[#733](https://github.com/pytest-dev/pytest-xdist/issues/733) &lt;https://github.com/pytest-dev/pytest-xdist/issues/733&gt;</code>_: New <code>--dist=loadgroup</code> option, which ensures all tests marked with <code>@pytest.mark.xdist_group</code> run in the same session/worker. Other tests run distributed as in <code>--dist=load</code>.</p>; </li>; </ul>; <h2>Trivial Changes</h2>; <ul>; <li>; <p><code>[#708](https://github.com/pytest-dev/pytest-xdist/issues/708) &lt;https://github.com/pytest-dev/pytest-xdist/issues/708&gt;</code>_: Use <code>@pytest.hookspec</code> decorator to declare hook options in <code>newhooks.py</code> to avoid warnings in <code>pytest 7.0</code>.</p>; </li>; <li>; <p><code>[#719](https://github.com/pytest-dev/pytest-xdist/issues/719) &lt;https://github.com/pytest-dev/pytest-xdist/issues/719&gt;</code>_: Use up-to-date <code>setup.cfg</code>/<code>pyproject.toml</code> packaging setup.</p>; </li>; <li>; <p><code>[#720](https://github.com/pytest-dev/pytest-xdist/issues/720) &lt;https://github.com/pytest-dev/pytest-xdist/issues/720&gt;</code>_: Require pytest&gt;=6.2.0.</p>; </li>; <li>; <p><code>[#721](https://github.com/pytest-dev/pytest-xdist/issues/721) &lt;https://github.com/pytest-dev/pytest-xdist/issues/721&gt;</code>_: Started using type annotations and mypy checking internally. The types are incomplete and not published.</p>; </li>; </ul>; <h1>pytest-xdist 2.4.0 (2021-09-20)</h1>; <h2>Features</h2>; <ul>; <li>; <p><code>[#696](https://github.com/pytest-dev/pytest-xdist/issues/696) &lt;https://github.com/pytest-dev/pytest-xdist/issues/696&gt;</code>_: On Linux, the process title now changes",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11491:1664,avoid,avoid,1664,https://hail.is,https://github.com/hail-is/hail/pull/11491,2,['avoid'],['avoid']
Safety,"but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiIzYWE2MzZiYi00NmJmLTQ3MjgtOGVjMC0yMDg0OWE4NzgyZGMiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjNhYTYzNmJiLTQ2YmYtNDcyOC04ZWMwLTIwODQ5YTg3ODJkYyJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""3aa636bb-46bf-4728-8ec0-20849a8782dc"",""prPublicId"":""3aa636bb-46bf-4728-8ec0-20849a8782dc"",""dependencies"":[{""name"":""tornado"",""from"":""6.2"",""to"":""6.3.3""}],""packageManager"":""pip"",""projectPublicId"":""20159ae6-a5aa-42fa-845a-c89f5bcbf999"",""projectUrl"":""https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-TORNADO-5840803""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""pr-warning-shown"",""priorityScore""],""priorityScoreList"":[566],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Learn about vulnerability in an interactive lesson of Snyk Learn.](https://learn.snyk.io/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13444:3241,remediat,remediationStrategy,3241,https://hail.is,https://github.com/hail-is/hail/pull/13444,1,['remediat'],['remediationStrategy']
Safety,c.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102) at io.netty.channel.AbstractChannelHandlerContext.innelHandlerContext.java:348) at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340) at lerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(Abstrac0) at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359) at io.netty.channel.AbstractChannelRead(AbstractChannelHandlerContext.java:348) at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935) at ocessSelectedKey(NioEventLoop.java:645) at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:580) at ava:459) at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858) at io.netty.util.concurrent. Java stack trace:; org.apache.spark.SparkException: Job aborted.; at org.apache.spark.internal.io.SparkHadoopWriter$.write(SparkHadoopWriter.scala:100); at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1.apply$mcV$sp(PairRDDFunctions.scala:1096); at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1.apply(PairRDDFunctions.scala:1094); at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1.apply(PairRDDFunctions.scala:1094); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); at org.apache.spark.rdd.RDD.withScope(RDD.scala:363); at org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopDataset(PairRDDFunctions.scala:1094); at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$4.apply$mcV$sp(PairRDDFunctions.scala:1067); at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$4.apply(PairRDDFunctions.scala:1032); at org.apache.spark.rdd.PairRDDFunctio,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8106:11106,abort,aborted,11106,https://hail.is,https://github.com/hail-is/hail/issues/8106,1,['abort'],['aborted']
Safety,"cala:198); at org.apache.spark.sql.DataFrameWriter.parquet(DataFrameWriter.scala:494); at is.hail.variant.VariantDatasetFunctions$.write$extension(VariantDataset.scala:751); at is.hail.variant.VariantDatasetFunctions.write(VariantDataset.scala:721); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); at py4j.Gateway.invoke(Gateway.java:280); at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); at py4j.commands.CallCommand.execute(CallCommand.java:79); at py4j.GatewayConnection.run(GatewayConnection.java:214); at java.lang.Thread.run(Thread.java:748)org.apache.spark.SparkException: Job aborted due to stage failure: Task 754 in stage 1.0 failed 1 times, most recent failure: Lost task 754.0 in stage 1.0 (TID 1625, localhost, executor driver): org.apache.spark.SparkException: Task failed while writing rows; at org.apache.spark.sql.execution.datasources.FileFormatWriter$.org$apache$spark$sql$execution$datasources$FileFormatWriter$$executeTask(FileFormatWriter.scala:204); at org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$write$1$$anonfun$3.apply(FileFormatWriter.scala:129); at org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$write$1$$anonfun$3.apply(FileFormatWriter.scala:128); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:99); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); at jav",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2407:4107,abort,aborted,4107,https://hail.is,https://github.com/hail-is/hail/issues/2407,1,['abort'],['aborted']
Safety,"cala:2118); at org.apache.spark.SparkContext$$anonfun$33.apply(SparkContext.scala:2118); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:108); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); ... 1 more. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/tmp/b09ec92a-49f4-4d16-ad6d-efc5a5805e92/05_variant_qc.py"", line 201, in <module>; cumcounts = {'step0': rt.aggregate(hl.agg.sum(hl.cond(rt.qccum.step0, 1, 0))),; File ""<decorator-gen-519>"", line 2, in aggregate; File ""/home/hail/hail.zip/hail/utils/java.py"", line 191, in handle_py4j; hail.utils.java.FatalError: AssertionError: assertion failed. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 7 in stage 6.0 failed 20 times, most recent failure: Lost task 7.19 in stage 6.0 (TID 179, robert1-w-0.c.ccdg-wgs.internal, executor 4): java.lang.AssertionError: assertion failed; at scala.Predef$.assert(Predef.scala:156); at is.hail.annotations.RegionValueBuilder.endStruct(RegionValueBuilder.scala:109); at is.hail.variant.MatrixTable$$anonfun$filterGenotypes$1$$anonfun$apply$80.apply(MatrixTable.scala:2645); at is.hail.variant.MatrixTable$$anonfun$filterGenotypes$1$$anonfun$apply$80.apply(MatrixTable.scala:2615); at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); at is.hail.rvd.OrderedRVD$$anonfun$apply$6$$anon$5.next(OrderedRVD.scala:736); at is.hail.rvd.OrderedRVD$$anonfun$apply$6$$anon$5.next(OrderedRVD.scala:730); at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); at is.hail.rvd.OrderedRVD$$anonfun$apply$6$$anon$5.next(OrderedRVD.scala:736); at is.hail.rvd.OrderedRVD$$anonfun$apply$6$$anon$5.next(OrderedRVD.scala:730); at scala.colle",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3063:11831,abort,aborted,11831,https://hail.is,https://github.com/hail-is/hail/issues/3063,1,['abort'],['aborted']
Safety,"call_soon() for raising TimeoutError if deadline is reached on entering into; async context manager</p>; </li>; </ol>; <p>(<a href=""https://github-redirect.dependabot.com/aio-libs/async-timeout/issues/258"">#258</a>)</p>; </li>; <li>; <p>Make <code>Timeout</code> class available in <code>__all__</code>.</p>; </li>; </ul>; <h1>4.0.0 (2021-11-01)</h1>; <ul>; <li>; <p>Implemented <code>timeout_at(deadline)</code> (<a href=""https://github-redirect.dependabot.com/aio-libs/async-timeout/issues/117"">#117</a>)</p>; </li>; <li>; <p>Supported <code>timeout.deadline</code> and <code>timeout.expired</code> properties.</p>; </li>; <li>; <p>Dropped <code>timeout.remaining</code> property: it can be calculated as; <code>timeout.deadline - loop.time()</code></p>; </li>; <li>; <p>Dropped <code>timeout.timeout</code> property that returns a relative timeout based on the; timeout object creation time; the absolute <code>timeout.deadline</code> should be used; instead.</p>; </li>; <li>; <p>Added the deadline modification methods: <code>timeout.reject()</code>,; <code>timeout.shift(delay)</code>, <code>timeout.update(deadline)</code>.</p>; </li>; <li>; <p>Deprecated synchronous context manager usage</p>; </li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/aio-libs/async-timeout/commit/5128f7f4ff73b165579006a8336978efaeeca07a""><code>5128f7f</code></a> Fix CHANGES</li>; <li><a href=""https://github.com/aio-libs/async-timeout/commit/18e718a56f9def7dc40bb9ce3a2962a8fb0c883c""><code>18e718a</code></a> Bump to 4.0.2</li>; <li><a href=""https://github.com/aio-libs/async-timeout/commit/48d1c4ce923b1da75976d7e2a6ca9234b3092c16""><code>48d1c4c</code></a> Setup towncrier</li>; <li><a href=""https://github.com/aio-libs/async-timeout/commit/2ede7d73e55f8d1a2279d78861af0009d96219fb""><code>2ede7d7</code></a> Fix annotations on <code>__exit__</code> and <code>__aexit__</code> (<a href=""https://github-redirect.dependabot.com/aio-libs/async-timeo",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11465:3721,timeout,timeout,3721,https://hail.is,https://github.com/hail-is/hail/pull/11465,1,['timeout'],['timeout']
Safety,"can be calculated as; <code>timeout.deadline - loop.time()</code></p>; </li>; <li>; <p>Dropped <code>timeout.timeout</code> property that returns a relative timeout based on the; timeout object creation time; the absolute <code>timeout.deadline</code> should be used; instead.</p>; </li>; <li>; <p>Added the deadline modification methods: <code>timeout.reject()</code>,; <code>timeout.shift(delay)</code>, <code>timeout.update(deadline)</code>.</p>; </li>; <li>; <p>Deprecated synchronous context manager usage</p>; </li>; </ul>; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/aio-libs/async-timeout/blob/master/CHANGES.rst"">async-timeout's changelog</a>.</em></p>; <blockquote>; <h1>4.0.2 (2021-12-20)</h1>; <h2>Misc</h2>; <ul>; <li><code>[#259](https://github.com/aio-libs/async-timeout/issues/259) &lt;https://github.com/aio-libs/async-timeout/issues/259&gt;</code><em>, <code>[#274](https://github.com/aio-libs/async-timeout/issues/274) &lt;https://github.com/aio-libs/async-timeout/issues/274&gt;</code></em></li>; </ul>; <h1>4.0.1 (2121-11-10)</h1>; <ul>; <li>; <p>Fix regression:</p>; <ol>; <li>; <p>Don't raise TimeoutError from timeout object that doesn't enter into async context; manager</p>; </li>; <li>; <p>Use call_soon() for raising TimeoutError if deadline is reached on entering into; async context manager</p>; </li>; </ol>; <p>(<a href=""https://github-redirect.dependabot.com/aio-libs/async-timeout/issues/258"">#258</a>)</p>; </li>; <li>; <p>Make <code>Timeout</code> class available in <code>__all__</code>.</p>; </li>; </ul>; <h1>4.0.0 (2021-11-01)</h1>; <ul>; <li>; <p>Implemented <code>timeout_at(deadline)</code> (<a href=""https://github-redirect.dependabot.com/aio-libs/async-timeout/issues/117"">#117</a>)</p>; </li>; <li>; <p>Supported <code>timeout.deadline</code> and <code>timeout.expired</code> properties.</p>; </li>; <li>; <p>Dropped <code>timeout.remaining</code> property: it can be calculated as;",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11465:2387,timeout,timeout,2387,https://hail.is,https://github.com/hail-is/hail/pull/11465,1,['timeout'],['timeout']
Safety,"cc @cseed, @jigold, @danking . Adds a `users.user_data` table reader. Upon login the user's `user_data` entry is read, stored in a `user` cookie, as a hmac/sha256-signed jwt. The secret key is the `'/notebook-secrets/secret-key'`. In order to avoid duplicating user data storage, I use the `user` cookie in place of `session['user']`, and to handle this wrote a decorator to decode the token and store it in Flask.g (for the duration of the request). The claims included:. ```python; {; 'id': [int],; 'auth0_id': [str],; 'name': [str],; 'email': [str],; 'picture': [str],; 'ksa_name': [str],; 'gsa_name': [str],; 'bucket_name': [str],; }; ```. An example cookie; ```python; { ; 'auth0_id': 'google-oauth2|000000000000000',; 'bucket_name': 'user-f2khk67pq8a9pc38wnbjigarg',; 'email': 'akotlar@broadinstitute.org',; 'gsa_name': 'projects/hail-vdc/serviceAccounts/user-f2khk67pq8a9pc38wnbjigarg@hail-vdc.iam.gserviceaccount.com',; 'id': 1,; 'ksa_name': 'user-4c4pr',; 'name': 'Alex Kotlar',; 'picture': 'https://lh4.googleusercontent.com/-QIkmrfGTN1M/AAAAAAAAAAI/AAAAAAAAAAA/ACHi3reUAvw1lwovp2ozAIThEN72j-qzeQ/mo/photo.jpg'; }; ```. Here 'id' means `users.user_data.id`. To parse the cookie in your applications:; ```python; SECRET_KEY = read_string('/notebook-secrets/secret-key'). def jwt_decode(token):; if token is None:; return None. try:; payload = jwt.decode(token, SECRET_KEY, algorithms=['HS256']); except jwt.exceptions.InvalidTokenError as e:; log.exception(e); payload = None. return payload. def jwt_encode(payload):; return jwt.encode(payload, SECRET_KEY, algorithm='HS256'). def get_domain(host):; parts = host.split('.'); p_len = len(parts). return f""{parts[p_len - 2]}.{parts[p_len - 1]}""; ```. And to use this (in Flask...aiohttp will be similar): `user = jwt_decode(request.cookies.get('user'))`. The cookie is scoped to hail.is (or whatever the lowest level domain happens to be if you're locally testing). I think this is a mostly straightforward implementation, but happy to take fe",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5633:243,avoid,avoid,243,https://hail.is,https://github.com/hail-is/hail/pull/5633,1,['avoid'],['avoid']
Safety,"cc: @cseed . In preparation for the terra integration prototype, I've modified build.yaml to build and publish two public images. Both are versioned by the hail_pip_version. The first, `hailgenetics/hail`, contains hail, common python libraries, and the google cloud sdk. The second, `hailgenetics/genetics`, contains a slew of genetics tools that were used by the CCG Workshop. There is no R in any of these images. That is intentional. The image push step is scoped to deploy (but I tested it in my dev environment), so it only runs on deploy. Ergo, we should only update the image during deploy. I also added a safety check that doesn't overwrite an extant tag, if, for example, a deploy partially ran. Maybe we should update the image? I'm not sure. It seems better to not change the image automatically.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8530:614,safe,safety,614,https://hail.is,https://github.com/hail-is/hail/pull/8530,1,['safe'],['safety']
Safety,"cc: @cseed @konradjk . This PCRelate should handle larger data sizes than the previous one by avoiding shuffles. It avoids the shuffle by writing the vds to a temporary directory in block matrix form. It then loads this BlockMatrix directly. Form that point forward, the PCRelate algorithm is just non-shuffling linear algebra (however: matrix multiplication will require each node to communicate with approximately `n+m` other nodes). I'm vaguely uncomfortable with two things:. 1. I've added some hail expr lang to mean impute missing values. This is written in python. As such, correctly mean imputing is not tested by our test system any more. The mean imputation is pretty simple, so maybe we should just verify my code is right?. 2. I noticed that at some earlier point PCA was moved outside of Java as well. This also makes me uncomfortable for the same reason. Moving the tests into python is a fair lift because, AFAIK, we don't have as robust test infrastructure over there. I'm torn between the desire to get this out for @konradjk and the desire to follow our normal testing standards. ---. I've played a bit with this locally, but have not tried it on a large cluster. @konradjk, I would be very interested in how this performs on a large dataset, if you would be so kind. Please don't try this until the CI tests and doc builds pass on this PR though. I haven't run the tests locally, so I'm not certain it passes them :P",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2821:94,avoid,avoiding,94,https://hail.is,https://github.com/hail-is/hail/pull/2821,2,['avoid'],"['avoiding', 'avoids']"
Safety,"cc: @daniel-goldstein, this is a tricky asyncio situation which you should also keep in mind. OK, there were two problems:. 1. A timeout of 5s appears to be now too short for Google Cloud Storage. I am not sure why but we; timeout substantially more frequently. I have observed this myself on my laptop. Just this; morning I saw it happen to Daniel. 2. When using an `aiohttp.AsyncIterablePayload`, it is *critical* to always check if the coroutine; which actually writes to GCS (which is stashed in the variable `request_task`) is still; alive. In the current `main`, we do not do this which causes hangs (in particular the timeout; exceptions are never thrown ergo we never retry). To understand the second problem, you must first recall how writing works in aiogoogle. There are; two Tasks and an `asyncio.Queue`. The terms ""writer"" and ""reader"" are somewhat confusing, so let's; use left and right. The left Task has the owning reference to both the source ""file"" and the; destination ""file"". In particular, it is the *left* Task which closes both ""files"". Moreover, the; left Task reads chunks from the source file and places those chunks on the `asyncio.Queue`. The; right Task takes chunks off the queue and writes those chunks to the destination file. This situation can go awry in two ways. First, if the right Task encounters any kind of failure, it will stop taking chunks off of the; queue. When the queue (which has a size limit of one) is full, the left Task will hang. The system; is stuck. The left Task will wait forever for the right Task to empty the queue. The second scenario is exactly the same except that the left Task is trying to add the ""stop""; message to the queue rather than a chunk. In either case, it is critical that the left Task waits simultaneously on the queue operation *and*; on the right Task completing. If the right Task has died, no further writes can occur and the left; Task must raise an exception. In the first scenario, we do not observe the right Task'",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11830:129,timeout,timeout,129,https://hail.is,https://github.com/hail-is/hail/pull/11830,3,['timeout'],['timeout']
Safety,"cc: @tpoterba . The main and cleanup containers run in parallel and thus should not be summed but max'ed (cleanup should always be longer, but this seems safer). I'm not sure why we return None if a duration is present in the dictionary but set to None (as opposed to missing from the dictionary), but I preserved that behavior.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7061:154,safe,safer,154,https://hail.is,https://github.com/hail-is/hail/pull/7061,1,['safe'],['safer']
Safety,"ccessfully, the job is marked as scheduled.; 4. Once all requests complete, goto 1. On the worker, what happens inside `/api/v1alpha/batches/jobs/create`:; 1. Read metadata describing the job to schedule from the request body; 2. Using that information, load the full job spec from blob storage; 3. Spawn a task to run the job asynchronously; 4. Respond to the driver with a 200. The key point relevant to this issue is that the driver currently must wait for all the requests to workers in an iteration to complete before it starts the next iteration of the scheduler. This leaves the scheduler vulnerable to problematic workers or workers that happen to be preempted during the scheduling process. So, the driver sets a [2 second timeout](https://github.com/hail-is/hail/blob/b27737f67bf9e69f1abed2fec07fc7c921790ef8/batch/batch/driver/job.py#L585) on the call to `/api/v1alpha/batches/jobs/create`. Additionally, this general design means that in the event of a request timeout or transient error, Batch cannot guarantee that there is always at most one concurrent running attempt for a given job. This ends up being a fine (and intentional) concession in practice because the idempotent design of preemptible jobs tends to cover this scenario, but it is regardless wasted compute and cost to users. Nevertheless, we strive to minimize cases where we might halt the scheduling loop or double-schedule work, and one way to do that in the current design is to minimize the variance in latency of `/api/v1alpha/batches/jobs/create`. The largest source of this latency is the request to blob storage. While GCS and ABS are relatively fast and highly available, Batch in Azure Terra requires first obtaining SAS tokens from the Terra control plane, which can introduce much higher and more variable latency. There have also been occurrences in the past of corrupted or deleted specs, which introduce unexpected failure modes that should error the job but instead disrupt the scheduling loop. Many of the",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14456:1414,timeout,timeout,1414,https://hail.is,https://github.com/hail-is/hail/issues/14456,1,['timeout'],['timeout']
Safety,ccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:280); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:214); 	at java.lang.Thread.run(Thread.java:748)java.lang.AssertionError: assertion failed; 	at scala.Predef$.assert(Predef.scala:156); 	at is.hail.annotations.Region.loadInt(Region.scala:36); 	at is.hail.expr.types.TBinary$.loadLength(TBinary.scala:62); 	at is.hail.annotations.UnsafeRow$.readBinary(UnsafeRow.scala:128); 	at is.hail.annotations.UnsafeRow$.readString(UnsafeRow.scala:139); 	at is.hail.annotations.UnsafeRow$.readAltAllele(UnsafeRow.scala:152); 	at is.hail.annotations.UnsafeRow$.readArrayAltAllele(UnsafeRow.scala:164); 	at is.hail.annotations.UnsafeRow$.read(UnsafeRow.scala:210); 	at is.hail.annotations.UnsafeRow.get(UnsafeRow.scala:257); 	at is.hail.expr.FilterVariants$$anonfun$10.apply(Relational.scala:503); 	at is.hail.expr.FilterVariants$$anonfun$10.apply(Relational.scala:500); 	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:463); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$9$$anon$5.hasNext(OrderedRVD.scala:658); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$9$$anon$5.hasNext(OrderedRVD.scala:658); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$9$$anon$5.hasNext(OrderedRVD.scala:658); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at is.hail.sparkextras.OrderedRDD$$anonfu,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2743:8028,Unsafe,UnsafeRow,8028,https://hail.is,https://github.com/hail-is/hail/issues/2743,1,['Unsafe'],['UnsafeRow']
Safety,"cda4ca9a617?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/fa47fca0-549b-41a3-8bf7-bcda4ca9a617?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""8f2f7ae4-0cec-47e6-822f-e81b1067da22"",""prPublicId"":""8f2f7ae4-0cec-47e6-822f-e81b1067da22"",""dependencies"":[{""name"":""ipython"",""from"":""7.34.0"",""to"":""8.10.0""},{""name"":""jupyter-server"",""from"":""1.24.0"",""to"":""2.7.2""},{""name"":""numpy"",""from"":""1.21.3"",""to"":""1.22.2""},{""name"":""setuptools"",""from"":""39.0.1"",""to"":""65.5.1""},{""name"":""tornado"",""from"":""6.2"",""to"":""6.3.3""}],""packageManager"":""pip"",""projectPublicId"":""fa47fca0-549b-41a3-8bf7-bcda4ca9a617"",""projectUrl"":""https://app.snyk.io/org/danking/project/fa47fca0-549b-41a3-8bf7-bcda4ca9a617?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-IPYTHON-3318382"",""SNYK-PYTHON-JUPYTERSERVER-5862881"",""SNYK-PYTHON-JUPYTERSERVER-5862882"",""SNYK-PYTHON-NUMPY-2321964"",""SNYK-PYTHON-NUMPY-2321966"",""SNYK-PYTHON-NUMPY-2321970"",""SNYK-PYTHON-SETUPTOOLS-3180412"",""SNYK-PYTHON-TORNADO-5537286"",""SNYK-PYTHON-TORNADO-5840803""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""pr-warning-shown"",""priorityScore""],""priorityScoreList"":[531,null,null,null,null,null,509,384,494],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Remote Code Execution (RCE)](https://learn.snyk.io/lesson/improper-input-validation/?loc&#x3D;fix-pr); 🦉 [Access Control Bypass](https://learn.snyk.io/lesson/broken-access-control/?loc&#x3D;fix-pr); 🦉 [Open Redirect](https://learn.snyk.io/lesson/open-redirect/?loc&#x3D;fix-pr); 🦉 [More lessons are available in Snyk Learn](https://learn.snyk.io/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13871:6679,remediat,remediationStrategy,6679,https://hail.is,https://github.com/hail-is/hail/pull/13871,1,['remediat'],['remediationStrategy']
Safety,"cda4ca9a617?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""f06f3836-ea3a-4143-ba99-12b7ad33753d"",""prPublicId"":""f06f3836-ea3a-4143-ba99-12b7ad33753d"",""dependencies"":[{""name"":""aiohttp"",""from"":""3.8.6"",""to"":""3.9.2""},{""name"":""ipython"",""from"":""7.34.0"",""to"":""8.10.0""},{""name"":""jupyter-server"",""from"":""1.24.0"",""to"":""2.11.2""},{""name"":""setuptools"",""from"":""39.0.1"",""to"":""65.5.1""},{""name"":""tornado"",""from"":""6.2"",""to"":""6.3.3""}],""packageManager"":""pip"",""projectPublicId"":""fa47fca0-549b-41a3-8bf7-bcda4ca9a617"",""projectUrl"":""https://app.snyk.io/org/danking/project/fa47fca0-549b-41a3-8bf7-bcda4ca9a617?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-AIOHTTP-6091621"",""SNYK-PYTHON-AIOHTTP-6091622"",""SNYK-PYTHON-AIOHTTP-6209406"",""SNYK-PYTHON-AIOHTTP-6209407"",""SNYK-PYTHON-IPYTHON-3318382"",""SNYK-PYTHON-JUPYTERSERVER-5862881"",""SNYK-PYTHON-JUPYTERSERVER-5862882"",""SNYK-PYTHON-JUPYTERSERVER-6099119"",""SNYK-PYTHON-SETUPTOOLS-3180412"",""SNYK-PYTHON-TORNADO-5537286"",""SNYK-PYTHON-TORNADO-5840803"",""SNYK-PYTHON-TORNADO-6041512""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""pr-warning-shown""],""priorityScoreList"":[null,null,null,null,531,null,null,null,509,384,494,539],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Improper Input Validation](https://learn.snyk.io/lesson/improper-input-validation/?loc&#x3D;fix-pr); 🦉 [Improper Limitation of a Pathname to a Restricted Directory (&#x27;Path Traversal&#x27;)](https://learn.snyk.io/lesson/directory-traversal/?loc&#x3D;fix-pr); 🦉 [Access Control Bypass](https://learn.snyk.io/lesson/broken-access-control/?loc&#x3D;fix-pr); 🦉 [More lessons are available in Snyk Learn](https://learn.snyk.io/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14259:7249,remediat,remediationStrategy,7249,https://hail.is,https://github.com/hail-is/hail/pull/14259,1,['remediat'],['remediationStrategy']
Safety,"ce.py"", line 38, in <module>; main(args); File ""/tmp/f93de2d1-2d89-43f9-9868-f266eb88a6f1/concordance.py"", line 19, in main; bi_summary, bi_samples, bi_variants = methods.concordance(bi_past_vds, bi_future_vds); File ""<decorator-gen-1304>"", line 2, in concordance; File ""/tmp/f93de2d1-2d89-43f9-9868-f266eb88a6f1/hail-devel-08a15431a0ef.zip/hail/utils/java.py"", line 155, in handle_py4j; hail.utils.java.FatalError: AssertionError: assertion failed. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 30 in stage 1.0 failed 20 times, most recent failure: Lost task 30.19 in stage 1.0 (TID 4847, lfdev2-sw-f5w2.c.broad-mpg-gnomad.internal): java.lang.AssertionError: assertion failed; 	at scala.Predef$.assert(Predef.scala:156); 	at is.hail.annotations.Region.loadInt(Region.scala:36); 	at is.hail.expr.types.TBinary$.loadLength(TBinary.scala:62); 	at is.hail.annotations.UnsafeRow$.readBinary(UnsafeRow.scala:128); 	at is.hail.annotations.UnsafeRow$.readString(UnsafeRow.scala:139); 	at is.hail.annotations.UnsafeRow$.readAltAllele(UnsafeRow.scala:152); 	at is.hail.annotations.UnsafeRow$.readArrayAltAllele(UnsafeRow.scala:164); 	at is.hail.annotations.UnsafeRow$.read(UnsafeRow.scala:210); 	at is.hail.annotations.UnsafeRow.get(UnsafeRow.scala:257); 	at is.hail.expr.FilterVariants$$anonfun$10.apply(Relational.scala:503); 	at is.hail.expr.FilterVariants$$anonfun$10.apply(Relational.scala:500); 	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:463); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$9$$anon$5.hasNext(OrderedRVD.scala:658); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$9$$anon$5.hasNext(OrderedRVD.scala:658); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$9$$anon$5.hasNext(OrderedRVD.scala:658); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at is.hail.sparkextras.OrderedRDD$$anonfu",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2743:2341,Unsafe,UnsafeRow,2341,https://hail.is,https://github.com/hail-is/hail/issues/2743,1,['Unsafe'],['UnsafeRow']
Safety,"ce; File ""/tmp/f93de2d1-2d89-43f9-9868-f266eb88a6f1/hail-devel-08a15431a0ef.zip/hail/utils/java.py"", line 155, in handle_py4j; hail.utils.java.FatalError: AssertionError: assertion failed. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 30 in stage 1.0 failed 20 times, most recent failure: Lost task 30.19 in stage 1.0 (TID 4847, lfdev2-sw-f5w2.c.broad-mpg-gnomad.internal): java.lang.AssertionError: assertion failed; 	at scala.Predef$.assert(Predef.scala:156); 	at is.hail.annotations.Region.loadInt(Region.scala:36); 	at is.hail.expr.types.TBinary$.loadLength(TBinary.scala:62); 	at is.hail.annotations.UnsafeRow$.readBinary(UnsafeRow.scala:128); 	at is.hail.annotations.UnsafeRow$.readString(UnsafeRow.scala:139); 	at is.hail.annotations.UnsafeRow$.readAltAllele(UnsafeRow.scala:152); 	at is.hail.annotations.UnsafeRow$.readArrayAltAllele(UnsafeRow.scala:164); 	at is.hail.annotations.UnsafeRow$.read(UnsafeRow.scala:210); 	at is.hail.annotations.UnsafeRow.get(UnsafeRow.scala:257); 	at is.hail.expr.FilterVariants$$anonfun$10.apply(Relational.scala:503); 	at is.hail.expr.FilterVariants$$anonfun$10.apply(Relational.scala:500); 	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:463); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$9$$anon$5.hasNext(OrderedRVD.scala:658); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$9$$anon$5.hasNext(OrderedRVD.scala:658); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$9$$anon$5.hasNext(OrderedRVD.scala:658); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at is.hail.sparkextras.OrderedRDD$$anonfun$apply$5$$anon$2.hasNext(OrderedRDD.scala:194); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at is.hail.sparkextras.PartitionKeyInfo$.apply(PartitionKeyInfo.scala:30);",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2743:2596,Unsafe,UnsafeRow,2596,https://hail.is,https://github.com/hail-is/hail/issues/2743,1,['Unsafe'],['UnsafeRow']
Safety,"ch this to a disk-based index.~ Made it disk-based, called it `OnDiskBTreeIndexToValue` #3794. - each hadoop `FileSplit` now contains a possibly null (indicating no filter) list of variants (by index) to keep, in practice this should be quite small. - ~I changed several asserts to `if`'s with fatals, so as not to allocate strings~ Moved to #3771. - ~We no longer copy the genotype data into a buffer in the block reader. This was forcing the `fastKeys` to do an unnecessary data copy~ Moved to #3783 (with some substantial refactoring so it doesn't look much like this PR anymore). - ~I changed the contract on BgenRecord to require that `getValue` is called to ""consume"" the record before the next record is taken~ Irrelevant thanks to #3783 's refactoring. - ~`getValue(null)` just skips bytes (no copy, no decompression)~ Irrelevant thanks to #3783 's refactoring. - ~I added `RegionValueBuilder.unsafeAdvance` which can be used when you're creating an array of empty structs but don't want to do all the unnecessary RVB bookkeeping work.~ Moved to #3773. - ~I use `RegionValueBuilder.unsafeAdvance` to make loading a BGEN without entry fields very fast.~ Rolled into #3783. - ~I fixed `Table.index` to not trigger a partition key info gathering~ Moved to #3774. I had to ship the arrays of filtered variant indices to the workers somehow, so I shipped them as base64 encoded arrays of bytes. It's pretty groady (and that's why I added the commons-codec library). I don't know how else to initialize record readers with hadoop. Generally, I think the BGEN loading code could use a clean up, and I haven't done that here, if anything I've made it more complicated. I also need to check that there are tests for or write tests for:. - indexing tables doesn't cause an extra shuffle; - ~the include lid and include raid flags~ included in #3779; - the variant list flag; - `getSplits`; - the variant filtering code; - ~loading a bgen with no entries~ exists: `BGENTests.test_import_bgen_no_entries`",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3727:2797,unsafe,unsafeAdvance,2797,https://hail.is,https://github.com/hail-is/hail/pull/3727,1,['unsafe'],['unsafeAdvance']
Safety,"changelog</a>.</em></p>; <blockquote>; <h1>v4.11.2</h1>; <ul>; <li><a href=""https://github-redirect.dependabot.com/python/importlib_metadata/issues/369"">#369</a>: Fixed bug where <code>EntryPoint.extras</code> was returning; match objects and not the extras strings.</li>; </ul>; <h1>v4.11.1</h1>; <ul>; <li><a href=""https://github-redirect.dependabot.com/python/importlib_metadata/issues/367"">#367</a>: In <code>Distribution.requires</code> for egg-info, if <code>requires.txt</code>; is empty, return an empty list.</li>; </ul>; <h1>v4.11.0</h1>; <ul>; <li>bpo-46246: Added <code>__slots__</code> to <code>EntryPoints</code>.</li>; </ul>; <h1>v4.10.2</h1>; <ul>; <li><a href=""https://github-redirect.dependabot.com/python/importlib_metadata/issues/365"">#365</a> and bpo-46546: Avoid leaking <code>method_name</code> in; <code>DeprecatedList</code>.</li>; </ul>; <h1>v4.10.1</h1>; <h1>v2.1.3</h1>; <ul>; <li><a href=""https://github-redirect.dependabot.com/python/importlib_metadata/issues/361"">#361</a>: Avoid potential REDoS in <code>EntryPoint.pattern</code>.</li>; </ul>; <h1>v4.10.0</h1>; <ul>; <li><a href=""https://github-redirect.dependabot.com/python/importlib_metadata/issues/354"">#354</a>: Removed <code>Distribution._local</code> factory. This; functionality was created as a demonstration of the; possible implementation. Now, the; <code>pep517 &lt;https://pypi.org/project/pep517&gt;</code>_ package; provides this functionality directly through; <code>pep517.meta.load &lt;https://github.com/pypa/pep517/blob/a942316305395f8f757f210e2b16f738af73f8b8/pep517/meta.py#L63-L73&gt;</code>_.</li>; </ul>; <h1>v4.9.0</h1>; <ul>; <li>Require Python 3.7 or later.</li>; </ul>; <h1>v4.8.3</h1>; <ul>; <li><a href=""https://github-redirect.dependabot.com/python/importlib_metadata/issues/357"">#357</a>: Fixed requirement generation from egg-info when a</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a hr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11525:1290,Avoid,Avoid,1290,https://hail.is,https://github.com/hail-is/hail/pull/11525,1,['Avoid'],['Avoid']
Safety,che.spark.sql.execution.datasources.FileFormatWriter$$anonfun$org$apache$spark$sql$execution$datasources$FileFormatWriter$$executeTask$3.apply(FileFormatWriter.scala:188); at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1341); at org.apache.spark.sql.execution.datasources.FileFormatWriter$.org$apache$spark$sql$execution$datasources$FileFormatWriter$$executeTask(FileFormatWriter.scala:193); ... 8 more. Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1435); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1423); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1422); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1422); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:802); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1650); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1605); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1594); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:628); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1918); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1931); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1951); at org,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2407:7652,abort,abortStage,7652,https://hail.is,https://github.com/hail-is/hail/issues/2407,1,['abort'],['abortStage']
Safety,"ched on entering into; async context manager</p>; </li>; </ol>; <p>(<a href=""https://github-redirect.dependabot.com/aio-libs/async-timeout/issues/258"">#258</a>)</p>; </li>; <li>; <p>Make <code>Timeout</code> class available in <code>__all__</code>.</p>; </li>; </ul>; <h1>4.0.0 (2021-11-01)</h1>; <ul>; <li>; <p>Implemented <code>timeout_at(deadline)</code> (<a href=""https://github-redirect.dependabot.com/aio-libs/async-timeout/issues/117"">#117</a>)</p>; </li>; <li>; <p>Supported <code>timeout.deadline</code> and <code>timeout.expired</code> properties.</p>; </li>; <li>; <p>Dropped <code>timeout.remaining</code> property: it can be calculated as; <code>timeout.deadline - loop.time()</code></p>; </li>; <li>; <p>Dropped <code>timeout.timeout</code> property that returns a relative timeout based on the; timeout object creation time; the absolute <code>timeout.deadline</code> should be used; instead.</p>; </li>; <li>; <p>Added the deadline modification methods: <code>timeout.reject()</code>,; <code>timeout.shift(delay)</code>, <code>timeout.update(deadline)</code>.</p>; </li>; <li>; <p>Deprecated synchronous context manager usage</p>; </li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/aio-libs/async-timeout/commit/5128f7f4ff73b165579006a8336978efaeeca07a""><code>5128f7f</code></a> Fix CHANGES</li>; <li><a href=""https://github.com/aio-libs/async-timeout/commit/18e718a56f9def7dc40bb9ce3a2962a8fb0c883c""><code>18e718a</code></a> Bump to 4.0.2</li>; <li><a href=""https://github.com/aio-libs/async-timeout/commit/48d1c4ce923b1da75976d7e2a6ca9234b3092c16""><code>48d1c4c</code></a> Setup towncrier</li>; <li><a href=""https://github.com/aio-libs/async-timeout/commit/2ede7d73e55f8d1a2279d78861af0009d96219fb""><code>2ede7d7</code></a> Fix annotations on <code>__exit__</code> and <code>__aexit__</code> (<a href=""https://github-redirect.dependabot.com/aio-libs/async-timeout/issues/274"">#274</a>)</li>; <li><a href=""https://gi",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11465:3753,timeout,timeout,3753,https://hail.is,https://github.com/hail-is/hail/pull/11465,1,['timeout'],['timeout']
Safety,cheduler.ResultTask.runTask(ResultTask.scala:70); 	at org.apache.spark.scheduler.Task.run(Task.scala:86); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); Caused by: org.elasticsearch.hadoop.EsHadoopIllegalArgumentException: Unsupported/Unknown Elasticsearch version 6.0.0; 	at org.elasticsearch.hadoop.util.EsMajorVersion.parse(EsMajorVersion.java:79); 	at org.elasticsearch.hadoop.rest.RestClient.remoteEsVersion(RestClient.java:613); 	at org.elasticsearch.hadoop.rest.InitializationUtils.discoverEsVersion(InitializationUtils.java:240); 	... 10 more. Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGSche,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4138:3304,abort,abortStage,3304,https://hail.is,https://github.com/hail-is/hail/issues/4138,1,['abort'],['abortStage']
Safety,"chols_model: generating genotypes for 1 populations, 1000 samples, and 50000 variants...; 	[Stage 9:> (0 + 18) / 18]; 	[FAIL] with 354 partitions; 	Traceback (most recent call last):; 	 File ""test_11_cluster_sampleqc.py"", line 20, in <module>; 		print(""\n[PASS] with"", N, ""partitions:"", Y.count()); 	 File ""/bmrn/apps/hail/0.2.44/python/hail-0.2.44-py3-none-any.egg/hail/matrixtable.py"", line 2426, in count; 		return Env.backend().execute(count_ir); 	 File ""/bmrn/apps/hail/0.2.44/python/hail-0.2.44-py3-none-any.egg/hail/backend/spark_backend.py"", line 296, in execute; 		result = json.loads(self._jhc.backend().executeJSON(jir)); 	 File ""/bmrn/apps/spark/2.4.5/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py"", line 1257, in __call__; 	 File ""/bmrn/apps/hail/0.2.44/python/hail-0.2.44-py3-none-any.egg/hail/backend/spark_backend.py"", line 41, in deco; 		'Error summary: %s' % (deepest, full, hail.__version__, deepest)) from None; 	hail.utils.java.FatalError: SparkException: Job aborted due to stage failure: ResultStage 9 (runJob at RVD.scala:688) has failed the maximum allowable number of times: 4. Most recent failure reason: org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 0 at org.apache.spark.MapOutputTracker$$anonfun$convertMapStatuses$2.apply(MapOutputTracker.scala:882) at org.apache.spark.MapOutputTracker$$anonfun$convertMapStatuses$2.apply(MapOutputTracker.scala:878) at scala.collection.Iterator$class.foreach(Iterator.scala:891) at scala.collection.AbstractIterator.foreach(Iterator.scala:1334) at org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:878) at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:691) at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49) at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105) at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346) at org.apache.spark.rdd.RDD.ite",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8944:3753,abort,aborted,3753,https://hail.is,https://github.com/hail-is/hail/issues/8944,1,['abort'],['aborted']
Safety,"ck the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI4MmVlNzU5Ny0wZmFhLTQ1NmUtOTA3Ny0zOTM4ODRjNzJmNGMiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjgyZWU3NTk3LTBmYWEtNDU2ZS05MDc3LTM5Mzg4NGM3MmY0YyJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""82ee7597-0faa-456e-9077-393884c72f4c"",""prPublicId"":""82ee7597-0faa-456e-9077-393884c72f4c"",""dependencies"":[{""name"":""cryptography"",""from"":""41.0.2"",""to"":""41.0.3""}],""packageManager"":""pip"",""projectPublicId"":""5ecb4152-94d0-44ff-86c6-21e542bb123d"",""projectUrl"":""https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-CRYPTOGRAPHY-5813745"",""SNYK-PYTHON-CRYPTOGRAPHY-5813746"",""SNYK-PYTHON-CRYPTOGRAPHY-5813750""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""pr-warning-shown"",""priorityScore""],""priorityScoreList"":[471,551,471],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Denial of Service (DoS)](https://learn.snyk.io/lesson/redos/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13370:4204,remediat,remediationStrategy,4204,https://hail.is,https://github.com/hail-is/hail/pull/13370,1,['remediat'],['remediationStrategy']
Safety,"ck the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiIxOGJjNGZiYS05ZTMwLTRmNWItYTE4Yy0wOGNmNDVmZDExMTciLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjE4YmM0ZmJhLTllMzAtNGY1Yi1hMThjLTA4Y2Y0NWZkMTExNyJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""18bc4fba-9e30-4f5b-a18c-08cf45fd1117"",""prPublicId"":""18bc4fba-9e30-4f5b-a18c-08cf45fd1117"",""dependencies"":[{""name"":""cryptography"",""from"":""41.0.2"",""to"":""41.0.3""}],""packageManager"":""pip"",""projectPublicId"":""c1c98f6a-57c6-4ecc-a329-3b744cab74bd"",""projectUrl"":""https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-CRYPTOGRAPHY-5813745"",""SNYK-PYTHON-CRYPTOGRAPHY-5813746"",""SNYK-PYTHON-CRYPTOGRAPHY-5813750""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""pr-warning-shown"",""priorityScore""],""priorityScoreList"":[471,551,471],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Denial of Service (DoS)](https://learn.snyk.io/lesson/redos/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13366:4212,remediat,remediationStrategy,4212,https://hail.is,https://github.com/hail-is/hail/pull/13366,1,['remediat'],['remediationStrategy']
Safety,"ckages varying only by non-normalized; name are hidden.</li>; </ul>; <h1>v4.11.3</h1>; <ul>; <li><a href=""https://github-redirect.dependabot.com/python/importlib_metadata/issues/372"">#372</a>: Removed cast of path items in FastPath, not needed.</li>; </ul>; <h1>v4.11.2</h1>; <ul>; <li><a href=""https://github-redirect.dependabot.com/python/importlib_metadata/issues/369"">#369</a>: Fixed bug where <code>EntryPoint.extras</code> was returning; match objects and not the extras strings.</li>; </ul>; <h1>v4.11.1</h1>; <ul>; <li><a href=""https://github-redirect.dependabot.com/python/importlib_metadata/issues/367"">#367</a>: In <code>Distribution.requires</code> for egg-info, if <code>requires.txt</code>; is empty, return an empty list.</li>; </ul>; <h1>v4.11.0</h1>; <ul>; <li>bpo-46246: Added <code>__slots__</code> to <code>EntryPoints</code>.</li>; </ul>; <h1>v4.10.2</h1>; <ul>; <li><a href=""https://github-redirect.dependabot.com/python/importlib_metadata/issues/365"">#365</a> and bpo-46546: Avoid leaking <code>method_name</code> in; <code>DeprecatedList</code>.</li>; </ul>; <h1>v4.10.1</h1>; <h1>v2.1.3</h1>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/python/importlib_metadata/commit/516f2a78061d27a3baff53ce4b08f95b638f60d3""><code>516f2a7</code></a> Fix reference in docs build.</li>; <li><a href=""https://github.com/python/importlib_metadata/commit/c8d7285af792d6851227212d4261ce7ae180a87c""><code>c8d7285</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/python/importlib_metadata/issues/391"">#391</a> from python/ghpython-93259/from-name-arg-validation-s...</li>; <li><a href=""https://github.com/python/importlib_metadata/commit/91b71494226a95251134c4fe6ea65a1dd25f495c""><code>91b7149</code></a> Update changelog</li>; <li><a href=""https://github.com/python/importlib_metadata/commit/c96dc1e77f032315bfc78f0c1d13c9a61fb68c3f""><code>c96dc1e</code></",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12000:1989,Avoid,Avoid,1989,https://hail.is,https://github.com/hail-is/hail/pull/12000,1,['Avoid'],['Avoid']
Safety,cluster sanity check,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4241:8,sanity check,sanity check,8,https://hail.is,https://github.com/hail-is/hail/pull/4241,1,['sanity check'],['sanity check']
Safety,"com/cbeust/testng/pull/2826"">cbeust/testng#2826</a></li>; <li>GITHUB-2830 - Failsafe parameter.toString by <a href=""https://github.com/seregamorph""><code>@​seregamorph</code></a> in <a href=""https://github-redirect.dependabot.com/cbeust/testng/pull/2831"">cbeust/testng#2831</a></li>; <li>Changing assertion message of the osgitest by <a href=""https://github.com/krmahadevan""><code>@​krmahadevan</code></a> in <a href=""https://github-redirect.dependabot.com/cbeust/testng/pull/2832"">cbeust/testng#2832</a></li>; <li>hidden spotbugs in release <a href=""https://github-redirect.dependabot.com/cbeust/testng/issues/2829"">#2829</a> by <a href=""https://github.com/bobshie""><code>@​bobshie</code></a> in <a href=""https://github-redirect.dependabot.com/cbeust/testng/pull/2833"">cbeust/testng#2833</a></li>; <li>Enhancing the Matrix by <a href=""https://github.com/krmahadevan""><code>@​krmahadevan</code></a> in <a href=""https://github-redirect.dependabot.com/cbeust/testng/pull/2834"">cbeust/testng#2834</a></li>; <li>Avoid Compilation errors on Semeru JDK flavour. by <a href=""https://github.com/krmahadevan""><code>@​krmahadevan</code></a> in <a href=""https://github-redirect.dependabot.com/cbeust/testng/pull/2835"">cbeust/testng#2835</a></li>; <li>Add addition yml extension by <a href=""https://github.com/speedythesnail""><code>@​speedythesnail</code></a> in <a href=""https://github-redirect.dependabot.com/cbeust/testng/pull/2837"">cbeust/testng#2837</a></li>; <li>Support getting dependencies info for a test by <a href=""https://github.com/krmahadevan""><code>@​krmahadevan</code></a> in <a href=""https://github-redirect.dependabot.com/cbeust/testng/pull/2839"">cbeust/testng#2839</a></li>; <li>Honour regex in dependsOnMethods by <a href=""https://github.com/krmahadevan""><code>@​krmahadevan</code></a> in <a href=""https://github-redirect.dependabot.com/cbeust/testng/pull/2838"">cbeust/testng#2838</a></li>; <li>Ensure All tests run all the time by <a href=""https://github.com/krmahadevan""><code>@​krmahadevan<",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12665:6005,Avoid,Avoid,6005,https://hail.is,https://github.com/hail-is/hail/pull/12665,1,['Avoid'],['Avoid']
Safety,"com/kohlschutter/junixsocket) from 2.3.2 to 2.6.1.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/kohlschutter/junixsocket/releases"">junixsocket-core's releases</a>.</em></p>; <blockquote>; <h2>junixsocket 2.6.1</h2>; <ul>; <li>Add AFSocket.checkConnectionClosed to probe connection status</li>; <li>Fix connection status checks and error handling</li>; <li>Fix bind behavior on Windows, support re-bind with reuseAddress</li>; <li>Fix and improve unit tests/selftests, remove several false-positive errors found in the wild (Azure Cloudshell/Microsoft CBL-Mariner 2.0, Amazon EC2, OpenBSD, etc.)</li>; <li>Fix SimpleTestServer demo, actually counting now to 5, not 6.</li>; <li>Make builds reproducible, align timestamps with git commit</li>; </ul>; <p>NOTE: If you're seeing unexpected errors in selftest, please verify with the attached <code>junixsocket-selftest-2.6.1-hotpatch-jar-with-dependencies.jar</code>. There may be false-positive socket timeout issues on very slow machines (e.g., qemu s390).</p>; <h2>junixsocket 2.6.0</h2>; <ul>; <li>Add support for GraalVM native-image</li>; <li>Add support for native-image selftest</li>; <li>Add support for AF_VSOCK (on Linux, and some macOS VMs)</li>; <li>Reintroduce deprecated legacy constructors for AFUNIXSocketAddress that were removed in 2.5.0.</li>; <li>Parent POM has been renamed from junixsocket-parent to junixsocket</li>; </ul>; <h2>junixsocket 2.5.2</h2>; <ul>; <li>Fix address handling in the Abstract Namespace</li>; <li>Fix support for very large datagrams (&gt; 1MB)</li>; <li>Fix InetAddress-wrapping of long addresses</li>; <li>Update Xcode support script, crossclang</li>; <li>Bump postgresql version in demo code</li>; <li>Fix dependency for custom architecture artifact</li>; </ul>; <h2>junixsocket 2.5.1</h2>; <ul>; <li>Add support for IBM z/OS (experimental, binary not included)</li>; <li>Add support for building from source on arm64-Linux</li>; <li>Add junixsocket suppor",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12483:1038,timeout,timeout,1038,https://hail.is,https://github.com/hail-is/hail/pull/12483,1,['timeout'],['timeout']
Safety,"command:. hail-new read -i /user/tpoterba/exac_reimport.vds \; filtersamples --remove -c ""file:///humgen/atgu1/fs03/wip/aganna/HCSCORE/CANCER/samples_to_keep.sample_list"" \; variantqc \; filtervariants --keep -c 'va.qc.MAC > 0' \; count \; filtersamples --keep -c 'false' \; write -o /user/aganna/exac_noCANCER.split.onlygeno.vep.NEWHAIL.vds. Error:. hail: info: running: write -o /user/aganna/exac_noCANCER.split.onlygeno.vep.NEWHAIL.vds; [Stage 2:> (0 + 72) / 14038]hail: write: caught exception: org.apache.spark.SparkException: Job aborted. [hail.log.txt](https://github.com/broadinstitute/hail/files/223029/hail.log.txt)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/304:536,abort,aborted,536,https://hail.is,https://github.com/hail-is/hail/issues/304,1,['abort'],['aborted']
Safety,"commit/ff493afce81b1bbe7a2f866cd27510e5d9b8feef""><code>ff493af</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pytest-dev/pytest-metadata/issues/47"">#47</a> from pytest-dev/pre-commit-ci-update-config</li>; <li><a href=""https://github.com/pytest-dev/pytest-metadata/commit/4591db1fa5546ff372ae95155caed99ce8dc4842""><code>4591db1</code></a> [pre-commit.ci] pre-commit autoupdate</li>; <li><a href=""https://github.com/pytest-dev/pytest-metadata/commit/0414bb9f81cc1856ea021504eecd22d202462f1d""><code>0414bb9</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pytest-dev/pytest-metadata/issues/46"">#46</a> from pytest-dev/pre-commit-ci-update-config</li>; <li><a href=""https://github.com/pytest-dev/pytest-metadata/commit/025be8999a22ae395b0e2b8ae4e7c9fa2334f874""><code>025be89</code></a> [pre-commit.ci] pre-commit autoupdate</li>; <li><a href=""https://github.com/pytest-dev/pytest-metadata/commit/429840f4de26276560961929f21aab79ed305875""><code>429840f</code></a> Avoid running nightly on forks</li>; <li><a href=""https://github.com/pytest-dev/pytest-metadata/commit/c1968f39609978ec9c6a4bcf91c37c6164483f04""><code>c1968f3</code></a> Fix nightly</li>; <li>See full diff in <a href=""https://github.com/pytest-dev/pytest-metadata/compare/v2.0.1...v2.0.2"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pytest-metadata&package-manager=pip&previous-version=2.0.1&new-version=2.0.2)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br /",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12188:1967,Avoid,Avoid,1967,https://hail.is,https://github.com/hail-is/hail/pull/12188,1,['Avoid'],['Avoid']
Safety,"conn.getresponse(); File ""/usr/local/lib/python3.6/http/client.py"", line 1354, in getresponse; response.begin(); File ""/usr/local/lib/python3.6/http/client.py"", line 307, in begin; version, status, reason = self._read_status(); File ""/usr/local/lib/python3.6/http/client.py"", line 268, in _read_status; line = str(self.fp.readline(_MAXLINE + 1), ""iso-8859-1""); File ""/usr/local/lib/python3.6/socket.py"", line 586, in readinto; return self._sock.recv_into(b); File ""/usr/local/lib/python3.6/ssl.py"", line 1012, in recv_into; return self.read(nbytes, buffer); File ""/usr/local/lib/python3.6/ssl.py"", line 874, in read; return self._sslobj.read(len, buffer); File ""/usr/local/lib/python3.6/ssl.py"", line 631, in read; v = self._sslobj.read(len, buffer); socket.timeout: The read operation timed out. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/usr/local/lib/python3.6/site-packages/requests/adapters.py"", line 449, in send; timeout=timeout; File ""/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py"", line 638, in urlopen; _stacktrace=sys.exc_info()[2]); File ""/usr/local/lib/python3.6/site-packages/urllib3/util/retry.py"", line 368, in increment; raise six.reraise(type(error), error, _stacktrace); File ""/usr/local/lib/python3.6/site-packages/urllib3/packages/six.py"", line 686, in reraise; raise value; File ""/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py"", line 600, in urlopen; chunked=chunked); File ""/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py"", line 386, in _make_request; self._raise_timeout(err=e, url=url, timeout_value=read_timeout); File ""/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py"", line 306, in _raise_timeout; raise ReadTimeoutError(self, url, ""Read timed out. (read timeout=%s)"" % timeout_value); urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='www.googleapis.com', port=443): Read timed out. (read timeout=60). During handling o",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8053:1326,timeout,timeout,1326,https://hail.is,https://github.com/hail-is/hail/issues/8053,6,['timeout'],['timeout']
Safety,"csearch. ### What went wrong (all error messages here, including the full java stack trace):; ```; Traceback (most recent call last):; File ""/hail-elasticsearch-pipelines/hail_scripts/v01/load_clinvar_to_es_pipeline.py"", line 112, in <module>; export_globals_to_index_meta=True,; File ""/hail-elasticsearch-pipelines/hail_scripts/v01/utils/elasticsearch_client.py"", line 142, in export_vds_to_elasticsearch; verbose=verbose); File ""/hail-elasticsearch-pipelines/hail_scripts/v01/utils/elasticsearch_client.py"", line 287, in export_kt_to_elasticsearch; kt.export_elasticsearch(self._host, int(self._port), index_name, index_type_name, block_size, config=elasticsearch_config); File ""<decorator-gen-143>"", line 2, in export_elasticsearch; File ""/hail/build/distributions/hail-python.zip/hail/java.py"", line 121, in handle_py4j; hail.java.FatalError: EsHadoopIllegalArgumentException: Unsupported/Unknown Elasticsearch version 6.0.0. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 12.0 failed 1 times, most recent failure: Lost task 0.0 in stage 12.0 (TID 20050, localhost): org.elasticsearch.hadoop.EsHadoopIllegalArgumentException: Cannot detect ES version - typically this happens if the network/Elasticsearch cluster is not accessible or when targeting a WAN/Cloud instance without the proper setting 'es.nodes.wan.only'; 	at org.elasticsearch.hadoop.rest.InitializationUtils.discoverEsVersion(InitializationUtils.java:247); 	at org.elasticsearch.hadoop.rest.RestService.createWriter(RestService.java:545); 	at org.elasticsearch.spark.rdd.EsRDDWriter.write(EsRDDWriter.scala:58); 	at org.elasticsearch.spark.rdd.EsSpark$$anonfun$doSaveToEs$1.apply(EsSpark.scala:102); 	at org.elasticsearch.spark.rdd.EsSpark$$anonfun$doSaveToEs$1.apply(EsSpark.scala:102); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); 	at org.apache.spark.scheduler.Task.run(Task.scala:86); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4138:1452,abort,aborted,1452,https://hail.is,https://github.com/hail-is/hail/issues/4138,1,['abort'],['aborted']
Safety,"ct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiIxMDU5YWVmMS00ZGY4LTQ2YjktYWYwNS02MWQzYTI2NjE5NWQiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjEwNTlhZWYxLTRkZjgtNDZiOS1hZjA1LTYxZDNhMjY2MTk1ZCJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/fa47fca0-549b-41a3-8bf7-bcda4ca9a617?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/fa47fca0-549b-41a3-8bf7-bcda4ca9a617?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""1059aef1-4df8-46b9-af05-61d3a266195d"",""prPublicId"":""1059aef1-4df8-46b9-af05-61d3a266195d"",""dependencies"":[{""name"":""tornado"",""from"":""6.2"",""to"":""6.3.3""}],""packageManager"":""pip"",""projectPublicId"":""fa47fca0-549b-41a3-8bf7-bcda4ca9a617"",""projectUrl"":""https://app.snyk.io/org/danking/project/fa47fca0-549b-41a3-8bf7-bcda4ca9a617?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-TORNADO-5840803""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""pr-warning-shown""],""priorityScoreList"":[null],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Learn about vulnerability in an interactive lesson of Snyk Learn.](https://learn.snyk.io/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13436:3130,remediat,remediationStrategy,3130,https://hail.is,https://github.com/hail-is/hail/pull/13436,1,['remediat'],['remediationStrategy']
Safety,"ct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJkNGViNWEyYS04NmZjLTRhZDQtYmM5MC1mZDViZWU4Mjg3YWUiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImQ0ZWI1YTJhLTg2ZmMtNGFkNC1iYzkwLWZkNWJlZTgyODdhZSJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""d4eb5a2a-86fc-4ad4-bc90-fd5bee8287ae"",""prPublicId"":""d4eb5a2a-86fc-4ad4-bc90-fd5bee8287ae"",""dependencies"":[{""name"":""cryptography"",""from"":""41.0.3"",""to"":""41.0.4""}],""packageManager"":""pip"",""projectPublicId"":""c1c98f6a-57c6-4ecc-a329-3b744cab74bd"",""projectUrl"":""https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-CRYPTOGRAPHY-5914629""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""pr-warning-shown"",""priorityScore""],""priorityScoreList"":[611],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Denial of Service (DoS)](https://learn.snyk.io/lesson/redos/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13701:3343,remediat,remediationStrategy,3343,https://hail.is,https://github.com/hail-is/hail/pull/13701,1,['remediat'],['remediationStrategy']
Safety,"ct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJmOTk4OWJlMC0yOWQ3LTQyYTctYTAzMC04NzljMTRmOGE2N2YiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImY5OTg5YmUwLTI5ZDctNDJhNy1hMDMwLTg3OWMxNGY4YTY3ZiJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""f9989be0-29d7-42a7-a030-879c14f8a67f"",""prPublicId"":""f9989be0-29d7-42a7-a030-879c14f8a67f"",""dependencies"":[{""name"":""cryptography"",""from"":""41.0.3"",""to"":""41.0.4""}],""packageManager"":""pip"",""projectPublicId"":""5ecb4152-94d0-44ff-86c6-21e542bb123d"",""projectUrl"":""https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-CRYPTOGRAPHY-5914629""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""pr-warning-shown"",""priorityScore""],""priorityScoreList"":[611],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Denial of Service (DoS)](https://learn.snyk.io/lesson/redos/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13700:3335,remediat,remediationStrategy,3335,https://hail.is,https://github.com/hail-is/hail/pull/13700,1,['remediat'],['remediationStrategy']
Safety,ct.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:280); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:214); 	at java.lang.Thread.run(Thread.java:748)java.lang.AssertionError: assertion failed; 	at scala.Predef$.assert(Predef.scala:156); 	at is.hail.annotations.Region.loadInt(Region.scala:36); 	at is.hail.expr.types.TBinary$.loadLength(TBinary.scala:62); 	at is.hail.annotations.UnsafeRow$.readBinary(UnsafeRow.scala:128); 	at is.hail.annotations.UnsafeRow$.readString(UnsafeRow.scala:139); 	at is.hail.annotations.UnsafeRow$.readAltAllele(UnsafeRow.scala:152); 	at is.hail.annotations.UnsafeRow$.readArrayAltAllele(UnsafeRow.scala:164); 	at is.hail.annotations.UnsafeRow$.read(UnsafeRow.scala:210); 	at is.hail.annotations.UnsafeRow.get(UnsafeRow.scala:257); 	at is.hail.expr.FilterVariants$$anonfun$10.apply(Relational.scala:503); 	at is.hail.expr.FilterVariants$$anonfun$10.apply(Relational.scala:500); 	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:463); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$9$$anon$5.hasNext(OrderedRVD.scala:658); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$9$$anon$5.hasNext(OrderedRVD.scala:658); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$9$$anon$5.hasNext(OrderedRVD.scala:658); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at is.hail.sparkextras.Or,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2743:8006,Unsafe,UnsafeRow,8006,https://hail.is,https://github.com/hail-is/hail/issues/2743,1,['Unsafe'],['UnsafeRow']
Safety,"ct.dependabot.com/kubernetes/kubernetes/pull/91637"">kubernetes/kubernetes#91637</a>, <a href=""https://github.com/robscott""><code>@​robscott</code></a>) [SIG API Machinery, Apps, Auth, Cloud Provider, Instrumentation, Network and Testing]</li>; <li>CustomResourceDefinitions added support for marking versions as deprecated by setting <code>spec.versions[*].deprecated</code> to <code>true</code>, and for optionally overriding the default deprecation warning with a <code>spec.versions[*].deprecationWarning</code> field. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/92329"">kubernetes/kubernetes#92329</a>, <a href=""https://github.com/liggitt""><code>@​liggitt</code></a>) [SIG API Machinery]</li>; <li>EnvVarSource api doc bug fixes (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/91194"">kubernetes/kubernetes#91194</a>, <a href=""https://github.com/wawa0210""><code>@​wawa0210</code></a>) [SIG Apps]</li>; <li>Fix bug in reflector that couldn't recover from &quot;Too large resource version&quot; errors (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/92537"">kubernetes/kubernetes#92537</a>, <a href=""https://github.com/wojtek-t""><code>@​wojtek-t</code></a>) [SIG API Machinery]</li>; <li>Fixed: log timestamps now include trailing zeros to maintain a fixed width (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/91207"">kubernetes/kubernetes#91207</a>, <a href=""https://github.com/iamchuckss""><code>@​iamchuckss</code></a>) [SIG Apps and Node]</li>; <li>Generic ephemeral volumes, a new alpha feature under the <code>GenericEphemeralVolume</code> feature gate, provide a more flexible alternative to <code>EmptyDir</code> volumes: as with <code>EmptyDir</code>, volumes are created and deleted for each pod automatically by Kubernetes. But because the normal provisioning process is used (<code>PersistentVolumeClaim</code>), storage can be provided by third-party storage vendors and al",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11462:6628,recover,recover,6628,https://hail.is,https://github.com/hail-is/hail/pull/11462,1,['recover'],['recover']
Safety,cution.datasources.DefaultWriterContainer$$anonfun$writeRows$1.apply(WriterContainer.scala:252); 	at org.apache.spark.sql.execution.datasources.DefaultWriterContainer$$anonfun$writeRows$1.apply(WriterContainer.scala:252); 	at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1348); 	at org.apache.spark.sql.execution.datasources.DefaultWriterContainer.writeRows(WriterContainer.scala:258); 	... 8 more. Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1873); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1886); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1822:6208,abort,abortStage,6208,https://hail.is,https://github.com/hail-is/hail/issues/1822,1,['abort'],['abortStage']
Safety,"d dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI2NWVkZTk2ZC0xYjZkLTQ1ZjktOTU3OC00NzdjMWNmNDhiZmQiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjY1ZWRlOTZkLTFiNmQtNDVmOS05NTc4LTQ3N2MxY2Y0OGJmZCJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""65ede96d-1b6d-45f9-9578-477c1cf48bfd"",""prPublicId"":""65ede96d-1b6d-45f9-9578-477c1cf48bfd"",""dependencies"":[{""name"":""msal"",""from"":""1.24.0"",""to"":""1.24.1""}],""packageManager"":""pip"",""projectPublicId"":""c1c98f6a-57c6-4ecc-a329-3b744cab74bd"",""projectUrl"":""https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-MSAL-5904284""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""pr-warning-shown"",""priorityScore""],""priorityScoreList"":[661],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Improper Neutralization of Special Elements in Data Query Logic](https://learn.snyk.io/lesson/nosql-injection-attack/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13754:3408,remediat,remediationStrategy,3408,https://hail.is,https://github.com/hail-is/hail/pull/13754,1,['remediat'],['remediationStrategy']
Safety,"d dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJhYjlhNGM2ZS0xOTg1LTRmYTctYjg0OC0zOTNmOWE3MGJkMWEiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImFiOWE0YzZlLTE5ODUtNGZhNy1iODQ4LTM5M2Y5YTcwYmQxYSJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""ab9a4c6e-1985-4fa7-b848-393f9a70bd1a"",""prPublicId"":""ab9a4c6e-1985-4fa7-b848-393f9a70bd1a"",""dependencies"":[{""name"":""msal"",""from"":""1.24.0"",""to"":""1.24.1""}],""packageManager"":""pip"",""projectPublicId"":""5ecb4152-94d0-44ff-86c6-21e542bb123d"",""projectUrl"":""https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-MSAL-5904284""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""pr-warning-shown"",""priorityScore""],""priorityScoreList"":[661],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Improper Neutralization of Special Elements in Data Query Logic](https://learn.snyk.io/lesson/nosql-injection-attack/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13753:3400,remediat,remediationStrategy,3400,https://hail.is,https://github.com/hail-is/hail/pull/13753,1,['remediat'],['remediationStrategy']
Safety,"d within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJlNTZiOGU3Ni1mMTk3LTQ0MmMtOGVlMC04MjFhMDk5YzM3YTAiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImU1NmI4ZTc2LWYxOTctNDQyYy04ZWUwLTgyMWEwOTljMzdhMCJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""e56b8e76-f197-442c-8ee0-821a099c37a0"",""prPublicId"":""e56b8e76-f197-442c-8ee0-821a099c37a0"",""dependencies"":[{""name"":""tornado"",""from"":""6.2"",""to"":""6.3.2""}],""packageManager"":""pip"",""projectPublicId"":""20159ae6-a5aa-42fa-845a-c89f5bcbf999"",""projectUrl"":""https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-TORNADO-5537286""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""priorityScore""],""priorityScoreList"":[556],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Open Redirect](https://learn.snyk.io/lessons/open-redirect/python/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13072:2993,remediat,remediationStrategy,2993,https://hail.is,https://github.com/hail-is/hail/pull/13072,1,['remediat'],['remediationStrategy']
Safety,"d"":""12972194-8c02-4a24-a046-2f21298b466a"",""dependencies"":[{""name"":""certifi"",""from"":""2021.10.8"",""to"":""2023.7.22""},{""name"":""cryptography"",""from"":""3.3.2"",""to"":""41.0.6""},{""name"":""pyjwt"",""from"":""1.7.1"",""to"":""2.4.0""},{""name"":""requests"",""from"":""2.27.1"",""to"":""2.31.0""},{""name"":""rsa"",""from"":""4.5"",""to"":""4.7""}],""packageManager"":""pip"",""projectPublicId"":""e7c92c7b-5282-49ea-940f-7a5797e2a45a"",""projectUrl"":""https://app.snyk.io/org/danking/project/e7c92c7b-5282-49ea-940f-7a5797e2a45a?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-CERTIFI-3164749"",""SNYK-PYTHON-CERTIFI-5805047"",""SNYK-PYTHON-CRYPTOGRAPHY-3172287"",""SNYK-PYTHON-CRYPTOGRAPHY-3314966"",""SNYK-PYTHON-CRYPTOGRAPHY-3315324"",""SNYK-PYTHON-CRYPTOGRAPHY-3315328"",""SNYK-PYTHON-CRYPTOGRAPHY-3315331"",""SNYK-PYTHON-CRYPTOGRAPHY-3315452"",""SNYK-PYTHON-CRYPTOGRAPHY-3315972"",""SNYK-PYTHON-CRYPTOGRAPHY-3315975"",""SNYK-PYTHON-CRYPTOGRAPHY-3316038"",""SNYK-PYTHON-CRYPTOGRAPHY-3316211"",""SNYK-PYTHON-CRYPTOGRAPHY-5663682"",""SNYK-PYTHON-CRYPTOGRAPHY-5777683"",""SNYK-PYTHON-CRYPTOGRAPHY-5813745"",""SNYK-PYTHON-CRYPTOGRAPHY-5813746"",""SNYK-PYTHON-CRYPTOGRAPHY-5813750"",""SNYK-PYTHON-CRYPTOGRAPHY-5914629"",""SNYK-PYTHON-CRYPTOGRAPHY-6036192"",""SNYK-PYTHON-CRYPTOGRAPHY-6092044"",""SNYK-PYTHON-PYJWT-2840625"",""SNYK-PYTHON-REQUESTS-5595532"",""SNYK-PYTHON-RSA-1038401""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[],""priorityScoreList"":[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Use After Free](https://learn.snyk.io/lesson/use-after-free/?loc&#x3D;fix-pr); 🦉 [Access of Resource Using Incompatible Type (&#x27;Type Confusion&#x27;)](https://learn.snyk.io/lesson/type-confusion/?loc&#x3D;fix-pr); 🦉 [Denial of Service (DoS)](https://learn.snyk.io/lesson/redos/?loc&#x3D;fix-pr); 🦉 [More lessons are available in S",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14134:10760,remediat,remediationStrategy,10760,https://hail.is,https://github.com/hail-is/hail/pull/14134,1,['remediat'],['remediationStrategy']
Safety,d.RDD.computeOrReadCheckpoint(RDD.scala:323); at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53); at org.apache.spark.scheduler.Task.run(Task.scala:108); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3413:4190,abort,abortStage,4190,https://hail.is,https://github.com/hail-is/hail/issues/3413,1,['abort'],['abortStage']
Safety,"d:; if handle._cancelled:; handle._scheduled = False; else:; new_scheduled.append(handle); ; heapq.heapify(new_scheduled); self._scheduled = new_scheduled; self._timer_cancelled_count = 0; else:; # Remove delayed calls that were cancelled from head of queue.; while self._scheduled and self._scheduled[0]._cancelled:; self._timer_cancelled_count -= 1; handle = heapq.heappop(self._scheduled); handle._scheduled = False; ; timeout = None; if self._ready or self._stopping:; timeout = 0; elif self._scheduled:; # Compute the desired timeout.; when = self._scheduled[0]._when; timeout = min(max(0, when - self.time()), MAXIMUM_SELECT_TIMEOUT); ; if self._debug and timeout != 0:; t0 = self.time(); event_list = self._selector.select(timeout); dt = self.time() - t0; if dt >= 1.0:; level = logging.INFO; else:; level = logging.DEBUG; nevent = len(event_list); if timeout is None:; logger.log(level, 'poll took %.3f ms: %s events',; dt * 1e3, nevent); elif nevent:; logger.log(level,; 'poll %.3f ms took %.3f ms: %s events',; timeout * 1e3, dt * 1e3, nevent); elif dt >= 1.0:; logger.log(level,; 'poll %.3f ms took %.3f ms: timeout',; timeout * 1e3, dt * 1e3); else:; event_list = self._selector.select(timeout); self._process_events(event_list); ; # Handle 'later' callbacks that are ready.; end_time = self.time() + self._clock_resolution; while self._scheduled:; handle = self._scheduled[0]; if handle._when >= end_time:; break; handle = heapq.heappop(self._scheduled); handle._scheduled = False; self._ready.append(handle); ; # This is the only place where callbacks are actually *called*.; # All other places just add them to ready.; # Note: We run all currently scheduled callbacks, but not any; # callbacks scheduled by callbacks run this time around --; # they will be run the next time (after another I/O poll).; # Use an idiom that is thread-safe without using locks.; ntodo = len(self._ready); for i in range(ntodo):; > handle = self._ready.popleft(); E IndexError: pop from an empty deque; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10705:3013,timeout,timeout,3013,https://hail.is,https://github.com/hail-is/hail/pull/10705,5,"['safe', 'timeout']","['safe', 'timeout']"
Safety,"d` an `OrderedRVD`, possibly with some non-empty key. This is consistent with the rule that the `rvd` must always have a stronger/longer key than the `TableType`.; * **small tweaks** - Now I start working through the `TableIR` nodes, rewriting them to remove explicit uses of `UnpartitionedRVD`. The general plan is to sandwich the rvd logic between `toOrderedRVD` and `toOldStyleRVD`. The first takes an `UnpartitionedRVD` to an `OrderedRVD` with empty key (and leaves `OrderedRVD`s alone), and the second takes an `OrderedRVD` to an `UnpartitionedRVD` if its key was empty, and leaves it alone otherwise. Once they're all rewritten this way, I redefine `toOldStyleRVD` to always return `OrderedRVD`, and `UnpartitionedRVD` is no longer used.; * **remove `TableUnkey`** - With `UnpartitionedRVD` going away, `TableUnkey` is no longer necessary, it's equivalent to keying by an empty key.; * **small tweaks** - these next two rewrite more `TableIR` nodes; * **Merge master** - the big one; * **tweak MatrixColsTable** - 1) Optimize `coerce` by checking if the requested key is empty, avoiding a scan in that case. 2) Optimize `sortedColsValue` by checking if the column key is empty, avoiding the sort in that case. 3) Simplify `colsRVD`, removing the case on the type of the `RVD`, just calling `coerce` and letting the previous optimizations avoid unnecessary work.; * **`distinctByKey` fix** - While looking over `TableIR` implementations, I noticed a bug in `distinctByKey`: you need to be sure no key is split across multiple partitions. To be sure the empty key edge case still works, I added a test to check that `strictify` on an empty-key partitioner will always collapse everything to one partition.; * **Flipped switch** - redifines `toOldStyleRVD` to just return the `OrderedRVD` unchanged, and asserts that `TableValue.rvd` is always an `OrderedRVD`.; * **rest of the `TableIR` tweaks** - added a factory method `OrderedRVD.unkeyed` to replace `UnpartitionedRVD.apply`.; * the rest are si",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4319:1894,avoid,avoiding,1894,https://hail.is,https://github.com/hail-is/hail/pull/4319,1,['avoid'],['avoiding']
Safety,dd.RDD.$anonfun$collect$2(RDD.scala:1021); 	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2276); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90); 	at org.apache.spark.scheduler.Task.run(Task.scala:136); 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548); 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551); 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128); 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628); 	at java.base/java.lang.Thread.run(Thread.java:829). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2673); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2609); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2608); 	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62); 	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2608); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1182); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1182); 	at scala.Option.foreach(Option.scala:407); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1182); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2861); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2803); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2792); 	at org.apache.spark.u,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12936:5253,abort,abortStage,5253,https://hail.is,https://github.com/hail-is/hail/issues/12936,1,['abort'],['abortStage']
Safety,"ded_gather`, allows it to be used recursively. In particular, suppose we had a semaphore of; 50. The outer `bounded_gather2` might need 20 slots to run its 20 paths in parallel. That leaves 30 slots of parallelism left over for its children. By passing the semaphore down, we let our children optimistically use some of that excess parallelism. 2. If we happen to have the `StatResult` for a particular object, we should never again look it up. In particular, getting the `StatResult` for every file in a directory can be done in O(1) requests. Getting the `StatResult` for each of those files individually (using their full paths) is necessarily O(N). If there was at least one glob and also there are no `suffix_components`, then we can use the `StatResult`s that we learned when checking the glog pattern. The latter point is perhaps a bit more clear with examples:. 1. `gs://foo/bar/baz`. Since there are no globs, we can make exactly one API request to list `gs://foo/bar/baz`. 2. `gs://foo/b*r/baz`. In this case, we must make one API request to list `gs://foo/`. This gives us a list of paths under that prefix. We check each path for conformance to the glob pattern `gs://foo/b*r`. For any path that matches, we must then list `<the matching path>/baz` which may itself be a directory containing files. Overall we make O(1) API requests to do the glob and then O(K) API requests to get the final `StatResult`s, where K is the number of paths matching the glob pattern. 3. `gs://foo/bar/b*z`. In this case, we must make one API request to list `gs://foo/bar/`. In `main`, we then throw away the `StatResult`s we got from that API request! Now we have to make O(K) requests to recover those `StatResult`s for all K paths that match the glob pattern. This PR just caches the `StatResult`s of the most recent globbing. If there is no suffix to later append, then we can just re-use the `StatResult`s we already have!. cc: @daniel-goldstein since you've reviewed this before. Might be of interest.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13253:1973,recover,recover,1973,https://hail.is,https://github.com/hail-is/hail/pull/13253,1,['recover'],['recover']
Safety,"def main(args):; hl.init(log='/variant_histograms.log'); data_type = 'genomes' if args.genomes else 'exomes'. metrics = ['FS', 'InbreedingCoeff', 'MQ', 'MQRankSum', 'QD', 'ReadPosRankSum', 'SOR', 'BaseQRankSum',; 'ClippingRankSum', 'DP', 'VQSLOD', 'rf_tp_probability', 'pab_max']. ht = hl.read_table(release_ht_path(data_type, nested=False)); # NOTE: histogram aggregations are done on the entire callset (not just PASS variants), on raw data. # Compute median and MAD on variant metrics; medmad_dict = {}; for metric in metrics:; medmad_dict[metric] = hl.struct(median=hl.median(hl.agg.collect(ht[metric])), mad=4*1.48268*hl.median(hl.abs(hl.agg.collect(ht[metric])-hl.median(hl.agg.collect(ht[metric]))))); medmad = ht.aggregate(hl.struct(**medmad_dict)); print(medmad); print(hl.eval_expr(hl.json(medmad))); ```. ### What went wrong (all error messages here, including the full java stack trace):; ```; [Stage 0:==================================================>(9853 + 93) / 10000]#; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x00007fbeaec3ca22, pid=6662, tid=0x00007fbe3dd81700; #; # JRE version: OpenJDK Runtime Environment (8.0_181-b13) (build 1.8.0_181-8u181-b13-1~deb9u1-b13); # Java VM: OpenJDK 64-Bit Server VM (25.181-b13 mixed mode linux-amd64 compressed oops); # Problematic frame:; # J 14270 C1 is.hail.annotations.Region.storeInt(JI)V (6 bytes) @ 0x00007fbeaec3ca22 [0x00007fbeaec3c980+0xa2]; #; # Failed to write core dump. Core dumps have been disabled. To enable core dumping, try ""ulimit -c unlimited"" before starting Java again; #; # An error report file with more information is saved as:; # /tmp/828e66d5a71741d7ab2c8d6580997da3/hs_err_pid6662.log; Compiled method (c1) 88328 14270 3 is.hail.annotations.Region::storeInt (6 bytes); total in heap [0x00007fbeaec3c810,0x00007fbeaec3cbc0] = 944; relocation [0x00007fbeaec3c938,0x00007fbeaec3c968] = 48; main code [0x00007fbeaec3c980,0x00007fbeaec3caa0] = 288; stub code [0x00007",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4418:1806,detect,detected,1806,https://hail.is,https://github.com/hail-is/hail/issues/4418,1,['detect'],['detected']
Safety,detect terminal dimensions for show like pandas does,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2847:0,detect,detect,0,https://hail.is,https://github.com/hail-is/hail/issues/2847,1,['detect'],['detect']
Safety,dex(RestRepository.java:168); 	at org.elasticsearch.spark.rdd.EsRDDWriter.write(EsRDDWriter.scala:67); 	at org.elasticsearch.spark.rdd.EsSpark$$anonfun$doSaveToEs$1.apply(EsSpark.scala:107); 	at org.elasticsearch.spark.rdd.EsSpark$$anonfun$doSaveToEs$1.apply(EsSpark.scala:107); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); 	at org.apache.spark.scheduler.Task.run(Task.scala:86); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.ap,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4250:5838,abort,abortStage,5838,https://hail.is,https://github.com/hail-is/hail/issues/4250,1,['abort'],['abortStage']
Safety,"dist-packages/hailtop/batch_client/client.py:84: in wait; return async_to_blocking(self._async_job.wait()); usr/local/lib/python3.9/dist-packages/hailtop/utils/utils.py:156: in async_to_blocking; return loop.run_until_complete(task); usr/lib/python3.9/asyncio/base_events.py:634: in run_until_complete; self.run_forever(); usr/lib/python3.9/asyncio/base_events.py:601: in run_forever; self._run_once(); usr/lib/python3.9/asyncio/base_events.py:1869: in _run_once; event_list = self._selector.select(timeout); _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . self = <selectors.EpollSelector object at 0x7fae890f2d30>; timeout = 15.402000000000001. def select(self, timeout=None):; if timeout is None:; timeout = -1; elif timeout <= 0:; timeout = 0; else:; # epoll_wait() has a resolution of 1 millisecond, round away; # from zero to wait *at least* timeout seconds.; timeout = math.ceil(timeout * 1e3) * 1e-3; ; # epoll_wait() expects `maxevents` to be greater than zero;; # we want to make sure that `select()` can be called when no; # FD is registered.; max_ev = max(len(self._fd_to_key), 1); ; ready = []; try:; > fd_event_list = self._selector.poll(timeout, max_ev); E Failed: Timeout >360.0s. usr/lib/python3.9/selectors.py:469: Failed; ------------------------------ Captured log setup ------------------------------; 2023-09-06T21:45:24 INFO test.conftest conftest.py:14:log_before_after starting test; 2023-09-06T21:45:24 INFO hailtop.aiocloud.aioazure.credentials credentials.py:99:default_credentials using credentials file /test-gsa-key/key.json; ------------------------------ Captured log call -------------------------------; 2023-09-06T21:45:25 INFO azure.identity.aio._internal.get_token_mixin get_token_mixin.py:93:get_token ClientSecretCredential.get_token succeeded; 2023-09-06T21:45:25 INFO batch_client.aioclient aioclient.py:809:_submit created batch 191; 2023-09-06T21:47:17 WARNING hailtop.utils utils.py:842:retry_transient_errors_with_debug_s",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13582:3313,timeout,timeout,3313,https://hail.is,https://github.com/hail-is/hail/issues/13582,1,['timeout'],['timeout']
Safety,"docker_prefix is not exactly the ""registry name"" in azure's definition, but it is `<registry_name>.azurecr.io` which `az acr login` accepts alternatively to just the registry name. Didn't seem worth adding a mostly redundant config field.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11301:215,redund,redundant,215,https://hail.is,https://github.com/hail-is/hail/pull/11301,1,['redund'],['redundant']
Safety,"duled 0 jobs for jpim job-private; INFO	2022-03-02 19:06:34,964	pool.py	create_instances:244	pool highcpu n_instances 0 {'pending': 0, 'active': 0, 'inactive': 0, 'deleted': 0} free_cores 0.0 live_free_cores 0.0 ready_cores 0.0; ERROR	2022-03-02 19:06:35,376	job.py	schedule_job:473	error while scheduling job (94, 2) on instance batch-worker-pr-11438-default-g6cibyji6520-standard-9xy2q	Traceback (most recent call last):\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 969, in _wrap_create_connection\n return await self._loop.create_connection(*args, **kwargs) # type: ignore # noqa\n File ""uvloop/loop.pyx"", line 1974, in create_connection\n File ""uvloop/loop.pyx"", line 1951, in uvloop.loop.Loop.create_connection\nConnectionRefusedError: [Errno 111] Connection refused\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n File ""/usr/local/lib/python3.7/dist-packages/batch/driver/job.py"", line 449, in schedule_job\n timeout=aiohttp.ClientTimeout(total=2),\n File ""/usr/local/lib/python3.7/dist-packages/hailtop/httpx.py"", line 113, in request_and_raise_for_status\n resp = await self.client_session._request(method, url, **kwargs)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/client.py"", line 521, in _request\n req, traces=traces, timeout=real_timeout\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 535, in connect\n proto = await self._create_connection(req, traces, timeout)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 892, in _create_connection\n _, proto = await self._create_direct_connection(req, traces, timeout)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 1051, in _create_direct_connection\n raise last_exc\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 1032, in _create_direct_connection\n client_error=client_error,\n File ""/usr/local/lib/python3.7/dist-packages/aioht",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11451:6130,timeout,timeout,6130,https://hail.is,https://github.com/hail-is/hail/pull/11451,1,['timeout'],['timeout']
Safety,"dump written. Default location: /home/BROAD.MIT.EDU/cvittal/src/hail/hail/core or core.23790 (max size 9223372036854775 kB). To ensure a full core dump, try ""ulimit -c unlimited"" before starting Java again; #; # An error report file with more information is saved as:; # /home/BROAD.MIT.EDU/cvittal/src/hail/hail/hs_err_pid23790.log; Compiled method (c1) 33969 8500 2 is.hail.annotations.UnsafeRow$::readLocus (78 bytes); total in heap [0x00007fe4a8b81810,0x00007fe4a8b83430] = 7200; relocation [0x00007fe4a8b81938,0x00007fe4a8b81a98] = 352; main code [0x00007fe4a8b81aa0,0x00007fe4a8b82100] = 1632; stub code [0x00007fe4a8b82100,0x00007fe4a8b822b8] = 440; oops [0x00007fe4a8b822b8,0x00007fe4a8b822c0] = 8; metadata [0x00007fe4a8b822c0,0x00007fe4a8b82338] = 120; scopes data [0x00007fe4a8b82338,0x00007fe4a8b82f30] = 3064; scopes pcs [0x00007fe4a8b82f30,0x00007fe4a8b83340] = 1040; dependencies [0x00007fe4a8b83340,0x00007fe4a8b83348] = 8; nul chk table [0x00007fe4a8b83348,0x00007fe4a8b83430] = 232; #; FATAL: caught signal 6 SIGABRT; # If you would like to submit a bug report, please visit:; # http://bugreport.sun.com/bugreport/; #; /tmp/libhail8122447512081932366.so(+0x18f5f)[0x7fe3a7bf0f5f]; /lib/x86_64-linux-gnu/libc.so.6(+0x3ef20)[0x7fe4be507f20]; /lib/x86_64-linux-gnu/libc.so.6(gsignal+0xc7)[0x7fe4be507e97]; /lib/x86_64-linux-gnu/libc.so.6(abort+0x141)[0x7fe4be509801]; /usr/lib/jvm/java-8-openjdk-amd64/jre/lib/amd64/server/libjvm.so(+0x8e80b9)[0x7fe4bd7f00b9]; /usr/lib/jvm/java-8-openjdk-amd64/jre/lib/amd64/server/libjvm.so(+0xaaed23)[0x7fe4bd9b6d23]; /usr/lib/jvm/java-8-openjdk-amd64/jre/lib/amd64/server/libjvm.so(JVM_handle_linux_signal+0x1b4)[0x7fe4bd7fa694]; /usr/lib/jvm/java-8-openjdk-amd64/jre/lib/amd64/server/libjvm.so(+0x8e5318)[0x7fe4bd7ed318]; /lib/x86_64-linux-gnu/libc.so.6(+0x3ef20)[0x7fe4be507f20]; [0x7fe4a85738ec]. 38 tests completed, 29 failed; :testCppCodegen FAILED; ```; [hs_err_pid23790.log](https://github.com/hail-is/hail/files/2540933/hs_err_pid23790.log)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4718:11518,abort,abort,11518,https://hail.is,https://github.com/hail-is/hail/issues/4718,1,['abort'],['abort']
Safety,"e (almost always either "" "" or """"), or, if that would cause the line to exceed `width`; * print `body` normally, as described in the previous paragraph, allowing nested `Group`s to print either flat or normally. This pretty-printer DSL has become fairly standard, with some common enhancements that I don't think we need. It was first described in [A prettier printer](https://homepages.inf.ed.ac.uk/wadler/papers/prettier/prettier.pdf) by Wadler (though my implementation is completely different). This achieves stack safety by `Concat` taking an `Iterable`, so each contained `Doc` can be produced on demand. `render` pulls from these iterators, keeping in memory only things that might print to the current line, but where the format hasn't been decided yet. As soon as the formatting of a group is decided, as much of its body as possible is written to the `java.io.Writer`. A very quick and dirty performance comparison had the new pretty printer about 20% slower. That's paying for both the stack safety and the added smarts. And I think there's still room for optimization if it becomes necessary. Here is a snippet of the IR generated by `test_ld_score_regression`, first on master, then this PR:; ```; (InsertFields; (SelectFields (SNP A1 A2 N Z); (Ref row)); None; (chi_squared; (Apply pow () Float64; (GetField Z; (Ref row)); (ApplyIR toFloat64 () Float64; (I32 2)))); (n; (GetField N; (Ref row))); (ld_score; (GetField L2; (GetField __uid_3; (Ref row)))); (locus; (Apply Locus () Locus(GRCh37); (GetField CHR; (GetField __uid_4; (Ref row))); (GetField BP; (GetField __uid_5; (Ref row))))); (alleles; (MakeArray Array[String]; (GetField A2; (Ref row)); (GetField A1; (Ref row)))); (phenotype; (Str ""50_irnt""))))); (InsertFields; (SelectFields (locus alleles chi_squared n ld_score phenotype); (SelectFields (SNP A1 A2 N Z chi_squared n ld_score locus alleles phenotype); (Ref row))); None)); ```; ```; (InsertFields; (SelectFields (SNP A1 A2 N Z) (Ref row)); None; (chi_squared; (Apply pow",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9652:3657,safe,safety,3657,https://hail.is,https://github.com/hail-is/hail/pull/9652,1,['safe'],['safety']
Safety,"e 2, in write; File ""/restricted/projectnb/genpro/github/hail/python/hail/typecheck/check.py"", line 481, in _typecheck; return __orig_func__(*args_, **kwargs_); File ""/restricted/projectnb/genpro/github/hail/python/hail/matrixtable.py"", line 1935, in write; self._jvds.write(output, overwrite, _codec_spec); File ""/share/pkg/spark/2.2.0/install/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py"", line 1133, in __call__; File ""/restricted/projectnb/genpro/github/hail/python/hail/utils/java.py"", line 196, in deco; 'Error summary: %s' % (deepest, full, hail.__version__, deepest)) from None; hail.utils.java.FatalError: HailException: gcad.sv.delly.5k.vcf.bgz:column 80816: invalid character '-' in integer literal; ... 2:0:0:0:6 ./.:0,0,0:0:LowQual:0:0:0:-1:0:0:0:0 ./.:0,0,0:0:LowQual:0:0:0 ...; ^; offending line: chr1 152267996 DEL00028254 AATATATATACTTTACGTAAAGT A . PASS ...; see the Hail log for the full offending line. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 20 in stage 2.0 failed 4 times, most recent failure: Lost task 20.3 in stage 2.0 (TID 485, scc-q08.scc.bu.edu, executor 2): is.hail.utils.HailException: gcad.sv.delly.5k.vcf.bgz:column 80816: invalid character '-' in integer literal; ... 2:0:0:0:6 ./.:0,0,0:0:LowQual:0:0:0:-1:0:0:0:0 ./.:0,0,0:0:LowQual:0:0:0 ...; ^; offending line: chr1 152267996 DEL00028254 AATATATATACTTTACGTAAAGT A . PASS ...; see the Hail log for the full offending line; at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:12); at is.hail.utils.package$.fatal(package.scala:26); at is.hail.io.vcf.LoadVCF$$anonfun$parseLines$1$$anon$1.hasNext(LoadVCF.scala:744); at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); at scala.collection.Iterator$$anon$1.hasNext(Iterator.scala:1004); at is.hail.rvd.OrderedRVD$$anon$2.hasNext(OrderedRVD.scala:413); at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); at is.hail.rvd.OrderedRVD$$anonfun$apply$10$$anon$3.hasNext(Order",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3379:2928,abort,aborted,2928,https://hail.is,https://github.com/hail-is/hail/issues/3379,1,['abort'],['aborted']
Safety,"e copy in Batch. After this goes in, these can mostly be developed in parallel. A few principles guided the implementation of copy: perform the minimal number of system calls or API requests per copy, and only do error checking when it doesn't involve additional FS operations. For example, it is too expensive to exhaustively check if we're creating a path that is a file and a directory in Google Storage. I considered doing additional and exhaustive checking for the actual copy arguments. For example, currently, `cp -T /path/to/file /path/to/dir` will not generate an error on Google Storage. In the end, I decided to go with the current behavior and I will add an option to do a postpass to check for file-and-dir paths. To achieve this, for each transfer, I simultaneously stat the destination (if needd) to determine if it is a file, directory or doesn't exist. For each source, I simultaneously try to copy it as a file and a directory. When copying each source, we don't need to know the type of the destination until after we've stat'ed the source, so stat'ing the sources and destinations are all overlapping. This avoids dependencies where I have to e.g. stat the input, decide what to do, and then perform a second action. I approached testing two ways: First, hand test common operations and errors (copy file, copy dir, overwrite, overwrite dir with file and vice versa, the various treat_dest_as settings, large files, detecting copy-and-files on input on Google Storage, etc.) Second, I enumerated essentially all single input transfers and recorded the results. These are then tested on every pair of file systems: file to file, file to gs, gs to file, etc. To make this run reasonably, I parallelize using xdist and the full tests (1364 tests) now take about 2 minutes. (If you restrict to the just the local filesystem, the tests just take a couple seconds.) The second test verifies that all cases run without unexpected errors, and that the behavior is file system independent.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9822:2072,avoid,avoids,2072,https://hail.is,https://github.com/hail-is/hail/pull/9822,2,"['avoid', 'detect']","['avoids', 'detecting']"
Safety,"e self._exception; /usr/local/lib/python3.9/dist-packages/hailtop/utils/utils.py:402: in run_and_cleanup; retval = await f(*args, **kwargs); /usr/local/lib/python3.9/dist-packages/hailtop/aiotools/local_fs.py:367: in rm_file; await self.remove(path); /usr/local/lib/python3.9/dist-packages/hailtop/aiotools/local_fs.py:348: in remove; return await blocking_to_async(self._thread_pool, os.remove, path); /usr/local/lib/python3.9/dist-packages/hailtop/utils/utils.py:162: in blocking_to_async; return await asyncio.get_event_loop().run_in_executor(; /usr/lib/python3.9/asyncio/base_events.py:819: in run_in_executor; executor.submit(func, *args), loop=self); _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . self = <concurrent.futures.thread.ThreadPoolExecutor object at 0x7f263d862100>; fn = <function blocking_to_async.<locals>.<lambda> at 0x7f263d781040>, args = (); kwargs = {}. def submit(self, fn, /, *args, **kwargs):; > with self._shutdown_lock, _global_shutdown_lock:; E Failed: Timeout >600.0s. /usr/lib/python3.9/concurrent/futures/thread.py:162: Failed; ---------------------------- Captured log teardown -----------------------------; INFO hailtop.utils:utils.py:450 discarding exception; Traceback (most recent call last):; File ""/usr/local/lib/python3.9/dist-packages/hailtop/aiotools/local_fs.py"", line 378, in rm_dir; await self.rmdir(path); File ""/usr/local/lib/python3.9/dist-packages/hailtop/aiotools/local_fs.py"", line 352, in rmdir; return await blocking_to_async(self._thread_pool, os.rmdir, path); File ""/usr/local/lib/python3.9/dist-packages/hailtop/utils/utils.py"", line 162, in blocking_to_async; return await asyncio.get_event_loop().run_in_executor(; File ""/usr/lib/python3.9/asyncio/futures.py"", line 284, in __await__; yield self # This tells Task to wait for completion.; File ""/usr/lib/python3.9/asyncio/tasks.py"", line 328, in __wakeup; future.result(); File ""/usr/lib/python3.9/asyncio/futures.py"", line 201, in result; raise self._exc",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13361:12063,Timeout,Timeout,12063,https://hail.is,https://github.com/hail-is/hail/issues/13361,1,['Timeout'],['Timeout']
Safety,"e"",""from"":""0.8.4"",""to"":""2.0.3""},{""name"":""nbconvert"",""from"":""5.6.1"",""to"":""6.3.0b0""},{""name"":""notebook"",""from"":""5.7.16"",""to"":""6.4.12""},{""name"":""pygments"",""from"":""2.5.2"",""to"":""2.15.0""},{""name"":""requests"",""from"":""2.27.1"",""to"":""2.31.0""},{""name"":""setuptools"",""from"":""39.0.1"",""to"":""65.5.1""},{""name"":""sphinx"",""from"":""1.8.6"",""to"":""3.3.0""},{""name"":""tornado"",""from"":""5.1.1"",""to"":""6.3.3""}],""packageManager"":""pip"",""projectPublicId"":""20159ae6-a5aa-42fa-845a-c89f5bcbf999"",""projectUrl"":""https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-CERTIFI-3164749"",""SNYK-PYTHON-CERTIFI-5805047"",""SNYK-PYTHON-IPYTHON-2348630"",""SNYK-PYTHON-IPYTHON-3318382"",""SNYK-PYTHON-JUPYTERCORE-3063766"",""SNYK-PYTHON-MISTUNE-2940625"",""SNYK-PYTHON-NBCONVERT-2979829"",""SNYK-PYTHON-NOTEBOOK-1041707"",""SNYK-PYTHON-NOTEBOOK-2441824"",""SNYK-PYTHON-NOTEBOOK-2928995"",""SNYK-PYTHON-PYGMENTS-1086606"",""SNYK-PYTHON-PYGMENTS-1088505"",""SNYK-PYTHON-PYGMENTS-5750273"",""SNYK-PYTHON-REQUESTS-5595532"",""SNYK-PYTHON-SETUPTOOLS-3180412"",""SNYK-PYTHON-SPHINX-570772"",""SNYK-PYTHON-SPHINX-570773"",""SNYK-PYTHON-SPHINX-5811865"",""SNYK-PYTHON-SPHINX-5812109"",""SNYK-PYTHON-TORNADO-5537286"",""SNYK-PYTHON-TORNADO-5840803""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""pr-warning-shown"",""priorityScore""],""priorityScoreList"":[554,704,624,531,604,589,726,434,589,449,696,589,479,519,509,711,701,586,586,384,494],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Remote Code Execution (RCE)](https://learn.snyk.io/lesson/improper-input-validation/?loc&#x3D;fix-pr); 🦉 [Improper Privilege Management](https://learn.snyk.io/lesson/insecure-design/?loc&#x3D;fix-pr); 🦉 [Regular Expression Denial of Service (ReDoS)](https://learn.snyk.io/lesson/redos/?loc&#x3D;fix-pr); 🦉 [More lessons are available in Snyk Learn](https://learn.snyk.io/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13717:11884,remediat,remediationStrategy,11884,https://hail.is,https://github.com/hail-is/hail/pull/13717,1,['remediat'],['remediationStrategy']
Safety,"e. File ~/.local/lib/python3.10/site-packages/hail/backend/py4j_backend.py:210, in Py4JBackend._rpc(self, action, payload); 208 path = action_routes[action]; 209 port = self._backend_server_port; --> 210 resp = self._requests_session.post(f'http://localhost:{port}{path}', data=data); 211 if resp.status_code >= 400:; 212 error_json = orjson.loads(resp.content). File /opt/conda/lib/python3.10/site-packages/requests/sessions.py:635, in Session.post(self, url, data, json, **kwargs); 624 def post(self, url, data=None, json=None, **kwargs):; 625 r""""""Sends a POST request. Returns :class:`Response` object.; 626 ; 627 :param url: URL for the new :class:`Request` object.; (...); 632 :rtype: requests.Response; 633 """"""; --> 635 return self.request(""POST"", url, data=data, json=json, **kwargs). File /opt/conda/lib/python3.10/site-packages/requests/sessions.py:587, in Session.request(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json); 582 send_kwargs = {; 583 ""timeout"": timeout,; 584 ""allow_redirects"": allow_redirects,; 585 }; 586 send_kwargs.update(settings); --> 587 resp = self.send(prep, **send_kwargs); 589 return resp. File /opt/conda/lib/python3.10/site-packages/requests/sessions.py:701, in Session.send(self, request, **kwargs); 698 start = preferred_clock(); 700 # Send the request; --> 701 r = adapter.send(request, **kwargs); 703 # Total elapsed time of the request (approximately); 704 elapsed = preferred_clock() - start. File /opt/conda/lib/python3.10/site-packages/requests/adapters.py:502, in HTTPAdapter.send(self, request, stream, timeout, verify, cert, proxies); 487 resp = conn.urlopen(; 488 method=request.method,; 489 url=url,; (...); 498 chunked=chunked,; 499 ); 501 except (ProtocolError, OSError) as err:; --> 502 raise ConnectionError(err, request=request); 504 except MaxRetryError as e:; 505 if isinstance(e.reason, ConnectTimeoutError):; 506 # TODO: Remove this in 3.0.0: see #2811. Conn",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13960:12331,timeout,timeout,12331,https://hail.is,https://github.com/hail-is/hail/issues/13960,3,['timeout'],['timeout']
Safety,"e2e3d2996 [query-service] switch to services team approved logging; - [ ] (@tpoterba) b18f86e647 [query-service] query workers need a hail context; - [ ] (@daniel-goldstein, @catoverdrive) 6d5d0b68af [query-service] use a UNIX Domain Socket for Py-Scala communication; - [ ] (@daniel-goldstein, @catoverdrive) 0d42df8b08 [query-service] run tests against query service; - [x] (@jigold) f9d361e686 [query-service] aiohttp.ClientSession must be created in async code; - [ ] (@cseed) c35f2e10e3 [query-service][hail][build.yaml] address miscellaneous comments from cotton; - [x] (@daniel-goldstein) 7f1b1363e9 [query-service] use two containers sharing an empty volume; - [x] (@daniel-goldstein) 2a8f23404a [query-service] in the service, log everything to stdout; - [x] (trivial) d8104a1dc4 [query-service] do not catch CancelledError; - [x] (trivial) efcb345185 [query-service] slightly more useful error message when socket dies; - [ ] (@tpoterba) f79c4023cf [shuffler] if we have an ExecuteContext, use it; - [x] (@daniel-goldstein,fyi: @tpoterba) 259f70dd25 [query-service] JSON Logging; - [ ] (@catoverdrive) f5c3ffcbd1 [query-service] pervasively retry all idempotent operations; - [ ] (@tpoterba) 507db4b468 [hail] fix using; - [x] (@jigold) c32a253bb9 [query] when testing, ensure our thread has an event loop; - [ ] (@tpoterba) 110469c2da [query][lir] avoid dumping massive classes onto stderr; - [ ] (@tpoterba) e4aa1c15fe [query] do not print misleading log in RegionPool.finalizer; - [x] (trivial) 33eab9a80e [query-service] better logging information; - [ ] (@catoverdrive) e358e8feeb [query-service] remove race conditions in user management; - [ ] (@tpoterba) b60cb2bae5 [lir] make LIR genName thread-safe; - [ ] (@catoverdrive) 2d82e5faf5 [query-service] send a token for job identifiability; - [x] (@daniel-goldstein) fd78caedcb [query-service] reduce image size by ~2GB; - [ ] (@catoverdrive) 00d1840421 [query-service] retry CLOSE, CLOSED (i.e. connection dropped); - [ ] (@catoverdri",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10100:2785,avoid,avoid,2785,https://hail.is,https://github.com/hail-is/hail/pull/10100,1,['avoid'],['avoid']
Safety,"e: 420; secretName: default-token-8h99c; status:; conditions:; - lastProbeTime: null; lastTransitionTime: ""2019-06-25T03:09:04Z""; status: ""True""; type: Initialized; - lastProbeTime: null; lastTransitionTime: ""2019-06-25T03:09:04Z""; message: 'containers with unready status: [main]'; reason: ContainersNotReady; status: ""False""; type: Ready; - lastProbeTime: null; lastTransitionTime: ""2019-06-25T03:09:04Z""; message: 'containers with unready status: [main]'; reason: ContainersNotReady; status: ""False""; type: ContainersReady; - lastProbeTime: null; lastTransitionTime: ""2019-06-25T03:09:04Z""; status: ""True""; type: PodScheduled; containerStatuses:; - image: konradjk/saige:0.35.8.2.2; imageID: """"; lastState: {}; name: main; ready: false; restartCount: 0; state:; waiting:; reason: ContainerCreating; hostIP: 10.128.0.8; phase: Pending; qosClass: Burstable; startTime: ""2019-06-25T03:09:04Z""; ```; PVC in question; ```; # k describe pvc batch-2554-job-4-8vvgl -n batch-pods; Name: batch-2554-job-4-8vvgl; Namespace: batch-pods; StorageClass: batch; Status: Bound; Volume: pvc-32804669-96f6-11e9-8aa3-42010a80015f; Labels: app=batch-job; hail.is/batch-instance=cd50b95a89914efb897965a5e982a29d; Annotations: pv.kubernetes.io/bind-completed: yes; pv.kubernetes.io/bound-by-controller: yes; volume.beta.kubernetes.io/storage-provisioner: kubernetes.io/gce-pd; Finalizers: [kubernetes.io/pvc-protection]; Capacity: 1Gi; Access Modes: RWO; VolumeMode: Filesystem; Events: <none>; Mounted By: batch-2554-job-4-main-cc8d4; ```; Events; ```; # k get events -n batch-pods --sort-by='.metadata.creationTimestamp' | grep 2554; 76s Warning FailedMount Pod Unable to mount volumes for pod ""batch-2554-job-4-main-cc8d4_batch-pods(968b4ba5-96f6-11e9-8aa3-42010a80015f)"": timeout expired waiting for volumes to attach or mount for pod ""batch-pods""/""batch-2554-job-4-main-cc8d4"". list of unmounted volumes=[batch-2554-job-4-8vvgl]. list of unattached volumes=[gsa-key batch-2554-job-4-8vvgl default-token-8h99c]; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6466:8593,timeout,timeout,8593,https://hail.is,https://github.com/hail-is/hail/issues/6466,1,['timeout'],['timeout']
Safety,"e</code> args to <code>namedtuple</code> (<a href=""https://github-redirect.dependabot.com/PyCQA/astroid/issues/1763"">#1763</a>)</li>; <li><a href=""https://github.com/PyCQA/astroid/commit/c313631bca83f7b6eb7dd8990aa702b85eb22d64""><code>c313631</code></a> Bump astroid to 2.12.5, update changelog</li>; <li><a href=""https://github.com/PyCQA/astroid/commit/8852ecda407598636fcd760877e5a093148e8e67""><code>8852ecd</code></a> Prevent first-party imports from being resolved to <code>site-packages</code> (<a href=""https://github-redirect.dependabot.com/PyCQA/astroid/issues/1756"">#1756</a>)</li>; <li><a href=""https://github.com/PyCQA/astroid/commit/92529b5eafc42e92b9dc18377532fda2d9cdfc49""><code>92529b5</code></a> Add a comment about missing <code>__spec__</code> on <code>PyPy</code> (<a href=""https://github-redirect.dependabot.com/PyCQA/astroid/issues/1758"">#1758</a>)</li>; <li><a href=""https://github.com/PyCQA/astroid/commit/ef55fd3cd477ebe3c693b4b9eb15f52b56449b55""><code>ef55fd3</code></a> Fix namespace package detection for frozen stdlib modules on PyPy (<a href=""https://github-redirect.dependabot.com/PyCQA/astroid/issues/1757"">#1757</a>)</li>; <li><a href=""https://github.com/PyCQA/astroid/commit/7fba17d69b033a5aace1d7b1aed7887a8ef2c4b4""><code>7fba17d</code></a> Bump astroid to 2.12.4, update changelog</li>; <li><a href=""https://github.com/PyCQA/astroid/commit/d463bd2de2c4565e7e630bc61aa4685acc1f5183""><code>d463bd2</code></a> Fix crash involving non-standard type comments (<a href=""https://github-redirect.dependabot.com/PyCQA/astroid/issues/1753"">#1753</a>)</li>; <li><a href=""https://github.com/PyCQA/astroid/commit/060cefa51884d176fdacf1b8ea18cee3ae0b0948""><code>060cefa</code></a> Bump astroid to 2.12.3, update changelog</li>; <li>Additional commits viewable in <a href=""https://github.com/PyCQA/astroid/compare/v2.11.5...v2.12.6"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_s",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12155:4004,detect,detection,4004,https://hail.is,https://github.com/hail-is/hail/pull/12155,1,['detect'],['detection']
Safety,"e==2.1.3|msal==1.25.0|msal-extensions==1.0.0|msrest==0.7.1|multidict==6.0.4|nest-asyncio==1.5.8|numpy==1.26.2|oauthlib==3.2.2|orjson==3.9.10|packaging==23.2|pandas==2.1.3|parsimonious==0.10.0|pillow==10.1.0|plotly==5.18.0|portalocker==2.8.2|protobuf==3.20.2|py4j==0.10.9.5|pyasn1==0.5.1|pyasn1-modules==0.3.0|pycares==4.4.0|pycparser==2.21|pygments==2.17.2|pyjwt[crypto]==2.8.0|python-dateutil==2.8.2|python-json-logger==2.0.7|pytz==2023.3.post1|pyyaml==6.0.1|regex==2023.10.3|requests==2.31.0|requests-oauthlib==1.3.1|rich==12.6.0|rsa==4.9|s3transfer==0.8.0|scipy==1.11.4|six==1.16.0|sortedcontainers==2.4.0|tabulate==0.9.0|tenacity==8.2.3|tornado==6.3.3|typer==0.9.0|typing-extensions==4.8.0|tzdata==2023.3|urllib3==1.26.18|uvloop==0.19.0;sys_platform!=""win32""|wrapt==1.16.0|xyzservices==2023.10.1|yarl==1.9.3 \; ---; > '--metadata=^|||^WHEEL=gs://hail-30-day/hailctl/dataproc/dking-dev/0.2.126-a51eabd65859/hail-0.2.126-py3-none-any.whl|||PKGS=aiodns==2.0.0|aiohttp==3.9.1|aiosignal==1.3.1|async-timeout==4.0.3|attrs==23.1.0|avro==1.11.3|azure-common==1.1.28|azure-core==1.29.5|azure-identity==1.15.0|azure-mgmt-core==1.4.0|azure-mgmt-storage==20.1.0|azure-storage-blob==12.19.0|bokeh==3.3.1|boto3==1.33.1|botocore==1.33.1|cachetools==5.3.2|certifi==2023.11.17|cffi==1.16.0|charset-normalizer==3.3.2|click==8.1.7|commonmark==0.9.1|contourpy==1.2.0|cryptography==41.0.7|decorator==4.4.2|deprecated==1.2.14|dill==0.3.7|frozenlist==1.4.0|google-auth==2.23.4|google-auth-oauthlib==0.8.0|humanize==1.1.0|idna==3.6|isodate==0.6.1|janus==1.0.0|jinja2==3.1.2|jmespath==1.0.1|jproperties==2.1.1|markupsafe==2.1.3|msal==1.25.0|msal-extensions==1.0.0|msrest==0.7.1|multidict==6.0.4|nest-asyncio==1.5.8|numpy==1.26.2|oauthlib==3.2.2|orjson==3.9.10|packaging==23.2|pandas==2.1.3|parsimonious==0.10.0|pillow==10.1.0|plotly==5.18.0|portalocker==2.8.2|protobuf==3.20.2|py4j==0.10.9.5|pyasn1==0.5.1|pyasn1-modules==0.3.0|pycares==4.4.0|pycparser==2.21|pygments==2.17.2|pyjwt[crypto]==2.8.0|python-dateutil==2.8.2|py",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14127:3466,timeout,timeout,3466,https://hail.is,https://github.com/hail-is/hail/pull/14127,1,['timeout'],['timeout']
Safety,"eContext.scala:18); at is.hail.backend.spark.SparkBackend.withExecuteContext(SparkBackend.scala:229); at is.hail.backend.spark.SparkBackend.execute(SparkBackend.scala:303); at is.hail.backend.spark.SparkBackend.executeJSON(SparkBackend.scala:323); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); at py4j.Gateway.invoke(Gateway.java:282); at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); at py4j.commands.CallCommand.execute(CallCommand.java:79); at py4j.GatewayConnection.run(GatewayConnection.java:238); at java.lang.Thread.run(Thread.java:745). org.apache.spark.SparkException: Job aborted due to stage failure: Task 9586 in stage 2.0 failed 4 times, most recent failure: Lost task 9586.3 in stage 2.0 (TID 40203, scc-q21.scc.bu.edu, executor 13): java.lang.IllegalArgumentException: Self-suppression not permitted; at java.lang.Throwable.addSuppressed(Throwable.java:1043); at java.io.FilterOutputStream.close(FilterOutputStream.java:159); at is.hail.utils.package$.using(package.scala:603); at is.hail.io.RichContextRDDRegionValue$.writeSplitRegion(RichContextRDDRegionValue.scala:99); at is.hail.rvd.RVD$$anonfun$25.apply(RVD.scala:939); at is.hail.rvd.RVD$$anonfun$25.apply(RVD.scala:937); at is.hail.sparkextras.ContextRDD$$anonfun$cmapPartitionsWithIndex$1$$anonfun$apply$18.apply(ContextRDD.scala:248); at is.hail.sparkextras.ContextRDD$$anonfun$cmapPartitionsWithIndex$1$$anonfun$apply$18.apply(ContextRDD.scala:248); at is.hail.utils.richUtils.RichContextRDD$$anonfun$cleanupRegions$1$$anonfun$1.apply(RichContextRDD.scala:22); at is.hail.utils.richUtils.RichContextRDD$$anonfun$cleanupReg",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/9293:5120,abort,aborted,5120,https://hail.is,https://github.com/hail-is/hail/issues/9293,1,['abort'],['aborted']
Safety,"eGlobal(is.hail.nativecode.NativeCodeSuite). Gradle suite > Gradle test > is.hail.nativecode.NativeCodeSuite.testNativeGlobal PASSED; Running test: Test method testNativePtr(is.hail.nativecode.NativeCodeSuite). Gradle suite > Gradle test > is.hail.nativecode.NativeCodeSuite.testNativePtr PASSED; Running test: Test method testNativeUpcall(is.hail.nativecode.NativeCodeSuite); DEBUG: Logging set_test_msg ... Gradle suite > Gradle test > is.hail.nativecode.NativeCodeSuite.testNativeUpcall PASSED; Running test: Test method testObjectArray(is.hail.nativecode.NativeCodeSuite). Gradle suite > Gradle test > is.hail.nativecode.NativeCodeSuite.testObjectArray PASSED; Running test: Test method testShuffleAndJoinDoesntMemoryLeak(is.hail.expr.ir.TableIRSuite). Gradle suite > Gradle test > is.hail.expr.ir.TableIRSuite.testShuffleAndJoinDoesntMemoryLeak PASSED; Running test: Test method testBufferWriteReadDoubles(is.hail.annotations.UnsafeSuite). Gradle suite > Gradle test > is.hail.annotations.UnsafeSuite.testBufferWriteReadDoubles PASSED; Running test: Test method testCodec(is.hail.annotations.UnsafeSuite); #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x00007fe4a85738ec, pid=23790, tid=0x00007fe48cdfa700; #; # JRE version: OpenJDK Runtime Environment (8.0_181-b13) (build 1.8.0_181-8u181-b13-0ubuntu0.18.04.1-b13); # Java VM: OpenJDK 64-Bit Server VM (25.181-b13 mixed mode linux-amd64 compressed oops); # Problematic frame:; # J 9008 C1 is.hail.annotations.UnsafeRow$.readBinary(Lis/hail/annotations/Region;J)[B (39 bytes) @ 0x00007fe4a85738ec [0x00007fe4a8573600+0x2ec]; #; # Core dump written. Default location: /home/BROAD.MIT.EDU/cvittal/src/hail/hail/core or core.23790 (max size 9223372036854775 kB). To ensure a full core dump, try ""ulimit -c unlimited"" before starting Java again; #; # An error report file with more information is saved as:; # /home/BROAD.MIT.EDU/cvittal/src/hail/hail/hs_err_pid23790.log; Compiled method (c1) 33969",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4718:9519,Unsafe,UnsafeSuite,9519,https://hail.is,https://github.com/hail-is/hail/issues/4718,1,['Unsafe'],['UnsafeSuite']
Safety,eMapTask.scala:96); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53); at org.apache.spark.scheduler.Task.run(Task.scala:108); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1658); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2022); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2119); at org.apache.spark.rdd.RDD$$anonfun$reduce$1.apply(RDD.scala:1026); at ,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3413:4529,abort,abortStage,4529,https://hail.is,https://github.com/hail-is/hail/issues/3413,1,['abort'],['abortStage']
Safety,ect$1$$anonfun$13.apply(RDD.scala:936); at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:936); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2062); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2062); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:108); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1658); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.s,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3379:8321,abort,abortStage,8321,https://hail.is,https://github.com/hail-is/hail/issues/3379,1,['abort'],['abortStage']
Safety,ect$1$$anonfun$13.apply(RDD.scala:936); at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:936); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:108); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); at java.lang.Thread.run(Thread.java:748); Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1517); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1505); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1504); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1504); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1732); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1687); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1676); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.s,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3507:5768,abort,abortStage,5768,https://hail.is,https://github.com/hail-is/hail/issues/3507,1,['abort'],['abortStage']
Safety,"ector Group and PSTN Audio Service APIs are now available in the Amazon Chime SDK Voice namespace. See <a href=""https://docs.aws.amazon.com/chime-sdk/latest/dg/sdk-available-regions.html"">https://docs.aws.amazon.com/chime-sdk/latest/dg/sdk-available-regions.html</a> for more details.</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/boto/boto3/commit/d872f34494e33473126a887499262c6d3139d0f3""><code>d872f34</code></a> Merge branch 'release-1.26.17'</li>; <li><a href=""https://github.com/boto/boto3/commit/c547ba545c4aeb40bc1848e50d9b89f54df8937c""><code>c547ba5</code></a> Bumping version to 1.26.17</li>; <li><a href=""https://github.com/boto/boto3/commit/083655fd0ece1370b4c5100fdb11f1cf11ac3f9a""><code>083655f</code></a> Add changelog entries from botocore</li>; <li><a href=""https://github.com/boto/boto3/commit/865ba3450a2408cf04413a2209e8fe4959f162e6""><code>865ba34</code></a> Avoid duplicate serialization in DynamoDB BatchWriter (<a href=""https://github-redirect.dependabot.com/boto/boto3/issues/3504"">#3504</a>)</li>; <li><a href=""https://github.com/boto/boto3/commit/f38ce50a317baf6715870b2706100d43b80b0c73""><code>f38ce50</code></a> Merge branch 'release-1.26.16'</li>; <li><a href=""https://github.com/boto/boto3/commit/47f348decf13d7cccba80c3c4fc592e127f5a1a9""><code>47f348d</code></a> Merge branch 'release-1.26.16' into develop</li>; <li><a href=""https://github.com/boto/boto3/commit/33d7d6f020510890b93edf49de3f81c0ba208cb3""><code>33d7d6f</code></a> Bumping version to 1.26.16</li>; <li><a href=""https://github.com/boto/boto3/commit/fb642196bd5dda0f48636e3eeae5f983835fcef5""><code>fb64219</code></a> Add changelog entries from botocore</li>; <li><a href=""https://github.com/boto/boto3/commit/cc2984fc4fe2a399404a81711eb9ece3fb8d6eb7""><code>cc2984f</code></a> Merge branch 'release-1.26.15'</li>; <li><a href=""https://github.com/boto/boto3/commit/9280e856b07feef67b8dc0",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12507:7274,Avoid,Avoid,7274,https://hail.is,https://github.com/hail-is/hail/pull/12507,1,['Avoid'],['Avoid']
Safety,"ecutor.Executor$TaskRunner.run(Executor.scala:414) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748). Spark Worker Logs (truncated to crash):. 2020-06-10 10:09:36 INFO ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 16 ms; 2020-06-10 10:09:36 INFO ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 17 ms; 2020-06-10 10:09:36 INFO ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 17 ms; 2020-06-10 10:09:36 INFO ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 17 ms; [thread 46926922934016 also had an error][thread 46922053207808 also had an error][thread 46926901880576 also had an error][thread 46926888195840 also had an error][thread 46926887143168 also had an error][thread 46924854015744 also had an error]; [thread 46924847699712 also had an error]. 	#. 	# A fatal error has been detected by the Java Runtime Environment:. 	[thread 46926905038592 also had an error]#; 	# ; 	[thread 46926895564544 also had an error][thread 46926900827904 also had an error]. 	SIGSEGV (0xb) at pc=0x00002aaab5115c88, pid=34051, tid=0x00002aae05d1a700; 	#; 	# JRE version: OpenJDK Runtime Environment (8.0_242-b08) (build 1.8.0_242-b08); 	# Java VM: OpenJDK 64-Bit Server VM (25.242-b08 mixed mode linux-amd64 compressed oops); 	# Problematic frame:; 	[thread 46926929250048 also had an error]# ; 	[thread 46926881888000 also had an error]; 	J 5583 C2 __C111CompiledWithAggs.__m131wrapped(Lis/hail/annotations/Region;J)V (280 bytes) @ 0x00002aaab5115c88 [0x00002aaab5115ae0+0x1a8]; 	#; 	# Failed to write core dump. Core dumps have been disabled. To enable core dumping, try ""ulimit -c unlimited"" before starting Java again; 	#; 	[thread 46924863489792 also had an error]; 	[thread 46924861384448 also had an error]; 	# An error report file with more information is saved as:; 	# /local/scratch/app-20200610",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8944:18784,detect,detected,18784,https://hail.is,https://github.com/hail-is/hail/issues/8944,1,['detect'],['detected']
Safety,ecutor.memoryOverhead=8755m|||spark:spark.memory.storageFraction=0.2|||spark:spark.executorEnv.HAIL_WORKER_OFF_HEAP_MEMORY_PER_CORE_MB=3648 \; ---; > '--properties=^|||^spark:spark.task.maxFailures=20|||spark:spark.driver.extraJavaOptions=-Xss4M|||spark:spark.executor.extraJavaOptions=-Xss4M|||spark:spark.speculation=true|||hdfs:dfs.replication=1|||dataproc:dataproc.logging.stackdriver.enable=false|||dataproc:dataproc.monitoring.stackdriver.enable=false|||spark:spark.driver.memory=36g|||yarn:yarn.nodemanager.resource.memory-mb=29184|||yarn:yarn.scheduler.maximum-allocation-mb=14592|||spark:spark.executor.cores=4|||spark:spark.executor.memory=5837m|||spark:spark.executor.memoryOverhead=8755m|||spark:spark.memory.storageFraction=0.2|||spark:spark.executorEnv.HAIL_WORKER_OFF_HEAP_MEMORY_PER_CORE_MB=3648' \; 9c9; < --metadata=^|||^WHEEL=gs://hail-30-day/hailctl/dataproc/dking-dev/0.2.126-a51eabd65859/hail-0.2.126-py3-none-any.whl|||PKGS=aiodns==2.0.0|aiohttp==3.9.1|aiosignal==1.3.1|async-timeout==4.0.3|attrs==23.1.0|avro==1.11.3|azure-common==1.1.28|azure-core==1.29.5|azure-identity==1.15.0|azure-mgmt-core==1.4.0|azure-mgmt-storage==20.1.0|azure-storage-blob==12.19.0|bokeh==3.3.1|boto3==1.33.1|botocore==1.33.1|cachetools==5.3.2|certifi==2023.11.17|cffi==1.16.0|charset-normalizer==3.3.2|click==8.1.7|commonmark==0.9.1|contourpy==1.2.0|cryptography==41.0.7|decorator==4.4.2|deprecated==1.2.14|dill==0.3.7|frozenlist==1.4.0|google-auth==2.23.4|google-auth-oauthlib==0.8.0|humanize==1.1.0|idna==3.6|isodate==0.6.1|janus==1.0.0|jinja2==3.1.2|jmespath==1.0.1|jproperties==2.1.1|markupsafe==2.1.3|msal==1.25.0|msal-extensions==1.0.0|msrest==0.7.1|multidict==6.0.4|nest-asyncio==1.5.8|numpy==1.26.2|oauthlib==3.2.2|orjson==3.9.10|packaging==23.2|pandas==2.1.3|parsimonious==0.10.0|pillow==10.1.0|plotly==5.18.0|portalocker==2.8.2|protobuf==3.20.2|py4j==0.10.9.5|pyasn1==0.5.1|pyasn1-modules==0.3.0|pycares==4.4.0|pycparser==2.21|pygments==2.17.2|pyjwt[crypto]==2.8.0|python-dateutil==2.8.2|py,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14127:1868,timeout,timeout,1868,https://hail.is,https://github.com/hail-is/hail/pull/14127,1,['timeout'],['timeout']
Safety,ed by one of the running tasks) Reason: Container from a bad node: container_e01_1690206305672_0001_01_000007 on host: all-of-us-1774-w-0.c.terra-vpc-sc-23dfb1a3.internal. Exit status: 137. Diagnostics: [2023-07-24 13:52:49.515]Container killed on request. Exit code is 137; [2023-07-24 13:52:49.517]Container exited with a non-zero exit code 137. ; [2023-07-24 13:52:49.518]Killed by external signal; .; Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2304); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2253); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2252); 	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62); 	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2252); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1124); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1124); 	at scala.Option.foreach(Option.scala:407); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1124); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2491); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2433); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2422); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:902); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2204); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2225); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:22,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13287:6939,abort,abortStage,6939,https://hail.is,https://github.com/hail-is/hail/issues/13287,1,['abort'],['abortStage']
Safety,"ed dataset; Traceback (most recent call last):; File ""/restricted/projectnb/genpro/github/hail/test.py"", line 3, in <module>; hl.import_vcf('/project/casa/vcf.5k/gatk.hc/adsp-5k.hg38.tileDB.recalibrate_SNP.chr22.biallelic.4795samples.g.vcf.bgz').write('/project/casa/vdf.5k/test. vdf'); File ""<decorator-gen-546>"", line 2, in write; File ""/restricted/projectnb/genpro/github/hail/build/distributions/hail-python.zip/hail/typecheck/check.py"", line 481, in _typecheck; File ""/restricted/projectnb/genpro/github/hail/build/distributions/hail-python.zip/hail/matrixtable.py"", line 1956, in write; File ""/share/pkg/spark/2.2.0/install/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py"", line 1133, in __call__; File ""/restricted/projectnb/genpro/github/hail/build/distributions/hail-python.zip/hail/utils/java.py"", line 196, in deco; hail.utils.java.FatalError: ClassNotFoundException: is.hail.utils.SerializableHadoopConfiguration. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 6 in stage 2.0 failed 4 times, most recent failure: Lost task 6.3 in stage 2.0 (TID 2 53, scc-q15.scc.bu.edu, executor 1): java.io.IOException: com.esotericsoftware.kryo.KryoException: Error during Java deserialization.; at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1310); at org.apache.spark.broadcast.TorrentBroadcast.readBroadcastBlock(TorrentBroadcast.scala:206); at org.apache.spark.broadcast.TorrentBroadcast._value$lzycompute(TorrentBroadcast.scala:66); at org.apache.spark.broadcast.TorrentBroadcast._value(TorrentBroadcast.scala:66); at org.apache.spark.broadcast.TorrentBroadcast.getValue(TorrentBroadcast.scala:96); at org.apache.spark.broadcast.Broadcast.value(Broadcast.scala:70); at is.hail.io.RichRDDRegionValue$$anonfun$5.apply(RowStore.scala:757); at is.hail.io.RichRDDRegionValue$$anonfun$5.apply(RowStore.scala:756); at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$26.apply(RDD.scala:844); at org.apache.spark.rdd.R",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3342:2317,abort,aborted,2317,https://hail.is,https://github.com/hail-is/hail/issues/3342,1,['abort'],['aborted']
Safety,"ed service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37833.; 17/01/17 09:24:46 INFO NettyBlockTransferService: Server created on 129.94.72.55:37833; 17/01/17 09:24:46 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 129.94.72.55, 37833); 17/01/17 09:24:46 INFO BlockManagerMasterEndpoint: Registering block manager 129.94.72.55:37833 with 15.8 GB RAM, BlockManagerId(driver, 129.94.72.55, 37833); 17/01/17 09:24:46 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 129.94.72.55, 37833); hail: info: running: read test.in.vds; SLF4J: Failed to load class ""org.slf4j.impl.StaticLoggerBinder"".; SLF4J: Defaulting to no-operation (NOP) logger implementation; SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.; hail: info: running: annotatevariants expr -c 'va = {}'; hail: info: running: write -o test.out.vds; [Stage 1:==> (1 + 24) / 25]hail: write: caught exception: org.apache.spark.SparkException: Job aborted.; at org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand$$anonfun$run$1.apply$mcV$sp(InsertIntoHadoopFsRelationCommand.scala:149); at org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand$$anonfun$run$1.apply(InsertIntoHadoopFsRelationCommand.scala:115); at org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand$$anonfun$run$1.apply(InsertIntoHadoopFsRelationCommand.scala:115); at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:57); at org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:115); at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:58); at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:56); at org.apache.spark.sql.execution.command.ExecutedCommandExec.doExecute(commands.scala:74); at org.apache.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1260:2983,abort,aborted,2983,https://hail.is,https://github.com/hail-is/hail/issues/1260,1,['abort'],['aborted']
Safety,"een a fluke. I see pretty consistent ~110MiB/s in the profiler's estimate of bandwidth to the FileOutputStream. When measured by `time python3 test.py` this script writes at ~93MiB/s. Ideally we would hit 250MiB/s (1/8th of an n1-standard-8's network bandwidth), but, considering that we have to split that bandwidth with reading in most cases, ~91 MiB/s ain't so bad. On main, this pipeline writes at 32 MiB/s. The wins in decreasing order of importance were:; 1. Use buffered I/O. All of our exporters should now use buffered I/O because I changed it in the EmitMethodBuilder. I didn't change it in HadoopFS because (a) Hail's native I/O has buffering and (b) buffering and position tracking requires work.; 2. Avoid String allocation, String to UTF8 conversion, and Array[Byte] allocation in VCF writing. In particular, for the most common types of Calls, I just return the UTF8 byte array in a switch statement.; 3. Use a fast path for diploid genotypes. In the worst case, we did 5 branches and now we do 2 which should be well predicted.; 4. Remove an allocation of a lambda in a hot method in Genotype.scala. Future Work:; 1. The randomness stuff still has a lot of low hanging fruit. NumPy can generate random numbers at bandwidths far above what we're managing here.; 2. For VCFs with more entry fields, we should not write ints and floats by generating strings and getting their UTF8 encoding; 3. Invert the writing control flow: serialization methods should take an OutputStream and write bytes directly into it. Contrast that with passing around arrays which are memcopied into a buffer. ---. Range table test:; ```; import hail as hl; hl.init(master='local[1]'); hl._set_flags(write_ir_files='1'); mt = hl.utils.range_matrix_table(n_rows=1000_000, n_cols=4_000); mt = mt.key_cols_by(s = hl.str(mt.col_idx)); mt = mt.key_rows_by(locus = hl.locus(""1"", mt.row_idx + 1), alleles = ['G', 'T']); mt = mt.annotate_entries(GT = hl.call(mt.row_idx % 2, mt.col_idx % 2)); hl.export_vcf(mt, '/tmp/fo",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12733:2111,predict,predicted,2111,https://hail.is,https://github.com/hail-is/hail/pull/12733,1,['predict'],['predicted']
Safety,"efines this API on the Scala-side. After writing to cloud storage, the ServiceBackend submits the one-job driver batch to Hail; Batch. It then waits for the driver job to complete. When the driver job is finished, it reads the; outputs from google cloud storage and returns the results to the user. All the meaningful changes to batch are in the worker. The worker starts one jvm per core on; startup. The mainclass is a new class called `JVMEntryway`. This entryway starts a UNIX socket and; speaks a very simple binary protocol. It accepts only one type of message:. ```; int32 the number of strings to expect; (; int32 the number of bytes in the next string; byte* UTF-8 string; )*; ```. The array of strings is interpreted as:. ```; comma-spearated-classpath; main-class-name; arg0; arg1; ...; ```. The entryway constructs a URLClassLoader with the given classpath, reflectively allocates an; instance of the mainclass and invokes the `main` method with the remaining arguments. This is; obviously a security risk. The system bans JARs from locations not controlled (and locked down) by; Hail Team. You should require me to hardcode the mainclass as; `is.hail.backend.service.ServiceBackendSocketAPI2` before we merge; however, this flexibility was; useful during development. The JVMEntryway will eventually be useful because we will keep a ClassLoader full of a bunch of; JIT-optimized Hail classes. I did not include that in this PR because we need to finish eliminating; global state used by Hail. Currently, two executions would try to re-use compiled class names for; different code, leading to very weird errors. # Changes to File Systems. Hail has three four file system interfaces:. | File System Interface | Public | Language | Async |; | ----------------------- | ------ | -------- | ----- |; | hail.utils.hadoop_utils | Yes | Python | no |; | hail.fs | Yes | Python | no |; | hailtop.aiotools.fs | No | Python | yes |; | is.hail.io.fs | No | Scala | no |. `hail.fs` is technically in ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11194:3632,risk,risk,3632,https://hail.is,https://github.com/hail-is/hail/pull/11194,1,['risk'],['risk']
Safety,either a filtermulti or unsafe mode for analyses that require splitmulti,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/769:24,unsafe,unsafe,24,https://hail.is,https://github.com/hail-is/hail/issues/769,1,['unsafe'],['unsafe']
Safety,"elasticsearch; disable_index_for_fields=(""sortedTranscriptConsequences"", ),; File ""/tmp/ffc9fb0b99f64080b674ab7a07962df9/load_dataset_to_es.py"", line 358, in export_to_elasticsearch; verbose=True,; File ""/tmp/ffc9fb0b99f64080b674ab7a07962df9/hail_scripts.zip/hail_scripts/v01/utils/elasticsearch_client.py"", line 140, in export_vds_to_elasticsearch; File ""/tmp/ffc9fb0b99f64080b674ab7a07962df9/hail_scripts.zip/hail_scripts/v01/utils/elasticsearch_client.py"", line 287, in export_kt_to_elasticsearch; File ""<decorator-gen-143>"", line 2, in export_elasticsearch; File ""/tmp/ffc9fb0b99f64080b674ab7a07962df9/hail-0.1-es-6.2.4-with-strip-chr-prefix.zip/hail/java.py"", line 121, in handle_py4j; hail.java.FatalError: EsHadoopIllegalArgumentException: Spark SQL types are not handled through basic RDD saveToEs() calls; typically this is a mistake(as the SQL schema will be ignored). Use 'org.elasticsearch.spark.sql' package instead. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 68 in stage 3.0 failed 20 times, most recent failure: Lost task 68.19 in stage 3.0 (TID 3771, vep-grch37-sw-9767.c.seqr-project.internal): org.elasticsearch.hadoop.EsHadoopIllegalArgumentException: Spark SQL types are not handled through basic RDD saveToEs() calls; typically this is a mistake(as the SQL schema will be ignored). Use 'org.elasticsearch.spark.sql' package instead; 	at org.elasticsearch.spark.serialization.ScalaValueWriter.doWriteScala(ScalaValueWriter.scala:124); 	at org.elasticsearch.spark.serialization.ScalaValueWriter.doWrite(ScalaValueWriter.scala:50); 	at org.elasticsearch.spark.serialization.ScalaValueWriter$$anonfun$doWriteScala$3.apply(ScalaValueWriter.scala:78); 	at org.elasticsearch.spark.serialization.ScalaValueWriter$$anonfun$doWriteScala$3.apply(ScalaValueWriter.scala:77); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.elast",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4250:2443,abort,aborted,2443,https://hail.is,https://github.com/hail-is/hail/issues/4250,1,['abort'],['aborted']
Safety,eldSerializer.write(FieldSerializer.java:518); 	at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:628); 	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.write(DefaultArraySerializers.java:366); 	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.write(DefaultArraySerializers.java:307); 	at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:628); 	at org.apache.spark.serializer.KryoSerializerInstance.serialize(KryoSerializer.scala:315); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:386); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748)sun.reflect.generics.reflectiveObjects.NotImplementedException: null; 	at is.hail.annotations.UnKryoSerializable$class.write(UnsafeRow.scala:15); 	at is.hail.annotations.UnsafeRow.write(UnsafeRow.scala:141); 	at com.esotericsoftware.kryo.serializers.DefaultSerializers$KryoSerializableSerializer.write(DefaultSerializers.java:505); 	at com.esotericsoftware.kryo.serializers.DefaultSerializers$KryoSerializableSerializer.write(DefaultSerializers.java:503); 	at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:628); 	at com.esotericsoftware.kryo.serializers.MapSerializer.write(MapSerializer.java:106); 	at com.esotericsoftware.kryo.serializers.MapSerializer.write(MapSerializer.java:39); 	at com.esotericsoftware.kryo.Kryo.writeObject(Kryo.java:552); 	at com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectField.java:80); 	at com.esotericsoftware.kryo.serializers.FieldSerializer.write(FieldSerializer.java:518); 	at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:628); 	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.write(DefaultArraySerializers.java:366); 	at com.esotericsoftware.kryo.serialize,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4215:6599,Unsafe,UnsafeRow,6599,https://hail.is,https://github.com/hail-is/hail/issues/4215,1,['Unsafe'],['UnsafeRow']
Safety,"elect_rows(self, caller, key_struct, value_struct, pk_size); 2814; 2815 return cleanup(MatrixTable(base._jvds.selectRows(row._ast.to_hql(),; -> 2816 new_key))); 2817; 2818 @typecheck_method(caller=str,. /usr/lib/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py in __call__(self, *args); 1131 answer = self.gateway_client.send_command(command); 1132 return_value = get_return_value(; -> 1133 answer, self.gateway_client, self.target_id, self.name); 1134; 1135 for temp_arg in temp_args:. /hadoop_gcs_connector_metadata_cache/hail/hail-devel-c8ca698c6ed5.zip/hail/utils/java.py in deco(*args, **kwargs); 194 raise FatalError('%s\n\nJava stack trace:\n%s\n'; 195 'Hail version: %s\n'; --> 196 'Error summary: %s' % (deepest, full, hail.__version__, deepest)) from None; 197 except pyspark.sql.utils.CapturedException as e:; 198 raise FatalError('%s\n\nJava stack trace:\n%s\n'. FatalError: NegativeArraySizeException: null. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 24 in stage 9.0 failed 20 times, most recent failure: Lost task 24.19 in stage 9.0 (TID 2874, berylc-sw-68wx.c.broad-mpg-gnomad.internal, executor 39): java.lang.NegativeArraySizeException; 	at java.util.Arrays.copyOf(Arrays.java:3236); 	at is.hail.annotations.Region.ensure(Region.scala:140); 	at is.hail.annotations.Region.allocate(Region.scala:153); 	at is.hail.annotations.Region.allocate(Region.scala:160); 	at is.hail.codegen.generated.C11.apply(Unknown Source); 	at is.hail.codegen.generated.C11.apply(Unknown Source); 	at is.hail.io.CompiledPackDecoder.readRegionValue(RowStore.scala:650); 	at is.hail.HailContext$$anon$2.next(HailContext.scala:245); 	at is.hail.HailContext$$anon$2.next(HailContext.scala:218); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at is.hail.sparkextras.ContextRDD$$anonfun$czip$1$$anon$1.next(ContextRDD.scala:333); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$1",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3583:3626,abort,aborted,3626,https://hail.is,https://github.com/hail-is/hail/issues/3583,1,['abort'],['aborted']
Safety,"emory parameters, but once we have some user feedback I'd like to consider re-implementing computeGramianLargeN to use BLAS3 outer product on blocks of (fewer than m) rows of the n x m matrix rather than inner product on all pairs of columns, which I think will boost speed and make it reasonable to kill the smallN routine entirely (the current largeN case benefits from dot product of sparse vectors when using hard calls, but that also goes away when we move to generic 0.2 and rip out the hardcall/dosage complexity). Then it will be natural for maxSize to control the number of rows in a block. - Added accuracy and iterations parameters to allow users to tune Davies, with R settings for Davies (1e-6, 10k) as default. This allows users to re-run groups with tiny p-values if desired to obtain greater accuracy. The R package runs additional p-value routines that may be faster when the p-value is very small, will keep in mind should this become an issue. - In remark above the Skat class, I've added an overview of how math in paper corresponds to implementation. - Simplified and re-organized the Skat class to cut down on the number and complexity of passed parameters and make the meaning of the code more transparent with respect to the overview. Killed the SkatModel class. - Fixed an oversight whereby the largeN route was never called by logistic. - Fixed a bug whereby a weight of null was passed to DoubleNumericConversion.to and then Option rather than the other way around to prevent null match exception. - Modified R test code to use Adjustment=False to avoid the small-sample adjustment made in the logistic case when running using than 2000 samples. I could then reduce the Balding-Nichols example from 2001 and 500 samples and run logistic on the smaller test set as well. - Further cleaned up the tests, and added a test of the size column and maxSize parameter. - More descriptive error message should Cholesky or inversion fail in logistic case. - Updated docs accordingly.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2248:2170,avoid,avoid,2170,https://hail.is,https://github.com/hail-is/hail/pull/2248,1,['avoid'],['avoid']
Safety,en.generated.C1.apply(Unknown Source); 	at is.hail.codegen.generated.C1.apply(Unknown Source); 	at is.hail.expr.CM$$anonfun$runWithDelayedValues$1.apply(CM.scala:84); 	at is.hail.expr.CM$$anonfun$runWithDelayedValues$1.apply(CM.scala:82); 	at is.hail.expr.AST$$anonfun$runAggregator$1.apply(AST.scala:270); 	at is.hail.expr.AST$$anonfun$runAggregator$1.apply(AST.scala:268); 	at is.hail.methods.Aggregators$$anonfun$11.apply(Aggregators.scala:304); 	at is.hail.methods.Aggregators$$anonfun$11.apply(Aggregators.scala:300); 	at is.hail.variant.MatrixTable$$anonfun$82$$anonfun$apply$64$$anonfun$apply$65.apply(MatrixTable.scala:1743); 	at is.hail.variant.MatrixTable$$anonfun$82$$anonfun$apply$64$$anonfun$apply$65.apply(MatrixTable.scala:1741); 	at scala.collection.Iterator$class.foreach(Iterator.scala:893); 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); 	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72); 	at is.hail.annotations.UnsafeIndexedSeq.foreach(UnsafeRow.scala:51); 	at is.hail.variant.MatrixTable$$anonfun$82$$anonfun$apply$64.apply(MatrixTable.scala:1741); 	at is.hail.variant.MatrixTable$$anonfun$82$$anonfun$apply$64.apply(MatrixTable.scala:1734); 	at scala.collection.Iterator$class.foreach(Iterator.scala:893); 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); 	at is.hail.variant.MatrixTable$$anonfun$82.apply(MatrixTable.scala:1734); 	at is.hail.variant.MatrixTable$$anonfun$82.apply(MatrixTable.scala:1728); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:797); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:797); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3276:1421,Unsafe,UnsafeRow,1421,https://hail.is,https://github.com/hail-is/hail/issues/3276,1,['Unsafe'],['UnsafeRow']
Safety,"endabot.com/aio-libs/async-timeout/issues/259"">#259</a>, <a href=""https://github-redirect.dependabot.com/aio-libs/async-timeout/issues/274"">#274</a></li>; </ul>; <h2>v4.0.1</h2>; <ul>; <li>; <p>Fix regression:</p>; <ol>; <li>; <p>Don't raise TimeoutError from timeout object that doesn't enter into async context; manager</p>; </li>; <li>; <p>Use call_soon() for raising TimeoutError if deadline is reached on entering into; async context manager</p>; </li>; </ol>; <p>(<a href=""https://github-redirect.dependabot.com/aio-libs/async-timeout/issues/258"">#258</a>)</p>; </li>; <li>; <p>Make <code>Timeout</code> class available in <code>__all__</code>.</p>; </li>; </ul>; <h2>async-timeout 4.0.0</h2>; <h1>Changes</h1>; <ul>; <li>; <p>Implemented <code>timeout_at(deadline)</code> (<a href=""https://github-redirect.dependabot.com/aio-libs/async-timeout/issues/117"">#117</a>)</p>; </li>; <li>; <p>Supported <code>timeout.deadline</code> and <code>timeout.expired</code> properties.</p>; </li>; <li>; <p>Drooped <code>timeout.remaining</code> property: it can be calculated as; <code>timeout.deadline - loop.time()</code></p>; </li>; <li>; <p>Dropped <code>timeout.timeout</code> property that returns a relative timeout based on the; timeout object creation time; the absolute <code>timeout.deadline</code> should be used; instead.</p>; </li>; <li>; <p>Added the deadline modification methods: <code>timeout.reject()</code>,; <code>timeout.shift(delay)</code>, <code>timeout.update(deadline)</code>.</p>; </li>; <li>; <p>Deprecated synchronous context manager usage</p>; </li>; </ul>; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/aio-libs/async-timeout/blob/master/CHANGES.rst"">async-timeout's changelog</a>.</em></p>; <blockquote>; <h1>4.0.2 (2021-12-20)</h1>; <h2>Misc</h2>; <ul>; <li><code>[#259](https://github.com/aio-libs/async-timeout/issues/259) &lt;https://github.com/aio-libs/async-timeout/issues/259&gt;</code><em>, <code",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11465:1359,timeout,timeout,1359,https://hail.is,https://github.com/hail-is/hail/pull/11465,1,['timeout'],['timeout']
Safety,"ent level of indentation (`ifFlat` is explained when we discuss `Group`); `Indent` increases the indentation of all `Line`s contained in `body` by `i`; and `Concat` simply prints all documents in `it` sequentially. `Group` is the sole source of alternatives which `render` must choose between. `Group(body)` can be rendered in one of two ways:; * replace all `Line`s contained in `body` (including in nested `Group`s) by their `ifFlat` alternative (almost always either "" "" or """"), or, if that would cause the line to exceed `width`; * print `body` normally, as described in the previous paragraph, allowing nested `Group`s to print either flat or normally. This pretty-printer DSL has become fairly standard, with some common enhancements that I don't think we need. It was first described in [A prettier printer](https://homepages.inf.ed.ac.uk/wadler/papers/prettier/prettier.pdf) by Wadler (though my implementation is completely different). This achieves stack safety by `Concat` taking an `Iterable`, so each contained `Doc` can be produced on demand. `render` pulls from these iterators, keeping in memory only things that might print to the current line, but where the format hasn't been decided yet. As soon as the formatting of a group is decided, as much of its body as possible is written to the `java.io.Writer`. A very quick and dirty performance comparison had the new pretty printer about 20% slower. That's paying for both the stack safety and the added smarts. And I think there's still room for optimization if it becomes necessary. Here is a snippet of the IR generated by `test_ld_score_regression`, first on master, then this PR:; ```; (InsertFields; (SelectFields (SNP A1 A2 N Z); (Ref row)); None; (chi_squared; (Apply pow () Float64; (GetField Z; (Ref row)); (ApplyIR toFloat64 () Float64; (I32 2)))); (n; (GetField N; (Ref row))); (ld_score; (GetField L2; (GetField __uid_3; (Ref row)))); (locus; (Apply Locus () Locus(GRCh37); (GetField CHR; (GetField __uid_4; (Ref row))); ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9652:3173,safe,safety,3173,https://hail.is,https://github.com/hail-is/hail/pull/9652,1,['safe'],['safety']
Safety,"ent.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJhZGQ5ZWQxOC00MjJhLTRkZWUtYWI4Yy01MTkyYmQ4ZmYxMzIiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImFkZDllZDE4LTQyMmEtNGRlZS1hYjhjLTUxOTJiZDhmZjEzMiJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/b72ce54d-5de3-48e5-a1d4-6f8967681a12?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/b72ce54d-5de3-48e5-a1d4-6f8967681a12?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""add9ed18-422a-4dee-ab8c-5192bd8ff132"",""prPublicId"":""add9ed18-422a-4dee-ab8c-5192bd8ff132"",""dependencies"":[{""name"":""certifi"",""from"":""2021.10.8"",""to"":""2023.7.22""},{""name"":""protobuf"",""from"":""3.17.3"",""to"":""3.18.3""},{""name"":""requests"",""from"":""2.27.1"",""to"":""2.31.0""},{""name"":""rsa"",""from"":""4.5"",""to"":""4.7""},{""name"":""setuptools"",""from"":""39.0.1"",""to"":""65.5.1""}],""packageManager"":""pip"",""projectPublicId"":""b72ce54d-5de3-48e5-a1d4-6f8967681a12"",""projectUrl"":""https://app.snyk.io/org/danking/project/b72ce54d-5de3-48e5-a1d4-6f8967681a12?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-CERTIFI-3164749"",""SNYK-PYTHON-CERTIFI-5805047"",""SNYK-PYTHON-PROTOBUF-3031740"",""SNYK-PYTHON-REQUESTS-5595532"",""SNYK-PYTHON-RSA-1038401"",""SNYK-PYTHON-SETUPTOOLS-3180412""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""pr-warning-shown""],""priorityScoreList"":[null,null,null,null,null,509],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Regular Expression Denial of Service (ReDoS)](https://learn.snyk.io/lesson/redos/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13975:4995,remediat,remediationStrategy,4995,https://hail.is,https://github.com/hail-is/hail/pull/13975,1,['remediat'],['remediationStrategy']
Safety,"ependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI1M2U3Mjk0MS01YmVjLTQ2MjYtYTY2Ny0wNzIxYjUwNjZlZjYiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjUzZTcyOTQxLTViZWMtNDYyNi1hNjY3LTA3MjFiNTA2NmVmNiJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/fa47fca0-549b-41a3-8bf7-bcda4ca9a617?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/fa47fca0-549b-41a3-8bf7-bcda4ca9a617?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""53e72941-5bec-4626-a667-0721b5066ef6"",""prPublicId"":""53e72941-5bec-4626-a667-0721b5066ef6"",""dependencies"":[{""name"":""aiohttp"",""from"":""3.8.6"",""to"":""3.9.0""}],""packageManager"":""pip"",""projectPublicId"":""fa47fca0-549b-41a3-8bf7-bcda4ca9a617"",""projectUrl"":""https://app.snyk.io/org/danking/project/fa47fca0-549b-41a3-8bf7-bcda4ca9a617?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-AIOHTTP-6091621"",""SNYK-PYTHON-AIOHTTP-6091622""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""pr-warning-shown"",""priorityScore""],""priorityScoreList"":[663,663],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Improper Input Validation](https://learn.snyk.io/lesson/improper-input-validation/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14043:3949,remediat,remediationStrategy,3949,https://hail.is,https://github.com/hail-is/hail/pull/14043,1,['remediat'],['remediationStrategy']
Safety,"ependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI3M2M5M2ZlNi0yOWM3LTQ4MWMtYTBiYy1lMzFkYzc3N2QyODEiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjczYzkzZmU2LTI5YzctNDgxYy1hMGJjLWUzMWRjNzc3ZDI4MSJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""73c93fe6-29c7-481c-a0bc-e31dc777d281"",""prPublicId"":""73c93fe6-29c7-481c-a0bc-e31dc777d281"",""dependencies"":[{""name"":""aiohttp"",""from"":""3.8.6"",""to"":""3.9.0""}],""packageManager"":""pip"",""projectPublicId"":""5ecb4152-94d0-44ff-86c6-21e542bb123d"",""projectUrl"":""https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-AIOHTTP-6091621"",""SNYK-PYTHON-AIOHTTP-6091622""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""pr-warning-shown"",""priorityScore""],""priorityScoreList"":[663,663],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Improper Input Validation](https://learn.snyk.io/lesson/improper-input-validation/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14041:3834,remediat,remediationStrategy,3834,https://hail.is,https://github.com/hail-is/hail/pull/14041,1,['remediat'],['remediationStrategy']
Safety,"ependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI4ZmFmZmYwNi1jOTI2LTQ5NjEtOTI4MC1iNGI0OTczNTg2MWMiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjhmYWZmZjA2LWM5MjYtNDk2MS05MjgwLWI0YjQ5NzM1ODYxYyJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""8fafff06-c926-4961-9280-b4b49735861c"",""prPublicId"":""8fafff06-c926-4961-9280-b4b49735861c"",""dependencies"":[{""name"":""aiohttp"",""from"":""3.8.6"",""to"":""3.9.0""}],""packageManager"":""pip"",""projectPublicId"":""c1c98f6a-57c6-4ecc-a329-3b744cab74bd"",""projectUrl"":""https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-AIOHTTP-6091621"",""SNYK-PYTHON-AIOHTTP-6091622""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""pr-warning-shown"",""priorityScore""],""priorityScoreList"":[663,663],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Improper Input Validation](https://learn.snyk.io/lesson/improper-input-validation/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14038:3842,remediat,remediationStrategy,3842,https://hail.is,https://github.com/hail-is/hail/pull/14038,1,['remediat'],['remediationStrategy']
Safety,"ependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI5NGM3N2YwYy0xN2JkLTRkMzQtYmJhOS1iNzBiNmVhMDllMjYiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6Ijk0Yzc3ZjBjLTE3YmQtNGQzNC1iYmE5LWI3MGI2ZWEwOWUyNiJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/0ba777e1-bc27-41cc-aefa-0ed1a253829e?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/0ba777e1-bc27-41cc-aefa-0ed1a253829e?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""94c77f0c-17bd-4d34-bba9-b70b6ea09e26"",""prPublicId"":""94c77f0c-17bd-4d34-bba9-b70b6ea09e26"",""dependencies"":[{""name"":""aiohttp"",""from"":""3.8.6"",""to"":""3.9.0""}],""packageManager"":""pip"",""projectPublicId"":""0ba777e1-bc27-41cc-aefa-0ed1a253829e"",""projectUrl"":""https://app.snyk.io/org/danking/project/0ba777e1-bc27-41cc-aefa-0ed1a253829e?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-AIOHTTP-6091621"",""SNYK-PYTHON-AIOHTTP-6091622""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""pr-warning-shown"",""priorityScore""],""priorityScoreList"":[663,663],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Improper Input Validation](https://learn.snyk.io/lesson/improper-input-validation/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14039:3769,remediat,remediationStrategy,3769,https://hail.is,https://github.com/hail-is/hail/pull/14039,1,['remediat'],['remediationStrategy']
Safety,"ependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiIxZjc1YjVmNi00MjFkLTQyN2YtYTk3OC0yNTBhNTgyNTI4YmUiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjFmNzViNWY2LTQyMWQtNDI3Zi1hOTc4LTI1MGE1ODI1MjhiZSJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/cbac91bd-aa95-4900-9a06-97404b268d6e?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/cbac91bd-aa95-4900-9a06-97404b268d6e?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""1f75b5f6-421d-427f-a978-250a582528be"",""prPublicId"":""1f75b5f6-421d-427f-a978-250a582528be"",""dependencies"":[{""name"":""aiohttp"",""from"":""3.8.6"",""to"":""3.9.0""}],""packageManager"":""pip"",""projectPublicId"":""cbac91bd-aa95-4900-9a06-97404b268d6e"",""projectUrl"":""https://app.snyk.io/org/danking/project/cbac91bd-aa95-4900-9a06-97404b268d6e?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-AIOHTTP-6091621"",""SNYK-PYTHON-AIOHTTP-6091622""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""pr-warning-shown"",""priorityScore""],""priorityScoreList"":[663,663],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Improper Input Validation](https://learn.snyk.io/lesson/improper-input-validation/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14035:3763,remediat,remediationStrategy,3763,https://hail.is,https://github.com/hail-is/hail/pull/14035,1,['remediat'],['remediationStrategy']
Safety,"ependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiIzMjkzZGUwOS01NmJjLTRkNWEtYWNkZC1iMzdlMDBkMzkwOTgiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjMyOTNkZTA5LTU2YmMtNGQ1YS1hY2RkLWIzN2UwMGQzOTA5OCJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/b72ce54d-5de3-48e5-a1d4-6f8967681a12?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/b72ce54d-5de3-48e5-a1d4-6f8967681a12?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""3293de09-56bc-4d5a-acdd-b37e00d39098"",""prPublicId"":""3293de09-56bc-4d5a-acdd-b37e00d39098"",""dependencies"":[{""name"":""aiohttp"",""from"":""3.8.6"",""to"":""3.9.0""}],""packageManager"":""pip"",""projectPublicId"":""b72ce54d-5de3-48e5-a1d4-6f8967681a12"",""projectUrl"":""https://app.snyk.io/org/danking/project/b72ce54d-5de3-48e5-a1d4-6f8967681a12?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-AIOHTTP-6091621"",""SNYK-PYTHON-AIOHTTP-6091622""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""pr-warning-shown"",""priorityScore""],""priorityScoreList"":[663,663],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Improper Input Validation](https://learn.snyk.io/lesson/improper-input-validation/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14034:3717,remediat,remediationStrategy,3717,https://hail.is,https://github.com/hail-is/hail/pull/14034,1,['remediat'],['remediationStrategy']
Safety,"ependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiIzODVlZjFmNi0zYjJhLTRjZTEtOTA5MS0xMWM1YzU3NDY0OTIiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjM4NWVmMWY2LTNiMmEtNGNlMS05MDkxLTExYzVjNTc0NjQ5MiJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/92d13c88-936f-40d3-b692-29e637c1a00c?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/92d13c88-936f-40d3-b692-29e637c1a00c?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""385ef1f6-3b2a-4ce1-9091-11c5c5746492"",""prPublicId"":""385ef1f6-3b2a-4ce1-9091-11c5c5746492"",""dependencies"":[{""name"":""aiohttp"",""from"":""3.8.6"",""to"":""3.9.0""}],""packageManager"":""pip"",""projectPublicId"":""92d13c88-936f-40d3-b692-29e637c1a00c"",""projectUrl"":""https://app.snyk.io/org/danking/project/92d13c88-936f-40d3-b692-29e637c1a00c?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-AIOHTTP-6091621"",""SNYK-PYTHON-AIOHTTP-6091622""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""pr-warning-shown"",""priorityScore""],""priorityScoreList"":[663,663],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Improper Input Validation](https://learn.snyk.io/lesson/improper-input-validation/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14044:3694,remediat,remediationStrategy,3694,https://hail.is,https://github.com/hail-is/hail/pull/14044,1,['remediat'],['remediationStrategy']
Safety,"ependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJhNGNiNTQzMi0zM2VmLTQ3ZmQtYmYzMy1lZGU2YzJlNDJiOTAiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImE0Y2I1NDMyLTMzZWYtNDdmZC1iZjMzLWVkZTZjMmU0MmI5MCJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""a4cb5432-33ef-47fd-bf33-ede6c2e42b90"",""prPublicId"":""a4cb5432-33ef-47fd-bf33-ede6c2e42b90"",""dependencies"":[{""name"":""aiohttp"",""from"":""3.8.6"",""to"":""3.9.0""}],""packageManager"":""pip"",""projectPublicId"":""20159ae6-a5aa-42fa-845a-c89f5bcbf999"",""projectUrl"":""https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-AIOHTTP-6091621"",""SNYK-PYTHON-AIOHTTP-6091622""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""pr-warning-shown"",""priorityScore""],""priorityScoreList"":[663,663],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Improper Input Validation](https://learn.snyk.io/lesson/improper-input-validation/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14042:3970,remediat,remediationStrategy,3970,https://hail.is,https://github.com/hail-is/hail/pull/14042,1,['remediat'],['remediationStrategy']
Safety,"ependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJlNDEzMjhlZS0zNDg5LTQ3NDItYTc3YS01ZDZhNTQ1ZWE2ZjIiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImU0MTMyOGVlLTM0ODktNDc0Mi1hNzdhLTVkNmE1NDVlYTZmMiJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/fdd23464-9a67-49b8-8d9c-08502282c5fb?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/fdd23464-9a67-49b8-8d9c-08502282c5fb?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""e41328ee-3489-4742-a77a-5d6a545ea6f2"",""prPublicId"":""e41328ee-3489-4742-a77a-5d6a545ea6f2"",""dependencies"":[{""name"":""aiohttp"",""from"":""3.8.6"",""to"":""3.9.0""}],""packageManager"":""pip"",""projectPublicId"":""fdd23464-9a67-49b8-8d9c-08502282c5fb"",""projectUrl"":""https://app.snyk.io/org/danking/project/fdd23464-9a67-49b8-8d9c-08502282c5fb?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-AIOHTTP-6091621"",""SNYK-PYTHON-AIOHTTP-6091622""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""pr-warning-shown"",""priorityScore""],""priorityScoreList"":[663,663],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Improper Input Validation](https://learn.snyk.io/lesson/improper-input-validation/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14037:3703,remediat,remediationStrategy,3703,https://hail.is,https://github.com/hail-is/hail/pull/14037,1,['remediat'],['remediationStrategy']
Safety,"ependencies</h3>; <ul>; <li>Update dependency org.graalvm.buildtools:native-maven-plugin to v0.9.24 (<a href=""https://redirect.github.com/googleapis/java-storage/issues/2158"">#2158</a>) (<a href=""https://github.com/googleapis/java-storage/commit/4f5682a4f6d6d5372a2d382ae3e47dace490ca0d"">4f5682a</a>)</li>; </ul>; <h2>v2.26.0</h2>; <h2><a href=""https://github.com/googleapis/java-storage/compare/v2.25.0...v2.26.0"">2.26.0</a> (2023-08-03)</h2>; <h3>Features</h3>; <ul>; <li>Implement BufferToDiskThenUpload BlobWriteSessionConfig (<a href=""https://redirect.github.com/googleapis/java-storage/issues/2139"">#2139</a>) (<a href=""https://github.com/googleapis/java-storage/commit/4dad2d5c3a81eda7190ad4f95316471e7fa30f66"">4dad2d5</a>)</li>; <li>Introduce new BlobWriteSession (<a href=""https://redirect.github.com/googleapis/java-storage/issues/2123"">#2123</a>) (<a href=""https://github.com/googleapis/java-storage/commit/e0191b518e50a49fae0691894b50f0c5f33fc6af"">e0191b5</a>)</li>; </ul>; <h3>Bug Fixes</h3>; <ul>; <li><strong>grpc:</strong> Return error if credentials are detected to be null (<a href=""https://redirect.github.com/googleapis/java-storage/issues/2142"">#2142</a>) (<a href=""https://github.com/googleapis/java-storage/commit/b61a9764a9d953d2b214edb2b543b8df42fbfa06"">b61a976</a>)</li>; <li>Possible NPE when HttpStorageOptions deserialized (<a href=""https://redirect.github.com/googleapis/java-storage/issues/2153"">#2153</a>) (<a href=""https://github.com/googleapis/java-storage/commit/68ad8e7357097e3dd161c2ab5f7a42a060a3702c"">68ad8e7</a>)</li>; <li>Update grpc default metadata projection to include acl same as json (<a href=""https://redirect.github.com/googleapis/java-storage/issues/2150"">#2150</a>) (<a href=""https://github.com/googleapis/java-storage/commit/330e795040592e5df22d44fb5216ad7cf2448e81"">330e795</a>)</li>; </ul>; <h3>Dependencies</h3>; <ul>; <li>Update dependency com.google.cloud:google-cloud-shared-dependencies to v3.14.0 (<a href=""https://redirect.github.com/google",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13605:2107,detect,detected,2107,https://hail.is,https://github.com/hail-is/hail/pull/13605,1,['detect'],['detected']
Safety,"equests/blob/main/HISTORY.md"">requests's changelog</a>.</em></p>; <blockquote>; <h2>2.32.0 (2024-05-20)</h2>; <p><strong>Security</strong></p>; <ul>; <li>Fixed an issue where setting <code>verify=False</code> on the first request from a; Session will cause subsequent requests to the <em>same origin</em> to also ignore; cert verification, regardless of the value of <code>verify</code>.; (<a href=""https://github.com/psf/requests/security/advisories/GHSA-9wx4-h78v-vm56"">https://github.com/psf/requests/security/advisories/GHSA-9wx4-h78v-vm56</a>)</li>; </ul>; <p><strong>Improvements</strong></p>; <ul>; <li><code>verify=True</code> now reuses a global SSLContext which should improve; request time variance between first and subsequent requests. It should; also minimize certificate load time on Windows systems when using a Python; version built with OpenSSL 3.x. (<a href=""https://redirect.github.com/psf/requests/issues/6667"">#6667</a>)</li>; <li>Requests now supports optional use of character detection; (<code>chardet</code> or <code>charset_normalizer</code>) when repackaged or vendored.; This enables <code>pip</code> and other projects to minimize their vendoring; surface area. The <code>Response.text()</code> and <code>apparent_encoding</code> APIs; will default to <code>utf-8</code> if neither library is present. (<a href=""https://redirect.github.com/psf/requests/issues/6702"">#6702</a>)</li>; </ul>; <p><strong>Bugfixes</strong></p>; <ul>; <li>Fixed bug in length detection where emoji length was incorrectly; calculated in the request content-length. (<a href=""https://redirect.github.com/psf/requests/issues/6589"">#6589</a>)</li>; <li>Fixed deserialization bug in JSONDecodeError. (<a href=""https://redirect.github.com/psf/requests/issues/6629"">#6629</a>)</li>; <li>Fixed bug where an extra leading <code>/</code> (path separator) could lead; urllib3 to unnecessarily reparse the request URI. (<a href=""https://redirect.github.com/psf/requests/issues/6644"">#6644</a>)</li>; </ul",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14555:5130,detect,detection,5130,https://hail.is,https://github.com/hail-is/hail/pull/14555,1,['detect'],['detection']
Safety,"er. ; 4. Optional Array of Optional Int32 (450, 138). These arrays will have a bunch of LEB128 encoded integers, which, as stated, has a bunch of branches making this fairly expensive.; 5. `BlockingInputBuffer.ensure` is expensive. (705, 130). The blocking happens *after* Zstd. This dataset is about 16 GiB when uncompressed. The block size is 65kB (ergo 244k blocks the uncompressed dataset) When reading a large numbers of bytes, `ensure` is called infrequently compared to actually reading the bytes. However, LEB128 relies heavily on `readByte` and thus issues O(N_BYTES) calls to `ensure`.; 6. `Zstd.decompressByteArray` (249, 111). This is eliminated in main by commit 507744f2d7. Patrick's branch (on which I ran these experiments) is out of date.; 7. `BlockingInputBuffer.readBytes` (798, 88). I think this is a bit unavoidable: we have to copy bytes from input to the region. We could avoid the intermediary buffer: copy as much as possible from the buffer to the destination, then modify `InputBlockBuffer` so that it can read directly into the region while spilling any remainder into a provided buffer. For large reads this saves O(N_BLOCKS) copies and branches.; 8. `ZstdDecompressCtx.decompressByteArray0` (2017, 80). Yikes. Decompression ain't cheap, but, at least on this dataset, it's ~10x decompression ratio. If we had better datatype-aware compressors (like dictionary coding of strings) maybe we could skip Zstd and use something lighter weight. The remaining methods are pretty minor or would be addressed by one of the above mentioned mitigations. <img width=""1551"" alt=""Screenshot 2023-10-11 at 13 27 34"" src=""https://github.com/hail-is/hail/assets/106194/cfd855d6-8762-4b94-8e53-1ef881fde6ae"">. ---. ### Conclusions. LEB128 should not be a buffer spec for two reasons:; 1. It is too slow to be a our default integer encoding.; 2. InputBuffers and OutputBuffers do not expose vectorized `read` and `write` primitives. We could mitigate the slowness of LEB128 with something l",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13792:5903,avoid,avoid,5903,https://hail.is,https://github.com/hail-is/hail/issues/13792,1,['avoid'],['avoid']
Safety,"er.max=1g,spark:spark.driver.extraJavaOptions=-Xss4M,spark:spark.executor.extraJavaOptions=-Xss4M,hdfs:dfs.replication=1,dataproc:dataproc.logging.stackdriver.enable=false,dataproc:dataproc.monitoring.stackdriver.enable=false,spark:spark.driver.memory=41g', '--initialization-actions=gs://hail-common/hailctl/dataproc/0.2.18/init_notebook.py,gs://gnomad-public/tools/inits/master-init.sh', '--metadata=^|||^WHEEL=gs://hail-common/hailctl/dataproc/0.2.18/hail-0.2.18-py3-none-any.whl|||PKGS=aiohttp|bokeh>1.1,<1.3|decorator<5|gcsfs==0.2.1|hurry.filesize==0.9|ipykernel<5|nest_asyncio|numpy<2|pandas>0.22,<0.24|parsimonious<0.9|PyJWT|python-json-logger==0.1.11|requests>=2.21.0,<2.21.1|scipy>1.2,<1.4|tabulate==0.8.3|slackclient==2.0.0|websocket-client|sklearn|tabulate|statsmodels|scikit-learn|hdbscan|matplotlib', '--master-machine-type=n1-highmem-8', '--master-boot-disk-size=100GB', '--num-master-local-ssds=0', '--num-preemptible-workers=0', '--num-worker-local-ssds=0', '--num-workers=2', '--preemptible-worker-boot-disk-size=40GB', '--worker-boot-disk-size=40', '--worker-machine-type=n1-standard-8', '--zone=us-central1-b', '--initialization-action-timeout=20m', '--labels=creator=weisburd_broadinstitute_org', '--max-idle=12h']' returned non-zero exit status 1.; ```. Then looking at the error log; ```; $ gsutil cat gs://dataproc-d919bddb-bde3-4138-bbe1-e068dfa1e550-us/google-cloud-dataproc-metainfo/3ec45dcc-d901-4777-930c-23046e64a97d/bw2-m/dataproc-initialization-script-0_output; pip packages are ['setuptools', 'mkl<2020', 'ipywidgets<8', 'jupyter_console<5', 'nbconvert<6', 'notebook<6', 'qtconsole<5', 'jupyter', 'tornado<6', 'lxml<5', 'google-cloud==0.32.0', 'ipython<7', 'jgscm<0.2', 'jupyter-spark', 'aiohttp', 'bokeh>1.1,<1.3', 'decorator<5', 'gcsfs==0.2.1', 'hurry.filesize==0.9', 'ipykernel<5', 'nest_asyncio', 'numpy<2', 'pandas>0.22,<0.24', 'parsimonious<0.9', 'PyJWT', 'python-json-logger==0.1.11', 'requests>=2.21.0,<2.21.1', 'scipy>1.2,<1.4', 'tabulate==0.8.3', 'slackclien",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6634:4700,timeout,timeout,4700,https://hail.is,https://github.com/hail-is/hail/issues/6634,1,['timeout'],['timeout']
Safety,"erted quantities are identical to the attempts that already exist in the database right after we converted the billing over to using resources. Once we have all resources for all attempts, the next step (future PR) is to do a scan and repopulate the new aggregated billing tables **by date**. In this PR, I don't try and add the usage to the existing `aggregated_*_resources` tables. I did this to cut down on time and space since we're eventually going to deprecate those tables anyways. Because I don't touch those tables, we don't need to worry about modifying the client code and how the current billing information is calculated. How this migration works is there are 5 phases:; 1. Compute the expected number of attempts to process for format version < 3. ; 2. Divide the search space into chunks of size 100 attempts (empirically determined this was the best chunk size) and randomize the order of the chunks.; 3. Serially process 5000 chunks with only 10 out of the 100 records as a ""burn in period"" to avoid the birthday problem when trying to insert records in parallel.; 4. In parallel, process all the chunks with 10 way parallelism (empirically determined to max CPU for a 4 core db instance); 5. Do an audit of the results to make sure the attempt resources now has the correct number of rows and the billing is within $0.001 per job with the old way and new way of computing the billing. The tolerance of $0.001 was empirically determined. At a threshold of $0.0001, 33/30,000,000 attempts failed. I think this is good enough as there's always going to be rounding errors. I did not do an explicit audit in the code to make sure the other aggregated_*_resources tables did not change. I spot checked this was correct in my test database. To do the complete audit during the actual migration would take more time. I made sure all the inserts were idempotent. Please double check this. The inserts use a temporary table with an isolation level of read committed. The reason for this is b",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11990:1467,avoid,avoid,1467,https://hail.is,https://github.com/hail-is/hail/pull/11990,1,['avoid'],['avoid']
Safety,"es the meaning of aggregation (`TableMapRows`, `AggFilter`, etc.), and which is implicitly referenced by any node which performs an aggregation (`ApplyAggOp`, `AggFilter`, etc.). This requires nodes to be able to bind variables which shadow variables already bound by parents, which it turns out wasn't handled correctly by the CSE algorithm. Fixing this required several changes:; * I moved free variable computation to a lazy value on `BaseIR`. This way, each time we see a subtree `x`, we can recompute the max depth of the binding sites of all of `x`'s free variables, since those binding sites may be different than last time we saw `x`. This also required splitting the free variables into value, agg, and scan sets, so they can be looked up in the correct context (previously context lookup was always done at the `Ref` node, at which point the variable was in the value context).; * Now, in the `CSEPrintPass`, we have to recompute the same binding depth calculation that was done in the analysis pass, so we know which binding site to look at (previously I just searched all binding sites in scope, but with shadowing handled correctly we don't have sufficient information to decide which binding site is valid). This requires maintaining contexts in the print pass, which is annoying because we are now traversing the tree of `Renderable` children, which is not exactly the same as the IR tree.; * To fix this, I duplicated all methods involving binding structure on `BaseIR`. To avoid having to write twice as many methods on concrete IR classes, I made the methods taking the index of the `Renderable` child (e.g. `renderable_bindings`) be the primary methods which are overridden. For all IR nodes, there is a map from IR child index to Renderable child index, defined in `renderable_idx_of_child`, which is used to define the `bindings` and similar methods in terms of the `renderable_bindings` and similar. This is messier than I would have liked, but I couldn't think of a better way.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7479:1803,avoid,avoid,1803,https://hail.is,https://github.com/hail-is/hail/pull/7479,1,['avoid'],['avoid']
Safety,"es/259) &lt;https://github.com/aio-libs/async-timeout/issues/259&gt;</code><em>, <code>[#274](https://github.com/aio-libs/async-timeout/issues/274) &lt;https://github.com/aio-libs/async-timeout/issues/274&gt;</code></em></li>; </ul>; <h1>4.0.1 (2121-11-10)</h1>; <ul>; <li>; <p>Fix regression:</p>; <ol>; <li>; <p>Don't raise TimeoutError from timeout object that doesn't enter into async context; manager</p>; </li>; <li>; <p>Use call_soon() for raising TimeoutError if deadline is reached on entering into; async context manager</p>; </li>; </ol>; <p>(<a href=""https://github-redirect.dependabot.com/aio-libs/async-timeout/issues/258"">#258</a>)</p>; </li>; <li>; <p>Make <code>Timeout</code> class available in <code>__all__</code>.</p>; </li>; </ul>; <h1>4.0.0 (2021-11-01)</h1>; <ul>; <li>; <p>Implemented <code>timeout_at(deadline)</code> (<a href=""https://github-redirect.dependabot.com/aio-libs/async-timeout/issues/117"">#117</a>)</p>; </li>; <li>; <p>Supported <code>timeout.deadline</code> and <code>timeout.expired</code> properties.</p>; </li>; <li>; <p>Dropped <code>timeout.remaining</code> property: it can be calculated as; <code>timeout.deadline - loop.time()</code></p>; </li>; <li>; <p>Dropped <code>timeout.timeout</code> property that returns a relative timeout based on the; timeout object creation time; the absolute <code>timeout.deadline</code> should be used; instead.</p>; </li>; <li>; <p>Added the deadline modification methods: <code>timeout.reject()</code>,; <code>timeout.shift(delay)</code>, <code>timeout.update(deadline)</code>.</p>; </li>; <li>; <p>Deprecated synchronous context manager usage</p>; </li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/aio-libs/async-timeout/commit/5128f7f4ff73b165579006a8336978efaeeca07a""><code>5128f7f</code></a> Fix CHANGES</li>; <li><a href=""https://github.com/aio-libs/async-timeout/commit/18e718a56f9def7dc40bb9ce3a2962a8fb0c883c""><code>18e718a</code></a> Bump ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11465:3268,timeout,timeout,3268,https://hail.is,https://github.com/hail-is/hail/pull/11465,1,['timeout'],['timeout']
Safety,"es/274"">#274</a></li>; </ul>; <h2>v4.0.1</h2>; <ul>; <li>; <p>Fix regression:</p>; <ol>; <li>; <p>Don't raise TimeoutError from timeout object that doesn't enter into async context; manager</p>; </li>; <li>; <p>Use call_soon() for raising TimeoutError if deadline is reached on entering into; async context manager</p>; </li>; </ol>; <p>(<a href=""https://github-redirect.dependabot.com/aio-libs/async-timeout/issues/258"">#258</a>)</p>; </li>; <li>; <p>Make <code>Timeout</code> class available in <code>__all__</code>.</p>; </li>; </ul>; <h2>async-timeout 4.0.0</h2>; <h1>Changes</h1>; <ul>; <li>; <p>Implemented <code>timeout_at(deadline)</code> (<a href=""https://github-redirect.dependabot.com/aio-libs/async-timeout/issues/117"">#117</a>)</p>; </li>; <li>; <p>Supported <code>timeout.deadline</code> and <code>timeout.expired</code> properties.</p>; </li>; <li>; <p>Drooped <code>timeout.remaining</code> property: it can be calculated as; <code>timeout.deadline - loop.time()</code></p>; </li>; <li>; <p>Dropped <code>timeout.timeout</code> property that returns a relative timeout based on the; timeout object creation time; the absolute <code>timeout.deadline</code> should be used; instead.</p>; </li>; <li>; <p>Added the deadline modification methods: <code>timeout.reject()</code>,; <code>timeout.shift(delay)</code>, <code>timeout.update(deadline)</code>.</p>; </li>; <li>; <p>Deprecated synchronous context manager usage</p>; </li>; </ul>; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/aio-libs/async-timeout/blob/master/CHANGES.rst"">async-timeout's changelog</a>.</em></p>; <blockquote>; <h1>4.0.2 (2021-12-20)</h1>; <h2>Misc</h2>; <ul>; <li><code>[#259](https://github.com/aio-libs/async-timeout/issues/259) &lt;https://github.com/aio-libs/async-timeout/issues/259&gt;</code><em>, <code>[#274](https://github.com/aio-libs/async-timeout/issues/274) &lt;https://github.com/aio-libs/async-timeout/issues/274&gt;</code></em",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11465:1498,timeout,timeout,1498,https://hail.is,https://github.com/hail-is/hail/pull/11465,1,['timeout'],['timeout']
Safety,"et_gcs_requester_pays_configuration( │; │ 311 │ │ │ gcs_requester_pays_configuration=gcs_requester_pays_configuration │; │ 312 │ │ ) │; │ │; │ /Users/cvittal/src/hail/hail/python/hailtop/aiocloud/aiogoogle/client/base_client.py:15 in │; │ __init__ │; │ │; │ 12 │ def __init__(self, base_url: str, *, session: Optional[GoogleSession] = None, │; │ 13 │ │ │ │ rate_limit: Optional[RateLimit] = None, **kwargs): │; │ 14 │ │ if session is None: │; │ ❱ 15 │ │ │ session = GoogleSession(**kwargs) │; │ 16 │ │ super().__init__(base_url, session, rate_limit=rate_limit) │; │ 17 │; │ │; │ /Users/cvittal/src/hail/hail/python/hailtop/aiocloud/aiogoogle/session.py:18 in __init__ │; │ │; │ 15 │ │ │ │ credentials = GoogleCredentials.from_file(credentials_file) │; │ 16 │ │ │ else: │; │ 17 │ │ │ │ credentials = GoogleCredentials.default_credentials() │; │ ❱ 18 │ │ super().__init__(credentials=credentials, params=params, **kwargs) │; │ 19 │; │ │; │ /Users/cvittal/src/hail/hail/python/hailtop/aiocloud/common/session.py:80 in __init__ │; │ │; │ 77 │ │ │ self._http_session = http_session │; │ 78 │ │ else: │; │ 79 │ │ │ self._owns_http_session = True │; │ ❱ 80 │ │ │ self._http_session = httpx.ClientSession(**kwargs) │; │ 81 │ │ self._credentials = credentials │; │ 82 │ │; │ 83 │ async def request(self, method: str, url: str, **kwargs) -> aiohttp.ClientResponse: │; │ │; │ /Users/cvittal/src/hail/hail/python/hailtop/httpx.py:110 in __init__ │; │ │; │ 107 │ │ │ timeout = aiohttp.ClientTimeout(total=5) │; │ 108 │ │ │; │ 109 │ │ self.raise_for_status = raise_for_status │; │ ❱ 110 │ │ self.client_session = aiohttp.ClientSession( │; │ 111 │ │ │ *args, │; │ 112 │ │ │ timeout=timeout, │; │ 113 │ │ │ raise_for_status=False, │; ╰──────────────────────────────────────────────────────────────────────────────────────────────────╯; TypeError: ClientSession.__init__() got an unexpected keyword argument 'project'; Unclosed client session; client_session: <aiohttp.client.ClientSession object at 0x1041b6980>; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13793:5650,timeout,timeout,5650,https://hail.is,https://github.com/hail-is/hail/issues/13793,3,['timeout'],['timeout']
Safety,"etails>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/googleapis/python-storage/commit/f80f69516b0eaa6ebef6a28d1fd12c9d78f362ce""><code>f80f695</code></a> chore(main): release 2.2.0 (<a href=""https://github-redirect.dependabot.com/googleapis/python-storage/issues/705"">#705</a>)</li>; <li><a href=""https://github.com/googleapis/python-storage/commit/eae1df0f4526eefb21f14eb3f5a319b9395b90c7""><code>eae1df0</code></a> chore(deps): update dependency pytest to v7.1.0 (<a href=""https://github-redirect.dependabot.com/googleapis/python-storage/issues/732"">#732</a>)</li>; <li><a href=""https://github.com/googleapis/python-storage/commit/5d1cfd2050321481a3bc4acbe80537ea666506fa""><code>5d1cfd2</code></a> fix: Fix BlobReader handling of interleaved reads and seeks (<a href=""https://github-redirect.dependabot.com/googleapis/python-storage/issues/721"">#721</a>)</li>; <li><a href=""https://github.com/googleapis/python-storage/commit/e0b3b354d51e4be7c563d7f2f628a7139df842c0""><code>e0b3b35</code></a> fix: retry client side requests timeout (<a href=""https://github-redirect.dependabot.com/googleapis/python-storage/issues/727"">#727</a>)</li>; <li><a href=""https://github.com/googleapis/python-storage/commit/c64779df2fb22d22e76adee00b8a40f3b5bb4b14""><code>c64779d</code></a> chore(deps): update dependency google-cloud-pubsub to v2.11.0 (<a href=""https://github-redirect.dependabot.com/googleapis/python-storage/issues/729"">#729</a>)</li>; <li><a href=""https://github.com/googleapis/python-storage/commit/2cb0892f4965a42c51b8d6b7127087a6f435b07b""><code>2cb0892</code></a> tests: add retry conf s7 resumable upload test cases (<a href=""https://github-redirect.dependabot.com/googleapis/python-storage/issues/720"">#720</a>)</li>; <li><a href=""https://github.com/googleapis/python-storage/commit/c7bf615909a04f3bab3efb1047a9f4ba659bba19""><code>c7bf615</code></a> fix: add user agent in python-storage when calling resumable media (WIP) (<a href=""https://github-redirect.dependabot.com/goo",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11578:7177,timeout,timeout,7177,https://hail.is,https://github.com/hail-is/hail/pull/11578,1,['timeout'],['timeout']
Safety,"existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJlYjc2ODRiYy00Njg4LTQ4ODktOTQyOS0xY2M4M2JhNzJmMDAiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImViNzY4NGJjLTQ2ODgtNDg4OS05NDI5LTFjYzgzYmE3MmYwMCJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/0ba777e1-bc27-41cc-aefa-0ed1a253829e?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/0ba777e1-bc27-41cc-aefa-0ed1a253829e?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""eb7684bc-4688-4889-9429-1cc83ba72f00"",""prPublicId"":""eb7684bc-4688-4889-9429-1cc83ba72f00"",""dependencies"":[{""name"":""orjson"",""from"":""3.9.7"",""to"":""3.9.15""}],""packageManager"":""pip"",""projectPublicId"":""0ba777e1-bc27-41cc-aefa-0ed1a253829e"",""projectUrl"":""https://app.snyk.io/org/danking/project/0ba777e1-bc27-41cc-aefa-0ed1a253829e?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-ORJSON-6276643""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title""],""priorityScoreList"":[null],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Relative Path Traversal](https://learn.snyk.io/lesson/directory-traversal/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14355:2861,remediat,remediationStrategy,2861,https://hail.is,https://github.com/hail-is/hail/pull/14355,1,['remediat'],['remediationStrategy']
Safety,"exit code 0 but actually a timeout. ```; {; ""batch_id"": 27671,; ""job_id"": 65,; ""name"": ""test_pipeline"",; ""state"": ""Error"",; ""exit_code"": 0,; ""duration"": 1211266,; ""msec_mcpu"": 1200805000,; ""cost"": ""$0.0072"",; ""status"": {; ""worker"": ""batch-worker-default-i68pm"",; ""batch_id"": 27671,; ""job_id"": 65,; ""attempt_id"": ""bpqqnj"",; ""user"": ""ci"",; ""state"": ""error"",; ""format_version"": 2,; ""container_statuses"": {; ""input"": {; ""name"": ""input"",; ""state"": ""succeeded"",; ""timing"": {; ""pulling"": {; ""start_time"": 1586188234696,; ""finish_time"": 1586188234698,; ""duration"": 2; },; ""creating"": {; ""start_time"": 1586188234699,; ""finish_time"": 1586188234766,; ""duration"": 67; },; ""runtime"": {; ""start_time"": 1586188234766,; ""finish_time"": 1586188245227,; ""duration"": 10461; },; ""starting"": {; ""start_time"": 1586188234767,; ""finish_time"": 1586188236190,; ""duration"": 1423; },; ""running"": {; ""start_time"": 1586188236190,; ""finish_time"": 1586188245227,; ""duration"": 9037; },; ""uploading_log"": {; ""start_time"": 1586188245231,; ""finish_time"": 1586188245276,; ""duration"": 45; },; ""deleting"": {; ""start_time"": 1586188245276,; ""finish_time"": 1586188245305,; ""duration"": 29; }; },; ""container_status"": {; ""state"": ""exited"",; ""started_at"": ""2020-04-06T15:50:36.182009912Z"",; ""finished_at"": ""2020-04-06T15:50:44.884808909Z"",; ""out_of_memory"": false,; ""exit_code"": 0; }; },; ""main"": {; ""name"": ""main"",; ""state"": ""error"",; ""timing"": {; ""pulling"": {; ""start_time"": 1586188245305,; ""finish_time"": 1586188245404,; ""duration"": 99; },; ""creating"": {; ""start_time"": 1586188245404,; ""finish_time"": 1586188245457,; ""duration"": 53; },; ""runtime"": {; ""start_time"": 1586188245458,; ""finish_time"": 1586189446263,; ""duration"": 1200805; },; ""starting"": {; ""start_time"": 1586188245458,; ""finish_time"": 1586188246261,; ""duration"": 803; },; ""running"": {; ""start_time"": 1586188246262,; ""finish_time"": 1586189446263,; ""duration"": 1200001; },; ""uploading_log"": {; ""start_time"": 1586189446266,; ""finish_time"": 1586189446350,; ""duration"": 84; },; ""deleting",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8473:27,timeout,timeout,27,https://hail.is,https://github.com/hail-is/hail/issues/8473,1,['timeout'],['timeout']
Safety,"ext manager</p>; </li>; </ol>; <p>(<a href=""https://github-redirect.dependabot.com/aio-libs/async-timeout/issues/258"">#258</a>)</p>; </li>; <li>; <p>Make <code>Timeout</code> class available in <code>__all__</code>.</p>; </li>; </ul>; <h1>4.0.0 (2021-11-01)</h1>; <ul>; <li>; <p>Implemented <code>timeout_at(deadline)</code> (<a href=""https://github-redirect.dependabot.com/aio-libs/async-timeout/issues/117"">#117</a>)</p>; </li>; <li>; <p>Supported <code>timeout.deadline</code> and <code>timeout.expired</code> properties.</p>; </li>; <li>; <p>Dropped <code>timeout.remaining</code> property: it can be calculated as; <code>timeout.deadline - loop.time()</code></p>; </li>; <li>; <p>Dropped <code>timeout.timeout</code> property that returns a relative timeout based on the; timeout object creation time; the absolute <code>timeout.deadline</code> should be used; instead.</p>; </li>; <li>; <p>Added the deadline modification methods: <code>timeout.reject()</code>,; <code>timeout.shift(delay)</code>, <code>timeout.update(deadline)</code>.</p>; </li>; <li>; <p>Deprecated synchronous context manager usage</p>; </li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/aio-libs/async-timeout/commit/5128f7f4ff73b165579006a8336978efaeeca07a""><code>5128f7f</code></a> Fix CHANGES</li>; <li><a href=""https://github.com/aio-libs/async-timeout/commit/18e718a56f9def7dc40bb9ce3a2962a8fb0c883c""><code>18e718a</code></a> Bump to 4.0.2</li>; <li><a href=""https://github.com/aio-libs/async-timeout/commit/48d1c4ce923b1da75976d7e2a6ca9234b3092c16""><code>48d1c4c</code></a> Setup towncrier</li>; <li><a href=""https://github.com/aio-libs/async-timeout/commit/2ede7d73e55f8d1a2279d78861af0009d96219fb""><code>2ede7d7</code></a> Fix annotations on <code>__exit__</code> and <code>__aexit__</code> (<a href=""https://github-redirect.dependabot.com/aio-libs/async-timeout/issues/274"">#274</a>)</li>; <li><a href=""https://github.com/aio-libs/async-timeout/co",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11465:3788,timeout,timeout,3788,https://hail.is,https://github.com/hail-is/hail/pull/11465,1,['timeout'],['timeout']
Safety,ext.java:340) at org.apacxt.invokeChannelRead(AbstractChannelHandlerContext.java:362) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelt io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359) at io.netty.channel.AbstractChannelHandlerCtractChannelHandlerContext.java:348) at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935) at io.nettyectedKey(NioEventLoop.java:645) at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:580) at io.netty at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858) at io.netty.util.concurrent.Default; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1889); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1876); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1876); at org.apache.spark.scheduler.DAGScheduler.handleTaskCompletion(DAGScheduler.scala:1493); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2107); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2059); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2048); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:737); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2061); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2082); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2114);,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8106:24174,abort,abortStage,24174,https://hail.is,https://github.com/hail-is/hail/issues/8106,1,['abort'],['abortStage']
Safety,"f()); ),; INDEL_Del_count_Het=hl.agg.count_where(; (hl.is_deletion(mt.alleles[0], mt.alleles[1])) & (mt.GT.is_het_ref()); ),; INDEL_Ins_count_Hom=hl.agg.count_where(; (hl.is_insertion(mt.alleles[0], mt.alleles[1])) & (mt.GT.is_hom_var()); ),; INDEL_Del_count_Hom=hl.agg.count_where(; (hl.is_deletion(mt.alleles[0], mt.alleles[1])) & (mt.GT.is_hom_var()); ),; )) for interval_name in interval_names}. mt2 = mt.annotate_cols(**annotate_dict); return mt2; ```; ```; interval_table_dict = dict(; zip(interval_names, [hl.is_defined(interval_table[filtered_mt.locus]) for interval_table in interval_tables]); ); ```. ### Version. 0.2.126. ### Relevant log output. ```shell; ---------------------------------------------------------------------------; RemoteDisconnected Traceback (most recent call last); File /opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py:703, in HTTPConnectionPool.urlopen(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw); 702 # Make the request on the httplib connection object.; --> 703 httplib_response = self._make_request(; 704 conn,; 705 method,; 706 url,; 707 timeout=timeout_obj,; 708 body=body,; 709 headers=headers,; 710 chunked=chunked,; 711 ); 713 # If we're going to release the connection in ``finally:``, then; 714 # the response doesn't need to know about the connection. Otherwise; 715 # it will also try to release it and we'll have a double-release; 716 # mess. File /opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py:449, in HTTPConnectionPool._make_request(self, conn, method, url, timeout, chunked, **httplib_request_kw); 445 except BaseException as e:; 446 # Remove the TypeError from the exception chain in; 447 # Python 3 (including for exceptions like SystemExit).; 448 # Otherwise it looks like a bug in the code.; --> 449 six.raise_from(e, None); 450 except (SocketTimeout, BaseSSLError, SocketError) as e:. File <string>:3, in raise",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13960:3917,timeout,timeout,3917,https://hail.is,https://github.com/hail-is/hail/issues/13960,1,['timeout'],['timeout']
Safety,"f, ir, timed=False):; --> 108 result = json.loads(Env.hc()._jhc.backend().executeJSON(self._to_java_ir(ir))); 109 value = ir.typ._from_json(result['value']); 110 timings = result['timings']. /usr/lib/spark/python/lib/py4j-src.zip/py4j/java_gateway.py in __call__(self, *args); 1255 answer = self.gateway_client.send_command(command); 1256 return_value = get_return_value(; -> 1257 answer, self.gateway_client, self.target_id, self.name); 1258 ; 1259 for temp_arg in temp_args:. /usr/local/lib/python3.6/site-packages/hail/utils/java.py in deco(*args, **kwargs); 223 raise FatalError('%s\n\nJava stack trace:\n%s\n'; 224 'Hail version: %s\n'; --> 225 'Error summary: %s' % (deepest, full, hail.__version__, deepest)) from None; 226 except pyspark.sql.utils.CapturedException as e:; 227 raise FatalError('%s\n\nJava stack trace:\n%s\n'. FatalError: NoSuchElementException: key not found: GRCh37. ```. ### Traces No. 1: . ```java ; Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 15 in stage 16.0 failed 4 times, most recent failure: Lost task 15.3 in stage 16.0 (TID 178, ip-172-31-1-20.ec2.internal, executor 4): org.json4s.package$MappingException: unknown error; 	at org.json4s.Extraction$.extract(Extraction.scala:43); 	at org.json4s.ExtractableJsonAstNode.extract(ExtractableJsonAstNode.scala:21); 	at is.hail.io.index.IndexReader$.readMetadata(IndexReader.scala:65); 	at is.hail.io.index.IndexReader.<init>(IndexReader.scala:90); 	at is.hail.io.index.IndexReaderBuilder$$anonfun$withDecoders$1.apply(IndexReader.scala:50); 	at is.hail.io.index.IndexReaderBuilder$$anonfun$withDecoders$1.apply(IndexReader.scala:50); 	at is.hail.HailContext$$anon$3$$anonfun$20.apply(HailContext.scala:879); 	at is.hail.HailContext$$anon$3$$anonfun$20.apply(HailContext.scala:877); 	at scala.Option.map(Option.scala:146); 	at is.hail.HailContext$$anon$3.compute(HailContext.scala:877); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); 	at org.apache.s",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7044:5156,abort,aborted,5156,https://hail.is,https://github.com/hail-is/hail/issues/7044,1,['abort'],['aborted']
Safety,"fc428ad</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/9822"">#9822</a> from jakobandersen/intersphinx_role</li>; <li><a href=""https://github.com/sphinx-doc/sphinx/commit/5d595ec0c4294f45f3138c4c581b84c39cae5e29""><code>5d595ec</code></a> intersphinx role, simplify role_name check</li>; <li><a href=""https://github.com/sphinx-doc/sphinx/commit/6ee0ecbe40ab8a3251538409cf35ffcc04765bfa""><code>6ee0ecb</code></a> intersphinx role, simplify role name matching</li>; <li><a href=""https://github.com/sphinx-doc/sphinx/commit/3bf8bcd6e151a78b0dd003a3e76ff4c65566b6e6""><code>3bf8bcd</code></a> intersphinx role, update docs</li>; <li><a href=""https://github.com/sphinx-doc/sphinx/commit/c11b109d591a74f87de071ec4782ac3ab782ea38""><code>c11b109</code></a> intersphinx role: :external+inv:<strong>: instead of :external:inv+</strong>:</li>; <li><a href=""https://github.com/sphinx-doc/sphinx/commit/9589a2bc0531598cdd69f260f2f2c2dbc5852d6e""><code>9589a2b</code></a> intersphinx role, remove redundant method</li>; <li><a href=""https://github.com/sphinx-doc/sphinx/commit/941db550f02d76ee2b93300584ac85dc599d21e6""><code>941db55</code></a> intersphinx role, fix flake8 warnings</li>; <li><a href=""https://github.com/sphinx-doc/sphinx/commit/9a3f2b85421948c98647b10106c1bbb5ff1b0628""><code>9a3f2b8</code></a> intersphinx role, CHANGES</li>; <li><a href=""https://github.com/sphinx-doc/sphinx/commit/540d76035cc6bbf7ee18d0eb9bf63e4c3651d1f9""><code>540d760</code></a> intersphinx role, documentation</li>; <li>Additional commits viewable in <a href=""https://github.com/sphinx-doc/sphinx/compare/v3.5.4...v4.4.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=sphinx&package-manager=pip&previous-version=3.5.4&new-version=4.4.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-comp",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11522:6597,redund,redundant,6597,https://hail.is,https://github.com/hail-is/hail/pull/11522,2,['redund'],['redundant']
Safety,"fe to delete it all and start clean), `build.gradle`, `gradle/`, `gradlew`, `gradlew.bat`, `pgradle`, `settings.gradle`; * run `mill mill.bsp.BSP/install` to generate the `.bsp` config directory (bsp is the Build Server Protocol); * In IntelliJ, go to File->Open, and choose the hail root directory; * When the project is open, go to File->Project Structure; * in the Project pane, set an sdk (8 or 11), and set the language level to 8; * in the Modules pane, delete the existing root module, click the plus sign -> Import Module, choose the `hail/` subdirectory, and choose ""Import module from external model"" and `BSP`; * you should see a progress bar at the bottom as it imports the project; * when it's done, quit and reopen IntelliJ. There should now be a bsp icon (two bars with two arrows between them) on the right, where the gradle elephant used to be. Just like before, sometimes you'll need to click the ""reload"" icon in there if things get wonky.; * if it says ""scalafmt configuration detected"", go ahead and enable the formatter. ## Metals setup. * delete any `.metals` directories; * open the hail repo in VSCode (even if you won't use VSCode, this seems to be the best way to get metals set up initially); * it should ask you to import a Mill build; * when that finishes, at the bottom it should say it's connected to a Bloop build server. In general, I think using Mill as the BSP directly will work best, but I don't have much experience to say for sure. To switch, run `Metals: switch build server` from the command palette. ## Debug and release builds. As before, debug mode adds some (fairly expensive) checking to our native memory system. But now there are a few other differences:; * treat warnings as errors only in release mode, so you can still compile, run tests, etc. during development without fixing all warnings; * enable optimization in scalac only in release mode. The intention is that we use debug mode during development, and release mode ony for published artifac",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14147:4596,detect,detected,4596,https://hail.is,https://github.com/hail-is/hail/pull/14147,1,['detect'],['detected']
Safety,"ferred to Scala `Iterator` throughout most of the codebase, especially for iterators of region values. This is a low-level change, which could affect all code involving iterators, so I welcome feedback from everybody. The new abstractions are what I called `FlipbookIterator` and `StagingIterator` (I'm open to name suggestions). My goal was to simplify and raise the level of abstraction of most of the iterator manipulating code in the codebase—which can be subtle and bug-prone, and difficult to read—while paying as minimal as possible a performance overhead for the abstraction. This was surprisingly subtle to find the right abstractions and get their implementation right, and my hope is that all the non-obvious iterator code will now be concentrated in a small, well tested, component. `FlipbookIterator` solves the confusing behavior where `hasNext` potentially wipes out the current value. (All methods on `FlipbookIterator` and `StagingIterator` should obey the rule that methods defined without trailing `()` do not change the state of the iterator in any way detectable through the API.) The core interface of `FlipbookIterator[A]` consists of the methods. * `isValid: Boolean`; * `value: A`; * `advance(): Unit`. The metaphor is a flipbook, where when you turn the page, you no longer have access to the previous page; where you can read the current page as many times as you want (no need to copy it); and where you only know you've reached the end of the flipbook when you turn the page and find that the next page is empty. In `FlipbookIterator`, `advance()` turns the page, `isValid` asks if the page you are on is non-empty, and `value` gives you the value on the current page (which is an error if the page is empty). `StagingIterator` is a subtype of `FlipbookIterator` which adds a bit of state to each page, together with the methods `consume()` and `stage()`. The bit of state on each page tracks whether the value has been ""consumed"" yet. `consume()` can only be called on a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3016:1141,detect,detectable,1141,https://hail.is,https://github.com/hail-is/hail/pull/3016,1,['detect'],['detectable']
Safety,"figuration option (<code>python-cell-magics</code>) to format cells with custom magics in Jupyter Notebooks (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2744"">#2744</a>)</li>; <li>Allow setting custom cache directory on all platforms with environment variable <code>BLACK_CACHE_DIR</code> (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2739"">#2739</a>).</li>; <li>Enable Python 3.10+ by default, without any extra need to specify -<code>-target-version=py310</code>. (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2758"">#2758</a>)</li>; <li>Make passing <code>SRC</code> or <code>--code</code> mandatory and mutually exclusive (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2804"">#2804</a>)</li>; </ul>; <h3>Output</h3>; <ul>; <li>Improve error message for invalid regular expression (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2678"">#2678</a>)</li>; <li>Improve error message when parsing fails during AST safety check by embedding the underlying SyntaxError (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2693"">#2693</a>)</li>; <li>No longer color diff headers white as it's unreadable in light themed terminals (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2691"">#2691</a>)</li>; <li>Text coloring added in the final statistics (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2712"">#2712</a>)</li>; <li>Verbose mode also now describes how a project root was discovered and which paths will be formatted. (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2526"">#2526</a>)</li>; </ul>; <h3>Packaging</h3>; <ul>; <li>All upper version bounds on dependencies have been removed (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2718"">#2718</a>)</li>; <li><code>typing-extensions</code> is no longer a required dependency in Python 3.10+ (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2772"">#2772",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11468:5741,safe,safety,5741,https://hail.is,https://github.com/hail-is/hail/pull/11468,1,['safe'],['safety']
Safety,fix test timeouts,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6082:9,timeout,timeouts,9,https://hail.is,https://github.com/hail-is/hail/pull/6082,1,['timeout'],['timeouts']
Safety,fix unsafe ordering on interval,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3355:4,unsafe,unsafe,4,https://hail.is,https://github.com/hail-is/hail/pull/3355,1,['unsafe'],['unsafe']
Safety,"fixes #6236. instead of calling `SafeRow` to manifest the entire row and then pick out the keys, create `UnsafeRow`s and then copy only the keys. added `RVD.toUnsafeRows`",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6666:33,Safe,SafeRow,33,https://hail.is,https://github.com/hail-is/hail/pull/6666,2,"['Safe', 'Unsafe']","['SafeRow', 'UnsafeRow']"
Safety,force_bgz is unsafe,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2600:13,unsafe,unsafe,13,https://hail.is,https://github.com/hail-is/hail/issues/2600,1,['unsafe'],['unsafe']
Safety,fun$collect$1$$anonfun$13.apply(RDD.scala:945); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2101); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2101); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90); 	at org.apache.spark.scheduler.Task.run(Task.scala:121); 	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:403); 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:409); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1889); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1876); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1876); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2110); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2059); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGSche,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8545:9465,abort,abortStage,9465,https://hail.is,https://github.com/hail-is/hail/issues/8545,1,['abort'],['abortStage']
Safety,fun$collect$1$$anonfun$15.apply(RDD.scala:990); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2101); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2101); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90); 	at org.apache.spark.scheduler.Task.run(Task.scala:123); 	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408); 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1892); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1880); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1879); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1879); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:927); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:927); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:927); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2113); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2062); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGSche,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8469:82292,abort,abortStage,82292,https://hail.is,https://github.com/hail-is/hail/issues/8469,1,['abort'],['abortStage']
Safety,fun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); 	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186); 	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); 	at scala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:186); 	at is.hail.io.vcf.FormatParser$.apply(LoadVCF.scala:470); 	at is.hail.io.vcf.ParseLineContext.getFormatParser(LoadVCF.scala:551); 	at is.hail.io.vcf.LoadVCF$$anonfun$14.apply(LoadVCF.scala:886); 	at is.hail.io.vcf.LoadVCF$$anonfun$14.apply(LoadVCF.scala:869); 	at is.hail.io.vcf.LoadVCF$$anonfun$parseLines$1$$anon$1.hasNext(LoadVCF.scala:737); 	... 34 more. Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1517); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1505); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1504); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1504); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1732); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1687); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGSche,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3467:4884,abort,abortStage,4884,https://hail.is,https://github.com/hail-is/hail/issues/3467,1,['abort'],['abortStage']
Safety,"future_vds); File ""<decorator-gen-1304>"", line 2, in concordance; File ""/tmp/f93de2d1-2d89-43f9-9868-f266eb88a6f1/hail-devel-08a15431a0ef.zip/hail/utils/java.py"", line 155, in handle_py4j; hail.utils.java.FatalError: AssertionError: assertion failed. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 30 in stage 1.0 failed 20 times, most recent failure: Lost task 30.19 in stage 1.0 (TID 4847, lfdev2-sw-f5w2.c.broad-mpg-gnomad.internal): java.lang.AssertionError: assertion failed; 	at scala.Predef$.assert(Predef.scala:156); 	at is.hail.annotations.Region.loadInt(Region.scala:36); 	at is.hail.expr.types.TBinary$.loadLength(TBinary.scala:62); 	at is.hail.annotations.UnsafeRow$.readBinary(UnsafeRow.scala:128); 	at is.hail.annotations.UnsafeRow$.readString(UnsafeRow.scala:139); 	at is.hail.annotations.UnsafeRow$.readAltAllele(UnsafeRow.scala:152); 	at is.hail.annotations.UnsafeRow$.readArrayAltAllele(UnsafeRow.scala:164); 	at is.hail.annotations.UnsafeRow$.read(UnsafeRow.scala:210); 	at is.hail.annotations.UnsafeRow.get(UnsafeRow.scala:257); 	at is.hail.expr.FilterVariants$$anonfun$10.apply(Relational.scala:503); 	at is.hail.expr.FilterVariants$$anonfun$10.apply(Relational.scala:500); 	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:463); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$9$$anon$5.hasNext(OrderedRVD.scala:658); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$9$$anon$5.hasNext(OrderedRVD.scala:658); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$9$$anon$5.hasNext(OrderedRVD.scala:658); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at is.hail.sparkextras.OrderedRDD$$anonfun$apply$5$$anon$2.hasNext(OrderedRDD.scala:194); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at is.hail.sp",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2743:2534,Unsafe,UnsafeRow,2534,https://hail.is,https://github.com/hail-is/hail/issues/2743,1,['Unsafe'],['UnsafeRow']
Safety,"gType,false), StructField(alt,StringType,false)),false),false)), 1, start), IntegerType), ref, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, validateexternaltype(getexternalrowfield(validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 0, variant), StructField(contig,StringType,false), StructField(start,IntegerType,false), StructField(ref,StringType,false), StructField(altAlleles,ArrayType(StructType(StructField(ref,StringType,false), StructField(alt,StringType,false)),false),false)), 2, ref), StringType), true), altAlleles, mapobjects(MapObjects_loopValue8, MapObjects_loopIsNull9, ObjectType(class java.lang.Object), if (isnull(validateexternaltype(lambdavariable(MapObjects_loopValue8, MapObjects_loopIsNull9, ObjectType(class java.lang.Object)), StructField(ref,StringType,false), StructField(alt,StringType,false)))) null else named_struct(ref, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, validateexternaltype(getexternalrowfield(validateexternaltype(lambdavariable(MapObjects_loopValue8, MapObjects_loopIsNull9, ObjectType(class java.lang.Object)), StructField(ref,StringType,false), StructField(alt,StringType,false)), 0, ref), StringType), true), alt, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, validateexternaltype(getexternalrowfield(validateexternaltype(lambdavariable(MapObjects_loopValue8, MapObjects_loopIsNull9, ObjectType(class java.lang.Object)), StructField(ref,StringType,false), StructField(alt,StringType,false)), 1, alt), StringType), true)), validateexternaltype(getexternalrowfield(validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 0, variant), StructField(contig,StringType,false), StructField(start,IntegerType,false), StructField(ref,StringType,false), StructField(altAlleles,ArrayType(StructType(StructField(r",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1260:9356,unsafe,unsafe,9356,https://hail.is,https://github.com/hail-is/hail/issues/1260,1,['unsafe'],['unsafe']
Safety,gateWithPartitionOp$1.apply(RVD.scala:558); 	at is.hail.rvd.RVD$$anonfun$aggregateWithPartitionOp$1.apply(RVD.scala:558); 	at org.apache.spark.SparkContext$$anonfun$33.apply(SparkContext.scala:2125); 	at org.apache.spark.SparkContext$$anonfun$33.apply(SparkContext.scala:2125); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:109); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:344); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1575); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1563); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1562); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1562); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:803); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:803); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:803); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1790); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1745); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1734); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.ap,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5846:6434,abort,abortStage,6434,https://hail.is,https://github.com/hail-is/hail/issues/5846,1,['abort'],['abortStage']
Safety,"github.com/scipy/scipy/commit/6b098c25223e224ff44101f86bbc86efecffe1d9""><code>6b098c2</code></a> TST: optimize.milp: remove problematic timeout/iteration test</li>; <li><a href=""https://github.com/scipy/scipy/commit/24dce9760b87934f1be046ec817c758b0f3952dc""><code>24dce97</code></a> DOC: stats.pearsonr: typo in coeffic<em>i</em>ent (<a href=""https://github-redirect.dependabot.com/scipy/scipy/issues/17153"">#17153</a>)</li>; <li><a href=""https://github.com/scipy/scipy/commit/a6ba7cad3b54c35d2ccb55c595691689004742c1""><code>a6ba7ca</code></a> MAINT: misc 1.9.2 updates</li>; <li><a href=""https://github.com/scipy/scipy/commit/ed9760e60a28b8f13e5644494033e2dab9aafbcd""><code>ed9760e</code></a> MAINT: stats.pearson3: fix ppf for negative skew (<a href=""https://github-redirect.dependabot.com/scipy/scipy/issues/17055"">#17055</a>)</li>; <li><a href=""https://github.com/scipy/scipy/commit/6fb67007dd7105755057f3379fb7ef423eae524e""><code>6fb6700</code></a> FIX: optimize.milp: return feasible solution if available on timeout/node lim...</li>; <li><a href=""https://github.com/scipy/scipy/commit/bcfce27fc061cbde6ac6531799362e0420ea4796""><code>bcfce27</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/scipy/scipy/issues/17132"">#17132</a> from tylerjereddy/treddy_192_backports</li>; <li><a href=""https://github.com/scipy/scipy/commit/2bc973a2c28c4b6b5bea0e288631834fe34b526e""><code>2bc973a</code></a> BLD: set version to 1.9.2.dev0 (and trigger wheel build CI)</li>; <li>Additional commits viewable in <a href=""https://github.com/scipy/scipy/compare/v1.2.1...v1.9.2"">compare view</a></li>; </ul>; </details>; <br />. Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by comm",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12352:2844,timeout,timeout,2844,https://hail.is,https://github.com/hail-is/hail/pull/12352,1,['timeout'],['timeout']
Safety,"gt;</code><em>, <code>[#274](https://github.com/aio-libs/async-timeout/issues/274) &lt;https://github.com/aio-libs/async-timeout/issues/274&gt;</code></em></li>; </ul>; <h1>4.0.1 (2121-11-10)</h1>; <ul>; <li>; <p>Fix regression:</p>; <ol>; <li>; <p>Don't raise TimeoutError from timeout object that doesn't enter into async context; manager</p>; </li>; <li>; <p>Use call_soon() for raising TimeoutError if deadline is reached on entering into; async context manager</p>; </li>; </ol>; <p>(<a href=""https://github-redirect.dependabot.com/aio-libs/async-timeout/issues/258"">#258</a>)</p>; </li>; <li>; <p>Make <code>Timeout</code> class available in <code>__all__</code>.</p>; </li>; </ul>; <h1>4.0.0 (2021-11-01)</h1>; <ul>; <li>; <p>Implemented <code>timeout_at(deadline)</code> (<a href=""https://github-redirect.dependabot.com/aio-libs/async-timeout/issues/117"">#117</a>)</p>; </li>; <li>; <p>Supported <code>timeout.deadline</code> and <code>timeout.expired</code> properties.</p>; </li>; <li>; <p>Dropped <code>timeout.remaining</code> property: it can be calculated as; <code>timeout.deadline - loop.time()</code></p>; </li>; <li>; <p>Dropped <code>timeout.timeout</code> property that returns a relative timeout based on the; timeout object creation time; the absolute <code>timeout.deadline</code> should be used; instead.</p>; </li>; <li>; <p>Added the deadline modification methods: <code>timeout.reject()</code>,; <code>timeout.shift(delay)</code>, <code>timeout.update(deadline)</code>.</p>; </li>; <li>; <p>Deprecated synchronous context manager usage</p>; </li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/aio-libs/async-timeout/commit/5128f7f4ff73b165579006a8336978efaeeca07a""><code>5128f7f</code></a> Fix CHANGES</li>; <li><a href=""https://github.com/aio-libs/async-timeout/commit/18e718a56f9def7dc40bb9ce3a2962a8fb0c883c""><code>18e718a</code></a> Bump to 4.0.2</li>; <li><a href=""https://github.com/aio-libs/async-tim",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11465:3338,timeout,timeout,3338,https://hail.is,https://github.com/hail-is/hail/pull/11465,1,['timeout'],['timeout']
Safety,"h==12.6.0', 'rsa==4.9', 's3transfer==0.10.2', 'scipy==1.11.4', 'shellingham==1.5.4', 'six==1.16.0', 'sortedcontainers==2.4.0', 'tabulate==0.9.0', 'tenacity==8.4.2', 'tornado==6.4.1', 'typer==0.12.3', 'typing-extensions==4.12.2', 'tzdata==2024.1', 'urllib3==1.26.19', 'uvloop==0.19.0', 'wrapt==1.16.0', 'xyzservices==2024.6.0', 'yarl==1.9.4']; Collecting https://github.com/hail-is/jgscm/archive/v0.1.13+hail.zip; WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ConnectTimeoutError(<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7fef979a53d0>, 'Connection to github.com timed out. (connect timeout=15)')': /hail-is/jgscm/archive/v0.1.13+hail.zip; WARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ConnectTimeoutError(<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7fef9797e050>, 'Connection to github.com timed out. (connect timeout=15)')': /hail-is/jgscm/archive/v0.1.13+hail.zip; WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ConnectTimeoutError(<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7fef979ba910>, 'Connection to github.com timed out. (connect timeout=15)')': /hail-is/jgscm/archive/v0.1.13+hail.zip; WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ConnectTimeoutError(<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7fef979cc310>, 'Connection to github.com timed out. (connect timeout=15)')': /hail-is/jgscm/archive/v0.1.13+hail.zip; WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ConnectTimeoutError(<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7fef979cce10>, 'Connection to github.com timed out. (connect timeout=15)')': /hail-is/jgscm/archive/v0.1.13+hail.zip; ERROR: Could not ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14652:3241,timeout,timeout,3241,https://hail.is,https://github.com/hail-is/hail/issues/14652,1,['timeout'],['timeout']
Safety,hail-new importvcf /user/lfran/MacArthur_Merck_Finns.vcf.bgz splitmulti \; write -o /user/aganna/MacArthur_Merck_Finns.vds. Error: (1525 + 59) / 23758]hail: write: caught exception: org.apache.spark.SparkException: Job aborted. [hail.log.txt](https://github.com/broadinstitute/hail/files/222377/hail.log.txt),MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/301:219,abort,aborted,219,https://hail.is,https://github.com/hail-is/hail/issues/301,1,['abort'],['aborted']
Safety,hail::hstring and hstringstream avoid std::string ABI incompatibility,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4422:32,avoid,avoid,32,https://hail.is,https://github.com/hail-is/hail/pull/4422,1,['avoid'],['avoid']
Safety,handle fatal exceptions inside run_command to avoid bad python error msgs,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1096:46,avoid,avoid,46,https://hail.is,https://github.com/hail-is/hail/issues/1096,1,['avoid'],['avoid']
Safety,"hangelog</a>.</em></p>; <blockquote>; <h2>Version 8.1.1</h2>; <p>Released 2022-03-30</p>; <ul>; <li>Fix an issue with decorator typing that caused type checking to; report that a command was not callable. :issue:<code>2227</code></li>; </ul>; <h2>Version 8.1.0</h2>; <p>Released 2022-03-28</p>; <ul>; <li>; <p>Drop support for Python 3.6. :pr:<code>2129</code></p>; </li>; <li>; <p>Remove previously deprecated code. :pr:<code>2130</code></p>; <ul>; <li><code>Group.resultcallback</code> is renamed to <code>result_callback</code>.</li>; <li><code>autocompletion</code> parameter to <code>Command</code> is renamed to; <code>shell_complete</code>.</li>; <li><code>get_terminal_size</code> is removed, use; <code>shutil.get_terminal_size</code> instead.</li>; <li><code>get_os_args</code> is removed, use <code>sys.argv[1:]</code> instead.</li>; </ul>; </li>; <li>; <p>Rely on :pep:<code>538</code> and :pep:<code>540</code> to handle selecting UTF-8 encoding; instead of ASCII. Click's locale encoding detection is removed.; :issue:<code>2198</code></p>; </li>; <li>; <p>Single options boolean flags with <code>show_default=True</code> only show; the default if it is <code>True</code>. :issue:<code>1971</code></p>; </li>; <li>; <p>The <code>command</code> and <code>group</code> decorators can be applied with or; without parentheses. :issue:<code>1359</code></p>; </li>; <li>; <p>The <code>Path</code> type can check whether the target is executable.; :issue:<code>1961</code></p>; </li>; <li>; <p><code>Command.show_default</code> overrides <code>Context.show_default</code>, instead; of the other way around. :issue:<code>1963</code></p>; </li>; <li>; <p>Parameter decorators and <code>@group</code> handles <code>cls=None</code> the same as; not passing <code>cls</code>. <code>@option</code> handles <code>help=None</code> the same as; not passing <code>help</code>. :issue:<code>[#1959](https://github.com/pallets/click/issues/1959)</code></p>; </li>; <li>; <p>A flag option with <code>requir",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11721:2605,detect,detection,2605,https://hail.is,https://github.com/hail-is/hail/pull/11721,1,['detect'],['detection']
Safety,"hangelog</summary>; <p><em>Sourced from <a href=""https://github.com/grantjenks/python-sortedcontainers/blob/master/HISTORY.rst"">sortedcontainers's changelog</a>.</em></p>; <blockquote>; <h2>2.4.0 (2021-05-16)</h2>; <p><strong>API Changes</strong></p>; <ul>; <li>Implement SortedDict methods: <strong>or</strong>, <strong>ror</strong>, and <strong>ior</strong> per PEP 584.</li>; </ul>; <h2>2.3.0 (2020-11-08)</h2>; <p><strong>Bugfixes</strong></p>; <ul>; <li>Make sort order stable when updating with large iterables.</li>; </ul>; <h2>2.2.2 (2020-06-07)</h2>; <p><strong>Miscellaneous</strong></p>; <ul>; <li>Add &quot;small slice&quot; optimization to <code>SortedList.__getitem__</code>.</li>; <li>Silence warning when testing <code>SortedList.iloc</code>.</li>; </ul>; <h2>2.2.1 (2020-06-06)</h2>; <p><strong>Miscellaneous</strong></p>; <ul>; <li>Fix a warning regarding <code>classifiers</code> in setup.py.</li>; </ul>; <h2>2.2.0 (2020-06-06)</h2>; <p><strong>Miscellaneous</strong></p>; <ul>; <li>Change SortedDict to avoid cycles for CPython reference counting.</li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/grantjenks/python-sortedcontainers/commit/a1f52d6713dd2c2713a881d4f4d86ed68ff71cab""><code>a1f52d6</code></a> Bump version to 2.4.0</li>; <li><a href=""https://github.com/grantjenks/python-sortedcontainers/commit/2678a78b6dacbe2352bff7876a26759d84971dac""><code>2678a78</code></a> Implement SortedDict methods: <strong>or</strong>, <strong>ror</strong>, and <strong>ior</strong> (<a href=""https://github-redirect.dependabot.com/grantjenks/python-sortedcontainers/issues/171"">#171</a>)</li>; <li><a href=""https://github.com/grantjenks/python-sortedcontainers/commit/9887989b21fc21fe572e0b4c30a3f3aa1eabbdca""><code>9887989</code></a> Bump version to 2.3.0</li>; <li><a href=""https://github.com/grantjenks/python-sortedcontainers/commit/da6d0d034822f66966e4a84a3a1e2f37cc83e3b0""><code>da6d0d0</code></a> Remove unneeded &",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11476:1147,avoid,avoid,1147,https://hail.is,https://github.com/hail-is/hail/pull/11476,1,['avoid'],['avoid']
Safety,have Scala tests error if memory leak is detected,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4237:41,detect,detected,41,https://hail.is,https://github.com/hail-is/hail/pull/4237,1,['detect'],['detected']
Safety,"he entire output in memory which is likely to cause OOMs. For reasons that are not entirely clear to me, sometimes these OOMs get muffled by our system and instead lead to non-termination. I vaguely remember this happening before with `using`. I suspect there is something somewhat subtle wrong with that method, but I am not certain. Anyway, there are four big changes here:; 1. Do not buffer the entire request body in memory when writing to memory.; 2. Because of (1) we have to pull retry behavior all the way up to the top-level where we know how to recreate the body.; 3. Because of (2) it is easier to provide a `write(url)(writerFunction)` style API, which I do here.; 4. Again, because of (2), and because I want to preserve the file-object-like interface, I added a somewhat funky anonymous class which uses a second thread to facilitate the movement of data written into the OutputStream returned by `create` into the OutputStream of the HTTP connection. Point (4) probably bears more explanation. The root issue is the bad Apache HTTP Client interface. Instead of `request` returning an OutputStream, it takes an ""entity"". An entity knows how to write itself into the OutputStream of an HTTP request. This works fine if the ""writer"" code is pased as a function (as in my new `write` method), but that does not work if the control flow looks like:. f = create(...); f.write(...); r.close(). We avoid this limited API by initiating the request in a second thread which will eventually block waiting to receive data from a PipedInputStream. That PipedInputStream produces the data written to a PipedOutputStream. The `create` call returns a positioned OutputStream which just writes data into the PipedOutputStream and handles cleaning up the thread when it is closed. In a multi-core system, network requests should proceed in parallel to the client code. In a single-core system, the written data will buffer until `close` is called which will definitely yield control to the other thread.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12691:1443,avoid,avoid,1443,https://hail.is,https://github.com/hail-is/hail/pull/12691,1,['avoid'],['avoid']
Safety,"he mutation is sufficiently well localized, and this is a common compiler pattern. This touches a lot of lines, but the high level changes are:; * Remove the `refMap` from the `IRParserEnvironment`, and remove all code that modifies the typing environment from the parser. Nodes like `Ref` that need a type from the environment get types set to `null`, to be filled in after parsing.; * Add `annotateTypes` pass to fill in type annotations from the environment. This is currently written in the parser, and always called after parsing. This means for the moment we can only parse type correct IR. But in the future we could move this to a separate stage of the compilation pipeline.; * Move typechecking logic on relational nodes from the constructors to a `typecheck` method, which is called from the `TypeCheck` pass.; * Make the `typ` field on IR nodes consistently lazy (or a def when the type is a child's type without modification). Before we sometimes did this for performance, but it's now required to avoid querying children's types during construction.; * Make types mutable on `AggSignature` and `ComparisonOp`, so they can be filled in after parsing.; * Ensure that the structure in `Binds.scala` satisfies the following invariant: to construct the typing environment of child `i`, we only need the types of children with index less than `i`. This was almost always satisfied already, and allows us to use the generic binds infrastucture in the pass to annotate types (where when visiting child `i`, we can only query types of already visited children).; * Change the text representation of `TailLoop`/`Recur` to move the explicit type annotation from `Recur` to `TailLoop`. This is necessary to comply with the previous point. It's also consistent with `Ref`, where types of references are inferred from the environment.; * Add explicit types in the text representation of `TableFilterIntervals` and `MatrixFilterIntervals`, where the types were needed during parsing and we can no longe",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13990:3041,avoid,avoid,3041,https://hail.is,https://github.com/hail-is/hail/pull/13990,1,['avoid'],['avoid']
Safety,he.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:803); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); at org.apache.spark.scheduler.Task.run(Task.scala:86); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.s,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1275:3943,abort,abortStage,3943,https://hail.is,https://github.com/hail-is/hail/issues/1275,1,['abort'],['abortStage']
Safety,"headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw); 785 e = ProtocolError(""Connection aborted."", e); --> 787 retries = retries.increment(; 788 method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]; 789 ); 790 retries.sleep(). File /opt/conda/lib/python3.10/site-packages/urllib3/util/retry.py:550, in Retry.increment(self, method, url, response, error, _pool, _stacktrace); 549 if read is False or not self._is_method_retryable(method):; --> 550 raise six.reraise(type(error), error, _stacktrace); 551 elif read is not None:. File /opt/conda/lib/python3.10/site-packages/urllib3/packages/six.py:769, in reraise(tp, value, tb); 768 if value.__traceback__ is not tb:; --> 769 raise value.with_traceback(tb); 770 raise value. File /opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py:703, in HTTPConnectionPool.urlopen(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw); 702 # Make the request on the httplib connection object.; --> 703 httplib_response = self._make_request(; 704 conn,; 705 method,; 706 url,; 707 timeout=timeout_obj,; 708 body=body,; 709 headers=headers,; 710 chunked=chunked,; 711 ); 713 # If we're going to release the connection in ``finally:``, then; 714 # the response doesn't need to know about the connection. Otherwise; 715 # it will also try to release it and we'll have a double-release; 716 # mess. File /opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py:449, in HTTPConnectionPool._make_request(self, conn, method, url, timeout, chunked, **httplib_request_kw); 445 except BaseException as e:; 446 # Remove the TypeError from the exception chain in; 447 # Python 3 (including for exceptions like SystemExit).; 448 # Otherwise it looks like a bug in the code.; --> 449 six.raise_from(e, None); 450 except (SocketTimeout, BaseSSLError, SocketError) as e:. File <string>:3, in raise",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13960:7841,timeout,timeout,7841,https://hail.is,https://github.com/hail-is/hail/issues/13960,1,['timeout'],['timeout']
Safety,"hed Pygments-2.8.1-py3-none-any.whl (983 kB); Collecting backcall; Using cached backcall-0.2.0-py2.py3-none-any.whl (11 kB); Collecting parso<0.9.0,>=0.8.0; Using cached parso-0.8.1-py2.py3-none-any.whl (93 kB); Collecting ptyprocess>=0.5; Using cached ptyprocess-0.7.0-py2.py3-none-any.whl (13 kB); Collecting wcwidth; Using cached wcwidth-0.2.5-py2.py3-none-any.whl (30 kB); Collecting ipython-genutils; Using cached ipython_genutils-0.2.0-py2.py3-none-any.whl (26 kB); Collecting requests-oauthlib>=0.7.0; Using cached requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB); Collecting oauthlib>=3.0.0; Using cached oauthlib-3.1.0-py2.py3-none-any.whl (147 kB); Installing collected packages: six, pyasn1, urllib3, rsa, pyparsing, pyasn1-modules, protobuf, idna, chardet, certifi, cachetools, requests, pytz, packaging, oauthlib, multidict, googleapis-common-protos, google-auth, yarl, typing-extensions, requests-oauthlib, MarkupSafe, google-api-core, attrs, async-timeout, wrapt, wcwidth, tornado, PyYAML, python-dateutil, py4j, ptyprocess, pillow, parso, numpy, Jinja2, ipython-genutils, google-resumable-media, google-cloud-core, google-auth-oauthlib, fsspec, decorator, aiohttp, traitlets, tqdm, tabulate, scipy, python-json-logger, pyspark, PyJWT, pygments, prompt-toolkit, pickleshare, pexpect, parsimonious, pandas, nest-asyncio, jedi, hurry.filesize, humanize, google-cloud-storage, gcsfs, dill, Deprecated, bokeh, backcall, asyncinit, aiohttp-session, ipython, hail; Successfully installed Deprecated-1.2.12 Jinja2-2.11.3 MarkupSafe-1.1.1 PyJWT-2.0.1 PyYAML-5.4.1 aiohttp-3.7.4 aiohttp-session-2.7.0 async-timeout-3.0.1 asyncinit-0.2.4 attrs-20.3.0 backcall-0.2.0 bokeh-1.4.0 cachetools-4.2.1 certifi-2020.12.5 chardet-3.0.4 decorator-4.4.2 dill-0.3.3 fsspec-0.8.7 gcsfs-0.7.2 google-api-core-1.26.1 google-auth-1.27.1 google-auth-oauthlib-0.4.3 google-cloud-core-1.6.0 google-cloud-storage-1.25.0 google-resumable-media-0.5.1 googleapis-common-protos-1.53.0 hail-0.2.64 humanize-1.0.0 hur",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/10197:7745,timeout,timeout,7745,https://hail.is,https://github.com/hail-is/hail/issues/10197,1,['timeout'],['timeout']
Safety,"her aggregated_*_resources tables did not change. I spot checked this was correct in my test database. To do the complete audit during the actual migration would take more time. I made sure all the inserts were idempotent. Please double check this. The inserts use a temporary table with an isolation level of read committed. The reason for this is because `INSERT INTO ... SELECT` locks the next gap lock if the isolation level is not read committed. Maybe what I did is overkill and it's no longer a problem with the new burn in period. https://dev.mysql.com/doc/refman/8.0/en/innodb-locks-set.html I'd be interested to hear @danking feedback on what the best query here is to allow parallelism. There are ~30 million attempts that need to be processed for hail-vdc (~60% of the attempts). This will add ~20Gi to the existing database. I use 4 cores to get this migration to be ~3 hours, so we will want to **upgrade the database to 8 cores** while this migration is running. The inserting takes about 2 hours and the audit is 45 minutes or so. For the Australians, I think this script should be a no-op because I believe they started their instance after the billing changes went in around May/June 2020. The main thing to look out for is whether I got the interval queries correct! For example:. ```python3; where_cond = 'WHERE (attempts.batch_id > %s OR ' \; '(attempts.batch_id = %s AND attempts.job_id > %s) OR ' \; '(attempts.batch_id = %s AND attempts.job_id = %s AND attempts.attempt_id >= %s)) ' \; 'AND (attempts.batch_id < %s OR ' \; '(attempts.batch_id = %s AND attempts.job_id < %s) OR ' \; '(attempts.batch_id = %s AND attempts.job_id = %s AND attempts.attempt_id < %s))'; ```. The last thing is to do a sanity check and triple check the new database trigger won't run anything for format version < 3. Also, a sanity check that format_version < 3 is the right cutoff. I got this by looking at the `BatchFormatVersion` class where we have the cost function depending on format version.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11990:3826,sanity check,sanity check,3826,https://hail.is,https://github.com/hail-is/hail/pull/11990,2,['sanity check'],['sanity check']
Safety,her.java:331); at java.lang.ClassLoader.loadClass(ClassLoader.java:357); at java.lang.Class.forName0(Native Method); at java.lang.Class.forName(Class.java:348); at java.io.ObjectInputStream.resolveClass(ObjectInputStream.java:677); at java.io.ObjectInputStream.readNonProxyDesc(ObjectInputStream.java:1819); at java.io.ObjectInputStream.readClassDesc(ObjectInputStream.java:1713); at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1986); at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535); at java.io.ObjectInputStream.readObject(ObjectInputStream.java:422); at com.esotericsoftware.kryo.serializers.JavaSerializer.read(JavaSerializer.java:63); ... 25 more. Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1658); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.s,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3342:6074,abort,abortStage,6074,https://hail.is,https://github.com/hail-is/hail/issues/3342,1,['abort'],['abortStage']
Safety,"hes-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""4c874ad7-563f-49cd-9773-8b9f1095e36c"",""prPublicId"":""4c874ad7-563f-49cd-9773-8b9f1095e36c"",""dependencies"":[{""name"":""certifi"",""from"":""2021.10.8"",""to"":""2023.7.22""},{""name"":""cryptography"",""from"":""3.3.2"",""to"":""41.0.6""},{""name"":""requests"",""from"":""2.27.1"",""to"":""2.31.0""}],""packageManager"":""pip"",""projectPublicId"":""c1c98f6a-57c6-4ecc-a329-3b744cab74bd"",""projectUrl"":""https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-CERTIFI-3164749"",""SNYK-PYTHON-CERTIFI-5805047"",""SNYK-PYTHON-CRYPTOGRAPHY-3172287"",""SNYK-PYTHON-CRYPTOGRAPHY-3314966"",""SNYK-PYTHON-CRYPTOGRAPHY-3315324"",""SNYK-PYTHON-CRYPTOGRAPHY-3315328"",""SNYK-PYTHON-CRYPTOGRAPHY-3315331"",""SNYK-PYTHON-CRYPTOGRAPHY-3315452"",""SNYK-PYTHON-CRYPTOGRAPHY-3315972"",""SNYK-PYTHON-CRYPTOGRAPHY-3315975"",""SNYK-PYTHON-CRYPTOGRAPHY-3316038"",""SNYK-PYTHON-CRYPTOGRAPHY-3316211"",""SNYK-PYTHON-CRYPTOGRAPHY-5663682"",""SNYK-PYTHON-CRYPTOGRAPHY-5777683"",""SNYK-PYTHON-CRYPTOGRAPHY-5813745"",""SNYK-PYTHON-CRYPTOGRAPHY-5813746"",""SNYK-PYTHON-CRYPTOGRAPHY-5813750"",""SNYK-PYTHON-CRYPTOGRAPHY-5914629"",""SNYK-PYTHON-CRYPTOGRAPHY-6036192"",""SNYK-PYTHON-CRYPTOGRAPHY-6092044"",""SNYK-PYTHON-REQUESTS-5595532""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""pr-warning-shown"",""priorityScore""],""priorityScoreList"":[554,704,509,454,616,584,479,509,509,509,509,589,509,691,399,479,399,539,479,616,519],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Use After Free](https://learn.snyk.io/lesson/use-after-free/?loc&#x3D;fix-pr); 🦉 [Access of Resource Using Incompatible Type (&#x27;Type Confusion&#x27;)](https://learn.snyk.io/lesson/type-confusion/?loc&#x3D;fix-pr); 🦉 [Denial of Service (DoS)](https://learn.snyk.io/lesson/redos/?loc&#x3D;fix-pr); 🦉 [More lessons are available in Snyk Learn](https://learn.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14148:11770,remediat,remediationStrategy,11770,https://hail.is,https://github.com/hail-is/hail/pull/14148,1,['remediat'],['remediationStrategy']
Safety,"his because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiIxZDhjNDI0MS1hOTllLTQwZDktOTM5Yy0zZWMzM2NkNTI0ZjkiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjFkOGM0MjQxLWE5OWUtNDBkOS05MzljLTNlYzMzY2Q1MjRmOSJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""1d8c4241-a99e-40d9-939c-3ec33cd524f9"",""prPublicId"":""1d8c4241-a99e-40d9-939c-3ec33cd524f9"",""dependencies"":[{""name"":""cryptography"",""from"":""41.0.7"",""to"":""42.0.2""}],""packageManager"":""pip"",""projectPublicId"":""c1c98f6a-57c6-4ecc-a329-3b744cab74bd"",""projectUrl"":""https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-CRYPTOGRAPHY-6149518"",""SNYK-PYTHON-CRYPTOGRAPHY-6157248""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""pr-warning-shown"",""priorityScore""],""priorityScoreList"":[581,581],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Use of a Broken or Risky Cryptographic Algorithm](https://learn.snyk.io/lesson/insecure-hash/?loc&#x3D;fix-pr); 🦉 [Uncontrolled Resource Consumption (&#x27;Resource Exhaustion&#x27;)](https://learn.snyk.io/lesson/redos/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14230:3906,remediat,remediationStrategy,3906,https://hail.is,https://github.com/hail-is/hail/pull/14230,2,"['Risk', 'remediat']","['Risky', 'remediationStrategy']"
Safety,"his cluster for our larger dataset. ```; [Stage 10:=====> (69 + 656) / 729]; raise err; File ""/opt/conda/default/lib/python3.8/site-packages/hail/backend/py4j_backend.py"", line 98, in execute; result_tuple = self._jbackend.executeEncode(jir, stream_codec, timed); File ""/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py"", line 1304, in __call__; File ""/opt/conda/default/lib/python3.8/site-packages/hail/backend/py4j_backend.py"", line 31, in deco; raise fatal_error_from_java_error_triplet(deepest, full, error_id) from None; hail.utils.java.FatalError: SparkException: Job aborted due to stage failure: Task 582 in stage 10.0 failed 20 times, most recent failure: Lost task 582.19 in stage 10.0 (TID 461381) (cluster-w-144.c.project-.internal executor 3568): ExecutorLostFailure (executor 3568 exited caused by one of the running tasks) Reason: Executor heartbeat timed out after 128936 ms; Driver stacktrace:. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 582 in stage 10.0 failed 20 times, most recent failure: Lost task 582.19 in stage 10.0 (TID 461381) (cluster-w-144.c.gbsc-project.internal executor 3568): ExecutorLostFailure (executor 3568 exited caused by one of the running tasks) Reason: Executor heartbeat timed out after 128936 ms; Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2304); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2253); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2252); 	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62); 	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2252); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12290:1775,abort,aborted,1775,https://hail.is,https://github.com/hail-is/hail/issues/12290,1,['abort'],['aborted']
Safety,"hod testObjectArray(is.hail.nativecode.NativeCodeSuite). Gradle suite > Gradle test > is.hail.nativecode.NativeCodeSuite.testObjectArray PASSED; Running test: Test method testShuffleAndJoinDoesntMemoryLeak(is.hail.expr.ir.TableIRSuite). Gradle suite > Gradle test > is.hail.expr.ir.TableIRSuite.testShuffleAndJoinDoesntMemoryLeak PASSED; Running test: Test method testBufferWriteReadDoubles(is.hail.annotations.UnsafeSuite). Gradle suite > Gradle test > is.hail.annotations.UnsafeSuite.testBufferWriteReadDoubles PASSED; Running test: Test method testCodec(is.hail.annotations.UnsafeSuite); #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x00007fe4a85738ec, pid=23790, tid=0x00007fe48cdfa700; #; # JRE version: OpenJDK Runtime Environment (8.0_181-b13) (build 1.8.0_181-8u181-b13-0ubuntu0.18.04.1-b13); # Java VM: OpenJDK 64-Bit Server VM (25.181-b13 mixed mode linux-amd64 compressed oops); # Problematic frame:; # J 9008 C1 is.hail.annotations.UnsafeRow$.readBinary(Lis/hail/annotations/Region;J)[B (39 bytes) @ 0x00007fe4a85738ec [0x00007fe4a8573600+0x2ec]; #; # Core dump written. Default location: /home/BROAD.MIT.EDU/cvittal/src/hail/hail/core or core.23790 (max size 9223372036854775 kB). To ensure a full core dump, try ""ulimit -c unlimited"" before starting Java again; #; # An error report file with more information is saved as:; # /home/BROAD.MIT.EDU/cvittal/src/hail/hail/hs_err_pid23790.log; Compiled method (c1) 33969 8500 2 is.hail.annotations.UnsafeRow$::readLocus (78 bytes); total in heap [0x00007fe4a8b81810,0x00007fe4a8b83430] = 7200; relocation [0x00007fe4a8b81938,0x00007fe4a8b81a98] = 352; main code [0x00007fe4a8b81aa0,0x00007fe4a8b82100] = 1632; stub code [0x00007fe4a8b82100,0x00007fe4a8b822b8] = 440; oops [0x00007fe4a8b822b8,0x00007fe4a8b822c0] = 8; metadata [0x00007fe4a8b822c0,0x00007fe4a8b82338] = 120; scopes data [0x00007fe4a8b82338,0x00007fe4a8b82f30] = 3064; scopes pcs [0x00007fe4a8b82f30,0x00007fe4a8b83340] = 1040;",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4718:10040,Unsafe,UnsafeRow,10040,https://hail.is,https://github.com/hail-is/hail/issues/4718,1,['Unsafe'],['UnsafeRow']
Safety,"hould not impact the average user, but extremely old; versions of packaging utilities may have issues with the new packaging format.</li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/psf/requests/commit/d6ebc4a2f1f68b7e355fb7e4dd5ffc0845547f9f""><code>d6ebc4a</code></a> v2.32.0</li>; <li><a href=""https://github.com/psf/requests/commit/9a40d1277807f0a4f26c9a37eea8ec90faa8aadc""><code>9a40d12</code></a> Avoid reloading root certificates to improve concurrent performance (<a href=""https://redirect.github.com/psf/requests/issues/6667"">#6667</a>)</li>; <li><a href=""https://github.com/psf/requests/commit/0c030f78d24f29a459dbf39b28b4cc765e2153d7""><code>0c030f7</code></a> Merge pull request <a href=""https://redirect.github.com/psf/requests/issues/6702"">#6702</a> from nateprewitt/no_char_detection</li>; <li><a href=""https://github.com/psf/requests/commit/555b870eb19d497ddb67042645420083ec8efb02""><code>555b870</code></a> Allow character detection dependencies to be optional in post-packaging steps</li>; <li><a href=""https://github.com/psf/requests/commit/d6dded3f00afcf56a7e866cb0732799045301eb0""><code>d6dded3</code></a> Merge pull request <a href=""https://redirect.github.com/psf/requests/issues/6700"">#6700</a> from franekmagiera/update-redirect-to-invalid-uri-test</li>; <li><a href=""https://github.com/psf/requests/commit/bf24b7d8d17da34be720c19e5978b2d3bf94a53b""><code>bf24b7d</code></a> Use an invalid URI that will not cause httpbin to throw 500</li>; <li><a href=""https://github.com/psf/requests/commit/2d5f54779ad174035c5437b3b3c1146b0eaf60fe""><code>2d5f547</code></a> Pin 3.8 and 3.9 runners back to macos-13 (<a href=""https://redirect.github.com/psf/requests/issues/6688"">#6688</a>)</li>; <li><a href=""https://github.com/psf/requests/commit/f1bb07d39b74d6444e333879f8b8a3d9dd4d2311""><code>f1bb07d</code></a> Merge pull request <a href=""https://redirect.github.com/psf/requests/issues/6687"">#6687</a> from psf/dependabo",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14555:8307,detect,detection,8307,https://hail.is,https://github.com/hail-is/hail/pull/14555,1,['detect'],['detection']
Safety,https://github.com/hail-is/hail/pull/8045 seems to have made some requests to services take obscene amounts of time or timeout. Two recent curls of ci.hail.is took 20s and 35s. Growing node pools leading to out of date hosts rendering a service not accessible:; https://github.com/kubernetes/kubernetes/issues/39423#issuecomment-370478433,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8047:119,timeout,timeout,119,https://hail.is,https://github.com/hail-is/hail/issues/8047,1,['timeout'],['timeout']
Safety,"hub-redirect.dependabot.com/jmoiron/humanize/issues/241"">#241</a>) <a href=""https://github.com/samueljsb""><code>@​samueljsb</code></a></li>; </ul>; <h2>3.14.0</h2>; <h2>Changed</h2>; <ul>; <li>Don't deprecate <code>time.Unit</code> enumeration (<a href=""https://github-redirect.dependabot.com/jmoiron/humanize/issues/252"">#252</a>) <a href=""https://github.com/hugovk""><code>@​hugovk</code></a></li>; <li>Use <code>humanize.intcomma</code> to format years in <code>time</code> module (<a href=""https://github-redirect.dependabot.com/jmoiron/humanize/issues/246"">#246</a>) <a href=""https://github.com/carterbox""><code>@​carterbox</code></a></li>; </ul>; <h2>Deprecated</h2>; <ul>; <li>Deprecate <code>when</code> parameter of <code>naturaldelta</code> (<a href=""https://github-redirect.dependabot.com/jmoiron/humanize/issues/248"">#248</a>) <a href=""https://github.com/carterbox""><code>@​carterbox</code></a></li>; </ul>; <h2>3.13.1</h2>; <h2>Fixed</h2>; <ul>; <li>Temporarily comment out to avoid warning during <code>import humanize</code> (<a href=""https://github-redirect.dependabot.com/jmoiron/humanize/issues/243"">#243</a>) <a href=""https://github.com/hugovk""><code>@​hugovk</code></a></li>; </ul>; <h2>3.13.0</h2>; <h2>Added</h2>; <ul>; <li>Add da_DK language (<a href=""https://github-redirect.dependabot.com/jmoiron/humanize/issues/238"">#238</a>) <a href=""https://github.com/dejurin""><code>@​dejurin</code></a></li>; <li>Fix and add Russian and Ukrainian words (<a href=""https://github-redirect.dependabot.com/jmoiron/humanize/issues/235"">#235</a>) <a href=""https://github.com/dejurin""><code>@​dejurin</code></a></li>; <li>Add missing strings for Polish translation (<a href=""https://github-redirect.dependabot.com/jmoiron/humanize/issues/182"">#182</a>) <a href=""https://github.com/kpostekk""><code>@​kpostekk</code></a></li>; <li>Add Traditional Chinese (zh-HK) (<a href=""https://github-redirect.dependabot.com/jmoiron/humanize/issues/233"">#233</a>) <a href=""https://github.com/edwardmfho""><code>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11517:2019,avoid,avoid,2019,https://hail.is,https://github.com/hail-is/hail/pull/11517,2,['avoid'],['avoid']
Safety,huffledRDD.compute(ShuffledRDD.scala:105); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1517); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1505); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1504); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1504); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1732); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1687); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1676); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2029); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2050); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2069); at org,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4780:10186,abort,abortStage,10186,https://hail.is,https://github.com/hail-is/hail/issues/4780,1,['abort'],['abortStage']
Safety,"i>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/PyCQA/astroid/commit/c313631bca83f7b6eb7dd8990aa702b85eb22d64""><code>c313631</code></a> Bump astroid to 2.12.5, update changelog</li>; <li><a href=""https://github.com/PyCQA/astroid/commit/8852ecda407598636fcd760877e5a093148e8e67""><code>8852ecd</code></a> Prevent first-party imports from being resolved to <code>site-packages</code> (<a href=""https://github-redirect.dependabot.com/PyCQA/astroid/issues/1756"">#1756</a>)</li>; <li><a href=""https://github.com/PyCQA/astroid/commit/92529b5eafc42e92b9dc18377532fda2d9cdfc49""><code>92529b5</code></a> Add a comment about missing <code>__spec__</code> on <code>PyPy</code> (<a href=""https://github-redirect.dependabot.com/PyCQA/astroid/issues/1758"">#1758</a>)</li>; <li><a href=""https://github.com/PyCQA/astroid/commit/ef55fd3cd477ebe3c693b4b9eb15f52b56449b55""><code>ef55fd3</code></a> Fix namespace package detection for frozen stdlib modules on PyPy (<a href=""https://github-redirect.dependabot.com/PyCQA/astroid/issues/1757"">#1757</a>)</li>; <li><a href=""https://github.com/PyCQA/astroid/commit/7fba17d69b033a5aace1d7b1aed7887a8ef2c4b4""><code>7fba17d</code></a> Bump astroid to 2.12.4, update changelog</li>; <li><a href=""https://github.com/PyCQA/astroid/commit/d463bd2de2c4565e7e630bc61aa4685acc1f5183""><code>d463bd2</code></a> Fix crash involving non-standard type comments (<a href=""https://github-redirect.dependabot.com/PyCQA/astroid/issues/1753"">#1753</a>)</li>; <li><a href=""https://github.com/PyCQA/astroid/commit/060cefa51884d176fdacf1b8ea18cee3ae0b0948""><code>060cefa</code></a> Bump astroid to 2.12.3, update changelog</li>; <li><a href=""https://github.com/PyCQA/astroid/commit/d0ecb2a58df1eae6c78c3dd39b5399d7f7a59ea3""><code>d0ecb2a</code></a> Remove str instance in model of BaseException.attrs (<a href=""https://github-redirect.dependabot.com/PyCQA/astroid/issues/1749"">#17",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12151:3462,detect,detection,3462,https://hail.is,https://github.com/hail-is/hail/pull/12151,1,['detect'],['detection']
Safety,"i>; <li>api-change:<code>logs</code>: [<code>botocore</code>] Updates to support CloudWatch Logs data protection and CloudWatch cross-account observability</li>; <li>api-change:<code>mgn</code>: [<code>botocore</code>] This release adds support for Application and Wave management. We also now support custom post-launch actions.</li>; <li>api-change:<code>oam</code>: [<code>botocore</code>] Amazon CloudWatch Observability Access Manager is a new service that allows configuration of the CloudWatch cross-account observability feature.</li>; <li>api-change:<code>organizations</code>: [<code>botocore</code>] This release introduces delegated administrator for AWS Organizations, a new feature to help you delegate the management of your Organizations policies, enabling you to govern your AWS organization in a decentralized way. You can now allow member accounts to manage Organizations policies.</li>; <li>api-change:<code>rds</code>: [<code>botocore</code>] This release enables new Aurora and RDS feature called Blue/Green Deployments that makes updates to databases safer, simpler and faster.</li>; <li>api-change:<code>textract</code>: [<code>botocore</code>] This release adds support for classifying and splitting lending documents by type, and extracting information by using the Analyze Lending APIs. This release also includes support for summarized information of the processed lending document package, in addition to per document results.</li>; <li>api-change:<code>transcribe</code>: [<code>botocore</code>] This release adds support for 'inputType' for post-call and real-time (streaming) Call Analytics within Amazon Transcribe.</li>; </ul>; <h1>1.26.16</h1>; <ul>; <li>api-change:<code>grafana</code>: [<code>botocore</code>] This release includes support for configuring a Grafana workspace to connect to a datasource within a VPC as well as new APIs for configuring Grafana settings.</li>; <li>api-change:<code>rbin</code>: [<code>botocore</code>] This release adds support for",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12507:3500,safe,safer,3500,https://hail.is,https://github.com/hail-is/hail/pull/12507,1,['safe'],['safer']
Safety,"i><a href=""https://redirect.github.com/numpy/numpy/pull/23030"">#23030</a>: DOC: Add version added information for the strict parameter in...</li>; <li><a href=""https://redirect.github.com/numpy/numpy/pull/23031"">#23031</a>: BUG: use <code>_Alignof</code> rather than <code>offsetof()</code> on most compilers</li>; <li><a href=""https://redirect.github.com/numpy/numpy/pull/23147"">#23147</a>: BUG: Fix for npyv__trunc_s32_f32 (VXE)</li>; <li><a href=""https://redirect.github.com/numpy/numpy/pull/23148"">#23148</a>: BUG: Fix integer / float scalar promotion</li>; <li><a href=""https://redirect.github.com/numpy/numpy/pull/23149"">#23149</a>: BUG: Add missing &lt;type_traits&gt; header.</li>; <li><a href=""https://redirect.github.com/numpy/numpy/pull/23150"">#23150</a>: TYP, MAINT: Add a missing explicit <code>Any</code> parameter to the <code>npt.ArrayLike</code>...</li>; <li><a href=""https://redirect.github.com/numpy/numpy/pull/23161"">#23161</a>: BLD: remove redundant definition of npy_nextafter [wheel build]</li>; </ul>; <h2>Checksums</h2>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/numpy/numpy/commit/85f38ab180ece5290f64e8ddbd9cf06ad8fa4a5e""><code>85f38ab</code></a> Merge pull request <a href=""https://redirect.github.com/numpy/numpy/issues/23159"">#23159</a> from charris/prepare-1.24.2-release</li>; <li><a href=""https://github.com/numpy/numpy/commit/124252537f526a059b6a5ee3ac1e3bf1442bbc13""><code>1242525</code></a> REL: Prepare for the NumPy 1.24.2 release</li>; <li><a href=""https://github.com/numpy/numpy/commit/de0ee415e45b09c86d1ddc04f51c11192b1e2fe6""><code>de0ee41</code></a> Merge pull request <a href=""https://redirect.github.com/numpy/numpy/issues/23161"">#23161</a> from mattip/npy_nextafter</li>; <li><a href=""https://github.com/numpy/numpy/commit/ed09037473581908f6b52ecc3cabc82a414e2a54""><code>ed09037</code></a> BLD: remove redundant definition of npy_nextafter [w",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12898:3494,redund,redundant,3494,https://hail.is,https://github.com/hail-is/hail/pull/12898,1,['redund'],['redundant']
Safety,"i>Added CEL runtime cost calculation into CustomerResource validation. CustomerResource validation will fail if runtime cost exceeds the budget. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/108482"">kubernetes/kubernetes#108482</a>, <a href=""https://github.com/cici37""><code>@​cici37</code></a>)</li>; <li>Added a new metric <code>webhook_fail_open_count</code> to monitor webhooks that fail to open. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/107171"">kubernetes/kubernetes#107171</a>, <a href=""https://github.com/ltagliamonte-dd""><code>@​ltagliamonte-dd</code></a>)</li>; <li>Adds a new Status subresource in Network Policy objects (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/107963"">kubernetes/kubernetes#107963</a>, <a href=""https://github.com/rikatz""><code>@​rikatz</code></a>)</li>; <li>Adds support for <code>InterfaceNamePrefix</code> and <code>BridgeInterface</code> as arguments to <code>--detect-local-mode</code> option and also introduces a new optional <code>--pod-interface-name-prefix</code> and <code>--pod-bridge-interface</code> flags to kube-proxy. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/95400"">kubernetes/kubernetes#95400</a>, <a href=""https://github.com/tssurya""><code>@​tssurya</code></a>)</li>; <li>CEL CRD validation expressions may now reference existing object state using the identifier <code>oldSelf</code>. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/108073"">kubernetes/kubernetes#108073</a>, <a href=""https://github.com/benluddy""><code>@​benluddy</code></a>)</li>; <li>CRD deep copies should no longer contain shallow copies of <code>JSONSchemaProps.XValidations</code>. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/107956"">kubernetes/kubernetes#107956</a>, <a href=""https://github.com/benluddy""><code>@​benluddy</code></a>)</li>; <li>CRD writes will generate validation erro",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12196:2674,detect,detect-local-mode,2674,https://hail.is,https://github.com/hail-is/hail/pull/12196,1,['detect'],['detect-local-mode']
Safety,"i>Remove unnecessary parentheses from <code>except</code> statements (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2939"">#2939</a>)</li>; <li>Remove unnecessary parentheses from tuple unpacking in <code>for</code> loops (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2945"">#2945</a>)</li>; <li>Avoid magic-trailing-comma in single-element subscripts (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2942"">#2942</a>)</li>; </ul>; <h3>Configuration</h3>; <ul>; <li>Do not format <code>__pypackages__</code> directories by default (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2836"">#2836</a>)</li>; <li>Add support for specifying stable version with <code>--required-version</code> (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2832"">#2832</a>).</li>; <li>Avoid crashing when the user has no homedir (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2814"">#2814</a>)</li>; <li>Avoid crashing when md5 is not available (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2905"">#2905</a>)</li>; <li>Fix handling of directory junctions on Windows (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2904"">#2904</a>)</li>; </ul>; <h3>Documentation</h3>; <ul>; <li>Update pylint config documentation (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2931"">#2931</a>)</li>; </ul>; <h3>Integrations</h3>; <ul>; <li>Move test to disable plugin in Vim/Neovim, which speeds up loading (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2896"">#2896</a>)</li>; </ul>; <h3>Output</h3>; <ul>; <li>In verbose, mode, log when <em>Black</em> is using user-level config (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2861"">#2861</a>)</li>; </ul>; <h3>Packaging</h3>; <ul>; <li>Fix Black to work with Click 8.1.0 (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2966"">#2966</a>)</li>; <li>On Python 3.11 and newer, ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11696:1436,Avoid,Avoid,1436,https://hail.is,https://github.com/hail-is/hail/pull/11696,2,['Avoid'],['Avoid']
Safety,"ice] slightly more useful error message when socket dies; - [ ] (@tpoterba) f79c4023cf [shuffler] if we have an ExecuteContext, use it; - [x] (@daniel-goldstein,fyi: @tpoterba) 259f70dd25 [query-service] JSON Logging; - [ ] (@catoverdrive) f5c3ffcbd1 [query-service] pervasively retry all idempotent operations; - [ ] (@tpoterba) 507db4b468 [hail] fix using; - [x] (@jigold) c32a253bb9 [query] when testing, ensure our thread has an event loop; - [ ] (@tpoterba) 110469c2da [query][lir] avoid dumping massive classes onto stderr; - [ ] (@tpoterba) e4aa1c15fe [query] do not print misleading log in RegionPool.finalizer; - [x] (trivial) 33eab9a80e [query-service] better logging information; - [ ] (@catoverdrive) e358e8feeb [query-service] remove race conditions in user management; - [ ] (@tpoterba) b60cb2bae5 [lir] make LIR genName thread-safe; - [ ] (@catoverdrive) 2d82e5faf5 [query-service] send a token for job identifiability; - [x] (@daniel-goldstein) fd78caedcb [query-service] reduce image size by ~2GB; - [ ] (@catoverdrive) 00d1840421 [query-service] retry CLOSE, CLOSED (i.e. connection dropped); - [ ] (@catoverdrive) c985d3e3de [query-service] remove old test code; - [ ] (@catoverdrive) 0a5dc8c651 [query-service] all operations are idempotent; - [ ] (@cseed) 6d02d173fa [make] fix config.mk; - [x] (@daniel-goldstein) d21df54e63 [devbin] teach devbin/functions.py about multiple containers; - [x] (@jigold) 38878f7874 [batch] remove batch_worker_image false dependency on service_base_image; - [x] (@daniel-goldstein) f03defab3d [java-services] avoid NPEs in isTransientError; - [x] (@jigold) e535bdc00d [dependencies] upgrade gcsfs to 0.7.2 to fix GoogleFS rmtree issue; - [x] (@cseed) 743b5ba62f [query-service] enable auto-scaling for PR and dev deploy; - [ ] (@cseed) 6a52d45f6f [query-service] retry EndOfStream errors from java; - [ ] (@jigold) 5853a0bec4 [batch] remove restrictions on PR and dev batch pools; - [ ] (@cseed) 035b19642a [query-service] resolve last two issues",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10100:3861,avoid,avoid,3861,https://hail.is,https://github.com/hail-is/hail/pull/10100,1,['avoid'],['avoid']
Safety,"ies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI3YjUwZjkzNy0zZjY4LTRkZjItYjliMC0zZjRiYzUyNmIwNWIiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjdiNTBmOTM3LTNmNjgtNGRmMi1iOWIwLTNmNGJjNTI2YjA1YiJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/fa47fca0-549b-41a3-8bf7-bcda4ca9a617?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/fa47fca0-549b-41a3-8bf7-bcda4ca9a617?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""7b50f937-3f68-4df2-b9b0-3f4bc526b05b"",""prPublicId"":""7b50f937-3f68-4df2-b9b0-3f4bc526b05b"",""dependencies"":[{""name"":""tornado"",""from"":""6.2"",""to"":""6.3.3""}],""packageManager"":""pip"",""projectPublicId"":""fa47fca0-549b-41a3-8bf7-bcda4ca9a617"",""projectUrl"":""https://app.snyk.io/org/danking/project/fa47fca0-549b-41a3-8bf7-bcda4ca9a617?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-TORNADO-5537286"",""SNYK-PYTHON-TORNADO-5840803"",""SNYK-PYTHON-TORNADO-6041512""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""pr-warning-shown"",""priorityScore""],""priorityScoreList"":[384,494,539],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Open Redirect](https://learn.snyk.io/lesson/open-redirect/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14244:4150,remediat,remediationStrategy,4150,https://hail.is,https://github.com/hail-is/hail/pull/14244,1,['remediat'],['remediationStrategy']
Safety,"if the job is cancelled. In addition, the ""Creating"" state is like ""Running"" for some operations in that an attempt has been created and actions are happening on behalf of the user. **Driver Changes:**; - New cancel_creating_jobs event; - Two separate methods to get the pools or job private UI pages and two separate configuration methods. One each for pool and job-private. **JobPrivateInstanceCollection:**; - Has two new loops: an instance creation loop and a scheduling loop; - The instance creation loop does a fair share calculation that is almost identical to the pool one except the resource being allocated is n_ready_jobs compared to total_jobs rather than ready_cores_mcpu. ; - The instance creation loop needs to extract the machine_type, storage_gib, and preemptible from the spec without hitting GCS. Therefore, it is stored in the ""spec"" field in the database which required changing the batch format version a bit.; - We avoid double scheduling by requiring that there are no live instances assigned to attempts for that job before creating an instance.; - We mark a job as creating after creating the instance for the new attempt; - The number of instances that can be created is similar to the pool control loop. The total number of instances we can create is fed to the fair share allocator.; - I added an asyncio.wait(15) at the end of the instance creation loop body to make sure we didn't run past our GCE limits.; - The scheduling loop iterates over all attempts with active instances in order of time of activation (no user fair share here -- FIFO); - There is no possibility of double scheduling because there must only be one active instance per job based on the create instances loop. **Canceller:**; - There's a new canceller loop that looks for jobs that need to be cancelled in the creating state. It marks these jobs as complete ""cancelled"" in the database and then calls GCE to delete the instance. **Mark Job Complete:**; - I modified this function to kill a job priv",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9972:2800,avoid,avoid,2800,https://hail.is,https://github.com/hail-is/hail/pull/9972,1,['avoid'],['avoid']
Safety,il.utils.HailException: cannot set missing field for required type +PFloat64; 	at is.hail.utils.ErrorHandling.fatal(ErrorHandling.scala:18); 	at is.hail.utils.ErrorHandling.fatal$(ErrorHandling.scala:18); 	at is.hail.utils.package$.fatal(package.scala:81); 	at is.hail.annotations.RegionValueBuilder.setMissing(RegionValueBuilder.scala:207); 	at is.hail.io.vcf.VCFLine.parseAddInfoArrayDouble(LoadVCF.scala:1034); 	at is.hail.io.vcf.VCFLine.parseAddInfoField(LoadVCF.scala:1055); 	at is.hail.io.vcf.VCFLine.addInfoField(LoadVCF.scala:1075); 	at is.hail.io.vcf.VCFLine.parseAddInfo(LoadVCF.scala:1112); 	at is.hail.io.vcf.LoadVCF$.parseLineInner(LoadVCF.scala:1541); 	at is.hail.io.vcf.LoadVCF$.parseLine(LoadVCF.scala:1409); 	at is.hail.io.vcf.MatrixVCFReader.$anonfun$executeGeneric$7(LoadVCF.scala:1916); 	... 21 more. Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2673); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2609); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2608); 	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62); 	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2608); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1182); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1182); 	at scala.Option.foreach(Option.scala:407); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1182); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2861); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2803); 	at org.apache.spark.s,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14102:10024,abort,abortStage,10024,https://hail.is,https://github.com/hail-is/hail/issues/14102,1,['abort'],['abortStage']
Safety,il.utils.package$.using(package.scala:577); 	at is.hail.sparkextras.ContextRDD$$anonfun$runJob$1.apply(ContextRDD.scala:458); 	at is.hail.sparkextras.ContextRDD$$anonfun$runJob$1.apply(ContextRDD.scala:458); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2062); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2062); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGSche,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3516:3644,abort,abortStage,3644,https://hail.is,https://github.com/hail-is/hail/issues/3516,1,['abort'],['abortStage']
Safety,"ile ""<ipython-input-9-304965820738>"", line 1, in <module>; x.key_by('y').show(); File ""<decorator-gen-598>"", line 2, in show; File ""/Users/konradk/Dropbox/src/python/hail/typecheck/check.py"", line 486, in _typecheck; return __orig_func__(*args_, **kwargs_); File ""/Users/konradk/Dropbox/src/python/hail/table.py"", line 1101, in show; print(self._show(n,width, truncate, types)); File ""/Users/konradk/Dropbox/src/python/hail/table.py"", line 1104, in _show; return self._jt.showString(n, joption(truncate), types, width); File ""/Users/konradk/programs/spark-2.2.0-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py"", line 1133, in __call__; answer, self.gateway_client, self.target_id, self.name); File ""/Users/konradk/Dropbox/src/python/hail/utils/java.py"", line 196, in deco; 'Error summary: %s' % (deepest, full, hail.__version__, deepest)) from None; hail.utils.java.FatalError: AssertionError: assertion failed; Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 9.0 failed 1 times, most recent failure: Lost task 0.0 in stage 9.0 (TID 49, localhost, executor driver): java.lang.AssertionError: assertion failed; 	at scala.Predef$.assert(Predef.scala:156); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$16$$anon$3.next(OrderedRVD.scala:926); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$16$$anon$3.next(OrderedRVD.scala:908); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at is.hail.utils.package$.getIteratorSizeWithMaxN(package.scala:349); 	at is.hail.sparkextras.ContextRDD$$anonfun$12.apply(ContextRDD.scala:433); 	at is.hail.sparkextras.ContextRDD$$anonfun$12.apply(ContextRDD.scala:433); 	at is.hail.sparkextras.ContextRDD$$anonfun$runJob$1$$anonfun$apply$34.apply(ContextRDD.scala:458); 	at is.hail.sparkextras.ContextRDD$$anonfun$runJob$1$$anonfun$apply$34.apply(ContextRDD.scala:458); 	at is.hail.utils.package$.using(package.scala:577); 	at is.hail.sparkextras.ContextRDD$$anonfun$runJob$1.apply(ContextRDD.s",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3516:1740,abort,aborted,1740,https://hail.is,https://github.com/hail-is/hail/issues/3516,1,['abort'],['aborted']
Safety,"ile ""uvloop/loop.pyx"", line 1951, in uvloop.loop.Loop.create_connection\nConnectionRefusedError: [Errno 111] Connection refused\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n File ""/usr/local/lib/python3.7/dist-packages/batch/driver/job.py"", line 449, in schedule_job\n timeout=aiohttp.ClientTimeout(total=2),\n File ""/usr/local/lib/python3.7/dist-packages/hailtop/httpx.py"", line 113, in request_and_raise_for_status\n resp = await self.client_session._request(method, url, **kwargs)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/client.py"", line 521, in _request\n req, traces=traces, timeout=real_timeout\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 535, in connect\n proto = await self._create_connection(req, traces, timeout)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 892, in _create_connection\n _, proto = await self._create_direct_connection(req, traces, timeout)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 1051, in _create_direct_connection\n raise last_exc\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 1032, in _create_direct_connection\n client_error=client_error,\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 975, in _wrap_create_connection\n raise client_error(req.connection_key, exc) from exc\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 10.128.0.11:5000 ssl:default [Connection refused]. ```. Now take a look at the worker: It takes us about nine seconds to get to; an initialized FileStore. Maybe FS creation is really slow? We create one; twice in activate. I think we might initialize credentials three times. I; will fix these in a future PR. The main issue, though, is that the driver *immediately* provides us with; work after we activate, but we are not yet ready for work. I suspect aiohttp; was ready at about 19:05:33 w",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11451:25472,timeout,timeout,25472,https://hail.is,https://github.com/hail-is/hail/pull/11451,1,['timeout'],['timeout']
Safety,"ile ""uvloop/loop.pyx"", line 1951, in uvloop.loop.Loop.create_connection\nConnectionRefusedError: [Errno 111] Connection refused\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n File ""/usr/local/lib/python3.7/dist-packages/batch/driver/job.py"", line 449, in schedule_job\n timeout=aiohttp.ClientTimeout(total=2),\n File ""/usr/local/lib/python3.7/dist-packages/hailtop/httpx.py"", line 113, in request_and_raise_for_status\n resp = await self.client_session._request(method, url, **kwargs)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/client.py"", line 521, in _request\n req, traces=traces, timeout=real_timeout\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 535, in connect\n proto = await self._create_connection(req, traces, timeout)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 892, in _create_connection\n _, proto = await self._create_direct_connection(req, traces, timeout)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 1051, in _create_direct_connection\n raise last_exc\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 1032, in _create_direct_connection\n client_error=client_error,\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 975, in _wrap_create_connection\n raise client_error(req.connection_key, exc) from exc\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 10.128.0.11:5000 ssl:default [Connection refused]; ERROR	2022-03-02 19:06:35,400	job.py	schedule_job:473	error while scheduling job (93, 1) on instance batch-worker-pr-11438-default-g6cibyji6520-standard-9xy2q	Traceback (most recent call last):\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 969, in _wrap_create_connection\n return await self._loop.create_connection(*args, **kwargs) # type: ignore # noqa\n File ""uvloop/loop.pyx"", line 1974, in create_connection",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11451:6795,timeout,timeout,6795,https://hail.is,https://github.com/hail-is/hail/pull/11451,1,['timeout'],['timeout']
Safety,"ile ""uvloop/loop.pyx"", line 1951, in uvloop.loop.Loop.create_connection\nConnectionRefusedError: [Errno 111] Connection refused\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n File ""/usr/local/lib/python3.7/dist-packages/batch/driver/job.py"", line 449, in schedule_job\n timeout=aiohttp.ClientTimeout(total=2),\n File ""/usr/local/lib/python3.7/dist-packages/hailtop/httpx.py"", line 113, in request_and_raise_for_status\n resp = await self.client_session._request(method, url, **kwargs)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/client.py"", line 521, in _request\n req, traces=traces, timeout=real_timeout\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 535, in connect\n proto = await self._create_connection(req, traces, timeout)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 892, in _create_connection\n _, proto = await self._create_direct_connection(req, traces, timeout)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 1051, in _create_direct_connection\n raise last_exc\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 1032, in _create_direct_connection\n client_error=client_error,\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 975, in _wrap_create_connection\n raise client_error(req.connection_key, exc) from exc\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 10.128.0.11:5000 ssl:default [Connection refused]; ERROR	2022-03-02 19:06:37,364	job.py	schedule_job:473	error while scheduling job (90, 1) on instance batch-worker-pr-11438-default-g6cibyji6520-standard-9xy2q	Traceback (most recent call last):\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 969, in _wrap_create_connection\n return await self._loop.create_connection(*args, **kwargs) # type: ignore # noqa\n File ""uvloop/loop.pyx"", line 1974, in create_connection",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11451:11296,timeout,timeout,11296,https://hail.is,https://github.com/hail-is/hail/pull/11451,1,['timeout'],['timeout']
Safety,"ile ""uvloop/loop.pyx"", line 1951, in uvloop.loop.Loop.create_connection\nConnectionRefusedError: [Errno 111] Connection refused\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n File ""/usr/local/lib/python3.7/dist-packages/batch/driver/job.py"", line 449, in schedule_job\n timeout=aiohttp.ClientTimeout(total=2),\n File ""/usr/local/lib/python3.7/dist-packages/hailtop/httpx.py"", line 113, in request_and_raise_for_status\n resp = await self.client_session._request(method, url, **kwargs)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/client.py"", line 521, in _request\n req, traces=traces, timeout=real_timeout\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 535, in connect\n proto = await self._create_connection(req, traces, timeout)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 892, in _create_connection\n _, proto = await self._create_direct_connection(req, traces, timeout)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 1051, in _create_direct_connection\n raise last_exc\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 1032, in _create_direct_connection\n client_error=client_error,\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 975, in _wrap_create_connection\n raise client_error(req.connection_key, exc) from exc\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 10.128.0.11:5000 ssl:default [Connection refused]; ERROR	2022-03-02 19:06:37,390	job.py	schedule_job:473	error while scheduling job (97, 1) on instance batch-worker-pr-11438-default-g6cibyji6520-standard-9xy2q	Traceback (most recent call last):\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 969, in _wrap_create_connection\n return await self._loop.create_connection(*args, **kwargs) # type: ignore # noqa\n File ""uvloop/loop.pyx"", line 1974, in create_connection",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11451:13301,timeout,timeout,13301,https://hail.is,https://github.com/hail-is/hail/pull/11451,1,['timeout'],['timeout']
Safety,"ile ""uvloop/loop.pyx"", line 1951, in uvloop.loop.Loop.create_connection\nConnectionRefusedError: [Errno 111] Connection refused\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n File ""/usr/local/lib/python3.7/dist-packages/batch/driver/job.py"", line 449, in schedule_job\n timeout=aiohttp.ClientTimeout(total=2),\n File ""/usr/local/lib/python3.7/dist-packages/hailtop/httpx.py"", line 113, in request_and_raise_for_status\n resp = await self.client_session._request(method, url, **kwargs)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/client.py"", line 521, in _request\n req, traces=traces, timeout=real_timeout\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 535, in connect\n proto = await self._create_connection(req, traces, timeout)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 892, in _create_connection\n _, proto = await self._create_direct_connection(req, traces, timeout)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 1051, in _create_direct_connection\n raise last_exc\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 1032, in _create_direct_connection\n client_error=client_error,\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 975, in _wrap_create_connection\n raise client_error(req.connection_key, exc) from exc\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 10.128.0.11:5000 ssl:default [Connection refused]; ERROR	2022-03-02 19:06:37,435	job.py	schedule_job:473	error while scheduling job (101, 1) on instance batch-worker-pr-11438-default-g6cibyji6520-standard-9xy2q	Traceback (most recent call last):\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 969, in _wrap_create_connection\n return await self._loop.create_connection(*args, **kwargs) # type: ignore # noqa\n File ""uvloop/loop.pyx"", line 1974, in create_connectio",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11451:15306,timeout,timeout,15306,https://hail.is,https://github.com/hail-is/hail/pull/11451,1,['timeout'],['timeout']
Safety,"ile ""uvloop/loop.pyx"", line 1951, in uvloop.loop.Loop.create_connection\nConnectionRefusedError: [Errno 111] Connection refused\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n File ""/usr/local/lib/python3.7/dist-packages/batch/driver/job.py"", line 449, in schedule_job\n timeout=aiohttp.ClientTimeout(total=2),\n File ""/usr/local/lib/python3.7/dist-packages/hailtop/httpx.py"", line 113, in request_and_raise_for_status\n resp = await self.client_session._request(method, url, **kwargs)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/client.py"", line 521, in _request\n req, traces=traces, timeout=real_timeout\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 535, in connect\n proto = await self._create_connection(req, traces, timeout)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 892, in _create_connection\n _, proto = await self._create_direct_connection(req, traces, timeout)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 1051, in _create_direct_connection\n raise last_exc\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 1032, in _create_direct_connection\n client_error=client_error,\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 975, in _wrap_create_connection\n raise client_error(req.connection_key, exc) from exc\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 10.128.0.11:5000 ssl:default [Connection refused]; ERROR	2022-03-02 19:06:37,447	job.py	schedule_job:473	error while scheduling job (102, 1) on instance batch-worker-pr-11438-default-g6cibyji6520-standard-9xy2q	Traceback (most recent call last):\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 969, in _wrap_create_connection\n return await self._loop.create_connection(*args, **kwargs) # type: ignore # noqa\n File ""uvloop/loop.pyx"", line 1974, in create_connectio",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11451:17312,timeout,timeout,17312,https://hail.is,https://github.com/hail-is/hail/pull/11451,1,['timeout'],['timeout']
Safety,"ile ""uvloop/loop.pyx"", line 1951, in uvloop.loop.Loop.create_connection\nConnectionRefusedError: [Errno 111] Connection refused\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n File ""/usr/local/lib/python3.7/dist-packages/batch/driver/job.py"", line 449, in schedule_job\n timeout=aiohttp.ClientTimeout(total=2),\n File ""/usr/local/lib/python3.7/dist-packages/hailtop/httpx.py"", line 113, in request_and_raise_for_status\n resp = await self.client_session._request(method, url, **kwargs)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/client.py"", line 521, in _request\n req, traces=traces, timeout=real_timeout\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 535, in connect\n proto = await self._create_connection(req, traces, timeout)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 892, in _create_connection\n _, proto = await self._create_direct_connection(req, traces, timeout)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 1051, in _create_direct_connection\n raise last_exc\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 1032, in _create_direct_connection\n client_error=client_error,\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 975, in _wrap_create_connection\n raise client_error(req.connection_key, exc) from exc\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 10.128.0.11:5000 ssl:default [Connection refused]; ERROR	2022-03-02 19:06:39,193	job.py	schedule_job:473	error while scheduling job (99, 1) on instance batch-worker-pr-11438-default-g6cibyji6520-standard-9xy2q	Traceback (most recent call last):\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 969, in _wrap_create_connection\n return await self._loop.create_connection(*args, **kwargs) # type: ignore # noqa\n File ""uvloop/loop.pyx"", line 1974, in create_connection",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11451:21461,timeout,timeout,21461,https://hail.is,https://github.com/hail-is/hail/pull/11451,1,['timeout'],['timeout']
Safety,"ile ""uvloop/loop.pyx"", line 1951, in uvloop.loop.Loop.create_connection\nConnectionRefusedError: [Errno 111] Connection refused\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n File ""/usr/local/lib/python3.7/dist-packages/batch/driver/job.py"", line 449, in schedule_job\n timeout=aiohttp.ClientTimeout(total=2),\n File ""/usr/local/lib/python3.7/dist-packages/hailtop/httpx.py"", line 113, in request_and_raise_for_status\n resp = await self.client_session._request(method, url, **kwargs)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/client.py"", line 521, in _request\n req, traces=traces, timeout=real_timeout\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 535, in connect\n proto = await self._create_connection(req, traces, timeout)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 892, in _create_connection\n _, proto = await self._create_direct_connection(req, traces, timeout)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 1051, in _create_direct_connection\n raise last_exc\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 1032, in _create_direct_connection\n client_error=client_error,\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 975, in _wrap_create_connection\n raise client_error(req.connection_key, exc) from exc\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 10.128.0.11:5000 ssl:default [Connection refused]; ERROR	2022-03-02 19:06:39,204	job.py	schedule_job:473	error while scheduling job (100, 1) on instance batch-worker-pr-11438-default-g6cibyji6520-standard-9xy2q	Traceback (most recent call last):\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 969, in _wrap_create_connection\n return await self._loop.create_connection(*args, **kwargs) # type: ignore # noqa\n File ""uvloop/loop.pyx"", line 1974, in create_connectio",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11451:23466,timeout,timeout,23466,https://hail.is,https://github.com/hail-is/hail/pull/11451,1,['timeout'],['timeout']
Safety,"ile ""uvloop/loop.pyx"", line 1951, in uvloop.loop.Loop.create_connection\nConnectionRefusedError: [Errno 111] Connection refused\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n File ""/usr/local/lib/python3.7/dist-packages/batch/driver/job.py"", line 449, in schedule_job\n timeout=aiohttp.ClientTimeout(total=2),\n File ""/usr/local/lib/python3.7/dist-packages/hailtop/httpx.py"", line 113, in request_and_raise_for_status\n resp = await self.client_session._request(method, url, **kwargs)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/client.py"", line 521, in _request\n req, traces=traces, timeout=real_timeout\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 535, in connect\n proto = await self._create_connection(req, traces, timeout)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 892, in _create_connection\n _, proto = await self._create_direct_connection(req, traces, timeout)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 1051, in _create_direct_connection\n raise last_exc\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 1032, in _create_direct_connection\n client_error=client_error,\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 975, in _wrap_create_connection\n raise client_error(req.connection_key, exc) from exc\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 10.128.0.11:5000 ssl:default [Connection refused]; INFO	2022-03-02 19:06:33,503	job_private.py	schedule_jobs_loop_body:142	starting scheduling jobs for jpim job-private; INFO	2022-03-02 19:06:33,533	job_private.py	schedule_jobs_loop_body:186	scheduled 0 jobs for jpim job-private; INFO	2022-03-02 19:06:34,964	pool.py	create_instances:244	pool highcpu n_instances 0 {'pending': 0, 'active': 0, 'inactive': 0, 'deleted': 0} free_cores 0.0 live_free_cores 0.0 ready_cores 0.0; ERROR	2022-03-02 ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11451:4366,timeout,timeout,4366,https://hail.is,https://github.com/hail-is/hail/pull/11451,1,['timeout'],['timeout']
Safety,"ile ""uvloop/loop.pyx"", line 1951, in uvloop.loop.Loop.create_connection\nConnectionRefusedError: [Errno 111] Connection refused\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n File ""/usr/local/lib/python3.7/dist-packages/batch/driver/job.py"", line 449, in schedule_job\n timeout=aiohttp.ClientTimeout(total=2),\n File ""/usr/local/lib/python3.7/dist-packages/hailtop/httpx.py"", line 113, in request_and_raise_for_status\n resp = await self.client_session._request(method, url, **kwargs)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/client.py"", line 521, in _request\n req, traces=traces, timeout=real_timeout\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 535, in connect\n proto = await self._create_connection(req, traces, timeout)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 892, in _create_connection\n _, proto = await self._create_direct_connection(req, traces, timeout)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 1051, in _create_direct_connection\n raise last_exc\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 1032, in _create_direct_connection\n client_error=client_error,\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 975, in _wrap_create_connection\n raise client_error(req.connection_key, exc) from exc\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 10.128.0.11:5000 ssl:default [Connection refused]; INFO	2022-03-02 19:06:35,620	pool.py	create_instances:244	pool standard n_instances 1 {'pending': 0, 'active': 1, 'inactive': 0, 'deleted': 0} free_cores 0.0 live_free_cores 8.0 ready_cores 11.0; INFO	2022-03-02 19:06:35,620	pool.py	create_instances_from_ready_cores:206	creating 1 new instances; INFO	2022-03-02 19:06:35,848	pool.py	create_instances:244	pool highmem n_instances 1 {'pending': 0, 'active': 1, 'inactive': 0, 'deleted': 0} fr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11451:8800,timeout,timeout,8800,https://hail.is,https://github.com/hail-is/hail/pull/11451,1,['timeout'],['timeout']
Safety,"ile ""uvloop/loop.pyx"", line 1951, in uvloop.loop.Loop.create_connection\nConnectionRefusedError: [Errno 111] Connection refused\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n File ""/usr/local/lib/python3.7/dist-packages/batch/driver/job.py"", line 449, in schedule_job\n timeout=aiohttp.ClientTimeout(total=2),\n File ""/usr/local/lib/python3.7/dist-packages/hailtop/httpx.py"", line 113, in request_and_raise_for_status\n resp = await self.client_session._request(method, url, **kwargs)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/client.py"", line 521, in _request\n req, traces=traces, timeout=real_timeout\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 535, in connect\n proto = await self._create_connection(req, traces, timeout)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 892, in _create_connection\n _, proto = await self._create_direct_connection(req, traces, timeout)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 1051, in _create_direct_connection\n raise last_exc\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 1032, in _create_direct_connection\n client_error=client_error,\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 975, in _wrap_create_connection\n raise client_error(req.connection_key, exc) from exc\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 10.128.0.11:5000 ssl:default [Connection refused]; INFO	2022-03-02 19:06:38,141	resource_manager.py	create_vm:191	created machine batch-worker-pr-11438-default-g6cibyji6520-standard-4d9n8; ERROR	2022-03-02 19:06:39,183	job.py	schedule_job:473	error while scheduling job (98, 1) on instance batch-worker-pr-11438-default-g6cibyji6520-standard-9xy2q	Traceback (most recent call last):\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 969, in _wrap_create_connection\n ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11451:19318,timeout,timeout,19318,https://hail.is,https://github.com/hail-is/hail/pull/11451,1,['timeout'],['timeout']
Safety,"ils>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/aio-libs/aiohttp_jinja2/releases"">aiohttp-jinja2's releases</a>.</em></p>; <blockquote>; <h2>aiohttp-jinja2 1.4.2 release</h2>; <h2>Changes</h2>; <ul>; <li>Add CHANGES.rst to MANIFEST.in and sdist <a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_jinja2/issues/402"">#402</a></li>; </ul>; <h2>aiohttp-jinja2 1.4.1 release</h2>; <h2>Changes</h2>; <ul>; <li>Document async rendering functions <a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_jinja2/issues/396"">#396</a></li>; </ul>; <h2>aiohttp-jinja2 1.4.0 release</h2>; <h1>Changes</h1>; <ul>; <li>; <p>Fix type annotation for <code>context_processors</code> argument <a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_jinja2/issues/354"">#354</a></p>; </li>; <li>; <p>Bump the minimal supported <code>aiohttp</code> version to 3.6.3 to avoid problems; with uncompatibility between <code>aiohttp</code> and <code>yarl</code></p>; </li>; <li>; <p>Add async rendering support <a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_jinja2/issues/393"">#393</a></p>; </li>; </ul>; <h2>aiohttp-jinja2 1.3.0 release</h2>; <h1>Changes</h1>; <ul>; <li>Remove Any from template annotations <a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_jinja2/issues/343"">#343</a></li>; <li>Fix type annotation for filters in aiohttp_jinja2.setup <a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_jinja2/issues/330"">#330</a></li>; <li>Drop Python 3.5, support Python 3.9</li>; </ul>; <h2>aiohttp-jinja2 1.2.0 release</h2>; <h2>Changes</h2>; <ul>; <li>Add type hints <a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_jinja2/issues/285"">#285</a></li>; </ul>; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/aio-libs/aiohttp-jinja2/blob/master/CHANGES.rst"">aiohttp-jinja2's changelog</a>.</em></p>; <blockquote>; <h2>1.5 (2",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11576:1010,avoid,avoid,1010,https://hail.is,https://github.com/hail-is/hail/pull/11576,1,['avoid'],['avoid']
Safety,"in the service, log everything to stdout; - [x] (trivial) d8104a1dc4 [query-service] do not catch CancelledError; - [x] (trivial) efcb345185 [query-service] slightly more useful error message when socket dies; - [ ] (@tpoterba) f79c4023cf [shuffler] if we have an ExecuteContext, use it; - [x] (@daniel-goldstein,fyi: @tpoterba) 259f70dd25 [query-service] JSON Logging; - [ ] (@catoverdrive) f5c3ffcbd1 [query-service] pervasively retry all idempotent operations; - [ ] (@tpoterba) 507db4b468 [hail] fix using; - [x] (@jigold) c32a253bb9 [query] when testing, ensure our thread has an event loop; - [ ] (@tpoterba) 110469c2da [query][lir] avoid dumping massive classes onto stderr; - [ ] (@tpoterba) e4aa1c15fe [query] do not print misleading log in RegionPool.finalizer; - [x] (trivial) 33eab9a80e [query-service] better logging information; - [ ] (@catoverdrive) e358e8feeb [query-service] remove race conditions in user management; - [ ] (@tpoterba) b60cb2bae5 [lir] make LIR genName thread-safe; - [ ] (@catoverdrive) 2d82e5faf5 [query-service] send a token for job identifiability; - [x] (@daniel-goldstein) fd78caedcb [query-service] reduce image size by ~2GB; - [ ] (@catoverdrive) 00d1840421 [query-service] retry CLOSE, CLOSED (i.e. connection dropped); - [ ] (@catoverdrive) c985d3e3de [query-service] remove old test code; - [ ] (@catoverdrive) 0a5dc8c651 [query-service] all operations are idempotent; - [ ] (@cseed) 6d02d173fa [make] fix config.mk; - [x] (@daniel-goldstein) d21df54e63 [devbin] teach devbin/functions.py about multiple containers; - [x] (@jigold) 38878f7874 [batch] remove batch_worker_image false dependency on service_base_image; - [x] (@daniel-goldstein) f03defab3d [java-services] avoid NPEs in isTransientError; - [x] (@jigold) e535bdc00d [dependencies] upgrade gcsfs to 0.7.2 to fix GoogleFS rmtree issue; - [x] (@cseed) 743b5ba62f [query-service] enable auto-scaling for PR and dev deploy; - [ ] (@cseed) 6a52d45f6f [query-service] retry EndOfStream errors from j",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10100:3140,safe,safe,3140,https://hail.is,https://github.com/hail-is/hail/pull/10100,1,['safe'],['safe']
Safety,"ind(c => c.consequence_terms.contains(va.vep.most_severe_consequence)).impact == ""HIGH"")' \; annotatevariants expr -c 'va.andrea.damaging = (va.vep.transcript_consequences.find(c => c.canonical == 1).consequence_terms.contains(""missense_variant"") || (va.vep.transcript_consequences.find(c => c.canonical == 1).canonical.isMissing && va.vep.most_severe_consequence == ""missense_variant"") || ; va.vep.transcript_consequences.find(c => c.canonical == 1).consequence_terms.contains(""inframe_deletion"") || (va.vep.transcript_consequences.find(c => c.canonical == 1).canonical.isMissing && va.vep.most_severe_consequence == ""inframe_deletion"") ||; va.vep.transcript_consequences.find(c => c.canonical == 1).consequence_terms.contains(""inframe_insertion"") || (va.vep.transcript_consequences.find(c => c.canonical == 1).canonical.isMissing && va.vep.most_severe_consequence == ""inframe_insertion"")) ; && ""D"" ~ va.dbNSFP.Polyphen2_HDIV_pred && ""D"" ~ va.dbNSFP.Polyphen2_HVAR_pred && ""D"" ~ va.dbNSFP.SIFT_pred && ""D"" ~ va.dbNSFP.LRT_pred && ""[AD]"" ~ va.dbNSFP.MutationTaster_pred && ""[HM]"" ~ va.dbNSFP.MutationAssessor_pred && ""D"" ~ va.dbNSFP.PROVEAN_pred ' \; annotatevariants expr -c 'va.andrea.synonymous = va.vep.transcript_consequences.find(c => c.canonical == 1).consequence_terms.contains(""synonymous_variant"") || (va.vep.transcript_consequences.find(c => c.canonical == 1).canonical.isMissing && va.vep.most_severe_consequence == ""synonymous_variant"")' \; annotatevariants expr -c 'va.andrea.genename = if (va.vep.transcript_consequences.find(c => c.canonical == 1).canonical.isMissing) va.vep.transcript_consequences.find(c => c.consequence_terms.contains(va.vep.most_severe_consequence)).gene_symbol else va.vep.transcript_consequences.find(c => c.canonical == 1).gene_symbol' \; write -o /user/aganna/IBD_ANNOT.vep.qced.otherann.vds. error:. hail: write: caught exception: org.apache.spark.SparkException: Job aborted. [hail.log.txt](https://github.com/broadinstitute/hail/files/227035/hail.log.txt)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/320:3347,abort,aborted,3347,https://hail.is,https://github.com/hail-is/hail/issues/320,1,['abort'],['aborted']
Safety,"ion of the</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/aio-libs/aiohttp/blob/master/CHANGES.rst"">aiohttp's changelog</a>.</em></p>; <blockquote>; <h1>3.8.3 (2022-09-21)</h1>; <p>.. attention::</p>; <p>This is the last :doc:<code>aiohttp &lt;index&gt;</code> release tested under; Python 3.6. The 3.9 stream is dropping it from the CI and the; distribution package metadata.</p>; <h2>Bugfixes</h2>; <ul>; <li>; <p>Increased the upper boundary of the :doc:<code>multidict:index</code> dependency; to allow for the version 6 -- by :user:<code>hugovk</code>.</p>; <p>It used to be limited below version 7 in :doc:<code>aiohttp &lt;index&gt;</code> v3.8.1 but; was lowered in v3.8.2 via :pr:<code>6550</code> and never brought back, causing; problems with dependency pins when upgrading. :doc:<code>aiohttp &lt;index&gt;</code> v3.8.3; fixes that by recovering the original boundary of <code>&lt; 7</code>.; <code>[#6950](https://github.com/aio-libs/aiohttp/issues/6950) &lt;https://github.com/aio-libs/aiohttp/issues/6950&gt;</code>_</p>; </li>; </ul>; <hr />; <h1>3.8.2 (2022-09-20, subsequently yanked on 2022-09-21)</h1>; <h2>Bugfixes</h2>; <ul>; <li>; <p>Support registering OPTIONS HTTP method handlers via RouteTableDef.; <code>[#4663](https://github.com/aio-libs/aiohttp/issues/4663) &lt;https://github.com/aio-libs/aiohttp/issues/4663&gt;</code>_</p>; </li>; <li>; <p>Started supporting <code>authority-form</code> and <code>absolute-form</code> URLs on the server-side.; <code>[#6227](https://github.com/aio-libs/aiohttp/issues/6227) &lt;https://github.com/aio-libs/aiohttp/issues/6227&gt;</code>_</p>; </li>; <li>; <p>Fix Python 3.11 alpha incompatibilities by using Cython 0.29.25; <code>[#6396](https://github.com/aio-libs/aiohttp/issues/6396) &lt;https://github.com/aio-libs/aiohttp/issues/6396&gt;</code>_</p>; </li>; <li>; <p>Remove a deprecated usage of",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12296:3395,recover,recovering,3395,https://hail.is,https://github.com/hail-is/hail/pull/12296,1,['recover'],['recovering']
Safety,ion.scala:546); 	at org.json4s.Extraction$ClassInstanceBuilder.result(Extraction.scala:597); 	at org.json4s.Extraction$$anonfun$extract$6.apply(Extraction.scala:400); 	at org.json4s.Extraction$$anonfun$extract$6.apply(Extraction.scala:392); 	at org.json4s.Extraction$.customOrElse(Extraction.scala:606); 	at org.json4s.Extraction$.extract(Extraction.scala:392); 	at org.json4s.Extraction$.extract(Extraction.scala:39); 	... 38 more. Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:2039); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:2027); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:2026); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2026); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:966); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:966); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:966); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2260); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2209); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2198); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:777); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2061); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2082); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7044:12356,abort,abortStage,12356,https://hail.is,https://github.com/hail-is/hail/issues/7044,2,['abort'],['abortStage']
Safety,"ion: Job aborted due to stage failure: Task 582 in stage 10.0 failed 20 times, most recent failure: Lost task 582.19 in stage 10.0 (TID 461381) (cluster-w-144.c.project-.internal executor 3568): ExecutorLostFailure (executor 3568 exited caused by one of the running tasks) Reason: Executor heartbeat timed out after 128936 ms; Driver stacktrace:. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 582 in stage 10.0 failed 20 times, most recent failure: Lost task 582.19 in stage 10.0 (TID 461381) (cluster-w-144.c.gbsc-project.internal executor 3568): ExecutorLostFailure (executor 3568 exited caused by one of the running tasks) Reason: Executor heartbeat timed out after 128936 ms; Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2304); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2253); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2252); 	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62); 	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2252); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1124); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1124); 	at scala.Option.foreach(Option.scala:407); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1124); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2491); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2433); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2422); 	at org.apache.spark.u",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12290:2360,abort,abortStage,2360,https://hail.is,https://github.com/hail-is/hail/issues/12290,1,['abort'],['abortStage']
Safety,"ion:</p>; <ol>; <li>; <p>Don't raise TimeoutError from timeout object that doesn't enter into async context; manager</p>; </li>; <li>; <p>Use call_soon() for raising TimeoutError if deadline is reached on entering into; async context manager</p>; </li>; </ol>; <p>(<a href=""https://github-redirect.dependabot.com/aio-libs/async-timeout/issues/258"">#258</a>)</p>; </li>; <li>; <p>Make <code>Timeout</code> class available in <code>__all__</code>.</p>; </li>; </ul>; <h1>4.0.0 (2021-11-01)</h1>; <ul>; <li>; <p>Implemented <code>timeout_at(deadline)</code> (<a href=""https://github-redirect.dependabot.com/aio-libs/async-timeout/issues/117"">#117</a>)</p>; </li>; <li>; <p>Supported <code>timeout.deadline</code> and <code>timeout.expired</code> properties.</p>; </li>; <li>; <p>Dropped <code>timeout.remaining</code> property: it can be calculated as; <code>timeout.deadline - loop.time()</code></p>; </li>; <li>; <p>Dropped <code>timeout.timeout</code> property that returns a relative timeout based on the; timeout object creation time; the absolute <code>timeout.deadline</code> should be used; instead.</p>; </li>; <li>; <p>Added the deadline modification methods: <code>timeout.reject()</code>,; <code>timeout.shift(delay)</code>, <code>timeout.update(deadline)</code>.</p>; </li>; <li>; <p>Deprecated synchronous context manager usage</p>; </li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/aio-libs/async-timeout/commit/5128f7f4ff73b165579006a8336978efaeeca07a""><code>5128f7f</code></a> Fix CHANGES</li>; <li><a href=""https://github.com/aio-libs/async-timeout/commit/18e718a56f9def7dc40bb9ce3a2962a8fb0c883c""><code>18e718a</code></a> Bump to 4.0.2</li>; <li><a href=""https://github.com/aio-libs/async-timeout/commit/48d1c4ce923b1da75976d7e2a6ca9234b3092c16""><code>48d1c4c</code></a> Setup towncrier</li>; <li><a href=""https://github.com/aio-libs/async-timeout/commit/2ede7d73e55f8d1a2279d78861af0009d96219fb""><code>2ede7d7</code>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11465:3485,timeout,timeout,3485,https://hail.is,https://github.com/hail-is/hail/pull/11465,4,['timeout'],['timeout']
Safety,ionRegistry.scala:685); 	at is.hail.expr.BinaryFun.apply(Fun.scala:122); 	at is.hail.codegen.generated.C9.apply(Unknown Source); 	at is.hail.codegen.generated.C9.apply(Unknown Source); 	at is.hail.expr.CM$$anonfun$runWithDelayedValues$1.apply(CM.scala:84); 	at is.hail.expr.CM$$anonfun$runWithDelayedValues$1.apply(CM.scala:82); 	at is.hail.expr.Parser$$anonfun$is$hail$expr$Parser$$evalNoTypeCheck$1.apply(Parser.scala:64); 	at is.hail.variant.MatrixTable$$anonfun$selectEntries$2.apply(MatrixTable.scala:1112); 	at is.hail.variant.MatrixTable$$anonfun$selectEntries$2.apply(MatrixTable.scala:1102); 	at is.hail.variant.MatrixTable$$anonfun$61$$anonfun$apply$52$$anonfun$apply$5.apply$mcV$sp(MatrixTable.scala:1364); 	at is.hail.expr.types.TStruct$$anonfun$unsafeInsert$1.apply(TStruct.scala:191); 	at is.hail.expr.types.TStruct$$anonfun$unsafeInsert$1.apply(TStruct.scala:191); 	at is.hail.expr.types.TStruct$$anonfun$unsafeInsert$2.apply(TStruct.scala:211); 	at is.hail.expr.types.TStruct$$anonfun$unsafeInsert$2.apply(TStruct.scala:200); 	at is.hail.variant.MatrixTable$$anonfun$61$$anonfun$apply$52.apply(MatrixTable.scala:1363); 	at is.hail.variant.MatrixTable$$anonfun$61$$anonfun$apply$52.apply(MatrixTable.scala:1359); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$10$$anon$3.next(OrderedRVD.scala:818); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$10$$anon$3.next(OrderedRVD.scala:812); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$10$$anon$3.next(OrderedRVD.scala:818); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$10$$anon$3.next(OrderedRVD.scala:812); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3465:3187,unsafe,unsafeInsert,3187,https://hail.is,https://github.com/hail-is/hail/issues/3465,2,['unsafe'],['unsafeInsert']
Safety,ionRegistry.scala:685); 	at is.hail.expr.FunctionRegistry$$anonfun$11.apply(FunctionRegistry.scala:685); 	at is.hail.expr.BinaryFun.apply(Fun.scala:122); 	at is.hail.codegen.generated.C9.apply(Unknown Source); 	at is.hail.codegen.generated.C9.apply(Unknown Source); 	at is.hail.expr.CM$$anonfun$runWithDelayedValues$1.apply(CM.scala:84); 	at is.hail.expr.CM$$anonfun$runWithDelayedValues$1.apply(CM.scala:82); 	at is.hail.expr.Parser$$anonfun$is$hail$expr$Parser$$evalNoTypeCheck$1.apply(Parser.scala:64); 	at is.hail.variant.MatrixTable$$anonfun$selectEntries$2.apply(MatrixTable.scala:1112); 	at is.hail.variant.MatrixTable$$anonfun$selectEntries$2.apply(MatrixTable.scala:1102); 	at is.hail.variant.MatrixTable$$anonfun$61$$anonfun$apply$52$$anonfun$apply$5.apply$mcV$sp(MatrixTable.scala:1364); 	at is.hail.expr.types.TStruct$$anonfun$unsafeInsert$1.apply(TStruct.scala:191); 	at is.hail.expr.types.TStruct$$anonfun$unsafeInsert$1.apply(TStruct.scala:191); 	at is.hail.expr.types.TStruct$$anonfun$unsafeInsert$2.apply(TStruct.scala:211); 	at is.hail.expr.types.TStruct$$anonfun$unsafeInsert$2.apply(TStruct.scala:200); 	at is.hail.variant.MatrixTable$$anonfun$61$$anonfun$apply$52.apply(MatrixTable.scala:1363); 	at is.hail.variant.MatrixTable$$anonfun$61$$anonfun$apply$52.apply(MatrixTable.scala:1359); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$10$$anon$3.next(OrderedRVD.scala:818); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$10$$anon$3.next(OrderedRVD.scala:812); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$10$$anon$3.next(OrderedRVD.scala:818); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$10$$anon$3.next(OrderedRVD.scala:812); 	at scala.collection.Iterator$$anon$12.nex,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3465:3106,unsafe,unsafeInsert,3106,https://hail.is,https://github.com/hail-is/hail/issues/3465,2,['unsafe'],['unsafeInsert']
Safety,ionRegistry.scala:685); 	at is.hail.expr.FunctionRegistry$$anonfun$11.apply(FunctionRegistry.scala:685); 	at is.hail.expr.FunctionRegistry$$anonfun$11.apply(FunctionRegistry.scala:685); 	at is.hail.expr.BinaryFun.apply(Fun.scala:122); 	at is.hail.codegen.generated.C9.apply(Unknown Source); 	at is.hail.codegen.generated.C9.apply(Unknown Source); 	at is.hail.expr.CM$$anonfun$runWithDelayedValues$1.apply(CM.scala:84); 	at is.hail.expr.CM$$anonfun$runWithDelayedValues$1.apply(CM.scala:82); 	at is.hail.expr.Parser$$anonfun$is$hail$expr$Parser$$evalNoTypeCheck$1.apply(Parser.scala:64); 	at is.hail.variant.MatrixTable$$anonfun$selectEntries$2.apply(MatrixTable.scala:1112); 	at is.hail.variant.MatrixTable$$anonfun$selectEntries$2.apply(MatrixTable.scala:1102); 	at is.hail.variant.MatrixTable$$anonfun$61$$anonfun$apply$52$$anonfun$apply$5.apply$mcV$sp(MatrixTable.scala:1364); 	at is.hail.expr.types.TStruct$$anonfun$unsafeInsert$1.apply(TStruct.scala:191); 	at is.hail.expr.types.TStruct$$anonfun$unsafeInsert$1.apply(TStruct.scala:191); 	at is.hail.expr.types.TStruct$$anonfun$unsafeInsert$2.apply(TStruct.scala:211); 	at is.hail.expr.types.TStruct$$anonfun$unsafeInsert$2.apply(TStruct.scala:200); 	at is.hail.variant.MatrixTable$$anonfun$61$$anonfun$apply$52.apply(MatrixTable.scala:1363); 	at is.hail.variant.MatrixTable$$anonfun$61$$anonfun$apply$52.apply(MatrixTable.scala:1359); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$10$$anon$3.next(OrderedRVD.scala:818); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$10$$anon$3.next(OrderedRVD.scala:812); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$10$$anon$3.next(OrderedRVD.scala:818); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3465:3025,unsafe,unsafeInsert,3025,https://hail.is,https://github.com/hail-is/hail/issues/3465,2,['unsafe'],['unsafeInsert']
Safety,"ire shuffles. The first change is easy. I added `RVDPartitioner.keysIfOneToOne` which looks; for these kinds of partitioners in the special case of keys consisting of 32-; and 64-bit integers. The second change eluded me for a long time. Finally, I discovered; `isSorted=true` and realized the optimizer refuses to modify such; `TableKeyBy`s. I exposed this field in Python as: `Table._key_by_assert_sorted`. With this infrastructure in place, I was able to implement read, write, and; matrix-multiply for DNDArray!. In addition, to the arguable hacks above, a couple pain points remain:; 1. I do not know how to rename keys in Python without triggering shuffles. If I; write `key_by(x=t.y, y=t.x)`, Hail implements this as; `TableKeyBy(TableMapRows(TableKeyBy(Array(), ...)`. The inner key by throws; the keys away so that they can be modified with TableMapRows. Unfortunately,; this completely defeats my attempts to avoid shuffles. I avoid this issue by; not using fixed names for the x and y block coordinates (their names are; stored in `x_field` and `y_field`).; 2. Hail lacks `ndarray_sum`. Instead, I convert from ndarray to array so that I; can use `array_sum`. Unfortunately, this operation seems to completely; dominate all of my time. It takes about 10x as much time as the matrix; multiplies take. I do not understand this. I should be reading the entries in; column-major order. Performance; -----------. ```; In [1]: %%time; ...: import hail as hl; ...: mt = hl.balding_nichols_model(n_populations=2,; ...: n_variants=10000,; ...: n_samples=10000,; ...: n_partitions=100); ...: mt = mt.select_entries(gt = hl.float(mt.GT.n_alt_alleles())); ...: da = hl.experimental.dnd.array(mt, 'gt'); ...: da.write('/tmp/in.da', overwrite=True); In [3]: %%time; ...: bm = hl.linalg.BlockMatrix.from_entry_expr(mt.gt); In [5]: %%time; ...: (bm @ bm.T).write('/tmp/foo.bm', overwrite=True); In [7]: %%time; ...: import hail as hl; ...: da = hl.experimental.dnd.read('/tmp/in.da'); ...: (da @ da.T).writ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8864:1528,avoid,avoid,1528,https://hail.is,https://github.com/hail-is/hail/pull/8864,1,['avoid'],['avoid']
Safety,"irect.dependabot.com/pytest-dev/pytest/issues/9355"">#9355</a>: Fixed error message prints function decorators when using assert in Python 3.8 and above.</li>; <li><a href=""https://github-redirect.dependabot.com/pytest-dev/pytest/issues/9396"">#9396</a>: Ensure <code>pytest.Config.inifile</code>{.interpreted-text role=&quot;attr&quot;} is available during the <code>pytest_cmdline_main &lt;_pytest.hookspec.pytest_cmdline_main&gt;</code>{.interpreted-text role=&quot;func&quot;} hook (regression during <code>7.0.0rc1</code>).</li>; </ul>; <h2>Improved Documentation</h2>; <ul>; <li><a href=""https://github-redirect.dependabot.com/pytest-dev/pytest/issues/9404"">#9404</a>: Added extra documentation on alternatives to common misuses of [pytest.warns(None)]{.title-ref} ahead of its deprecation.</li>; <li><a href=""https://github-redirect.dependabot.com/pytest-dev/pytest/issues/9505"">#9505</a>: Clarify where the configuration files are located. To avoid confusions documentation mentions; that configuration file is located in the root of the repository.</li>; </ul>; <h2>Trivial/Internal Changes</h2>; <ul>; <li><a href=""https://github-redirect.dependabot.com/pytest-dev/pytest/issues/9521"">#9521</a>: Add test coverage to assertion rewrite path.</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/pytest-dev/pytest/commit/3f12087fe0d86a319216653b08b66a96d400bee2""><code>3f12087</code></a> [pre-commit.ci] auto fixes from pre-commit.com hooks</li>; <li><a href=""https://github.com/pytest-dev/pytest/commit/bc3021cdfd76507aa3d9e278bd885da9bc1907b2""><code>bc3021c</code></a> Prepare release version 7.0.1</li>; <li><a href=""https://github.com/pytest-dev/pytest/commit/591d476f14e3e83d90fbea75d326a93c5e368708""><code>591d476</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pytest-dev/pytest/issues/9673"">#9673</a> from nicoddemus/backport-9511</li>; <li>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11516:3548,avoid,avoid,3548,https://hail.is,https://github.com/hail-is/hail/pull/11516,3,['avoid'],['avoid']
Safety,"is filter:; passed=passed.filter_rows((passed.variant_qc.AC>= 10)); Without this filter it runs OK. This file is a merged vcf file from Lumpy. Some sites may have no alternate alleles called (all 0/0 or ./.). ### What went wrong (all error messages here, including the full java stack trace):; [Stage 2:> (0 + 72) / 125]Traceback (most recent call last):; File ""/restricted/projectnb/casa/wgs.hg38/hail/lumpy/models.all.py"", line 80, in <module>; print(""Filtered Passed Rows:"",passed.count_rows()); File ""/restricted/projectnb/genpro/github/hail/build/distributions/hail-python.zip/hail/matrixtable.py"", line 2072, in count_rows; File ""/share/pkg/spark/2.2.0/install/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py"", line 1133, in __call__; File ""/restricted/projectnb/genpro/github/hail/build/distributions/hail-python.zip/hail/utils/java.py"", line 196, in deco; hail.utils.java.FatalError: NegativeArraySizeException: null. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 30 in stage 2.0 failed 4 times, most recent failure: Lost task 30.3 in stage 2.0 (TID 91, scc-q05.scc.bu.edu, executor 9): java.lang.NegativeArraySizeException; 	at java.util.Arrays.copyOf(Arrays.java:3236); 	at is.hail.annotations.Region.ensure(Region.scala:139); 	at is.hail.annotations.Region.allocate(Region.scala:152); 	at is.hail.annotations.Region.allocate(Region.scala:159); 	at is.hail.codegen.generated.C4.apply(Unknown Source); 	at is.hail.codegen.generated.C4.apply(Unknown Source); 	at is.hail.io.CompiledPackDecoder.readRegionValue(RowStore.scala:649); 	at is.hail.HailContext$$anon$2.next(HailContext.scala:246); 	at is.hail.HailContext$$anon$2.next(HailContext.scala:219); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at is.hail.sparkextras.ContextRDD$$anonfun$czip$1$$anon$1.next(ContextRDD.scala:322); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$16$$anon$3.next(OrderedRVD.scala",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3901:1355,abort,aborted,1355,https://hail.is,https://github.com/hail-is/hail/issues/3901,1,['abort'],['aborted']
Safety,"ise <code>AccessDenied</code></em> because the; internal buffer of <code>proc_pidinfo(PROC_PIDLISTFDS)</code> syscall was not big enough.; We now dynamically increase the buffer size until it's big enough instead of; giving up and raising <code>AccessDenied</code>_, which was a fallback to avoid crashing.</li>; <li>1904_, [Windows]: <code>OpenProcess</code> fails with <code>ERROR_SUCCESS</code> due to; <code>GetLastError()</code> called after <code>sprintf()</code>. (patch by alxchk)</li>; <li>1913_, [Linux]: <code>wait_procs()</code>_ should catch <code>subprocess.TimeoutExpired</code>; exception.</li>; <li>1919_, [Linux]: <code>sensors_battery()</code>_ can raise <code>TypeError</code> on PureOS.</li>; <li>1921_, [Windows]: <code>swap_memory()</code>_ shows committed memory instead of swap.</li>; <li>1940_, [Linux]: psutil does not handle <code>ENAMETOOLONG</code> when accessing process; file descriptors in procfs. (patch by Nikita Radchenko)</li>; <li>1948_, <strong>[critical]</strong>: <code>memoize_when_activated</code> decorator is not thread-safe.; (patch by Xuehai Pan)</li>; <li>1953_, [Windows], <strong>[critical]</strong>: <code>disk_partitions()</code>_ crashes due to; insufficient buffer len. (patch by MaWe2019)</li>; <li>1965_, [Windows], <strong>[critical]</strong>: fix &quot;Fatal Python error: deallocating None&quot;; when calling <code>users()</code>_ multiple times.</li>; <li>1980_, [Windows]: 32bit / WoW64 processes fails to read <code>Process.name()</code>_ longer</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/giampaolo/psutil/commit/f1a54ad88527e0706fb8a88ad7daae80686acc62""><code>f1a54ad</code></a> pre-release</li>; <li><a href=""https://github.com/giampaolo/psutil/commit/d81e75e94a1dd2b8d64caa0e72c771a7196a5d15""><code>d81e75e</code></a> HISTORY.rst add hyperlinks pointing to psutil API doc (<a href=""https://github-redirect.dep",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11459:3191,safe,safe,3191,https://hail.is,https://github.com/hail-is/hail/pull/11459,1,['safe'],['safe']
Safety,"ised to <code># %%</code> (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2919"">#2919</a>)</li>; <li>Remove unnecessary parentheses from <code>except</code> statements (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2939"">#2939</a>)</li>; <li>Remove unnecessary parentheses from tuple unpacking in <code>for</code> loops (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2945"">#2945</a>)</li>; <li>Avoid magic-trailing-comma in single-element subscripts (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2942"">#2942</a>)</li>; </ul>; <h3>Configuration</h3>; <ul>; <li>Do not format <code>__pypackages__</code> directories by default (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2836"">#2836</a>)</li>; <li>Add support for specifying stable version with <code>--required-version</code> (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2832"">#2832</a>).</li>; <li>Avoid crashing when the user has no homedir (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2814"">#2814</a>)</li>; <li>Avoid crashing when md5 is not available (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2905"">#2905</a>)</li>; <li>Fix handling of directory junctions on Windows (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2904"">#2904</a>)</li>; </ul>; <h3>Documentation</h3>; <ul>; <li>Update pylint config documentation (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2931"">#2931</a>)</li>; </ul>; <h3>Integrations</h3>; <ul>; <li>Move test to disable plugin in Vim/Neovim, which speeds up loading (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2896"">#2896</a>)</li>; </ul>; <h3>Output</h3>; <ul>; <li>In verbose, mode, log when <em>Black</em> is using user-level config (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2861"">#2861</a>)</li>; </ul>; <h3>Packaging</h3>; <ul>; <li>Fix Black to work with Click 8.1.0 (<",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11696:1299,Avoid,Avoid,1299,https://hail.is,https://github.com/hail-is/hail/pull/11696,2,['Avoid'],['Avoid']
Safety,"it may be possible to avoid creating a new generator per block, but given that each block samples 16M entries for the default blockSize (which I've changed to 4096 in another PR), I don't think it's a big deal.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2849:22,avoid,avoid,22,https://hail.is,https://github.com/hail-is/hail/pull/2849,1,['avoid'],['avoid']
Safety,iter$SingleDirectoryWriteTask.execute(FileFormatWriter.scala:244); at org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$org$apache$spark$sql$execution$datasources$FileFormatWriter$$executeTask$3.apply(FileFormatWriter.scala:190); at org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$org$apache$spark$sql$execution$datasources$FileFormatWriter$$executeTask$3.apply(FileFormatWriter.scala:188); at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1341); at org.apache.spark.sql.execution.datasources.FileFormatWriter$.org$apache$spark$sql$execution$datasources$FileFormatWriter$$executeTask(FileFormatWriter.scala:193); ... 8 more. Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1435); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1423); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1422); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1422); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:802); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1650); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1605); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1594); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.s,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2407:7410,abort,abortStage,7410,https://hail.is,https://github.com/hail-is/hail/issues/2407,1,['abort'],['abortStage']
Safety,"ithub&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/fa47fca0-549b-41a3-8bf7-bcda4ca9a617?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""5da7ca75-f161-4f7a-ae7f-c92bb747eca9"",""prPublicId"":""5da7ca75-f161-4f7a-ae7f-c92bb747eca9"",""dependencies"":[{""name"":""aiohttp"",""from"":""3.8.6"",""to"":""3.9.0""},{""name"":""ipython"",""from"":""7.34.0"",""to"":""8.10.0""},{""name"":""jupyter-server"",""from"":""1.24.0"",""to"":""2.11.2""},{""name"":""setuptools"",""from"":""39.0.1"",""to"":""65.5.1""},{""name"":""tornado"",""from"":""6.2"",""to"":""6.3.3""}],""packageManager"":""pip"",""projectPublicId"":""fa47fca0-549b-41a3-8bf7-bcda4ca9a617"",""projectUrl"":""https://app.snyk.io/org/danking/project/fa47fca0-549b-41a3-8bf7-bcda4ca9a617?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-AIOHTTP-6091621"",""SNYK-PYTHON-AIOHTTP-6091622"",""SNYK-PYTHON-IPYTHON-3318382"",""SNYK-PYTHON-JUPYTERSERVER-5862881"",""SNYK-PYTHON-JUPYTERSERVER-5862882"",""SNYK-PYTHON-JUPYTERSERVER-6099119"",""SNYK-PYTHON-SETUPTOOLS-3180412"",""SNYK-PYTHON-TORNADO-5537286"",""SNYK-PYTHON-TORNADO-5840803"",""SNYK-PYTHON-TORNADO-6041512""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""pr-warning-shown""],""priorityScoreList"":[null,null,531,null,null,null,509,384,494,539],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Improper Input Validation](https://learn.snyk.io/lesson/improper-input-validation/?loc&#x3D;fix-pr); 🦉 [Access Control Bypass](https://learn.snyk.io/lesson/broken-access-control/?loc&#x3D;fix-pr); 🦉 [Open Redirect](https://learn.snyk.io/lesson/open-redirect/?loc&#x3D;fix-pr); 🦉 [More lessons are available in Snyk Learn](https://learn.snyk.io/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14074:6523,remediat,remediationStrategy,6523,https://hail.is,https://github.com/hail-is/hail/pull/14074,1,['remediat'],['remediationStrategy']
Safety,"ization-script-0"", line 61, in <module>; safe_call(*command); File ""/etc/google-dataproc/startup-scripts/dataproc-initialization-script-0"", line 17, in safe_call; raise e; File ""/etc/google-dataproc/startup-scripts/dataproc-initialization-script-0"", line 14, in safe_call; sp.check_output(args, stderr=sp.STDOUT, **kwargs); File ""/opt/conda/default/lib/python3.11/subprocess.py"", line 466, in check_output; return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; File ""/opt/conda/default/lib/python3.11/subprocess.py"", line 571, in run; raise CalledProcessError(retcode, process.args,; subprocess.CalledProcessError: Command '('pip', 'install', 'setuptools', 'mkl<2020', 'lxml<5', 'https://github.com/hail-is/jgscm/archive/v0.1.13+hail.zip', 'ipykernel==6.22.0', 'ipywidgets==8.0.6', 'jupyter-console==6.6.3', 'nbconvert==7.3.1', 'notebook==6.5.6', 'qtconsole==5.4.2', 'aiodns==2.0.0', 'aiohttp==3.9.5', 'aiosignal==1.3.1', 'async-timeout==4.0.3', 'attrs==23.2.0', 'avro==1.11.3', 'azure-common==1.1.28', 'azure-core==1.30.2', 'azure-identity==1.17.1', 'azure-mgmt-core==1.4.0', 'azure-mgmt-storage==20.1.0', 'azure-storage-blob==12.20.0', 'bokeh==3.3.4', 'boto3==1.34.138', 'botocore==1.34.138', 'cachetools==5.3.3', 'certifi==2024.6.2', 'cffi==1.16.0', 'charset-normalizer==3.3.2', 'click==8.1.7', 'commonmark==0.9.1', 'contourpy==1.2.1', 'cryptography==42.0.8', 'decorator==4.4.2', 'deprecated==1.2.14', 'dill==0.3.8', 'frozenlist==1.4.1', 'google-auth==2.31.0', 'google-auth-oauthlib==0.8.0', 'humanize==1.1.0', 'idna==3.7', 'isodate==0.6.1', 'janus==1.0.0', 'jinja2==3.1.4', 'jmespath==1.0.1', 'jproperties==2.1.1', 'markupsafe==2.1.5', 'msal==1.29.0', 'msal-extensions==1.2.0', 'msrest==0.7.1', 'multidict==6.0.5', 'nest-asyncio==1.6.0', 'numpy==1.26.4', 'oauthlib==3.2.2', 'orjson==3.10.6', 'packaging==24.1', 'pandas==2.2.2', 'parsimonious==0.10.0', 'pillow==10.4.0', 'plotly==5.22.0', 'portalocker==2.10.0', 'protobuf==3.2",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14652:5677,timeout,timeout,5677,https://hail.is,https://github.com/hail-is/hail/issues/14652,1,['timeout'],['timeout']
Safety,k.storage.BlockManager.getOrElseUpdate(BlockManager.scala:663); 	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:330); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:281); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); 	at org.apache.spark.scheduler.Task.run(Task.scala:86); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGSche,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1806:2824,abort,abortStage,2824,https://hail.is,https://github.com/hail-is/hail/issues/1806,1,['abort'],['abortStage']
Safety,k.storage.BlockManager.getOrElseUpdate(BlockManager.scala:670); 	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:330); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:281); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); 	at org.apache.spark.scheduler.Task.run(Task.scala:86); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGSche,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3760:8690,abort,abortStage,8690,https://hail.is,https://github.com/hail-is/hail/issues/3760,1,['abort'],['abortStage']
Safety,"kages/hail/backend/hail-all-spark.jar \; --conf spark.executor.extraClassPath=./hail-all-spark.jar \; --conf spark.kryo.registrator=is.hail.kryo.HailKryoRegistrator \; --conf spark.serializer=org.apache.spark.serializer.KryoSerializer \; pyspark-shell '. from pyspark import SparkContext; sc=SparkContext.getOrCreate(). import hail as hl; hl.init(sc=sc); ```. - Error logs ; ```; 22/05/11 14:31:21 WARN Utils: Your hostname, spacerider.local resolves to a loopback address: 127.0.0.1; using 172.20.10.4 instead (on interface en6); 22/05/11 14:31:21 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address; WARNING: An illegal reflective access operation has occurred; WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/Users/username/miniforge3/envs/hail/lib/python3.9/site-packages/pyspark/jars/spark-unsafe_2.12-3.1.2.jar) to constructor java.nio.DirectByteBuffer(long,int); WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform; WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations; WARNING: All illegal access operations will be denied in a future release; 22/05/11 14:31:21 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel). ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); Input In [2], in <cell line: 6>(); 3 sc = spark._sc; 5 import hail as hl; ----> 6 hl.init(sc=sc). File <decorator-gen-1703>:2, in init(sc, app_name, master, local, log, quiet, append, min_block_size, branching_factor, tmp_dir, default_reference, idempotent, global_seed, spark_conf, skip_logging_configuration, local_tmpdir, _optim",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/11827:1470,unsafe,unsafe,1470,https://hail.is,https://github.com/hail-is/hail/issues/11827,1,['unsafe'],['unsafe']
Safety,kpoint(RDD.scala:323); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1658); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.ap,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3235:5936,abort,abortStage,5936,https://hail.is,https://github.com/hail-is/hail/issues/3235,1,['abort'],['abortStage']
Safety,"kubernetes/kubernetes#105405</a>, <a href=""https://github.com/verb""><code>@​verb</code></a>)</li>; <li>Fix kube-proxy regression on UDP services because the logic to detect stale connections was not considering if the endpoint was ready. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/106163"">kubernetes/kubernetes#106163</a>, <a href=""https://github.com/aojea""><code>@​aojea</code></a>) [SIG API Machinery, Apps, Architecture, Auth, Autoscaling, CLI, Cloud Provider, Contributor Experience, Instrumentation, Network, Node, Release, Scalability, Scheduling, Storage, Testing and Windows]</li>; <li>If a conflict occurs when creating an object with <code>generateName</code>, the server now returns an &quot;AlreadyExists&quot; error with a retry option. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/104699"">kubernetes/kubernetes#104699</a>, <a href=""https://github.com/vincepri""><code>@​vincepri</code></a>)</li>; <li>Implement support for recovering from volume expansion failures (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/106154"">kubernetes/kubernetes#106154</a>, <a href=""https://github.com/gnufied""><code>@​gnufied</code></a>) [SIG API Machinery, Apps and Storage]</li>; <li>In kubelet, log verbosity and flush frequency can also be configured via the configuration file and not just via command line flags. In other commands (kube-apiserver, kube-controller-manager), the flags are listed in the &quot;Logs flags&quot; group and not under &quot;Global&quot; or &quot;Misc&quot;. The type for <code>-vmodule</code> was made a bit more descriptive (<code>pattern=N,...</code> instead of <code>moduleSpec</code>). (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/106090"">kubernetes/kubernetes#106090</a>, <a href=""https://github.com/pohly""><code>@​pohly</code></a>) [SIG API Machinery, Architecture, CLI, Cluster Lifecycle, Instrumentation, Node and Scheduling]</li>; <li>Introd",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11957:4581,recover,recovering,4581,https://hail.is,https://github.com/hail-is/hail/pull/11957,1,['recover'],['recovering']
Safety,"l of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI3ZTZiMDk2ZC0xYzc5LTQ2ZjctYjY5Ni0yNjFlM2QzYzU2ZmMiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjdlNmIwOTZkLTFjNzktNDZmNy1iNjk2LTI2MWUzZDNjNTZmYyJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/b7c31419-ec34-40f1-8bc6-ad8303fb329b?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/b7c31419-ec34-40f1-8bc6-ad8303fb329b?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""7e6b096d-1c79-46f7-b696-261e3d3c56fc"",""prPublicId"":""7e6b096d-1c79-46f7-b696-261e3d3c56fc"",""dependencies"":[{""name"":""aiohttp"",""from"":""3.8.6"",""to"":""3.9.0""}],""packageManager"":""pip"",""projectPublicId"":""b7c31419-ec34-40f1-8bc6-ad8303fb329b"",""projectUrl"":""https://app.snyk.io/org/danking/project/b7c31419-ec34-40f1-8bc6-ad8303fb329b?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-AIOHTTP-6091621"",""SNYK-PYTHON-AIOHTTP-6091622""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""priorityScore""],""priorityScoreList"":[663,663],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Improper Input Validation](https://learn.snyk.io/lesson/improper-input-validation/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14036:3557,remediat,remediationStrategy,3557,https://hail.is,https://github.com/hail-is/hail/pull/14036,1,['remediat'],['remediationStrategy']
Safety,"l of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJiOGQwNmE2Yi00MTg0LTRhMzAtOGMxYi0wYzNhZDVkZDk2OTQiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImI4ZDA2YTZiLTQxODQtNGEzMC04YzFiLTBjM2FkNWRkOTY5NCJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/e7c92c7b-5282-49ea-940f-7a5797e2a45a?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/e7c92c7b-5282-49ea-940f-7a5797e2a45a?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""b8d06a6b-4184-4a30-8c1b-0c3ad5dd9694"",""prPublicId"":""b8d06a6b-4184-4a30-8c1b-0c3ad5dd9694"",""dependencies"":[{""name"":""aiohttp"",""from"":""3.8.6"",""to"":""3.9.0""}],""packageManager"":""pip"",""projectPublicId"":""e7c92c7b-5282-49ea-940f-7a5797e2a45a"",""projectUrl"":""https://app.snyk.io/org/danking/project/e7c92c7b-5282-49ea-940f-7a5797e2a45a?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-AIOHTTP-6091621"",""SNYK-PYTHON-AIOHTTP-6091622""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""priorityScore""],""priorityScoreList"":[663,663],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Improper Input Validation](https://learn.snyk.io/lesson/improper-input-validation/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14045:3559,remediat,remediationStrategy,3559,https://hail.is,https://github.com/hail-is/hail/pull/14045,1,['remediat'],['remediationStrategy']
Safety,"l/lib/python3.6/site-packages/hail/matrixtable.py"", line 2371, in count; return (self.count_rows(), self.count_cols()); File ""/Users/dking/anaconda2/envs/hail/lib/python3.6/site-packages/hail/matrixtable.py"", line 2331, in count_rows; TableCount(MatrixRowsTable(self._mir))); File ""/Users/dking/anaconda2/envs/hail/lib/python3.6/site-packages/hail/backend/backend.py"", line 94, in execute; self._to_java_ir(ir))); File ""/Users/dking/anaconda2/envs/hail/lib/python3.6/site-packages/py4j/java_gateway.py"", line 1257, in __call__; answer, self.gateway_client, self.target_id, self.name); File ""/Users/dking/anaconda2/envs/hail/lib/python3.6/site-packages/hail/utils/java.py"", line 227, in deco; 'Error summary: %s' % (deepest, full, hail.__version__, deepest)) from None; hail.utils.java.FatalError: HailException: Error parsing row fields in row 0:; expected 5 fields but only 5 found.; File: foo; Line:; 7	75216143	75216143	C/T	+. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 1.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1.0 (TID 1, localhost, executor driver): is.hail.utils.HailException: foo: Error parsing row fields in row 0:; expected 5 fields but only 5 found.; File: foo; Line:; 7	75216143	75216143	C/T	+; offending line: 7	75216143	75216143	C/T	+; 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:20); 	at is.hail.utils.package$.fatal(package.scala:28); 	at is.hail.utils.Context.wrapException(Context.scala:19); 	at is.hail.utils.WithContext.wrap(Context.scala:43); 	at is.hail.io.LoadMatrix$$anonfun$16$$anonfun$apply$6.apply(LoadMatrix.scala:377); 	at is.hail.io.LoadMatrix$$anonfun$16$$anonfun$apply$6.apply(LoadMatrix.scala:375); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at scala.collection.Iterator$class.foreach(Iterator.scala:893); 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); 	at",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5718:2496,abort,aborted,2496,https://hail.is,https://github.com/hail-is/hail/issues/5718,1,['abort'],['aborted']
Safety,"lContext(); input_vcf = ""gs://seqr-hail/reference_data/GRCh38/1kg/ALL.GRCh38_sites.20170504.vcf.gz""; vds = hc.import_vcf(input_vcf, npartitions=1000, force=True); ```. causes. ```; FatalErrorTraceback (most recent call last); <ipython-input-4-5e86630fbae5> in <module>(); ----> 1 vds = hc.import_vcf(input_vcf, npartitions=1000, force=True). <decorator-gen-291> in import_vcf(self, path, force, force_bgz, header_file, npartitions, sites_only, store_gq, pp_as_pl, skip_bad_ad, generic, call_fields). /home/hail/pyhail-hail-is-master-ebabd77.zip/hail/java.pyc in handle_py4j(func, *args, **kwargs); 111 raise FatalError('%s\n\nJava stack trace:\n%s\n'; 112 'Hail version: %s\n'; --> 113 'Error summary: %s' % (deepest, full, Env.hc().version, deepest)); 114 except py4j.protocol.Py4JError as e:; 115 if e.args[0].startswith('An error occurred while calling'):. FatalError: IllegalArgumentException: Size exceeds Integer.MAX_VALUE. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 0.0 failed 20 times, most recent failure: Lost task 0.19 in stage 0.0 (TID 19, seqr-pipeline-cluster-grch38-w-0.c.seqr-project.internal): java.lang.IllegalArgumentException: Size exceeds Integer.MAX_VALUE; 	at sun.nio.ch.FileChannelImpl.map(FileChannelImpl.java:869); 	at org.apache.spark.storage.DiskStore$$anonfun$getBytes$2.apply(DiskStore.scala:103); 	at org.apache.spark.storage.DiskStore$$anonfun$getBytes$2.apply(DiskStore.scala:91); 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1310); 	at org.apache.spark.storage.DiskStore.getBytes(DiskStore.scala:105); 	at org.apache.spark.storage.BlockManager.getLocalValues(BlockManager.scala:438); 	at org.apache.spark.storage.BlockManager.get(BlockManager.scala:606); 	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:663); 	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:330); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:281); 	at org.apache.spark.rdd.MapPartitions",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1806:1019,abort,aborted,1019,https://hail.is,https://github.com/hail-is/hail/issues/1806,1,['abort'],['aborted']
Safety,la:86); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); Caused by: org.elasticsearch.hadoop.EsHadoopIllegalArgumentException: Unsupported/Unknown Elasticsearch version 6.0.0; 	at org.elasticsearch.hadoop.util.EsMajorVersion.parse(EsMajorVersion.java:79); 	at org.elasticsearch.hadoop.rest.RestClient.remoteEsVersion(RestClient.java:613); 	at org.elasticsearch.hadoop.rest.InitializationUtils.discoverEsVersion(InitializationUtils.java:240); 	... 10 more. Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.ap,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4138:3402,abort,abortStage,3402,https://hail.is,https://github.com/hail-is/hail/issues/4138,1,['abort'],['abortStage']
Safety,lang.Thread.run(Thread.java:748); Caused by: org.elasticsearch.hadoop.EsHadoopIllegalArgumentException: Unsupported/Unknown Elasticsearch version 6.0.0; 	at org.elasticsearch.hadoop.util.EsMajorVersion.parse(EsMajorVersion.java:79); 	at org.elasticsearch.hadoop.rest.RestClient.remoteEsVersion(RestClient.java:613); 	at org.elasticsearch.hadoop.rest.InitializationUtils.discoverEsVersion(InitializationUtils.java:240); 	... 10 more. Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1873); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1886); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4138:3647,abort,abortStage,3647,https://hail.is,https://github.com/hail-is/hail/issues/4138,1,['abort'],['abortStage']
Safety,latedBulk.write(TemplatedBulk.java:58); 	at org.elasticsearch.hadoop.rest.RestRepository.writeToIndex(RestRepository.java:168); 	at org.elasticsearch.spark.rdd.EsRDDWriter.write(EsRDDWriter.scala:67); 	at org.elasticsearch.spark.rdd.EsSpark$$anonfun$doSaveToEs$1.apply(EsSpark.scala:107); 	at org.elasticsearch.spark.rdd.EsSpark$$anonfun$doSaveToEs$1.apply(EsSpark.scala:107); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); 	at org.apache.spark.scheduler.Task.run(Task.scala:86); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGSche,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4250:5740,abort,abortStage,5740,https://hail.is,https://github.com/hail-is/hail/issues/4250,1,['abort'],['abortStage']
Safety,"lcome in the discussion here. # Idea; For any key type, create an encoding to variable-length byte arrays, which preserves the key ordering. That way, algorithms and data structures which use key comparisons can be written monomorphically, with `memcmp` as the only comparison function needed. Idea inspired by [Fast and Memory Efficient Multi-Column Sorts in Apache Arrow Rust](https://arrow.apache.org/blog/2022/11/07/multi-column-sorts-in-arrow-rust-part-2/) blog post. But while they've optimized for vectorized encoding (which we currently can't do), I've preferred simplicity and smaller encodings. # Design; Type encoders can emit three kinds of output to a byte array buffer:; - byte - simply add a byte to the result, first padding an incomplete byte if necessary; - bit - add a bit to the result, possibly leaving an incomplete byte. We must know statically how many bits are used in the byte.; - pad - add `0`s to pad the last incomplete byte. This is safe (prefix-free) because the number of used bits is a (statically known) constant. We use this to ensure the number of used bits is known statically.; 	; Types:; - missingness; - treat as a type constructor `optional<T>`, i.e. base types don't encode missingness. Emits a single bit in the encoding. Can invert this bit to control whether missing values come first or last in the ordering. If missing, nothing is emitted after.; - sort-order; - treat reversing the default ordering as a type constructor `reverse<T>`; - simply inverts the encoding bitwise; - primitive types; - same as in datafusion, encoding has same size as original type; - signed integers - flip the sign bit; - floating point numbers - if sign bit is set, invert all bits, otherwise only flip the sign bit; - arrays; - before each element and after last element, emit continuation bit (0 if no more elements); - pad before each element. This prevents a variable number of missing bits packing into a byte; - strings and byte-arrays; - simply use null-terminated st",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14396:1109,safe,safe,1109,https://hail.is,https://github.com/hail-is/hail/issues/14396,1,['safe'],['safe']
Safety,"ld be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI5Nzc0NDQwMi1iNzEyLTQ5NjMtYWQ0Zi01YjFhZWZmOTcwZDciLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6Ijk3NzQ0NDAyLWI3MTItNDk2My1hZDRmLTViMWFlZmY5NzBkNyJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/701495b8-b53d-48af-82fe-1a6c57aa56cb?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/701495b8-b53d-48af-82fe-1a6c57aa56cb?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""97744402-b712-4963-ad4f-5b1aeff970d7"",""prPublicId"":""97744402-b712-4963-ad4f-5b1aeff970d7"",""dependencies"":[{""name"":""cryptography"",""from"":""41.0.2"",""to"":""41.0.3""}],""packageManager"":""pip"",""projectPublicId"":""701495b8-b53d-48af-82fe-1a6c57aa56cb"",""projectUrl"":""https://app.snyk.io/org/danking/project/701495b8-b53d-48af-82fe-1a6c57aa56cb?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-CRYPTOGRAPHY-5813745"",""SNYK-PYTHON-CRYPTOGRAPHY-5813746"",""SNYK-PYTHON-CRYPTOGRAPHY-5813750""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""priorityScore""],""priorityScoreList"":[471,551,471],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Denial of Service (DoS)](https://learn.snyk.io/lesson/redos/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13365:3984,remediat,remediationStrategy,3984,https://hail.is,https://github.com/hail-is/hail/pull/13365,1,['remediat'],['remediationStrategy']
Safety,lformed at approximately line number 458249: unparsable vcf record with allele M; 	at htsjdk.variant.vcf.AbstractVCFCodec.generateException(AbstractVCFCodec.java:783); 	at htsjdk.variant.vcf.AbstractVCFCodec.checkAllele(AbstractVCFCodec.java:569); 	at htsjdk.variant.vcf.AbstractVCFCodec.parseAlleles(AbstractVCFCodec.java:531); 	at htsjdk.variant.vcf.AbstractVCFCodec.parseVCFLine(AbstractVCFCodec.java:336); 	at htsjdk.variant.vcf.AbstractVCFCodec.decodeLine(AbstractVCFCodec.java:279); 	at htsjdk.variant.vcf.AbstractVCFCodec.decode(AbstractVCFCodec.java:257); 	at is.hail.io.vcf.LoadVCF$$anonfun$13.apply(LoadVCF.scala:850); 	at is.hail.io.vcf.LoadVCF$$anonfun$13.apply(LoadVCF.scala:849); 	at is.hail.io.vcf.LoadVCF$$anonfun$parseLines$1$$anon$1.hasNext(LoadVCF.scala:718); 	... 17 more. Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGSche,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3015:2848,abort,abortStage,2848,https://hail.is,https://github.com/hail-is/hail/issues/3015,1,['abort'],['abortStage']
Safety,"li>; </ol>; <p>(<a href=""https://github-redirect.dependabot.com/aio-libs/async-timeout/issues/258"">#258</a>)</p>; </li>; <li>; <p>Make <code>Timeout</code> class available in <code>__all__</code>.</p>; </li>; </ul>; <h2>async-timeout 4.0.0</h2>; <h1>Changes</h1>; <ul>; <li>; <p>Implemented <code>timeout_at(deadline)</code> (<a href=""https://github-redirect.dependabot.com/aio-libs/async-timeout/issues/117"">#117</a>)</p>; </li>; <li>; <p>Supported <code>timeout.deadline</code> and <code>timeout.expired</code> properties.</p>; </li>; <li>; <p>Drooped <code>timeout.remaining</code> property: it can be calculated as; <code>timeout.deadline - loop.time()</code></p>; </li>; <li>; <p>Dropped <code>timeout.timeout</code> property that returns a relative timeout based on the; timeout object creation time; the absolute <code>timeout.deadline</code> should be used; instead.</p>; </li>; <li>; <p>Added the deadline modification methods: <code>timeout.reject()</code>,; <code>timeout.shift(delay)</code>, <code>timeout.update(deadline)</code>.</p>; </li>; <li>; <p>Deprecated synchronous context manager usage</p>; </li>; </ul>; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/aio-libs/async-timeout/blob/master/CHANGES.rst"">async-timeout's changelog</a>.</em></p>; <blockquote>; <h1>4.0.2 (2021-12-20)</h1>; <h2>Misc</h2>; <ul>; <li><code>[#259](https://github.com/aio-libs/async-timeout/issues/259) &lt;https://github.com/aio-libs/async-timeout/issues/259&gt;</code><em>, <code>[#274](https://github.com/aio-libs/async-timeout/issues/274) &lt;https://github.com/aio-libs/async-timeout/issues/274&gt;</code></em></li>; </ul>; <h1>4.0.1 (2121-11-10)</h1>; <ul>; <li>; <p>Fix regression:</p>; <ol>; <li>; <p>Don't raise TimeoutError from timeout object that doesn't enter into async context; manager</p>; </li>; <li>; <p>Use call_soon() for raising TimeoutError if deadline is reached on entering into; async context manager</p>; </li>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11465:1809,timeout,timeout,1809,https://hail.is,https://github.com/hail-is/hail/pull/11465,1,['timeout'],['timeout']
Safety,"lick/milestone/9?closed=1</a></li>; </ul>; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/pallets/click/blob/main/CHANGES.rst"">click's changelog</a>.</em></p>; <blockquote>; <h2>Version 8.1.0</h2>; <p>Released 2022-03-28</p>; <ul>; <li>; <p>Drop support for Python 3.6. :pr:<code>2129</code></p>; </li>; <li>; <p>Remove previously deprecated code. :pr:<code>2130</code></p>; <ul>; <li><code>Group.resultcallback</code> is renamed to <code>result_callback</code>.</li>; <li><code>autocompletion</code> parameter to <code>Command</code> is renamed to; <code>shell_complete</code>.</li>; <li><code>get_terminal_size</code> is removed, use; <code>shutil.get_terminal_size</code> instead.</li>; <li><code>get_os_args</code> is removed, use <code>sys.argv[1:]</code> instead.</li>; </ul>; </li>; <li>; <p>Rely on :pep:<code>538</code> and :pep:<code>540</code> to handle selecting UTF-8 encoding; instead of ASCII. Click's locale encoding detection is removed.; :issue:<code>2198</code></p>; </li>; <li>; <p>Single options boolean flags with <code>show_default=True</code> only show; the default if it is <code>True</code>. :issue:<code>1971</code></p>; </li>; <li>; <p>The <code>command</code> and <code>group</code> decorators can be applied with or; without parentheses. :issue:<code>1359</code></p>; </li>; <li>; <p>The <code>Path</code> type can check whether the target is executable.; :issue:<code>1961</code></p>; </li>; <li>; <p><code>Command.show_default</code> overrides <code>Context.show_default</code>, instead; of the other way around. :issue:<code>1963</code></p>; </li>; <li>; <p>Parameter decorators and <code>@group</code> handles <code>cls=None</code> the same as; not passing <code>cls</code>. <code>@option</code> handles <code>help=None</code> the same as; not passing <code>help</code>. :issue:<code>[#1959](https://github.com/pallets/click/issues/1959)</code></p>; </li>; <li>; <p>A flag option with <code>requir",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11706:1934,detect,detection,1934,https://hail.is,https://github.com/hail-is/hail/pull/11706,1,['detect'],['detection']
Safety,"lier PR are responded to there and addressed in the code for this one. This PR is to enable `hail-az/https` Azure file references to contain SAS tokens to enable bearer-auth style file access to Azure storage. Basic summary of the changes:; - Update `AzureAsyncFS` url parsing function to look for and separate out a SAS-token-like query string. Note: made fairly specific to SAS tokens - generic detection of query string syntax interferes with glob support and '?' characters in file names; - Added `generate_sas_token` convenience function to `AzureAsyncFS`. Adds new azure-mgmt-storage package requirement.; - Updated `AzureAsyncFS` to use `(account, container, credential)` tuple as internal `BlobServiceClient` cache key; - Updated `AzureAsyncFSURL` and `AzureFileListEntry` to track the token separately from the name, and extend the base classes to allow returning url with or without a token; - Update `RouterFS.ls` function and associated listfiles function to allow for trailing query strings during path traversal; - Update `AsyncFS.open_from` function to handle query-string urls in zero-length case; - Change to existing behavior: `LocalAsyncFSURL.__str__` no longer returns 'file:' prefix. Done to make `str()` output be appropriate for input to `fs` functions across all subclasses; - Updated `InputResource` to not include the SAS token as part of the destination file name; - Updated `inter_cloud/test_fs.py` to generically use query-string-friendly file path building functions to respect the new model, where it is no longer safe to extend URLs by just appending new segments with `+ ""/""` because there may be a query string, and added `'sas/azure-https'` test case to the fixture. Running tests for the SAS case requires some new test variables to allow the test code to generate SAS tokens (`build.yaml/test_hail_python_fs`):; ```; # Required for SAS testing on Azure; export HAIL_TEST_AZURE_RESGRP=haildev; export HAIL_TEST_AZURE_SUBID=12ab51c6-da79-4a99-8dec-3d2decc97343; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13140:1737,safe,safe,1737,https://hail.is,https://github.com/hail-is/hail/pull/13140,1,['safe'],['safe']
Safety,"ll last):; File ""/tmp/f93de2d1-2d89-43f9-9868-f266eb88a6f1/concordance.py"", line 38, in <module>; main(args); File ""/tmp/f93de2d1-2d89-43f9-9868-f266eb88a6f1/concordance.py"", line 19, in main; bi_summary, bi_samples, bi_variants = methods.concordance(bi_past_vds, bi_future_vds); File ""<decorator-gen-1304>"", line 2, in concordance; File ""/tmp/f93de2d1-2d89-43f9-9868-f266eb88a6f1/hail-devel-08a15431a0ef.zip/hail/utils/java.py"", line 155, in handle_py4j; hail.utils.java.FatalError: AssertionError: assertion failed. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 30 in stage 1.0 failed 20 times, most recent failure: Lost task 30.19 in stage 1.0 (TID 4847, lfdev2-sw-f5w2.c.broad-mpg-gnomad.internal): java.lang.AssertionError: assertion failed; 	at scala.Predef$.assert(Predef.scala:156); 	at is.hail.annotations.Region.loadInt(Region.scala:36); 	at is.hail.expr.types.TBinary$.loadLength(TBinary.scala:62); 	at is.hail.annotations.UnsafeRow$.readBinary(UnsafeRow.scala:128); 	at is.hail.annotations.UnsafeRow$.readString(UnsafeRow.scala:139); 	at is.hail.annotations.UnsafeRow$.readAltAllele(UnsafeRow.scala:152); 	at is.hail.annotations.UnsafeRow$.readArrayAltAllele(UnsafeRow.scala:164); 	at is.hail.annotations.UnsafeRow$.read(UnsafeRow.scala:210); 	at is.hail.annotations.UnsafeRow.get(UnsafeRow.scala:257); 	at is.hail.expr.FilterVariants$$anonfun$10.apply(Relational.scala:503); 	at is.hail.expr.FilterVariants$$anonfun$10.apply(Relational.scala:500); 	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:463); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$9$$anon$5.hasNext(OrderedRVD.scala:658); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$9$$anon$5.hasNext(OrderedRVD.scala:658); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$9$$anon$5.hasNext(OrderedRVD.scala:658); 	at scala.collection.Iterator$$anon$11.has",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2743:2273,Unsafe,UnsafeRow,2273,https://hail.is,https://github.com/hail-is/hail/issues/2743,1,['Unsafe'],['UnsafeRow']
Safety,ll.scala:128); 	at is.hail.expr.FunctionRegistry$$anonfun$11.apply$mcIII$sp(FunctionRegistry.scala:685); 	at is.hail.expr.FunctionRegistry$$anonfun$11.apply(FunctionRegistry.scala:685); 	at is.hail.expr.FunctionRegistry$$anonfun$11.apply(FunctionRegistry.scala:685); 	at is.hail.expr.BinaryFun.apply(Fun.scala:122); 	at is.hail.codegen.generated.C9.apply(Unknown Source); 	at is.hail.codegen.generated.C9.apply(Unknown Source); 	at is.hail.expr.CM$$anonfun$runWithDelayedValues$1.apply(CM.scala:84); 	at is.hail.expr.CM$$anonfun$runWithDelayedValues$1.apply(CM.scala:82); 	at is.hail.expr.Parser$$anonfun$is$hail$expr$Parser$$evalNoTypeCheck$1.apply(Parser.scala:64); 	at is.hail.variant.MatrixTable$$anonfun$selectEntries$2.apply(MatrixTable.scala:1112); 	at is.hail.variant.MatrixTable$$anonfun$selectEntries$2.apply(MatrixTable.scala:1102); 	at is.hail.variant.MatrixTable$$anonfun$61$$anonfun$apply$52$$anonfun$apply$5.apply$mcV$sp(MatrixTable.scala:1364); 	at is.hail.expr.types.TStruct$$anonfun$unsafeInsert$1.apply(TStruct.scala:191); 	at is.hail.expr.types.TStruct$$anonfun$unsafeInsert$1.apply(TStruct.scala:191); 	at is.hail.expr.types.TStruct$$anonfun$unsafeInsert$2.apply(TStruct.scala:211); 	at is.hail.expr.types.TStruct$$anonfun$unsafeInsert$2.apply(TStruct.scala:200); 	at is.hail.variant.MatrixTable$$anonfun$61$$anonfun$apply$52.apply(MatrixTable.scala:1363); 	at is.hail.variant.MatrixTable$$anonfun$61$$anonfun$apply$52.apply(MatrixTable.scala:1359); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$10$$anon$3.next(OrderedRVD.scala:818); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$10$$anon$3.next(OrderedRVD.scala:812); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3465:2944,unsafe,unsafeInsert,2944,https://hail.is,https://github.com/hail-is/hail/issues/3465,2,['unsafe'],['unsafeInsert']
Safety,"ll/15650"">#15650</a> (<a href=""https://github.com/Sarthug99""><code>@​Sarthug99</code></a>)</li>; <li>Fix search highlights removal on clearing input box <a href=""https://redirect.github.com/jupyterlab/jupyterlab/pull/15690"">#15690</a> (<a href=""https://github.com/krassowski""><code>@​krassowski</code></a>)</li>; <li>Add scroll margin to headings for better alignment <a href=""https://redirect.github.com/jupyterlab/jupyterlab/pull/15703"">#15703</a> (<a href=""https://github.com/krassowski""><code>@​krassowski</code></a>)</li>; <li>Fix shortcut UI failing on filtering when empty command is given <a href=""https://redirect.github.com/jupyterlab/jupyterlab/pull/15695"">#15695</a> (<a href=""https://github.com/krassowski""><code>@​krassowski</code></a>)</li>; <li>Fix connection loop issue with standalone foreign document in LSP <a href=""https://redirect.github.com/jupyterlab/jupyterlab/pull/15262"">#15262</a> (<a href=""https://github.com/trungleduc""><code>@​trungleduc</code></a>)</li>; <li>Fix outputarea package from not detecting updates <a href=""https://redirect.github.com/jupyterlab/jupyterlab/pull/15642"">#15642</a> (<a href=""https://github.com/MFA-X-AI""><code>@​MFA-X-AI</code></a>)</li>; </ul>; <h3>Maintenance and upkeep improvements</h3>; <ul>; <li>Backport PR <a href=""https://redirect.github.com/jupyterlab/jupyterlab/issues/15524"">#15524</a>: Fix visual tests <a href=""https://redirect.github.com/jupyterlab/jupyterlab/pull/15578"">#15578</a> (<a href=""https://github.com/krassowski""><code>@​krassowski</code></a>)</li>; </ul>; <h3>Documentation improvements</h3>; <ul>; <li>Remove Python 3.0, Notebook 5 mentions from contributor docs <a href=""https://redirect.github.com/jupyterlab/jupyterlab/pull/15710"">#15710</a> (<a href=""https://github.com/JasonWeill""><code>@​JasonWeill</code></a>)</li>; </ul>; <h3>Contributors to this release</h3>; <p>(<a href=""https://github.com/jupyterlab/jupyterlab/graphs/contributors?from=2024-01-19&amp;to=2024-01-30&amp;type=c"">GitHub contributors page f",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14218:1606,detect,detecting,1606,https://hail.is,https://github.com/hail-is/hail/pull/14218,2,['detect'],['detecting']
Safety,"llback will return immediately. The callback is pushed on to the event-loop stack, and on each tick, is checked to determine whether it has returned or not. Blocking operations within the callbacks will block the event loop. This is how CPU viruses, like blockchain manage to slow down web pages that are hijacked to include some mining script: hashing something 30 million times, takes a long time, and JS cannot do anything besides waiting for those operations to finish in a synchronous fashion. Luckily, asynchronous functions are the norm in the JS ecosystem, such that both in the browser, and nodejs, IO functions are (mostly?) asynchronous.; * For NodeJS: Transparently to the user, blocking operations (IO) are executed from kernel threads that Node maintains in the background, effectively making these operations non-blocking (until the thread pool is exhausted). Browsers and NodeJS use different event loops:. NodeJS: libuv event loop; * Node maintains a hidden worker thread pool (kernel threads) through which it issues sys calls, to avoid blocking the event loop. Web: depends on the underlying Javascript Engine; * Chromium: V8: libevent: https://stackoverflow.com/questions/25750884/are-there-significant-differences-between-the-chrome-browser-event-loop-versus-t; * Firefox: Spidermonkey: ?; * https://developer.mozilla.org/en-US/docs/Web/JavaScript/EventLoop#Event_loop. #### Using callbacks; ```js. # Callback-based; function asyncCall(arg, cb => {; const (err, result) = someSynchronousOperation();. cb(err, result);; }. asyncCall(arg,(r, err) => { if(err){ throw new Error(err); doSomething(r)} ); ```. #### Using async/await; Deeply nested callbacks are hard to follow. This is called ""callback hell"". To help combat this, JS, in both NodeJS and Web context, developed Promises. Promises flatten the callback tree. ```js; function asyncPromise(arg) {; return new Promise((resolve, reject) => {; const (err, result) = someSynchronousOperation();; ; if(err) {; reject(err);; retu",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5162:4582,avoid,avoid,4582,https://hail.is,https://github.com/hail-is/hail/pull/5162,1,['avoid'],['avoid']
Safety,llection.AbstractIterator.toArray(Iterator.scala:1336); at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:936); at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:936); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2062); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2062); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:108); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3379:8224,abort,abortStage,8224,https://hail.is,https://github.com/hail-is/hail/issues/3379,1,['abort'],['abortStage']
Safety,llection.AbstractIterator.toArray(Iterator.scala:1336); at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:936); at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:936); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:108); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); at java.lang.Thread.run(Thread.java:748); Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1517); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1505); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1504); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1504); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1732); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1687); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3507:5671,abort,abortStage,5671,https://hail.is,https://github.com/hail-is/hail/issues/3507,1,['abort'],['abortStage']
Safety,"loadField, loadElement returns the field/element address and not the corresponding value (requiring a 2nd load operations specific to the underlying type to retrieve the value, such as unsafe.getInt via Memory.loadInt). Makes for slightly strange semantics, as seen in ArrayElementLengthCheckAggregator.scala:. ```scala; def copyFromAddress(src: Code[Long]): Code[Unit] = {; val srcOff = fb.newField[Long]; //loadField is actually an offset/memory address; // and is actually a no-op unless the field is a pointer type (array currently); val initOffset = typ.loadField(srcOff, 0); //same ; val eltOffset = arrayType.loadElement(region, typ.loadField(srcOff, 1), idx) . Code(; srcOff := src,; init(initContainer.copyFrom(initOffset), initLen = false),; typ.isFieldMissing(srcOff, 1).mux(; Code(typ.setFieldMissing(off, 1),; lenRef := -1),; Code(; lenRef := arrayType.loadLength(typ.loadField(srcOff, 1)), #loadLength calls loadInt on the address returned; seq(container.copyFrom(eltOffset))))); }; ```. cc @tpoterba in case you disagree",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7829:185,unsafe,unsafe,185,https://hail.is,https://github.com/hail-is/hail/issues/7829,1,['unsafe'],['unsafe']
Safety,"loop.run_until_complete(task); usr/lib/python3.9/asyncio/base_events.py:634: in run_until_complete; self.run_forever(); usr/lib/python3.9/asyncio/base_events.py:601: in run_forever; self._run_once(); usr/lib/python3.9/asyncio/base_events.py:1869: in _run_once; event_list = self._selector.select(timeout); _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . self = <selectors.EpollSelector object at 0x7fae890f2d30>; timeout = 15.402000000000001. def select(self, timeout=None):; if timeout is None:; timeout = -1; elif timeout <= 0:; timeout = 0; else:; # epoll_wait() has a resolution of 1 millisecond, round away; # from zero to wait *at least* timeout seconds.; timeout = math.ceil(timeout * 1e3) * 1e-3; ; # epoll_wait() expects `maxevents` to be greater than zero;; # we want to make sure that `select()` can be called when no; # FD is registered.; max_ev = max(len(self._fd_to_key), 1); ; ready = []; try:; > fd_event_list = self._selector.poll(timeout, max_ev); E Failed: Timeout >360.0s. usr/lib/python3.9/selectors.py:469: Failed; ------------------------------ Captured log setup ------------------------------; 2023-09-06T21:45:24 INFO test.conftest conftest.py:14:log_before_after starting test; 2023-09-06T21:45:24 INFO hailtop.aiocloud.aioazure.credentials credentials.py:99:default_credentials using credentials file /test-gsa-key/key.json; ------------------------------ Captured log call -------------------------------; 2023-09-06T21:45:25 INFO azure.identity.aio._internal.get_token_mixin get_token_mixin.py:93:get_token ClientSecretCredential.get_token succeeded; 2023-09-06T21:45:25 INFO batch_client.aioclient aioclient.py:809:_submit created batch 191; 2023-09-06T21:47:17 WARNING hailtop.utils utils.py:842:retry_transient_errors_with_debug_string A transient error occured. We will automatically retry. Do not be alarmed. We have thus far seen 2 transient errors (next delay: 3.794s). The most recent error was <class 'asyncio.exceptions.Timeou",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13582:3579,timeout,timeout,3579,https://hail.is,https://github.com/hail-is/hail/issues/13582,2,"['Timeout', 'timeout']","['Timeout', 'timeout']"
Safety,m.readNonProxyDesc(ObjectInputStream.java:1819); at java.io.ObjectInputStream.readClassDesc(ObjectInputStream.java:1713); at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1986); at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535); at java.io.ObjectInputStream.readObject(ObjectInputStream.java:422); at com.esotericsoftware.kryo.serializers.JavaSerializer.read(JavaSerializer.java:63); ... 25 more. Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1658); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2022); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2043); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2062); at org,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3342:6316,abort,abortStage,6316,https://hail.is,https://github.com/hail-is/hail/issues/3342,1,['abort'],['abortStage']
Safety,"m/aio-libs/async-timeout/commit/8685c60dc0e82ee246fbe3d1aa272d1dfe57c24c""><code>8685c60</code></a> Bump mypy from 0.910 to 0.920 (<a href=""https://github-redirect.dependabot.com/aio-libs/async-timeout/issues/273"">#273</a>)</li>; <li><a href=""https://github.com/aio-libs/async-timeout/commit/f0a0914345b224448220aeb00d71e6a04a5d24bd""><code>f0a0914</code></a> Bump twine from 3.7.0 to 3.7.1 (<a href=""https://github-redirect.dependabot.com/aio-libs/async-timeout/issues/272"">#272</a>)</li>; <li><a href=""https://github.com/aio-libs/async-timeout/commit/e5c813173b8811b30f4a30eeba56fa8808ab15bb""><code>e5c8131</code></a> [pre-commit.ci] pre-commit autoupdate (<a href=""https://github-redirect.dependabot.com/aio-libs/async-timeout/issues/271"">#271</a>)</li>; <li><a href=""https://github.com/aio-libs/async-timeout/commit/c7e10db3d0965422122bef263fb36f6fd7572330""><code>c7e10db</code></a> Fix linter configs</li>; <li><a href=""https://github.com/aio-libs/async-timeout/commit/6af8bf421a799208b27d57c6bf69de0d998fedec""><code>6af8bf4</code></a> Bump pre-commit from 2.15 to 2.16.0 (<a href=""https://github-redirect.dependabot.com/aio-libs/async-timeout/issues/269"">#269</a>)</li>; <li><a href=""https://github.com/aio-libs/async-timeout/commit/c71bbb5b5d7330f6dabfde7a1adec30a4611c0be""><code>c71bbb5</code></a> Bump docutils from 0.18 to 0.18.1 (<a href=""https://github-redirect.dependabot.com/aio-libs/async-timeout/issues/266"">#266</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/aio-libs/async-timeout/compare/v3.0.1...v4.0.2"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=async-timeout&package-manager=pip&previous-version=3.0.1&new-version=4.0.2)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alt",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11465:5709,timeout,timeout,5709,https://hail.is,https://github.com/hail-is/hail/pull/11465,1,['timeout'],['timeout']
Safety,"m/python/importlib_metadata) to permit the latest version.; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/python/importlib_metadata/blob/main/CHANGES.rst"">importlib-metadata's changelog</a>.</em></p>; <blockquote>; <h1>v4.11.2</h1>; <ul>; <li><a href=""https://github-redirect.dependabot.com/python/importlib_metadata/issues/369"">#369</a>: Fixed bug where <code>EntryPoint.extras</code> was returning; match objects and not the extras strings.</li>; </ul>; <h1>v4.11.1</h1>; <ul>; <li><a href=""https://github-redirect.dependabot.com/python/importlib_metadata/issues/367"">#367</a>: In <code>Distribution.requires</code> for egg-info, if <code>requires.txt</code>; is empty, return an empty list.</li>; </ul>; <h1>v4.11.0</h1>; <ul>; <li>bpo-46246: Added <code>__slots__</code> to <code>EntryPoints</code>.</li>; </ul>; <h1>v4.10.2</h1>; <ul>; <li><a href=""https://github-redirect.dependabot.com/python/importlib_metadata/issues/365"">#365</a> and bpo-46546: Avoid leaking <code>method_name</code> in; <code>DeprecatedList</code>.</li>; </ul>; <h1>v4.10.1</h1>; <h1>v2.1.3</h1>; <ul>; <li><a href=""https://github-redirect.dependabot.com/python/importlib_metadata/issues/361"">#361</a>: Avoid potential REDoS in <code>EntryPoint.pattern</code>.</li>; </ul>; <h1>v4.10.0</h1>; <ul>; <li><a href=""https://github-redirect.dependabot.com/python/importlib_metadata/issues/354"">#354</a>: Removed <code>Distribution._local</code> factory. This; functionality was created as a demonstration of the; possible implementation. Now, the; <code>pep517 &lt;https://pypi.org/project/pep517&gt;</code>_ package; provides this functionality directly through; <code>pep517.meta.load &lt;https://github.com/pypa/pep517/blob/a942316305395f8f757f210e2b16f738af73f8b8/pep517/meta.py#L63-L73&gt;</code>_.</li>; </ul>; <h1>v4.9.0</h1>; <ul>; <li>Require Python 3.7 or later.</li>; </ul>; <h1>v4.8.3</h1>; <ul>; <li><a href=""https://github-redirect.dependabot.com/python/importlib_metadata",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11525:1064,Avoid,Avoid,1064,https://hail.is,https://github.com/hail-is/hail/pull/11525,1,['Avoid'],['Avoid']
Safety,"m/vitejs/vite/tree/HEAD/packages/vite/issues/8"">#8</a>...</li>; <li><a href=""https://github.com/vitejs/vite/commit/1afc1c2370e09998f800f9067491a25e9dd463a0""><code>1afc1c2</code></a> fix(wasm): support decoding data URL in Node &lt; v16 (<a href=""https://github.com/vitejs/vite/tree/HEAD/packages/vite/issues/8668"">#8668</a>)</li>; <li><a href=""https://github.com/vitejs/vite/commit/86a55d3cc0668eca79a55f5cf8b6034b9e3bf835""><code>86a55d3</code></a> release: v2.9.12</li>; <li><a href=""https://github.com/vitejs/vite/commit/c0d6c60b45d89e0995a5ea6bf74e9e3c023ae828""><code>c0d6c60</code></a> fix: backport outdated optimized dep removed from module graph (<a href=""https://github.com/vitejs/vite/tree/HEAD/packages/vite/issues/8534"">#8534</a>)</li>; <li><a href=""https://github.com/vitejs/vite/commit/078a7dcabc8ffc93a06c84063fba04e0e2157f3b""><code>078a7dc</code></a> release: v2.9.11</li>; <li><a href=""https://github.com/vitejs/vite/commit/01fa8070fab5faa590fbe312d2465897a0e6c6a2""><code>01fa807</code></a> fix(dev): avoid FOUC when swapping out link tag (fix <a href=""https://github.com/vitejs/vite/tree/HEAD/packages/vite/issues/7973"">#7973</a>) (<a href=""https://github.com/vitejs/vite/tree/HEAD/packages/vite/issues/8495"">#8495</a>)</li>; <li><a href=""https://github.com/vitejs/vite/commit/ab7dc1c4405ce2814ccc38d5979b51ad2f37d4e6""><code>ab7dc1c</code></a> fix: backport respect server.headers in static middlewares (<a href=""https://github.com/vitejs/vite/tree/HEAD/packages/vite/issues/8481"">#8481</a>)</li>; <li><a href=""https://github.com/vitejs/vite/commit/ced0374b867db3c01b910275fda6b76548d72f47""><code>ced0374</code></a> release: v2.9.10</li>; <li><a href=""https://github.com/vitejs/vite/commit/9fdd0a3ae8caaf8a3633b9e2cc81a350ed5cef63""><code>9fdd0a3</code></a> feat: backport treat Astro file scripts as TS (<a href=""https://github.com/vitejs/vite/tree/HEAD/packages/vite/issues/8151"">#8151</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/vitejs/vite/commits/v2.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12142:12365,avoid,avoid,12365,https://hail.is,https://github.com/hail-is/hail/pull/12142,2,['avoid'],['avoid']
Safety,"m_java_error_triplet(deepest, full, error_id) from None; hail.utils.java.FatalError: SparkException: Job aborted due to stage failure: Task 582 in stage 10.0 failed 20 times, most recent failure: Lost task 582.19 in stage 10.0 (TID 461381) (cluster-w-144.c.project-.internal executor 3568): ExecutorLostFailure (executor 3568 exited caused by one of the running tasks) Reason: Executor heartbeat timed out after 128936 ms; Driver stacktrace:. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 582 in stage 10.0 failed 20 times, most recent failure: Lost task 582.19 in stage 10.0 (TID 461381) (cluster-w-144.c.gbsc-project.internal executor 3568): ExecutorLostFailure (executor 3568 exited caused by one of the running tasks) Reason: Executor heartbeat timed out after 128936 ms; Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2304); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2253); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2252); 	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62); 	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2252); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1124); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1124); 	at scala.Option.foreach(Option.scala:407); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1124); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2491); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2433); 	at org.apache.spark.s",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12290:2268,abort,abortStage,2268,https://hail.is,https://github.com/hail-is/hail/issues/12290,1,['abort'],['abortStage']
Safety,make TableOrderBy not use SafeRow,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4433:26,Safe,SafeRow,26,https://hail.is,https://github.com/hail-is/hail/pull/4433,1,['Safe'],['SafeRow']
Safety,make a typechecking safety mode to use in VSM tests,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1858:20,safe,safety,20,https://hail.is,https://github.com/hail-is/hail/issues/1858,1,['safe'],['safety']
Safety,make extra-sure we're not actually trying to serialize UnsafeRow and UIS,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3288:55,Unsafe,UnsafeRow,55,https://hail.is,https://github.com/hail-is/hail/pull/3288,1,['Unsafe'],['UnsafeRow']
Safety,make polygenic risk score example,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/436:15,risk,risk,15,https://hail.is,https://github.com/hail-is/hail/issues/436,1,['risk'],['risk']
Safety,"mand(Command.scala:259); at org.broadinstitute.hail.driver.Main$.runCommand(Main.scala:91); at org.broadinstitute.hail.driver.Main$$anonfun$runCommands$1$$anonfun$1.apply(Main.scala:115); at org.broadinstitute.hail.driver.Main$$anonfun$runCommands$1$$anonfun$1.apply(Main.scala:115); at org.broadinstitute.hail.utils.package$.time(package.scala:119); at org.broadinstitute.hail.driver.Main$$anonfun$runCommands$1.apply(Main.scala:114); at org.broadinstitute.hail.driver.Main$$anonfun$runCommands$1.apply(Main.scala:108); at scala.collection.IndexedSeqOptimized$class.foldl(IndexedSeqOptimized.scala:57); at scala.collection.IndexedSeqOptimized$class.foldLeft(IndexedSeqOptimized.scala:66); at scala.collection.mutable.ArrayOps$ofRef.foldLeft(ArrayOps.scala:186); at org.broadinstitute.hail.driver.Main$.runCommands(Main.scala:108); at org.broadinstitute.hail.driver.Main$.main(Main.scala:233); at org.broadinstitute.hail.driver.Main.main(Main.scala)org.apache.spark.SparkException: Job aborted due to stage failure: Task 3 in stage 1.0 failed 1 times, most recent failure: Lost task 3.0 in stage 1.0 (TID 4, localhost): org.apache.spark.SparkException: Task failed while writing rows; at org.apache.spark.sql.execution.datasources.DefaultWriterContainer.writeRows(WriterContainer.scala:261); at org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand$$anonfun$run$1$$anonfun$apply$mcV$sp$1.apply(InsertIntoHadoopFsRelationCommand.scala:143); at org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand$$anonfun$run$1$$anonfun$apply$mcV$sp$1.apply(InsertIntoHadoopFsRelationCommand.scala:143); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); at org.apache.spark.scheduler.Task.run(Task.scala:86); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1260:6197,abort,aborted,6197,https://hail.is,https://github.com/hail-is/hail/issues/1260,1,['abort'],['aborted']
Safety,"me); Mounts:; /gsa-key from gsa-key (rw); /io from batch-2554-job-4-8vvgl (rw); /var/run/secrets/kubernetes.io/serviceaccount from default-token-8h99c (ro); Conditions:; Type Status; Initialized True ; Ready False ; ContainersReady False ; PodScheduled True ; Volumes:; gsa-key:; Type: Secret (a volume populated by a Secret); SecretName: konradk-gsa-key; Optional: false; batch-2554-job-4-8vvgl:; Type: PersistentVolumeClaim (a reference to a PersistentVolumeClaim in the same namespace); ClaimName: batch-2554-job-4-8vvgl; ReadOnly: false; default-token-8h99c:; Type: Secret (a volume populated by a Secret); SecretName: default-token-8h99c; Optional: false; QoS Class: Burstable; Node-Selectors: <none>; Tolerations: node.kubernetes.io/not-ready:NoExecute for 300s; node.kubernetes.io/unreachable:NoExecute for 300s; preemptible=true; Events:; Type Reason Age From Message; ---- ------ ---- ---- -------; Warning FailedMount 2m59s (x248 over 9h) kubelet, gke-vdc-preemptible-pool-9c7148b2-4gq2 Unable to mount volumes for pod ""batch-2554-job-4-main-cc8d4_batch-pods(968b4ba5-96f6-11e9-8aa3-42010a80015f)"": timeout expired waiting for volumes to attach or mount for pod ""batch-pods""/""batch-2554-job-4-main-cc8d4"". list of unmounted volumes=[batch-2554-job-4-8vvgl]. list of unattached volumes=[gsa-key batch-2554-job-4-8vvgl default-token-8h99c]; # k get pod batch-2554-job-4-main-cc8d4 -n batch-pods -o yaml ; apiVersion: v1; kind: Pod; metadata:; creationTimestamp: ""2019-06-25T03:09:04Z""; generateName: batch-2554-job-4-main-; labels:; app: batch-job; hail.is/batch-instance: cd50b95a89914efb897965a5e982a29d; uuid: 3bf0b121f62d4cfea15cf187a21bc0ed; name: batch-2554-job-4-main-cc8d4; namespace: batch-pods; resourceVersion: ""72628848""; selfLink: /api/v1/namespaces/batch-pods/pods/batch-2554-job-4-main-cc8d4; uid: 968b4ba5-96f6-11e9-8aa3-42010a80015f; spec:; containers:; - command:; - /bin/bash; - -c; - set -ex; mkdir -p /io/pipeline/pipeline-f559bb010746/__TASK__3/; __RESOURCE_FILE__747=/i",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6466:3292,timeout,timeout,3292,https://hail.is,https://github.com/hail-is/hail/issues/6466,1,['timeout'],['timeout']
Safety,"ment; - Implement `app.on_shutdown` signal handler to wait for all asyncio tasks to complete before returning.; - Upgrade `aiohttp == 0.7.3` to address tasks being cancelled before the on_shutdown method is called: https://github.com/aio-libs/aiohttp/issues/3593. ## Testing. - Adding a ""wait `n` seconds"" method that slept for n seconds, and returned the value of an environment variable. This environment variable meant I could track which version of the deployment my script ran against.; - Taking the `deploy.yaml` from the `deploy query` step of the dev deploy, adding the `TEST_VALUE` environment variable with some value and saving it as `new-deploy.yaml`; - Issuing the first wait request (for 50 seconds) (`https://internal.hail.populationgenomics.org.au/$NAMESPACE/query/api/v1alpha/wait?duration=50`); - Issuing the new deploy with:; ```bash; kubectl -n $NAMESPACE apply -f new-deploy.yaml; kubectl -n $NAMESPACE rollout status --timeout=10m deployment query; ```; - When the new pod is created (seen with `kubectl --namespace $NAMESPACE get pod`), issue the second request to the wait method.; - If all goes well, you should have:; - termination logs like those below,; - the first request successfully fulfilled with the response of env value being None (filled by the first pod); - The second request successfully filled, but has the value of the environment value, the one you set in the deploy.yaml (it got scheduled to the new node). Termination logs:. ```; {""severity"": ""INFO"", ""levelname"": ""INFO"", ""asctime"": ""2021-02-24 23:22:40,472"", ""filename"": ""query.py"", ""funcNameAndLine"": ""on_shutdown:253"", ""message"": ""On shutdown request received, with 2 tasks left"", ""hail_log"": 1}; ++ term; ++ kill -TERM 7; + true; + '[' no == yes ']'; + trap - SIGTERM SIGINT; + wait 7; {""severity"": ""INFO"", ""levelname"": ""INFO"", ""asctime"": ""2021-02-24 23:23:26,004"", ""filename"": ""hail_logging.py"", ""funcNameAndLine"": ""log:40"", ""message"": ""https GET /michaelfranklin/query/api/v1alpha/wait done in 50.02",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10106:1005,timeout,timeout,1005,https://hail.is,https://github.com/hail-is/hail/pull/10106,1,['timeout'],['timeout']
Safety,"meout.deadline</code> and <code>timeout.expired</code> properties.</p>; </li>; <li>; <p>Drooped <code>timeout.remaining</code> property: it can be calculated as; <code>timeout.deadline - loop.time()</code></p>; </li>; <li>; <p>Dropped <code>timeout.timeout</code> property that returns a relative timeout based on the; timeout object creation time; the absolute <code>timeout.deadline</code> should be used; instead.</p>; </li>; <li>; <p>Added the deadline modification methods: <code>timeout.reject()</code>,; <code>timeout.shift(delay)</code>, <code>timeout.update(deadline)</code>.</p>; </li>; <li>; <p>Deprecated synchronous context manager usage</p>; </li>; </ul>; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/aio-libs/async-timeout/blob/master/CHANGES.rst"">async-timeout's changelog</a>.</em></p>; <blockquote>; <h1>4.0.2 (2021-12-20)</h1>; <h2>Misc</h2>; <ul>; <li><code>[#259](https://github.com/aio-libs/async-timeout/issues/259) &lt;https://github.com/aio-libs/async-timeout/issues/259&gt;</code><em>, <code>[#274](https://github.com/aio-libs/async-timeout/issues/274) &lt;https://github.com/aio-libs/async-timeout/issues/274&gt;</code></em></li>; </ul>; <h1>4.0.1 (2121-11-10)</h1>; <ul>; <li>; <p>Fix regression:</p>; <ol>; <li>; <p>Don't raise TimeoutError from timeout object that doesn't enter into async context; manager</p>; </li>; <li>; <p>Use call_soon() for raising TimeoutError if deadline is reached on entering into; async context manager</p>; </li>; </ol>; <p>(<a href=""https://github-redirect.dependabot.com/aio-libs/async-timeout/issues/258"">#258</a>)</p>; </li>; <li>; <p>Make <code>Timeout</code> class available in <code>__all__</code>.</p>; </li>; </ul>; <h1>4.0.0 (2021-11-01)</h1>; <ul>; <li>; <p>Implemented <code>timeout_at(deadline)</code> (<a href=""https://github-redirect.dependabot.com/aio-libs/async-timeout/issues/117"">#117</a>)</p>; </li>; <li>; <p>Supported <code>timeout.deadline</code>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11465:2247,timeout,timeout,2247,https://hail.is,https://github.com/hail-is/hail/pull/11465,1,['timeout'],['timeout']
Safety,"meout](https://github.com/aio-libs/async-timeout) from 3.0.1 to 4.0.2.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/aio-libs/async-timeout/releases"">async-timeout's releases</a>.</em></p>; <blockquote>; <h2>v4.0.2</h2>; <h2>Misc</h2>; <ul>; <li><a href=""https://github-redirect.dependabot.com/aio-libs/async-timeout/issues/259"">#259</a>, <a href=""https://github-redirect.dependabot.com/aio-libs/async-timeout/issues/274"">#274</a></li>; </ul>; <h2>v4.0.1</h2>; <ul>; <li>; <p>Fix regression:</p>; <ol>; <li>; <p>Don't raise TimeoutError from timeout object that doesn't enter into async context; manager</p>; </li>; <li>; <p>Use call_soon() for raising TimeoutError if deadline is reached on entering into; async context manager</p>; </li>; </ol>; <p>(<a href=""https://github-redirect.dependabot.com/aio-libs/async-timeout/issues/258"">#258</a>)</p>; </li>; <li>; <p>Make <code>Timeout</code> class available in <code>__all__</code>.</p>; </li>; </ul>; <h2>async-timeout 4.0.0</h2>; <h1>Changes</h1>; <ul>; <li>; <p>Implemented <code>timeout_at(deadline)</code> (<a href=""https://github-redirect.dependabot.com/aio-libs/async-timeout/issues/117"">#117</a>)</p>; </li>; <li>; <p>Supported <code>timeout.deadline</code> and <code>timeout.expired</code> properties.</p>; </li>; <li>; <p>Drooped <code>timeout.remaining</code> property: it can be calculated as; <code>timeout.deadline - loop.time()</code></p>; </li>; <li>; <p>Dropped <code>timeout.timeout</code> property that returns a relative timeout based on the; timeout object creation time; the absolute <code>timeout.deadline</code> should be used; instead.</p>; </li>; <li>; <p>Added the deadline modification methods: <code>timeout.reject()</code>,; <code>timeout.shift(delay)</code>, <code>timeout.update(deadline)</code>.</p>; </li>; <li>; <p>Deprecated synchronous context manager usage</p>; </li>; </ul>; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11465:1025,timeout,timeout,1025,https://hail.is,https://github.com/hail-is/hail/pull/11465,1,['timeout'],['timeout']
Safety,"more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI3YTljMjVmNy0wMTBmLTQxNmItYjc0OS1jNzFkY2I4YjY5YjgiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjdhOWMyNWY3LTAxMGYtNDE2Yi1iNzQ5LWM3MWRjYjhiNjliOCJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/e7c92c7b-5282-49ea-940f-7a5797e2a45a?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/e7c92c7b-5282-49ea-940f-7a5797e2a45a?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""7a9c25f7-010f-416b-b749-c71dcb8b69b8"",""prPublicId"":""7a9c25f7-010f-416b-b749-c71dcb8b69b8"",""dependencies"":[{""name"":""orjson"",""from"":""3.9.7"",""to"":""3.9.15""}],""packageManager"":""pip"",""projectPublicId"":""e7c92c7b-5282-49ea-940f-7a5797e2a45a"",""projectUrl"":""https://app.snyk.io/org/danking/project/e7c92c7b-5282-49ea-940f-7a5797e2a45a?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-ORJSON-6276643""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""priorityScore""],""priorityScoreList"":[661],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Relative Path Traversal](https://learn.snyk.io/lesson/directory-traversal/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14361:3089,remediat,remediationStrategy,3089,https://hail.is,https://github.com/hail-is/hail/pull/14361,1,['remediat'],['remediationStrategy']
Safety,"mp/f93de2d1-2d89-43f9-9868-f266eb88a6f1/hail-devel-08a15431a0ef.zip/hail/utils/java.py"", line 155, in handle_py4j; hail.utils.java.FatalError: AssertionError: assertion failed. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 30 in stage 1.0 failed 20 times, most recent failure: Lost task 30.19 in stage 1.0 (TID 4847, lfdev2-sw-f5w2.c.broad-mpg-gnomad.internal): java.lang.AssertionError: assertion failed; 	at scala.Predef$.assert(Predef.scala:156); 	at is.hail.annotations.Region.loadInt(Region.scala:36); 	at is.hail.expr.types.TBinary$.loadLength(TBinary.scala:62); 	at is.hail.annotations.UnsafeRow$.readBinary(UnsafeRow.scala:128); 	at is.hail.annotations.UnsafeRow$.readString(UnsafeRow.scala:139); 	at is.hail.annotations.UnsafeRow$.readAltAllele(UnsafeRow.scala:152); 	at is.hail.annotations.UnsafeRow$.readArrayAltAllele(UnsafeRow.scala:164); 	at is.hail.annotations.UnsafeRow$.read(UnsafeRow.scala:210); 	at is.hail.annotations.UnsafeRow.get(UnsafeRow.scala:257); 	at is.hail.expr.FilterVariants$$anonfun$10.apply(Relational.scala:503); 	at is.hail.expr.FilterVariants$$anonfun$10.apply(Relational.scala:500); 	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:463); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$9$$anon$5.hasNext(OrderedRVD.scala:658); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$9$$anon$5.hasNext(OrderedRVD.scala:658); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$9$$anon$5.hasNext(OrderedRVD.scala:658); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at is.hail.sparkextras.OrderedRDD$$anonfun$apply$5$$anon$2.hasNext(OrderedRDD.scala:194); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at is.hail.sparkextras.PartitionKeyInfo$.apply(PartitionKeyInfo.scala:30); 	at is.hail",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2743:2610,Unsafe,UnsafeRow,2610,https://hail.is,https://github.com/hail-is/hail/issues/2743,1,['Unsafe'],['UnsafeRow']
Safety,"n _wrap_create_connection\n return await self._loop.create_connection(*args, **kwargs) # type: ignore # noqa\n File ""uvloop/loop.pyx"", line 1974, in create_connection\n File ""uvloop/loop.pyx"", line 1951, in uvloop.loop.Loop.create_connection\nConnectionRefusedError: [Errno 111] Connection refused\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n File ""/usr/local/lib/python3.7/dist-packages/batch/driver/job.py"", line 449, in schedule_job\n timeout=aiohttp.ClientTimeout(total=2),\n File ""/usr/local/lib/python3.7/dist-packages/hailtop/httpx.py"", line 113, in request_and_raise_for_status\n resp = await self.client_session._request(method, url, **kwargs)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/client.py"", line 521, in _request\n req, traces=traces, timeout=real_timeout\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 535, in connect\n proto = await self._create_connection(req, traces, timeout)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 892, in _create_connection\n _, proto = await self._create_direct_connection(req, traces, timeout)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 1051, in _create_direct_connection\n raise last_exc\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 1032, in _create_direct_connection\n client_error=client_error,\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 975, in _wrap_create_connection\n raise client_error(req.connection_key, exc) from exc\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 10.128.0.11:5000 ssl:default [Connection refused]. ```. Now take a look at the worker: It takes us about nine seconds to get to; an initialized FileStore. Maybe FS creation is really slow? We create one; twice in activate. I think we might initialize credentials three times. I; will fix these in a future PR. The main is",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11451:25298,timeout,timeout,25298,https://hail.is,https://github.com/hail-is/hail/pull/11451,1,['timeout'],['timeout']
Safety,"n _wrap_create_connection\n return await self._loop.create_connection(*args, **kwargs) # type: ignore # noqa\n File ""uvloop/loop.pyx"", line 1974, in create_connection\n File ""uvloop/loop.pyx"", line 1951, in uvloop.loop.Loop.create_connection\nConnectionRefusedError: [Errno 111] Connection refused\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n File ""/usr/local/lib/python3.7/dist-packages/batch/driver/job.py"", line 449, in schedule_job\n timeout=aiohttp.ClientTimeout(total=2),\n File ""/usr/local/lib/python3.7/dist-packages/hailtop/httpx.py"", line 113, in request_and_raise_for_status\n resp = await self.client_session._request(method, url, **kwargs)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/client.py"", line 521, in _request\n req, traces=traces, timeout=real_timeout\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 535, in connect\n proto = await self._create_connection(req, traces, timeout)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 892, in _create_connection\n _, proto = await self._create_direct_connection(req, traces, timeout)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 1051, in _create_direct_connection\n raise last_exc\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 1032, in _create_direct_connection\n client_error=client_error,\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 975, in _wrap_create_connection\n raise client_error(req.connection_key, exc) from exc\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 10.128.0.11:5000 ssl:default [Connection refused]; ERROR	2022-03-02 19:06:35,400	job.py	schedule_job:473	error while scheduling job (93, 1) on instance batch-worker-pr-11438-default-g6cibyji6520-standard-9xy2q	Traceback (most recent call last):\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 9",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11451:6621,timeout,timeout,6621,https://hail.is,https://github.com/hail-is/hail/pull/11451,1,['timeout'],['timeout']
Safety,"n _wrap_create_connection\n return await self._loop.create_connection(*args, **kwargs) # type: ignore # noqa\n File ""uvloop/loop.pyx"", line 1974, in create_connection\n File ""uvloop/loop.pyx"", line 1951, in uvloop.loop.Loop.create_connection\nConnectionRefusedError: [Errno 111] Connection refused\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n File ""/usr/local/lib/python3.7/dist-packages/batch/driver/job.py"", line 449, in schedule_job\n timeout=aiohttp.ClientTimeout(total=2),\n File ""/usr/local/lib/python3.7/dist-packages/hailtop/httpx.py"", line 113, in request_and_raise_for_status\n resp = await self.client_session._request(method, url, **kwargs)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/client.py"", line 521, in _request\n req, traces=traces, timeout=real_timeout\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 535, in connect\n proto = await self._create_connection(req, traces, timeout)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 892, in _create_connection\n _, proto = await self._create_direct_connection(req, traces, timeout)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 1051, in _create_direct_connection\n raise last_exc\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 1032, in _create_direct_connection\n client_error=client_error,\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 975, in _wrap_create_connection\n raise client_error(req.connection_key, exc) from exc\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 10.128.0.11:5000 ssl:default [Connection refused]; ERROR	2022-03-02 19:06:37,364	job.py	schedule_job:473	error while scheduling job (90, 1) on instance batch-worker-pr-11438-default-g6cibyji6520-standard-9xy2q	Traceback (most recent call last):\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 9",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11451:11122,timeout,timeout,11122,https://hail.is,https://github.com/hail-is/hail/pull/11451,1,['timeout'],['timeout']
Safety,"n _wrap_create_connection\n return await self._loop.create_connection(*args, **kwargs) # type: ignore # noqa\n File ""uvloop/loop.pyx"", line 1974, in create_connection\n File ""uvloop/loop.pyx"", line 1951, in uvloop.loop.Loop.create_connection\nConnectionRefusedError: [Errno 111] Connection refused\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n File ""/usr/local/lib/python3.7/dist-packages/batch/driver/job.py"", line 449, in schedule_job\n timeout=aiohttp.ClientTimeout(total=2),\n File ""/usr/local/lib/python3.7/dist-packages/hailtop/httpx.py"", line 113, in request_and_raise_for_status\n resp = await self.client_session._request(method, url, **kwargs)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/client.py"", line 521, in _request\n req, traces=traces, timeout=real_timeout\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 535, in connect\n proto = await self._create_connection(req, traces, timeout)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 892, in _create_connection\n _, proto = await self._create_direct_connection(req, traces, timeout)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 1051, in _create_direct_connection\n raise last_exc\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 1032, in _create_direct_connection\n client_error=client_error,\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 975, in _wrap_create_connection\n raise client_error(req.connection_key, exc) from exc\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 10.128.0.11:5000 ssl:default [Connection refused]; ERROR	2022-03-02 19:06:37,390	job.py	schedule_job:473	error while scheduling job (97, 1) on instance batch-worker-pr-11438-default-g6cibyji6520-standard-9xy2q	Traceback (most recent call last):\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 9",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11451:13127,timeout,timeout,13127,https://hail.is,https://github.com/hail-is/hail/pull/11451,1,['timeout'],['timeout']
Safety,"n _wrap_create_connection\n return await self._loop.create_connection(*args, **kwargs) # type: ignore # noqa\n File ""uvloop/loop.pyx"", line 1974, in create_connection\n File ""uvloop/loop.pyx"", line 1951, in uvloop.loop.Loop.create_connection\nConnectionRefusedError: [Errno 111] Connection refused\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n File ""/usr/local/lib/python3.7/dist-packages/batch/driver/job.py"", line 449, in schedule_job\n timeout=aiohttp.ClientTimeout(total=2),\n File ""/usr/local/lib/python3.7/dist-packages/hailtop/httpx.py"", line 113, in request_and_raise_for_status\n resp = await self.client_session._request(method, url, **kwargs)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/client.py"", line 521, in _request\n req, traces=traces, timeout=real_timeout\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 535, in connect\n proto = await self._create_connection(req, traces, timeout)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 892, in _create_connection\n _, proto = await self._create_direct_connection(req, traces, timeout)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 1051, in _create_direct_connection\n raise last_exc\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 1032, in _create_direct_connection\n client_error=client_error,\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 975, in _wrap_create_connection\n raise client_error(req.connection_key, exc) from exc\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 10.128.0.11:5000 ssl:default [Connection refused]; ERROR	2022-03-02 19:06:37,435	job.py	schedule_job:473	error while scheduling job (101, 1) on instance batch-worker-pr-11438-default-g6cibyji6520-standard-9xy2q	Traceback (most recent call last):\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11451:15132,timeout,timeout,15132,https://hail.is,https://github.com/hail-is/hail/pull/11451,1,['timeout'],['timeout']
Safety,"n _wrap_create_connection\n return await self._loop.create_connection(*args, **kwargs) # type: ignore # noqa\n File ""uvloop/loop.pyx"", line 1974, in create_connection\n File ""uvloop/loop.pyx"", line 1951, in uvloop.loop.Loop.create_connection\nConnectionRefusedError: [Errno 111] Connection refused\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n File ""/usr/local/lib/python3.7/dist-packages/batch/driver/job.py"", line 449, in schedule_job\n timeout=aiohttp.ClientTimeout(total=2),\n File ""/usr/local/lib/python3.7/dist-packages/hailtop/httpx.py"", line 113, in request_and_raise_for_status\n resp = await self.client_session._request(method, url, **kwargs)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/client.py"", line 521, in _request\n req, traces=traces, timeout=real_timeout\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 535, in connect\n proto = await self._create_connection(req, traces, timeout)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 892, in _create_connection\n _, proto = await self._create_direct_connection(req, traces, timeout)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 1051, in _create_direct_connection\n raise last_exc\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 1032, in _create_direct_connection\n client_error=client_error,\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 975, in _wrap_create_connection\n raise client_error(req.connection_key, exc) from exc\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 10.128.0.11:5000 ssl:default [Connection refused]; ERROR	2022-03-02 19:06:37,447	job.py	schedule_job:473	error while scheduling job (102, 1) on instance batch-worker-pr-11438-default-g6cibyji6520-standard-9xy2q	Traceback (most recent call last):\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11451:17138,timeout,timeout,17138,https://hail.is,https://github.com/hail-is/hail/pull/11451,1,['timeout'],['timeout']
Safety,"n _wrap_create_connection\n return await self._loop.create_connection(*args, **kwargs) # type: ignore # noqa\n File ""uvloop/loop.pyx"", line 1974, in create_connection\n File ""uvloop/loop.pyx"", line 1951, in uvloop.loop.Loop.create_connection\nConnectionRefusedError: [Errno 111] Connection refused\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n File ""/usr/local/lib/python3.7/dist-packages/batch/driver/job.py"", line 449, in schedule_job\n timeout=aiohttp.ClientTimeout(total=2),\n File ""/usr/local/lib/python3.7/dist-packages/hailtop/httpx.py"", line 113, in request_and_raise_for_status\n resp = await self.client_session._request(method, url, **kwargs)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/client.py"", line 521, in _request\n req, traces=traces, timeout=real_timeout\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 535, in connect\n proto = await self._create_connection(req, traces, timeout)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 892, in _create_connection\n _, proto = await self._create_direct_connection(req, traces, timeout)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 1051, in _create_direct_connection\n raise last_exc\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 1032, in _create_direct_connection\n client_error=client_error,\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 975, in _wrap_create_connection\n raise client_error(req.connection_key, exc) from exc\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 10.128.0.11:5000 ssl:default [Connection refused]; ERROR	2022-03-02 19:06:39,193	job.py	schedule_job:473	error while scheduling job (99, 1) on instance batch-worker-pr-11438-default-g6cibyji6520-standard-9xy2q	Traceback (most recent call last):\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 9",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11451:21287,timeout,timeout,21287,https://hail.is,https://github.com/hail-is/hail/pull/11451,1,['timeout'],['timeout']
Safety,"n _wrap_create_connection\n return await self._loop.create_connection(*args, **kwargs) # type: ignore # noqa\n File ""uvloop/loop.pyx"", line 1974, in create_connection\n File ""uvloop/loop.pyx"", line 1951, in uvloop.loop.Loop.create_connection\nConnectionRefusedError: [Errno 111] Connection refused\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n File ""/usr/local/lib/python3.7/dist-packages/batch/driver/job.py"", line 449, in schedule_job\n timeout=aiohttp.ClientTimeout(total=2),\n File ""/usr/local/lib/python3.7/dist-packages/hailtop/httpx.py"", line 113, in request_and_raise_for_status\n resp = await self.client_session._request(method, url, **kwargs)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/client.py"", line 521, in _request\n req, traces=traces, timeout=real_timeout\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 535, in connect\n proto = await self._create_connection(req, traces, timeout)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 892, in _create_connection\n _, proto = await self._create_direct_connection(req, traces, timeout)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 1051, in _create_direct_connection\n raise last_exc\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 1032, in _create_direct_connection\n client_error=client_error,\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 975, in _wrap_create_connection\n raise client_error(req.connection_key, exc) from exc\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 10.128.0.11:5000 ssl:default [Connection refused]; ERROR	2022-03-02 19:06:39,204	job.py	schedule_job:473	error while scheduling job (100, 1) on instance batch-worker-pr-11438-default-g6cibyji6520-standard-9xy2q	Traceback (most recent call last):\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11451:23292,timeout,timeout,23292,https://hail.is,https://github.com/hail-is/hail/pull/11451,1,['timeout'],['timeout']
Safety,"n _wrap_create_connection\n return await self._loop.create_connection(*args, **kwargs) # type: ignore # noqa\n File ""uvloop/loop.pyx"", line 1974, in create_connection\n File ""uvloop/loop.pyx"", line 1951, in uvloop.loop.Loop.create_connection\nConnectionRefusedError: [Errno 111] Connection refused\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n File ""/usr/local/lib/python3.7/dist-packages/batch/driver/job.py"", line 449, in schedule_job\n timeout=aiohttp.ClientTimeout(total=2),\n File ""/usr/local/lib/python3.7/dist-packages/hailtop/httpx.py"", line 113, in request_and_raise_for_status\n resp = await self.client_session._request(method, url, **kwargs)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/client.py"", line 521, in _request\n req, traces=traces, timeout=real_timeout\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 535, in connect\n proto = await self._create_connection(req, traces, timeout)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 892, in _create_connection\n _, proto = await self._create_direct_connection(req, traces, timeout)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 1051, in _create_direct_connection\n raise last_exc\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 1032, in _create_direct_connection\n client_error=client_error,\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 975, in _wrap_create_connection\n raise client_error(req.connection_key, exc) from exc\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 10.128.0.11:5000 ssl:default [Connection refused]; INFO	2022-03-02 19:06:33,503	job_private.py	schedule_jobs_loop_body:142	starting scheduling jobs for jpim job-private; INFO	2022-03-02 19:06:33,533	job_private.py	schedule_jobs_loop_body:186	scheduled 0 jobs for jpim job-private; INFO	2022-03-02 19:06:34,964	pool.py	cre",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11451:4192,timeout,timeout,4192,https://hail.is,https://github.com/hail-is/hail/pull/11451,1,['timeout'],['timeout']
Safety,"n _wrap_create_connection\n return await self._loop.create_connection(*args, **kwargs) # type: ignore # noqa\n File ""uvloop/loop.pyx"", line 1974, in create_connection\n File ""uvloop/loop.pyx"", line 1951, in uvloop.loop.Loop.create_connection\nConnectionRefusedError: [Errno 111] Connection refused\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n File ""/usr/local/lib/python3.7/dist-packages/batch/driver/job.py"", line 449, in schedule_job\n timeout=aiohttp.ClientTimeout(total=2),\n File ""/usr/local/lib/python3.7/dist-packages/hailtop/httpx.py"", line 113, in request_and_raise_for_status\n resp = await self.client_session._request(method, url, **kwargs)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/client.py"", line 521, in _request\n req, traces=traces, timeout=real_timeout\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 535, in connect\n proto = await self._create_connection(req, traces, timeout)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 892, in _create_connection\n _, proto = await self._create_direct_connection(req, traces, timeout)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 1051, in _create_direct_connection\n raise last_exc\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 1032, in _create_direct_connection\n client_error=client_error,\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 975, in _wrap_create_connection\n raise client_error(req.connection_key, exc) from exc\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 10.128.0.11:5000 ssl:default [Connection refused]; INFO	2022-03-02 19:06:35,620	pool.py	create_instances:244	pool standard n_instances 1 {'pending': 0, 'active': 1, 'inactive': 0, 'deleted': 0} free_cores 0.0 live_free_cores 8.0 ready_cores 11.0; INFO	2022-03-02 19:06:35,620	pool.py	create_instances_from_ready_cores:206",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11451:8626,timeout,timeout,8626,https://hail.is,https://github.com/hail-is/hail/pull/11451,1,['timeout'],['timeout']
Safety,"n _wrap_create_connection\n return await self._loop.create_connection(*args, **kwargs) # type: ignore # noqa\n File ""uvloop/loop.pyx"", line 1974, in create_connection\n File ""uvloop/loop.pyx"", line 1951, in uvloop.loop.Loop.create_connection\nConnectionRefusedError: [Errno 111] Connection refused\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n File ""/usr/local/lib/python3.7/dist-packages/batch/driver/job.py"", line 449, in schedule_job\n timeout=aiohttp.ClientTimeout(total=2),\n File ""/usr/local/lib/python3.7/dist-packages/hailtop/httpx.py"", line 113, in request_and_raise_for_status\n resp = await self.client_session._request(method, url, **kwargs)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/client.py"", line 521, in _request\n req, traces=traces, timeout=real_timeout\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 535, in connect\n proto = await self._create_connection(req, traces, timeout)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 892, in _create_connection\n _, proto = await self._create_direct_connection(req, traces, timeout)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 1051, in _create_direct_connection\n raise last_exc\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 1032, in _create_direct_connection\n client_error=client_error,\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 975, in _wrap_create_connection\n raise client_error(req.connection_key, exc) from exc\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 10.128.0.11:5000 ssl:default [Connection refused]; INFO	2022-03-02 19:06:38,141	resource_manager.py	create_vm:191	created machine batch-worker-pr-11438-default-g6cibyji6520-standard-4d9n8; ERROR	2022-03-02 19:06:39,183	job.py	schedule_job:473	error while scheduling job (98, 1) on instance batch-worker-pr-11438-default-g",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11451:19144,timeout,timeout,19144,https://hail.is,https://github.com/hail-is/hail/pull/11451,1,['timeout'],['timeout']
Safety,"n discussing, for which while loops and if's were not sufficient. We've also discussed plans for implementing join points as a feature in the IR. ### Notable examples:. * Implementation of `whileLoop` (emits bytecode identical to current version):; ```scala; def whileLoop(cond: Code[Boolean], body: Code[Unit]): Code[Unit] =; JoinPoint.CallCC[Unit] { (jb, break) =>; val continue = jb.joinPoint(); val loopBody = jb.joinPoint(); continue.define { _ => JoinPoint.mux(cond, loopBody, break) }; loopBody.define { _ => Code(body, continue(())) }; continue(()); }; ```. * Mutual recursion:; ```scala; def parity(; n: Code[Int],; even: Code[Ctrl],; odd: Code[Ctrl]; ): Code[Ctrl] = {; val isEven = jb.joinPoint[Code[Int]](mb); val isOdd = jb.joinPoint[Code[Int]](mb); isEven.define { i => (i ceq 0).mux(even, isOdd(i - 1)) }; isOdd.define { i => (i ceq 0).mux(odd, isEven(i - 1)) }; isEven(n); }; ```. ### Classes of interest (tl;dr). - `JoinPoint` - Non-returning function. Used to implement control flow in a type-safe, functional way.; - `ParameterPack` - Trait used for tuple deforesting. Allows join-points to be provided multiple; arguments.; - `JoinPointBuilder` - Used to define new join points.; - `CallCC` - Entry-point for expressions with complex control flow. Provides a `JoinPointBuilder`; and a `JoinPoint` to return a value from the expression. ### `JoinPoint`. A `JoinPoint[A]` acts like a non-returning function with an argument of type `A`. The type of an; applied join point is `Code[Ctrl]`, which indicates that this code does some sort of control flow; (like a jump, or a loop), instead of returning a value. Under the hood, `JoinPoint`s are implemented; with a label and a `GOTO` instruction. ```scala; def example1(j: JoinPoint[Code[Int]]): Code[Ctrl] = Code(; j(3),; ""this line is never reached"".println,; j(4)); ```. ### `ParameterPack`. The trait `ParameterPack[A]` says that the type `A` is comprised of a list of `Code[T]`s, such that the structure of that list is statically k",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7055:1512,safe,safe,1512,https://hail.is,https://github.com/hail-is/hail/pull/7055,1,['safe'],['safe']
Safety,n$11.hasNext(Iterator.scala:408); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at org.apache.spark.sql.execution.datasources.DefaultWriterContainer$$anonfun$writeRows$1.apply$mcV$sp(WriterContainer.scala:253); 	at org.apache.spark.sql.execution.datasources.DefaultWriterContainer$$anonfun$writeRows$1.apply(WriterContainer.scala:252); 	at org.apache.spark.sql.execution.datasources.DefaultWriterContainer$$anonfun$writeRows$1.apply(WriterContainer.scala:252); 	at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1348); 	at org.apache.spark.sql.execution.datasources.DefaultWriterContainer.writeRows(WriterContainer.scala:258); 	... 8 more. Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.ap,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1822:5963,abort,abortStage,5963,https://hail.is,https://github.com/hail-is/hail/issues/1822,1,['abort'],['abortStage']
Safety,n$aggregate$1$$anonfun$22.apply(RDD.scala:1113); at org.apache.spark.rdd.RDD$$anonfun$aggregate$1$$anonfun$22.apply(RDD.scala:1113); at org.apache.spark.SparkContext$$anonfun$33.apply(SparkContext.scala:2118); at org.apache.spark.SparkContext$$anonfun$33.apply(SparkContext.scala:2118); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:108); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1658); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.s,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3063:5388,abort,abortStage,5388,https://hail.is,https://github.com/hail-is/hail/issues/3063,2,['abort'],['abortStage']
Safety,"n, payload); 208 path = action_routes[action]; 209 port = self._backend_server_port; --> 210 resp = self._requests_session.post(f'http://localhost:{port}{path}', data=data); 211 if resp.status_code >= 400:; 212 error_json = orjson.loads(resp.content). File /opt/conda/lib/python3.10/site-packages/requests/sessions.py:635, in Session.post(self, url, data, json, **kwargs); 624 def post(self, url, data=None, json=None, **kwargs):; 625 r""""""Sends a POST request. Returns :class:`Response` object.; 626 ; 627 :param url: URL for the new :class:`Request` object.; (...); 632 :rtype: requests.Response; 633 """"""; --> 635 return self.request(""POST"", url, data=data, json=json, **kwargs). File /opt/conda/lib/python3.10/site-packages/requests/sessions.py:587, in Session.request(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json); 582 send_kwargs = {; 583 ""timeout"": timeout,; 584 ""allow_redirects"": allow_redirects,; 585 }; 586 send_kwargs.update(settings); --> 587 resp = self.send(prep, **send_kwargs); 589 return resp. File /opt/conda/lib/python3.10/site-packages/requests/sessions.py:701, in Session.send(self, request, **kwargs); 698 start = preferred_clock(); 700 # Send the request; --> 701 r = adapter.send(request, **kwargs); 703 # Total elapsed time of the request (approximately); 704 elapsed = preferred_clock() - start. File /opt/conda/lib/python3.10/site-packages/requests/adapters.py:502, in HTTPAdapter.send(self, request, stream, timeout, verify, cert, proxies); 487 resp = conn.urlopen(; 488 method=request.method,; 489 url=url,; (...); 498 chunked=chunked,; 499 ); 501 except (ProtocolError, OSError) as err:; --> 502 raise ConnectionError(err, request=request); 504 except MaxRetryError as e:; 505 if isinstance(e.reason, ConnectTimeoutError):; 506 # TODO: Remove this in 3.0.0: see #2811. ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')); ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13960:13019,timeout,timeout,13019,https://hail.is,https://github.com/hail-is/hail/issues/13960,2,"['abort', 'timeout']","['aborted', 'timeout']"
Safety,"nc-timeout's releases</a>.</em></p>; <blockquote>; <h2>v4.0.2</h2>; <h2>Misc</h2>; <ul>; <li><a href=""https://github-redirect.dependabot.com/aio-libs/async-timeout/issues/259"">#259</a>, <a href=""https://github-redirect.dependabot.com/aio-libs/async-timeout/issues/274"">#274</a></li>; </ul>; <h2>v4.0.1</h2>; <ul>; <li>; <p>Fix regression:</p>; <ol>; <li>; <p>Don't raise TimeoutError from timeout object that doesn't enter into async context; manager</p>; </li>; <li>; <p>Use call_soon() for raising TimeoutError if deadline is reached on entering into; async context manager</p>; </li>; </ol>; <p>(<a href=""https://github-redirect.dependabot.com/aio-libs/async-timeout/issues/258"">#258</a>)</p>; </li>; <li>; <p>Make <code>Timeout</code> class available in <code>__all__</code>.</p>; </li>; </ul>; <h2>async-timeout 4.0.0</h2>; <h1>Changes</h1>; <ul>; <li>; <p>Implemented <code>timeout_at(deadline)</code> (<a href=""https://github-redirect.dependabot.com/aio-libs/async-timeout/issues/117"">#117</a>)</p>; </li>; <li>; <p>Supported <code>timeout.deadline</code> and <code>timeout.expired</code> properties.</p>; </li>; <li>; <p>Drooped <code>timeout.remaining</code> property: it can be calculated as; <code>timeout.deadline - loop.time()</code></p>; </li>; <li>; <p>Dropped <code>timeout.timeout</code> property that returns a relative timeout based on the; timeout object creation time; the absolute <code>timeout.deadline</code> should be used; instead.</p>; </li>; <li>; <p>Added the deadline modification methods: <code>timeout.reject()</code>,; <code>timeout.shift(delay)</code>, <code>timeout.update(deadline)</code>.</p>; </li>; <li>; <p>Deprecated synchronous context manager usage</p>; </li>; </ul>; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/aio-libs/async-timeout/blob/master/CHANGES.rst"">async-timeout's changelog</a>.</em></p>; <blockquote>; <h1>4.0.2 (2021-12-20)</h1>; <h2>Misc</h2>; <ul>; <li><code>[#259](htt",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11465:1188,timeout,timeout,1188,https://hail.is,https://github.com/hail-is/hail/pull/11465,2,['timeout'],['timeout']
Safety,nce.apply(CalculateConcordance.scala); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:280); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:214); 	at java.lang.Thread.run(Thread.java:748)java.lang.AssertionError: assertion failed; 	at scala.Predef$.assert(Predef.scala:156); 	at is.hail.annotations.Region.loadInt(Region.scala:36); 	at is.hail.expr.types.TBinary$.loadLength(TBinary.scala:62); 	at is.hail.annotations.UnsafeRow$.readBinary(UnsafeRow.scala:128); 	at is.hail.annotations.UnsafeRow$.readString(UnsafeRow.scala:139); 	at is.hail.annotations.UnsafeRow$.readAltAllele(UnsafeRow.scala:152); 	at is.hail.annotations.UnsafeRow$.readArrayAltAllele(UnsafeRow.scala:164); 	at is.hail.annotations.UnsafeRow$.read(UnsafeRow.scala:210); 	at is.hail.annotations.UnsafeRow.get(UnsafeRow.scala:257); 	at is.hail.expr.FilterVariants$$anonfun$10.apply(Relational.scala:503); 	at is.hail.expr.FilterVariants$$anonfun$10.apply(Relational.scala:500); 	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:463); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$9$$anon$5.hasNext(OrderedRVD.scala:658); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$9$$anon$5.hasNext(OrderedRVD.scala:658); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$9$$anon$5.hasNext(OrderedRVD.scala:658); 	at scala.collection.Iterator$$anon$11.has,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2743:7960,Unsafe,UnsafeRow,7960,https://hail.is,https://github.com/hail-is/hail/issues/2743,1,['Unsafe'],['UnsafeRow']
Safety,"ncy, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiIwMjJhZDMzNS1kYzBkLTQxZWYtYmRjYi03ZTFkODQwNWJhYTYiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjAyMmFkMzM1LWRjMGQtNDFlZi1iZGNiLTdlMWQ4NDA1YmFhNiJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""022ad335-dc0d-41ef-bdcb-7e1d8405baa6"",""prPublicId"":""022ad335-dc0d-41ef-bdcb-7e1d8405baa6"",""dependencies"":[{""name"":""cryptography"",""from"":""41.0.1"",""to"":""41.0.2""}],""packageManager"":""pip"",""projectPublicId"":""5ecb4152-94d0-44ff-86c6-21e542bb123d"",""projectUrl"":""https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-CRYPTOGRAPHY-5777683""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""priorityScore""],""priorityScoreList"":[763],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Learn about vulnerability in an interactive lesson of Snyk Learn.](https://learn.snyk.io/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13247:3154,remediat,remediationStrategy,3154,https://hail.is,https://github.com/hail-is/hail/pull/13247,1,['remediat'],['remediationStrategy']
Safety,"nd': ['/bin/bash',; '-c',; 'set -e; mkdir -p /io/pipeline/pipeline-f0c3c92aa1c4/__TASK__0/; true'],; 'image': 'gcr.io/hail-vdc/benchmark_tpoterba:latest',; 'job_id': 1,; 'mount_docker_socket': False,; 'resources': {'cpu': '1', 'memory': '7G'},; 'pvc_size': '100G',; 'secrets': [{'namespace': 'batch-pods',; 'name': 'dking-gsa-key',; 'mount_path': '/gsa-key',; 'mount_in_copy': True}],; 'env': []},; 'attributes': {'task_uid': '__TASK__0', 'name': 'replicate_0'},; 'status': {'worker': 'batch-worker-default-5t5e9',; 'batch_id': 767,; 'job_id': 1,; 'attempt_id': 'be692b',; 'user': 'dking',; 'state': 'succeeded',; 'container_statuses': {'main': {'name': 'main',; 'state': 'succeeded',; 'timing': {'pulling': {'start_time': 1576710190946,; 'finish_time': 1576710248882,; 'duration': 57936},; 'creating': {'start_time': 1576710248882,; 'finish_time': 1576710248963,; 'duration': 81},; 'runtime': {'start_time': 1576710248963,; 'finish_time': 1576710250461,; 'duration': 1498},; 'starting': {'start_time': 1576710248963,; 'finish_time': 1576710249898,; 'duration': 935},; 'running': {'start_time': 1576710249898,; 'finish_time': 1576710250461,; 'duration': 563},; 'uploading_log': {'start_time': 1576710250464,; 'finish_time': 1576710250742,; 'duration': 278},; 'deleting': {'start_time': 1576710250743,; 'finish_time': 1576710250776,; 'duration': 33}},; 'container_status': {'state': 'exited',; 'started_at': '2019-12-18T23:04:09.890460985Z',; 'finished_at': '2019-12-18T23:04:10.111873413Z',; 'out_of_memory': False,; 'exit_code': 0}}},; 'start_time': 1576710248963,; 'end_time': 1576710250461},; 'msec_mcpu': 2796766,; 'cost': '$0.0000'}; ```. I'd like to be able to load this list as a struct with one command. One would think this arcane magic would do it:; ```; In [16]: t = hl.Table.parallelize([hl.struct(**x) for x in jobs]) ; ```; but of course, nested fields. Probably some partial specification of the type will be necessary, but I would like to avoid specifying the whole thing if possible.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7778:2068,avoid,avoid,2068,https://hail.is,https://github.com/hail-is/hail/issues/7778,1,['avoid'],['avoid']
Safety,"ndarray 3: NDArray, SafeRow, RVB.addAnnotation, JSONAnnotationImpex",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5117:20,Safe,SafeRow,20,https://hail.is,https://github.com/hail-is/hail/pull/5117,1,['Safe'],['SafeRow']
Safety,"ne 449, in send; timeout=timeout; File ""/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py"", line 638, in urlopen; _stacktrace=sys.exc_info()[2]); File ""/usr/local/lib/python3.6/site-packages/urllib3/util/retry.py"", line 368, in increment; raise six.reraise(type(error), error, _stacktrace); File ""/usr/local/lib/python3.6/site-packages/urllib3/packages/six.py"", line 686, in reraise; raise value; File ""/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py"", line 600, in urlopen; chunked=chunked); File ""/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py"", line 386, in _make_request; self._raise_timeout(err=e, url=url, timeout_value=read_timeout); File ""/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py"", line 306, in _raise_timeout; raise ReadTimeoutError(self, url, ""Read timed out. (read timeout=%s)"" % timeout_value); urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='www.googleapis.com', port=443): Read timed out. (read timeout=60). During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/usr/local/lib/python3.6/site-packages/batch/worker.py"", line 293, in run; await self.get_container_log()); File ""/usr/local/lib/python3.6/site-packages/batch/log_store.py"", line 36, in write_log_file; return await self.gcs.write_gs_file(path, data); File ""/usr/local/lib/python3.6/site-packages/batch/google_storage.py"", line 37, in write_gs_file; return await self._wrapped_write_gs_file(self, uri, string, *args, **kwargs); File ""/usr/local/lib/python3.6/site-packages/batch/google_storage.py"", line 56, in wrapped; **kwargs); File ""/usr/local/lib/python3.6/site-packages/hailtop/utils/utils.py"", line 35, in blocking_to_async; thread_pool, lambda: fun(*args, **kwargs)); File ""/usr/local/lib/python3.6/concurrent/futures/thread.py"", line 56, in run; result = self.fn(*self.args, **self.kwargs); File ""/usr/local/lib/python3.6/site-packages/hailtop/utils/utils.py"", line 35, i",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8053:2307,timeout,timeout,2307,https://hail.is,https://github.com/hail-is/hail/issues/8053,2,['timeout'],['timeout']
Safety,"ne 449, in send; timeout=timeout; File ""/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py"", line 638, in urlopen; _stacktrace=sys.exc_info()[2]); File ""/usr/local/lib/python3.6/site-packages/urllib3/util/retry.py"", line 368, in increment; raise six.reraise(type(error), error, _stacktrace); File ""/usr/local/lib/python3.6/site-packages/urllib3/packages/six.py"", line 686, in reraise; raise value; File ""/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py"", line 600, in urlopen; chunked=chunked); File ""/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py"", line 386, in _make_request; self._raise_timeout(err=e, url=url, timeout_value=read_timeout); File ""/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py"", line 306, in _raise_timeout; raise ReadTimeoutError(self, url, ""Read timed out. (read timeout=%s)"" % timeout_value); urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='www.googleapis.com', port=443): Read timed out. (read timeout=60). During handling of the above exception, another exception occurred; result = self.fn(*self.args, **self.kwargs); File ""/usr/local/lib/python3.6/site-packages/hailtop/utils/utils.py"", line 35, in <lambda>; thread_pool, lambda: fun(*args, **kwargs)); File ""/usr/local/lib/python3.6/site-packages/batch/google_storage.py"", line 65, in _write_gs_file; f.upload_from_string(string, *args, **kwargs); File ""/usr/local/lib/python3.6/site-packages/google/cloud/storage/blob.py"", line 1257, in upload_from_string; predefined_acl=predefined_acl,; File ""/usr/local/lib/python3.6/site-packages/google/cloud/storage/blob.py"", line 1157, in upload_from_file; client, file_obj, content_type, size, num_retries, predefined_acl; File ""/usr/local/lib/python3.6/site-packages/google/cloud/storage/blob.py"", line 1063, in _do_upload; client, stream, content_type, size, num_retries, predefined_acl; File ""/usr/local/lib/python3.6/site-packages/google/cloud/storage/blob.py"", line 857, in _do_multipart_upload; ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8054:2743,timeout,timeout,2743,https://hail.is,https://github.com/hail-is/hail/pull/8054,1,['timeout'],['timeout']
Safety,"ne direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJhYmU2OWI5ZC1kMzViLTQ1Y2ItYWY2NS04ZDEwN2YxZWMzZmMiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImFiZTY5YjlkLWQzNWItNDVjYi1hZjY1LThkMTA3ZjFlYzNmYyJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""abe69b9d-d35b-45cb-af65-8d107f1ec3fc"",""prPublicId"":""abe69b9d-d35b-45cb-af65-8d107f1ec3fc"",""dependencies"":[{""name"":""cryptography"",""from"":""40.0.2"",""to"":""41.0.0""}],""packageManager"":""pip"",""projectPublicId"":""5ecb4152-94d0-44ff-86c6-21e542bb123d"",""projectUrl"":""https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-CRYPTOGRAPHY-5663682""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""priorityScore""],""priorityScoreList"":[581],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Denial of Service (DoS)](https://learn.snyk.io/lessons/redos/javascript/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13139:3124,remediat,remediationStrategy,3124,https://hail.is,https://github.com/hail-is/hail/pull/13139,1,['remediat'],['remediationStrategy']
Safety,"ne direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJiYWUwMDM5My05NGUzLTRhNjYtYTE5Ni0xMjUwZDg0ZGZiZDgiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImJhZTAwMzkzLTk0ZTMtNGE2Ni1hMTk2LTEyNTBkODRkZmJkOCJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/701495b8-b53d-48af-82fe-1a6c57aa56cb?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/701495b8-b53d-48af-82fe-1a6c57aa56cb?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""bae00393-94e3-4a66-a196-1250d84dfbd8"",""prPublicId"":""bae00393-94e3-4a66-a196-1250d84dfbd8"",""dependencies"":[{""name"":""cryptography"",""from"":""42.0.2"",""to"":""42.0.4""}],""packageManager"":""pip"",""projectPublicId"":""701495b8-b53d-48af-82fe-1a6c57aa56cb"",""projectUrl"":""https://app.snyk.io/org/danking/project/701495b8-b53d-48af-82fe-1a6c57aa56cb?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-CRYPTOGRAPHY-6261585""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""priorityScore""],""priorityScoreList"":[581],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [NULL Pointer Dereference](https://learn.snyk.io/lesson/null-dereference/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14343:3116,remediat,remediationStrategy,3116,https://hail.is,https://github.com/hail-is/hail/pull/14343,1,['remediat'],['remediationStrategy']
Safety,"ne direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJjOTM3MTIxYy1lZTM3LTQ2ZmMtYTcxMC04MWY4YzdhZmUyN2IiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImM5MzcxMjFjLWVlMzctNDZmYy1hNzEwLTgxZjhjN2FmZTI3YiJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/701495b8-b53d-48af-82fe-1a6c57aa56cb?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/701495b8-b53d-48af-82fe-1a6c57aa56cb?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""c937121c-ee37-46fc-a710-81f8c7afe27b"",""prPublicId"":""c937121c-ee37-46fc-a710-81f8c7afe27b"",""dependencies"":[{""name"":""cryptography"",""from"":""40.0.2"",""to"":""41.0.0""}],""packageManager"":""pip"",""projectPublicId"":""701495b8-b53d-48af-82fe-1a6c57aa56cb"",""projectUrl"":""https://app.snyk.io/org/danking/project/701495b8-b53d-48af-82fe-1a6c57aa56cb?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-CRYPTOGRAPHY-5663682""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""priorityScore""],""priorityScoreList"":[581],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Denial of Service (DoS)](https://learn.snyk.io/lessons/redos/javascript/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13136:3115,remediat,remediationStrategy,3115,https://hail.is,https://github.com/hail-is/hail/pull/13136,1,['remediat'],['remediationStrategy']
Safety,"ne direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJmZWM3ZmQ2Ny0xZmE0LTRlNzEtODQ4Ni1hMDk5YThmYWM3NzgiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImZlYzdmZDY3LTFmYTQtNGU3MS04NDg2LWEwOTlhOGZhYzc3OCJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""fec7fd67-1fa4-4e71-8486-a099a8fac778"",""prPublicId"":""fec7fd67-1fa4-4e71-8486-a099a8fac778"",""dependencies"":[{""name"":""cryptography"",""from"":""40.0.2"",""to"":""41.0.0""}],""packageManager"":""pip"",""projectPublicId"":""c1c98f6a-57c6-4ecc-a329-3b744cab74bd"",""projectUrl"":""https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-CRYPTOGRAPHY-5663682""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""priorityScore""],""priorityScoreList"":[581],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Denial of Service (DoS)](https://learn.snyk.io/lessons/redos/javascript/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13138:3040,remediat,remediationStrategy,3040,https://hail.is,https://github.com/hail-is/hail/pull/13138,1,['remediat'],['remediationStrategy']
Safety,"ne)</code>.</p>; </li>; <li>; <p>Deprecated synchronous context manager usage</p>; </li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/aio-libs/async-timeout/commit/5128f7f4ff73b165579006a8336978efaeeca07a""><code>5128f7f</code></a> Fix CHANGES</li>; <li><a href=""https://github.com/aio-libs/async-timeout/commit/18e718a56f9def7dc40bb9ce3a2962a8fb0c883c""><code>18e718a</code></a> Bump to 4.0.2</li>; <li><a href=""https://github.com/aio-libs/async-timeout/commit/48d1c4ce923b1da75976d7e2a6ca9234b3092c16""><code>48d1c4c</code></a> Setup towncrier</li>; <li><a href=""https://github.com/aio-libs/async-timeout/commit/2ede7d73e55f8d1a2279d78861af0009d96219fb""><code>2ede7d7</code></a> Fix annotations on <code>__exit__</code> and <code>__aexit__</code> (<a href=""https://github-redirect.dependabot.com/aio-libs/async-timeout/issues/274"">#274</a>)</li>; <li><a href=""https://github.com/aio-libs/async-timeout/commit/8685c60dc0e82ee246fbe3d1aa272d1dfe57c24c""><code>8685c60</code></a> Bump mypy from 0.910 to 0.920 (<a href=""https://github-redirect.dependabot.com/aio-libs/async-timeout/issues/273"">#273</a>)</li>; <li><a href=""https://github.com/aio-libs/async-timeout/commit/f0a0914345b224448220aeb00d71e6a04a5d24bd""><code>f0a0914</code></a> Bump twine from 3.7.0 to 3.7.1 (<a href=""https://github-redirect.dependabot.com/aio-libs/async-timeout/issues/272"">#272</a>)</li>; <li><a href=""https://github.com/aio-libs/async-timeout/commit/e5c813173b8811b30f4a30eeba56fa8808ab15bb""><code>e5c8131</code></a> [pre-commit.ci] pre-commit autoupdate (<a href=""https://github-redirect.dependabot.com/aio-libs/async-timeout/issues/271"">#271</a>)</li>; <li><a href=""https://github.com/aio-libs/async-timeout/commit/c7e10db3d0965422122bef263fb36f6fd7572330""><code>c7e10db</code></a> Fix linter configs</li>; <li><a href=""https://github.com/aio-libs/async-timeout/commit/6af8bf421a799208b27d57c6bf69de0d998fedec""><code>6af8bf4</code></a> Bump pre-commit fr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11465:4769,timeout,timeout,4769,https://hail.is,https://github.com/hail-is/hail/pull/11465,1,['timeout'],['timeout']
Safety,"nection to github.com timed out. (connect timeout=15)')': /hail-is/jgscm/archive/v0.1.13+hail.zip; WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ConnectTimeoutError(<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7fef979ba910>, 'Connection to github.com timed out. (connect timeout=15)')': /hail-is/jgscm/archive/v0.1.13+hail.zip; WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ConnectTimeoutError(<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7fef979cc310>, 'Connection to github.com timed out. (connect timeout=15)')': /hail-is/jgscm/archive/v0.1.13+hail.zip; WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ConnectTimeoutError(<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7fef979cce10>, 'Connection to github.com timed out. (connect timeout=15)')': /hail-is/jgscm/archive/v0.1.13+hail.zip; ERROR: Could not install packages due to an OSError: HTTPSConnectionPool(host='github.com', port=443): Max retries exceeded with url: /hail-is/jgscm/archive/v0.1.13+hail.zip (Caused by ConnectTimeoutError(<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7fef979ce290>, 'Connection to github.com timed out. (connect timeout=15)')). Traceback (most recent call last):; File ""/etc/google-dataproc/startup-scripts/dataproc-initialization-script-0"", line 61, in <module>; safe_call(*command); File ""/etc/google-dataproc/startup-scripts/dataproc-initialization-script-0"", line 17, in safe_call; raise e; File ""/etc/google-dataproc/startup-scripts/dataproc-initialization-script-0"", line 14, in safe_call; sp.check_output(args, stderr=sp.STDOUT, **kwargs); File ""/opt/conda/default/lib/python3.11/subprocess.py"", line 466, in check_output; return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14652:4183,timeout,timeout,4183,https://hail.is,https://github.com/hail-is/hail/issues/14652,1,['timeout'],['timeout']
Safety,"nection to github.com timed out. (connect timeout=15)')': /hail-is/jgscm/archive/v0.1.13+hail.zip; WARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ConnectTimeoutError(<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7fef9797e050>, 'Connection to github.com timed out. (connect timeout=15)')': /hail-is/jgscm/archive/v0.1.13+hail.zip; WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ConnectTimeoutError(<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7fef979ba910>, 'Connection to github.com timed out. (connect timeout=15)')': /hail-is/jgscm/archive/v0.1.13+hail.zip; WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ConnectTimeoutError(<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7fef979cc310>, 'Connection to github.com timed out. (connect timeout=15)')': /hail-is/jgscm/archive/v0.1.13+hail.zip; WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ConnectTimeoutError(<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7fef979cce10>, 'Connection to github.com timed out. (connect timeout=15)')': /hail-is/jgscm/archive/v0.1.13+hail.zip; ERROR: Could not install packages due to an OSError: HTTPSConnectionPool(host='github.com', port=443): Max retries exceeded with url: /hail-is/jgscm/archive/v0.1.13+hail.zip (Caused by ConnectTimeoutError(<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7fef979ce290>, 'Connection to github.com timed out. (connect timeout=15)')). Traceback (most recent call last):; File ""/etc/google-dataproc/startup-scripts/dataproc-initialization-script-0"", line 61, in <module>; safe_call(*command); File ""/etc/google-dataproc/startup-scripts/dataproc-initialization-script-0"", line 17, in safe_call; raise e; File ""/etc/google-dataproc/startup-s",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14652:3869,timeout,timeout,3869,https://hail.is,https://github.com/hail-is/hail/issues/14652,1,['timeout'],['timeout']
Safety,"nes that need to change with `# FIXME:; mTLS`. ### Batch Confused Deputy. The [confused deputy; problem](https://en.wikipedia.org/wiki/Confused_deputy_problem) is a classic; in computer security. It refers to a situation with two parties: the deputy and; the attacker. The deputy has authority that the attacker does not. For example,; the deputy can arrest people. A *confused deputy* is one which has been tricked; by the attacker into misusing its authority. In master, Batch has a confused deputy problem: it issues a callback in response; to a batch finishing. That callback is issued from within the cluster and; therefore can name many of our services which are not exposed to the; internet. With the introduction of TLS everywhere, a confused deputy callback; will fail because the victim will not receive a valid Batch certificate (batch; purposely does not send certificates with the callbacks). Batch only uses its; certificate to send a callback for CI. This is safe because we control CI and; ensure it is not compromised. In the long run, I want to fix batch to use an entirely different network for; callbacks. ### Notes of Annoyance. `aiohttp` silently ignores most invalid TLS requests, this makes debugging a TLS; issue difficult. `aiohttp`'s `raise_for_status` does not include the HTTP body in the; message. NGINX sometimes returns 400 in response to TLS issues with a proxy. It; includes crucial details in the HTTP body. I usually debug these issues by; sshing to the client pod and using curl to manually reproduce the error. Readiness and liveness probes cannot use HTTP. Although k8s supports HTTPS, it; does not support so-called ""mTLS"" or ""mutual TLS."" This is fancy verbiage for; servers that require clients to send trusted certificates. I will eventually require; this. There is a lot of information in GitHub issues and the Istio web pages; about this, but at the end of the day, kubernetes does not support this. TCP; probes are the best we can do. There [was a; PR](k",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8561:10053,safe,safe,10053,https://hail.is,https://github.com/hail-is/hail/pull/8561,1,['safe'],['safe']
Safety,ngMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:280); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:214); 	at java.lang.Thread.run(Thread.java:748)java.lang.AssertionError: assertion failed; 	at scala.Predef$.assert(Predef.scala:156); 	at is.hail.annotations.Region.loadInt(Region.scala:36); 	at is.hail.expr.types.TBinary$.loadLength(TBinary.scala:62); 	at is.hail.annotations.UnsafeRow$.readBinary(UnsafeRow.scala:128); 	at is.hail.annotations.UnsafeRow$.readString(UnsafeRow.scala:139); 	at is.hail.annotations.UnsafeRow$.readAltAllele(UnsafeRow.scala:152); 	at is.hail.annotations.UnsafeRow$.readArrayAltAllele(UnsafeRow.scala:164); 	at is.hail.annotations.UnsafeRow$.read(UnsafeRow.scala:210); 	at is.hail.annotations.UnsafeRow.get(UnsafeRow.scala:257); 	at is.hail.expr.FilterVariants$$anonfun$10.apply(Relational.scala:503); 	at is.hail.expr.FilterVariants$$anonfun$10.apply(Relational.scala:500); 	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:463); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$9$$anon$5.hasNext(OrderedRVD.scala:658); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$9$$anon$5.hasNext(OrderedRVD.scala:658); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$9$$anon$5.hasNext(OrderedRVD.scala:658); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at is.hail.sparkextras.OrderedRDD$$anonfun$apply$5$$anon$2.hasNext(OrderedRDD.scala:194); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at scala.collection.Itera,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2743:8175,Unsafe,UnsafeRow,8175,https://hail.is,https://github.com/hail-is/hail/issues/2743,1,['Unsafe'],['UnsafeRow']
Safety,"nginx can use more than one core and at max load + PRs we're maxing out internal-gateway cycles, which add latency, timeouts, retries, and generally degrade the experience in one namespace based on activity in others. Allowing nginx to use more cores (in this case this is up to half our node size) got our system back into its intended state with graceful throttling. I'll admit, other than being half a node size, 4 is a bit arbitrary here. I think our k8s nodes are annoyingly underutilized enough that we shouldn't see issues in practice with letting internal-gateway use cores that are very likely idle.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11876:116,timeout,timeouts,116,https://hail.is,https://github.com/hail-is/hail/pull/11876,1,['timeout'],['timeouts']
Safety,"nixSelectorEventLoop running=False closed=False debug=False>. def _run_once(self):; """"""Run one full iteration of the event loop.; ; This calls all currently ready callbacks, polls for I/O,; schedules the resulting callbacks, and finally schedules; 'call_later' callbacks.; """"""; ; sched_count = len(self._scheduled); if (sched_count > _MIN_SCHEDULED_TIMER_HANDLES and; self._timer_cancelled_count / sched_count >; _MIN_CANCELLED_TIMER_HANDLES_FRACTION):; # Remove delayed calls that were cancelled if their number; # is too high; new_scheduled = []; for handle in self._scheduled:; if handle._cancelled:; handle._scheduled = False; else:; new_scheduled.append(handle); ; heapq.heapify(new_scheduled); self._scheduled = new_scheduled; self._timer_cancelled_count = 0; else:; # Remove delayed calls that were cancelled from head of queue.; while self._scheduled and self._scheduled[0]._cancelled:; self._timer_cancelled_count -= 1; handle = heapq.heappop(self._scheduled); handle._scheduled = False; ; timeout = None; if self._ready or self._stopping:; timeout = 0; elif self._scheduled:; # Compute the desired timeout.; when = self._scheduled[0]._when; timeout = min(max(0, when - self.time()), MAXIMUM_SELECT_TIMEOUT); ; event_list = self._selector.select(timeout); self._process_events(event_list); ; # Handle 'later' callbacks that are ready.; end_time = self.time() + self._clock_resolution; while self._scheduled:; handle = self._scheduled[0]; if handle._when >= end_time:; break; handle = heapq.heappop(self._scheduled); handle._scheduled = False; self._ready.append(handle); ; # This is the only place where callbacks are actually *called*.; # All other places just add them to ready.; # Note: We run all currently scheduled callbacks, but not any; # callbacks scheduled by callbacks run this time around --; # they will be run the next time (after another I/O poll).; # Use an idiom that is thread-safe without using locks.; ntodo = len(self._ready); for i in range(ntodo):; > handle = self._re",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13997:3325,timeout,timeout,3325,https://hail.is,https://github.com/hail-is/hail/issues/13997,1,['timeout'],['timeout']
Safety,"nixSelectorEventLoop running=False closed=False debug=False>. def _run_once(self):; """"""Run one full iteration of the event loop.; ; This calls all currently ready callbacks, polls for I/O,; schedules the resulting callbacks, and finally schedules; 'call_later' callbacks.; """"""; ; sched_count = len(self._scheduled); if (sched_count > _MIN_SCHEDULED_TIMER_HANDLES and; self._timer_cancelled_count / sched_count >; _MIN_CANCELLED_TIMER_HANDLES_FRACTION):; # Remove delayed calls that were cancelled if their number; # is too high; new_scheduled = []; for handle in self._scheduled:; if handle._cancelled:; handle._scheduled = False; else:; new_scheduled.append(handle); ; heapq.heapify(new_scheduled); self._scheduled = new_scheduled; self._timer_cancelled_count = 0; else:; # Remove delayed calls that were cancelled from head of queue.; while self._scheduled and self._scheduled[0]._cancelled:; self._timer_cancelled_count -= 1; handle = heapq.heappop(self._scheduled); handle._scheduled = False; ; timeout = None; if self._ready or self._stopping:; timeout = 0; elif self._scheduled:; # Compute the desired timeout.; when = self._scheduled[0]._when; timeout = min(max(0, when - self.time()), MAXIMUM_SELECT_TIMEOUT); ; if self._debug and timeout != 0:; t0 = self.time(); event_list = self._selector.select(timeout); dt = self.time() - t0; if dt >= 1.0:; level = logging.INFO; else:; level = logging.DEBUG; nevent = len(event_list); if timeout is None:; logger.log(level, 'poll took %.3f ms: %s events',; dt * 1e3, nevent); elif nevent:; logger.log(level,; 'poll %.3f ms took %.3f ms: %s events',; timeout * 1e3, dt * 1e3, nevent); elif dt >= 1.0:; logger.log(level,; 'poll %.3f ms took %.3f ms: timeout',; timeout * 1e3, dt * 1e3); else:; event_list = self._selector.select(timeout); self._process_events(event_list); ; # Handle 'later' callbacks that are ready.; end_time = self.time() + self._clock_resolution; while self._scheduled:; handle = self._scheduled[0]; if handle._when >= end_time:; bre",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10705:2414,timeout,timeout,2414,https://hail.is,https://github.com/hail-is/hail/pull/10705,1,['timeout'],['timeout']
Safety,"nkId{streamId=830947795015, chunkIndex=0}: java.nio.file.NoSuchFileException: /data03/hadoop/yarn/local/usercache/farrell/appcache/application_ion(UnixException.java:86) at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) at sun.nio.fs.UnixException.rethrow.nio.file.Files.newByteChannel(Files.java:361) at java.nio.file.Files.newByteChannel(Files.java:407) at org.apache.spark.shuffle.IndexShuffleBloa:382) at org.apache.spark.network.netty.NettyBlockRpcServer$$anonfun$1.apply(NettyBlockRpcServer.scala:61) at org.apache.spark.network.netty.Na.collection.convert.Wrappers$IteratorWrapper.next(Wrappers.scala:31) at org.apache.spark.network.server.OneForOneStreamManager.getChunk(OneForOn) at org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:101) at org.apache.spark.network.server.Read(AbstractChannelHandlerContext.java:362) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.jdler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(Abstrac348) at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340) at io.netty.handler.codec.MRead(AbstractChannelHandlerContext.java:362) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.jpark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:85) at io.netty.channel.AbstractChannelHandlerContext.invokeChalerContext.java:348) at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340) at io.nettyxt.invokeChannelRead(AbstractChannelHandlerContext.java:362) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelnnel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:138) at io.netty.channel.nio.NioEventLoop.processSelectedKey(Nio.NioEventLoop.pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8106:4473,timeout,timeout,4473,https://hail.is,https://github.com/hail-is/hail/issues/8106,1,['timeout'],['timeout']
Safety,"nnector.py"", line 975, in _wrap_create_connection\n raise client_error(req.connection_key, exc) from exc\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 10.128.0.11:5000 ssl:default [Connection refused]; ERROR	2022-03-02 19:06:37,435	job.py	schedule_job:473	error while scheduling job (101, 1) on instance batch-worker-pr-11438-default-g6cibyji6520-standard-9xy2q	Traceback (most recent call last):\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 969, in _wrap_create_connection\n return await self._loop.create_connection(*args, **kwargs) # type: ignore # noqa\n File ""uvloop/loop.pyx"", line 1974, in create_connection\n File ""uvloop/loop.pyx"", line 1951, in uvloop.loop.Loop.create_connection\nConnectionRefusedError: [Errno 111] Connection refused\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n File ""/usr/local/lib/python3.7/dist-packages/batch/driver/job.py"", line 449, in schedule_job\n timeout=aiohttp.ClientTimeout(total=2),\n File ""/usr/local/lib/python3.7/dist-packages/hailtop/httpx.py"", line 113, in request_and_raise_for_status\n resp = await self.client_session._request(method, url, **kwargs)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/client.py"", line 521, in _request\n req, traces=traces, timeout=real_timeout\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 535, in connect\n proto = await self._create_connection(req, traces, timeout)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 892, in _create_connection\n _, proto = await self._create_direct_connection(req, traces, timeout)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 1051, in _create_direct_connection\n raise last_exc\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 1032, in _create_direct_connection\n client_error=client_error,\n File ""/usr/local/lib/python3.7/dist-packages/aioht",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11451:16647,timeout,timeout,16647,https://hail.is,https://github.com/hail-is/hail/pull/11451,1,['timeout'],['timeout']
Safety,"nnector.py"", line 975, in _wrap_create_connection\n raise client_error(req.connection_key, exc) from exc\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 10.128.0.11:5000 ssl:default [Connection refused]; ERROR	2022-03-02 19:06:37,447	job.py	schedule_job:473	error while scheduling job (102, 1) on instance batch-worker-pr-11438-default-g6cibyji6520-standard-9xy2q	Traceback (most recent call last):\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 969, in _wrap_create_connection\n return await self._loop.create_connection(*args, **kwargs) # type: ignore # noqa\n File ""uvloop/loop.pyx"", line 1974, in create_connection\n File ""uvloop/loop.pyx"", line 1951, in uvloop.loop.Loop.create_connection\nConnectionRefusedError: [Errno 111] Connection refused\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n File ""/usr/local/lib/python3.7/dist-packages/batch/driver/job.py"", line 449, in schedule_job\n timeout=aiohttp.ClientTimeout(total=2),\n File ""/usr/local/lib/python3.7/dist-packages/hailtop/httpx.py"", line 113, in request_and_raise_for_status\n resp = await self.client_session._request(method, url, **kwargs)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/client.py"", line 521, in _request\n req, traces=traces, timeout=real_timeout\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 535, in connect\n proto = await self._create_connection(req, traces, timeout)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 892, in _create_connection\n _, proto = await self._create_direct_connection(req, traces, timeout)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 1051, in _create_direct_connection\n raise last_exc\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 1032, in _create_direct_connection\n client_error=client_error,\n File ""/usr/local/lib/python3.7/dist-packages/aioht",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11451:18653,timeout,timeout,18653,https://hail.is,https://github.com/hail-is/hail/pull/11451,1,['timeout'],['timeout']
Safety,"nnector.py"", line 975, in _wrap_create_connection\n raise client_error(req.connection_key, exc) from exc\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 10.128.0.11:5000 ssl:default [Connection refused]; ERROR	2022-03-02 19:06:39,204	job.py	schedule_job:473	error while scheduling job (100, 1) on instance batch-worker-pr-11438-default-g6cibyji6520-standard-9xy2q	Traceback (most recent call last):\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 969, in _wrap_create_connection\n return await self._loop.create_connection(*args, **kwargs) # type: ignore # noqa\n File ""uvloop/loop.pyx"", line 1974, in create_connection\n File ""uvloop/loop.pyx"", line 1951, in uvloop.loop.Loop.create_connection\nConnectionRefusedError: [Errno 111] Connection refused\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n File ""/usr/local/lib/python3.7/dist-packages/batch/driver/job.py"", line 449, in schedule_job\n timeout=aiohttp.ClientTimeout(total=2),\n File ""/usr/local/lib/python3.7/dist-packages/hailtop/httpx.py"", line 113, in request_and_raise_for_status\n resp = await self.client_session._request(method, url, **kwargs)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/client.py"", line 521, in _request\n req, traces=traces, timeout=real_timeout\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 535, in connect\n proto = await self._create_connection(req, traces, timeout)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 892, in _create_connection\n _, proto = await self._create_direct_connection(req, traces, timeout)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 1051, in _create_direct_connection\n raise last_exc\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 1032, in _create_direct_connection\n client_error=client_error,\n File ""/usr/local/lib/python3.7/dist-packages/aioht",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11451:24807,timeout,timeout,24807,https://hail.is,https://github.com/hail-is/hail/pull/11451,1,['timeout'],['timeout']
Safety,"nomad --requester-pays-allow-buckets gnomad-public-requester-pays \; 	--master-machine-type=n1-highmem-8 --worker-machine-type=n1-highmem-8 \; 	--num-workers=300	--num-secondary-workers=0 \; 	--worker-boot-disk-size=1000 \; 	--properties=dataproc:dataproc.logging.stackdriver.enable=true,dataproc:dataproc.monitoring.stackdriver.enable=true; ```; We are currently receiving a spark error when using this cluster for our larger dataset. ```; [Stage 10:=====> (69 + 656) / 729]; raise err; File ""/opt/conda/default/lib/python3.8/site-packages/hail/backend/py4j_backend.py"", line 98, in execute; result_tuple = self._jbackend.executeEncode(jir, stream_codec, timed); File ""/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py"", line 1304, in __call__; File ""/opt/conda/default/lib/python3.8/site-packages/hail/backend/py4j_backend.py"", line 31, in deco; raise fatal_error_from_java_error_triplet(deepest, full, error_id) from None; hail.utils.java.FatalError: SparkException: Job aborted due to stage failure: Task 582 in stage 10.0 failed 20 times, most recent failure: Lost task 582.19 in stage 10.0 (TID 461381) (cluster-w-144.c.project-.internal executor 3568): ExecutorLostFailure (executor 3568 exited caused by one of the running tasks) Reason: Executor heartbeat timed out after 128936 ms; Driver stacktrace:. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 582 in stage 10.0 failed 20 times, most recent failure: Lost task 582.19 in stage 10.0 (TID 461381) (cluster-w-144.c.gbsc-project.internal executor 3568): ExecutorLostFailure (executor 3568 exited caused by one of the running tasks) Reason: Executor heartbeat timed out after 128936 ms; Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2304); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2253); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGSchedul",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12290:1381,abort,aborted,1381,https://hail.is,https://github.com/hail-is/hail/issues/12290,1,['abort'],['aborted']
Safety,nonfun$mapPartitionsWithIndex$1$$anonfun$apply$26.apply(RDD.scala:844); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$26.apply(RDD.scala:844); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGSche,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3040:6948,abort,abortStage,6948,https://hail.is,https://github.com/hail-is/hail/issues/3040,1,['abort'],['abortStage']
Safety,"notebook"",""from"":""5.7.16"",""to"":""6.4.12""},{""name"":""pygments"",""from"":""2.5.2"",""to"":""2.15.0""},{""name"":""requests"",""from"":""2.27.1"",""to"":""2.31.0""},{""name"":""setuptools"",""from"":""39.0.1"",""to"":""65.5.1""},{""name"":""sphinx"",""from"":""1.8.6"",""to"":""3.3.0""},{""name"":""tornado"",""from"":""5.1.1"",""to"":""6.3.3""},{""name"":""wheel"",""from"":""0.30.0"",""to"":""0.38.0""}],""packageManager"":""pip"",""projectPublicId"":""fa47fca0-549b-41a3-8bf7-bcda4ca9a617"",""projectUrl"":""https://app.snyk.io/org/danking/project/fa47fca0-549b-41a3-8bf7-bcda4ca9a617?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-CERTIFI-3164749"",""SNYK-PYTHON-CERTIFI-5805047"",""SNYK-PYTHON-IPYTHON-2348630"",""SNYK-PYTHON-IPYTHON-3318382"",""SNYK-PYTHON-JUPYTERCORE-3063766"",""SNYK-PYTHON-MISTUNE-2940625"",""SNYK-PYTHON-NBCONVERT-2979829"",""SNYK-PYTHON-NOTEBOOK-1041707"",""SNYK-PYTHON-NOTEBOOK-2441824"",""SNYK-PYTHON-NOTEBOOK-2928995"",""SNYK-PYTHON-PYGMENTS-1086606"",""SNYK-PYTHON-PYGMENTS-1088505"",""SNYK-PYTHON-PYGMENTS-5750273"",""SNYK-PYTHON-REQUESTS-5595532"",""SNYK-PYTHON-SETUPTOOLS-3180412"",""SNYK-PYTHON-SPHINX-570772"",""SNYK-PYTHON-SPHINX-570773"",""SNYK-PYTHON-SPHINX-5811865"",""SNYK-PYTHON-SPHINX-5812109"",""SNYK-PYTHON-TORNADO-5537286"",""SNYK-PYTHON-TORNADO-5840803"",""SNYK-PYTHON-TORNADO-6041512"",""SNYK-PYTHON-WHEEL-3180413""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""pr-warning-shown""],""priorityScoreList"":[null,null,null,531,null,null,null,null,null,null,null,null,null,null,509,null,null,null,null,384,494,539,null],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Remote Code Execution (RCE)](https://learn.snyk.io/lesson/improper-input-validation/?loc&#x3D;fix-pr); 🦉 [Improper Privilege Management](https://learn.snyk.io/lesson/insecure-design/?loc&#x3D;fix-pr); 🦉 [Regular Expression Denial of Service (ReDoS)](https://learn.snyk.io/lesson/redos/?loc&#x3D;fix-pr); 🦉 [More lessons are available in Snyk Learn](https://learn.sny",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14024:11092,remediat,remediationStrategy,11092,https://hail.is,https://github.com/hail-is/hail/pull/14024,1,['remediat'],['remediationStrategy']
Safety,"nother exception occurred:. Traceback (most recent call last):; File ""/usr/local/lib/python3.6/site-packages/requests/adapters.py"", line 449, in send; timeout=timeout; File ""/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py"", line 638, in urlopen; _stacktrace=sys.exc_info()[2]); File ""/usr/local/lib/python3.6/site-packages/urllib3/util/retry.py"", line 368, in increment; raise six.reraise(type(error), error, _stacktrace); File ""/usr/local/lib/python3.6/site-packages/urllib3/packages/six.py"", line 686, in reraise; raise value; File ""/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py"", line 600, in urlopen; chunked=chunked); File ""/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py"", line 386, in _make_request; self._raise_timeout(err=e, url=url, timeout_value=read_timeout); File ""/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py"", line 306, in _raise_timeout; raise ReadTimeoutError(self, url, ""Read timed out. (read timeout=%s)"" % timeout_value); urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='www.googleapis.com', port=443): Read timed out. (read timeout=60). During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/usr/local/lib/python3.6/site-packages/batch/worker.py"", line 293, in run; await self.get_container_log()); File ""/usr/local/lib/python3.6/site-packages/batch/log_store.py"", line 36, in write_log_file; return await self.gcs.write_gs_file(path, data); File ""/usr/local/lib/python3.6/site-packages/batch/google_storage.py"", line 37, in write_gs_file; return await self._wrapped_write_gs_file(self, uri, string, *args, **kwargs); File ""/usr/local/lib/python3.6/site-packages/batch/google_storage.py"", line 56, in wrapped; **kwargs); File ""/usr/local/lib/python3.6/site-packages/hailtop/utils/utils.py"", line 35, in blocking_to_async; thread_pool, lambda: fun(*args, **kwargs)); File ""/usr/local/lib/python3.6/concurrent/futures/thread.py"", line 56",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8053:2159,timeout,timeout,2159,https://hail.is,https://github.com/hail-is/hail/issues/8053,2,['timeout'],['timeout']
Safety,"nother exception occurred:. Traceback (most recent call last):; File ""/usr/local/lib/python3.6/site-packages/requests/adapters.py"", line 449, in send; timeout=timeout; File ""/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py"", line 638, in urlopen; _stacktrace=sys.exc_info()[2]); File ""/usr/local/lib/python3.6/site-packages/urllib3/util/retry.py"", line 368, in increment; raise six.reraise(type(error), error, _stacktrace); File ""/usr/local/lib/python3.6/site-packages/urllib3/packages/six.py"", line 686, in reraise; raise value; File ""/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py"", line 600, in urlopen; chunked=chunked); File ""/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py"", line 386, in _make_request; self._raise_timeout(err=e, url=url, timeout_value=read_timeout); File ""/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py"", line 306, in _raise_timeout; raise ReadTimeoutError(self, url, ""Read timed out. (read timeout=%s)"" % timeout_value); urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='www.googleapis.com', port=443): Read timed out. (read timeout=60). During handling of the above exception, another exception occurred; result = self.fn(*self.args, **self.kwargs); File ""/usr/local/lib/python3.6/site-packages/hailtop/utils/utils.py"", line 35, in <lambda>; thread_pool, lambda: fun(*args, **kwargs)); File ""/usr/local/lib/python3.6/site-packages/batch/google_storage.py"", line 65, in _write_gs_file; f.upload_from_string(string, *args, **kwargs); File ""/usr/local/lib/python3.6/site-packages/google/cloud/storage/blob.py"", line 1257, in upload_from_string; predefined_acl=predefined_acl,; File ""/usr/local/lib/python3.6/site-packages/google/cloud/storage/blob.py"", line 1157, in upload_from_file; client, file_obj, content_type, size, num_retries, predefined_acl; File ""/usr/local/lib/python3.6/site-packages/google/cloud/storage/blob.py"", line 1063, in _do_upload; client, stream, content_type, size, num_r",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8054:2595,timeout,timeout,2595,https://hail.is,https://github.com/hail-is/hail/pull/8054,1,['timeout'],['timeout']
Safety,"nspace-data</code>: [<code>botocore</code>] Add new APIs for managing Users and Permission Groups.</li>; <li>api-change:<code>amplify</code>: [<code>botocore</code>] Add repositoryCloneMethod field for hosting an Amplify app. This field shows what authorization method is used to clone the repo: SSH, TOKEN, or SIGV4.</li>; <li>api-change:<code>fsx</code>: [<code>botocore</code>] This release adds support for the following FSx for OpenZFS features: snapshot lifecycle transition messages, force flag for deleting file systems with child resources, LZ4 data compression, custom record sizes, and unsetting volume quotas and reservations.</li>; <li>api-change:<code>fis</code>: [<code>botocore</code>] This release adds logging support for AWS Fault Injection Simulator experiments. Experiment templates can now be configured to send experiment activity logs to Amazon CloudWatch Logs or to an S3 bucket.</li>; <li>api-change:<code>route53-recovery-cluster</code>: [<code>botocore</code>] This release adds a new API option to enable overriding safety rules to allow routing control state updates.</li>; <li>api-change:<code>amplifyuibuilder</code>: [<code>botocore</code>] We are adding the ability to configure workflows and actions for components.</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/boto/boto3/commit/67b84e02c185294c54a8e49510d4cb962e89cee2""><code>67b84e0</code></a> Merge branch 'release-1.21.13'</li>; <li><a href=""https://github.com/boto/boto3/commit/99acd545b20fe30ffa2f589a674c5a7ad74c266b""><code>99acd54</code></a> Bumping version to 1.21.13</li>; <li><a href=""https://github.com/boto/boto3/commit/83a8f662655bada44d442df7f33cb20d71ead257""><code>83a8f66</code></a> Add changelog entries from botocore</li>; <li><a href=""https://github.com/boto/boto3/commit/261b0f2ffe079b6940d683657fcad358195f882e""><code>261b0f2</code></a> Merge branch 'release-1.21.12'</li",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11504:5132,recover,recovery-cluster,5132,https://hail.is,https://github.com/hail-is/hail/pull/11504,2,"['recover', 'safe']","['recovery-cluster', 'safety']"
Safety,"nspace-data</code>: [<code>botocore</code>] Add new APIs for managing Users and Permission Groups.</li>; <li>api-change:<code>amplify</code>: [<code>botocore</code>] Add repositoryCloneMethod field for hosting an Amplify app. This field shows what authorization method is used to clone the repo: SSH, TOKEN, or SIGV4.</li>; <li>api-change:<code>fsx</code>: [<code>botocore</code>] This release adds support for the following FSx for OpenZFS features: snapshot lifecycle transition messages, force flag for deleting file systems with child resources, LZ4 data compression, custom record sizes, and unsetting volume quotas and reservations.</li>; <li>api-change:<code>fis</code>: [<code>botocore</code>] This release adds logging support for AWS Fault Injection Simulator experiments. Experiment templates can now be configured to send experiment activity logs to Amazon CloudWatch Logs or to an S3 bucket.</li>; <li>api-change:<code>route53-recovery-cluster</code>: [<code>botocore</code>] This release adds a new API option to enable overriding safety rules to allow routing control state updates.</li>; <li>api-change:<code>amplifyuibuilder</code>: [<code>botocore</code>] We are adding the ability to configure workflows and actions for components.</li>; <li>api-change:<code>athena</code>: [<code>botocore</code>] This release adds support for updating an existing named query.</li>; <li>api-change:<code>ec2</code>: [<code>botocore</code>] This release adds support for new AMI property 'lastLaunchedTime'</li>; <li>api-change:<code>servicecatalog-appregistry</code>: [<code>botocore</code>] AppRegistry is deprecating Application and Attribute-Group Name update feature. In this release, we are marking the name attributes for Update APIs as deprecated to give a heads up to our customers.</li>; </ul>; <h1>1.21.8</h1>; <ul>; <li>api-change:<code>elasticache</code>: [<code>botocore</code>] Doc only update for ElastiCache</li>; <li>api-change:<code>panorama</code>: [<code>botocore</code>] Added",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11486:3685,recover,recovery-cluster,3685,https://hail.is,https://github.com/hail-is/hail/pull/11486,2,"['recover', 'safe']","['recovery-cluster', 'safety']"
Safety,nt.vcf.AbstractVCFCodec.generateException(AbstractVCFCodec.java:783); 	at htsjdk.variant.vcf.AbstractVCFCodec.checkAllele(AbstractVCFCodec.java:569); 	at htsjdk.variant.vcf.AbstractVCFCodec.parseAlleles(AbstractVCFCodec.java:531); 	at htsjdk.variant.vcf.AbstractVCFCodec.parseVCFLine(AbstractVCFCodec.java:336); 	at htsjdk.variant.vcf.AbstractVCFCodec.decodeLine(AbstractVCFCodec.java:279); 	at htsjdk.variant.vcf.AbstractVCFCodec.decode(AbstractVCFCodec.java:257); 	at is.hail.io.vcf.LoadVCF$$anonfun$13.apply(LoadVCF.scala:850); 	at is.hail.io.vcf.LoadVCF$$anonfun$13.apply(LoadVCF.scala:849); 	at is.hail.io.vcf.LoadVCF$$anonfun$parseLines$1$$anon$1.hasNext(LoadVCF.scala:718); 	... 17 more. Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1658); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.ap,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3015:2946,abort,abortStage,2946,https://hail.is,https://github.com/hail-is/hail/issues/3015,1,['abort'],['abortStage']
Safety,"o be delayed by pre-emptive promise creation (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/2702"">#2702</a>)</li>; <li>Adding &quot;synchronous&quot; and &quot;runWhen&quot; options to interceptors api (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/2702"">#2702</a>)</li>; <li>Updating of transformResponse (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3377"">#3377</a>)</li>; <li>Adding ability to omit User-Agent header (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3703"">#3703</a>)</li>; <li>Adding multiple JSON improvements (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3688"">#3688</a>, <a href=""https://github-redirect.dependabot.com/axios/axios/pull/3763"">#3763</a>)</li>; <li>Fixing quadratic runtime and extra memory usage when setting a maxContentLength (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3738"">#3738</a>)</li>; <li>Adding parseInt to config.timeout (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3781"">#3781</a>)</li>; <li>Adding custom return type support to interceptor (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3783"">#3783</a>)</li>; <li>Adding security fix for ReDoS vulnerability (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3980"">#3980</a>)</li>; </ul>; <p>Internal and Tests:</p>; <ul>; <li>Updating build dev dependancies (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3401"">#3401</a>)</li>; <li>Fixing builds running on Travis CI (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3538"">#3538</a>)</li>; <li>Updating follow rediect version (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3694"">#3694</a>, <a href=""https://github-redirect.dependabot.com/axios/axios/pull/3771"">#3771</a>)</li>; <li>Updating karma sauce launcher to fix failing sauce tests (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3712"">#3712</a>, ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11080:1333,timeout,timeout,1333,https://hail.is,https://github.com/hail-is/hail/pull/11080,4,['timeout'],['timeout']
Safety,"o-libs/async-timeout/issues/272"">#272</a>)</li>; <li><a href=""https://github.com/aio-libs/async-timeout/commit/e5c813173b8811b30f4a30eeba56fa8808ab15bb""><code>e5c8131</code></a> [pre-commit.ci] pre-commit autoupdate (<a href=""https://github-redirect.dependabot.com/aio-libs/async-timeout/issues/271"">#271</a>)</li>; <li><a href=""https://github.com/aio-libs/async-timeout/commit/c7e10db3d0965422122bef263fb36f6fd7572330""><code>c7e10db</code></a> Fix linter configs</li>; <li><a href=""https://github.com/aio-libs/async-timeout/commit/6af8bf421a799208b27d57c6bf69de0d998fedec""><code>6af8bf4</code></a> Bump pre-commit from 2.15 to 2.16.0 (<a href=""https://github-redirect.dependabot.com/aio-libs/async-timeout/issues/269"">#269</a>)</li>; <li><a href=""https://github.com/aio-libs/async-timeout/commit/c71bbb5b5d7330f6dabfde7a1adec30a4611c0be""><code>c71bbb5</code></a> Bump docutils from 0.18 to 0.18.1 (<a href=""https://github-redirect.dependabot.com/aio-libs/async-timeout/issues/266"">#266</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/aio-libs/async-timeout/compare/v3.0.1...v4.0.2"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=async-timeout&package-manager=pip&previous-version=3.0.1&new-version=4.0.2)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11465:6154,timeout,timeout,6154,https://hail.is,https://github.com/hail-is/hail/pull/11465,1,['timeout'],['timeout']
Safety,"obuf==3.20.2', 'py4j==0.10.9.7', 'pyasn1==0.6.0', 'pyasn1-modules==0.4.0', 'pycares==4.4.0', 'pycparser==2.22', 'pygments==2.18.0', 'pyjwt==2.8.0', 'python-dateutil==2.9.0.post0', 'python-json-logger==2.0.7', 'pytz==2024.1', 'pyyaml==6.0.1', 'regex==2024.5.15', 'requests==2.32.3', 'requests-oauthlib==2.0.0', 'rich==12.6.0', 'rsa==4.9', 's3transfer==0.10.2', 'scipy==1.11.4', 'shellingham==1.5.4', 'six==1.16.0', 'sortedcontainers==2.4.0', 'tabulate==0.9.0', 'tenacity==8.4.2', 'tornado==6.4.1', 'typer==0.12.3', 'typing-extensions==4.12.2', 'tzdata==2024.1', 'urllib3==1.26.19', 'uvloop==0.19.0', 'wrapt==1.16.0', 'xyzservices==2024.6.0', 'yarl==1.9.4']; Collecting https://github.com/hail-is/jgscm/archive/v0.1.13+hail.zip; WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ConnectTimeoutError(<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7fef979a53d0>, 'Connection to github.com timed out. (connect timeout=15)')': /hail-is/jgscm/archive/v0.1.13+hail.zip; WARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ConnectTimeoutError(<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7fef9797e050>, 'Connection to github.com timed out. (connect timeout=15)')': /hail-is/jgscm/archive/v0.1.13+hail.zip; WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ConnectTimeoutError(<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7fef979ba910>, 'Connection to github.com timed out. (connect timeout=15)')': /hail-is/jgscm/archive/v0.1.13+hail.zip; WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ConnectTimeoutError(<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7fef979cc310>, 'Connection to github.com timed out. (connect timeout=15)')': /hail-is/jgscm/archive/v0.1.13+hail.zip; WARNING: Retrying",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14652:2927,timeout,timeout,2927,https://hail.is,https://github.com/hail-is/hail/issues/14652,1,['timeout'],['timeout']
Safety,"oducing-jsx.html. ```jsx; # Renders Hello World; # Biggest annoyance (may go away in 2019) is that ""class"" is not a valid tag (reserved by React); export default function SomePage() {; const name = 'Alex'. # Renders ""Hello Alex""; return (; <div className='some-class'> Hello {name} </div>; ); }; ```. ## Challenges; 1. Auth ; Authentication is tricky, but not for any reason specific to React, Next, Node. Server-side rendered apps tie the web app to the resource server; as such it's easier to hide sensitive information. . Mobile and desktop apps have dealt with this for 2 decades. We should build a robust infrastructure, and not one that requires server-rendered web pages for security. Currently it seems Auth0 may not be the best choice: it does not interface for us with third-party API's; requires us to either insecurely store 3rd party access tokens (with at least 1 extra round trip), or altogether proxy all third-party requests through our own resource server... Firebase Auth seems to avoid these limitations. ## TODO:; 1. Create a structured description of this pull request; 2. Incorporate Firebase Auth in place of Auth0 for 3rd party access token benefits.; 3: Scorecard; 3a. Draft working GraphQL V4 scorecard implementation; 3b. Finish authenticated GraphQL V4 scorecard implementation; 4. Batch; 4a: Setup dev batch endpoint; 4b: Call batch endpoint (no auth), and return any data; 4c: List all available jobs; * By querying Batch api, or Kubernetes directly; 4d: Receive current status of 1 job; 4e: Authentication; 4f: Polish (longest step): make interacting with batch achievable within perceived 16ms.; * goal: subscribe to events in web socket; * may want to save user job state in a Hail-controlled database (possible to use Firebase or Mongo, may prefer relational db, maybe Postgres or MySQL).; 4other: Figure out state question (sufficient to use Kubernetes); 5. Basic notebook interface.; 6. Connect websocket logic (non-GraphQL); 7. Authenticate web socket via Oauth2",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4931:6684,avoid,avoid,6684,https://hail.is,https://github.com/hail-is/hail/pull/4931,1,['avoid'],['avoid']
Safety,"oject.</h3>. #### Changes included in this PR. - Changes to the following files to upgrade the vulnerable dependencies to a fixed version:; - hail/python/hailtop/pinned-requirements.txt. <details>; <summary>⚠️ <b>Warning</b></summary>. ```; msal-extensions 1.0.0 requires portalocker, which is not installed.; aiosignal 1.3.1 requires frozenlist, which is not installed.; aiodns 2.0.0 requires pycares, which is not installed. ```; </details>. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **581/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 5.9 | Use of a Broken or Risky Cryptographic Algorithm <br/>[SNYK-PYTHON-CRYPTOGRAPHY-6149518](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-6149518) | `cryptography:` <br> `41.0.7 -> 42.0.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **581/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 5.9 | Uncontrolled Resource Consumption (&#x27;Resource Exhaustion&#x27;) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-6157248](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-6157248) | `cryptography:` <br> `41.0.7 -> 42.0.2` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with y",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14230:1166,Risk,Risky,1166,https://hail.is,https://github.com/hail-is/hail/pull/14230,1,['Risk'],['Risky']
Safety,"olders whose names match but either differ in size or differ in type. Four columns: source URL, destination URL, source state, destination state. The states are either: `file`, `dif`, or a size. If either state is a size, both states are sizes. 3. `srconly` files only present in the source. One column: source URL. 4. `dstonly` files only present in the destination. One column: destination URL. 5. `plan` a proposed set of object-to-object copies. Two columns: source URL, destination URL. 6. `summary` a one-line file containing the total number of copies in plan and the total number of bytes which would be copied. As described in the CLI documentation, the intended use of these commands is:. ```; hailctl fs sync --make-plan plan1 --copy-to gs://gcs-bucket/a s3://s3-bucket/b; hailctl fs sync --use-plan plan1; ```. The first command generates a plan folder and the second command executes the plan. Separating this process into two commands allows the user to verify what exactly will be copied including the exact destination URLs. Moreover, if `hailctl fs sync --use-plan` fails, the user can re-run `hailctl fs sync --make-plan` to generate a new plan which will avoid copying already successfully copied files. Moreover, the user can re-run `hailctl fs sync --make-plan` to verify that every file was indeed successfully copied. Testing. This change has a few sync-specific tests but largely reuses the tests for `hailtop.aiotools.copy`. Future Work. Propagating a consistent kind of hash across all clouds and using that for detecting differences is a better solution than the file-size based difference used here. If all the clouds always provided the same type of hash value, this would be trivial to add. Alas, at time of writing, S3 and Google both support CRC32C for every blob (though, in S3, you must explicitly request it at object creation time), but *Azure Blob Storage does not*. ABS only supports MD5 sums which Google does not support for multi-part uploads. Resolves #14654",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14248:2370,avoid,avoid,2370,https://hail.is,https://github.com/hail-is/hail/pull/14248,2,"['avoid', 'detect']","['avoid', 'detecting']"
Safety,"ollow-redirects/follow-redirects/commit/8b347cbcef7c7b72a6e9be20f5710c17d6163c22""><code>8b347cb</code></a> Drop Cookie header across domains.</li>; <li><a href=""https://github.com/follow-redirects/follow-redirects/commit/6f5029ae1a0fdab4dc25f6379a5ee303c2319070""><code>6f5029a</code></a> Release version 1.14.6 of the npm package.</li>; <li><a href=""https://github.com/follow-redirects/follow-redirects/commit/af706bee57de954414c0bde0a9f33e62beea3e52""><code>af706be</code></a> Ignore null headers.</li>; <li><a href=""https://github.com/follow-redirects/follow-redirects/commit/d01ab7a5c5df3617c7a40a03de7af6427fdfac55""><code>d01ab7a</code></a> Release version 1.14.5 of the npm package.</li>; <li><a href=""https://github.com/follow-redirects/follow-redirects/commit/40052ea8aa13559becee5795715c1d45b1f0eb76""><code>40052ea</code></a> Make compatible with Node 17.</li>; <li><a href=""https://github.com/follow-redirects/follow-redirects/commit/86f7572f9365dadc39f85916259b58973819617f""><code>86f7572</code></a> Fix: clear internal timer on request abort to avoid leakage</li>; <li><a href=""https://github.com/follow-redirects/follow-redirects/commit/2e1eaf0218c5315a2ab27f53964d0535d4dafb51""><code>2e1eaf0</code></a> Keep Authorization header on subdomain redirects.</li>; <li><a href=""https://github.com/follow-redirects/follow-redirects/commit/2ad9e82b6277ae2104f7770e9ff1186cc6da29d4""><code>2ad9e82</code></a> Carry over Host header on relative redirects (<a href=""https://github-redirect.dependabot.com/follow-redirects/follow-redirects/issues/172"">#172</a>)</li>; <li><a href=""https://github.com/follow-redirects/follow-redirects/commit/77e2a581e1d1811674b7b74745a9c20a5b939488""><code>77e2a58</code></a> Release version 1.14.4 of the npm package.</li>; <li>Additional commits viewable in <a href=""https://github.com/follow-redirects/follow-redirects/compare/v1.14.1...v1.14.7"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11283:1416,abort,abort,1416,https://hail.is,https://github.com/hail-is/hail/pull/11283,4,"['abort', 'avoid']","['abort', 'avoid']"
Safety,"ommit/ac8d3ee22e73bd95170091993cdbb9071b304573""><code>ac8d3ee</code></a> feat: Add support for Python 3.12 (<a href=""https://redirect.github.com/GoogleCloudPlatform/google-auth-library-python-oauthlib/issues/318"">#318</a>)</li>; <li><a href=""https://github.com/googleapis/google-auth-library-python-oauthlib/commit/fbce656b23a1c8afed3955bf26472d8eff331777""><code>fbce656</code></a> chore: bump urllib3 from 1.26.12 to 1.26.18 (<a href=""https://redirect.github.com/GoogleCloudPlatform/google-auth-library-python-oauthlib/issues/317"">#317</a>)</li>; <li><a href=""https://github.com/googleapis/google-auth-library-python-oauthlib/commit/b303c66305a8dd17b375aa719a87dd3f619cccaa""><code>b303c66</code></a> chore: update docfx minimum Python version (<a href=""https://redirect.github.com/GoogleCloudPlatform/google-auth-library-python-oauthlib/issues/316"">#316</a>)</li>; <li><a href=""https://github.com/googleapis/google-auth-library-python-oauthlib/commit/fc1fad5d7b9b7774273b379d52022a9b294f7619""><code>fc1fad5</code></a> chore: rename rst files to avoid conflict with service names (<a href=""https://redirect.github.com/GoogleCloudPlatform/google-auth-library-python-oauthlib/issues/315"">#315</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/GoogleCloudPlatform/google-auth-library-python-oauthlib/compare/v0.8.0...v1.2.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=google-auth-oauthlib&package-manager=pip&previous-version=0.8.0&new-version=1.2.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependa",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14510:10254,avoid,avoid,10254,https://hail.is,https://github.com/hail-is/hail/pull/14510,1,['avoid'],['avoid']
Safety,on; 	at is.hail.annotations.UnKryoSerializable$class.write(UnsafeRow.scala:15); 	at is.hail.annotations.UnsafeRow.write(UnsafeRow.scala:141); 	at com.esotericsoftware.kryo.serializers.DefaultSerializers$KryoSerializableSerializer.write(DefaultSerializers.java:505); 	at com.esotericsoftware.kryo.serializers.DefaultSerializers$KryoSerializableSerializer.write(DefaultSerializers.java:503); 	at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:628); 	at com.esotericsoftware.kryo.serializers.MapSerializer.write(MapSerializer.java:106); 	at com.esotericsoftware.kryo.serializers.MapSerializer.write(MapSerializer.java:39); 	at com.esotericsoftware.kryo.Kryo.writeObject(Kryo.java:552); 	at com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectField.java:80); 	... 10 more; Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1517); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1505); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1504); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1504); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1732); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1687); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGSche,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4215:2666,abort,abortStage,2666,https://hail.is,https://github.com/hail-is/hail/issues/4215,1,['abort'],['abortStage']
Safety,"one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiIyOTUzNDFmZi1lMjQ4LTRiOTItYTY1Yy1kYjJiZWQ3ZDQxMGQiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjI5NTM0MWZmLWUyNDgtNGI5Mi1hNjVjLWRiMmJlZDdkNDEwZCJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/fa47fca0-549b-41a3-8bf7-bcda4ca9a617?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/fa47fca0-549b-41a3-8bf7-bcda4ca9a617?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""295341ff-e248-4b92-a65c-db2bed7d410d"",""prPublicId"":""295341ff-e248-4b92-a65c-db2bed7d410d"",""dependencies"":[{""name"":""tornado"",""from"":""6.2"",""to"":""6.3.2""}],""packageManager"":""pip"",""projectPublicId"":""fa47fca0-549b-41a3-8bf7-bcda4ca9a617"",""projectUrl"":""https://app.snyk.io/org/danking/project/fa47fca0-549b-41a3-8bf7-bcda4ca9a617?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-TORNADO-5537286""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""pr-warning-shown"",""priorityScore""],""priorityScoreList"":[556],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Open Redirect](https://learn.snyk.io/lessons/open-redirect/python/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13066:3238,remediat,remediationStrategy,3238,https://hail.is,https://github.com/hail-is/hail/pull/13066,1,['remediat'],['remediationStrategy']
Safety,"onnector.py"", line 975, in _wrap_create_connection\n raise client_error(req.connection_key, exc) from exc\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 10.128.0.11:5000 ssl:default [Connection refused]; ERROR	2022-03-02 19:06:35,400	job.py	schedule_job:473	error while scheduling job (93, 1) on instance batch-worker-pr-11438-default-g6cibyji6520-standard-9xy2q	Traceback (most recent call last):\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 969, in _wrap_create_connection\n return await self._loop.create_connection(*args, **kwargs) # type: ignore # noqa\n File ""uvloop/loop.pyx"", line 1974, in create_connection\n File ""uvloop/loop.pyx"", line 1951, in uvloop.loop.Loop.create_connection\nConnectionRefusedError: [Errno 111] Connection refused\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n File ""/usr/local/lib/python3.7/dist-packages/batch/driver/job.py"", line 449, in schedule_job\n timeout=aiohttp.ClientTimeout(total=2),\n File ""/usr/local/lib/python3.7/dist-packages/hailtop/httpx.py"", line 113, in request_and_raise_for_status\n resp = await self.client_session._request(method, url, **kwargs)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/client.py"", line 521, in _request\n req, traces=traces, timeout=real_timeout\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 535, in connect\n proto = await self._create_connection(req, traces, timeout)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 892, in _create_connection\n _, proto = await self._create_direct_connection(req, traces, timeout)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 1051, in _create_direct_connection\n raise last_exc\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 1032, in _create_direct_connection\n client_error=client_error,\n File ""/usr/local/lib/python3.7/dist-packages/aioht",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11451:8135,timeout,timeout,8135,https://hail.is,https://github.com/hail-is/hail/pull/11451,1,['timeout'],['timeout']
Safety,"onnector.py"", line 975, in _wrap_create_connection\n raise client_error(req.connection_key, exc) from exc\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 10.128.0.11:5000 ssl:default [Connection refused]; ERROR	2022-03-02 19:06:37,364	job.py	schedule_job:473	error while scheduling job (90, 1) on instance batch-worker-pr-11438-default-g6cibyji6520-standard-9xy2q	Traceback (most recent call last):\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 969, in _wrap_create_connection\n return await self._loop.create_connection(*args, **kwargs) # type: ignore # noqa\n File ""uvloop/loop.pyx"", line 1974, in create_connection\n File ""uvloop/loop.pyx"", line 1951, in uvloop.loop.Loop.create_connection\nConnectionRefusedError: [Errno 111] Connection refused\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n File ""/usr/local/lib/python3.7/dist-packages/batch/driver/job.py"", line 449, in schedule_job\n timeout=aiohttp.ClientTimeout(total=2),\n File ""/usr/local/lib/python3.7/dist-packages/hailtop/httpx.py"", line 113, in request_and_raise_for_status\n resp = await self.client_session._request(method, url, **kwargs)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/client.py"", line 521, in _request\n req, traces=traces, timeout=real_timeout\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 535, in connect\n proto = await self._create_connection(req, traces, timeout)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 892, in _create_connection\n _, proto = await self._create_direct_connection(req, traces, timeout)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 1051, in _create_direct_connection\n raise last_exc\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 1032, in _create_direct_connection\n client_error=client_error,\n File ""/usr/local/lib/python3.7/dist-packages/aioht",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11451:12636,timeout,timeout,12636,https://hail.is,https://github.com/hail-is/hail/pull/11451,1,['timeout'],['timeout']
Safety,"onnector.py"", line 975, in _wrap_create_connection\n raise client_error(req.connection_key, exc) from exc\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 10.128.0.11:5000 ssl:default [Connection refused]; ERROR	2022-03-02 19:06:37,390	job.py	schedule_job:473	error while scheduling job (97, 1) on instance batch-worker-pr-11438-default-g6cibyji6520-standard-9xy2q	Traceback (most recent call last):\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 969, in _wrap_create_connection\n return await self._loop.create_connection(*args, **kwargs) # type: ignore # noqa\n File ""uvloop/loop.pyx"", line 1974, in create_connection\n File ""uvloop/loop.pyx"", line 1951, in uvloop.loop.Loop.create_connection\nConnectionRefusedError: [Errno 111] Connection refused\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n File ""/usr/local/lib/python3.7/dist-packages/batch/driver/job.py"", line 449, in schedule_job\n timeout=aiohttp.ClientTimeout(total=2),\n File ""/usr/local/lib/python3.7/dist-packages/hailtop/httpx.py"", line 113, in request_and_raise_for_status\n resp = await self.client_session._request(method, url, **kwargs)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/client.py"", line 521, in _request\n req, traces=traces, timeout=real_timeout\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 535, in connect\n proto = await self._create_connection(req, traces, timeout)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 892, in _create_connection\n _, proto = await self._create_direct_connection(req, traces, timeout)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 1051, in _create_direct_connection\n raise last_exc\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 1032, in _create_direct_connection\n client_error=client_error,\n File ""/usr/local/lib/python3.7/dist-packages/aioht",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11451:14641,timeout,timeout,14641,https://hail.is,https://github.com/hail-is/hail/pull/11451,1,['timeout'],['timeout']
Safety,"onnector.py"", line 975, in _wrap_create_connection\n raise client_error(req.connection_key, exc) from exc\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 10.128.0.11:5000 ssl:default [Connection refused]; ERROR	2022-03-02 19:06:39,193	job.py	schedule_job:473	error while scheduling job (99, 1) on instance batch-worker-pr-11438-default-g6cibyji6520-standard-9xy2q	Traceback (most recent call last):\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 969, in _wrap_create_connection\n return await self._loop.create_connection(*args, **kwargs) # type: ignore # noqa\n File ""uvloop/loop.pyx"", line 1974, in create_connection\n File ""uvloop/loop.pyx"", line 1951, in uvloop.loop.Loop.create_connection\nConnectionRefusedError: [Errno 111] Connection refused\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n File ""/usr/local/lib/python3.7/dist-packages/batch/driver/job.py"", line 449, in schedule_job\n timeout=aiohttp.ClientTimeout(total=2),\n File ""/usr/local/lib/python3.7/dist-packages/hailtop/httpx.py"", line 113, in request_and_raise_for_status\n resp = await self.client_session._request(method, url, **kwargs)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/client.py"", line 521, in _request\n req, traces=traces, timeout=real_timeout\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 535, in connect\n proto = await self._create_connection(req, traces, timeout)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 892, in _create_connection\n _, proto = await self._create_direct_connection(req, traces, timeout)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 1051, in _create_direct_connection\n raise last_exc\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 1032, in _create_direct_connection\n client_error=client_error,\n File ""/usr/local/lib/python3.7/dist-packages/aioht",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11451:22801,timeout,timeout,22801,https://hail.is,https://github.com/hail-is/hail/pull/11451,1,['timeout'],['timeout']
Safety,"ons (<a href=""https://github-redirect.dependabot.com/pytest-dev/pytest-html/issues/360"">#360</a>) <a href=""https://github.com/ssbarnea""><code>@​ssbarnea</code></a></li>; <li>Respect --show-capture=no flag (<a href=""https://github-redirect.dependabot.com/pytest-dev/pytest-html/issues/359"">#359</a>) <a href=""https://github.com/gnikonorov""><code>@​gnikonorov</code></a></li>; <li>Respect pytest --capture=no and -s flags (<a href=""https://github-redirect.dependabot.com/pytest-dev/pytest-html/issues/353"">#353</a>) <a href=""https://github.com/gnikonorov""><code>@​gnikonorov</code></a></li>; <li>Stop shadowing the 'format' builtin (<a href=""https://github-redirect.dependabot.com/pytest-dev/pytest-html/issues/347"">#347</a>) <a href=""https://github.com/gnikonorov""><code>@​gnikonorov</code></a></li>; <li>Post process html to include teardown in log (<a href=""https://github-redirect.dependabot.com/pytest-dev/pytest-html/issues/271"">#271</a>) <a href=""https://github.com/csm10495""><code>@​csm10495</code></a></li>; <li>Avoid pytest 6.0.0 (<a href=""https://github-redirect.dependabot.com/pytest-dev/pytest-html/issues/319"">#319</a>) <a href=""https://github.com/ssbarnea""><code>@​ssbarnea</code></a></li>; <li>Rename &quot;slave&quot; -&gt; &quot;worker&quot; for xdist compatibility (<a href=""https://github-redirect.dependabot.com/pytest-dev/pytest-html/issues/307"">#307</a>) <a href=""https://github.com/Zac-HD""><code>@​Zac-HD</code></a></li>; <li>Fix embedded images (and videos) (<a href=""https://github-redirect.dependabot.com/pytest-dev/pytest-html/issues/298"">#298</a>) <a href=""https://github.com/dhalperi""><code>@​dhalperi</code></a></li>; <li>Fix image missing when using Base64 content (<a href=""https://github-redirect.dependabot.com/pytest-dev/pytest-html/issues/277"">#277</a>) <a href=""https://github.com/christiansandberg""><code>@​christiansandberg</code></a></li>; <li>Better fix for TerminalReporter issue (<a href=""https://github-redirect.dependabot.com/pytest-dev/pytest-html/issues/2",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11524:4193,Avoid,Avoid,4193,https://hail.is,https://github.com/hail-is/hail/pull/11524,1,['Avoid'],['Avoid']
Safety,"ons in the target of <code>for</code> and <code>async for</code>; statements, e.g <code>for item in *items_1, *items_2: pass</code> (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2879"">#2879</a>).</li>; </ul>; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/psf/black/blob/main/CHANGES.md"">black's changelog</a>.</em></p>; <blockquote>; <h2>22.3.0</h2>; <h3>Preview style</h3>; <ul>; <li>Code cell separators <code>#%%</code> are now standardised to <code># %%</code> (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2919"">#2919</a>)</li>; <li>Remove unnecessary parentheses from <code>except</code> statements (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2939"">#2939</a>)</li>; <li>Remove unnecessary parentheses from tuple unpacking in <code>for</code> loops (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2945"">#2945</a>)</li>; <li>Avoid magic-trailing-comma in single-element subscripts (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2942"">#2942</a>)</li>; </ul>; <h3>Configuration</h3>; <ul>; <li>Do not format <code>__pypackages__</code> directories by default (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2836"">#2836</a>)</li>; <li>Add support for specifying stable version with <code>--required-version</code> (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2832"">#2832</a>).</li>; <li>Avoid crashing when the user has no homedir (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2814"">#2814</a>)</li>; <li>Avoid crashing when md5 is not available (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2905"">#2905</a>)</li>; <li>Fix handling of directory junctions on Windows (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2904"">#2904</a>)</li>; </ul>; <h3>Documentation</h3>; <ul>; <li>Update pylint config documentation (<a href=""https://git",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11696:3931,Avoid,Avoid,3931,https://hail.is,https://github.com/hail-is/hail/pull/11696,1,['Avoid'],['Avoid']
Safety,"ool.scala:17); 	at is.hail.backend.ExecuteContext$.scoped(ExecuteContext.scala:59); 	at is.hail.backend.spark.SparkBackend.withExecuteContext(SparkBackend.scala:310); 	at is.hail.backend.spark.SparkBackend.$anonfun$executeEncode$1(SparkBackend.scala:449); 	at is.hail.utils.ExecutionTimer$.time(ExecutionTimer.scala:52); 	at is.hail.backend.spark.SparkBackend.executeEncode(SparkBackend.scala:448); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:282); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:238); 	at java.lang.Thread.run(Thread.java:750). Hail version: 0.2.98-f8833c1ae16b; Error summary: SparkException: Job aborted due to stage failure: Task 582 in stage 10.0 failed 20 times, most recent failure: Lost task 582.19 in stage 10.0 (TID 461381) (cluster-w-144.c.project.internal executor 3568): ExecutorLostFailure (executor 3568 exited caused by one of the running tasks) Reason: Executor heartbeat timed out after 128936 ms; Driver stacktrace:; ```; We also tried using a similar cluster configuration with dynamic scaling and received the same error. Do you have a recommended cluster configuration to run king() on this many samples?. To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: ; https://discuss.hail.is/. Please include the full Hail version and as much detail as possible. -----------------------------------------------------------------------------",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12290:7858,abort,aborted,7858,https://hail.is,https://github.com/hail-is/hail/issues/12290,1,['abort'],['aborted']
Safety,oolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745); Caused by: is.hail.utils.HailException: Error parsing row fields in row 0:; expected 5 fields but only 5 found.; File: foo; Line:; 7	75216143	75216143	C/T	+; 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:9); 	at is.hail.utils.package$.fatal(package.scala:28); 	at is.hail.io.LoadMatrixParser.parseLine(LoadMatrix.scala:33); 	at is.hail.io.LoadMatrix$$anonfun$16$$anonfun$apply$6$$anonfun$apply$7.apply(LoadMatrix.scala:383); 	at is.hail.io.LoadMatrix$$anonfun$16$$anonfun$apply$6$$anonfun$apply$7.apply(LoadMatrix.scala:377); 	at is.hail.utils.WithContext.wrap(Context.scala:41); 	... 30 more. Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1575); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1563); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1562); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1562); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:803); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:803); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:803); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1790); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1745); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGSche,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5718:6149,abort,abortStage,6149,https://hail.is,https://github.com/hail-is/hail/issues/5718,1,['abort'],['abortStage']
Safety,orHandling$class.fatal(ErrorHandling.scala:9); 	at is.hail.utils.package$.fatal(package.scala:28); 	at is.hail.io.LoadMatrixParser.parseLine(LoadMatrix.scala:33); 	at is.hail.io.LoadMatrix$$anonfun$16$$anonfun$apply$6$$anonfun$apply$7.apply(LoadMatrix.scala:383); 	at is.hail.io.LoadMatrix$$anonfun$16$$anonfun$apply$6$$anonfun$apply$7.apply(LoadMatrix.scala:377); 	at is.hail.utils.WithContext.wrap(Context.scala:41); 	... 30 more. Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1575); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1563); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1562); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1562); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:803); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:803); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:803); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1790); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1745); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1734); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:619); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2029); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2126); 	at org.apache.spark.rdd.RDD$$anonfun$fold$1.apply(RDD.scala:,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5718:6492,abort,abortStage,6492,https://hail.is,https://github.com/hail-is/hail/issues/5718,1,['abort'],['abortStage']
Safety,orImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:280); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:214); 	at java.lang.Thread.run(Thread.java:748)java.lang.AssertionError: assertion failed; 	at scala.Predef$.assert(Predef.scala:156); 	at is.hail.annotations.Region.loadInt(Region.scala:36); 	at is.hail.expr.types.TBinary$.loadLength(TBinary.scala:62); 	at is.hail.annotations.UnsafeRow$.readBinary(UnsafeRow.scala:128); 	at is.hail.annotations.UnsafeRow$.readString(UnsafeRow.scala:139); 	at is.hail.annotations.UnsafeRow$.readAltAllele(UnsafeRow.scala:152); 	at is.hail.annotations.UnsafeRow$.readArrayAltAllele(UnsafeRow.scala:164); 	at is.hail.annotations.UnsafeRow$.read(UnsafeRow.scala:210); 	at is.hail.annotations.UnsafeRow.get(UnsafeRow.scala:257); 	at is.hail.expr.FilterVariants$$anonfun$10.apply(Relational.scala:503); 	at is.hail.expr.FilterVariants$$anonfun$10.apply(Relational.scala:500); 	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:463); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$9$$anon$5.hasNext(OrderedRVD.scala:658); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$9$$anon$5.hasNext(OrderedRVD.scala:658); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$9$$anon$5.hasNext(OrderedRVD.scala:658); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at is.hail.sparkextras.OrderedRDD$$anonfun$apply$5$$anon$2.hasNext(OrderedRDD.scala:194); 	at scala.collection,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2743:8099,Unsafe,UnsafeRow,8099,https://hail.is,https://github.com/hail-is/hail/issues/2743,1,['Unsafe'],['UnsafeRow']
Safety,"ores:206	creating 1 new instances; INFO	2022-03-02 19:06:35,848	pool.py	create_instances:244	pool highmem n_instances 1 {'pending': 0, 'active': 1, 'inactive': 0, 'deleted': 0} free_cores 4.0 live_free_cores 4.0 ready_cores 0.0; ERROR	2022-03-02 19:06:37,336	job.py	schedule_job:473	error while scheduling job (94, 1) on instance batch-worker-pr-11438-default-g6cibyji6520-standard-9xy2q	Traceback (most recent call last):\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 969, in _wrap_create_connection\n return await self._loop.create_connection(*args, **kwargs) # type: ignore # noqa\n File ""uvloop/loop.pyx"", line 1974, in create_connection\n File ""uvloop/loop.pyx"", line 1951, in uvloop.loop.Loop.create_connection\nConnectionRefusedError: [Errno 111] Connection refused\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n File ""/usr/local/lib/python3.7/dist-packages/batch/driver/job.py"", line 449, in schedule_job\n timeout=aiohttp.ClientTimeout(total=2),\n File ""/usr/local/lib/python3.7/dist-packages/hailtop/httpx.py"", line 113, in request_and_raise_for_status\n resp = await self.client_session._request(method, url, **kwargs)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/client.py"", line 521, in _request\n req, traces=traces, timeout=real_timeout\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 535, in connect\n proto = await self._create_connection(req, traces, timeout)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 892, in _create_connection\n _, proto = await self._create_direct_connection(req, traces, timeout)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 1051, in _create_direct_connection\n raise last_exc\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 1032, in _create_direct_connection\n client_error=client_error,\n File ""/usr/local/lib/python3.7/dist-packages/aioht",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11451:10631,timeout,timeout,10631,https://hail.is,https://github.com/hail-is/hail/pull/11451,1,['timeout'],['timeout']
Safety,org$apache$spark$HeartbeatReceiver$$expireDeadHosts$3.apply(HeartbeatReceiver.scala:196); at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733); at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99); at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99); at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230); at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40); at scala.collection.mutable.HashMap.foreach(HashMap.scala:99); at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732); at org.apache.spark.HeartbeatReceiver.org$apache$spark$HeartbeatReceiver$$expireDeadHosts(HeartbeatReceiver.scala:196); at org.apache.spark.HeartbeatReceiver$$anonfun$receiveAndReply$1.applyOrElse(HeartbeatReceiver.scala:119); at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105); at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205); at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101); at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:216); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); java.lang.OutOfMemoryError: GC overhead limit exceeded; at scala.collection.mutable.ListBuffer.$plus$eq(ListBuffer.scala:170); at scala.collection.mutable.ListBuffer.$plus$eq(ListBuffer.scala:45); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.mutable.HashMap$$anon$2$$anonfun$foreach$3.apply(HashMap.scala:108); at scala.collection.mutable.HashMap$$anon$2$$anonfun$foreach$3.apply(HashMap.scala:108); at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230); at s,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4780:3118,safe,safelyCall,3118,https://hail.is,https://github.com/hail-is/hail/issues/4780,1,['safe'],['safelyCall']
Safety,orker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745); Caused by: is.hail.utils.HailException: Error parsing row fields in row 0:; expected 5 fields but only 5 found.; File: foo; Line:; 7	75216143	75216143	C/T	+; 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:9); 	at is.hail.utils.package$.fatal(package.scala:28); 	at is.hail.io.LoadMatrixParser.parseLine(LoadMatrix.scala:33); 	at is.hail.io.LoadMatrix$$anonfun$16$$anonfun$apply$6$$anonfun$apply$7.apply(LoadMatrix.scala:383); 	at is.hail.io.LoadMatrix$$anonfun$16$$anonfun$apply$6$$anonfun$apply$7.apply(LoadMatrix.scala:377); 	at is.hail.utils.WithContext.wrap(Context.scala:41); 	... 30 more. Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1575); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1563); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1562); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1562); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:803); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:803); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:803); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1790); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1745); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1734); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.ap,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5718:6247,abort,abortStage,6247,https://hail.is,https://github.com/hail-is/hail/issues/5718,1,['abort'],['abortStage']
Safety,"ormation: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJjMjFkYTE5Ny1lMDgzLTRiNzEtODc1Yi0xZmY0MjNhZWZmOWEiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImMyMWRhMTk3LWUwODMtNGI3MS04NzViLTFmZjQyM2FlZmY5YSJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/701495b8-b53d-48af-82fe-1a6c57aa56cb?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/701495b8-b53d-48af-82fe-1a6c57aa56cb?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""c21da197-e083-4b71-875b-1ff423aeff9a"",""prPublicId"":""c21da197-e083-4b71-875b-1ff423aeff9a"",""dependencies"":[{""name"":""cryptography"",""from"":""41.0.7"",""to"":""42.0.2""}],""packageManager"":""pip"",""projectPublicId"":""701495b8-b53d-48af-82fe-1a6c57aa56cb"",""projectUrl"":""https://app.snyk.io/org/danking/project/701495b8-b53d-48af-82fe-1a6c57aa56cb?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-CRYPTOGRAPHY-6149518"",""SNYK-PYTHON-CRYPTOGRAPHY-6157248"",""SNYK-PYTHON-CRYPTOGRAPHY-6210214""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""priorityScore""],""priorityScoreList"":[509,581,451],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Use of a Broken or Risky Cryptographic Algorithm](https://learn.snyk.io/lesson/insecure-hash/?loc&#x3D;fix-pr); 🦉 [Uncontrolled Resource Consumption (&#x27;Resource Exhaustion&#x27;)](https://learn.snyk.io/lesson/redos/?loc&#x3D;fix-pr); 🦉 [NULL Pointer Dereference](https://learn.snyk.io/lesson/null-dereference/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14236:4017,remediat,remediationStrategy,4017,https://hail.is,https://github.com/hail-is/hail/pull/14236,2,"['Risk', 'remediat']","['Risky', 'remediationStrategy']"
Safety,"ort](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""514b5ede-26fa-4106-8310-c2ceed7c08a9"",""prPublicId"":""514b5ede-26fa-4106-8310-c2ceed7c08a9"",""dependencies"":[{""name"":""ipython"",""from"":""7.34.0"",""to"":""8.10.0""},{""name"":""jupyter-server"",""from"":""1.24.0"",""to"":""2.11.2""},{""name"":""setuptools"",""from"":""40.5.0"",""to"":""65.5.1""},{""name"":""tornado"",""from"":""6.2"",""to"":""6.3.3""}],""packageManager"":""pip"",""projectPublicId"":""20159ae6-a5aa-42fa-845a-c89f5bcbf999"",""projectUrl"":""https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-IPYTHON-3318382"",""SNYK-PYTHON-JUPYTERSERVER-5862881"",""SNYK-PYTHON-JUPYTERSERVER-5862882"",""SNYK-PYTHON-JUPYTERSERVER-6099119"",""SNYK-PYTHON-SETUPTOOLS-3180412"",""SNYK-PYTHON-TORNADO-5537286"",""SNYK-PYTHON-TORNADO-5840803"",""SNYK-PYTHON-TORNADO-6041512""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""pr-warning-shown"",""priorityScore""],""priorityScoreList"":[531,null,null,null,509,384,494,539],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Remote Code Execution (RCE)](https://learn.snyk.io/lesson/improper-input-validation/?loc&#x3D;fix-pr); 🦉 [Access Control Bypass](https://learn.snyk.io/lesson/broken-access-control/?loc&#x3D;fix-pr); 🦉 [Open Redirect](https://learn.snyk.io/lesson/open-redirect/?loc&#x3D;fix-pr); 🦉 [More lessons are available in Snyk Learn](https://learn.snyk.io/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14365:6578,remediat,remediationStrategy,6578,https://hail.is,https://github.com/hail-is/hail/pull/14365,1,['remediat'],['remediationStrategy']
Safety,"ort](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""bc93468d-68e9-4fac-a335-f87261706f48"",""prPublicId"":""bc93468d-68e9-4fac-a335-f87261706f48"",""dependencies"":[{""name"":""ipython"",""from"":""7.34.0"",""to"":""8.10.0""},{""name"":""jupyter-server"",""from"":""1.24.0"",""to"":""2.11.2""},{""name"":""setuptools"",""from"":""39.0.1"",""to"":""65.5.1""},{""name"":""tornado"",""from"":""6.2"",""to"":""6.3.3""}],""packageManager"":""pip"",""projectPublicId"":""20159ae6-a5aa-42fa-845a-c89f5bcbf999"",""projectUrl"":""https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-IPYTHON-3318382"",""SNYK-PYTHON-JUPYTERSERVER-5862881"",""SNYK-PYTHON-JUPYTERSERVER-5862882"",""SNYK-PYTHON-JUPYTERSERVER-6099119"",""SNYK-PYTHON-SETUPTOOLS-3180412"",""SNYK-PYTHON-TORNADO-5537286"",""SNYK-PYTHON-TORNADO-5840803"",""SNYK-PYTHON-TORNADO-6041512""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""pr-warning-shown"",""priorityScore""],""priorityScoreList"":[531,null,null,null,509,384,494,539],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Remote Code Execution (RCE)](https://learn.snyk.io/lesson/improper-input-validation/?loc&#x3D;fix-pr); 🦉 [Access Control Bypass](https://learn.snyk.io/lesson/broken-access-control/?loc&#x3D;fix-pr); 🦉 [Open Redirect](https://learn.snyk.io/lesson/open-redirect/?loc&#x3D;fix-pr); 🦉 [More lessons are available in Snyk Learn](https://learn.snyk.io/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14211:6508,remediat,remediationStrategy,6508,https://hail.is,https://github.com/hail-is/hail/pull/14211,1,['remediat'],['remediationStrategy']
Safety,"ot all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiIyMTAxMzNhYS03MjA2LTRmMzQtYTQ2OC1iYjY5YWJmYTUzZjEiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjIxMDEzM2FhLTcyMDYtNGYzNC1hNDY4LWJiNjlhYmZhNTNmMSJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/701495b8-b53d-48af-82fe-1a6c57aa56cb?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/701495b8-b53d-48af-82fe-1a6c57aa56cb?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""210133aa-7206-4f34-a468-bb69abfa53f1"",""prPublicId"":""210133aa-7206-4f34-a468-bb69abfa53f1"",""dependencies"":[{""name"":""cryptography"",""from"":""41.0.7"",""to"":""42.0.0""}],""packageManager"":""pip"",""projectPublicId"":""701495b8-b53d-48af-82fe-1a6c57aa56cb"",""projectUrl"":""https://app.snyk.io/org/danking/project/701495b8-b53d-48af-82fe-1a6c57aa56cb?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-CRYPTOGRAPHY-6050294"",""SNYK-PYTHON-CRYPTOGRAPHY-6126975""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""priorityScore""],""priorityScoreList"":[479,616],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Denial of Service (DoS)](https://learn.snyk.io/lesson/redos/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14200:3527,remediat,remediationStrategy,3527,https://hail.is,https://github.com/hail-is/hail/pull/14200,1,['remediat'],['remediationStrategy']
Safety,"out/commit/48d1c4ce923b1da75976d7e2a6ca9234b3092c16""><code>48d1c4c</code></a> Setup towncrier</li>; <li><a href=""https://github.com/aio-libs/async-timeout/commit/2ede7d73e55f8d1a2279d78861af0009d96219fb""><code>2ede7d7</code></a> Fix annotations on <code>__exit__</code> and <code>__aexit__</code> (<a href=""https://github-redirect.dependabot.com/aio-libs/async-timeout/issues/274"">#274</a>)</li>; <li><a href=""https://github.com/aio-libs/async-timeout/commit/8685c60dc0e82ee246fbe3d1aa272d1dfe57c24c""><code>8685c60</code></a> Bump mypy from 0.910 to 0.920 (<a href=""https://github-redirect.dependabot.com/aio-libs/async-timeout/issues/273"">#273</a>)</li>; <li><a href=""https://github.com/aio-libs/async-timeout/commit/f0a0914345b224448220aeb00d71e6a04a5d24bd""><code>f0a0914</code></a> Bump twine from 3.7.0 to 3.7.1 (<a href=""https://github-redirect.dependabot.com/aio-libs/async-timeout/issues/272"">#272</a>)</li>; <li><a href=""https://github.com/aio-libs/async-timeout/commit/e5c813173b8811b30f4a30eeba56fa8808ab15bb""><code>e5c8131</code></a> [pre-commit.ci] pre-commit autoupdate (<a href=""https://github-redirect.dependabot.com/aio-libs/async-timeout/issues/271"">#271</a>)</li>; <li><a href=""https://github.com/aio-libs/async-timeout/commit/c7e10db3d0965422122bef263fb36f6fd7572330""><code>c7e10db</code></a> Fix linter configs</li>; <li><a href=""https://github.com/aio-libs/async-timeout/commit/6af8bf421a799208b27d57c6bf69de0d998fedec""><code>6af8bf4</code></a> Bump pre-commit from 2.15 to 2.16.0 (<a href=""https://github-redirect.dependabot.com/aio-libs/async-timeout/issues/269"">#269</a>)</li>; <li><a href=""https://github.com/aio-libs/async-timeout/commit/c71bbb5b5d7330f6dabfde7a1adec30a4611c0be""><code>c71bbb5</code></a> Bump docutils from 0.18 to 0.18.1 (<a href=""https://github-redirect.dependabot.com/aio-libs/async-timeout/issues/266"">#266</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/aio-libs/async-timeout/compare/v3.0.1...v4.0.2"">compare view</a></li>; </",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11465:5288,timeout,timeout,5288,https://hail.is,https://github.com/hail-is/hail/pull/11465,1,['timeout'],['timeout']
Safety,"out_at(deadline)</code> (<a href=""https://github-redirect.dependabot.com/aio-libs/async-timeout/issues/117"">#117</a>)</p>; </li>; <li>; <p>Supported <code>timeout.deadline</code> and <code>timeout.expired</code> properties.</p>; </li>; <li>; <p>Dropped <code>timeout.remaining</code> property: it can be calculated as; <code>timeout.deadline - loop.time()</code></p>; </li>; <li>; <p>Dropped <code>timeout.timeout</code> property that returns a relative timeout based on the; timeout object creation time; the absolute <code>timeout.deadline</code> should be used; instead.</p>; </li>; <li>; <p>Added the deadline modification methods: <code>timeout.reject()</code>,; <code>timeout.shift(delay)</code>, <code>timeout.update(deadline)</code>.</p>; </li>; <li>; <p>Deprecated synchronous context manager usage</p>; </li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/aio-libs/async-timeout/commit/5128f7f4ff73b165579006a8336978efaeeca07a""><code>5128f7f</code></a> Fix CHANGES</li>; <li><a href=""https://github.com/aio-libs/async-timeout/commit/18e718a56f9def7dc40bb9ce3a2962a8fb0c883c""><code>18e718a</code></a> Bump to 4.0.2</li>; <li><a href=""https://github.com/aio-libs/async-timeout/commit/48d1c4ce923b1da75976d7e2a6ca9234b3092c16""><code>48d1c4c</code></a> Setup towncrier</li>; <li><a href=""https://github.com/aio-libs/async-timeout/commit/2ede7d73e55f8d1a2279d78861af0009d96219fb""><code>2ede7d7</code></a> Fix annotations on <code>__exit__</code> and <code>__aexit__</code> (<a href=""https://github-redirect.dependabot.com/aio-libs/async-timeout/issues/274"">#274</a>)</li>; <li><a href=""https://github.com/aio-libs/async-timeout/commit/8685c60dc0e82ee246fbe3d1aa272d1dfe57c24c""><code>8685c60</code></a> Bump mypy from 0.910 to 0.920 (<a href=""https://github-redirect.dependabot.com/aio-libs/async-timeout/issues/273"">#273</a>)</li>; <li><a href=""https://github.com/aio-libs/async-timeout/commit/f0a0914345b224448220aeb00d71e6a04a5d2",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11465:4025,timeout,timeout,4025,https://hail.is,https://github.com/hail-is/hail/pull/11465,1,['timeout'],['timeout']
Safety,"p pygments from 2.7.2 to 2.7.3 (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp/issues/5318"">#5318</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/5085173d947e6cc01b6daf1aa48fe7698834c569""><code>5085173</code></a> Bump multidict from 5.0.2 to 5.1.0 (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp/issues/5308"">#5308</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/5d1a75e68d278c641c90021409f4eb5de1810e5e""><code>5d1a75e</code></a> Bump pre-commit from 2.9.0 to 2.9.2 (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp/issues/5290"">#5290</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/6724d0e7a944fd7e3a710dc292d785fa8fe424fd""><code>6724d0e</code></a> Bump pre-commit from 2.8.2 to 2.9.0 (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp/issues/5273"">#5273</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/c688451ce31b914c71b11d2ac6c326b0c87e6d1f""><code>c688451</code></a> Removed duplicate timeout parameter in ClientSession reference docs. (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp/issues/5262"">#5262</a>) ...</li>; <li>Additional commits viewable in <a href=""https://github.com/aio-libs/aiohttp/compare/v3.6.0...v3.7.4"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=aiohttp&package-manager=pip&previous-version=3.6.0&new-version=3.7.4)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10115:8650,timeout,timeout,8650,https://hail.is,https://github.com/hail-is/hail/pull/10115,1,['timeout'],['timeout']
Safety,"p>; <ul>; <li>Respect <code>dot_notation</code> flag in ignore argument (<a href=""https://github.com/yoyonel""><code>@​yoyonel</code></a>) (<a href=""https://github-redirect.dependabot.com/inveniosoftware/dictdiffer/issues/107"">#107</a>)</li>; <li>Adds argument for toggling dot notation in diff. (<a href=""https://github.com/robinchew""><code>@​robinchew</code></a>)</li>; </ul>; <p>Version 0.7.2 (released 2019-02-22)</p>; <ul>; <li>Two NaN values are considered the same, hence they are not shown in <code>diff</code>; output. (<a href=""https://github-redirect.dependabot.com/inveniosoftware/dictdiffer/issues/114"">#114</a>) (<a href=""https://github.com/t-b""><code>@​t-b</code></a>)</li>; <li>Refactors <code>diff</code> method to reduce recursive call stack size. (<a href=""https://github-redirect.dependabot.com/inveniosoftware/dictdiffer/issues/112"">#112</a>); (<a href=""https://github.com/yoyonel""><code>@​yoyonel</code></a>)</li>; <li>Python porting best practice use feature detection instead; of version detection to save an import and pass both PyLint; and Flake8 tests with neither 'pragma' nor 'noqa'. (<a href=""https://github.com/cclauss""><code>@​cclauss</code></a>)</li>; </ul>; <p>Version 0.7.1 (released 2018-05-04)</p>; <ul>; <li>Resolves issue with keys containing dots. (<a href=""https://github-redirect.dependabot.com/inveniosoftware/dictdiffer/issues/101"">#101</a>)</li>; </ul>; <p>Version 0.7.0 (released 2017-10-16)</p>; <ul>; <li>Fixes problem with diff results that reference the original structure by; introduction of <code>deepcopy</code> for all possibly unhashable items. Thus the diff; does not change later when the diffed structures change.</li>; <li>Adds new option for patching and reverting patches in-place.</li>; <li>Adds Python 3.6 to test matrix.</li>; <li>Fixes the <code>ignore</code> argument when it contains a unicode value.</li>; </ul>; <p>Version 0.6.1 (released 2016-11-22)</p>; <ul>; <li>Changes order of items for REMOVE section of generated patches whe",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11485:4217,detect,detection,4217,https://hail.is,https://github.com/hail-is/hail/pull/11485,2,['detect'],['detection']
Safety,parameterize some IRSuite tests to avoid c++ recompilation,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5582:35,avoid,avoid,35,https://hail.is,https://github.com/hail-is/hail/pull/5582,1,['avoid'],['avoid']
Safety,park.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:803); at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:803); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); at org.apache.spark.scheduler.Task.run(Task.scala:86); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1275:3846,abort,abortStage,3846,https://hail.is,https://github.com/hail-is/hail/issues/1275,1,['abort'],['abortStage']
Safety,park.scala:107); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); 	at org.apache.spark.scheduler.Task.run(Task.scala:86); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1873); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1886); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4250:6083,abort,abortStage,6083,https://hail.is,https://github.com/hail-is/hail/issues/4250,1,['abort'],['abortStage']
Safety,park.util.CompletionIterator.hasNext(CompletionIterator.scala:32); at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37); at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:199); at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:103); at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1517); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1505); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1504); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1504); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1732); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1687); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4780:9847,abort,abortStage,9847,https://hail.is,https://github.com/hail-is/hail/issues/4780,1,['abort'],['abortStage']
Safety,"pendabot.com/PyCQA/pylint/issues/6577"">#6577</a>)</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/e8202000e046e286816375f5887110cacda4d11b""><code>e820200</code></a> Normalize path before checking if path should be ignored (<a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/7080"">#7080</a>)</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/c82d08c8433de92433b9b555dd2eb50a7987060f""><code>c82d08c</code></a> Don't report <code>import-private-name</code> for relative imports (<a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/7079"">#7079</a>)</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/f8f05f12522c0036668f9a0da86fa0d3456ed795""><code>f8f05f1</code></a> Don't emit <code>modified-iterating-dict</code> when updating existing keys (<a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/7037"">#7037</a>)</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/bee24cd55af4f1231e787aed5a1cc072492adee6""><code>bee24cd</code></a> Avoid hangs on many-core Windows machines (<a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/7035"">#7035</a>)</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/b379ef3acc2a983140994c93a2ea2c99e260c9c1""><code>b379ef3</code></a> Fix handling of quoted <code>init-hook</code> (<a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/7010"">#7010</a>)</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/c15902462af9100b5f7301f0cc978f2296e5d42f""><code>c159024</code></a> Fix differing param doc false positive (<a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/6980"">#6980</a>)</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/680edebc686cad664bbed934a490aeafa775f163""><code>680edeb</code></a> Bump pylint to 2.14.3, update changelog</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/b05ac51ad2e3785b6b9b071b8cb241993c914105""><code>b05ac51</code></a> Pin <code>colorama</code> to lowest supported version (<a href=""http",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11980:1592,Avoid,Avoid,1592,https://hail.is,https://github.com/hail-is/hail/pull/11980,1,['Avoid'],['Avoid']
Safety,"pendabot.com/tox-dev/py-filelock/pull/154"">tox-dev/py-filelock#154</a></li>; <li>Bump actions/download-artifact from 2 to 3 by <a href=""https://github.com/dependabot""><code>@​dependabot</code></a> in <a href=""https://github-redirect.dependabot.com/tox-dev/py-filelock/pull/152"">tox-dev/py-filelock#152</a></li>; <li>Bump pre-commit/action from 2.0.3 to 3.0.0 by <a href=""https://github.com/dependabot""><code>@​dependabot</code></a> in <a href=""https://github-redirect.dependabot.com/tox-dev/py-filelock/pull/151"">tox-dev/py-filelock#151</a></li>; <li>Bump actions/checkout from 2 to 3 by <a href=""https://github.com/dependabot""><code>@​dependabot</code></a> in <a href=""https://github-redirect.dependabot.com/tox-dev/py-filelock/pull/153"">tox-dev/py-filelock#153</a></li>; <li>Bump actions/setup-python from 2 to 4 by <a href=""https://github.com/dependabot""><code>@​dependabot</code></a> in <a href=""https://github-redirect.dependabot.com/tox-dev/py-filelock/pull/150"">tox-dev/py-filelock#150</a></li>; <li>Add timeout unit to docstrings by <a href=""https://github.com/jnordberg""><code>@​jnordberg</code></a> in <a href=""https://github-redirect.dependabot.com/tox-dev/py-filelock/pull/148"">tox-dev/py-filelock#148</a></li>; <li>Unify badges style by <a href=""https://github.com/DeadNews""><code>@​DeadNews</code></a> in <a href=""https://github-redirect.dependabot.com/tox-dev/py-filelock/pull/155"">tox-dev/py-filelock#155</a></li>; <li>[pre-commit.ci] pre-commit autoupdate by <a href=""https://github.com/pre-commit-ci""><code>@​pre-commit-ci</code></a> in <a href=""https://github-redirect.dependabot.com/tox-dev/py-filelock/pull/156"">tox-dev/py-filelock#156</a></li>; <li>[pre-commit.ci] pre-commit autoupdate by <a href=""https://github.com/pre-commit-ci""><code>@​pre-commit-ci</code></a> in <a href=""https://github-redirect.dependabot.com/tox-dev/py-filelock/pull/157"">tox-dev/py-filelock#157</a></li>; <li>Check 3.11 support by <a href=""https://github.com/gaborbernat""><code>@​gaborbernat</code></a>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12157:1701,timeout,timeout,1701,https://hail.is,https://github.com/hail-is/hail/pull/12157,1,['timeout'],['timeout']
Safety,"pendency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI1NDMwZTFmMi0wNDZjLTQwNDctYmI3Mi1hZmJkZmM1MDViNGEiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjU0MzBlMWYyLTA0NmMtNDA0Ny1iYjcyLWFmYmRmYzUwNWI0YSJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""5430e1f2-046c-4047-bb72-afbdfc505b4a"",""prPublicId"":""5430e1f2-046c-4047-bb72-afbdfc505b4a"",""dependencies"":[{""name"":""certifi"",""from"":""2023.5.7"",""to"":""2023.7.22""}],""packageManager"":""pip"",""projectPublicId"":""c1c98f6a-57c6-4ecc-a329-3b744cab74bd"",""projectUrl"":""https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-CERTIFI-5805047""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""priorityScore""],""priorityScoreList"":[471],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Learn about vulnerability in an interactive lesson of Snyk Learn.](https://learn.snyk.io/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13304:3145,remediat,remediationStrategy,3145,https://hail.is,https://github.com/hail-is/hail/pull/13304,1,['remediat'],['remediationStrategy']
Safety,"pendency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI3Mzc3ZjFlZS1kMjJjLTQ0MDAtYmE1Yy04NGNkYWZmZWJmYzgiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjczNzdmMWVlLWQyMmMtNDQwMC1iYTVjLTg0Y2RhZmZlYmZjOCJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/701495b8-b53d-48af-82fe-1a6c57aa56cb?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/701495b8-b53d-48af-82fe-1a6c57aa56cb?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""7377f1ee-d22c-4400-ba5c-84cdaffebfc8"",""prPublicId"":""7377f1ee-d22c-4400-ba5c-84cdaffebfc8"",""dependencies"":[{""name"":""certifi"",""from"":""2023.5.7"",""to"":""2023.7.22""}],""packageManager"":""pip"",""projectPublicId"":""701495b8-b53d-48af-82fe-1a6c57aa56cb"",""projectUrl"":""https://app.snyk.io/org/danking/project/701495b8-b53d-48af-82fe-1a6c57aa56cb?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-CERTIFI-5805047""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""priorityScore""],""priorityScoreList"":[471],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Learn about vulnerability in an interactive lesson of Snyk Learn.](https://learn.snyk.io/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13305:3128,remediat,remediationStrategy,3128,https://hail.is,https://github.com/hail-is/hail/pull/13305,1,['remediat'],['remediationStrategy']
Safety,"pendency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJjMDQ5NzlhMC1iYWM3LTRiMjEtYmE0ZS02OWU5YjAzMTE5ZjAiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImMwNDk3OWEwLWJhYzctNGIyMS1iYTRlLTY5ZTliMDMxMTlmMCJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/7fad328c-8d01-4768-8813-73d6c644e2d4?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/7fad328c-8d01-4768-8813-73d6c644e2d4?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""c04979a0-bac7-4b21-ba4e-69e9b03119f0"",""prPublicId"":""c04979a0-bac7-4b21-ba4e-69e9b03119f0"",""dependencies"":[{""name"":""certifi"",""from"":""2023.5.7"",""to"":""2023.7.22""}],""packageManager"":""pip"",""projectPublicId"":""7fad328c-8d01-4768-8813-73d6c644e2d4"",""projectUrl"":""https://app.snyk.io/org/danking/project/7fad328c-8d01-4768-8813-73d6c644e2d4?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-CERTIFI-5805047""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""priorityScore""],""priorityScoreList"":[471],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Learn about vulnerability in an interactive lesson of Snyk Learn.](https://learn.snyk.io/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13309:3130,remediat,remediationStrategy,3130,https://hail.is,https://github.com/hail-is/hail/pull/13309,1,['remediat'],['remediationStrategy']
Safety,"pendency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJkY2E2ZDI1ZC1hZGM3LTRiNTctYWU3Zi0yNjExOTYzNTY5MmUiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImRjYTZkMjVkLWFkYzctNGI1Ny1hZTdmLTI2MTE5NjM1NjkyZSJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""dca6d25d-adc7-4b57-ae7f-26119635692e"",""prPublicId"":""dca6d25d-adc7-4b57-ae7f-26119635692e"",""dependencies"":[{""name"":""certifi"",""from"":""2023.5.7"",""to"":""2023.7.22""}],""packageManager"":""pip"",""projectPublicId"":""5ecb4152-94d0-44ff-86c6-21e542bb123d"",""projectUrl"":""https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-CERTIFI-5805047""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""priorityScore""],""priorityScoreList"":[471],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Learn about vulnerability in an interactive lesson of Snyk Learn.](https://learn.snyk.io/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13294:3137,remediat,remediationStrategy,3137,https://hail.is,https://github.com/hail-is/hail/pull/13294,1,['remediat'],['remediationStrategy']
Safety,"pendency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJlMjNiYjk0OC04YjdmLTQ5MzUtYTRkMi05ZWJmNjg4NjZlMmUiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImUyM2JiOTQ4LThiN2YtNDkzNS1hNGQyLTllYmY2ODg2NmUyZSJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""e23bb948-8b7f-4935-a4d2-9ebf68866e2e"",""prPublicId"":""e23bb948-8b7f-4935-a4d2-9ebf68866e2e"",""dependencies"":[{""name"":""certifi"",""from"":""2023.5.7"",""to"":""2023.7.22""}],""packageManager"":""pip"",""projectPublicId"":""20159ae6-a5aa-42fa-845a-c89f5bcbf999"",""projectUrl"":""https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-CERTIFI-5805047""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""priorityScore""],""priorityScoreList"":[471],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Learn about vulnerability in an interactive lesson of Snyk Learn.](https://learn.snyk.io/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13316:3141,remediat,remediationStrategy,3141,https://hail.is,https://github.com/hail-is/hail/pull/13316,1,['remediat'],['remediationStrategy']
Safety,"pendency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJmYWJiOGYzZi1mMDFjLTQxMjktODJjNC1kZjQzMjRmZTU4YTIiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImZhYmI4ZjNmLWYwMWMtNDEyOS04MmM0LWRmNDMyNGZlNThhMiJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/b72ce54d-5de3-48e5-a1d4-6f8967681a12?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/b72ce54d-5de3-48e5-a1d4-6f8967681a12?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""fabb8f3f-f01c-4129-82c4-df4324fe58a2"",""prPublicId"":""fabb8f3f-f01c-4129-82c4-df4324fe58a2"",""dependencies"":[{""name"":""certifi"",""from"":""2023.5.7"",""to"":""2023.7.22""}],""packageManager"":""pip"",""projectPublicId"":""b72ce54d-5de3-48e5-a1d4-6f8967681a12"",""projectUrl"":""https://app.snyk.io/org/danking/project/b72ce54d-5de3-48e5-a1d4-6f8967681a12?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-CERTIFI-5805047""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""priorityScore""],""priorityScoreList"":[471],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Learn about vulnerability in an interactive lesson of Snyk Learn.](https://learn.snyk.io/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13296:3130,remediat,remediationStrategy,3130,https://hail.is,https://github.com/hail-is/hail/pull/13296,1,['remediat'],['remediationStrategy']
Safety,"pip` dependencies of this project.</h3>. #### Changes included in this PR. - Changes to the following files to upgrade the vulnerable dependencies to a fixed version:; - hail/python/pinned-requirements.txt. <details>; <summary>⚠️ <b>Warning</b></summary>. ```; msal-extensions 1.0.0 requires portalocker, which is not installed.; aiosignal 1.3.1 requires frozenlist, which is not installed.; aiodns 2.0.0 requires pycares, which is not installed. ```; </details>. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **509/1000** <br/> **Why?** Has a fix available, CVSS 5.9 | Use of a Broken or Risky Cryptographic Algorithm <br/>[SNYK-PYTHON-CRYPTOGRAPHY-6149518](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-6149518) | `cryptography:` <br> `41.0.7 -> 42.0.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **581/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 5.9 | Uncontrolled Resource Consumption (&#x27;Resource Exhaustion&#x27;) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-6157248](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-6157248) | `cryptography:` <br> `41.0.7 -> 42.0.2` <br> | No | No Known Exploit ; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **451/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 3.3 | NULL Pointer Dereference <br/>[SNYK-PYTHON-CRYPTOGRAPHY-6210214](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-6210214) | `cryptography:` <br> `41.0.7 -> 42.0.2` <br> | No | No Known Exploit . (*) Note that",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14234:1138,Risk,Risky,1138,https://hail.is,https://github.com/hail-is/hail/pull/14234,1,['Risk'],['Risky']
Safety,"ples, bi_variants = methods.concordance(bi_past_vds, bi_future_vds); File ""<decorator-gen-1304>"", line 2, in concordance; File ""/tmp/f93de2d1-2d89-43f9-9868-f266eb88a6f1/hail-devel-08a15431a0ef.zip/hail/utils/java.py"", line 155, in handle_py4j; hail.utils.java.FatalError: AssertionError: assertion failed. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 30 in stage 1.0 failed 20 times, most recent failure: Lost task 30.19 in stage 1.0 (TID 4847, lfdev2-sw-f5w2.c.broad-mpg-gnomad.internal): java.lang.AssertionError: assertion failed; 	at scala.Predef$.assert(Predef.scala:156); 	at is.hail.annotations.Region.loadInt(Region.scala:36); 	at is.hail.expr.types.TBinary$.loadLength(TBinary.scala:62); 	at is.hail.annotations.UnsafeRow$.readBinary(UnsafeRow.scala:128); 	at is.hail.annotations.UnsafeRow$.readString(UnsafeRow.scala:139); 	at is.hail.annotations.UnsafeRow$.readAltAllele(UnsafeRow.scala:152); 	at is.hail.annotations.UnsafeRow$.readArrayAltAllele(UnsafeRow.scala:164); 	at is.hail.annotations.UnsafeRow$.read(UnsafeRow.scala:210); 	at is.hail.annotations.UnsafeRow.get(UnsafeRow.scala:257); 	at is.hail.expr.FilterVariants$$anonfun$10.apply(Relational.scala:503); 	at is.hail.expr.FilterVariants$$anonfun$10.apply(Relational.scala:500); 	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:463); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$9$$anon$5.hasNext(OrderedRVD.scala:658); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$9$$anon$5.hasNext(OrderedRVD.scala:658); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$9$$anon$5.hasNext(OrderedRVD.scala:658); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at is.hail.sparkextras.OrderedRDD$$anonfun$apply$5$$anon$2.hasNext(OrderedRDD.scala:194); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at scala.collection.Itera",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2743:2488,Unsafe,UnsafeRow,2488,https://hail.is,https://github.com/hail-is/hail/issues/2743,1,['Unsafe'],['UnsafeRow']
Safety,ply(TraversableLike.scala:234); 	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); 	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186); 	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); 	at scala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:186); 	at is.hail.io.vcf.FormatParser$.apply(LoadVCF.scala:470); 	at is.hail.io.vcf.ParseLineContext.getFormatParser(LoadVCF.scala:551); 	at is.hail.io.vcf.LoadVCF$$anonfun$14.apply(LoadVCF.scala:886); 	at is.hail.io.vcf.LoadVCF$$anonfun$14.apply(LoadVCF.scala:869); 	at is.hail.io.vcf.LoadVCF$$anonfun$parseLines$1$$anon$1.hasNext(LoadVCF.scala:737); 	... 34 more. Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1517); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1505); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1504); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1504); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1732); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1687); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1676); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.ap,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3467:4982,abort,abortStage,4982,https://hail.is,https://github.com/hail-is/hail/issues/3467,1,['abort'],['abortStage']
Safety,"pool.py"", line 384, in _make_request; six.raise_from(e, None); File ""<string>"", line 2, in raise_from; File ""/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py"", line 380, in _make_request; httplib_response = conn.getresponse(); File ""/usr/local/lib/python3.6/http/client.py"", line 1354, in getresponse; response.begin(); File ""/usr/local/lib/python3.6/http/client.py"", line 307, in begin; version, status, reason = self._read_status(); File ""/usr/local/lib/python3.6/http/client.py"", line 268, in _read_status; line = str(self.fp.readline(_MAXLINE + 1), ""iso-8859-1""); File ""/usr/local/lib/python3.6/socket.py"", line 586, in readinto; return self._sock.recv_into(b); File ""/usr/local/lib/python3.6/ssl.py"", line 1012, in recv_into; return self.read(nbytes, buffer); File ""/usr/local/lib/python3.6/ssl.py"", line 874, in read; return self._sslobj.read(len, buffer); File ""/usr/local/lib/python3.6/ssl.py"", line 631, in read; v = self._sslobj.read(len, buffer); socket.timeout: The read operation timed out. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/usr/local/lib/python3.6/site-packages/requests/adapters.py"", line 449, in send; timeout=timeout; File ""/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py"", line 638, in urlopen; _stacktrace=sys.exc_info()[2]); File ""/usr/local/lib/python3.6/site-packages/urllib3/util/retry.py"", line 368, in increment; raise six.reraise(type(error), error, _stacktrace); File ""/usr/local/lib/python3.6/site-packages/urllib3/packages/six.py"", line 686, in reraise; raise value; File ""/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py"", line 600, in urlopen; chunked=chunked); File ""/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py"", line 386, in _make_request; self._raise_timeout(err=e, url=url, timeout_value=read_timeout); File ""/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py"", line 306, in _raise_timeout; raise ReadTi",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8053:1095,timeout,timeout,1095,https://hail.is,https://github.com/hail-is/hail/issues/8053,3,['timeout'],['timeout']
Safety,"ported by; this release are 3.8-3.11.</p>; <h2>Contributors</h2>; <p>A total of 14 people contributed to this release. People with a &quot;+&quot; by; their names contributed a patch for the first time.</p>; <ul>; <li>Bas van Beek</li>; <li>Charles Harris</li>; <li>Khem Raj +</li>; <li>Mark Harfouche</li>; <li>Matti Picus</li>; <li>Panagiotis Zestanakis +</li>; <li>Peter Hawkins</li>; <li>Pradipta Ghosh</li>; <li>Ross Barnowski</li>; <li>Sayed Adel</li>; <li>Sebastian Berg</li>; <li>Syam Gadde +</li>; <li>dmbelov +</li>; <li>pkubaj +</li>; </ul>; <h2>Pull requests merged</h2>; <p>A total of 17 pull requests were merged for this release.</p>; <ul>; <li><a href=""https://redirect.github.com/numpy/numpy/pull/22965"">#22965</a>: MAINT: Update python 3.11-dev to 3.11.</li>; <li><a href=""https://redirect.github.com/numpy/numpy/pull/22966"">#22966</a>: DOC: Remove dangling deprecation warning</li>; <li><a href=""https://redirect.github.com/numpy/numpy/pull/22967"">#22967</a>: ENH: Detect CPU features on FreeBSD/powerpc64*</li>; <li><a href=""https://redirect.github.com/numpy/numpy/pull/22968"">#22968</a>: BUG: np.loadtxt cannot load text file with quoted fields separated...</li>; <li><a href=""https://redirect.github.com/numpy/numpy/pull/22969"">#22969</a>: TST: Add fixture to avoid issue with randomizing test order.</li>; <li><a href=""https://redirect.github.com/numpy/numpy/pull/22970"">#22970</a>: BUG: Fix fill violating read-only flag. (<a href=""https://redirect.github.com/numpy/numpy/issues/22959"">#22959</a>)</li>; <li><a href=""https://redirect.github.com/numpy/numpy/pull/22971"">#22971</a>: MAINT: Add additional information to missing scalar AttributeError</li>; <li><a href=""https://redirect.github.com/numpy/numpy/pull/22972"">#22972</a>: MAINT: Move export for scipy arm64 helper into main module</li>; <li><a href=""https://redirect.github.com/numpy/numpy/pull/22976"">#22976</a>: BUG, SIMD: Fix spurious invalid exception for sin/cos on arm64/clang</li>; <li><a href=""https://redirect",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12898:1404,Detect,Detect,1404,https://hail.is,https://github.com/hail-is/hail/pull/12898,1,['Detect'],['Detect']
Safety,pply(ContextRDD.scala:458); 	at is.hail.sparkextras.ContextRDD$$anonfun$runJob$1.apply(ContextRDD.scala:458); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2062); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2062); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1658); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.ap,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3516:3742,abort,abortStage,3742,https://hail.is,https://github.com/hail-is/hail/issues/3516,1,['abort'],['abortStage']
Safety,pply(ContextRDD.scala:469); 	at is.hail.sparkextras.ContextRDD$$anonfun$runJob$1.apply(ContextRDD.scala:467); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1517); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1505); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1504); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1504); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1732); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1687); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1676); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.ap,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3790:6639,abort,abortStage,6639,https://hail.is,https://github.com/hail-is/hail/issues/3790,1,['abort'],['abortStage']
Safety,pply(ContextRDD.scala:471); 	at is.hail.sparkextras.ContextRDD$$anonfun$runJob$1.apply(ContextRDD.scala:469); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2062); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2062); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1658); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.ap,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4055:5897,abort,abortStage,5897,https://hail.is,https://github.com/hail-is/hail/issues/4055,2,['abort'],['abortStage']
Safety,"project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJlZjJlMTU4YS01YTI0LTQ2NjgtYjY2My1iMmYzYmNmZjM3NmUiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImVmMmUxNThhLTVhMjQtNDY2OC1iNjYzLWIyZjNiY2ZmMzc2ZSJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/fa47fca0-549b-41a3-8bf7-bcda4ca9a617?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/fa47fca0-549b-41a3-8bf7-bcda4ca9a617?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""ef2e158a-5a24-4668-b663-b2f3bcff376e"",""prPublicId"":""ef2e158a-5a24-4668-b663-b2f3bcff376e"",""dependencies"":[{""name"":""numpy"",""from"":""1.21.3"",""to"":""1.22.2""}],""packageManager"":""pip"",""projectPublicId"":""fa47fca0-549b-41a3-8bf7-bcda4ca9a617"",""projectUrl"":""https://app.snyk.io/org/danking/project/fa47fca0-549b-41a3-8bf7-bcda4ca9a617?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-NUMPY-2321964"",""SNYK-PYTHON-NUMPY-2321966"",""SNYK-PYTHON-NUMPY-2321970""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""pr-warning-shown""],""priorityScoreList"":[null,null,null],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [NULL Pointer Dereference](https://learn.snyk.io/lessons/null-dereference/cpp/?loc&#x3D;fix-pr); 🦉 [Denial of Service (DoS)](https://learn.snyk.io/lessons/redos/javascript/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12895:3639,remediat,remediationStrategy,3639,https://hail.is,https://github.com/hail-is/hail/pull/12895,1,['remediat'],['remediationStrategy']
Safety,"pyterlab/issues/15650"">#15650</a>: Fix jupyterlab downgrade issue on extension installation ...</li>; <li><a href=""https://github.com/jupyterlab/jupyterlab/commit/58fb4a9b630cd22d7b064b3c8fef503b11afe077""><code>58fb4a9</code></a> Backport PR <a href=""https://redirect.github.com/jupyterlab/jupyterlab/issues/15690"">#15690</a>: Fix search highlights removal on clearing input box (<a href=""https://redirect.github.com/jupyterlab/jupyterlab/issues/15712"">#15712</a>)</li>; <li><a href=""https://github.com/jupyterlab/jupyterlab/commit/5062929f60ac770c7048350260636d3f63ea1c8d""><code>5062929</code></a> Backport PR <a href=""https://redirect.github.com/jupyterlab/jupyterlab/issues/15703"">#15703</a> on branch 4.0.x (Add scroll margin to headings for better ...</li>; <li><a href=""https://github.com/jupyterlab/jupyterlab/commit/c00b0ca0cc631992c7681473d88208fcc74de00e""><code>c00b0ca</code></a> Backport PR <a href=""https://redirect.github.com/jupyterlab/jupyterlab/issues/15642"">#15642</a>: Fix outputarea package from not detecting updates (<a href=""https://redirect.github.com/jupyterlab/jupyterlab/issues/15652"">#15652</a>)</li>; <li><a href=""https://github.com/jupyterlab/jupyterlab/commit/8326236cf42c43ee1ed9657c09d7c4cbad5973f1""><code>8326236</code></a> Backport PR <a href=""https://redirect.github.com/jupyterlab/jupyterlab/issues/15262"">#15262</a> on branch 4.0.x (Fix connection loop issue with standalone...</li>; <li><a href=""https://github.com/jupyterlab/jupyterlab/commit/8a5acf284b1e6defc6b15f22ec11c3cae67eaba1""><code>8a5acf2</code></a> Backport PR <a href=""https://redirect.github.com/jupyterlab/jupyterlab/issues/15695"">#15695</a>: Fix shortcut UI failing on filtering when empty command i...</li>; <li><a href=""https://github.com/jupyterlab/jupyterlab/commit/9d4a3611bae6868f7de7584f8c0b16b8a7535e70""><code>9d4a361</code></a> Automated Changelog Entry - Remove 1 placeholder entries. (<a href=""https://redirect.github.com/jupyterlab/jupyterlab/issues/15667"">#15667</a>)</li>; <li>Addit",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14218:13422,detect,detecting,13422,https://hail.is,https://github.com/hail-is/hail/pull/14218,1,['detect'],['detecting']
Safety,"pytest and jvm-test pass, so it seems the looser assertion can be tightened to make this safer.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8042:89,safe,safer,89,https://hail.is,https://github.com/hail-is/hail/pull/8042,1,['safe'],['safer']
Safety,"quest; headers=headers); File ""/usr/local/lib/python3.6/dist-packages/kubernetes/client/rest.py"", line 231, in GET; query_params=query_params); File ""/usr/local/lib/python3.6/dist-packages/kubernetes/client/rest.py"", line 222, in request; raise ApiException(http_resp=r); {""levelname"": ""INFO"", ""asctime"": ""2019-07-11 14:19:39,924"", ""filename"": ""batch.py"", ""funcNameAndLine"": ""mark_complete:591"", ""message"": ""no logs for batch-9-job-1-c8b9b2 due to previous error, rescheduling pod Error: (400)\nReason: Bad Request\nHTTP response headers: HTTPHeaderDict({'Audit-Id': '6a744afc-154f-4b48-b4bb-51a15078d999', 'Content-Type': 'application/json', 'Date': 'Thu, 11 Jul 2019 14:19:39 GMT', 'Content-Length': '179'})\nHTTP response body: {\""kind\"":\""Status\"",\""apiVersion\"":\""v1\"",\""metadata\"":{},\""status\"":\""Failure\"",\""message\"":\""container \\\""main\\\"" in pod \\\""batch-9-job-1-c8b9b2\\\"" is terminated\"",\""reason\"":\""BadRequest\"",\""code\"":400}\n\n""}; ```. And finally, this k8s refresh loop sequence repeats until CI kills the tests due to a timeout. ```; {""levelname"": ""INFO"", ""asctime"": ""2019-07-11 14:23:41,070"", ""filename"": ""batch.py"", ""funcNameAndLine"": ""refresh_k8s_state:1261"", ""message"": ""started k8s state refresh""}; {""levelname"": ""INFO"", ""asctime"": ""2019-07-11 14:23:41,085"", ""filename"": ""batch.py"", ""funcNameAndLine"": ""refresh_k8s_pods:1210"", ""message"": ""k8s had 3 pods""}; {""levelname"": ""INFO"", ""asctime"": ""2019-07-11 14:23:41,088"", ""filename"": ""batch.py"", ""funcNameAndLine"": ""update_job_with_pod:1145"", ""message"": ""update job (11, 1, 'output') with pod batch-11-job-1-4f1118""}; {""levelname"": ""INFO"", ""asctime"": ""2019-07-11 14:23:41,090"", ""filename"": ""batch.py"", ""funcNameAndLine"": ""update_job_with_pod:1145"", ""message"": ""update job (11, 2, 'output') with pod batch-11-job-2-ad1587""}; {""levelname"": ""INFO"", ""asctime"": ""2019-07-11 14:23:41,093"", ""filename"": ""batch.py"", ""funcNameAndLine"": ""update_job_with_pod:1145"", ""message"": ""update job (11, 3, 'output') with pod batch-11-job-3-d826dd""}; {",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6617:14756,timeout,timeout,14756,https://hail.is,https://github.com/hail-is/hail/issues/6617,1,['timeout'],['timeout']
Safety,"r every file). I should switch this to a disk-based index.~ Made it disk-based, called it `OnDiskBTreeIndexToValue` #3794. - each hadoop `FileSplit` now contains a possibly null (indicating no filter) list of variants (by index) to keep, in practice this should be quite small. - ~I changed several asserts to `if`'s with fatals, so as not to allocate strings~ Moved to #3771. - ~We no longer copy the genotype data into a buffer in the block reader. This was forcing the `fastKeys` to do an unnecessary data copy~ Moved to #3783 (with some substantial refactoring so it doesn't look much like this PR anymore). - ~I changed the contract on BgenRecord to require that `getValue` is called to ""consume"" the record before the next record is taken~ Irrelevant thanks to #3783 's refactoring. - ~`getValue(null)` just skips bytes (no copy, no decompression)~ Irrelevant thanks to #3783 's refactoring. - ~I added `RegionValueBuilder.unsafeAdvance` which can be used when you're creating an array of empty structs but don't want to do all the unnecessary RVB bookkeeping work.~ Moved to #3773. - ~I use `RegionValueBuilder.unsafeAdvance` to make loading a BGEN without entry fields very fast.~ Rolled into #3783. - ~I fixed `Table.index` to not trigger a partition key info gathering~ Moved to #3774. I had to ship the arrays of filtered variant indices to the workers somehow, so I shipped them as base64 encoded arrays of bytes. It's pretty groady (and that's why I added the commons-codec library). I don't know how else to initialize record readers with hadoop. Generally, I think the BGEN loading code could use a clean up, and I haven't done that here, if anything I've made it more complicated. I also need to check that there are tests for or write tests for:. - indexing tables doesn't cause an extra shuffle; - ~the include lid and include raid flags~ included in #3779; - the variant list flag; - `getSplits`; - the variant filtering code; - ~loading a bgen with no entries~ exists: `BGENTests.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3727:2608,unsafe,unsafeAdvance,2608,https://hail.is,https://github.com/hail-is/hail/pull/3727,1,['unsafe'],['unsafeAdvance']
Safety,"r. I think this is currently impossible due to lack of permissions, but we should either explicitly prohibit this or ensure our solution encompasses it. In particular, I am concerned OpenID could be used to grant permission for a GCP identity to write to S3 or ABS. . Pulling an image shouldn’t trigger substantial egress. In the first case, there are three kinds of possible egress:; 1. Egress to the Public Internet.; 2. Egress to a VM in a different Google region.; 3. Egress to a Google Service in a different Google region (e.g. uploading to a bucket in a different region). I believe (2) and (3) are charged equivalently. (1) is simply Internet egress pricing. In (3), I’m not sure who pays the egress from a VM to a bucket in a different region. I assume the VM owner. In all three cases, the destination’s location matters. For public Internet egress, we can use GeoIP to determine the region of the planet. I’m not sure if we can determine the region of (2) and (3). If we can’t, we should either prevent such traffic or we should charge the maximum egress. A final caveat is that we use Premium Networking. As a result, our traffic can use Google’s internal backbone. It’s not clear to me if this means that a packet from us-central to a public IP in Australia incurs just Internet egress or that *and* a region-to-region egress to pay for the use of GCP’s internal global backbone. The priority of various considerations:; 1. Top priority within this issue is to track and recover costs. Even if this means charging a flat fee across all possible kinds of egress. Even if that fee is substantially higher than the real cost to us.; 2. Second priority is to surface this information to the user. Simply providing, in the job page, the usage and cost of each resource for this job.; 3. Fine grained egress so that users can actually intentionally use it at cost or near cost to, for example, move data between clouds or regions. . ### Version. 0.2.120. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13428:1907,recover,recover,1907,https://hail.is,https://github.com/hail-is/hail/issues/13428,1,['recover'],['recover']
Safety,"r.buffer.max=1g,spark:spark.driver.extraJavaOptions=-Xss4M,spark:spark.executor.extraJavaOptions=-Xss4M,hdfs:dfs.replication=1,dataproc:dataproc.logging.stackdriver.enable=false,dataproc:dataproc.monitoring.stackdriver.enable=false,spark:spark.driver.memory=41g \; --initialization-actions=gs://hail-common/hailctl/dataproc/0.2.18/init_notebook.py,gs://gnomad-public/tools/inits/master-init.sh \; --metadata=^|||^WHEEL=gs://hail-common/hailctl/dataproc/0.2.18/hail-0.2.18-py3-none-any.whl|||PKGS=aiohttp|bokeh>1.1,<1.3|decorator<5|gcsfs==0.2.1|hurry.filesize==0.9|ipykernel<5|nest_asyncio|numpy<2|pandas>0.22,<0.24|parsimonious<0.9|PyJWT|python-json-logger==0.1.11|requests>=2.21.0,<2.21.1|scipy>1.2,<1.4|tabulate==0.8.3|slackclient==2.0.0|websocket-client|sklearn|tabulate|statsmodels|scikit-learn|hdbscan|matplotlib \; --master-machine-type=n1-highmem-8 \; --master-boot-disk-size=100GB \; --num-master-local-ssds=0 \; --num-preemptible-workers=0 \; --num-worker-local-ssds=0 \; --num-workers=2 \; --preemptible-worker-boot-disk-size=40GB \; --worker-boot-disk-size=40 \; --worker-machine-type=n1-standard-8 \; --zone=us-central1-b \; --initialization-action-timeout=20m \; --labels=creator=weisburd_broadinstitute_org \; --max-idle=12h; Starting cluster 'bw2'...; Waiting on operation [projects/seqr-project/regions/global/operations/46f1d37d-798a-3fc0-8f70-eac304448a08].; Waiting for cluster creation operation...; WARNING: For PD-Standard without local SSDs, we strongly recommend provisioning 1TB or larger to ensure consistently high I/O performance. See https://cloud.google.com/compute/docs/disks/performance for information on disk I/O performance.; Waiting for cluster creation operation...done.; ERROR: (gcloud.beta.dataproc.clusters.create) Operation [projects/seqr-project/regions/global/operations/46f1d37d-798a-3fc0-8f70-eac304448a08] failed: Initialization action failed. Failed action 'gs://hail-common/hailctl/dataproc/0.2.18/init_notebook.py', see output in: gs://dataproc-d919bdd",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6634:1598,timeout,timeout,1598,https://hail.is,https://github.com/hail-is/hail/issues/6634,1,['timeout'],['timeout']
Safety,"raemer/gradle-download-task/commit/4c983ed5cd229fa64912294737c858c2ba8486d6""><code>4c983ed</code></a> Bump up version number to 5.4.0</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/cc20442ab67bf37687c08e67af7e7de3a21c8fbe""><code>cc20442</code></a> Add integration tests for Gradle 8.0.2</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/472920e572e4cf45d321868874ced50ad8d1e2d5""><code>472920e</code></a> Add possibility to set request method and body</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/82e70cae2a8d48b4f5165a9b543d4e65bb793d88""><code>82e70ca</code></a> Update dependencies</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/86a15f1c16eb729dc71b6caf30237d07b8e0bb01""><code>86a15f1</code></a> Fix compiler warnings and deprecations</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/86363072c8239330b28976109a622bdd073507b6""><code>8636307</code></a> Negative timeouts are actually not allowed</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/4ff0ff0e63e0dd45f231990d0dcebffde6e6b709""><code>4ff0ff0</code></a> Update dependencies</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/a1858b494b5f3a51ccef7580c243c6dfdf520731""><code>a1858b4</code></a> Merge pull request <a href=""https://redirect.github.com/michel-kraemer/gradle-download-task/issues/295"">#295</a> from michel-kraemer/dependabot/npm_and_yarn/screencas...</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/c1e212c0fb41b3ea9185a9ea463fb1ea7142f748""><code>c1e212c</code></a> Add integration tests for Gradle 8.0 and 8.0.1</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/304f68e25f53633a92a4d2d6ce003a4986929503""><code>304f68e</code></a> Fix type inference issue</li>; <li>Additional commits viewable in <a href=""https://github.com/michel-kraemer/g",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12893:1730,timeout,timeouts,1730,https://hail.is,https://github.com/hail-is/hail/pull/12893,1,['timeout'],['timeouts']
Safety,"rderedRVD.scala:285); is.hail.rvd.OrderedRVD.head(OrderedRVD.scala:21); is.hail.rvd.RVD$class.takeAsBytes(RVD.scala:243); is.hail.rvd.OrderedRVD.takeAsBytes(OrderedRVD.scala:21); is.hail.rvd.RVD$class.take(RVD.scala:247); is.hail.rvd.OrderedRVD.take(OrderedRVD.scala:21); is.hail.table.Table.take(Table.scala:990); is.hail.table.Table.showString(Table.scala:1031); sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); java.lang.reflect.Method.invoke(Method.java:498); py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); py4j.Gateway.invoke(Gateway.java:280); py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); py4j.commands.CallCommand.execute(CallCommand.java:79); ```. Also under Failed Stages, the Failure Reason was given as:; ```; Job aborted due to stage failure: Task 0 in stage 10.0 failed 20 times, most recent failure: Lost task 0.19 in stage 10.0 (TID 526, ccarey-sw-svrp.c.ukbb-robinson.internal, executor 43): java.lang.NegativeArraySizeException; 	at java.util.Arrays.copyOf(Arrays.java:3236); 	at is.hail.annotations.Region.ensure(Region.scala:139); 	at is.hail.annotations.Region.allocate(Region.scala:152); 	at is.hail.annotations.Region.allocate(Region.scala:159); 	at is.hail.expr.types.TBinary$.allocate(TBinary.scala:101); 	at is.hail.annotations.RegionValueBuilder.fixupBinary(RegionValueBuilder.scala:263); 	at is.hail.annotations.RegionValueBuilder.fixupStruct(RegionValueBuilder.scala:319); 	at is.hail.annotations.RegionValueBuilder.fixupArray(RegionValueBuilder.scala:288); 	at is.hail.annotations.RegionValueBuilder.addRegionValue(RegionValueBuilder.scala:432); 	at is.hail.expr.MatrixMapRows$$anonfun$31$$anonfun$apply$21.apply(Relational.scala:975); 	at is.hail.expr.MatrixMapRows$$anonfun$31$$anonfu",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3508:7546,abort,aborted,7546,https://hail.is,https://github.com/hail-is/hail/issues/3508,1,['abort'],['aborted']
Safety,"re are two ordering operations in hail: `Table.order_by`, and `MatrixTable.choose_cols`. Of the three keying operations, only `Table.key_by` and `MatrixTable.key_rows_by` enforce ordering. The ordering of the columns of a matrix table has no relationship to the keys of the columns of a MatrixTable. **NB**: when a table is created from the columns of a matrix table (`MatrixTable.cols`), the table is sorted by the keys (there exists an implicit `Table.key_by`). Moreover, we guarantee and document (in `MatrixTable.cols`) that when the matrix table has a zero-length column key, the table's ordering is given by matrix table columns' ordering. According to ""Ordering and keys in relational objects"", all sorts (whether triggered by an order_by or a key_by) are unstable. A common user operation is to export or collect a field of a relational object. Sometimes users do not want the keys of an expression exported or collected. In this situation, the user requires that the data is sorted in a sensible way (otherwise they cannot recover which item came from which key). Hail internally guarantees (but does not guarantee to our users or document) that localizing operations (take, collect, and show) and `export` produce data in the ordering of the relational object. For example:. ```; In [38]: t = hl.utils.range_table(3) ; ...: t = t.order_by(-t.idx).show() ; +-------+; | idx |; +-------+; | int32 |; +-------+; | 2 |; | 1 |; | 0 |; +-------+; ```. # Ordering and Library Developers. On occasion, a user may have a table of unknown ordering and keying. For example, the implementor of `Expression.collect` (e.g. `mt.GT.collect()`). In this situation, it is desirable to be able to remove keys without modifying the order. In particular, the values should appear in the same order that they appear in the relational object (for a table, in the order of the rows; for a matrix table, ordered first by the row and then by the column). For example, the multiplication table for 0 to 2:. ```; In [39",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6929:1312,recover,recover,1312,https://hail.is,https://github.com/hail-is/hail/issues/6929,1,['recover'],['recover']
Safety,"re than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI1ZTRkMTU3Zi04YTdjLTRhNzctYTZlNC00YTdmNGU4Y2I0YzkiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjVlNGQxNTdmLThhN2MtNGE3Ny1hNmU0LTRhN2Y0ZThjYjRjOSJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""5e4d157f-8a7c-4a77-a6e4-4a7f4e8cb4c9"",""prPublicId"":""5e4d157f-8a7c-4a77-a6e4-4a7f4e8cb4c9"",""dependencies"":[{""name"":""tornado"",""from"":""6.2"",""to"":""6.3.2""}],""packageManager"":""pip"",""projectPublicId"":""20159ae6-a5aa-42fa-845a-c89f5bcbf999"",""projectUrl"":""https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-TORNADO-5537286""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""pr-warning-shown"",""priorityScore""],""priorityScoreList"":[384],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Open Redirect](https://learn.snyk.io/lesson/open-redirect/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13323:3206,remediat,remediationStrategy,3206,https://hail.is,https://github.com/hail-is/hail/pull/13323,1,['remediat'],['remediationStrategy']
Safety,"re</code>] This release add new api listRelatedResourcesForAuditFinding and new member type IssuerCertificates for Iot device device defender Audit.</li>; <li>api-change:<code>license-manager</code>: [<code>botocore</code>] AWS License Manager now supports onboarded Management Accounts or Delegated Admins to view granted licenses aggregated from all accounts in the organization.</li>; <li>api-change:<code>marketplace-catalog</code>: [<code>botocore</code>] Added three new APIs to support tagging and tag-based authorization: TagResource, UntagResource, and ListTagsForResource. Added optional parameters to the StartChangeSet API to support tagging a resource while making a request to create it.</li>; <li>api-change:<code>rekognition</code>: [<code>botocore</code>] Adding support for ImageProperties feature to detect dominant colors and image brightness, sharpness, and contrast, inclusion and exclusion filters for labels and label categories, new fields to the API response, &quot;aliases&quot; and &quot;categories&quot;</li>; <li>api-change:<code>securityhub</code>: [<code>botocore</code>] Documentation updates for Security Hub</li>; <li>api-change:<code>ssm-incidents</code>: [<code>botocore</code>] RelatedItems now have an ID field which can be used for referencing them else where. Introducing event references in TimelineEvent API and increasing maximum length of &quot;eventData&quot; to 12K characters.</li>; </ul>; <h1>1.26.7</h1>; <ul>; <li>api-change:<code>autoscaling</code>: [<code>botocore</code>] This release adds a new price capacity optimized allocation strategy for Spot Instances to help customers optimize provisioning of Spot Instances via EC2 Auto Scaling, EC2 Fleet, and Spot Fleet. It allocates Spot Instances based on both spare capacity availability and Spot Instance price.</li>; <li>api-change:<code>ec2</code>: [<code>botocore</code>] This release adds a new price capacity optimized allocation strategy for Spot Instances to help customers optimize provisi",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12458:1243,detect,detect,1243,https://hail.is,https://github.com/hail-is/hail/pull/12458,2,['detect'],['detect']
Safety,"reamId=830947795015, chunkIndex=0}: java.nio.file.NoSuchFileException: /data03/hadoop/yarn/t sun.nio.fs.UnixException.translateToIOException(UnixException.java:86) at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.javannel(UnixFileSystemProvider.java:214) at java.nio.file.Files.newByteChannel(Files.java:361) at java.nio.file.Files.newByteChannel(Files.java:40rage.BlockManager.getBlockData(BlockManager.scala:382) at org.apache.spark.network.netty.NettyBlockRpcServer$$anonfun$1.apply(NettyBlockRpcServer.rator$$anon$11.next(Iterator.scala:410) at scala.collection.convert.Wrappers$IteratorWrapper.next(Wrappers.scala:31) at org.apache.sparkler.processFetchRequest(TransportRequestHandler.java:130) at org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHetty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362) at io.netty.channel.AbstractChannelHandlerCactChannelHandlerContext.java:340) at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286) at io.netty.channelxt.invokeChannelRead(AbstractChannelHandlerContext.java:348) at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHaetty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362) at io.netty.channel.AbstractChannelHandlerCactChannelHandlerContext.java:340) at org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:85) at nnelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348) at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(A1359) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362) at io.netty.channel.Abstracead(DefaultChannelPipeline.java:935) at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:138) at ed(NioEventLoop.java:580) at io.netty.channel.nio.NioEventLoop.processSel",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8106:8459,timeout,timeout,8459,https://hail.is,https://github.com/hail-is/hail/issues/8106,1,['timeout'],['timeout']
Safety,"reason = self._read_status(); 319 if status != CONTINUE:. File /opt/conda/lib/python3.10/http/client.py:287, in HTTPResponse._read_status(self); 284 if not line:; 285 # Presumably, the server closed the connection before; 286 # sending a valid response.; --> 287 raise RemoteDisconnected(""Remote end closed connection without""; 288 "" response""); 289 try:. RemoteDisconnected: Remote end closed connection without response. During handling of the above exception, another exception occurred:. ProtocolError Traceback (most recent call last); File /opt/conda/lib/python3.10/site-packages/requests/adapters.py:487, in HTTPAdapter.send(self, request, stream, timeout, verify, cert, proxies); 486 try:; --> 487 resp = conn.urlopen(; 488 method=request.method,; 489 url=url,; 490 body=request.body,; 491 headers=request.headers,; 492 redirect=False,; 493 assert_same_host=False,; 494 preload_content=False,; 495 decode_content=False,; 496 retries=self.max_retries,; 497 timeout=timeout,; 498 chunked=chunked,; 499 ); 501 except (ProtocolError, OSError) as err:. File /opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py:787, in HTTPConnectionPool.urlopen(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw); 785 e = ProtocolError(""Connection aborted."", e); --> 787 retries = retries.increment(; 788 method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]; 789 ); 790 retries.sleep(). File /opt/conda/lib/python3.10/site-packages/urllib3/util/retry.py:550, in Retry.increment(self, method, url, response, error, _pool, _stacktrace); 549 if read is False or not self._is_method_retryable(method):; --> 550 raise six.reraise(type(error), error, _stacktrace); 551 elif read is not None:. File /opt/conda/lib/python3.10/site-packages/urllib3/packages/six.py:769, in reraise(tp, value, tb); 768 if value.__traceback__ is not tb:; --> 769 raise value.with_traceback(tb); 770 raise value. File /opt/conda",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13960:6642,timeout,timeout,6642,https://hail.is,https://github.com/hail-is/hail/issues/13960,2,['timeout'],['timeout']
Safety,"rect dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI2ZWQ3MzlmOS1mZjc4LTQzYzgtYWQwOC05MThjNmRhMWNlOTYiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjZlZDczOWY5LWZmNzgtNDNjOC1hZDA4LTkxOGM2ZGExY2U5NiJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/b72ce54d-5de3-48e5-a1d4-6f8967681a12?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/b72ce54d-5de3-48e5-a1d4-6f8967681a12?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""6ed739f9-ff78-43c8-ad08-918c6da1ce96"",""prPublicId"":""6ed739f9-ff78-43c8-ad08-918c6da1ce96"",""dependencies"":[{""name"":""aiohttp"",""from"":""3.8.4"",""to"":""3.8.5""}],""packageManager"":""pip"",""projectPublicId"":""b72ce54d-5de3-48e5-a1d4-6f8967681a12"",""projectUrl"":""https://app.snyk.io/org/danking/project/b72ce54d-5de3-48e5-a1d4-6f8967681a12?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-AIOHTTP-5798483""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""priorityScore""],""priorityScoreList"":[658],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Learn about vulnerability in an interactive lesson of Snyk Learn.](https://learn.snyk.io/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13284:3113,remediat,remediationStrategy,3113,https://hail.is,https://github.com/hail-is/hail/pull/13284,1,['remediat'],['remediationStrategy']
Safety,"rect dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI4YTljZTU5Zi0yOTY3LTQ2MTQtOGE5YS1iY2M5YjU1ZWZkZGQiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjhhOWNlNTlmLTI5NjctNDYxNC04YTlhLWJjYzliNTVlZmRkZCJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""8a9ce59f-2967-4614-8a9a-bcc9b55efddd"",""prPublicId"":""8a9ce59f-2967-4614-8a9a-bcc9b55efddd"",""dependencies"":[{""name"":""aiohttp"",""from"":""3.8.4"",""to"":""3.8.5""}],""packageManager"":""pip"",""projectPublicId"":""c1c98f6a-57c6-4ecc-a329-3b744cab74bd"",""projectUrl"":""https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-AIOHTTP-5798483""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""priorityScore""],""priorityScoreList"":[658],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Learn about vulnerability in an interactive lesson of Snyk Learn.](https://learn.snyk.io/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13282:3128,remediat,remediationStrategy,3128,https://hail.is,https://github.com/hail-is/hail/pull/13282,1,['remediat'],['remediationStrategy']
Safety,"rect dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJjZmU2NDEwYi1jYjQ3LTQ2YzgtOTYwYy1kOWRlY2UxMjI5ZTIiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImNmZTY0MTBiLWNiNDctNDZjOC05NjBjLWQ5ZGVjZTEyMjllMiJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/b7c31419-ec34-40f1-8bc6-ad8303fb329b?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/b7c31419-ec34-40f1-8bc6-ad8303fb329b?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""cfe6410b-cb47-46c8-960c-d9dece1229e2"",""prPublicId"":""cfe6410b-cb47-46c8-960c-d9dece1229e2"",""dependencies"":[{""name"":""aiohttp"",""from"":""3.8.4"",""to"":""3.8.5""}],""packageManager"":""pip"",""projectPublicId"":""b7c31419-ec34-40f1-8bc6-ad8303fb329b"",""projectUrl"":""https://app.snyk.io/org/danking/project/b7c31419-ec34-40f1-8bc6-ad8303fb329b?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-AIOHTTP-5798483""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""priorityScore""],""priorityScoreList"":[658],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Learn about vulnerability in an interactive lesson of Snyk Learn.](https://learn.snyk.io/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13286:3119,remediat,remediationStrategy,3119,https://hail.is,https://github.com/hail-is/hail/pull/13286,1,['remediat'],['remediationStrategy']
Safety,"rect dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJlMjk5ZmU1Ni0wNGI1LTQ3MzEtYmUzYS03M2ZmYzgxZTZjYjgiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImUyOTlmZTU2LTA0YjUtNDczMS1iZTNhLTczZmZjODFlNmNiOCJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""e299fe56-04b5-4731-be3a-73ffc81e6cb8"",""prPublicId"":""e299fe56-04b5-4731-be3a-73ffc81e6cb8"",""dependencies"":[{""name"":""aiohttp"",""from"":""3.8.4"",""to"":""3.8.5""}],""packageManager"":""pip"",""projectPublicId"":""5ecb4152-94d0-44ff-86c6-21e542bb123d"",""projectUrl"":""https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-AIOHTTP-5798483""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""priorityScore""],""priorityScoreList"":[658],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Learn about vulnerability in an interactive lesson of Snyk Learn.](https://learn.snyk.io/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13283:3120,remediat,remediationStrategy,3120,https://hail.is,https://github.com/hail-is/hail/pull/13283,1,['remediat'],['remediationStrategy']
Safety,"rect dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJmZmEwNjUyZi1hMzc2LTQ0NmQtYWJjNC04NmJhMzUwNmY3MzMiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImZmYTA2NTJmLWEzNzYtNDQ2ZC1hYmM0LTg2YmEzNTA2ZjczMyJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/cbac91bd-aa95-4900-9a06-97404b268d6e?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/cbac91bd-aa95-4900-9a06-97404b268d6e?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""ffa0652f-a376-446d-abc4-86ba3506f733"",""prPublicId"":""ffa0652f-a376-446d-abc4-86ba3506f733"",""dependencies"":[{""name"":""aiohttp"",""from"":""3.8.4"",""to"":""3.8.5""}],""packageManager"":""pip"",""projectPublicId"":""cbac91bd-aa95-4900-9a06-97404b268d6e"",""projectUrl"":""https://app.snyk.io/org/danking/project/cbac91bd-aa95-4900-9a06-97404b268d6e?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-AIOHTTP-5798483""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""priorityScore""],""priorityScoreList"":[658],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Learn about vulnerability in an interactive lesson of Snyk Learn.](https://learn.snyk.io/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13285:3114,remediat,remediationStrategy,3114,https://hail.is,https://github.com/hail-is/hail/pull/13285,1,['remediat'],['remediationStrategy']
Safety,"redirect.dependabot.com/jmoiron/humanize/issues/243"">#243</a>) <a href=""https://github.com/hugovk""><code>@​hugovk</code></a></li>; </ul>; <h2>3.13.0</h2>; <h2>Added</h2>; <ul>; <li>Add da_DK language (<a href=""https://github-redirect.dependabot.com/jmoiron/humanize/issues/238"">#238</a>) <a href=""https://github.com/dejurin""><code>@​dejurin</code></a></li>; <li>Fix and add Russian and Ukrainian words (<a href=""https://github-redirect.dependabot.com/jmoiron/humanize/issues/235"">#235</a>) <a href=""https://github.com/dejurin""><code>@​dejurin</code></a></li>; <li>Add missing strings for Polish translation (<a href=""https://github-redirect.dependabot.com/jmoiron/humanize/issues/182"">#182</a>) <a href=""https://github.com/kpostekk""><code>@​kpostekk</code></a></li>; <li>Add Traditional Chinese (zh-HK) (<a href=""https://github-redirect.dependabot.com/jmoiron/humanize/issues/233"">#233</a>) <a href=""https://github.com/edwardmfho""><code>@​edwardmfho</code></a></li>; </ul>; <h2>Changed</h2>; <ul>; <li>Remove redundant setuptools from install_requires (<a href=""https://github-redirect.dependabot.com/jmoiron/humanize/issues/232"">#232</a>) <a href=""https://github.com/arthurzam""><code>@​arthurzam</code></a></li>; </ul>; <h2>Deprecated</h2>; <ul>; <li>This is the last release to support Python 3.6</li>; <li>Deprecate private functions (<a href=""https://github-redirect.dependabot.com/jmoiron/humanize/issues/234"">#234</a>) <a href=""https://github.com/samueljsb""><code>@​samueljsb</code></a></li>; <li>Reinstate <code>VERSION</code> and deprecate (<a href=""https://github-redirect.dependabot.com/jmoiron/humanize/issues/240"">#240</a>) <a href=""https://github.com/hugovk""><code>@​hugovk</code></a></li>; </ul>; <h2>3.12.0</h2>; <h2>Added</h2>; <ul>; <li>Add support for Python 3.10 (<a href=""https://github-redirect.dependabot.com/jmoiron/humanize/issues/223"">#223</a>) <a href=""https://github.com/hugovk""><code>@​hugovk</code></a></li>; </ul>; <h2>Changed</h2>; <ul>; <li>Use importlib.metadata to ge",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11517:3103,redund,redundant,3103,https://hail.is,https://github.com/hail-is/hail/pull/11517,2,['redund'],['redundant']
Safety,"redirect.dependabot.com/psf/black/issues/3168"">#3168</a>)</li>; <li>When using <code>--skip-magic-trailing-comma</code> or <code>-C</code>, trailing commas are stripped from; subscript expressions with more than 1 element (<a href=""https://github-redirect.dependabot.com/psf/black/issues/3209"">#3209</a>)</li>; <li>Implicitly concatenated strings inside a list, set, or tuple are now wrapped inside; parentheses (<a href=""https://github-redirect.dependabot.com/psf/black/issues/3162"">#3162</a>)</li>; <li>Fix a string merging/split issue when a comment is present in the middle of implicitly; concatenated strings on its own line (<a href=""https://github-redirect.dependabot.com/psf/black/issues/3227"">#3227</a>)</li>; </ul>; <h3><em>Blackd</em></h3>; <ul>; <li><code>blackd</code> now supports enabling the preview style via the <code>X-Preview</code> header (<a href=""https://github-redirect.dependabot.com/psf/black/issues/3217"">#3217</a>)</li>; </ul>; <h3>Configuration</h3>; <ul>; <li>Black now uses the presence of debug f-strings to detect target version (<a href=""https://github-redirect.dependabot.com/psf/black/issues/3215"">#3215</a>)</li>; <li>Fix misdetection of project root and verbose logging of sources in cases involving; <code>--stdin-filename</code> (<a href=""https://github-redirect.dependabot.com/psf/black/issues/3216"">#3216</a>)</li>; <li>Immediate <code>.gitignore</code> files in source directories given on the command line are now; also respected, previously only <code>.gitignore</code> files in the project root and; automatically discovered directories were respected (<a href=""https://github-redirect.dependabot.com/psf/black/issues/3237"">#3237</a>)</li>; </ul>; <h3>Documentation</h3>; <ul>; <li>Recommend using BlackConnect in IntelliJ IDEs (<a href=""https://github-redirect.dependabot.com/psf/black/issues/3150"">#3150</a>)</li>; </ul>; <h3>Integrations</h3>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</s",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12174:7943,detect,detect,7943,https://hail.is,https://github.com/hail-is/hail/pull/12174,1,['detect'],['detect']
Safety,"ree` - show the tree of external dependencies of the root module, highlighting potential incompatibilities in transitive dependencies. `mill ivyDepsTree --withCompile --withRuntime` includes compile-only and runtime-only dependencies. Use `--whatDependsOn` to see an inverted tree showing how a transitive dependency is getting pulled in, e.g. `mill ivyDepsTree --withCompile --withRuntime --whatDependsOn org.slf4j:slf4j-api`; * `mill mill.scalalib.Dependency/showUpdates` - show outdated dependencies (we have a lot!). See [here](https://mill-build.com/mill/Intro_to_Mill.html) and [here](https://mill-build.com/mill/Builtin_Commands.html) for more details. ## IntelliJ setup. To import from scratch:; * delete any `.idea` directories in the hail root, or `hail/` subdirectory (you could try skipping this, but you're on your own); * in the `hail/` subdirectory, you can also delete `.classpath`, `.gradle`, `.project`, `.settings/`, `build/` (we still use this for a few things, but most of it is dead gradle output, and it's safe to delete it all and start clean), `build.gradle`, `gradle/`, `gradlew`, `gradlew.bat`, `pgradle`, `settings.gradle`; * run `mill mill.bsp.BSP/install` to generate the `.bsp` config directory (bsp is the Build Server Protocol); * In IntelliJ, go to File->Open, and choose the hail root directory; * When the project is open, go to File->Project Structure; * in the Project pane, set an sdk (8 or 11), and set the language level to 8; * in the Modules pane, delete the existing root module, click the plus sign -> Import Module, choose the `hail/` subdirectory, and choose ""Import module from external model"" and `BSP`; * you should see a progress bar at the bottom as it imports the project; * when it's done, quit and reopen IntelliJ. There should now be a bsp icon (two bars with two arrows between them) on the right, where the gradle elephant used to be. Just like before, sometimes you'll need to click the ""reload"" icon in there if things get wonky.; * if it s",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14147:3597,safe,safe,3597,https://hail.is,https://github.com/hail-is/hail/pull/14147,1,['safe'],['safe']
Safety,reflection.MethodInvoker.invoke(MethodInvoker.java:237); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:280); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:214); 	at java.lang.Thread.run(Thread.java:748)java.lang.AssertionError: assertion failed; 	at scala.Predef$.assert(Predef.scala:156); 	at is.hail.annotations.Region.loadInt(Region.scala:36); 	at is.hail.expr.types.TBinary$.loadLength(TBinary.scala:62); 	at is.hail.annotations.UnsafeRow$.readBinary(UnsafeRow.scala:128); 	at is.hail.annotations.UnsafeRow$.readString(UnsafeRow.scala:139); 	at is.hail.annotations.UnsafeRow$.readAltAllele(UnsafeRow.scala:152); 	at is.hail.annotations.UnsafeRow$.readArrayAltAllele(UnsafeRow.scala:164); 	at is.hail.annotations.UnsafeRow$.read(UnsafeRow.scala:210); 	at is.hail.annotations.UnsafeRow.get(UnsafeRow.scala:257); 	at is.hail.expr.FilterVariants$$anonfun$10.apply(Relational.scala:503); 	at is.hail.expr.FilterVariants$$anonfun$10.apply(Relational.scala:500); 	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:463); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$9$$anon$5.hasNext(OrderedRVD.scala:658); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$9$$anon$5.hasNext(OrderedRVD.scala:658); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$9$$anon$5.hasNext(OrderedRVD.scala:658); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at is.hail.sparkextras.OrderedRDD$$anonfun$apply$5$$anon$2.hasNext(OrderedRDD.scala:194); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at is.hail.sparkextras.PartitionKeyInfo$.apply(PartitionKeyInfo.scala:30); 	at is.hail,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2743:8297,Unsafe,UnsafeRow,8297,https://hail.is,https://github.com/hail-is/hail/issues/2743,1,['Unsafe'],['UnsafeRow']
Safety,remove KryoSerializable from UnsafeRow and UnsafeIndexedSeq,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3219:29,Unsafe,UnsafeRow,29,https://hail.is,https://github.com/hail-is/hail/pull/3219,2,['Unsafe'],"['UnsafeIndexedSeq', 'UnsafeRow']"
Safety,remove redundant fixmes (obviated by Literal IR),MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4381:7,redund,redundant,7,https://hail.is,https://github.com/hail-is/hail/pull/4381,1,['redund'],['redundant']
Safety,remove unused regions from UnsafeOrdering,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8272:27,Unsafe,UnsafeOrdering,27,https://hail.is,https://github.com/hail-is/hail/pull/8272,1,['Unsafe'],['UnsafeOrdering']
Safety,"renamed fromKeyTable => fromTable.; made generic (single key until we have compound keys in MT). The two FIXMEs will use infrastructure from other, pending PRs. To avoid stacking, I'll rebase one side or the other depending on which goes in first.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2714:164,avoid,avoid,164,https://hail.is,https://github.com/hail-is/hail/pull/2714,1,['avoid'],['avoid']
Safety,"reproduces with this command:. ``` text; hail importvcf src/test/resources/sample.vcf annotatevariants expr -c 'va.filters = ""HELLO""' exportvcf -o /tmp/out.vcf; ```. ``` text; hail: exportvcf: caught exception: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 1.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1.0 (TID 1, localhost): java.lang.ClassCastException: java.lang.String cannot be cast to scala.collection.immutable.Set; at org.broadinstitute.hail.driver.ExportVCF$$anonfun$6.apply(ExportVCF.scala:185); at org.broadinstitute.hail.driver.ExportVCF$$anonfun$6.apply(ExportVCF.scala:185); at scala.Option.map(Option.scala:145); at org.broadinstitute.hail.driver.ExportVCF$.org$broadinstitute$hail$driver$ExportVCF$$appendRow$1(ExportVCF.scala:185); at org.broadinstitute.hail.driver.ExportVCF$$anonfun$run$1$$anonfun$apply$11.apply(ExportVCF.scala:278); at org.broadinstitute.hail.driver.ExportVCF$$anonfun$run$1$$anonfun$apply$11.apply(ExportVCF.scala:276); at scala.collection.Iterator$$anon$11.next(Iterator.scala:328); at scala.collection.Iterator$$anon$11.next(Iterator.scala:328); at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13$$anonfun$apply$6.apply$mcV$sp(PairRDDFunctions.scala:1109); at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13$$anonfun$apply$6.apply(PairRDDFunctions.scala:1108); at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13$$anonfun$apply$6.apply(PairRDDFunctions.scala:1108); at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1206); at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13.apply(PairRDDFunctions.scala:1116); at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13.apply(PairRDDFunctions.scala:1095); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66); at org.apache.spark.scheduler.Task.run(Task.scala:88); at o",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/785:248,abort,aborted,248,https://hail.is,https://github.com/hail-is/hail/issues/785,1,['abort'],['aborted']
Safety,"resolves #14749. Leave the override in Backend as well to avoid duplication. Future enhancements may enable us to construct a ServiceBackend from argv alone, allowing this to be reverted. ## Security Assessment. Delete all except the correct answer:; - This change has no security impact. ### Impact Description; This change restores known good functionality.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14750:58,avoid,avoid,58,https://hail.is,https://github.com/hail-is/hail/pull/14750,1,['avoid'],['avoid']
Safety,"retry in get_userinfo; retry on ClientOSError (client connection error) on timeout; log errno to diagnose future failures. Some of the current errors are ClientOSErrors (ClientConnectionErrors, actually) with strerror ""Connect call failed"" but that doesn't correspond to a standard errno message returned by perror/os.strerror as far as I can tell. So I'm retrying on timeout (good) and logging the errno so we can diagnose future transient failures.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7279:75,timeout,timeout,75,https://hail.is,https://github.com/hail-is/hail/pull/7279,2,['timeout'],['timeout']
Safety,retry on timeout similar to exportvariantssolr,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1214:9,timeout,timeout,9,https://hail.is,https://github.com/hail-is/hail/pull/1214,1,['timeout'],['timeout']
Safety,"rgs_); File ""/opt/conda/default/lib/python3.8/site-packages/hail/table.py"", line 1335, in write; Env.backend().execute(ir.TableWrite(self._tir, ir.TableNativeWriter(output, overwrite, stage_locally, _codec_spec))); File ""/opt/conda/default/lib/python3.8/site-packages/hail/backend/py4j_backend.py"", line 105, in execute; raise e.maybe_user_error(ir) from None; File ""/opt/conda/default/lib/python3.8/site-packages/hail/backend/py4j_backend.py"", line 99, in execute; result_tuple = self._jbackend.executeEncode(jir, stream_codec, timed); File ""/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py"", line 1304, in __call__; File ""/opt/conda/default/lib/python3.8/site-packages/hail/backend/py4j_backend.py"", line 31, in deco; raise fatal_error_from_java_error_triplet(deepest, full, error_id) from None; hail.utils.java.FatalError: ClassFormatError: Too many arguments in method signature in class file __C2866stream. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 3 in stage 8.0 failed 20 times, most recent failure: Lost task 3.19 in stage 8.0 (TID 54368) (leo-test-w-8.australia-southeast1-a.c.ourdna-browser.internal executor 14): java.lang.ClassFormatError: Too many arguments in method signature in class file __C2866stream; 	at java.lang.ClassLoader.defineClass1(Native Method); 	at java.lang.ClassLoader.defineClass(ClassLoader.java:756); 	at java.lang.ClassLoader.defineClass(ClassLoader.java:635); 	at is.hail.asm4s.HailClassLoader.liftedTree1$1(HailClassLoader.scala:10); 	at is.hail.asm4s.HailClassLoader.loadOrDefineClass(HailClassLoader.scala:6); 	at is.hail.asm4s.ClassesBytes.$anonfun$load$1(ClassBuilder.scala:64); 	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36); 	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33); 	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198); 	at is.hail.asm4s.ClassesBytes.load(ClassBuilder.scala:62); 	at is.hail.expr.i",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12532:3126,abort,aborted,3126,https://hail.is,https://github.com/hail-is/hail/issues/12532,1,['abort'],['aborted']
Safety,"richlet-Multinomial distribution](https://en.wikipedia.org/wiki/Dirichlet-multinomial_distribution) with all α_n set to `parts`, which tends towards a uniformly distributed vector. Upon writing this PR, I realize it might be more desirable to set all α_n to 1. Commentary welcome. 3. When we choose the length of a random sequence, we choose it using the [Beta-Binomial Distribution](https://en.wikipedia.org/wiki/Beta-binomial_distribution) with `n` set to the maximum sequence size (usually the Gen's `size`), α set to `3` and β set to `6 * ln(n + 0.01)`. My choice of β is motivated by keeping the mass away from `0` when `n` is small. In particular, I'd like the mean to be greater than or equal to one, so `nα/(α+β) >= 1` so for, say, n=4, `β/α <= 3`. For large values of `n` I want values closer to zero than given by α=3, β=4. I really want commentary on how to choose sequence lengths. Choosing from a Beta-Binomial with a beta weighted by the natural log (shifted by 0.01 to avoid ln(1) = 0) seems very unnatural. Here's α=3, β=6, at n=4 and n=100:. <img width=""752"" alt=""screen shot 2017-06-05 at 2 40 04 pm"" src=""https://cloud.githubusercontent.com/assets/106194/26798031/1c14c0d4-49fd-11e7-9423-0cc46f412145.png"">; <img width=""752"" alt=""screen shot 2017-06-05 at 2 40 18 pm"" src=""https://cloud.githubusercontent.com/assets/106194/26798032/1c16b7d6-49fd-11e7-9a5c-04766ddab9ba.png"">. Note that the mean for n=100 is close to 35, pretty big. Now here's α=3, β=6*ln(n+0.01), at n=4 and n=100:. <img width=""752"" alt=""screen shot 2017-06-05 at 2 40 54 pm"" src=""https://cloud.githubusercontent.com/assets/106194/26798030/1bfc3e06-49fd-11e7-80d9-882e050c5087.png"">; <img width=""752"" alt=""screen shot 2017-06-05 at 2 40 34 pm"" src=""https://cloud.githubusercontent.com/assets/106194/26798033/1c1ad85c-49fd-11e7-8294-b8a5466ade4c.png"">. The n=4 case doesn't change much but the n=100 case biases towards smaller values, which is generally what we want for random sequences (if any algorithm works o",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1902:10960,avoid,avoid,10960,https://hail.is,https://github.com/hail-is/hail/pull/1902,1,['avoid'],['avoid']
Safety,"rk releases</li>; <li><a href=""https://github.com/apache/spark/commit/001d8b0cddcec46a44e7c6e31612dc2baada05d5""><code>001d8b0</code></a> [SPARK-37554][BUILD] Add PyArrow, pandas and plotly to release Docker image d...</li>; <li><a href=""https://github.com/apache/spark/commit/9dd4c07475c82f922c29d67a4db4bb42676c5c07""><code>9dd4c07</code></a> [SPARK-37730][PYTHON][FOLLOWUP] Split comments to comply pycodestyle check</li>; <li><a href=""https://github.com/apache/spark/commit/bc54a3f0c2e08893702c3929bfe7a9d543a08cdb""><code>bc54a3f</code></a> [SPARK-37730][PYTHON] Replace use of MPLPlot._add_legend_handle with MPLPlot....</li>; <li><a href=""https://github.com/apache/spark/commit/c5983c1691f20590abf80b17bdc029b584b89521""><code>c5983c1</code></a> [SPARK-38018][SQL][3.2] Fix ColumnVectorUtils.populate to handle CalendarInte...</li>; <li><a href=""https://github.com/apache/spark/commit/32aff86477ac001b0ee047db08591d89e90c6eb8""><code>32aff86</code></a> [SPARK-39447][SQL][3.2] Avoid AssertionError in AdaptiveSparkPlanExec.doExecu...</li>; <li><a href=""https://github.com/apache/spark/commit/be891ad99083564a7bf7f421e00b2cc4759a679f""><code>be891ad</code></a> [SPARK-39551][SQL][3.2] Add AQE invalid plan check</li>; <li><a href=""https://github.com/apache/spark/commit/1c0bd4c15a28d7c6a2dca846a5b8d0eb1d152aae""><code>1c0bd4c</code></a> [SPARK-39656][SQL][3.2] Fix wrong namespace in DescribeNamespaceExec</li>; <li><a href=""https://github.com/apache/spark/commit/3d084fe3217bea9af4c544f10ead8a2e5b97dad4""><code>3d084fe</code></a> [SPARK-39677][SQL][DOCS][3.2] Fix args formatting of the regexp and like func...</li>; <li>Additional commits viewable in <a href=""https://github.com/apache/spark/compare/v3.1.3...v3.2.2"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pyspark&package-manager=pip&previous-version=3.1.3&new-version=3.2.2)](https://docs.github.com/en/github/managing-",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12452:1442,Avoid,Avoid,1442,https://hail.is,https://github.com/hail-is/hail/pull/12452,1,['Avoid'],['Avoid']
Safety,rmatString(FloatingDecimal.java:2043); at sun.misc.FloatingDecimal.parseDouble(FloatingDecimal.java:110); at java.lang.Double.parseDouble(Double.java:538); at scala.collection.immutable.StringLike$class.toDouble(StringLike.scala:284); at scala.collection.immutable.StringOps.toDouble(StringOps.scala:29); at is.hail.io.vcf.VCFLine.parseDoubleInFormatArray(LoadVCF.scala:371); at is.hail.io.vcf.VCFLine.parseAddFormatArrayDouble(LoadVCF.scala:431); at is.hail.io.vcf.FormatParser.parseAddField(LoadVCF.scala:483); at is.hail.io.vcf.FormatParser.parse(LoadVCF.scala:514); at is.hail.io.vcf.LoadVCF$$anonfun$13.apply(LoadVCF.scala:867); at is.hail.io.vcf.LoadVCF$$anonfun$13.apply(LoadVCF.scala:848); at is.hail.io.vcf.LoadVCF$$anonfun$parseLines$1$$anon$1.hasNext(LoadVCF.scala:717); ... 35 more. Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3361:6514,abort,abortStage,6514,https://hail.is,https://github.com/hail-is/hail/issues/3361,1,['abort'],['abortStage']
Safety,"rt it properly due to <a href=""https://github-redirect.dependabot.com/urllib3/urllib3/issues/2282"">reasons listed in this issue</a>. If you are a user of this module please leave a comment.</li>; <li>Changed <code>HTTPConnection.request_chunked()</code> to not erroneously emit multiple <code>Transfer-Encoding</code> headers in the case that one is already specified.</li>; <li>Fixed typo in deprecation message to recommend <code>Retry.DEFAULT_ALLOWED_METHODS</code>.</li>; </ul>; <p><strong>If you or your organization rely on urllib3 consider supporting us via <a href=""https://github.com/sponsors/urllib3"">GitHub Sponsors</a></strong></p>; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/urllib3/urllib3/blob/main/CHANGES.rst"">urllib3's changelog</a>.</em></p>; <blockquote>; <h2>1.26.8 (2022-01-07)</h2>; <ul>; <li>Added extra message to <code>urllib3.exceptions.ProxyError</code> when urllib3 detects that; a proxy is configured to use HTTPS but the proxy itself appears to only use HTTP.</li>; <li>Added a mention of the size of the connection pool when discarding a connection due to the pool being full.</li>; <li>Added explicit support for Python 3.11.</li>; <li>Deprecated the <code>Retry.MAX_BACKOFF</code> class property in favor of <code>Retry.DEFAULT_MAX_BACKOFF</code>; to better match the rest of the default parameter names. <code>Retry.MAX_BACKOFF</code> is removed in v2.0.</li>; <li>Changed location of the vendored <code>ssl.match_hostname</code> function from <code>urllib3.packages.ssl_match_hostname</code>; to <code>urllib3.util.ssl_match_hostname</code> to ensure Python 3.10+ compatibility after being repackaged; by downstream distributors.</li>; <li>Fixed absolute imports, all imports are now relative.</li>; </ul>; <h1>1.26.7 (2021-09-22)</h1>; <ul>; <li>Fixed a bug with HTTPS hostname verification involving IP addresses and lack; of SNI. (Issue <a href=""https://github-redirect.dependabot.com/url",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11532:3524,detect,detects,3524,https://hail.is,https://github.com/hail-is/hail/pull/11532,1,['detect'],['detects']
Safety,"ry>; <ul>; <li><a href=""https://github.com/aio-libs/async-timeout/commit/5128f7f4ff73b165579006a8336978efaeeca07a""><code>5128f7f</code></a> Fix CHANGES</li>; <li><a href=""https://github.com/aio-libs/async-timeout/commit/18e718a56f9def7dc40bb9ce3a2962a8fb0c883c""><code>18e718a</code></a> Bump to 4.0.2</li>; <li><a href=""https://github.com/aio-libs/async-timeout/commit/48d1c4ce923b1da75976d7e2a6ca9234b3092c16""><code>48d1c4c</code></a> Setup towncrier</li>; <li><a href=""https://github.com/aio-libs/async-timeout/commit/2ede7d73e55f8d1a2279d78861af0009d96219fb""><code>2ede7d7</code></a> Fix annotations on <code>__exit__</code> and <code>__aexit__</code> (<a href=""https://github-redirect.dependabot.com/aio-libs/async-timeout/issues/274"">#274</a>)</li>; <li><a href=""https://github.com/aio-libs/async-timeout/commit/8685c60dc0e82ee246fbe3d1aa272d1dfe57c24c""><code>8685c60</code></a> Bump mypy from 0.910 to 0.920 (<a href=""https://github-redirect.dependabot.com/aio-libs/async-timeout/issues/273"">#273</a>)</li>; <li><a href=""https://github.com/aio-libs/async-timeout/commit/f0a0914345b224448220aeb00d71e6a04a5d24bd""><code>f0a0914</code></a> Bump twine from 3.7.0 to 3.7.1 (<a href=""https://github-redirect.dependabot.com/aio-libs/async-timeout/issues/272"">#272</a>)</li>; <li><a href=""https://github.com/aio-libs/async-timeout/commit/e5c813173b8811b30f4a30eeba56fa8808ab15bb""><code>e5c8131</code></a> [pre-commit.ci] pre-commit autoupdate (<a href=""https://github-redirect.dependabot.com/aio-libs/async-timeout/issues/271"">#271</a>)</li>; <li><a href=""https://github.com/aio-libs/async-timeout/commit/c7e10db3d0965422122bef263fb36f6fd7572330""><code>c7e10db</code></a> Fix linter configs</li>; <li><a href=""https://github.com/aio-libs/async-timeout/commit/6af8bf421a799208b27d57c6bf69de0d998fedec""><code>6af8bf4</code></a> Bump pre-commit from 2.15 to 2.16.0 (<a href=""https://github-redirect.dependabot.com/aio-libs/async-timeout/issues/269"">#269</a>)</li>; <li><a href=""https://github.com/aio-libs/",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11465:4945,timeout,timeout,4945,https://hail.is,https://github.com/hail-is/hail/pull/11465,1,['timeout'],['timeout']
Safety,"s-dev/pandas/issues/45924"">#45924</a>)</li>; <li><a href=""https://github.com/pandas-dev/pandas/commit/f035290718ef8e0683ecb16a20639ed5e57e10eb""><code>f035290</code></a> Backport PR <a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/45853"">#45853</a>: Fixing documentation format in read_csv (<a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/45922"">#45922</a>)</li>; <li><a href=""https://github.com/pandas-dev/pandas/commit/ebf024eb886a8e81922250a386c8d1c8bfa13b2a""><code>ebf024e</code></a> Backport PR <a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/45923"">#45923</a>: DOC: add Python 3.10 to doc (<a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/45927"">#45927</a>)</li>; <li><a href=""https://github.com/pandas-dev/pandas/commit/deea0562e1ebabc874011575293103d0ba35d0f0""><code>deea056</code></a> Backport PR <a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/45910"">#45910</a>: TST/CI: Set hypothesis deadline to None to avoid flaky fa...</li>; <li><a href=""https://github.com/pandas-dev/pandas/commit/58aebf1940b56b77279174f5413b76a5aaba465c""><code>58aebf1</code></a> Backport PR <a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/45909"">#45909</a>: BUG: DateOffset(n) not defaulting to days (<a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/45918"">#45918</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/pandas-dev/pandas/compare/v1.3.0...v1.4.1"">compare view</a></li>; </ul>; </details>; <br />. Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11521:3965,avoid,avoid,3965,https://hail.is,https://github.com/hail-is/hail/pull/11521,1,['avoid'],['avoid']
Safety,"s-dev/pandas/issues/45924"">#45924</a>)</li>; <li><a href=""https://github.com/pandas-dev/pandas/commit/f035290718ef8e0683ecb16a20639ed5e57e10eb""><code>f035290</code></a> Backport PR <a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/45853"">#45853</a>: Fixing documentation format in read_csv (<a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/45922"">#45922</a>)</li>; <li><a href=""https://github.com/pandas-dev/pandas/commit/ebf024eb886a8e81922250a386c8d1c8bfa13b2a""><code>ebf024e</code></a> Backport PR <a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/45923"">#45923</a>: DOC: add Python 3.10 to doc (<a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/45927"">#45927</a>)</li>; <li><a href=""https://github.com/pandas-dev/pandas/commit/deea0562e1ebabc874011575293103d0ba35d0f0""><code>deea056</code></a> Backport PR <a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/45910"">#45910</a>: TST/CI: Set hypothesis deadline to None to avoid flaky fa...</li>; <li><a href=""https://github.com/pandas-dev/pandas/commit/58aebf1940b56b77279174f5413b76a5aaba465c""><code>58aebf1</code></a> Backport PR <a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/45909"">#45909</a>: BUG: DateOffset(n) not defaulting to days (<a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/45918"">#45918</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/pandas-dev/pandas/compare/v1.3.0...v1.4.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pandas&package-manager=pip&previous-version=1.3.0&new-version=1.4.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11539:5483,avoid,avoid,5483,https://hail.is,https://github.com/hail-is/hail/pull/11539,1,['avoid'],['avoid']
Safety,"s-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""648a0aea-922c-46c9-b851-66c7e282d2e5"",""prPublicId"":""648a0aea-922c-46c9-b851-66c7e282d2e5"",""dependencies"":[{""name"":""certifi"",""from"":""2021.10.8"",""to"":""2023.7.22""},{""name"":""cryptography"",""from"":""3.3.2"",""to"":""41.0.6""},{""name"":""requests"",""from"":""2.27.1"",""to"":""2.31.0""}],""packageManager"":""pip"",""projectPublicId"":""5ecb4152-94d0-44ff-86c6-21e542bb123d"",""projectUrl"":""https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-CERTIFI-3164749"",""SNYK-PYTHON-CERTIFI-5805047"",""SNYK-PYTHON-CRYPTOGRAPHY-3172287"",""SNYK-PYTHON-CRYPTOGRAPHY-3314966"",""SNYK-PYTHON-CRYPTOGRAPHY-3315324"",""SNYK-PYTHON-CRYPTOGRAPHY-3315328"",""SNYK-PYTHON-CRYPTOGRAPHY-3315331"",""SNYK-PYTHON-CRYPTOGRAPHY-3315452"",""SNYK-PYTHON-CRYPTOGRAPHY-3315972"",""SNYK-PYTHON-CRYPTOGRAPHY-3315975"",""SNYK-PYTHON-CRYPTOGRAPHY-3316038"",""SNYK-PYTHON-CRYPTOGRAPHY-3316211"",""SNYK-PYTHON-CRYPTOGRAPHY-5663682"",""SNYK-PYTHON-CRYPTOGRAPHY-5777683"",""SNYK-PYTHON-CRYPTOGRAPHY-5813745"",""SNYK-PYTHON-CRYPTOGRAPHY-5813746"",""SNYK-PYTHON-CRYPTOGRAPHY-5813750"",""SNYK-PYTHON-CRYPTOGRAPHY-5914629"",""SNYK-PYTHON-CRYPTOGRAPHY-6036192"",""SNYK-PYTHON-CRYPTOGRAPHY-6092044"",""SNYK-PYTHON-REQUESTS-5595532""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""pr-warning-shown""],""priorityScoreList"":[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Use After Free](https://learn.snyk.io/lesson/use-after-free/?loc&#x3D;fix-pr); 🦉 [Access of Resource Using Incompatible Type (&#x27;Type Confusion&#x27;)](https://learn.snyk.io/lesson/type-confusion/?loc&#x3D;fix-pr); 🦉 [Denial of Service (DoS)](https://learn.snyk.io/lesson/redos/?loc&#x3D;fix-pr); 🦉 [More lessons are available in Snyk Learn](https://lear",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14196:10311,remediat,remediationStrategy,10311,https://hail.is,https://github.com/hail-is/hail/pull/14196,1,['remediat'],['remediationStrategy']
Safety,"s. If you have an Apple M1 or Apple M2 and `/usr/libexec/java_home -V` does not include `(arm64)`, you must switch to an arm64 version of the JVM. Fixes (hail#14000). Fixes #14000. Hail has never supported its native functionality on Mac OS X Apple M1 chips. In particular, we only built x86_64 compatible dylibs. M1 chips will try to simulate a very basic x86_64 ISA using Rosetta 2 but our x86_64 dylibs expect the ISA of at least sandybridge, which includes some SIMD instructions not supported by Rosetta 2. This PR bifurcates our native build into x86_64 and arm64 targets which live in build/x86_64 and build/arm64, respectively. In Linux, this moves where the object files live, but should otherwise have no effect. The test and benchmark targets use the ""native"" build which always points at the x86_64 object files. The shared object targets, LIBBOOT & LIBHAIL, explicitly depend on x86_64 because that is the only linux architecture we support. In OS X, we only test and benchmark the ""native"" build, which is detected using `uname -m`. For the shared objects (the dylibs) we have four new files: libboot and libbhail for x86_64 and for arm64. Each pair files is placed in `darwin/x86_64/` and `darwin/arm64/`, respectively. Those dylibs are never meant to escape the src/main/c world. The LIBBOOT and LIBHAIL targets (which are invoked by hail/Makefile) combine the two architecture-specific dylibs into a ""universal"" dylib. You can verify this by running `file` on the dylibs. Here I run them on the new ""prebuilt"" files which are in this PR:. ```; (base) dking@wm28c-761 hail % file hail/prebuilt/lib/darwin/libboot.dylib; hail/prebuilt/lib/darwin/libboot.dylib: Mach-O universal binary with 2 architectures: [x86_64:Mach-O 64-bit dynamically linked shared library x86_64] [arm64:Mach-O 64-bit dynamically linked shared library arm64]; hail/prebuilt/lib/darwin/libboot.dylib (for architecture x86_64):	Mach-O 64-bit dynamically linked shared library x86_64; hail/prebuilt/lib/darwin/libb",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14006:1223,detect,detected,1223,https://hail.is,https://github.com/hail-is/hail/pull/14006,1,['detect'],['detected']
Safety,"s/339"">#339</a>)</li>; <li>Infer default resource in logger (<a href=""https://github-redirect.dependabot.com/googleapis/python-logging/issues/315"">#315</a>)</li>; <li>support json logs (<a href=""https://github-redirect.dependabot.com/googleapis/python-logging/issues/316"">#316</a>)</li>; <li>deprecate AppEngineHandler and ContainerEngineHandler (<a href=""https://github-redirect.dependabot.com/googleapis/python-logging/issues/310"">#310</a>)</li>; </ul>; <h3>Features</h3>; <ul>; <li>add api key support (<a href=""https://github-redirect.dependabot.com/googleapis/python-logging/issues/472"">#472</a>) (<a href=""https://github.com/googleapis/python-logging/commit/81ca8c616acb988be1fbecfc2a0b1a5b39280149"">81ca8c6</a>)</li>; <li>add json_fields extras argument for adding to jsonPayload (<a href=""https://github-redirect.dependabot.com/googleapis/python-logging/issues/447"">#447</a>) (<a href=""https://github.com/googleapis/python-logging/commit/a760e02371a55d6262e42de9e0222fffa2c7192b"">a760e02</a>)</li>; <li>avoid importing grpc when explicitly disabled (<a href=""https://github-redirect.dependabot.com/googleapis/python-logging/issues/416"">#416</a>) (<a href=""https://github.com/googleapis/python-logging/commit/818213e143d6a1941211a48e0b23069a426ac300"">818213e</a>)</li>; <li>Infer default resource in logger (<a href=""https://github-redirect.dependabot.com/googleapis/python-logging/issues/315"">#315</a>) (<a href=""https://github.com/googleapis/python-logging/commit/c63250399fcd6e1317d341e98fab11095c443e5e"">c632503</a>)</li>; <li>make logging API more friendly to use (<a href=""https://github-redirect.dependabot.com/googleapis/python-logging/issues/422"">#422</a>) (<a href=""https://github.com/googleapis/python-logging/commit/83d9ca8521fe7c470bb6755a48a97496515d7abc"">83d9ca8</a>)</li>; <li>support json logs (<a href=""https://github-redirect.dependabot.com/googleapis/python-logging/issues/316"">#316</a>) (<a href=""https://github.com/googleapis/python-logging/commit/5267152574b2ee96eb6f5c5",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11574:1873,avoid,avoid,1873,https://hail.is,https://github.com/hail-is/hail/pull/11574,2,['avoid'],['avoid']
Safety,"s/async-timeout/issues/274) &lt;https://github.com/aio-libs/async-timeout/issues/274&gt;</code></em></li>; </ul>; <h1>4.0.1 (2121-11-10)</h1>; <ul>; <li>; <p>Fix regression:</p>; <ol>; <li>; <p>Don't raise TimeoutError from timeout object that doesn't enter into async context; manager</p>; </li>; <li>; <p>Use call_soon() for raising TimeoutError if deadline is reached on entering into; async context manager</p>; </li>; </ol>; <p>(<a href=""https://github-redirect.dependabot.com/aio-libs/async-timeout/issues/258"">#258</a>)</p>; </li>; <li>; <p>Make <code>Timeout</code> class available in <code>__all__</code>.</p>; </li>; </ul>; <h1>4.0.0 (2021-11-01)</h1>; <ul>; <li>; <p>Implemented <code>timeout_at(deadline)</code> (<a href=""https://github-redirect.dependabot.com/aio-libs/async-timeout/issues/117"">#117</a>)</p>; </li>; <li>; <p>Supported <code>timeout.deadline</code> and <code>timeout.expired</code> properties.</p>; </li>; <li>; <p>Dropped <code>timeout.remaining</code> property: it can be calculated as; <code>timeout.deadline - loop.time()</code></p>; </li>; <li>; <p>Dropped <code>timeout.timeout</code> property that returns a relative timeout based on the; timeout object creation time; the absolute <code>timeout.deadline</code> should be used; instead.</p>; </li>; <li>; <p>Added the deadline modification methods: <code>timeout.reject()</code>,; <code>timeout.shift(delay)</code>, <code>timeout.update(deadline)</code>.</p>; </li>; <li>; <p>Deprecated synchronous context manager usage</p>; </li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/aio-libs/async-timeout/commit/5128f7f4ff73b165579006a8336978efaeeca07a""><code>5128f7f</code></a> Fix CHANGES</li>; <li><a href=""https://github.com/aio-libs/async-timeout/commit/18e718a56f9def7dc40bb9ce3a2962a8fb0c883c""><code>18e718a</code></a> Bump to 4.0.2</li>; <li><a href=""https://github.com/aio-libs/async-timeout/commit/48d1c4ce923b1da75976d7e2a6ca9234b3092c16""><",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11465:3404,timeout,timeout,3404,https://hail.is,https://github.com/hail-is/hail/pull/11465,1,['timeout'],['timeout']
Safety,"s://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""12691d21-0395-41b3-80d2-f212830f66ea"",""prPublicId"":""12691d21-0395-41b3-80d2-f212830f66ea"",""dependencies"":[{""name"":""ipython"",""from"":""7.34.0"",""to"":""8.10.0""},{""name"":""jupyter-server"",""from"":""1.24.0"",""to"":""2.7.2""},{""name"":""setuptools"",""from"":""39.0.1"",""to"":""65.5.1""},{""name"":""tornado"",""from"":""6.2"",""to"":""6.3.3""},{""name"":""urllib3"",""from"":""1.26.17"",""to"":""1.26.18""}],""packageManager"":""pip"",""projectPublicId"":""20159ae6-a5aa-42fa-845a-c89f5bcbf999"",""projectUrl"":""https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-IPYTHON-3318382"",""SNYK-PYTHON-JUPYTERSERVER-5862881"",""SNYK-PYTHON-JUPYTERSERVER-5862882"",""SNYK-PYTHON-SETUPTOOLS-3180412"",""SNYK-PYTHON-TORNADO-5537286"",""SNYK-PYTHON-TORNADO-5840803"",""SNYK-PYTHON-URLLIB3-6002459""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""pr-warning-shown"",""priorityScore""],""priorityScoreList"":[531,null,null,509,384,494,496],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Remote Code Execution (RCE)](https://learn.snyk.io/lesson/improper-input-validation/?loc&#x3D;fix-pr); 🦉 [Access Control Bypass](https://learn.snyk.io/lesson/broken-access-control/?loc&#x3D;fix-pr); 🦉 [Open Redirect](https://learn.snyk.io/lesson/open-redirect/?loc&#x3D;fix-pr); 🦉 [More lessons are available in Snyk Learn](https://learn.snyk.io/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13873:5929,remediat,remediationStrategy,5929,https://hail.is,https://github.com/hail-is/hail/pull/13873,1,['remediat'],['remediationStrategy']
Safety,"s=resources, always_run=True); b.submit(); b.cancel(); > status = j.wait(). io/test/test_batch.py:1487: ; _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ; usr/local/lib/python3.9/dist-packages/hailtop/batch_client/client.py:84: in wait; return async_to_blocking(self._async_job.wait()); usr/local/lib/python3.9/dist-packages/hailtop/utils/utils.py:156: in async_to_blocking; return loop.run_until_complete(task); usr/lib/python3.9/asyncio/base_events.py:634: in run_until_complete; self.run_forever(); usr/lib/python3.9/asyncio/base_events.py:601: in run_forever; self._run_once(); usr/lib/python3.9/asyncio/base_events.py:1869: in _run_once; event_list = self._selector.select(timeout); _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . self = <selectors.EpollSelector object at 0x7fae890f2d30>; timeout = 15.402000000000001. def select(self, timeout=None):; if timeout is None:; timeout = -1; elif timeout <= 0:; timeout = 0; else:; # epoll_wait() has a resolution of 1 millisecond, round away; # from zero to wait *at least* timeout seconds.; timeout = math.ceil(timeout * 1e3) * 1e-3; ; # epoll_wait() expects `maxevents` to be greater than zero;; # we want to make sure that `select()` can be called when no; # FD is registered.; max_ev = max(len(self._fd_to_key), 1); ; ready = []; try:; > fd_event_list = self._selector.poll(timeout, max_ev); E Failed: Timeout >360.0s. usr/lib/python3.9/selectors.py:469: Failed; ------------------------------ Captured log setup ------------------------------; 2023-09-06T21:45:24 INFO test.conftest conftest.py:14:log_before_after starting test; 2023-09-06T21:45:24 INFO hailtop.aiocloud.aioazure.credentials credentials.py:99:default_credentials using credentials file /test-gsa-key/key.json; ------------------------------ Captured log call -------------------------------; 2023-09-06T21:45:25 INFO azure.identity.aio._internal.get_token_mixin get_token_mixin.py:93:get_token ClientSecretCr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13582:3091,timeout,timeout,3091,https://hail.is,https://github.com/hail-is/hail/issues/13582,6,['timeout'],['timeout']
Safety,"s`: this parameter now defaults to `True` and includes the; response body text in the error message. Both; Both parameters may be overridden on a per-request basis. - `httpx.ResponseManager` and `httpx.ClientSession` work together to enable; `retry_transient` and `raise_for_status`. Aiohttp has this unusual structure where; all the request methods are synchronous but they return an object that is both; awaitable and an async context manager. I mirror their structure exactly. The; `httpx.ResponseManager` is both awaitable and an async context manager. Its; `response_coroutine` field is a coroutine that includes the retry and; raise-for-status logic. - The `HailResolver` overrides domain name resolution to first consult the Hail; `address` service. `address` is effectively a domain name server. It watches; kubernetes services and publishes the pod IPs. It supports two name styles:; `service` and `service.namespace`. The former uses the deploy config to; determine in which namespace to find the given service. Currently, the; client-side library only looks up IPs for `shuffler` and `address`. - `BlockingClientSession` and `BlockingContextManager` wrap the; aforementioned `httpx` classes. `BlockingClientResponse` wraps an; `aiohttp.ClientResponse`. ---. Examples of correct usage:. A blocking HTTPS request:. ```python3; with httpx.blocking_client_session() as session:; with session.post(url, json=config, headers=headers) as resp:; assert resp.status == 200; print(resp.text()); ```. An asynchronous HTTPS request to auth:; ```python3; async with httpx.client_session() as session:; async with session.get(; deploy_config.url('auth', '/api/v1alpha/userinfo'),; headers=headers) as resp:; assert resp.status == 200; print(await resp.json()); ```. A blocking HTTPS session with a large default timeout:. ```python3; httpx.blocking_client_session(; headers=service_auth_headers(deploy_config, 'query'),; timeout=aiohttp.ClientTimeout(total=600)); ```. cc: @catoverdrive @Dania-Abuhijleh",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9554:3254,timeout,timeout,3254,https://hail.is,https://github.com/hail-is/hail/pull/9554,2,['timeout'],['timeout']
Safety,scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at org.apache.spark.sql.execution.datasources.DefaultWriterContainer$$anonfun$writeRows$1.apply$mcV$sp(WriterContainer.scala:253); 	at org.apache.spark.sql.execution.datasources.DefaultWriterContainer$$anonfun$writeRows$1.apply(WriterContainer.scala:252); 	at org.apache.spark.sql.execution.datasources.DefaultWriterContainer$$anonfun$writeRows$1.apply(WriterContainer.scala:252); 	at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1348); 	at org.apache.spark.sql.execution.datasources.DefaultWriterContainer.writeRows(WriterContainer.scala:258); 	... 8 more. Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGSche,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1822:5865,abort,abortStage,5865,https://hail.is,https://github.com/hail-is/hail/issues/1822,1,['abort'],['abortStage']
Safety,scala:73); 	at is.hail.io.ElasticsearchConnector$.export(ElasticsearchConnector.scala:33); 	at is.hail.keytable.KeyTable.exportElasticsearch(KeyTable.scala:751); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:280); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:214); 	at java.lang.Thread.run(Thread.java:748)org.elasticsearch.hadoop.EsHadoopIllegalArgumentException: Cannot detect ES version - typically this happens if the network/Elasticsearch cluster is not accessible or when targeting a WAN/Cloud instance without the proper setting 'es.nodes.wan.only'; 	at org.elasticsearch.hadoop.rest.InitializationUtils.discoverEsVersion(InitializationUtils.java:247); 	at org.elasticsearch.hadoop.rest.RestService.createWriter(RestService.java:545); 	at org.elasticsearch.spark.rdd.EsRDDWriter.write(EsRDDWriter.scala:58); 	at org.elasticsearch.spark.rdd.EsSpark$$anonfun$doSaveToEs$1.apply(EsSpark.scala:102); 	at org.elasticsearch.spark.rdd.EsSpark$$anonfun$doSaveToEs$1.apply(EsSpark.scala:102); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); 	at org.apache.spark.scheduler.Task.run(Task.scala:86); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748)org.elasticsearch.hadoop.EsHado,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4138:5801,detect,detect,5801,https://hail.is,https://github.com/hail-is/hail/issues/4138,1,['detect'],['detect']
Safety,"se.; --> 287 raise RemoteDisconnected(""Remote end closed connection without""; 288 "" response""); 289 try:. RemoteDisconnected: Remote end closed connection without response. During handling of the above exception, another exception occurred:. ProtocolError Traceback (most recent call last); File /opt/conda/lib/python3.10/site-packages/requests/adapters.py:487, in HTTPAdapter.send(self, request, stream, timeout, verify, cert, proxies); 486 try:; --> 487 resp = conn.urlopen(; 488 method=request.method,; 489 url=url,; 490 body=request.body,; 491 headers=request.headers,; 492 redirect=False,; 493 assert_same_host=False,; 494 preload_content=False,; 495 decode_content=False,; 496 retries=self.max_retries,; 497 timeout=timeout,; 498 chunked=chunked,; 499 ); 501 except (ProtocolError, OSError) as err:. File /opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py:787, in HTTPConnectionPool.urlopen(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw); 785 e = ProtocolError(""Connection aborted."", e); --> 787 retries = retries.increment(; 788 method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]; 789 ); 790 retries.sleep(). File /opt/conda/lib/python3.10/site-packages/urllib3/util/retry.py:550, in Retry.increment(self, method, url, response, error, _pool, _stacktrace); 549 if read is False or not self._is_method_retryable(method):; --> 550 raise six.reraise(type(error), error, _stacktrace); 551 elif read is not None:. File /opt/conda/lib/python3.10/site-packages/urllib3/packages/six.py:769, in reraise(tp, value, tb); 768 if value.__traceback__ is not tb:; --> 769 raise value.with_traceback(tb); 770 raise value. File /opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py:703, in HTTPConnectionPool.urlopen(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw); 702 # Make the r",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13960:6911,timeout,timeout,6911,https://hail.is,https://github.com/hail-is/hail/issues/13960,2,"['abort', 'timeout']","['aborted', 'timeout']"
Safety,"sing TimeoutError if deadline is reached on entering into; async context manager</p>; </li>; </ol>; <p>(<a href=""https://github-redirect.dependabot.com/aio-libs/async-timeout/issues/258"">#258</a>)</p>; </li>; <li>; <p>Make <code>Timeout</code> class available in <code>__all__</code>.</p>; </li>; </ul>; <h2>async-timeout 4.0.0</h2>; <h1>Changes</h1>; <ul>; <li>; <p>Implemented <code>timeout_at(deadline)</code> (<a href=""https://github-redirect.dependabot.com/aio-libs/async-timeout/issues/117"">#117</a>)</p>; </li>; <li>; <p>Supported <code>timeout.deadline</code> and <code>timeout.expired</code> properties.</p>; </li>; <li>; <p>Drooped <code>timeout.remaining</code> property: it can be calculated as; <code>timeout.deadline - loop.time()</code></p>; </li>; <li>; <p>Dropped <code>timeout.timeout</code> property that returns a relative timeout based on the; timeout object creation time; the absolute <code>timeout.deadline</code> should be used; instead.</p>; </li>; <li>; <p>Added the deadline modification methods: <code>timeout.reject()</code>,; <code>timeout.shift(delay)</code>, <code>timeout.update(deadline)</code>.</p>; </li>; <li>; <p>Deprecated synchronous context manager usage</p>; </li>; </ul>; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/aio-libs/async-timeout/blob/master/CHANGES.rst"">async-timeout's changelog</a>.</em></p>; <blockquote>; <h1>4.0.2 (2021-12-20)</h1>; <h2>Misc</h2>; <ul>; <li><code>[#259](https://github.com/aio-libs/async-timeout/issues/259) &lt;https://github.com/aio-libs/async-timeout/issues/259&gt;</code><em>, <code>[#274](https://github.com/aio-libs/async-timeout/issues/274) &lt;https://github.com/aio-libs/async-timeout/issues/274&gt;</code></em></li>; </ul>; <h1>4.0.1 (2121-11-10)</h1>; <ul>; <li>; <p>Fix regression:</p>; <ol>; <li>; <p>Don't raise TimeoutError from timeout object that doesn't enter into async context; manager</p>; </li>; <li>; <p>Use call_soon() for raisin",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11465:1742,timeout,timeout,1742,https://hail.is,https://github.com/hail-is/hail/pull/11465,1,['timeout'],['timeout']
Safety,"skopeo avoids downloading images that are already up-to-date, so it; is often a lot faster.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11190:7,avoid,avoids,7,https://hail.is,https://github.com/hail-is/hail/pull/11190,1,['avoid'],['avoids']
Safety,"slack_utils.py"", line 97, in try_slack; File ""/tmp/88fe16cd-42a9-4d26-ac71-5e6676ff3392/pyscripts_F47nn5.zip/gnomad_hail/slack_utils.py"", line 77, in try_slack; File ""/tmp/88fe16cd-42a9-4d26-ac71-5e6676ff3392/generate_qc_annotations.py"", line 203, in main; vds.write(annotations_vds_path(data_type, 'truth_data'), args.overwrite); File ""<decorator-gen-528>"", line 2, in write; File ""/tmp/88fe16cd-42a9-4d26-ac71-5e6676ff3392/hail-devel-6d6d3d2d7992.zip/hail/typecheck/check.py"", line 479, in _typecheck; File ""/tmp/88fe16cd-42a9-4d26-ac71-5e6676ff3392/hail-devel-6d6d3d2d7992.zip/hail/matrixtable.py"", line 1807, in write; File ""/usr/lib/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py"", line 1133, in __call__; File ""/tmp/88fe16cd-42a9-4d26-ac71-5e6676ff3392/hail-devel-6d6d3d2d7992.zip/hail/utils/java.py"", line 238, in deco; hail.utils.java.FatalError: HailException: found non-left aligned variant: 18:76051965:C:G. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 56 in stage 3.0 failed 20 times, most recent failure: Lost task 56.19 in stage 3.0 (TID 685, exomes2-sw-8mf1.c.broad-mpg-gnomad.internal, executor 55): is.hail.utils.HailException: found non-left aligned variant: 18:76051965:C:G; 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:6); 	at is.hail.utils.package$.fatal(package.scala:26); 	at is.hail.methods.SplitMultiPartitionContext.splitRow(SplitMulti.scala:98); 	at is.hail.methods.SplitMulti$$anonfun$split$1$$anonfun$apply$1.apply(SplitMulti.scala:226); 	at is.hail.methods.SplitMulti$$anonfun$split$1$$anonfun$apply$1.apply(SplitMulti.scala:225); 	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$6$$anon$5.hasNext(OrderedRVD.scala:733); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$6$$anon$5.hasNext(OrderedRVD.scala:",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3040:1345,abort,aborted,1345,https://hail.is,https://github.com/hail-is/hail/issues/3040,1,['abort'],['aborted']
Safety,spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:403); 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:409); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1889); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1876); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1876); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2110); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2059); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2048); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:737); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2061); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2082); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8545:9808,abort,abortStage,9808,https://hail.is,https://github.com/hail-is/hail/issues/8545,1,['abort'],['abortStage']
Safety,spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408); 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1892); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1880); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1879); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1879); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:927); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:927); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:927); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2113); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2062); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2051); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:738); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2061); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2082); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8469:82635,abort,abortStage,82635,https://hail.is,https://github.com/hail-is/hail/issues/8469,1,['abort'],['abortStage']
Safety,"st):; File ""/usr/local/lib/python3.7/site-packages/batch/worker/worker.py"", line 359, in ensure_image_is_pulled; docker.images.get, self.image); File ""/usr/local/lib/python3.7/site-packages/batch/worker/worker.py"", line 111, in wrapper; return await asyncio.wait_for(f(*args, **kwargs), timeout); File ""/usr/local/lib/python3.7/asyncio/tasks.py"", line 442, in wait_for; return fut.result(); File ""/usr/local/lib/python3.7/asyncio/futures.py"", line 181, in result; raise self._exception; File ""/usr/local/lib/python3.7/asyncio/tasks.py"", line 249, in __step; result = coro.send(None); File ""/usr/local/lib/python3.7/site-packages/aiodocker/images.py"", line 46, in get; return await self.inspect(name); File ""/usr/local/lib/python3.7/site-packages/aiodocker/images.py"", line 36, in inspect; response = await self.docker._query_json(""images/{name}/json"".format(name=name)); File ""/usr/local/lib/python3.7/site-packages/aiodocker/docker.py"", line 223, in _query_json; path, method, params=params, data=data, headers=headers, timeout=timeout; File ""/usr/local/lib/python3.7/site-packages/aiodocker/docker.py"", line 291, in __aenter__; resp = await self._coro; File ""/usr/local/lib/python3.7/site-packages/aiodocker/docker.py"", line 206, in _do_query; raise DockerError(response.status, json.loads(what.decode(""utf8""))); aiodocker.exceptions.DockerError: DockerError(404, 'no such image: gcr.io/hail-vdc/query:tfkm2kev7zcf: No such image: gcr.io/hail-vdc/query:tfkm2kev7zcf'). During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/usr/local/lib/python3.7/site-packages/batch/worker/worker.py"", line 372, in run; await self.ensure_image_is_pulled(); File ""/usr/local/lib/python3.7/site-packages/batch/worker/worker.py"", line 363, in ensure_image_is_pulled; docker.images.pull, self.image); File ""/usr/local/lib/python3.7/site-packages/batch/worker/worker.py"", line 111, in wrapper; return await asyncio.wait_for(f(*args, **kwargs), timeout); File ""/",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9902:2381,timeout,timeout,2381,https://hail.is,https://github.com/hail-is/hail/pull/9902,2,['timeout'],['timeout']
Safety,"st.collect</code> module - import from <code>pytest</code> directly.</li>; </ul>; <p>For more information consult; <a href=""https://docs.pytest.org/en/latest/deprecations.html"">Deprecations and Removals</a> in the docs.</p>; </li>; <li>; <p><a href=""https://github-redirect.dependabot.com/pytest-dev/pytest/issues/9437"">#9437</a>: Dropped support for Python 3.6, which reached <a href=""https://devguide.python.org/#status-of-python-branches"">end-of-life</a> at 2021-12-23.</p>; </li>; </ul>; <h2>Improvements</h2>; <ul>; <li>; <p><a href=""https://github-redirect.dependabot.com/pytest-dev/pytest/issues/5192"">#5192</a>: Fixed test output for some data types where <code>-v</code> would show less information.</p>; <p>Also, when showing diffs for sequences, <code>-q</code> would produce full diffs instead of the expected diff.</p>; </li>; <li>; <p><a href=""https://github-redirect.dependabot.com/pytest-dev/pytest/issues/9362"">#9362</a>: pytest now avoids specialized assert formatting when it is detected that the default <code>__eq__</code> is overridden in <code>attrs</code> or <code>dataclasses</code>.</p>; </li>; <li>; <p><a href=""https://github-redirect.dependabot.com/pytest-dev/pytest/issues/9536"">#9536</a>: When <code>-vv</code> is given on command line, show skipping and xfail reasons in full instead of truncating them to fit the terminal width.</p>; </li>; <li>; <p><a href=""https://github-redirect.dependabot.com/pytest-dev/pytest/issues/9644"">#9644</a>: More information about the location of resources that led Python to raise <code>ResourceWarning</code>{.interpreted-text role=&quot;class&quot;} can now; be obtained by enabling <code>tracemalloc</code>{.interpreted-text role=&quot;mod&quot;}.</p>; <p>See <code>resource-warnings</code>{.interpreted-text role=&quot;ref&quot;} for more information.</p>; </li>; <li>; <p><a href=""https://github-redirect.dependabot.com/pytest-dev/pytest/issues/9678"">#9678</a>: More types are now accepted in the <code>ids</code> argument to <cod",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11571:1790,avoid,avoids,1790,https://hail.is,https://github.com/hail-is/hail/pull/11571,6,"['avoid', 'detect']","['avoids', 'detected']"
Safety,"streamId=830947795015, chunkIndex=0}: java.nio.file.NoSuchFileException: /data03/hadoop/yarn/local/usnio.fs.UnixException.translateToIOException(UnixException.java:86) at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) xFileSystemProvider.java:214) at java.nio.file.Files.newByteChannel(Files.java:361) at java.nio.file.Files.newByteChannel(Files.java:407) at ckManager.getBlockData(BlockManager.scala:382) at org.apache.spark.network.netty.NettyBlockRpcServer$$anonfun$1.apply(NettyBlockRpcServer.scala:61non$11.next(Iterator.scala:410) at scala.collection.convert.Wrappers$IteratorWrapper.next(Wrappers.scala:31) at org.apache.spark.networkessFetchRequest(TransportRequestHandler.java:130) at org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.jnnel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362) at io.netty.channel.AbstractChannelHandlerContext.ielHandlerContext.java:340) at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286) at io.netty.channel.AbstraceChannelRead(AbstractChannelHandlerContext.java:348) at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerConnnel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362) at io.netty.channel.AbstractChannelHandlerContext.ielHandlerContext.java:340) at org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:85) at io.nettylerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348) at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractCt io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362) at io.netty.channel.AbstractChannelultChannelPipeline.java:935) at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:138) at io.nettyentLoop.java:580) at io.netty.channel.nio.NioEventLoop.processSe",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8106:21277,timeout,timeout,21277,https://hail.is,https://github.com/hail-is/hail/issues/8106,2,['timeout'],['timeout']
Safety,"strong>Bug fixes</strong></p>; <ul>; <li>1456_, [macOS], <strong>[critical]</strong>: <code>cpu_freq()</code>_ <code>min</code> and <code>max</code> are set to; 0 if can't be determined (instead of crashing).</li>; <li>1512_, [macOS]: sometimes <code>Process.connections()</code>_ will crash with; <code>EOPNOTSUPP</code> for one connection; this is now ignored.</li>; <li>1598_, [Windows]: <code>disk_partitions()</code>_ only returns mountpoints on drives; where it first finds one.</li>; <li>1874_, [SunOS]: swap output error due to incorrect range.</li>; <li>1892_, [macOS]: <code>cpu_freq()</code>_ broken on Apple M1.</li>; <li>1901_, [macOS]: different functions, especially <code>Process.open_files()</code>_ and; <code>Process.connections()</code><em>, could randomly raise <code>AccessDenied</code></em> because the; internal buffer of <code>proc_pidinfo(PROC_PIDLISTFDS)</code> syscall was not big enough.; We now dynamically increase the buffer size until it's big enough instead of; giving up and raising <code>AccessDenied</code>_, which was a fallback to avoid crashing.</li>; <li>1904_, [Windows]: <code>OpenProcess</code> fails with <code>ERROR_SUCCESS</code> due to; <code>GetLastError()</code> called after <code>sprintf()</code>. (patch by alxchk)</li>; <li>1913_, [Linux]: <code>wait_procs()</code>_ should catch <code>subprocess.TimeoutExpired</code>; exception.</li>; <li>1919_, [Linux]: <code>sensors_battery()</code>_ can raise <code>TypeError</code> on PureOS.</li>; <li>1921_, [Windows]: <code>swap_memory()</code>_ shows committed memory instead of swap.</li>; <li>1940_, [Linux]: psutil does not handle <code>ENAMETOOLONG</code> when accessing process; file descriptors in procfs. (patch by Nikita Radchenko)</li>; <li>1948_, <strong>[critical]</strong>: <code>memoize_when_activated</code> decorator is not thread-safe.; (patch by Xuehai Pan)</li>; <li>1953_, [Windows], <strong>[critical]</strong>: <code>disk_partitions()</code>_ crashes due to; insufficient buffer len",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11459:2417,avoid,avoid,2417,https://hail.is,https://github.com/hail-is/hail/pull/11459,1,['avoid'],['avoid']
Safety,sun.nio.ch.SocketChannelImpl.<init>(SocketChannelImpl.java:105); at sun.nio.ch.SelectorProviderImpl.openSocketChannel(SelectorProviderImpl.java:60); at java.nio.channels.SocketChannel.open(SocketChannel.java:145); at org.apache.hadoop.net.StandardSocketFactory.createSocket(StandardSocketFactory.java:62); at org.apache.hadoop.hdfs.DFSOutputStream.createSocketForPipeline(DFSOutputStream.java:1531); at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.createBlockOutputStream(DFSOutputStream.java:1309); at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.nextBlockOutputStream(DFSOutputStream.java:1262); at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:448). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1889); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1876); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1876); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2110); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2059); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2048); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49); at org.apache.spark.s,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/9293:9372,abort,abortStage,9372,https://hail.is,https://github.com/hail-is/hail/issues/9293,1,['abort'],['abortStage']
Safety,sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:280); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:214); 	at java.lang.Thread.run(Thread.java:748)java.lang.AssertionError: assertion failed; 	at scala.Predef$.assert(Predef.scala:156); 	at is.hail.annotations.Region.loadInt(Region.scala:36); 	at is.hail.expr.types.TBinary$.loadLength(TBinary.scala:62); 	at is.hail.annotations.UnsafeRow$.readBinary(UnsafeRow.scala:128); 	at is.hail.annotations.UnsafeRow$.readString(UnsafeRow.scala:139); 	at is.hail.annotations.UnsafeRow$.readAltAllele(UnsafeRow.scala:152); 	at is.hail.annotations.UnsafeRow$.readArrayAltAllele(UnsafeRow.scala:164); 	at is.hail.annotations.UnsafeRow$.read(UnsafeRow.scala:210); 	at is.hail.annotations.UnsafeRow.get(UnsafeRow.scala:257); 	at is.hail.expr.FilterVariants$$anonfun$10.apply(Relational.scala:503); 	at is.hail.expr.FilterVariants$$anonfun$10.apply(Relational.scala:500); 	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:463); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$9$$anon$5.hasNext(OrderedRVD.scala:658); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$9$$anon$5.hasNext(OrderedRVD.scala:658); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$9$$anon$5.hasNext(OrderedRVD.scala:658); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at is.hail.sparkextras.OrderedRDD$$anonfun$apply$5$$anon$2.hasNext(OrderedRDD.scala:194); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at sc,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2743:8145,Unsafe,UnsafeRow,8145,https://hail.is,https://github.com/hail-is/hail/issues/2743,1,['Unsafe'],['UnsafeRow']
Safety,support outlier detection in PCA a la smartpca and EIGENSTRAT,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/179:16,detect,detection,16,https://hail.is,https://github.com/hail-is/hail/issues/179,1,['detect'],['detection']
Safety,"support</li>; <li>Janus is marked as stable, no API changes was made for years</li>; </ul>; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/aio-libs/janus/blob/master/CHANGES.rst"">janus's changelog</a>.</em></p>; <blockquote>; <h2>1.0.0 (2021-12-17)</h2>; <ul>; <li>Drop Python 3.6 support</li>; </ul>; <h2>0.7.0 (2021-11-24)</h2>; <ul>; <li>Add SyncQueue and AsyncQueue Protocols to provide type hints for sync and async queues <a href=""https://github-redirect.dependabot.com/aio-libs/janus/issues/374"">#374</a></li>; </ul>; <h2>0.6.2 (2021-10-24)</h2>; <ul>; <li>Fix Python 3.10 compatibility <a href=""https://github-redirect.dependabot.com/aio-libs/janus/issues/358"">#358</a></li>; </ul>; <h2>0.6.1 (2020-10-26)</h2>; <ul>; <li>; <p>Raise RuntimeError on queue.join() after queue closing. <a href=""https://github-redirect.dependabot.com/aio-libs/janus/issues/295"">#295</a></p>; </li>; <li>; <p>Replace <code>timeout</code> type from <code>Optional[int]</code> to <code>Optional[float]</code> <a href=""https://github-redirect.dependabot.com/aio-libs/janus/issues/267"">#267</a></p>; </li>; </ul>; <h2>0.6.0 (2020-10-10)</h2>; <ul>; <li>; <p>Drop Python 3.5, the minimal supported version is Python 3.6</p>; </li>; <li>; <p>Support Python 3.9</p>; </li>; <li>; <p>Refomat with <code>black</code></p>; </li>; </ul>; <h2>0.5.0 (2020-04-23)</h2>; <ul>; <li>Remove explicit loop arguments and forbid creating queues outside event loops <a href=""https://github-redirect.dependabot.com/aio-libs/janus/issues/246"">#246</a></li>; </ul>; <h2>0.4.0 (2018-07-28)</h2>; <ul>; <li>; <p>Add <code>py.typed</code> macro <a href=""https://github-redirect.dependabot.com/aio-libs/janus/issues/89"">#89</a></p>; </li>; <li>; <p>Drop python 3.4 support and fix minimal version python3.5.3 <a href=""https://github-redirect.dependabot.com/aio-libs/janus/issues/88"">#88</a></p>; </li>; <li>; <p>Add property with that indicates if queue is closed <a href=""",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11466:1304,timeout,timeout,1304,https://hail.is,https://github.com/hail-is/hail/pull/11466,1,['timeout'],['timeout']
Safety,switched to unsafeValueAt in RichDenseMatrixDouble,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1566:12,unsafe,unsafeValueAt,12,https://hail.is,https://github.com/hail-is/hail/pull/1566,1,['unsafe'],['unsafeValueAt']
Safety,"t all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI0MmRjMDIwMC02MDI1LTQ1M2QtYWUxNC00NDRlZjM5MmU4NTciLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjQyZGMwMjAwLTYwMjUtNDUzZC1hZTE0LTQ0NGVmMzkyZTg1NyJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""42dc0200-6025-453d-ae14-444ef392e857"",""prPublicId"":""42dc0200-6025-453d-ae14-444ef392e857"",""dependencies"":[{""name"":""urllib3"",""from"":""1.26.17"",""to"":""1.26.18""}],""packageManager"":""pip"",""projectPublicId"":""c1c98f6a-57c6-4ecc-a329-3b744cab74bd"",""projectUrl"":""https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-URLLIB3-6002459""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""pr-warning-shown"",""priorityScore""],""priorityScoreList"":[496],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Learn about vulnerability in an interactive lesson of Snyk Learn.](https://learn.snyk.io/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13854:3406,remediat,remediationStrategy,3406,https://hail.is,https://github.com/hail-is/hail/pull/13854,1,['remediat'],['remediationStrategy']
Safety,"t all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI3OWQ3MTdiYy05MThjLTRlMjctOGQ2OC0xNTNhNWIxZGFmM2YiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6Ijc5ZDcxN2JjLTkxOGMtNGUyNy04ZDY4LTE1M2E1YjFkYWYzZiJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""79d717bc-918c-4e27-8d68-153a5b1daf3f"",""prPublicId"":""79d717bc-918c-4e27-8d68-153a5b1daf3f"",""dependencies"":[{""name"":""urllib3"",""from"":""1.26.17"",""to"":""1.26.18""}],""packageManager"":""pip"",""projectPublicId"":""20159ae6-a5aa-42fa-845a-c89f5bcbf999"",""projectUrl"":""https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-URLLIB3-6002459""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""pr-warning-shown"",""priorityScore""],""priorityScoreList"":[496],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Learn about vulnerability in an interactive lesson of Snyk Learn.](https://learn.snyk.io/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13850:3404,remediat,remediationStrategy,3404,https://hail.is,https://github.com/hail-is/hail/pull/13850,1,['remediat'],['remediationStrategy']
Safety,"t all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI4MmZhNTRjZC0yOGI4LTQ3OTUtYWFjNy02MDE0NjY3NjMwNTUiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjgyZmE1NGNkLTI4YjgtNDc5NS1hYWM3LTYwMTQ2Njc2MzA1NSJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/b72ce54d-5de3-48e5-a1d4-6f8967681a12?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/b72ce54d-5de3-48e5-a1d4-6f8967681a12?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""82fa54cd-28b8-4795-aac7-601466763055"",""prPublicId"":""82fa54cd-28b8-4795-aac7-601466763055"",""dependencies"":[{""name"":""urllib3"",""from"":""1.26.16"",""to"":""1.26.17""}],""packageManager"":""pip"",""projectPublicId"":""b72ce54d-5de3-48e5-a1d4-6f8967681a12"",""projectUrl"":""https://app.snyk.io/org/danking/project/b72ce54d-5de3-48e5-a1d4-6f8967681a12?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-URLLIB3-5926907""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""pr-warning-shown"",""priorityScore""],""priorityScoreList"":[581],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Learn about vulnerability in an interactive lesson of Snyk Learn.](https://learn.snyk.io/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13771:3322,remediat,remediationStrategy,3322,https://hail.is,https://github.com/hail-is/hail/pull/13771,1,['remediat'],['remediationStrategy']
Safety,"t all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiIxNGQyZDIxMi00ZjI4LTQ0OGEtYWRkNS02NThkNDEwNzQxZDYiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjE0ZDJkMjEyLTRmMjgtNDQ4YS1hZGQ1LTY1OGQ0MTA3NDFkNiJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/b72ce54d-5de3-48e5-a1d4-6f8967681a12?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/b72ce54d-5de3-48e5-a1d4-6f8967681a12?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""14d2d212-4f28-448a-add5-658d410741d6"",""prPublicId"":""14d2d212-4f28-448a-add5-658d410741d6"",""dependencies"":[{""name"":""urllib3"",""from"":""1.26.17"",""to"":""1.26.18""}],""packageManager"":""pip"",""projectPublicId"":""b72ce54d-5de3-48e5-a1d4-6f8967681a12"",""projectUrl"":""https://app.snyk.io/org/danking/project/b72ce54d-5de3-48e5-a1d4-6f8967681a12?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-URLLIB3-6002459""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""pr-warning-shown"",""priorityScore""],""priorityScoreList"":[496],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Learn about vulnerability in an interactive lesson of Snyk Learn.](https://learn.snyk.io/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13847:3322,remediat,remediationStrategy,3322,https://hail.is,https://github.com/hail-is/hail/pull/13847,1,['remediat'],['remediationStrategy']
Safety,"t all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiIxOGU4YzI4Yi1kYWQ0LTQ5ZDUtOTExNi04NjFkYTdkODk5OTYiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjE4ZThjMjhiLWRhZDQtNDlkNS05MTE2LTg2MWRhN2Q4OTk5NiJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""18e8c28b-dad4-49d5-9116-861da7d89996"",""prPublicId"":""18e8c28b-dad4-49d5-9116-861da7d89996"",""dependencies"":[{""name"":""urllib3"",""from"":""1.26.16"",""to"":""1.26.17""}],""packageManager"":""pip"",""projectPublicId"":""c1c98f6a-57c6-4ecc-a329-3b744cab74bd"",""projectUrl"":""https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-URLLIB3-5926907""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""pr-warning-shown"",""priorityScore""],""priorityScoreList"":[581],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Learn about vulnerability in an interactive lesson of Snyk Learn.](https://learn.snyk.io/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13773:3406,remediat,remediationStrategy,3406,https://hail.is,https://github.com/hail-is/hail/pull/13773,1,['remediat'],['remediationStrategy']
Safety,"t all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJiNzM0YmY4Ni1mNzQyLTQyMjMtOWVlYS1lNGU3ZjNmMTVlYWMiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImI3MzRiZjg2LWY3NDItNDIyMy05ZWVhLWU0ZTdmM2YxNWVhYyJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""b734bf86-f742-4223-9eea-e4e7f3f15eac"",""prPublicId"":""b734bf86-f742-4223-9eea-e4e7f3f15eac"",""dependencies"":[{""name"":""urllib3"",""from"":""1.26.16"",""to"":""1.26.17""}],""packageManager"":""pip"",""projectPublicId"":""20159ae6-a5aa-42fa-845a-c89f5bcbf999"",""projectUrl"":""https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-URLLIB3-5926907""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""pr-warning-shown"",""priorityScore""],""priorityScoreList"":[581],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Learn about vulnerability in an interactive lesson of Snyk Learn.](https://learn.snyk.io/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13772:3336,remediat,remediationStrategy,3336,https://hail.is,https://github.com/hail-is/hail/pull/13772,1,['remediat'],['remediationStrategy']
Safety,"t all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJiODhmOTA3Ny02ZjlmLTRiZjEtYjFiYy0yZjNkNTE1MDEwYWEiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImI4OGY5MDc3LTZmOWYtNGJmMS1iMWJjLTJmM2Q1MTUwMTBhYSJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""b88f9077-6f9f-4bf1-b1bc-2f3d515010aa"",""prPublicId"":""b88f9077-6f9f-4bf1-b1bc-2f3d515010aa"",""dependencies"":[{""name"":""urllib3"",""from"":""1.26.16"",""to"":""1.26.17""}],""packageManager"":""pip"",""projectPublicId"":""5ecb4152-94d0-44ff-86c6-21e542bb123d"",""projectUrl"":""https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-URLLIB3-5926907""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""pr-warning-shown"",""priorityScore""],""priorityScoreList"":[581],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Learn about vulnerability in an interactive lesson of Snyk Learn.](https://learn.snyk.io/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13783:3398,remediat,remediationStrategy,3398,https://hail.is,https://github.com/hail-is/hail/pull/13783,1,['remediat'],['remediationStrategy']
Safety,"t all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJmNDI4YzVjNi05NmZmLTQ1ZTMtYjY4ZC0zYzU5NjY3MjA3MGUiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImY0MjhjNWM2LTk2ZmYtNDVlMy1iNjhkLTNjNTk2NjcyMDcwZSJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""f428c5c6-96ff-45e3-b68d-3c596672070e"",""prPublicId"":""f428c5c6-96ff-45e3-b68d-3c596672070e"",""dependencies"":[{""name"":""urllib3"",""from"":""1.26.17"",""to"":""1.26.18""}],""packageManager"":""pip"",""projectPublicId"":""5ecb4152-94d0-44ff-86c6-21e542bb123d"",""projectUrl"":""https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-URLLIB3-6002459""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""pr-warning-shown"",""priorityScore""],""priorityScoreList"":[496],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Learn about vulnerability in an interactive lesson of Snyk Learn.](https://learn.snyk.io/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13851:3398,remediat,remediationStrategy,3398,https://hail.is,https://github.com/hail-is/hail/pull/13851,1,['remediat'],['remediationStrategy']
Safety,"t dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiIzNTM4YWIwOC03Yzk4LTRjMDUtOTQ0Ny0yMjYwYjliNjhmY2IiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjM1MzhhYjA4LTdjOTgtNGMwNS05NDQ3LTIyNjBiOWI2OGZjYiJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/fa47fca0-549b-41a3-8bf7-bcda4ca9a617?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/fa47fca0-549b-41a3-8bf7-bcda4ca9a617?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""3538ab08-7c98-4c05-9447-2260b9b68fcb"",""prPublicId"":""3538ab08-7c98-4c05-9447-2260b9b68fcb"",""dependencies"":[{""name"":""pillow"",""from"":""9.5.0"",""to"":""10.0.1""}],""packageManager"":""pip"",""projectPublicId"":""fa47fca0-549b-41a3-8bf7-bcda4ca9a617"",""projectUrl"":""https://app.snyk.io/org/danking/project/fa47fca0-549b-41a3-8bf7-bcda4ca9a617?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-PILLOW-5918878""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""pr-warning-shown""],""priorityScoreList"":[null],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Learn about vulnerability in an interactive lesson of Snyk Learn.](https://learn.snyk.io/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13708:3254,remediat,remediationStrategy,3254,https://hail.is,https://github.com/hail-is/hail/pull/13708,1,['remediat'],['remediationStrategy']
Safety,t is.hail.io.vcf.VCFLine.parseAddInfoField(LoadVCF.scala:1055); 	at is.hail.io.vcf.VCFLine.addInfoField(LoadVCF.scala:1075); 	at is.hail.io.vcf.VCFLine.parseAddInfo(LoadVCF.scala:1112); 	at is.hail.io.vcf.LoadVCF$.parseLineInner(LoadVCF.scala:1541); 	at is.hail.io.vcf.LoadVCF$.parseLine(LoadVCF.scala:1409); 	at is.hail.io.vcf.MatrixVCFReader.$anonfun$executeGeneric$7(LoadVCF.scala:1916); 	... 21 more. Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2673); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2609); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2608); 	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62); 	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2608); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1182); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1182); 	at scala.Option.foreach(Option.scala:407); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1182); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2861); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2803); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2792); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:952); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2236); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2257); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:22,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14102:10436,abort,abortStage,10436,https://hail.is,https://github.com/hail-is/hail/issues/14102,1,['abort'],['abortStage']
Safety,t java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:280); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:214); 	at java.lang.Thread.run(Thread.java:748)java.lang.AssertionError: assertion failed; 	at scala.Predef$.assert(Predef.scala:156); 	at is.hail.annotations.Region.loadInt(Region.scala:36); 	at is.hail.expr.types.TBinary$.loadLength(TBinary.scala:62); 	at is.hail.annotations.UnsafeRow$.readBinary(UnsafeRow.scala:128); 	at is.hail.annotations.UnsafeRow$.readString(UnsafeRow.scala:139); 	at is.hail.annotations.UnsafeRow$.readAltAllele(UnsafeRow.scala:152); 	at is.hail.annotations.UnsafeRow$.readArrayAltAllele(UnsafeRow.scala:164); 	at is.hail.annotations.UnsafeRow$.read(UnsafeRow.scala:210); 	at is.hail.annotations.UnsafeRow.get(UnsafeRow.scala:257); 	at is.hail.expr.FilterVariants$$anonfun$10.apply(Relational.scala:503); 	at is.hail.expr.FilterVariants$$anonfun$10.apply(Relational.scala:500); 	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:463); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$9$$anon$5.hasNext(OrderedRVD.scala:658); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$9$$anon$5.hasNext(OrderedRVD.scala:658); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$9$$anon$5.hasNext(OrderedRVD.scala:658); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at is.hail.sparkextras.OrderedRDD$$anonfun$apply$5$$anon$2.hasNext(OrderedRDD.scala:194); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at is.hail.sparkextras.Par,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2743:8237,Unsafe,UnsafeRow,8237,https://hail.is,https://github.com/hail-is/hail/issues/2743,1,['Unsafe'],['UnsafeRow']
Safety,t org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:329); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90); 	at org.apache.spark.scheduler.Task.run(Task.scala:136); 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548); 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551); 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128); 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628); 	at java.base/java.lang.Thread.run(Thread.java:829). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2717); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2653); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2652); 	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62); 	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2652); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1189); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1189); 	at scala.Option.foreach(Option.scala:407); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1189); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2913); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2855); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2844); 	at org.apache.spark.u,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14513:8429,abort,abortStage,8429,https://hail.is,https://github.com/hail-is/hail/issues/14513,1,['abort'],['abortStage']
Safety,"t org.apache.spark.sql.DataFrameWriter.parquet(DataFrameWriter.scala:488); 	at is.hail.variant.VariantDatasetFunctions$.write$extension(VariantDataset.scala:941); 	at is.hail.variant.VariantDatasetFunctions.write(VariantDataset.scala:911); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:280); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:214); 	at java.lang.Thread.run(Thread.java:745)org.apache.spark.SparkException: Job aborted due to stage failure: Task 22 in stage 5.0 failed 20 times, most recent failure: Lost task 22.19 in stage 5.0 (TID 133, seqr-pipeline-cluster-grch38-w-1.c.seqr-project.internal): org.apache.spark.SparkException: Task failed while writing rows; 	at org.apache.spark.sql.execution.datasources.DefaultWriterContainer.writeRows(WriterContainer.scala:261); 	at org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand$$anonfun$run$1$$anonfun$apply$mcV$sp$1.apply(InsertIntoHadoopFsRelationCommand.scala:143); 	at org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand$$anonfun$run$1$$anonfun$apply$mcV$sp$1.apply(InsertIntoHadoopFsRelationCommand.scala:143); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); 	at org.apache.spark.scheduler.Task.run(Task.scala:86); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurren",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1822:3478,abort,aborted,3478,https://hail.is,https://github.com/hail-is/hail/issues/1822,1,['abort'],['aborted']
Safety,"t(self._hail_package.expr.ir.Pretty.apply(jir, True, -1)); 73 try:; ---> 74 result = json.loads(self._jhc.backend().executeJSON(jir)); 75 value = ir.typ._from_json(result['value']); 76 timings = result['timings']. /usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py in __call__(self, *args); 1302; 1303 answer = self.gateway_client.send_command(command); -> 1304 return_value = get_return_value(; 1305 answer, self.gateway_client, self.target_id, self.name); 1306. /opt/conda/miniconda3/lib/python3.8/site-packages/hail/backend/py4j_backend.py in deco(*args, **kwargs); 28 raise FatalError('Error summary: %s' % (deepest,), error_id) from None; 29 else:; ---> 30 raise FatalError('%s\n\nJava stack trace:\n%s\n'; 31 'Hail version: %s\n'; 32 'Error summary: %s' % (deepest, full, hail.__version__, deepest), error_id) from None. FatalError: NoClassDefFoundError: Could not initialize class __C147RGContainer_GRCh38. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 0.0 failed 20 times, most recent failure: Lost task 0.19 in stage 0.0 (TID 19) (my-first-hail-cluster-w-0.c.open-targets-eu-dev.internal executor 1): java.lang.NoClassDefFoundError: Could not initialize class __C147RGContainer_GRCh38; 	at __C144Compiled.applyregion0_8(Emit.scala); 	at __C144Compiled.apply(Emit.scala); 	at is.hail.expr.ir.TableMapRows.$anonfun$execute$43(TableIR.scala:1938); 	at scala.runtime.java8.JFunction1$mcJJ$sp.apply(JFunction1$mcJJ$sp.java:23); 	at scala.collection.Iterator$$anon$10.next(Iterator.scala:461); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:496); 	at is.hail.utils.richUtils.RichContextRDD$$anon$1.next(RichContextRDD.scala:79); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:496); 	at is.hail.utils.package$.getIteratorSizeWithMaxN(package.scala:415); 	at is.hail.rvd.RVD.$anonfun$head$2(RVD.scala:526); 	at is.hail.rvd.RVD.$anonfun$head$2$adapted(RVD.scala:526); 	at is.hail.sparkextras.ContextRDD.$",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/10682:5965,abort,aborted,5965,https://hail.is,https://github.com/hail-is/hail/issues/10682,1,['abort'],['aborted']
Safety,"t.BatchClient object at 0x7fae899806a0>. def test_always_run_job_private_instance_cancel(client: BatchClient):; b = create_batch(client); resources = {'machine_type': smallest_machine_type()}; j = b.create_job(DOCKER_ROOT_IMAGE, ['true'], resources=resources, always_run=True); b.submit(); b.cancel(); > status = j.wait(). io/test/test_batch.py:1487: ; _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ; usr/local/lib/python3.9/dist-packages/hailtop/batch_client/client.py:84: in wait; return async_to_blocking(self._async_job.wait()); usr/local/lib/python3.9/dist-packages/hailtop/utils/utils.py:156: in async_to_blocking; return loop.run_until_complete(task); usr/lib/python3.9/asyncio/base_events.py:634: in run_until_complete; self.run_forever(); usr/lib/python3.9/asyncio/base_events.py:601: in run_forever; self._run_once(); usr/lib/python3.9/asyncio/base_events.py:1869: in _run_once; event_list = self._selector.select(timeout); _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . self = <selectors.EpollSelector object at 0x7fae890f2d30>; timeout = 15.402000000000001. def select(self, timeout=None):; if timeout is None:; timeout = -1; elif timeout <= 0:; timeout = 0; else:; # epoll_wait() has a resolution of 1 millisecond, round away; # from zero to wait *at least* timeout seconds.; timeout = math.ceil(timeout * 1e3) * 1e-3; ; # epoll_wait() expects `maxevents` to be greater than zero;; # we want to make sure that `select()` can be called when no; # FD is registered.; max_ev = max(len(self._fd_to_key), 1); ; ready = []; try:; > fd_event_list = self._selector.poll(timeout, max_ev); E Failed: Timeout >360.0s. usr/lib/python3.9/selectors.py:469: Failed; ------------------------------ Captured log setup ------------------------------; 2023-09-06T21:45:24 INFO test.conftest conftest.py:14:log_before_after starting test; 2023-09-06T21:45:24 INFO hailtop.aiocloud.aioazure.credentials credentials.py:99:default_credential",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13582:2893,timeout,timeout,2893,https://hail.is,https://github.com/hail-is/hail/issues/13582,1,['timeout'],['timeout']
Safety,"t.dependabot.com/aio-libs/async-timeout/issues/273"">#273</a>)</li>; <li><a href=""https://github.com/aio-libs/async-timeout/commit/f0a0914345b224448220aeb00d71e6a04a5d24bd""><code>f0a0914</code></a> Bump twine from 3.7.0 to 3.7.1 (<a href=""https://github-redirect.dependabot.com/aio-libs/async-timeout/issues/272"">#272</a>)</li>; <li><a href=""https://github.com/aio-libs/async-timeout/commit/e5c813173b8811b30f4a30eeba56fa8808ab15bb""><code>e5c8131</code></a> [pre-commit.ci] pre-commit autoupdate (<a href=""https://github-redirect.dependabot.com/aio-libs/async-timeout/issues/271"">#271</a>)</li>; <li><a href=""https://github.com/aio-libs/async-timeout/commit/c7e10db3d0965422122bef263fb36f6fd7572330""><code>c7e10db</code></a> Fix linter configs</li>; <li><a href=""https://github.com/aio-libs/async-timeout/commit/6af8bf421a799208b27d57c6bf69de0d998fedec""><code>6af8bf4</code></a> Bump pre-commit from 2.15 to 2.16.0 (<a href=""https://github-redirect.dependabot.com/aio-libs/async-timeout/issues/269"">#269</a>)</li>; <li><a href=""https://github.com/aio-libs/async-timeout/commit/c71bbb5b5d7330f6dabfde7a1adec30a4611c0be""><code>c71bbb5</code></a> Bump docutils from 0.18 to 0.18.1 (<a href=""https://github-redirect.dependabot.com/aio-libs/async-timeout/issues/266"">#266</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/aio-libs/async-timeout/compare/v3.0.1...v4.0.2"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=async-timeout&package-manager=pip&previous-version=3.0.1&new-version=4.0.2)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11465:5891,timeout,timeout,5891,https://hail.is,https://github.com/hail-is/hail/pull/11465,1,['timeout'],['timeout']
Safety,"t.dependabot.com/brettcannon/gidgethub/issues/155"">#155</a>](<a href=""https://github.com/brettcannon/gidgethub/discussions/155"">https://github.com/brettcannon/gidgethub/discussions/155</a>)</li>; </ul>; <h2>5.0.0</h2>; <ul>; <li>Add <code>gidgethub.routing.Router.fetch</code> for obtaining a frozenset of functions; registered to the router that the event would be called on.; [Issue <a href=""https://github-redirect.dependabot.com/brettcannon/gidgethub/issues/74"">#74</a>](<a href=""https://github-redirect.dependabot.com/brettcannon/gidgethub/issues/74"">brettcannon/gidgethub#74</a>).</li>; <li>Add support for GitHub Actions Environment Files with <code>gidgethub.actions.setenv</code>; and <code>gidgethub.actions.addpath</code>.; [Issue <a href=""https://github-redirect.dependabot.com/brettcannon/gidgethub/issues/137"">#137</a>](<a href=""https://github-redirect.dependabot.com/brettcannon/gidgethub/issues/132"">brettcannon/gidgethub#132</a>).</li>; <li>Make router callback execution order non-deterministic to avoid relying on; registration order.; [Issue <a href=""https://github-redirect.dependabot.com/brettcannon/gidgethub/issues/74"">#74</a>](<a href=""https://github-redirect.dependabot.com/brettcannon/gidgethub/issues/74"">brettcannon/gidgethub#74</a>).</li>; <li>Fix mypy errors in <code>gidgethub.httpx.GitHubAPI._request</code>[Issue <a href=""https://github-redirect.dependabot.com/brettcannon/gidgethub/issues/133"">#133</a>](<a href=""https://github-redirect.dependabot.com/brettcannon/gidgethub/issues/133"">brettcannon/gidgethub#133</a>).</li>; <li>Make the minimum version of PyJWT be v2.0.0.</li>; </ul>; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/brettcannon/gidgethub/blob/main/docs/changelog.rst"">gidgethub's changelog</a>.</em></p>; <blockquote>; <h2>5.2.1</h2>; <ul>; <li>; <p>Fix cgi and importlib_resources deprecations.; (<code>PR [#185](https://github.com/brettcannon/gidgethub/issues/185) &lt;https://",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12328:3497,avoid,avoid,3497,https://hail.is,https://github.com/hail-is/hail/pull/12328,1,['avoid'],['avoid']
Safety,"tConnectorError: Cannot connect to host 10.128.0.11:5000 ssl:default [Connection refused]; INFO	2022-03-02 19:06:38,141	resource_manager.py	create_vm:191	created machine batch-worker-pr-11438-default-g6cibyji6520-standard-4d9n8; ERROR	2022-03-02 19:06:39,183	job.py	schedule_job:473	error while scheduling job (98, 1) on instance batch-worker-pr-11438-default-g6cibyji6520-standard-9xy2q	Traceback (most recent call last):\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 969, in _wrap_create_connection\n return await self._loop.create_connection(*args, **kwargs) # type: ignore # noqa\n File ""uvloop/loop.pyx"", line 1974, in create_connection\n File ""uvloop/loop.pyx"", line 1951, in uvloop.loop.Loop.create_connection\nConnectionRefusedError: [Errno 111] Connection refused\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n File ""/usr/local/lib/python3.7/dist-packages/batch/driver/job.py"", line 449, in schedule_job\n timeout=aiohttp.ClientTimeout(total=2),\n File ""/usr/local/lib/python3.7/dist-packages/hailtop/httpx.py"", line 113, in request_and_raise_for_status\n resp = await self.client_session._request(method, url, **kwargs)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/client.py"", line 521, in _request\n req, traces=traces, timeout=real_timeout\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 535, in connect\n proto = await self._create_connection(req, traces, timeout)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 892, in _create_connection\n _, proto = await self._create_direct_connection(req, traces, timeout)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 1051, in _create_direct_connection\n raise last_exc\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 1032, in _create_direct_connection\n client_error=client_error,\n File ""/usr/local/lib/python3.7/dist-packages/aioht",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11451:20796,timeout,timeout,20796,https://hail.is,https://github.com/hail-is/hail/pull/11451,1,['timeout'],['timeout']
Safety,tTask.runTask(ResultTask.scala:70); 	at org.apache.spark.scheduler.Task.run(Task.scala:86); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745); Caused by: java.lang.ArrayIndexOutOfBoundsException. Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1873); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1886); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1202:5591,abort,abortStage,5591,https://hail.is,https://github.com/hail-is/hail/issues/1202,1,['abort'],['abortStage']
Safety,"tain the credentials; themselves. The Docker docs note [""Authentication for registries is handled client side. The client; has to send authentication details to various endpoints that need to communicate with; registries""](https://docs.docker.com/engine/api/v1.41/#section/Authentication). I request a short-lived oauth2 access token from the Google metadata endpoint. The google; [documentation obliquely notes that the username should be; `oauth2accesstoken`](https://cloud.google.com/container-registry/docs/advanced-authentication). I; use this only for retrieving a ""public gcr image"" which I fix in this PR to be images whose; ""repository"" [1] is one of these:; - gcr.io/PROJECT/query; - gcr.io/PROJECT/hail; - gcr.io/PROJECT/python-dill. A previous Shuffler PR taught worker.py to translate our `hailgenetics` Docker image names to; `gcr.io/PROJECT` image names. I had to move the docker-worker into a new Docker network which allows it to access the metadata server. I think this is safe because we trust our own code. From a relevant Docker worker log:. ```; Traceback (most recent call last):; File ""/usr/local/lib/python3.7/site-packages/batch/worker/worker.py"", line 359, in ensure_image_is_pulled; docker.images.get, self.image); File ""/usr/local/lib/python3.7/site-packages/batch/worker/worker.py"", line 111, in wrapper; return await asyncio.wait_for(f(*args, **kwargs), timeout); File ""/usr/local/lib/python3.7/asyncio/tasks.py"", line 442, in wait_for; return fut.result(); File ""/usr/local/lib/python3.7/asyncio/futures.py"", line 181, in result; raise self._exception; File ""/usr/local/lib/python3.7/asyncio/tasks.py"", line 249, in __step; result = coro.send(None); File ""/usr/local/lib/python3.7/site-packages/aiodocker/images.py"", line 46, in get; return await self.inspect(name); File ""/usr/local/lib/python3.7/site-packages/aiodocker/images.py"", line 36, in inspect; response = await self.docker._query_json(""images/{name}/json"".format(name=name)); File ""/usr/local/lib/python3.7/",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9902:1253,safe,safe,1253,https://hail.is,https://github.com/hail-is/hail/pull/9902,1,['safe'],['safe']
Safety,"tation</strong></p>; <ul>; <li>Various typo fixes and doc improvements.</li>; </ul>; <p><strong>Packaging</strong></p>; <ul>; <li>Requests has started adopting some modern packaging practices.; The source files for the projects (formerly <code>requests</code>) is now located; in <code>src/requests</code> in the Requests sdist. (<a href=""https://redirect.github.com/psf/requests/issues/6506"">#6506</a>)</li>; <li>Starting in Requests 2.33.0, Requests will migrate to a PEP 517 build system; using <code>hatchling</code>. This should not impact the average user, but extremely old; versions of packaging utilities may have issues with the new packaging format.</li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/psf/requests/commit/d6ebc4a2f1f68b7e355fb7e4dd5ffc0845547f9f""><code>d6ebc4a</code></a> v2.32.0</li>; <li><a href=""https://github.com/psf/requests/commit/9a40d1277807f0a4f26c9a37eea8ec90faa8aadc""><code>9a40d12</code></a> Avoid reloading root certificates to improve concurrent performance (<a href=""https://redirect.github.com/psf/requests/issues/6667"">#6667</a>)</li>; <li><a href=""https://github.com/psf/requests/commit/0c030f78d24f29a459dbf39b28b4cc765e2153d7""><code>0c030f7</code></a> Merge pull request <a href=""https://redirect.github.com/psf/requests/issues/6702"">#6702</a> from nateprewitt/no_char_detection</li>; <li><a href=""https://github.com/psf/requests/commit/555b870eb19d497ddb67042645420083ec8efb02""><code>555b870</code></a> Allow character detection dependencies to be optional in post-packaging steps</li>; <li><a href=""https://github.com/psf/requests/commit/d6dded3f00afcf56a7e866cb0732799045301eb0""><code>d6dded3</code></a> Merge pull request <a href=""https://redirect.github.com/psf/requests/issues/6700"">#6700</a> from franekmagiera/update-redirect-to-invalid-uri-test</li>; <li><a href=""https://github.com/psf/requests/commit/bf24b7d8d17da34be720c19e5978b2d3bf94a53b""><code>bf24b7d</code></a> Use an ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14555:7771,Avoid,Avoid,7771,https://hail.is,https://github.com/hail-is/hail/pull/14555,1,['Avoid'],['Avoid']
Safety,"tations.Region$.scoped(Region.scala:18); at is.hail.expr.ir.ExecuteContext$.scoped(ExecuteContext.scala:7); at is.hail.backend.Backend.execute(Backend.scala:86); at is.hail.backend.Backend.executeJSON(Backend.scala:92); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); at py4j.Gateway.invoke(Gateway.java:282); at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); at py4j.commands.CallCommand.execute(CallCommand.java:79); at py4j.GatewayConnection.run(GatewayConnection.java:238); at java.lang.Thread.run(Thread.java:745). Hail version: 0.2.19-c6ec8b76eb26; Error summary: SparkException: Job aborted due to stage failure: ResultStage 2 (runJob at SparkHadoopWriter.scala:78) has failed the maximum allowaamId=830947795015, chunkIndex=0}: java.nio.file.NoSuchFileException: /data03/hadoop/yarn/local/usercache/farrell/appcache/application_1565788829616Exception.java:86) at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) at sun.nio.fs.UnixException.rethrowAsIOExcee.Files.newByteChannel(Files.java:361) at java.nio.file.Files.newByteChannel(Files.java:407) at org.apache.spark.shuffle.IndexShuffleBlockResolvt org.apache.spark.network.netty.NettyBlockRpcServer$$anonfun$1.apply(NettyBlockRpcServer.scala:61) at org.apache.spark.network.netty.NettyBloction.convert.Wrappers$IteratorWrapper.next(Wrappers.scala:31) at org.apache.spark.network.server.OneForOneStreamManager.getChunk(OneForOneStreamMt org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:101) at org.apache.spark.network.server.TransportractChannelHandlerContext.java:362) at io.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8106:30273,abort,aborted,30273,https://hail.is,https://github.com/hail-is/hail/issues/8106,1,['abort'],['aborted']
Safety,"ted dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiIxNjVmNDVkMi00ZDM3LTRmNzAtOGU1OC00OGIxOGJhNmVlOTgiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjE2NWY0NWQyLTRkMzctNGY3MC04ZTU4LTQ4YjE4YmE2ZWU5OCJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""165f45d2-4d37-4f70-8e58-48b18ba6ee98"",""prPublicId"":""165f45d2-4d37-4f70-8e58-48b18ba6ee98"",""dependencies"":[{""name"":""cryptography"",""from"":""41.0.7"",""to"":""42.0.0""}],""packageManager"":""pip"",""projectPublicId"":""c1c98f6a-57c6-4ecc-a329-3b744cab74bd"",""projectUrl"":""https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-CRYPTOGRAPHY-6050294"",""SNYK-PYTHON-CRYPTOGRAPHY-6126975""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""pr-warning-shown"",""priorityScore""],""priorityScoreList"":[479,616],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Denial of Service (DoS)](https://learn.snyk.io/lesson/redos/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14203:3820,remediat,remediationStrategy,3820,https://hail.is,https://github.com/hail-is/hail/pull/14203,1,['remediat'],['remediationStrategy']
Safety,"ted dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJkYWIzNjU3Mi1hNTUwLTQwY2EtYThjZi0zN2ZjODljOWI1OGEiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImRhYjM2NTcyLWE1NTAtNDBjYS1hOGNmLTM3ZmM4OWM5YjU4YSJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""dab36572-a550-40ca-a8cf-37fc89c9b58a"",""prPublicId"":""dab36572-a550-40ca-a8cf-37fc89c9b58a"",""dependencies"":[{""name"":""cryptography"",""from"":""41.0.7"",""to"":""42.0.0""}],""packageManager"":""pip"",""projectPublicId"":""5ecb4152-94d0-44ff-86c6-21e542bb123d"",""projectUrl"":""https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-CRYPTOGRAPHY-6050294"",""SNYK-PYTHON-CRYPTOGRAPHY-6126975""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""pr-warning-shown"",""priorityScore""],""priorityScoreList"":[265,402],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Denial of Service (DoS)](https://learn.snyk.io/lesson/redos/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14201:3770,remediat,remediationStrategy,3770,https://hail.is,https://github.com/hail-is/hail/pull/14201,1,['remediat'],['remediationStrategy']
Safety,"tervalFilters. Instead of matching against very specific patterns, and failing completely for things that don't quite match (e.g. an input is let bound, or the fold implementing ""locus is contained in a set of intervals"" is written slightly differently), this uses a standard abstract interpretation framework, which is almost completely insensitive to the form of the IR, only depending on the semantics. It also correctly handles missing key fields, where the previous implementation often produced an unsound transformation of the IR. Also adds a much more thorough test suite than we had before. At the top level, the analysis takes a boolean typed IR `cond` in an environment where there is a reference to some `key`, and produces a set `intervals`, such that `cond` is equivalent to `cond & intervals.contains(key)` (in other words `cond` implies `intervals.contains(key)`, or `intervals` contains all rows where `cond` is true). This means for instance it is safe to replace `TableFilter(t, cond)` with `TableFilter(TableFilterIntervals(t, intervals), cond)`. Then in a second pass it rewrites `cond` to `cond2`, such that `cond & (intervals.contains(key))` is equivalent to `cond2 & intervals.contains(key)` (in other words `cond` implies `cond2`, and `cond2 & intervals.contains(key)` implies `cond`). This means it is safe to replace the `TableFilter(t, cond)` with `TableFilter(TableFilterIntervals(t, intervals), cond2)`. A common example is when `cond` can be completely captured by the interval filter, i.e. `cond` is equivant to `intervals.contains(key)`, in which case we can take `cond2 = True`, and the `TableFilter` can be optimized away. This all happens in the function; ```scala; def extractPartitionFilters(ctx: ExecuteContext, cond: IR, ref: Ref, key: IndexedSeq[String]): Option[(IR, IndexedSeq[Interval])] = {; if (key.isEmpty) None; else {; val extract = new ExtractIntervalFilters(ctx, ref.typ.asInstanceOf[TStruct].typeAfterSelectNames(key)); val trueSet = extract.analyze",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13355:1094,safe,safe,1094,https://hail.is,https://github.com/hail-is/hail/pull/13355,1,['safe'],['safe']
Safety,"testNativeCallSpeed PASSED; Running test: Test method testNativeGlobal(is.hail.nativecode.NativeCodeSuite). Gradle suite > Gradle test > is.hail.nativecode.NativeCodeSuite.testNativeGlobal PASSED; Running test: Test method testNativePtr(is.hail.nativecode.NativeCodeSuite). Gradle suite > Gradle test > is.hail.nativecode.NativeCodeSuite.testNativePtr PASSED; Running test: Test method testNativeUpcall(is.hail.nativecode.NativeCodeSuite); DEBUG: Logging set_test_msg ... Gradle suite > Gradle test > is.hail.nativecode.NativeCodeSuite.testNativeUpcall PASSED; Running test: Test method testObjectArray(is.hail.nativecode.NativeCodeSuite). Gradle suite > Gradle test > is.hail.nativecode.NativeCodeSuite.testObjectArray PASSED; Running test: Test method testShuffleAndJoinDoesntMemoryLeak(is.hail.expr.ir.TableIRSuite). Gradle suite > Gradle test > is.hail.expr.ir.TableIRSuite.testShuffleAndJoinDoesntMemoryLeak PASSED; Running test: Test method testBufferWriteReadDoubles(is.hail.annotations.UnsafeSuite). Gradle suite > Gradle test > is.hail.annotations.UnsafeSuite.testBufferWriteReadDoubles PASSED; Running test: Test method testCodec(is.hail.annotations.UnsafeSuite); #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x00007fe4a85738ec, pid=23790, tid=0x00007fe48cdfa700; #; # JRE version: OpenJDK Runtime Environment (8.0_181-b13) (build 1.8.0_181-8u181-b13-0ubuntu0.18.04.1-b13); # Java VM: OpenJDK 64-Bit Server VM (25.181-b13 mixed mode linux-amd64 compressed oops); # Problematic frame:; # J 9008 C1 is.hail.annotations.UnsafeRow$.readBinary(Lis/hail/annotations/Region;J)[B (39 bytes) @ 0x00007fe4a85738ec [0x00007fe4a8573600+0x2ec]; #; # Core dump written. Default location: /home/BROAD.MIT.EDU/cvittal/src/hail/hail/core or core.23790 (max size 9223372036854775 kB). To ensure a full core dump, try ""ulimit -c unlimited"" before starting Java again; #; # An error report file with more information is saved as:; # /home/BROAD.MIT.EDU/cvittal",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4718:9456,Unsafe,UnsafeSuite,9456,https://hail.is,https://github.com/hail-is/hail/issues/4718,1,['Unsafe'],['UnsafeSuite']
Safety,"than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI0M2ViODJhZS04ZDkwLTRjZWUtYjIzMS01ZDMyYmZiZWM4OWEiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjQzZWI4MmFlLThkOTAtNGNlZS1iMjMxLTVkMzJiZmJlYzg5YSJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""43eb82ae-8d90-4cee-b231-5d32bfbec89a"",""prPublicId"":""43eb82ae-8d90-4cee-b231-5d32bfbec89a"",""dependencies"":[{""name"":""jinja2"",""from"":""3.1.2"",""to"":""3.1.3""}],""packageManager"":""pip"",""projectPublicId"":""5ecb4152-94d0-44ff-86c6-21e542bb123d"",""projectUrl"":""https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-JINJA2-6150717""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""pr-warning-shown"",""priorityScore""],""priorityScoreList"":[556],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Cross-site Scripting (XSS)](https://learn.snyk.io/lesson/xss/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14136:3369,remediat,remediationStrategy,3369,https://hail.is,https://github.com/hail-is/hail/pull/14136,1,['remediat'],['remediationStrategy']
Safety,"than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJlOTc1OTMyYy1kNmNhLTQ0NTUtYmU4ZC04NzY1ZGY0MTZjMWMiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImU5NzU5MzJjLWQ2Y2EtNDQ1NS1iZThkLTg3NjVkZjQxNmMxYyJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""e975932c-d6ca-4455-be8d-8765df416c1c"",""prPublicId"":""e975932c-d6ca-4455-be8d-8765df416c1c"",""dependencies"":[{""name"":""jinja2"",""from"":""3.1.2"",""to"":""3.1.3""}],""packageManager"":""pip"",""projectPublicId"":""20159ae6-a5aa-42fa-845a-c89f5bcbf999"",""projectUrl"":""https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-JINJA2-6150717""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""pr-warning-shown"",""priorityScore""],""priorityScoreList"":[556],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Cross-site Scripting (XSS)](https://learn.snyk.io/lesson/xss/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14141:3687,remediat,remediationStrategy,3687,https://hail.is,https://github.com/hail-is/hail/pull/14141,1,['remediat'],['remediationStrategy']
Safety,"than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJlYTQ5ODFkZC02M2FmLTQ4YzYtYTIwMC05NjkyZjg2ZTlhNjIiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImVhNDk4MWRkLTYzYWYtNDhjNi1hMjAwLTk2OTJmODZlOWE2MiJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/b7c31419-ec34-40f1-8bc6-ad8303fb329b?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/b7c31419-ec34-40f1-8bc6-ad8303fb329b?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""ea4981dd-63af-48c6-a200-9692f86e9a62"",""prPublicId"":""ea4981dd-63af-48c6-a200-9692f86e9a62"",""dependencies"":[{""name"":""jinja2"",""from"":""3.1.2"",""to"":""3.1.3""}],""packageManager"":""pip"",""projectPublicId"":""b7c31419-ec34-40f1-8bc6-ad8303fb329b"",""projectUrl"":""https://app.snyk.io/org/danking/project/b7c31419-ec34-40f1-8bc6-ad8303fb329b?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-JINJA2-6150717""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""pr-warning-shown"",""priorityScore""],""priorityScoreList"":[556],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Cross-site Scripting (XSS)](https://learn.snyk.io/lesson/xss/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14140:3243,remediat,remediationStrategy,3243,https://hail.is,https://github.com/hail-is/hail/pull/14140,1,['remediat'],['remediationStrategy']
Safety,"the entire output in memory which is likely to cause OOMs. For reasons that are not entirely clear to me, sometimes these OOMs get muffled by our system and instead lead to non-termination. I vaguely remember this happening before with `using`. I suspect there is something somewhat subtle wrong with that method, but I am not certain. Anyway, there are two big changes here:; 1. Do not buffer the entire request body in memory when writing to memory.; 2. Because of (1) we have to pull retry behavior all the way up to the top-level where we know how to recreate the body.; 3. Because of (2) it is easier to provide a `write(url)(writerFunction)` style API, which I do here.; 4. Again, because of (2), and because I want to preserve the file-object-like interface, I added a somewhat funky anonymous class which uses a second thread to facilitate the movement of data written into the OutputStream returned by `create` into the OutputStream of the HTTP connection. Point (4) probably bears more explanation. The root issue is the bad Apache HTTP Client interface. Instead of `request` returning an OutputStream, it takes an ""entity"". An entity knows how to write itself into the OutputStream of an HTTP request. This works fine if the ""writer"" code is pased as a function (as in my new `write` method), but that does not work if the control flow looks like:. f = create(...); f.write(...); r.close(). We avoid this limited API by initiating the request in a second thread which will eventually block waiting to receive data from a PipedInputStream. That PipedInputStream produces the data written to a PipedOutputStream. The `create` call returns a positioned OutputStream which just writes data into the PipedOutputStream and handles cleaning up the thread when it is closed. In a multi-core system, network requests should proceed in parallel to the client code. In a single-core system, the written data will buffer until `close` is called which will definitely yield control to the other thread.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12689:1442,avoid,avoid,1442,https://hail.is,https://github.com/hail-is/hail/pull/12689,2,['avoid'],['avoid']
Safety,"the following tests causes a segfault:. ```python; def test_agg_table_take(self):; ht = hl.utils.range_table(10).annotate(x = 'a'); ht.aggregate(agg.take(ht.x, 2)); ```. *only* as long as you run the test `test_init_hail_context_twice` in the same execution, i.e. ```; hail/python $ pytest -k 'test_init_hail_context_twice or test_agg_table_take'; platform darwin -- Python 3.6.0, pytest-4.5.0, py-1.8.0, pluggy-0.12.0; collected 653 items / 651 deselected / 2 selected ; test/hail/test_context.py . [ 50%]; test/hail/expr/test_expr.py F [100%]. .... # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x000000010ac8bbe2, pid=92110, tid=0x0000000000013d03; #; # JRE version: Java(TM) SE Runtime Environment (8.0_211-b12) (build 1.8.0_211-b12); # Java VM: Java HotSpot(TM) 64-Bit Server VM (25.211-b12 mixed mode bsd-amd64 compressed oops); # Problematic frame:; # J 5335 C1 is.hail.annotations.Region$.loadInt(J)I (5 bytes) @ 0x000000010ac8bbe2 [0x000000010ac8bb40+0xa2]; #; # Failed to write core dump. Core dumps have been disabled. To enable core dumping, try ""ulimit -c unlimited"" before starting Java again; #; # An error report file with more information is saved as:; # /Users/mturner/Documents/hail/hail/python/hs_err_pid92110.log; Compiled method (c1) 4061 5335 3 is.hail.annotations.Region$::loadInt (5 bytes); total in heap [0x000000010ac8b9d0,0x000000010ac8bd78] = 936; relocation [0x000000010ac8baf8,0x000000010ac8bb28] = 48; main code [0x000000010ac8bb40,0x000000010ac8bc60] = 288; stub code [0x000000010ac8bc60,0x000000010ac8bcf0] = 144; oops [0x000000010ac8bcf0,0x000000010ac8bcf8] = 8; metadata [0x000000010ac8bcf8,0x000000010ac8bd08] = 16; scopes data [0x000000010ac8bd08,0x000000010ac8bd30] = 40; scopes pcs [0x000000010ac8bd30,0x000000010ac8bd70] = 64; dependencies [0x000000010ac8bd70,0x000000010ac8bd78] = 8; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp. ....; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6860:576,detect,detected,576,https://hail.is,https://github.com/hail-is/hail/issues/6860,1,['detect'],['detected']
Safety,"the number of used bits is a (statically known) constant. We use this to ensure the number of used bits is known statically.; 	; Types:; - missingness; - treat as a type constructor `optional<T>`, i.e. base types don't encode missingness. Emits a single bit in the encoding. Can invert this bit to control whether missing values come first or last in the ordering. If missing, nothing is emitted after.; - sort-order; - treat reversing the default ordering as a type constructor `reverse<T>`; - simply inverts the encoding bitwise; - primitive types; - same as in datafusion, encoding has same size as original type; - signed integers - flip the sign bit; - floating point numbers - if sign bit is set, invert all bits, otherwise only flip the sign bit; - arrays; - before each element and after last element, emit continuation bit (0 if no more elements); - pad before each element. This prevents a variable number of missing bits packing into a byte; - strings and byte-arrays; - simply use null-terminated strings (being careful to do this in a unicode-safe way); - structs; - simply concatenate element encodings. safe because codes are prefix-free; - key structs; - support variable length ""interval endpoints""; - e.g. for a key type `struct<t1, t2>`, the interval `[{a}, {a, b})` contains all keys with first field `a` and second field less than `b`. We break it into two ""interval endpoints"", `({a}, -1)` and `({a, b}, -1)`, which consist of a struct value which is a prefix of the key struct type, and a ""sign"". In this case, both endpoints ""lean left"".; - needed for working with partitioners at runtime; - like an array with fixed but heterogenous types and a max length; - before each element and after last element, emit two continuation bits; - `00` - end of key, leans left (less than all longer keys with this prefix); - `01` - continue, or after last key field of actual key value (not interval endpoint); - unambiguous because key value can't terminate early, and can't continue past",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14396:2192,safe,safe,2192,https://hail.is,https://github.com/hail-is/hail/issues/14396,1,['safe'],['safe']
Safety,the uri got dropped in refactoring on PR that just went in #5686. Reverted the change and added a test to cluster sanity check.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5709:114,sanity check,sanity check,114,https://hail.is,https://github.com/hail-is/hail/pull/5709,1,['sanity check'],['sanity check']
Safety,this line in OrderedRVD.coalesce:; ``` ; val newRangeBounds = newPartEnd.init.map(partitioner.rangeBounds).asInstanceOf[UnsafeIndexedSeq]; ```. Robert's stack trace:; ```; hail.utils.java.FatalError: ClassCastException: [Ljava.lang.Object; cannot be cast to is.hail.annotations.UnsafeIndexedSeq. Java stack trace:; java.lang.ClassCastException: [Ljava.lang.Object; cannot be cast to is.hail.annotations.UnsafeIndexedSeq; at is.hail.rvd.OrderedRVD.coalesce(OrderedRVD.scala:217); at is.hail.variant.MatrixTable.coalesce(MatrixTable.scala:2331); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237); at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); at py4j.Gateway.invoke(Gateway.java:280); at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); at py4j.commands.CallCommand.execute(CallCommand.java:79); at py4j.GatewayConnection.run(GatewayConnection.java:214); at java.lang.Thread.run(Thread.java:748); ```,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2731:120,Unsafe,UnsafeIndexedSeq,120,https://hail.is,https://github.com/hail-is/hail/issues/2731,3,['Unsafe'],['UnsafeIndexedSeq']
Safety,"this small PR addresses #452 . alternatively, we could only have inParX and inParY, but this introduces redundant contig checks in two of three usages.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/499:104,redund,redundant,104,https://hail.is,https://github.com/hail-is/hail/pull/499,1,['redund'],['redundant']
Safety,"thods: <code>timeout.reject()</code>,; <code>timeout.shift(delay)</code>, <code>timeout.update(deadline)</code>.</p>; </li>; <li>; <p>Deprecated synchronous context manager usage</p>; </li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/aio-libs/async-timeout/commit/5128f7f4ff73b165579006a8336978efaeeca07a""><code>5128f7f</code></a> Fix CHANGES</li>; <li><a href=""https://github.com/aio-libs/async-timeout/commit/18e718a56f9def7dc40bb9ce3a2962a8fb0c883c""><code>18e718a</code></a> Bump to 4.0.2</li>; <li><a href=""https://github.com/aio-libs/async-timeout/commit/48d1c4ce923b1da75976d7e2a6ca9234b3092c16""><code>48d1c4c</code></a> Setup towncrier</li>; <li><a href=""https://github.com/aio-libs/async-timeout/commit/2ede7d73e55f8d1a2279d78861af0009d96219fb""><code>2ede7d7</code></a> Fix annotations on <code>__exit__</code> and <code>__aexit__</code> (<a href=""https://github-redirect.dependabot.com/aio-libs/async-timeout/issues/274"">#274</a>)</li>; <li><a href=""https://github.com/aio-libs/async-timeout/commit/8685c60dc0e82ee246fbe3d1aa272d1dfe57c24c""><code>8685c60</code></a> Bump mypy from 0.910 to 0.920 (<a href=""https://github-redirect.dependabot.com/aio-libs/async-timeout/issues/273"">#273</a>)</li>; <li><a href=""https://github.com/aio-libs/async-timeout/commit/f0a0914345b224448220aeb00d71e6a04a5d24bd""><code>f0a0914</code></a> Bump twine from 3.7.0 to 3.7.1 (<a href=""https://github-redirect.dependabot.com/aio-libs/async-timeout/issues/272"">#272</a>)</li>; <li><a href=""https://github.com/aio-libs/async-timeout/commit/e5c813173b8811b30f4a30eeba56fa8808ab15bb""><code>e5c8131</code></a> [pre-commit.ci] pre-commit autoupdate (<a href=""https://github-redirect.dependabot.com/aio-libs/async-timeout/issues/271"">#271</a>)</li>; <li><a href=""https://github.com/aio-libs/async-timeout/commit/c7e10db3d0965422122bef263fb36f6fd7572330""><code>c7e10db</code></a> Fix linter configs</li>; <li><a href=""https://github.com/aio-libs/async-",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11465:4686,timeout,timeout,4686,https://hail.is,https://github.com/hail-is/hail/pull/11465,1,['timeout'],['timeout']
Safety,"thon-storage/issues/617"">#617</a>) (<a href=""https://www.github.com/googleapis/python-storage/commit/9dd78df444d21af51af7858e8958b505a26c0b79"">9dd78df</a>)</li>; </ul>; <h3>Documentation</h3>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/googleapis/python-storage/commit/8622440f216a9de36698f6af67af249a52134bd7""><code>8622440</code></a> chore(main): release 2.1.0 (<a href=""https://github-redirect.dependabot.com/googleapis/python-storage/issues/695"">#695</a>)</li>; <li><a href=""https://github.com/googleapis/python-storage/commit/46c3e66862b536393503ad213a30670f2f5e752e""><code>46c3e66</code></a> chore(python): Noxfile recognizes that tests can live in a folder (<a href=""https://github-redirect.dependabot.com/googleapis/python-storage/issues/696"">#696</a>)</li>; <li><a href=""https://github.com/googleapis/python-storage/commit/8789afaaa1b2bd6f03fae72e3d87ce004ec10129""><code>8789afa</code></a> feat: avoid authentication with storage emulator (<a href=""https://github-redirect.dependabot.com/googleapis/python-storage/issues/679"">#679</a>)</li>; <li><a href=""https://github.com/googleapis/python-storage/commit/71a453531603b442e26f1c78ab519cc0248e16c8""><code>71a4535</code></a> samples: add async upload sample (<a href=""https://github-redirect.dependabot.com/googleapis/python-storage/issues/665"">#665</a>)</li>; <li><a href=""https://github.com/googleapis/python-storage/commit/4dafc815470480ce9de7f0357e331d3fbd0ae9b7""><code>4dafc81</code></a> feat: add turbo replication support and samples (<a href=""https://github-redirect.dependabot.com/googleapis/python-storage/issues/622"">#622</a>)</li>; <li><a href=""https://github.com/googleapis/python-storage/commit/8aa4130ee068a1922161c8ca54a53a4a51d65ce0""><code>8aa4130</code></a> feat: remove python 3.6 support (<a href=""https://github-redirect.dependabot.com/googleapis/python-storage/issues/689"">#689</a>)</li>; <li><a href=""https:/",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11520:6323,avoid,avoid,6323,https://hail.is,https://github.com/hail-is/hail/pull/11520,1,['avoid'],['avoid']
Safety,"threaded JVM, we'll need to ensure the top-level; ClassLoader *does not have Hail on its classpath*. I looked briefly at this approach and found it; more work than the current approach. ---. My apologies for eliminating JVMProcess in this PR. It's an unrelated change which facilitated my; understanding worker.py. I essentially inlined JVMProcess into JVMJob and eliminated any duplicative; code. ---. After making this change I restored the tests. Some tests had bitrotted. In the process of fixing; those tests, I found a few other bugs. Fixing these lower-level bugs unlocked a number of new; tests. A couple tests (which were added since the service tests were removed) had to be marked as; failing. Here are the bugs I fixed:. 1. Correct the error message raised when tests are run in a non-main thread (we look for this; message and start an event loop for Hail's async code because asyncio refuses to start an event; loop in a non-main thread). 2. Use a `SafeRow` to copy the globals data out of a Region and into durable, GC'ed objects. 3. Re-enable serialization of GoogleStorageFS (including its private key, which we really shouldn't; do; Tim is working on it), which was broken (presumably) when we changed Scala versions. The; `var` modifier ensures the name is compiled as a JVM field. 4. Correctly convert from a `Byte` to an `Int`. By default `Byte` to `Int` conversion (which is done; automatically when you return a `Byte` from a function whose return type is `Int`) is; sign-preserving. That means that the byte `0000 1111` is converted to the `Int` 15 and the byte; `1000 1111` is converted to the `Int` -113. The contract of; [`InputStream.read`](https://docs.oracle.com/javase/8/docs/api/java/io/InputStream.html#read--); is to return the unsigned integeral value of the next `Byte` or `-1` if we've reached the end of; the stream. `DataInputStream` treats any negative value as EOS which lead to perplexing EOSes; when reading data from GCS. 5. Retain the `gs://` protocol whe",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10390:1916,Safe,SafeRow,1916,https://hail.is,https://github.com/hail-is/hail/pull/10390,1,['Safe'],['SafeRow']
Safety,"ths for static resources requests to the server -- by :user:<code>bdraco</code>.</p>; </li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/aio-libs/aiohttp/blob/master/CHANGES.rst"">aiohttp's changelog</a>.</em></p>; <blockquote>; <h1>3.9.2 (2024-01-28)</h1>; <h2>Bug fixes</h2>; <ul>; <li>; <p>Fixed server-side websocket connection leak.</p>; <p><em>Related issues and pull requests on GitHub:</em>; :issue:<code>7978</code>.</p>; </li>; <li>; <p>Fixed <code>web.FileResponse</code> doing blocking I/O in the event loop.</p>; <p><em>Related issues and pull requests on GitHub:</em>; :issue:<code>8012</code>.</p>; </li>; <li>; <p>Fixed double compress when compression enabled and compressed file exists in server file responses.</p>; <p><em>Related issues and pull requests on GitHub:</em>; :issue:<code>8014</code>.</p>; </li>; <li>; <p>Added runtime type check for <code>ClientSession</code> <code>timeout</code> parameter.</p>; <p><em>Related issues and pull requests on GitHub:</em>; :issue:<code>8021</code>.</p>; </li>; <li>; <p>Fixed an unhandled exception in the Python HTTP parser on header lines starting with a colon -- by :user:<code>pajod</code>.</p>; <p>Invalid request lines with anything but a dot between the HTTP major and minor version are now rejected.; Invalid header field names containing question mark or slash are now rejected.; Such requests are incompatible with :rfc:<code>9110#section-5.6.2</code> and are not known to be of any legitimate use.</p>; <p><em>Related issues and pull requests on GitHub:</em>; :issue:<code>8074</code>.</p>; </li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/24a6d64966d99182e95f5d3a29541ef2fec397ad""><code>24a6d64</code></a> Release v3.9.2 (<a href=""https://redirect.gi",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14212:2900,timeout,timeout,2900,https://hail.is,https://github.com/hail-is/hail/pull/14212,6,['timeout'],['timeout']
Safety,"timeout/issues/271"">#271</a>)</li>; <li><a href=""https://github.com/aio-libs/async-timeout/commit/c7e10db3d0965422122bef263fb36f6fd7572330""><code>c7e10db</code></a> Fix linter configs</li>; <li><a href=""https://github.com/aio-libs/async-timeout/commit/6af8bf421a799208b27d57c6bf69de0d998fedec""><code>6af8bf4</code></a> Bump pre-commit from 2.15 to 2.16.0 (<a href=""https://github-redirect.dependabot.com/aio-libs/async-timeout/issues/269"">#269</a>)</li>; <li><a href=""https://github.com/aio-libs/async-timeout/commit/c71bbb5b5d7330f6dabfde7a1adec30a4611c0be""><code>c71bbb5</code></a> Bump docutils from 0.18 to 0.18.1 (<a href=""https://github-redirect.dependabot.com/aio-libs/async-timeout/issues/266"">#266</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/aio-libs/async-timeout/compare/v3.0.1...v4.0.2"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=async-timeout&package-manager=pip&previous-version=3.0.1&new-version=4.0.2)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11465:6475,timeout,timeout,6475,https://hail.is,https://github.com/hail-is/hail/pull/11465,1,['timeout'],['timeout']
Safety,tions.UnsafeRow.write(UnsafeRow.scala:141); 	at com.esotericsoftware.kryo.serializers.DefaultSerializers$KryoSerializableSerializer.write(DefaultSerializers.java:505); 	at com.esotericsoftware.kryo.serializers.DefaultSerializers$KryoSerializableSerializer.write(DefaultSerializers.java:503); 	at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:628); 	at com.esotericsoftware.kryo.serializers.MapSerializer.write(MapSerializer.java:106); 	at com.esotericsoftware.kryo.serializers.MapSerializer.write(MapSerializer.java:39); 	at com.esotericsoftware.kryo.Kryo.writeObject(Kryo.java:552); 	at com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectField.java:80); 	... 10 more; Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1517); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1505); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1504); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1504); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1732); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1687); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1676); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.ap,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4215:2764,abort,abortStage,2764,https://hail.is,https://github.com/hail-is/hail/issues/4215,1,['abort'],['abortStage']
Safety,tive Method); at sun.nio.ch.Net.socket(Net.java:411); at sun.nio.ch.Net.socket(Net.java:404); at sun.nio.ch.SocketChannelImpl.<init>(SocketChannelImpl.java:105); at sun.nio.ch.SelectorProviderImpl.openSocketChannel(SelectorProviderImpl.java:60); at java.nio.channels.SocketChannel.open(SocketChannel.java:145); at org.apache.hadoop.net.StandardSocketFactory.createSocket(StandardSocketFactory.java:62); at org.apache.hadoop.hdfs.DFSOutputStream.createSocketForPipeline(DFSOutputStream.java:1531); at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.createBlockOutputStream(DFSOutputStream.java:1309); at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.nextBlockOutputStream(DFSOutputStream.java:1262); at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:448). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1889); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1876); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1876); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2110); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2059); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/9293:9275,abort,abortStage,9275,https://hail.is,https://github.com/hail-is/hail/issues/9293,1,['abort'],['abortStage']
Safety,"tm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/fa47fca0-549b-41a3-8bf7-bcda4ca9a617?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""49ddea8a-962c-4889-b800-3d64b82a0b38"",""prPublicId"":""49ddea8a-962c-4889-b800-3d64b82a0b38"",""dependencies"":[{""name"":""aiohttp"",""from"":""3.8.6"",""to"":""3.9.0""},{""name"":""ipython"",""from"":""7.34.0"",""to"":""8.10.0""},{""name"":""jupyter-server"",""from"":""1.24.0"",""to"":""2.11.2""},{""name"":""setuptools"",""from"":""39.0.1"",""to"":""65.5.1""},{""name"":""tornado"",""from"":""6.2"",""to"":""6.3.3""}],""packageManager"":""pip"",""projectPublicId"":""fa47fca0-549b-41a3-8bf7-bcda4ca9a617"",""projectUrl"":""https://app.snyk.io/org/danking/project/fa47fca0-549b-41a3-8bf7-bcda4ca9a617?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-AIOHTTP-6091621"",""SNYK-PYTHON-AIOHTTP-6091622"",""SNYK-PYTHON-IPYTHON-3318382"",""SNYK-PYTHON-JUPYTERSERVER-5862881"",""SNYK-PYTHON-JUPYTERSERVER-5862882"",""SNYK-PYTHON-JUPYTERSERVER-6099119"",""SNYK-PYTHON-SETUPTOOLS-3180412"",""SNYK-PYTHON-TORNADO-5537286"",""SNYK-PYTHON-TORNADO-5840803"",""SNYK-PYTHON-TORNADO-6041512""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""pr-warning-shown"",""priorityScore""],""priorityScoreList"":[591,591,531,444,429,501,509,384,494,539],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Improper Input Validation](https://learn.snyk.io/lesson/improper-input-validation/?loc&#x3D;fix-pr); 🦉 [Access Control Bypass](https://learn.snyk.io/lesson/broken-access-control/?loc&#x3D;fix-pr); 🦉 [Open Redirect](https://learn.snyk.io/lesson/open-redirect/?loc&#x3D;fix-pr); 🦉 [More lessons are available in Snyk Learn](https://learn.snyk.io/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14109:7356,remediat,remediationStrategy,7356,https://hail.is,https://github.com/hail-is/hail/pull/14109,1,['remediat'],['remediationStrategy']
Safety,"tnb/ukbiobank/ad/analysis/liftover/liftover.py"", line 29, in <module>; hl.export_vcf(mt,""/project/ukbiobank/imp/uk.v3.GRCh38/uk.v3.r38.chr""+chr+"".vcf.bgz""); File ""</share/pkg.7/hail/0.2.19/install/python/lib/python3.6/site-packages/decorator.py:decorator-gen-1289>"", line 2, in export_vcf; File ""/share/pkg.7/hail/0.2.19/install/hail/hail/build/distributions/hail-python.zip/hail/typecheck/check.py"", line 585, in wrapper; File ""/share/pkg.7/hail/0.2.19/install/hail/hail/build/distributions/hail-python.zip/hail/methods/impex.py"", line 513, in export_vcf; File ""/share/pkg.7/hail/0.2.19/install/hail/hail/build/distributions/hail-python.zip/hail/backend/backend.py"", line 108, in execute; File ""/share/pkg.7/spark/2.4.3/install/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py"", line 1257, in __call__; File ""/share/pkg.7/hail/0.2.19/install/hail/hail/build/distributions/hail-python.zip/hail/utils/java.py"", line 221, in deco; hail.utils.java.FatalError: SparkException: Job aborted due to stage failure: ResultStage 2 (runJob at SparkHadoopWriter.scala:78) has failed the mmChunkId{streamId=830947795015, chunkIndex=0}: java.nio.file.NoSuchFileException: /data03/hadoop/yarn/local/usercache/farrell/appcache/application_ion(UnixException.java:86) at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) at sun.nio.fs.UnixException.rethrow.nio.file.Files.newByteChannel(Files.java:361) at java.nio.file.Files.newByteChannel(Files.java:407) at org.apache.spark.shuffle.IndexShuffleBloa:382) at org.apache.spark.network.netty.NettyBlockRpcServer$$anonfun$1.apply(NettyBlockRpcServer.scala:61) at org.apache.spark.network.netty.Na.collection.convert.Wrappers$IteratorWrapper.next(Wrappers.scala:31) at org.apache.spark.network.server.OneForOneStreamManager.getChunk(OneForOn) at org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:101) at org.apache.spark.network.server.Read(AbstractChannelHandlerContext.java:362) at io.netty.channel.Abstra",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8106:3374,abort,aborted,3374,https://hail.is,https://github.com/hail-is/hail/issues/8106,1,['abort'],['aborted']
Safety,"to github.com timed out. (connect timeout=15)')': /hail-is/jgscm/archive/v0.1.13+hail.zip; ERROR: Could not install packages due to an OSError: HTTPSConnectionPool(host='github.com', port=443): Max retries exceeded with url: /hail-is/jgscm/archive/v0.1.13+hail.zip (Caused by ConnectTimeoutError(<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7fef979ce290>, 'Connection to github.com timed out. (connect timeout=15)')). Traceback (most recent call last):; File ""/etc/google-dataproc/startup-scripts/dataproc-initialization-script-0"", line 61, in <module>; safe_call(*command); File ""/etc/google-dataproc/startup-scripts/dataproc-initialization-script-0"", line 17, in safe_call; raise e; File ""/etc/google-dataproc/startup-scripts/dataproc-initialization-script-0"", line 14, in safe_call; sp.check_output(args, stderr=sp.STDOUT, **kwargs); File ""/opt/conda/default/lib/python3.11/subprocess.py"", line 466, in check_output; return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; File ""/opt/conda/default/lib/python3.11/subprocess.py"", line 571, in run; raise CalledProcessError(retcode, process.args,; subprocess.CalledProcessError: Command '('pip', 'install', 'setuptools', 'mkl<2020', 'lxml<5', 'https://github.com/hail-is/jgscm/archive/v0.1.13+hail.zip', 'ipykernel==6.22.0', 'ipywidgets==8.0.6', 'jupyter-console==6.6.3', 'nbconvert==7.3.1', 'notebook==6.5.6', 'qtconsole==5.4.2', 'aiodns==2.0.0', 'aiohttp==3.9.5', 'aiosignal==1.3.1', 'async-timeout==4.0.3', 'attrs==23.2.0', 'avro==1.11.3', 'azure-common==1.1.28', 'azure-core==1.30.2', 'azure-identity==1.17.1', 'azure-mgmt-core==1.4.0', 'azure-mgmt-storage==20.1.0', 'azure-storage-blob==12.20.0', 'bokeh==3.3.4', 'boto3==1.34.138', 'botocore==1.34.138', 'cachetools==5.3.3', 'certifi==2024.6.2', 'cffi==1.16.0', 'charset-normalizer==3.3.2', 'click==8.1.7', 'commonmark==0.9.1', 'contourpy==1.2.1', 'cryptography==42.0.8', 'decorator==4.4.2', 'deprecated==1.2.1",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14652:5120,timeout,timeout,5120,https://hail.is,https://github.com/hail-is/hail/issues/14652,2,['timeout'],['timeout']
Safety,"to replicate:; ```python; In [2]: mt = hl.import_vcf('src/test/resources/sample.vcf'); In [3]: mt.aggregate_entries(hl.agg.counter(hl.agg.explode(mt.PL))); ```; ```; Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 2.0 failed 1 times, most recent failure: Lost task 0.0 in stage 2.0 (TID 2, localhost, executor driver): java.lang.NullPointerException; 	at is.hail.codegen.generated.C1.apply(Unknown Source); 	at is.hail.codegen.generated.C1.apply(Unknown Source); 	at is.hail.expr.CM$$anonfun$runWithDelayedValues$1.apply(CM.scala:84); 	at is.hail.expr.CM$$anonfun$runWithDelayedValues$1.apply(CM.scala:82); 	at is.hail.expr.AST$$anonfun$runAggregator$1.apply(AST.scala:270); 	at is.hail.expr.AST$$anonfun$runAggregator$1.apply(AST.scala:268); 	at is.hail.methods.Aggregators$$anonfun$11.apply(Aggregators.scala:304); 	at is.hail.methods.Aggregators$$anonfun$11.apply(Aggregators.scala:300); 	at is.hail.variant.MatrixTable$$anonfun$82$$anonfun$apply$64$$anonfun$apply$65.apply(MatrixTable.scala:1743); 	at is.hail.variant.MatrixTable$$anonfun$82$$anonfun$apply$64$$anonfun$apply$65.apply(MatrixTable.scala:1741); 	at scala.collection.Iterator$class.foreach(Iterator.scala:893); 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); 	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72); 	at is.hail.annotations.UnsafeIndexedSeq.foreach(UnsafeRow.scala:51); 	at is.hail.variant.MatrixTable$$anonfun$82$$anonfun$apply$64.apply(MatrixTable.scala:1741); 	at is.hail.variant.MatrixTable$$anonfun$82$$anonfun$apply$64.apply(MatrixTable.scala:1734); 	at scala.collection.Iterator$class.foreach(Iterator.scala:893); 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); 	at is.hail.variant.MatrixTable$$anonfun$82.apply(MatrixTable.scala:1734); 	at is.hail.variant.MatrixTable$$anonfun$82.apply(MatrixTable.scala:1728); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:79",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3276:222,abort,aborted,222,https://hail.is,https://github.com/hail-is/hail/issues/3276,1,['abort'],['aborted']
Safety,"to; async context manager</p>; </li>; </ol>; <p>(<a href=""https://github-redirect.dependabot.com/aio-libs/async-timeout/issues/258"">#258</a>)</p>; </li>; <li>; <p>Make <code>Timeout</code> class available in <code>__all__</code>.</p>; </li>; </ul>; <h2>async-timeout 4.0.0</h2>; <h1>Changes</h1>; <ul>; <li>; <p>Implemented <code>timeout_at(deadline)</code> (<a href=""https://github-redirect.dependabot.com/aio-libs/async-timeout/issues/117"">#117</a>)</p>; </li>; <li>; <p>Supported <code>timeout.deadline</code> and <code>timeout.expired</code> properties.</p>; </li>; <li>; <p>Drooped <code>timeout.remaining</code> property: it can be calculated as; <code>timeout.deadline - loop.time()</code></p>; </li>; <li>; <p>Dropped <code>timeout.timeout</code> property that returns a relative timeout based on the; timeout object creation time; the absolute <code>timeout.deadline</code> should be used; instead.</p>; </li>; <li>; <p>Added the deadline modification methods: <code>timeout.reject()</code>,; <code>timeout.shift(delay)</code>, <code>timeout.update(deadline)</code>.</p>; </li>; <li>; <p>Deprecated synchronous context manager usage</p>; </li>; </ul>; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/aio-libs/async-timeout/blob/master/CHANGES.rst"">async-timeout's changelog</a>.</em></p>; <blockquote>; <h1>4.0.2 (2021-12-20)</h1>; <h2>Misc</h2>; <ul>; <li><code>[#259](https://github.com/aio-libs/async-timeout/issues/259) &lt;https://github.com/aio-libs/async-timeout/issues/259&gt;</code><em>, <code>[#274](https://github.com/aio-libs/async-timeout/issues/274) &lt;https://github.com/aio-libs/async-timeout/issues/274&gt;</code></em></li>; </ul>; <h1>4.0.1 (2121-11-10)</h1>; <ul>; <li>; <p>Fix regression:</p>; <ol>; <li>; <p>Don't raise TimeoutError from timeout object that doesn't enter into async context; manager</p>; </li>; <li>; <p>Use call_soon() for raising TimeoutError if deadline is reached on entering into",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11465:1774,timeout,timeout,1774,https://hail.is,https://github.com/hail-is/hail/pull/11465,1,['timeout'],['timeout']
Safety,tor$$anon$11.next(Iterator.scala:409); at org.apache.spark.sql.execution.datasources.FileFormatWriter$SingleDirectoryWriteTask.execute(FileFormatWriter.scala:244); at org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$org$apache$spark$sql$execution$datasources$FileFormatWriter$$executeTask$3.apply(FileFormatWriter.scala:190); at org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$org$apache$spark$sql$execution$datasources$FileFormatWriter$$executeTask$3.apply(FileFormatWriter.scala:188); at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1341); at org.apache.spark.sql.execution.datasources.FileFormatWriter$.org$apache$spark$sql$execution$datasources$FileFormatWriter$$executeTask(FileFormatWriter.scala:193); ... 8 more. Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1435); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1423); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1422); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1422); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:802); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1650); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1605); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2407:7313,abort,abortStage,7313,https://hail.is,https://github.com/hail-is/hail/issues/2407,1,['abort'],['abortStage']
Safety,tor.scala:548); 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551); 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128); 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628); 	at java.base/java.lang.Thread.run(Thread.java:829). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2673); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2609); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2608); 	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62); 	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2608); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1182); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1182); 	at scala.Option.foreach(Option.scala:407); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1182); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2861); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2803); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2792); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:952); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2236); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2257); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:22,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12936:5573,abort,abortStage,5573,https://hail.is,https://github.com/hail-is/hail/issues/12936,1,['abort'],['abortStage']
Safety,tor.scala:548); 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551); 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128); 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628); 	at java.base/java.lang.Thread.run(Thread.java:829). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2717); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2653); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2652); 	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62); 	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2652); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1189); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1189); 	at scala.Option.foreach(Option.scala:407); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1189); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2913); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2855); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2844); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:959); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2261); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2282); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:23,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14513:8749,abort,abortStage,8749,https://hail.is,https://github.com/hail-is/hail/issues/14513,1,['abort'],['abortStage']
Safety,tractIterator.toArray(Iterator.scala:1336); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:936); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:936); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2062); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2062); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGSche,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3901:7106,abort,abortStage,7106,https://hail.is,https://github.com/hail-is/hail/issues/3901,2,['abort'],['abortStage']
Safety,tractIterator.toArray(Iterator.scala:1336); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:936); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:936); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1517); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1505); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1504); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1504); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1732); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1687); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGSche,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3465:8732,abort,abortStage,8732,https://hail.is,https://github.com/hail-is/hail/issues/3465,5,['abort'],['abortStage']
Safety,"ttps://github-redirect.dependabot.com/googleapis/python-api-core/issues/385"">#385</a>) (<a href=""https://github.com/googleapis/python-api-core/commit/d84d66c2a4107f5f9a20c53e870a27fb1250ea3d"">d84d66c</a>)</li>; </ul>; <h2>v2.8.0</h2>; <h2><a href=""https://github.com/googleapis/python-api-core/compare/v2.7.3...v2.8.0"">2.8.0</a> (2022-05-18)</h2>; <h3>Features</h3>; <ul>; <li>adds support for audience in client_options (<a href=""https://github-redirect.dependabot.com/googleapis/python-api-core/issues/379"">#379</a>) (<a href=""https://github.com/googleapis/python-api-core/commit/c97c4980125a86f384cdf12720df7bb1a2adf9d2"">c97c498</a>)</li>; <li>adds support for audience in client_options. (<a href=""https://github.com/googleapis/python-api-core/commit/c97c4980125a86f384cdf12720df7bb1a2adf9d2"">c97c498</a>)</li>; </ul>; <h2>v2.7.3</h2>; <h3><a href=""https://github.com/googleapis/python-api-core/compare/v2.7.2...v2.7.3"">2.7.3</a> (2022-04-29)</h3>; <h3>Bug Fixes</h3>; <ul>; <li>Avoid AttributeError if grpcio-status is not installed (<a href=""https://github-redirect.dependabot.com/googleapis/python-api-core/issues/370"">#370</a>) (<a href=""https://github.com/googleapis/python-api-core/commit/022add16266f9c07f0f88eea13472cc2e0bfc991"">022add1</a>)</li>; </ul>; <h2>v2.7.2</h2>; <h3><a href=""https://github.com/googleapis/python-api-core/compare/v2.7.1...v2.7.2"">2.7.2</a> (2022-04-13)</h3>; <h3>Bug Fixes</h3>; <ul>; <li>allow grpc without grpcio-status (<a href=""https://github-redirect.dependabot.com/googleapis/python-api-core/issues/355"">#355</a>) (<a href=""https://github.com/googleapis/python-api-core/commit/112049e79f5a5b0a989d85d438a1bd29485f46f7"">112049e</a>)</li>; <li>remove dependency on pkg_resources (<a href=""https://github-redirect.dependabot.com/googleapis/python-api-core/issues/361"">#361</a>) (<a href=""https://github.com/googleapis/python-api-core/commit/523dbd0b10d37ffcf83fa751f0bad313f162abf1"">523dbd0</a>)</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11970:2973,Avoid,Avoid,2973,https://hail.is,https://github.com/hail-is/hail/pull/11970,1,['Avoid'],['Avoid']
Safety,"ttps://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10177"">#10177</a>: std domain: Disallow to refer an inline target via; :rst:role:<code>ref</code> role</li>; </ul>; <h2>Deprecated</h2>; <ul>; <li><code>sphinx.ext.napoleon.docstring.GoogleDocstring._qualify_name()</code></li>; </ul>; <h2>Features added</h2>; <ul>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10260"">#10260</a>: Enable <code>FORCE_COLOR</code> and <code>NO_COLOR</code> for terminal colouring</li>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10234"">#10234</a>: autosummary: Add &quot;autosummary&quot; CSS class to summary tables</li>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10125"">#10125</a>: extlinks: Improve suggestion message for a reference having title</li>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10112"">#10112</a>: extlinks: Add :confval:<code>extlinks_detect_hardcoded_links</code> to enable; hardcoded links detector feature</li>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/9494"">#9494</a>, <a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/9456"">#9456</a>: html search: Add a config variable; :confval:<code>html_show_search_summary</code> to enable/disable the search summaries</li>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/9337"">#9337</a>: HTML theme, add option <code>enable_search_shortcuts</code> that enables :kbd:'/' as; a Quick search shortcut and :kbd:<code>Esc</code> shortcut that; removes search highlighting.</li>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10107"">#10107</a>: i18n: Allow to suppress translation warnings by adding <code>#noqa</code>; comment to the tail of each translation message</li>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10252"">#10252</a>: C++, support attributes",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11714:2182,detect,detector,2182,https://hail.is,https://github.com/hail-is/hail/pull/11714,2,['detect'],['detector']
Safety,"ub-redirect.dependabot.com/psf/black/issues/3168"">#3168</a>)</li>; <li>When using <code>--skip-magic-trailing-comma</code> or <code>-C</code>, trailing commas are stripped from subscript expressions with more than 1 element (<a href=""https://github-redirect.dependabot.com/psf/black/issues/3209"">#3209</a>)</li>; <li>Implicitly concatenated strings inside a list, set, or tuple are now wrapped inside parentheses (<a href=""https://github-redirect.dependabot.com/psf/black/issues/3162"">#3162</a>)</li>; <li>Fix a string merging/split issue when a comment is present in the middle of implicitly concatenated strings on its own line (<a href=""https://github-redirect.dependabot.com/psf/black/issues/3227"">#3227</a>)</li>; </ul>; <h3><em>Blackd</em></h3>; <ul>; <li><code>blackd</code> now supports enabling the preview style via the <code>X-Preview</code> header (<a href=""https://github-redirect.dependabot.com/psf/black/issues/3217"">#3217</a>)</li>; </ul>; <h3>Configuration</h3>; <ul>; <li>Black now uses the presence of debug f-strings to detect target version (<a href=""https://github-redirect.dependabot.com/psf/black/issues/3215"">#3215</a>)</li>; <li>Fix misdetection of project root and verbose logging of sources in cases involving <code>--stdin-filename</code> (<a href=""https://github-redirect.dependabot.com/psf/black/issues/3216"">#3216</a>)</li>; <li>Immediate <code>.gitignore</code> files in source directories given on the command line are now also respected, previously only <code>.gitignore</code> files in the project root and automatically discovered directories were respected (<a href=""https://github-redirect.dependabot.com/psf/black/issues/3237"">#3237</a>)</li>; </ul>; <h3>Documentation</h3>; <ul>; <li>Recommend using BlackConnect in IntelliJ IDEs (<a href=""https://github-redirect.dependabot.com/psf/black/issues/3150"">#3150</a>)</li>; </ul>; <h3>Integrations</h3>; <ul>; <li>Vim plugin: prefix messages with <code>Black: </code> so it's clear they come from Black (<a href=""ht",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12174:2921,detect,detect,2921,https://hail.is,https://github.com/hail-is/hail/pull/12174,1,['detect'],['detect']
Safety,"ub.com/aio-libs/aiohttp) from 3.9.1 to 3.9.2.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/aio-libs/aiohttp/releases"">aiohttp's releases</a>.</em></p>; <blockquote>; <h2>3.9.2</h2>; <h2>Bug fixes</h2>; <ul>; <li>; <p>Fixed server-side websocket connection leak.</p>; <p><em>Related issues and pull requests on GitHub:</em>; <a href=""https://redirect.github.com/aio-libs/aiohttp/issues/7978"">#7978</a>.</p>; </li>; <li>; <p>Fixed <code>web.FileResponse</code> doing blocking I/O in the event loop.</p>; <p><em>Related issues and pull requests on GitHub:</em>; <a href=""https://redirect.github.com/aio-libs/aiohttp/issues/8012"">#8012</a>.</p>; </li>; <li>; <p>Fixed double compress when compression enabled and compressed file exists in server file responses.</p>; <p><em>Related issues and pull requests on GitHub:</em>; <a href=""https://redirect.github.com/aio-libs/aiohttp/issues/8014"">#8014</a>.</p>; </li>; <li>; <p>Added runtime type check for <code>ClientSession</code> <code>timeout</code> parameter.</p>; <p><em>Related issues and pull requests on GitHub:</em>; <a href=""https://redirect.github.com/aio-libs/aiohttp/issues/8021"">#8021</a>.</p>; </li>; <li>; <p>Fixed an unhandled exception in the Python HTTP parser on header lines starting with a colon -- by :user:<code>pajod</code>.</p>; <p>Invalid request lines with anything but a dot between the HTTP major and minor version are now rejected.; Invalid header field names containing question mark or slash are now rejected.; Such requests are incompatible with :rfc:<code>9110#section-5.6.2</code> and are not known to be of any legitimate use.</p>; <p><em>Related issues and pull requests on GitHub:</em>; <a href=""https://redirect.github.com/aio-libs/aiohttp/issues/8074"">#8074</a>.</p>; </li>; <li>; <p>Improved validation of paths for static resources requests to the server -- by :user:<code>bdraco</code>.</p>; </li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14212:1058,timeout,timeout,1058,https://hail.is,https://github.com/hail-is/hail/pull/14212,6,['timeout'],['timeout']
Safety,"ues/274&gt;</code></em></li>; </ul>; <h1>4.0.1 (2121-11-10)</h1>; <ul>; <li>; <p>Fix regression:</p>; <ol>; <li>; <p>Don't raise TimeoutError from timeout object that doesn't enter into async context; manager</p>; </li>; <li>; <p>Use call_soon() for raising TimeoutError if deadline is reached on entering into; async context manager</p>; </li>; </ol>; <p>(<a href=""https://github-redirect.dependabot.com/aio-libs/async-timeout/issues/258"">#258</a>)</p>; </li>; <li>; <p>Make <code>Timeout</code> class available in <code>__all__</code>.</p>; </li>; </ul>; <h1>4.0.0 (2021-11-01)</h1>; <ul>; <li>; <p>Implemented <code>timeout_at(deadline)</code> (<a href=""https://github-redirect.dependabot.com/aio-libs/async-timeout/issues/117"">#117</a>)</p>; </li>; <li>; <p>Supported <code>timeout.deadline</code> and <code>timeout.expired</code> properties.</p>; </li>; <li>; <p>Dropped <code>timeout.remaining</code> property: it can be calculated as; <code>timeout.deadline - loop.time()</code></p>; </li>; <li>; <p>Dropped <code>timeout.timeout</code> property that returns a relative timeout based on the; timeout object creation time; the absolute <code>timeout.deadline</code> should be used; instead.</p>; </li>; <li>; <p>Added the deadline modification methods: <code>timeout.reject()</code>,; <code>timeout.shift(delay)</code>, <code>timeout.update(deadline)</code>.</p>; </li>; <li>; <p>Deprecated synchronous context manager usage</p>; </li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/aio-libs/async-timeout/commit/5128f7f4ff73b165579006a8336978efaeeca07a""><code>5128f7f</code></a> Fix CHANGES</li>; <li><a href=""https://github.com/aio-libs/async-timeout/commit/18e718a56f9def7dc40bb9ce3a2962a8fb0c883c""><code>18e718a</code></a> Bump to 4.0.2</li>; <li><a href=""https://github.com/aio-libs/async-timeout/commit/48d1c4ce923b1da75976d7e2a6ca9234b3092c16""><code>48d1c4c</code></a> Setup towncrier</li>; <li><a href=""https://github.com/",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11465:3477,timeout,timeout,3477,https://hail.is,https://github.com/hail-is/hail/pull/11465,1,['timeout'],['timeout']
Safety,"uite). Gradle suite > Gradle test > is.hail.nativecode.NativeCodeSuite.testNativePtr PASSED; Running test: Test method testNativeUpcall(is.hail.nativecode.NativeCodeSuite); DEBUG: Logging set_test_msg ... Gradle suite > Gradle test > is.hail.nativecode.NativeCodeSuite.testNativeUpcall PASSED; Running test: Test method testObjectArray(is.hail.nativecode.NativeCodeSuite). Gradle suite > Gradle test > is.hail.nativecode.NativeCodeSuite.testObjectArray PASSED; Running test: Test method testShuffleAndJoinDoesntMemoryLeak(is.hail.expr.ir.TableIRSuite). Gradle suite > Gradle test > is.hail.expr.ir.TableIRSuite.testShuffleAndJoinDoesntMemoryLeak PASSED; Running test: Test method testBufferWriteReadDoubles(is.hail.annotations.UnsafeSuite). Gradle suite > Gradle test > is.hail.annotations.UnsafeSuite.testBufferWriteReadDoubles PASSED; Running test: Test method testCodec(is.hail.annotations.UnsafeSuite); #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x00007fe4a85738ec, pid=23790, tid=0x00007fe48cdfa700; #; # JRE version: OpenJDK Runtime Environment (8.0_181-b13) (build 1.8.0_181-8u181-b13-0ubuntu0.18.04.1-b13); # Java VM: OpenJDK 64-Bit Server VM (25.181-b13 mixed mode linux-amd64 compressed oops); # Problematic frame:; # J 9008 C1 is.hail.annotations.UnsafeRow$.readBinary(Lis/hail/annotations/Region;J)[B (39 bytes) @ 0x00007fe4a85738ec [0x00007fe4a8573600+0x2ec]; #; # Core dump written. Default location: /home/BROAD.MIT.EDU/cvittal/src/hail/hail/core or core.23790 (max size 9223372036854775 kB). To ensure a full core dump, try ""ulimit -c unlimited"" before starting Java again; #; # An error report file with more information is saved as:; # /home/BROAD.MIT.EDU/cvittal/src/hail/hail/hs_err_pid23790.log; Compiled method (c1) 33969 8500 2 is.hail.annotations.UnsafeRow$::readLocus (78 bytes); total in heap [0x00007fe4a8b81810,0x00007fe4a8b83430] = 7200; relocation [0x00007fe4a8b81938,0x00007fe4a8b81a98] = 352; main code [0x00007fe4a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4718:9622,Unsafe,UnsafeSuite,9622,https://hail.is,https://github.com/hail-is/hail/issues/4718,2,"['Unsafe', 'detect']","['UnsafeSuite', 'detected']"
Safety,ul>; <h2>Bugfixes</h2>; <ul>; <li>Raise a ClientResponseError instead of an AssertionError for a blank; HTTP Reason Phrase.; <code>[#3532](https://github.com/aio-libs/aiohttp/issues/3532) &lt;https://github.com/aio-libs/aiohttp/issues/3532&gt;</code>_</li>; <li>Fix <code>web_middlewares.normalize_path_middleware</code> behavior for patch without slash.; <code>[#3669](https://github.com/aio-libs/aiohttp/issues/3669) &lt;https://github.com/aio-libs/aiohttp/issues/3669&gt;</code>_</li>; <li>Fix overshadowing of overlapped sub-applications prefixes.; <code>[#3701](https://github.com/aio-libs/aiohttp/issues/3701) &lt;https://github.com/aio-libs/aiohttp/issues/3701&gt;</code>_</li>; <li>Make <code>BaseConnector.close()</code> a coroutine and wait until the client closes all connections. Drop deprecated &quot;with Connector():&quot; syntax.; <code>[#3736](https://github.com/aio-libs/aiohttp/issues/3736) &lt;https://github.com/aio-libs/aiohttp/issues/3736&gt;</code>_</li>; <li>Reset the <code>sock_read</code> timeout each time data is received for a <code>aiohttp.client</code> response.; <code>[#3808](https://github.com/aio-libs/aiohttp/issues/3808) &lt;https://github.com/aio-libs/aiohttp/issues/3808&gt;</code>_</li>; <li>Fixed type annotation for add_view method of UrlDispatcher to accept any subclass of View; <code>[#3880](https://github.com/aio-libs/aiohttp/issues/3880) &lt;https://github.com/aio-libs/aiohttp/issues/3880&gt;</code>_</li>; <li>Fixed querying the address families from DNS that the current host supports.; <code>[#5156](https://github.com/aio-libs/aiohttp/issues/5156) &lt;https://github.com/aio-libs/aiohttp/issues/5156&gt;</code>_</li>; <li>Change return type of MultipartReader.<strong>aiter</strong>() and BodyPartReader.<strong>aiter</strong>() to AsyncIterator.; <code>[#5163](https://github.com/aio-libs/aiohttp/issues/5163) &lt;https://github.com/aio-libs/aiohttp/issues/5163&gt;</code>_</li>; <li>Provide x86 Windows wheels.; <code>[#5230](https://github.com,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10115:1696,timeout,timeout,1696,https://hail.is,https://github.com/hail-is/hail/pull/10115,1,['timeout'],['timeout']
Safety,"ulate_concordance; mt = unphase_mt(mt.filter_cols(hl.is_defined(dup_ht[mt.s]) | (mt.s == 'NA12878') | (mt.s == 'syndip'))); File ""<decorator-gen-510>"", line 2, in filter_cols; File ""/tmp/478e9775e51b49afb6828e4a014c7a7a/hail-devel-d7e032a87341.zip/hail/typecheck/check.py"", line 480, in _typecheck; File ""/tmp/478e9775e51b49afb6828e4a014c7a7a/hail-devel-d7e032a87341.zip/hail/matrixtable.py"", line 1419, in filter_cols; File ""/tmp/478e9775e51b49afb6828e4a014c7a7a/hail-devel-d7e032a87341.zip/hail/matrixtable.py"", line 2241, in _process_joins; File ""/tmp/478e9775e51b49afb6828e4a014c7a7a/hail-devel-d7e032a87341.zip/hail/table.py"", line 1233, in <lambda>; File ""/usr/lib/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py"", line 1133, in __call__; File ""/tmp/478e9775e51b49afb6828e4a014c7a7a/hail-devel-d7e032a87341.zip/hail/utils/java.py"", line 196, in deco; hail.utils.java.FatalError: AssertionError: assertion failed. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 250 in stage 16.0 failed 20 times, most recent failure: Lost task 250.19 in stage 16.0 (TID 5993, exomes2-sw-znhp.c.broad-mpg-gnomad.internal, executor 1): java.lang.AssertionError: assertion failed; 	at scala.Predef$.assert(Predef.scala:156); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$10$$anon$3.next(OrderedRVD.scala:751); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$10$$anon$3.next(OrderedRVD.scala:733); 	at scala.collection.Iterator$$anon$1.next(Iterator.scala:1010); 	at scala.collection.Iterator$$anon$1.head(Iterator.scala:997); 	at is.hail.utils.richUtils.RichIterator$$anon$5.value(RichIterator.scala:18); 	at is.hail.utils.StagingIterator.value(FlipbookIterator.scala:47); 	at is.hail.utils.FlipbookIterator$$anon$5.value(FlipbookIterator.scala:167); 	at is.hail.utils.FlipbookIterator$$anon$5.isValid(FlipbookIterator.scala:168); 	at is.hail.utils.StagingIterator.isValid(FlipbookIterator.scala:46); 	at is.hail.utils.FlipbookIterator.exhaust(FlipbookIterator.scala:110);",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3235:1421,abort,aborted,1421,https://hail.is,https://github.com/hail-is/hail/issues/3235,1,['abort'],['aborted']
Safety,un$13.apply(RDD.scala:936); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:936); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2062); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2062); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1658); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.ap,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3901:7204,abort,abortStage,7204,https://hail.is,https://github.com/hail-is/hail/issues/3901,2,['abort'],['abortStage']
Safety,un$13.apply(RDD.scala:936); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:936); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1517); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1505); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1504); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1504); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1732); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1687); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1676); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.ap,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3465:8830,abort,abortStage,8830,https://hail.is,https://github.com/hail-is/hail/issues/3465,5,['abort'],['abortStage']
Safety,"ure storage. Basic summary of the changes:; 	- Update `AzureAsyncFS` url parsing function to look for and separate out a SAS-token-like query string. Note: made fairly specific to SAS tokens - generic detection of query string syntax interferes with glob support and '?' characters in file names; 	- Added `generate_sas_token` convenience function to `AzureAsyncFS`. Adds new `azure-mgmt-storage` package requirement.; 	- Updated `AzureAsyncFS` to use `(account, credential)` tuple as internal `BlobServiceClient` cache key; 	- Updated `AzureAsyncFSURL` and `AzureFileListEntry` to track the token separately from the name, and extend the base classes to allow returning url with or without a token ; 	- Update `RouterFS.ls` function and associated `listfiles` function to allow for trailing query strings during path traversal ; 	- Change to existing behavior: `LocalAsyncFSURL.__str__`no longer returns 'file:' prefix. Done to make `str()` output be appropriate for input to `fs` functions across all subclasses; 	- Updated `inter_cloud/test_fs.py` to generically use query-string-friendly file path building functions; - Updated InputResource to not include the SAS token as part of the destination file name . `test_fs.py` has been updated to respect the new model, where it is no longer safe to extend URLs by just appending new segments with + ""/"" because there may be a query string. But actually running those tests for the SAS case will require some new test variables to allow the test code to generate SAS tokens (`build.yaml/test_hail_python_fs`): ; ```; export HAIL_TEST_AZURE_ACCOUNT=hailtest; export HAIL_TEST_AZURE_CONTAINER=hail-test-4nxei; # Required for SAS testing on Azure; export HAIL_TEST_AZURE_RESGRP=hailms02; export HAIL_TEST_AZURE_SUBID=12ab51c6-da79-4a99-8dec-3d2decc97343; ```; So the SAS case is disabled for now (`test_fs.py`):; ```; @pytest.fixture(params=['file', 'gs', 's3', 'hail-az', 'router/file', 'router/gs', 'router/s3', 'router/hail-az']) # 'sas/hail-az'; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12877:1407,safe,safe,1407,https://hail.is,https://github.com/hail-is/hail/pull/12877,1,['safe'],['safe']
Safety,"urllib3/urllib3/issues/883"">#883</a>, <a href=""https://redirect.github.com/urllib3/urllib3/issues/2336"">#2336</a>).</li>; <li>Removed fallback on certificate <code>commonName</code> in <code>match_hostname()</code> function. This behavior was deprecated in May 2000 in RFC 2818. Instead only <code>subjectAltName</code> is used to verify the hostname by default. To enable verifying the hostname against <code>commonName</code> use <code>SSLContext.hostname_checks_common_name = True</code> (<a href=""https://redirect.github.com/urllib3/urllib3/issues/2113"">#2113</a>).</li>; <li>Removed support for Python with an <code>ssl</code> module compiled with LibreSSL, CiscoSSL, wolfSSL, and all other OpenSSL alternatives. Python is moving to require OpenSSL with PEP 644 (<a href=""https://redirect.github.com/urllib3/urllib3/issues/2168"">#2168</a>).</li>; <li>Removed support for OpenSSL versions earlier than 1.1.1 or that don't have SNI support. When an incompatible OpenSSL version is detected an <code>ImportError</code> is raised (<a href=""https://redirect.github.com/urllib3/urllib3/issues/2168"">#2168</a>).</li>; <li>Removed the list of default ciphers for OpenSSL 1.1.1+ and SecureTransport as their own defaults are already secure (<a href=""https://redirect.github.com/urllib3/urllib3/issues/2082"">#2082</a>).</li>; <li>Removed <code>urllib3.contrib.appengine.AppEngineManager</code> and support for Google App Engine Standard Environment (<a href=""https://redirect.github.com/urllib3/urllib3/issues/2044"">#2044</a>).</li>; <li>Removed deprecated <code>Retry</code> options <code>method_whitelist</code>, <code>DEFAULT_REDIRECT_HEADERS_BLACKLIST</code> (<a href=""https://redirect.github.com/urllib3/urllib3/issues/2086"">#2086</a>).</li>; <li>Removed <code>urllib3.HTTPResponse.from_httplib</code> (<a href=""https://redirect.github.com/urllib3/urllib3/issues/2648"">#2648</a>).</li>; <li>Removed default value of <code>None</code> for the <code>request_context</code> parameter of <code>urllib3.Poo",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13768:4510,detect,detected,4510,https://hail.is,https://github.com/hail-is/hail/pull/13768,3,['detect'],['detected']
Safety,use cp instead of rsync to avoid updating pr-builder,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5929:27,avoid,avoid,27,https://hail.is,https://github.com/hail-is/hail/pull/5929,1,['avoid'],['avoid']
Safety,use nonExtremeDouble to avoid test failures,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2366:24,avoid,avoid,24,https://hail.is,https://github.com/hail-is/hail/pull/2366,1,['avoid'],['avoid']
Safety,"ut `count`ed before that, so I don't think that was the problem):. `ukbb_in_tgp = ukbb.filter_rows(hl.is_defined(tgp[ukbb.row_key, :]))`. ```; FatalError: ClassCastException: null. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 40.0 failed 20 times, most recent failure: Lost task 0.19 in stage 40.0 (TID 2222, pca-w-8.c.daly-ibd.internal, executor 25): java.lang.ClassCastException. Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1517); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1505); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1504); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1504); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1732); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1687); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1676); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2029); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2050); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2069); at org",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3447:1093,abort,abortStage,1093,https://hail.is,https://github.com/hail-is/hail/issues/3447,1,['abort'],['abortStage']
Safety,va:110); at java.lang.Double.parseDouble(Double.java:538); at scala.collection.immutable.StringLike$class.toDouble(StringLike.scala:284); at scala.collection.immutable.StringOps.toDouble(StringOps.scala:29); at is.hail.io.vcf.VCFLine.parseDoubleInFormatArray(LoadVCF.scala:371); at is.hail.io.vcf.VCFLine.parseAddFormatArrayDouble(LoadVCF.scala:431); at is.hail.io.vcf.FormatParser.parseAddField(LoadVCF.scala:483); at is.hail.io.vcf.FormatParser.parse(LoadVCF.scala:514); at is.hail.io.vcf.LoadVCF$$anonfun$13.apply(LoadVCF.scala:867); at is.hail.io.vcf.LoadVCF$$anonfun$13.apply(LoadVCF.scala:848); at is.hail.io.vcf.LoadVCF$$anonfun$parseLines$1$$anon$1.hasNext(LoadVCF.scala:717); ... 35 more. Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1658); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.s,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3361:6611,abort,abortStage,6611,https://hail.is,https://github.com/hail-is/hail/issues/3361,1,['abort'],['abortStage']
Safety,"ved the code). - `.strip()` the GitHub token in case there are newlines. - print the SHA being deployed in the log statement. - add `hail-ci-build.sh` to CI, which just invokes `make test-in-cluster`(which in turn runs `test-in-cluster.sh`. - `test-in-cluster.sh` copies the secrets for testing to the expected locations and exposes the pod in which it is running with an internal service, recent changes to `site` [redirect sub URLs of ci.test.is to services named using this scheme](https://github.com/hail-is/hail/blob/master/site/hail.nginx.conf#L38-L41). GitHub uses these URLs to send updates to the CI under test about the watched repositories. - `test-locally.sh` now installs `../batch` into the currently running `pip` before testing (NB: if you edit batch and run the tests without committing the changes you've made to batch, this will pass tests but fail when pushed to a PR!). - `test-locally.sh` activates the `hail-ci` conda environment itself because it was not being propagated from the `Makefile`. I don't know why, but this is a simple fix. - `test-locally.sh` starts the ci after the repository is created. CI will print error messages if a watched repository doesn't exist. - `test/test-ci.py` now uses access tokens for all interaction with GitHub, previously it relied on the latent privileges that I and Cotton had in our environments. - `test/test-ci.py` uses a temporary, but not automatically deleted, directory when the environment variable `IN_CLUSTER` is set to `true` (to which it is set by `test-in-cluster.sh`). I noticed that, when running in a batch job pod, if an error occurred, `pytest` failed to print any error information and instead failed because the current working directory no longer existed. I found very little information on Google about this. It seems safe to not clean up temporary directories created in the batch job pod because pods are ephemeral. cc: @cseed. Assigning to @tpoterba since he has the most context on this stuff other than Cotton.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4474:2271,safe,safe,2271,https://hail.is,https://github.com/hail-is/hail/pull/4474,1,['safe'],['safe']
Safety,"veltejs/svelte/issues/6538"">#6538</a>)</li>; <li>Do not generate <code>unused-export-let</code> warning inside <code>&lt;script context=&quot;module&quot;&gt;</code> blocks (<a href=""https://github-redirect.dependabot.com/sveltejs/svelte/issues/7055"">#7055</a>)</li>; <li>Do not collapse whitespace-only CSS vars (<a href=""https://github-redirect.dependabot.com/sveltejs/svelte/issues/7152"">#7152</a>)</li>; <li>Add <code>aria-description</code> to the list of allowed ARIA attributes (<a href=""https://github-redirect.dependabot.com/sveltejs/svelte/issues/7301"">#7301</a>)</li>; <li>Fix attribute escaping during SSR (<a href=""https://github-redirect.dependabot.com/sveltejs/svelte/issues/7327"">#7327</a>)</li>; <li>Prevent <code>.innerHTML</code> optimization from being used when <code>style:</code> directive is present (<a href=""https://github-redirect.dependabot.com/sveltejs/svelte/issues/7386"">#7386</a>)</li>; </ul>; <h2>3.46.4</h2>; <ul>; <li>Avoid <code>maximum call stack size exceeded</code> errors on large components (<a href=""https://github-redirect.dependabot.com/sveltejs/svelte/issues/4694"">#4694</a>)</li>; <li>Preserve leading space with <code>preserveWhitespace: true</code> (<a href=""https://github-redirect.dependabot.com/sveltejs/svelte/issues/4731"">#4731</a>)</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/sveltejs/svelte/commit/52153dbce0237f0c36e4ff36377398d7f95276ef""><code>52153db</code></a> -&gt; v3.49.0</li>; <li><a href=""https://github.com/sveltejs/svelte/commit/3798808e7484b7eeee6acb2860c45bb2e59d84bd""><code>3798808</code></a> update changelog</li>; <li><a href=""https://github.com/sveltejs/svelte/commit/0fa0a38d5168a1767843fdb0a43c00aa30b8670f""><code>0fa0a38</code></a> [fix] export CompileOptions (<a href=""https://github-redirect.dependabot.com/sveltejs/svelte/issues/7658"">#7658</a>)</li>; <li><a href=""https://github.com/sveltejs/svelte",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12032:5831,Avoid,Avoid,5831,https://hail.is,https://github.com/hail-is/hail/pull/12032,3,['Avoid'],['Avoid']
Safety,"verwrite=True); ```. and got:. ```; Traceback (most recent call last):; File ""foo.py"", line 7, in <module>; t.write('foo.ht', overwrite=True); File ""/Users/cseed/hail/python/hail/typecheck/check.py"", line 547, in wrapper; return f(*args_, **kwargs_); File ""/Users/cseed/hail/python/hail/table.py"", line 1183, in write; self._jt.write(output, overwrite, stage_locally, _codec_spec); File ""/Users/cseed/py4j/java_gateway.py"", line 1133, in __call__; answer, self.gateway_client, self.target_id, self.name); File ""/Users/cseed/hail/python/hail/utils/java.py"", line 200, in deco; 'Error summary: %s' % (deepest, full, hail.__version__, deepest)) from None; hail.utils.java.FatalError: HailException: OrderedRVD error! Unexpected key in partition 7; Range bounds for partition 7: ([0.8599223493342859]-[0.9976076885349009]]; Key should be in partition 7: ([0.8599223493342859]-[0.9976076885349009]]; Invalid key: [0.9986274705095608]. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 7 in stage 2.0 failed 1 times, most recent failure: Lost task 7.0 in stage 2.0 (TID 23, localhost, executor driver): is.hail.utils.HailException: OrderedRVD error! Unexpected key in partition 7; Range bounds for partition 7: ([0.8599223493342859]-[0.9976076885349009]]; Key should be in partition 7: ([0.8599223493342859]-[0.9976076885349009]]; Invalid key: [0.9986274705095608]; 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:9); 	at is.hail.utils.package$.fatal(package.scala:26); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$21$$anon$3.next(OrderedRVD.scala:1031); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$21$$anon$3.next(OrderedRVD.scala:1011); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at scala.collection.Iterator$class.foreach(Iterator.scala:893); 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); 	at is.hail.io.RichContextRDDRegionValue$.writeRowsPartition(RowStore.scala:1071); 	at is.hail.io.RichContextRDDRegio",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4096:1211,abort,aborted,1211,https://hail.is,https://github.com/hail-is/hail/issues/4096,1,['abort'],['aborted']
Safety,wait for 1h for resources to be scheduled; add timeouts for pods and services; set timeout to 2x average time from a dozen recent successful runs of the step,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6082:47,timeout,timeouts,47,https://hail.is,https://github.com/hail-is/hail/pull/6082,2,['timeout'],"['timeout', 'timeouts']"
Safety,"work updates; <ul>; <li>enable <code>py3.10</code> tests</li>; <li>add <code>conda</code> dependencies</li>; <li>update pre-commit hooks</li>; <li>fix <code>pytest</code> config (<code>nbval</code>, <code>asyncio</code>)</li>; <li>fix dependencies &amp; tests</li>; <li>fix site deployment</li>; </ul>; </li>; </ul>; <h2>tqdm v4.62.3 stable</h2>; <ul>; <li>fix minor typo (<a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1246"">#1246</a>)</li>; <li>minor example fix (<a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1246"">#1246</a>)</li>; <li>misc tidying &amp; refactoring</li>; <li>misc build/dev framework updates; <ul>; <li>update dependencies</li>; <li>update linters</li>; <li>update docs deployment branches</li>; </ul>; </li>; <li>misc test/ci updates; <ul>; <li>test forks</li>; <li>tidy OS &amp; Python version tests</li>; <li>bump primary python version 3.7 =&gt; 3.8</li>; <li>beta py3.10 testing</li>; <li>fix py2.7 tests</li>; <li>better timeout handling</li>; </ul>; </li>; </ul>; <h2>tqdm v4.62.2 stable</h2>; <ul>; <li>fix notebook memory leak (<a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1216"">#1216</a>)</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/tqdm/tqdm/commit/6791e8c5b3d6c30bdd2060c346996bfb5a6f10d1""><code>6791e8c</code></a> bump version, merge pull request <a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1366"">#1366</a> from tqdm/devel</li>; <li><a href=""https://github.com/tqdm/tqdm/commit/754186291e6b4e28ea8b56c9493adc03bf14c404""><code>7541862</code></a> tests: hotfix skip windows errors</li>; <li><a href=""https://github.com/tqdm/tqdm/commit/8fb3d91f561e2a286a7fda13291eda16613dac39""><code>8fb3d91</code></a> fix ipywidgets&gt;=8 display</li>; <li><a href=""https://github.com/tqdm/tqdm/commit/05e3d32a5fc8559e133e6d627d44afda93018637""><code>05e3d32</code></a> fix jupyterla",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12260:3667,timeout,timeout,3667,https://hail.is,https://github.com/hail-is/hail/pull/12260,1,['timeout'],['timeout']
Safety,"work updates; <ul>; <li>enable <code>py3.10</code> tests</li>; <li>add <code>conda</code> dependencies</li>; <li>update pre-commit hooks</li>; <li>fix <code>pytest</code> config (<code>nbval</code>, <code>asyncio</code>)</li>; <li>fix dependencies &amp; tests</li>; <li>fix site deployment</li>; </ul>; </li>; </ul>; <h2>tqdm v4.62.3 stable</h2>; <ul>; <li>fix minor typo (<a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1246"">#1246</a>)</li>; <li>minor example fix (<a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1246"">#1246</a>)</li>; <li>misc tidying &amp; refactoring</li>; <li>misc build/dev framework updates; <ul>; <li>update dependencies</li>; <li>update linters</li>; <li>update docs deployment branches</li>; </ul>; </li>; <li>misc test/ci updates; <ul>; <li>test forks</li>; <li>tidy OS &amp; Python version tests</li>; <li>bump primary python version 3.7 =&gt; 3.8</li>; <li>beta py3.10 testing</li>; <li>fix py2.7 tests</li>; <li>better timeout handling</li>; </ul>; </li>; </ul>; <h2>tqdm v4.62.2 stable</h2>; <ul>; <li>fix notebook memory leak (<a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1216"">#1216</a>)</li>; <li>fix <code>contrib.concurrent</code> with generators (<a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1233"">#1233</a> &lt;- <a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1231"">#1231</a>)</li>; </ul>; <h2>tqdm v4.62.1 stable</h2>; <ul>; <li><code>contrib.logging</code>: inherit existing handler output stream (<a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1191"">#1191</a>)</li>; <li>fix <code>PermissionError</code> by using <code>weakref</code> in <code>DisableOnWriteError</code> (<a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1207"">#1207</a>)</li>; <li>fix <code>contrib.telegram</code> creation rate limit handling (<a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1223"">#1223</a>, <a href=""https://github-redirect.depend",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11587:1877,timeout,timeout,1877,https://hail.is,https://github.com/hail-is/hail/pull/11587,1,['timeout'],['timeout']
Safety,"worker-pr-11438-default-g6cibyji6520-standard-9xy2q	Traceback (most recent call last):\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 969, in _wrap_create_connection\n return await self._loop.create_connection(*args, **kwargs) # type: ignore # noqa\n File ""uvloop/loop.pyx"", line 1974, in create_connection\n File ""uvloop/loop.pyx"", line 1951, in uvloop.loop.Loop.create_connection\nConnectionRefusedError: [Errno 111] Connection refused\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n File ""/usr/local/lib/python3.7/dist-packages/batch/driver/job.py"", line 449, in schedule_job\n timeout=aiohttp.ClientTimeout(total=2),\n File ""/usr/local/lib/python3.7/dist-packages/hailtop/httpx.py"", line 113, in request_and_raise_for_status\n resp = await self.client_session._request(method, url, **kwargs)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/client.py"", line 521, in _request\n req, traces=traces, timeout=real_timeout\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 535, in connect\n proto = await self._create_connection(req, traces, timeout)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 892, in _create_connection\n _, proto = await self._create_direct_connection(req, traces, timeout)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 1051, in _create_direct_connection\n raise last_exc\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 1032, in _create_direct_connection\n client_error=client_error,\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 975, in _wrap_create_connection\n raise client_error(req.connection_key, exc) from exc\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 10.128.0.11:5000 ssl:default [Connection refused]. ```. Now take a look at the worker: It takes us about nine seconds to get to; an initialized FileStore.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11451:25133,timeout,timeout,25133,https://hail.is,https://github.com/hail-is/hail/pull/11451,1,['timeout'],['timeout']
Safety,"worker-pr-11438-default-g6cibyji6520-standard-9xy2q	Traceback (most recent call last):\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 969, in _wrap_create_connection\n return await self._loop.create_connection(*args, **kwargs) # type: ignore # noqa\n File ""uvloop/loop.pyx"", line 1974, in create_connection\n File ""uvloop/loop.pyx"", line 1951, in uvloop.loop.Loop.create_connection\nConnectionRefusedError: [Errno 111] Connection refused\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n File ""/usr/local/lib/python3.7/dist-packages/batch/driver/job.py"", line 449, in schedule_job\n timeout=aiohttp.ClientTimeout(total=2),\n File ""/usr/local/lib/python3.7/dist-packages/hailtop/httpx.py"", line 113, in request_and_raise_for_status\n resp = await self.client_session._request(method, url, **kwargs)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/client.py"", line 521, in _request\n req, traces=traces, timeout=real_timeout\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 535, in connect\n proto = await self._create_connection(req, traces, timeout)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 892, in _create_connection\n _, proto = await self._create_direct_connection(req, traces, timeout)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 1051, in _create_direct_connection\n raise last_exc\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 1032, in _create_direct_connection\n client_error=client_error,\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 975, in _wrap_create_connection\n raise client_error(req.connection_key, exc) from exc\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 10.128.0.11:5000 ssl:default [Connection refused]; ERROR	2022-03-02 19:06:35,400	job.py	schedule_job:473	error while scheduling job (93, 1) on instance ba",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11451:6456,timeout,timeout,6456,https://hail.is,https://github.com/hail-is/hail/pull/11451,1,['timeout'],['timeout']
Safety,"worker-pr-11438-default-g6cibyji6520-standard-9xy2q	Traceback (most recent call last):\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 969, in _wrap_create_connection\n return await self._loop.create_connection(*args, **kwargs) # type: ignore # noqa\n File ""uvloop/loop.pyx"", line 1974, in create_connection\n File ""uvloop/loop.pyx"", line 1951, in uvloop.loop.Loop.create_connection\nConnectionRefusedError: [Errno 111] Connection refused\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n File ""/usr/local/lib/python3.7/dist-packages/batch/driver/job.py"", line 449, in schedule_job\n timeout=aiohttp.ClientTimeout(total=2),\n File ""/usr/local/lib/python3.7/dist-packages/hailtop/httpx.py"", line 113, in request_and_raise_for_status\n resp = await self.client_session._request(method, url, **kwargs)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/client.py"", line 521, in _request\n req, traces=traces, timeout=real_timeout\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 535, in connect\n proto = await self._create_connection(req, traces, timeout)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 892, in _create_connection\n _, proto = await self._create_direct_connection(req, traces, timeout)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 1051, in _create_direct_connection\n raise last_exc\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 1032, in _create_direct_connection\n client_error=client_error,\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 975, in _wrap_create_connection\n raise client_error(req.connection_key, exc) from exc\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 10.128.0.11:5000 ssl:default [Connection refused]; ERROR	2022-03-02 19:06:37,364	job.py	schedule_job:473	error while scheduling job (90, 1) on instance ba",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11451:10957,timeout,timeout,10957,https://hail.is,https://github.com/hail-is/hail/pull/11451,1,['timeout'],['timeout']
Safety,"worker-pr-11438-default-g6cibyji6520-standard-9xy2q	Traceback (most recent call last):\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 969, in _wrap_create_connection\n return await self._loop.create_connection(*args, **kwargs) # type: ignore # noqa\n File ""uvloop/loop.pyx"", line 1974, in create_connection\n File ""uvloop/loop.pyx"", line 1951, in uvloop.loop.Loop.create_connection\nConnectionRefusedError: [Errno 111] Connection refused\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n File ""/usr/local/lib/python3.7/dist-packages/batch/driver/job.py"", line 449, in schedule_job\n timeout=aiohttp.ClientTimeout(total=2),\n File ""/usr/local/lib/python3.7/dist-packages/hailtop/httpx.py"", line 113, in request_and_raise_for_status\n resp = await self.client_session._request(method, url, **kwargs)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/client.py"", line 521, in _request\n req, traces=traces, timeout=real_timeout\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 535, in connect\n proto = await self._create_connection(req, traces, timeout)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 892, in _create_connection\n _, proto = await self._create_direct_connection(req, traces, timeout)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 1051, in _create_direct_connection\n raise last_exc\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 1032, in _create_direct_connection\n client_error=client_error,\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 975, in _wrap_create_connection\n raise client_error(req.connection_key, exc) from exc\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 10.128.0.11:5000 ssl:default [Connection refused]; ERROR	2022-03-02 19:06:37,390	job.py	schedule_job:473	error while scheduling job (97, 1) on instance ba",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11451:12962,timeout,timeout,12962,https://hail.is,https://github.com/hail-is/hail/pull/11451,1,['timeout'],['timeout']
Safety,"worker-pr-11438-default-g6cibyji6520-standard-9xy2q	Traceback (most recent call last):\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 969, in _wrap_create_connection\n return await self._loop.create_connection(*args, **kwargs) # type: ignore # noqa\n File ""uvloop/loop.pyx"", line 1974, in create_connection\n File ""uvloop/loop.pyx"", line 1951, in uvloop.loop.Loop.create_connection\nConnectionRefusedError: [Errno 111] Connection refused\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n File ""/usr/local/lib/python3.7/dist-packages/batch/driver/job.py"", line 449, in schedule_job\n timeout=aiohttp.ClientTimeout(total=2),\n File ""/usr/local/lib/python3.7/dist-packages/hailtop/httpx.py"", line 113, in request_and_raise_for_status\n resp = await self.client_session._request(method, url, **kwargs)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/client.py"", line 521, in _request\n req, traces=traces, timeout=real_timeout\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 535, in connect\n proto = await self._create_connection(req, traces, timeout)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 892, in _create_connection\n _, proto = await self._create_direct_connection(req, traces, timeout)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 1051, in _create_direct_connection\n raise last_exc\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 1032, in _create_direct_connection\n client_error=client_error,\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 975, in _wrap_create_connection\n raise client_error(req.connection_key, exc) from exc\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 10.128.0.11:5000 ssl:default [Connection refused]; ERROR	2022-03-02 19:06:37,435	job.py	schedule_job:473	error while scheduling job (101, 1) on instance b",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11451:14967,timeout,timeout,14967,https://hail.is,https://github.com/hail-is/hail/pull/11451,1,['timeout'],['timeout']
Safety,"worker-pr-11438-default-g6cibyji6520-standard-9xy2q	Traceback (most recent call last):\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 969, in _wrap_create_connection\n return await self._loop.create_connection(*args, **kwargs) # type: ignore # noqa\n File ""uvloop/loop.pyx"", line 1974, in create_connection\n File ""uvloop/loop.pyx"", line 1951, in uvloop.loop.Loop.create_connection\nConnectionRefusedError: [Errno 111] Connection refused\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n File ""/usr/local/lib/python3.7/dist-packages/batch/driver/job.py"", line 449, in schedule_job\n timeout=aiohttp.ClientTimeout(total=2),\n File ""/usr/local/lib/python3.7/dist-packages/hailtop/httpx.py"", line 113, in request_and_raise_for_status\n resp = await self.client_session._request(method, url, **kwargs)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/client.py"", line 521, in _request\n req, traces=traces, timeout=real_timeout\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 535, in connect\n proto = await self._create_connection(req, traces, timeout)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 892, in _create_connection\n _, proto = await self._create_direct_connection(req, traces, timeout)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 1051, in _create_direct_connection\n raise last_exc\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 1032, in _create_direct_connection\n client_error=client_error,\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 975, in _wrap_create_connection\n raise client_error(req.connection_key, exc) from exc\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 10.128.0.11:5000 ssl:default [Connection refused]; ERROR	2022-03-02 19:06:37,447	job.py	schedule_job:473	error while scheduling job (102, 1) on instance b",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11451:16973,timeout,timeout,16973,https://hail.is,https://github.com/hail-is/hail/pull/11451,1,['timeout'],['timeout']
Safety,"worker-pr-11438-default-g6cibyji6520-standard-9xy2q	Traceback (most recent call last):\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 969, in _wrap_create_connection\n return await self._loop.create_connection(*args, **kwargs) # type: ignore # noqa\n File ""uvloop/loop.pyx"", line 1974, in create_connection\n File ""uvloop/loop.pyx"", line 1951, in uvloop.loop.Loop.create_connection\nConnectionRefusedError: [Errno 111] Connection refused\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n File ""/usr/local/lib/python3.7/dist-packages/batch/driver/job.py"", line 449, in schedule_job\n timeout=aiohttp.ClientTimeout(total=2),\n File ""/usr/local/lib/python3.7/dist-packages/hailtop/httpx.py"", line 113, in request_and_raise_for_status\n resp = await self.client_session._request(method, url, **kwargs)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/client.py"", line 521, in _request\n req, traces=traces, timeout=real_timeout\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 535, in connect\n proto = await self._create_connection(req, traces, timeout)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 892, in _create_connection\n _, proto = await self._create_direct_connection(req, traces, timeout)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 1051, in _create_direct_connection\n raise last_exc\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 1032, in _create_direct_connection\n client_error=client_error,\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 975, in _wrap_create_connection\n raise client_error(req.connection_key, exc) from exc\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 10.128.0.11:5000 ssl:default [Connection refused]; ERROR	2022-03-02 19:06:39,193	job.py	schedule_job:473	error while scheduling job (99, 1) on instance ba",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11451:21122,timeout,timeout,21122,https://hail.is,https://github.com/hail-is/hail/pull/11451,1,['timeout'],['timeout']
Safety,"worker-pr-11438-default-g6cibyji6520-standard-9xy2q	Traceback (most recent call last):\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 969, in _wrap_create_connection\n return await self._loop.create_connection(*args, **kwargs) # type: ignore # noqa\n File ""uvloop/loop.pyx"", line 1974, in create_connection\n File ""uvloop/loop.pyx"", line 1951, in uvloop.loop.Loop.create_connection\nConnectionRefusedError: [Errno 111] Connection refused\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n File ""/usr/local/lib/python3.7/dist-packages/batch/driver/job.py"", line 449, in schedule_job\n timeout=aiohttp.ClientTimeout(total=2),\n File ""/usr/local/lib/python3.7/dist-packages/hailtop/httpx.py"", line 113, in request_and_raise_for_status\n resp = await self.client_session._request(method, url, **kwargs)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/client.py"", line 521, in _request\n req, traces=traces, timeout=real_timeout\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 535, in connect\n proto = await self._create_connection(req, traces, timeout)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 892, in _create_connection\n _, proto = await self._create_direct_connection(req, traces, timeout)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 1051, in _create_direct_connection\n raise last_exc\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 1032, in _create_direct_connection\n client_error=client_error,\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 975, in _wrap_create_connection\n raise client_error(req.connection_key, exc) from exc\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 10.128.0.11:5000 ssl:default [Connection refused]; ERROR	2022-03-02 19:06:39,204	job.py	schedule_job:473	error while scheduling job (100, 1) on instance b",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11451:23127,timeout,timeout,23127,https://hail.is,https://github.com/hail-is/hail/pull/11451,1,['timeout'],['timeout']
Safety,"worker-pr-11438-default-g6cibyji6520-standard-9xy2q	Traceback (most recent call last):\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 969, in _wrap_create_connection\n return await self._loop.create_connection(*args, **kwargs) # type: ignore # noqa\n File ""uvloop/loop.pyx"", line 1974, in create_connection\n File ""uvloop/loop.pyx"", line 1951, in uvloop.loop.Loop.create_connection\nConnectionRefusedError: [Errno 111] Connection refused\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n File ""/usr/local/lib/python3.7/dist-packages/batch/driver/job.py"", line 449, in schedule_job\n timeout=aiohttp.ClientTimeout(total=2),\n File ""/usr/local/lib/python3.7/dist-packages/hailtop/httpx.py"", line 113, in request_and_raise_for_status\n resp = await self.client_session._request(method, url, **kwargs)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/client.py"", line 521, in _request\n req, traces=traces, timeout=real_timeout\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 535, in connect\n proto = await self._create_connection(req, traces, timeout)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 892, in _create_connection\n _, proto = await self._create_direct_connection(req, traces, timeout)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 1051, in _create_direct_connection\n raise last_exc\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 1032, in _create_direct_connection\n client_error=client_error,\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 975, in _wrap_create_connection\n raise client_error(req.connection_key, exc) from exc\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 10.128.0.11:5000 ssl:default [Connection refused]; INFO	2022-03-02 19:06:33,503	job_private.py	schedule_jobs_loop_body:142	starting scheduling jobs for jp",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11451:4027,timeout,timeout,4027,https://hail.is,https://github.com/hail-is/hail/pull/11451,1,['timeout'],['timeout']
Safety,"worker-pr-11438-default-g6cibyji6520-standard-9xy2q	Traceback (most recent call last):\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 969, in _wrap_create_connection\n return await self._loop.create_connection(*args, **kwargs) # type: ignore # noqa\n File ""uvloop/loop.pyx"", line 1974, in create_connection\n File ""uvloop/loop.pyx"", line 1951, in uvloop.loop.Loop.create_connection\nConnectionRefusedError: [Errno 111] Connection refused\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n File ""/usr/local/lib/python3.7/dist-packages/batch/driver/job.py"", line 449, in schedule_job\n timeout=aiohttp.ClientTimeout(total=2),\n File ""/usr/local/lib/python3.7/dist-packages/hailtop/httpx.py"", line 113, in request_and_raise_for_status\n resp = await self.client_session._request(method, url, **kwargs)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/client.py"", line 521, in _request\n req, traces=traces, timeout=real_timeout\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 535, in connect\n proto = await self._create_connection(req, traces, timeout)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 892, in _create_connection\n _, proto = await self._create_direct_connection(req, traces, timeout)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 1051, in _create_direct_connection\n raise last_exc\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 1032, in _create_direct_connection\n client_error=client_error,\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 975, in _wrap_create_connection\n raise client_error(req.connection_key, exc) from exc\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 10.128.0.11:5000 ssl:default [Connection refused]; INFO	2022-03-02 19:06:35,620	pool.py	create_instances:244	pool standard n_instances 1 {'pending': 0, 'a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11451:8461,timeout,timeout,8461,https://hail.is,https://github.com/hail-is/hail/pull/11451,1,['timeout'],['timeout']
Safety,"worker-pr-11438-default-g6cibyji6520-standard-9xy2q	Traceback (most recent call last):\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 969, in _wrap_create_connection\n return await self._loop.create_connection(*args, **kwargs) # type: ignore # noqa\n File ""uvloop/loop.pyx"", line 1974, in create_connection\n File ""uvloop/loop.pyx"", line 1951, in uvloop.loop.Loop.create_connection\nConnectionRefusedError: [Errno 111] Connection refused\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n File ""/usr/local/lib/python3.7/dist-packages/batch/driver/job.py"", line 449, in schedule_job\n timeout=aiohttp.ClientTimeout(total=2),\n File ""/usr/local/lib/python3.7/dist-packages/hailtop/httpx.py"", line 113, in request_and_raise_for_status\n resp = await self.client_session._request(method, url, **kwargs)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/client.py"", line 521, in _request\n req, traces=traces, timeout=real_timeout\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 535, in connect\n proto = await self._create_connection(req, traces, timeout)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 892, in _create_connection\n _, proto = await self._create_direct_connection(req, traces, timeout)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 1051, in _create_direct_connection\n raise last_exc\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 1032, in _create_direct_connection\n client_error=client_error,\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 975, in _wrap_create_connection\n raise client_error(req.connection_key, exc) from exc\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 10.128.0.11:5000 ssl:default [Connection refused]; INFO	2022-03-02 19:06:38,141	resource_manager.py	create_vm:191	created machine batch-worker-pr-11438-de",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11451:18979,timeout,timeout,18979,https://hail.is,https://github.com/hail-is/hail/pull/11451,1,['timeout'],['timeout']
Safety,"xcept FatalError as e:; --> 180 raise e.maybe_user_error(ir) from None; 181 if ir.typ == tvoid:; 182 value = None. File /opt/conda/lib/python3.10/site-packages/hail/backend/backend.py:178, in Backend.execute(self, ir, timed); 176 payload = ExecutePayload(self._render_ir(ir), '{""name"":""StreamBufferSpec""}', timed); 177 try:; --> 178 result, timings = self._rpc(ActionTag.EXECUTE, payload); 179 except FatalError as e:; 180 raise e.maybe_user_error(ir) from None. File /opt/conda/lib/python3.10/site-packages/hail/backend/py4j_backend.py:213, in Py4JBackend._rpc(self, action, payload); 211 if resp.status_code >= 400:; 212 error_json = orjson.loads(resp.content); --> 213 raise fatal_error_from_java_error_triplet(error_json['short'], error_json['expanded'], error_json['error_id']); 214 return resp.content, resp.headers.get('X-Hail-Timings', ''). FatalError: HailException: cannot set missing field for required type +PFloat64. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 5 in stage 6.0 failed 4 times, most recent failure: Lost task 5.3 in stage 6.0 (TID 67) (saturn-machinenumber.c.terra-code.internal executor 4): is.hail.utils.HailException: gs://path/to/bucket/chrY.0002.hard_filtered_with_genotypes.vcf.gz:offset 23933331019603: error while parsing line; chrY	113	.	GG	G,*,AG,CG	596	PASS	AC=2,4,6,1;AF=1.23e-03,5.550e-05,4.44e-05,2.00e-04;AN=265;AS_AltDP=10,0,3,10;AS_BaseQRankSum=0.000,.,0.100,0.500;AS_FS=7.777,.,2.144,8.001;AS_MQ=55.75,.,38.98,40.20;AS_MQRankSum=0.200,.,-1.050,-0.500;AS_QD=0.50,0.00,0.25,0.52;AS_ReadPosRankSum=-0.200,.,0.500,-0.220;AS_SOR=2.300,.,1.600,3.000;BaseQRankSum=0.200;DP=600000;ExcessHet=0.0477;FS=0.900;MQ=55.02;MQRankSum=-0.553;QD=1.00;ReadPosRankSum=-0.162;SOR=0.792;VarDP=650	GT:AD:DP:GQ:PGT:PID:PL:PS:SB	0/0:.:21:30	0/0:.:300:20	0/0:.:30:72	0/0:.:31:98	0|1:29,3,0,0,0:33:78:0|1:113_GG_G:78,0,1100,140,1400,1200,172,1600,1200,1000,175,1100,1100,1300,1000:113:19,19,2,1	0/0:.:20:19	0/0:.:19:20	0/0:.:25:50		0|1",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14102:5997,abort,aborted,5997,https://hail.is,https://github.com/hail-is/hail/issues/14102,1,['abort'],['aborted']
Safety,xt.scala:2062); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1658); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2022); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2043); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3901:7449,abort,abortStage,7449,https://hail.is,https://github.com/hail-is/hail/issues/3901,2,['abort'],['abortStage']
Safety,xt.scala:2062); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1658); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2022); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2043); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4055:6142,abort,abortStage,6142,https://hail.is,https://github.com/hail-is/hail/issues/4055,2,['abort'],['abortStage']
Safety,xt.scala:2062); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1658); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2022); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2043); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3516:3987,abort,abortStage,3987,https://hail.is,https://github.com/hail-is/hail/issues/3516,1,['abort'],['abortStage']
Safety,xt.scala:2069); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1517); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1505); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1504); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1504); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1732); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1687); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1676); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2029); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2050); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3465:9075,abort,abortStage,9075,https://hail.is,https://github.com/hail-is/hail/issues/3465,6,['abort'],['abortStage']
Safety,xt.scala:2125); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:109); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:344); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1575); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1563); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1562); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1562); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:803); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:803); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:803); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1790); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1745); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1734); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:619); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2029); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2126); 	at is.hail.rvd.RVD.aggregateWithPartitionOp(RVD.scala:558); ,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5846:6679,abort,abortStage,6679,https://hail.is,https://github.com/hail-is/hail/issues/5846,1,['abort'],['abortStage']
Safety,"y jobs from the database to schedule on available workers; 2. Compute placement of a subset of the jobs in available slots in the worker pool; 3. Concurrently call `/api/v1alpha/batches/jobs/create` on available workers for each placed job. If/when the request completes successfully, the job is marked as scheduled.; 4. Once all requests complete, goto 1. On the worker, what happens inside `/api/v1alpha/batches/jobs/create`:; 1. Read metadata describing the job to schedule from the request body; 2. Using that information, load the full job spec from blob storage; 3. Spawn a task to run the job asynchronously; 4. Respond to the driver with a 200. The key point relevant to this issue is that the driver currently must wait for all the requests to workers in an iteration to complete before it starts the next iteration of the scheduler. This leaves the scheduler vulnerable to problematic workers or workers that happen to be preempted during the scheduling process. So, the driver sets a [2 second timeout](https://github.com/hail-is/hail/blob/b27737f67bf9e69f1abed2fec07fc7c921790ef8/batch/batch/driver/job.py#L585) on the call to `/api/v1alpha/batches/jobs/create`. Additionally, this general design means that in the event of a request timeout or transient error, Batch cannot guarantee that there is always at most one concurrent running attempt for a given job. This ends up being a fine (and intentional) concession in practice because the idempotent design of preemptible jobs tends to cover this scenario, but it is regardless wasted compute and cost to users. Nevertheless, we strive to minimize cases where we might halt the scheduling loop or double-schedule work, and one way to do that in the current design is to minimize the variance in latency of `/api/v1alpha/batches/jobs/create`. The largest source of this latency is the request to blob storage. While GCS and ABS are relatively fast and highly available, Batch in Azure Terra requires first obtaining SAS tokens from the Te",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14456:1173,timeout,timeout,1173,https://hail.is,https://github.com/hail-is/hail/issues/14456,1,['timeout'],['timeout']
Safety,"y keyed by locus, and removed the MatrixKeyRowsBy in combine_gvcfs. To goal here is to avoid re-buidling an re-broadcasting the partitioner once for each gVCF. We'll need to re-key at the very end. I'm not so familiar with the end of the joint calling pipeline. @chrisvittal can you take care of that?. Second, I don't repartition in TableMultiWayZipJoin if the partitioners all match (which they should in in the joint calling pipeline). For that to work right, I need allowedOverlap == 0 (or to verify the partitions are in fact disjoint). Turns out allowedOverlap wasn't being propagated in various places. I fixed that. @patrick-schultz can you look at the RVDPartitioner changes? They just look like oversights to me, but maybe there was a reason why, for example, copy and coarsen wasn't preserving allowedOverlap?. Finally, now the joint calling pipeline/test_combiner_works segfaults, ugh:. ```; $ hail -m unittest test.hail.methods.test_impex.VCFTests.test_combiner_works; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x000000010e5fa090, pid=64905, tid=33795; #; # JRE version: Java(TM) SE Runtime Environment (8.0_45-b14) (build 1.8.0_45-b14); # Java VM: Java HotSpot(TM) 64-Bit Server VM (25.45-b02 mixed mode bsd-amd64 compressed oops); # Problematic frame:; # J 8877 C1 is.hail.expr.types.physical.PLocus$$anon$1.compare(Lis/hail/annotations/Region;JLis/hail/annotations/Region;J)I (117 bytes) @ 0x000000010e5fa090 [0x000000010e5f9de0+0x2b0]; #; ```. The rest of the tests pass (the other Python failures are cascaded failures from test_combiner_works, I double-checked in the hopes of finding an easier example to debug.) It is pretty clearly related to the no repartition optimization. If I disable it, test_combiner_works passes. I haven't tracked this down, but I do have one question @chrisvittal: who's responsible for freeing the inputs (that is, clearing the input regions) to multi-way zip join? I don't see where that happens.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5424:1066,detect,detected,1066,https://hail.is,https://github.com/hail-is/hail/pull/5424,1,['detect'],['detected']
Safety,y(SparkContext.scala:2062); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:108); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1658); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2022); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2043); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2062); at org,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3379:8563,abort,abortStage,8563,https://hail.is,https://github.com/hail-is/hail/issues/3379,1,['abort'],['abortStage']
Safety,y(SparkContext.scala:2069); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:108); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); at java.lang.Thread.run(Thread.java:748); Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1517); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1505); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1504); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1504); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1732); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1687); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1676); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2029); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2050); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2069); at org,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3507:6010,abort,abortStage,6010,https://hail.is,https://github.com/hail-is/hail/issues/3507,1,['abort'],['abortStage']
Safety,y(SparkContext.scala:2118); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:108); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1658); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2022); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2119); at org.apache.spark.rdd.RDD$$anonfun$aggregate$1.apply(RDD.scala:1115); ,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3063:5630,abort,abortStage,5630,https://hail.is,https://github.com/hail-is/hail/issues/3063,2,['abort'],['abortStage']
Safety,"y, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI0Y2E5NmE2ZC02MjMxLTQ1YTctYmQyOS1kYTA0ZmZhNTliYzQiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjRjYTk2YTZkLTYyMzEtNDVhNy1iZDI5LWRhMDRmZmE1OWJjNCJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""4ca96a6d-6231-45a7-bd29-da04ffa59bc4"",""prPublicId"":""4ca96a6d-6231-45a7-bd29-da04ffa59bc4"",""dependencies"":[{""name"":""cryptography"",""from"":""41.0.7"",""to"":""42.0.2""}],""packageManager"":""pip"",""projectPublicId"":""c1c98f6a-57c6-4ecc-a329-3b744cab74bd"",""projectUrl"":""https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-CRYPTOGRAPHY-6210214""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""pr-warning-shown"",""priorityScore""],""priorityScoreList"":[451],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [NULL Pointer Dereference](https://learn.snyk.io/lesson/null-dereference/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14238:3403,remediat,remediationStrategy,3403,https://hail.is,https://github.com/hail-is/hail/pull/14238,1,['remediat'],['remediationStrategy']
Safety,"y, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI1MzAxOWZkZC04YjQwLTQ5NmUtYjRmYS0wMzA5MTAxOTBkZWMiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjUzMDE5ZmRkLThiNDAtNDk2ZS1iNGZhLTAzMDkxMDE5MGRlYyJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""53019fdd-8b40-496e-b4fa-030910190dec"",""prPublicId"":""53019fdd-8b40-496e-b4fa-030910190dec"",""dependencies"":[{""name"":""cryptography"",""from"":""42.0.2"",""to"":""42.0.4""}],""packageManager"":""pip"",""projectPublicId"":""c1c98f6a-57c6-4ecc-a329-3b744cab74bd"",""projectUrl"":""https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-CRYPTOGRAPHY-6261585""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""pr-warning-shown"",""priorityScore""],""priorityScoreList"":[581],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [NULL Pointer Dereference](https://learn.snyk.io/lesson/null-dereference/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14344:3409,remediat,remediationStrategy,3409,https://hail.is,https://github.com/hail-is/hail/pull/14344,1,['remediat'],['remediationStrategy']
Safety,y.createSocket(StandardSocketFactory.java:62); at org.apache.hadoop.hdfs.DFSOutputStream.createSocketForPipeline(DFSOutputStream.java:1531); at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.createBlockOutputStream(DFSOutputStream.java:1309); at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.nextBlockOutputStream(DFSOutputStream.java:1262); at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:448). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1889); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1876); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1876); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2110); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2059); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2048); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:737); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2061); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2082); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2101); at org,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/9293:9614,abort,abortStage,9614,https://hail.is,https://github.com/hail-is/hail/issues/9293,1,['abort'],['abortStage']
Safety,"yload); 216 path = action_routes[action]; 217 port = self._backend_server_port; → 218 resp = self._requests_session.post(f’http://localhost:{port}{path}', data=data); 219 if resp.status_code >= 400:; 220 error_json = orjson.loads(resp.content). File ~/Library/Python/3.9/lib/python/site-packages/requests/sessions.py:637, in Session.post(self, url, data, json, **kwargs); 626 def post(self, url, data=None, json=None, **kwargs):; 627 r""""“Sends a POST request. Returns :class:Response object.; 628; 629 :param url: URL for the new :class:Request object.; (…); 634 :rtype: requests.Response; 635 “””; → 637 return self.request(“POST”, url, data=data, json=json, **kwargs). File ~/Library/Python/3.9/lib/python/site-packages/requests/sessions.py:589, in Session.request(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json); 584 send_kwargs = {; 585 “timeout”: timeout,; 586 “allow_redirects”: allow_redirects,; 587 }; 588 send_kwargs.update(settings); → 589 resp = self.send(prep, **send_kwargs); 591 return resp. File ~/Library/Python/3.9/lib/python/site-packages/requests/sessions.py:703, in Session.send(self, request, **kwargs); 700 start = preferred_clock(); 702 # Send the request; → 703 r = adapter.send(request, **kwargs); 705 # Total elapsed time of the request (approximately); 706 elapsed = preferred_clock() - start. File ~/Library/Python/3.9/lib/python/site-packages/requests/adapters.py:501, in HTTPAdapter.send(self, request, stream, timeout, verify, cert, proxies); 486 resp = conn.urlopen(; 487 method=request.method,; 488 url=url,; (…); 497 chunked=chunked,; 498 ); 500 except (ProtocolError, OSError) as err:; → 501 raise ConnectionError(err, request=request); 503 except MaxRetryError as e:; 504 if isinstance(e.reason, ConnectTimeoutError):; 505 # TODO: Remove this in 3.0.0: see #2811. ConnectionError: (‘Connection aborted.’, RemoteDisconnected(‘Remote end closed connection without response’)); ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14557:2830,timeout,timeout,2830,https://hail.is,https://github.com/hail-is/hail/issues/14557,2,"['abort', 'timeout']","['aborted', 'timeout']"
Safety,"},; ""main"": {; ""name"": ""main"",; ""state"": ""error"",; ""timing"": {; ""pulling"": {; ""start_time"": 1586188245305,; ""finish_time"": 1586188245404,; ""duration"": 99; },; ""creating"": {; ""start_time"": 1586188245404,; ""finish_time"": 1586188245457,; ""duration"": 53; },; ""runtime"": {; ""start_time"": 1586188245458,; ""finish_time"": 1586189446263,; ""duration"": 1200805; },; ""starting"": {; ""start_time"": 1586188245458,; ""finish_time"": 1586188246261,; ""duration"": 803; },; ""running"": {; ""start_time"": 1586188246262,; ""finish_time"": 1586189446263,; ""duration"": 1200001; },; ""uploading_log"": {; ""start_time"": 1586189446266,; ""finish_time"": 1586189446350,; ""duration"": 84; },; ""deleting"": {; ""start_time"": 1586189446351,; ""finish_time"": 1586189456802,; ""duration"": 10451; }; },; ""error"": ""Traceback (most recent call last):\n File \""/usr/local/lib/python3.6/site-packages/batch/worker.py\"", line 387, in run\n raise JobTimeoutError(f'timed out after {self.timeout}s')\nJobTimeoutError: timed out after 1200s\n"",; ""container_status"": {; ""state"": ""running"",; ""started_at"": ""2020-04-06T15:50:46.250931386Z"",; ""finished_at"": ""0001-01-01T00:00:00Z"",; ""out_of_memory"": false,; ""exit_code"": 0; }; }; },; ""start_time"": 1586188245458,; ""end_time"": 1586189446263; },; ""spec"": {; ""command"": [; ""bash"",; ""-c"",; ""export HAIL_DEPLOY_CONFIG_FILE=/deploy-config/deploy-config.json\nexport SCRATCH=gs://hail-test-dmk9z/o1111h6zxn1p/pipeline\npython3 -m pytest --log-cli-level=INFO -s -vv --instafail /io/test/""; ],; ""image"": ""gcr.io/hail-vdc/ci-intermediate:q7503hc818u5"",; ""job_id"": 65,; ""mount_docker_socket"": false,; ""secrets"": [; {; ""namespace"": ""pr-8470-default-dyvil12gxzyf"",; ""name"": ""gce-deploy-config"",; ""mount_path"": ""/deploy-config""; },; {; ""namespace"": ""pr-8470-batch-pods-r3e5lmgvb8dl"",; ""name"": ""test-tokens"",; ""mount_path"": ""/user-tokens""; },; {; ""namespace"": ""batch-pods"",; ""name"": ""ci-gsa-key"",; ""mount_path"": ""/gsa-key"",; ""mount_in_copy"": true; }; ],; ""timeout"": 1200,; ""input_files"": [; {; ""from"": ""gs://hail-ci-bpk3h/buil",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8473:2271,timeout,timeout,2271,https://hail.is,https://github.com/hail-is/hail/issues/8473,1,['timeout'],['timeout']
Safety,"~Stacked on #10770~; ~Stacked on #10791~. This PR attempts to allow linear algebra codegen methods, like the LAPACK wrappers and the local whitening methods I'm working on, to defensively assert shape compatibility preconditions, without generating redundant runtime checks. (I always hate when we're pushed to avoid using code generation abstractions (in this case, just factoring code into smaller functions), because they generate worse code.). The method is pretty simple. SNDArray shapes are now arrays of `SizeValue`, which is a sum type with cases `SizeValueDyn(Value[Long])` and `SizeValueStatic(Long)`. I don't think static sizes occur very often, but it was a simple addition. `SizeValue`s can be compared statically with `==`, or at runtime with `ceq`: the former is true only if we can prove statically that the two sizes must be equal, while the latter emits code to check equality at runtime, using static knowledge to elide dynamic checks where possible. The way we encode static knowledge that two sizes are equal is by using the same local variable to store both. The primary interface to introduce that static knowledge (other than using the same set of sizes to construct multiple SNDArrays), is the method `coerceToShape(cb: CodeBuilder, newShape: Seq[SizeValue]): SNDArrayValue`, which emits code to dynamically assert that `this.shape` agrees with `newShape`, then returns `this` with shape replaced by `newShape`. Thus, `a.coerceToShape(cb, newShape).shape == newShape` will always be true, preserving the static knowledge about the shape of `a`. As a simple example, `gemm` verifies its inputs with (simplifying to the case with no transposes); ```; val Seq(m, n) = C.shapes; val k = A.shapes(1); A.assertHasShape(cb, FastIndexedSeq(m, k), errMsg); B.assertHasShape(cb, FastIndexedSeq(k, n), errMsg); ```; If we call this with; ```; val m, n, k = \\ compute expected dim sizes. \\ emit dynamic size checks once; val A_ = A.coerceToShape(cb, IndexedSeq(m, k)); val B_ = B.coerce",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10783:249,redund,redundant,249,https://hail.is,https://github.com/hail-is/hail/pull/10783,2,"['avoid', 'redund']","['avoid', 'redundant']"
Safety,"~Stacked on #10791~. A few high level changes got mixed up in this PR, since I couldn't predict where a thread would lead once I started pulling. If you would like, I can try to disentangle them. Here are the conceptual changes:; * add a CodeBuilder argument to `getEmitParam`, so that parameters which are pointers to region values can be loaded into `SValue`s with multiple locals; * make `EmitValue` a concrete class, consisting of an optional boolean value and an `SValue`; * add `valueTuple` to both `SValue` and `EmitValue`; * copy the `SCode` interface onto `SValue`, to make it easier to replace `SCode`s with `SValues` ; * add `loadToSValue` to `SingleCodeType`; * add `SStreamValue`. This loses the single use assertion, but that doesn't seem like it asserts much, since the stream producer can be freely accessed without memoizing the `SStreamCode`",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10797:88,predict,predict,88,https://hail.is,https://github.com/hail-is/hail/pull/10797,1,['predict'],['predict']
Safety,"~~Stacked on #8172~~. Implement emitters for StreamScan, RunAggScan, and StreamLeftJoinDistinct. These complete the handling in the new emitter for non-root stream nodes (i.e. those which take stream children). Thus it is now safe to delete non-root nodes from the previous EmitStream. This also implements length tracking in the new EmitStream, and adds back the optimizations that take advantage of knowing the length, plus some we weren't doing before, like in ArraySort and CollectDistributedArray.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8204:226,safe,safe,226,https://hail.is,https://github.com/hail-is/hail/pull/8204,1,['safe'],['safe']
Safety,"~~Stacked on #9320~~. Use the framework introduced in #9320 to make the IR parser stack safe. This touches a lot of lines, but it is a completely mechanical refactoring. I did some preliminary benchmarking by timing the parse of the IR in `test_ld_prune`. (I chose that test fairly arbitrarily, and we can probably find better test cases, or generate synthetic large IRs.) Running a loop parsing the same IR repeatedly, with 10 burn-in rounds, and 60 timed rounds, I got the following results:; * On main; ```; quartiles = [4.55816, 5.209579, 5.647135]; avg = 5.332496950000001, std = 1.13761574944604; ```; * Using `StackSafe`, without the optimization in `repUntil`; ```; quantiles = [4.610798, 5.09793, 7.159075]; avg = 5.7519015000000016, std = 1.612397075594852; ```; * Using `StackSafe, with the optimization which reuses the `cont` closure, instead of allocating a new one for each token.; ```; quantiles = [4.466849, 4.826873, 5.719238]; avg = 5.2787357833333335, std = 1.272006325411254; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9332:88,safe,safe,88,https://hail.is,https://github.com/hail-is/hail/pull/9332,1,['safe'],['safe']
Safety,"~~Stacked on #9490~~. With the stronger invariants enforced by the previous PRs, some of the work done in `asBytes` is redundant.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9491:119,redund,redundant,119,https://hail.is,https://github.com/hail-is/hail/pull/9491,1,['redund'],['redundant']
Safety,"━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 1/1 0:00:00 0:00:00; 2023-09-06T21:47:17 WARNING hailtop.utils utils.py:842:retry_transient_errors_with_debug_string A transient error occured. We will automatically retry. Do not be alarmed. We have thus far seen 2 transient errors (next delay: 3.794s). The most recent error was <class 'asyncio.exceptions.TimeoutError'> . . +++++++++++++++++++++++++++++++++++ Timeout ++++++++++++++++++++++++++++++++++++. ~~~~~~~~~~~~~~~~~~~~~ Stack of asyncio_0 (140387515627072) ~~~~~~~~~~~~~~~~~~~~~; File ""/usr/lib/python3.9/threading.py"", line 937, in _bootstrap; self._bootstrap_inner(); File ""/usr/lib/python3.9/threading.py"", line 980, in _bootstrap_inner; self.run(); File ""/usr/lib/python3.9/threading.py"", line 917, in run; self._target(*self._args, **self._kwargs); File ""/usr/lib/python3.9/concurrent/futures/thread.py"", line 81, in _worker; work_item = work_queue.get(block=True). +++++++++++++++++++++++++++++++++++ Timeout ++++++++++++++++++++++++++++++++++++; FAILED; _________________ test_always_run_job_private_instance_cancel __________________. client = <hailtop.batch_client.client.BatchClient object at 0x7fae899806a0>. def test_always_run_job_private_instance_cancel(client: BatchClient):; b = create_batch(client); resources = {'machine_type': smallest_machine_type()}; j = b.create_job(DOCKER_ROOT_IMAGE, ['true'], resources=resources, always_run=True); b.submit(); b.cancel(); > status = j.wait(). io/test/test_batch.py:1487: ; _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ; usr/local/lib/python3.9/dist-packages/hailtop/batch_client/client.py:84: in wait; return async_to_blocking(self._async_job.wait()); usr/local/lib/python3.9/dist-packages/hailtop/utils/utils.py:156: in async_to_blocking; return loop.run_until_complete(task); usr/lib/python3.9/asyncio/base_events.py:634: in run_until_complete; self.run_forever(); usr/lib/python3.9/asyncio/base_events.py:601: in run_forever; self._run_once(); usr/lib/python3",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13582:1763,Timeout,Timeout,1763,https://hail.is,https://github.com/hail-is/hail/issues/13582,1,['Timeout'],['Timeout']
Security,	at is.hail.utils.Graph$$anonfun$2$$anonfun$apply$2$$anonfun$apply$3.apply(Graph.scala:54); 	at is.hail.utils.package$.using(package.scala:587); 	at is.hail.annotations.Region$.scoped(Region.scala:20); 	at is.hail.utils.Graph$$anonfun$2$$anonfun$apply$2.apply(Graph.scala:54); 	at is.hail.utils.Graph$$anonfun$2$$anonfun$apply$2.apply(Graph.scala:53); 	at is.hail.utils.BinaryHeap.isLeftFavoredTie(BinaryHeap.scala:16); 	at is.hail.utils.BinaryHeap.is$hail$utils$BinaryHeap$$bubbleUp(BinaryHeap.scala:161); 	at is.hail.utils.BinaryHeap.insert(BinaryHeap.scala:40); 	at is.hail.utils.Graph$$anonfun$maximalIndependentSet$1.apply(Graph.scala:91); 	at is.hail.utils.Graph$$anonfun$maximalIndependentSet$1.apply(Graph.scala:90); 	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99); 	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99); 	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230); 	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40); 	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99); 	at is.hail.utils.Graph$.maximalIndependentSet(Graph.scala:90); 	at is.hail.utils.Graph$.maximalIndependentSet(Graph.scala:76); 	at is.hail.utils.Graph.maximalIndependentSet(Graph.scala); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:280); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:214); 	at java.lang.Thread.run(Thread.java:748). H,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4857:4366,Hash,HashMap,4366,https://hail.is,https://github.com/hail-is/hail/issues/4857,1,['Hash'],['HashMap']
Security,"	at is.hail.utils.package$.using(package.scala:637) ~[gs:__hail-query-ger0g_jars_b115f6a6ec23f111a4512b562b52d9f8a52ec41c.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.backend.service.Worker$.main(Worker.scala:164) ~[gs:__hail-query-ger0g_jars_b115f6a6ec23f111a4512b562b52d9f8a52ec41c.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.backend.service.Main$.main(Main.scala:14) ~[gs:__hail-query-ger0g_jars_b115f6a6ec23f111a4512b562b52d9f8a52ec41c.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.backend.service.Main.main(Main.scala) ~[gs:__hail-query-ger0g_jars_b115f6a6ec23f111a4512b562b52d9f8a52ec41c.jar.jar:0.0.1-SNAPSHOT]; 	... 12 more; 	Suppressed: is.hail.relocated.com.google.cloud.storage.StorageException: 403 Forbidden; POST https://storage.googleapis.com/upload/storage/v1/b/neale-bge/o?name=foo.ht/index/part-0-c7ba7549-bf68-42db-a8ef-0f1b13721c79.idx/index&uploadType=resumable; {; ""error"": {; ""code"": 403,; ""message"": ""dking-ae4q6@hail-vdc.iam.gserviceaccount.com does not have storage.objects.create access to the Google Cloud Storage object. Permission 'storage.objects.create' denied on resource (or it may not exist)."",; ""errors"": [; {; ""message"": ""dking-ae4q6@hail-vdc.iam.gserviceaccount.com does not have storage.objects.create access to the Google Cloud Storage object. Permission 'storage.objects.create' denied on resource (or it may not exist)."",; ""domain"": ""global"",; ""reason"": ""forbidden""; }; ]; }; }. 		at is.hail.relocated.com.google.cloud.storage.StorageException.translate(StorageException.java:165) ~[gs:__hail-query-ger0g_jars_b115f6a6ec23f111a4512b562b52d9f8a52ec41c.jar.jar:0.0.1-SNAPSHOT]; 		at is.hail.relocated.com.google.cloud.storage.spi.v1.HttpStorageRpc.translate(HttpStorageRpc.java:298) ~[gs:__hail-query-ger0g_jars_b115f6a6ec23f111a4512b562b52d9f8a52ec41c.jar.jar:0.0.1-SNAPSHOT]; 		at is.hail.relocated.com.google.cloud.storage.spi.v1.HttpStorageRpc.open(HttpStorageRpc.java:1029) ~[gs:__hail-query-ger0g_jars_b115f6a6ec23f111a4512b562b52d9f8a52ec41c.jar.jar:0.0.1-SNAPSHOT]; 		at is.hai",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13697:17658,access,access,17658,https://hail.is,https://github.com/hail-is/hail/issues/13697,1,['access'],['access']
Security, 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:750). java.net.SocketException: Connection reset; 	at java.net.SocketInputStream.read(SocketInputStream.java:210); 	at java.net.SocketInputStream.read(SocketInputStream.java:141); 	at sun.security.ssl.SSLSocketInputRecord.read(SSLSocketInputRecord.java:464); 	at sun.security.ssl.SSLSocketInputRecord.decodeInputRecord(SSLSocketInputRecord.java:237); 	at sun.security.ssl.SSLSocketInputRecord.decode(SSLSocketInputRecord.java:190); 	at sun.security.ssl.SSLTransport.decode(SSLTransport.java:109); 	at sun.security.ssl.SSLSocketImpl.decode(SSLSocketImpl.java:1400); 	at sun.security.ssl.SSLSocketImpl.readApplicationRecord(SSLSocketImpl.java:1368); 	at sun.security.ssl.SSLSocketImpl.access$300(SSLSocketImpl.java:73); 	at sun.security.ssl.SSLSocketImpl$AppInputStream.read(SSLSocketImpl.java:962); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:284); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.MeteredStream.read(MeteredStream.java:134); 	at java.io.FilterInputStream.read(FilterInputStream.java:133); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3456); 	at com.google.api.client.http.javanet.NetHttpResponse$SizeValidatingInputStream.read(NetHttpResponse.java:164); 	at java.nio.channels.Channels$ReadableByteChannelImpl.read(Channels.java:385); 	at is.hail.relocated.com.google.cloud.storage.StorageByteChannels$ScatteringByteChannelFacade.read(StorageByteChannels.java:226); 	at is.hail.relocated.com.google.cloud.storage.ApiaryUnbufferedReadableByteChannel.read(ApiaryUnbufferedReadableByteChannel.java:104); 	at is.hail.relocated.com.google.cloud.storage.UnbufferedReadableByteChannelSession$UnbufferedReadableByteChannel.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12982:15000,secur,security,15000,https://hail.is,https://github.com/hail-is/hail/issues/12982,3,['secur'],['security']
Security, 	at org.elasticsearch.spark.serialization.ScalaValueWriter$$anonfun$doWriteScala$3.apply(ScalaValueWriter.scala:77); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.elasticsearch.spark.serialization.ScalaValueWriter.doWriteScala(ScalaValueWriter.scala:77); 	at org.elasticsearch.spark.serialization.ScalaValueWriter.doWrite(ScalaValueWriter.scala:50); 	at org.elasticsearch.spark.serialization.ScalaValueWriter$$anonfun$doWriteScala$2.apply(ScalaValueWriter.scala:66); 	at org.elasticsearch.spark.serialization.ScalaValueWriter$$anonfun$doWriteScala$2.apply(ScalaValueWriter.scala:63); 	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733); 	at scala.collection.immutable.HashMap$HashMap1.foreach(HashMap.scala:221); 	at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428); 	at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428); 	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732); 	at org.elasticsearch.spark.serialization.ScalaValueWriter.doWriteScala(ScalaValueWriter.scala:63); 	at org.elasticsearch.spark.serialization.ScalaValueWriter.write(ScalaValueWriter.scala:46); 	at org.elasticsearch.hadoop.serialization.builder.ContentBuilder.value(ContentBuilder.java:53); 	at org.elasticsearch.hadoop.serialization.bulk.TemplatedBulk.doWriteObject(TemplatedBulk.java:71); 	at org.elasticsearch.hadoop.serialization.bulk.TemplatedBulk.write(TemplatedBulk.java:58); 	at org.elasticsearch.hadoop.rest.RestRepository.writeToIndex(RestRepository.java:168); 	at org.elasticsearch.spark.rdd.EsRDDWriter.write(EsRDDWriter.scala:67); 	at org.elasticsearch.spark.rdd.EsSpark$$anonfun$doSaveToEs$1.apply(EsSpark.scala:107); 	at org.elasticsearch.spark.rdd.EsSpark$$anonfun$doSaveToEs$1.apply(EsSpark.scala:107); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTas,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4250:4161,Hash,HashMap,4161,https://hail.is,https://github.com/hail-is/hail/issues/4250,4,['Hash'],"['HashMap', 'HashTrieMap']"
Security," #### Changes included in this PR. - Changes to the following files to upgrade the vulnerable dependencies to a fixed version:; - hail/python/hailtop/pinned-requirements.txt. <details>; <summary>⚠️ <b>Warning</b></summary>. ```; msal-extensions 1.0.0 requires portalocker, which is not installed.; aiosignal 1.3.1 requires frozenlist, which is not installed.; aiodns 2.0.0 requires pycares, which is not installed. ```; </details>. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **663/1000** <br/> **Why?** Proof of Concept exploit, Recently disclosed, Has a fix available, CVSS 5.4 | Improper Input Validation <br/>[SNYK-PYTHON-AIOHTTP-6091621](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-6091621) | `aiohttp:` <br> `3.8.6 -> 3.9.0` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **663/1000** <br/> **Why?** Proof of Concept exploit, Recently disclosed, Has a fix available, CVSS 5.4 | Improper Input Validation <br/>[SNYK-PYTHON-AIOHTTP-6091622](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-6091622) | `aiohttp:` <br> `3.8.6 -> 3.9.0` <br> | No | Proof of Concept . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this b",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14038:1188,Validat,Validation,1188,https://hail.is,https://github.com/hail-is/hail/pull/14038,1,['Validat'],['Validation']
Security," &lt;/details&gt;. &lt;br /&gt;; </code></pre>. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pyjwt&package-manager=pip&previous-version=1.7.1&new-version=2.4.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself); You can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/hail-is/hail/network/alerts). </details>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11866:16461,secur,security,16461,https://hail.is,https://github.com/hail-is/hail/pull/11866,2,"['Secur', 'secur']","['Security', 'security']"
Security," (oh the irony). The major new build step is `create_certs` which creates a certificate, key, and; list of trusted ""principals"" for each ""principal"". ""Principal"" is a computer; security term referring to an authenticatable identity. In our system, the; services are each unique principals and every client (e.g. the test_batch CI; step) is also a principal. A principal's certificate is a unforgeable proof of; their identity. A principal's ""key"", in our system, is actually a public-private; (i.e. asymmetric) key pair which the client and server use to establish a; symmetric key for each new connection. A list of trusted principals is a list of; certificates. Every incoming connection must provide a certificate in the; trusted list or the server will drop the connection. Every service depends on the `create_certs` step because their deployment's load; secrets created by `create_certs`. The blog service is implemented by Ghost. Ghost only supports HTTP. As a result; we cannot make all network traffic in our cluster TLS-secured. However, we can; use an nginx sidecar on the blog pod which terminates TLS connections and sends; plaintext traffic on the loopback interface to Ghost. Thus, our goal is: no; plaintext traffic on non-loopback interfaces. Readiness and liveness probes cannot use HTTP. Although k8s supports HTTPS, it; does not support so-called ""mTLS"" or ""mutual TLS."" This is fancy verbiage for; servers that require clients to send trusted certificates. We require; this. There is a lot of information in GitHub issues and the Istio web pages; about this, but at the end of the day, kubernetes does not support this. TCP; probes are the best we can do. There [was a; PR](https://github.com/kubernetes/kubernetes/pull/61231) to allow httpGet probes; to send the kubelet certificate, but it was closed because, apparently, the; [httpGet probes can be targeted at arbitrary IP; addresses](https://github.com/kubernetes/kubernetes/pull/61231#pullrequestreview-104364784) (what; th",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8513:1278,secur,secured,1278,https://hail.is,https://github.com/hail-is/hail/pull/8513,1,['secur'],['secured']
Security," + '/out'); File ""/usr/local/lib/python3.10/site-packages/hailtop/utils/utils.py"", line 774, in retry_transient_errors; return await retry_transient_errors_with_debug_string('', 0, f, *args, **kwargs); File ""/usr/local/lib/python3.10/site-packages/hailtop/utils/utils.py"", line 787, in retry_transient_errors_with_debug_string; return await f(*args, **kwargs); File ""/usr/local/lib/python3.10/site-packages/hail/backend/service_backend.py"", line 475, in _read_output; raise reconstructed_error.maybe_user_error(ir); hail.utils.java.FatalError: SocketException: Connection reset. Java stack trace:; javax.net.ssl.SSLException: Connection reset; 	at sun.security.ssl.Alert.createSSLException(Alert.java:127); 	at sun.security.ssl.TransportContext.fatal(TransportContext.java:324); 	at sun.security.ssl.TransportContext.fatal(TransportContext.java:267); 	at sun.security.ssl.TransportContext.fatal(TransportContext.java:262); 	at sun.security.ssl.SSLTransport.decode(SSLTransport.java:138); 	at sun.security.ssl.SSLSocketImpl.decode(SSLSocketImpl.java:1400); 	at sun.security.ssl.SSLSocketImpl.readApplicationRecord(SSLSocketImpl.java:1368); 	at sun.security.ssl.SSLSocketImpl.access$300(SSLSocketImpl.java:73); 	at sun.security.ssl.SSLSocketImpl$AppInputStream.read(SSLSocketImpl.java:962); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:284); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.MeteredStream.read(MeteredStream.java:134); 	at java.io.FilterInputStream.read(FilterInputStream.java:133); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3456); 	at com.google.api.client.http.javanet.NetHttpResponse$SizeValidatingInputStream.read(NetHttpResponse.java:164); 	at java.nio.channels.Channels$ReadableByteChannelImpl.read(Channels.java:385); 	at is.hail.relocated.com.google.cloud.storage.StorageByteChannels$ScatteringByteChannelFacade.read(StorageByteChannels.java:226); 	at is.hail.relocated.com.go",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12982:3101,secur,security,3101,https://hail.is,https://github.com/hail-is/hail/issues/12982,1,['secur'],['security']
Security," + '/out'); File ""/usr/local/lib/python3.10/site-packages/hailtop/utils/utils.py"", line 779, in retry_transient_errors; return await retry_transient_errors_with_debug_string('', 0, f, *args, **kwargs); File ""/usr/local/lib/python3.10/site-packages/hailtop/utils/utils.py"", line 792, in retry_transient_errors_with_debug_string; return await f(*args, **kwargs); File ""/usr/local/lib/python3.10/site-packages/hail/backend/service_backend.py"", line 477, in _read_output; raise reconstructed_error.maybe_user_error(ir); hail.utils.java.FatalError: SocketException: Connection reset. Java stack trace:; javax.net.ssl.SSLException: Connection reset; 	at sun.security.ssl.Alert.createSSLException(Alert.java:127); 	at sun.security.ssl.TransportContext.fatal(TransportContext.java:324); 	at sun.security.ssl.TransportContext.fatal(TransportContext.java:267); 	at sun.security.ssl.TransportContext.fatal(TransportContext.java:262); 	at sun.security.ssl.SSLTransport.decode(SSLTransport.java:138); 	at sun.security.ssl.SSLSocketImpl.decode(SSLSocketImpl.java:1400); 	at sun.security.ssl.SSLSocketImpl.readApplicationRecord(SSLSocketImpl.java:1368); 	at sun.security.ssl.SSLSocketImpl.access$300(SSLSocketImpl.java:73); 	at sun.security.ssl.SSLSocketImpl$AppInputStream.read(SSLSocketImpl.java:962); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:284); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.MeteredStream.read(MeteredStream.java:134); 	at java.io.FilterInputStream.read(FilterInputStream.java:133); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3456); 	at com.google.api.client.http.javanet.NetHttpResponse$SizeValidatingInputStream.read(NetHttpResponse.java:164); 	at java.nio.channels.Channels$ReadableByteChannelImpl.read(Channels.java:385); 	at is.hail.relocated.com.google.cloud.storage.StorageByteChannels$ScatteringByteChannelFacade.read(StorageByteChannels.java:226); 	at is.hail.relocated.com.go",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12983:3989,secur,security,3989,https://hail.is,https://github.com/hail-is/hail/issues/12983,1,['secur'],['security']
Security," 1.5.5.; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/erdewit/nest_asyncio/commit/3cfd2c8bc453174ec0be57cd3bb8ec16dbcde1b4""><code>3cfd2c8</code></a> Potential fix for issue <a href=""https://github-redirect.dependabot.com/erdewit/nest_asyncio/issues/65"">#65</a></li>; <li><a href=""https://github.com/erdewit/nest_asyncio/commit/616d9a5e15d8d75e3343422778e49af2e9ac80ea""><code>616d9a5</code></a> Patch asyncio.get_event_loop to not require a running loop, fixes <a href=""https://github-redirect.dependabot.com/erdewit/nest_asyncio/issues/70"">#70</a></li>; <li>See full diff in <a href=""https://github.com/erdewit/nest_asyncio/compare/v1.5.4...v1.5.5"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=nest-asyncio&package-manager=pip&previous-version=1.5.4&new-version=1.5.5)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12209:1043,secur,security-vulnerabilities,1043,https://hail.is,https://github.com/hail-is/hail/pull/12209,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security," 2, in import_vcf; File ""/tmp/7417fcfbbeee44d0b3f4c0b3750121a7/hail-0.1-es-6.2.4-with-strip-chr-prefix.zip/hail/java.py"", line 121, in handle_py4j; hail.java.FatalError: FileNotFoundException: File file:/tmp/clinvar.vcf.gz does not exist. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 0.0 failed 20 times, most recent failure: Lost task 0.19 in stage 0.0 (TID 19, without-vep-520334-sw-rmwj.c.seqr-project.internal): java.io.FileNotFoundException: File file:/tmp/clinvar.vcf.gz does not exist; 	at org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:611); 	at org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:824); 	at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:601); 	at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:428); 	at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:142); 	at org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:346); 	at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:769); 	at org.apache.hadoop.mapred.LineRecordReader.<init>(LineRecordReader.java:109); 	at org.apache.hadoop.mapred.TextInputFormat.getRecordReader(TextInputFormat.java:67); 	at org.apache.spark.rdd.HadoopRDD$$anon$1.<init>(HadoopRDD.scala:245); 	at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:208); 	at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:101); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3760:5777,Checksum,ChecksumFileSystem,5777,https://hail.is,https://github.com/hail-is/hail/issues/3760,1,['Checksum'],['ChecksumFileSystem']
Security," <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **519/1000** <br/> **Why?** Has a fix available, CVSS 6.1 | Information Exposure <br/>[SNYK-PYTHON-REQUESTS-5595532](https://snyk.io/vuln/SNYK-PYTHON-REQUESTS-5595532) | `requests:` <br> `2.27.1 -> 2.31.0` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **509/1000** <br/> **Why?** Has a fix available, CVSS 5.9 | Regular Expression Denial of Service (ReDoS) <br/>[SNYK-PYTHON-SETUPTOOLS-3180412](https://snyk.io/vuln/SNYK-PYTHON-SETUPTOOLS-3180412) | `setuptools:` <br> `39.0.1 -> 65.5.1` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **711/1000** <br/> **Why?** Mature exploit, Has a fix available, CVSS 6.5 | Cross-site Scripting (XSS) <br/>[SNYK-PYTHON-SPHINX-570772](https://snyk.io/vuln/SNYK-PYTHON-SPHINX-570772) | `sphinx:` <br> `1.8.6 -> 3.3.0` <br> | No | Mature ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **701/1000** <br/> **Why?** Mature exploit, Has a fix available, CVSS 6.3 | Cross-site Scripting (XSS) <br/>[SNYK-PYTHON-SPHINX-570773](https://snyk.io/vuln/SNYK-PYTHON-SPHINX-570773) | `sphinx:` <br> `1.8.6 -> 3.3.0` <br> | No | Mature ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **586/1000** <br/> **Why?** Proof of Concept exploit, Has a fix available, CVSS 5.3 | Regular Expression Denial of Service (ReDoS) <br/>[SNYK-PYTHON-SPHINX-5811865](https://snyk.io/vuln/SNYK-PYTHON-SPHINX-5811865) | `sphinx:` <br> `1.8.6 -> 3.3.0` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13717:6652,Cross-site Scripting,Cross-site Scripting,6652,https://hail.is,https://github.com/hail-is/hail/pull/13717,6,"['Cross-site Scripting', 'XSS']","['Cross-site Scripting', 'XSS']"
Security," <li><a href=""https://github.com/PyCQA/mccabe/commit/4ba21d2e8db92534914a89f44b5dfd0fb2e29e9c""><code>4ba21d2</code></a> Travis CI: allow_failures in Python end of life branches</li>; <li><a href=""https://github.com/PyCQA/mccabe/commit/80794d37d7d3e35cf243877a396e53f70243e154""><code>80794d3</code></a> Apply suggestions from code review</li>; <li><a href=""https://github.com/PyCQA/mccabe/commit/e864119dca577a38552b0d32c66d0ef3dc7779e0""><code>e864119</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pycqa/mccabe/issues/86"">#86</a> from cclauss/patch-1</li>; <li>Additional commits viewable in <a href=""https://github.com/pycqa/mccabe/compare/0.6.1...0.7.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=mccabe&package-manager=pip&previous-version=0.6.1&new-version=0.7.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12449:2435,secur,security-vulnerabilities,2435,https://hail.is,https://github.com/hail-is/hail/pull/12449,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security," <li><a href=""https://github.com/apache/spark/commit/7c465bc3154cdd0d578f837c9b82e4289caf0b14""><code>7c465bc</code></a> Preparing Spark release v3.3.1-rc3</li>; <li><a href=""https://github.com/apache/spark/commit/5fe895a65a4a9d65f81d43af473b5e3a855ed8c8""><code>5fe895a</code></a> [SPARK-40660][SQL][3.3] Switch to XORShiftRandom to distribute elements</li>; <li><a href=""https://github.com/apache/spark/commit/5dc9ba0d22741173bd122afb387c54d7ca4bfb6d""><code>5dc9ba0</code></a> [SPARK-40669][SQL][TESTS] Parameterize <code>rowsNum</code> in <code>InMemoryColumnarBenchmark</code></li>; <li>Additional commits viewable in <a href=""https://github.com/apache/spark/compare/v3.1.3...v3.3.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pyspark&package-manager=pip&previous-version=3.1.3&new-version=3.3.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12455:2437,secur,security-vulnerabilities,2437,https://hail.is,https://github.com/hail-is/hail/pull/12455,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security," <li><strong>BACKWARDS INCOMPATIBLE:</strong> Support for Python 3.6 has been removed.</li>; <li><strong>BACKWARDS INCOMPATIBLE:</strong> Dropped support for LibreSSL &lt; 3.6.</li>; <li>Updated the minimum supported Rust version (MSRV) to 1.56.0, from 1.48.0.</li>; <li>Updated Windows, macOS, and Linux wheels to be compiled with OpenSSL 3.1.1.</li>; <li>Added support for the :class:<code>~cryptography.x509.OCSPAcceptableResponses</code>; OCSP extension.</li>; <li>Added support for the :class:<code>~cryptography.x509.MSCertificateTemplate</code>; proprietary Microsoft certificate extension.</li>; <li>Implemented support for equality checks on all asymmetric public key types.</li>; <li>Added support for <code>aes256-gcm@openssh.com</code> encrypted keys in; :func:<code>~cryptography.hazmat.primitives.serialization.load_ssh_private_key</code>.</li>; <li>Added support for obtaining X.509 certificate signature algorithm parameters; (including PSS) via; :meth:<code>~cryptography.x509.Certificate.signature_algorithm_parameters</code>.</li>; <li>Support signing :class:<code>~cryptography.hazmat.primitives.asymmetric.padding.PSS</code>; X.509 certificates via the new keyword-only argument <code>rsa_padding</code> on; :meth:<code>~cryptography.x509.CertificateBuilder.sign</code>.</li>; <li>Added support for; :class:<code>~cryptography.hazmat.primitives.ciphers.aead.ChaCha20Poly1305</code>; on BoringSSL.</li>; </ul>; <p>.. _v40-0-2:</p>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/pyca/cryptography/commit/d02de9f26e9a2353e89427c1cea8b9ed2bae969e""><code>d02de9f</code></a> changelog and version bump (<a href=""https://redirect.github.com/pyca/cryptography/issues/9008"">#9008</a>)</li>; <li><a href=""https://github.com/pyca/cryptography/commit/53dc686431f59658d892b83383a330d796105843""><code>53dc686</code></a> Backport null fix (<a href=""https://redirect.github.com/pyca/cryptography/issues/9007"">#9007</a>)</li>; <li><a href",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13146:1740,Certificate,Certificate,1740,https://hail.is,https://github.com/hail-is/hail/pull/13146,1,['Certificate'],['Certificate']
Security," <li>Updating documentation around dispatching requests (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3772"">#3772</a>)</li>; <li>Adding documentation for the type guard isAxiosError (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3767"">#3767</a>)</li>; <li>Adding explanation of cancel token (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3803"">#3803</a>)</li>; <li>Updating CI status badge (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3953"">#3953</a>)</li>; <li>Fixing errors with JSON documentation (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3936"">#3936</a>)</li>; <li>Fixing README typo under Request Config (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3825"">#3825</a>)</li>; <li>Adding axios-multi-api to the ecosystem file (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3817"">#3817</a>)</li>; <li>Adding SECURITY.md to properly disclose security vulnerabilities (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3981"">#3981</a>)</li>; </ul>; <p>Huge thanks to everyone who contributed to this release via code (authors listed below) or via reviews and triaging on GitHub:</p>; <ul>; <li><a href=""https://github.com/SashaKoro"">Sasha Korotkov</a></li>; <li><a href=""https://github.com/timemachine3030"">Daniel Lopretto</a></li>; <li><a href=""https://github.com/MikeBishop"">Mike Bishop</a></li>; <li><a href=""https://github.com/DigitalBrainJS"">Dmitriy Mozgovoy</a></li>; <li><a href=""https://github.com/bimbiltu"">Mark</a></li>; <li><a href=""https://github.com/piiih"">Philipe Gouveia Paixão</a></li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/axios/axios/blob/master/CHANGELOG.md"">axios's changelog</a>.</em></p>; <blockquote>; <h3>0.21.2 (September 4, 2021)</h3>; <p>Fixes and Functionality:</p>; <ul>; <li>Upda",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11080:4840,secur,security,4840,https://hail.is,https://github.com/hail-is/hail/pull/11080,2,['secur'],['security']
Security," <li>Updating documentation around dispatching requests (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3772"">#3772</a>)</li>; <li>Adding documentation for the type guard isAxiosError (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3767"">#3767</a>)</li>; <li>Adding explanation of cancel token (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3803"">#3803</a>)</li>; <li>Updating CI status badge (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3953"">#3953</a>)</li>; <li>Fixing errors with JSON documentation (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3936"">#3936</a>)</li>; <li>Fixing README typo under Request Config (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3825"">#3825</a>)</li>; <li>Adding axios-multi-api to the ecosystem file (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3817"">#3817</a>)</li>; <li>Adding SECURITY.md to properly disclose security vulnerabilities (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3981"">#3981</a>)</li>; </ul>; <p>Huge thanks to everyone who contributed to this release via code (authors listed below) or via reviews and triaging on GitHub:</p>; <ul>; <li><a href=""https://github.com/axios/axios/blob/master/mailto:jasonsaayman@gmail.com"">Jay</a></li>; <li><a href=""https://github.com/SashaKoro"">Sasha Korotkov</a></li>; <li><a href=""https://github.com/timemachine3030"">Daniel Lopretto</a></li>; <li><a href=""https://github.com/MikeBishop"">Mike Bishop</a></li>; <li><a href=""https://github.com/DigitalBrainJS"">Dmitriy Mozgovoy</a></li>; <li><a href=""https://github.com/bimbiltu"">Mark</a></li>; <li><a href=""https://github.com/piiih"">Philipe Gouveia Paixão</a></li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/axios/axios/commit/c0c87610911e1edebc923d0e932fea28cdfddae3""><code>c0c8761</code",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11080:10365,secur,security,10365,https://hail.is,https://github.com/hail-is/hail/pull/11080,2,['secur'],['security']
Security," <summary>⚠️ <b>Warning</b></summary>. ```; jupyter 1.0.0 requires notebook, which is not installed.; beautifulsoup4 4.12.2 requires soupsieve, which is not installed.; argon2-cffi-bindings 21.2.0 requires cffi, which is not installed. ```; </details>. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | Insufficient Verification of Data Authenticity <br/>[SNYK-PYTHON-CERTIFI-3164749](https://snyk.io/vuln/SNYK-PYTHON-CERTIFI-3164749) | `certifi:` <br> `2021.10.8 -> 2023.7.22` <br> | No | No Known Exploit ; ![critical severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/c.png ""critical severity"") | Improper Following of a Certificate&#x27;s Chain of Trust <br/>[SNYK-PYTHON-CERTIFI-5805047](https://snyk.io/vuln/SNYK-PYTHON-CERTIFI-5805047) | `certifi:` <br> `2021.10.8 -> 2023.7.22` <br> | No | No Known Exploit ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | Arbitrary Code Execution <br/>[SNYK-PYTHON-IPYTHON-2348630](https://snyk.io/vuln/SNYK-PYTHON-IPYTHON-2348630) | `ipython:` <br> `5.10.0 -> 8.10.0` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | Remote Code Execution (RCE) <br/>[SNYK-PYTHON-IPYTHON-3318382](https://snyk.io/vuln/SNYK-PYTHON-IPYTHON-3318382) | `ipython:` <br> `5.10.0 -> 8.10.0` <br> | No | Proof of Concept ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | Improper Privilege Management <br/>[SNYK-PYTHON-JUPYTERCORE-3063766](https://snyk.io/vuln/SNYK-PYTHON-JUPYTERCORE-3063",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13835:1374,Certificate,Certificate,1374,https://hail.is,https://github.com/hail-is/hail/pull/13835,2,['Certificate'],['Certificate']
Security," Add Windows support to CI (<a href=""https://redirect.github.com/bartdag/py4j/issues/487"">#487</a>)</li>; <li><a href=""https://github.com/py4j/py4j/commit/1c622faa81e983f5ceface5290859d6a49974849""><code>1c622fa</code></a> Migrate nosetest to pytest (<a href=""https://redirect.github.com/bartdag/py4j/issues/481"">#481</a>)</li>; <li><a href=""https://github.com/py4j/py4j/commit/64ba89c5a680218d682161a4a6d952a969d1299b""><code>64ba89c</code></a> Add explanations for releasing Py4J for eclipse. Convert .txt to .md (<a href=""https://redirect.github.com/bartdag/py4j/issues/479"">#479</a>)</li>; <li>See full diff in <a href=""https://github.com/bartdag/py4j/compare/0.10.9.5...0.10.9.7"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=py4j&package-manager=pip&previous-version=0.10.9.5&new-version=0.10.9.7)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12978:2653,secur,security-vulnerabilities,2653,https://hail.is,https://github.com/hail-is/hail/pull/12978,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security," Amazon Redshift Data API service. This feature will support the Redshift destination connector on both public and private accessible Amazon Redshift Clusters and Amazon Redshift Serverless.</li>; <li>api-change:<code>kinesisanalyticsv2</code>: [<code>botocore</code>] Support for Apache Flink 1.15 in Kinesis Data Analytics.</li>; </ul>; <h1>1.26.14</h1>; <ul>; <li>api-change:<code>route53</code>: [<code>botocore</code>] Amazon Route 53 now supports the Asia Pacific (Hyderabad) Region (ap-south-2) for latency records, geoproximity records, and private DNS for Amazon VPCs in that region.</li>; </ul>; <h1>1.26.13</h1>; <ul>; <li>api-change:<code>appflow</code>: [<code>botocore</code>] AppFlow provides a new API called UpdateConnectorRegistration to update a custom connector that customers have previously registered. With this API, customers no longer need to unregister and then register a connector to make an update.</li>; <li>api-change:<code>auditmanager</code>: [<code>botocore</code>] This release introduces a new feature for Audit Manager: Evidence finder. You can now use evidence finder to quickly query your evidence, and add the matching evidence results to an assessment report.</li>; <li>api-change:<code>chime-sdk-voice</code>: [<code>botocore</code>] Amazon Chime Voice Connector, Voice Connector Group and PSTN Audio Service APIs are now available in the Amazon Chime SDK Voice namespace. See <a href=""https://docs.aws.amazon.com/chime-sdk/latest/dg/sdk-available-regions.html"">https://docs.aws.amazon.com/chime-sdk/latest/dg/sdk-available-regions.html</a> for more details.</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/boto/boto3/commit/d872f34494e33473126a887499262c6d3139d0f3""><code>d872f34</code></a> Merge branch 'release-1.26.17'</li>; <li><a href=""https://github.com/boto/boto3/commit/c547ba545c4aeb40bc1848e50d9b89f54df8937c""><code>c547ba5</co",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12507:5912,audit,auditmanager,5912,https://hail.is,https://github.com/hail-is/hail/pull/12507,2,"['Audit', 'audit']","['Audit', 'auditmanager']"
Security," Amazon Redshift Data API service. This feature will support the Redshift destination connector on both public and private accessible Amazon Redshift Clusters and Amazon Redshift Serverless.</li>; <li>api-change:<code>kinesisanalyticsv2</code>: [<code>botocore</code>] Support for Apache Flink 1.15 in Kinesis Data Analytics.</li>; </ul>; <h1>1.26.14</h1>; <ul>; <li>api-change:<code>route53</code>: [<code>botocore</code>] Amazon Route 53 now supports the Asia Pacific (Hyderabad) Region (ap-south-2) for latency records, geoproximity records, and private DNS for Amazon VPCs in that region.</li>; </ul>; <h1>1.26.13</h1>; <ul>; <li>api-change:<code>appflow</code>: [<code>botocore</code>] AppFlow provides a new API called UpdateConnectorRegistration to update a custom connector that customers have previously registered. With this API, customers no longer need to unregister and then register a connector to make an update.</li>; <li>api-change:<code>auditmanager</code>: [<code>botocore</code>] This release introduces a new feature for Audit Manager: Evidence finder. You can now use evidence finder to quickly query your evidence, and add the matching evidence results to an assessment report.</li>; <li>api-change:<code>chime-sdk-voice</code>: [<code>botocore</code>] Amazon Chime Voice Connector, Voice Connector Group and PSTN Audio Service APIs are now available in the Amazon Chime SDK Voice namespace. See <a href=""https://docs.aws.amazon.com/chime-sdk/latest/dg/sdk-available-regions.html"">https://docs.aws.amazon.com/chime-sdk/latest/dg/sdk-available-regions.html</a> for more details.</li>; <li>api-change:<code>cloudfront</code>: [<code>botocore</code>] CloudFront API support for staging distributions and associated traffic management policies.</li>; <li>api-change:<code>connect</code>: [<code>botocore</code>] Added AllowedAccessControlTags and TagRestrictedResource for Tag Based Access Control on Amazon Connect Webpage</li>; <li>api-change:<code>dynamodb</code>: [<code>botoco",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12498:1598,audit,auditmanager,1598,https://hail.is,https://github.com/hail-is/hail/pull/12498,4,"['Audit', 'audit']","['Audit', 'auditmanager']"
Security," Fix python release on macos (<a href=""https://github-redirect.dependabot.com/protocolbuffers/protobuf/issues/10512"">#10512</a>)</li>; <li><a href=""https://github.com/protocolbuffers/protobuf/commit/a826282e15efe3ae3a2aebb040fb1691b2233a1e""><code>a826282</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/protocolbuffers/protobuf/issues/10505"">#10505</a> from deannagarcia/3.20.x</li>; <li><a href=""https://github.com/protocolbuffers/protobuf/commit/7639a710e10beb47bfc62f363680f7b04e8b3d26""><code>7639a71</code></a> Add version file</li>; <li>Additional commits viewable in <a href=""https://github.com/protocolbuffers/protobuf/compare/v3.20.1...v3.20.2"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=protobuf&package-manager=pip&previous-version=3.20.1&new-version=3.20.2)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12223:3117,secur,security-vulnerabilities,3117,https://hail.is,https://github.com/hail-is/hail/pull/12223,6,['secur'],"['security-updates', 'security-vulnerabilities']"
Security," Keep Authorization header on subdomain redirects.</li>; <li><a href=""https://github.com/follow-redirects/follow-redirects/commit/2ad9e82b6277ae2104f7770e9ff1186cc6da29d4""><code>2ad9e82</code></a> Carry over Host header on relative redirects (<a href=""https://github-redirect.dependabot.com/follow-redirects/follow-redirects/issues/172"">#172</a>)</li>; <li><a href=""https://github.com/follow-redirects/follow-redirects/commit/77e2a581e1d1811674b7b74745a9c20a5b939488""><code>77e2a58</code></a> Release version 1.14.4 of the npm package.</li>; <li>Additional commits viewable in <a href=""https://github.com/follow-redirects/follow-redirects/compare/v1.14.1...v1.14.7"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=follow-redirects&package-manager=npm_and_yarn&previous-version=1.14.1&new-version=1.14.7)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11283:2552,secur,security-vulnerabilities,2552,https://hail.is,https://github.com/hail-is/hail/pull/11283,4,['secur'],"['security-updates', 'security-vulnerabilities']"
Security," No | No Known Exploit ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | **604/1000** <br/> **Why?** Has a fix available, CVSS 7.8 | Improper Privilege Management <br/>[SNYK-PYTHON-JUPYTERCORE-3063766](https://snyk.io/vuln/SNYK-PYTHON-JUPYTERCORE-3063766) | `jupyter-core:` <br> `4.6.3 -> 4.11.2` <br> | No | No Known Exploit ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | **589/1000** <br/> **Why?** Has a fix available, CVSS 7.5 | Regular Expression Denial of Service (ReDoS) <br/>[SNYK-PYTHON-MISTUNE-2940625](https://snyk.io/vuln/SNYK-PYTHON-MISTUNE-2940625) | `mistune:` <br> `0.8.4 -> 2.0.3` <br> | No | No Known Exploit ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | **726/1000** <br/> **Why?** Proof of Concept exploit, Has a fix available, CVSS 8.1 | Cross-site Scripting (XSS) <br/>[SNYK-PYTHON-NBCONVERT-2979829](https://snyk.io/vuln/SNYK-PYTHON-NBCONVERT-2979829) | `nbconvert:` <br> `5.6.1 -> 6.3.0b0` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **434/1000** <br/> **Why?** Has a fix available, CVSS 4.4 | Open Redirect <br/>[SNYK-PYTHON-NOTEBOOK-1041707](https://snyk.io/vuln/SNYK-PYTHON-NOTEBOOK-1041707) | `notebook:` <br> `5.7.16 -> 6.4.12` <br> | No | No Known Exploit ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | **589/1000** <br/> **Why?** Has a fix available, CVSS 7.5 | Information Exposure <br/>[SNYK-PYTHON-NOTEBOOK-2441824](https://snyk.io/vuln/SNYK-PYTHON-NOTEBOOK-2441824) | `notebook:` <br> `5.7.16 -> 6.4.12` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **449/1000** <br/> **Why?** Has a ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14205:4034,Cross-site Scripting,Cross-site Scripting,4034,https://hail.is,https://github.com/hail-is/hail/pull/14205,2,"['Cross-site Scripting', 'XSS']","['Cross-site Scripting', 'XSS']"
Security," No | Proof of Concept ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | **604/1000** <br/> **Why?** Has a fix available, CVSS 7.8 | Improper Privilege Management <br/>[SNYK-PYTHON-JUPYTERCORE-3063766](https://snyk.io/vuln/SNYK-PYTHON-JUPYTERCORE-3063766) | `jupyter-core:` <br> `4.6.3 -> 4.11.2` <br> | No | No Known Exploit ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | **589/1000** <br/> **Why?** Has a fix available, CVSS 7.5 | Regular Expression Denial of Service (ReDoS) <br/>[SNYK-PYTHON-MISTUNE-2940625](https://snyk.io/vuln/SNYK-PYTHON-MISTUNE-2940625) | `mistune:` <br> `0.8.4 -> 2.0.3` <br> | No | No Known Exploit ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | **726/1000** <br/> **Why?** Proof of Concept exploit, Has a fix available, CVSS 8.1 | Cross-site Scripting (XSS) <br/>[SNYK-PYTHON-NBCONVERT-2979829](https://snyk.io/vuln/SNYK-PYTHON-NBCONVERT-2979829) | `nbconvert:` <br> `5.6.1 -> 6.3.0b0` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **434/1000** <br/> **Why?** Has a fix available, CVSS 4.4 | Open Redirect <br/>[SNYK-PYTHON-NOTEBOOK-1041707](https://snyk.io/vuln/SNYK-PYTHON-NOTEBOOK-1041707) | `notebook:` <br> `5.7.16 -> 6.4.12` <br> | No | No Known Exploit ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | **589/1000** <br/> **Why?** Has a fix available, CVSS 7.5 | Information Exposure <br/>[SNYK-PYTHON-NOTEBOOK-2441824](https://snyk.io/vuln/SNYK-PYTHON-NOTEBOOK-2441824) | `notebook:` <br> `5.7.16 -> 6.4.12` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **449/1000** <br/> **Why?** Has a ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13717:3342,Cross-site Scripting,Cross-site Scripting,3342,https://hail.is,https://github.com/hail-is/hail/pull/13717,4,"['Cross-site Scripting', 'XSS']","['Cross-site Scripting', 'XSS']"
Security," Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **591/1000** <br/> **Why?** Proof of Concept exploit, Has a fix available, CVSS 5.4 | Improper Input Validation <br/>[SNYK-PYTHON-AIOHTTP-6091622](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-6091622) | `aiohttp:` <br> `3.8.6 -> 3.9.0` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **531/1000** <br/> **Why?** Proof of Concept exploit, Has a fix available, CVSS 4.2 | Remote Code Execution (RCE) <br/>[SNYK-PYTHON-IPYTHON-3318382](https://snyk.io/vuln/SNYK-PYTHON-IPYTHON-3318382) | `ipython:` <br> `7.34.0 -> 8.10.0` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **444/1000** <br/> **Why?** Has a fix available, CVSS 4.6 | Access Control Bypass <br/>[SNYK-PYTHON-JUPYTERSERVER-5862881](https://snyk.io/vuln/SNYK-PYTHON-JUPYTERSERVER-5862881) | `jupyter-server:` <br> `1.24.0 -> 2.11.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **429/1000** <br/> **Why?** Has a fix available, CVSS 4.3 | Open Redirect <br/>[SNYK-PYTHON-JUPYTERSERVER-5862882](https://snyk.io/vuln/SNYK-PYTHON-JUPYTERSERVER-5862882) | `jupyter-server:` <br> `1.24.0 -> 2.11.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **501/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 4.3 | Generation of Error Message Containing Sensitive Information <br/>[SNYK-PYTHON-JUPYTERSERVER-6099119](https://snyk.io/vuln/SNYK-PYTHON-JUPYTERSERVER-6099119) | `jupyter-server:` <br> `1.24.0 -> 2.11.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/s",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14109:2381,Access,Access,2381,https://hail.is,https://github.com/hail-is/hail/pull/14109,1,['Access'],['Access']
Security," Redirect <br/>[SNYK-PYTHON-TORNADO-5537286](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-5537286) | `tornado:` <br> `5.1.1 -> 6.3.3` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **494/1000** <br/> **Why?** Has a fix available, CVSS 5.6 | HTTP Request Smuggling <br/>[SNYK-PYTHON-TORNADO-5840803](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-5840803) | `tornado:` <br> `5.1.1 -> 6.3.3` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiIyMjlkNGUyNC0xMDE4LTQ5ZDItYTQ3NC04MmViZDVhNzZlMDEiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjIyOWQ0ZTI0LTEwMTgtNDlkMi1hNDc0LTgyZWJkNWE3NmUwMSJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""229d4e24-1018-49d2-a474-82ebd5a76e01"",""pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13717:9144,access,access,9144,https://hail.is,https://github.com/hail-is/hail/pull/13717,2,"['access', 'authoriz']","['access', 'authorized']"
Security," Security. Preceded by Secure Sockets Layer (SSL) which; is not obsolete and insecure. After SSL version 3, a new version of SSL was; proposed in RFC 2246. This new version was backwards-incompatible and was; thus given a new name: Transport Layer Security. In common discussion, SSL; and TLS are used interchangeable. Indeed, the python TLS library is called; `ssl`. [2] Forward secrecy is a property of an encryption system. Forward secrecy means; a message cannot be decrypted in the future by an adversary who learned one; of the private keys. For example, imagine you are sending sensitive messages; to another individual. If that individual is later coerced into revealing; their secret key, forward secrecy would prevent the coercer from reading; your messages. Forward secrecy is achieved by negotiating a shared private; key between the two parties that is only used for a ""session"" and then; discarded. If the session key is securely discarded and neither key can; recreate it without cooperation from the other key, then *one* leaked key is; insufficient to reveal the messages. ---. Things for you to verify:; - does every service load *its own unqiue* ssl-config secret?; - does every service use an SSL context for serving?; - does everyone who makes http requests to internal services use an SSL client; session?; - do all TLS-secured nginx instances include their http.conf in the `http`; section and the `proxy.conf` file in any proxying sections?; - Do the SSLContext's from `ssl.py` and the nginx configurations generated by; `create_certs.py` actually ensure security?. Post-merge actions:; - deploy gateway; - deploy internal-gateway; - deploy router-resolver. Anticipated outages:. - Before a service is redeployed it will be inaccessible from the outside; because the router will try to speak to it on HTTPS. Services that speak to; one another (ci<->batch, everyone<->auth) will lose connections while the; deploy is happening. Deploy should move smoothly because CI will compl",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8561:12508,secur,securely,12508,https://hail.is,https://github.com/hail-is/hail/pull/8561,1,['secur'],['securely']
Security," StandardHCAnnotation --dbsnp /home/fgc3/dbsnp/150/GRCh38/All_20170710.vcf.gz --variant 3P5CH.new.g.vcf.gz --reference /home/fgc3/10x/refdata-GRCh38-2.1.0/fasta/genome.fa --create-output-variant-index false --verbosity ERROR --annotate-with-num-discovered-alleles false --heterozygosity 0.001 --indel-heterozygosity 1.25E-4 --heterozygosity-stdev 0.01 --standard-min-confidence-threshold-for-calling 10.0 --max-alternate-alleles 6 --max-genotype-count 1024 --sample-ploidy 2 --disable-tool-default-annotations false --only-output-calls-starting-in-intervals false --interval-set-rule UNION --interval-padding 0 --interval-exclusion-padding 0 --interval-merging-rule ALL --read-validation-stringency SILENT --seconds-between-progress-updates 10.0 --disable-sequence-dictionary-validation false --create-output-bam-index true --create-output-bam-md5 false --create-output-variant-md5 false --lenient false --add-output-sam-program-record true --add-output-vcf-command-line true --cloud-prefetch-buffer 40 --cloud-index-prefetch-buffer -1 --disable-bam-index-caching false --help false --version false --showHidden false --QUIET false --use-jdk-deflater false --use-jdk-inflater false --gcs-max-retries 20 --disable-tool-default-read-filters false"",Version=4.0.1.2,Date=""March 22, 2018 1:12:03 AM EDT"">; ##INFO=<ID=ClippingRankSum,Number=1,Type=Float,Description=""Z-score From Wilcoxon rank sum test of Alt vs. Ref number of hard clipped bases"">; ##INFO=<ID=DB,Number=0,Type=Flag,Description=""dbSNP Membership"">; ##INFO=<ID=END,Number=1,Type=Integer,Description=""Stop position of the interval"">; ##VEP=""v91"" time=""2018-03-22 04:15:25"" cache=""/media/SE5/.vep/homo_sapiens/91_GRCh38"" db=""homo_sapiens_core_91_38@ensembldb.ensembl.org"" ensembl-variation=91.c78d8b4 ensembl-funcgen=91.4681d69 ensembl-io=91.923d668 ensembl=91.18ee742 1000genomes=""phase3"" COSMIC=""82"" ClinVar=""201710"" ESP=""V2-SSA137"" HGMD-PUBLIC=""20172"" assembly=""GRCh38.p10"" dbSNP=""150"" gencode=""GENCODE 27"" genebuild=""2014-07"" gnomAD=""1702",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8469:23849,validat,validation,23849,https://hail.is,https://github.com/hail-is/hail/issues/8469,1,['validat'],['validation']
Security," [<code>botocore</code>] This release includes a new feature for customers to calculate the position of their devices by adding three new APIs: UpdateResourcePosition, GetResourcePosition, and GetPositionEstimate.</li>; <li>api-change:<code>kendra</code>: [<code>botocore</code>] Amazon Kendra now supports preview of table information from HTML tables in the search results. The most relevant cells with their corresponding rows, columns are displayed as a preview in the search result. The most relevant table cell or cells are also highlighted in table preview.</li>; <li>api-change:<code>logs</code>: [<code>botocore</code>] Updates to support CloudWatch Logs data protection and CloudWatch cross-account observability</li>; <li>api-change:<code>mgn</code>: [<code>botocore</code>] This release adds support for Application and Wave management. We also now support custom post-launch actions.</li>; <li>api-change:<code>oam</code>: [<code>botocore</code>] Amazon CloudWatch Observability Access Manager is a new service that allows configuration of the CloudWatch cross-account observability feature.</li>; <li>api-change:<code>organizations</code>: [<code>botocore</code>] This release introduces delegated administrator for AWS Organizations, a new feature to help you delegate the management of your Organizations policies, enabling you to govern your AWS organization in a decentralized way. You can now allow member accounts to manage Organizations policies.</li>; <li>api-change:<code>rds</code>: [<code>botocore</code>] This release enables new Aurora and RDS feature called Blue/Green Deployments that makes updates to databases safer, simpler and faster.</li>; <li>api-change:<code>textract</code>: [<code>botocore</code>] This release adds support for classifying and splitting lending documents by type, and extracting information by using the Analyze Lending APIs. This release also includes support for summarized information of the processed lending document package, in addition to",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12507:2851,Access,Access,2851,https://hail.is,https://github.com/hail-is/hail/pull/12507,1,['Access'],['Access']
Security," _intervals=intervals). - reference_data = VariantDataset._add_len_end(reference_data); + # if LEN is missing, add it, _add_len is a no-op if LEN is already present; + reference_data = VariantDataset._add_len(reference_data); if _drop_end:; - reference_data = reference_data.drop('END'); + if 'END' in reference_data.entry:; + reference_data = reference_data.drop('END'); + else: # if END is missing, add it, _add_end is a no-op if END is already present; + reference_data = VariantDataset._add_end(reference_data); +; vds = VariantDataset(reference_data, variant_data); if VariantDataset.ref_block_max_length_field not in vds.reference_data.globals:; fs = hl.current_backend().fs; ```. There was nothing in the IR that stood out when I examined it, but I will admit that I'm not the best at digging into it. ### Version. https://github.com/chrisvittal/hail/tree/vds/repro-example. ### Relevant log output. ```shell; E hail.utils.java.FatalError: RuntimeException: invalid memory access: 140a68008/00000001: not in 140a58008/00010000; E; E Java stack trace:; E java.lang.RuntimeException: invalid memory access: 140a68008/00000001: not in 140a58008/00010000; E 	at is.hail.annotations.Memory.checkAddress(Memory.java:226); E 	at is.hail.annotations.Memory.loadByte(Memory.java:130); E 	at is.hail.annotations.Region$.loadByte(Region.scala:28); E 	at is.hail.annotations.Region$.loadBit(Region.scala:86); E 	at __C23148collect_distributed_array_matrix_native_writer.__m23333split_ToArray(Unknown Source); E 	at __C23148collect_distributed_array_matrix_native_writer.apply_region478_486(Unknown Source); E 	at __C23148collect_distributed_array_matrix_native_writer.apply_region16_503(Unknown Source); E 	at __C23148collect_distributed_array_matrix_native_writer.apply_region14_529(Unknown Source); E 	at __C23148collect_distributed_array_matrix_native_writer.apply(Unknown Source); E 	at __C23148collect_distributed_array_matrix_native_writer.apply(Unknown Source); E 	at is.hail.backend.BackendUtils.$a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14705:2306,access,access,2306,https://hail.is,https://github.com/hail-is/hail/issues/14705,1,['access'],['access']
Security," a real user.</p><br /><h3>Snyk has created this PR to fix one or more vulnerable packages in the `pip` dependencies of this project.</h3>. #### Changes included in this PR. - Changes to the following files to upgrade the vulnerable dependencies to a fixed version:; - web_common/requirements.txt. <details>; <summary>⚠️ <b>Warning</b></summary>. ```; aiohttp-jinja2 1.5.1 requires aiohttp, which is not installed. ```; </details>. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **663/1000** <br/> **Why?** Proof of Concept exploit, Recently disclosed, Has a fix available, CVSS 5.4 | Improper Input Validation <br/>[SNYK-PYTHON-AIOHTTP-6091621](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-6091621) | `aiohttp:` <br> `3.8.6 -> 3.9.0` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **663/1000** <br/> **Why?** Proof of Concept exploit, Recently disclosed, Has a fix available, CVSS 5.4 | Improper Input Validation <br/>[SNYK-PYTHON-AIOHTTP-6091622](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-6091622) | `aiohttp:` <br> `3.8.6 -> 3.9.0` <br> | No | Proof of Concept . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this b",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14037:1049,Validat,Validation,1049,https://hail.is,https://github.com/hail-is/hail/pull/14037,1,['Validat'],['Validation']
Security," an error since `start` has no option `--beta`. This PR rewrites argument parsing to use click instead of argparse: https://click.palletsprojects.com/en/7.x/. Things you need to know about click:; - A group is a group of commands or subgroups, like `hailctl dataproc`, `hailctl batch`, etc. Groups are defined like this:; ; ```; @hailctl.group(; help=""Manage the Hail Batch service.""); def batch():; pass; ```; - A command in a group is defined like this:. ```; @batch.command(; help=""Get a particular batch's info.""); @click.argument('batch_id', type=int); @click.option('--output-format', '-o',; type=click.Choice(['yaml', 'json']),; default='yaml', show_default=True,; help=""Specify output format"",); def get(batch_id, output_format):; ...; ```. The command decorator replaces the function with one that takes a `List[str]` of command line parameters, parses them, and calls the original function. The option options are pretty self-explanatory. - To access an argument to a group (like `dataproc --beta`) in a (sub)command, use the decorator `click.pass_context` to pass the click context which allows you to access parent group parameters. `dataproc start` is an example:. ```; @dataproc.command(; help=""Start a Dataproc cluster configured for Hail.""); @click.argument('cluster_name'); ...; @click.pass_context; def start(ctx, cluster_name, ...):; beta = ctx.parent.params['beta']; ```. The help output for a group looks like this:. ```; $ hailctl dataproc --help; Usage: hailctl dataproc [OPTIONS] COMMAND [ARGS]... Manage and monitor Hail deployments. Options:; --beta Force use of `beta` in gcloud commands; --help Show this message and exit. Commands:; connect Connect to a running Dataproc cluster; describe Gather information about a Hail (Table or MatrixTable) file...; diagnose Diagnose problems in a Dataproc cluster.; list List Dataproc clusters.; modify; start Start a Dataproc cluster configured for Hail.; stop Shut down a Dataproc cluster.; submit Submit a Python script to a runnin",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9842:2214,access,access,2214,https://hail.is,https://github.com/hail-is/hail/pull/9842,1,['access'],['access']
Security," and 3.7 (<a href=""https://redirect.github.com/pyasn1/pyasn1-modules/issues/14"">#14</a>)</li>; <li><a href=""https://github.com/pyasn1/pyasn1-modules/commit/9ec54091547330aaf994e82ba759cb1fe071e070""><code>9ec5409</code></a> Drop support for EOL Python 2.7 (<a href=""https://redirect.github.com/pyasn1/pyasn1-modules/issues/12"">#12</a>)</li>; <li><a href=""https://github.com/pyasn1/pyasn1-modules/commit/252ac00bf1e119a044cc579ffade30164e2cdfff""><code>252ac00</code></a> Add support for Python 3.12 (<a href=""https://redirect.github.com/pyasn1/pyasn1-modules/issues/11"">#11</a>)</li>; <li>See full diff in <a href=""https://github.com/pyasn1/pyasn1-modules/compare/v0.3.0...v0.4.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pyasn1-modules&package-manager=pip&previous-version=0.3.0&new-version=0.4.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14472:2382,secur,security-vulnerabilities,2382,https://hail.is,https://github.com/hail-is/hail/pull/14472,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security," and Java 11, and the minimal supported Java version will be Java 17; > Support for Scala 2.12, and the minimal supported Scala version will be 2.13. Also, requiring specifically Java 8 or 11 has led to some friction for students and researchers who are first evaluating hail. In the past few weeks, I've talked to a lot of students and researchers who wanted to evaluate hail, followed the documentation to install Azul Java 8 but already had an existing Java install and did not update their PATH or JAVA_HOME. Most of their existing Java versions were 17, as 17 is the current default on most Linux distros and a common one to have been installed via Brew in the past few years on Mac. Alternatively, if you don't want to allow Java 17, potentially Hail could bundle a JRE with it in the PyPI distributable? Using jdeps on the Hail shadow jar, I saw that it only needs these modules in a JRE:; ```; java.base,java.compiler,java.desktop,java.management,java.naming,java.rmi,java.scripting,java.security.jgss,java.sql,jdk.httpserver,jdk.unsupported; ```. That means that a JRE created with jlink like this:; ```; jlink --add-modules java.base,java.compiler,java.desktop,java.management,java.naming,java.rmi,java.scripting,java.security.jgss,java.sql,jdk.httpserver,jdk.unsupported --output minimaljre --strip-debug --no-man-pages --no-header-files --compress=2; ```; comes in at under 30MB gzipped, which would increase the PyPI package by about 20% in size, while allowing users to install and run Hail in _any_ supported python environment without having to consider Java versions at all. Alternatively, have you ever considered distributing Hail through conda-forge or bioconda, where you could specify a JRE that should be installed with it and automatically linked?. Is there a better channel than Github Issues for feature requests? I realize this is not a bug report, and if you want to just close it and say ""nope"" that's fine, but I've seen a good number of first-time hail users get a bad i",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14433:2305,secur,security,2305,https://hail.is,https://github.com/hail-is/hail/issues/14433,1,['secur'],['security']
Security," and lazy=True</li>; <li><a href=""https://github.com/fonttools/fonttools/commit/1d5feb81e597db8faa53695315befbccf0075b2e""><code>1d5feb8</code></a> ttFont_test: add reproducer for SpooledTemporaryFile has no seekable</li>; <li><a href=""https://github.com/fonttools/fonttools/commit/f1c609aa57fa11ab98f2152275f2c709e06c0680""><code>f1c609a</code></a> .readthedocs.yml: don't use 'legacy' build specification</li>; <li><a href=""https://github.com/fonttools/fonttools/commit/f9b941d226242c6b481e752036654aa346409036""><code>f9b941d</code></a> use python3.10 for ReadTheDocs</li>; <li>Additional commits viewable in <a href=""https://github.com/fonttools/fonttools/compare/4.38.0...4.39.3"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=fonttools&package-manager=pip&previous-version=4.38.0&new-version=4.39.3)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12910:17326,secur,security-vulnerabilities,17326,https://hail.is,https://github.com/hail-is/hail/pull/12910,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security," architectures were part of 5.10) - <a href=""https://github.com/matthiasblaesing""><code>@​matthiasblaesing</code></a>.</li>; <li><a href=""https://github-redirect.dependabot.com/java-native-access/jna/issues/1404"">#1404</a>: Added Solaris Kstat2 library - <a href=""https://github.com/dbwiddis""><code>@​dbwiddis</code></a>.</li>; <li><a href=""https://github-redirect.dependabot.com/java-native-access/jna/pull/1416"">#1416</a>: Add <code>CFDictionaryGetCount</code> to <code>c.s.j.p.mac.CoreFoundation</code> - <a href=""https://github.com/shalupov""><code>@​shalupov</code></a></li>; <li><a href=""https://github-redirect.dependabot.com/java-native-access/jna/pull/1418"">#1418</a>: Add <code>CertOpenStore</code> to <code>c.s.j.p.win32.Crypt32</code> - <a href=""https://github.com/shalupov""><code>@​shalupov</code></a></li>; </ul>; <h2>Bug Fixes</h2>; <ul>; <li><a href=""https://github-redirect.dependabot.com/java-native-access/jna/pull/1411"">#1411</a>: Do not throw <code>Win32Exception</code> on success for empty section in <code>Kernel32Util#getPrivateProfileSection</code> - <a href=""https://github.com/mkarg""><code>@​mkarg</code></a>.</li>; <li><a href=""https://github-redirect.dependabot.com/java-native-access/jna/pull/1414"">#1414</a>: Fix definition of <code>c.s.j.p.unix.X11.XK_Shift_R</code> - <a href=""https://github.com/matthiasblaesing""><code>@​matthiasblaesing</code></a>.</li>; <li><a href=""https://github-redirect.dependabot.com/java-native-access/jna/issues/1323"">#1323</a>. Fix crashes in direct callbacks on mac OS aarch64 - <a href=""https://github.com/matthiasblaesing""><code>@​matthiasblaesing</code></a>.</li>; <li><a href=""https://github-redirect.dependabot.com/java-native-access/jna/pull/1422"">#1422</a>: Load jawt library relative to <code>sun.boot.library.path</code> system on unix OSes - <a href=""https://github.com/matthiasblaesing""><code>@​matthiasblaesing</code></a>.</li>; <li><a href=""https://github-redirect.dependabot.com/java-native-access/jna/pull/1427"">#1427</a>: R",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12438:4017,access,access,4017,https://hail.is,https://github.com/hail-is/hail/pull/12438,1,['access'],['access']
Security," because this PR addresses questions of state and will take care of this. ```python; self.exit_code = pod.status.container_statuses[0].state.terminated.exit_code; ```. We should probably do something like . ```python; self.exit_code = max(status.state.terminated.exit_code for status in pod.status.container_statuses); ```; although I also see that in update_job_with_pod we effectively restrict to a single container. I'm not sure why this limit exists, but if needed, should probably occur during creation. In the upcoming PR, which moves state to MySQL 5.7+, and a different server model (async), I think it would be neat to represent meta-state (across all containers, and potentially the job subgraph whose first node is the inspected job) as:. ```go; const (; 	Cancelled = -3; 	Initialized = -2; 	Created = -1; ); ```. with values >=0 being the maximum of the linux error codes, 0-255, of the subgraph. Simple queries. Alternative is to use NULL when not completed, but when used in a client would require a null check, or potentially have surprising side effects (i.e where the default value is 0). We could also use a separate, text-based status field, but I will store a queryable JSON field containing the full status as well. In a similar vein, we have some state race conditions. For instance:. ```python; self.pod_template = kube.client.V1Pod(; metadata=kube.client.V1ObjectMeta(generate_name='job-{}-'.format(self.id),; labels={; 'app': 'batch-job',; 'hail.is/batch-instance': instance_id,; 'uuid': uuid.uuid4().hex; }),; spec=pod_spec). self._pod_name = None; self.exit_code = None. self._state = 'Created'; log.info('created job {}'.format(self.id)). self._create_pod(); ```. Here, every time pod creation fails, _state will be misaligned, and will have potential side effects (say in get_log). One solution could be to validate and rewind state in _create_pod. In any case, I will do my best to address state questions in the upcoming PR, and will close this when / if we approve it.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5118:1919,validat,validate,1919,https://hail.is,https://github.com/hail-is/hail/issues/5118,1,['validat'],['validate']
Security," checking of node.docstring (<a href=""https://github-redirect.dependabot.com/PyCQA/pyflakes/issues/704"">#704</a>)</li>; <li><a href=""https://github.com/PyCQA/pyflakes/commit/405a0906c8debafaae419472d3f51b84b7ba5c49""><code>405a090</code></a> simplify PYPY check (<a href=""https://github-redirect.dependabot.com/PyCQA/pyflakes/issues/703"">#703</a>)</li>; <li><a href=""https://github.com/PyCQA/pyflakes/commit/30ec8589e183f76f40764a8dd78591719f521943""><code>30ec858</code></a> remove unused WIN (<a href=""https://github-redirect.dependabot.com/PyCQA/pyflakes/issues/702"">#702</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/PyCQA/pyflakes/compare/2.4.0...2.5.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pyflakes&package-manager=pip&previous-version=2.4.0&new-version=2.5.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12149:3825,secur,security-vulnerabilities,3825,https://hail.is,https://github.com/hail-is/hail/pull/12149,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security," configuration file that configures TLS for; outgoing (proxy_pass) requests.; - `site-key.pem`: a private key.; - `site-cert.pem`: a certificate.; - `site-incoming.pem`: a list of certificates trusted for incoming requests.; - `site-outgoing.pem`: a list of certificates expected from outgoing requests. If site makes an HTTP request to a server and that server does not return a; certificate in `site-outgoing.pem`, it will immediately halt the connection. I; intend (though do not currently) site to also reject incoming requests that are; not accompanied by a certificate in `site-incoming.pem`. I describe the [trouble; with that later](#incoming-trust). There are two other kinds: `json` and `curl`. The former is for Hail Python; services. The later is for the admin-pod and image-fetcher. Deploy will run `create_certs` on every master deploy. Newly deployed services; will be unable to talk to not-yet-deployed services. I include the; one-deploy-ago certificates in the trust chains, but once incoming trust is; fixed, I am unsure how to smoothly upgrade services. I probably need to notify; old services to refresh their certificates after the secrets are updated. ### Incoming Trust. Mutual TLS (mTLS) refers to TLS connections wherein both sides are; authenticated. This is rare on the web. In our system, it means verifying that a; request made to you carries a certificate in the `NAME-incoming.pem` file. I; cannot enable that in this PR because the three unmanaged services,; router-resolver, internal-gateway, and gateway, do not currently have; certificates. As a result, all the services in the PR namespace reject the; requests from the unmangaed services. In particular, batch pods cannot; communicate with batch-driver. After this PR is deployed and the unmanaged services have certificates, I can; enable mutual TLS. I've marked the tow lines that need to change with `# FIXME:; mTLS`. ### Batch Confused Deputy. The [confused deputy; problem](https://en.wikipedia.org/wiki/Conf",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8561:8176,certificate,certificates,8176,https://hail.is,https://github.com/hail-is/hail/pull/8561,1,['certificate'],['certificates']
Security," extension. This allows multiple files to be downloaded in parallel if the download extension is used. For normal download tasks, multiple files were downloaded in parallel already.</li>; </ul>; <h2>5.1.3</h2>; <p>Bug fixes:</p>; <ul>; <li>Initialize progress logger just before the download starts (see <a href=""https://github-redirect.dependabot.com/michel-kraemer/gradle-download-task/issues/243"">#243</a>)</li>; </ul>; <h2>5.1.2</h2>; <p>Bug fixes:</p>; <ul>; <li>Do not include default HTTP and HTTPS ports in <code>Host</code> header unless explicitly specified by the user</li>; </ul>; <h2>5.1.1</h2>; <p>Bug fixes:</p>; <ul>; <li>Correctly update cached sources</li>; </ul>; <p>Maintenance:</p>; <ul>; <li>Add integration tests for Gradle 7.5 and 7.5.1</li>; <li>Update dependencies</li>; </ul>; <h2>5.1.0</h2>; <p>New features:</p>; <ul>; <li>Add possibility to enable preemptive Basic authentication (through the new <code>preemptiveAuth</code> flag)</li>; <li>Warn if server does not send <code>WWW-Authenticate</code> header in 401 response</li>; <li>Log request and response headers in debug mode</li>; </ul>; <p>Maintenance:</p>; <ul>; <li>Add integration tests for Gradle 7.4.1 and 7.4.2</li>; <li>Update dependencies</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/0f43ce67de72bd511d849c07bd7728c0d6f2e6dd""><code>0f43ce6</code></a> Document path and relativePath properties</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/a8504f9d60d0264808894e4bb80d4a73b8086a3e""><code>a8504f9</code></a> Bump up version number to 5.3.0</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/708067cd11c4a013da7a8c15d91f7f946967cf94""><code>708067c</code></a> Update dependencies</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/0fdebf3c7ad43ed4739",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12345:2688,authenticat,authentication,2688,https://hail.is,https://github.com/hail-is/hail/pull/12345,2,"['Authenticat', 'authenticat']","['Authenticate', 'authentication']"
Security," extension. This allows multiple files to be downloaded in parallel if the download extension is used. For normal download tasks, multiple files were downloaded in parallel already.</li>; </ul>; <h2>5.1.3</h2>; <p>Bug fixes:</p>; <ul>; <li>Initialize progress logger just before the download starts (see <a href=""https://github-redirect.dependabot.com/michel-kraemer/gradle-download-task/issues/243"">#243</a>)</li>; </ul>; <h2>5.1.2</h2>; <p>Bug fixes:</p>; <ul>; <li>Do not include default HTTP and HTTPS ports in <code>Host</code> header unless explicitly specified by the user</li>; </ul>; <h2>5.1.1</h2>; <p>Bug fixes:</p>; <ul>; <li>Correctly update cached sources</li>; </ul>; <p>Maintenance:</p>; <ul>; <li>Add integration tests for Gradle 7.5 and 7.5.1</li>; <li>Update dependencies</li>; </ul>; <h2>5.1.0</h2>; <p>New features:</p>; <ul>; <li>Add possibility to enable preemptive Basic authentication (through the new <code>preemptiveAuth</code> flag)</li>; <li>Warn if server does not send <code>WWW-Authenticate</code> header in 401 response</li>; <li>Log request and response headers in debug mode</li>; </ul>; <p>Maintenance:</p>; <ul>; <li>Add integration tests for Gradle 7.4.1 and 7.4.2</li>; <li>Update dependencies</li>; </ul>; <h2>5.0.5</h2>; <p>Maintenance:</p>; <ul>; <li>Publish signed artifacts to Gradle plugin portal</li>; <li>Update dependencies</li>; </ul>; <h2>5.0.4</h2>; <p>Bug fixes:</p>; <ul>; <li>Fix deadlock in <code>DownloadExtension</code> if <code>max-workers</code> equals 1 (thanks to <a href=""https://github.com/beatbrot""><code>@​beatbrot</code></a> for spotting this, see <a href=""https://github-redirect.dependabot.com/michel-kraemer/gradle-download-task/issues/205"">#205</a>)</li>; </ul>; <p>Maintenance:</p>; <ul>; <li>Update dependencies</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/1b5d69",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12332:1969,authenticat,authentication,1969,https://hail.is,https://github.com/hail-is/hail/pull/12332,2,"['Authenticat', 'authenticat']","['Authenticate', 'authentication']"
Security," extra dependency</li>; <li><a href=""https://github.com/tqdm/tqdm/commit/4a1d10e19fdca00db47fd50725715dc5e4aa68e6""><code>4a1d10e</code></a> consistent ordering</li>; <li><a href=""https://github.com/tqdm/tqdm/commit/bf6c960f60f8a390b47ac55d2ece3ffc419e5dcd""><code>bf6c960</code></a> emoji bars</li>; <li><a href=""https://github.com/tqdm/tqdm/commit/7994aa8285743b351cf1a3b36275335d8d0730b7""><code>7994aa8</code></a> warn once on error</li>; <li><a href=""https://github.com/tqdm/tqdm/commit/a1d4401f186dc5a79b4ad452f38cae75e1f2e6da""><code>a1d4401</code></a> remove unneeded variable</li>; <li>Additional commits viewable in <a href=""https://github.com/tqdm/tqdm/compare/v4.42.1...v4.64.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=tqdm&package-manager=pip&previous-version=4.42.1&new-version=4.64.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12260:5964,secur,security-vulnerabilities,5964,https://hail.is,https://github.com/hail-is/hail/pull/12260,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security," fix one or more vulnerable packages in the `pip` dependencies of this project.</h3>. #### Changes included in this PR. - Changes to the following files to upgrade the vulnerable dependencies to a fixed version:; - hail/python/hailtop/requirements.txt. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | Insufficient Verification of Data Authenticity <br/>[SNYK-PYTHON-CERTIFI-3164749](https://snyk.io/vuln/SNYK-PYTHON-CERTIFI-3164749) | `certifi:` <br> `2021.10.8 -> 2023.7.22` <br> | No | No Known Exploit ; ![critical severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/c.png ""critical severity"") | Improper Following of a Certificate&#x27;s Chain of Trust <br/>[SNYK-PYTHON-CERTIFI-5805047](https://snyk.io/vuln/SNYK-PYTHON-CERTIFI-5805047) | `certifi:` <br> `2021.10.8 -> 2023.7.22` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3172287](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3172287) | `cryptography:` <br> `3.3.2 -> 41.0.6` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | Expected Behavior Violation <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3314966](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3314966) | `cryptography:` <br> `3.3.2 -> 41.0.6` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | Use After Free <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3315324](https://snyk.io/vuln/SNYK-PY",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14134:1108,Certificate,Certificate,1108,https://hail.is,https://github.com/hail-is/hail/pull/14134,1,['Certificate'],['Certificate']
Security," gcr.io/hail-vdc/query:tfkm2kev7zcf'). During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/usr/local/lib/python3.7/site-packages/batch/worker/worker.py"", line 372, in run; await self.ensure_image_is_pulled(); File ""/usr/local/lib/python3.7/site-packages/batch/worker/worker.py"", line 363, in ensure_image_is_pulled; docker.images.pull, self.image); File ""/usr/local/lib/python3.7/site-packages/batch/worker/worker.py"", line 111, in wrapper; return await asyncio.wait_for(f(*args, **kwargs), timeout); File ""/usr/local/lib/python3.7/asyncio/tasks.py"", line 442, in wait_for; return fut.result(); File ""/usr/local/lib/python3.7/asyncio/futures.py"", line 181, in result; raise self._exception; File ""/usr/local/lib/python3.7/asyncio/tasks.py"", line 249, in __step; result = coro.send(None); File ""/usr/local/lib/python3.7/site-packages/aiodocker/images.py"", line 104, in _handle_list; async with cm as response:; File ""/usr/local/lib/python3.7/site-packages/aiodocker/docker.py"", line 291, in __aenter__; resp = await self._coro; File ""/usr/local/lib/python3.7/site-packages/aiodocker/docker.py"", line 206, in _do_query; raise DockerError(response.status, json.loads(what.decode(""utf8""))); aiodocker.exceptions.DockerError: DockerError(500, ""unauthorized: You don't have the needed permissions to perform this operation, and you may have invalid credentials. To authenticate your request, follow the steps in: https://cloud.google.com/container-registry/docs/advanced-authentication""); ```. [1] The Docker specifications are confusing. After reading; [v1](https://github.com/moby/moby/blob/master/image/spec/v1.md) and; [v1.2](https://github.com/moby/moby/blob/master/image/spec/v1.2.md), it seems that the ""repository""; is everything before the last colon and the ""image name suffix"" is everything after the last; colon. For example, in `server:8080/abc/def:123`, the repository is `server:8080/abc/def` and the; ""image name suffix"" is `123`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9902:4211,authenticat,authenticate,4211,https://hail.is,https://github.com/hail-is/hail/pull/9902,2,['authenticat'],"['authenticate', 'authentication']"
Security," href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/654"">jpadilla/pyjwt#654</a></li>; <li>Ignore coverage files generated during test runs by <a href=""https://github.com/makusu2""><code>@​makusu2</code></a> in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/617"">jpadilla/pyjwt#617</a></li>; <li>[pre-commit.ci] pre-commit autoupdate by <a href=""https://github.com/pre-commit-ci""><code>@​pre-commit-ci</code></a> in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/656"">jpadilla/pyjwt#656</a></li>; <li>[pre-commit.ci] pre-commit autoupdate by <a href=""https://github.com/pre-commit-ci""><code>@​pre-commit-ci</code></a> in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/658"">jpadilla/pyjwt#658</a></li>; <li>[pre-commit.ci] pre-commit autoupdate by <a href=""https://github.com/pre-commit-ci""><code>@​pre-commit-ci</code></a> in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/667"">jpadilla/pyjwt#667</a></li>; <li>Fix aud validation to support {'aud': null} case. by <a href=""https://github.com/dajiaji""><code>@​dajiaji</code></a> in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/670"">jpadilla/pyjwt#670</a></li>; <li>[pre-commit.ci] pre-commit autoupdate by <a href=""https://github.com/pre-commit-ci""><code>@​pre-commit-ci</code></a> in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/678"">jpadilla/pyjwt#678</a></li>; <li>Prefer headers['alg'] to algorithm parameter in encode(). by <a href=""https://github.com/dajiaji""><code>@​dajiaji</code></a> in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/673"">jpadilla/pyjwt#673</a></li>; <li>DOC: Clarify RSA encoding and decoding depend on the cryptography package by <a href=""https://github.com/TPXP""><code>@​TPXP</code></a> in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/664"">jpadilla/pyjwt#664</a></li>; <li>Make typ optional by <a href=""https://github.com/dajiaji""><code>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11457:2929,validat,validation,2929,https://hail.is,https://github.com/hail-is/hail/pull/11457,1,['validat'],['validation']
Security," href=""https://github-redirect.dependabot.com/plotly/plotly.js/pull/6193"">plotly.js#6193</a>, <a href=""https://github-redirect.dependabot.com/plotly/plotly.py/pull/3749"">#3749</a></li>; </ul>; <h2>[5.8.2] - 2022-06-10</h2>; <h3>Fixed</h3>; <ul>; <li>Fixed a syntax error that caused rendering issues in Databricks notebooks and likely elsewhere. <a href=""https://github-redirect.dependabot.com/plotly/plotly.py/pull/3763"">#3763</a> with thanks to <a href=""https://github.com/fwetdb""><code>@​fwetdb</code></a></li>; </ul>; <h2>[5.8.1] - 2022-06-08</h2>; <p>(no changes, due to a mixup with the build process!)</p>; <h2>[5.8.0] - 2022-05-09</h2>; <h3>Fixed</h3>; <ul>; <li>Improve support for type checking and IDE auto-completion by bypassing lazy-loading when type checking. <a href=""https://github-redirect.dependabot.com/plotly/plotly.py/pull/3425"">#3425</a> with thanks to <a href=""https://github.com/JP-Ellis""><code>@​JP-Ellis</code></a></li>; <li>line dash-style validators are now correctly used everywhere so that values like <code>10px 2px</code> are accepted <a href=""https://github-redirect.dependabot.com/plotly/plotly.py/pull/3722"">#3722</a></li>; <li>Resolved various deprecation warning messages and compatibility issues with upstream dependencies and Python 3.11, plus removed dependency on <code>six</code>, with thanks to <a href=""https://github.com/maresb""><code>@​maresb</code></a>, <a href=""https://github.com/hugovk""><code>@​hugovk</code></a>, <a href=""https://github.com/tirkarthi""><code>@​tirkarthi</code></a>, <a href=""https://github.com/martinRenou""><code>@​martinRenou</code></a>, and <a href=""https://github.com/BjoernLudwigPTB""><code>@​BjoernLudwigPTB</code></a></li>; <li>Better support for MathJax 3 <a href=""https://github-redirect.dependabot.com/plotly/plotly.py/pull/3706"">#3706</a></li>; </ul>; <h3>Added</h3>; <ul>; <li>Type annotations for Plotly Express functions and chainable <code>go.Figure</code> methods, for better IDE auto-completion <a href=""https://github",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12113:3896,validat,validators,3896,https://hail.is,https://github.com/hail-is/hail/pull/12113,1,['validat'],['validators']
Security," href=""https://github.com/boto/boto3/commit/1de404aff4ecb1c5560b4e023f0614d8149622ed""><code>1de404a</code></a> fix typo: 'are specified the' should be 'are specified in the' (<a href=""https://github-redirect.dependabot.com/boto/boto3/issues/3499"">#3499</a>)</li>; <li><a href=""https://github.com/boto/boto3/commit/47f20744b3c57223da5e14e185120586f8212af8""><code>47f2074</code></a> Merge branch 'release-1.26.13'</li>; <li><a href=""https://github.com/boto/boto3/commit/3d4081ccb7c350538ba3d6a5073c59575a812eb0""><code>3d4081c</code></a> Merge branch 'release-1.26.13' into develop</li>; <li>Additional commits viewable in <a href=""https://github.com/boto/boto3/compare/1.26.7...1.26.15"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=boto3&package-manager=pip&previous-version=1.26.7&new-version=1.26.15)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12498:9558,secur,security-vulnerabilities,9558,https://hail.is,https://github.com/hail-is/hail/pull/12498,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security," href=""https://github.com/dateutil/dateutil/commit/ee85831cc25d34ff597cfb3f2d90ce5904dbc561""><code>ee85831</code></a> Build releases with Python 3.9</li>; <li><a href=""https://github.com/dateutil/dateutil/commit/6b337ea412d399fb48771c544b1a6880763b46c6""><code>6b337ea</code></a> Automate cutting new releases</li>; <li><a href=""https://github.com/dateutil/dateutil/commit/9c2ad8f981ece1bdb3d52527f1cb39523b11d862""><code>9c2ad8f</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/dateutil/dateutil/issues/1056"">#1056</a> from ffe4/issue_1029</li>; <li>Additional commits viewable in <a href=""https://github.com/dateutil/dateutil/compare/2.8.1...2.8.2"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=python-dateutil&package-manager=pip&previous-version=2.8.1&new-version=2.8.2)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11518:11407,secur,security-vulnerabilities,11407,https://hail.is,https://github.com/hail-is/hail/pull/11518,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security," href=""https://github.com/prometheus/client_python/commit/da15e4a4d671b8aea0e60fc859d5df8102be3897""><code>da15e4a</code></a> Change to imports to fix go-to-declaration in editors (<a href=""https://github-redirect.dependabot.com/prometheus/client_python/issues/747"">#747</a>)</li>; <li><a href=""https://github.com/prometheus/client_python/commit/3ef865e1cccae66f63ae764762a700c5775a5190""><code>3ef865e</code></a> Allow to add labels inside a context manager (<a href=""https://github-redirect.dependabot.com/prometheus/client_python/issues/730"">#730</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/prometheus/client_python/compare/v0.11.0...v0.13.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=prometheus-client&package-manager=pip&previous-version=0.11.0&new-version=0.13.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11515:5611,secur,security-vulnerabilities,5611,https://hail.is,https://github.com/hail-is/hail/pull/11515,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security," in <a href=""https://redirect.github.com/PyMySQL/PyMySQL/pull/1134"">PyMySQL/PyMySQL#1134</a></li>; <li><a href=""https://github.com/svaskov""><code>@​svaskov</code></a> made their first contribution in <a href=""https://redirect.github.com/PyMySQL/PyMySQL/pull/1145"">PyMySQL/PyMySQL#1145</a></li>; </ul>; <p><strong>Full Changelog</strong>: <a href=""https://github.com/PyMySQL/PyMySQL/compare/v1.1.0...v1.1.1"">https://github.com/PyMySQL/PyMySQL/compare/v1.1.0...v1.1.1</a></p>; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/PyMySQL/PyMySQL/blob/main/CHANGELOG.md"">pymysql's changelog</a>.</em></p>; <blockquote>; <h2>v1.1.1</h2>; <p>Release date: 2024-05-21</p>; <blockquote>; <p>[!WARNING]; This release fixes a vulnerability (CVE-2024-36039).; All users are recommended to update to this version.</p>; <p>If you can not update soon, check the input value from; untrusted source has an expected type. Only dict input; from untrusted source can be an attack vector.</p>; </blockquote>; <ul>; <li>Prohibit dict parameter for <code>Cursor.execute()</code>. It didn't produce valid SQL; and might cause SQL injection. (CVE-2024-36039)</li>; <li>Added ssl_key_password param. <a href=""https://redirect.github.com/PyMySQL/PyMySQL/issues/1145"">#1145</a></li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/PyMySQL/PyMySQL/commit/2cab9ecc641e962565c6254a5091f90c47f59b35""><code>2cab9ec</code></a> v1.1.1</li>; <li><a href=""https://github.com/PyMySQL/PyMySQL/commit/521e40050cb386a499f68f483fefd144c493053c""><code>521e400</code></a> forbid dict parameter</li>; <li><a href=""https://github.com/PyMySQL/PyMySQL/commit/7f032a699d55340f05101deb4d7d4f63db4adc11""><code>7f032a6</code></a> remove coveralls from requirements</li>; <li><a href=""https://github.com/PyMySQL/PyMySQL/commit/69f6c7439bee14784e0ea70ae107af6446cc0c67""><code>69f6c74</code></a> ruff format</li>; <li><a href=",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14556:4886,attack,attack,4886,https://hail.is,https://github.com/hail-is/hail/pull/14556,1,['attack'],['attack']
Security," in RFC 2246. This new version was backwards-incompatible and was; thus given a new name: Transport Layer Security. In common discussion, SSL; and TLS are used interchangeable. Indeed, the python TLS library is called; `ssl`. [2] Forward secrecy is a property of an encryption system. Forward secrecy means; a message cannot be decrypted in the future by an adversary who learned one; of the private keys. For example, imagine you are sending sensitive messages; to another individual. If that individual is later coerced into revealing; their secret key, forward secrecy would prevent the coercer from reading; your messages. Forward secrecy is achieved by negotiating a shared private; key between the two parties that is only used for a ""session"" and then; discarded. If the session key is securely discarded and neither key can; recreate it without cooperation from the other key, then *one* leaked key is; insufficient to reveal the messages. ---. Things for you to verify:; - does every service load *its own unqiue* ssl-config secret?; - does every service use an SSL context for serving?; - does everyone who makes http requests to internal services use an SSL client; session?; - do all TLS-secured nginx instances include their http.conf in the `http`; section and the `proxy.conf` file in any proxying sections?; - Do the SSLContext's from `ssl.py` and the nginx configurations generated by; `create_certs.py` actually ensure security?. Post-merge actions:; - deploy gateway; - deploy internal-gateway; - deploy router-resolver. Anticipated outages:. - Before a service is redeployed it will be inaccessible from the outside; because the router will try to speak to it on HTTPS. Services that speak to; one another (ci<->batch, everyone<->auth) will lose connections while the; deploy is happening. Deploy should move smoothly because CI will completely; transmit the deploy batch to batch before batch goes dark.; - dev namespaces will be broken until the owner redeploys the router, etc.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8561:12915,secur,secured,12915,https://hail.is,https://github.com/hail-is/hail/pull/8561,2,['secur'],"['secured', 'security']"
Security," is forbidden: User ""system:serviceaccount:batch-pods:deploy-svc"" cannot get namespaces in the namespace ""batch-pods"": Unknown user ""system:serviceaccount:batch-pods:deploy-svc""; Error from server (Forbidden): error when retrieving current configuration of:; Resource: ""/v1, Resource=serviceaccounts"", GroupVersionKind: ""/v1, Kind=ServiceAccount""; Name: ""batch-svc"", Namespace: ""batch-pods""; Object: &{map[""kind"":""ServiceAccount"" ""metadata"":map[""name"":""batch-svc"" ""namespace"":""batch-pods"" ""annotations"":map[""kubectl.kubernetes.io/last-applied-configuration"":""""]] ""apiVersion"":""v1""]}; from server for: ""deployment.yaml"": serviceaccounts ""batch-svc"" is forbidden: User ""system:serviceaccount:batch-pods:deploy-svc"" cannot get serviceaccounts in the namespace ""batch-pods"": Unknown user ""system:serviceaccount:batch-pods:deploy-svc""; Error from server (Forbidden): error when retrieving current configuration of:; Resource: ""rbac.authorization.k8s.io/v1, Resource=roles"", GroupVersionKind: ""rbac.authorization.k8s.io/v1, Kind=Role""; Name: ""batch-pods-admin"", Namespace: ""batch-pods""; Object: &{map[""apiVersion"":""rbac.authorization.k8s.io/v1"" ""kind"":""Role"" ""metadata"":map[""name"":""batch-pods-admin"" ""namespace"":""batch-pods"" ""annotations"":map[""kubectl.kubernetes.io/last-applied-configuration"":""""]] ""rules"":[map[""apiGroups"":[""""] ""resources"":[""pods""] ""verbs"":[""get"" ""list"" ""watch"" ""create"" ""update"" ""patch"" ""delete""]] map[""apiGroups"":[""""] ""resources"":[""pods/log""] ""verbs"":[""get""]]]]}; from server for: ""deployment.yaml"": roles.rbac.authorization.k8s.io ""batch-pods-admin"" is forbidden: User ""system:serviceaccount:batch-pods:deploy-svc"" cannot get roles.rbac.authorization.k8s.io in the namespace ""batch-pods"": Unknown user ""system:serviceaccount:batch-pods:deploy-svc""; Error from server (Forbidden): error when retrieving current configuration of:; Resource: ""rbac.authorization.k8s.io/v1, Resource=rolebindings"", GroupVersionKind: ""rbac.authorization.k8s.io/v1, Kind=RoleBinding""; Name: ""batch-pods-admin",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4609:1463,authoriz,authorization,1463,https://hail.is,https://github.com/hail-is/hail/issues/4609,1,['authoriz'],['authorization']
Security," is implemented on TCP/IP. HTTPS is also implemented on TCP/IP and differs; very mildly. After the socket is opened, a TLS [1] connection is established; over the socket. Thereafter, every HTTP message is encrypted and transported by; the TLS machinery. The HTTP protocol is unchanged. The default port fort HTTP is; 80 and the default port for HTTPS 443, however any port may be used. There are currently four versions of TLS, the latest is TLS 1.3. All versions of; SSL are considered insecure. The OpenSSL library implements TLS. There are other implementations, such as; LibreSSL, but they implement roughly the same interface as OpenSSL. The TLS protocol defines both a scheme for the *encryption of messages* and for; the *authentication of parties*. The protocol defines authentication as; optional. In practice, at least one party presents authentication. For example,; public web servers authenticate themselves to clients but clients do not; reciprocate. ### Authentication; #### X.509 Certificates. TLS uses X.509 Certificates for authentication. X.509 is a rather complicated; standard. X.509 Certificates can be serialized in a variety of ways. We use the; Privacy-enhanced Electronic Mail (PEM) file format for serialization. PEM is; really simple. A file may contain multiple base64-encoded blobs each with a; header and footer of the form:. ```; -----BEGIN LABEL-----; ...; -----END LABEL-----; ```. where `LABEL` describes the data. We only use two labels: `CERTIFICATE` and; `PRIVATE KEY`. An X.509 Certificate is an unforgeable proof of identity. It usually is paired; with a private key that was used to digitally sign the certificate. In the; security literature, an authenticatable entity is usually called a; *principal*. Each principal should have a unique private key. In our system the; principals are both our services (e.g. `batch`, `batch-driver`) and any; non-serving clients (e.g. `test-batch`, `admin-pod`). A key and certificate are; generated ad nihilum by `openssl r",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8561:2334,Certificate,Certificates,2334,https://hail.is,https://github.com/hail-is/hail/pull/8561,1,['Certificate'],['Certificates']
Security," line 2, in import_vcf; File ""/tmp/7417fcfbbeee44d0b3f4c0b3750121a7/hail-0.1-es-6.2.4-with-strip-chr-prefix.zip/hail/java.py"", line 121, in handle_py4j; hail.java.FatalError: FileNotFoundException: File file:/tmp/clinvar.vcf.gz does not exist. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 0.0 failed 20 times, most recent failure: Lost task 0.19 in stage 0.0 (TID 19, without-vep-520334-sw-rmwj.c.seqr-project.internal): java.io.FileNotFoundException: File file:/tmp/clinvar.vcf.gz does not exist; at org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:611); at org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:824); at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:601); at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:428); at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:142); at org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:346); at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:769); at org.apache.hadoop.mapred.LineRecordReader.<init>(LineRecordReader.java:109); at org.apache.hadoop.mapred.TextInputFormat.getRecordReader(TextInputFormat.java:67); at org.apache.spark.rdd.HadoopRDD$$anon$1.<init>(HadoopRDD.scala:245); at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:208); at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:101); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3760:1937,Checksum,ChecksumFileSystem,1937,https://hail.is,https://github.com/hail-is/hail/issues/3760,1,['Checksum'],['ChecksumFileSystem']
Security," merge <code>matchLabels</code> content and replace <code>matchExpressions</code> content. In 1.21, patch requests touching the <code>selector</code> field started replacing the entire selector. This is consistent with server-side apply and the v1 PodDisruptionBudget behavior, but should not have been changed for v1beta1. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/108139"">kubernetes/kubernetes#108139</a>, <a href=""https://github.com/liggitt""><code>@​liggitt</code></a>) [SIG Auth and Testing]</li>; <li>Fix OpenAPI serialization of the x-kubernetes-validations field (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/108030"">kubernetes/kubernetes#108030</a>, <a href=""https://github.com/liggitt""><code>@​liggitt</code></a>) [SIG API Machinery]</li>; <li>A new field <code>omitManagedFields</code> has been added to both <code>audit.Policy</code> and <code>audit.PolicyRule</code>; so cluster operators can opt in to omit managed fields of the request and response bodies from; being written to the API audit log. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/94986"">kubernetes/kubernetes#94986</a>, <a href=""https://github.com/tkashem""><code>@​tkashem</code></a>) [SIG API Machinery, Auth, Cloud Provider and Testing]</li>; <li>A small regression in Service updates was fixed. The circumstances are so unlikely that probably nobody would ever hit it. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/104601"">kubernetes/kubernetes#104601</a>, <a href=""https://github.com/thockin""><code>@​thockin</code></a>)</li>; <li>Added a feature gate <code>StatefulSetAutoDeletePVC</code>, which allows PVCs automatically created for StatefulSet pods to be automatically deleted. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/99728"">kubernetes/kubernetes#99728</a>, <a href=""https://github.com/mattcary""><code>@​mattcary</code></a>)</li>; <li>Client-go impersonat",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11957:1896,audit,audit,1896,https://hail.is,https://github.com/hail-is/hail/pull/11957,1,['audit'],['audit']
Security," migration works is there are 5 phases:; 1. Compute the expected number of attempts to process for format version < 3. ; 2. Divide the search space into chunks of size 100 attempts (empirically determined this was the best chunk size) and randomize the order of the chunks.; 3. Serially process 5000 chunks with only 10 out of the 100 records as a ""burn in period"" to avoid the birthday problem when trying to insert records in parallel.; 4. In parallel, process all the chunks with 10 way parallelism (empirically determined to max CPU for a 4 core db instance); 5. Do an audit of the results to make sure the attempt resources now has the correct number of rows and the billing is within $0.001 per job with the old way and new way of computing the billing. The tolerance of $0.001 was empirically determined. At a threshold of $0.0001, 33/30,000,000 attempts failed. I think this is good enough as there's always going to be rounding errors. I did not do an explicit audit in the code to make sure the other aggregated_*_resources tables did not change. I spot checked this was correct in my test database. To do the complete audit during the actual migration would take more time. I made sure all the inserts were idempotent. Please double check this. The inserts use a temporary table with an isolation level of read committed. The reason for this is because `INSERT INTO ... SELECT` locks the next gap lock if the isolation level is not read committed. Maybe what I did is overkill and it's no longer a problem with the new burn in period. https://dev.mysql.com/doc/refman/8.0/en/innodb-locks-set.html I'd be interested to hear @danking feedback on what the best query here is to allow parallelism. There are ~30 million attempts that need to be processed for hail-vdc (~60% of the attempts). This will add ~20Gi to the existing database. I use 4 cores to get this migration to be ~3 hours, so we will want to **upgrade the database to 8 cores** while this migration is running. The inserting t",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11990:2069,audit,audit,2069,https://hail.is,https://github.com/hail-is/hail/pull/11990,1,['audit'],['audit']
Security," module importer was used, importing modules could fail if the; custom module importer didn't use the latest Python import hook finder/loader; APIs and instead used the deprecated API. This was actually occurring with the; <code>zipimporter</code> in Python itself, which was not updated to use the newer Python; APIs until Python 3.10.</li>; </ul>; <h2>Version 1.14.0</h2>; <p><strong>Bugs Fixed</strong></p>; <ul>; <li>; <p>Python 3.11 dropped <code>inspect.formatargspec()</code> which was used in creating; signature changing decorators. Now bundling a version of this function; which uses <code>Parameter</code> and <code>Signature</code> from <code>inspect</code> module when; available. The replacement function is exposed as <code>wrapt.formatargspec()</code>; if need it for your own code.</p>; </li>; <li>; <p>When using a decorator on a class, <code>isinstance()</code> checks wouldn't previously; work as expected and you had to manually use <code>Type.__wrapped__</code> to access; the real type when doing instance checks. The <code>__instancecheck__</code> hook is; now implemented such that you don't have to use <code>Type.__wrapped__</code> instead; of <code>Type</code> as last argument to <code>isinstance()</code>.</p>; </li>; <li>; <p>Eliminated deprecation warnings related to Python module import system, which; would have turned into broken code in Python 3.12. This was used by the post; import hook mechanism.</p>; </li>; </ul>; <p><strong>New Features</strong></p>; <ul>; <li>Binary wheels provided on PyPi for <code>aarch64</code> Linux systems and macOS; native silicon where supported by Python when using <code>pypa/cibuildwheel</code>.</li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/GrahamDumpleton/wrapt/commit/f2f1a680113d500f525de78da91ae19235efef16""><code>f2f1a68</code></a> Merge branch 'release/1.14.1'</li>; <li><a href=""https://github.com/GrahamDumpleton/wrapt/commit/97b72d49a8cda771c60065",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12102:1421,access,access,1421,https://hail.is,https://github.com/hail-is/hail/pull/12102,1,['access'],['access']
Security," not require calling &quot;exec&quot;).; Added a way to mimic functools.wraps-generated decorators.; Ported the Continuous Integration from Travis to GitHub.</p>; <h2>4.4.2 (2020-02-29)</h2>; <p>Sylvan Mosberger (<a href=""https://github.com/Infinisil"">https://github.com/Infinisil</a>) contributed a patch to; some doctests that were breaking on NixOS.; John Vandenberg (<a href=""https://github.com/jayvdb"">https://github.com/jayvdb</a>) made a case for removing the usage</p>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li>See full diff in <a href=""https://github.com/micheles/decorator/commits/5.1.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=decorator&package-manager=pip&previous-version=4.4.0&new-version=5.1.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11799:2974,secur,security-vulnerabilities,2974,https://hail.is,https://github.com/hail-is/hail/pull/11799,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security," occurred:. Traceback (most recent call last):; File ""/usr/lib/python3/dist-packages/pip/basecommand.py"", line 215, in main; status = self.run(options, args); File ""/usr/lib/python3/dist-packages/pip/commands/install.py"", line 342, in run; requirement_set.prepare_files(finder); File ""/usr/lib/python3/dist-packages/pip/req/req_set.py"", line 380, in prepare_files; ignore_dependencies=self.ignore_dependencies)); File ""/usr/lib/python3/dist-packages/pip/req/req_set.py"", line 620, in _prepare_file; session=self.session, hashes=hashes); File ""/usr/lib/python3/dist-packages/pip/download.py"", line 821, in unpack_url; hashes=hashes; File ""/usr/lib/python3/dist-packages/pip/download.py"", line 659, in unpack_http_url; hashes); File ""/usr/lib/python3/dist-packages/pip/download.py"", line 882, in _download_http_url; _download_url(resp, link, content_file, hashes); File ""/usr/lib/python3/dist-packages/pip/download.py"", line 603, in _download_url; hashes.check_against_chunks(downloaded_chunks); File ""/usr/lib/python3/dist-packages/pip/utils/hashes.py"", line 46, in check_against_chunks; for chunk in chunks:; File ""/usr/lib/python3/dist-packages/pip/download.py"", line 571, in written_chunks; for chunk in chunks:; File ""/usr/lib/python3/dist-packages/pip/utils/ui.py"", line 139, in iter; for x in it:; File ""/usr/lib/python3/dist-packages/pip/download.py"", line 560, in resp_read; decode_content=False):; File ""/usr/share/python-wheels/urllib3-1.22-py2.py3-none-any.whl/urllib3/response.py"", line 436, in stream; data = self.read(amt=amt, decode_content=decode_content); File ""/usr/share/python-wheels/urllib3-1.22-py2.py3-none-any.whl/urllib3/response.py"", line 401, in read; raise IncompleteRead(self._fp_bytes_read, self.length_remaining); File ""/usr/lib/python3.6/contextlib.py"", line 99, in __exit__; self.gen.throw(type, value, traceback); File ""/usr/share/python-wheels/urllib3-1.22-py2.py3-none-any.whl/urllib3/response.py"", line 307, in _error_catcher; raise ReadTimeoutError(self._pool, Non",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8390:1980,hash,hashes,1980,https://hail.is,https://github.com/hail-is/hail/issues/8390,1,['hash'],['hashes']
Security," of sharing the CloudSQL database server. The areas of change are as follows:. ### Generation of the namespace's database-server-config; The current approach in main does a little trick. Since the current `createDatabase` step uses the `database-server-config` from default to generate admin/user sql configs, the CI pipeline creates a dummy database `test-database-instance` to create a `sql-test-instance-admin-config` that inherits the credentials from the production `database-server-config`, and then copies that within the test namespace to `database-server-config`. In this change, since we are creating the server ourselves, we can just replace these with a step that creates a `database-server-config` from scratch, and then uses that for the DB pod. Overall making these changes really gave me the heebie jeebies that the test and dev namespaces have all these credentials to the CloudSQL server. I'm glad this gets rid of that. ### Accessing the database server; We use the DB pod's service DNS name as the `host` so inside Kubernetes this Just Works. The one caveat is the CI pipeline in which we run migrations in batch jobs. Those jobs need a way to reach the DB pod. I achieve this with a NodePort and then use the job's K8s credentials to resolve the node and port that the DB is on. The code I've added to do this resolution feels a bit janky, wouldn't mind some feedback on that. In terms of security, if a user job was able to somehow resolve the address of a test db, they would still not have the credentials to access it, and this is currently also the case with the production database. Nevertheless, this does raise an action item that we should only allow traffic to the k8s and DB subnets for `network=private` jobs, but I think we should make that a separate PR. ### Database creation; In order to test this properly in a dev deploy, I needed to make some changes to `create_database.py`. In main, dev deploys can't create databases. I think they should be able to, and tho",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13030:1010,Access,Accessing,1010,https://hail.is,https://github.com/hail-is/hail/pull/13030,1,['Access'],['Accessing']
Security," on light</li>; <li><a href=""https://github.com/Textualize/rich/commit/a972ca05522577de2f98eb7c957deead9c87b38f""><code>a972ca0</code></a> changelog</li>; <li><a href=""https://github.com/Textualize/rich/commit/bef0e50b63cf7294ae6c27bf8a79cbe3592599a0""><code>bef0e50</code></a> Merge pull request <a href=""https://redirect.github.com/Textualize/rich/issues/3130"">#3130</a> from Textualize/fix-table-inline-styles</li>; <li><a href=""https://github.com/Textualize/rich/commit/e30b822ecc264c5c4f984a023124d31d8052de49""><code>e30b822</code></a> Fix markdown table rendering issue.</li>; <li>Additional commits viewable in <a href=""https://github.com/Textualize/rich/compare/v12.6.0...v13.5.3"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=rich&package-manager=pip&previous-version=12.6.0&new-version=13.5.3)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13651:7144,secur,security-vulnerabilities,7144,https://hail.is,https://github.com/hail-is/hail/pull/13651,4,['secur'],"['security-updates', 'security-vulnerabilities']"
Security," osgi.version is defined, wrap create-export-pac...</li>; <li><a href=""https://github.com/java-native-access/jna/commit/65cf52803ec2249c61573bdc7bd4314b77c019a0""><code>65cf528</code></a> add utility shell script to create 'Export-Package' metadata</li>; <li><a href=""https://github.com/java-native-access/jna/commit/b3984aaf1bf87c8da2e84797f62180adc405b48a""><code>b3984aa</code></a> Add 'uses' information to OSGI metadata in MANIFEST.MF</li>; <li><a href=""https://github.com/java-native-access/jna/commit/780facdf55b488d504c17183066df6a34531d747""><code>780facd</code></a> Add missing change log entry for libffi update</li>; <li><a href=""https://github.com/java-native-access/jna/commit/5dd4bd707f8f1f49b5d1af158402859a86161367""><code>5dd4bd7</code></a> Merge pull request <a href=""https://redirect.github.com/java-native-access/jna/issues/1491"">#1491</a> from matthiasblaesing/update_libffi</li>; <li><a href=""https://github.com/java-native-access/jna/commit/db1b5531b10fed9fb68d6d4d79913660759b22d3""><code>db1b553</code></a> Merge pull request <a href=""https://redirect.github.com/java-native-access/jna/issues/1490"">#1490</a> from korlibs/feature/direct.mapping.custom.symbol.pr...</li>; <li>Additional commits viewable in <a href=""https://github.com/java-native-access/jna/compare/5.12.1...5.13.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=net.java.dev.jna:jna&package-manager=gradle&previous-version=5.12.1&new-version=5.13.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12886:5734,access,access,5734,https://hail.is,https://github.com/hail-is/hail/pull/12886,1,['access'],['access']
Security," own `config` or `url`. `Dataset.from_name_and_json()` now calls `DatasetVersion.get_region()` method to retrieve the dataset from the bucket in the selected region if `custom_config` is `False`. ; - The `DatasetVersion.get_region()` method takes the dataset `name`, a list of `DatasetVersion` objects, and a `region`, and returns a list of the versions that are available for that region. This method calls the instance method `in_region()` to check if the dataset is available in the requested region.; - If `in_region()` determines the desired region is not available for some dataset that otherwise is available in another region, it will raise a warning. If user still tries to call `db.annotate_rows_db()` using a dataset unavailable in their region, then it will get caught by the `_check_availability` instance method in the `DB` class and raise a `ValueError`.; - Started to add documentation to the classes and methods, still a work in progress. Changes to datasets and datasets API site:; - Added the `ldsc_baselineLD_annotations`, `ldsc_baselineLD_ldscores`, and `ldsc_baseline_ldscores` datasets to the `annotation_db.json` configuration file. Now accessible via `load_dataset()` and `db.annotate_rows_db()` (for the annotations at least).; - New `.rst` files in `hail/python/hail/docs/datasets` have been generated to reflect the available datasets in the config file, and `hail/python/hail/docs/datasets.rst` has been updated with the new files as well. Future updates:; - In next PR can add the functionality to automatically determine the users region.; - Also considering modifying the `load_datasets()` function a bit to only require one `version` parameter, to be consistent with the way the version strings are formatted in `annotation_db.json`, and to avoid having to check if the version and reference genome are available separately. Something like this:. ```; mt_1kg = hl.experimental.load_dataset(name='1000_Genomes_autosomes',; version='phase_3-GRCh37', ; region='us'); ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9496:2311,access,accessible,2311,https://hail.is,https://github.com/hail-is/hail/pull/9496,1,['access'],['accessible']
Security," pervasive (but minor) improvements to Hail's I/O infrastructure. We should start with the egregious examples. Consider `AzureStorageFS.createNoCompression`'s [`OutputStream`](https://github.com/hail-is/hail/blob/main/hail/src/main/scala/is/hail/io/fs/AzureStorageFS.scala#L332-L342):; ```scala; val os: PositionedOutputStream = new FSPositionedOutputStream(4 * 1024 * 1024) {; private[this] val client: BlockBlobClient = blockBlobClient; private[this] val blobOutputStream = client.getBlobOutputStream(true). override def flush(): Unit = {; bb.flip(). if (bb.limit() > 0) {; blobOutputStream.write(bb.array(), 0, bb.limit()); }. bb.clear(); }; // ...; }; ```. Notice how we already have a `ByteBuffer` but we convert it to an array and send that to the OutputStream. Instead, we could just use the [`ByteChannel` methods of `BlockBlobClient`](https://learn.microsoft.com/en-us/java/api/com.azure.storage.blob.specialized.blockblobclient?view=azure-java-stable#com-azure-storage-blob-specialized-blockblobclient-openseekablebytechannelwrite(com-azure-storage-blob-options-blockblobseekablebytechannelwriteoptions)). The [read case also supports a channel](https://learn.microsoft.com/en-us/java/api/com.azure.storage.blob.specialized.blobclientbase?view=azure-java-stable#com-azure-storage-blob-specialized-blobclientbase-openseekablebytechannelread(com-azure-storage-blob-options-blobseekablebytechannelreadoptions-com-azure-core-util-context)). The next, more complicated problem, is the InputBuffer and OutputBuffer interfaces. These assume their sources/sinks are `java.io.InputStream` and `java.io.OutputStream`. Moreover, they too rely on and expose `Array[Byte]` interfaces (e.g. `readBytesArray` and the implementation of `StreamInputBuffer.readBytes`). Let's start with InputBuffer and the decoders and use decoding of VDS variant matrix tables as our benchmark. ```python3; import hail as hl; hl.init(master='local[1]'); vds = hl.vds.read_vds(...); vds.variant_data._force_count_rows(); ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13840:1832,expose,expose,1832,https://hail.is,https://github.com/hail-is/hail/issues/13840,1,['expose'],['expose']
Security," pybind11 fixups</li>; <li><a href=""https://github.com/scipy/scipy/commit/843500aabde17aaf1eec65c589d50bd12ee35039""><code>843500a</code></a> Merge pull request <a href=""https://redirect.github.com/scipy/scipy/issues/17689"">#17689</a> from mdhaber/gh17686</li>; <li><a href=""https://github.com/scipy/scipy/commit/089924b61012a106ffa4f58939b0180124051a0b""><code>089924b</code></a> REL: integrate.qmc_quad: remove from release notes</li>; <li><a href=""https://github.com/scipy/scipy/commit/3e47110f10e3267d228e9da84174f3cee325e7c3""><code>3e47110</code></a> REL: 1.10.0rc3 unreleased</li>; <li>Additional commits viewable in <a href=""https://github.com/scipy/scipy/compare/v1.9.3...v1.10.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=scipy&package-manager=pip&previous-version=1.9.3&new-version=1.10.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13227:5137,secur,security-vulnerabilities,5137,https://hail.is,https://github.com/hail-is/hail/pull/13227,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security," pyzmq 25.1.1.; matplotlib 3.5.3 requires numpy, which is not installed.; matplotlib 3.5.3 requires pillow, which is not installed. ```; </details>. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **531/1000** <br/> **Why?** Proof of Concept exploit, Has a fix available, CVSS 4.2 | Remote Code Execution (RCE) <br/>[SNYK-PYTHON-IPYTHON-3318382](https://snyk.io/vuln/SNYK-PYTHON-IPYTHON-3318382) | `ipython:` <br> `7.34.0 -> 8.10.0` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **/1000** <br/> **Why?** | Access Control Bypass <br/>[SNYK-PYTHON-JUPYTERSERVER-5862881](https://snyk.io/vuln/SNYK-PYTHON-JUPYTERSERVER-5862881) | `jupyter-server:` <br> `1.24.0 -> 2.7.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **/1000** <br/> **Why?** | Open Redirect <br/>[SNYK-PYTHON-JUPYTERSERVER-5862882](https://snyk.io/vuln/SNYK-PYTHON-JUPYTERSERVER-5862882) | `jupyter-server:` <br> `1.24.0 -> 2.7.2` <br> | No | No Known Exploit ; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **/1000** <br/> **Why?** | NULL Pointer Dereference <br/>[SNYK-PYTHON-NUMPY-2321964](https://snyk.io/vuln/SNYK-PYTHON-NUMPY-2321964) | `numpy:` <br> `1.21.3 -> 1.22.2` <br> | No | Proof of Concept ; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **/1000** <br/> **Why?** | Buffer Overflow <br/>[SNYK-PYTHON-NUMPY",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13871:1639,Access,Access,1639,https://hail.is,https://github.com/hail-is/hail/pull/13871,1,['Access'],['Access']
Security," regression in <code>metadata.managedFields</code> handling in update/patch requests submitted by older API clients (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/91748"">kubernetes/kubernetes#91748</a>, <a href=""https://github.com/apelisse""><code>@​apelisse</code></a>)</li>; <li>Scheduler: optionally check for available storage capacity before scheduling pods which have unbound volumes (alpha feature with the new <code>CSIStorageCapacity</code> feature gate, only works for CSI drivers and depends on support for the feature in a CSI driver deployment) (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/92387"">kubernetes/kubernetes#92387</a>, <a href=""https://github.com/pohly""><code>@​pohly</code></a>) [SIG API Machinery, Apps, Auth, Scheduling, Storage and Testing]</li>; <li>Seccomp support has graduated to GA. A new <code>seccompProfile</code> field is added to pod and container securityContext objects. Support for <code>seccomp.security.alpha.kubernetes.io/pod</code> and <code>container.seccomp.security.alpha.kubernetes.io/...</code> annotations is deprecated, and will be removed in v1.22. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/91381"">kubernetes/kubernetes#91381</a>, <a href=""https://github.com/pjbgf""><code>@​pjbgf</code></a>) [SIG Apps, Auth, Node, Release, Scheduling and Testing]</li>; <li>ServiceAppProtocol feature gate is now beta and enabled by default, adding new AppProtocol field to Services and Endpoints. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/90023"">kubernetes/kubernetes#90023</a>, <a href=""https://github.com/robscott""><code>@​robscott</code></a>) [SIG Apps and Network]</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/tomplus/kubernetes_asyncio/commit/bcfd4ed2ec3b2f503adc4f2e681f9404216d302c""><code>bcfd4ed</code></a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11462:13431,secur,security,13431,https://hail.is,https://github.com/hail-is/hail/pull/11462,1,['secur'],['security']
Security," removed.; Users on older version of OpenSSL will need to upgrade.</li>; <li><strong>BACKWARDS INCOMPATIBLE:</strong> Dropped support for LibreSSL &lt; 3.5. The new; minimum LibreSSL version is 3.5.0. Going forward our policy is to support; versions of LibreSSL that are available in versions of OpenBSD that are; still receiving security support.</li>; <li><strong>BACKWARDS INCOMPATIBLE:</strong> Removed the <code>encode_point</code> and; <code>from_encoded_point</code> methods on; :class:<code>~cryptography.hazmat.primitives.asymmetric.ec.EllipticCurvePublicNumbers</code>,; which had been deprecated for several years.; :meth:<code>~cryptography.hazmat.primitives.asymmetric.ec.EllipticCurvePublicKey.public_bytes</code>; and; :meth:<code>~cryptography.hazmat.primitives.asymmetric.ec.EllipticCurvePublicKey.from_encoded_point</code>; should be used instead.</li>; <li><strong>BACKWARDS INCOMPATIBLE:</strong> Support for using MD5 or SHA1 in; :class:<code>~cryptography.x509.CertificateBuilder</code>, other X.509 builders, and; PKCS7 has been removed.</li>; <li><strong>BACKWARDS INCOMPATIBLE:</strong> Dropped support for macOS 10.10 and 10.11, macOS; users must upgrade to 10.12 or newer.</li>; <li><strong>ANNOUNCEMENT:</strong> The next version of <code>cryptography</code> (40.0) will change; the way we link OpenSSL. This will only impact users who build; <code>cryptography</code> from source (i.e., not from a <code>wheel</code>), and specify their; own version of OpenSSL. For those users, the <code>CFLAGS</code>, <code>LDFLAGS</code>,; <code>INCLUDE</code>, <code>LIB</code>, and <code>CRYPTOGRAPHY_SUPPRESS_LINK_FLAGS</code> environment; variables will no longer be respected. Instead, users will need to; configure their builds <code>as documented here</code>_.</li>; <li>Added support for; :ref:<code>disabling the legacy provider in OpenSSL 3.0.x&lt;legacy-provider&gt;</code>.</li>; <li>Added support for disabling RSA key validation checks when loading RSA; keys via; :func:<",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12668:1678,Certificate,CertificateBuilder,1678,https://hail.is,https://github.com/hail-is/hail/pull/12668,4,['Certificate'],['CertificateBuilder']
Security," requirement docutils<0.19, but you have docutils 0.20.1.; notebook 6.5.6 has requirement pyzmq<25,>=17, but you have pyzmq 25.1.1. ```; </details>. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **531/1000** <br/> **Why?** Proof of Concept exploit, Has a fix available, CVSS 4.2 | Remote Code Execution (RCE) <br/>[SNYK-PYTHON-IPYTHON-3318382](https://snyk.io/vuln/SNYK-PYTHON-IPYTHON-3318382) | `ipython:` <br> `7.34.0 -> 8.10.0` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **/1000** <br/> **Why?** | Access Control Bypass <br/>[SNYK-PYTHON-JUPYTERSERVER-5862881](https://snyk.io/vuln/SNYK-PYTHON-JUPYTERSERVER-5862881) | `jupyter-server:` <br> `1.24.0 -> 2.7.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **/1000** <br/> **Why?** | Open Redirect <br/>[SNYK-PYTHON-JUPYTERSERVER-5862882](https://snyk.io/vuln/SNYK-PYTHON-JUPYTERSERVER-5862882) | `jupyter-server:` <br> `1.24.0 -> 2.7.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **509/1000** <br/> **Why?** Has a fix available, CVSS 5.9 | Regular Expression Denial of Service (ReDoS) <br/>[SNYK-PYTHON-SETUPTOOLS-3180412](https://snyk.io/vuln/SNYK-PYTHON-SETUPTOOLS-3180412) | `setuptools:` <br> `39.0.1 -> 65.5.1` <br> | No | No Known Exploit ; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low sever",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14026:1522,Access,Access,1522,https://hail.is,https://github.com/hail-is/hail/pull/14026,1,['Access'],['Access']
Security," severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **616/1000** <br/> **Why?** Proof of Concept exploit, Has a fix available, CVSS 5.9 | Use After Free <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3315324](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3315324) | `cryptography:` <br> `3.3.2 -> 41.0.6` <br> | No | Proof of Concept ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | **584/1000** <br/> **Why?** Has a fix available, CVSS 7.4 | Access of Resource Using Incompatible Type (&#x27;Type Confusion&#x27;) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3315328](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3315328) | `cryptography:` <br> `3.3.2 -> 41.0.6` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **479/1000** <br/> **Why?** Has a fix available, CVSS 5.3 | Timing Attack <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3315331](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3315331) | `cryptography:` <br> `3.3.2 -> 41.0.6` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **509/1000** <br/> **Why?** Has a fix available, CVSS 5.9 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3315452](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3315452) | `cryptography:` <br> `3.3.2 -> 41.0.6` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **509/1000** <br/> **Why?** Has a fix available, CVSS 5.9 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3315972](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3315972) | `cryptography:` <br> `3.3.2 -> 41.0.6` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14148:3458,Attack,Attack,3458,https://hail.is,https://github.com/hail-is/hail/pull/14148,1,['Attack'],['Attack']
Security," severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **616/1000** <br/> **Why?** Proof of Concept exploit, Has a fix available, CVSS 5.9 | Use After Free <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3315324](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3315324) | `cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No | Proof of Concept ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | **584/1000** <br/> **Why?** Has a fix available, CVSS 7.4 | Access of Resource Using Incompatible Type (&#x27;Type Confusion&#x27;) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3315328](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3315328) | `cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **479/1000** <br/> **Why?** Has a fix available, CVSS 5.3 | Timing Attack <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3315331](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3315331) | `cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **509/1000** <br/> **Why?** Has a fix available, CVSS 5.9 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3315452](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3315452) | `cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **509/1000** <br/> **Why?** Has a fix available, CVSS 5.9 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3315972](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3315972) | `cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14327:3450,Attack,Attack,3450,https://hail.is,https://github.com/hail-is/hail/pull/14327,2,['Attack'],['Attack']
Security," severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | Timing Attack <br/>[SNYK-PYTHON-RSA-1038401](https://snyk.io/vuln/SNYK-PYTHON-RSA-1038401) | `rsa:` <br> `4.5 -> 4.7` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | Regular Expression Denial of Service (ReDoS) <br/>[SNYK-PYTHON-SETUPTOOLS-3180412](https://snyk.io/vuln/SNYK-PYTHON-SETUPTOOLS-3180412) | `setuptools:` <br> `39.0.1 -> 65.5.1` <br> | No | No Known Exploit . Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJhZGQ5ZWQxOC00MjJhLTRkZWUtYWI4Yy01MTkyYmQ4ZmYxMzIiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImFkZDllZDE4LTQyMmEtNGRlZS1hYjhjLTUxOTJiZDhmZjEzMiJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/b72ce54d-5de3-48e5-a1d4-6f8967681a12?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/b72ce54d-5de3-48e5-a1d4-6f8967681a12?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""add9ed18-422a-4dee-ab8c-5192bd8ff132"",""pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13975:3088,access,access,3088,https://hail.is,https://github.com/hail-is/hail/pull/13975,2,"['access', 'authoriz']","['access', 'authorized']"
Security," speaking to servers with certs they didn't trust. Now everyone trusts everyone. As long as the root key is not leaked this is OK. Only `create_certs` mounts this secret. The key is used to sign every certificate and the cert is included in each principal's incoming and outgoing trust lists. The root certificate and key are never re-created, so our deploys have no downtime and we avoid addressing the rotation problem. I removed all the trust specifications. A later PR will resolve rotation and mTLS. That PR will restore the trust specifications. I didn't change the structure of the secrets (they still have an incoming and outgoing trust list which only contains the root cert) because I need this structure for mTLS anyway. The original PR text follows. ---. ## HTTPS and TLS. HTTP is implemented on TCP/IP. HTTPS is also implemented on TCP/IP and differs; very mildly. After the socket is opened, a TLS [1] connection is established; over the socket. Thereafter, every HTTP message is encrypted and transported by; the TLS machinery. The HTTP protocol is unchanged. The default port fort HTTP is; 80 and the default port for HTTPS 443, however any port may be used. There are currently four versions of TLS, the latest is TLS 1.3. All versions of; SSL are considered insecure. The OpenSSL library implements TLS. There are other implementations, such as; LibreSSL, but they implement roughly the same interface as OpenSSL. The TLS protocol defines both a scheme for the *encryption of messages* and for; the *authentication of parties*. The protocol defines authentication as; optional. In practice, at least one party presents authentication. For example,; public web servers authenticate themselves to clients but clients do not; reciprocate. ### Authentication; #### X.509 Certificates. TLS uses X.509 Certificates for authentication. X.509 is a rather complicated; standard. X.509 Certificates can be serialized in a variety of ways. We use the; Privacy-enhanced Electronic Mail (PEM) fil",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8561:1543,encrypt,encrypted,1543,https://hail.is,https://github.com/hail-is/hail/pull/8561,1,['encrypt'],['encrypted']
Security," tables **by date**. In this PR, I don't try and add the usage to the existing `aggregated_*_resources` tables. I did this to cut down on time and space since we're eventually going to deprecate those tables anyways. Because I don't touch those tables, we don't need to worry about modifying the client code and how the current billing information is calculated. How this migration works is there are 5 phases:; 1. Compute the expected number of attempts to process for format version < 3. ; 2. Divide the search space into chunks of size 100 attempts (empirically determined this was the best chunk size) and randomize the order of the chunks.; 3. Serially process 5000 chunks with only 10 out of the 100 records as a ""burn in period"" to avoid the birthday problem when trying to insert records in parallel.; 4. In parallel, process all the chunks with 10 way parallelism (empirically determined to max CPU for a 4 core db instance); 5. Do an audit of the results to make sure the attempt resources now has the correct number of rows and the billing is within $0.001 per job with the old way and new way of computing the billing. The tolerance of $0.001 was empirically determined. At a threshold of $0.0001, 33/30,000,000 attempts failed. I think this is good enough as there's always going to be rounding errors. I did not do an explicit audit in the code to make sure the other aggregated_*_resources tables did not change. I spot checked this was correct in my test database. To do the complete audit during the actual migration would take more time. I made sure all the inserts were idempotent. Please double check this. The inserts use a temporary table with an isolation level of read committed. The reason for this is because `INSERT INTO ... SELECT` locks the next gap lock if the isolation level is not read committed. Maybe what I did is overkill and it's no longer a problem with the new burn in period. https://dev.mysql.com/doc/refman/8.0/en/innodb-locks-set.html I'd be interested to h",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11990:1672,audit,audit,1672,https://hail.is,https://github.com/hail-is/hail/pull/11990,1,['audit'],['audit']
Security," the end of the day, kubernetes does not support this. TCP; probes are the best we can do. There [was a; PR](kubernetes/kubernetes#61231) to allow httpGet probes; to send the kubelet certificate, but it was closed because, apparently, the; [httpGet probes can be targeted at arbitrary IP; addresses](kubernetes/kubernetes#61231 (review)) (what; the hell?), ergo Confused Deputy. ### Future Work. - Require TLS 1.3 everywhere.; - Comply with Mozilla's ""Modern"" recommendations.; - [Incoming Trust](#incoming-trust).; - Refresh certificates after deploying new ones. ### Footnotes. [1] TLS: Transport Layer Security. Preceded by Secure Sockets Layer (SSL) which; is not obsolete and insecure. After SSL version 3, a new version of SSL was; proposed in RFC 2246. This new version was backwards-incompatible and was; thus given a new name: Transport Layer Security. In common discussion, SSL; and TLS are used interchangeable. Indeed, the python TLS library is called; `ssl`. [2] Forward secrecy is a property of an encryption system. Forward secrecy means; a message cannot be decrypted in the future by an adversary who learned one; of the private keys. For example, imagine you are sending sensitive messages; to another individual. If that individual is later coerced into revealing; their secret key, forward secrecy would prevent the coercer from reading; your messages. Forward secrecy is achieved by negotiating a shared private; key between the two parties that is only used for a ""session"" and then; discarded. If the session key is securely discarded and neither key can; recreate it without cooperation from the other key, then *one* leaked key is; insufficient to reveal the messages. ---. Things for you to verify:; - does every service load *its own unqiue* ssl-config secret?; - does every service use an SSL context for serving?; - does everyone who makes http requests to internal services use an SSL client; session?; - do all TLS-secured nginx instances include their http.conf in the ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8561:11981,encrypt,encryption,11981,https://hail.is,https://github.com/hail-is/hail/pull/8561,1,['encrypt'],['encryption']
Security," to latest models</li>; <li><a href=""https://github.com/boto/botocore/commit/7b4b3bbb13a5d59097e6d5f178de58e280fdb553""><code>7b4b3bb</code></a> Resolve endpoint with default partition when no region is set (<a href=""https://github-redirect.dependabot.com/boto/botocore/issues/2818"">#2818</a>)</li>; <li><a href=""https://github.com/boto/botocore/commit/cc3f1c22f55ba50ca792eb73e7a6f721abdcc5ee""><code>cc3f1c2</code></a> Fix: S3 Object Lambda requests miss x-amz-content-sha256 headers (<a href=""https://github-redirect.dependabot.com/boto/botocore/issues/2819"">#2819</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/boto/botocore/compare/1.29.13...1.29.16"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=botocore&package-manager=pip&previous-version=1.29.13&new-version=1.29.16)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12503:3839,secur,security-vulnerabilities,3839,https://hail.is,https://github.com/hail-is/hail/pull/12503,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security," use two labels: `CERTIFICATE` and; `PRIVATE KEY`. An X.509 Certificate is an unforgeable proof of identity. It usually is paired; with a private key that was used to digitally sign the certificate. In the; security literature, an authenticatable entity is usually called a; *principal*. Each principal should have a unique private key. In our system the; principals are both our services (e.g. `batch`, `batch-driver`) and any; non-serving clients (e.g. `test-batch`, `admin-pod`). A key and certificate are; generated ad nihilum by `openssl req -new`:. ```; openssl req -new \; -x509; -keyout key_file; -out cert_file; -newkey rsa:4096; -nodes; -subj /CN=example.com; -addext subjectAltName = DNS:www.example.com,DNS:foo.com; ```. The first three arguments are self-explanatory. I explain the rest:. - `-newkey rsa:4096`. TLS supports many different kinds of private keys. This; generates a 4096-bit private key.; - `-nodes`. This should be read as ""no DES"". It means that the private key is not; itself encrypted using DES and a password.; - `-subj /CN=example.com`. This certificate is valid for a server whose DNS name; is `example.com`. If ""hostname checking"" is enabled (web browsers always; enable it), then the client will reject the certificate if the hostname used; to open the socket does not match the certificate.; - `-addext subjectAltName = ...`. This specifies additional acceptable hostnames; for the aformentioned hostname check. #### Trust. An X.509 Certificate only proves that the principal has a private key. On the; world wide web, ownership of a particular domain, e.g. `example.com`, is; guaranteed by a Certificate Authority (CA). A Certificate Authority (like; letsencypt or VeriSign) digitally signs the certificate of a user that has; proven they own the domain name mentioned in the certificate (see above; discussion of `CN` and `subjectAltName`). Web browsers have a file of the ""root""; certificates of the public Certificate Authorities. They establish a ""chain of; t",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8561:3801,encrypt,encrypted,3801,https://hail.is,https://github.com/hail-is/hail/pull/8561,2,"['encrypt', 'password']","['encrypted', 'password']"
Security," using DES and a password.; - `-subj /CN=example.com`. This certificate is valid for a server whose DNS name; is `example.com`. If ""hostname checking"" is enabled (web browsers always; enable it), then the client will reject the certificate if the hostname used; to open the socket does not match the certificate.; - `-addext subjectAltName = ...`. This specifies additional acceptable hostnames; for the aformentioned hostname check. #### Trust. An X.509 Certificate only proves that the principal has a private key. On the; world wide web, ownership of a particular domain, e.g. `example.com`, is; guaranteed by a Certificate Authority (CA). A Certificate Authority (like; letsencypt or VeriSign) digitally signs the certificate of a user that has; proven they own the domain name mentioned in the certificate (see above; discussion of `CN` and `subjectAltName`). Web browsers have a file of the ""root""; certificates of the public Certificate Authorities. They establish a ""chain of; trust"" from a root certificate to the server's certificate. Our system is simpler. We have no root certificate. Each principal has a; certificate which is given to all the principals to which it might; communicate. ### Encryption. TLS has many encryption schemes. I will focus on encryption using a *symmetric*; key because asymmetric schemes do not enable *forward secrecy* [2]. Under; forward secret schemes, the two parties share a private key unknown to all; adversaries. TLS 1.3 makes forward secrecy mandatory. I intend to eventually; require all our services to refuse to speak anything other than TLS 1.3. The shared private key is used to encrypt and decrypt messages sent over a; socket. This poses a problem: how do two parties who have never met each other; agree on a private key without revealing the key to the public? This is a; classic cryptography problem called [key; exchange](https://en.wikipedia.org/wiki/Key_exchange). The classic solution to; this problem is [Diffie-Hellman key; exchange](h",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8561:4814,certificate,certificate,4814,https://hail.is,https://github.com/hail-is/hail/pull/8561,2,['certificate'],['certificate']
Security," via &quot;argsCanBeInterpretedByShell&quot;</li>; <li><a href=""https://github.com/microsoft/debugpy/commit/6b276e339cd850c5f8c93ff4bdbd305dd963d7bb""><code>6b276e3</code></a> Step in/step over support for IPython. Fixes <a href=""https://github-redirect.dependabot.com/microsoft/debugpy/issues/869"">#869</a></li>; <li><a href=""https://github.com/microsoft/debugpy/commit/a294092d9c6d8459126ecb8f537b6012fb7e7d28""><code>a294092</code></a> Properly stop at line 1 in frame eval mode. Fixes <a href=""https://github-redirect.dependabot.com/microsoft/debugpy/issues/995"">#995</a></li>; <li>Additional commits viewable in <a href=""https://github.com/microsoft/debugpy/compare/v1.6.0...v1.6.3"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=debugpy&package-manager=pip&previous-version=1.6.0&new-version=1.6.3)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12103:5651,secur,security-vulnerabilities,5651,https://hail.is,https://github.com/hail-is/hail/pull/12103,4,['secur'],"['security-updates', 'security-vulnerabilities']"
Security," view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=protobuf&package-manager=pip&previous-version=3.20.1&new-version=3.20.2)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself); You can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/hail-is/hail/network/alerts). </details>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12223:4717,secur,security,4717,https://hail.is,https://github.com/hail-is/hail/pull/12223,6,"['Secur', 'secur']","['Security', 'security']"
Security," view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=requests&package-manager=pip&previous-version=2.28.2&new-version=2.31.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself); You can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/hail-is/hail/network/alerts). </details>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13091:9146,secur,security,9146,https://hail.is,https://github.com/hail-is/hail/pull/13091,12,"['Secur', 'secur']","['Security', 'security']"
Security," when retrieving current configuration of:; Resource: ""rbac.authorization.k8s.io/v1, Resource=roles"", GroupVersionKind: ""rbac.authorization.k8s.io/v1, Kind=Role""; Name: ""batch-pods-admin"", Namespace: ""batch-pods""; Object: &{map[""apiVersion"":""rbac.authorization.k8s.io/v1"" ""kind"":""Role"" ""metadata"":map[""name"":""batch-pods-admin"" ""namespace"":""batch-pods"" ""annotations"":map[""kubectl.kubernetes.io/last-applied-configuration"":""""]] ""rules"":[map[""apiGroups"":[""""] ""resources"":[""pods""] ""verbs"":[""get"" ""list"" ""watch"" ""create"" ""update"" ""patch"" ""delete""]] map[""apiGroups"":[""""] ""resources"":[""pods/log""] ""verbs"":[""get""]]]]}; from server for: ""deployment.yaml"": roles.rbac.authorization.k8s.io ""batch-pods-admin"" is forbidden: User ""system:serviceaccount:batch-pods:deploy-svc"" cannot get roles.rbac.authorization.k8s.io in the namespace ""batch-pods"": Unknown user ""system:serviceaccount:batch-pods:deploy-svc""; Error from server (Forbidden): error when retrieving current configuration of:; Resource: ""rbac.authorization.k8s.io/v1, Resource=rolebindings"", GroupVersionKind: ""rbac.authorization.k8s.io/v1, Kind=RoleBinding""; Name: ""batch-pods-admin-binding"", Namespace: ""batch-pods""; Object: &{map[""apiVersion"":""rbac.authorization.k8s.io/v1"" ""kind"":""RoleBinding"" ""metadata"":map[""annotations"":map[""kubectl.kubernetes.io/last-applied-configuration"":""""] ""name"":""batch-pods-admin-binding"" ""namespace"":""batch-pods""] ""roleRef"":map[""apiGroup"":"""" ""kind"":""Role"" ""name"":""batch-pods-admin""] ""subjects"":[map[""kind"":""ServiceAccount"" ""name"":""batch-svc"" ""namespace"":""default""]]]}; from server for: ""deployment.yaml"": rolebindings.rbac.authorization.k8s.io ""batch-pods-admin-binding"" is forbidden: User ""system:serviceaccount:batch-pods:deploy-svc"" cannot get rolebindings.rbac.authorization.k8s.io in the namespace ""batch-pods"": Unknown user ""system:serviceaccount:batch-pods:deploy-svc""; Error from server (Forbidden): error when retrieving current configuration of:; Resource: ""apps/v1beta2, Resource=deployments"", GroupVersionK",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4609:2330,authoriz,authorization,2330,https://hail.is,https://github.com/hail-is/hail/issues/4609,1,['authoriz'],['authorization']
Security," which is not installed. ```; </details>. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | Heap-based Buffer Overflow <br/>[SNYK-PYTHON-PILLOW-5918878](https://snyk.io/vuln/SNYK-PYTHON-PILLOW-5918878) | `pillow:` <br> `9.5.0 -> 10.0.1` <br> | No | Mature . Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiIzNTM4YWIwOC03Yzk4LTRjMDUtOTQ0Ny0yMjYwYjliNjhmY2IiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjM1MzhhYjA4LTdjOTgtNGMwNS05NDQ3LTIyNjBiOWI2OGZjYiJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/fa47fca0-549b-41a3-8bf7-bcda4ca9a617?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/fa47fca0-549b-41a3-8bf7-bcda4ca9a617?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""3538ab08-7c98-4c05-9447-2260b9b68fcb"",""pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13708:1702,access,access,1702,https://hail.is,https://github.com/hail-is/hail/pull/13708,2,"['access', 'authoriz']","['access', 'authorized']"
Security," | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | Information Exposure <br/>[SNYK-PYTHON-REQUESTS-5595532](https://snyk.io/vuln/SNYK-PYTHON-REQUESTS-5595532) | `requests:` <br> `2.27.1 -> 2.31.0` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | Timing Attack <br/>[SNYK-PYTHON-RSA-1038401](https://snyk.io/vuln/SNYK-PYTHON-RSA-1038401) | `rsa:` <br> `4.5 -> 4.7` <br> | No | No Known Exploit . Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiIxMjk3MjE5NC04YzAyLTRhMjQtYTA0Ni0yZjIxMjk4YjQ2NmEiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjEyOTcyMTk0LThjMDItNGEyNC1hMDQ2LTJmMjEyOThiNDY2YSJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/e7c92c7b-5282-49ea-940f-7a5797e2a45a?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/e7c92c7b-5282-49ea-940f-7a5797e2a45a?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""12972194-8c02-4a24-a046-2f21298b466a"",""pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14134:8195,access,access,8195,https://hail.is,https://github.com/hail-is/hail/pull/14134,2,"['access', 'authoriz']","['access', 'authorized']"
Security,"![Finally.](https://media.giphy.com/media/yIsbuPCEOgNHO/giphy.gif). - update endpoints to handle the ""zen"" that GitHub sends when a web hook is created. - update `make run-local` and friends for the new IP of the `dk-test` micro instance. - remove the unused `refresh_statuses` (this was intended to recover build state from github's commit statuses, but the commit status description is limited to like 120 characters, so I gave up on this a while ago, but never removed the code). - `.strip()` the GitHub token in case there are newlines. - print the SHA being deployed in the log statement. - add `hail-ci-build.sh` to CI, which just invokes `make test-in-cluster`(which in turn runs `test-in-cluster.sh`. - `test-in-cluster.sh` copies the secrets for testing to the expected locations and exposes the pod in which it is running with an internal service, recent changes to `site` [redirect sub URLs of ci.test.is to services named using this scheme](https://github.com/hail-is/hail/blob/master/site/hail.nginx.conf#L38-L41). GitHub uses these URLs to send updates to the CI under test about the watched repositories. - `test-locally.sh` now installs `../batch` into the currently running `pip` before testing (NB: if you edit batch and run the tests without committing the changes you've made to batch, this will pass tests but fail when pushed to a PR!). - `test-locally.sh` activates the `hail-ci` conda environment itself because it was not being propagated from the `Makefile`. I don't know why, but this is a simple fix. - `test-locally.sh` starts the ci after the repository is created. CI will print error messages if a watched repository doesn't exist. - `test/test-ci.py` now uses access tokens for all interaction with GitHub, previously it relied on the latent privileges that I and Cotton had in our environments. - `test/test-ci.py` uses a temporary, but not automatically deleted, directory when the environment variable `IN_CLUSTER` is set to `true` (to which it is set by `test-in-c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4474:793,expose,exposes,793,https://hail.is,https://github.com/hail-is/hail/pull/4474,1,['expose'],['exposes']
Security,""" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/fa47fca0-549b-41a3-8bf7-bcda4ca9a617?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/fa47fca0-549b-41a3-8bf7-bcda4ca9a617?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""4d1e728e-269c-49a2-a2d0-bf1c04966e29"",""prPublicId"":""4d1e728e-269c-49a2-a2d0-bf1c04966e29"",""dependencies"":[{""name"":""ipython"",""from"":""7.34.0"",""to"":""8.10.0""},{""name"":""jupyter-server"",""from"":""1.24.0"",""to"":""2.7.2""},{""name"":""setuptools"",""from"":""39.0.1"",""to"":""65.5.1""},{""name"":""tornado"",""from"":""6.2"",""to"":""6.3.3""}],""packageManager"":""pip"",""projectPublicId"":""fa47fca0-549b-41a3-8bf7-bcda4ca9a617"",""projectUrl"":""https://app.snyk.io/org/danking/project/fa47fca0-549b-41a3-8bf7-bcda4ca9a617?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-IPYTHON-3318382"",""SNYK-PYTHON-JUPYTERSERVER-5862881"",""SNYK-PYTHON-JUPYTERSERVER-5862882"",""SNYK-PYTHON-SETUPTOOLS-3180412"",""SNYK-PYTHON-TORNADO-5537286"",""SNYK-PYTHON-TORNADO-5840803"",""SNYK-PYTHON-TORNADO-6041512""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""pr-warning-shown"",""priorityScore""],""priorityScoreList"":[531,null,null,509,384,494,539],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Remote Code Execution (RCE)](https://learn.snyk.io/lesson/improper-input-validation/?loc&#x3D;fix-pr); 🦉 [Access Control Bypass](https://learn.snyk.io/lesson/broken-access-control/?loc&#x3D;fix-pr); 🦉 [Open Redirect](https://learn.snyk.io/lesson/open-redirect/?loc&#x3D;fix-pr); 🦉 [More lessons are available in Snyk Learn](https://learn.snyk.io/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14026:6058,validat,validation,6058,https://hail.is,https://github.com/hail-is/hail/pull/14026,3,"['Access', 'access', 'validat']","['Access', 'access-control', 'validation']"
Security,"""""]]}; from server for: ""deployment.yaml"": namespaces ""batch-pods"" is forbidden: User ""system:serviceaccount:batch-pods:deploy-svc"" cannot get namespaces in the namespace ""batch-pods"": Unknown user ""system:serviceaccount:batch-pods:deploy-svc""; Error from server (Forbidden): error when retrieving current configuration of:; Resource: ""/v1, Resource=serviceaccounts"", GroupVersionKind: ""/v1, Kind=ServiceAccount""; Name: ""batch-svc"", Namespace: ""batch-pods""; Object: &{map[""kind"":""ServiceAccount"" ""metadata"":map[""name"":""batch-svc"" ""namespace"":""batch-pods"" ""annotations"":map[""kubectl.kubernetes.io/last-applied-configuration"":""""]] ""apiVersion"":""v1""]}; from server for: ""deployment.yaml"": serviceaccounts ""batch-svc"" is forbidden: User ""system:serviceaccount:batch-pods:deploy-svc"" cannot get serviceaccounts in the namespace ""batch-pods"": Unknown user ""system:serviceaccount:batch-pods:deploy-svc""; Error from server (Forbidden): error when retrieving current configuration of:; Resource: ""rbac.authorization.k8s.io/v1, Resource=roles"", GroupVersionKind: ""rbac.authorization.k8s.io/v1, Kind=Role""; Name: ""batch-pods-admin"", Namespace: ""batch-pods""; Object: &{map[""apiVersion"":""rbac.authorization.k8s.io/v1"" ""kind"":""Role"" ""metadata"":map[""name"":""batch-pods-admin"" ""namespace"":""batch-pods"" ""annotations"":map[""kubectl.kubernetes.io/last-applied-configuration"":""""]] ""rules"":[map[""apiGroups"":[""""] ""resources"":[""pods""] ""verbs"":[""get"" ""list"" ""watch"" ""create"" ""update"" ""patch"" ""delete""]] map[""apiGroups"":[""""] ""resources"":[""pods/log""] ""verbs"":[""get""]]]]}; from server for: ""deployment.yaml"": roles.rbac.authorization.k8s.io ""batch-pods-admin"" is forbidden: User ""system:serviceaccount:batch-pods:deploy-svc"" cannot get roles.rbac.authorization.k8s.io in the namespace ""batch-pods"": Unknown user ""system:serviceaccount:batch-pods:deploy-svc""; Error from server (Forbidden): error when retrieving current configuration of:; Resource: ""rbac.authorization.k8s.io/v1, Resource=rolebindings"", GroupVersionKind: ""rbac.a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4609:1397,authoriz,authorization,1397,https://hail.is,https://github.com/hail-is/hail/issues/4609,1,['authoriz'],['authorization']
Security,""",""from"":""0.8.4"",""to"":""2.0.3""},{""name"":""nbconvert"",""from"":""5.6.1"",""to"":""6.3.0b0""},{""name"":""notebook"",""from"":""5.7.16"",""to"":""6.4.12""},{""name"":""pygments"",""from"":""2.5.2"",""to"":""2.15.0""},{""name"":""requests"",""from"":""2.27.1"",""to"":""2.31.0""},{""name"":""setuptools"",""from"":""39.0.1"",""to"":""65.5.1""},{""name"":""sphinx"",""from"":""1.8.6"",""to"":""3.3.0""},{""name"":""tornado"",""from"":""5.1.1"",""to"":""6.3.3""}],""packageManager"":""pip"",""projectPublicId"":""20159ae6-a5aa-42fa-845a-c89f5bcbf999"",""projectUrl"":""https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-CERTIFI-3164749"",""SNYK-PYTHON-CERTIFI-5805047"",""SNYK-PYTHON-IPYTHON-2348630"",""SNYK-PYTHON-IPYTHON-3318382"",""SNYK-PYTHON-JUPYTERCORE-3063766"",""SNYK-PYTHON-MISTUNE-2940625"",""SNYK-PYTHON-NBCONVERT-2979829"",""SNYK-PYTHON-NOTEBOOK-1041707"",""SNYK-PYTHON-NOTEBOOK-2441824"",""SNYK-PYTHON-NOTEBOOK-2928995"",""SNYK-PYTHON-PYGMENTS-1086606"",""SNYK-PYTHON-PYGMENTS-1088505"",""SNYK-PYTHON-PYGMENTS-5750273"",""SNYK-PYTHON-REQUESTS-5595532"",""SNYK-PYTHON-SETUPTOOLS-3180412"",""SNYK-PYTHON-SPHINX-570772"",""SNYK-PYTHON-SPHINX-570773"",""SNYK-PYTHON-SPHINX-5811865"",""SNYK-PYTHON-SPHINX-5812109"",""SNYK-PYTHON-TORNADO-5537286"",""SNYK-PYTHON-TORNADO-5840803""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""pr-warning-shown""],""priorityScoreList"":[null,null,null,531,null,null,null,null,null,null,null,null,null,null,509,null,null,null,null,384,494],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Remote Code Execution (RCE)](https://learn.snyk.io/lesson/improper-input-validation/?loc&#x3D;fix-pr); 🦉 [Improper Privilege Management](https://learn.snyk.io/lesson/insecure-design/?loc&#x3D;fix-pr); 🦉 [Regular Expression Denial of Service (ReDoS)](https://learn.snyk.io/lesson/redos/?loc&#x3D;fix-pr); 🦉 [More lessons are available in Snyk Learn](https://learn.snyk.io/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13835:10594,validat,validation,10594,https://hail.is,https://github.com/hail-is/hail/pull/13835,1,['validat'],['validation']
Security,""",""from"":""0.8.4"",""to"":""2.0.3""},{""name"":""nbconvert"",""from"":""5.6.1"",""to"":""6.3.0b0""},{""name"":""notebook"",""from"":""5.7.16"",""to"":""6.4.12""},{""name"":""pygments"",""from"":""2.5.2"",""to"":""2.15.0""},{""name"":""requests"",""from"":""2.27.1"",""to"":""2.31.0""},{""name"":""setuptools"",""from"":""39.0.1"",""to"":""65.5.1""},{""name"":""sphinx"",""from"":""1.8.6"",""to"":""3.3.0""},{""name"":""tornado"",""from"":""5.1.1"",""to"":""6.3.3""}],""packageManager"":""pip"",""projectPublicId"":""fa47fca0-549b-41a3-8bf7-bcda4ca9a617"",""projectUrl"":""https://app.snyk.io/org/danking/project/fa47fca0-549b-41a3-8bf7-bcda4ca9a617?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-CERTIFI-3164749"",""SNYK-PYTHON-CERTIFI-5805047"",""SNYK-PYTHON-IPYTHON-2348630"",""SNYK-PYTHON-IPYTHON-3318382"",""SNYK-PYTHON-JUPYTERCORE-3063766"",""SNYK-PYTHON-MISTUNE-2940625"",""SNYK-PYTHON-NBCONVERT-2979829"",""SNYK-PYTHON-NOTEBOOK-1041707"",""SNYK-PYTHON-NOTEBOOK-2441824"",""SNYK-PYTHON-NOTEBOOK-2928995"",""SNYK-PYTHON-PYGMENTS-1086606"",""SNYK-PYTHON-PYGMENTS-1088505"",""SNYK-PYTHON-PYGMENTS-5750273"",""SNYK-PYTHON-REQUESTS-5595532"",""SNYK-PYTHON-SETUPTOOLS-3180412"",""SNYK-PYTHON-SPHINX-570772"",""SNYK-PYTHON-SPHINX-570773"",""SNYK-PYTHON-SPHINX-5811865"",""SNYK-PYTHON-SPHINX-5812109"",""SNYK-PYTHON-TORNADO-5537286"",""SNYK-PYTHON-TORNADO-5840803""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""pr-warning-shown""],""priorityScoreList"":[null,null,null,531,null,null,null,null,null,null,null,null,null,null,509,null,null,null,null,384,494],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Remote Code Execution (RCE)](https://learn.snyk.io/lesson/improper-input-validation/?loc&#x3D;fix-pr); 🦉 [Improper Privilege Management](https://learn.snyk.io/lesson/insecure-design/?loc&#x3D;fix-pr); 🦉 [Regular Expression Denial of Service (ReDoS)](https://learn.snyk.io/lesson/redos/?loc&#x3D;fix-pr); 🦉 [More lessons are available in Snyk Learn](https://learn.snyk.io/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13866:10620,validat,validation,10620,https://hail.is,https://github.com/hail-is/hail/pull/13866,1,['validat'],['validation']
Security,"""./gradlew"", ""test"", ""shadowJar""]; outputs:; - ""build/libs/hail-all-spark.jar""; - type: exec; name: pytests; image: hail-pr-builder; dependsOn:; - build-jar; command: [""./run-python-tests-using-input-jar.sh""]; ```. A series of steps that get us there:. - [x] (https://github.com/hail-is/hail/pull/5231) jobs may only depend on other jobs in the same batch ; - [x] (https://github.com/hail-is/hail/pull/5232) a batch can be `closed` indicating no more jobs will be added; - [ ] (https://github.com/hail-is/hail/pull/5233) a batch is automatically closed after 30 minutes; - [ ] add ""outputs"" to batch jobs. When a batch job is complete, the batch system copies its outputs to some durable storage (e.g. GCS), this is not user-visible; - [ ] add input/output dependencies to batch jobs. A batch job always receives the output of its parents. The data is copied (somehow) from the durable storage to the pod's filesystem at the path `/input/PARENT_JOB_NAME` and set to permissions 777. The copying is done in a secure way. In particular, the job container can be completely unprivileged (e.g. no credentials in the job's image, no credentials in the mounted volumes, no way to escalate to these credentials); - [ ] parse and run a series of `exec` commands that execute in parallel but no namespace dependencies and no image dependencies. This immediately puts us in a better place wrt logging. All artifacts, such as HTML reports are served through the batch outputs mechanism described above. Job file dependencies are handled exactly as described in input/output dependencies above.; - [ ] allow ""finalizer"" jobs. A finalizer job executes when its parents are all complete or cancelled. It is not cancelled when its parents are cancelled.; - [ ] add namespace dependencies. CI allocates anonymous namespaces as requested by the build process. All `exec`s are, by default, run in an anonymous namespace. CI adds a finalizer job that deletes namespaces when all relevant `exec`s are finished; - [ ] add ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5193:1311,secur,secure,1311,https://hail.is,https://github.com/hail-is/hail/issues/5193,1,['secur'],['secure']
Security,""":""2.15.0""},{""name"":""requests"",""from"":""2.27.1"",""to"":""2.31.0""},{""name"":""setuptools"",""from"":""39.0.1"",""to"":""65.5.1""},{""name"":""sphinx"",""from"":""1.8.6"",""to"":""3.3.0""},{""name"":""tornado"",""from"":""5.1.1"",""to"":""6.3.3""},{""name"":""wheel"",""from"":""0.30.0"",""to"":""0.38.0""}],""packageManager"":""pip"",""projectPublicId"":""fa47fca0-549b-41a3-8bf7-bcda4ca9a617"",""projectUrl"":""https://app.snyk.io/org/danking/project/fa47fca0-549b-41a3-8bf7-bcda4ca9a617?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-CERTIFI-3164749"",""SNYK-PYTHON-CERTIFI-5805047"",""SNYK-PYTHON-IPYTHON-2348630"",""SNYK-PYTHON-IPYTHON-3318382"",""SNYK-PYTHON-JINJA2-6150717"",""SNYK-PYTHON-JUPYTERCORE-3063766"",""SNYK-PYTHON-MISTUNE-2940625"",""SNYK-PYTHON-NBCONVERT-2979829"",""SNYK-PYTHON-NOTEBOOK-1041707"",""SNYK-PYTHON-NOTEBOOK-2441824"",""SNYK-PYTHON-NOTEBOOK-2928995"",""SNYK-PYTHON-PROMPTTOOLKIT-6141120"",""SNYK-PYTHON-PYGMENTS-1086606"",""SNYK-PYTHON-PYGMENTS-1088505"",""SNYK-PYTHON-PYGMENTS-5750273"",""SNYK-PYTHON-REQUESTS-5595532"",""SNYK-PYTHON-SETUPTOOLS-3180412"",""SNYK-PYTHON-SPHINX-570772"",""SNYK-PYTHON-SPHINX-570773"",""SNYK-PYTHON-SPHINX-5811865"",""SNYK-PYTHON-SPHINX-5812109"",""SNYK-PYTHON-TORNADO-5537286"",""SNYK-PYTHON-TORNADO-5840803"",""SNYK-PYTHON-TORNADO-6041512"",""SNYK-PYTHON-WHEEL-3180413""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""pr-warning-shown""],""priorityScoreList"":[null,null,null,531,null,null,null,null,null,null,null,null,null,null,null,null,509,null,null,null,null,384,494,539,null],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Remote Code Execution (RCE)](https://learn.snyk.io/lesson/improper-input-validation/?loc&#x3D;fix-pr); 🦉 [Cross-site Scripting (XSS)](https://learn.snyk.io/lesson/xss/?loc&#x3D;fix-pr); 🦉 [Improper Privilege Management](https://learn.snyk.io/lesson/insecure-design/?loc&#x3D;fix-pr); 🦉 [More lessons are available in Snyk Learn](https://learn.snyk.io/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14257:12044,validat,validation,12044,https://hail.is,https://github.com/hail-is/hail/pull/14257,4,"['Cross-site Scripting', 'XSS', 'validat', 'xss']","['Cross-site Scripting', 'XSS', 'validation', 'xss']"
Security,""":""2.15.0""},{""name"":""requests"",""from"":""2.27.1"",""to"":""2.31.0""},{""name"":""setuptools"",""from"":""40.5.0"",""to"":""65.5.1""},{""name"":""sphinx"",""from"":""1.8.6"",""to"":""3.3.0""},{""name"":""tornado"",""from"":""5.1.1"",""to"":""6.3.3""},{""name"":""wheel"",""from"":""0.32.2"",""to"":""0.38.0""}],""packageManager"":""pip"",""projectPublicId"":""20159ae6-a5aa-42fa-845a-c89f5bcbf999"",""projectUrl"":""https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-CERTIFI-3164749"",""SNYK-PYTHON-CERTIFI-5805047"",""SNYK-PYTHON-IPYTHON-2348630"",""SNYK-PYTHON-IPYTHON-3318382"",""SNYK-PYTHON-JINJA2-6150717"",""SNYK-PYTHON-JUPYTERCORE-3063766"",""SNYK-PYTHON-MISTUNE-2940625"",""SNYK-PYTHON-NBCONVERT-2979829"",""SNYK-PYTHON-NOTEBOOK-1041707"",""SNYK-PYTHON-NOTEBOOK-2441824"",""SNYK-PYTHON-NOTEBOOK-2928995"",""SNYK-PYTHON-PROMPTTOOLKIT-6141120"",""SNYK-PYTHON-PYGMENTS-1086606"",""SNYK-PYTHON-PYGMENTS-1088505"",""SNYK-PYTHON-PYGMENTS-5750273"",""SNYK-PYTHON-REQUESTS-5595532"",""SNYK-PYTHON-SETUPTOOLS-3180412"",""SNYK-PYTHON-SPHINX-570772"",""SNYK-PYTHON-SPHINX-570773"",""SNYK-PYTHON-SPHINX-5811865"",""SNYK-PYTHON-SPHINX-5812109"",""SNYK-PYTHON-TORNADO-5537286"",""SNYK-PYTHON-TORNADO-5840803"",""SNYK-PYTHON-TORNADO-6041512"",""SNYK-PYTHON-WHEEL-3180413""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""pr-warning-shown""],""priorityScoreList"":[null,null,null,531,null,null,null,null,null,null,null,null,null,null,null,null,509,null,null,null,null,384,494,539,null],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Remote Code Execution (RCE)](https://learn.snyk.io/lesson/improper-input-validation/?loc&#x3D;fix-pr); 🦉 [Cross-site Scripting (XSS)](https://learn.snyk.io/lesson/xss/?loc&#x3D;fix-pr); 🦉 [Improper Privilege Management](https://learn.snyk.io/lesson/insecure-design/?loc&#x3D;fix-pr); 🦉 [More lessons are available in Snyk Learn](https://learn.snyk.io/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14364:12397,validat,validation,12397,https://hail.is,https://github.com/hail-is/hail/pull/14364,4,"['Cross-site Scripting', 'XSS', 'validat', 'xss']","['Cross-site Scripting', 'XSS', 'validation', 'xss']"
Security,"""global"",; ""reason"": ""forbidden""; }; ]; }; }. 		at com.google.api.client.http.HttpResponseException$Builder.build(HttpResponseException.java:293) ~[gs:__hail-query-ger0g_jars_b115f6a6ec23f111a4512b562b52d9f8a52ec41c.jar.jar:0.0.1-SNAPSHOT]; 		at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1118) ~[gs:__hail-query-ger0g_jars_b115f6a6ec23f111a4512b562b52d9f8a52ec41c.jar.jar:0.0.1-SNAPSHOT]; 		at is.hail.relocated.com.google.cloud.storage.spi.v1.HttpStorageRpc.open(HttpStorageRpc.java:1022) ~[gs:__hail-query-ger0g_jars_b115f6a6ec23f111a4512b562b52d9f8a52ec41c.jar.jar:0.0.1-SNAPSHOT]; 		... 48 more; Caused by: com.google.api.client.http.HttpResponseException: 403 Forbidden; POST https://storage.googleapis.com/upload/storage/v1/b/neale-bge/o?name=foo.ht/index/part-0-c7ba7549-bf68-42db-a8ef-0f1b13721c79.idx/index&uploadType=resumable; {; ""error"": {; ""code"": 403,; ""message"": ""dking-ae4q6@hail-vdc.iam.gserviceaccount.com does not have storage.objects.create access to the Google Cloud Storage object. Permission 'storage.objects.create' denied on resource (or it may not exist)."",; ""errors"": [; {; ""message"": ""dking-ae4q6@hail-vdc.iam.gserviceaccount.com does not have storage.objects.create access to the Google Cloud Storage object. Permission 'storage.objects.create' denied on resource (or it may not exist)."",; ""domain"": ""global"",; ""reason"": ""forbidden""; }; ]; }; }. 	at com.google.api.client.http.HttpResponseException$Builder.build(HttpResponseException.java:293) ~[gs:__hail-query-ger0g_jars_b115f6a6ec23f111a4512b562b52d9f8a52ec41c.jar.jar:0.0.1-SNAPSHOT]; 	at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1118) ~[gs:__hail-query-ger0g_jars_b115f6a6ec23f111a4512b562b52d9f8a52ec41c.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.spi.v1.HttpStorageRpc.open(HttpStorageRpc.java:1022) ~[gs:__hail-query-ger0g_jars_b115f6a6ec23f111a4512b562b52d9f8a52ec41c.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13697:27387,access,access,27387,https://hail.is,https://github.com/hail-is/hail/issues/13697,1,['access'],['access']
Security,"""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiIyN2MzNWY4NC0yNDIyLTRmNzUtYWMxYy1mODQxOGJmNzRlMzciLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjI3YzM1Zjg0LTI0MjItNGY3NS1hYzFjLWY4NDE4YmY3NGUzNyJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""27c35f84-2422-4f75-ac1c-f8418bf74e37"",""prPublicId"":""27c35f84-2422-4f75-ac1c-f8418bf74e37"",""dependencies"":[{""name"":""cryptography"",""from"":""41.0.7"",""to"":""42.0.2""}],""packageManager"":""pip"",""projectPublicId"":""5ecb4152-94d0-44ff-86c6-21e542bb123d"",""projectUrl"":""https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-CRYPTOGRAPHY-6149518"",""SNYK-PYTHON-CRYPTOGRAPHY-6157248"",""SNYK-PYTHON-CRYPTOGRAPHY-6210214""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""pr-warning-shown"",""priorityScore""],""priorityScoreList"":[509,581,451],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Use of a Broken or Risky Cryptographic Algorithm](https://learn.snyk.io/lesson/insecure-hash/?loc&#x3D;fix-pr); 🦉 [Uncontrolled Resource Consumption (&#x27;Resource Exhaustion&#x27;)](https://learn.snyk.io/lesson/redos/?loc&#x3D;fix-pr); 🦉 [NULL Pointer Dereference](https://learn.snyk.io/lesson/null-dereference/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14234:4498,hash,hash,4498,https://hail.is,https://github.com/hail-is/hail/pull/14234,1,['hash'],['hash']
Security,"""https://github-redirect.dependabot.com/lepture/mistune/issues/307"">#307</a> from jieter/patch-1</li>; <li><a href=""https://github.com/lepture/mistune/commit/0eba47196a81453bafe1f2492748a87475063dff""><code>0eba471</code></a> Fix typo in guide.rst</li>; <li><a href=""https://github.com/lepture/mistune/commit/61e9337884e20f9f8fdc0b7788d319afdd259729""><code>61e9337</code></a> Fix table plugin</li>; <li><a href=""https://github.com/lepture/mistune/commit/76dec68c4514c2612ef9263b49c6ec7f4d77bd14""><code>76dec68</code></a> Add documentation for renderer heading when TOC enabled</li>; <li>Additional commits viewable in <a href=""https://github.com/lepture/mistune/compare/v0.8.4...v2.0.4"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=mistune&package-manager=pip&previous-version=0.8.4&new-version=2.0.4)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12066:4191,secur,security-vulnerabilities,4191,https://hail.is,https://github.com/hail-is/hail/pull/12066,4,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2301"">#2301</a> from jeff-m-sullivan/rscript-path</li>; <li><a href=""https://github.com/pre-commit/pre-commit/commit/d65016042b67d09139876e1903e839a168dfa7c3""><code>d650160</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2252"">#2252</a> from daschuer/worktree_fix</li>; <li><a href=""https://github.com/pre-commit/pre-commit/commit/fd0177ae3ae5f94b36aafb54ab496f76fcead7b9""><code>fd0177a</code></a> implement default_install_hook_types</li>; <li>Additional commits viewable in <a href=""https://github.com/pre-commit/pre-commit/compare/v2.17.0...v2.18.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pre-commit&package-manager=pip&previous-version=2.17.0&new-version=2.18.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11731:13110,secur,security-vulnerabilities,13110,https://hail.is,https://github.com/hail-is/hail/pull/11731,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"""https://github.com/PyCQA/pylint/commit/c73353064f934ae49472eb6138e1f8071b6b733e""><code>c733530</code></a> <code>unnecessary-ellipsis</code> false positive: allow ellipsis as default argument (<a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/6"">#6</a>...</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/19e6531068cf95d602054ff8638adcb79971d552""><code>19e6531</code></a> Fix crash on unbalanced tuple unpacking</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/2066cab9bbe43341b84014ac9610e275db586431""><code>2066cab</code></a> Bump pylint to 2.13.2, update changelog</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/6a25d7048edadc18a05e999021049ade86ef2bd9""><code>6a25d70</code></a> Better error message when we cant write the crash files (<a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/5987"">#5987</a>)</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/c42fe73a1613bbfb52a5ba9129efa45a3fd76401""><code>c42fe73</code></a> Fix false negative for <code>protected-access</code> on functions (<a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/5990"">#5990</a>)</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/dec241b1787e6c99a092bb9ef6a993abf51fea91""><code>dec241b</code></a> Add regression test for <a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/5982"">#5982</a> upgrade astroid to 2.11.2 (<a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/5988"">#5988</a>)</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/b25859c4a56ccce61087f7a1270f40deaed68169""><code>b25859c</code></a> Fix false positive for <code>superfluous-parens</code> for <code>return (a or b) in iterable</code>...</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/0e1ca11ac65cbe5a65437518fca1e25f1ad0e48e""><code>0e1ca11</code></a> Bump pylint to 2.13.1, update changelog</li>; <li>Additional commits viewable in <a href=""https://github.com/PyCQA/pylint/compare/v2.12.2...v2.13.3"">compar",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11702:3731,access,access,3731,https://hail.is,https://github.com/hail-is/hail/pull/11702,1,['access'],['access']
Security,"""https://github.com/lepture/authlib/releases"">authlib's releases</a>.</em></p>; <blockquote>; <h2>Version 0.15.5</h2>; <ul>; <li>Make Authlib compatible with latest httpx</li>; <li>Make Authlib compatible with latest werkzeug</li>; <li>Allow customize RFC7523 <code>alg</code> value</li>; </ul>; <h2>Version 0.15.4</h2>; <p>Security fix when JWT claims is None.</p>; <p>For example, JWT payload has <code>iss=None</code>:</p>; <pre><code>{; &quot;iss&quot;: None,; ...; }; </code></pre>; <p>But we need to decode it with claims:</p>; <pre><code>claims_options = {; 'iss': {'essential': True, 'values': ['required']}; }; jwt.decode(token, key, claims_options=claims_options); </code></pre>; <p>It didn't raise an error before this fix.</p>; <h2>Version 0.15.3</h2>; <p>Fixed <code>.authorize_access_token</code> for OAuth 1.0 services, via <a href=""https://github-redirect.dependabot.com/lepture/authlib/issues/308"">lepture/authlib#308</a></p>; <h2>Version 0.15.2</h2>; <p>Fixed httpx authentication bug via <a href=""https://github-redirect.dependabot.com/lepture/authlib/issues/283"">#283</a></p>; <h2>Version 0.15.1</h2>; <p>Backward compitable fix for using JWKs in JWT, via <a href=""https://github-redirect.dependabot.com/lepture/authlib/issues/280"">#280</a>.</p>; <h2>Version 0.15</h2>; <p>This is the last release before v1.0. In this release, we added more RFCs; implementations and did some refactors for JOSE:</p>; <ul>; <li>RFC8037: CFRG Elliptic Curve Diffie-Hellman (ECDH) and Signatures in JSON Object Signing and Encryption (JOSE)</li>; <li>RFC7638: JSON Web Key (JWK) Thumbprint</li>; </ul>; <p>We also fixed bugs for integrations:</p>; <ul>; <li>Fixed support for HTTPX&gt;=0.14.3</li>; <li>Added OAuth clients of HTTPX back via <a href=""https://github-redirect.dependabot.com/lepture/authlib/issues/270"">#270</a></li>; <li>Fixed parallel token refreshes for HTTPX async OAuth 2 client</li>; <li>Raise OAuthError when callback contains errors via <a href=""https://github-redirect.dependa",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11483:1131,authenticat,authentication,1131,https://hail.is,https://github.com/hail-is/hail/pull/11483,1,['authenticat'],['authentication']
Security,# Batch Inter-Job File Dependencies. The important addition of this PR is a `copy_service_account_name` field on batch jobs that permits the client to authorize with some GCP credentials stored in a k8s secret. The copy pods and the main pod only share the `/io` folder (k8s forbids mounting a volume as `/`). This interface is pretty onerous. Pipelines will be updated to use this interface. Pipelines is becoming the easy-to-use interface to batch.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5574:151,authoriz,authorize,151,https://hail.is,https://github.com/hail-is/hail/pull/5574,1,['authoriz'],['authorize']
Security,"# SRE; - The Google SRE Books https://landing.google.com/sre/books/; - Distributed Systems Observability https://www.oreilly.com/library/view/distributed-systems-observability/9781492033431/; - ""Learning to Build Distributed Systems"" http://brooker.co.za/blog/2019/04/03/learning.html; - Increment's On-Call issue https://increment.com/on-call/; # SWE; - ""Designing Data-Intensive Systems"" by Kleppman https://www.amazon.com/gp/product/1449373321/; # SEC; - ""The Confused Deputy"" http://zoo.cs.yale.edu/classes/cs422/2010/bib/hardy88confused.pdf; - ""Blueprint fo a science of cybersecurity"" http://www.cs.cornell.edu/fbs/publications/SoS.blueprint.pdf; - ""Macaroons: Cookies with Contextual Caveats for Decentralized Authorization in the Cloud"" https://ai.google/research/pubs/pub41892; - ""Native Client: A Sandbox for Portable, Untrusted x86 Native Code"" https://ai.google/research/pubs/pub34913; - What is CSRF https://www.owasp.org/index.php/Cross-Site_Request_Forgery_(CSRF); - What is XSS https://www.owasp.org/index.php/Cross-site_Scripting_(XSS); ## Containers; - gVisor Architecture Guide https://gvisor.dev/docs/architecture_guide/; - ""cgroups"" https://www.kernel.org/doc/Documentation/cgroup-v1/cgroups.txt; - ""cgroups v2"" https://github.com/torvalds/linux/blob/master/Documentation/admin-guide/cgroup-v2.rst; - ""Docker Security"" https://docs.docker.com/engine/security/security/; - ""On the security of containers"" https://medium.com/@ewindisch/on-the-security-of-containers-2c60ffe25a9e; - ""User namespaces might not be enough"" https://medium.com/@ewindisch/linux-user-namespaces-might-not-be-secure-enough-a-k-a-subverting-posix-capabilities-f1c4ae19cad; - ""OS-level virtualization"" https://en.wikipedia.org/wiki/OS-level_virtualisation; - ""Sandbox (computer security)"" https://en.wikipedia.org/wiki/Sandbox_(computer_security); - ""Making Containers More Isolated: An Overview of Sandboxed Container Technologies"" https://unit42.paloaltonetworks.com/making-containers-more-isolated-an-over",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6720:717,Authoriz,Authorization,717,https://hail.is,https://github.com/hail-is/hail/issues/6720,2,"['Authoriz', 'XSS']","['Authorization', 'XSS']"
Security,"## Bug fixes to enable Azure deployment. Most of these bugs were discovered in deploying the MySQL server from scratch, specifically deploying version 8.0. ; Some were encountered when we hit certificate issues in trying to run the `./bootstrap.sh deploy_unmanaged` step multiple times within 24hrs. Documentation was clarified in order to resolve this issue. - build.yaml; - Step one fails on rerun since the /repo directory exists, -p to fix; - ci/create_database.py; - In MySQL 8 a new error was introduced [4006](https://dev.mysql.com/doc/mysql-errors/8.0/en/server-error-reference.html#error_er_cannot_user_referenced_as_definer); - This error gets triggered on the CREATE USER IF NOT EXISTS commands for both user and admin if the user was previously created and set a a definer on any events/triggers.; - Really this statement should be a no-op given that the user exists, but for some reason the error triggers anyway.; - To get around this I added a manual check if the user/admin exists and if they do simply skip the create user command. This fixes the bug and allows the MySQL db deploy to finish properly. - dev-docs/letsencrypt.md; - Debugging was confusing since the revoke command addressed ids we were unable to find.; - After extensive searching I added to the documentation how to find your existing cert IDs if you need to revoke them. - infra/azure/README.md; - Added clarity to the Azure deployment documentation. - infra/azure/bootstrap.sh; - Added the passing of additional flag arguments to terraform; - In our case the passing of the `-upgrade` flag to the terraform init step was required in order to continue. - infra/azure/main.tf, infra/azure/modules/batch/main.tf, infra/azure/modules/batch/variables.tf infra/azure/variables.tf; - Add additional argument for the az_storage_account.; - The name must be globally unique in Azure, so the original argument failed on our deployment since it shared the name with the Hail team's Azure deployment",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12065:192,certificate,certificate,192,https://hail.is,https://github.com/hail-is/hail/pull/12065,1,['certificate'],['certificate']
Security,## Change Description. AWS no longer maintains the Hail on AWS quickstart. This PR removes the reference to this now-broken documentation. ## Security Assessment. - This change has no security impact. ### Impact Description. This PR removes broken documentation. There is no end user impact.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14738:142,Secur,Security,142,https://hail.is,https://github.com/hail-is/hail/pull/14738,2,"['Secur', 'secur']","['Security', 'security']"
Security,"## Change Description. Config and records relating to the appsec deployment instance. Necessary for future maintenance and management of the appsec instance. ## Security Assessment. - This change has no security impact. ### Impact Description. No impact because this relates only to the parallel appsec instance, not the main production instance. (Reviewers: please confirm the security impact before approving)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14726:161,Secur,Security,161,https://hail.is,https://github.com/hail-is/hail/pull/14726,3,"['Secur', 'secur']","['Security', 'security']"
Security,"## Change Description. Corrects our gsa-key copying instructions (from #14664) to copy the key contents, not the entire secret metadata. The batch service seems resilient to these badly formed secrets, but the rotate_keys.py script was not. ## Security Assessment. Delete all except the correct answer:; - This change has a low security impact. ### Impact Description. - Not a production change; - Does not add any new information to the secrets, only formats them a useable way. ; - Only in dev namespaces. (Reviewers: please confirm the security impact before approving)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14735:244,Secur,Security,244,https://hail.is,https://github.com/hail-is/hail/pull/14735,3,"['Secur', 'secur']","['Security', 'security']"
Security,"## Change Description. Fixes #14597. ## Security Assessment. Delete all except the correct answer:; - This change has a high security impact; - [ ] Required: The impact has been assessed and approved by appsec; - This change has a medium security impact; - This change has a low security impact; - This change has no security impact. ### Impact Description. For none/low impact: a quick one/two sentence justification of the rating.; - Example: ""Docs only"", ""Low-level refactoring of non-security code"", etc.; For medium/high impact: provide a description of the impact and the mitigations in place.; - Example: ""New UI text field added in analogy to existing elements, with input strings escaped and validated against code injection"". (Reviewers: please confirm the security impact before approving)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14745:40,Secur,Security,40,https://hail.is,https://github.com/hail-is/hail/pull/14745,9,"['Secur', 'inject', 'secur', 'validat']","['Security', 'injection', 'security', 'validated']"
Security,## Change Description. Fixes #14597. cancel_after_n_failures = 1; cancels whole job group if one partition fails. ## Security Assessment. - This change has no security impact. ### Impact Description. Unit tests and no interaction on anything secure. (Reviewers: please confirm the security impact before approving),MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14747:117,Secur,Security,117,https://hail.is,https://github.com/hail-is/hail/pull/14747,4,"['Secur', 'secur']","['Security', 'secure', 'security']"
Security,"## Change Description. Fixes #<issue_number> (delete if N/A). Brief description and justification of what this PR is doing. ## Security Assessment. Delete all except the correct answer:; - This change has a high security impact; - [ ] Required: The impact has been assessed and approved by appsec; - This change has a medium security impact; - This change has a low security impact; - This change has no security impact. ### Impact Description. For none/low impact: a quick one/two sentence justification of the rating.; - Example: ""Docs only"", ""Low-level refactoring of non-security code"", etc.; For medium/high impact: provide a description of the impact and the mitigations in place.; - Example: ""New UI text field added in analogy to existing elements, with input strings escaped and validated against code injection"". (Reviewers: please confirm the security impact before approving)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14732:127,Secur,Security,127,https://hail.is,https://github.com/hail-is/hail/pull/14732,18,"['Secur', 'inject', 'secur', 'validat']","['Security', 'injection', 'security', 'validated']"
Security,"## Change Description. On windows, gcloud is 'gcloud.cmd' and as such, it needs to be run via the command shell. Other platforms are not affected. This change is in response to Nico Valencia having difficulties running hailctl on Windows. ## Security Assessment. Delete all except the correct answer:; - This change has a medium security impact. ### Impact Description. Technically speaking, this opens up users of `hailctl dataproc` to command injection, but only on platforms where `sys.platform == 'win32'`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14736:242,Secur,Security,242,https://hail.is,https://github.com/hail-is/hail/pull/14736,3,"['Secur', 'inject', 'secur']","['Security', 'injection', 'security']"
Security,"## Change Description. Replacing pyright with pyright[nodejs] in /dev/requirements.txt, allowing for installation of necessary node.js binaries to run pyright when one installs dev requirements. As per https://pypi.org/project/pyright/, pyright needs node to run, but pip installing pyright doesn't also install node. Pyright acknowledges this, and they have a separate pip installation command that will also give you the necessary node binaries to run pyright. We now specify that proper pyright+node install in our requirements.txt. ## Security Assessment. Delete all except the correct answer:; - This change has a low security impact; - [ ] Required: The impact has been assessed and approved by appsec. ### Impact Description. Updating old pyright installation in /dev/requirements.txt, no impact on security-sensitive systems. (Reviewers: please confirm the security impact before approving)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14741:539,Secur,Security,539,https://hail.is,https://github.com/hail-is/hail/pull/14741,4,"['Secur', 'secur']","['Security', 'security', 'security-sensitive']"
Security,## Change Description. This PR updates the tutorial instructions for running Hail on Dataproc to clarify that the Google Cloud SDK must be installed and configured before Hail can be run. I made this change to prevent future users from also needing to Google these setup instructions. ## Security Assessment. - This change has no security impact. ### Impact Description. This change only updates documentation and has no immediate end user impact. The updated documentation does not leak any proprietary / confidential / sensitive information about Hail or any related systems.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14737:288,Secur,Security,288,https://hail.is,https://github.com/hail-is/hail/pull/14737,3,"['Secur', 'confidential', 'secur']","['Security', 'confidential', 'security']"
Security,"## Change Description. Updates new developer template to include the need for a Google project role. ## Security Assessment. - This change has no security impact. ### Impact Description. None, documentation change only. (Reviewers: please confirm the security impact before approving)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14733:104,Secur,Security,104,https://hail.is,https://github.com/hail-is/hail/pull/14733,3,"['Secur', 'secur']","['Security', 'security']"
Security,"## Change Description. When going through the [documentation for installing Hail on OSX](https://hail.is/docs/0.2/install/macosx.html), I noticed that the syntax for installing Java via Homebrew was out of date. This PR updates the documentation to use the latest syntax for Homebrew. It also updates the command to install version 11 of Temurin instead of version 8. ## Security Assessment. - This change has no security impact. ### Impact Description. This change updates documentation only and has no immediate end user impact. This change updates the recommended version of Temurin to a newer version (11 vs. 8). It is reasonable to assume that the newer version is at least as secure as previous versions. So, there also should be no negative security impact on future users of this documentation.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14729:371,Secur,Security,371,https://hail.is,https://github.com/hail-is/hail/pull/14729,4,"['Secur', 'secur']","['Security', 'secure', 'security']"
Security,"## Change Description; - Added ability to check job status in individual jobs in a JobGroup; - Cancel JobGroup if any jobs in the partition fail; - Added test functionality for detecting cancelled, failed jobs; - Query batch for which jobs have failed within a JobGroup, rather than go through every job in the group. ## Security Assessment. Delete all except the correct answer:; - This change has no security impact. ### Impact Description; Mainly just code for testing, nothing security related. (Reviewers: please confirm the security impact before approving)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14751:321,Secur,Security,321,https://hail.is,https://github.com/hail-is/hail/pull/14751,4,"['Secur', 'secur']","['Security', 'security']"
Security,## Change Description; Add section on authenticating to GKS+GAR and AKS+ACR and then setting the kubectl context to the appropriate cluster. Note that the one should clean the letsencrypt image files created by make. ## Security Assessment. - This change has no security impact. ### Impact Description. Only documentation changes.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14734:38,authenticat,authenticating,38,https://hail.is,https://github.com/hail-is/hail/pull/14734,3,"['Secur', 'authenticat', 'secur']","['Security', 'authenticating', 'security']"
Security,"## HTTPS and TLS. HTTP is implemented on TCP/IP. HTTPS is also implemented on TCP/IP and differs; very mildly. After the socket is opened, a TLS [1] connection is established; over the socket. Thereafter, every HTTP message is encrypted and transported by; the TLS machinery. The HTTP protocol is unchanged. The default port fort HTTP is; 80 and the default port for HTTPS 443, however any port may be used. There are currently four versions of TLS, the latest is TLS 1.3. All versions of; SSL are considered insecure. The OpenSSL library implements TLS. There are other implementations, such as; LibreSSL, but they implement roughly the same interface as OpenSSL. The TLS protocol defines both a scheme for the *encryption of messages* and for; the *authentication of parties*. The protocol defines authentication as; optional. In practice, at least one party presents authentication. For example,; public web servers authenticate themselves to clients but clients do not; reciprocate. ### Authentication; #### X.509 Certificates. TLS uses X.509 Certificates for authentication. X.509 is a rather complicated; standard. X.509 Certificates can be serialized in a variety of ways. We use the; Privacy-enhanced Electronic Mail (PEM) file format for serialization. PEM is; really simple. A file may contain multiple base64-encoded blobs each with a; header and footer of the form:. ```; -----BEGIN LABEL-----; ...; -----END LABEL-----; ```. where `LABEL` describes the data. We only use two labels: `CERTIFICATE` and; `PRIVATE KEY`. An X.509 Certificate is an unforgeable proof of identity. It usually is paired; with a private key that was used to digitally sign the certificate. In the; security literature, an authenticatable entity is usually called a; *principal*. Each principal should have a unique private key. In our system the; principals are both our services (e.g. `batch`, `batch-driver`) and any; non-serving clients (e.g. `test-batch`, `admin-pod`). A key and certificate are; generated a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8561:2307,Authenticat,Authentication,2307,https://hail.is,https://github.com/hail-is/hail/pull/8561,1,['Authenticat'],['Authentication']
Security,## Security Assessment. Delete all except the correct answer:; - This change has no security impact. ### Impact Description; Docs only,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14730:3,Secur,Security,3,https://hail.is,https://github.com/hail-is/hail/pull/14730,2,"['Secur', 'secur']","['Security', 'security']"
Security,"### Change Description. A convenience template for creating ""add new developer"" issues and documenting the steps required. ### Security Assessment; This change has no security impact. #### Description of the security impact and necessary mitigations:. No impact, only a new github issue creation form. (Reviewers: please confirm the security impact before approving)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14719:127,Secur,Security,127,https://hail.is,https://github.com/hail-is/hail/pull/14719,4,"['Secur', 'secur']","['Security', 'security']"
Security,### Change Description. Adds grohli to list of AUTHORIZED_USERS. ### Security Assessment; - [x] This change has a low security impact. (Reviewers: please confirm the security impact before approving),MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14716:69,Secur,Security,69,https://hail.is,https://github.com/hail-is/hail/pull/14716,3,"['Secur', 'secur']","['Security', 'security']"
Security,"### Change Description. Adds more logging around CI decisions, to make future debugging of ""why is my PR stuck"" easier to trace through. ### Security Assessment. - [ ] This change has a high security impact; - [ ] Required: and the impact has been assessed and approved by appsec; - [ ] This change has a medium security impact; - [X] This change has a low security impact; - [ ] This change has no security impact. Description of the security impact and necessary mitigations:. Logs-only change in non-user-data-facing component.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14674:141,Secur,Security,141,https://hail.is,https://github.com/hail-is/hail/pull/14674,6,"['Secur', 'secur']","['Security', 'security']"
Security,### Change Description. Corrections and updates to the gcp deploy instructions following a fresh deployment in a brand new project. ### Security Assessment. This change has no security impact. No impact because this does not impact the production system. (Reviewers: please confirm the security impact before approving),MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14722:136,Secur,Security,136,https://hail.is,https://github.com/hail-is/hail/pull/14722,3,"['Secur', 'secur']","['Security', 'security']"
Security,"### Change Description. In [09437c5](https://github.com/hail-is/hail/commit/09437c531b47c9af2faa196817c6edeaba17fced), I moved `pytest.ini` up a directory but didn't update the artefacts built in ci.; As a consequence, test stages like `test_unchecked_allocator` have not run since. ### Security Assessment. This change has no security impact",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14721:287,Secur,Security,287,https://hail.is,https://github.com/hail-is/hail/pull/14721,2,"['Secur', 'secur']","['Security', 'security']"
Security,"### Change Description. Jobs within our CI pipeline often invoke `mill` indirectly through `Makefile` prerequisites.; By staging mill's build area to and from `/derived/{release/debug}/hail/out`, mill will not rebuild artefacts from previous steps.; Exposing `MILLOPTS` in `hail/Makefile` allows us to build in CI without a compilation server. ; Using a compilation server may have been why we experienced intermittent failures between building the jar and copying to its final destination.; Note that the `--no-server` option must be the first argument to `millw`. ### Security Assessment; - [x] This change has no security impact. Description of the security impact and necessary mitigations:. Only derived files from the mill + python build process are staged and unstaged.; No secrets or otherwise sensitive information are contained therein. (Reviewers: please confirm the security impact before approving)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14709:570,Secur,Security,570,https://hail.is,https://github.com/hail-is/hail/pull/14709,4,"['Secur', 'secur']","['Security', 'security']"
Security,### Change Description. Make the PR template a little easier to work with. ### Security Assessment. - This change has no security impact. Description of the security impact and necessary mitigations:. No impact because this is not code being deployed to production. (Reviewers: please confirm the security impact before approving),MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14723:79,Secur,Security,79,https://hail.is,https://github.com/hail-is/hail/pull/14723,4,"['Secur', 'secur']","['Security', 'security']"
Security,### Change Description. Seems like only yesterday that we had #14668. Also removes @illusional as I believe he's no longer in a contributing role (... but please shout out if you disagree! And cc @jmarshall). ### Security Assessment. - [ ] This change has a high security impact; - [ ] Required: and the impact has been assessed and approved by appsec; - [ ] This change has a medium security impact; - [X] This change has a low security impact; - [ ] This change has no security impact. Description of the security impact and necessary mitigations:. Removes entries from the allow-list of contributors and recommended reviewers.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14704:213,Secur,Security,213,https://hail.is,https://github.com/hail-is/hail/pull/14704,6,"['Secur', 'secur']","['Security', 'security']"
Security,### Change Description. The `letsencrypt` inputs to `batch_worker_image` are duplicated (though; the second time were localised to an unreachable location). . ### Security Assessment. - [x] This change has no security impact. Description of the security impact and necessary mitigations:. These files were unreachable from the ci job. (Reviewers: please confirm the security impact before approving),MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14712:163,Secur,Security,163,https://hail.is,https://github.com/hail-is/hail/pull/14712,4,"['Secur', 'secur']","['Security', 'security']"
Security,"### Change Description. The changes in #14708 caused our vep images to be rebuilt, breaking them. The solution here is the one that we should have done from the beginning, install dependencies through the system package manager. In the interest of my sanity and effort, I only added the libraries that were being problematic from CPAN to the list of system installed ones. ### Security Assessment; - [x] This change has no security impact",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14713:377,Secur,Security,377,https://hail.is,https://github.com/hail-is/hail/pull/14713,2,"['Secur', 'secur']","['Security', 'security']"
Security,"### Change Description. This change exists as part of larger refactoring work. Herein, I've exchanged; hard-coded contextual strings passed to `ExecutionTimer.time` with implict; contexts, drawing inspiration from scalatest. These contexts are now supplied after entering functions like `Compile` and; `Emit` instead of before (see `ExecuteContext.time`). By sprinking calls to ; `time` throughout the codebase after entering functions, we obtain a nice trace; of the timings with `sourcecode.Enclosing`, minus the previous verbosity. See [1] for more information about what pre-built macros are available. We can; always build our own later. See comments in [pull request id] for example output.; Note that `ExectionTimer.time` still accepts a string to support uses like; `Optimise` and `LoweringPass` where those contexts are provided already.; It is also exception-safe now. This change exposed many similarities between the implementations of query; execution across all three backends. I've stopped short of full unification; which is a greater work, I've instead simplified and moved duplicated result; encoding into the various backend api implementations. More interesting changes are to `ExecuteContext`, which now supports; - `time`, as discussed above; - `local`, a generalisation for temporarily overriding properties of an ; `ExecuteContext` (inspired by [2]). While I've long wanted this for testing,; we were doing some questionable things when reporting timings back to python,; for which locally overriding the `timer` of a `ctx` has been very useful.; We also follow this pattern for local regions. [1] https://github.com/com-lihaoyi/sourcecode; [2] https://hackage.haskell.org/package/mtl-2.3.1/docs/Control-Monad-Reader.html#v:local. ### Security Assessment. This change has no security impact as it's confined to refactoring of existing non-security-related code.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14683:891,expose,exposed,891,https://hail.is,https://github.com/hail-is/hail/pull/14683,4,"['Secur', 'expose', 'secur']","['Security', 'exposed', 'security', 'security-related']"
Security,"### Change Description. This is the vep85/grch37 analogue to #14713. ### Security Assessment. - [x] This change has a low security impact. Description of the security impact and necessary mitigations:; Rebuilds a docker image could introduce new vulnerabilities, but in all likelihood, fixes more/more critical vulnerabilities than it would introduce.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14714:73,Secur,Security,73,https://hail.is,https://github.com/hail-is/hail/pull/14714,3,"['Secur', 'secur']","['Security', 'security']"
Security,"### Change Description. `test_dataproc-*` is failing with:; ```; ERROR: (gcloud.dataproc.clusters.create) unrecognized arguments: --public-ip-address (did you mean '--no-address'?) ; ```; Went into the pushed `ci-utils` image, and verified that gcloud didn't have the `--public-ip-address` flag. Version 495 is current and has the flag. ### Security Assessment. - [x] This change has a low security impact",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14707:341,Secur,Security,341,https://hail.is,https://github.com/hail-is/hail/pull/14707,2,"['Secur', 'secur']","['Security', 'security']"
Security,### Description. Creation of a new hail developer account - . Github username - @grohli; Hail username - grohlice. Action items:; - Coordinate with appsec; - Create a new developer account [here](https://auth.hail.is/users); - Add a new authorized CI user [here](https://github.com/hail-is/hail/blob/main/ci/ci/constants.py). ### Security Impact. High. ### Security Impact Description. High because we are granting new administrative privileges. ### Appsec Signoff. - [x] Reviewed and approved,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14718:237,authoriz,authorized,237,https://hail.is,https://github.com/hail-is/hail/issues/14718,3,"['Secur', 'authoriz']","['Security', 'authorized']"
Security,### Description. Creation of a new hail developer account - . Github username - @kasittig kasittig; Hail username - ksittig. Action items:; - Existing developer: Coordinate with appsec; - Existing developer: Create a new developer account - see [here](https://github.com/hail-is/hail/blob/main/dev-docs/services/creating-a-developer-account.md#creating-a-developer-account); - New developer: Create a PR to add yourself as a new CI user (see [here](https://github.com/hail-is/hail/blob/main/ci/ci/constants.py)); - Existing developers: review and approve PR. ### Security Impact. High. ### Security Impact Description. High because a new user will be granted administrative privileges and developer access. ### Appsec Signoff. - [ ] Reviewed and approved,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14728:563,Secur,Security,563,https://hail.is,https://github.com/hail-is/hail/issues/14728,3,"['Secur', 'access']","['Security', 'access']"
Security,"### Description. In this pull request, I add a function to perform a Cochran-Mantel-Haenszel statistical test for association. This pull request closes #13481. ### Testing. I add unit tests. Since I have not used R before (the [associated GitHub issue](https://github.com/hail-is/hail/issues/13481) suggests using R to create test cases), I created the unit tests from examples that I found on the internet. I linked these sources in the code for the unit tests. I built the documentation locally and inspected it to confirm that it matches my expectations. I am having trouble testing the docstring examples locally. When I run `make -C hail doctest-query`, the tests error due to a checksum exception. ### Discussion. ~I have not added an example to the documentation that uses a matrix table yet. (This is an acceptance criteria in #13481.) I wanted to get some advice about the best way to do this. I think ideally, the example would have a binary phenotype, an allele to test for association, and some stratifying variable. I tried to search through the existing code to find suitable example matrix tables in the docstrings, but I didn't find anything promising. I would appreciate help here.~. Update: thanks to @patrick-schultz's recommendation, I have added an example using a matrix table.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14255:684,checksum,checksum,684,https://hail.is,https://github.com/hail-is/hail/pull/14255,1,['checksum'],['checksum']
Security,"### Description. Today our APIs are ""documented"" only through the list of endpoint handlers in implementation code ([example](https://github.com/hail-is/hail/blob/main/batch/batch/front_end/front_end.py#L239)). We can and should:; - Create OpenAPI documentation for our APIs (maybe per-service, maybe once in the gateway?); - Host swagger page/pages for exploring and testing out APIs . ### Security Impact. High. ### Security Impact Description. ""None"" for the creation of documentation, since we do not believe that documenting our APIs is inherently risky. ""High"" for hosting a new functional component on our web endpoints. Mitigating factor: swagger pages are loaded as static html with no need (or ability) to interact with other functional components, except through the same public APIs as are already accessible. ### Appsec Signoff. - [ ] Reviewed and approved",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14725:391,Secur,Security,391,https://hail.is,https://github.com/hail-is/hail/issues/14725,3,"['Secur', 'access']","['Security', 'accessible']"
Security,### Security Assessment. - [x] This change has no security impact,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14701:4,Secur,Security,4,https://hail.is,https://github.com/hail-is/hail/pull/14701,2,"['Secur', 'secur']","['Security', 'security']"
Security,"### Security Assessment. - [x] This change has no security impact. Description of the security impact and necessary mitigations:; This change doesn't change anything that we actually run, we just split the `make_pr_for` step of the release script into its own file.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14715:4,Secur,Security,4,https://hail.is,https://github.com/hail-is/hail/pull/14715,3,"['Secur', 'secur']","['Security', 'security']"
Security,### Security Assessment. This change has no security impact as it just moves code around. (Reviewers: please confirm the security impact before approving),MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14731:4,Secur,Security,4,https://hail.is,https://github.com/hail-is/hail/pull/14731,3,"['Secur', 'secur']","['Security', 'security']"
Security,"### What happened?. # Problem. A user submitted a Hail Batch batch which read from a bucket whose storage class was ""Archive"". This produced a large unexpected spend because Archive class objects cost 0.05 USD per GB whereas Standard class objects are free. # Solution. Hail Batch and Hail Query should collect the set of buckets which were used as reads, imports, input files, or temporary intermediates and assert that the bucket default storage class is the standard class / hot tier. In Google this is called the [Standard storage class](https://cloud.google.com/storage/docs/storage-classes#standard). In Azure, this is called the [Hot tier](https://learn.microsoft.com/en-us/azure/storage/blobs/access-tiers-overview?tabs=azure-portal). A user should be able to explicitly override this setting with an allowlist. The allowlist should be initialized using Hail's [standard configuration system](https://github.com/hail-is/hail/blob/48d7b5cfbf9a2231d72dd0a1a682da28422fde4b/hail/python/hailtop/config/user_config.py#L42). In Hail Query, this allowlist should be a setting on `hl.init`. In Hail Batch, it should be a setting on `ServiceBackend`. ### Version. 0.2.115. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13003:701,access,access-tiers-overview,701,https://hail.is,https://github.com/hail-is/hail/issues/13003,1,['access'],['access-tiers-overview']
Security,"### What happened?. #13131 Adds the ability for users to authenticate with the hail service using access tokens from their hail identity provider (GCP IAM or Azure AAD) instead of using tokens minted by the hail auth service. It does *not*, however, remove the old form of authentication. There are two actions that must be taken to fully remove the old authentication method:. 1. In #13131, the hail python client attempts to use the new `identity.json` cloud credentials for authentication, but falls back to the old `tokens.json` credentials if present.; 2. The `auth` server still supports the old `/api/v1alpha/login` endpoint. This is unused in the new authentication flow and should ultimately be removed. Removing these old code paths can be done in a two-step process, first with deprecation/warnings (the user need only run `hailctl auth login` to start using the new code paths) and then with removal of the old code paths. This issue is considered complete when the new code paths are removed. ### Version. 0.2.120. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13531:57,authenticat,authenticate,57,https://hail.is,https://github.com/hail-is/hail/issues/13531,6,"['access', 'authenticat']","['access', 'authenticate', 'authentication']"
Security,"### What happened?. > Laura Gauthier: I'm struggling with some DRAGEN data that probably doesn't quite meet the VCF spec. I got the import working, but once I go to split multi-allelics, one of the annotations seems to be the wrong length because I get an array index out of bounds exception. Is there anyway to get more info on the variant that's causing the problem? VCFtool validator found a bunch of issues with FORMAT annotations and I've turned them all into count=1 strings, but there must be something else.; > ...; > Tim Poterba (he/him): yeah, the answer is that this isn't a parse failure, it's a failure of the split_multi_hts method to support haploid sex chromosome calls; > Tim Poterba (he/him): the right plan is to support sex chromosomes The Right Way™ and update all of Hail to infer, track, and use appropriate ploidy but that's not at all what the system looks like right now. ### Version. 0.2.117. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13149:377,validat,validator,377,https://hail.is,https://github.com/hail-is/hail/issues/13149,1,['validat'],['validator']
Security,"### What happened?. After sorting our costs into ""cost of goods"", ""operating expenses"", and ""capital expenses"", I realized there are four ""operating expenses"" that are not tracked and reported with the other expenses. I regressed these costs against the core-hours to estimate the cost per core-hour. resource | intercept (USD) | cost (USD/core-hour); -- | -- | --; GCP Support Variable fee | 3.46403 +- 0.49155 | 0.00123 +- 0.00007; System logs costs SKU#1 | 13.09991 +- 3.13991 | 0.00093 +- 0.00039; System logs costs SKU#2 | 7.87838 +- 0.81695 | 0.00027 +- 0.00012; Job specifications | 5.41150 +- 0.36608 | 0.00025 +- 0.00005; Firewall policy | 0.51216 +- 0.03185 | 0.00012 +- 0.00000. To fully recover the operating expenses at our current revenue, we need an additional 0.005 USD per core-hour (which is 0.002 more than the sum of intercepts). This issue is complete after we add a new product:. resource | cost (USD/core-hour); -- | --; support-logs-specs-and-firewall-fees/1 | 0.005. ### Version. 0.2.120. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13526:631,Firewall,Firewall,631,https://hail.is,https://github.com/hail-is/hail/issues/13526,2,"['Firewall', 'firewall']","['Firewall', 'firewall-fees']"
Security,"### What happened?. Although it is not possible to avoid all cross-region access (and thus costs), there are some obvious preventable misuses. For example, the following pipeline should error:. ```; b = hb.Batch(regions=['us-east1']); x = b.read_input('gs://bucket-in-central1/'); b.new_job(f'cat {x}'); b.run(); ```; But the following pipeline should not error:; ```; b = hb.Batch(regions=['us-east1']); x = b.read_input('gs://bucket-in-central1/'); j = b.new_job(f'cat {x}'); j.regions(['us-central1']); ```; The following should error because the job *could* be in us-east1:; ```; b = hb.Batch(regions=['us-east1', 'us-central1']); x = b.read_input('gs://bucket-in-central1/'); b.new_job(f'cat {x}'); b.run(); ```; The following should error:; ```; b = hb.Batch(regions=['us-east1']) # remote_tmpdir is set in config file as a us-centra1 bucket; j = b.new_job(f'echo hi > {j.f}'); j2 = b.new_job(f'cat {j.f}'); b.run(); ```. ### Version. 0.2.119. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13232:74,access,access,74,https://hail.is,https://github.com/hail-is/hail/issues/13232,1,['access'],['access']
Security,"### What happened?. Batch should expose a job's cloud location to the job. In particular, now that multi-regional buckets charge egress, users needing large numbers of cores will need to manually duplicate their data in multiple regions and then choose the correct data source based on the region in which the job is scheduled. The implementor should consider other options but here is an initial proposal:. 1. Input and output files become dictionaries mapping from location to input/output. (If location is not found in list, job fails).; 2. Main container's file system and environment are populated with information about the location. Implementor should consider whether region, zone, or both should be exposed in GCP. Likewise for Azure regions and AZs. ### References; - https://hail.zulipchat.com/#narrow/stream/127527-team/topic/batch.20cluster/near/417261935 . ### Version. 0.2.127. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14189:33,expose,expose,33,https://hail.is,https://github.com/hail-is/hail/issues/14189,2,['expose'],"['expose', 'exposed']"
Security,"### What happened?. Currently, the `ServiceBackend`'s implementation of collect distributed array submits a job group full of worker jobs (1 per partition) and waits for the job group to complete before reading the results of the worker jobs. For small analyses this is fine, but when a query has tens of thousands of partitions it can take time to schedule and complete all of the worker jobs and reading back those results on the driver can become a bottleneck. Below is one possible solution to this problem:. #### Expose log for job completions in a job group. The Query Driver should attempt to read worker job results while the stage is running, but to do this it needs the Batch API to provide an append-only log of completed jobs in a job group that the Query Driver can consume instead of issuing O(jobs) job status requests during each stage. It may be that this is already possible with the current database schema, but can at worst be achieved by creating an indexed column on jobs that contain the spot they completed in in the job group. . Completion of this feature would require:; - Carefully evaluating the Batch data model to determine if there are any database changes necessary to construct an append-only log of job completions in a job group from the state of the database; - If changes are needed, design and implement a batch front end API endpoint to query the log; - (Separately) Add support for streaming the log in the Scala BatchClient and use it to read partition results before the job group completes. ### Version. 0.2.132. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14607:518,Expose,Expose,518,https://hail.is,https://github.com/hail-is/hail/issues/14607,1,['Expose'],['Expose']
Security,### What happened?. From Mike Wilson on hail zulip [here](https://hail.zulipchat.com/#narrow/stream/123010-Hail-Query-0.2E2-support/topic/hail.200.2E2.2E132.20streamconstraintsexception/near/453934859). > I'm running the new vds combiner on ~340 DRAGEN gVCFs and have hit this error; >; > ```; > Error summary: StreamConstraintsException: String length (20054016) exceeds the maximum length (20000000); > ```. ### Version. 0.2.132. ### Relevant log output. ```shell; Full java stack trace:. Java stack trace:; com.fasterxml.jackson.core.exc.StreamConstraintsException: String length (20054016) exceeds the maximum length (20000000); at com.fasterxml.jackson.core.StreamReadConstraints.validateStringLength(StreamReadConstraints.java:324); at com.fasterxml.jackson.core.util.ReadConstrainedTextBuffer.validateStringLength(ReadConstrainedTextBuffer.java:27); at com.fasterxml.jackson.core.util.TextBuffer.finishCurrentSegment(TextBuffer.java:939); at com.fasterxml.jackson.core.json.UTF8StreamJsonParser._finishString2(UTF8StreamJsonParser.java:2584); at com.fasterxml.jackson.core.json.UTF8StreamJsonParser._finishAndReturnString(UTF8StreamJsonParser.java:2560); at com.fasterxml.jackson.core.json.UTF8StreamJsonParser.getText(UTF8StreamJsonParser.java:335); at is.hail.relocated.org.json4s.jackson.JValueDeserializer._deserialize$1(JValueDeserializer.scala:26); at is.hail.relocated.org.json4s.jackson.JValueDeserializer._deserialize$1(JValueDeserializer.scala:48); at is.hail.relocated.org.json4s.jackson.JValueDeserializer.deserialize(JValueDeserializer.scala:57); at com.fasterxml.jackson.databind.deser.DefaultDeserializationContext.readRootValue(DefaultDeserializationContext.java:323); at com.fasterxml.jackson.databind.ObjectReader._bindAndClose(ObjectReader.java:2105); at com.fasterxml.jackson.databind.ObjectReader.readValue(ObjectReader.java:1481); at is.hail.relocated.org.json4s.jackson.JsonMethods.parse(JsonMethods.scala:35); at is.hail.relocated.org.json4s.jackson.JsonMethods.parse$(J,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14650:685,validat,validateStringLength,685,https://hail.is,https://github.com/hail-is/hail/issues/14650,2,['validat'],['validateStringLength']
Security,"### What happened?. Google will start to enforce egress fees on Broad multi-region buckets in March 2024. The remaining multi-regional buckets that the hail team pays for are:. ```; ""gs://artifacts.broad-ctsa.appspot.com/""; ""gs://broad/""; ""gs://broad-ctsa-usage-export/""; ""gs://cdv-hail-us/""; ""gs://danking/""; ""gs://dataproc-7f9e9d5e-03bd-4e95-bea1-fe0321239b35-us/""; ""gs://dataproc-temp-us-842871226259-x3fbdioe/""; ""gs://hail/""; ""gs://hail-1kg/""; ""gs://hail-benchmarks-2/""; ""gs://hail-ci/""; ""gs://hail-ci-0-1-dataproc-staging-bucket/""; ""gs://hail-ci-test/""; ""gs://hail-common/""; ""gs://hail-common-coldline/""; ""gs://hail-cseed/""; ""gs://hail-dataproc-deps/""; ""gs://hail-dataproc-images-scratch/""; ""gs://hail-datasets-eu/""; ""gs://hail-datasets-tmp/""; ""gs://hail-datasets-us/""; ""gs://hail-docker-build-0-1/""; ""gs://hail-ekelmins/""; ""gs://hail-eu-vep/""; ""gs://hail-internal/""; ""gs://hail-rnaseq/""; ""gs://hail-test/""; ""gs://hail-tutorial/""; ""gs://hail-us-vep/""; ""gs://hail-wgspd/""; ""gs://jbloom/""; ""gs://jigold/""; ""gs://johnc-seqr-temp-bucket/""; ```. Obtained by running: . ```bash; gcloud storage ls --project broad-ctsa -b -j | jq '.[] | select(.metadata.locationType==""multi-region"") | .url'; ```. These buckets should either be deleted (some are no longer used) or moved to an appropriate region. The appspot bucket is GCR and has been deprecated for months now. It should be unused and can be deleted (but worth checking if it has been accessed recently first). US-based user-facing buckets should probably be moved to `us-central1`. This issue requires no PR and can be closed when no buckets in the `broad-ctsa` and `hail-vdc` projects are multi-regional. ### Version. 0.2.120. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13507:1436,access,accessed,1436,https://hail.is,https://github.com/hail-is/hail/issues/13507,1,['access'],['accessed']
Security,"### What happened?. Hail's google/azure credential classes do not require the caller to specify scopes when requesting access tokens, and thus default to a [very wide set of scopes](https://github.com/hail-is/hail/blob/91f5a0bfc30927014b60b11a353a4d95db009427/hail/python/hailtop/aiocloud/aiogoogle/credentials.py#L140), making those access tokens excessively powerful. An access token does not need to have the `https://www.googleapis.com/auth/appengine.admin` scope to read a blob from GCS. This poses an unnecessary risk if such a token were leaked. These classes should instead require that scopes be specified when requesting an access token, and call sights should specify the minimum set of scopes necessary to perform their function. ### Version. 0.2.120. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13530:119,access,access,119,https://hail.is,https://github.com/hail-is/hail/issues/13530,4,['access'],['access']
Security,### What happened?. I cannot access the hail website.; ![Screenshot 2024-07-16 at 8 03 18 AM](https://github.com/user-attachments/assets/d576c595-d9fd-46fe-b982-3ee58e212ee1). ### Version. 0.2.57. ### Relevant log output. _No response_,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14616:29,access,access,29,https://hail.is,https://github.com/hail-is/hail/issues/14616,1,['access'],['access']
Security,"### What happened?. In #14675 I replaced `END` with `LEN` in VDS. In doing so, I made sure that both fields were present so as to not break people's existing pipelines. I added a hidden `_drop_end` flag to `read_vds` in order to be able to (mostly in the combiner) not have the `END` field present. This lead to a strange code pattern:. https://github.com/chrisvittal/hail/blob/f39364c177e0b009589826b2c6b3cd36c3ec359d/hail/python/hail/vds/variant_dataset.py#L44-L46. When running the final VDS+VDS merge in [`test_combiner_run`](https://github.com/chrisvittal/hail/blob/f39364c177e0b009589826b2c6b3cd36c3ec359d/hail/python/test/hail/vds/test_combiner.py#L178-L222) on the local backend, this failed with a memory error (in debug mode):. ```; RuntimeException: invalid memory access: 140a68008/00000001: not in 140a58008/00010000; ```. Applying this patch fixed `test_combiner_run`:; ```patch; diff --git a/hail/python/hail/vds/variant_dataset.py b/hail/python/hail/vds/variant_dataset.py; index 0f851e7364..01be83a982 100644; --- a/hail/python/hail/vds/variant_dataset.py; +++ b/hail/python/hail/vds/variant_dataset.py; @@ -41,9 +41,14 @@ def read_vds(; reference_data = hl.read_matrix_table(VariantDataset._reference_path(path), _intervals=intervals); variant_data = hl.read_matrix_table(VariantDataset._variants_path(path), _intervals=intervals). - reference_data = VariantDataset._add_len_end(reference_data); + # if LEN is missing, add it, _add_len is a no-op if LEN is already present; + reference_data = VariantDataset._add_len(reference_data); if _drop_end:; - reference_data = reference_data.drop('END'); + if 'END' in reference_data.entry:; + reference_data = reference_data.drop('END'); + else: # if END is missing, add it, _add_end is a no-op if END is already present; + reference_data = VariantDataset._add_end(reference_data); +; vds = VariantDataset(reference_data, variant_data); if VariantDataset.ref_block_max_length_field not in vds.reference_data.globals:; fs = hl.current_backend",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14705:776,access,access,776,https://hail.is,https://github.com/hail-is/hail/issues/14705,1,['access'],['access']
Security,"### What happened?. Public access buckets typically grant; ```yaml; - members:; - allUsers; role: roles/storage.objectViewer; ```; which permits; ```; resourcemanager.projects.get; resourcemanager.projects.list; storage.managedFolders.get; storage.managedFolders.list; storage.objects.get; storage.objects.list; ```; Notably excluding; ```; storage.buckets.get; ```; Which is necessary for getting metadata like storage class about a bucket. Reported here: https://hail.zulipchat.com/#narrow/stream/123010-Hail-Query-0.2E2-support/topic/No.20storage.2Ebuckets.2Eget.20access.20to.20gs.3A.2F.2Fhail-common. ### Version. 0.2.127. ### Relevant log output. Example code:; ```; rg37.add_sequence(; ""gs://hail-common/references/human_g1k_v37.fasta.gz"",; ""gs://hail-common/references/human_g1k_v37.fasta.fai""; ); ```. ```; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.2.127-bb535cd096c5; LOGGING: writing to /Users/mkanai/Dropbox/Workspace/github.com/mkanai/immune_v2f/python/hail-20240214-1046-0.2.127-bb535cd096c5.log; Traceback (most recent call last):; File ""/Users/mkanai/Dropbox/Workspace/github.com/mkanai/immune_v2f/python/annotate_base_editing_variants.py"", line 21, in <module>; rg37.add_sequence(; File ""<decorator-gen-34>"", line 2, in add_sequence; File ""/Users/mkanai/.anyenv/envs/pyenv/versions/anaconda3-2022.05/lib/python3.9/site-packages/hail/typecheck/check.py"", line 584, in wrapper; return __original_func(*args_, **kwargs_); File ""/Users/mkanai/.anyenv/envs/pyenv/versions/anaconda3-2022.05/lib/python3.9/site-packages/hail/genetics/reference_genome.py"", line 390, in add_sequence; Env.backend().add_sequence(self.name, fasta_file, index_file); File ""/Users/mkanai/.anyenv/envs/pyenv/versions/anaconda3-2022.05/lib/python3.9/site-packages/hail/backend/service_backend.py"", line 548, in add_sequence; self.validate_file(blob); File ""/Users/mkanai/.anyenv/envs/pyenv/versions/anaconda3-2022.05/lib/python3.9/site-packages/hail/backend/service_backen",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14291:27,access,access,27,https://hail.is,https://github.com/hail-is/hail/issues/14291,1,['access'],['access']
Security,### What happened?. Reported here: https://discuss.hail.is/t/how-to-capture-summarize-outputs/3348/2. Maybe make it easier to return the `Summary` object from `ht.x.summarize()` so you can access its `summ_fields`?. ### Version. 0.2.114. ### Relevant log output. _No response_,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12943:189,access,access,189,https://hail.is,https://github.com/hail-is/hail/issues/12943,1,['access'],['access']
Security,"### What happened?. See #13489 for context. We want to use terraform to keep track of artifact registry cleanup policies once it is available in Terraform. Relevant links:; https://github.com/hashicorp/terraform-provider-google-beta/commit/bc4aa512356891f78415d5f309bfe47b0697ac11; https://github.com/hashicorp/terraform-provider-google/issues/13824. It's not in 4.79.0 (see [what was added since then](https://github.com/hashicorp/terraform-provider-google-beta/compare/v4.79.0...main)). Releases appear to happen ~once a week, so we should be able to import into terraform in September. ### Version. 0.2.120. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13504:192,hash,hashicorp,192,https://hail.is,https://github.com/hail-is/hail/issues/13504,3,['hash'],['hashicorp']
Security,"### What happened?. See [Batch Metadata Server RFC](https://github.com/hail-is/hail-rfcs/blob/main/rfc/0012-keyless-job-auth.rst) for background. The objective of this issue is to fully remove GSA key files from Batch job filesystems, preventing possible exfiltration of long-lived credentials. Each remaining task should get its own issue if there isn't already one. Breakdown of tasks:. - [X] Implement a Batch metadata server and expose it in GCP `DockerJob`s (#14019); - [ ] Add metadata server support for `JVMJob`s aka Query-on-Batch in GCP (#14487); - [ ] Add metadata server support in Azure; - [ ] Deprecate and remove support for key files in `DockerJob`s; - [ ] Deprecate and remove support for key files in `JVMJob`s. This requires dropping support for old versions of hail that depend on the key file (up to and including at least 0.2.130). These steps get us past the security milestone of not exposing GSA key files to jobs and risking exfiltration. We might be able to go even further and get rid of key files entirely, which would reduce our operational burden of securing and rotating them.; - [ ] In GCP, use Service Account Impersonation to have the Batch Worker identity impersonate user GSAs, allowing it to create metadata server access tokens without the key files themselves; - [ ] In Azure, investigate if something like the above is even possible. At time of writing, it does not appear that there is an alternative other than storing credentials or adding users to the VM's metadata server. It is unclear whether this can be done dynamically and with what frequency and feels like not their intended use case. ### Version. 0.2.130. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14486:433,expose,expose,433,https://hail.is,https://github.com/hail-is/hail/issues/14486,4,"['access', 'expose', 'secur']","['access', 'expose', 'securing', 'security']"
Security,"### What happened?. Semantic hash assumes the params.files is a list of concrete file paths but it is a list of file paths with glob expressions. Consider the following example. Part of this ticket must also determine why this was not caught by `test_glob`.; ```; (base) dking@wm28c-761 hail % gsutil cp ./src/test/resources/ldprune2.vcf gs://danking/chr1.vcf; Copying file://./src/test/resources/ldprune2.vcf [Content-Type=text/x-vcard]...; / [1 files][ 11.5 KiB/ 11.5 KiB] ; Operation completed over 1 objects/11.5 KiB. ; (base) dking@wm28c-761 hail % gsutil cp ./src/test/resources/ldprune2.vcf gs://danking/chr2.vcf; Copying file://./src/test/resources/ldprune2.vcf [Content-Type=text/x-vcard]...; / [1 files][ 11.5 KiB/ 11.5 KiB] ; Operation completed over 1 objects/11.5 KiB. ; (base) dking@wm28c-761 hail % ipython ; Python 3.10.9 (main, Jan 11 2023, 09:18:18) [Clang 14.0.6 ]; Type 'copyright', 'credits' or 'license' for more information; IPython 8.16.1 -- An enhanced Interactive Python. Type '?' for help. In [1]: import hail as hl; ...: hl.import_vcf('gs://danking/chr*.vcf').count(); Initializing Hail with default parameters...; /Users/dking/miniconda3/lib/python3.10/site-packages/hailtop/aiocloud/aiogoogle/user_config.py:29: UserWarning: You have specified the GCS requester pays configuration in both your spark-defaults.conf (/Users/dking/miniconda3/lib/python3.10/site-packages/pyspark/conf/spark-defaults.conf) and either an explicit argument or through `hailctl config`. For GCS requester pays configuration, Hail first checks explicit arguments, then `hailctl config`, then spark-defaults.conf.; warnings.warn(; SLF4J: No SLF4J providers were found.; SLF4J: Defaulting to no-operation (NOP) logger implementation; SLF4J: See https://www.slf4j.org/codes.html#noProviders for further details.; SLF4J: Class path contains SLF4J bindings targeting slf4j-api versions 1.7.x or earlier.; SLF4J: Ignoring binding found at [jar:file:/Users/dking/miniconda3/lib/python3.10/site-packages/",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13915:29,hash,hash,29,https://hail.is,https://github.com/hail-is/hail/issues/13915,1,['hash'],['hash']
Security,"### What happened?. Since we guarantee a job will run at least once, there are two issues that can happen:. 1. A user can write a pipeline in which two jobs race to write the same file, e.g.; ```; j = b.new_job(); j.command('echo hello > {j.out}'); j.write_output(j.out, ""gs://bucket/final-output""); ```; 2. Or, a clever user can avoid this race with some randomness:; ```; j = b.new_job(); j.command('echo hello gsutil cp - gs://bucket/final-output-$RANDOM'); ```. The former is a really common pattern and a bit of a footgun! The latter is rare (I don't know anyone who does it) and hard to work with: how would you know the output file of the *successful* attempt?. Hail should provide some mechanism for a user to get the list of successful attempts and their outputs. One simple option is to include some kind of seeded randomness which the user can access and to return either the seed or all the draws of the successful attempt for each job in `/jobs` or for the one job in `/job/{job_id}`. For example, consider:. ```; j = b.new_job(); j.command('echo hello gsutil cp - gs://bucket/final-output-$(/hail-random-str)'); ```. Where `/hail-random-str` is a binary we mount into the container that randomly generates numbers seeded by `(batch id, job id, attempt id)`. Hail should use the same randomness to ensure that `write_output` is reliable. We might also want a way to automatically remove the output files of the non-successful (e.g. preempted) attempts. ### Version. 0.2.120. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13502:855,access,access,855,https://hail.is,https://github.com/hail-is/hail/issues/13502,1,['access'],['access']
Security,"### What happened?. The Batch UI should only show the most recent 50 batches that the user has submitted, but I suspect there is a flaw in the search query that is doing a full scan on one of the main tables. Searching for `user = ci` in the Batch UI nearly times out. First thing I would do here is get the SQL query that is run for `user = ci` (can hopefully do this in `ipython`) and run an `EXPLAIN` against the database. That should hopefully expose a `WHERE` condition that could be re-written to use an existing index or at worst add an index for. ### Version. 0.2.131. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14599:448,expose,expose,448,https://hail.is,https://github.com/hail-is/hail/issues/14599,1,['expose'],['expose']
Security,"### What happened?. The infrastructure necessary to run a Hail Batch deployment (network, buckets, DB, Kubernetes cluster) are managed through Terraform in `infra/gcp` and `infra/azure`. In order to migrate terraform resources, the terraform module need to be given input variables specific to our deployment provided through a `global.tfvars` file. Since this file contains secrets, in GCP we encrypt the file with [SOPS](https://github.com/getsops/sops) and check it into the repo so that any developer with the credentials to our deployment can run the terraform. This is not the case in Azure, so if a developer wants to run the Azure terraform they have to obtain the `global.tfvars` from myself. We should use the same strategy for communicating this file as we do in GCP. ### Version. 0.2.129. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14457:394,encrypt,encrypt,394,https://hail.is,https://github.com/hail-is/hail/issues/14457,1,['encrypt'],['encrypt']
Security,"### What happened?. Try running a job with `_machine_type: 'n1-highmem-64'`. This is necessary to get enough memory for some larger jobs (> ~200GB). Startup on the batch worker fails because the job is calculating how many theoretical network namespaces it could support (4 per CPU, 64 CPUS, plus some for JVMs), but not considering that the IPv4 schema puts a hard limit of 255 on namespaces if only one subnet value is changing each time. ### Version. Live 7/30/24. ### Relevant log output. _No response_. ### Security considerations:. Low risk of impacting security. High CPU machine types are not materially different from others with respect to security considerations, and the bug is a simple logic error.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14644:512,Secur,Security,512,https://hail.is,https://github.com/hail-is/hail/issues/14644,3,"['Secur', 'secur']","['Security', 'security']"
Security,"### What happened?. Try writing to a bucket to which your service account has read-only access:; ```; hl.utils.range_table(5,n_partitions=5).write('gs://neale-bge/foo.ht'); ```. https://batch.hail.is/batches/8042383. The client gets an error like this:; ```; Java stack trace:; is.hail.relocated.com.google.cloud.storage.StorageException: 404 Not Found; GET https://storage.googleapis.com/download/storage/v1/b/1-day/o/parallelizeAndComputeWithIndex%2FO3mcL5QoyfBBMz0eSi7uIjGQkV3FuD5vCON_8i4r0ss=%2Fresult.0?alt=media; No such object: 1-day/parallelizeAndComputeWithIndex/O3mcL5QoyfBBMz0eSi7uIjGQkV3FuD5vCON_8i4r0ss=/result.0; 	at is.hail.relocated.com.google.cloud.storage.StorageException.translate(StorageException.java:165); 	at is.hail.relocated.com.google.cloud.storage.spi.v1.HttpStorageRpc.translate(HttpStorageRpc.java:298); 	at is.hail.relocated.com.google.cloud.storage.spi.v1.HttpStorageRpc.load(HttpStorageRpc.java:729); 	at is.hail.relocated.com.google.cloud.storage.StorageImpl.lambda$readAllBytes$20(StorageImpl.java:610); 	at com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:103); 	at is.hail.relocated.com.google.cloud.RetryHelper.run(RetryHelper.java:76); 	at is.hail.relocated.com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:50); 	at is.hail.relocated.com.google.cloud.storage.Retrying.run(Retrying.java:65); 	at is.hail.relocated.com.google.cloud.storage.StorageImpl.run(StorageImpl.java:1515); 	at is.hail.relocated.com.google.cloud.storage.StorageImpl.readAllBytes(StorageImpl.java:610); 	at is.hail.relocated.com.google.cloud.storage.StorageImpl.readAllBytes(StorageImpl.java:599); 	at is.hail.io.fs.GoogleStorageFS.$anonfun$readNoCompression$1(GoogleStorageFS.scala:280); 	at is.hail.services.package$.retryTransientErrors(package.scala:182); 	at is.hail.io.fs.GoogleStorageFS.readNoCompression(GoogleStorageFS.scala:278); 	at is.hail.io.fs.RouterFS.readNoCompression(RouterFS.scala:25); 	at is.hail.backend.service.ServiceBac",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13697:88,access,access,88,https://hail.is,https://github.com/hail-is/hail/issues/13697,1,['access'],['access']
Security,"### What happened?. Using Google Dataproc Apache Spark cluster. We're getting access to the source paths now. ```python3. import hail as hl; hl.init(default_reference='GRCh38'); marazita_mt_path = # ...; hapmap_snps_path = # ...; marazita_mt = hl.read_matrix_table(marazita_mt_path, _n_partitions=500); hapmap_snps = (hl.import_table(hapmap_snps_path, ; impute = True, ; no_header=True)); hapmap_snps = hapmap_snps.annotate(interval = hl.locus_interval(hapmap_snps.f0,; hapmap_snps.f1,; hapmap_snps.f2)); hapmap_snps = hapmap_snps.annotate(locus = hapmap_snps.f0 + ':' + hl.str(hapmap_snps.f1)); hapmap_snps = hapmap_snps.annotate(locus = hl.locus(hapmap_snps.f0, hapmap_snps.f1)); hapmap_snps = hapmap_snps.key_by(hapmap_snps.locus); hapmap_snps.count(); marazita_mt.count(); marazita_hapmap = marazita_mt.filter_rows(hl.is_defined(hapmap_snps[marazita_mt.locus])); # Here is where the number of variants changed prior to writing out the hapmap keyed mt; # other numbers I got: 1498507, 1498499, 1498506; # I am still getting more SNPs than prior to intersection; # I would expect it to be less than the 1437453 in hapmap; marazita_hapmap.count(); ```. ### Version. 0.2.122-be9d88a80695. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13689:78,access,access,78,https://hail.is,https://github.com/hail-is/hail/issues/13689,1,['access'],['access']
Security,"### What happened?. When using logistic regression, the null model tells me about the relationship between my covariates and the phenotype(s). In particular, if my covariates perfectly predict my phenotype, the model will fail to converge on every row. Investigating this situation demands access to the null model.; ```; import hail as hl; mt = hl.utils.range_matrix_table(3,3); mt = mt.annotate_entries(prod = mt.row_idx * mt.col_idx); hl.logistic_regression_rows('wald', y=[hl.bool(mt.col_idx)], x=mt.prod, covariates=[1.0]).describe(); ```. When using the Query-on-Spark backend, I receive no access to the null model parameters:; ```; ----------------------------------------; Global fields:; None; ----------------------------------------; Row fields:; 'row_idx': int32 ; 'logistic_regression': array<struct {; beta: float64, ; standard_error: float64, ; z_stat: float64, ; p_value: float64, ; fit: struct {; n_iterations: int32, ; converged: bool, ; exploded: bool; }; }> ; ----------------------------------------; Key: ['row_idx']; ----------------------------------------; ```. In contrast, the Query-on-Batch backend exposes this information:; ```; Global fields:; 'null_fits': array<struct {; b: ndarray<float64, 1>, ; score: ndarray<float64, 1>, ; fisher: ndarray<float64, 2>, ; mu: ndarray<float64, 1>, ; n_iterations: int32, ; log_lkhd: float64, ; converged: bool, ; exploded: bool; }> ; ```. The Query-on-Spark backend should expose the same information for the benefit of the user. ### Version. 0.2.124. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13789:290,access,access,290,https://hail.is,https://github.com/hail-is/hail/issues/13789,4,"['access', 'expose']","['access', 'expose', 'exposes']"
Security,### What happened?. [Open ID Connect](https://auth0.com/docs/authenticate/protocols/openid-connect-protocol) is a standard that allows you to basically exchange a proof of identity from identity provider X for an authorized token at identity provider Y. We should support using GCP credentials + OIDC to copy files to and from AWS and Azure. We should then remove the AWS and Azure keys from our GCP deployment that are used to run inter-cloud copy tests. ### Version. 0.2.122. ### Relevant log output. _No response_,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13613:61,authenticat,authenticate,61,https://hail.is,https://github.com/hail-is/hail/issues/13613,2,"['authenticat', 'authoriz']","['authenticate', 'authorized']"
Security,"### What happened?. [SAIGE](https://github.com/weizhouUMICH/SAIGE) and its competitor [REGENIE](https://rgcgithub.github.io/regenie/) are the standard bearers for modern GWAS. Hail should expose SAIGE within the Hail Query language. The interface should roughly match `hl.linear_regression_rows`. A Batch pipeline would serve the needs of Broadies (and, indeed, such a pipeline already exists) but has two downsides:; 1. There is substantial I/O involved in exporting the data from Hail-native formats to SAIGE-compatible formats.; 2. Non-Broadies cannot use this pipeline. Query language support for SAIGE would transform the accessibility of SAIGE by making it usable at scale by anyone with access to Hail, which is basically anyone with a large dataset (e.g. [DNANexus](https://med.stanford.edu/gbsc/projects/vapahcs.html), [AoU RWB](https://support.researchallofus.org/hc/en-us/articles/6090679838100-How-to-Work-with-All-of-Us-Genomic-Data-Hail-Plink-), [MVP](https://med.stanford.edu/gbsc/projects/vapahcs.html), [FinnGen](https://www.medrxiv.org/content/10.1101/2022.03.03.22271360v1.full)). There are two options:; 1. Determine and implement the linear algebraic primitives necessary for SAIGE.; 2. Compile and link directly against SAIGE. Expose these functions, via JNI, to the Hail Query language. ### Version. 0.2.120. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13442:188,expose,expose,188,https://hail.is,https://github.com/hail-is/hail/issues/13442,4,"['Expose', 'access', 'expose']","['Expose', 'access', 'accessibility', 'expose']"
Security,"### What happened?. [reporter's note: IIRC, exit code 137 indicates that the ""container"" in which the worker JVM was executing exceeded memory limits. It seems likely that whole stage codegen has either (1) changed memory management in a way that uses more memory or (2) is newly lowering code that exposes a latent issue in memory management that uses too much (or leaks) memory.]. Reported by Ben Weisburd and Julia Goodrich. [Ben is] running the first step of readviz for gnomAD v4 and we are hitting a 137 error on a partition that includes a site that has 27374 alleles. His code is [here](https://github.com/broadinstitute/gnomad-readviz/blob/step1_optimizations/step1__select_samples.py). I was testing his code out on just that failing partition (just added mt = vds.variant_data._filter_partitions([41229])) and I was able to recreate the error using Hail 0.2.119 (this is what Ben was using when he hit the error on the full dataset). However, the first time I tried to recreate the error I was accidentally using a different version of Hail and it ran with no memory error. It seems that 0.2.117 runs without error, but 0.2.118 and 0.2.119 both hit the 137 error. I am currently rerunning these tests so I can get logs:. Test with Hail 0.2.118:. Cluster:; ```; hailctl dataproc start readviz-118 \; --requester-pays-allow-all \; --packages=""git+https://github.com/broadinstitute/gnomad_methods.git@main"",""git+https://github.com/broadinstitute/gnomad_qc.git@main"" \; --autoscaling-policy=max-20 \; --master-machine-type n1-highmem-16 \; --no-off-heap-memory \; --worker-machine-type n1-highmem-8 \; --max-idle 560m \; --labels gnomad_release=gnomad_v4,gnomad_v4_testing=readviz_test_118; ```; Command:; ```; hailctl dataproc submit readviz-118 /Users/jgoodric/PycharmProjects/gnomad-readviz/step1__select_samples.py --sample-metadata-tsv gs://gnomad-readviz/v4.0/gnomad.exomes.v4.0.metadata.tsv.gz --output-ht-path gs://gnomad-tmp/julia/readviz/gnomad.exomes.v4.0.readviz_crams.part_41229.ha",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13248:299,expose,exposes,299,https://hail.is,https://github.com/hail-is/hail/issues/13248,1,['expose'],['exposes']
Security,"### What happened?. `hail-0.2.129-py3-none-any.whl` bundled a version of `hailtop/hailctl/deploy.yaml` that was intended for internal testing only. This file provides configuration variables for `hailctl`. The file in [0.2.129](https://github.com/hail-is/hail/releases/tag/0.2.129) pointed to cloud resources in `gs://hail-30-day/` that cause commands like `hailctl dataproc start` to fail due to one of the following:; - the user does not have access to `gs://hail-30-day`, or; - the resources have been deleted according to the bucket's 30-day lifecycle policy. ### Version. 0.2.129. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14452:445,access,access,445,https://hail.is,https://github.com/hail-is/hail/issues/14452,1,['access'],['access']
Security,"### What happened?. `hailctl dataproc start` fails with an error message like the one below because [in Dataproc 2.2](https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/network#:~:text=Internal%20addresses%20only%20(no%2Daddress)%20is%20set%20by%20default%20when%20creating%20a%20Dataproc%202.2%20image%20version%20cluster.%20You%20can%20use%20the%20gcloud%20dataproc%20clusters%20create%20%2D%2Dpublic%2Dip%2Daddress%20flag%20to%20enable%20public%20IP%20addresses.), clusters are created without public internet access by default. A workaround is to pass the `--public-ip-address` flag to the command. Error message:. ```python; pip packages are ['setuptools', 'mkl<2020', 'lxml<5', 'https://github.com/hail-is/jgscm/archive/v0.1.13+hail.zip', 'ipykernel==6.22.0', 'ipywidgets==8.0.6', 'jupyter-console==6.6.3', 'nbconvert==7.3.1', 'notebook==6.5.6', 'qtconsole==5.4.2', 'aiodns==2.0.0', 'aiohttp==3.9.5', 'aiosignal==1.3.1', 'async-timeout==4.0.3', 'attrs==23.2.0', 'avro==1.11.3', 'azure-common==1.1.28', 'azure-core==1.30.2', 'azure-identity==1.17.1', 'azure-mgmt-core==1.4.0', 'azure-mgmt-storage==20.1.0', 'azure-storage-blob==12.20.0', 'bokeh==3.3.4', 'boto3==1.34.138', 'botocore==1.34.138', 'cachetools==5.3.3', 'certifi==2024.6.2', 'cffi==1.16.0', 'charset-normalizer==3.3.2', 'click==8.1.7', 'commonmark==0.9.1', 'contourpy==1.2.1', 'cryptography==42.0.8', 'decorator==4.4.2', 'deprecated==1.2.14', 'dill==0.3.8', 'frozenlist==1.4.1', 'google-auth==2.31.0', 'google-auth-oauthlib==0.8.0', 'humanize==1.1.0', 'idna==3.7', 'isodate==0.6.1', 'janus==1.0.0', 'jinja2==3.1.4', 'jmespath==1.0.1', 'jproperties==2.1.1', 'markupsafe==2.1.5', 'msal==1.29.0', 'msal-extensions==1.2.0', 'msrest==0.7.1', 'multidict==6.0.5', 'nest-asyncio==1.6.0', 'numpy==1.26.4', 'oauthlib==3.2.2', 'orjson==3.10.6', 'packaging==24.1', 'pandas==2.2.2', 'parsimonious==0.10.0', 'pillow==10.4.0', 'plotly==5.22.0', 'portalocker==2.10.0', 'protobuf==3.20.2', 'py4j==0.10.9.7', 'pyasn1==0.6.0', 'pyasn1-",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14652:531,access,access,531,https://hail.is,https://github.com/hail-is/hail/issues/14652,1,['access'],['access']
Security,"### What happened?. `hl.maximal_independent_set` should return the same independent set regardless of the ordering of the input table. gnomAD team reports that the returned set can differ depending on whether or not the input table had been written or came directly from PC-Relate. I have yet to create a simple reproducible example. Permuting the entries in this array does not change the output. I always get 'a' and 'b'. I suspect this is because what really matters is the order in which we traverse the entries of the multi map which depends on the hash of the nodes. I think a durable fix might be to eliminate the MultiMap, insert all the nodes into the binary heap, then increment priority for each edge detected. This will perform more reflows of the heap, but eliminates the non-determinism of MultiMap iteration order. ```; import hail as hl; ht = hl.Table.parallelize([; hl.Struct(i=hl.Struct(s=x[0]), j=hl.Struct(s=x[1])); for x in [('c', 'a'), ('a', 'b'), ('b', 'c'), ]; ]); hl.maximal_independent_set(ht.i, ht.j, False).collect(); ```. ### Version. 0.2.122. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13635:554,hash,hash,554,https://hail.is,https://github.com/hail-is/hail/issues/13635,1,['hash'],['hash']
Security,### What happened?. https://discuss.hail.is/t/matrixtable-filter-rows-produces-error-for-data-on-secure-lustre/3344/2. Seems like we drop the file:// scheme at some point when generating code that uses PartitionNativeIntervalReader. ### Version. ????. ### Relevant log output. _No response_,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13998:97,secur,secure-lustre,97,https://hail.is,https://github.com/hail-is/hail/issues/13998,1,['secur'],['secure-lustre']
Security,"### What happened?. ~~I have a PR that proposes something roughly along these lines: https://github.com/hail-is/hail/pull/13057/files It has some problems:~~; ~~1. It should use a cron job.~~; ~~2. The last time I ran this code, I'm pretty sure I deleted things I shouldn't have. We should audit the `find-expired-images.py` code again.~~. We should probably just use https://cloud.google.com/artifact-registry/docs/repositories/cleanup-policy. ### Version. 0.2.120. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13441:290,audit,audit,290,https://hail.is,https://github.com/hail-is/hail/issues/13441,1,['audit'],['audit']
Security,"#133</a>](<a href=""https://github-redirect.dependabot.com/brettcannon/gidgethub/issues/133"">brettcannon/gidgethub#133</a>).</li>; <li>Make the minimum version of PyJWT be v2.0.0.</li>; </ul>; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/brettcannon/gidgethub/blob/main/docs/changelog.rst"">gidgethub's changelog</a>.</em></p>; <blockquote>; <h2>5.2.1</h2>; <ul>; <li>; <p>Fix cgi and importlib_resources deprecations.; (<code>PR [#185](https://github.com/brettcannon/gidgethub/issues/185) &lt;https://github.com/brettcannon/gidgethub/pull/185&gt;_</code>)</p>; </li>; <li>; <p>Add support for Python 3.11 and drop EOL Python 3.6; (<code>PR [#184](https://github.com/brettcannon/gidgethub/issues/184) &lt;https://github.com/brettcannon/gidgethub/pull/184&gt;_</code>)</p>; </li>; </ul>; <h2>5.2.0</h2>; <ul>; <li>Make the minimum version of PyJWT be v2.4.0.</li>; </ul>; <h2>5.1.0</h2>; <ul>; <li>; <p>Use <code>X-Hub-Signature-256</code> header for webhook validation when available.; (<code>PR [#160](https://github.com/brettcannon/gidgethub/issues/160) &lt;https://github.com/brettcannon/gidgethub/pull/160&gt;</code>_).</p>; </li>; <li>; <p>The documentation is now built using Sphinx v&gt;= 4.0.0.; (<code>Issue [#143](https://github.com/brettcannon/gidgethub/issues/143) &lt;https://github.com/brettcannon/gidgethub/issues/143&gt;</code>_)</p>; </li>; <li>; <p>:meth:<code>gidgethub.abc.GitHubAPI.getiter</code> now accepts <code>iterable_key</code> parameter; in order to support the Checks API.; (<code>Issue [#164](https://github.com/brettcannon/gidgethub/issues/164) &lt;https://github.com/brettcannon/gidgethub/issues/164&gt;</code>_)</p>; </li>; <li>; <p>Accept HTTP 202 ACCEPTED as successful.; (<code>PR [#174](https://github.com/brettcannon/gidgethub/issues/174) &lt;https://github.com/brettcannon/gidgethub/pull/174&gt;</code>_)</p>; </li>; </ul>; <h2>5.0.1</h2>; <ul>; <li>Drop the <code>machine-man-preview</code> ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12328:4937,validat,validation,4937,https://hail.is,https://github.com/hail-is/hail/pull/12328,1,['validat'],['validation']
Security,"#7246</a>; [radarhere]</p>; </li>; <li>; <p>Added ImageFont.MAX_STRING_LENGTH <a href=""https://redirect.github.com/python-pillow/Pillow/issues/7244"">#7244</a>; [radarhere, hugovk]</p>; </li>; <li>; <p>Fix Windows build with pyproject.toml <a href=""https://redirect.github.com/python-pillow/Pillow/issues/7230"">#7230</a>; [hugovk, nulano, radarhere]</p>; </li>; <li>; <p>Do not close provided file handles with libtiff <a href=""https://redirect.github.com/python-pillow/Pillow/issues/7199"">#7199</a>; [radarhere]</p>; </li>; <li>; <p>Convert to HSV if mode is HSV in getcolor() <a href=""https://redirect.github.com/python-pillow/Pillow/issues/7226"">#7226</a>; [radarhere]</p>; </li>; <li>; <p>Added alpha_only argument to getbbox() <a href=""https://redirect.github.com/python-pillow/Pillow/issues/7123"">#7123</a>; [radarhere. hugovk]</p>; </li>; <li>; <p>Prioritise speed in <em>repr_png</em> <a href=""https://redirect.github.com/python-pillow/Pillow/issues/7242"">#7242</a>; [radarhere]</p>; </li>; <li>; <p>Do not use CFFI access by default on PyPy <a href=""https://redirect.github.com/python-pillow/Pillow/issues/7236"">#7236</a>; [radarhere]</p>; </li>; <li>; <p>Limit size even if one dimension is zero in decompression bomb check <a href=""https://redirect.github.com/python-pillow/Pillow/issues/7235"">#7235</a>; [radarhere]</p>; </li>; <li>; <p>Use --config-settings instead of deprecated --global-option <a href=""https://redirect.github.com/python-pillow/Pillow/issues/7171"">#7171</a>; [radarhere]</p>; </li>; <li>; <p>Better C integer definitions <a href=""https://redirect.github.com/python-pillow/Pillow/issues/6645"">#6645</a>; [Yay295, hugovk]</p>; </li>; <li>; <p>Fixed finding dependencies on Cygwin <a href=""https://redirect.github.com/python-pillow/Pillow/issues/7175"">#7175</a>; [radarhere]</p>; </li>; <li>; <p>Changed grabclipboard() to use PNG instead of JPG compression on macOS <a href=""https://redirect.github.com/python-pillow/Pillow/issues/7219"">#7219</a>; [abey79, radarhere]</p>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13321:10838,access,access,10838,https://hail.is,https://github.com/hail-is/hail/pull/13321,1,['access'],['access']
Security,"#PdhEnumObjectItems (<a href=""https://github-redirect.dependabot.com/java-native-access/jna/issues/1442"">#1442</a>)</li>; <li><a href=""https://github.com/java-native-access/jna/commit/99fcfa822db86b1f2ba5823dbf17efeb3d246ad5""><code>99fcfa8</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/java-native-access/jna/issues/1444"">#1444</a> from matthiasblaesing/update_libffi</li>; <li><a href=""https://github.com/java-native-access/jna/commit/9e473350a5ad5e04aab8b01e4018f973976e19f8""><code>9e47335</code></a> Update CHANGES.md</li>; <li>Additional commits viewable in <a href=""https://github.com/java-native-access/jna/compare/5.6.0...5.12.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=net.java.dev.jna:jna&package-manager=gradle&previous-version=5.6.0&new-version=5.12.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12438:8120,secur,security-vulnerabilities,8120,https://hail.is,https://github.com/hail-is/hail/pull/12438,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,$$evalNoTypeCheck$1.apply(Parser.scala:64); 	at is.hail.expr.Parser$$anonfun$parseTypedExpr$1.apply(Parser.scala:102); 	at scala.Function0$class.apply$mcJ$sp(Function0.scala:34); 	at scala.runtime.AbstractFunction0.apply$mcJ$sp(AbstractFunction0.scala:12); 	at is.hail.utils.Graph$$anonfun$2$$anonfun$apply$4.apply(Graph.scala:81); 	at is.hail.utils.Graph$$anonfun$2$$anonfun$apply$4.apply(Graph.scala:79); 	at is.hail.utils.BinaryHeap.isLeftFavoredTie(BinaryHeap.scala:16); 	at is.hail.utils.BinaryHeap.is$hail$utils$BinaryHeap$$bubbleUp(BinaryHeap.scala:161); 	at is.hail.utils.BinaryHeap.insert(BinaryHeap.scala:40); 	at is.hail.utils.Graph$$anonfun$maximalIndependentSet$1.apply(Graph.scala:101); 	at is.hail.utils.Graph$$anonfun$maximalIndependentSet$1.apply(Graph.scala:100); 	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99); 	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99); 	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230); 	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40); 	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99); 	at is.hail.utils.Graph$.maximalIndependentSet(Graph.scala:100); 	at is.hail.utils.Graph$.maximalIndependentSet(Graph.scala:86); 	at is.hail.utils.Graph.maximalIndependentSet(Graph.scala); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:497); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:280); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnectio,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3704:2530,Hash,HashTable,2530,https://hail.is,https://github.com/hail-is/hail/pull/3704,1,['Hash'],['HashTable']
Security,$1.run(URLClassLoader.java:362); at java.security.AccessController.doPrivileged(Native Method); at java.net.URLClassLoader.findClass(URLClassLoader.java:361); at java.lang.ClassLoader.loadClass(ClassLoader.java:424); at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331); at java.lang.ClassLoader.loadClass(ClassLoader.java:357); at org.apache.spark.HeartbeatReceiver$$anonfun$org$apache$spark$HeartbeatReceiver$$expireDeadHosts$3.apply(HeartbeatReceiver.scala:198); at org.apache.spark.HeartbeatReceiver$$anonfun$org$apache$spark$HeartbeatReceiver$$expireDeadHosts$3.apply(HeartbeatReceiver.scala:196); at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733); at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99); at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99); at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230); at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40); at scala.collection.mutable.HashMap.foreach(HashMap.scala:99); at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732); at org.apache.spark.HeartbeatReceiver.org$apache$spark$HeartbeatReceiver$$expireDeadHosts(HeartbeatReceiver.scala:196); at org.apache.spark.HeartbeatReceiver$$anonfun$receiveAndReply$1.applyOrElse(HeartbeatReceiver.scala:119); at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105); at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205); at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101); at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:216); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); java.lang.OutOfMemoryError: GC overhead limit exceeded; at scala.collection.mutable.ListBuffer.$plus$eq,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4780:2604,Hash,HashMap,2604,https://hail.is,https://github.com/hail-is/hail/issues/4780,1,['Hash'],['HashMap']
Security,$anonfun$apply$2$$anonfun$apply$3.apply(Graph.scala:60); 	at is.hail.utils.Graph$$anonfun$2$$anonfun$apply$2$$anonfun$apply$3.apply(Graph.scala:54); 	at is.hail.utils.package$.using(package.scala:587); 	at is.hail.annotations.Region$.scoped(Region.scala:20); 	at is.hail.utils.Graph$$anonfun$2$$anonfun$apply$2.apply(Graph.scala:54); 	at is.hail.utils.Graph$$anonfun$2$$anonfun$apply$2.apply(Graph.scala:53); 	at is.hail.utils.BinaryHeap.isLeftFavoredTie(BinaryHeap.scala:16); 	at is.hail.utils.BinaryHeap.is$hail$utils$BinaryHeap$$bubbleUp(BinaryHeap.scala:161); 	at is.hail.utils.BinaryHeap.insert(BinaryHeap.scala:40); 	at is.hail.utils.Graph$$anonfun$maximalIndependentSet$1.apply(Graph.scala:91); 	at is.hail.utils.Graph$$anonfun$maximalIndependentSet$1.apply(Graph.scala:90); 	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99); 	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99); 	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230); 	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40); 	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99); 	at is.hail.utils.Graph$.maximalIndependentSet(Graph.scala:90); 	at is.hail.utils.Graph$.maximalIndependentSet(Graph.scala:76); 	at is.hail.utils.Graph.maximalIndependentSet(Graph.scala); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:280); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4857:4315,Hash,HashTable,4315,https://hail.is,https://github.com/hail-is/hail/issues/4857,1,['Hash'],['HashTable']
Security,$anonfun$runWithDelayedValues$1.apply(CM.scala:84); 	at is.hail.expr.CM$$anonfun$runWithDelayedValues$1.apply(CM.scala:82); 	at is.hail.expr.Parser$$anonfun$is$hail$expr$Parser$$evalNoTypeCheck$1.apply(Parser.scala:64); 	at is.hail.expr.Parser$$anonfun$parseTypedExpr$1.apply(Parser.scala:102); 	at scala.Function0$class.apply$mcJ$sp(Function0.scala:34); 	at scala.runtime.AbstractFunction0.apply$mcJ$sp(AbstractFunction0.scala:12); 	at is.hail.utils.Graph$$anonfun$2$$anonfun$apply$4.apply(Graph.scala:81); 	at is.hail.utils.Graph$$anonfun$2$$anonfun$apply$4.apply(Graph.scala:79); 	at is.hail.utils.BinaryHeap.isLeftFavoredTie(BinaryHeap.scala:16); 	at is.hail.utils.BinaryHeap.is$hail$utils$BinaryHeap$$bubbleUp(BinaryHeap.scala:161); 	at is.hail.utils.BinaryHeap.insert(BinaryHeap.scala:40); 	at is.hail.utils.Graph$$anonfun$maximalIndependentSet$1.apply(Graph.scala:101); 	at is.hail.utils.Graph$$anonfun$maximalIndependentSet$1.apply(Graph.scala:100); 	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99); 	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99); 	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230); 	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40); 	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99); 	at is.hail.utils.Graph$.maximalIndependentSet(Graph.scala:100); 	at is.hail.utils.Graph$.maximalIndependentSet(Graph.scala:86); 	at is.hail.utils.Graph.maximalIndependentSet(Graph.scala); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:497); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:280); 	at p,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3704:2339,Hash,HashMap,2339,https://hail.is,https://github.com/hail-is/hail/pull/3704,1,['Hash'],['HashMap']
Security,"$run$1$$anonfun$apply$mcV$sp$1.apply(InsertIntoHadoopFsRelationCommand.scala:143); at org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand$$anonfun$run$1$$anonfun$apply$mcV$sp$1.apply(InsertIntoHadoopFsRelationCommand.scala:143); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); at org.apache.spark.scheduler.Task.run(Task.scala:86); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); Caused by: java.lang.RuntimeException: Error while encoding: java.lang.RuntimeException: org.apache.spark.sql.catalyst.expressions.GenericRow is not a valid external type for schema of boolean; named_struct(contig, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, validateexternaltype(getexternalrowfield(validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 0, variant), StructField(contig,StringType,false), StructField(start,IntegerType,false), StructField(ref,StringType,false), StructField(altAlleles,ArrayType(StructType(StructField(ref,StringType,false), StructField(alt,StringType,false)),false),false)), 0, contig), StringType), true), start, validateexternaltype(getexternalrowfield(validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 0, variant), StructField(contig,StringType,false), StructField(start,IntegerType,false), StructField(ref,StringType,false), StructField(altAlleles,ArrayType(StructType(StructField(ref,StringType,false), StructField(alt,StringType,false)),false),false)), 1, start), IntegerType), ref, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, validateexternaltype(getexternalrowfield(validateexte",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1260:7555,validat,validateexternaltype,7555,https://hail.is,https://github.com/hail-is/hail/issues/1260,2,['validat'],['validateexternaltype']
Security,"', inputs, ir=ir, progress=progress); File ""/usr/local/lib/python3.10/site-packages/hail/backend/service_backend.py"", line 449, in _rpc; result_bytes = await retry_transient_errors(self._read_output, ir, iodir + '/out'); File ""/usr/local/lib/python3.10/site-packages/hailtop/utils/utils.py"", line 774, in retry_transient_errors; return await retry_transient_errors_with_debug_string('', 0, f, *args, **kwargs); File ""/usr/local/lib/python3.10/site-packages/hailtop/utils/utils.py"", line 787, in retry_transient_errors_with_debug_string; return await f(*args, **kwargs); File ""/usr/local/lib/python3.10/site-packages/hail/backend/service_backend.py"", line 475, in _read_output; raise reconstructed_error.maybe_user_error(ir); hail.utils.java.FatalError: SocketException: Connection reset. Java stack trace:; javax.net.ssl.SSLException: Connection reset; 	at sun.security.ssl.Alert.createSSLException(Alert.java:127); 	at sun.security.ssl.TransportContext.fatal(TransportContext.java:324); 	at sun.security.ssl.TransportContext.fatal(TransportContext.java:267); 	at sun.security.ssl.TransportContext.fatal(TransportContext.java:262); 	at sun.security.ssl.SSLTransport.decode(SSLTransport.java:138); 	at sun.security.ssl.SSLSocketImpl.decode(SSLSocketImpl.java:1400); 	at sun.security.ssl.SSLSocketImpl.readApplicationRecord(SSLSocketImpl.java:1368); 	at sun.security.ssl.SSLSocketImpl.access$300(SSLSocketImpl.java:73); 	at sun.security.ssl.SSLSocketImpl$AppInputStream.read(SSLSocketImpl.java:962); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:284); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.MeteredStream.read(MeteredStream.java:134); 	at java.io.FilterInputStream.read(FilterInputStream.java:133); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3456); 	at com.google.api.client.http.javanet.NetHttpResponse$SizeValidatingInputStream.read(NetHttpResponse.java:164); 	at java.nio.channels.Channels",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12982:2892,secur,security,2892,https://hail.is,https://github.com/hail-is/hail/issues/12982,1,['secur'],['security']
Security,"', inputs, ir=ir, progress=progress); File ""/usr/local/lib/python3.10/site-packages/hail/backend/service_backend.py"", line 451, in _rpc; result_bytes = await retry_transient_errors(self._read_output, ir, iodir + '/out'); File ""/usr/local/lib/python3.10/site-packages/hailtop/utils/utils.py"", line 779, in retry_transient_errors; return await retry_transient_errors_with_debug_string('', 0, f, *args, **kwargs); File ""/usr/local/lib/python3.10/site-packages/hailtop/utils/utils.py"", line 792, in retry_transient_errors_with_debug_string; return await f(*args, **kwargs); File ""/usr/local/lib/python3.10/site-packages/hail/backend/service_backend.py"", line 477, in _read_output; raise reconstructed_error.maybe_user_error(ir); hail.utils.java.FatalError: SocketException: Connection reset. Java stack trace:; javax.net.ssl.SSLException: Connection reset; 	at sun.security.ssl.Alert.createSSLException(Alert.java:127); 	at sun.security.ssl.TransportContext.fatal(TransportContext.java:324); 	at sun.security.ssl.TransportContext.fatal(TransportContext.java:267); 	at sun.security.ssl.TransportContext.fatal(TransportContext.java:262); 	at sun.security.ssl.SSLTransport.decode(SSLTransport.java:138); 	at sun.security.ssl.SSLSocketImpl.decode(SSLSocketImpl.java:1400); 	at sun.security.ssl.SSLSocketImpl.readApplicationRecord(SSLSocketImpl.java:1368); 	at sun.security.ssl.SSLSocketImpl.access$300(SSLSocketImpl.java:73); 	at sun.security.ssl.SSLSocketImpl$AppInputStream.read(SSLSocketImpl.java:962); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:284); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.MeteredStream.read(MeteredStream.java:134); 	at java.io.FilterInputStream.read(FilterInputStream.java:133); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3456); 	at com.google.api.client.http.javanet.NetHttpResponse$SizeValidatingInputStream.read(NetHttpResponse.java:164); 	at java.nio.channels.Channels",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12983:3780,secur,security,3780,https://hail.is,https://github.com/hail-is/hail/issues/12983,1,['secur'],['security']
Security,'may or may not' is redundant phrasing. The word 'may' is sufficient to indicate the optional nature of glob expressions in the `path` argument to `import_vcf`. ## Security Assessment; - This change has no security impact. ### Impact Description; Docs only,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14746:164,Secur,Security,164,https://hail.is,https://github.com/hail-is/hail/pull/14746,2,"['Secur', 'secur']","['Security', 'security']"
Security,"(2021-01-31)</h1>; <ul>; <li>Support initialising <code>EncryptedCookieStorage</code> with <code>Fernet</code> object directly.</li>; <li>Fix an issue where the session would get reset before the cookie expiry.</li>; </ul>; <h1>2.10.0 (2021-12-30)</h1>; <ul>; <li>Typing support</li>; <li>Add samesite cookie option</li>; <li>Support aioredis 2</li>; </ul>; <h1>2.9.0 (2019-11-04)</h1>; <ul>; <li>Fix memcached expiring time (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_session/issues/398"">#398</a>)</li>; </ul>; <h1>2.8.0 (2019-09-17)</h1>; <ul>; <li>Make this compatible with Python 3.7+. Import from collections.abc, instead; of from collections. (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_session/issues/373"">#373</a>)</li>; </ul>; <h1>2.7.0 (2018-10-13)</h1>; <ul>; <li>; <p>Reset a session if the session age &gt; max_age (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_session/issues/331"">#331</a>)</p>; </li>; <li>; <p>Reset a session on TTL expiration for EncryptedCookieStorage (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_session/issues/326"">#326</a>)</p>; </li>; </ul>; <h1>2.6.0 (2018-09-12)</h1>; <ul>; <li>Create a new session if <code>NaClCookieStorage</code> cannot decode a; corrupted cookie (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_session/issues/317"">#317</a>)</li>; </ul>; <h1>2.5.0 (2018-05-12)</h1>; <ul>; <li>Add an API for requesting new session explicitly (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_session/issues/281"">#281</a>)</li>; </ul>; <h1>2.4.0 (2018-05-04)</h1>; <ul>; <li>Fix a bug for session fixation (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_session/issues/272"">#272</a>)</li>; </ul>; <h1>2.3.0 (2018-02-13)</h1>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/aio-libs/aiohttp-session/commit/af05608",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11577:1790,Encrypt,EncryptedCookieStorage,1790,https://hail.is,https://github.com/hail-is/hail/pull/11577,1,['Encrypt'],['EncryptedCookieStorage']
Security,"(<a href=""https://redirect.github.com/pallets/jinja/issues/1918"">#1918</a>)</li>; <li><a href=""https://github.com/pallets/jinja/commit/19a55db3b411343309f2faaffaedbb089e841895""><code>19a55db</code></a> Make nested-trans-block exceptions nicer</li>; <li><a href=""https://github.com/pallets/jinja/commit/716795349a41d4983a9a4771f7d883c96ea17be7""><code>7167953</code></a> Merge pull request from GHSA-h5c8-rqwp-cp95</li>; <li><a href=""https://github.com/pallets/jinja/commit/7dd3680e6eea0d77fde024763657aa4d884ddb23""><code>7dd3680</code></a> xmlattr filter disallows keys with spaces</li>; <li>Additional commits viewable in <a href=""https://github.com/pallets/jinja/compare/3.1.2...3.1.3"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=jinja2&package-manager=pip&previous-version=3.1.2&new-version=3.1.3)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14144:3549,secur,security-vulnerabilities,3549,https://hail.is,https://github.com/hail-is/hail/pull/14144,6,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"(<a href=""https://redirect.github.com/urllib3/urllib3/issues/3009"">urllib3/urllib3#3009</a>)</li>; </ul>; <h2>2.0.1</h2>; <ul>; <li>Fixed a socket leak when fingerprint or hostname verifications fail. (<a href=""https://redirect.github.com/urllib3/urllib3/issues/2991"">#2991</a>)</li>; <li>Fixed an error when <code>HTTPResponse.read(0)</code> was the first <code>read</code> call or when the internal response body buffer was otherwise empty. (<a href=""https://redirect.github.com/urllib3/urllib3/issues/2998"">#2998</a>)</li>; </ul>; <h2>2.0.0</h2>; <p>Read the <a href=""https://urllib3.readthedocs.io/en/latest/v2-migration-guide.html"">v2.0 migration guide</a> for help upgrading to the latest version of urllib3.</p>; <h1>Removed</h1>; <ul>; <li>Removed support for Python 2.7, 3.5, and 3.6 (<a href=""https://redirect.github.com/urllib3/urllib3/issues/883"">#883</a>, <a href=""https://redirect.github.com/urllib3/urllib3/issues/2336"">#2336</a>).</li>; <li>Removed fallback on certificate <code>commonName</code> in <code>match_hostname()</code> function. This behavior was deprecated in May 2000 in RFC 2818. Instead only <code>subjectAltName</code> is used to verify the hostname by default. To enable verifying the hostname against <code>commonName</code> use <code>SSLContext.hostname_checks_common_name = True</code> (<a href=""https://redirect.github.com/urllib3/urllib3/issues/2113"">#2113</a>).</li>; <li>Removed support for Python with an <code>ssl</code> module compiled with LibreSSL, CiscoSSL, wolfSSL, and all other OpenSSL alternatives. Python is moving to require OpenSSL with PEP 644 (<a href=""https://redirect.github.com/urllib3/urllib3/issues/2168"">#2168</a>).</li>; <li>Removed support for OpenSSL versions earlier than 1.1.1 or that don't have SNI support. When an incompatible OpenSSL version is detected an <code>ImportError</code> is raised (<a href=""https://redirect.github.com/urllib3/urllib3/issues/2168"">#2168</a>).</li>; <li>Removed the list of default ciphers for OpenSSL 1.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13768:3672,certificate,certificate,3672,https://hail.is,https://github.com/hail-is/hail/pull/13768,3,['certificate'],['certificate']
Security,(RegionValueBuilder.scala:298); 	at is.hail.annotations.RegionValueBuilder.addAnnotation(RegionValueBuilder.scala:541); 	at is.hail.utils.Graph$$anonfun$2$$anonfun$apply$2$$anonfun$apply$3.apply(Graph.scala:60); 	at is.hail.utils.Graph$$anonfun$2$$anonfun$apply$2$$anonfun$apply$3.apply(Graph.scala:54); 	at is.hail.utils.package$.using(package.scala:587); 	at is.hail.annotations.Region$.scoped(Region.scala:20); 	at is.hail.utils.Graph$$anonfun$2$$anonfun$apply$2.apply(Graph.scala:54); 	at is.hail.utils.Graph$$anonfun$2$$anonfun$apply$2.apply(Graph.scala:53); 	at is.hail.utils.BinaryHeap.isLeftFavoredTie(BinaryHeap.scala:16); 	at is.hail.utils.BinaryHeap.is$hail$utils$BinaryHeap$$bubbleUp(BinaryHeap.scala:161); 	at is.hail.utils.BinaryHeap.insert(BinaryHeap.scala:40); 	at is.hail.utils.Graph$$anonfun$maximalIndependentSet$1.apply(Graph.scala:91); 	at is.hail.utils.Graph$$anonfun$maximalIndependentSet$1.apply(Graph.scala:90); 	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99); 	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99); 	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230); 	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40); 	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99); 	at is.hail.utils.Graph$.maximalIndependentSet(Graph.scala:90); 	at is.hail.utils.Graph$.maximalIndependentSet(Graph.scala:76); 	at is.hail.utils.Graph.maximalIndependentSet(Graph.scala); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:280); 	at py4j.commands.Abstract,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4857:4157,Hash,HashMap,4157,https://hail.is,https://github.com/hail-is/hail/issues/4857,1,['Hash'],['HashMap']
Security,"(getexternalrowfield(validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 0, variant), StructField(contig,StringType,false), StructField(start,IntegerType,false), StructField(ref,StringType,false), StructField(altAlleles,ArrayType(StructType(StructField(ref,StringType,false), StructField(alt,StringType,false)),false),false)), 0, contig), StringType), true), start, validateexternaltype(getexternalrowfield(validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 0, variant), StructField(contig,StringType,false), StructField(start,IntegerType,false), StructField(ref,StringType,false), StructField(altAlleles,ArrayType(StructType(StructField(ref,StringType,false), StructField(alt,StringType,false)),false),false)), 1, start), IntegerType), ref, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, validateexternaltype(getexternalrowfield(validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 0, variant), StructField(contig,StringType,false), StructField(start,IntegerType,false), StructField(ref,StringType,false), StructField(altAlleles,ArrayType(StructType(StructField(ref,StringType,false), StructField(alt,StringType,false)),false),false)), 2, ref), StringType), true), altAlleles, mapobjects(MapObjects_loopValue8, MapObjects_loopIsNull9, ObjectType(class java.lang.Object), if (isnull(validateexternaltype(lambdavariable(MapObjects_loopValue8, MapObjects_loopIsNull9, ObjectType(class java.lang.Object)), StructField(ref,StringType,false), StructField(alt,StringType,false)))) null else named_struct(ref, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, validateexternaltype(getexternalrowfield(validateexternaltype(lambdavariable(MapObjects_loopValue8, MapObjects_loopIsNull9, ObjectType(class java.lang.Object)), StructFiel",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1260:8539,validat,validateexternaltype,8539,https://hail.is,https://github.com/hail-is/hail/issues/1260,2,['validat'],['validateexternaltype']
Security,"(https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5813746) | `cryptography:` <br> `41.0.2 -> 41.0.3` <br> | No | No Known Exploit ; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **471/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 3.7 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-5813750](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5813750) | `cryptography:` <br> `41.0.2 -> 41.0.3` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI4MmVlNzU5Ny0wZmFhLTQ1NmUtOTA3Ny0zOTM4ODRjNzJmNGMiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjgyZWU3NTk3LTBmYWEtNDU2ZS05MDc3LTM5Mzg4NGM3MmY0YyJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""82ee7597-0faa-456e-9077-393884c72f4c"",""pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13370:2546,access,access,2546,https://hail.is,https://github.com/hail-is/hail/pull/13370,2,"['access', 'authoriz']","['access', 'authorized']"
Security,"(https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5813746) | `cryptography:` <br> `41.0.2 -> 41.0.3` <br> | No | No Known Exploit ; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **471/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 3.7 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-5813750](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5813750) | `cryptography:` <br> `41.0.2 -> 41.0.3` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI5Nzc0NDQwMi1iNzEyLTQ5NjMtYWQ0Zi01YjFhZWZmOTcwZDciLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6Ijk3NzQ0NDAyLWI3MTItNDk2My1hZDRmLTViMWFlZmY5NzBkNyJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/701495b8-b53d-48af-82fe-1a6c57aa56cb?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/701495b8-b53d-48af-82fe-1a6c57aa56cb?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""97744402-b712-4963-ad4f-5b1aeff970d7"",""pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13365:2345,access,access,2345,https://hail.is,https://github.com/hail-is/hail/pull/13365,2,"['access', 'authoriz']","['access', 'authorized']"
Security,"(https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5813746) | `cryptography:` <br> `41.0.2 -> 41.0.3` <br> | No | No Known Exploit ; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **471/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 3.7 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-5813750](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5813750) | `cryptography:` <br> `41.0.2 -> 41.0.3` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiIxOGJjNGZiYS05ZTMwLTRmNWItYTE4Yy0wOGNmNDVmZDExMTciLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjE4YmM0ZmJhLTllMzAtNGY1Yi1hMThjLTA4Y2Y0NWZkMTExNyJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""18bc4fba-9e30-4f5b-a18c-08cf45fd1117"",""pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13366:2554,access,access,2554,https://hail.is,https://github.com/hail-is/hail/pull/13366,2,"['access', 'authoriz']","['access', 'authorized']"
Security,"). A Certificate Authority (like; letsencypt or VeriSign) digitally signs the certificate of a user that has; proven they own the domain name mentioned in the certificate (see above; discussion of `CN` and `subjectAltName`). Web browsers have a file of the ""root""; certificates of the public Certificate Authorities. They establish a ""chain of; trust"" from a root certificate to the server's certificate. Our system is simpler. We have no root certificate. Each principal has a; certificate which is given to all the principals to which it might; communicate. ### Encryption. TLS has many encryption schemes. I will focus on encryption using a *symmetric*; key because asymmetric schemes do not enable *forward secrecy* [2]. Under; forward secret schemes, the two parties share a private key unknown to all; adversaries. TLS 1.3 makes forward secrecy mandatory. I intend to eventually; require all our services to refuse to speak anything other than TLS 1.3. The shared private key is used to encrypt and decrypt messages sent over a; socket. This poses a problem: how do two parties who have never met each other; agree on a private key without revealing the key to the public? This is a; classic cryptography problem called [key; exchange](https://en.wikipedia.org/wiki/Key_exchange). The classic solution to; this problem is [Diffie-Hellman key; exchange](https://en.wikipedia.org/wiki/Diffie–Hellman_key_exchange). The; Wikipedia article has ""General overview"" which is quite clear. In addition to a key, the parties must agree on a cipher. There are many old,; insecure ciphers available. In the future I intend all our servers to refuse to; use insecure ciphers. Mozilla; [has a list of secure cipher suites](https://wiki.mozilla.org/Security/Server_Side_TLS#Recommended_configurations). ## New Hail Concepts. Every principal in our system has a secret: `ssl-config-NAME`. These secrets are; automatically created for a particular namespace by `tls/create_certs.py`. Who; trusts who (i.e. who i",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8561:5443,encrypt,encrypt,5443,https://hail.is,https://github.com/hail-is/hail/pull/8561,1,['encrypt'],['encrypt']
Security,); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:280); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:214); 	at java.lang.Thread.run(Thread.java:748)java.io.FileNotFoundException: File file:/tmp/clinvar.vcf.gz does not exist; 	at org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:611); 	at org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:824); 	at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:601); 	at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:428); 	at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:142); 	at org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:346); 	at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:769); 	at org.apache.hadoop.mapred.LineRecordReader.<init>(LineRecordReader.java:109); 	at org.apache.hadoop.mapred.TextInputFormat.getRecordReader(TextInputFormat.java:67); 	at org.apache.spark.rdd.HadoopRDD$$anon$1.<init>(HadoopRDD.scala:245); 	at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:208); 	at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:101); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3760:11815,Checksum,ChecksumFileSystem,11815,https://hail.is,https://github.com/hail-is/hail/issues/3760,1,['Checksum'],['ChecksumFileSystem']
Security,")</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/437ac47fe332106a07a2d5335bb89619f1bc23f7""><code>437ac47</code></a> [PR <a href=""https://redirect.github.com/aio-libs/aiohttp/issues/7995"">#7995</a>/43a5bc50 backport][3.9] Fix examples of <code>fallback_charset_resolver</code>...</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/034e5e34ee11c6138c773d85123490e691e1b708""><code>034e5e3</code></a> [PR <a href=""https://redirect.github.com/aio-libs/aiohttp/issues/8042"">#8042</a>/4b91b530 backport][3.9] Tightening the runtime type check for ssl (...</li>; <li>Additional commits viewable in <a href=""https://github.com/aio-libs/aiohttp/compare/v3.9.1...v3.9.2"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=aiohttp&package-manager=pip&previous-version=3.9.1&new-version=3.9.2)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14212:7013,secur,security-vulnerabilities,7013,https://hail.is,https://github.com/hail-is/hail/pull/14212,12,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"* Fix error in TableKeyByAndAggregate caused by field name clobbering; * Fix error in TableLeftJoinRightDistinct with non-strict left tables; * Fix erroneous key preservation in TableStage.mapPartition; * Add Consume to TypeCheck; * Fix error where globals were not exposed in TableAggregate; * Fix error where globals were not exposed in TableAggregate. New local backend success rate:. ```; 271 failed, 496 passed, 75 skipped, 15 warnings in 368.17 seconds; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9202:266,expose,exposed,266,https://hail.is,https://github.com/hail-is/hail/pull/9202,2,['expose'],['exposed']
Security,"* Implement arithemetic in the finite field of order 2^32, as; polynomials over F_2 modulo the irreducible polynomial; x^32 + x^7 + x^3 + x^2 + 1. * Define class `PolyHash`, implementing polynomials over above field,; using Horner's rule for polynomial evaluation. * Use random polynomials to fill tables in tabulation hashes, for; guaranteed 32-independent randomness.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2452:319,hash,hashes,319,https://hail.is,https://github.com/hail-is/hail/pull/2452,1,['hash'],['hashes']
Security,"** Dropped support for LibreSSL &lt; 3.6.; * Updated the minimum supported Rust version (MSRV) to 1.56.0, from 1.48.0.; * Updated Windows, macOS, and Linux wheels to be compiled with OpenSSL 3.1.1.; * Added support for the :class:`~cryptography.x509.OCSPAcceptableResponses`; OCSP extension.; * Added support for the :class:`~cryptography.x509.MSCertificateTemplate`; proprietary Microsoft certificate extension.; * Implemented support for equality checks on all asymmetric public key types.; * Added support for ``aes256-gcm@openssh.com`` encrypted keys in; :func:`~cryptography.hazmat.primitives.serialization.load_ssh_private_key`.; * Added support for obtaining X.509 certificate signature algorithm parameters; (including PSS) via; :meth:`~cryptography.x509.Certificate.signature_algorithm_parameters`.; * Support signing :class:`~cryptography.hazmat.primitives.asymmetric.padding.PSS`; X.509 certificates via the new keyword-only argument ``rsa_padding`` on; :meth:`~cryptography.x509.CertificateBuilder.sign`.; * Added support for; :class:`~cryptography.hazmat.primitives.ciphers.aead.ChaCha20Poly1305`; on BoringSSL.; <p>.. _v40-0-2:; </code></pre></p>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/pyca/cryptography/commit/c4d494fd3ee907316bd846e90cbf4a8df75a25ac""><code>c4d494f</code></a> 41.0.0 version bump (<a href=""https://redirect.github.com/pyca/cryptography/issues/8991"">#8991</a>)</li>; <li><a href=""https://github.com/pyca/cryptography/commit/8708245ccdeaff21d65eea68a4f8d2a7c5949a22""><code>8708245</code></a> new openssl day (<a href=""https://redirect.github.com/pyca/cryptography/issues/8990"">#8990</a>)</li>; <li><a href=""https://github.com/pyca/cryptography/commit/31436a486661cd863d4c77e40facf93fbb2d9f54""><code>31436a4</code></a> admit to the existence of nuance in HKDF (<a href=""https://redirect.github.com/pyca/cryptography/issues/8987"">#8987</a>)</li>; <li><a href=""https://github.com/pyca/cryptography/commit/91e",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13141:1543,Certificate,CertificateBuilder,1543,https://hail.is,https://github.com/hail-is/hail/pull/13141,3,['Certificate'],['CertificateBuilder']
Security,"+updated%3A2024-01-19..2024-01-30&amp;type=Issues""><code>@​jupyterlab-probot</code></a> | <a href=""https://github.com/search?q=repo%3Ajupyterlab%2Fjupyterlab+involves%3Akrassowski+updated%3A2024-01-19..2024-01-30&amp;type=Issues""><code>@​krassowski</code></a> | <a href=""https://github.com/search?q=repo%3Ajupyterlab%2Fjupyterlab+involves%3Alumberbot-app+updated%3A2024-01-19..2024-01-30&amp;type=Issues""><code>@​lumberbot-app</code></a> | <a href=""https://github.com/search?q=repo%3Ajupyterlab%2Fjupyterlab+involves%3Ameeseeksmachine+updated%3A2024-01-19..2024-01-30&amp;type=Issues""><code>@​meeseeksmachine</code></a> | <a href=""https://github.com/search?q=repo%3Ajupyterlab%2Fjupyterlab+involves%3Awelcome+updated%3A2024-01-19..2024-01-30&amp;type=Issues""><code>@​welcome</code></a></p>; <!-- raw HTML omitted -->; <h2>4.0.11</h2>; <p>(<a href=""https://github.com/jupyterlab/jupyterlab/compare/v4.0.10...0708330843fd087134a239d2ad6005b1d543e246"">Full Changelog</a>)</p>; <h3>Security fixes</h3>; <ul>; <li>Potential authentication and CSRF tokens leak in JupyterLab (<a href=""https://github.com/jupyterlab/jupyterlab/security/advisories/GHSA-44cc-43rp-5947"">GHSA-44cc-43rp-5947</a>)</li>; <li>SXSS in Markdown Preview (<a href=""https://github.com/jupyterlab/jupyterlab/security/advisories/GHSA-4m77-cmpx-vjc4"">GHSA-4m77-cmpx-vjc4</a>)</li>; </ul>; <h3>Bugs fixed</h3>; <ul>; <li>Fixes focus indicator on input checkbox for Firefox <a href=""https://redirect.github.com/jupyterlab/jupyterlab/pull/15612"">#15612</a> (<a href=""https://github.com/alden-ilao""><code>@​alden-ilao</code></a>)</li>; </ul>; <h3>Documentation improvements</h3>; <ul>; <li>Fix link to yarn docs in extension migration guide <a href=""https://redirect.github.com/jupyterlab/jupyterlab/pull/15640"">#15640</a> (<a href=""https://github.com/krassowski""><code>@​krassowski</code></a>)</li>; </ul>; <h3>Contributors to this release</h3>; <p>(<a href=""https://github.com/jupyterlab/jupyterlab/graphs/contributors?from=2023-12-29&amp;to",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14218:10205,Secur,Security,10205,https://hail.is,https://github.com/hail-is/hail/pull/14218,2,"['Secur', 'authenticat']","['Security', 'authentication']"
Security,", but we do not verify; (proxied) servers. I load the client certificates anyway so that I can smoke; test them before I require servers verify them. For VERIFY_CA, we load server; certs, load client certs, verify clients, and verify (proxied) servers. For Hail principals, we only generate a json configuration; file containing the ssl mode and some named paths. The new `hailtop/ssl.py`; module defines the mapping from configuration to Python's; [`SSLContext`](https://docs.python.org/3.6/library/ssl.html#ssl.SSLContext). There is also one ""curl"" principal: the admin-pod. REQUIRED and DISABLED are; mostly the same because required passes the `insecure` flag. As curl is; client-only, there is no notion of ""incoming connection"". ---. FAQ. Does this recreate certs on each deploy?. Yes. How do services speak to each other while a deploy is happening? Newly deployed; services will only trust newly deployed clients?. `create_certs.py` includes the previous deploy's certificates in the trust; chain, so we can always accept clients from one deploy backwards. Old services; will not trust the new clients, but the `build.yaml` ensures things are deployed; in dependency order. Deploy would never work if a client could depend on; a not-yet-deployed server. ---. Things for you to verify:; - does every service load *its own unqiue* ssl-config secret?; - does every service use an SSL context for serving?; - does everyone who makes http requests to internal services use an SSL client; session?; - do all TLS-secured nginx instances include their http.conf in the `http`; section and the `proxy.conf` file in any proxying sections?; - Do the SSLContext's from `ssl.py` and the nginx configurations generated by; `create_certs.py` obey the aforementioned matrix?. Post-merge actions:; - deploy gateway; - deploy internal-gateway; - deploy router-resolver. Anticipated outages:. - Before a service is redeployed it will be inaccessible from the outside; because the router will try to speak to it o",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8513:5560,certificate,certificates,5560,https://hail.is,https://github.com/hail-is/hail/pull/8513,1,['certificate'],['certificates']
Security,", instead of returning a value. Under the hood, `JoinPoint`s are implemented; with a label and a `GOTO` instruction. ```scala; def example1(j: JoinPoint[Code[Int]]): Code[Ctrl] = Code(; j(3),; ""this line is never reached"".println,; j(4)); ```. ### `ParameterPack`. The trait `ParameterPack[A]` says that the type `A` is comprised of a list of `Code[T]`s, such that the structure of that list is statically known. While this is generally useful for representing deforested tuples, it is specifically useful here because it allows `JoinPoint`s to take multiple arguments as a tuple of the individual arguments. This ""tuple"" will be represented at runtime by pushing or popping multiple values from the JVM argument stack. ```scala; // case class JoinPoint[A: ParameterPack] ( .... ); def example2(j: JoinPoint[(Code[Int], Code[Boolean], Code[Int])]): Code[Ctrl] =; j((8, true, 9)); /* LDC 8; * LDC 1; * LDC 9; * GOTO j */; ```. ### `JoinPointBuilder`. The only way to create new join-points is via a `JoinPointBuilder` object, using the `joinPoint[A]` method (where `A` is the desired argument type). Then the body of the join-point can be provided by calling `define`. ```scala; val mb: MethodBuilder; // method builder required to create locals to store join point arguments; def example3(jb: JoinPointBuilder, exit: JoinPoint[Code[Int]]): JoinPoint[Code[Int]] = {; val j = jb.joinPoint[Code[Int]](mb); j.define { n => exit(n + 1) }; j; }; ```. ### `CallCC`. The only way to obtain a `JoinPointBuilder` is through a `CallCC`. `CallCC` also provides access to; the ""current continuation"" -- a join-point which takes an argument that will become the final result; of the entire `CallCC` expression. In fact, the only way to return a value from a `CallCC` is by; eventually calling this join-point. ```scala; val example4: Code[Boolean] =; JoinPoint.CallCC { (jb: JoinPointBuilder, ret: JoinPoint[Code[Boolean]]) =>; const(false).mux(; ret(false),; ret(true)); }; // running 'example4' gives 'true'; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7055:3644,access,access,3644,https://hail.is,https://github.com/hail-is/hail/pull/7055,1,['access'],['access']
Security,",""dependencies"":[{""name"":""certifi"",""from"":""2021.10.8"",""to"":""2023.7.22""},{""name"":""cryptography"",""from"":""3.3.2"",""to"":""42.0.2""},{""name"":""requests"",""from"":""2.27.1"",""to"":""2.31.0""}],""packageManager"":""pip"",""projectPublicId"":""5ecb4152-94d0-44ff-86c6-21e542bb123d"",""projectUrl"":""https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-CERTIFI-3164749"",""SNYK-PYTHON-CERTIFI-5805047"",""SNYK-PYTHON-CRYPTOGRAPHY-3172287"",""SNYK-PYTHON-CRYPTOGRAPHY-3314966"",""SNYK-PYTHON-CRYPTOGRAPHY-3315324"",""SNYK-PYTHON-CRYPTOGRAPHY-3315328"",""SNYK-PYTHON-CRYPTOGRAPHY-3315331"",""SNYK-PYTHON-CRYPTOGRAPHY-3315452"",""SNYK-PYTHON-CRYPTOGRAPHY-3315972"",""SNYK-PYTHON-CRYPTOGRAPHY-3315975"",""SNYK-PYTHON-CRYPTOGRAPHY-3316038"",""SNYK-PYTHON-CRYPTOGRAPHY-3316211"",""SNYK-PYTHON-CRYPTOGRAPHY-5663682"",""SNYK-PYTHON-CRYPTOGRAPHY-5777683"",""SNYK-PYTHON-CRYPTOGRAPHY-5813745"",""SNYK-PYTHON-CRYPTOGRAPHY-5813746"",""SNYK-PYTHON-CRYPTOGRAPHY-5813750"",""SNYK-PYTHON-CRYPTOGRAPHY-5914629"",""SNYK-PYTHON-CRYPTOGRAPHY-6036192"",""SNYK-PYTHON-CRYPTOGRAPHY-6050294"",""SNYK-PYTHON-CRYPTOGRAPHY-6092044"",""SNYK-PYTHON-CRYPTOGRAPHY-6126975"",""SNYK-PYTHON-CRYPTOGRAPHY-6210214"",""SNYK-PYTHON-REQUESTS-5595532""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""pr-warning-shown""],""priorityScoreList"":[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Use After Free](https://learn.snyk.io/lesson/use-after-free/?loc&#x3D;fix-pr); 🦉 [Access of Resource Using Incompatible Type (&#x27;Type Confusion&#x27;)](https://learn.snyk.io/lesson/type-confusion/?loc&#x3D;fix-pr); 🦉 [Denial of Service (DoS)](https://learn.snyk.io/lesson/redos/?loc&#x3D;fix-pr); 🦉 [More lessons are available in Snyk Learn](https://learn.snyk.io/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14296:11546,Access,Access,11546,https://hail.is,https://github.com/hail-is/hail/pull/14296,1,['Access'],['Access']
Security,",""to"":""2.15.0""},{""name"":""requests"",""from"":""2.27.1"",""to"":""2.31.0""},{""name"":""setuptools"",""from"":""39.0.1"",""to"":""65.5.1""},{""name"":""sphinx"",""from"":""1.8.6"",""to"":""3.3.0""},{""name"":""tornado"",""from"":""5.1.1"",""to"":""6.3.3""},{""name"":""wheel"",""from"":""0.30.0"",""to"":""0.38.0""}],""packageManager"":""pip"",""projectPublicId"":""20159ae6-a5aa-42fa-845a-c89f5bcbf999"",""projectUrl"":""https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-CERTIFI-3164749"",""SNYK-PYTHON-CERTIFI-5805047"",""SNYK-PYTHON-IPYTHON-2348630"",""SNYK-PYTHON-IPYTHON-3318382"",""SNYK-PYTHON-JINJA2-6150717"",""SNYK-PYTHON-JUPYTERCORE-3063766"",""SNYK-PYTHON-MISTUNE-2940625"",""SNYK-PYTHON-NBCONVERT-2979829"",""SNYK-PYTHON-NOTEBOOK-1041707"",""SNYK-PYTHON-NOTEBOOK-2441824"",""SNYK-PYTHON-NOTEBOOK-2928995"",""SNYK-PYTHON-PROMPTTOOLKIT-6141120"",""SNYK-PYTHON-PYGMENTS-1086606"",""SNYK-PYTHON-PYGMENTS-1088505"",""SNYK-PYTHON-PYGMENTS-5750273"",""SNYK-PYTHON-REQUESTS-5595532"",""SNYK-PYTHON-SETUPTOOLS-3180412"",""SNYK-PYTHON-SPHINX-570772"",""SNYK-PYTHON-SPHINX-570773"",""SNYK-PYTHON-SPHINX-5811865"",""SNYK-PYTHON-SPHINX-5812109"",""SNYK-PYTHON-TORNADO-5537286"",""SNYK-PYTHON-TORNADO-5840803"",""SNYK-PYTHON-TORNADO-6041512"",""SNYK-PYTHON-WHEEL-3180413""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""pr-warning-shown"",""priorityScore""],""priorityScoreList"":[554,704,624,531,556,604,589,726,434,589,449,399,696,589,479,519,509,711,701,586,586,384,494,539,589],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Remote Code Execution (RCE)](https://learn.snyk.io/lesson/improper-input-validation/?loc&#x3D;fix-pr); 🦉 [Cross-site Scripting (XSS)](https://learn.snyk.io/lesson/xss/?loc&#x3D;fix-pr); 🦉 [Improper Privilege Management](https://learn.snyk.io/lesson/insecure-design/?loc&#x3D;fix-pr); 🦉 [More lessons are available in Snyk Learn](https://learn.snyk.io/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14205:14123,validat,validation,14123,https://hail.is,https://github.com/hail-is/hail/pull/14205,4,"['Cross-site Scripting', 'XSS', 'validat', 'xss']","['Cross-site Scripting', 'XSS', 'validation', 'xss']"
Security,",StringType,false), StructField(altAlleles,ArrayType(StructType(StructField(ref,StringType,false), StructField(alt,StringType,false)),false),false)), 2, ref), StringType), true), altAlleles, mapobjects(MapObjects_loopValue8, MapObjects_loopIsNull9, ObjectType(class java.lang.Object), if (isnull(validateexternaltype(lambdavariable(MapObjects_loopValue8, MapObjects_loopIsNull9, ObjectType(class java.lang.Object)), StructField(ref,StringType,false), StructField(alt,StringType,false)))) null else named_struct(ref, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, validateexternaltype(getexternalrowfield(validateexternaltype(lambdavariable(MapObjects_loopValue8, MapObjects_loopIsNull9, ObjectType(class java.lang.Object)), StructField(ref,StringType,false), StructField(alt,StringType,false)), 0, ref), StringType), true), alt, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, validateexternaltype(getexternalrowfield(validateexternaltype(lambdavariable(MapObjects_loopValue8, MapObjects_loopIsNull9, ObjectType(class java.lang.Object)), StructField(ref,StringType,false), StructField(alt,StringType,false)), 1, alt), StringType), true)), validateexternaltype(getexternalrowfield(validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true], top level row object), 0, variant), StructField(contig,StringType,false), StructField(start,IntegerType,false), StructField(ref,StringType,false), StructField(altAlleles,ArrayType(StructType(StructField(ref,StringType,false), StructField(alt,StringType,false)),false),false)), 3, altAlleles), ArrayType(StructType(StructField(ref,StringType,false), StructField(alt,StringType,false)),false)))) AS variant#8; ```. Attached is a toy test.in.vds that reproduces the problem [test.in.vds.tar.gz](https://github.com/hail-is/hail/files/709524/test.in.vds.tar.gz). Tested on a clean ed544897f04722142b14b8e620614587c8f398a0 built with gradlew installDist.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1260:9756,validat,validateexternaltype,9756,https://hail.is,https://github.com/hail-is/hail/issues/1260,4,['validat'],['validateexternaltype']
Security,",h_20/v1561977819/icon/m.png ""medium severity"") | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3316038](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3316038) | `cryptography:` <br> `3.3.2 -> 41.0.4` <br> | No | No Known Exploit ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3316211](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3316211) | `cryptography:` <br> `3.3.2 -> 41.0.4` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-5663682](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5663682) | `cryptography:` <br> `3.3.2 -> 41.0.4` <br> | No | No Known Exploit ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | Improper Certificate Validation <br/>[SNYK-PYTHON-CRYPTOGRAPHY-5777683](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5777683) | `cryptography:` <br> `3.3.2 -> 41.0.4` <br> | No | Proof of Concept ; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | Insufficient Verification of Data Authenticity <br/>[SNYK-PYTHON-CRYPTOGRAPHY-5813745](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5813745) | `cryptography:` <br> `3.3.2 -> 41.0.4` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-5813746](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5813746) | `cryptography:` <br> `3.3.2 -> 41.0.4` <br> | No | No Known Exploit ; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-5813750](https://snyk.io/vuln/",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13736:5116,Certificate,Certificate,5116,https://hail.is,https://github.com/hail-is/hail/pull/13736,4,"['Certificate', 'Validat']","['Certificate', 'Validation']"
Security,",h_20/v1561977819/icon/m.png ""medium severity"") | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3316038](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3316038) | `cryptography:` <br> `3.3.2 -> 41.0.5` <br> | No | No Known Exploit ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3316211](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3316211) | `cryptography:` <br> `3.3.2 -> 41.0.5` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-5663682](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5663682) | `cryptography:` <br> `3.3.2 -> 41.0.5` <br> | No | No Known Exploit ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | Improper Certificate Validation <br/>[SNYK-PYTHON-CRYPTOGRAPHY-5777683](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5777683) | `cryptography:` <br> `3.3.2 -> 41.0.5` <br> | No | Proof of Concept ; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | Insufficient Verification of Data Authenticity <br/>[SNYK-PYTHON-CRYPTOGRAPHY-5813745](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5813745) | `cryptography:` <br> `3.3.2 -> 41.0.5` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-5813746](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5813746) | `cryptography:` <br> `3.3.2 -> 41.0.5` <br> | No | No Known Exploit ; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-5813750](https://snyk.io/vuln/",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13938:5172,Certificate,Certificate,5172,https://hail.is,https://github.com/hail-is/hail/pull/13938,2,"['Certificate', 'Validat']","['Certificate', 'Validation']"
Security,",h_20/v1561977819/icon/m.png ""medium severity"") | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3316038](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3316038) | `cryptography:` <br> `3.3.2 -> 41.0.6` <br> | No | No Known Exploit ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3316211](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3316211) | `cryptography:` <br> `3.3.2 -> 41.0.6` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-5663682](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5663682) | `cryptography:` <br> `3.3.2 -> 41.0.6` <br> | No | No Known Exploit ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | Improper Certificate Validation <br/>[SNYK-PYTHON-CRYPTOGRAPHY-5777683](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5777683) | `cryptography:` <br> `3.3.2 -> 41.0.6` <br> | No | Proof of Concept ; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | Insufficient Verification of Data Authenticity <br/>[SNYK-PYTHON-CRYPTOGRAPHY-5813745](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5813745) | `cryptography:` <br> `3.3.2 -> 41.0.6` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-5813746](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5813746) | `cryptography:` <br> `3.3.2 -> 41.0.6` <br> | No | No Known Exploit ; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-5813750](https://snyk.io/vuln/",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14134:4848,Certificate,Certificate,4848,https://hail.is,https://github.com/hail-is/hail/pull/14134,4,"['Certificate', 'Validat']","['Certificate', 'Validation']"
Security,",h_20/v1561977819/icon/m.png ""medium severity"") | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3316038](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3316038) | `cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No | No Known Exploit ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3316211](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3316211) | `cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-5663682](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5663682) | `cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No | No Known Exploit ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | Improper Certificate Validation <br/>[SNYK-PYTHON-CRYPTOGRAPHY-5777683](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5777683) | `cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No | Proof of Concept ; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | Insufficient Verification of Data Authenticity <br/>[SNYK-PYTHON-CRYPTOGRAPHY-5813745](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5813745) | `cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-5813746](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5813746) | `cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No | No Known Exploit ; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-5813750](https://snyk.io/vuln/",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14296:5104,Certificate,Certificate,5104,https://hail.is,https://github.com/hail-is/hail/pull/14296,2,"['Certificate', 'Validat']","['Certificate', 'Validation']"
Security,"- Added IR node to go from a BlockMatrix to a value; - Added BlockMatrixToValueFunction to get an element at a certain index and used it to access elements in BlockMatrix.__getitem__; - This raises an interesting question of whether accessing an element of a tensor should return a Python value or a Hail expr. Right now, it just builds a BlockMatrixToValue IR and immediately executes it to return a Python number (matches existing behavior), but we could just as easily return the IR node.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5402:140,access,access,140,https://hail.is,https://github.com/hail-is/hail/pull/5402,2,['access'],"['access', 'accessing']"
Security,- Added Scala infrastructure to aggregate to new row fields (current is only entry fields). To Do:; - Expose in Python interface (currently just passing an empty struct); - Write tests in Python,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4131:102,Expose,Expose,102,https://hail.is,https://github.com/hail-is/hail/pull/4131,1,['Expose'],['Expose']
Security,- Added a new annotate module due to demand from users to be able to annotate variants without ref/alt.; - Added `Locus` constructor and accessor methods in the expr language,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/516:137,access,accessor,137,https://hail.is,https://github.com/hail-is/hail/pull/516,1,['access'],['accessor']
Security,"- Added a shared image gallery to terraform; - Added a managed identity `batch-worker` to terraform; - Gave `batch-worker` ""acrpull"" privileges for the resource group; - Added new config variables in config.mk that are specific to Azure; - Added commands to batch/Makefile to create a boot disk image; - Added an Azure-specific startup script that installs Docker and the CLI and then authenticates and pulls the base image. The disk image we create is specialized. This means it has credentials in there after publishing it. I think this is okay and I specifically used the batch-worker managed identity to login for this. I can try and double check this assumption if you think I'm not correct after reading these docs: https://docs.microsoft.com/en-us/cli/azure/vm?view=azure-cli-latest#az_vm_create. > Accept system or user assigned identities separated by spaces. Use '[system]' to refer system assigned identity, or a resource id to refer user assigned identity. Check out help for more examples. I had to give the batch-worker managed identity in the resource group we want permissions to be an identity for a VM in the build-batch-worker-image resource group.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10834:385,authenticat,authenticates,385,https://hail.is,https://github.com/hail-is/hail/pull/10834,1,['authenticat'],['authenticates']
Security,"- Added support for blobfuse, which is Azure's equivalent of gcsfuse.; - Renamed operations/variables to cloudfuse to be generic; - The validator is slightly more complicated because there is a double renaming of gcsfuse to cloud fuse to gcsfuse for old clients. This is to maintain backwards compatibility with old instances. Once v21 instances die, then we can remove the extra backwards compatibility step.; - renamed instance_env.py files to worker_api.py files. @daniel-goldstein @danking Can you decide amongst yourselves who should review this? Maybe Dan takes a first glance and then Daniel reads it in more detail?",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11211:136,validat,validator,136,https://hail.is,https://github.com/hail-is/hail/pull/11211,1,['validat'],['validator']
Security,- Added the AzureGraphClient which creates applications and service principals; - Modified Auth to create service principals and delete them; - Added two fields to the auth database that optionally store the application ID and the credentials secret name; - Had to modify AzureCredentials a bit to account for a different scope (one of the Azure Credentials types cannot take multiple scopes for some reason); - There's an auth database migration here!; - I tried to figure out what API calls result in the same result in the portal. It's possible the exact calls are not quite right (ex: addPassword on the application versus the service principal). TODO:; - Figure out how to use the global config in auth/Makefile to template global.cloud; - Double check the service principal creation is correct (I know the appID and password end up working to create resources at least). cc: @danking,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10986:822,password,password,822,https://hail.is,https://github.com/hail-is/hail/pull/10986,1,['password'],['password']
Security,"- Adds typeArgs: Array[Type] to registered functions. Exposed on Apply, ApplyIR, ApplySpecial, but currently not on ApplySeeded. - Removes munging of reference genome function names: there is no longer a global registry of ""{function}_{rg}"" functions. - Minor: (bug) unify was previously being used without asserts (in apply methods on IRFunctions)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8538:54,Expose,Exposed,54,https://hail.is,https://github.com/hail-is/hail/pull/8538,1,['Expose'],['Exposed']
Security,"- Also moved the location of where buckets are mounted to not be in /batch so as to avoid accidentally deleting entire buckets.; - The file mode didn't do what I expected (allowed you to write to a bucket), but now that I think about it, we probably do want to expose this and my first intuition was right. We probably want files to be specified as read only when they're created on the local file system. I can make this a separate PR.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8979:261,expose,expose,261,https://hail.is,https://github.com/hail-is/hail/pull/8979,1,['expose'],['expose']
Security,"- Basic JSON format for NGINX access logs; - `message`, `remote_address`, `request_duration`, `response_status` and `x_real_ip` should match the Python Access logger so we should be able to query these fields all at once; - Unfortunately the NGINX `error_log` does not allow the same custom formatter, but we can create multiple, [custom access logs](https://www.nginx.com/blog/diagnostic-logging-nginx-javascript-module/#proxy_next_upstream) based on arbitrary failure criteria if there's a particular class of error logs we want to get in the future.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9928:30,access,access,30,https://hail.is,https://github.com/hail-is/hail/pull/9928,3,"['Access', 'access']","['Access', 'access']"
Security,"- Expose init_local.; - Fix formatting of some error messages (stray }).; - Fix index paths, they don't have a ""parts"" component, have "".idx"" suffix. This showed up as an issue interopreating between Spark and local modes. FYI @tpoterba rather than just testing them independently, it might be worthwhile to have write/read interop tests between the various backends. Spark to local is partially tested by the pre-existing (matrix)tables tests, but not the other way.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9596:2,Expose,Expose,2,https://hail.is,https://github.com/hail-is/hail/pull/9596,1,['Expose'],['Expose']
Security,- Expose the ability to permute dimensions on NDArrays in Python,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6059:2,Expose,Expose,2,https://hail.is,https://github.com/hail-is/hail/pull/6059,1,['Expose'],['Expose']
Security,"- Nested arrays appear to be supported in the current code, and I don't think this is intended.; - Why do exportFormat and exportInfo differ?; - Number is accessed from the field attrs without being checked. There could be something silly in there.; - Bad error messages (don't say which field was the problem)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1820:155,access,accessed,155,https://hail.is,https://github.com/hail-is/hail/issues/1820,1,['access'],['accessed']
Security,- Only batch for now -- will add for pipeline and ci later; - This should fail until the kubernetes secret is added; - Requires a password `CLOUD_SQL_PASSWORD` to run the tests locally; (not sure what the best way to distribute this is); - Requires downloading the `cloud_sql_proxy` binary to run the tests locally,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5615:130,password,password,130,https://hail.is,https://github.com/hail-is/hail/pull/5615,1,['password'],['password']
Security,"- Use the scorecard tag or design-docs tag to have Asana tasks show up in scorecard; - Easy to add different tags to track; - Currently using my personal access token. Not sure if that's ideal, but seemed fine for now.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9488:154,access,access,154,https://hail.is,https://github.com/hail-is/hail/pull/9488,1,['access'],['access']
Security,"- [x] Remove the reader permission created during testing. - [ ] Convert user service accounts permission from owner to read/write. - [ ] Give user email address read/write permissions to the bucket that we create on their behalf. - [ ] Ensure equivalent of chmod -R 600; right now appears that (at least) legacy owners don't have automatic, recursive read access to objects in their bucket.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5920:357,access,access,357,https://hail.is,https://github.com/hail-is/hail/issues/5920,1,['access'],['access']
Security,"- add PIndexableValue. This represents canonical array, set and dict values.; - use in ArrayRef; - newP{Local, FIeld} now has a `PV <: PValue` type parameter to eliminate some casting. Where I'm going:. There will be a abstract PValue with the interface for each virtual type (container/indexable, base struct, etc.) Each concrete PType will have a corresponding PValue implementation (in this case, PCanonicalArray is implemented by PCanonicalIndexableValue.) I think this will allow us to get rid of PArrayBackedContainer. Only primitive PValues will have a code method (since other types might be compound). The code generator should then dispatch through downcasts of PValues get access to the relevant methods.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8213:684,access,access,684,https://hail.is,https://github.com/hail-is/hail/pull/8213,1,['access'],['access']
Security,"- add ci database with 1 table: authorized_shas; - only start build if authorized author or source_sha is authorized; - form on main page to add authorized sha,; - unauthorized PRs are created, but not tested, and shown as unauthorized in UI",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6308:71,authoriz,authorized,71,https://hail.is,https://github.com/hail-is/hail/pull/6308,3,['authoriz'],['authorized']
Security,- added `entropy` to IR and wrote missing 0.2 documentation; - fixed entropy to handle the empty string correctly; - exposed the `sign` documentation; - made `NaN` consistently Python's `nan` in docs,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3793:117,expose,exposed,117,https://hail.is,https://github.com/hail-is/hail/pull/3793,1,['expose'],['exposed']
Security,- fixed structure of docs + links (hail/* -> docs/stable/*); - Added Hail version + supported spark versions + git hash as gradle variables; - Used these versions in Sphinx.; - Changed path of distribution links in getting started to point at current hash.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2034:115,hash,hash,115,https://hail.is,https://github.com/hail-is/hail/pull/2034,2,['hash'],['hash']
Security,"- hail/python/dev/pinned-requirements.txt. <details>; <summary>⚠️ <b>Warning</b></summary>. ```; jupyter 1.0.0 requires qtconsole, which is not installed.; jupyter 1.0.0 requires notebook, which is not installed.; beautifulsoup4 4.12.2 requires soupsieve, which is not installed.; argon2-cffi-bindings 21.2.0 requires cffi, which is not installed.; aiohttp-devtools 1.1 requires watchfiles, which is not installed. ```; </details>. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **663/1000** <br/> **Why?** Proof of Concept exploit, Recently disclosed, Has a fix available, CVSS 5.4 | Improper Input Validation <br/>[SNYK-PYTHON-AIOHTTP-6091621](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-6091621) | `aiohttp:` <br> `3.8.6 -> 3.9.0` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **663/1000** <br/> **Why?** Proof of Concept exploit, Recently disclosed, Has a fix available, CVSS 5.4 | Improper Input Validation <br/>[SNYK-PYTHON-AIOHTTP-6091622](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-6091622) | `aiohttp:` <br> `3.8.6 -> 3.9.0` <br> | No | Proof of Concept . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this b",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14042:1316,Validat,Validation,1316,https://hail.is,https://github.com/hail-is/hail/pull/14042,1,['Validat'],['Validation']
Security,"- made decoder stuff modular/composable; - CodecSpec, stored in RVDSpec (and hence in metadata) describes the en/decoding process; - exposed to Python (private parameter in MT and Table.write)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2859:133,expose,exposed,133,https://hail.is,https://github.com/hail-is/hail/pull/2859,1,['expose'],['exposed']
Security,"- new filter_alleles method: takes MT and lambda,; produces the fields needed to update row/entry fields; (old_to_new, new_to_old, old_locus, old_alleles); - subset_entries_hts and downcode_entries_hts are now; filter_alleles_hts, which calls filter_alleles.; - Exposed min_rep expr function in Python; - Added min_rep to AST FunctionRegistry (Scala); - Removed hl.min_rep method to minrep a MT (easy with the; function now); - Deleted FilterAlleles; - Deleted FilterAlleles (Scala); - Deleted minRep (Scala); - Moved MinRepSuite to Python",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3505:262,Expose,Exposed,262,https://hail.is,https://github.com/hail-is/hail/pull/3505,1,['Expose'],['Exposed']
Security,"---------------------------; Column key: ['s']; Row key: ['locus', 'alleles']; ----------------------------------------; [Stage 4:===================================================> (480 + 20) / 500]2020-04-05 14:09:48 Hail: INFO: Coerced almost-sorted dataset; [Stage 5:======================================================>(498 + 2) / 500]2020-04-05 14:09:50 Hail: INFO: Coerced almost-sorted dataset; [Stage 7:> (0 + 108) / 500]ERROR: [pid 11941] Worker Worker(salt=943636132, workers=1, host=seqr-loading-cluster-m, username=root, pid=11941) failed SeqrVCFToMTTask(source_paths=gs://seqr-bw/merged_phased_3P5CH.split.vcf.gz, dest_path=gs://seqr-bw/merged_phased_3P5CH.mt, genome_version=38, vep_runner=VEP, reference_ht_path=gs://seqr-reference-data/GRCh38/all_reference_data/combined_reference_data_grch38.ht, clinvar_ht_path=gs://seqr-reference-data/GRCh38/clinvar/clinvar.GRCh38.2020-03-29.ht, hgmd_ht_path=None, sample_type=WGS, validate=False, dataset_type=VARIANTS, remap_path=, subset_path=, vep_config_json_path=); Traceback (most recent call last):; File ""/opt/conda/default/lib/python3.6/site-packages/luigi/worker.py"", line 199, in run; new_deps = self._run_get_new_deps(); File ""/opt/conda/default/lib/python3.6/site-packages/luigi/worker.py"", line 141, in _run_get_new_deps; task_gen = self.task.run(); File ""/tmp/c7e0443c47b54e91b295e2bff7b554b9/seqr_loading.py"", line 54, in run; self.read_vcf_write_mt(); File ""/tmp/c7e0443c47b54e91b295e2bff7b554b9/seqr_loading.py"", line 84, in read_vcf_write_mt; mt.write(self.output().path, stage_locally=True, overwrite=True); File ""<decorator-gen-1092>"", line 2, in write; File ""/opt/conda/default/lib/python3.6/site-packages/hail/typecheck/check.py"", line 585, in wrapper; return __original_func(*args_, **kwargs_); File ""/opt/conda/default/lib/python3.6/site-packages/hail/matrixtable.py"", line 2529, in write; Env.backend().execute(MatrixWrite(self._mir, writer)); File ""/opt/conda/default/lib/python3.6/site-packages/hail/backend/backend",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8469:47366,validat,validate,47366,https://hail.is,https://github.com/hail-is/hail/issues/8469,1,['validat'],['validate']
Security,"-------------------------. Running on Ubuntu 18.04. I had installed openjdk-11-jre-headless instead of openjdk-8-jre-headless. ### Hail version:; 0.2 ; ### What you did:. ### What went wrong (all error messages here, including the full java stack trace):; 2018-12-04 22:13:57 root: ERROR: IllegalArgumentException: null; From java.lang.IllegalArgumentException: null; at org.apache.xbean.asm5.ClassReader.<init>(Unknown Source); at org.apache.xbean.asm5.ClassReader.<init>(Unknown Source); at org.apache.xbean.asm5.ClassReader.<init>(Unknown Source); at org.apache.spark.util.ClosureCleaner$.getClassReader(ClosureCleaner.scala:46); at org.apache.spark.util.FieldAccessFinder$$anon$3$$anonfun$visitMethodInsn$2.apply(ClosureCleaner.scala:443); at org.apache.spark.util.FieldAccessFinder$$anon$3$$anonfun$visitMethodInsn$2.apply(ClosureCleaner.scala:426); at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733); at scala.collection.mutable.HashMap$$anon$1$$anonfun$foreach$2.apply(HashMap.scala:103); at scala.collection.mutable.HashMap$$anon$1$$anonfun$foreach$2.apply(HashMap.scala:103); at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230); at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40); at scala.collection.mutable.HashMap$$anon$1.foreach(HashMap.scala:103); at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732); at org.apache.spark.util.FieldAccessFinder$$anon$3.visitMethodInsn(ClosureCleaner.scala:426); at org.apache.xbean.asm5.ClassReader.a(Unknown Source); at org.apache.xbean.asm5.ClassReader.b(Unknown Source); at org.apache.xbean.asm5.ClassReader.accept(Unknown Source); at org.apache.xbean.asm5.ClassReader.accept(Unknown Source); at org.apache.spark.util.ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$14.apply(ClosureCleaner.scala:257); at org.apache.spark.util.ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$14.apply(Closure",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4896:1191,Hash,HashMap,1191,https://hail.is,https://github.com/hail-is/hail/issues/4896,1,['Hash'],['HashMap']
Security,"----------------------|:-------------------------|:-------------------------|:-------------------------; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **471/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 3.7 | Improper Following of a Certificate&#x27;s Chain of Trust <br/>[SNYK-PYTHON-CERTIFI-5805047](https://snyk.io/vuln/SNYK-PYTHON-CERTIFI-5805047) | `certifi:` <br> `2023.5.7 -> 2023.7.22` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI1NDMwZTFmMi0wNDZjLTQwNDctYmI3Mi1hZmJkZmM1MDViNGEiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjU0MzBlMWYyLTA0NmMtNDA0Ny1iYjcyLWFmYmRmYzUwNWI0YSJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""5430e1f2-046c-4047-bb72-afbdfc505b4a"",""pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13304:1589,access,access,1589,https://hail.is,https://github.com/hail-is/hail/pull/13304,2,"['access', 'authoriz']","['access', 'authorized']"
Security,"----------------------|:-------------------------|:-------------------------|:-------------------------; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **471/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 3.7 | Improper Following of a Certificate&#x27;s Chain of Trust <br/>[SNYK-PYTHON-CERTIFI-5805047](https://snyk.io/vuln/SNYK-PYTHON-CERTIFI-5805047) | `certifi:` <br> `2023.5.7 -> 2023.7.22` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI3Mzc3ZjFlZS1kMjJjLTQ0MDAtYmE1Yy04NGNkYWZmZWJmYzgiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjczNzdmMWVlLWQyMmMtNDQwMC1iYTVjLTg0Y2RhZmZlYmZjOCJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/701495b8-b53d-48af-82fe-1a6c57aa56cb?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/701495b8-b53d-48af-82fe-1a6c57aa56cb?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""7377f1ee-d22c-4400-ba5c-84cdaffebfc8"",""pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13305:1572,access,access,1572,https://hail.is,https://github.com/hail-is/hail/pull/13305,2,"['access', 'authoriz']","['access', 'authorized']"
Security,"----------------------|:-------------------------|:-------------------------|:-------------------------; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **471/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 3.7 | Improper Following of a Certificate&#x27;s Chain of Trust <br/>[SNYK-PYTHON-CERTIFI-5805047](https://snyk.io/vuln/SNYK-PYTHON-CERTIFI-5805047) | `certifi:` <br> `2023.5.7 -> 2023.7.22` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJjMDQ5NzlhMC1iYWM3LTRiMjEtYmE0ZS02OWU5YjAzMTE5ZjAiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImMwNDk3OWEwLWJhYzctNGIyMS1iYTRlLTY5ZTliMDMxMTlmMCJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/7fad328c-8d01-4768-8813-73d6c644e2d4?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/7fad328c-8d01-4768-8813-73d6c644e2d4?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""c04979a0-bac7-4b21-ba4e-69e9b03119f0"",""pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13309:1574,access,access,1574,https://hail.is,https://github.com/hail-is/hail/pull/13309,2,"['access', 'authoriz']","['access', 'authorized']"
Security,"----------------------|:-------------------------|:-------------------------|:-------------------------; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **471/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 3.7 | Improper Following of a Certificate&#x27;s Chain of Trust <br/>[SNYK-PYTHON-CERTIFI-5805047](https://snyk.io/vuln/SNYK-PYTHON-CERTIFI-5805047) | `certifi:` <br> `2023.5.7 -> 2023.7.22` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJkY2E2ZDI1ZC1hZGM3LTRiNTctYWU3Zi0yNjExOTYzNTY5MmUiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImRjYTZkMjVkLWFkYzctNGI1Ny1hZTdmLTI2MTE5NjM1NjkyZSJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""dca6d25d-adc7-4b57-ae7f-26119635692e"",""pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13294:1581,access,access,1581,https://hail.is,https://github.com/hail-is/hail/pull/13294,2,"['access', 'authoriz']","['access', 'authorized']"
Security,"----------------------|:-------------------------|:-------------------------|:-------------------------; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **471/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 3.7 | Improper Following of a Certificate&#x27;s Chain of Trust <br/>[SNYK-PYTHON-CERTIFI-5805047](https://snyk.io/vuln/SNYK-PYTHON-CERTIFI-5805047) | `certifi:` <br> `2023.5.7 -> 2023.7.22` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJlMjNiYjk0OC04YjdmLTQ5MzUtYTRkMi05ZWJmNjg4NjZlMmUiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImUyM2JiOTQ4LThiN2YtNDkzNS1hNGQyLTllYmY2ODg2NmUyZSJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""e23bb948-8b7f-4935-a4d2-9ebf68866e2e"",""pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13316:1585,access,access,1585,https://hail.is,https://github.com/hail-is/hail/pull/13316,2,"['access', 'authoriz']","['access', 'authorized']"
Security,"----------------------|:-------------------------|:-------------------------|:-------------------------; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **471/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 3.7 | Improper Following of a Certificate&#x27;s Chain of Trust <br/>[SNYK-PYTHON-CERTIFI-5805047](https://snyk.io/vuln/SNYK-PYTHON-CERTIFI-5805047) | `certifi:` <br> `2023.5.7 -> 2023.7.22` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJmYWJiOGYzZi1mMDFjLTQxMjktODJjNC1kZjQzMjRmZTU4YTIiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImZhYmI4ZjNmLWYwMWMtNDEyOS04MmM0LWRmNDMyNGZlNThhMiJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/b72ce54d-5de3-48e5-a1d4-6f8967681a12?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/b72ce54d-5de3-48e5-a1d4-6f8967681a12?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""fabb8f3f-f01c-4129-82c4-df4324fe58a2"",""pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13296:1574,access,access,1574,https://hail.is,https://github.com/hail-is/hail/pull/13296,2,"['access', 'authoriz']","['access', 'authorized']"
Security,"------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **451/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 3.3 | NULL Pointer Dereference <br/>[SNYK-PYTHON-CRYPTOGRAPHY-6210214](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-6210214) | `cryptography:` <br> `41.0.7 -> 42.0.2` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI0Y2E5NmE2ZC02MjMxLTQ1YTctYmQyOS1kYTA0ZmZhNTliYzQiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjRjYTk2YTZkLTYyMzEtNDVhNy1iZDI5LWRhMDRmZmE1OWJjNCJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""4ca96a6d-6231-45a7-bd29-da04ffa59bc4"",""pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14238:1823,access,access,1823,https://hail.is,https://github.com/hail-is/hail/pull/14238,2,"['access', 'authoriz']","['access', 'authorized']"
Security,"------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **509/1000** <br/> **Why?** Has a fix available, CVSS 5.9 | Regular Expression Denial of Service (ReDoS) <br/>[SNYK-PYTHON-SETUPTOOLS-3180412](https://snyk.io/vuln/SNYK-PYTHON-SETUPTOOLS-3180412) | `setuptools:` <br> `39.0.1 -> 65.5.1` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI5NmE4NGVhMS1hYzgxLTQxYmEtOGYzNC02MGU1ZTdhYzNjZTMiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6Ijk2YTg0ZWExLWFjODEtNDFiYS04ZjM0LTYwZTVlN2FjM2NlMyJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""96a84ea1-ac81-41ba-8f34-60e5e7ac3ce3"",""pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12896:1690,access,access,1690,https://hail.is,https://github.com/hail-is/hail/pull/12896,2,"['access', 'authoriz']","['access', 'authorized']"
Security,"---------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **556/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 5.4 | Open Redirect <br/>[SNYK-PYTHON-TORNADO-5537286](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-5537286) | `tornado:` <br> `6.2 -> 6.3.2` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiIyOTUzNDFmZi1lMjQ4LTRiOTItYTY1Yy1kYjJiZWQ3ZDQxMGQiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjI5NTM0MWZmLWUyNDgtNGI5Mi1hNjVjLWRiMmJlZDdkNDEwZCJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/fa47fca0-549b-41a3-8bf7-bcda4ca9a617?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/fa47fca0-549b-41a3-8bf7-bcda4ca9a617?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""295341ff-e248-4b92-a65c-db2bed7d410d"",""pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13066:1672,access,access,1672,https://hail.is,https://github.com/hail-is/hail/pull/13066,2,"['access', 'authoriz']","['access', 'authorized']"
Security,"---------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **556/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 5.4 | Open Redirect <br/>[SNYK-PYTHON-TORNADO-5537286](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-5537286) | `tornado:` <br> `6.2 -> 6.3.2` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJlNTZiOGU3Ni1mMTk3LTQ0MmMtOGVlMC04MjFhMDk5YzM3YTAiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImU1NmI4ZTc2LWYxOTctNDQyYy04ZWUwLTgyMWEwOTljMzdhMCJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""e56b8e76-f197-442c-8ee0-821a099c37a0"",""pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13072:1446,access,access,1446,https://hail.is,https://github.com/hail-is/hail/pull/13072,2,"['access', 'authoriz']","['access', 'authorized']"
Security,"-------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **581/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 5.9 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-5663682](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5663682) | `cryptography:` <br> `40.0.2 -> 41.0.0` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJhYmU2OWI5ZC1kMzViLTQ1Y2ItYWY2NS04ZDEwN2YxZWMzZmMiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImFiZTY5YjlkLWQzNWItNDVjYi1hZjY1LThkMTA3ZjFlYzNmYyJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""abe69b9d-d35b-45cb-af65-8d107f1ec3fc"",""pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13139:1563,access,access,1563,https://hail.is,https://github.com/hail-is/hail/pull/13139,2,"['access', 'authoriz']","['access', 'authorized']"
Security,"-------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **581/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 5.9 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-5663682](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5663682) | `cryptography:` <br> `40.0.2 -> 41.0.0` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJjOTM3MTIxYy1lZTM3LTQ2ZmMtYTcxMC04MWY4YzdhZmUyN2IiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImM5MzcxMjFjLWVlMzctNDZmYy1hNzEwLTgxZjhjN2FmZTI3YiJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/701495b8-b53d-48af-82fe-1a6c57aa56cb?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/701495b8-b53d-48af-82fe-1a6c57aa56cb?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""c937121c-ee37-46fc-a710-81f8c7afe27b"",""pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13136:1554,access,access,1554,https://hail.is,https://github.com/hail-is/hail/pull/13136,2,"['access', 'authoriz']","['access', 'authorized']"
Security,"-------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **581/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 5.9 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-5663682](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5663682) | `cryptography:` <br> `40.0.2 -> 41.0.0` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJmZWM3ZmQ2Ny0xZmE0LTRlNzEtODQ4Ni1hMDk5YThmYWM3NzgiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImZlYzdmZDY3LTFmYTQtNGU3MS04NDg2LWEwOTlhOGZhYzc3OCJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""fec7fd67-1fa4-4e71-8486-a099a8fac778"",""pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13138:1479,access,access,1479,https://hail.is,https://github.com/hail-is/hail/pull/13138,2,"['access', 'authoriz']","['access', 'authorized']"
Security,"-------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **611/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 6.5 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-5914629](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5914629) | `cryptography:` <br> `41.0.3 -> 41.0.4` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJiN2QwMTZlZS0zODA0LTQwMjItOWE0Yi01MzExNjZhNjBjMWQiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImI3ZDAxNmVlLTM4MDQtNDAyMi05YTRiLTUzMTE2NmE2MGMxZCJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/701495b8-b53d-48af-82fe-1a6c57aa56cb?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/701495b8-b53d-48af-82fe-1a6c57aa56cb?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""b7d016ee-3804-4022-9a4b-531166a60c1d"",""pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13698:1554,access,access,1554,https://hail.is,https://github.com/hail-is/hail/pull/13698,2,"['access', 'authoriz']","['access', 'authorized']"
Security,"-------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **611/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 6.5 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-5914629](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5914629) | `cryptography:` <br> `41.0.3 -> 41.0.4` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJkNGViNWEyYS04NmZjLTRhZDQtYmM5MC1mZDViZWU4Mjg3YWUiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImQ0ZWI1YTJhLTg2ZmMtNGFkNC1iYzkwLWZkNWJlZTgyODdhZSJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""d4eb5a2a-86fc-4ad4-bc90-fd5bee8287ae"",""pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13701:1763,access,access,1763,https://hail.is,https://github.com/hail-is/hail/pull/13701,2,"['access', 'authoriz']","['access', 'authorized']"
Security,"-------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **611/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 6.5 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-5914629](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5914629) | `cryptography:` <br> `41.0.3 -> 41.0.4` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJmOTk4OWJlMC0yOWQ3LTQyYTctYTAzMC04NzljMTRmOGE2N2YiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImY5OTg5YmUwLTI5ZDctNDJhNy1hMDMwLTg3OWMxNGY4YTY3ZiJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""f9989be0-29d7-42a7-a030-879c14f8a67f"",""pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13700:1755,access,access,1755,https://hail.is,https://github.com/hail-is/hail/pull/13700,2,"['access', 'authoriz']","['access', 'authorized']"
Security,"------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **581/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 5.9 | NULL Pointer Dereference <br/>[SNYK-PYTHON-CRYPTOGRAPHY-6261585](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-6261585) | `cryptography:` <br> `42.0.2 -> 42.0.4` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI1MzAxOWZkZC04YjQwLTQ5NmUtYjRmYS0wMzA5MTAxOTBkZWMiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjUzMDE5ZmRkLThiNDAtNDk2ZS1iNGZhLTAzMDkxMDE5MGRlYyJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""53019fdd-8b40-496e-b4fa-030910190dec"",""pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14344:1829,access,access,1829,https://hail.is,https://github.com/hail-is/hail/pull/14344,2,"['access', 'authoriz']","['access', 'authorized']"
Security,"------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **581/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 5.9 | NULL Pointer Dereference <br/>[SNYK-PYTHON-CRYPTOGRAPHY-6261585](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-6261585) | `cryptography:` <br> `42.0.2 -> 42.0.4` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJiYWUwMDM5My05NGUzLTRhNjYtYTE5Ni0xMjUwZDg0ZGZiZDgiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImJhZTAwMzkzLTk0ZTMtNGE2Ni1hMTk2LTEyNTBkODRkZmJkOCJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/701495b8-b53d-48af-82fe-1a6c57aa56cb?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/701495b8-b53d-48af-82fe-1a6c57aa56cb?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""bae00393-94e3-4a66-a196-1250d84dfbd8"",""pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14343:1555,access,access,1555,https://hail.is,https://github.com/hail-is/hail/pull/14343,2,"['access', 'authoriz']","['access', 'authorized']"
Security,"-----------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **496/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 4.2 | Information Exposure Through Sent Data <br/>[SNYK-PYTHON-URLLIB3-6002459](https://snyk.io/vuln/SNYK-PYTHON-URLLIB3-6002459) | `urllib3:` <br> `1.26.17 -> 1.26.18` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI0MmRjMDIwMC02MDI1LTQ1M2QtYWUxNC00NDRlZjM5MmU4NTciLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjQyZGMwMjAwLTYwMjUtNDUzZC1hZTE0LTQ0NGVmMzkyZTg1NyJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""42dc0200-6025-453d-ae14-444ef392e857"",""pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13854:1834,access,access,1834,https://hail.is,https://github.com/hail-is/hail/pull/13854,2,"['access', 'authoriz']","['access', 'authorized']"
Security,"-----------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **496/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 4.2 | Information Exposure Through Sent Data <br/>[SNYK-PYTHON-URLLIB3-6002459](https://snyk.io/vuln/SNYK-PYTHON-URLLIB3-6002459) | `urllib3:` <br> `1.26.17 -> 1.26.18` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI3OWQ3MTdiYy05MThjLTRlMjctOGQ2OC0xNTNhNWIxZGFmM2YiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6Ijc5ZDcxN2JjLTkxOGMtNGUyNy04ZDY4LTE1M2E1YjFkYWYzZiJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""79d717bc-918c-4e27-8d68-153a5b1daf3f"",""pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13850:1832,access,access,1832,https://hail.is,https://github.com/hail-is/hail/pull/13850,2,"['access', 'authoriz']","['access', 'authorized']"
Security,"-----------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **496/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 4.2 | Information Exposure Through Sent Data <br/>[SNYK-PYTHON-URLLIB3-6002459](https://snyk.io/vuln/SNYK-PYTHON-URLLIB3-6002459) | `urllib3:` <br> `1.26.17 -> 1.26.18` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiIxNGQyZDIxMi00ZjI4LTQ0OGEtYWRkNS02NThkNDEwNzQxZDYiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjE0ZDJkMjEyLTRmMjgtNDQ4YS1hZGQ1LTY1OGQ0MTA3NDFkNiJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/b72ce54d-5de3-48e5-a1d4-6f8967681a12?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/b72ce54d-5de3-48e5-a1d4-6f8967681a12?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""14d2d212-4f28-448a-add5-658d410741d6"",""pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13847:1750,access,access,1750,https://hail.is,https://github.com/hail-is/hail/pull/13847,2,"['access', 'authoriz']","['access', 'authorized']"
Security,"-----------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **496/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 4.2 | Information Exposure Through Sent Data <br/>[SNYK-PYTHON-URLLIB3-6002459](https://snyk.io/vuln/SNYK-PYTHON-URLLIB3-6002459) | `urllib3:` <br> `1.26.17 -> 1.26.18` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiIyNWE2ZGYzMi1kYmEzLTQzOTctYmIyNC0zNjdlMzhmZWQ3ZmUiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjI1YTZkZjMyLWRiYTMtNDM5Ny1iYjI0LTM2N2UzOGZlZDdmZSJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/701495b8-b53d-48af-82fe-1a6c57aa56cb?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/701495b8-b53d-48af-82fe-1a6c57aa56cb?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""25a6df32-dba3-4397-bb24-367e38fed7fe"",""pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13848:1556,access,access,1556,https://hail.is,https://github.com/hail-is/hail/pull/13848,2,"['access', 'authoriz']","['access', 'authorized']"
Security,"-----------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **496/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 4.2 | Information Exposure Through Sent Data <br/>[SNYK-PYTHON-URLLIB3-6002459](https://snyk.io/vuln/SNYK-PYTHON-URLLIB3-6002459) | `urllib3:` <br> `1.26.17 -> 1.26.18` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJmNDI4YzVjNi05NmZmLTQ1ZTMtYjY4ZC0zYzU5NjY3MjA3MGUiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImY0MjhjNWM2LTk2ZmYtNDVlMy1iNjhkLTNjNTk2NjcyMDcwZSJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""f428c5c6-96ff-45e3-b68d-3c596672070e"",""pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13851:1826,access,access,1826,https://hail.is,https://github.com/hail-is/hail/pull/13851,2,"['access', 'authoriz']","['access', 'authorized']"
Security,"-----------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **581/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 5.9 | Information Exposure Through Sent Data <br/>[SNYK-PYTHON-URLLIB3-5926907](https://snyk.io/vuln/SNYK-PYTHON-URLLIB3-5926907) | `urllib3:` <br> `1.26.16 -> 1.26.17` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI3ZGVlZGFlMy1mZmE3LTQxYmUtOGY4MS1lNmYwZTA5YTczOTMiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjdkZWVkYWUzLWZmYTctNDFiZS04ZjgxLWU2ZjBlMDlhNzM5MyJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/701495b8-b53d-48af-82fe-1a6c57aa56cb?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/701495b8-b53d-48af-82fe-1a6c57aa56cb?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""7deedae3-ffa7-41be-8f81-e6f0e09a7393"",""pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13770:1556,access,access,1556,https://hail.is,https://github.com/hail-is/hail/pull/13770,2,"['access', 'authoriz']","['access', 'authorized']"
Security,"-----------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **581/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 5.9 | Information Exposure Through Sent Data <br/>[SNYK-PYTHON-URLLIB3-5926907](https://snyk.io/vuln/SNYK-PYTHON-URLLIB3-5926907) | `urllib3:` <br> `1.26.16 -> 1.26.17` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI4MmZhNTRjZC0yOGI4LTQ3OTUtYWFjNy02MDE0NjY3NjMwNTUiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjgyZmE1NGNkLTI4YjgtNDc5NS1hYWM3LTYwMTQ2Njc2MzA1NSJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/b72ce54d-5de3-48e5-a1d4-6f8967681a12?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/b72ce54d-5de3-48e5-a1d4-6f8967681a12?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""82fa54cd-28b8-4795-aac7-601466763055"",""pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13771:1750,access,access,1750,https://hail.is,https://github.com/hail-is/hail/pull/13771,2,"['access', 'authoriz']","['access', 'authorized']"
Security,"-----------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **581/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 5.9 | Information Exposure Through Sent Data <br/>[SNYK-PYTHON-URLLIB3-5926907](https://snyk.io/vuln/SNYK-PYTHON-URLLIB3-5926907) | `urllib3:` <br> `1.26.16 -> 1.26.17` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiIxOGU4YzI4Yi1kYWQ0LTQ5ZDUtOTExNi04NjFkYTdkODk5OTYiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjE4ZThjMjhiLWRhZDQtNDlkNS05MTE2LTg2MWRhN2Q4OTk5NiJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""18e8c28b-dad4-49d5-9116-861da7d89996"",""pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13773:1834,access,access,1834,https://hail.is,https://github.com/hail-is/hail/pull/13773,2,"['access', 'authoriz']","['access', 'authorized']"
Security,"-----------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **581/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 5.9 | Information Exposure Through Sent Data <br/>[SNYK-PYTHON-URLLIB3-5926907](https://snyk.io/vuln/SNYK-PYTHON-URLLIB3-5926907) | `urllib3:` <br> `1.26.16 -> 1.26.17` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJiNzM0YmY4Ni1mNzQyLTQyMjMtOWVlYS1lNGU3ZjNmMTVlYWMiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImI3MzRiZjg2LWY3NDItNDIyMy05ZWVhLWU0ZTdmM2YxNWVhYyJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""b734bf86-f742-4223-9eea-e4e7f3f15eac"",""pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13772:1764,access,access,1764,https://hail.is,https://github.com/hail-is/hail/pull/13772,2,"['access', 'authoriz']","['access', 'authorized']"
Security,"-----------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **581/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 5.9 | Information Exposure Through Sent Data <br/>[SNYK-PYTHON-URLLIB3-5926907](https://snyk.io/vuln/SNYK-PYTHON-URLLIB3-5926907) | `urllib3:` <br> `1.26.16 -> 1.26.17` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJiODhmOTA3Ny02ZjlmLTRiZjEtYjFiYy0yZjNkNTE1MDEwYWEiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImI4OGY5MDc3LTZmOWYtNGJmMS1iMWJjLTJmM2Q1MTUwMTBhYSJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""b88f9077-6f9f-4bf1-b1bc-2f3d515010aa"",""pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13783:1826,access,access,1826,https://hail.is,https://github.com/hail-is/hail/pull/13783,2,"['access', 'authoriz']","['access', 'authorized']"
Security,"----------|:-------------------------|:-------------------------|:-------------------------; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | **763/1000** <br/> **Why?** Proof of Concept exploit, Recently disclosed, Has a fix available, CVSS 7.4 | Improper Certificate Validation <br/>[SNYK-PYTHON-CRYPTOGRAPHY-5777683](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5777683) | `cryptography:` <br> `41.0.1 -> 41.0.2` <br> | No | Proof of Concept . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiIwMjJhZDMzNS1kYzBkLTQxZWYtYmRjYi03ZTFkODQwNWJhYTYiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjAyMmFkMzM1LWRjMGQtNDFlZi1iZGNiLTdlMWQ4NDA1YmFhNiJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""022ad335-dc0d-41ef-bdcb-7e1d8405baa6"",""pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13247:1593,access,access,1593,https://hail.is,https://github.com/hail-is/hail/pull/13247,2,"['access', 'authoriz']","['access', 'authorized']"
Security,"---------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | **661/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 7.5 | Relative Path Traversal <br/>[SNYK-PYTHON-ORJSON-6276643](https://snyk.io/vuln/SNYK-PYTHON-ORJSON-6276643) | `orjson:` <br> `3.9.7 -> 3.9.15` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI3YTljMjVmNy0wMTBmLTQxNmItYjc0OS1jNzFkY2I4YjY5YjgiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjdhOWMyNWY3LTAxMGYtNDE2Yi1iNzQ5LWM3MWRjYjhiNjliOCJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/e7c92c7b-5282-49ea-940f-7a5797e2a45a?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/e7c92c7b-5282-49ea-940f-7a5797e2a45a?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""7a9c25f7-010f-416b-b749-c71dcb8b69b8"",""pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14361:1541,access,access,1541,https://hail.is,https://github.com/hail-is/hail/pull/14361,2,"['access', 'authoriz']","['access', 'authorized']"
Security,"------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **566/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 5.6 | HTTP Request Smuggling <br/>[SNYK-PYTHON-TORNADO-5840803](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-5840803) | `tornado:` <br> `6.2 -> 6.3.3` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiIzYWE2MzZiYi00NmJmLTQ3MjgtOGVjMC0yMDg0OWE4NzgyZGMiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjNhYTYzNmJiLTQ2YmYtNDcyOC04ZWMwLTIwODQ5YTg3ODJkYyJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""3aa636bb-46bf-4728-8ec0-20849a8782dc"",""pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13444:1675,access,access,1675,https://hail.is,https://github.com/hail-is/hail/pull/13444,2,"['access', 'authoriz']","['access', 'authorized']"
Security,"-----|:-------------------------|:-------------------------|:-------------------------; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **461/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 3.5 | Generation of Error Message Containing Sensitive Information <br/>[SNYK-PYTHON-JUPYTERSERVER-6099119](https://snyk.io/vuln/SNYK-PYTHON-JUPYTERSERVER-6099119) | `jupyter-server:` <br> `1.24.0 -> 2.11.2` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI3MThjYjgyZC1jNGU3LTRlNWEtODgzZi02NjQ0NjlmYzA4MGEiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjcxOGNiODJkLWM0ZTctNGU1YS04ODNmLTY2NDQ2OWZjMDgwYSJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""718cb82d-c4e7-4e5a-883f-664469fc080a"",""pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14070:1986,access,access,1986,https://hail.is,https://github.com/hail-is/hail/pull/14070,2,"['access', 'authoriz']","['access', 'authorized']"
Security,"-----|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **658/1000** <br/> **Why?** Proof of Concept exploit, Recently disclosed, Has a fix available, CVSS 5.3 | HTTP Request Smuggling <br/>[SNYK-PYTHON-AIOHTTP-5798483](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-5798483) | `aiohttp:` <br> `3.8.4 -> 3.8.5` <br> | No | Proof of Concept . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI2ZWQ3MzlmOS1mZjc4LTQzYzgtYWQwOC05MThjNmRhMWNlOTYiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjZlZDczOWY5LWZmNzgtNDNjOC1hZDA4LTkxOGM2ZGExY2U5NiJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/b72ce54d-5de3-48e5-a1d4-6f8967681a12?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/b72ce54d-5de3-48e5-a1d4-6f8967681a12?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""6ed739f9-ff78-43c8-ad08-918c6da1ce96"",""pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13284:1564,access,access,1564,https://hail.is,https://github.com/hail-is/hail/pull/13284,2,"['access', 'authoriz']","['access', 'authorized']"
Security,"-----|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **658/1000** <br/> **Why?** Proof of Concept exploit, Recently disclosed, Has a fix available, CVSS 5.3 | HTTP Request Smuggling <br/>[SNYK-PYTHON-AIOHTTP-5798483](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-5798483) | `aiohttp:` <br> `3.8.4 -> 3.8.5` <br> | No | Proof of Concept . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI4YTljZTU5Zi0yOTY3LTQ2MTQtOGE5YS1iY2M5YjU1ZWZkZGQiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjhhOWNlNTlmLTI5NjctNDYxNC04YTlhLWJjYzliNTVlZmRkZCJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""8a9ce59f-2967-4614-8a9a-bcc9b55efddd"",""pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13282:1579,access,access,1579,https://hail.is,https://github.com/hail-is/hail/pull/13282,2,"['access', 'authoriz']","['access', 'authorized']"
Security,"-----|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **658/1000** <br/> **Why?** Proof of Concept exploit, Recently disclosed, Has a fix available, CVSS 5.3 | HTTP Request Smuggling <br/>[SNYK-PYTHON-AIOHTTP-5798483](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-5798483) | `aiohttp:` <br> `3.8.4 -> 3.8.5` <br> | No | Proof of Concept . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJjZmU2NDEwYi1jYjQ3LTQ2YzgtOTYwYy1kOWRlY2UxMjI5ZTIiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImNmZTY0MTBiLWNiNDctNDZjOC05NjBjLWQ5ZGVjZTEyMjllMiJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/b7c31419-ec34-40f1-8bc6-ad8303fb329b?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/b7c31419-ec34-40f1-8bc6-ad8303fb329b?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""cfe6410b-cb47-46c8-960c-d9dece1229e2"",""pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13286:1570,access,access,1570,https://hail.is,https://github.com/hail-is/hail/pull/13286,2,"['access', 'authoriz']","['access', 'authorized']"
Security,"-----|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **658/1000** <br/> **Why?** Proof of Concept exploit, Recently disclosed, Has a fix available, CVSS 5.3 | HTTP Request Smuggling <br/>[SNYK-PYTHON-AIOHTTP-5798483](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-5798483) | `aiohttp:` <br> `3.8.4 -> 3.8.5` <br> | No | Proof of Concept . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJlMjk5ZmU1Ni0wNGI1LTQ3MzEtYmUzYS03M2ZmYzgxZTZjYjgiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImUyOTlmZTU2LTA0YjUtNDczMS1iZTNhLTczZmZjODFlNmNiOCJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""e299fe56-04b5-4731-be3a-73ffc81e6cb8"",""pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13283:1571,access,access,1571,https://hail.is,https://github.com/hail-is/hail/pull/13283,2,"['access', 'authoriz']","['access', 'authorized']"
Security,"-----|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **658/1000** <br/> **Why?** Proof of Concept exploit, Recently disclosed, Has a fix available, CVSS 5.3 | HTTP Request Smuggling <br/>[SNYK-PYTHON-AIOHTTP-5798483](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-5798483) | `aiohttp:` <br> `3.8.4 -> 3.8.5` <br> | No | Proof of Concept . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJmZmEwNjUyZi1hMzc2LTQ0NmQtYWJjNC04NmJhMzUwNmY3MzMiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImZmYTA2NTJmLWEzNzYtNDQ2ZC1hYmM0LTg2YmEzNTA2ZjczMyJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/cbac91bd-aa95-4900-9a06-97404b268d6e?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/cbac91bd-aa95-4900-9a06-97404b268d6e?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""ffa0652f-a376-446d-abc4-86ba3506f733"",""pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13285:1565,access,access,1565,https://hail.is,https://github.com/hail-is/hail/pull/13285,2,"['access', 'authoriz']","['access', 'authorized']"
Security,"---:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **556/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 5.4 | Cross-site Scripting (XSS) <br/>[SNYK-PYTHON-JINJA2-6150717](https://snyk.io/vuln/SNYK-PYTHON-JINJA2-6150717) | `jinja2:` <br> `3.1.2 -> 3.1.3` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI0M2ViODJhZS04ZDkwLTRjZWUtYjIzMS01ZDMyYmZiZWM4OWEiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjQzZWI4MmFlLThkOTAtNGNlZS1iMjMxLTVkMzJiZmJlYzg5YSJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""43eb82ae-8d90-4cee-b231-5d32bfbec89a"",""pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14136:1803,access,access,1803,https://hail.is,https://github.com/hail-is/hail/pull/14136,2,"['access', 'authoriz']","['access', 'authorized']"
Security,"---:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **556/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 5.4 | Cross-site Scripting (XSS) <br/>[SNYK-PYTHON-JINJA2-6150717](https://snyk.io/vuln/SNYK-PYTHON-JINJA2-6150717) | `jinja2:` <br> `3.1.2 -> 3.1.3` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJlOTc1OTMyYy1kNmNhLTQ0NTUtYmU4ZC04NzY1ZGY0MTZjMWMiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImU5NzU5MzJjLWQ2Y2EtNDQ1NS1iZThkLTg3NjVkZjQxNmMxYyJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""e975932c-d6ca-4455-be8d-8765df416c1c"",""pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14141:2121,access,access,2121,https://hail.is,https://github.com/hail-is/hail/pull/14141,2,"['access', 'authoriz']","['access', 'authorized']"
Security,"---:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **556/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 5.4 | Cross-site Scripting (XSS) <br/>[SNYK-PYTHON-JINJA2-6150717](https://snyk.io/vuln/SNYK-PYTHON-JINJA2-6150717) | `jinja2:` <br> `3.1.2 -> 3.1.3` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJlYTQ5ODFkZC02M2FmLTQ4YzYtYTIwMC05NjkyZjg2ZTlhNjIiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImVhNDk4MWRkLTYzYWYtNDhjNi1hMjAwLTk2OTJmODZlOWE2MiJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/b7c31419-ec34-40f1-8bc6-ad8303fb329b?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/b7c31419-ec34-40f1-8bc6-ad8303fb329b?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""ea4981dd-63af-48c6-a200-9692f86e9a62"",""pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14140:1677,access,access,1677,https://hail.is,https://github.com/hail-is/hail/pull/14140,2,"['access', 'authoriz']","['access', 'authorized']"
Security,"-42010a8000af; spec:; containers:; - command:; - bash; - -c; - |-; set -e; gcloud -q auth activate-service-account --key-file=/test-gsa-key/privateKeyData; gsutil -m cp -r /test/resources/* gs://hail-test-1c9nm/sj0nb47zqys1/pipeline/input/; env:; - name: POD_IP; valueFrom:; fieldRef:; apiVersion: v1; fieldPath: status.podIP; - name: POD_NAME; valueFrom:; fieldRef:; apiVersion: v1; fieldPath: metadata.name; image: gcr.io/hail-vdc/ci-intermediate:oyyg6y2um4kx; imagePullPolicy: IfNotPresent; name: main; resources:; requests:; cpu: 100m; memory: 500M; terminationMessagePath: /dev/termination-log; terminationMessagePolicy: File; volumeMounts:; - mountPath: /test-gsa-key; name: test-gsa-key; - mountPath: /gsa-key; name: gsa-key; - mountPath: /var/run/secrets/kubernetes.io/serviceaccount; name: default-token-8h99c; readOnly: true; dnsPolicy: ClusterFirst; enableServiceLinks: true; nodeName: gke-vdc-preemptible-pool-9c7148b2-1f89; priority: 500000; priorityClassName: user; restartPolicy: Never; schedulerName: default-scheduler; securityContext: {}; serviceAccount: default; serviceAccountName: default; terminationGracePeriodSeconds: 30; tolerations:; - key: preemptible; value: ""true""; - effect: NoExecute; key: node.kubernetes.io/not-ready; operator: Exists; tolerationSeconds: 300; - effect: NoExecute; key: node.kubernetes.io/unreachable; operator: Exists; tolerationSeconds: 300; volumes:; - name: test-gsa-key; secret:; defaultMode: 420; optional: false; secretName: test-gsa-key; - name: gsa-key; secret:; defaultMode: 420; secretName: ci-gsa-key; - name: default-token-8h99c; secret:; defaultMode: 420; secretName: default-token-8h99c; status:; conditions:; - lastProbeTime: null; lastTransitionTime: ""2019-07-12T17:17:15Z""; status: ""True""; type: Initialized; - lastProbeTime: null; lastTransitionTime: ""2019-07-12T17:17:15Z""; message: 'containers with unready status: [main]'; reason: ContainersNotReady; status: ""False""; type: Ready; - lastProbeTime: null; lastTransitionTime: ""2019",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6625:4208,secur,securityContext,4208,https://hail.is,https://github.com/hail-is/hail/issues/6625,1,['secur'],['securityContext']
Security,"-6.2.4-with-strip-chr-prefix.zip/hail/java.py"", line 121, in handle_py4j; hail.java.FatalError: FileNotFoundException: File file:/tmp/clinvar.vcf.gz does not exist. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 0.0 failed 20 times, most recent failure: Lost task 0.19 in stage 0.0 (TID 19, without-vep-520334-sw-rmwj.c.seqr-project.internal): java.io.FileNotFoundException: File file:/tmp/clinvar.vcf.gz does not exist; at org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:611); at org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:824); at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:601); at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:428); at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:142); at org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:346); at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:769); at org.apache.hadoop.mapred.LineRecordReader.<init>(LineRecordReader.java:109); at org.apache.hadoop.mapred.TextInputFormat.getRecordReader(TextInputFormat.java:67); at org.apache.spark.rdd.HadoopRDD$$anon$1.<init>(HadoopRDD.scala:245); at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:208); at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:101); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.rdd.MapPartit",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3760:2015,Checksum,ChecksumFileSystem,2015,https://hail.is,https://github.com/hail-is/hail/issues/3760,1,['Checksum'],['ChecksumFileSystem']
Security,"-:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **591/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 6.1 | Information Exposure <br/>[SNYK-PYTHON-REQUESTS-5595532](https://snyk.io/vuln/SNYK-PYTHON-REQUESTS-5595532) | `requests:` <br> `2.28.2 -> 2.31.0` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI1ZDhmZDhmZC1mZGUxLTRiYmMtYWMzMi0xOTE1NmY0ZDFjZjIiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjVkOGZkOGZkLWZkZTEtNGJiYy1hYzMyLTE5MTU2ZjRkMWNmMiJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/7fad328c-8d01-4768-8813-73d6c644e2d4?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/7fad328c-8d01-4768-8813-73d6c644e2d4?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""5d8fd8fd-fde1-4bbc-ac32-19156f4d1cf2"",""pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13112:1541,access,access,1541,https://hail.is,https://github.com/hail-is/hail/pull/13112,2,"['access', 'authoriz']","['access', 'authorized']"
Security,"-:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **591/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 6.1 | Information Exposure <br/>[SNYK-PYTHON-REQUESTS-5595532](https://snyk.io/vuln/SNYK-PYTHON-REQUESTS-5595532) | `requests:` <br> `2.28.2 -> 2.31.0` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI2YzU3NmY1Yi1lNGM5LTQ4ZjctYmYxNy04YjEzOTIxODlmZDQiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjZjNTc2ZjViLWU0YzktNDhmNy1iZjE3LThiMTM5MjE4OWZkNCJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""6c576f5b-e4c9-48f7-bf17-8b1392189fd4"",""pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13097:1464,access,access,1464,https://hail.is,https://github.com/hail-is/hail/pull/13097,2,"['access', 'authoriz']","['access', 'authorized']"
Security,"-:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **591/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 6.1 | Information Exposure <br/>[SNYK-PYTHON-REQUESTS-5595532](https://snyk.io/vuln/SNYK-PYTHON-REQUESTS-5595532) | `requests:` <br> `2.28.2 -> 2.31.0` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiIwMzdiOGRmZS1hZDA4LTRmZjUtYTFkOC1hNGM4Nzg2N2NkYjAiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjAzN2I4ZGZlLWFkMDgtNGZmNS1hMWQ4LWE0Yzg3ODY3Y2RiMCJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""037b8dfe-ad08-4ff5-a1d8-a4c87867cdb0"",""pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13159:1556,access,access,1556,https://hail.is,https://github.com/hail-is/hail/pull/13159,2,"['access', 'authoriz']","['access', 'authorized']"
Security,"-:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **591/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 6.1 | Information Exposure <br/>[SNYK-PYTHON-REQUESTS-5595532](https://snyk.io/vuln/SNYK-PYTHON-REQUESTS-5595532) | `requests:` <br> `2.28.2 -> 2.31.0` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiIzM2VkMzM4Ny0zZTVmLTRkZDgtYjIxYy1iYzIyNzk4ODViZjMiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjMzZWQzMzg3LTNlNWYtNGRkOC1iMjFjLWJjMjI3OTg4NWJmMyJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/b72ce54d-5de3-48e5-a1d4-6f8967681a12?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/b72ce54d-5de3-48e5-a1d4-6f8967681a12?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""33ed3387-3e5f-4dd8-b21c-bc2279885bf3"",""pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13107:1449,access,access,1449,https://hail.is,https://github.com/hail-is/hail/pull/13107,2,"['access', 'authoriz']","['access', 'authorized']"
Security,"-:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **591/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 6.1 | Information Exposure <br/>[SNYK-PYTHON-REQUESTS-5595532](https://snyk.io/vuln/SNYK-PYTHON-REQUESTS-5595532) | `requests:` <br> `2.28.2 -> 2.31.0` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiIzYWEwNDk2OC02NDIxLTRmODktYTBjYy03MjE4MzExNDNiZGQiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjNhYTA0OTY4LTY0MjEtNGY4OS1hMGNjLTcyMTgzMTE0M2JkZCJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""3aa04968-6421-4f89-a0cc-721831143bdd"",""pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13100:1552,access,access,1552,https://hail.is,https://github.com/hail-is/hail/pull/13100,2,"['access', 'authoriz']","['access', 'authorized']"
Security,"-:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **591/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 6.1 | Information Exposure <br/>[SNYK-PYTHON-REQUESTS-5595532](https://snyk.io/vuln/SNYK-PYTHON-REQUESTS-5595532) | `requests:` <br> `2.28.2 -> 2.31.0` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJiNzM2NzI0Yi1hY2RiLTRiOTUtYWQwMy1hYWI3MjkyZGNlYzQiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImI3MzY3MjRiLWFjZGItNGI5NS1hZDAzLWFhYjcyOTJkY2VjNCJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""b736724b-acdb-4b95-ad03-aab7292dcec4"",""pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13116:1456,access,access,1456,https://hail.is,https://github.com/hail-is/hail/pull/13116,2,"['access', 'authoriz']","['access', 'authorized']"
Security,"-:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **591/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 6.1 | Information Exposure <br/>[SNYK-PYTHON-REQUESTS-5595532](https://snyk.io/vuln/SNYK-PYTHON-REQUESTS-5595532) | `requests:` <br> `2.28.2 -> 2.31.0` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJlNDQxZTBmNS1jZDQ4LTQzZDUtYTdkMy1kMTM4YzQ2ZTc2NTgiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImU0NDFlMGY1LWNkNDgtNDNkNS1hN2QzLWQxMzhjNDZlNzY1OCJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""e441e0f5-cd48-43d5-a7d3-d138c46e7658"",""pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13158:1548,access,access,1548,https://hail.is,https://github.com/hail-is/hail/pull/13158,2,"['access', 'authoriz']","['access', 'authorized']"
Security,"-:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **591/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 6.1 | Information Exposure <br/>[SNYK-PYTHON-REQUESTS-5595532](https://snyk.io/vuln/SNYK-PYTHON-REQUESTS-5595532) | `requests:` <br> `2.28.2 -> 2.31.0` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJlZjQxMWYxOC1hM2JiLTQ1YzgtODFjOS1hNmNhNjI4MWI1ZjMiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImVmNDExZjE4LWEzYmItNDVjOC04MWM5LWE2Y2E2MjgxYjVmMyJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/701495b8-b53d-48af-82fe-1a6c57aa56cb?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/701495b8-b53d-48af-82fe-1a6c57aa56cb?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""ef411f18-a3bb-45c8-81c9-a6ca6281b5f3"",""pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13108:1539,access,access,1539,https://hail.is,https://github.com/hail-is/hail/pull/13108,2,"['access', 'authoriz']","['access', 'authorized']"
Security,"-entryway.jar:?]; 		at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_382]; 		at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_382]; 		at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_382]; 		at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_382]; 		at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_382]; 		at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_382]; 		at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_382]; 	Caused by: com.google.api.client.http.HttpResponseException: 403 Forbidden; POST https://storage.googleapis.com/upload/storage/v1/b/neale-bge/o?name=foo.ht/index/part-0-c7ba7549-bf68-42db-a8ef-0f1b13721c79.idx/index&uploadType=resumable; {; ""error"": {; ""code"": 403,; ""message"": ""dking-ae4q6@hail-vdc.iam.gserviceaccount.com does not have storage.objects.create access to the Google Cloud Storage object. Permission 'storage.objects.create' denied on resource (or it may not exist)."",; ""errors"": [; {; ""message"": ""dking-ae4q6@hail-vdc.iam.gserviceaccount.com does not have storage.objects.create access to the Google Cloud Storage object. Permission 'storage.objects.create' denied on resource (or it may not exist)."",; ""domain"": ""global"",; ""reason"": ""forbidden""; }; ]; }; }. 		at com.google.api.client.http.HttpResponseException$Builder.build(HttpResponseException.java:293) ~[gs:__hail-query-ger0g_jars_b115f6a6ec23f111a4512b562b52d9f8a52ec41c.jar.jar:0.0.1-SNAPSHOT]; 		at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1118) ~[gs:__hail-query-ger0g_jars_b115f6a6ec23f111a4512b562b52d9f8a52ec41c.jar.jar:0.0.1-SNAPSHOT]; 		at is.hail.relocated.com.google.cloud.storage.spi.v1.HttpStorageRpc.open(HttpStorageRpc.java:1022) ~[gs:__hail-query-ger0g_jars_b115f6a6ec23f111a4512b562b52d9f8a52ec41c.jar.jar:0.0.1-SNAPSHOT]; 		... 48 more; Caused by: com.google.api.cl",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13697:26036,access,access,26036,https://hail.is,https://github.com/hail-is/hail/issues/13697,1,['access'],['access']
Security,"-java/commit/47e36b651e9abc80f8d711cbff69c821539851c2""><code>47e36b6</code></a> Updating CODEOWNERS for Communication Identity &amp; Common Packages (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-java/issues/32222"">#32222</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-java/commit/c051757b394000308e0a79bcb93da05875892401""><code>c051757</code></a> Increment package versions for cosmos releases (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-java/issues/32209"">#32209</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/Azure/azure-sdk-for-java/compare/v1.2.1...azure-identity_1.7.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=com.azure:azure-identity&package-manager=gradle&previous-version=1.2.1&new-version=1.7.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12508:4627,secur,security-vulnerabilities,4627,https://hail.is,https://github.com/hail-is/hail/pull/12508,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"-metadata/issues/46"">#46</a> from pytest-dev/pre-commit-ci-update-config</li>; <li><a href=""https://github.com/pytest-dev/pytest-metadata/commit/025be8999a22ae395b0e2b8ae4e7c9fa2334f874""><code>025be89</code></a> [pre-commit.ci] pre-commit autoupdate</li>; <li><a href=""https://github.com/pytest-dev/pytest-metadata/commit/429840f4de26276560961929f21aab79ed305875""><code>429840f</code></a> Avoid running nightly on forks</li>; <li><a href=""https://github.com/pytest-dev/pytest-metadata/commit/c1968f39609978ec9c6a4bcf91c37c6164483f04""><code>c1968f3</code></a> Fix nightly</li>; <li>See full diff in <a href=""https://github.com/pytest-dev/pytest-metadata/compare/v2.0.1...v2.0.2"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pytest-metadata&package-manager=pip&previous-version=2.0.1&new-version=2.0.2)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12188:2546,secur,security-vulnerabilities,2546,https://hail.is,https://github.com/hail-is/hail/pull/12188,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"-packages/hail/context.py"", line 345, in init; return init_spark(; File ""<decorator-gen-1760>"", line 2, in init_spark; File ""/opt/homebrew/lib/python3.10/site-packages/hail/typecheck/check.py"", line 577, in wrapper; return __original_func(*args_, **kwargs_); File ""/opt/homebrew/lib/python3.10/site-packages/hail/context.py"", line 424, in init_spark; backend = SparkBackend(; File ""/opt/homebrew/lib/python3.10/site-packages/hail/backend/spark_backend.py"", line 188, in __init__; self._jbackend = hail_package.backend.spark.SparkBackend.apply(; File ""/opt/homebrew/lib/python3.10/site-packages/py4j/java_gateway.py"", line 1304, in __call__; return_value = get_return_value(; File ""/opt/homebrew/lib/python3.10/site-packages/py4j/protocol.py"", line 326, in get_return_value; raise Py4JJavaError(; py4j.protocol.Py4JJavaError: An error occurred while calling z:is.hail.backend.spark.SparkBackend.apply.; : java.lang.IllegalAccessError: class org.apache.spark.storage.StorageUtils$ (in unnamed module @0x4d740d85) cannot access class sun.nio.ch.DirectBuffer (in module java.base) because module java.base does not export sun.nio.ch to unnamed module @0x4d740d85; 	at org.apache.spark.storage.StorageUtils$.<init>(StorageUtils.scala:213); 	at org.apache.spark.storage.StorageUtils$.<clinit>(StorageUtils.scala); 	at org.apache.spark.storage.BlockManagerMasterEndpoint.<init>(BlockManagerMasterEndpoint.scala:109); 	at org.apache.spark.SparkEnv$.$anonfun$create$9(SparkEnv.scala:371); 	at org.apache.spark.SparkEnv$.registerOrLookupEndpoint$1(SparkEnv.scala:311); 	at org.apache.spark.SparkEnv$.create(SparkEnv.scala:359); 	at org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:189); 	at org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:277); 	at org.apache.spark.SparkContext.<init>(SparkContext.scala:458); 	at is.hail.backend.spark.SparkBackend$.configureAndCreateSparkContext(SparkBackend.scala:148); 	at is.hail.backend.spark.SparkBackend$.apply(SparkBackend.scala:230); 	at is.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12630:1983,access,access,1983,https://hail.is,https://github.com/hail-is/hail/issues/12630,1,['access'],['access']
Security,"-session[aioredis]</code> then it will be necessary to manually install <code>redis</code>).</li>; </ul>; <h2>v2.11.0</h2>; <ul>; <li>Support initialising <code>EncryptedCookieStorage</code> with <code>Fernet</code> object directly.</li>; <li>Fix an issue where the session would get reset before the cookie expiry.</li>; </ul>; <h2>v2.10.0</h2>; <ul>; <li>Typing support</li>; <li>Add samesite cookie option</li>; <li>Support aioredis 2</li>; </ul>; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/aio-libs/aiohttp-session/blob/master/CHANGES.txt"">aiohttp-session's changelog</a>.</em></p>; <blockquote>; <h1>2.12.0 (2022-10-28)</h1>; <ul>; <li>Migrated from <code>aioredis</code> to <code>redis</code> (if using redis without installing; <code>aiohttp-session[aioredis]</code> then it will be necessary to manually install <code>redis</code>).</li>; </ul>; <h1>2.11.0 (2021-01-31)</h1>; <ul>; <li>Support initialising <code>EncryptedCookieStorage</code> with <code>Fernet</code> object directly.</li>; <li>Fix an issue where the session would get reset before the cookie expiry.</li>; </ul>; <h1>2.10.0 (2021-12-30)</h1>; <ul>; <li>Typing support</li>; <li>Add samesite cookie option</li>; <li>Support aioredis 2</li>; </ul>; <h1>2.9.0 (2019-11-04)</h1>; <ul>; <li>Fix memcached expiring time (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_session/issues/398"">#398</a>)</li>; </ul>; <h1>2.8.0 (2019-09-17)</h1>; <ul>; <li>Make this compatible with Python 3.7+. Import from collections.abc, instead; of from collections. (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_session/issues/373"">#373</a>)</li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/aio-libs/aiohttp-session/commit/4cedef7c62419de606aca7464a2e3247fdb0dd3c""><code>4cedef7</code></a> Release 2.12 (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_s",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12499:1405,Encrypt,EncryptedCookieStorage,1405,https://hail.is,https://github.com/hail-is/hail/pull/12499,1,['Encrypt'],['EncryptedCookieStorage']
Security,"-with-strip-chr-prefix.zip/hail/java.py"", line 121, in handle_py4j; hail.java.FatalError: FileNotFoundException: File file:/tmp/clinvar.vcf.gz does not exist. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 0.0 failed 20 times, most recent failure: Lost task 0.19 in stage 0.0 (TID 19, without-vep-520334-sw-rmwj.c.seqr-project.internal): java.io.FileNotFoundException: File file:/tmp/clinvar.vcf.gz does not exist; 	at org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:611); 	at org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:824); 	at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:601); 	at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:428); 	at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:142); 	at org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:346); 	at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:769); 	at org.apache.hadoop.mapred.LineRecordReader.<init>(LineRecordReader.java:109); 	at org.apache.hadoop.mapred.TextInputFormat.getRecordReader(TextInputFormat.java:67); 	at org.apache.spark.rdd.HadoopRDD$$anon$1.<init>(HadoopRDD.scala:245); 	at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:208); 	at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:101); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); 	at org.apache.spar",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3760:5856,Checksum,ChecksumFileSystem,5856,https://hail.is,https://github.com/hail-is/hail/issues/3760,1,['Checksum'],['ChecksumFileSystem']
Security,"-|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | **661/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 7.5 | Improper Neutralization of Special Elements in Data Query Logic <br/>[SNYK-PYTHON-MSAL-5904284](https://snyk.io/vuln/SNYK-PYTHON-MSAL-5904284) | `msal:` <br> `1.24.0 -> 1.24.1` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI2NWVkZTk2ZC0xYjZkLTQ1ZjktOTU3OC00NzdjMWNmNDhiZmQiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjY1ZWRlOTZkLTFiNmQtNDVmOS05NTc4LTQ3N2MxY2Y0OGJmZCJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""65ede96d-1b6d-45f9-9578-477c1cf48bfd"",""pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13754:1844,access,access,1844,https://hail.is,https://github.com/hail-is/hail/pull/13754,2,"['access', 'authoriz']","['access', 'authorized']"
Security,"-|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | **661/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 7.5 | Improper Neutralization of Special Elements in Data Query Logic <br/>[SNYK-PYTHON-MSAL-5904284](https://snyk.io/vuln/SNYK-PYTHON-MSAL-5904284) | `msal:` <br> `1.24.0 -> 1.24.1` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJhYjlhNGM2ZS0xOTg1LTRmYTctYjg0OC0zOTNmOWE3MGJkMWEiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImFiOWE0YzZlLTE5ODUtNGZhNy1iODQ4LTM5M2Y5YTcwYmQxYSJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""ab9a4c6e-1985-4fa7-b848-393f9a70bd1a"",""pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13753:1836,access,access,1836,https://hail.is,https://github.com/hail-is/hail/pull/13753,2,"['access', 'authoriz']","['access', 'authorized']"
Security,". ### Notes of Annoyance. `aiohttp` silently ignores most invalid TLS requests, this makes debugging a TLS; issue difficult. `aiohttp`'s `raise_for_status` does not include the HTTP body in the; message. NGINX sometimes returns 400 in response to TLS issues with a proxy. It; includes crucial details in the HTTP body. I usually debug these issues by; sshing to the client pod and using curl to manually reproduce the error. Readiness and liveness probes cannot use HTTP. Although k8s supports HTTPS, it; does not support so-called ""mTLS"" or ""mutual TLS."" This is fancy verbiage for; servers that require clients to send trusted certificates. I will eventually require; this. There is a lot of information in GitHub issues and the Istio web pages; about this, but at the end of the day, kubernetes does not support this. TCP; probes are the best we can do. There [was a; PR](kubernetes/kubernetes#61231) to allow httpGet probes; to send the kubelet certificate, but it was closed because, apparently, the; [httpGet probes can be targeted at arbitrary IP; addresses](kubernetes/kubernetes#61231 (review)) (what; the hell?), ergo Confused Deputy. ### Future Work. - Require TLS 1.3 everywhere.; - Comply with Mozilla's ""Modern"" recommendations.; - [Incoming Trust](#incoming-trust).; - Refresh certificates after deploying new ones. ### Footnotes. [1] TLS: Transport Layer Security. Preceded by Secure Sockets Layer (SSL) which; is not obsolete and insecure. After SSL version 3, a new version of SSL was; proposed in RFC 2246. This new version was backwards-incompatible and was; thus given a new name: Transport Layer Security. In common discussion, SSL; and TLS are used interchangeable. Indeed, the python TLS library is called; `ssl`. [2] Forward secrecy is a property of an encryption system. Forward secrecy means; a message cannot be decrypted in the future by an adversary who learned one; of the private keys. For example, imagine you are sending sensitive messages; to another individual. If",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8561:11152,certificate,certificate,11152,https://hail.is,https://github.com/hail-is/hail/pull/8561,1,['certificate'],['certificate']
Security,". ### What went wrong (all error messages here, including the full java stack trace):; 2018-12-04 22:13:57 root: ERROR: IllegalArgumentException: null; From java.lang.IllegalArgumentException: null; at org.apache.xbean.asm5.ClassReader.<init>(Unknown Source); at org.apache.xbean.asm5.ClassReader.<init>(Unknown Source); at org.apache.xbean.asm5.ClassReader.<init>(Unknown Source); at org.apache.spark.util.ClosureCleaner$.getClassReader(ClosureCleaner.scala:46); at org.apache.spark.util.FieldAccessFinder$$anon$3$$anonfun$visitMethodInsn$2.apply(ClosureCleaner.scala:443); at org.apache.spark.util.FieldAccessFinder$$anon$3$$anonfun$visitMethodInsn$2.apply(ClosureCleaner.scala:426); at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733); at scala.collection.mutable.HashMap$$anon$1$$anonfun$foreach$2.apply(HashMap.scala:103); at scala.collection.mutable.HashMap$$anon$1$$anonfun$foreach$2.apply(HashMap.scala:103); at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230); at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40); at scala.collection.mutable.HashMap$$anon$1.foreach(HashMap.scala:103); at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732); at org.apache.spark.util.FieldAccessFinder$$anon$3.visitMethodInsn(ClosureCleaner.scala:426); at org.apache.xbean.asm5.ClassReader.a(Unknown Source); at org.apache.xbean.asm5.ClassReader.b(Unknown Source); at org.apache.xbean.asm5.ClassReader.accept(Unknown Source); at org.apache.xbean.asm5.ClassReader.accept(Unknown Source); at org.apache.spark.util.ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$14.apply(ClosureCleaner.scala:257); at org.apache.spark.util.ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$14.apply(ClosureCleaner.scala:256); at scala.collection.immutable.List.foreach(List.scala:381); at org.apache.spark.util.ClosureCleaner$.org$apache$spark$util$ClosureCleaner$$clean(Clo",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4896:1369,Hash,HashTable,1369,https://hail.is,https://github.com/hail-is/hail/issues/4896,1,['Hash'],['HashTable']
Security,". (<a href=""https://github-redirect.dependabot.com/tomplus/kubernetes_asyncio/issues/206"">#206</a>)</li>; <li><a href=""https://github.com/tomplus/kubernetes_asyncio/commit/308f153f91b7942476f2d4ddda3dc8c99933d598""><code>308f153</code></a> ci: add workflow to publish sdist/wheel to PyPI (<a href=""https://github-redirect.dependabot.com/tomplus/kubernetes_asyncio/issues/202"">#202</a>)</li>; <li><a href=""https://github.com/tomplus/kubernetes_asyncio/commit/961624063383cbcdc78a61b1d18448429a61a489""><code>9616240</code></a> [chore] update changelog</li>; <li>Additional commits viewable in <a href=""https://github.com/tomplus/kubernetes_asyncio/compare/v19.15.1...23.6.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=kubernetes-asyncio&package-manager=pip&previous-version=19.15.1&new-version=23.6.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11957:15811,secur,security-vulnerabilities,15811,https://hail.is,https://github.com/hail-is/hail/pull/11957,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,". Running on Ubuntu 18.04. I had installed openjdk-11-jre-headless instead of openjdk-8-jre-headless. ### Hail version:; 0.2 ; ### What you did:. ### What went wrong (all error messages here, including the full java stack trace):; 2018-12-04 22:13:57 root: ERROR: IllegalArgumentException: null; From java.lang.IllegalArgumentException: null; at org.apache.xbean.asm5.ClassReader.<init>(Unknown Source); at org.apache.xbean.asm5.ClassReader.<init>(Unknown Source); at org.apache.xbean.asm5.ClassReader.<init>(Unknown Source); at org.apache.spark.util.ClosureCleaner$.getClassReader(ClosureCleaner.scala:46); at org.apache.spark.util.FieldAccessFinder$$anon$3$$anonfun$visitMethodInsn$2.apply(ClosureCleaner.scala:443); at org.apache.spark.util.FieldAccessFinder$$anon$3$$anonfun$visitMethodInsn$2.apply(ClosureCleaner.scala:426); at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733); at scala.collection.mutable.HashMap$$anon$1$$anonfun$foreach$2.apply(HashMap.scala:103); at scala.collection.mutable.HashMap$$anon$1$$anonfun$foreach$2.apply(HashMap.scala:103); at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230); at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40); at scala.collection.mutable.HashMap$$anon$1.foreach(HashMap.scala:103); at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732); at org.apache.spark.util.FieldAccessFinder$$anon$3.visitMethodInsn(ClosureCleaner.scala:426); at org.apache.xbean.asm5.ClassReader.a(Unknown Source); at org.apache.xbean.asm5.ClassReader.b(Unknown Source); at org.apache.xbean.asm5.ClassReader.accept(Unknown Source); at org.apache.xbean.asm5.ClassReader.accept(Unknown Source); at org.apache.spark.util.ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$14.apply(ClosureCleaner.scala:257); at org.apache.spark.util.ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$14.apply(ClosureCleaner.scala:256); at s",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4896:1232,Hash,HashMap,1232,https://hail.is,https://github.com/hail-is/hail/issues/4896,1,['Hash'],['HashMap']
Security,"..</li>; <li><a href=""https://github.com/apache/spark/commit/be891ad99083564a7bf7f421e00b2cc4759a679f""><code>be891ad</code></a> [SPARK-39551][SQL][3.2] Add AQE invalid plan check</li>; <li><a href=""https://github.com/apache/spark/commit/1c0bd4c15a28d7c6a2dca846a5b8d0eb1d152aae""><code>1c0bd4c</code></a> [SPARK-39656][SQL][3.2] Fix wrong namespace in DescribeNamespaceExec</li>; <li><a href=""https://github.com/apache/spark/commit/3d084fe3217bea9af4c544f10ead8a2e5b97dad4""><code>3d084fe</code></a> [SPARK-39677][SQL][DOCS][3.2] Fix args formatting of the regexp and like func...</li>; <li>Additional commits viewable in <a href=""https://github.com/apache/spark/compare/v3.1.3...v3.2.2"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pyspark&package-manager=pip&previous-version=3.1.3&new-version=3.2.2)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12452:2464,secur,security-vulnerabilities,2464,https://hail.is,https://github.com/hail-is/hail/pull/12452,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,".1 (2022-08-04)</h2>; <h3>Bugs Fixed</h3>; <ul>; <li>Fixed two rare issues with ranged blob download when using client-side encryption V1 or V2.</li>; </ul>; <h2>azure-storage-blob_12.13.0</h2>; <h2>12.13.0 (2022-07-07)</h2>; <h3>Bugs Fixed</h3>; <ul>; <li>Stable release of features from 12.13.0b1.</li>; <li>Added support for deleting versions in <code>delete_blobs</code> by supplying <code>version_id</code>.</li>; </ul>; <h2>azure-storage-blob_12.13.0b1</h2>; <h2>12.13.0b1 (2022-06-15)</h2>; <h3>Features Added</h3>; <ul>; <li>Added support for service version 2021-08-06.</li>; <li>Added a new version of client-side encryption for blobs (version 2.0) which utilizes AES-GCM-256 encryption.; If you are currently using client-side encryption, it is <strong>highly recommended</strong> to switch to a form of server-side; encryption (Customer-Provided Key, Encryption Scope, etc.) or version 2.0 of client-side encryption. The encryption; version can be specified on any client constructor via the <code>encryption_version</code> keyword (<code>encryption_version='2.0'</code>).</li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/13989b5b1253e26f3f3ee24013a3013fea1bdf73""><code>13989b5</code></a> [Storage] Fix ranged download for client-side encryption (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/25522"">#25522</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/e90af4374bfd7c139737ad2888fcd269b3023520""><code>e90af43</code></a> DataLake funny dependency (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/25129"">#25129</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/cbec3383039ffeb46760268d1a8f81cf1b4d2219""><code>cbec338</code></a> [AutoRelease] t2-storagecache-2022-07-06-35884(Do not merge) (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-pyt",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12109:1268,encrypt,encryption,1268,https://hail.is,https://github.com/hail-is/hail/pull/12109,1,['encrypt'],['encryption']
Security,".1.; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/java-native-access/jna/blob/master/CHANGES.md"">jna's changelog</a>.</em></p>; <blockquote>; <h1>Release 5.12.1</h1>; <h2>Bug Fixes</h2>; <ul>; <li><a href=""https://github-redirect.dependabot.com/java-native-access/jna/issues/1447"">#1447</a>: Null-check cleanable in <code>c.s.j.Memory#close</code> - <a href=""https://github.com/dbwiddis""><code>@​dbwiddis</code></a>.</li>; </ul>; <h1>Release 5.12.0</h1>; <h2>Features</h2>; <ul>; <li><a href=""https://github-redirect.dependabot.com/java-native-access/jna/pull/1433"">#1433</a>: Add <code>CFEqual</code>, <code>CFDictionaryRef.ByReference</code>, <code>CFStringRef.ByReference</code> to <code>c.s.j.p.mac.CoreFoundation</code> - <a href=""https://github.com/shalupov""><code>@​shalupov</code></a></li>; <li><a href=""https://github-redirect.dependabot.com/java-native-access/jna/issues/978"">#978</a>: Remove use of finalizers in JNA and improve concurrency for <code>Memory</code>, <code>CallbackReference</code> and <code>NativeLibrary</code> - <a href=""https://github.com/matthiasblaesing""><code>@​matthiasblaesing</code></a>.</li>; <li><a href=""https://github-redirect.dependabot.com/java-native-access/jna/pull/1440"">#1440</a>: Support for LoongArch64 - <a href=""https://github.com/Panxuefeng-loongson""><code>@​Panxuefeng-loongson</code></a>.</li>; <li><a href=""https://github-redirect.dependabot.com/java-native-access/jna/pull/1444"">#1444</a>: Update embedded libffi to 1f14b3fa92d4442a60233e9596ddec428a985e3c and rebuild native libraries - <a href=""https://github.com/matthiasblaesing""><code>@​matthiasblaesing</code></a>.</li>; </ul>; <h2>Bug Fixes</h2>; <ul>; <li><a href=""https://github-redirect.dependabot.com/java-native-access/jna/pull/1438"">#1438</a>: Handle arrays in structures with differing size - <a href=""https://github.com/matthiasblaesing""><code>@​matthiasblaesing</code></a>.</li>; <li><a href=""https://github-redirect.dependabot.com/jav",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12438:980,access,access,980,https://hail.is,https://github.com/hail-is/hail/pull/12438,1,['access'],['access']
Security,".16"",""to"":""6.4.12""},{""name"":""pygments"",""from"":""2.5.2"",""to"":""2.15.0""},{""name"":""requests"",""from"":""2.27.1"",""to"":""2.31.0""},{""name"":""setuptools"",""from"":""39.0.1"",""to"":""65.5.1""},{""name"":""sphinx"",""from"":""1.8.6"",""to"":""3.3.0""},{""name"":""tornado"",""from"":""5.1.1"",""to"":""6.3.3""},{""name"":""wheel"",""from"":""0.30.0"",""to"":""0.38.0""}],""packageManager"":""pip"",""projectPublicId"":""fa47fca0-549b-41a3-8bf7-bcda4ca9a617"",""projectUrl"":""https://app.snyk.io/org/danking/project/fa47fca0-549b-41a3-8bf7-bcda4ca9a617?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-CERTIFI-3164749"",""SNYK-PYTHON-CERTIFI-5805047"",""SNYK-PYTHON-IPYTHON-2348630"",""SNYK-PYTHON-IPYTHON-3318382"",""SNYK-PYTHON-JUPYTERCORE-3063766"",""SNYK-PYTHON-MISTUNE-2940625"",""SNYK-PYTHON-NBCONVERT-2979829"",""SNYK-PYTHON-NOTEBOOK-1041707"",""SNYK-PYTHON-NOTEBOOK-2441824"",""SNYK-PYTHON-NOTEBOOK-2928995"",""SNYK-PYTHON-PYGMENTS-1086606"",""SNYK-PYTHON-PYGMENTS-1088505"",""SNYK-PYTHON-PYGMENTS-5750273"",""SNYK-PYTHON-REQUESTS-5595532"",""SNYK-PYTHON-SETUPTOOLS-3180412"",""SNYK-PYTHON-SPHINX-570772"",""SNYK-PYTHON-SPHINX-570773"",""SNYK-PYTHON-SPHINX-5811865"",""SNYK-PYTHON-SPHINX-5812109"",""SNYK-PYTHON-TORNADO-5537286"",""SNYK-PYTHON-TORNADO-5840803"",""SNYK-PYTHON-TORNADO-6041512"",""SNYK-PYTHON-WHEEL-3180413""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""pr-warning-shown"",""priorityScore""],""priorityScoreList"":[554,704,624,531,604,589,726,434,589,449,696,589,479,519,509,711,701,586,586,384,494,539,589],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Remote Code Execution (RCE)](https://learn.snyk.io/lesson/improper-input-validation/?loc&#x3D;fix-pr); 🦉 [Improper Privilege Management](https://learn.snyk.io/lesson/insecure-design/?loc&#x3D;fix-pr); 🦉 [Regular Expression Denial of Service (ReDoS)](https://learn.snyk.io/lesson/redos/?loc&#x3D;fix-pr); 🦉 [More lessons are available in Snyk Learn](https://learn.snyk.io/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14108:12931,validat,validation,12931,https://hail.is,https://github.com/hail-is/hail/pull/14108,1,['validat'],['validation']
Security,".16.2 to 2.16.4 (<a href=""https://redirect.github.com/aio-libs/aiohttp/issues/8092"">#8092</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/5ff4b3c405ee741a46d6743209cd32259f939313""><code>5ff4b3c</code></a> Update version</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/94462eea445d43bf574ca6321349f67219ce9cb0""><code>94462ee</code></a> [PR <a href=""https://redirect.github.com/aio-libs/aiohttp/issues/3957"">#3957</a>/79fe2045 backport][3.9] Improve test suite handling of paths, temp ...</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/24a6d64966d99182e95f5d3a29541ef2fec397ad""><code>24a6d64</code></a> Release v3.9.2 (<a href=""https://redirect.github.com/aio-libs/aiohttp/issues/8082"">#8082</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/9118a5831e8a65b8c839eb7e4ac983e040ff41df""><code>9118a58</code></a> [PR <a href=""https://redirect.github.com/aio-libs/aiohttp/issues/8079"">#8079</a>/1c335944 backport][3.9] Validate static paths (<a href=""https://redirect.github.com/aio-libs/aiohttp/issues/8080"">#8080</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/435ad46e6c26cbf6ed9a38764e9ba8e7441a0e3b""><code>435ad46</code></a> [PR <a href=""https://redirect.github.com/aio-libs/aiohttp/issues/3955"">#3955</a>/8960063e backport][3.9] Replace all tmpdir fixtures with tmp_path (...</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/d33bc21414e283c9e6fe7f6caf69e2ed60d66c82""><code>d33bc21</code></a> Improve validation in HTTP parser (<a href=""https://redirect.github.com/aio-libs/aiohttp/issues/8074"">#8074</a>) (<a href=""https://redirect.github.com/aio-libs/aiohttp/issues/8078"">#8078</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/0d945d1be08f2ba8475513216a66411f053c3217""><code>0d945d1</code></a> [PR <a href=""https://redirect.github.com/aio-libs/aiohttp/issues/7916"">#7916</a>/822fbc74 backport][3.9] Add more information to contributing page (...</li>; <li>Additional commits viewable i",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14219:4845,Validat,Validate,4845,https://hail.is,https://github.com/hail-is/hail/pull/14219,2,['Validat'],['Validate']
Security,".9.19...</li>; <li><a href=""https://github.com/googleapis/java-storage/commit/7d6742115bcea6b848a289fdf5c4e4bbafc4cf18""><code>7d67421</code></a> build(deps): update dependency com.google.cloud:google-cloud-shared-config to...</li>; <li><a href=""https://github.com/googleapis/java-storage/commit/3bf403e94c035e6cf936e062a1ced2b5221b3912""><code>3bf403e</code></a> deps: update dependency org.apache.httpcomponents:httpcore to v4.4.16 (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1786"">#1786</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/googleapis/java-storage/compare/v1.106.0...v2.16.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=com.google.cloud:google-cloud-storage&package-manager=gradle&previous-version=1.106.0&new-version=2.16.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12545:13073,secur,security-vulnerabilities,13073,https://hail.is,https://github.com/hail-is/hail/pull/12545,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,".; <p>.. _v41-0-0:</p>; <p>41.0.0 - 2023-05-30; </code></pre></p>; <ul>; <li><strong>BACKWARDS INCOMPATIBLE:</strong> Support for OpenSSL less than 1.1.1d has been; removed. Users on older version of OpenSSL will need to upgrade.</li>; <li><strong>BACKWARDS INCOMPATIBLE:</strong> Support for Python 3.6 has been removed.</li>; <li><strong>BACKWARDS INCOMPATIBLE:</strong> Dropped support for LibreSSL &lt; 3.6.</li>; <li>Updated the minimum supported Rust version (MSRV) to 1.56.0, from 1.48.0.</li>; <li>Updated Windows, macOS, and Linux wheels to be compiled with OpenSSL 3.1.1.</li>; <li>Added support for the :class:<code>~cryptography.x509.OCSPAcceptableResponses</code>; OCSP extension.</li>; <li>Added support for the :class:<code>~cryptography.x509.MSCertificateTemplate</code>; proprietary Microsoft certificate extension.</li>; <li>Implemented support for equality checks on all asymmetric public key types.</li>; <li>Added support for <code>aes256-gcm@openssh.com</code> encrypted keys in; :func:<code>~cryptography.hazmat.primitives.serialization.load_ssh_private_key</code>.</li>; <li>Added support for obtaining X.509 certificate signature algorithm parameters; (including PSS) via; :meth:<code>~cryptography.x509.Certificate.signature_algorithm_parameters</code>.</li>; <li>Support signing :class:<code>~cryptography.hazmat.primitives.asymmetric.padding.PSS</code>; X.509 certificates via the new keyword-only argument <code>rsa_padding</code> on; :meth:<code>~cryptography.x509.CertificateBuilder.sign</code>.</li>; <li>Added support for; :class:<code>~cryptography.hazmat.primitives.ciphers.aead.ChaCha20Poly1305</code>; on BoringSSL.</li>; </ul>; <p>.. _v40-0-2:</p>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/pyca/cryptography/commit/d02de9f26e9a2353e89427c1cea8b9ed2bae969e""><code>d02de9f</code></a> changelog and version bump (<a href=""https://redirect.github.com/pyca/cryptography/issues/9008"">#9008</a>)</li>; <li>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13146:1494,encrypt,encrypted,1494,https://hail.is,https://github.com/hail-is/hail/pull/13146,1,['encrypt'],['encrypted']
Security,".; argon2-cffi-bindings 21.2.0 requires cffi, which is not installed.; aiosignal 1.3.1 requires frozenlist, which is not installed. ```; </details>. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **531/1000** <br/> **Why?** Proof of Concept exploit, Has a fix available, CVSS 4.2 | Remote Code Execution (RCE) <br/>[SNYK-PYTHON-IPYTHON-3318382](https://snyk.io/vuln/SNYK-PYTHON-IPYTHON-3318382) | `ipython:` <br> `7.34.0 -> 8.10.0` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **/1000** <br/> **Why?** | Access Control Bypass <br/>[SNYK-PYTHON-JUPYTERSERVER-5862881](https://snyk.io/vuln/SNYK-PYTHON-JUPYTERSERVER-5862881) | `jupyter-server:` <br> `1.24.0 -> 2.11.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **/1000** <br/> **Why?** | Open Redirect <br/>[SNYK-PYTHON-JUPYTERSERVER-5862882](https://snyk.io/vuln/SNYK-PYTHON-JUPYTERSERVER-5862882) | `jupyter-server:` <br> `1.24.0 -> 2.11.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **/1000** <br/> **Why?** | Generation of Error Message Containing Sensitive Information <br/>[SNYK-PYTHON-JUPYTERSERVER-6099119](https://snyk.io/vuln/SNYK-PYTHON-JUPYTERSERVER-6099119) | `jupyter-server:` <br> `1.24.0 -> 2.11.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium seve",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14211:1731,Access,Access,1731,https://hail.is,https://github.com/hail-is/hail/pull/14211,2,['Access'],['Access']
Security,".</li>; <li>Added a mention of the size of the connection pool when discarding a connection due to the pool being full.</li>; <li>Added explicit support for Python 3.11.</li>; <li>Deprecated the <code>Retry.MAX_BACKOFF</code> class property in favor of <code>Retry.DEFAULT_MAX_BACKOFF</code>; to better match the rest of the default parameter names. <code>Retry.MAX_BACKOFF</code> is removed in v2.0.</li>; <li>Changed location of the vendored <code>ssl.match_hostname</code> function from <code>urllib3.packages.ssl_match_hostname</code>; to <code>urllib3.util.ssl_match_hostname</code> to ensure Python 3.10+ compatibility after being repackaged; by downstream distributors.</li>; <li>Fixed absolute imports, all imports are now relative.</li>; </ul>; <h1>1.26.7 (2021-09-22)</h1>; <ul>; <li>Fixed a bug with HTTPS hostname verification involving IP addresses and lack; of SNI. (Issue <a href=""https://github-redirect.dependabot.com/urllib3/urllib3/issues/2400"">#2400</a>)</li>; <li>Fixed a bug where IPv6 braces weren't stripped during certificate hostname; matching. (Issue <a href=""https://github-redirect.dependabot.com/urllib3/urllib3/issues/2240"">#2240</a>)</li>; </ul>; <h1>1.26.6 (2021-06-25)</h1>; <ul>; <li>Deprecated the <code>urllib3.contrib.ntlmpool</code> module. urllib3 is not able to support; it properly due to <code>reasons listed in this issue &lt;https://github.com/urllib3/urllib3/issues/2282&gt;</code>_.; If you are a user of this module please leave a comment.</li>; <li>Changed <code>HTTPConnection.request_chunked()</code> to not erroneously emit multiple; <code>Transfer-Encoding</code> headers in the case that one is already specified.</li>; <li>Fixed typo in deprecation message to recommend <code>Retry.DEFAULT_ALLOWED_METHODS</code>.</li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/urllib3/urllib3/commit/b1f60e44d43b13e5272d5b6003f125af9c25c8ad""><code>b1f60e4</code></a> Release 1.26.8</li>; <li>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11532:4657,certificate,certificate,4657,https://hail.is,https://github.com/hail-is/hail/pull/11532,1,['certificate'],['certificate']
Security,".Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105); at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205); at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101); at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:216); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); java.lang.OutOfMemoryError: GC overhead limit exceeded; at scala.collection.mutable.ListBuffer.$plus$eq(ListBuffer.scala:170); at scala.collection.mutable.ListBuffer.$plus$eq(ListBuffer.scala:45); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.mutable.HashMap$$anon$2$$anonfun$foreach$3.apply(HashMap.scala:108); at scala.collection.mutable.HashMap$$anon$2$$anonfun$foreach$3.apply(HashMap.scala:108); at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230); at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40); at scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:108); at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); at scala.collection.AbstractTraversable.map(Traversable.scala:104); at org.apache.spark.SparkStatusTracker.getActiveStageIds(SparkStatusTracker.scala:61); at org.apache.spark.ui.ConsoleProgressBar.org$apache$spark$ui$ConsoleProgressBar$$refresh(ConsoleProgressBar.scala:67); at org.apache.spark.ui.ConsoleProgressBar$$anon$1.run(ConsoleProgressBar.scala:55); at java.util.TimerThread.mainLoop(Timer.java:555); at java.util.TimerThread.run(Timer.java:505); ---------------------------------------------------------------------------; FatalError Traceback (most recent call last); /restricted/projectnb/ukbiobank/ad/analysis/ad.v1/bgen2mt.py in <module>; 6 sample=""/project/ukbiobank/imp/uk",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4780:4024,Hash,HashMap,4024,https://hail.is,https://github.com/hail-is/hail/issues/4780,1,['Hash'],['HashMap']
Security,.Parser$$anonfun$parseTypedExpr$1.apply(Parser.scala:102); 	at scala.Function0$class.apply$mcJ$sp(Function0.scala:34); 	at scala.runtime.AbstractFunction0.apply$mcJ$sp(AbstractFunction0.scala:12); 	at is.hail.utils.Graph$$anonfun$2$$anonfun$apply$4.apply(Graph.scala:81); 	at is.hail.utils.Graph$$anonfun$2$$anonfun$apply$4.apply(Graph.scala:79); 	at is.hail.utils.BinaryHeap.isLeftFavoredTie(BinaryHeap.scala:16); 	at is.hail.utils.BinaryHeap.is$hail$utils$BinaryHeap$$bubbleUp(BinaryHeap.scala:161); 	at is.hail.utils.BinaryHeap.insert(BinaryHeap.scala:40); 	at is.hail.utils.Graph$$anonfun$maximalIndependentSet$1.apply(Graph.scala:101); 	at is.hail.utils.Graph$$anonfun$maximalIndependentSet$1.apply(Graph.scala:100); 	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99); 	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99); 	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230); 	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40); 	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99); 	at is.hail.utils.Graph$.maximalIndependentSet(Graph.scala:100); 	at is.hail.utils.Graph$.maximalIndependentSet(Graph.scala:86); 	at is.hail.utils.Graph.maximalIndependentSet(Graph.scala); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:497); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:280); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:214); 	at java.lang.Thread.run(Thread.java:745); ```,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3704:2602,Hash,HashMap,2602,https://hail.is,https://github.com/hail-is/hail/pull/3704,3,['Hash'],['HashMap']
Security,".call(Executors.java:511) ~[?:1.8.0_382]; 	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_382]; 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_382]; 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_382]; 	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_382]; Caused by: is.hail.relocated.com.google.cloud.storage.StorageException: 403 Forbidden; POST https://storage.googleapis.com/upload/storage/v1/b/neale-bge/o?name=foo.ht/index/part-0-c7ba7549-bf68-42db-a8ef-0f1b13721c79.idx/index&uploadType=resumable; {; ""error"": {; ""code"": 403,; ""message"": ""dking-ae4q6@hail-vdc.iam.gserviceaccount.com does not have storage.objects.create access to the Google Cloud Storage object. Permission 'storage.objects.create' denied on resource (or it may not exist)."",; ""errors"": [; {; ""message"": ""dking-ae4q6@hail-vdc.iam.gserviceaccount.com does not have storage.objects.create access to the Google Cloud Storage object. Permission 'storage.objects.create' denied on resource (or it may not exist)."",; ""domain"": ""global"",; ""reason"": ""forbidden""; }; ]; }; }. 	at is.hail.relocated.com.google.cloud.storage.StorageException.translate(StorageException.java:165) ~[gs:__hail-query-ger0g_jars_b115f6a6ec23f111a4512b562b52d9f8a52ec41c.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.spi.v1.HttpStorageRpc.translate(HttpStorageRpc.java:298) ~[gs:__hail-query-ger0g_jars_b115f6a6ec23f111a4512b562b52d9f8a52ec41c.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.spi.v1.HttpStorageRpc.open(HttpStorageRpc.java:1029) ~[gs:__hail-query-ger0g_jars_b115f6a6ec23f111a4512b562b52d9f8a52ec41c.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.ResumableMedia.lambda$startUploadForBlobInfo$0(ResumableMedia.java:40) ~[gs:__hail-query-ger0g_jars_b115f6a6ec23f111a4512b562b52d9f8a52ec41c.jar.jar:0.0.1-SNAPSHOT]; 	at com.google.api.gax.retrying.Dir",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13697:10938,access,access,10938,https://hail.is,https://github.com/hail-is/hail/issues/13697,1,['access'],['access']
Security,".com/Crain-32""><code>@​crain-32</code></a>.</li>; <li><a href=""https://redirect.github.com/java-native-access/jna/pull/1459"">#1459</a>: Add <code>VirtualLock</code> and <code>VirtualUnlock</code> in <code>c.s.j.p.win32.Kernel32</code> - <a href=""https://github.com/matthiasblaesing""><code>@​matthiasblaesing</code></a>.</li>; <li><a href=""https://redirect.github.com/java-native-access/jna/pull/1471"">#1471</a>: Add <code>c.s.j.p.win32.Advapi32Util#isCurrentProcessElevated</code> and associated Types - <a href=""https://github.com/dbwiddis""><code>@​dbwiddis</code></a>.</li>; <li><a href=""https://redirect.github.com/java-native-access/jna/pull/1474"">#1474</a>: Add <code>c.s.j.p.win32.WbemCli#IWbemClassObject.IWbemQualifierSet</code>, <code>IWbemServices.GetObject</code>, <code>IWbemContext.SetValue</code> and associated methods - <a href=""https://github.com/rchateauneu""><code>@​rchateauneu</code></a>.</li>; <li><a href=""https://redirect.github.com/java-native-access/jna/pull/1482"">#1482</a>: Add multilingual support of <code>Kernel32Util.formatMessage</code> - <a href=""https://github.com/overpathz""><code>@​overpathz</code></a>.</li>; <li><a href=""https://redirect.github.com/java-native-access/jna/pull/1490"">#1490</a>: Adds support for a custom <code>SymbolProvider</code> in <code>NativeLibrary</code> &amp; <code>Library</code> - <a href=""https://github.com/soywiz""><code>@​soywiz</code></a>.</li>; <li><a href=""https://redirect.github.com/java-native-access/jna/pull/1491"">#1491</a>: Update libffi to v3.4.4 - <a href=""https://github.com/matthiasblaesing""><code>@​matthiasblaesing</code></a>.</li>; <li><a href=""https://redirect.github.com/java-native-access/jna/issues/1487"">#1487</a>: Add 'uses' information to OSGI metadata in MANIFEST.MF to improve stability of package resolution - <a href=""https://github.com/sratz""><code>@​sratz</code></a>.</li>; </ul>; <h2>Bug Fixes</h2>; <ul>; <li><a href=""https://redirect.github.com/java-native-access/jna/issues/1452"">#1452</a>: Fix memor",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12886:1501,access,access,1501,https://hail.is,https://github.com/hail-is/hail/pull/12886,1,['access'],['access']
Security,".com/ai/nanoid/issues/335"">#335</a>)</li>; <li><a href=""https://github.com/ai/nanoid/commit/90a446fef3ecaac78e5af2ea01025c4f40182e2b""><code>90a446f</code></a> Update benchmark results</li>; <li><a href=""https://github.com/ai/nanoid/commit/8ba2319b579895cc1f9060b9946a44852f97c509""><code>8ba2319</code></a> bench: add <code>@​napi-rs/uuid</code> v4 (<a href=""https://github-redirect.dependabot.com/ai/nanoid/issues/333"">#333</a>)</li>; <li><a href=""https://github.com/ai/nanoid/commit/f4257780ece488734a65c176e80c2fd8ab6aab8e""><code>f425778</code></a> Release 3.1.32 version</li>; <li>Additional commits viewable in <a href=""https://github.com/ai/nanoid/compare/3.1.23...3.2.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=nanoid&package-manager=npm_and_yarn&previous-version=3.1.23&new-version=3.2.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11284:3592,secur,security-vulnerabilities,3592,https://hail.is,https://github.com/hail-is/hail/pull/11284,4,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,".com/chardet/chardet/issues/244"">#244</a>)</li>; <li><a href=""https://github.com/chardet/chardet/commit/49b8341f507bed68f7d3ff7138bb97047a0e04f0""><code>49b8341</code></a> Configure setuptools using the declarative syntax in setup.cfg (<a href=""https://github-redirect.dependabot.com/chardet/chardet/issues/239"">#239</a>)</li>; <li><a href=""https://github.com/chardet/chardet/commit/5c73bfcdf819251d1a1d0de672e34480ebafbe1f""><code>5c73bfc</code></a> Run all pre-commit hooks on pull requests (<a href=""https://github-redirect.dependabot.com/chardet/chardet/issues/236"">#236</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/chardet/chardet/compare/4.0.0...5.0.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=chardet&package-manager=pip&previous-version=4.0.0&new-version=5.0.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12107:5791,secur,security-vulnerabilities,5791,https://hail.is,https://github.com/hail-is/hail/pull/12107,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,".com/protocolbuffers/protobuf) from 3.20.1 to 4.21.6.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/protocolbuffers/protobuf/releases"">protobuf's releases</a>.</em></p>; <blockquote>; <h2>Protocol Buffers v3.20.2</h2>; <h1>C++</h1>; <ul>; <li>Reduce memory consumption of MessageSet parsing</li>; <li>This release addresses a <a href=""https://github.com/protocolbuffers/protobuf/security/advisories/GHSA-8gq9-2x98-w8hf"">Security Advisory for C++ and Python users</a></li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li>See full diff in <a href=""https://github.com/protocolbuffers/protobuf/commits"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=protobuf&package-manager=pip&previous-version=3.20.1&new-version=4.21.6)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12227:999,secur,security-vulnerabilities,999,https://hail.is,https://github.com/hail-is/hail/pull/12227,4,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,".dependabot.com/pandas-dev/pandas/issues/50"">#50</a>...</li>; <li><a href=""https://github.com/pandas-dev/pandas/commit/54b40379e3fe6825f676cf02767ee81adb6ffeb5""><code>54b4037</code></a> Backport PR on Branch 1.5.x (REV: revert deprecation of Series.<strong>getitem</strong> sl...</li>; <li><a href=""https://github.com/pandas-dev/pandas/commit/71db310a328a0dfa194ef0fe2b95238817b4f419""><code>71db310</code></a> Backport PR <a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/50396"">#50396</a> on branch 1.5.x (BUG/COMPAT: fix assert_* functions for ne...</li>; <li>Additional commits viewable in <a href=""https://github.com/pandas-dev/pandas/compare/v1.3.5...v1.5.3"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pandas&package-manager=pip&previous-version=1.3.5&new-version=1.5.3)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). You can trigger a rebase of this PR by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Depe",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12610:5649,secur,security-vulnerabilities,5649,https://hail.is,https://github.com/hail-is/hail/pull/12610,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,.doPrivileged(Native Method); at java.net.URLClassLoader.findClass(URLClassLoader.java:361); at java.lang.ClassLoader.loadClass(ClassLoader.java:424); at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331); at java.lang.ClassLoader.loadClass(ClassLoader.java:357); at org.apache.spark.HeartbeatReceiver$$anonfun$org$apache$spark$HeartbeatReceiver$$expireDeadHosts$3.apply(HeartbeatReceiver.scala:198); at org.apache.spark.HeartbeatReceiver$$anonfun$org$apache$spark$HeartbeatReceiver$$expireDeadHosts$3.apply(HeartbeatReceiver.scala:196); at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733); at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99); at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99); at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230); at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40); at scala.collection.mutable.HashMap.foreach(HashMap.scala:99); at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732); at org.apache.spark.HeartbeatReceiver.org$apache$spark$HeartbeatReceiver$$expireDeadHosts(HeartbeatReceiver.scala:196); at org.apache.spark.HeartbeatReceiver$$anonfun$receiveAndReply$1.applyOrElse(HeartbeatReceiver.scala:119); at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105); at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205); at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101); at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:216); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); java.lang.OutOfMemoryError: GC overhead limit exceeded; at scala.collection.mutable.ListBuffer.$plus$eq(ListBuffer.scala:170); at scala.collection.mutable.ListBuffer.$p,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4780:2667,Hash,HashMap,2667,https://hail.is,https://github.com/hail-is/hail/issues/4780,1,['Hash'],['HashMap']
Security,.invoke(Method.java:566) ~[?:?]; 	at is.hail.JVMEntryway$1.run(JVMEntryway.java:119) [jvm-entryway.jar:?]; 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]; 	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]; 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]; 	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]; 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]; 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]; 	at java.lang.Thread.run(Thread.java:829) [?:?]; Caused by: com.fasterxml.jackson.core.exc.StreamConstraintsException: String length (20013488) exceeds the maximum length (20000000); 	at com.fasterxml.jackson.core.StreamReadConstraints.validateStringLength(StreamReadConstraints.java:324) ~[jackson-core-2.15.2.jar:2.15.2]; 	at com.fasterxml.jackson.core.util.ReadConstrainedTextBuffer.validateStringLength(ReadConstrainedTextBuffer.java:27) ~[jackson-core-2.15.2.jar:2.15.2]; 	at com.fasterxml.jackson.core.util.TextBuffer.finishCurrentSegment(TextBuffer.java:939) ~[jackson-core-2.15.2.jar:2.15.2]; 	at com.fasterxml.jackson.core.json.UTF8StreamJsonParser._finishString2(UTF8StreamJsonParser.java:2584) ~[jackson-core-2.15.2.jar:2.15.2]; 	at com.fasterxml.jackson.core.json.UTF8StreamJsonParser._finishAndReturnString(UTF8StreamJsonParser.java:2560) ~[jackson-core-2.15.2.jar:2.15.2]; 	at com.fasterxml.jackson.core.json.UTF8StreamJsonParser.getText(UTF8StreamJsonParser.java:335) ~[jackson-core-2.15.2.jar:2.15.2]; 	at is.hail.relocated.org.json4s.jackson.JValueDeserializer._deserialize$1(JValueDeserializer.scala:26) ~[gs:__hail-query-daaf463550_jars_4c60fddb171a52c21f41a81995c53a28e375c26b.jar.jar:?]; 	at is.hail.relocated.org.json4s.jackson.JValueDeserializer._deserialize$1(JValueDeserializer.scala:48) ~[gs:__hail-query-daaf463550_jars_4c60fddb171a52c21f41a81995c53a28e375c26b.jar.jar:?]; 	at is.hai,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14749:3539,validat,validateStringLength,3539,https://hail.is,https://github.com/hail-is/hail/issues/14749,1,['validat'],['validateStringLength']
Security,.java:498); at is.hail.JVMEntryway$1.run(JVMEntryway.java:105); ... 7 more; Caused by: is.hail.relocated.com.google.cloud.storage.StorageException: Unable to recover in upload.; This may be a symptom of multiple clients uploading to the same upload session. For debugging purposes:; uploadId: https://storage.googleapis.com/upload/storage/v1/b/rwalters-hail-tmp/o?name=merged_round2_sumstats.fix_lowconf.mt/entries/rows/parts/part-15801-2fde3786-67cb-42ed-8aac-f900cfcc4c00&uploadType=resumable&upload_id=ADPycduMEzX6d_uX4CiP6_XItJKmP8UnUnYBfyPoselMbyLUkxs1wDLPnxWl5gXr5LnBaVntYR_i7jchyxgVsRb_5PknvcCIcfDJ; chunkOffset: 16777216; chunkLength: 0; localOffset: 0; remoteOffset: 16777216; lastChunk: false. at is.hail.relocated.com.google.cloud.storage.BlobWriteChannel.unrecoverableState(BlobWriteChannel.java:131); at is.hail.relocated.com.google.cloud.storage.BlobWriteChannel.unrecoverableState(BlobWriteChannel.java:87); at is.hail.relocated.com.google.cloud.storage.BlobWriteChannel.access$1000(BlobWriteChannel.java:35); at is.hail.relocated.com.google.cloud.storage.BlobWriteChannel$1.run(BlobWriteChannel.java:267); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:103); at is.hail.relocated.com.google.cloud.RetryHelper.run(RetryHelper.java:76); at is.hail.relocated.com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:50); at is.hail.relocated.com.google.cloud.storage.BlobWriteChannel.flushBuffer(BlobWriteChannel.java:189); at is.hail.relocated.com.google.cloud.BaseWriteChannel.flush(BaseWriteChannel.java:112); at is.hail.relocated.com.google.cloud.BaseWriteChannel.write(BaseWriteChannel.java:139); at is.hail.io.fs.GoogleStorageFS$$anon$2.flush(GoogleStorageFS.scala:270); at is.hail.io.fs.FSPositionedOutputStream.write(FS.scala:218); at java.io.DataOutputStream.write(DataOutputStream.java:107); at is.hail.utils.richUtils.ByteTrackingOutputStream.write(ByteTr,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12950:3124,access,access,3124,https://hail.is,https://github.com/hail-is/hail/issues/12950,1,['access'],['access']
Security,".k8s.io/v1, Resource=roles"", GroupVersionKind: ""rbac.authorization.k8s.io/v1, Kind=Role""; Name: ""batch-pods-admin"", Namespace: ""batch-pods""; Object: &{map[""apiVersion"":""rbac.authorization.k8s.io/v1"" ""kind"":""Role"" ""metadata"":map[""name"":""batch-pods-admin"" ""namespace"":""batch-pods"" ""annotations"":map[""kubectl.kubernetes.io/last-applied-configuration"":""""]] ""rules"":[map[""apiGroups"":[""""] ""resources"":[""pods""] ""verbs"":[""get"" ""list"" ""watch"" ""create"" ""update"" ""patch"" ""delete""]] map[""apiGroups"":[""""] ""resources"":[""pods/log""] ""verbs"":[""get""]]]]}; from server for: ""deployment.yaml"": roles.rbac.authorization.k8s.io ""batch-pods-admin"" is forbidden: User ""system:serviceaccount:batch-pods:deploy-svc"" cannot get roles.rbac.authorization.k8s.io in the namespace ""batch-pods"": Unknown user ""system:serviceaccount:batch-pods:deploy-svc""; Error from server (Forbidden): error when retrieving current configuration of:; Resource: ""rbac.authorization.k8s.io/v1, Resource=rolebindings"", GroupVersionKind: ""rbac.authorization.k8s.io/v1, Kind=RoleBinding""; Name: ""batch-pods-admin-binding"", Namespace: ""batch-pods""; Object: &{map[""apiVersion"":""rbac.authorization.k8s.io/v1"" ""kind"":""RoleBinding"" ""metadata"":map[""annotations"":map[""kubectl.kubernetes.io/last-applied-configuration"":""""] ""name"":""batch-pods-admin-binding"" ""namespace"":""batch-pods""] ""roleRef"":map[""apiGroup"":"""" ""kind"":""Role"" ""name"":""batch-pods-admin""] ""subjects"":[map[""kind"":""ServiceAccount"" ""name"":""batch-svc"" ""namespace"":""default""]]]}; from server for: ""deployment.yaml"": rolebindings.rbac.authorization.k8s.io ""batch-pods-admin-binding"" is forbidden: User ""system:serviceaccount:batch-pods:deploy-svc"" cannot get rolebindings.rbac.authorization.k8s.io in the namespace ""batch-pods"": Unknown user ""system:serviceaccount:batch-pods:deploy-svc""; Error from server (Forbidden): error when retrieving current configuration of:; Resource: ""apps/v1beta2, Resource=deployments"", GroupVersionKind: ""apps/v1beta2, Kind=Deployment""; Name: ""batch-deployment"", Namespace",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4609:2403,authoriz,authorization,2403,https://hail.is,https://github.com/hail-is/hail/issues/4609,1,['authoriz'],['authorization']
Security,".org/en/master/changes.html</a></p>; <h2>v5.0.0</h2>; <p>No release notes provided.</p>; <h2>v5.0.0b1</h2>; <p>Changelog: <a href=""https://www.sphinx-doc.org/en/master/changes.html"">https://www.sphinx-doc.org/en/master/changes.html</a></p>; <h2>v4.5.0</h2>; <p>Changelog: <a href=""https://www.sphinx-doc.org/en/master/changes.html"">https://www.sphinx-doc.org/en/master/changes.html</a></p>; <h2>v4.4.0</h2>; <p>Changelog: <a href=""https://www.sphinx-doc.org/en/master/changes.html"">https://www.sphinx-doc.org/en/master/changes.html</a></p>; <h2>v4.3.1</h2>; <p>No release notes provided.</p>; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/sphinx-doc/sphinx/blob/5.x/CHANGES"">sphinx's changelog</a>.</em></p>; <blockquote>; <h1>Release 5.0.2 (released Jun 17, 2022)</h1>; <h2>Features added</h2>; <ul>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10523"">#10523</a>: HTML Theme: Expose the Docutils's version info tuple as a template; variable, <code>docutils_version_info</code>. Patch by Adam Turner.</li>; </ul>; <h2>Bugs fixed</h2>; <ul>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10538"">#10538</a>: autodoc: Inherited class attribute having docstring is documented even; if :confval:<code>autodoc_inherit_docstring</code> is disabled</li>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10509"">#10509</a>: autosummary: autosummary fails with a shared library</li>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10497"">#10497</a>: py domain: Failed to resolve strings in Literal. Patch by Adam Turner.</li>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10523"">#10523</a>: HTML Theme: Fix double brackets on citation references in Docutils 0.18+.; Patch by Adam Turner.</li>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10534"">#10534</a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11925:1486,Expose,Expose,1486,https://hail.is,https://github.com/hail-is/hail/pull/11925,1,['Expose'],['Expose']
Security,".p.win32.Crypt32</code> - <a href=""https://github.com/shalupov""><code>@​shalupov</code></a></li>; </ul>; <h2>Bug Fixes</h2>; <ul>; <li><a href=""https://github-redirect.dependabot.com/java-native-access/jna/pull/1411"">#1411</a>: Do not throw <code>Win32Exception</code> on success for empty section in <code>Kernel32Util#getPrivateProfileSection</code> - <a href=""https://github.com/mkarg""><code>@​mkarg</code></a>.</li>; <li><a href=""https://github-redirect.dependabot.com/java-native-access/jna/pull/1414"">#1414</a>: Fix definition of <code>c.s.j.p.unix.X11.XK_Shift_R</code> - <a href=""https://github.com/matthiasblaesing""><code>@​matthiasblaesing</code></a>.</li>; <li><a href=""https://github-redirect.dependabot.com/java-native-access/jna/issues/1323"">#1323</a>. Fix crashes in direct callbacks on mac OS aarch64 - <a href=""https://github.com/matthiasblaesing""><code>@​matthiasblaesing</code></a>.</li>; <li><a href=""https://github-redirect.dependabot.com/java-native-access/jna/pull/1422"">#1422</a>: Load jawt library relative to <code>sun.boot.library.path</code> system on unix OSes - <a href=""https://github.com/matthiasblaesing""><code>@​matthiasblaesing</code></a>.</li>; <li><a href=""https://github-redirect.dependabot.com/java-native-access/jna/pull/1427"">#1427</a>: Rebuild all binaries with fix from <a href=""https://github-redirect.dependabot.com/java-native-access/jna/issues/1422"">#1422</a> and <a href=""https://github-redirect.dependabot.com/java-native-access/jna/issues/1323"">#1323</a> - <a href=""https://github.com/matthiasblaesing""><code>@​matthiasblaesing</code></a>.</li>; </ul>; <h1>Release 5.10.0</h1>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/java-native-access/jna/commit/3705b849892aa3c37e5608e640eff19047811a5c""><code>3705b84</code></a> Release 5.12.1</li>; <li><a href=""https://github.com/java-native-access/jna/commit/2f919e56bad203494fe9589206d6d23f27ef4f",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12438:4794,access,access,4794,https://hail.is,https://github.com/hail-is/hail/pull/12438,1,['access'],['access']
Security,".png ""medium severity"") | Improper Limitation of a Pathname to a Restricted Directory (&#x27;Path Traversal&#x27;) <br/>[SNYK-PYTHON-AIOHTTP-6209406](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-6209406) | `aiohttp:` <br> `3.8.6 -> 3.9.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | HTTP Request Smuggling <br/>[SNYK-PYTHON-AIOHTTP-6209407](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-6209407) | `aiohttp:` <br> `3.8.6 -> 3.9.2` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | Remote Code Execution (RCE) <br/>[SNYK-PYTHON-IPYTHON-3318382](https://snyk.io/vuln/SNYK-PYTHON-IPYTHON-3318382) | `ipython:` <br> `7.34.0 -> 8.10.0` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | Access Control Bypass <br/>[SNYK-PYTHON-JUPYTERSERVER-5862881](https://snyk.io/vuln/SNYK-PYTHON-JUPYTERSERVER-5862881) | `jupyter-server:` <br> `1.24.0 -> 2.11.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | Open Redirect <br/>[SNYK-PYTHON-JUPYTERSERVER-5862882](https://snyk.io/vuln/SNYK-PYTHON-JUPYTERSERVER-5862882) | `jupyter-server:` <br> `1.24.0 -> 2.11.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | Generation of Error Message Containing Sensitive Information <br/>[SNYK-PYTHON-JUPYTERSERVER-6099119](https://snyk.io/vuln/SNYK-PYTHON-JUPYTERSERVER-6099119) | `jupyter-server:` <br> `1.24.0 -> 2.11.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | Regular Expression Denial of Service (ReDoS) <br/>[SNYK-PYT",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14259:2666,Access,Access,2666,https://hail.is,https://github.com/hail-is/hail/pull/14259,1,['Access'],['Access']
Security,".py"", line 21, in <module>; rg37.add_sequence(; File ""<decorator-gen-34>"", line 2, in add_sequence; File ""/Users/mkanai/.anyenv/envs/pyenv/versions/anaconda3-2022.05/lib/python3.9/site-packages/hail/typecheck/check.py"", line 584, in wrapper; return __original_func(*args_, **kwargs_); File ""/Users/mkanai/.anyenv/envs/pyenv/versions/anaconda3-2022.05/lib/python3.9/site-packages/hail/genetics/reference_genome.py"", line 390, in add_sequence; Env.backend().add_sequence(self.name, fasta_file, index_file); File ""/Users/mkanai/.anyenv/envs/pyenv/versions/anaconda3-2022.05/lib/python3.9/site-packages/hail/backend/service_backend.py"", line 548, in add_sequence; self.validate_file(blob); File ""/Users/mkanai/.anyenv/envs/pyenv/versions/anaconda3-2022.05/lib/python3.9/site-packages/hail/backend/service_backend.py"", line 337, in validate_file; validate_file(uri, self._async_fs, validate_scheme=True); File ""/Users/mkanai/.anyenv/envs/pyenv/versions/anaconda3-2022.05/lib/python3.9/site-packages/hailtop/aiotools/validators.py"", line 19, in validate_file; return hail_event_loop().run_until_complete(; File ""/Users/mkanai/.anyenv/envs/pyenv/versions/anaconda3-2022.05/lib/python3.9/site-packages/nest_asyncio.py"", line 99, in run_until_complete; return f.result(); File ""/Users/mkanai/.anyenv/envs/pyenv/versions/anaconda3-2022.05/lib/python3.9/asyncio/futures.py"", line 201, in result; raise self._exception; File ""/Users/mkanai/.anyenv/envs/pyenv/versions/anaconda3-2022.05/lib/python3.9/asyncio/tasks.py"", line 256, in __step; result = coro.send(None); File ""/Users/mkanai/.anyenv/envs/pyenv/versions/anaconda3-2022.05/lib/python3.9/site-packages/hailtop/aiotools/validators.py"", line 38, in _async_validate_file; if not await fs.is_hot_storage(location):; File ""/Users/mkanai/.anyenv/envs/pyenv/versions/anaconda3-2022.05/lib/python3.9/site-packages/hailtop/aiocloud/aiogoogle/client/storage_client.py"", line 630, in is_hot_storage; return (await self._storage_client.bucket_info(location))[""storag",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14291:2205,validat,validators,2205,https://hail.is,https://github.com/hail-is/hail/issues/14291,1,['validat'],['validators']
Security,"//]: # (snyk:metadata:{""prId"":""648a0aea-922c-46c9-b851-66c7e282d2e5"",""prPublicId"":""648a0aea-922c-46c9-b851-66c7e282d2e5"",""dependencies"":[{""name"":""certifi"",""from"":""2021.10.8"",""to"":""2023.7.22""},{""name"":""cryptography"",""from"":""3.3.2"",""to"":""41.0.6""},{""name"":""requests"",""from"":""2.27.1"",""to"":""2.31.0""}],""packageManager"":""pip"",""projectPublicId"":""5ecb4152-94d0-44ff-86c6-21e542bb123d"",""projectUrl"":""https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-CERTIFI-3164749"",""SNYK-PYTHON-CERTIFI-5805047"",""SNYK-PYTHON-CRYPTOGRAPHY-3172287"",""SNYK-PYTHON-CRYPTOGRAPHY-3314966"",""SNYK-PYTHON-CRYPTOGRAPHY-3315324"",""SNYK-PYTHON-CRYPTOGRAPHY-3315328"",""SNYK-PYTHON-CRYPTOGRAPHY-3315331"",""SNYK-PYTHON-CRYPTOGRAPHY-3315452"",""SNYK-PYTHON-CRYPTOGRAPHY-3315972"",""SNYK-PYTHON-CRYPTOGRAPHY-3315975"",""SNYK-PYTHON-CRYPTOGRAPHY-3316038"",""SNYK-PYTHON-CRYPTOGRAPHY-3316211"",""SNYK-PYTHON-CRYPTOGRAPHY-5663682"",""SNYK-PYTHON-CRYPTOGRAPHY-5777683"",""SNYK-PYTHON-CRYPTOGRAPHY-5813745"",""SNYK-PYTHON-CRYPTOGRAPHY-5813746"",""SNYK-PYTHON-CRYPTOGRAPHY-5813750"",""SNYK-PYTHON-CRYPTOGRAPHY-5914629"",""SNYK-PYTHON-CRYPTOGRAPHY-6036192"",""SNYK-PYTHON-CRYPTOGRAPHY-6092044"",""SNYK-PYTHON-REQUESTS-5595532""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""pr-warning-shown""],""priorityScoreList"":[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Use After Free](https://learn.snyk.io/lesson/use-after-free/?loc&#x3D;fix-pr); 🦉 [Access of Resource Using Incompatible Type (&#x27;Type Confusion&#x27;)](https://learn.snyk.io/lesson/type-confusion/?loc&#x3D;fix-pr); 🦉 [Denial of Service (DoS)](https://learn.snyk.io/lesson/redos/?loc&#x3D;fix-pr); 🦉 [More lessons are available in Snyk Learn](https://learn.snyk.io/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14196:10501,Access,Access,10501,https://hail.is,https://github.com/hail-is/hail/pull/14196,1,['Access'],['Access']
Security,"//github-redirect.dependabot.com/axios/axios/pull/2702"">#2702</a>)</li>; <li>Updating of transformResponse (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3377"">#3377</a>)</li>; <li>Adding ability to omit User-Agent header (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3703"">#3703</a>)</li>; <li>Adding multiple JSON improvements (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3688"">#3688</a>, <a href=""https://github-redirect.dependabot.com/axios/axios/pull/3763"">#3763</a>)</li>; <li>Fixing quadratic runtime and extra memory usage when setting a maxContentLength (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3738"">#3738</a>)</li>; <li>Adding parseInt to config.timeout (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3781"">#3781</a>)</li>; <li>Adding custom return type support to interceptor (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3783"">#3783</a>)</li>; <li>Adding security fix for ReDoS vulnerability (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3980"">#3980</a>)</li>; </ul>; <p>Internal and Tests:</p>; <ul>; <li>Updating build dev dependancies (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3401"">#3401</a>)</li>; <li>Fixing builds running on Travis CI (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3538"">#3538</a>)</li>; <li>Updating follow rediect version (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3694"">#3694</a>, <a href=""https://github-redirect.dependabot.com/axios/axios/pull/3771"">#3771</a>)</li>; <li>Updating karma sauce launcher to fix failing sauce tests (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3712"">#3712</a>, <a href=""https://github-redirect.dependabot.com/axios/axios/pull/3717"">#3717</a>)</li>; <li>Updating content-type header for application/json to not contain charset field, according do RFC 8259 (<a href=""https://github-redirect.dependabo",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11080:1583,secur,security,1583,https://hail.is,https://github.com/hail-is/hail/pull/11080,4,['secur'],['security']
Security,"//github-redirect.dependabot.com/bartdag/py4j/issues/487"">#487</a>)</li>; <li><a href=""https://github.com/py4j/py4j/commit/1c622faa81e983f5ceface5290859d6a49974849""><code>1c622fa</code></a> Migrate nosetest to pytest (<a href=""https://github-redirect.dependabot.com/bartdag/py4j/issues/481"">#481</a>)</li>; <li><a href=""https://github.com/py4j/py4j/commit/64ba89c5a680218d682161a4a6d952a969d1299b""><code>64ba89c</code></a> Add explanations for releasing Py4J for eclipse. Convert .txt to .md (<a href=""https://github-redirect.dependabot.com/bartdag/py4j/issues/479"">#479</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/bartdag/py4j/compare/0.10.9...0.10.9.7"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=py4j&package-manager=pip&previous-version=0.10.9&new-version=0.10.9.7)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12298:2749,secur,security-vulnerabilities,2749,https://hail.is,https://github.com/hail-is/hail/pull/12298,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"//github-redirect.dependabot.com/brettcannon/gidgethub/issues/180"">#180</a>)</li>; <li><a href=""https://github.com/brettcannon/gidgethub/commit/cf2cb85551a8aa36536dc828e830e13032e594d4""><code>cf2cb85</code></a> Bump min PyJWT v2.4.0 (<a href=""https://github-redirect.dependabot.com/brettcannon/gidgethub/issues/179"">#179</a>)</li>; <li><a href=""https://github.com/brettcannon/gidgethub/commit/9096d1b79447a3ef81b331457ea39c43f43e2f2d""><code>9096d1b</code></a> Release v5.1.0 (<a href=""https://github-redirect.dependabot.com/brettcannon/gidgethub/issues/175"">#175</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/brettcannon/gidgethub/compare/v4.2.0...v5.2.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=gidgethub&package-manager=pip&previous-version=4.2.0&new-version=5.2.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12328:9635,secur,security-vulnerabilities,9635,https://hail.is,https://github.com/hail-is/hail/pull/12328,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"//github.com/eranl""><code>@​eranl</code></a>.</li>; <li><a href=""https://redirect.github.com/java-native-access/jna/issues/1472"">#1472</a>: Fix incorrect bitmask in <code>c.s.j.Pointer#createConstant(int)</code> - <a href=""https://github.com/dbwiddis""><code>@​dbwiddis</code></a>.</li>; <li><a href=""https://redirect.github.com/java-native-access/jna/issues/1481"">#1481</a>: Fix NPE in NativeLibrary when unpacking from classpath is disabled - <a href=""https://github.com/trespasserw""><code>@​trespasserw</code></a>.</li>; <li><a href=""https://redirect.github.com/java-native-access/jna/pull/1489"">#1489</a>: Fixes typo in <code>OpenGL32Util#wglGetProcAddress</code>, instead of parameter <code>procName</code> the hardcoded value <code>wglEnumGpusNV</code> was used - <a href=""https://github.com/soywiz""><code>@​soywiz</code></a>.</li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/java-native-access/jna/commit/4962fd7758493b7395e86578705d8a32f6238872""><code>4962fd7</code></a> Release 5.13.0</li>; <li><a href=""https://github.com/java-native-access/jna/commit/a56504611b00cc7d90c165f924c3915cb7a6f759""><code>a565046</code></a> Adjust release directions</li>; <li><a href=""https://github.com/java-native-access/jna/commit/f7017c4f957d7fc13c7455efcae200e29407a729""><code>f7017c4</code></a> Remove artifacts classified as &quot;-jpms&quot;, there are the jna-jpms and jna-platfo...</li>; <li><a href=""https://github.com/java-native-access/jna/commit/a5f47cd359d5fe62a0e5d6c2bd9d649874be955d""><code>a5f47cd</code></a> Merge pull request <a href=""https://redirect.github.com/java-native-access/jna/issues/1494"">#1494</a> from matthiasblaesing/pr-1492</li>; <li><a href=""https://github.com/java-native-access/jna/commit/1af6eb14e0059c7acd5d5ee71fd62e519536fac5""><code>1af6eb1</code></a> Improve documentation, ensure osgi.version is defined, wrap create-export-pac...</li>; <li><a href=""https://github.com/java-native-access/jna/commit/65",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12886:3873,access,access,3873,https://hail.is,https://github.com/hail-is/hail/pull/12886,1,['access'],['access']
Security,"//github.com/matthiasblaesing""><code>@​matthiasblaesing</code></a>.</li>; <li><a href=""https://github-redirect.dependabot.com/java-native-access/jna/pull/1422"">#1422</a>: Load jawt library relative to <code>sun.boot.library.path</code> system on unix OSes - <a href=""https://github.com/matthiasblaesing""><code>@​matthiasblaesing</code></a>.</li>; <li><a href=""https://github-redirect.dependabot.com/java-native-access/jna/pull/1427"">#1427</a>: Rebuild all binaries with fix from <a href=""https://github-redirect.dependabot.com/java-native-access/jna/issues/1422"">#1422</a> and <a href=""https://github-redirect.dependabot.com/java-native-access/jna/issues/1323"">#1323</a> - <a href=""https://github.com/matthiasblaesing""><code>@​matthiasblaesing</code></a>.</li>; </ul>; <h1>Release 5.10.0</h1>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/java-native-access/jna/commit/3705b849892aa3c37e5608e640eff19047811a5c""><code>3705b84</code></a> Release 5.12.1</li>; <li><a href=""https://github.com/java-native-access/jna/commit/2f919e56bad203494fe9589206d6d23f27ef4f26""><code>2f919e5</code></a> Null-check cleanable in Memory#close (<a href=""https://github-redirect.dependabot.com/java-native-access/jna/issues/1447"">#1447</a>)</li>; <li><a href=""https://github.com/java-native-access/jna/commit/1eec7dd76830af97ed64ecb2d8d39a56db104dcd""><code>1eec7dd</code></a> Prepare next development iteration</li>; <li><a href=""https://github.com/java-native-access/jna/commit/0d7499f105e4495bdea15fc21f5b1046e81ca822""><code>0d7499f</code></a> Release 5.12.0</li>; <li><a href=""https://github.com/java-native-access/jna/commit/fa86166d4f75ef4478de7ad9d7d6c0b6b6933ee0""><code>fa86166</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/java-native-access/jna/issues/1445"">#1445</a> from matthiasblaesing/aix</li>; <li><a href=""https://github.com/java-native-access/jna/commit/4cca4405f7",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12438:5617,access,access,5617,https://hail.is,https://github.com/hail-is/hail/pull/12438,1,['access'],['access']
Security,"//redirect.github.com/jaraco/zipp/issues/106"">#106</a>.</li>; <li><a href=""https://github.com/jaraco/zipp/commit/4cceb497c278ad0ecb11a9472e58f4130f5ff16b""><code>4cceb49</code></a> Add special accounting for pypy when computing the stack level for text encod...</li>; <li><a href=""https://github.com/jaraco/zipp/commit/2ec3ed8567d0842675c38fd8ef0a28db668e602d""><code>2ec3ed8</code></a> Add another test at another magnitude.</li>; <li><a href=""https://github.com/jaraco/zipp/commit/d9bf5aab8b39c6a124d9499ae0315d3bf2ac2f46""><code>d9bf5aa</code></a> Fix name generator for width=1</li>; <li>Additional commits viewable in <a href=""https://github.com/jaraco/zipp/compare/v3.17.0...v3.18.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=zipp&package-manager=pip&previous-version=3.17.0&new-version=3.18.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14473:3083,secur,security-vulnerabilities,3083,https://hail.is,https://github.com/hail-is/hail/pull/14473,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"/2752"">#2752</a>)</li>; </ul>; <h3>Style</h3>; <ul>; <li>Deprecate <code>--experimental-string-processing</code> and move the functionality under; <code>--preview</code> (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2789"">#2789</a>)</li>; <li>For stubs, one blank line between class attributes and methods is now kept if there's; at least one pre-existing blank line (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2736"">#2736</a>)</li>; <li>Black now normalizes string prefix order (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2297"">#2297</a>)</li>; <li>Remove spaces around power operators if both operands are simple (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2726"">#2726</a>)</li>; <li>Work around bug that causes unstable formatting in some cases in the presence of the; magic trailing comma (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2807"">#2807</a>)</li>; <li>Use parentheses for attribute access on decimal float and int literals (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2799"">#2799</a>)</li>; <li>Don't add whitespace for attribute access on hexadecimal, binary, octal, and complex; literals (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2799"">#2799</a>)</li>; <li>Treat blank lines in stubs the same inside top-level <code>if</code> statements (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2820"">#2820</a>)</li>; <li>Fix unstable formatting with semicolons and arithmetic expressions (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2817"">#2817</a>)</li>; <li>Fix unstable formatting around magic trailing comma (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2572"">#2572</a>)</li>; </ul>; <h3>Parser</h3>; <ul>; <li>Fix mapping cases that contain as-expressions, like <code>case {&quot;key&quot;: 1 | 2 as password}</code>; (<a href=""https://github-redirect.dependabot.com/psf/black/is",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11468:8753,access,access,8753,https://hail.is,https://github.com/hail-is/hail/pull/11468,1,['access'],['access']
Security,"/65cf52803ec2249c61573bdc7bd4314b77c019a0""><code>65cf528</code></a> add utility shell script to create 'Export-Package' metadata</li>; <li><a href=""https://github.com/java-native-access/jna/commit/b3984aaf1bf87c8da2e84797f62180adc405b48a""><code>b3984aa</code></a> Add 'uses' information to OSGI metadata in MANIFEST.MF</li>; <li><a href=""https://github.com/java-native-access/jna/commit/780facdf55b488d504c17183066df6a34531d747""><code>780facd</code></a> Add missing change log entry for libffi update</li>; <li><a href=""https://github.com/java-native-access/jna/commit/5dd4bd707f8f1f49b5d1af158402859a86161367""><code>5dd4bd7</code></a> Merge pull request <a href=""https://redirect.github.com/java-native-access/jna/issues/1491"">#1491</a> from matthiasblaesing/update_libffi</li>; <li><a href=""https://github.com/java-native-access/jna/commit/db1b5531b10fed9fb68d6d4d79913660759b22d3""><code>db1b553</code></a> Merge pull request <a href=""https://redirect.github.com/java-native-access/jna/issues/1490"">#1490</a> from korlibs/feature/direct.mapping.custom.symbol.pr...</li>; <li>Additional commits viewable in <a href=""https://github.com/java-native-access/jna/compare/5.12.1...5.13.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=net.java.dev.jna:jna&package-manager=gradle&previous-version=5.12.1&new-version=5.13.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@de",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12886:5887,access,access,5887,https://hail.is,https://github.com/hail-is/hail/pull/12886,1,['access'],['access']
Security,"/665"">#665</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp-session/commit/29ddff39290f4e2fbc7b9feb94eb622763e156e2""><code>29ddff3</code></a> Bump pytest-aiohttp from 0.3.0 to 1.0.3 (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_session/issues/668"">#668</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp-session/commit/3bc517092aff39330f2f96315e6f542e23415831""><code>3bc5170</code></a> Bump multidict from 5.2.0 to 6.0.2 (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_session/issues/670"">#670</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/aio-libs/aiohttp_session/compare/v2.7.0...v2.11.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=aiohttp-session&package-manager=pip&previous-version=2.7.0&new-version=2.11.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11544:4664,secur,security-vulnerabilities,4664,https://hail.is,https://github.com/hail-is/hail/pull/11544,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"/77"">#77</a>)</li>; <li><a href=""https://github.com/hagenw/sphinxcontrib-katex/commit/258a8832d9518340386e584206d7b5116185b182""><code>258a883</code></a> DOC: adjust test badge to point to Github Actions (<a href=""https://github-redirect.dependabot.com/hagenw/sphinxcontrib-katex/issues/76"">#76</a>)</li>; <li><a href=""https://github.com/hagenw/sphinxcontrib-katex/commit/ef894b2bf6ae4b1eaa0c5adec7ab5c1540da97cd""><code>ef894b2</code></a> Support Python 3.10 (<a href=""https://github-redirect.dependabot.com/hagenw/sphinxcontrib-katex/issues/74"">#74</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/hagenw/sphinxcontrib-katex/compare/0.5.1...v0.9.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=sphinxcontrib-katex&package-manager=pip&previous-version=0.5.1&new-version=0.9.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12241:6622,secur,security-vulnerabilities,6622,https://hail.is,https://github.com/hail-is/hail/pull/12241,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"/797b57a4ac8da86c13e52bf60586cd2432864400""><code>797b57a</code></a> Fixed pyproject.toml and setup.py.</li>; <li><a href=""https://github.com/mrabarnett/mrab-regex/commit/16bcce0d56e84367f61c24b369e23e73a3e9ad9e""><code>16bcce0</code></a> Add changelog.txt.</li>; <li><a href=""https://github.com/mrabarnett/mrab-regex/commit/d235c2c17f2335dd7699f3c29a6ae6db6dbe6dab""><code>d235c2c</code></a> pyproject.toml was missing.</li>; <li><a href=""https://github.com/mrabarnett/mrab-regex/commit/78460dc755b09966ee6e87d04c8dcfca7212256b""><code>78460dc</code></a> Added pyproject.toml.</li>; <li>See full diff in <a href=""https://github.com/mrabarnett/mrab-regex/compare/2023.3.23...2023.5.5"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=regex&package-manager=pip&previous-version=2023.3.23&new-version=2023.5.5)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12989:3181,secur,security-vulnerabilities,3181,https://hail.is,https://github.com/hail-is/hail/pull/12989,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"/9319"">#9319</a>)</li>; <li><a href=""https://github.com/pyca/cryptography/commit/bfa4d95f0f356f2d535efd5c775e0fb3efe90ef2""><code>bfa4d95</code></a> changelog for 41.0.3 (<a href=""https://redirect.github.com/pyca/cryptography/issues/9320"">#9320</a>)</li>; <li><a href=""https://github.com/pyca/cryptography/commit/0da7165aa73c0a4865b0a4d9e019db3c16eea55a""><code>0da7165</code></a> backport fix the memory leak in fixedpool (<a href=""https://redirect.github.com/pyca/cryptography/issues/9272"">#9272</a>) (<a href=""https://redirect.github.com/pyca/cryptography/issues/9309"">#9309</a>)</li>; <li>See full diff in <a href=""https://github.com/pyca/cryptography/compare/41.0.2...41.0.3"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=cryptography&package-manager=pip&previous-version=41.0.2&new-version=41.0.3)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13357:2175,secur,security-vulnerabilities,2175,https://hail.is,https://github.com/hail-is/hail/pull/13357,6,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"/AzureAD/microsoft-authentication-extensions-for-python/commit/bd5b4074dbb7d03c9d91ce6a75378851be92552a""><code>bd5b407</code></a> Update README to reflect the new APIs</li>; <li><a href=""https://github.com/AzureAD/microsoft-authentication-extensions-for-python/commit/6f77b1e70be086aae752dcf7e08d7f06bcabdcd7""><code>6f77b1e</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/AzureAD/microsoft-authentication-extensions-for-python/issues/109"">#109</a> from AzureAD/release-1.0.0</li>; <li><a href=""https://github.com/AzureAD/microsoft-authentication-extensions-for-python/commit/50bf9674f9c65229a1573be39ef4ef507eee17fa""><code>50bf967</code></a> MSAL EX for Python 1.0.0</li>; <li><a href=""https://github.com/AzureAD/microsoft-authentication-extensions-for-python/commit/6b904af1a3d4fc0e28e3f090fa3dd8492f79e6bf""><code>6b904af</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/AzureAD/microsoft-authentication-extensions-for-python/issues/110"">#110</a> from AzureAD/persistence-factory</li>; <li><a href=""https://github.com/AzureAD/microsoft-authentication-extensions-for-python/commit/d0696aeb6f65168b1e0d405cd871b80bb101cd76""><code>d0696ae</code></a> Add build_encrypted_persistence() factory</li>; <li><a href=""https://github.com/AzureAD/microsoft-authentication-extensions-for-python/commit/289a94f694645c642ae67b2d5972d3f9fdadb928""><code>289a94f</code></a> Remove old classes that are deprecated for 2 years</li>; <li><a href=""https://github.com/AzureAD/microsoft-authentication-extensions-for-python/commit/fa1f45b556341b2c34e9bf63c06a5068571cd337""><code>fa1f45b</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/AzureAD/microsoft-authentication-extensions-for-python/issues/108"">#108</a> from AzureAD/actionable-encryption-exceptions</li>; <li><a href=""https://github.com/AzureAD/microsoft-authentication-extensions-for-python/commit/effe77842d25a8b093d18d9e33347f13e2ee094f""><code>effe778</code></a> Provide act",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11992:2984,authenticat,authentication-extensions-for-python,2984,https://hail.is,https://github.com/hail-is/hail/pull/11992,1,['authenticat'],['authentication-extensions-for-python']
Security,"/AzureAD/microsoft-authentication-extensions-for-python/issues/110"">#110</a>)</li>; <li>Enhancement: Make all platform-dependent parameters optional (<a href=""https://github-redirect.dependabot.com/AzureAD/microsoft-authentication-extensions-for-python/issues/103"">#103</a>)</li>; <li>Enhancement: Provide <code>PersistenceEncryptError</code> and <code>PersistenceDecryptError</code>, currently raised when encryption on Windows fails. (<a href=""https://github-redirect.dependabot.com/AzureAD/microsoft-authentication-extensions-for-python/issues/108"">#108</a>)</li>; <li>Enhancement: The data file will be created with <code>600</code> permission when running in Unix-like systems. (<a href=""https://github-redirect.dependabot.com/AzureAD/microsoft-authentication-extensions-for-python/issues/107"">#107</a>)</li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/AzureAD/microsoft-authentication-extensions-for-python/commit/a88fa673af3602fe7c8c922314599b0c245e7add""><code>a88fa67</code></a> Merge branch 'release-1.0.0'</li>; <li><a href=""https://github.com/AzureAD/microsoft-authentication-extensions-for-python/commit/bd5b4074dbb7d03c9d91ce6a75378851be92552a""><code>bd5b407</code></a> Update README to reflect the new APIs</li>; <li><a href=""https://github.com/AzureAD/microsoft-authentication-extensions-for-python/commit/6f77b1e70be086aae752dcf7e08d7f06bcabdcd7""><code>6f77b1e</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/AzureAD/microsoft-authentication-extensions-for-python/issues/109"">#109</a> from AzureAD/release-1.0.0</li>; <li><a href=""https://github.com/AzureAD/microsoft-authentication-extensions-for-python/commit/50bf9674f9c65229a1573be39ef4ef507eee17fa""><code>50bf967</code></a> MSAL EX for Python 1.0.0</li>; <li><a href=""https://github.com/AzureAD/microsoft-authentication-extensions-for-python/commit/6b904af1a3d4fc0e28e3f090fa3dd8492f79e6bf""><code>6b904af</code></a> Merge pull reque",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11992:1858,authenticat,authentication-extensions-for-python,1858,https://hail.is,https://github.com/hail-is/hail/pull/11992,1,['authenticat'],['authentication-extensions-for-python']
Security,"/Users/mkanai/.anyenv/envs/pyenv/versions/anaconda3-2022.05/lib/python3.9/site-packages/hailtop/aiocloud/common/base_client.py"", line 21, in request; async with await self._session.request(method, url, **kwargs) as resp:; File ""/Users/mkanai/.anyenv/envs/pyenv/versions/anaconda3-2022.05/lib/python3.9/site-packages/hailtop/aiocloud/common/session.py"", line 103, in request; return await retry_transient_errors(self._request_with_valid_authn, method, url, **kwargs); File ""/Users/mkanai/.anyenv/envs/pyenv/versions/anaconda3-2022.05/lib/python3.9/site-packages/hailtop/utils/utils.py"", line 769, in retry_transient_errors; return await retry_transient_errors_with_debug_string('', 0, f, *args, **kwargs); File ""/Users/mkanai/.anyenv/envs/pyenv/versions/anaconda3-2022.05/lib/python3.9/site-packages/hailtop/utils/utils.py"", line 785, in retry_transient_errors_with_debug_string; return await f(*args, **kwargs); File ""/Users/mkanai/.anyenv/envs/pyenv/versions/anaconda3-2022.05/lib/python3.9/site-packages/hailtop/aiocloud/common/session.py"", line 115, in _request_with_valid_authn; return await self._http_session.request(method, url, **kwargs); File ""/Users/mkanai/.anyenv/envs/pyenv/versions/anaconda3-2022.05/lib/python3.9/site-packages/hailtop/httpx.py"", line 138, in request_and_raise_for_status; raise ClientResponseError(; hailtop.httpx.ClientResponseError: 403, message='Forbidden', url=URL('https://storage.googleapis.com/storage/v1/b/hail-common?userProject=finngen-xavier') body='{\n ""error"": {\n ""code"": 403,\n ""message"": ""mkanai@broadinstitute.org does not have storage.buckets.get access to the Google Cloud Storage bucket. Permission \'storage.buckets.get\' denied on resource (or it may not exist)."",\n ""errors"": [\n {\n ""message"": ""mkanai@broadinstitute.org does not have storage.buckets.get access to the Google Cloud Storage bucket. Permission \'storage.buckets.get\' denied on resource (or it may not exist)."",\n ""domain"": ""global"",\n ""reason"": ""forbidden""\n }\n ]\n }\n}\n'; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14291:5245,access,access,5245,https://hail.is,https://github.com/hail-is/hail/issues/14291,2,['access'],['access']
Security,"/a> Name as 'options' in lambda_eval and unsafe_eval, but '_dict' in deprecated eval</li>; <li><a href=""https://github.com/python-pillow/Pillow/commit/facf3af93dabcbdd8cdbda8c3b50eefafa3bb04c""><code>facf3af</code></a> Added release notes</li>; <li><a href=""https://github.com/python-pillow/Pillow/commit/2a93aba5cfcf6e241ab4f9392c13e3b74032c061""><code>2a93aba</code></a> Use strncpy to avoid buffer overflow</li>; <li><a href=""https://github.com/python-pillow/Pillow/commit/a670597bc30e9d489656fc9d807170b8f3d7ca57""><code>a670597</code></a> Update CHANGES.rst [ci skip]</li>; <li>Additional commits viewable in <a href=""https://github.com/python-pillow/Pillow/compare/10.2.0...10.3.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pillow&package-manager=pip&previous-version=10.2.0&new-version=10.3.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14439:15466,secur,security-vulnerabilities,15466,https://hail.is,https://github.com/hail-is/hail/pull/14439,6,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"/a> Slight perf enhancement in Empty</li>; <li><a href=""https://github.com/pyparsing/pyparsing/commit/801863aa4582a8ce5e6a7408d4966afcd247ea90""><code>801863a</code></a> Make htmlStripper.py and html_table_parser examples use PEP-8 names, add comm...</li>; <li><a href=""https://github.com/pyparsing/pyparsing/commit/7d4da80b2bca8a2767134f4a181ea9aac4bbb230""><code>7d4da80</code></a> Prep for release</li>; <li><a href=""https://github.com/pyparsing/pyparsing/commit/be0310a83436bb4893d0068bb5da3059199e4c0b""><code>be0310a</code></a> Add bf parser/executor example</li>; <li>Additional commits viewable in <a href=""https://github.com/pyparsing/pyparsing/compare/pyparsing_3.0.9...3.1.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pyparsing&package-manager=pip&previous-version=3.0.9&new-version=3.1.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13334:9111,secur,security-vulnerabilities,9111,https://hail.is,https://github.com/hail-is/hail/pull/13334,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"/a> Test all constructors</li>; <li><a href=""https://github.com/apache/commons-codec/commit/3535c17eccb2251fc518aa545a800b4922c8dc35""><code>3535c17</code></a> Test encode of null and empty array with an offset</li>; <li><a href=""https://github.com/apache/commons-codec/commit/e42dfe1ff2f273926fd759abea82b1c7b3021985""><code>e42dfe1</code></a> Fix test names</li>; <li><a href=""https://github.com/apache/commons-codec/commit/536587931cb77538709c57455165379a74e2f04f""><code>5365879</code></a> Test the codec policy property</li>; <li>Additional commits viewable in <a href=""https://github.com/apache/commons-codec/compare/commons-codec-1.11...rel/commons-codec-1.15"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=commons-codec:commons-codec&package-manager=gradle&previous-version=1.11&new-version=1.15)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12385:4940,secur,security-vulnerabilities,4940,https://hail.is,https://github.com/hail-is/hail/pull/12385,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"/a>)</li>; <li><a href=""https://github.com/python/typing_extensions/commit/9683c1a82add3182be967050d164349da426a20f""><code>9683c1a</code></a> Backport test case from #python/cpython/96358 (<a href=""https://github-redirect.dependabot.com/python/typing_extensions/issues/71"">#71</a>)</li>; <li><a href=""https://github.com/python/typing_extensions/commit/db79268673ac10412b4aad19efea03948869b7db""><code>db79268</code></a> Silence a <code>flake8-bugbear</code> warning (<a href=""https://github-redirect.dependabot.com/python/typing_extensions/issues/72"">#72</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/python/typing_extensions/compare/4.3.0...4.4.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=typing-extensions&package-manager=pip&previous-version=4.3.0&new-version=4.4.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12288:4403,secur,security-vulnerabilities,4403,https://hail.is,https://github.com/hail-is/hail/pull/12288,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"/aio-libs/aiorwlock/issues/250"">#250</a>)</li>; <li><a href=""https://github.com/aio-libs/aiorwlock/commit/63f68eb11d293a5e15133ef933304eddf61753e7""><code>63f68eb</code></a> Bump pytest-asyncio from 0.16.0 to 0.17.0 (<a href=""https://github-redirect.dependabot.com/aio-libs/aiorwlock/issues/249"">#249</a>)</li>; <li><a href=""https://github.com/aio-libs/aiorwlock/commit/34092ffd1f8927d68dc3e3e9f2a0bfddbdc3a382""><code>34092ff</code></a> Bump flake8-bugbear from 21.11.29 to 22.1.11 (<a href=""https://github-redirect.dependabot.com/aio-libs/aiorwlock/issues/248"">#248</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/aio-libs/aiorwlock/compare/v1.0.0...v1.3.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=aiorwlock&package-manager=pip&previous-version=1.0.0&new-version=1.3.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11514:3804,secur,security-vulnerabilities,3804,https://hail.is,https://github.com/hail-is/hail/pull/11514,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"/authlib/issues/275"">#275</a></li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/lepture/authlib/blob/master/docs/changelog.rst"">authlib's changelog</a>.</em></p>; <blockquote>; <h2>Version 0.15.5</h2>; <p><strong>Released on Oct 18, 2021.</strong></p>; <ul>; <li>Make Authlib compatible with latest httpx</li>; <li>Make Authlib compatible with latest werkzeug</li>; <li>Allow customize RFC7523 <code>alg</code> value</li>; </ul>; <h2>Version 0.15.4</h2>; <p><strong>Released on Jul 17, 2021.</strong></p>; <ul>; <li>Security fix when JWT claims is None.</li>; </ul>; <h2>Version 0.15.3</h2>; <p><strong>Released on Jan 15, 2021.</strong></p>; <ul>; <li>Fixed <code>.authorize_access_token</code> for OAuth 1.0 services, via :gh:<code>issue#308</code>.</li>; </ul>; <h2>Version 0.15.2</h2>; <p><strong>Released on Oct 18, 2020.</strong></p>; <ul>; <li>Fixed HTTPX authentication bug, via :gh:<code>issue#283</code>.</li>; </ul>; <h2>Version 0.15.1</h2>; <p><strong>Released on Oct 14, 2020.</strong></p>; <ul>; <li>Backward compitable fix for using JWKs in JWT, via :gh:<code>issue#280</code>.</li>; </ul>; <h2>Version 0.15</h2>; <p><strong>Released on Oct 10, 2020.</strong></p>; <p>This is the last release before v1.0. In this release, we added more RFCs; implementations and did some refactors for JOSE:</p>; <ul>; <li>RFC8037: CFRG Elliptic Curve Diffie-Hellman (ECDH) and Signatures in JSON Object Signing and Encryption (JOSE)</li>; <li>RFC7638: JSON Web Key (JWK) Thumbprint</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/lepture/authlib/commit/d8e428c9350c792fc3d25dbaaffa3bfefaabd8e3""><code>d8e428c</code></a> Version bump 0.15.5</li>; <li><a href=""https://github.com/lepture/authlib/commit/f24962835fd0725349cb1b368ee69ba0cc8670f9""><code>f",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11483:3156,authenticat,authentication,3156,https://hail.is,https://github.com/hail-is/hail/pull/11483,1,['authenticat'],['authentication']
Security,"/b64ec22effafffc6a1371e544c560e6bfc24b56e""><code>b64ec22</code></a> Add explicit name in setup.py</li>; <li><a href=""https://github.com/thibaudcolas/curlylint/commit/4f8ef056177513ea599597d4089fed4275ae5d12""><code>4f8ef05</code></a> chore(deps): update actions/checkout action to v3 (<a href=""https://github-redirect.dependabot.com/thibaudcolas/curlylint/issues/121"">#121</a>)</li>; <li><a href=""https://github.com/thibaudcolas/curlylint/commit/6389c5acb15153df43b0681cb1333bbd892c3a16""><code>6389c5a</code></a> chore: allow automerge for official GitHub Actions</li>; <li>Additional commits viewable in <a href=""https://github.com/thibaudcolas/curlylint/compare/v0.12.0...v0.13.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=curlylint&package-manager=pip&previous-version=0.12.0&new-version=0.13.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11713:9350,secur,security-vulnerabilities,9350,https://hail.is,https://github.com/hail-is/hail/pull/11713,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"/code> to monitor webhooks that fail to open. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/107171"">kubernetes/kubernetes#107171</a>, <a href=""https://github.com/ltagliamonte-dd""><code>@​ltagliamonte-dd</code></a>)</li>; <li>Adds a new Status subresource in Network Policy objects (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/107963"">kubernetes/kubernetes#107963</a>, <a href=""https://github.com/rikatz""><code>@​rikatz</code></a>)</li>; <li>Adds support for <code>InterfaceNamePrefix</code> and <code>BridgeInterface</code> as arguments to <code>--detect-local-mode</code> option and also introduces a new optional <code>--pod-interface-name-prefix</code> and <code>--pod-bridge-interface</code> flags to kube-proxy. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/95400"">kubernetes/kubernetes#95400</a>, <a href=""https://github.com/tssurya""><code>@​tssurya</code></a>)</li>; <li>CEL CRD validation expressions may now reference existing object state using the identifier <code>oldSelf</code>. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/108073"">kubernetes/kubernetes#108073</a>, <a href=""https://github.com/benluddy""><code>@​benluddy</code></a>)</li>; <li>CRD deep copies should no longer contain shallow copies of <code>JSONSchemaProps.XValidations</code>. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/107956"">kubernetes/kubernetes#107956</a>, <a href=""https://github.com/benluddy""><code>@​benluddy</code></a>)</li>; <li>CRD writes will generate validation errors if a CEL validation rule references the identifier <code>oldSelf</code> on a part of the schema that does not support it. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/108013"">kubernetes/kubernetes#108013</a>, <a href=""https://github.com/benluddy""><code>@​benluddy</code></a>)</li>; <li>CSIStorageCapacity.storage.k8s.io: The v1beta1 version of this AP",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12196:3042,validat,validation,3042,https://hail.is,https://github.com/hail-is/hail/pull/12196,1,['validat'],['validation']
Security,"/github-redirect.dependabot.com/grpc/grpc/issues/30326"">#30326</a>)</li>; <li><a href=""https://github.com/grpc/grpc/commit/4c51abf12053e3c43a62059c693322ea992b35ce""><code>4c51abf</code></a> Bump version to 1.48.0-pre1 (on v1.48.x branch) (<a href=""https://github-redirect.dependabot.com/grpc/grpc/issues/30194"">#30194</a>)</li>; <li><a href=""https://github.com/grpc/grpc/commit/46bd0be2c99aa8228ec5d93d8a27f20ab0c61956""><code>46bd0be</code></a> Bump core version to 26.0.0 for upcoming release (<a href=""https://github-redirect.dependabot.com/grpc/grpc/issues/30163"">#30163</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/grpc/grpc/compare/v1.47.0...v1.48.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=grpcio&package-manager=pip&previous-version=1.47.0&new-version=1.48.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12201:6355,secur,security-vulnerabilities,6355,https://hail.is,https://github.com/hail-is/hail/pull/12201,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"/github-redirect.dependabot.com/jaraco/zipp/issues/62"">#62</a>)</li>; <li><a href=""https://github.com/jaraco/zipp/commit/a4f5b769793af19f7b858816889c1bf026f55f5c""><code>a4f5b76</code></a> Update base URL for PEPs (<a href=""https://github-redirect.dependabot.com/jaraco/zipp/issues/61"">#61</a>)</li>; <li><a href=""https://github.com/jaraco/zipp/commit/10bf1b1fb9e09e9836bea9e2edec620cd9eea7f9""><code>10bf1b1</code></a> Add Python 3.11 into the matrix using workaround from <a href=""https://github-redirect.dependabot.com/actions/setup-python/issues/21"">actions/setup-python#21</a>...</li>; <li>Additional commits viewable in <a href=""https://github.com/jaraco/zipp/compare/v3.8.0...v3.8.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=zipp&package-manager=pip&previous-version=3.8.0&new-version=3.8.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12108:2891,secur,security-vulnerabilities,2891,https://hail.is,https://github.com/hail-is/hail/pull/12108,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"/github.com/michel-kraemer/gradle-download-task/commit/b3fa29f9ffb4d4544e13ef84601e371fb2778ddf""><code>b3fa29f</code></a> Revert &quot;Update Apache HttpClient to 5.2.1&quot;</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/01f05e046be0dca18f506723c79e88f208336e71""><code>01f05e0</code></a> Add integration tests for Gradle 6.9.3 and 7.6</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/a998a544908a8b39f713f4526f717fcb328c06eb""><code>a998a54</code></a> Upgrade Gradle to 7.6</li>; <li>Additional commits viewable in <a href=""https://github.com/michel-kraemer/gradle-download-task/compare/5.3.0...5.3.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=de.undercouch.download&package-manager=gradle&previous-version=5.3.0&new-version=5.3.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12707:3520,secur,security-vulnerabilities,3520,https://hail.is,https://github.com/hail-is/hail/pull/12707,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"/github.com/psf/black/commit/afed2c01903465f9a486ac481a66aa3413cc1b01""><code>afed2c0</code></a> Load .gitignore and exclude regex at time of use</li>; <li><a href=""https://github.com/psf/black/commit/e269f44b25737360e0dc65379f889dfa931dc68a""><code>e269f44</code></a> Lazily import parallelized format modules</li>; <li><a href=""https://github.com/psf/black/commit/c47b91f513052cd39b818ea7c19716423c85c04e""><code>c47b91f</code></a> Fix misdetection of project root with <code>--stdin-filename</code> (<a href=""https://github-redirect.dependabot.com/psf/black/issues/3216"">#3216</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/psf/black/compare/22.3.0...22.8.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=black&package-manager=pip&previous-version=22.3.0&new-version=22.8.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12174:11511,secur,security-vulnerabilities,11511,https://hail.is,https://github.com/hail-is/hail/pull/12174,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"/github.com/python-jsonschema/jsonschema/commit/76b2e597d691e4cf5e9ebb7f3d1cff4f5da0115a""><code>76b2e59</code></a> Merge commit '095a009acc1938caf9596085d5581e7196021f66'</li>; <li><a href=""https://github.com/python-jsonschema/jsonschema/commit/aeecae37b17b430c328d3c3e15bec90d30c8848b""><code>aeecae3</code></a> Squashed 'json/' changes from d40b3e62f..cf78d97d0</li>; <li><a href=""https://github.com/python-jsonschema/jsonschema/commit/2f3a79c61176f60c9244d07fa8afb728218270ff""><code>2f3a79c</code></a> Merge commit 'aeecae37b17b430c328d3c3e15bec90d30c8848b'</li>; <li>Additional commits viewable in <a href=""https://github.com/python-jsonschema/jsonschema/compare/v4.6.0...v4.6.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=jsonschema&package-manager=pip&previous-version=4.6.0&new-version=4.6.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11981:4199,secur,security-vulnerabilities,4199,https://hail.is,https://github.com/hail-is/hail/pull/11981,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"/github.com/tornadoweb/tornado/commit/7dfe8b597f2d179334d7b528f61e9449ac131273""><code>7dfe8b5</code></a> httpserver_test: Add ExpectLog to fix CI</li>; <li><a href=""https://github.com/tornadoweb/tornado/commit/217295b1dd30f556ea374d62007f6821688f00f0""><code>217295b</code></a> http1connection: Make content-length parsing more strict</li>; <li><a href=""https://github.com/tornadoweb/tornado/commit/e3aa6c5e2943242d8ab25448c2798365b3cb9945""><code>e3aa6c5</code></a> Merge pull request <a href=""https://redirect.github.com/tornadoweb/tornado/issues/3267"">#3267</a> from bdarnell/branch6.3</li>; <li>See full diff in <a href=""https://github.com/tornadoweb/tornado/compare/v6.3.2...v6.3.3"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=tornado&package-manager=pip&previous-version=6.3.2&new-version=6.3.3)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13432:2760,secur,security-vulnerabilities,2760,https://hail.is,https://github.com/hail-is/hail/pull/13432,4,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"/issues/1481"">#1481</a>: Fix NPE in NativeLibrary when unpacking from classpath is disabled - <a href=""https://github.com/trespasserw""><code>@​trespasserw</code></a>.</li>; <li><a href=""https://redirect.github.com/java-native-access/jna/pull/1489"">#1489</a>: Fixes typo in <code>OpenGL32Util#wglGetProcAddress</code>, instead of parameter <code>procName</code> the hardcoded value <code>wglEnumGpusNV</code> was used - <a href=""https://github.com/soywiz""><code>@​soywiz</code></a>.</li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/java-native-access/jna/commit/4962fd7758493b7395e86578705d8a32f6238872""><code>4962fd7</code></a> Release 5.13.0</li>; <li><a href=""https://github.com/java-native-access/jna/commit/a56504611b00cc7d90c165f924c3915cb7a6f759""><code>a565046</code></a> Adjust release directions</li>; <li><a href=""https://github.com/java-native-access/jna/commit/f7017c4f957d7fc13c7455efcae200e29407a729""><code>f7017c4</code></a> Remove artifacts classified as &quot;-jpms&quot;, there are the jna-jpms and jna-platfo...</li>; <li><a href=""https://github.com/java-native-access/jna/commit/a5f47cd359d5fe62a0e5d6c2bd9d649874be955d""><code>a5f47cd</code></a> Merge pull request <a href=""https://redirect.github.com/java-native-access/jna/issues/1494"">#1494</a> from matthiasblaesing/pr-1492</li>; <li><a href=""https://github.com/java-native-access/jna/commit/1af6eb14e0059c7acd5d5ee71fd62e519536fac5""><code>1af6eb1</code></a> Improve documentation, ensure osgi.version is defined, wrap create-export-pac...</li>; <li><a href=""https://github.com/java-native-access/jna/commit/65cf52803ec2249c61573bdc7bd4314b77c019a0""><code>65cf528</code></a> add utility shell script to create 'Export-Package' metadata</li>; <li><a href=""https://github.com/java-native-access/jna/commit/b3984aaf1bf87c8da2e84797f62180adc405b48a""><code>b3984aa</code></a> Add 'uses' information to OSGI metadata in MANIFEST.MF</li>; <li><a href=""https://github.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12886:4184,access,access,4184,https://hail.is,https://github.com/hail-is/hail/pull/12886,1,['access'],['access']
Security,"/li>; <li><a href=""https://github.com/AzureAD/microsoft-authentication-extensions-for-python/commit/fa1f45b556341b2c34e9bf63c06a5068571cd337""><code>fa1f45b</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/AzureAD/microsoft-authentication-extensions-for-python/issues/108"">#108</a> from AzureAD/actionable-encryption-exceptions</li>; <li><a href=""https://github.com/AzureAD/microsoft-authentication-extensions-for-python/commit/effe77842d25a8b093d18d9e33347f13e2ee094f""><code>effe778</code></a> Provide actionable messages for 2 dpapi errors</li>; <li><a href=""https://github.com/AzureAD/microsoft-authentication-extensions-for-python/commit/b674b6a07ca27b2c1b6f371040f035a546cfd468""><code>b674b6a</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/AzureAD/microsoft-authentication-extensions-for-python/issues/107"">#107</a> from AzureAD/file600</li>; <li>Additional commits viewable in <a href=""https://github.com/AzureAD/microsoft-authentication-extensions-for-python/compare/0.3.1...1.0.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=msal-extensions&package-manager=pip&previous-version=0.3.1&new-version=1.0.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI p",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11992:4490,authenticat,authentication-extensions-for-python,4490,https://hail.is,https://github.com/hail-is/hail/pull/11992,1,['authenticat'],['authentication-extensions-for-python']
Security,"/li>; <li><a href=""https://github.com/pallets/jinja/commit/466a200ea40642b674db77588d13889abbad55f5""><code>466a200</code></a> update requirements</li>; <li><a href=""https://github.com/pallets/jinja/commit/990602f719b4086540287e95f601baefd830d790""><code>990602f</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pallets/jinja/issues/1647"">#1647</a> from Tom-Brouwer/202204/add-missing-overlay-options</li>; <li><a href=""https://github.com/pallets/jinja/commit/5d3d2414710c1439105d84efc58e4aba8e453cb3""><code>5d3d241</code></a> fix flake8-bugbear finding</li>; <li>Additional commits viewable in <a href=""https://github.com/pallets/jinja/compare/3.0.3...3.1.2"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=jinja2&package-manager=pip&previous-version=3.0.3&new-version=3.1.2)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12173:6806,secur,security-vulnerabilities,6806,https://hail.is,https://github.com/hail-is/hail/pull/12173,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"/numpy/numpy/issues/22593"">#22593</a> from charris/backport-22447</li>; <li><a href=""https://github.com/numpy/numpy/commit/3ca02ce5b1a4ec2412cad839d42452a4200a5270""><code>3ca02ce</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/numpy/numpy/issues/22594"">#22594</a> from charris/backport-22450</li>; <li><a href=""https://github.com/numpy/numpy/commit/8cededdf4eeebd4f1985bd74c11fbf44f367937f""><code>8cededd</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/numpy/numpy/issues/22592"">#22592</a> from charris/backport-22393</li>; <li>Additional commits viewable in <a href=""https://github.com/numpy/numpy/compare/v1.21.6...v1.23.5"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=numpy&package-manager=pip&previous-version=1.21.6&new-version=1.23.5)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12515:6498,secur,security-vulnerabilities,6498,https://hail.is,https://github.com/hail-is/hail/pull/12515,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"/p>; <blockquote>; <h1>1.26.16</h1>; <ul>; <li>api-change:<code>grafana</code>: [<code>botocore</code>] This release includes support for configuring a Grafana workspace to connect to a datasource within a VPC as well as new APIs for configuring Grafana settings.</li>; <li>api-change:<code>rbin</code>: [<code>botocore</code>] This release adds support for Rule Lock for Recycle Bin, which allows you to lock retention rules so that they can no longer be modified or deleted.</li>; </ul>; <h1>1.26.15</h1>; <ul>; <li>bugfix:Endpoints: [<code>botocore</code>] Resolve endpoint with default partition when no region is set</li>; <li>bugfix:s3: [<code>botocore</code>] fixes missing x-amz-content-sha256 header for s3 object lambda</li>; <li>api-change:<code>appflow</code>: [<code>botocore</code>] Adding support for Amazon AppFlow to transfer the data to Amazon Redshift databases through Amazon Redshift Data API service. This feature will support the Redshift destination connector on both public and private accessible Amazon Redshift Clusters and Amazon Redshift Serverless.</li>; <li>api-change:<code>kinesisanalyticsv2</code>: [<code>botocore</code>] Support for Apache Flink 1.15 in Kinesis Data Analytics.</li>; </ul>; <h1>1.26.14</h1>; <ul>; <li>api-change:<code>route53</code>: [<code>botocore</code>] Amazon Route 53 now supports the Asia Pacific (Hyderabad) Region (ap-south-2) for latency records, geoproximity records, and private DNS for Amazon VPCs in that region.</li>; </ul>; <h1>1.26.13</h1>; <ul>; <li>api-change:<code>appflow</code>: [<code>botocore</code>] AppFlow provides a new API called UpdateConnectorRegistration to update a custom connector that customers have previously registered. With this API, customers no longer need to unregister and then register a connector to make an update.</li>; <li>api-change:<code>auditmanager</code>: [<code>botocore</code>] This release introduces a new feature for Audit Manager: Evidence finder. You can now use evidence finder to qui",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12502:1237,access,accessible,1237,https://hail.is,https://github.com/hail-is/hail/pull/12502,1,['access'],['accessible']
Security,"/p><br /><h3>Snyk has created this PR to fix one or more vulnerable packages in the `pip` dependencies of this project.</h3>. #### Changes included in this PR. - Changes to the following files to upgrade the vulnerable dependencies to a fixed version:; - gear/pinned-requirements.txt. <details>; <summary>⚠️ <b>Warning</b></summary>. ```; prometheus-async 19.2.0 requires prometheus-client, which is not installed. ```; </details>. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **663/1000** <br/> **Why?** Proof of Concept exploit, Recently disclosed, Has a fix available, CVSS 5.4 | Improper Input Validation <br/>[SNYK-PYTHON-AIOHTTP-6091621](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-6091621) | `aiohttp:` <br> `3.8.6 -> 3.9.0` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **663/1000** <br/> **Why?** Proof of Concept exploit, Recently disclosed, Has a fix available, CVSS 5.4 | Improper Input Validation <br/>[SNYK-PYTHON-AIOHTTP-6091622](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-6091622) | `aiohttp:` <br> `3.8.6 -> 3.9.0` <br> | No | Proof of Concept . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this b",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14034:1063,Validat,Validation,1063,https://hail.is,https://github.com/hail-is/hail/pull/14034,1,['Validat'],['Validation']
Security,"/protobuf/issues/9486"">#9486</a>)</li>; <li>Allocate with xrealloc()/xfree() so message allocation is visible to the; Ruby GC. In certain tests this leads to much lower memory usage due to more; frequent GC runs (<a href=""https://github-redirect.dependabot.com/protocolbuffers/protobuf/issues/9586"">#9586</a>).</li>; <li>Fix conversion of singleton classes in Ruby (<a href=""https://github-redirect.dependabot.com/protocolbuffers/protobuf/issues/9342"">#9342</a>)</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li>See full diff in <a href=""https://github.com/protocolbuffers/protobuf/commits"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=protobuf&package-manager=pip&previous-version=3.19.6&new-version=4.21.12)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12563:4213,secur,security-vulnerabilities,4213,https://hail.is,https://github.com/hail-is/hail/pull/12563,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"/redirect.github.com/pyca/cryptography/issues/8975"">#8975</a>)</li>; <li><a href=""https://github.com/pyca/cryptography/commit/851d8ccb340bfc93c827b9e80af939a216b34925""><code>851d8cc</code></a> Bump openssl from 0.10.52 to 0.10.53 in /src/rust (<a href=""https://redirect.github.com/pyca/cryptography/issues/8986"">#8986</a>)</li>; <li><a href=""https://github.com/pyca/cryptography/commit/0918c7236c94c29272e0790ba0227cfa9401943b""><code>0918c72</code></a> Bump coverage from 7.2.6 to 7.2.7 (<a href=""https://redirect.github.com/pyca/cryptography/issues/8985"">#8985</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/pyca/cryptography/compare/40.0.2...41.0.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=cryptography&package-manager=pip&previous-version=40.0.2&new-version=41.0.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13146:5042,secur,security-vulnerabilities,5042,https://hail.is,https://github.com/hail-is/hail/pull/13146,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"/samtools/htsjdk/issues/1592"">#1592</a>); 6507249a4 Make the CRAM MD5 failure message more user friendly. (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1607"">#1607</a>); b5af659e6 Fix restoration of read base feature code. <a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1379"">#1379</a> (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1590"">#1590</a>); e63c34a92 Ignore TC, TN on CRAM read (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1578"">#1578</a>)</p>; <p>BAM/SAM; 1449dec45 Support loading of CSI from URLs/streams. <a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1507"">#1507</a> (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1595"">#1595</a>); a38c78d6c Add an option to SAMFileWriter to disable checking of ordering of rec… (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1599"">#1599</a>); 51aa6ed2b Validate that SAM header tag keys are exactly 2 characters long (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1561"">#1561</a>); fbd9e96d5 Deprecate OTHER as a PL value (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1552"">#1552</a>); d5f7e106b Adding PL Tag 'DNBSEQ' as the Platform/Technology for BGI/MGI (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1547"">#1547</a>)</p>; <p>Misc Improvements; f461401e3 Silence AsciiLineReader warning when creating a FASTA sequence index (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1559"">#1559</a>); 8f82871c1 Update explain samflags script to python3 (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1585"">#1585</a>); 4ba4c0678 Update to new version of the snappy library which will work with M1 macs (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1580"">#1580</a>); e92706452 add predicate to GFF3Codec to give a chance to filter ou",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12229:3329,Validat,Validate,3329,https://hail.is,https://github.com/hail-is/hail/pull/12229,2,['Validat'],['Validate']
Security,"/summary>; <ul>; <li><a href=""https://github.com/ipython/comm/commit/d119118d950f2c64f184c37e7e42b4c968701668""><code>d119118</code></a> Publish 0.2.2</li>; <li><a href=""https://github.com/ipython/comm/commit/76149e7ee0f331772c964ae86cdb8bafebe6dfa2""><code>76149e7</code></a> Update Release Scripts (<a href=""https://redirect.github.com/ipython/comm/issues/27"">#27</a>)</li>; <li><a href=""https://github.com/ipython/comm/commit/915898ddeddd0d1c8a1b87c5dcfbe6392fd225b7""><code>915898d</code></a> chore: update pre-commit hooks (<a href=""https://redirect.github.com/ipython/comm/issues/26"">#26</a>)</li>; <li>See full diff in <a href=""https://github.com/ipython/comm/compare/v0.2.1...v0.2.2"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=comm&package-manager=pip&previous-version=0.2.1&new-version=0.2.2)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14492:3771,secur,security-vulnerabilities,3771,https://hail.is,https://github.com/hail-is/hail/pull/14492,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"00</a></li>; <li>Add exception chaining by <a href=""https://github.com/ehdgua01""><code>@​ehdgua01</code></a> in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/702"">jpadilla/pyjwt#702</a></li>; <li>Revert &quot;Remove arbitrary kwargs.&quot; by <a href=""https://github.com/auvipy""><code>@​auvipy</code></a> in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/701"">jpadilla/pyjwt#701</a></li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/jpadilla/pyjwt/blob/master/CHANGELOG.rst"">pyjwt's changelog</a>.</em></p>; <blockquote>; <h2><code>v2.4.0 &lt;https://github.com/jpadilla/pyjwt/compare/2.3.0...2.4.0&gt;</code>__</h2>; <p>Security</p>; <pre><code>; - [CVE-2022-29217] Prevent key confusion through non-blocklisted public key formats. https://github.com/jpadilla/pyjwt/security/advisories/GHSA-ffqj-6fqr-9h24; <p>Changed</p>; <pre><code>; - Explicit check the key for ECAlgorithm by @estin in https://github.com/jpadilla/pyjwt/pull/713; - Raise DeprecationWarning for jwt.decode(verify=...) by @akx in https://github.com/jpadilla/pyjwt/pull/742. Fixed; ~~~~~. - Don't use implicit optionals by @rekyungmin in https://github.com/jpadilla/pyjwt/pull/705; - documentation fix: show correct scope for decode_complete() by @sseering in https://github.com/jpadilla/pyjwt/pull/661; - fix: Update copyright information by @kkirsche in https://github.com/jpadilla/pyjwt/pull/729; - Don't mutate options dictionary in .decode_complete() by @akx in https://github.com/jpadilla/pyjwt/pull/743. Added; ~~~~~. - Add support for Python 3.10 by @hugovk in https://github.com/jpadilla/pyjwt/pull/699; - api_jwk: Add PyJWKSet.__getitem__ by @woodruffw in https://github.com/jpadilla/pyjwt/pull/725; - Update usage.rst by @guneybilen in https://github.com/jpadilla/pyjwt/pull/727; - Docs: mention performance reasons for reusing RSAPrivateKey when ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11866:9335,secur,security,9335,https://hail.is,https://github.com/hail-is/hail/pull/11866,1,['secur'],['security']
Security,"01:04:37.601 : INFO: TaskReport: stage=0, partition=0, attempt=0, peakBytes=0, peakBytesReadable=0.00 B, chunks requested=0, cache hits=0; 2023-05-04 01:04:37.601 : INFO: RegionPool: FREE: 0 allocated (0 blocks / 0 chunks), regions.size = 0, 0 current java objects, thread 8: pool-1-thread-1; 2023-05-04 01:04:37.601 : INFO: RegionPool: FREE: 128.0K allocated (128.0K blocks / 0 chunks), regions.size = 2, 0 current java objects, thread 8: pool-1-thread-1; 2023-05-04 01:04:37.603 : ERROR: SocketException: Connection reset; From javax.net.ssl.SSLException: Connection reset; 	at sun.security.ssl.Alert.createSSLException(Alert.java:127); 	at sun.security.ssl.TransportContext.fatal(TransportContext.java:324); 	at sun.security.ssl.TransportContext.fatal(TransportContext.java:267); 	at sun.security.ssl.TransportContext.fatal(TransportContext.java:262); 	at sun.security.ssl.SSLTransport.decode(SSLTransport.java:138); 	at sun.security.ssl.SSLSocketImpl.decode(SSLSocketImpl.java:1400); 	at sun.security.ssl.SSLSocketImpl.readApplicationRecord(SSLSocketImpl.java:1368); 	at sun.security.ssl.SSLSocketImpl.access$300(SSLSocketImpl.java:73); 	at sun.security.ssl.SSLSocketImpl$AppInputStream.read(SSLSocketImpl.java:962); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:284); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.MeteredStream.read(MeteredStream.java:134); 	at java.io.FilterInputStream.read(FilterInputStream.java:133); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3456); 	at com.google.api.client.http.javanet.NetHttpResponse$SizeValidatingInputStream.read(NetHttpResponse.java:164); 	at java.nio.channels.Channels$ReadableByteChannelImpl.read(Channels.java:385); 	at is.hail.relocated.com.google.cloud.storage.StorageByteChannels$ScatteringByteChannelFacade.read(StorageByteChannels.java:226); 	at is.hail.relocated.com.google.cloud.storage.ApiaryUnbufferedReadableByteChannel.read(ApiaryUn",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12983:24058,secur,security,24058,https://hail.is,https://github.com/hail-is/hail/issues/12983,1,['secur'],['security']
Security,"024</a>)</li>; <li><a href=""https://github.com/giampaolo/psutil/commit/a1ae994cabff37eb86c6ca4564b4f193a73a7b0d""><code>a1ae994</code></a> fix <a href=""https://github-redirect.dependabot.com/giampaolo/psutil/issues/2023"">#2023</a> [Linux] cpu_freq() return order is wrong on systems with &gt; 9 CPUs.</li>; <li><a href=""https://github.com/giampaolo/psutil/commit/875d2195fc8efa642c7bca714d468551d1805c6c""><code>875d219</code></a> Handle missing dependencies on MidnightBSD (<a href=""https://github-redirect.dependabot.com/giampaolo/psutil/issues/2019"">#2019</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/giampaolo/psutil/compare/release-5.8.0...release-5.9.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=psutil&package-manager=pip&previous-version=5.8.0&new-version=5.9.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11459:6469,secur,security-vulnerabilities,6469,https://hail.is,https://github.com/hail-is/hail/pull/11459,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"04:37.601 : INFO: RegionPool: FREE: 0 allocated (0 blocks / 0 chunks), regions.size = 0, 0 current java objects, thread 8: pool-1-thread-1; 2023-05-04 01:04:37.601 : INFO: RegionPool: FREE: 128.0K allocated (128.0K blocks / 0 chunks), regions.size = 2, 0 current java objects, thread 8: pool-1-thread-1; 2023-05-04 01:04:37.603 : ERROR: SocketException: Connection reset; From javax.net.ssl.SSLException: Connection reset; 	at sun.security.ssl.Alert.createSSLException(Alert.java:127); 	at sun.security.ssl.TransportContext.fatal(TransportContext.java:324); 	at sun.security.ssl.TransportContext.fatal(TransportContext.java:267); 	at sun.security.ssl.TransportContext.fatal(TransportContext.java:262); 	at sun.security.ssl.SSLTransport.decode(SSLTransport.java:138); 	at sun.security.ssl.SSLSocketImpl.decode(SSLSocketImpl.java:1400); 	at sun.security.ssl.SSLSocketImpl.readApplicationRecord(SSLSocketImpl.java:1368); 	at sun.security.ssl.SSLSocketImpl.access$300(SSLSocketImpl.java:73); 	at sun.security.ssl.SSLSocketImpl$AppInputStream.read(SSLSocketImpl.java:962); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:284); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.MeteredStream.read(MeteredStream.java:134); 	at java.io.FilterInputStream.read(FilterInputStream.java:133); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3456); 	at com.google.api.client.http.javanet.NetHttpResponse$SizeValidatingInputStream.read(NetHttpResponse.java:164); 	at java.nio.channels.Channels$ReadableByteChannelImpl.read(Channels.java:385); 	at is.hail.relocated.com.google.cloud.storage.StorageByteChannels$ScatteringByteChannelFacade.read(StorageByteChannels.java:226); 	at is.hail.relocated.com.google.cloud.storage.ApiaryUnbufferedReadableByteChannel.read(ApiaryUnbufferedReadableByteChannel.java:104); 	at is.hail.relocated.com.google.cloud.storage.UnbufferedReadableByteChannelSession$UnbufferedReadableByteChannel.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12983:24211,secur,security,24211,https://hail.is,https://github.com/hail-is/hail/issues/12983,1,['secur'],['security']
Security,"05ee42</code></a> test(deps): update testbench version to v0.32.0 (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1768"">#1768</a>)</li>; <li><a href=""https://github.com/googleapis/java-storage/commit/8ea8131d17eba29859518da7199bbd03019d0644""><code>8ea8131</code></a> chore: update google-auth to 2.14.1 (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1703"">#1703</a>) (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1767"">#1767</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/googleapis/java-storage/compare/v1.106.0...v2.15.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=com.google.cloud:google-cloud-storage&package-manager=gradle&previous-version=1.106.0&new-version=2.15.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12529:14359,secur,security-vulnerabilities,14359,https://hail.is,https://github.com/hail-is/hail/pull/12529,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"0696</a> from jfbu/latex_fix_for_old_latex</li>; <li><a href=""https://github.com/sphinx-doc/sphinx/commit/d1b4a75f4f09281af70a04fb405c126744c54651""><code>d1b4a75</code></a> LaTeX: fix another incompatibility with old pict2e LaTeX</li>; <li><a href=""https://github.com/sphinx-doc/sphinx/commit/faccc2182275354ebe7d85ac61dd753887b98315""><code>faccc21</code></a> Fix <a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10695"">#10695</a>: old LaTeX does not allow <a href=""https://github.com/ifpackageloaded""><code>@​ifpackageloaded</code></a> usage in body</li>; <li>Additional commits viewable in <a href=""https://github.com/sphinx-doc/sphinx/compare/v3.5.4...v5.1.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=sphinx&package-manager=pip&previous-version=3.5.4&new-version=5.1.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12165:8005,secur,security-vulnerabilities,8005,https://hail.is,https://github.com/hail-is/hail/pull/12165,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"074d6e9""><code>a41e349</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pallets/click/issues/2234"">#2234</a> from pallets/release-8.1.1</li>; <li><a href=""https://github.com/pallets/click/commit/3c301ebacbfe8ec7dc3d9d46ebf517082a8ee4b1""><code>3c301eb</code></a> release version 8.1.1</li>; <li><a href=""https://github.com/pallets/click/commit/d5741a2ca2ebc21d525c903f628b1bebad75b735""><code>d5741a2</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pallets/click/issues/2233"">#2233</a> from henryiii/henryiii/fix/commandtype</li>; <li>Additional commits viewable in <a href=""https://github.com/pallets/click/compare/8.0.4...8.1.2"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=click&package-manager=pip&previous-version=8.0.4&new-version=8.1.2)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11801:6989,secur,security-vulnerabilities,6989,https://hail.is,https://github.com/hail-is/hail/pull/11801,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"08-0.2.34-914bd8a10ca2.log; {'_Task__hash': -3818947167740532127,; 'clinvar_ht_path': 'gs://seqr-reference-data/GRCh38/clinvar/clinvar.GRCh38.2020-03-29.ht',; 'dataset_type': 'VARIANTS',; 'decrease_running_resources': <bound method TaskStatusReporter.decrease_running_resources of <luigi.worker.TaskStatusReporter object at 0x7f0583f0f588>>,; 'dest_path': 'gs://seqr-bw/merged_phased_3P5CH.mt',; 'genome_version': '38',; 'hgmd_ht_path': None,; 'param_kwargs': {'clinvar_ht_path': 'gs://seqr-reference-data/GRCh38/clinvar/clinvar.GRCh38.2020-03-29.ht',; 'dataset_type': 'VARIANTS',; 'dest_path': 'gs://seqr-bw/merged_phased_3P5CH.mt',; 'genome_version': '38',; 'hgmd_ht_path': None,; 'reference_ht_path': 'gs://seqr-reference-data/GRCh38/all_reference_data/combined_reference_data_grch38.ht',; 'remap_path': None,; 'sample_type': 'WGS',; 'source_paths': 'gs://seqr-bw/merged_phased_3P5CH.split.vcf.gz',; 'subset_path': None,; 'validate': False,; 'vep_config_json_path': None,; 'vep_runner': 'VEP'},; 'reference_ht_path': 'gs://seqr-reference-data/GRCh38/all_reference_data/combined_reference_data_grch38.ht',; 'remap_path': None,; 'sample_type': 'WGS',; 'scheduler_messages': None,; 'set_progress_percentage': <bound method TaskStatusReporter.update_progress_percentage of <luigi.worker.TaskStatusReporter object at 0x7f0583f0f588>>,; 'set_status_message': <bound method TaskStatusReporter.update_status_message of <luigi.worker.TaskStatusReporter object at 0x7f0583f0f588>>,; 'set_tracking_url': <bound method TaskStatusReporter.update_tracking_url of <luigi.worker.TaskStatusReporter object at 0x7f0583f0f588>>,; 'source_paths': ['gs://seqr-bw/merged_phased_3P5CH.split.vcf.gz'],; 'subset_path': None,; 'task_id': 'SeqrVCFToMTTask_gs___seqr_refere_VARIANTS_gs___seqr_bw_mer_b185718e87',; 'validate': False,; 'vep_config_json_path': None,; 'vep_runner': 'VEP'}; [Stage 1:======================================================>(492 + 8) / 500]2020-04-05 14:09:30 Hail: INFO: Coerced almost-sorted data",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8469:37919,validat,validate,37919,https://hail.is,https://github.com/hail-is/hail/issues/8469,1,['validat'],['validate']
Security,"0</a>)</li>; <li><a href=""https://github.com/googleapis/python-cloud-core/commit/70b348bdfd4c11c77793b907468c206ee457bd32""><code>70b348b</code></a> chore(deps): update all dependencies (<a href=""https://github-redirect.dependabot.com/googleapis/python-cloud-core/issues/188"">#188</a>)</li>; <li><a href=""https://github.com/googleapis/python-cloud-core/commit/6014db08ca2078a1c8ebb37ee46c53dae381e7d5""><code>6014db0</code></a> chore(main): release 2.3.0 (<a href=""https://github-redirect.dependabot.com/googleapis/python-cloud-core/issues/185"">#185</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/googleapis/python-cloud-core/compare/v1.7.2...v2.3.2"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=google-cloud-core&package-manager=pip&previous-version=1.7.2&new-version=2.3.2)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12175:10275,secur,security-vulnerabilities,10275,https://hail.is,https://github.com/hail-is/hail/pull/12175,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"0e55bd51d3693d381ccc06f2fd4b5443d86""><code>c196f0e</code></a> 3.6.6</li>; <li><a href=""https://github.com/ijl/orjson/commit/81890b097f7a479d1c1e697d21467952e0be24a9""><code>81890b0</code></a> Fix 53-bit error on value between isize and usize</li>; <li><a href=""https://github.com/ijl/orjson/commit/8fc1e8989d6a72581aa71533384cb1ef9a260ebc""><code>8fc1e89</code></a> Fast conditional for zoneinfo.ZoneInfo</li>; <li><a href=""https://github.com/ijl/orjson/commit/853ffbdf8dc5f34792765c22aa835e1b67d90a76""><code>853ffbd</code></a> fix(errors): adjust column offset if not at char boundary</li>; <li>Additional commits viewable in <a href=""https://github.com/ijl/orjson/compare/3.6.4...3.6.7"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=orjson&package-manager=pip&previous-version=3.6.4&new-version=3.6.7)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11572:4552,secur,security-vulnerabilities,4552,https://hail.is,https://github.com/hail-is/hail/pull/11572,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,1(LocalBackend.scala:272); E 	at is.hail.backend.local.LocalBackend.$anonfun$execute$1$adapted(LocalBackend.scala:271); E 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$3(ExecuteContext.scala:78); E 	at is.hail.utils.package$.using(package.scala:673); E 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$2(ExecuteContext.scala:78); E 	at is.hail.utils.package$.using(package.scala:673); E 	at is.hail.annotations.RegionPool$.scoped(RegionPool.scala:13); E 	at is.hail.backend.ExecuteContext$.scoped(ExecuteContext.scala:65); E 	at is.hail.backend.local.LocalBackend.$anonfun$withExecuteContext$2(LocalBackend.scala:120); E 	at is.hail.utils.ExecutionTimer$.time(ExecutionTimer.scala:55); E 	at is.hail.utils.ExecutionTimer$.logTime(ExecutionTimer.scala:62); E 	at is.hail.backend.local.LocalBackend.withExecuteContext(LocalBackend.scala:105); E 	at is.hail.backend.local.LocalBackend.execute(LocalBackend.scala:271); E 	at is.hail.backend.BackendHttpHandler.handle(BackendServer.scala:88); E 	at jdk.httpserver/com.sun.net.httpserver.Filter$Chain.doFilter(Filter.java:77); E 	at jdk.httpserver/sun.net.httpserver.AuthFilter.doFilter(AuthFilter.java:82); E 	at jdk.httpserver/com.sun.net.httpserver.Filter$Chain.doFilter(Filter.java:80); E 	at jdk.httpserver/sun.net.httpserver.ServerImpl$Exchange$LinkHandler.handle(ServerImpl.java:848); E 	at jdk.httpserver/com.sun.net.httpserver.Filter$Chain.doFilter(Filter.java:77); E 	at jdk.httpserver/sun.net.httpserver.ServerImpl$Exchange.run(ServerImpl.java:817); E 	at jdk.httpserver/sun.net.httpserver.ServerImpl$DefaultExecutor.execute(ServerImpl.java:201); E 	at jdk.httpserver/sun.net.httpserver.ServerImpl$Dispatcher.handle(ServerImpl.java:560); E 	at jdk.httpserver/sun.net.httpserver.ServerImpl$Dispatcher.run(ServerImpl.java:526); E 	at java.base/java.lang.Thread.run(Thread.java:829); E; E; E; E Hail version: 0.2.132-f39364c177e0; E Error summary: RuntimeException: invalid memory access: 140a68008/00000001: not in 140a58008/00010000; ```,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14705:8619,access,access,8619,https://hail.is,https://github.com/hail-is/hail/issues/14705,1,['access'],['access']
Security,"1. Do not leak the private key for lets encrypt into the renewal container's stdout and consequently into the logs.; 2. Do not revert the secret to an empty state before renewing the certificate. Doing so causes a failed renewal (e.g. 500s from lets encrypt) to destroy the extant keys. ---. Anyone using the Hail infrastructure should both regenerate their lets encrypt certificates with the changes in that PR. To do so they can execute the following from the root of the Hail repository:. make -C letsencrypt run. To take advantage of this vulnerability, someone would need access to the k8s container logs and the ability to redirect the relevant domain name to an IP they control. We have no evidence anyone has done this with Hail’s certs.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11743:40,encrypt,encrypt,40,https://hail.is,https://github.com/hail-is/hail/pull/11743,6,"['access', 'certificate', 'encrypt']","['access', 'certificate', 'certificates', 'encrypt']"
Security,"1. If the user has not specified a configuration for disable_progress_bar, then only disable it if we are noninteractive. 2. Change @fails_service_backend to @skip... for a `to_spark` test. 3. Pass the path collision test by using `Validate`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12535:232,Validat,Validate,232,https://hail.is,https://github.com/hail-is/hail/pull/12535,1,['Validat'],['Validate']
Security,"1. Implement hailtop.aiotools.delete.; 2. Unify most definitions of rmtree and actually use parallelism.; 3. Remove unnecesary and confusing async annotation on OnlineBoundedGather2.call.; 4. Substantially increase the complexity of the rmtree test. I had to fix a circularity caused by RouterAsyncFS referencing the other clouds. The fix was easy, I don't re-expose it in hailtop.aiotools.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11072:360,expose,expose,360,https://hail.is,https://github.com/hail-is/hail/pull/11072,1,['expose'],['expose']
Security,1.apply(CM.scala:82); 	at is.hail.expr.Parser$$anonfun$is$hail$expr$Parser$$evalNoTypeCheck$1.apply(Parser.scala:64); 	at is.hail.expr.Parser$$anonfun$parseTypedExpr$1.apply(Parser.scala:102); 	at scala.Function0$class.apply$mcJ$sp(Function0.scala:34); 	at scala.runtime.AbstractFunction0.apply$mcJ$sp(AbstractFunction0.scala:12); 	at is.hail.utils.Graph$$anonfun$2$$anonfun$apply$4.apply(Graph.scala:81); 	at is.hail.utils.Graph$$anonfun$2$$anonfun$apply$4.apply(Graph.scala:79); 	at is.hail.utils.BinaryHeap.isLeftFavoredTie(BinaryHeap.scala:16); 	at is.hail.utils.BinaryHeap.is$hail$utils$BinaryHeap$$bubbleUp(BinaryHeap.scala:161); 	at is.hail.utils.BinaryHeap.insert(BinaryHeap.scala:40); 	at is.hail.utils.Graph$$anonfun$maximalIndependentSet$1.apply(Graph.scala:101); 	at is.hail.utils.Graph$$anonfun$maximalIndependentSet$1.apply(Graph.scala:100); 	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99); 	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99); 	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230); 	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40); 	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99); 	at is.hail.utils.Graph$.maximalIndependentSet(Graph.scala:100); 	at is.hail.utils.Graph$.maximalIndependentSet(Graph.scala:86); 	at is.hail.utils.Graph.maximalIndependentSet(Graph.scala); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:497); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:280); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.ex,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3704:2453,Hash,HashMap,2453,https://hail.is,https://github.com/hail-is/hail/pull/3704,1,['Hash'],['HashMap']
Security,105); 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:750). java.net.SocketException: Connection reset; 	at java.net.SocketInputStream.read(SocketInputStream.java:210); 	at java.net.SocketInputStream.read(SocketInputStream.java:141); 	at sun.security.ssl.SSLSocketInputRecord.read(SSLSocketInputRecord.java:464); 	at sun.security.ssl.SSLSocketInputRecord.decodeInputRecord(SSLSocketInputRecord.java:237); 	at sun.security.ssl.SSLSocketInputRecord.decode(SSLSocketInputRecord.java:190); 	at sun.security.ssl.SSLTransport.decode(SSLTransport.java:109); 	at sun.security.ssl.SSLSocketImpl.decode(SSLSocketImpl.java:1400); 	at sun.security.ssl.SSLSocketImpl.readApplicationRecord(SSLSocketImpl.java:1368); 	at sun.security.ssl.SSLSocketImpl.access$300(SSLSocketImpl.java:73); 	at sun.security.ssl.SSLSocketImpl$AppInputStream.read(SSLSocketImpl.java:962); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:284); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.MeteredStream.read(MeteredStream.java:134); 	at java.io.FilterInputStream.read(FilterInputStream.java:133); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3456); 	at com.google.api.client.http.javanet.NetHttpResponse$SizeValidatingInputStream.read(NetHttpResponse.java:164); 	at java.nio.channels.Channels$ReadableByteChannelImpl.read(Channels.java:385); 	at is.hail.relocated.com.google.cloud.storage.StorageByteChannels$ScatteringByteChannelFacade.read(StorageByteChannels.java:226); 	at is.hail.relocated.com.go,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12982:14779,secur,security,14779,https://hail.is,https://github.com/hail-is/hail/issues/12982,3,['secur'],['security']
Security,"10db</code></a> Fix linter configs</li>; <li><a href=""https://github.com/aio-libs/async-timeout/commit/6af8bf421a799208b27d57c6bf69de0d998fedec""><code>6af8bf4</code></a> Bump pre-commit from 2.15 to 2.16.0 (<a href=""https://github-redirect.dependabot.com/aio-libs/async-timeout/issues/269"">#269</a>)</li>; <li><a href=""https://github.com/aio-libs/async-timeout/commit/c71bbb5b5d7330f6dabfde7a1adec30a4611c0be""><code>c71bbb5</code></a> Bump docutils from 0.18 to 0.18.1 (<a href=""https://github-redirect.dependabot.com/aio-libs/async-timeout/issues/266"">#266</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/aio-libs/async-timeout/compare/v3.0.1...v4.0.2"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=async-timeout&package-manager=pip&previous-version=3.0.1&new-version=4.0.2)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11465:6589,secur,security-vulnerabilities,6589,https://hail.is,https://github.com/hail-is/hail/pull/11465,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"11509c75cfffd10e1ede1e2266249c0a""><code>b557851</code></a> Make section labels verbose to avoid numeric labels</li>; <li><a href=""https://github.com/readthedocs/sphinx_rtd_theme/commit/73d1707e791712efb837167065c4173ce9b380f8""><code>73d1707</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/readthedocs/sphinx_rtd_theme/issues/1088"">#1088</a> from readthedocs/Blendify/fix-717</li>; <li><a href=""https://github.com/readthedocs/sphinx_rtd_theme/commit/3a031121ed86bc2b857f734eede0b48d8164545b""><code>3a03112</code></a> Fix build</li>; <li>Additional commits viewable in <a href=""https://github.com/readthedocs/sphinx_rtd_theme/compare/0.4.2...1.0.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=sphinx-rtd-theme&package-manager=pip&previous-version=0.4.2&new-version=1.0.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11464:7201,secur,security-vulnerabilities,7201,https://hail.is,https://github.com/hail-is/hail/pull/11464,4,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"12.1</li>; <li><a href=""https://github.com/java-native-access/jna/commit/2f919e56bad203494fe9589206d6d23f27ef4f26""><code>2f919e5</code></a> Null-check cleanable in Memory#close (<a href=""https://github-redirect.dependabot.com/java-native-access/jna/issues/1447"">#1447</a>)</li>; <li><a href=""https://github.com/java-native-access/jna/commit/1eec7dd76830af97ed64ecb2d8d39a56db104dcd""><code>1eec7dd</code></a> Prepare next development iteration</li>; <li><a href=""https://github.com/java-native-access/jna/commit/0d7499f105e4495bdea15fc21f5b1046e81ca822""><code>0d7499f</code></a> Release 5.12.0</li>; <li><a href=""https://github.com/java-native-access/jna/commit/fa86166d4f75ef4478de7ad9d7d6c0b6b6933ee0""><code>fa86166</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/java-native-access/jna/issues/1445"">#1445</a> from matthiasblaesing/aix</li>; <li><a href=""https://github.com/java-native-access/jna/commit/4cca4405f7f6bc32d2a08495efb81c081b065279""><code>4cca440</code></a> Fix name mapping difference between AIX JDK 8 and Semeru JDK 18</li>; <li><a href=""https://github.com/java-native-access/jna/commit/f58b0f8f6b5c013adfe44a2cfb018ccb6ef6a688""><code>f58b0f8</code></a> Improve test stability on AIX (exclude tests that are expected to fail)</li>; <li><a href=""https://github.com/java-native-access/jna/commit/c1565fb89469cbcba67b1cc305e16d520779b270""><code>c1565fb</code></a> Handle race condition in PdhUtil#PdhEnumObjectItems (<a href=""https://github-redirect.dependabot.com/java-native-access/jna/issues/1442"">#1442</a>)</li>; <li><a href=""https://github.com/java-native-access/jna/commit/99fcfa822db86b1f2ba5823dbf17efeb3d246ad5""><code>99fcfa8</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/java-native-access/jna/issues/1444"">#1444</a> from matthiasblaesing/update_libffi</li>; <li><a href=""https://github.com/java-native-access/jna/commit/9e473350a5ad5e04aab8b01e4018f973976e19f8""><code>9e47335</code></a> Update CHANGES.md</li>; <l",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12438:6629,access,access,6629,https://hail.is,https://github.com/hail-is/hail/pull/12438,1,['access'],['access']
Security,"167b6""><code>bbc1d75</code></a> Test example code as part of tests</li>; <li><a href=""https://github.com/python-parsy/parsy/commit/18df37a479f1bc4170999866433ca19f92f19f63""><code>18df37a</code></a> Dropped Python 3.4 from tox</li>; <li><a href=""https://github.com/python-parsy/parsy/commit/1d7189b5bf78bd0d8d6e4bb2170dfeabba659c5c""><code>1d7189b</code></a> Merge branch 'master' of github.com:python-parsy/parsy</li>; <li><a href=""https://github.com/python-parsy/parsy/commit/8ec01153ccf6c58e2811c0e4c760b98125aeebca""><code>8ec0115</code></a> Link to SQL example from README</li>; <li>Additional commits viewable in <a href=""https://github.com/python-parsy/parsy/compare/v1.1.0...v1.4.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=parsy&package-manager=pip&previous-version=1.1.0&new-version=1.4.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12007:3461,secur,security-vulnerabilities,3461,https://hail.is,https://github.com/hail-is/hail/pull/12007,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,18-12-04 22:13:57 root: ERROR: IllegalArgumentException: null; From java.lang.IllegalArgumentException: null; at org.apache.xbean.asm5.ClassReader.<init>(Unknown Source); at org.apache.xbean.asm5.ClassReader.<init>(Unknown Source); at org.apache.xbean.asm5.ClassReader.<init>(Unknown Source); at org.apache.spark.util.ClosureCleaner$.getClassReader(ClosureCleaner.scala:46); at org.apache.spark.util.FieldAccessFinder$$anon$3$$anonfun$visitMethodInsn$2.apply(ClosureCleaner.scala:443); at org.apache.spark.util.FieldAccessFinder$$anon$3$$anonfun$visitMethodInsn$2.apply(ClosureCleaner.scala:426); at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733); at scala.collection.mutable.HashMap$$anon$1$$anonfun$foreach$2.apply(HashMap.scala:103); at scala.collection.mutable.HashMap$$anon$1$$anonfun$foreach$2.apply(HashMap.scala:103); at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230); at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40); at scala.collection.mutable.HashMap$$anon$1.foreach(HashMap.scala:103); at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732); at org.apache.spark.util.FieldAccessFinder$$anon$3.visitMethodInsn(ClosureCleaner.scala:426); at org.apache.xbean.asm5.ClassReader.a(Unknown Source); at org.apache.xbean.asm5.ClassReader.b(Unknown Source); at org.apache.xbean.asm5.ClassReader.accept(Unknown Source); at org.apache.xbean.asm5.ClassReader.accept(Unknown Source); at org.apache.spark.util.ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$14.apply(ClosureCleaner.scala:257); at org.apache.spark.util.ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$14.apply(ClosureCleaner.scala:256); at scala.collection.immutable.List.foreach(List.scala:381); at org.apache.spark.util.ClosureCleaner$.org$apache$spark$util$ClosureCleaner$$clean(ClosureCleaner.scala:256); at org.apache.spark.util.ClosureCleaner$.clean(ClosureCleaner.scal,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4896:1469,Hash,HashMap,1469,https://hail.is,https://github.com/hail-is/hail/issues/4896,1,['Hash'],['HashMap']
Security,"1bc1497"",""dependencies"":[{""name"":""certifi"",""from"":""2021.10.8"",""to"":""2023.7.22""},{""name"":""cryptography"",""from"":""3.3.2"",""to"":""42.0.2""},{""name"":""requests"",""from"":""2.27.1"",""to"":""2.31.0""}],""packageManager"":""pip"",""projectPublicId"":""5ecb4152-94d0-44ff-86c6-21e542bb123d"",""projectUrl"":""https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-CERTIFI-3164749"",""SNYK-PYTHON-CERTIFI-5805047"",""SNYK-PYTHON-CRYPTOGRAPHY-3172287"",""SNYK-PYTHON-CRYPTOGRAPHY-3314966"",""SNYK-PYTHON-CRYPTOGRAPHY-3315324"",""SNYK-PYTHON-CRYPTOGRAPHY-3315328"",""SNYK-PYTHON-CRYPTOGRAPHY-3315331"",""SNYK-PYTHON-CRYPTOGRAPHY-3315452"",""SNYK-PYTHON-CRYPTOGRAPHY-3315972"",""SNYK-PYTHON-CRYPTOGRAPHY-3315975"",""SNYK-PYTHON-CRYPTOGRAPHY-3316038"",""SNYK-PYTHON-CRYPTOGRAPHY-3316211"",""SNYK-PYTHON-CRYPTOGRAPHY-5663682"",""SNYK-PYTHON-CRYPTOGRAPHY-5777683"",""SNYK-PYTHON-CRYPTOGRAPHY-5813745"",""SNYK-PYTHON-CRYPTOGRAPHY-5813746"",""SNYK-PYTHON-CRYPTOGRAPHY-5813750"",""SNYK-PYTHON-CRYPTOGRAPHY-5914629"",""SNYK-PYTHON-CRYPTOGRAPHY-6036192"",""SNYK-PYTHON-CRYPTOGRAPHY-6050294"",""SNYK-PYTHON-CRYPTOGRAPHY-6092044"",""SNYK-PYTHON-CRYPTOGRAPHY-6126975"",""SNYK-PYTHON-CRYPTOGRAPHY-6210214"",""SNYK-PYTHON-REQUESTS-5595532""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""pr-warning-shown"",""priorityScore""],""priorityScoreList"":[554,704,509,454,616,584,479,509,509,509,509,589,509,691,399,479,399,539,479,479,616,616,561,519],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Use After Free](https://learn.snyk.io/lesson/use-after-free/?loc&#x3D;fix-pr); 🦉 [Access of Resource Using Incompatible Type (&#x27;Type Confusion&#x27;)](https://learn.snyk.io/lesson/type-confusion/?loc&#x3D;fix-pr); 🦉 [Denial of Service (DoS)](https://learn.snyk.io/lesson/redos/?loc&#x3D;fix-pr); 🦉 [More lessons are available in Snyk Learn](https://learn.snyk.io/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14327:13220,Access,Access,13220,https://hail.is,https://github.com/hail-is/hail/pull/14327,1,['Access'],['Access']
Security,"1plus: error: unrecognized command line option ""-std=c++11""; make: *** [ibs.o] Error 1; :nativeLib FAILED. FAILURE: Build failed with an exception. * What went wrong:; Execution failed for task ':nativeLib'.; > Process 'command 'make'' finished with non-zero exit value 2. * Try:; Run with --info or --debug option to get more log output. * Exception is:; org.gradle.api.tasks.TaskExecutionException: Execution failed for task ':nativeLib'.; at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.executeActions(ExecuteActionsTaskExecuter.java:69); at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.execute(ExecuteActionsTaskExecuter.java:46); at org.gradle.api.internal.tasks.execution.PostExecutionAnalysisTaskExecuter.execute(PostExecutionAnalysisTaskExecuter.java:35); at org.gradle.api.internal.tasks.execution.SkipUpToDateTaskExecuter.execute(SkipUpToDateTaskExecuter.java:66); at org.gradle.api.internal.tasks.execution.ValidatingTaskExecuter.execute(ValidatingTaskExecuter.java:58); at org.gradle.api.internal.tasks.execution.SkipEmptySourceFilesTaskExecuter.execute(SkipEmptySourceFilesTaskExecuter.java:52); at org.gradle.api.internal.tasks.execution.SkipTaskWithNoActionsExecuter.execute(SkipTaskWithNoActionsExecuter.java:52); at org.gradle.api.internal.tasks.execution.SkipOnlyIfTaskExecuter.execute(SkipOnlyIfTaskExecuter.java:53); at org.gradle.api.internal.tasks.execution.ExecuteAtMostOnceTaskExecuter.execute(ExecuteAtMostOnceTaskExecuter.java:43); at org.gradle.execution.taskgraph.DefaultTaskGraphExecuter$EventFiringTaskWorker.execute(DefaultTaskGraphExecuter.java:203); at org.gradle.execution.taskgraph.DefaultTaskGraphExecuter$EventFiringTaskWorker.execute(DefaultTaskGraphExecuter.java:185); at org.gradle.execution.taskgraph.AbstractTaskPlanExecutor$TaskExecutorWorker.processTask(AbstractTaskPlanExecutor.java:66); at org.gradle.execution.taskgraph.AbstractTaskPlanExecutor$TaskExecutorWorker.run(AbstractTaskPlanExecutor.java:50); at org.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3705:1891,Validat,ValidatingTaskExecuter,1891,https://hail.is,https://github.com/hail-is/hail/issues/3705,1,['Validat'],['ValidatingTaskExecuter']
Security,"2""><code>f6a3c11</code></a> Adding missing Py_DECREF call on iter</li>; <li><a href=""https://github.com/numpy/numpy/commit/8274a16bd4434405597f32aacaf8a53002718fc5""><code>8274a16</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/numpy/numpy/issues/22391"">#22391</a> from charris/backport-22372</li>; <li><a href=""https://github.com/numpy/numpy/commit/fa16a0ca51ef0654f541fcf6fa8d30f0f6263a94""><code>fa16a0c</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/numpy/numpy/issues/22390"">#22390</a> from charris/backport-22360</li>; <li>Additional commits viewable in <a href=""https://github.com/numpy/numpy/compare/v1.21.6...v1.23.4"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=numpy&package-manager=pip&previous-version=1.21.6&new-version=1.23.4)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12441:6101,secur,security-vulnerabilities,6101,https://hail.is,https://github.com/hail-is/hail/pull/12441,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"217a1ce694e169ea2b33219d""><code>5166ee9</code></a> [Storage] Fix <code>upload_blob()</code> from an OS pipe on Linux (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/23211"">#23211</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/84cbec033ed8e4df87f44a82dcebb96aa19deac0""><code>84cbec0</code></a> [Storage] Adjust some file-datalake test recordings (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/23147"">#23147</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/Azure/azure-sdk-for-python/compare/azure-storage-blob_12.8.1...azure-storage-blob_12.10.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=azure-storage-blob&package-manager=pip&previous-version=12.8.1&new-version=12.10.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11610:6072,secur,security-vulnerabilities,6072,https://hail.is,https://github.com/hail-is/hail/pull/11610,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"21a7/hail-0.1-es-6.2.4-with-strip-chr-prefix.zip/hail/java.py"", line 121, in handle_py4j; hail.java.FatalError: FileNotFoundException: File file:/tmp/clinvar.vcf.gz does not exist. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 0.0 failed 20 times, most recent failure: Lost task 0.19 in stage 0.0 (TID 19, without-vep-520334-sw-rmwj.c.seqr-project.internal): java.io.FileNotFoundException: File file:/tmp/clinvar.vcf.gz does not exist; 	at org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:611); 	at org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:824); 	at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:601); 	at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:428); 	at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:142); 	at org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:346); 	at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:769); 	at org.apache.hadoop.mapred.LineRecordReader.<init>(LineRecordReader.java:109); 	at org.apache.hadoop.mapred.TextInputFormat.getRecordReader(TextInputFormat.java:67); 	at org.apache.spark.rdd.HadoopRDD$$anon$1.<init>(HadoopRDD.scala:245); 	at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:208); 	at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:101); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3760:5832,Checksum,ChecksumFileSystem,5832,https://hail.is,https://github.com/hail-is/hail/issues/3760,1,['Checksum'],['ChecksumFileSystem']
Security,23); at sun.misc.URLClassPath$JarLoader.getResource(URLClassPath.java:1042); at sun.misc.URLClassPath.getResource(URLClassPath.java:239); at java.net.URLClassLoader$1.run(URLClassLoader.java:365); at java.net.URLClassLoader$1.run(URLClassLoader.java:362); at java.security.AccessController.doPrivileged(Native Method); at java.net.URLClassLoader.findClass(URLClassLoader.java:361); at java.lang.ClassLoader.loadClass(ClassLoader.java:424); at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331); at java.lang.ClassLoader.loadClass(ClassLoader.java:357); at org.apache.spark.HeartbeatReceiver$$anonfun$org$apache$spark$HeartbeatReceiver$$expireDeadHosts$3.apply(HeartbeatReceiver.scala:198); at org.apache.spark.HeartbeatReceiver$$anonfun$org$apache$spark$HeartbeatReceiver$$expireDeadHosts$3.apply(HeartbeatReceiver.scala:196); at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733); at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99); at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99); at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230); at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40); at scala.collection.mutable.HashMap.foreach(HashMap.scala:99); at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732); at org.apache.spark.HeartbeatReceiver.org$apache$spark$HeartbeatReceiver$$expireDeadHosts(HeartbeatReceiver.scala:196); at org.apache.spark.HeartbeatReceiver$$anonfun$receiveAndReply$1.applyOrElse(HeartbeatReceiver.scala:119); at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105); at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205); at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101); at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:216); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at ja,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4780:2377,Hash,HashMap,2377,https://hail.is,https://github.com/hail-is/hail/issues/4780,1,['Hash'],['HashMap']
Security,"3-05-04 01:04:37.560 : INFO: RegionPool: FREE: 129.0K allocated (129.0K blocks / 0 chunks), regions.size = 3, 0 current java objects, thread 8: pool-1-thread-1; 2023-05-04 01:04:37.561 : ERROR: error while applying lowering 'LowerAndExecuteShuffles'; 2023-05-04 01:04:37.600 : INFO: RegionPool: initialized for thread 8: pool-1-thread-1; 2023-05-04 01:04:37.601 : INFO: TaskReport: stage=0, partition=0, attempt=0, peakBytes=0, peakBytesReadable=0.00 B, chunks requested=0, cache hits=0; 2023-05-04 01:04:37.601 : INFO: RegionPool: FREE: 0 allocated (0 blocks / 0 chunks), regions.size = 0, 0 current java objects, thread 8: pool-1-thread-1; 2023-05-04 01:04:37.601 : INFO: RegionPool: FREE: 128.0K allocated (128.0K blocks / 0 chunks), regions.size = 2, 0 current java objects, thread 8: pool-1-thread-1; 2023-05-04 01:04:37.603 : ERROR: SocketException: Connection reset; From javax.net.ssl.SSLException: Connection reset; 	at sun.security.ssl.Alert.createSSLException(Alert.java:127); 	at sun.security.ssl.TransportContext.fatal(TransportContext.java:324); 	at sun.security.ssl.TransportContext.fatal(TransportContext.java:267); 	at sun.security.ssl.TransportContext.fatal(TransportContext.java:262); 	at sun.security.ssl.SSLTransport.decode(SSLTransport.java:138); 	at sun.security.ssl.SSLSocketImpl.decode(SSLSocketImpl.java:1400); 	at sun.security.ssl.SSLSocketImpl.readApplicationRecord(SSLSocketImpl.java:1368); 	at sun.security.ssl.SSLSocketImpl.access$300(SSLSocketImpl.java:73); 	at sun.security.ssl.SSLSocketImpl$AppInputStream.read(SSLSocketImpl.java:962); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:284); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.MeteredStream.read(MeteredStream.java:134); 	at java.io.FilterInputStream.read(FilterInputStream.java:133); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3456); 	at com.google.api.client.http.javanet.NetHttpResponse$SizeValidatingIn",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12983:23709,secur,security,23709,https://hail.is,https://github.com/hail-is/hail/issues/12983,1,['secur'],['security']
Security,"3103d0ba35d0f0""><code>deea056</code></a> Backport PR <a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/45910"">#45910</a>: TST/CI: Set hypothesis deadline to None to avoid flaky fa...</li>; <li><a href=""https://github.com/pandas-dev/pandas/commit/58aebf1940b56b77279174f5413b76a5aaba465c""><code>58aebf1</code></a> Backport PR <a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/45909"">#45909</a>: BUG: DateOffset(n) not defaulting to days (<a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/45918"">#45918</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/pandas-dev/pandas/compare/v1.3.0...v1.4.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pandas&package-manager=pip&previous-version=1.3.0&new-version=1.4.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11539:6263,secur,security-vulnerabilities,6263,https://hail.is,https://github.com/hail-is/hail/pull/11539,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"33d5f380513308f3e1a2d""><code>8dfa47d</code></a> Merge pull request <a href=""https://redirect.github.com/numpy/numpy/issues/23148"">#23148</a> from charris/backport-23079</li>; <li><a href=""https://github.com/numpy/numpy/commit/62af62aa546e27f6f3348c950a76aca9a230e37c""><code>62af62a</code></a> Merge pull request <a href=""https://redirect.github.com/numpy/numpy/issues/23147"">#23147</a> from charris/backport-23077</li>; <li><a href=""https://github.com/numpy/numpy/commit/2de8e5228a2df34160709b570df16070ba23818b""><code>2de8e52</code></a> Add missing &lt;type_traits&gt; header.</li>; <li>Additional commits viewable in <a href=""https://github.com/numpy/numpy/compare/v1.21.6...v1.24.2"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=numpy&package-manager=pip&previous-version=1.21.6&new-version=1.24.2)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12898:6307,secur,security-vulnerabilities,6307,https://hail.is,https://github.com/hail-is/hail/pull/12898,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"365e196daa39d038035325d5ed""><code>a47764b</code></a> docs: fix typo and unnecessary word in docstring (<a href=""https://github-redirect.dependabot.com/googleapis/google-api-python-client/issues/1692"">#1692</a>)</li>; <li><a href=""https://github.com/googleapis/google-api-python-client/commit/755cff661f95430dee01e676f63267ae0b97119c""><code>755cff6</code></a> chore(deps): update dependency google-api-python-client to v2.37.0 (<a href=""https://github-redirect.dependabot.com/googleapis/google-api-python-client/issues/1690"">#1690</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/googleapis/google-api-python-client/compare/v1.7.10...v2.39.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=google-api-python-client&package-manager=pip&previous-version=1.7.10&new-version=2.39.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11541:35449,secur,security-vulnerabilities,35449,https://hail.is,https://github.com/hail-is/hail/pull/11541,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"3</a>)</li>; <li><a href=""https://github.com/python/typing_extensions/commit/bc9317ef90a629f27f1ab706bfce99da873044b4""><code>bc9317e</code></a> Change home URL to tree instead of README (<a href=""https://github-redirect.dependabot.com/python/typing_extensions/issues/1157"">#1157</a>)</li>; <li><a href=""https://github.com/python/typing_extensions/commit/c10296f15f92277ed1d3ed0c83103ae3818d3669""><code>c10296f</code></a> Add a README.rst file back temporarily. (<a href=""https://github-redirect.dependabot.com/python/typing_extensions/issues/1156"">#1156</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/python/typing_extensions/compare/4.2.0...4.3.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=typing-extensions&package-manager=pip&previous-version=4.2.0&new-version=4.3.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12200:4214,secur,security-vulnerabilities,4214,https://hail.is,https://github.com/hail-is/hail/pull/12200,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"3</h1>; <ul>; <li>api-change:<code>synthetics</code>: [<code>botocore</code>] Allow custom handler function.</li>; <li>api-change:<code>transfer</code>: [<code>botocore</code>] Add waiters for server online and offline.</li>; <li>api-change:<code>devops-guru</code>: [<code>botocore</code>] Amazon DevOps Guru now integrates with Amazon CodeGuru Profiler. You can view CodeGuru Profiler recommendations for your AWS Lambda function in DevOps Guru. This feature is enabled by default for new customers as of 3/4/2022. Existing customers can enable this feature with UpdateEventSourcesConfig.</li>; <li>api-change:<code>macie</code>: [<code>botocore</code>] Amazon Macie Classic (macie) has been discontinued and is no longer available. A new Amazon Macie (macie2) is now available with significant design improvements and additional features.</li>; <li>api-change:<code>ec2</code>: [<code>botocore</code>] Documentation updates for Amazon EC2.</li>; <li>api-change:<code>sts</code>: [<code>botocore</code>] Documentation updates for AWS Security Token Service.</li>; <li>api-change:<code>connect</code>: [<code>botocore</code>] This release updates the *InstanceStorageConfig APIs so they support a new ResourceType: REAL_TIME_CONTACT_ANALYSIS_SEGMENTS. Use this resource type to enable streaming for real-time contact analysis and to associate the Kinesis stream where real-time contact analysis segments will be published.</li>; </ul>; <h1>1.21.12</h1>; <ul>; <li>api-change:<code>greengrassv2</code>: [<code>botocore</code>] Doc only update that clarifies Create Deployment section.</li>; <li>api-change:<code>fsx</code>: [<code>botocore</code>] This release adds support for data repository associations to use root (&quot;/&quot;) as the file system path</li>; <li>api-change:<code>kendra</code>: [<code>botocore</code>] Amazon Kendra now suggests spell corrections for a query. For more information, see <a href=""https://docs.aws.amazon.com/kendra/latest/dg/query-spell-check.html"">https://docs.a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11504:1292,Secur,Security,1292,https://hail.is,https://github.com/hail-is/hail/pull/11504,1,['Secur'],['Security']
Security,"3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""50e1cce8-d68e-4133-a591-e2d1a6257337"",""prPublicId"":""50e1cce8-d68e-4133-a591-e2d1a6257337"",""dependencies"":[{""name"":""certifi"",""from"":""2021.10.8"",""to"":""2023.7.22""},{""name"":""cryptography"",""from"":""3.3.2"",""to"":""41.0.4""},{""name"":""requests"",""from"":""2.27.1"",""to"":""2.31.0""}],""packageManager"":""pip"",""projectPublicId"":""c1c98f6a-57c6-4ecc-a329-3b744cab74bd"",""projectUrl"":""https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-CERTIFI-3164749"",""SNYK-PYTHON-CERTIFI-5805047"",""SNYK-PYTHON-CRYPTOGRAPHY-3172287"",""SNYK-PYTHON-CRYPTOGRAPHY-3314966"",""SNYK-PYTHON-CRYPTOGRAPHY-3315324"",""SNYK-PYTHON-CRYPTOGRAPHY-3315328"",""SNYK-PYTHON-CRYPTOGRAPHY-3315331"",""SNYK-PYTHON-CRYPTOGRAPHY-3315452"",""SNYK-PYTHON-CRYPTOGRAPHY-3315972"",""SNYK-PYTHON-CRYPTOGRAPHY-3315975"",""SNYK-PYTHON-CRYPTOGRAPHY-3316038"",""SNYK-PYTHON-CRYPTOGRAPHY-3316211"",""SNYK-PYTHON-CRYPTOGRAPHY-5663682"",""SNYK-PYTHON-CRYPTOGRAPHY-5777683"",""SNYK-PYTHON-CRYPTOGRAPHY-5813745"",""SNYK-PYTHON-CRYPTOGRAPHY-5813746"",""SNYK-PYTHON-CRYPTOGRAPHY-5813750"",""SNYK-PYTHON-CRYPTOGRAPHY-5914629"",""SNYK-PYTHON-REQUESTS-5595532""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""pr-warning-shown""],""priorityScoreList"":[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Use After Free](https://learn.snyk.io/lesson/use-after-free/?loc&#x3D;fix-pr); 🦉 [Access of Resource Using Incompatible Type (&#x27;Type Confusion&#x27;)](https://learn.snyk.io/lesson/type-confusion/?loc&#x3D;fix-pr); 🦉 [Denial of Service (DoS)](https://learn.snyk.io/lesson/redos/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13887:9811,Access,Access,9811,https://hail.is,https://github.com/hail-is/hail/pull/13887,1,['Access'],['Access']
Security,"3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""d900f7ca-fce7-41d4-a16d-bad109338beb"",""prPublicId"":""d900f7ca-fce7-41d4-a16d-bad109338beb"",""dependencies"":[{""name"":""certifi"",""from"":""2021.10.8"",""to"":""2023.7.22""},{""name"":""cryptography"",""from"":""3.3.2"",""to"":""41.0.4""},{""name"":""requests"",""from"":""2.27.1"",""to"":""2.31.0""}],""packageManager"":""pip"",""projectPublicId"":""c1c98f6a-57c6-4ecc-a329-3b744cab74bd"",""projectUrl"":""https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-CERTIFI-3164749"",""SNYK-PYTHON-CERTIFI-5805047"",""SNYK-PYTHON-CRYPTOGRAPHY-3172287"",""SNYK-PYTHON-CRYPTOGRAPHY-3314966"",""SNYK-PYTHON-CRYPTOGRAPHY-3315324"",""SNYK-PYTHON-CRYPTOGRAPHY-3315328"",""SNYK-PYTHON-CRYPTOGRAPHY-3315331"",""SNYK-PYTHON-CRYPTOGRAPHY-3315452"",""SNYK-PYTHON-CRYPTOGRAPHY-3315972"",""SNYK-PYTHON-CRYPTOGRAPHY-3315975"",""SNYK-PYTHON-CRYPTOGRAPHY-3316038"",""SNYK-PYTHON-CRYPTOGRAPHY-3316211"",""SNYK-PYTHON-CRYPTOGRAPHY-5663682"",""SNYK-PYTHON-CRYPTOGRAPHY-5777683"",""SNYK-PYTHON-CRYPTOGRAPHY-5813745"",""SNYK-PYTHON-CRYPTOGRAPHY-5813746"",""SNYK-PYTHON-CRYPTOGRAPHY-5813750"",""SNYK-PYTHON-CRYPTOGRAPHY-5914629"",""SNYK-PYTHON-REQUESTS-5595532""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""pr-warning-shown""],""priorityScoreList"":[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Use After Free](https://learn.snyk.io/lesson/use-after-free/?loc&#x3D;fix-pr); 🦉 [Access of Resource Using Incompatible Type (&#x27;Type Confusion&#x27;)](https://learn.snyk.io/lesson/type-confusion/?loc&#x3D;fix-pr); 🦉 [Denial of Service (DoS)](https://learn.snyk.io/lesson/redos/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13736:9811,Access,Access,9811,https://hail.is,https://github.com/hail-is/hail/pull/13736,1,['Access'],['Access']
Security,"3aa65c4291b8a1a134cd024fbe071323f400c83""><code>83aa65c</code></a> Add mamba support to <code>language: conda</code></li>; <li><a href=""https://github.com/pre-commit/pre-commit/commit/657e76ba77ef4ae5b6e2ebe5f06cacdbf22a19a2""><code>657e76b</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2205"">#2205</a> from jalessio/jamie/upgrade-rbenv</li>; <li><a href=""https://github.com/pre-commit/pre-commit/commit/428dc6e46eb68065bfc115419927949cdd056811""><code>428dc6e</code></a> Update rbenv / ruby-build versions</li>; <li>Additional commits viewable in <a href=""https://github.com/pre-commit/pre-commit/compare/v2.9.2...v2.17.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pre-commit&package-manager=pip&previous-version=2.9.2&new-version=2.17.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11460:14660,secur,security-vulnerabilities,14660,https://hail.is,https://github.com/hail-is/hail/pull/11460,4,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"3bef2d6e531e83cefd65be4cbbf41fcf2531""><code>66dd3be</code></a> [Storage] Fix more flaky lease tests (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/25011"">#25011</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/030141734a239fa6fb1aa7a8c43d322c82753510""><code>0301417</code></a> [Storage] Add argument to perf tests to use client-side encryption (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/24978"">#24978</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/Azure/azure-sdk-for-python/compare/azure-storage-blob_12.11.0...azure-storage-blob_12.13.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=azure-storage-blob&package-manager=pip&previous-version=12.11.0&new-version=12.13.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12109:4897,secur,security-vulnerabilities,4897,https://hail.is,https://github.com/hail-is/hail/pull/12109,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"40803](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-5840803) | `tornado:` <br> `6.2 -> 6.3.3` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **496/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 4.2 | Information Exposure Through Sent Data <br/>[SNYK-PYTHON-URLLIB3-6002459](https://snyk.io/vuln/SNYK-PYTHON-URLLIB3-6002459) | `urllib3:` <br> `1.26.17 -> 1.26.18` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiIxMjY5MWQyMS0wMzk1LTQxYjMtODBkMi1mMjEyODMwZjY2ZWEiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjEyNjkxZDIxLTAzOTUtNDFiMy04MGQyLWYyMTI4MzBmNjZlYSJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""12691d21-0395-41b3-80d2-f212830f66ea"",""pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13873:3955,access,access,3955,https://hail.is,https://github.com/hail-is/hail/pull/13873,2,"['access', 'authoriz']","['access', 'authorized']"
Security,"41fa331a5b4d129d94""><code>2004149</code></a> Update test</li>; <li><a href=""https://github.com/sphinx-doc/sphinx/commit/78c478a579b9d3f57091544d1717ee7f1c507ff1""><code>78c478a</code></a> Merge remote-tracking branch 'upstream/5.0.x' into lang-none-en</li>; <li><a href=""https://github.com/sphinx-doc/sphinx/commit/479e48266c025c99025787a8004a82b2afda8e6c""><code>479e482</code></a> Update warning, revert my original warning patch</li>; <li><a href=""https://github.com/sphinx-doc/sphinx/commit/fb6db30c1024ce5838dcf330f275cdf2adbd94b6""><code>fb6db30</code></a> Update comment</li>; <li>Additional commits viewable in <a href=""https://github.com/sphinx-doc/sphinx/compare/v3.5.4...v5.0.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=sphinx&package-manager=pip&previous-version=3.5.4&new-version=5.0.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11871:6525,secur,security-vulnerabilities,6525,https://hail.is,https://github.com/hail-is/hail/pull/11871,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"4423b434495f5""><code>8b8e4b5</code></a> Temporary fix for SLSA generator</li>; <li><a href=""https://github.com/urllib3/urllib3/commit/cc9b0dc10eaf83b1242d710222525edd73555b6d""><code>cc9b0dc</code></a> [1.26] Fix logo URL in README</li>; <li><a href=""https://github.com/urllib3/urllib3/commit/eb47444a9dfaa045cc4753e4d77c57fbdccaa619""><code>eb47444</code></a> [1.26] Fix CI by switching to macOS 11</li>; <li><a href=""https://github.com/urllib3/urllib3/commit/34d7348bb96eca390c2115aeeee31d1147830844""><code>34d7348</code></a> Remove &quot;&lt;4&quot; upper bound from python_requires</li>; <li>See full diff in <a href=""https://github.com/urllib3/urllib3/compare/1.26.12...1.26.13"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=urllib3&package-manager=pip&previous-version=1.26.12&new-version=1.26.13)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12506:3539,secur,security-vulnerabilities,3539,https://hail.is,https://github.com/hail-is/hail/pull/12506,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"4a""><code>3f2143d</code></a> Always allow use of <code>type[T]</code> in stubs (<a href=""https://github-redirect.dependabot.com/python/mypy/issues/11863"">#11863</a>)</li>; <li><a href=""https://github.com/python/mypy/commit/12290decccf3d60e3b56c23be09bc853a3ed6051""><code>12290de</code></a> Bump version to 0.931+dev</li>; <li><a href=""https://github.com/python/mypy/commit/8ce64aca6e84860ffbd2605f7cb52e97c8c10771""><code>8ce64ac</code></a> [0.931 backport] Fix <strong>reduce</strong> regression (<a href=""https://github-redirect.dependabot.com/python/mypy/issues/11866"">#11866</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/python/mypy/compare/v0.780...v0.931"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=mypy&package-manager=pip&previous-version=0.780&new-version=0.931)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11498:2860,secur,security-vulnerabilities,2860,https://hail.is,https://github.com/hail-is/hail/pull/11498,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"506, in _async_execute; _, resp, timings = await self._rpc('execute(...)', inputs, ir=ir, progress=progress); File ""/usr/local/lib/python3.10/site-packages/hail/backend/service_backend.py"", line 449, in _rpc; result_bytes = await retry_transient_errors(self._read_output, ir, iodir + '/out'); File ""/usr/local/lib/python3.10/site-packages/hailtop/utils/utils.py"", line 774, in retry_transient_errors; return await retry_transient_errors_with_debug_string('', 0, f, *args, **kwargs); File ""/usr/local/lib/python3.10/site-packages/hailtop/utils/utils.py"", line 787, in retry_transient_errors_with_debug_string; return await f(*args, **kwargs); File ""/usr/local/lib/python3.10/site-packages/hail/backend/service_backend.py"", line 475, in _read_output; raise reconstructed_error.maybe_user_error(ir); hail.utils.java.FatalError: SocketException: Connection reset. Java stack trace:; javax.net.ssl.SSLException: Connection reset; 	at sun.security.ssl.Alert.createSSLException(Alert.java:127); 	at sun.security.ssl.TransportContext.fatal(TransportContext.java:324); 	at sun.security.ssl.TransportContext.fatal(TransportContext.java:267); 	at sun.security.ssl.TransportContext.fatal(TransportContext.java:262); 	at sun.security.ssl.SSLTransport.decode(SSLTransport.java:138); 	at sun.security.ssl.SSLSocketImpl.decode(SSLSocketImpl.java:1400); 	at sun.security.ssl.SSLSocketImpl.readApplicationRecord(SSLSocketImpl.java:1368); 	at sun.security.ssl.SSLSocketImpl.access$300(SSLSocketImpl.java:73); 	at sun.security.ssl.SSLSocketImpl$AppInputStream.read(SSLSocketImpl.java:962); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:284); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.MeteredStream.read(MeteredStream.java:134); 	at java.io.FilterInputStream.read(FilterInputStream.java:133); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3456); 	at com.google.api.client.http.javanet.NetHttpResponse$SizeValidatingIn",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12982:2820,secur,security,2820,https://hail.is,https://github.com/hail-is/hail/issues/12982,1,['secur'],['security']
Security,"509, in _async_execute; _, resp, timings = await self._rpc('execute(...)', inputs, ir=ir, progress=progress); File ""/usr/local/lib/python3.10/site-packages/hail/backend/service_backend.py"", line 451, in _rpc; result_bytes = await retry_transient_errors(self._read_output, ir, iodir + '/out'); File ""/usr/local/lib/python3.10/site-packages/hailtop/utils/utils.py"", line 779, in retry_transient_errors; return await retry_transient_errors_with_debug_string('', 0, f, *args, **kwargs); File ""/usr/local/lib/python3.10/site-packages/hailtop/utils/utils.py"", line 792, in retry_transient_errors_with_debug_string; return await f(*args, **kwargs); File ""/usr/local/lib/python3.10/site-packages/hail/backend/service_backend.py"", line 477, in _read_output; raise reconstructed_error.maybe_user_error(ir); hail.utils.java.FatalError: SocketException: Connection reset. Java stack trace:; javax.net.ssl.SSLException: Connection reset; 	at sun.security.ssl.Alert.createSSLException(Alert.java:127); 	at sun.security.ssl.TransportContext.fatal(TransportContext.java:324); 	at sun.security.ssl.TransportContext.fatal(TransportContext.java:267); 	at sun.security.ssl.TransportContext.fatal(TransportContext.java:262); 	at sun.security.ssl.SSLTransport.decode(SSLTransport.java:138); 	at sun.security.ssl.SSLSocketImpl.decode(SSLSocketImpl.java:1400); 	at sun.security.ssl.SSLSocketImpl.readApplicationRecord(SSLSocketImpl.java:1368); 	at sun.security.ssl.SSLSocketImpl.access$300(SSLSocketImpl.java:73); 	at sun.security.ssl.SSLSocketImpl$AppInputStream.read(SSLSocketImpl.java:962); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:284); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.MeteredStream.read(MeteredStream.java:134); 	at java.io.FilterInputStream.read(FilterInputStream.java:133); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3456); 	at com.google.api.client.http.javanet.NetHttpResponse$SizeValidatingIn",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12983:3708,secur,security,3708,https://hail.is,https://github.com/hail-is/hail/issues/12983,1,['secur'],['security']
Security,"51</code></a> Merge branch 'release/v3.8.2' into 3.8</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/3ef9cab654f1d2101d4e243cd5907966f9953f4c""><code>3ef9cab</code></a> Bump the hardcoded version to v3.8.2.post0.dev0</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/99c8d0d7706153970bc1cbace8bdf4ab137783c7""><code>99c8d0d</code></a> Brush up the changelog wording for v3.8.2</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/a56b31cae75506e0640808567372359a159b1f96""><code>a56b31c</code></a> Add a note about Python 3.6 in the changelog</li>; <li>Additional commits viewable in <a href=""https://github.com/aio-libs/aiohttp/compare/v3.8.1...v3.8.3"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=aiohttp&package-manager=pip&previous-version=3.8.1&new-version=3.8.3)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12296:7732,secur,security-vulnerabilities,7732,https://hail.is,https://github.com/hail-is/hail/pull/12296,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"5b97ccab04ab""><code>1957538</code></a> [pre-commit.ci] pre-commit autoupdate (<a href=""https://github-redirect.dependabot.com/tox-dev/py-filelock/issues/157"">#157</a>)</li>; <li><a href=""https://github.com/tox-dev/py-filelock/commit/e6c1a64d24eb9f1524cc0464bf6acd87a82b08fd""><code>e6c1a64</code></a> [pre-commit.ci] pre-commit autoupdate (<a href=""https://github-redirect.dependabot.com/tox-dev/py-filelock/issues/156"">#156</a>)</li>; <li><a href=""https://github.com/tox-dev/py-filelock/commit/fbf0e45745556f508b0861f370ba8af13a09d07e""><code>fbf0e45</code></a> Add funding</li>; <li>Additional commits viewable in <a href=""https://github.com/tox-dev/py-filelock/compare/3.7.1...3.8.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=filelock&package-manager=pip&previous-version=3.7.1&new-version=3.8.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12157:6859,secur,security-vulnerabilities,6859,https://hail.is,https://github.com/hail-is/hail/pull/12157,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"5bf9f9115e6a3a455d8cc947790b64f8c7101a7""><code>45bf9f9</code></a> Merge remote-tracking branch 'upstream/main' into patch-1</li>; <li><a href=""https://github.com/docker/docker-py/commit/c03aeb659e2ac996aa69927e928b73d2979b9fce""><code>c03aeb6</code></a> Merge remote-tracking branch 'upstream/main' into connect-with-mac</li>; <li><a href=""https://github.com/docker/docker-py/commit/58aa62bb154a2ccea433cf475aefbd695fb5abc8""><code>58aa62b</code></a> swarm: add sysctl support for services (<a href=""https://github-redirect.dependabot.com/docker/docker-py/issues/3029"">#3029</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/docker/docker-py/compare/5.0.3...6.0.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=docker&package-manager=pip&previous-version=5.0.3&new-version=6.0.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12475:7410,secur,security-vulnerabilities,7410,https://hail.is,https://github.com/hail-is/hail/pull/12475,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"6"",""to"":""6.4.12""},{""name"":""pygments"",""from"":""2.5.2"",""to"":""2.15.0""},{""name"":""requests"",""from"":""2.27.1"",""to"":""2.31.0""},{""name"":""setuptools"",""from"":""39.0.1"",""to"":""65.5.1""},{""name"":""sphinx"",""from"":""1.8.6"",""to"":""3.3.0""},{""name"":""tornado"",""from"":""5.1.1"",""to"":""6.3.3""},{""name"":""wheel"",""from"":""0.30.0"",""to"":""0.38.0""}],""packageManager"":""pip"",""projectPublicId"":""fa47fca0-549b-41a3-8bf7-bcda4ca9a617"",""projectUrl"":""https://app.snyk.io/org/danking/project/fa47fca0-549b-41a3-8bf7-bcda4ca9a617?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-CERTIFI-3164749"",""SNYK-PYTHON-CERTIFI-5805047"",""SNYK-PYTHON-IPYTHON-2348630"",""SNYK-PYTHON-IPYTHON-3318382"",""SNYK-PYTHON-JUPYTERCORE-3063766"",""SNYK-PYTHON-MISTUNE-2940625"",""SNYK-PYTHON-NBCONVERT-2979829"",""SNYK-PYTHON-NOTEBOOK-1041707"",""SNYK-PYTHON-NOTEBOOK-2441824"",""SNYK-PYTHON-NOTEBOOK-2928995"",""SNYK-PYTHON-PYGMENTS-1086606"",""SNYK-PYTHON-PYGMENTS-1088505"",""SNYK-PYTHON-PYGMENTS-5750273"",""SNYK-PYTHON-REQUESTS-5595532"",""SNYK-PYTHON-SETUPTOOLS-3180412"",""SNYK-PYTHON-SPHINX-570772"",""SNYK-PYTHON-SPHINX-570773"",""SNYK-PYTHON-SPHINX-5811865"",""SNYK-PYTHON-SPHINX-5812109"",""SNYK-PYTHON-TORNADO-5537286"",""SNYK-PYTHON-TORNADO-5840803"",""SNYK-PYTHON-TORNADO-6041512"",""SNYK-PYTHON-WHEEL-3180413""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""pr-warning-shown""],""priorityScoreList"":[null,null,null,531,null,null,null,null,null,null,null,null,null,null,509,null,null,null,null,384,494,539,null],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Remote Code Execution (RCE)](https://learn.snyk.io/lesson/improper-input-validation/?loc&#x3D;fix-pr); 🦉 [Improper Privilege Management](https://learn.snyk.io/lesson/insecure-design/?loc&#x3D;fix-pr); 🦉 [Regular Expression Denial of Service (ReDoS)](https://learn.snyk.io/lesson/redos/?loc&#x3D;fix-pr); 🦉 [More lessons are available in Snyk Learn](https://learn.snyk.io/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14024:11273,validat,validation,11273,https://hail.is,https://github.com/hail-is/hail/pull/14024,1,['validat'],['validation']
Security,"6)</h2>; <p><strong>Improvements</strong></p>; <ul>; <li>Requests now defers chunked requests to the urllib3 implementation to improve; standardization. (<a href=""https://redirect.github.com/psf/requests/issues/6226"">#6226</a>)</li>; <li>Requests relaxes header component requirements to support bytes/str subclasses. (<a href=""https://redirect.github.com/psf/requests/issues/6356"">#6356</a>)</li>; </ul>; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/psf/requests/blob/main/HISTORY.md"">requests's changelog</a>.</em></p>; <blockquote>; <h2>2.31.0 (2023-05-22)</h2>; <p><strong>Security</strong></p>; <ul>; <li>; <p>Versions of Requests between v2.3.0 and v2.30.0 are vulnerable to potential; forwarding of <code>Proxy-Authorization</code> headers to destination servers when; following HTTPS redirects.</p>; <p>When proxies are defined with user info (<a href=""https://user:pass@proxy:8080"">https://user:pass@proxy:8080</a>), Requests; will construct a <code>Proxy-Authorization</code> header that is attached to the request to; authenticate with the proxy.</p>; <p>In cases where Requests receives a redirect response, it previously reattached; the <code>Proxy-Authorization</code> header incorrectly, resulting in the value being; sent through the tunneled connection to the destination server. Users who rely on; defining their proxy credentials in the URL are <em>strongly</em> encouraged to upgrade; to Requests 2.31.0+ to prevent unintentional leakage and rotate their proxy; credentials once the change has been fully deployed.</p>; <p>Users who do not use a proxy or do not supply their proxy credentials through; the user information portion of their proxy URL are not subject to this; vulnerability.</p>; <p>Full details can be read in our <a href=""https://github.com/psf/requests/security/advisories/GHSA-j8r2-6x86-q33q"">Github Security Advisory</a>; and <a href=""https://nvd.nist.gov/vuln/detail/CVE-2023-32681"">CVE-20",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13091:3257,Authoriz,Authorization,3257,https://hail.is,https://github.com/hail-is/hail/pull/13091,12,"['Authoriz', 'authenticat']","['Authorization', 'authenticate']"
Security,"6456</a></li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/psf/requests/blob/main/HISTORY.md"">requests's changelog</a>.</em></p>; <blockquote>; <h2>2.32.0 (2024-05-20)</h2>; <p><strong>Security</strong></p>; <ul>; <li>Fixed an issue where setting <code>verify=False</code> on the first request from a; Session will cause subsequent requests to the <em>same origin</em> to also ignore; cert verification, regardless of the value of <code>verify</code>.; (<a href=""https://github.com/psf/requests/security/advisories/GHSA-9wx4-h78v-vm56"">https://github.com/psf/requests/security/advisories/GHSA-9wx4-h78v-vm56</a>)</li>; </ul>; <p><strong>Improvements</strong></p>; <ul>; <li><code>verify=True</code> now reuses a global SSLContext which should improve; request time variance between first and subsequent requests. It should; also minimize certificate load time on Windows systems when using a Python; version built with OpenSSL 3.x. (<a href=""https://redirect.github.com/psf/requests/issues/6667"">#6667</a>)</li>; <li>Requests now supports optional use of character detection; (<code>chardet</code> or <code>charset_normalizer</code>) when repackaged or vendored.; This enables <code>pip</code> and other projects to minimize their vendoring; surface area. The <code>Response.text()</code> and <code>apparent_encoding</code> APIs; will default to <code>utf-8</code> if neither library is present. (<a href=""https://redirect.github.com/psf/requests/issues/6702"">#6702</a>)</li>; </ul>; <p><strong>Bugfixes</strong></p>; <ul>; <li>Fixed bug in length detection where emoji length was incorrectly; calculated in the request content-length. (<a href=""https://redirect.github.com/psf/requests/issues/6589"">#6589</a>)</li>; <li>Fixed deserialization bug in JSONDecodeError. (<a href=""https://redirect.github.com/psf/requests/issues/6629"">#6629</a>)</li>; <li>Fixed bug where an ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14555:4903,certificate,certificate,4903,https://hail.is,https://github.com/hail-is/hail/pull/14555,1,['certificate'],['certificate']
Security,"66d4f75ef4478de7ad9d7d6c0b6b6933ee0""><code>fa86166</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/java-native-access/jna/issues/1445"">#1445</a> from matthiasblaesing/aix</li>; <li><a href=""https://github.com/java-native-access/jna/commit/4cca4405f7f6bc32d2a08495efb81c081b065279""><code>4cca440</code></a> Fix name mapping difference between AIX JDK 8 and Semeru JDK 18</li>; <li><a href=""https://github.com/java-native-access/jna/commit/f58b0f8f6b5c013adfe44a2cfb018ccb6ef6a688""><code>f58b0f8</code></a> Improve test stability on AIX (exclude tests that are expected to fail)</li>; <li><a href=""https://github.com/java-native-access/jna/commit/c1565fb89469cbcba67b1cc305e16d520779b270""><code>c1565fb</code></a> Handle race condition in PdhUtil#PdhEnumObjectItems (<a href=""https://github-redirect.dependabot.com/java-native-access/jna/issues/1442"">#1442</a>)</li>; <li><a href=""https://github.com/java-native-access/jna/commit/99fcfa822db86b1f2ba5823dbf17efeb3d246ad5""><code>99fcfa8</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/java-native-access/jna/issues/1444"">#1444</a> from matthiasblaesing/update_libffi</li>; <li><a href=""https://github.com/java-native-access/jna/commit/9e473350a5ad5e04aab8b01e4018f973976e19f8""><code>9e47335</code></a> Update CHANGES.md</li>; <li>Additional commits viewable in <a href=""https://github.com/java-native-access/jna/compare/5.6.0...5.12.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=net.java.dev.jna:jna&package-manager=gradle&previous-version=5.6.0&new-version=5.12.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]:",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12438:7318,access,access,7318,https://hail.is,https://github.com/hail-is/hail/pull/12438,1,['access'],['access']
Security,"718c4a5d3ddd671fbd4881bf176e7d6e2""><code>0818628</code></a> Check input type before escaping</li>; <li><a href=""https://github.com/jupyter/nbconvert/commit/b206470f9ecd71b006a37dd1298dd3d9e3dd46dd""><code>b206470</code></a> GHSL-2021-1017, GHSL-2021-1020, GHSL-2021-1021</li>; <li><a href=""https://github.com/jupyter/nbconvert/commit/a03cbb8a8d04d47aefec51e7b1b816045682aed5""><code>a03cbb8</code></a> GHSL-2021-1026, GHSL-2021-1025</li>; <li><a href=""https://github.com/jupyter/nbconvert/commit/48fe71eb3335caf4e03166e56e0d16efcfbeaf44""><code>48fe71e</code></a> GHSL-2021-1024</li>; <li>Additional commits viewable in <a href=""https://github.com/jupyter/nbconvert/compare/6.5...6.5.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=nbconvert&package-manager=pip&previous-version=6.5.0&new-version=6.5.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12125:2065,secur,security-vulnerabilities,2065,https://hail.is,https://github.com/hail-is/hail/pull/12125,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"7742b6cee738aa295d8b835c3a195""><code>e04ea73</code></a> cargo update, build misc</li>; <li><a href=""https://github.com/ijl/orjson/commit/ba8c701292e4720b4e10210b266be5666d098fb6""><code>ba8c701</code></a> 3.9.14</li>; <li><a href=""https://github.com/ijl/orjson/commit/a2f7b7bfa4987c102892793ab7c7483fcb8050a0""><code>a2f7b7b</code></a> impl_format_simd!() lift create from loop, rotate left</li>; <li><a href=""https://github.com/ijl/orjson/commit/528220fb0d18bbf0212de7f0ce5c7aec209bc6e7""><code>528220f</code></a> format_escaped_str() fast and slow paths depending on page boundary</li>; <li>Additional commits viewable in <a href=""https://github.com/ijl/orjson/compare/3.9.10...3.10.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=orjson&package-manager=pip&previous-version=3.9.10&new-version=3.10.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14427:5157,secur,security-vulnerabilities,5157,https://hail.is,https://github.com/hail-is/hail/pull/14427,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"77819/icon/m.png ""medium severity"") | Regular Expression Denial of Service (ReDoS) <br/>[SNYK-PYTHON-PYGMENTS-5750273](https://snyk.io/vuln/SNYK-PYTHON-PYGMENTS-5750273) | `pygments:` <br> `2.5.2 -> 2.15.0` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | Information Exposure <br/>[SNYK-PYTHON-REQUESTS-5595532](https://snyk.io/vuln/SNYK-PYTHON-REQUESTS-5595532) | `requests:` <br> `2.27.1 -> 2.31.0` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | Regular Expression Denial of Service (ReDoS) <br/>[SNYK-PYTHON-SETUPTOOLS-3180412](https://snyk.io/vuln/SNYK-PYTHON-SETUPTOOLS-3180412) | `setuptools:` <br> `39.0.1 -> 65.5.1` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | Cross-site Scripting (XSS) <br/>[SNYK-PYTHON-SPHINX-570772](https://snyk.io/vuln/SNYK-PYTHON-SPHINX-570772) | `sphinx:` <br> `1.8.6 -> 3.3.0` <br> | No | Mature ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | Cross-site Scripting (XSS) <br/>[SNYK-PYTHON-SPHINX-570773](https://snyk.io/vuln/SNYK-PYTHON-SPHINX-570773) | `sphinx:` <br> `1.8.6 -> 3.3.0` <br> | No | Mature ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | Regular Expression Denial of Service (ReDoS) <br/>[SNYK-PYTHON-SPHINX-5811865](https://snyk.io/vuln/SNYK-PYTHON-SPHINX-5811865) | `sphinx:` <br> `1.8.6 -> 3.3.0` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | Regular Expression Denial of Service (ReDoS) <br/>[SNYK-PYTHON-SPHINX-5812109](https://snyk.io/vuln/SNYK-PYTHON-SPHINX-5812109) | `sphinx:` <br> `1.8.6",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13835:5619,Cross-site Scripting,Cross-site Scripting,5619,https://hail.is,https://github.com/hail-is/hail/pull/13835,10,"['Cross-site Scripting', 'XSS']","['Cross-site Scripting', 'XSS']"
Security,"77819/icon/m.png ""medium severity"") | Regular Expression Denial of Service (ReDoS) <br/>[SNYK-PYTHON-PYGMENTS-5750273](https://snyk.io/vuln/SNYK-PYTHON-PYGMENTS-5750273) | `pygments:` <br> `2.5.2 -> 2.15.0` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | Information Exposure <br/>[SNYK-PYTHON-REQUESTS-5595532](https://snyk.io/vuln/SNYK-PYTHON-REQUESTS-5595532) | `requests:` <br> `2.27.1 -> 2.31.0` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | Regular Expression Denial of Service (ReDoS) <br/>[SNYK-PYTHON-SETUPTOOLS-3180412](https://snyk.io/vuln/SNYK-PYTHON-SETUPTOOLS-3180412) | `setuptools:` <br> `40.5.0 -> 65.5.1` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | Cross-site Scripting (XSS) <br/>[SNYK-PYTHON-SPHINX-570772](https://snyk.io/vuln/SNYK-PYTHON-SPHINX-570772) | `sphinx:` <br> `1.8.6 -> 3.3.0` <br> | No | Mature ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | Cross-site Scripting (XSS) <br/>[SNYK-PYTHON-SPHINX-570773](https://snyk.io/vuln/SNYK-PYTHON-SPHINX-570773) | `sphinx:` <br> `1.8.6 -> 3.3.0` <br> | No | Mature ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | Regular Expression Denial of Service (ReDoS) <br/>[SNYK-PYTHON-SPHINX-5811865](https://snyk.io/vuln/SNYK-PYTHON-SPHINX-5811865) | `sphinx:` <br> `1.8.6 -> 3.3.0` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | Regular Expression Denial of Service (ReDoS) <br/>[SNYK-PYTHON-SPHINX-5812109](https://snyk.io/vuln/SNYK-PYTHON-SPHINX-5812109) | `sphinx:` <br> `1.8.6",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14364:6532,Cross-site Scripting,Cross-site Scripting,6532,https://hail.is,https://github.com/hail-is/hail/pull/14364,2,"['Cross-site Scripting', 'XSS']","['Cross-site Scripting', 'XSS']"
Security,"7cf0b55a1""><code>3de7f40</code></a> Remove dependency on deprecated keyring.util.properties. Fixes <a href=""https://github-redirect.dependabot.com/jaraco/keyrings.alt/issues/47"">#47</a>.</li>; <li><a href=""https://github.com/jaraco/keyrings.alt/commit/010fe59c64ffacbc0f97405d3bf21072d811baf1""><code>010fe59</code></a> Merge <a href=""https://github.com/jaraco/skeleton"">https://github.com/jaraco/skeleton</a></li>; <li><a href=""https://github.com/jaraco/keyrings.alt/commit/47c2cb324e20f784289496ef3a7b19a1cd23d196""><code>47c2cb3</code></a> Also update release to v4</li>; <li>Additional commits viewable in <a href=""https://github.com/jaraco/keyrings.alt/compare/v3.5.2...v4.2.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=keyrings-alt&package-manager=pip&previous-version=3.5.2&new-version=4.2.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12448:3647,secur,security-vulnerabilities,3647,https://hail.is,https://github.com/hail-is/hail/pull/12448,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"8""><code>c3c0b3f</code></a> Fix potential ReDoS (<a href=""https://github-redirect.dependabot.com/chalk/ansi-regex/issues/37"">#37</a>)</li>; <li><a href=""https://github.com/chalk/ansi-regex/commit/178363b3a297b712a0054e702d8ddde3879913e5""><code>178363b</code></a> Move to GitHub Actions (<a href=""https://github-redirect.dependabot.com/chalk/ansi-regex/issues/35"">#35</a>)</li>; <li><a href=""https://github.com/chalk/ansi-regex/commit/0755e661553387cfebcb62378181e9f55b2567ff""><code>0755e66</code></a> Add <a href=""https://github.com/Qix""><code>@​Qix</code></a>- to funding.yml</li>; <li>See full diff in <a href=""https://github.com/chalk/ansi-regex/compare/v5.0.0...v5.0.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=ansi-regex&package-manager=npm_and_yarn&previous-version=5.0.0&new-version=5.0.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11287:2694,secur,security-vulnerabilities,2694,https://hail.is,https://github.com/hail-is/hail/pull/11287,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"80f7bc40d39""><code>d9ac3f3</code></a> FIX:linalg:Guard against possible permute_l out of bound behavior</li>; <li><a href=""https://github.com/scipy/scipy/commit/7ec501097b3a22569025bf0d62cb2d89474c812b""><code>7ec5010</code></a> BUG: fix handling for <code>factorial(..., exact=False)</code> for 0-dim array inputs (#...</li>; <li><a href=""https://github.com/scipy/scipy/commit/90415c6890365585576e96e42c5aeba253da0091""><code>90415c6</code></a> BUG: Fix work array construction for various weight shapes. (<a href=""https://redirect.github.com/scipy/scipy/issues/18741"">#18741</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/scipy/scipy/compare/v1.9.3...v1.11.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=scipy&package-manager=pip&previous-version=1.9.3&new-version=1.11.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). You can trigger a rebase of this PR by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Depe",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13228:4782,secur,security-vulnerabilities,4782,https://hail.is,https://github.com/hail-is/hail/pull/13228,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"82 indicate that a bad interaction between the data and a hash function can cause this integer map to exceed its size limitations at a load factor of 5%. Even a 20x increase in footprint puts us at 400 million. Each element of that array has 6 entries, so we're at 1.2 billion. That definitely feels like the danger zone. Maybe there's more variants than Danfeng expects, maybe there's more overhead than we've accounted for. The GATK folks have been chasing down the fix. Kryo [released 4.0.0](https://github.com/EsotericSoftware/kryo/issues/431) which should fix this issue. Spark [upgraded to Kryo 4.0.0](https://github.com/apache/spark/pull/22179) on September 8th of 2018. (resolving [Spark-20389](https://issues.apache.org/jira/browse/SPARK-20389)). This change made it to 2.4.0, but it was not back ported to other versions of Spark. GATK [references a temporary fix via JVM options](; https://github.com/broadinstitute/gatk/issues/1524#issuecomment-189368808), which apparently forces the JVM to use an alternative hash function with better behavior in this specific case:; ```; spark.executor.extraJavaOptions -XX:hashCode=0; spark.driver.extraJavaOptions -XX:hashCode=0; ```; A [generally interesting blog post on Java's hashCode](https://srvaroa.github.io/jvm/java/openjdk/biased-locking/2017/01/30/hashCode.html), which I haven't fully read, claims that the JVM previously defaulted to a PRNG draw for an object's hash code. In JDK 8 it uses some function of the current thread state. It appears this old strategy is preserved as JVM hashCode parameter value 0 and is less likely to trigger the bad behavior in Kryo. This `-XX:hashCode` option is undocumented [1](https://docs.oracle.com/javase/8/docs/technotes/tools/windows/java.html), [2](https://www.oracle.com/technetwork/java/javase/tech/vmoptions-jsp-140102.html) 🤷‍♀️. Another suggested Kryo option is to disable reference tracking. This would cause duplicate objects in the object graph to be serialized twice:; ```java; Kryo kryo",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5564:1565,hash,hash,1565,https://hail.is,https://github.com/hail-is/hail/issues/5564,1,['hash'],['hash']
Security,"898</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/ipython/ipython/issues/13905"">#13905</a> from Carreau/bad-fd</li>; <li><a href=""https://github.com/ipython/ipython/commit/4a065015a1b987ac6f30fff9180efbd93cffbed6""><code>4a06501</code></a> Remove opening/at-exit closing of devnull.</li>; <li><a href=""https://github.com/ipython/ipython/commit/9d0419bed36bae7228b2ad48296e58b918b1a9b8""><code>9d0419b</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/ipython/ipython/issues/13900"">#13900</a> from Carreau/doc-autosugg</li>; <li>Additional commits viewable in <a href=""https://github.com/ipython/ipython/compare/7.34.0...8.9.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=ipython&package-manager=pip&previous-version=7.34.0&new-version=8.9.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12664:2510,secur,security-vulnerabilities,2510,https://hail.is,https://github.com/hail-is/hail/pull/12664,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"89a94f694645c642ae67b2d5972d3f9fdadb928""><code>289a94f</code></a> Remove old classes that are deprecated for 2 years</li>; <li><a href=""https://github.com/AzureAD/microsoft-authentication-extensions-for-python/commit/fa1f45b556341b2c34e9bf63c06a5068571cd337""><code>fa1f45b</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/AzureAD/microsoft-authentication-extensions-for-python/issues/108"">#108</a> from AzureAD/actionable-encryption-exceptions</li>; <li><a href=""https://github.com/AzureAD/microsoft-authentication-extensions-for-python/commit/effe77842d25a8b093d18d9e33347f13e2ee094f""><code>effe778</code></a> Provide actionable messages for 2 dpapi errors</li>; <li><a href=""https://github.com/AzureAD/microsoft-authentication-extensions-for-python/commit/b674b6a07ca27b2c1b6f371040f035a546cfd468""><code>b674b6a</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/AzureAD/microsoft-authentication-extensions-for-python/issues/107"">#107</a> from AzureAD/file600</li>; <li>Additional commits viewable in <a href=""https://github.com/AzureAD/microsoft-authentication-extensions-for-python/compare/0.3.1...1.0.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=msal-extensions&package-manager=pip&previous-version=0.3.1&new-version=1.0.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recre",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11992:4324,authenticat,authentication-extensions-for-python,4324,https://hail.is,https://github.com/hail-is/hail/pull/11992,1,['authenticat'],['authentication-extensions-for-python']
Security,9); at java.net.URLClassLoader$1.run(URLClassLoader.java:365); at java.net.URLClassLoader$1.run(URLClassLoader.java:362); at java.security.AccessController.doPrivileged(Native Method); at java.net.URLClassLoader.findClass(URLClassLoader.java:361); at java.lang.ClassLoader.loadClass(ClassLoader.java:424); at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331); at java.lang.ClassLoader.loadClass(ClassLoader.java:357); at org.apache.spark.HeartbeatReceiver$$anonfun$org$apache$spark$HeartbeatReceiver$$expireDeadHosts$3.apply(HeartbeatReceiver.scala:198); at org.apache.spark.HeartbeatReceiver$$anonfun$org$apache$spark$HeartbeatReceiver$$expireDeadHosts$3.apply(HeartbeatReceiver.scala:196); at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733); at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99); at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99); at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230); at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40); at scala.collection.mutable.HashMap.foreach(HashMap.scala:99); at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732); at org.apache.spark.HeartbeatReceiver.org$apache$spark$HeartbeatReceiver$$expireDeadHosts(HeartbeatReceiver.scala:196); at org.apache.spark.HeartbeatReceiver$$anonfun$receiveAndReply$1.applyOrElse(HeartbeatReceiver.scala:119); at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105); at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205); at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101); at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:216); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); java.lang.Out,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4780:2504,Hash,HashTable,2504,https://hail.is,https://github.com/hail-is/hail/issues/4780,1,['Hash'],['HashTable']
Security,"912</code></a> MAINT: mock slowest test.</li>; <li><a href=""https://github.com/ipython/ipython/commit/a011765b44febfb11bae122d2ed7db763621ac8f""><code>a011765</code></a> Isolate the attack tests with setUp and tearDown methods</li>; <li><a href=""https://github.com/ipython/ipython/commit/c7a9470e540392c575aac46c3ee5cf4fe5123eb1""><code>c7a9470</code></a> Add some regression tests for this change</li>; <li><a href=""https://github.com/ipython/ipython/commit/fd34cf5f1f6e243243c738c6e0cf62eb682c4d68""><code>fd34cf5</code></a> Swallow potential exceptions from showtraceback()</li>; <li>Additional commits viewable in <a href=""https://github.com/ipython/ipython/compare/7.34.0...8.10.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=ipython&package-manager=pip&previous-version=7.34.0&new-version=8.10.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12683:2436,secur,security-vulnerabilities,2436,https://hail.is,https://github.com/hail-is/hail/pull/12683,4,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"93b95d</code></a> Merge CHANGES entry for 4.4.1 to 4.5.0</li>; <li><a href=""https://github.com/sphinx-doc/sphinx/commit/a001bf47d66ae804a9a6e5d754de9b5eda4d0eb9""><code>a001bf4</code></a> Update CHANGES for PR <a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10107"">#10107</a></li>; <li><a href=""https://github.com/sphinx-doc/sphinx/commit/b20e04968e73234da9fff7d19b12dfbeebebe944""><code>b20e049</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10107"">#10107</a> from Jean-Abou-Samra/intl-warnings</li>; <li>Additional commits viewable in <a href=""https://github.com/sphinx-doc/sphinx/compare/v3.5.4...v4.5.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=sphinx&package-manager=pip&previous-version=3.5.4&new-version=4.5.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11714:7779,secur,security-vulnerabilities,7779,https://hail.is,https://github.com/hail-is/hail/pull/11714,4,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"9518) | `cryptography:` <br> `41.0.7 -> 42.0.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **581/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 5.9 | Uncontrolled Resource Consumption (&#x27;Resource Exhaustion&#x27;) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-6157248](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-6157248) | `cryptography:` <br> `41.0.7 -> 42.0.2` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiIxZDhjNDI0MS1hOTllLTQwZDktOTM5Yy0zZWMzM2NkNTI0ZjkiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjFkOGM0MjQxLWE5OWUtNDBkOS05MzljLTNlYzMzY2Q1MjRmOSJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""1d8c4241-a99e-40d9-939c-3ec33cd524f9"",""pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14230:2287,access,access,2287,https://hail.is,https://github.com/hail-is/hail/pull/14230,2,"['access', 'authoriz']","['access', 'authorized']"
Security,"9717165b352c7f2f207c8e4ef624a01""><code>8bd8288</code></a> Build(deps): Bump pytest from 8.0.2 to 8.1.1 in /dependencies/default</li>; <li><a href=""https://github.com/pytest-dev/pytest-asyncio/commit/ef3b3477070d6a270e1bb2c1d438c64dba42724c""><code>ef3b347</code></a> Build(deps): Bump packaging from 23.2 to 24.0 in /dependencies/default</li>; <li><a href=""https://github.com/pytest-dev/pytest-asyncio/commit/b22d84e1f0d53920352be4c66d1b6c7f7a9ce005""><code>b22d84e</code></a> [docs] Fixes the example showing how to run all tests in a session-scoped loop.</li>; <li>Additional commits viewable in <a href=""https://github.com/pytest-dev/pytest-asyncio/compare/v0.21.1...v0.23.6"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pytest-asyncio&package-manager=pip&previous-version=0.21.1&new-version=0.23.6)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14507:9438,secur,security-vulnerabilities,9438,https://hail.is,https://github.com/hail-is/hail/pull/14507,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"99fd48d029f326cc54e036c994084c190""><code>18e1933</code></a> Migrate KeyVault Secrets to Autorest and stream-style serialization (<a href=""https://redirect.github.com/Azure/azure-sdk-for-java/issues/36461"">#36461</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-java/commit/910c88d6e85ba55d62062bf502055dfefa109530""><code>910c88d</code></a> mgmt compute, support convenience API listVmByVmss (<a href=""https://redirect.github.com/Azure/azure-sdk-for-java/issues/36631"">#36631</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/Azure/azure-sdk-for-java/compare/azure-core-http-netty_1.13.3...azure-core-http-netty_1.13.7"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=com.azure:azure-core-http-netty&package-manager=gradle&previous-version=1.13.3&new-version=1.13.7)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13597:3812,secur,security-vulnerabilities,3812,https://hail.is,https://github.com/hail-is/hail/pull/13597,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"9c4acb8d289e51005b8""><code>441d458</code></a> fix FUNDING file</li>; <li><a href=""https://github.com/qos-ch/slf4j/commit/f5e741ba1af6565269499d34c725c32ef8ca467f""><code>f5e741b</code></a> add FUNDING file</li>; <li><a href=""https://github.com/qos-ch/slf4j/commit/2e71327c8ee745927d731e8d9f4e51d331dad138""><code>2e71327</code></a> remove unused log4j dependency in the version definition section of pom.xml</li>; <li><a href=""https://github.com/qos-ch/slf4j/commit/3ff2a30e05e5825d96ddb54da243df48f1a9d897""><code>3ff2a30</code></a> start work on 2.0.6-SNAPSHOT</li>; <li>Additional commits viewable in <a href=""https://github.com/qos-ch/slf4j/compare/v_1.7.25...v_2.0.6"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=org.slf4j:slf4j-api&package-manager=gradle&previous-version=1.7.25&new-version=2.0.6)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12714:2084,secur,security-vulnerabilities,2084,https://hail.is,https://github.com/hail-is/hail/pull/12714,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"9d6805c47a175""><code>e89c8c8</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/jmoiron/humanize/issues/241"">#241</a> from samueljsb/remove-deprecated-private-function-ali...</li>; <li><a href=""https://github.com/jmoiron/humanize/commit/ffe4bcfaa6cfbd95ba47315f8f71a206485af6ae""><code>ffe4bcf</code></a> Remove deprecated VERSION, use <strong>version</strong> instead</li>; <li><a href=""https://github.com/jmoiron/humanize/commit/eb3e2534267714361da866109bd33ff20e63416c""><code>eb3e253</code></a> Merge branch 'master' into no-overflow-naturaldelta</li>; <li>Additional commits viewable in <a href=""https://github.com/jmoiron/humanize/compare/1.0.0...4.0.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=humanize&package-manager=pip&previous-version=1.0.0&new-version=4.0.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11517:6962,secur,security-vulnerabilities,6962,https://hail.is,https://github.com/hail-is/hail/pull/11517,4,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"9e6eee0e9edf010034b63b""><code>d725a9b</code></a> Add Python 3.10 to GitHub Actions</li>; <li><a href=""https://github.com/urllib3/urllib3/commit/339ad34c677c98fd9ad008de1d8bbeb9dbf34381""><code>339ad34</code></a> Use pytest==6.2.4 on Python 3.10+</li>; <li><a href=""https://github.com/urllib3/urllib3/commit/f271c9c3149e20d7feffb6429b135bbb6c09ddf4""><code>f271c9c</code></a> Apply latest Black formatting</li>; <li><a href=""https://github.com/urllib3/urllib3/commit/1884878aac87ef0494b282e940c32c24ee917d52""><code>1884878</code></a> [1.26] Properly proxy EOF on the SSLTransport test suite</li>; <li>See full diff in <a href=""https://github.com/urllib3/urllib3/compare/1.26.4...1.26.5"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=urllib3&package-manager=pip&previous-version=1.26.4&new-version=1.26.5)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10544:3069,secur,security-vulnerabilities,3069,https://hail.is,https://github.com/hail-is/hail/pull/10544,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"9f69135f292903d046207773794""><code>b0942e1</code></a> Add initial 'Methods, helpers and QtPy namespace specifics' section to the RE...</li>; <li><a href=""https://github.com/spyder-ide/qtpy/commit/b3efba8b2f5ef670842c73dd171aaa98e298db37""><code>b3efba8</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/spyder-ide/qtpy/issues/354"">#354</a> from zjp/objectisalive</li>; <li><a href=""https://github.com/spyder-ide/qtpy/commit/60af2d85eb25590e2ae7c1382011fe7fac818279""><code>60af2d8</code></a> compat.py: Add wrapper around sip/shiboken isdeleted/isvalid</li>; <li>Additional commits viewable in <a href=""https://github.com/spyder-ide/qtpy/compare/v2.1.0...v2.2.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=qtpy&package-manager=pip&previous-version=2.1.0&new-version=2.2.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12194:8745,secur,security-vulnerabilities,8745,https://hail.is,https://github.com/hail-is/hail/pull/12194,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,": None,; 'vep_runner': 'VEP'},; 'reference_ht_path': 'gs://seqr-reference-data/GRCh38/all_reference_data/combined_reference_data_grch38.ht',; 'remap_path': None,; 'sample_type': 'WGS',; 'scheduler_messages': None,; 'set_progress_percentage': <bound method TaskStatusReporter.update_progress_percentage of <luigi.worker.TaskStatusReporter object at 0x7f0583f0f588>>,; 'set_status_message': <bound method TaskStatusReporter.update_status_message of <luigi.worker.TaskStatusReporter object at 0x7f0583f0f588>>,; 'set_tracking_url': <bound method TaskStatusReporter.update_tracking_url of <luigi.worker.TaskStatusReporter object at 0x7f0583f0f588>>,; 'source_paths': ['gs://seqr-bw/merged_phased_3P5CH.split.vcf.gz'],; 'subset_path': None,; 'task_id': 'SeqrVCFToMTTask_gs___seqr_refere_VARIANTS_gs___seqr_bw_mer_b185718e87',; 'validate': False,; 'vep_config_json_path': None,; 'vep_runner': 'VEP'}; [Stage 1:======================================================>(492 + 8) / 500]2020-04-05 14:09:30 Hail: INFO: Coerced almost-sorted dataset; [Stage 2:====================================================> (485 + 15) / 500]2020-04-05 14:09:34 Hail: INFO: Coerced almost-sorted dataset; [Stage 3:==================================================> (467 + 33) / 500]MT using schema class <class 'lib.model.seqr_mt_schema.SeqrVariantsAndGenotypesSchema'> already has vep annotation.; MT using schema class <class 'lib.model.seqr_mt_schema.SeqrVariantsAndGenotypesSchema'> already has filters annotation.; MT using schema class <class 'lib.model.seqr_mt_schema.SeqrVariantsAndGenotypesSchema'> already has rsid annotation.; MT using schema class <class 'lib.model.seqr_mt_schema.SeqrVariantsAndGenotypesSchema'> already has vep annotation.; ----------------------------------------; Global fields:; 'gencodeVersion': str; 'sourceFilePath': str; 'genomeVersion': str; 'sampleType': str; 'hail_version': str; ----------------------------------------; Column fields:; 's': str; -----------------------------------",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8469:38783,validat,validate,38783,https://hail.is,https://github.com/hail-is/hail/issues/8469,1,['validat'],['validate']
Security,": RegionPool: initialized for thread 8: pool-1-thread-1; 2023-05-04 01:04:37.601 : INFO: TaskReport: stage=0, partition=0, attempt=0, peakBytes=0, peakBytesReadable=0.00 B, chunks requested=0, cache hits=0; 2023-05-04 01:04:37.601 : INFO: RegionPool: FREE: 0 allocated (0 blocks / 0 chunks), regions.size = 0, 0 current java objects, thread 8: pool-1-thread-1; 2023-05-04 01:04:37.601 : INFO: RegionPool: FREE: 128.0K allocated (128.0K blocks / 0 chunks), regions.size = 2, 0 current java objects, thread 8: pool-1-thread-1; 2023-05-04 01:04:37.603 : ERROR: SocketException: Connection reset; From javax.net.ssl.SSLException: Connection reset; 	at sun.security.ssl.Alert.createSSLException(Alert.java:127); 	at sun.security.ssl.TransportContext.fatal(TransportContext.java:324); 	at sun.security.ssl.TransportContext.fatal(TransportContext.java:267); 	at sun.security.ssl.TransportContext.fatal(TransportContext.java:262); 	at sun.security.ssl.SSLTransport.decode(SSLTransport.java:138); 	at sun.security.ssl.SSLSocketImpl.decode(SSLSocketImpl.java:1400); 	at sun.security.ssl.SSLSocketImpl.readApplicationRecord(SSLSocketImpl.java:1368); 	at sun.security.ssl.SSLSocketImpl.access$300(SSLSocketImpl.java:73); 	at sun.security.ssl.SSLSocketImpl$AppInputStream.read(SSLSocketImpl.java:962); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:284); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.MeteredStream.read(MeteredStream.java:134); 	at java.io.FilterInputStream.read(FilterInputStream.java:133); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3456); 	at com.google.api.client.http.javanet.NetHttpResponse$SizeValidatingInputStream.read(NetHttpResponse.java:164); 	at java.nio.channels.Channels$ReadableByteChannelImpl.read(Channels.java:385); 	at is.hail.relocated.com.google.cloud.storage.StorageByteChannels$ScatteringByteChannelFacade.read(StorageByteChannels.java:226); 	at is.hail.relocated.com.go",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12983:23990,secur,security,23990,https://hail.is,https://github.com/hail-is/hail/issues/12983,1,['secur'],['security']
Security,"://github-redirect.dependabot.com/axios/axios/pull/3707"">#3707</a>)</li>; <li>Updating documentation around dispatching requests (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3772"">#3772</a>)</li>; <li>Adding documentation for the type guard isAxiosError (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3767"">#3767</a>)</li>; <li>Adding explanation of cancel token (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3803"">#3803</a>)</li>; <li>Updating CI status badge (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3953"">#3953</a>)</li>; <li>Fixing errors with JSON documentation (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3936"">#3936</a>)</li>; <li>Fixing README typo under Request Config (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3825"">#3825</a>)</li>; <li>Adding axios-multi-api to the ecosystem file (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3817"">#3817</a>)</li>; <li>Adding SECURITY.md to properly disclose security vulnerabilities (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3981"">#3981</a>)</li>; </ul>; <p>Huge thanks to everyone who contributed to this release via code (authors listed below) or via reviews and triaging on GitHub:</p>; <ul>; <li><a href=""https://github.com/SashaKoro"">Sasha Korotkov</a></li>; <li><a href=""https://github.com/timemachine3030"">Daniel Lopretto</a></li>; <li><a href=""https://github.com/MikeBishop"">Mike Bishop</a></li>; <li><a href=""https://github.com/DigitalBrainJS"">Dmitriy Mozgovoy</a></li>; <li><a href=""https://github.com/bimbiltu"">Mark</a></li>; <li><a href=""https://github.com/piiih"">Philipe Gouveia Paixão</a></li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/axios/axios/blob/master/CHANGELOG.md"">axios's changelog</a>.</em></p>; <blockquote>; <h3>0.21.2",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11080:4807,SECUR,SECURITY,4807,https://hail.is,https://github.com/hail-is/hail/pull/11080,2,['SECUR'],['SECURITY']
Security,"://github-redirect.dependabot.com/axios/axios/pull/3707"">#3707</a>)</li>; <li>Updating documentation around dispatching requests (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3772"">#3772</a>)</li>; <li>Adding documentation for the type guard isAxiosError (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3767"">#3767</a>)</li>; <li>Adding explanation of cancel token (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3803"">#3803</a>)</li>; <li>Updating CI status badge (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3953"">#3953</a>)</li>; <li>Fixing errors with JSON documentation (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3936"">#3936</a>)</li>; <li>Fixing README typo under Request Config (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3825"">#3825</a>)</li>; <li>Adding axios-multi-api to the ecosystem file (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3817"">#3817</a>)</li>; <li>Adding SECURITY.md to properly disclose security vulnerabilities (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3981"">#3981</a>)</li>; </ul>; <p>Huge thanks to everyone who contributed to this release via code (authors listed below) or via reviews and triaging on GitHub:</p>; <ul>; <li><a href=""https://github.com/axios/axios/blob/master/mailto:jasonsaayman@gmail.com"">Jay</a></li>; <li><a href=""https://github.com/SashaKoro"">Sasha Korotkov</a></li>; <li><a href=""https://github.com/timemachine3030"">Daniel Lopretto</a></li>; <li><a href=""https://github.com/MikeBishop"">Mike Bishop</a></li>; <li><a href=""https://github.com/DigitalBrainJS"">Dmitriy Mozgovoy</a></li>; <li><a href=""https://github.com/bimbiltu"">Mark</a></li>; <li><a href=""https://github.com/piiih"">Philipe Gouveia Paixão</a></li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/axios/",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11080:10332,SECUR,SECURITY,10332,https://hail.is,https://github.com/hail-is/hail/pull/11080,2,['SECUR'],['SECURITY']
Security,"://github-redirect.dependabot.com/pytest-dev/pytest/issues/9668"">#9668</a> from hugovk/test-me-latest-3.10</li>; <li><a href=""https://github.com/pytest-dev/pytest/commit/0fae45bb6e4ecf177afdfa3bf03738813ec7b913""><code>0fae45b</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pytest-dev/pytest/issues/9660"">#9660</a> from pytest-dev/backport-9646-to-7.0.x</li>; <li><a href=""https://github.com/pytest-dev/pytest/commit/37d434f5fcb5f80188b3d5b8f22d418dc191b955""><code>37d434f</code></a> [7.0.x] Delay warning about collector/item diamond inheritance</li>; <li>Additional commits viewable in <a href=""https://github.com/pytest-dev/pytest/compare/6.2.5...7.0.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pytest&package-manager=pip&previous-version=6.2.5&new-version=7.0.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11516:6799,secur,security-vulnerabilities,6799,https://hail.is,https://github.com/hail-is/hail/pull/11516,6,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"://github.com/tomplus/kubernetes_asyncio/commit/11c3eb4d50ae822545572aa7b8c15f7153f65a1c""><code>11c3eb4</code></a> [feat] regenerate library using API K8s v23.6.0 (<a href=""https://github-redirect.dependabot.com/tomplus/kubernetes_asyncio/issues/211"">#211</a>)</li>; <li><a href=""https://github.com/tomplus/kubernetes_asyncio/commit/35f109ce6e093285f232b4f45d68f44a964c6d11""><code>35f109c</code></a> chore(deps): bump actions/setup-python from 3 to 4 (<a href=""https://github-redirect.dependabot.com/tomplus/kubernetes_asyncio/issues/208"">#208</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/tomplus/kubernetes_asyncio/compare/v19.15.1...24.2.2"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=kubernetes-asyncio&package-manager=pip&previous-version=19.15.1&new-version=24.2.2)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12196:16816,secur,security-vulnerabilities,16816,https://hail.is,https://github.com/hail-is/hail/pull/12196,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | Cross-site Scripting (XSS) <br/>[SNYK-PYTHON-NBCONVERT-2979829](https://snyk.io/vuln/SNYK-PYTHON-NBCONVERT-2979829) | `nbconvert:` <br> `5.6.1 -> 6.3.0b0` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | Open Redirect <br/>[SNYK-PYTHON-NOTEBOOK-1041707](https://snyk.io/vuln/SNYK-PYTHON-NOTEBOOK-1041707) | `notebook:` <br> `5.7.16 -> 6.4.12` <br> | No | No Known Exploit ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | Information Exposure <br/>[SNYK-PYTHON-NOTEBOOK-2441824](https://snyk.io/vuln/SNYK-PYTHON-NOTEBOOK-2441824) | `notebook:` <br> `5.7.16 -> 6.4.12` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | Access Restriction Bypass <br/>[SNYK-PYTHON-NOTEBOOK-2928995](https://snyk.io/vuln/SNYK-PYTHON-NOTEBOOK-2928995) | `notebook:` <br> `5.7.16 -> 6.4.12` <br> | No | No Known Exploit ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | Regular Expression Denial of Service (ReDoS) <br/>[SNYK-PYTHON-PYGMENTS-1086606](https://snyk.io/vuln/SNYK-PYTHON-PYGMENTS-1086606) | `pygments:` <br> `2.5.2 -> 2.15.0` <br> | No | Proof of Concept ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | Denial of Service (DoS) <br/>[SNYK-PYTHON-PYGMENTS-1088505](https://snyk.io/vuln/SNYK-PYTHON-PYGMENTS-1088505) | `pygments:` <br> `2.5.2 -> 2.15.0` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | Regular Expression Denial of Service (ReDoS) <br/>[SNYK-PYTHON-PYGMENTS-5750273](https://snyk.io/vuln/SNYK-PYTHON-PYGM",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13835:3774,Access,Access,3774,https://hail.is,https://github.com/hail-is/hail/pull/13835,4,['Access'],['Access']
Security,"://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | Cross-site Scripting (XSS) <br/>[SNYK-PYTHON-NBCONVERT-2979829](https://snyk.io/vuln/SNYK-PYTHON-NBCONVERT-2979829) | `nbconvert:` <br> `5.6.1 -> 6.3.0b0` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | Open Redirect <br/>[SNYK-PYTHON-NOTEBOOK-1041707](https://snyk.io/vuln/SNYK-PYTHON-NOTEBOOK-1041707) | `notebook:` <br> `5.7.16 -> 6.4.12` <br> | No | No Known Exploit ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | Information Exposure <br/>[SNYK-PYTHON-NOTEBOOK-2441824](https://snyk.io/vuln/SNYK-PYTHON-NOTEBOOK-2441824) | `notebook:` <br> `5.7.16 -> 6.4.12` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | Access Restriction Bypass <br/>[SNYK-PYTHON-NOTEBOOK-2928995](https://snyk.io/vuln/SNYK-PYTHON-NOTEBOOK-2928995) | `notebook:` <br> `5.7.16 -> 6.4.12` <br> | No | No Known Exploit ; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | Race Condition <br/>[SNYK-PYTHON-PROMPTTOOLKIT-6141120](https://snyk.io/vuln/SNYK-PYTHON-PROMPTTOOLKIT-6141120) | `prompt-toolkit:` <br> `1.0.18 -> 3.0.13` <br> | No | No Known Exploit ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | Regular Expression Denial of Service (ReDoS) <br/>[SNYK-PYTHON-PYGMENTS-1086606](https://snyk.io/vuln/SNYK-PYTHON-PYGMENTS-1086606) | `pygments:` <br> `2.5.2 -> 2.15.0` <br> | No | Proof of Concept ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | Denial of Service (DoS) <br/>[SNYK-PYTHON-PYGMENTS-1088505](https://snyk.io/vuln/SNYK-PYTHON-PYGMENTS-1088505) | `py",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14257:4035,Access,Access,4035,https://hail.is,https://github.com/hail-is/hail/pull/14257,2,['Access'],['Access']
Security,"; <li><a href=""https://github.com/lepture/mistune/commit/babb0cfa57a983ead615286a2b7c8f6885c46721""><code>babb0cf</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/lepture/mistune/issues/295"">#295</a> from dairiki/bug.escape_url</li>; <li><a href=""https://github.com/lepture/mistune/commit/fc2cd53d7698e432ab5b250ffac53458263a49e2""><code>fc2cd53</code></a> Make mistune.util.escape_url less aggressive</li>; <li><a href=""https://github.com/lepture/mistune/commit/3e8d35215120ac82176f300dd5e20c0bea5464ea""><code>3e8d352</code></a> Version bump 2.0.1</li>; <li>Additional commits viewable in <a href=""https://github.com/lepture/mistune/compare/v0.8.4...v2.0.3"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=mistune&package-manager=pip&previous-version=0.8.4&new-version=2.0.3)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12064:4147,secur,security-vulnerabilities,4147,https://hail.is,https://github.com/hail-is/hail/pull/12064,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"; <li><a href=""https://github.com/samtools/htsjdk/commit/500cffda9c511d88a736bcbb91d3f10259b967fb""><code>500cffd</code></a> Test fix</li>; <li><a href=""https://github.com/samtools/htsjdk/commit/662c8274fad42e001e63e2b9c9c2066714b42a0d""><code>662c827</code></a> Test fix</li>; <li><a href=""https://github.com/samtools/htsjdk/commit/e58f8a2250fc47afecfa38611b0f51b02ac6b933""><code>e58f8a2</code></a> Minor code cleanup</li>; <li><a href=""https://github.com/samtools/htsjdk/commit/b1085dab46bc220b1f6d3eb92fcbe73818ade3eb""><code>b1085da</code></a> Test fixes</li>; <li>Additional commits viewable in <a href=""https://github.com/samtools/htsjdk/compare/3.0.4...4.0.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=com.github.samtools:htsjdk&package-manager=gradle&previous-version=3.0.4&new-version=4.0.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13576:8450,secur,security-vulnerabilities,8450,https://hail.is,https://github.com/hail-is/hail/pull/13576,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"; <li>Address remaining <code>ResourceWarning</code> related to the socket used by <code>run_simple</code>.; Remove <code>prepare_socket</code>, which now happens when creating the server. :issue:<code>2421</code></li>; <li>Update pre-existing headers for <code>multipart/form-data</code> requests with the test; client. :issue:<code>2549</code></li>; <li>Fix handling of header extended parameters such that they are no longer quoted.; :issue:<code>2529</code></li>; <li><code>LimitedStream.read</code> works correctly when wrapping a stream that may not return; the requested size in one <code>read</code> call. :issue:<code>2558</code></li>; <li>A cookie header that starts with <code>=</code> is treated as an empty key and discarded,; rather than stripping the leading <code>==</code>.</li>; <li>Specify a maximum number of multipart parts, default 1000, after which a; <code>RequestEntityTooLarge</code> exception is raised on parsing. This mitigates a DoS; attack where a larger number of form/file parts would result in disproportionate; resource use.</li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/pallets/werkzeug/commit/22a254fca2ad0130adbbcbd11d3de51bcb04a08b""><code>22a254f</code></a> release version 2.2.3</li>; <li><a href=""https://github.com/pallets/werkzeug/commit/517cac5a804e8c4dc4ed038bb20dacd038e7a9f1""><code>517cac5</code></a> Merge pull request from GHSA-xg9f-g7g7-2323</li>; <li><a href=""https://github.com/pallets/werkzeug/commit/babc8d9e8c9fa995ef26050698bc9b5a92803664""><code>babc8d9</code></a> rewrite docs about request data limits</li>; <li><a href=""https://github.com/pallets/werkzeug/commit/09449ee77934a0c883f5959785864ecae6aaa2c9""><code>09449ee</code></a> clean up docs</li>; <li><a href=""https://github.com/pallets/werkzeug/commit/fe899d0cdf767a7289a8bf746b7f72c2907a1b4b""><code>fe899d0</code></a> limit the maximum number of multipart form parts</li>; <li><a href=""https://github.com/pallets/we",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12703:2822,attack,attack,2822,https://hail.is,https://github.com/hail-is/hail/pull/12703,1,['attack'],['attack']
Security,"; <li>Deprecated the <code>urllib3[secure]</code> extra and the <code>urllib3.contrib.pyopenssl</code> module.; Both will be removed in v2.x. See this <code>GitHub issue &lt;https://github.com/urllib3/urllib3/issues/2680&gt;</code>_; for justification and info on how to migrate.</li>; </ul>; <h1>1.26.11 (2022-07-25)</h1>; <ul>; <li>Fixed an issue where reading more than 2 GiB in a call to <code>HTTPResponse.read</code> would; raise an <code>OverflowError</code> on Python 3.9 and earlier.</li>; </ul>; <h1>1.26.10 (2022-07-07)</h1>; <ul>; <li>Removed support for Python 3.5</li>; <li>Fixed an issue where a <code>ProxyError</code> recommending configuring the proxy as HTTP; instead of HTTPS could appear even when an HTTPS proxy wasn't configured.</li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/urllib3/urllib3/commit/a5b29ac1025f9bb30f2c9b756f3b171389c2c039""><code>a5b29ac</code></a> Add outputs.hashes to build action</li>; <li><a href=""https://github.com/urllib3/urllib3/commit/a0b22f820639e6212994ba147f76b60d88185792""><code>a0b22f8</code></a> Release 1.26.12</li>; <li><a href=""https://github.com/urllib3/urllib3/commit/13f11172648e880bb4a385fc4425420cd2534516""><code>13f1117</code></a> [1.26] Add SLSA generic generator to publish workflow</li>; <li><a href=""https://github.com/urllib3/urllib3/commit/f95b9640604e7dd70d50d81f68fd14a36c082841""><code>f95b964</code></a> Add deprecation warnings for pyOpenSSL and the [secure] extra</li>; <li><a href=""https://github.com/urllib3/urllib3/commit/aa3def7d242525e6e854991247c4b68583d15135""><code>aa3def7</code></a> Release 1.26.11</li>; <li><a href=""https://github.com/urllib3/urllib3/commit/6f93b8f450b18b4c9f4c6333d759a911a63d15ae""><code>6f93b8f</code></a> Fix <code>OverflowError</code> when TLS is used on some Python versions</li>; <li><a href=""https://github.com/urllib3/urllib3/commit/0a5f34d2c2ee6457e8365543243eccd3d1dc9430""><code>0a5f34d</code></a> Set GHA token perm",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12140:3105,hash,hashes,3105,https://hail.is,https://github.com/hail-is/hail/pull/12140,1,['hash'],['hashes']
Security,"; File ""<decorator-gen-502>"", line 2, in import_vcf; File ""/tmp/7417fcfbbeee44d0b3f4c0b3750121a7/hail-0.1-es-6.2.4-with-strip-chr-prefix.zip/hail/java.py"", line 121, in handle_py4j; hail.java.FatalError: FileNotFoundException: File file:/tmp/clinvar.vcf.gz does not exist. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 0.0 failed 20 times, most recent failure: Lost task 0.19 in stage 0.0 (TID 19, without-vep-520334-sw-rmwj.c.seqr-project.internal): java.io.FileNotFoundException: File file:/tmp/clinvar.vcf.gz does not exist; 	at org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:611); 	at org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:824); 	at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:601); 	at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:428); 	at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:142); 	at org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:346); 	at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:769); 	at org.apache.hadoop.mapred.LineRecordReader.<init>(LineRecordReader.java:109); 	at org.apache.hadoop.mapred.TextInputFormat.getRecordReader(TextInputFormat.java:67); 	at org.apache.spark.rdd.HadoopRDD$$anon$1.<init>(HadoopRDD.scala:245); 	at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:208); 	at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:101); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3760:5728,Checksum,ChecksumFileSystem,5728,https://hail.is,https://github.com/hail-is/hail/issues/3760,2,['Checksum'],"['ChecksumFSInputChecker', 'ChecksumFileSystem']"
Security,"; aiodns 2.0.0 requires pycares, which is not installed. ```; </details>. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **554/1000** <br/> **Why?** Has a fix available, CVSS 6.8 | Insufficient Verification of Data Authenticity <br/>[SNYK-PYTHON-CERTIFI-3164749](https://snyk.io/vuln/SNYK-PYTHON-CERTIFI-3164749) | `certifi:` <br> `2021.10.8 -> 2023.7.22` <br> | No | No Known Exploit ; ![critical severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/c.png ""critical severity"") | **704/1000** <br/> **Why?** Has a fix available, CVSS 9.8 | Improper Following of a Certificate&#x27;s Chain of Trust <br/>[SNYK-PYTHON-CERTIFI-5805047](https://snyk.io/vuln/SNYK-PYTHON-CERTIFI-5805047) | `certifi:` <br> `2021.10.8 -> 2023.7.22` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **509/1000** <br/> **Why?** Has a fix available, CVSS 5.9 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3172287](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3172287) | `cryptography:` <br> `3.3.2 -> 41.0.6` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **454/1000** <br/> **Why?** Has a fix available, CVSS 4.8 | Expected Behavior Violation <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3314966](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3314966) | `cryptography:` <br> `3.3.2 -> 41.0.6` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14148:1539,Certificate,Certificate,1539,https://hail.is,https://github.com/hail-is/hail/pull/14148,1,['Certificate'],['Certificate']
Security,"; aiodns 2.0.0 requires pycares, which is not installed. ```; </details>. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **554/1000** <br/> **Why?** Has a fix available, CVSS 6.8 | Insufficient Verification of Data Authenticity <br/>[SNYK-PYTHON-CERTIFI-3164749](https://snyk.io/vuln/SNYK-PYTHON-CERTIFI-3164749) | `certifi:` <br> `2021.10.8 -> 2023.7.22` <br> | No | No Known Exploit ; ![critical severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/c.png ""critical severity"") | **704/1000** <br/> **Why?** Has a fix available, CVSS 9.8 | Improper Following of a Certificate&#x27;s Chain of Trust <br/>[SNYK-PYTHON-CERTIFI-5805047](https://snyk.io/vuln/SNYK-PYTHON-CERTIFI-5805047) | `certifi:` <br> `2021.10.8 -> 2023.7.22` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **509/1000** <br/> **Why?** Has a fix available, CVSS 5.9 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3172287](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3172287) | `cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **454/1000** <br/> **Why?** Has a fix available, CVSS 4.8 | Expected Behavior Violation <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3314966](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3314966) | `cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14327:1531,Certificate,Certificate,1531,https://hail.is,https://github.com/hail-is/hail/pull/14327,2,['Certificate'],['Certificate']
Security,; at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.util.HadoopConfigurationProperty.getPropsWithPrefix(HadoopConfigurationProperty.java:106); at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemConfiguration.getGcsOptionsBuilder(GoogleHadoopFileSystemConfiguration.java:421); at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemConfiguration.getGcsFsOptionsBuilder(GoogleHadoopFileSystemConfiguration.java:383); at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.createGcsFs(GoogleHadoopFileSystemBase.java:1516); at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.configure(GoogleHadoopFileSystemBase.java:1486); at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.initialize(GoogleHadoopFileSystemBase.java:541); at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.initialize(GoogleHadoopFileSystemBase.java:494); at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2669); at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:94); at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2703); at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2685); at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:373); at org.apache.hadoop.fs.Path.getFileSystem(Path.java:295); at is.hail.io.fs.HadoopFS.is$hail$io$fs$HadoopFS$$_fileSystem(HadoopFS.scala:157); at is.hail.io.fs.HadoopFS.glob(HadoopFS.scala:244); at is.hail.io.fs.HadoopFS$$anonfun$globAll$1.apply(HadoopFS.scala:226); at is.hail.io.fs.HadoopFS$$anonfun$globAll$1.apply(HadoopFS.scala:225); at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:435); at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:441); at scala.collection.Iterator$class.foreach(Iterator.scala:891); at scala.collection.AbstractIterator.foreach(Iterator.scala:1334); at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59); at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104); at scala.collect,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8343:3811,access,access,3811,https://hail.is,https://github.com/hail-is/hail/issues/8343,1,['access'],['access']
Security,"; at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205); at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101); at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:216); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); java.lang.OutOfMemoryError: GC overhead limit exceeded; at scala.collection.mutable.ListBuffer.$plus$eq(ListBuffer.scala:170); at scala.collection.mutable.ListBuffer.$plus$eq(ListBuffer.scala:45); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.mutable.HashMap$$anon$2$$anonfun$foreach$3.apply(HashMap.scala:108); at scala.collection.mutable.HashMap$$anon$2$$anonfun$foreach$3.apply(HashMap.scala:108); at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230); at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40); at scala.collection.mutable.HashMap$$anon$2.foreach(HashMap.scala:108); at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); at scala.collection.AbstractTraversable.map(Traversable.scala:104); at org.apache.spark.SparkStatusTracker.getActiveStageIds(SparkStatusTracker.scala:61); at org.apache.spark.ui.ConsoleProgressBar.org$apache$spark$ui$ConsoleProgressBar$$refresh(ConsoleProgressBar.scala:67); at org.apache.spark.ui.ConsoleProgressBar$$anon$1.run(ConsoleProgressBar.scala:55); at java.util.TimerThread.mainLoop(Timer.java:555); at java.util.TimerThread.run(Timer.java:505); ---------------------------------------------------------------------------; FatalError Traceback (most recent call last); /restricted/projectnb/ukbiobank/ad/analysis/ad.v1/bgen2mt.py in <module>; 6 sample=""/project/ukbiobank/imp/uk.v3/bgen/ukb19416_imp_chr""+chr+""_v3_s487327.sample""; 7 ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4780:4072,Hash,HashTable,4072,https://hail.is,https://github.com/hail-is/hail/issues/4780,1,['Hash'],['HashTable']
Security,"; }; ```; * Scripts are thing that can be run by typing, in shell `npm run`. Ex: `npm run dev`. ### Async, Await, Promises and callback (WIP); Javascript is async-first. This is most obvious in Node.js, which is the most popular library for server-side JS.; * [How event loop works](https://nodejs.org/en/docs/guides/event-loop-timers-and-nexttick/); <img width=""765"" alt=""screen shot 2019-01-18 at 11 20 51 am"" src=""https://user-images.githubusercontent.com/5543229/51399094-1f999c00-1b13-11e9-8dfb-da8aa20807b0.png"">. * The event loop call stack: https://www.youtube.com/watch?v=8aGhZQkoFbQ. At a high level, a function that defines a callback will return immediately. The callback is pushed on to the event-loop stack, and on each tick, is checked to determine whether it has returned or not. Blocking operations within the callbacks will block the event loop. This is how CPU viruses, like blockchain manage to slow down web pages that are hijacked to include some mining script: hashing something 30 million times, takes a long time, and JS cannot do anything besides waiting for those operations to finish in a synchronous fashion. Luckily, asynchronous functions are the norm in the JS ecosystem, such that both in the browser, and nodejs, IO functions are (mostly?) asynchronous.; * For NodeJS: Transparently to the user, blocking operations (IO) are executed from kernel threads that Node maintains in the background, effectively making these operations non-blocking (until the thread pool is exhausted). Browsers and NodeJS use different event loops:. NodeJS: libuv event loop; * Node maintains a hidden worker thread pool (kernel threads) through which it issues sys calls, to avoid blocking the event loop. Web: depends on the underlying Javascript Engine; * Chromium: V8: libevent: https://stackoverflow.com/questions/25750884/are-there-significant-differences-between-the-chrome-browser-event-loop-versus-t; * Firefox: Spidermonkey: ?; * https://developer.mozilla.org/en-US/docs/Web/Jav",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5162:3878,hash,hashing,3878,https://hail.is,https://github.com/hail-is/hail/pull/5162,1,['hash'],['hashing']
Security,"</a> release 8.12.0</li>; <li><a href=""https://github.com/ipython/ipython/commit/2bb46729ded8e58153f10629c3b6fa0d42acb751""><code>2bb4672</code></a> Update whats new for 3.12 (<a href=""https://redirect.github.com/ipython/ipython/issues/14000"">#14000</a>)</li>; <li><a href=""https://github.com/ipython/ipython/commit/4f0b2357354aa35042244f902f9bcea9da65dfd9""><code>4f0b235</code></a> upate whats new for 3.12</li>; <li><a href=""https://github.com/ipython/ipython/commit/d52bf622ce9922106f8bcc1867c0a27a884201a0""><code>d52bf62</code></a> Allow to dispatch getting documentation on objects. (<a href=""https://redirect.github.com/ipython/ipython/issues/13975"">#13975</a>)</li>; <li><a href=""https://github.com/ipython/ipython/commit/3a9419dce7d6ccf7de39be606eec2fc212ef4445""><code>3a9419d</code></a> Update completer documentation (<a href=""https://redirect.github.com/ipython/ipython/issues/13999"">#13999</a>)</li>; <li><a href=""https://github.com/ipython/ipython/commit/a7d8defdecca3cfa54eada171181e0880c8b6b5f""><code>a7d8def</code></a> Expose <code>auto_suggest.resume_hinting</code>, fix resume on backspace (<a href=""https://redirect.github.com/ipython/ipython/issues/13994"">#13994</a>)</li>; <li><a href=""https://github.com/ipython/ipython/commit/4e7b9408a0b35cabbdc973f131257f4e97a3ddcf""><code>4e7b940</code></a> Fix autosuggestions in multi-line mode, vi command mode delay (<a href=""https://redirect.github.com/ipython/ipython/issues/13991"">#13991</a>)</li>; <li><a href=""https://github.com/ipython/ipython/commit/ad452c1d8bb25e742caa152fb301e0e6626b6faa""><code>ad452c1</code></a> Improve API documentation around configuration of embedded IPython (<a href=""https://redirect.github.com/ipython/ipython/issues/13989"">#13989</a>)</li>; <li><a href=""https://github.com/ipython/ipython/commit/92027083ab69186db3f104fe38651086bcf4e760""><code>9202708</code></a> Handle OSError cases where traceback frames occur from built files (<a href=""https://redirect.github.com/ipython/ipython/issues/13964"">#1396",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12832:1272,Expose,Expose,1272,https://hail.is,https://github.com/hail-is/hail/pull/12832,2,['Expose'],['Expose']
Security,"</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=certifi&package-manager=pip&previous-version=2022.9.24&new-version=2022.12.7)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself); You can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/hail-is/hail/network/alerts). </details>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12549:2275,secur,security,2275,https://hail.is,https://github.com/hail-is/hail/pull/12549,6,"['Secur', 'secur']","['Security', 'security']"
Security,"</code> &amp; <code>Library</code> - <a href=""https://github.com/soywiz""><code>@​soywiz</code></a>.</li>; <li><a href=""https://redirect.github.com/java-native-access/jna/pull/1491"">#1491</a>: Update libffi to v3.4.4 - <a href=""https://github.com/matthiasblaesing""><code>@​matthiasblaesing</code></a>.</li>; <li><a href=""https://redirect.github.com/java-native-access/jna/issues/1487"">#1487</a>: Add 'uses' information to OSGI metadata in MANIFEST.MF to improve stability of package resolution - <a href=""https://github.com/sratz""><code>@​sratz</code></a>.</li>; </ul>; <h2>Bug Fixes</h2>; <ul>; <li><a href=""https://redirect.github.com/java-native-access/jna/issues/1452"">#1452</a>: Fix memory allocation/handling for error message generation in native library code (<code>dispatch.c</code>) - <a href=""https://github.com/matthiasblaesing""><code>@​matthiasblaesing</code></a>.</li>; <li><a href=""https://redirect.github.com/java-native-access/jna/issues/1460"">#1460</a>: Fix win32 variant date conversion in DST offest window and with millisecond values - <a href=""https://github.com/eranl""><code>@​eranl</code></a>.</li>; <li><a href=""https://redirect.github.com/java-native-access/jna/issues/1472"">#1472</a>: Fix incorrect bitmask in <code>c.s.j.Pointer#createConstant(int)</code> - <a href=""https://github.com/dbwiddis""><code>@​dbwiddis</code></a>.</li>; <li><a href=""https://redirect.github.com/java-native-access/jna/issues/1481"">#1481</a>: Fix NPE in NativeLibrary when unpacking from classpath is disabled - <a href=""https://github.com/trespasserw""><code>@​trespasserw</code></a>.</li>; <li><a href=""https://redirect.github.com/java-native-access/jna/pull/1489"">#1489</a>: Fixes typo in <code>OpenGL32Util#wglGetProcAddress</code>, instead of parameter <code>procName</code> the hardcoded value <code>wglEnumGpusNV</code> was used - <a href=""https://github.com/soywiz""><code>@​soywiz</code></a>.</li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12886:2777,access,access,2777,https://hail.is,https://github.com/hail-is/hail/pull/12886,1,['access'],['access']
Security,"</code></a> [Storage] Fix bug with <code>ignore_read_only</code> in <code>start_copy_from_url()</code> (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/23141"">#23141</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/5166ee94acdb80f2217a1ce694e169ea2b33219d""><code>5166ee9</code></a> [Storage] Fix <code>upload_blob()</code> from an OS pipe on Linux (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/23211"">#23211</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/Azure/azure-sdk-for-python/compare/azure-storage-blob_12.8.1...azure-storage-blob_12.11.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=azure-storage-blob&package-manager=pip&previous-version=12.8.1&new-version=12.11.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11703:6550,secur,security-vulnerabilities,6550,https://hail.is,https://github.com/hail-is/hail/pull/11703,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"</li>; <li><a href=""https://github.com/googleapis/java-storage/commit/45e66e89373ef016eff9b7deb30dbdfa818770d2""><code>45e66e8</code></a> deps: update actions/checkout action to v4 (<a href=""https://redirect.github.com/googleapis/java-storage/issues/2190"">#2190</a>)</li>; <li><a href=""https://github.com/googleapis/java-storage/commit/5c048c499eef224dade8f4409dfae732cb5a7017""><code>5c048c4</code></a> deps: update actions/checkout action to v4 (<a href=""https://redirect.github.com/googleapis/java-storage/issues/2189"">#2189</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/googleapis/java-storage/compare/v2.17.1...v2.27.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=com.google.cloud:google-cloud-storage&package-manager=gradle&previous-version=2.17.1&new-version=2.27.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13624:15492,secur,security-vulnerabilities,15492,https://hail.is,https://github.com/hail-is/hail/pull/13624,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"<a href=""https://github-redirect.dependabot.com/python-jsonschema/jsonschema/pull/983"">python-jsonschema/jsonschema#983</a></li>; </ul>; <p><strong>Full Changelog</strong>: <a href=""https://github.com/python-jsonschema/jsonschema/compare/v4.10.3...v4.11.0"">https://github.com/python-jsonschema/jsonschema/compare/v4.10.3...v4.11.0</a></p>; <h2>v4.10.3</h2>; <p><strong>Full Changelog</strong>: <a href=""https://github.com/python-jsonschema/jsonschema/compare/v4.10.2...v4.10.3"">https://github.com/python-jsonschema/jsonschema/compare/v4.10.2...v4.10.3</a></p>; <h2>v4.10.2</h2>; <ul>; <li>Fix a second place where subclasses may have added attrs attributes (<a href=""https://github-redirect.dependabot.com/python-jsonschema/jsonschema/issues/982"">#982</a>).</li>; </ul>; <p><strong>Full Changelog</strong>: <a href=""https://github.com/python-jsonschema/jsonschema/compare/v4.10.1...v4.10.2"">https://github.com/python-jsonschema/jsonschema/compare/v4.10.1...v4.10.2</a></p>; <h2>v4.10.1</h2>; <ul>; <li>Fix Validator.evolve (and APIs like <code>iter_errors</code> which call it) for cases; where the validator class has been subclassed. Doing so wasn't intended to be; public API, but given it didn't warn or raise an error it's of course; understandable. The next release however will make it warn (and a future one; will make it error). If you need help migrating usage of inheriting from a; validator class feel free to open a discussion and I'll try to give some; guidance (<a href=""https://github-redirect.dependabot.com/python-jsonschema/jsonschema/issues/982"">#982</a>).</li>; </ul>; <p><strong>Full Changelog</strong>: <a href=""https://github.com/python-jsonschema/jsonschema/compare/v4.10.0...v4.10.1"">https://github.com/python-jsonschema/jsonschema/compare/v4.10.0...v4.10.1</a></p>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/python-jsonschema/jsonschema/blob/main/C",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12163:3088,Validat,Validator,3088,https://hail.is,https://github.com/hail-is/hail/pull/12163,1,['Validat'],['Validator']
Security,"<a href=""https://github.com/AzureAD/microsoft-authentication-extensions-for-python/commit/6f77b1e70be086aae752dcf7e08d7f06bcabdcd7""><code>6f77b1e</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/AzureAD/microsoft-authentication-extensions-for-python/issues/109"">#109</a> from AzureAD/release-1.0.0</li>; <li><a href=""https://github.com/AzureAD/microsoft-authentication-extensions-for-python/commit/50bf9674f9c65229a1573be39ef4ef507eee17fa""><code>50bf967</code></a> MSAL EX for Python 1.0.0</li>; <li><a href=""https://github.com/AzureAD/microsoft-authentication-extensions-for-python/commit/6b904af1a3d4fc0e28e3f090fa3dd8492f79e6bf""><code>6b904af</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/AzureAD/microsoft-authentication-extensions-for-python/issues/110"">#110</a> from AzureAD/persistence-factory</li>; <li><a href=""https://github.com/AzureAD/microsoft-authentication-extensions-for-python/commit/d0696aeb6f65168b1e0d405cd871b80bb101cd76""><code>d0696ae</code></a> Add build_encrypted_persistence() factory</li>; <li><a href=""https://github.com/AzureAD/microsoft-authentication-extensions-for-python/commit/289a94f694645c642ae67b2d5972d3f9fdadb928""><code>289a94f</code></a> Remove old classes that are deprecated for 2 years</li>; <li><a href=""https://github.com/AzureAD/microsoft-authentication-extensions-for-python/commit/fa1f45b556341b2c34e9bf63c06a5068571cd337""><code>fa1f45b</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/AzureAD/microsoft-authentication-extensions-for-python/issues/108"">#108</a> from AzureAD/actionable-encryption-exceptions</li>; <li><a href=""https://github.com/AzureAD/microsoft-authentication-extensions-for-python/commit/effe77842d25a8b093d18d9e33347f13e2ee094f""><code>effe778</code></a> Provide actionable messages for 2 dpapi errors</li>; <li><a href=""https://github.com/AzureAD/microsoft-authentication-extensions-for-python/commit/b674b6a07ca27b2c1b6f371040f035a546cfd468"">",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11992:3131,authenticat,authentication-extensions-for-python,3131,https://hail.is,https://github.com/hail-is/hail/pull/11992,1,['authenticat'],['authentication-extensions-for-python']
Security,"<a href=""https://github.com/java-native-access/jna/commit/f58b0f8f6b5c013adfe44a2cfb018ccb6ef6a688""><code>f58b0f8</code></a> Improve test stability on AIX (exclude tests that are expected to fail)</li>; <li><a href=""https://github.com/java-native-access/jna/commit/c1565fb89469cbcba67b1cc305e16d520779b270""><code>c1565fb</code></a> Handle race condition in PdhUtil#PdhEnumObjectItems (<a href=""https://github-redirect.dependabot.com/java-native-access/jna/issues/1442"">#1442</a>)</li>; <li><a href=""https://github.com/java-native-access/jna/commit/99fcfa822db86b1f2ba5823dbf17efeb3d246ad5""><code>99fcfa8</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/java-native-access/jna/issues/1444"">#1444</a> from matthiasblaesing/update_libffi</li>; <li><a href=""https://github.com/java-native-access/jna/commit/9e473350a5ad5e04aab8b01e4018f973976e19f8""><code>9e47335</code></a> Update CHANGES.md</li>; <li>Additional commits viewable in <a href=""https://github.com/java-native-access/jna/compare/5.6.0...5.12.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=net.java.dev.jna:jna&package-manager=gradle&previous-version=5.6.0&new-version=5.12.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12438:7786,access,access,7786,https://hail.is,https://github.com/hail-is/hail/pull/12438,1,['access'],['access']
Security,"<code>fc3b525</code></a> Fix typos in docs</li>; <li><a href=""https://github.com/ipython/ipython/commit/75ecfe932fc9ca3505efbebc016b046ffc7d0d68""><code>75ecfe9</code></a> capture_output does not respect trailing semicolon (<a href=""https://redirect.github.com/ipython/ipython/issues/13940"">#13940</a>)</li>; <li><a href=""https://github.com/ipython/ipython/commit/3edbe3bd10c434af6458bdbe02269880b10b9adf""><code>3edbe3b</code></a> Resurrect fast (non-highlighted) traceback code for long files. (<a href=""https://redirect.github.com/ipython/ipython/issues/13947"">#13947</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/ipython/ipython/compare/7.34.0...8.11.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=ipython&package-manager=pip&previous-version=7.34.0&new-version=8.11.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12807:2394,secur,security-vulnerabilities,2394,https://hail.is,https://github.com/hail-is/hail/pull/12807,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"<li><a href=""https://github.com/googleapis/python-api-core/commit/d84d66c2a4107f5f9a20c53e870a27fb1250ea3d""><code>d84d66c</code></a> fix(deps): require protobuf&gt;= 3.15.0, &lt;4.0.0dev (<a href=""https://github-redirect.dependabot.com/googleapis/python-api-core/issues/385"">#385</a>)</li>; <li><a href=""https://github.com/googleapis/python-api-core/commit/eed844f211ad8c6ab2c4cb0d6f089e1f11999f71""><code>eed844f</code></a> chore(main): release 2.8.0 (<a href=""https://github-redirect.dependabot.com/googleapis/python-api-core/issues/381"">#381</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/googleapis/python-api-core/compare/v1.31.6...v2.8.2"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=google-api-core[grpc]&package-manager=pip&previous-version=1.31.6&new-version=2.8.2)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11970:11220,secur,security-vulnerabilities,11220,https://hail.is,https://github.com/hail-is/hail/pull/11970,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"<li><a href=""https://github.com/googleapis/python-logging/commit/e1506fa9030776353878048ce562c53bf6ccf7bf""><code>e1506fa</code></a> fix!: api consistency between HTTP and Gapic layers (<a href=""https://github-redirect.dependabot.com/googleapis/python-logging/issues/375"">#375</a>)</li>; <li><a href=""https://github.com/googleapis/python-logging/commit/6fa17735fe3edb45483ec5e3abd1f53c24ffa881""><code>6fa1773</code></a> feat!: support string-encoded json (<a href=""https://github-redirect.dependabot.com/googleapis/python-logging/issues/339"">#339</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/googleapis/python-logging/compare/v1.12.1...v3.0.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=google-cloud-logging&package-manager=pip&previous-version=1.12.1&new-version=3.0.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11574:14320,secur,security-vulnerabilities,14320,https://hail.is,https://github.com/hail-is/hail/pull/11574,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"<li><a href=""https://github.com/psf/requests/commit/87d63de8739263bbe17034fba2285c79780da7e8""><code>87d63de</code></a> v2.29.0</li>; <li><a href=""https://github.com/psf/requests/commit/51716c4ef390136b0d4b800ec7665dd5503e64fc""><code>51716c4</code></a> enable the warnings plugin (<a href=""https://redirect.github.com/psf/requests/issues/6416"">#6416</a>)</li>; <li><a href=""https://github.com/psf/requests/commit/a7da1ab3498b10ec3a3582244c94b2845f8a8e71""><code>a7da1ab</code></a> try on ubuntu 22.04 (<a href=""https://redirect.github.com/psf/requests/issues/6418"">#6418</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/psf/requests/compare/v2.28.2...v2.31.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=requests&package-manager=pip&previous-version=2.28.2&new-version=2.31.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13091:7546,secur,security-vulnerabilities,7546,https://hail.is,https://github.com/hail-is/hail/pull/13091,12,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"<li><a href=""https://github.com/tox-dev/sphinx-autodoc-typehints/commit/f9219b21ef8807150dbbcbaf45d6118387ff9a32""><code>f9219b2</code></a> [pre-commit.ci] pre-commit autoupdate (<a href=""https://github-redirect.dependabot.com/tox-dev/sphinx-autodoc-typehints/issues/222"">#222</a>)</li>; <li><a href=""https://github.com/tox-dev/sphinx-autodoc-typehints/commit/a9b90238f74f1c5f69d7dcafb83c9775504f9b3b""><code>a9b9023</code></a> Fix typos (<a href=""https://github-redirect.dependabot.com/tox-dev/sphinx-autodoc-typehints/issues/224"">#224</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/tox-dev/sphinx-autodoc-typehints/compare/1.11.1...1.18.3"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=sphinx-autodoc-typehints&package-manager=pip&previous-version=1.11.1&new-version=1.18.3)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11909:7564,secur,security-vulnerabilities,7564,https://hail.is,https://github.com/hail-is/hail/pull/11909,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"<li>When starting the development server, a warning not to use it in a; production deployment is always shown. :issue:<code>2480</code></li>; <li><code>LocalProxy.__wrapped__</code> is always set to the wrapped object when; the proxy is unbound, fixing an issue in doctest that would cause it; to fail. :issue:<code>2485</code></li>; <li>Address one <code>ResourceWarning</code> related to the socket used by; <code>run_simple</code>. :issue:<code>2421</code></li>; </ul>; <h2>Version 2.2.1</h2>; <p>Released 2022-07-27</p>; <ul>; <li>Fix router so that <code>/path/</code> will match a rule <code>/path</code> if strict; slashes mode is disabled for the rule. :issue:<code>2467</code></li>; <li>Fix router so that partial part matches are not allowed; i.e. <code>/2df</code> does not match <code>/&lt;int&gt;</code>. :pr:<code>2470</code></li>; <li>Fix router static part weighting, so that simpler routes are matched; before more complex ones. :issue:<code>2471</code></li>; <li>Restore <code>ValidationError</code> to be importable from; <code>werkzeug.routing</code>. :issue:<code>2465</code></li>; </ul>; <h2>Version 2.2.0</h2>; <p>Released 2022-07-23</p>; <ul>; <li>Deprecated <code>get_script_name</code>, <code>get_query_string</code>,; <code>peek_path_info</code>, <code>pop_path_info</code>, and; <code>extract_path_info</code>. :pr:<code>2461</code></li>; <li>Remove previously deprecated code. :pr:<code>2461</code></li>; <li>Add MarkupSafe as a dependency and use it to escape values when; rendering HTML. :issue:<code>2419</code></li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/pallets/werkzeug/commit/15fcb87d36f4ed45b127692d2d739266b918503c""><code>15fcb87</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pallets/werkzeug/issues/2499"">#2499</a> from pallets/release-2.2.2</li>; <li><a href=""https://github.com/pallets/werkzeug/commit/87",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12119:3833,Validat,ValidationError,3833,https://hail.is,https://github.com/hail-is/hail/pull/12119,1,['Validat'],['ValidationError']
Security,"<p>This PR was automatically created by Snyk using the credentials of a real user.</p><br /><h3>Snyk has created this PR to fix one or more vulnerable packages in the `pip` dependencies of this project.</h3>. #### Changes included in this PR. - Changes to the following files to upgrade the vulnerable dependencies to a fixed version:; - auth/pinned-requirements.txt. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **471/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 3.7 | Improper Following of a Certificate&#x27;s Chain of Trust <br/>[SNYK-PYTHON-CERTIFI-5805047](https://snyk.io/vuln/SNYK-PYTHON-CERTIFI-5805047) | `certifi:` <br> `2023.5.7 -> 2023.7.22` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJjMDQ5NzlhMC1iYWM3LTRiMjEtYmE0ZS02OWU5YjAzMTE5ZjAiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImMwNDk3OWEwLWJhYzctNGIyMS1iYTRlLTY5ZTliMDMxMTlmMCJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13309:893,Certificate,Certificate,893,https://hail.is,https://github.com/hail-is/hail/pull/13309,1,['Certificate'],['Certificate']
Security,"<p>This PR was automatically created by Snyk using the credentials of a real user.</p><br /><h3>Snyk has created this PR to fix one or more vulnerable packages in the `pip` dependencies of this project.</h3>. #### Changes included in this PR. - Changes to the following files to upgrade the vulnerable dependencies to a fixed version:; - ci/pinned-requirements.txt. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **471/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 3.7 | Improper Following of a Certificate&#x27;s Chain of Trust <br/>[SNYK-PYTHON-CERTIFI-5805047](https://snyk.io/vuln/SNYK-PYTHON-CERTIFI-5805047) | `certifi:` <br> `2023.5.7 -> 2023.7.22` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI3Mzc3ZjFlZS1kMjJjLTQ0MDAtYmE1Yy04NGNkYWZmZWJmYzgiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjczNzdmMWVlLWQyMmMtNDQwMC1iYTVjLTg0Y2RhZmZlYmZjOCJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest proj",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13305:891,Certificate,Certificate,891,https://hail.is,https://github.com/hail-is/hail/pull/13305,1,['Certificate'],['Certificate']
Security,"<p>This PR was automatically created by Snyk using the credentials of a real user.</p><br /><h3>Snyk has created this PR to fix one or more vulnerable packages in the `pip` dependencies of this project.</h3>. #### Changes included in this PR. - Changes to the following files to upgrade the vulnerable dependencies to a fixed version:; - gear/pinned-requirements.txt. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **471/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 3.7 | Improper Following of a Certificate&#x27;s Chain of Trust <br/>[SNYK-PYTHON-CERTIFI-5805047](https://snyk.io/vuln/SNYK-PYTHON-CERTIFI-5805047) | `certifi:` <br> `2023.5.7 -> 2023.7.22` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJmYWJiOGYzZi1mMDFjLTQxMjktODJjNC1kZjQzMjRmZTU4YTIiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImZhYmI4ZjNmLWYwMWMtNDEyOS04MmM0LWRmNDMyNGZlNThhMiJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13296:893,Certificate,Certificate,893,https://hail.is,https://github.com/hail-is/hail/pull/13296,1,['Certificate'],['Certificate']
Security,"<p>This PR was automatically created by Snyk using the credentials of a real user.</p><br /><h3>Snyk has created this PR to fix one or more vulnerable packages in the `pip` dependencies of this project.</h3>. #### Changes included in this PR. - Changes to the following files to upgrade the vulnerable dependencies to a fixed version:; - hail/python/dev/pinned-requirements.txt. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **471/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 3.7 | Improper Following of a Certificate&#x27;s Chain of Trust <br/>[SNYK-PYTHON-CERTIFI-5805047](https://snyk.io/vuln/SNYK-PYTHON-CERTIFI-5805047) | `certifi:` <br> `2023.5.7 -> 2023.7.22` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJlMjNiYjk0OC04YjdmLTQ5MzUtYTRkMi05ZWJmNjg4NjZlMmUiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImUyM2JiOTQ4LThiN2YtNDkzNS1hNGQyLTllYmY2ODg2NmUyZSJ9fQ=="" width=""0"" height=""0""/>; 🧐 [Vie",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13316:904,Certificate,Certificate,904,https://hail.is,https://github.com/hail-is/hail/pull/13316,1,['Certificate'],['Certificate']
Security,"<p>This PR was automatically created by Snyk using the credentials of a real user.</p><br /><h3>Snyk has created this PR to fix one or more vulnerable packages in the `pip` dependencies of this project.</h3>. #### Changes included in this PR. - Changes to the following files to upgrade the vulnerable dependencies to a fixed version:; - hail/python/dev/pinned-requirements.txt. <details>; <summary>⚠️ <b>Warning</b></summary>. ```; jupyter 1.0.0 requires notebook, which is not installed. ```; </details>. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | Access Control Bypass <br/>[SNYK-PYTHON-JUPYTERSERVER-5862881](https://snyk.io/vuln/SNYK-PYTHON-JUPYTERSERVER-5862881) | `jupyter-server:` <br> `1.24.0 -> 2.7.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | Open Redirect <br/>[SNYK-PYTHON-JUPYTERSERVER-5862882](https://snyk.io/vuln/SNYK-PYTHON-JUPYTERSERVER-5862882) | `jupyter-server:` <br> `1.24.0 -> 2.7.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | Regular Expression Denial of Service (ReDoS) <br/>[SNYK-PYTHON-SETUPTOOLS-3180412](https://snyk.io/vuln/SNYK-PYTHON-SETUPTOOLS-3180412) | `setuptools:` <br> `39.0.1 -> 65.5.1` <br> | No | No Known Exploit . Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ens",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13517:887,Access,Access,887,https://hail.is,https://github.com/hail-is/hail/pull/13517,1,['Access'],['Access']
Security,"<p>This PR was automatically created by Snyk using the credentials of a real user.</p><br /><h3>Snyk has created this PR to fix one or more vulnerable packages in the `pip` dependencies of this project.</h3>. #### Changes included in this PR. - Changes to the following files to upgrade the vulnerable dependencies to a fixed version:; - hail/python/hailtop/pinned-requirements.txt. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **471/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 3.7 | Improper Following of a Certificate&#x27;s Chain of Trust <br/>[SNYK-PYTHON-CERTIFI-5805047](https://snyk.io/vuln/SNYK-PYTHON-CERTIFI-5805047) | `certifi:` <br> `2023.5.7 -> 2023.7.22` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI1NDMwZTFmMi0wNDZjLTQwNDctYmI3Mi1hZmJkZmM1MDViNGEiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjU0MzBlMWYyLTA0NmMtNDA0Ny1iYjcyLWFmYmRmYzUwNWI0YSJ9fQ=="" width=""0"" height=""0""/>; 🧐 ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13304:908,Certificate,Certificate,908,https://hail.is,https://github.com/hail-is/hail/pull/13304,1,['Certificate'],['Certificate']
Security,"<p>This PR was automatically created by Snyk using the credentials of a real user.</p><br /><h3>Snyk has created this PR to fix one or more vulnerable packages in the `pip` dependencies of this project.</h3>. #### Changes included in this PR. - Changes to the following files to upgrade the vulnerable dependencies to a fixed version:; - hail/python/hailtop/requirements.txt. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **663/1000** <br/> **Why?** Proof of Concept exploit, Recently disclosed, Has a fix available, CVSS 5.4 | Improper Input Validation <br/>[SNYK-PYTHON-AIOHTTP-6091621](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-6091621) | `aiohttp:` <br> `3.8.6 -> 3.9.0` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **663/1000** <br/> **Why?** Proof of Concept exploit, Recently disclosed, Has a fix available, CVSS 5.4 | Improper Input Validation <br/>[SNYK-PYTHON-AIOHTTP-6091622](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-6091622) | `aiohttp:` <br> `3.8.6 -> 3.9.0` <br> | No | Proof of Concept . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14045:924,Validat,Validation,924,https://hail.is,https://github.com/hail-is/hail/pull/14045,1,['Validat'],['Validation']
Security,"<p>This PR was automatically created by Snyk using the credentials of a real user.</p><br /><h3>Snyk has created this PR to fix one or more vulnerable packages in the `pip` dependencies of this project.</h3>. #### Changes included in this PR. - Changes to the following files to upgrade the vulnerable dependencies to a fixed version:; - hail/python/pinned-requirements.txt. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | **763/1000** <br/> **Why?** Proof of Concept exploit, Recently disclosed, Has a fix available, CVSS 7.4 | Improper Certificate Validation <br/>[SNYK-PYTHON-CRYPTOGRAPHY-5777683](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5777683) | `cryptography:` <br> `41.0.1 -> 41.0.2` <br> | No | Proof of Concept . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiIwMjJhZDMzNS1kYzBkLTQxZWYtYmRjYi03ZTFkODQwNWJhYTYiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjAyMmFkMzM1LWRjMGQtNDFlZi1iZGNiLTdlMWQ4NDA1YmFhNiJ9fQ=="" width=""0"" height=""0""/>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13247:913,Certificate,Certificate,913,https://hail.is,https://github.com/hail-is/hail/pull/13247,2,"['Certificate', 'Validat']","['Certificate', 'Validation']"
Security,"<p>This PR was automatically created by Snyk using the credentials of a real user.</p><br /><h3>Snyk has created this PR to fix one or more vulnerable packages in the `pip` dependencies of this project.</h3>. #### Changes included in this PR. - Changes to the following files to upgrade the vulnerable dependencies to a fixed version:; - hail/python/pinned-requirements.txt. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **471/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 3.7 | Improper Following of a Certificate&#x27;s Chain of Trust <br/>[SNYK-PYTHON-CERTIFI-5805047](https://snyk.io/vuln/SNYK-PYTHON-CERTIFI-5805047) | `certifi:` <br> `2023.5.7 -> 2023.7.22` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJkY2E2ZDI1ZC1hZGM3LTRiNTctYWU3Zi0yNjExOTYzNTY5MmUiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImRjYTZkMjVkLWFkYzctNGI1Ny1hZTdmLTI2MTE5NjM1NjkyZSJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View la",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13294:900,Certificate,Certificate,900,https://hail.is,https://github.com/hail-is/hail/pull/13294,1,['Certificate'],['Certificate']
Security,"<p>This PR was automatically created by Snyk using the credentials of a real user.</p><br /><h3>Snyk has created this PR to fix one or more vulnerable packages in the `pip` dependencies of this project.</h3>. #### Changes included in this PR. - Changes to the following files to upgrade the vulnerable dependencies to a fixed version:; - web_common/pinned-requirements.txt. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **663/1000** <br/> **Why?** Proof of Concept exploit, Recently disclosed, Has a fix available, CVSS 5.4 | Improper Input Validation <br/>[SNYK-PYTHON-AIOHTTP-6091621](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-6091621) | `aiohttp:` <br> `3.8.6 -> 3.9.0` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **663/1000** <br/> **Why?** Proof of Concept exploit, Recently disclosed, Has a fix available, CVSS 5.4 | Improper Input Validation <br/>[SNYK-PYTHON-AIOHTTP-6091622](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-6091622) | `aiohttp:` <br> `3.8.6 -> 3.9.0` <br> | No | Proof of Concept . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository h",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14036:922,Validat,Validation,922,https://hail.is,https://github.com/hail-is/hail/pull/14036,1,['Validat'],['Validation']
Security,"<strong>getitem</strong></li>; <li><a href=""https://github.com/grantjenks/python-sortedcontainers/commit/6ee5d57fc8d691fbab4972b853a60348d0f922ef""><code>6ee5d57</code></a> improve SortedList.<strong>getitem</strong>() performance for small slices</li>; <li><a href=""https://github.com/grantjenks/python-sortedcontainers/commit/ac80254fb6a08045ced7d9704412878ff8000fa7""><code>ac80254</code></a> suppress warning in test of deprecated function (<a href=""https://github-redirect.dependabot.com/grantjenks/python-sortedcontainers/issues/118"">#118</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/grantjenks/python-sortedcontainers/compare/v2.1.0...v2.4.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=sortedcontainers&package-manager=pip&previous-version=2.1.0&new-version=2.4.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11476:4012,secur,security-vulnerabilities,4012,https://hail.is,https://github.com/hail-is/hail/pull/11476,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"<ul>; <li><a href=""https://github-redirect.dependabot.com/java-native-access/jna/pull/1438"">#1438</a>: Handle arrays in structures with differing size - <a href=""https://github.com/matthiasblaesing""><code>@​matthiasblaesing</code></a>.</li>; <li><a href=""https://github-redirect.dependabot.com/java-native-access/jna/issues/1442"">#1442</a>: Handle race condition in <code>c.s.j.p.win32.PdhUtil#PdhEnumObjectItems</code> - <a href=""https://github.com/dbwiddis""><code>@​dbwiddis</code></a>.</li>; </ul>; <h2>Important Changes</h2>; <ul>; <li><code>Memory#dispose</code>, <code>CallbackReference#dispose</code> and <code>NativeLibrary#dispose</code>; were called by the <code>Object#finalize</code> override. These calls were replaced by; the use of a cleaner. It is not guaranteed anymore, that <code>dispose</code> is called; on subclasses on finalization.</li>; </ul>; <h1>Release 5.11.0</h1>; <h2>Features</h2>; <ul>; <li><a href=""https://github-redirect.dependabot.com/java-native-access/jna/pull/1398"">#1398</a>: Increase <code>c.s.j.p.win32.Sspi#MAX_TOKEN_SIZE</code> on Windows 8/Server 2012 and later - <a href=""https://github.com/dbwiddis""><code>@​dbwiddis</code></a>.</li>; <li><a href=""https://github-redirect.dependabot.com/java-native-access/jna/pull/1403"">#1403</a>: Rebuild AIX binaries with libffi 3.4.2 (other architectures were part of 5.10) - <a href=""https://github.com/matthiasblaesing""><code>@​matthiasblaesing</code></a>.</li>; <li><a href=""https://github-redirect.dependabot.com/java-native-access/jna/issues/1404"">#1404</a>: Added Solaris Kstat2 library - <a href=""https://github.com/dbwiddis""><code>@​dbwiddis</code></a>.</li>; <li><a href=""https://github-redirect.dependabot.com/java-native-access/jna/pull/1416"">#1416</a>: Add <code>CFDictionaryGetCount</code> to <code>c.s.j.p.mac.CoreFoundation</code> - <a href=""https://github.com/shalupov""><code>@​shalupov</code></a></li>; <li><a href=""https://github-redirect.dependabot.com/java-native-access/jna/pull/1418"">#1418</a>:",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12438:2759,access,access,2759,https://hail.is,https://github.com/hail-is/hail/pull/12438,1,['access'],['access']
Security,"=""https://github-redirect.dependabot.com/docker/docker-py/pull/3056"">docker/docker-py#3056</a></li>; </ul>; <p><strong>Full Changelog</strong>: <a href=""https://github.com/docker/docker-py/compare/6.0.0...6.0.1"">https://github.com/docker/docker-py/compare/6.0.0...6.0.1</a></p>; <h2>6.0.0</h2>; <h3>ℹ️ Upgrade Notes</h3>; <ul>; <li>Minimum supported Python version is 3.7+</li>; <li>When installing with pip, the <code>docker[tls]</code> extra is deprecated and a no-op,; use <code>docker</code> for same functionality (TLS support is always available now)</li>; <li>Native Python SSH client (used by default / <code>use_ssh_client=False</code>) will now; reject unknown host keys with <code>paramiko.ssh_exception.SSHException</code></li>; <li>Short IDs are now 12 characters instead of 10 characters (same as Docker CLI)</li>; <li>Version metadata is now exposed as <code>__version__</code></li>; </ul>; <h3>✨ Features</h3>; <ul>; <li>Python 3.10 support</li>; <li>Automatically negotiate most secure TLS version</li>; <li>Add <code>platform</code> (e.g. <code>linux/amd64</code>, <code>darwin/arm64</code>) to container create &amp; run</li>; <li>Add support for <code>GlobalJob</code> and <code>ReplicatedJobs</code> for Swarm</li>; <li>Add <code>remove()</code> method on <code>Image</code></li>; <li>Add <code>force</code> param to <code>disable()</code> on <code>Plugin</code></li>; </ul>; <h3>🐛 Bugfixes</h3>; <ul>; <li>Fix install issues on Windows related to <code>pywin32</code></li>; <li>Do not accept unknown SSH host keys in native Python SSH mode</li>; <li>Use 12 character short IDs for consistency with Docker CLI</li>; <li>Ignore trailing whitespace in <code>.dockerignore</code> files</li>; <li>Fix IPv6 host parsing when explicit port specified</li>; <li>Fix <code>ProxyCommand</code> option for SSH connections</li>; <li>Do not spawn extra subshell when launching external SSH client</li>; <li>Improve exception semantics to preserve context</li>; <li>Documentation improvements ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12475:3174,secur,secure,3174,https://hail.is,https://github.com/hail-is/hail/pull/12475,1,['secur'],['secure']
Security,"=""https://github.com/Azure/azure-sdk-for-python/commit/9791fb5bc4cb6001768e6e1fb986b8d8f8326c43""><code>9791fb5</code></a> [core] add error body to HttpResponseError str (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/22302"">#22302</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/772054c9cf24e860cf08563ac33caab50e904dd5""><code>772054c</code></a> drop py27 support (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/22531"">#22531</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/Azure/azure-sdk-for-python/compare/azure-identity_1.6.0...azure-identity_1.8.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=azure-identity&package-manager=pip&previous-version=1.6.0&new-version=1.8.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11493:5138,secur,security-vulnerabilities,5138,https://hail.is,https://github.com/hail-is/hail/pull/11493,4,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"=""https://github.com/googleapis/google-auth-library-python/commit/5a09454703bd004d23355a6f660ec8579597d981""><code>5a09454</code></a> chore(main): release 2.4.1 (<a href=""https://github-redirect.dependabot.com/googleapis/google-auth-library-python/issues/955"">#955</a>)</li>; <li><a href=""https://github.com/googleapis/google-auth-library-python/commit/c8b5cae3da5eb9d40067d38dac51a4a8c1e0763e""><code>c8b5cae</code></a> fix: urllib3 import (<a href=""https://github-redirect.dependabot.com/googleapis/google-auth-library-python/issues/953"">#953</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/googleapis/google-auth-library-python/compare/v1.27.0...v2.6.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=google-auth&package-manager=pip&previous-version=1.27.0&new-version=2.6.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11546:12695,secur,security-vulnerabilities,12695,https://hail.is,https://github.com/hail-is/hail/pull/11546,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"> Add more basic CLI tests</li>; <li><a href=""https://github.com/thibaudcolas/curlylint/commit/08bdb0ce9e044e008eb487f32162865740c25232""><code>08bdb0c</code></a> Switch to official GitHub Actions coveralls integration</li>; <li><a href=""https://github.com/thibaudcolas/curlylint/commit/3a92cc4b4e6f5951bea72234f57b32bef133ab75""><code>3a92cc4</code></a> Tentatively declare support for Python 3.10</li>; <li><a href=""https://github.com/thibaudcolas/curlylint/commit/145983f7a3764743a653ef61595dd3ea33f24620""><code>145983f</code></a> Declare support for Python 3.9</li>; <li>Additional commits viewable in <a href=""https://github.com/thibaudcolas/curlylint/compare/v0.12.0...v0.13.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=curlylint&package-manager=pip&previous-version=0.12.0&new-version=0.13.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11494:7450,secur,security-vulnerabilities,7450,https://hail.is,https://github.com/hail-is/hail/pull/11494,4,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"> DOC: Update what's new for 8.10</li>; <li><a href=""https://github.com/ipython/ipython/commit/385d69325319a5972ee9b5983638e3617f21cb1f""><code>385d693</code></a> Merge pull request from GHSA-29gw-9793-fvw7</li>; <li><a href=""https://github.com/ipython/ipython/commit/e548ee23ac460a99901f1cd43b94ae84a35ec393""><code>e548ee2</code></a> Swallow potential exceptions from showtraceback() (<a href=""https://github-redirect.dependabot.com/ipython/ipython/issues/13934"">#13934</a>)</li>; <li><a href=""https://github.com/ipython/ipython/commit/0694b08b436203817059ec7e7136cf8561a6f013""><code>0694b08</code></a> MAINT: mock slowest test. (<a href=""https://github-redirect.dependabot.com/ipython/ipython/issues/13885"">#13885</a>)</li>; <li><a href=""https://github.com/ipython/ipython/commit/865591252a67c6907fe03228b4053305715286e6""><code>8655912</code></a> MAINT: mock slowest test.</li>; <li><a href=""https://github.com/ipython/ipython/commit/a011765b44febfb11bae122d2ed7db763621ac8f""><code>a011765</code></a> Isolate the attack tests with setUp and tearDown methods</li>; <li><a href=""https://github.com/ipython/ipython/commit/c7a9470e540392c575aac46c3ee5cf4fe5123eb1""><code>c7a9470</code></a> Add some regression tests for this change</li>; <li><a href=""https://github.com/ipython/ipython/commit/fd34cf5f1f6e243243c738c6e0cf62eb682c4d68""><code>fd34cf5</code></a> Swallow potential exceptions from showtraceback()</li>; <li>Additional commits viewable in <a href=""https://github.com/ipython/ipython/compare/7.34.0...8.10.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=ipython&package-manager=pip&previous-version=7.34.0&new-version=8.10.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12683:1649,attack,attack,1649,https://hail.is,https://github.com/hail-is/hail/pull/12683,1,['attack'],['attack']
Security,"> Merge pull request <a href=""https://redirect.github.com/michel-kraemer/gradle-download-task/issues/295"">#295</a> from michel-kraemer/dependabot/npm_and_yarn/screencas...</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/c1e212c0fb41b3ea9185a9ea463fb1ea7142f748""><code>c1e212c</code></a> Add integration tests for Gradle 8.0 and 8.0.1</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/304f68e25f53633a92a4d2d6ce003a4986929503""><code>304f68e</code></a> Fix type inference issue</li>; <li>Additional commits viewable in <a href=""https://github.com/michel-kraemer/gradle-download-task/compare/5.3.1...5.4.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=de.undercouch.download&package-manager=gradle&previous-version=5.3.1&new-version=5.4.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12893:3046,secur,security-vulnerabilities,3046,https://hail.is,https://github.com/hail-is/hail/pull/12893,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,">#1123</a>)</li>; <li>Add support for Docutils 0.17 (<a href=""https://github-redirect.dependabot.com/readthedocs/sphinx_rtd_theme/issues/1185"">#1185</a> and <a href=""https://github-redirect.dependabot.com/readthedocs/sphinx_rtd_theme/issues/1199"">#1199</a>)</li>; <li>Fixed logo scaling on IE11 (<a href=""https://github-redirect.dependabot.com/readthedocs/sphinx_rtd_theme/issues/1183"">#1183</a>)</li>; <li>Added support for logos as URLs (<a href=""https://github-redirect.dependabot.com/readthedocs/sphinx_rtd_theme/issues/1171"">#1171</a>)</li>; <li>Align top and side navigation background colors on mobile (<a href=""https://github-redirect.dependabot.com/readthedocs/sphinx_rtd_theme/issues/1132"">#1132</a>)</li>; <li>Added support for deep toc levels (<a href=""https://github-redirect.dependabot.com/readthedocs/sphinx_rtd_theme/issues/1089"">#1089</a>)</li>; <li>Updated translations for Chinese, Dutch, Estonian, French, German, Italian,; Lithuanian, Persian, Polish, Portuguese, Russian, Spanish, Swedish, and; Turkish locales</li>; </ul>; <p>A number of accessibility features were added in this release:</p>; <ul>; <li>Allow keyboard to toggle menu expansion (<a href=""https://github-redirect.dependabot.com/readthedocs/sphinx_rtd_theme/issues/1167"">#1167</a>)</li>; <li>Allow keyboard to activate permalink (<a href=""https://github-redirect.dependabot.com/readthedocs/sphinx_rtd_theme/issues/1162"">#1162</a>)</li>; <li>Show keyboard focus on buttons (<a href=""https://github-redirect.dependabot.com/readthedocs/sphinx_rtd_theme/issues/1161"">#1161</a>)</li>; <li>Maintain aria-expanded along with .current in menu (<a href=""https://github-redirect.dependabot.com/readthedocs/sphinx_rtd_theme/issues/1151"">#1151</a>)</li>; <li>Respect tab order for prev/next buttons (<a href=""https://github-redirect.dependabot.com/readthedocs/sphinx_rtd_theme/issues/1051"">#1051</a>)</li>; </ul>; <h2>Fixes</h2>; <ul>; <li>Updated Google analytics integration (<a href=""https://github-redirect.dependabot.com/",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11464:2139,access,accessibility,2139,https://hail.is,https://github.com/hail-is/hail/pull/11464,2,['access'],['accessibility']
Security,">#8028</a>) (<a href=""https://github.com/vitejs/vite/tree/HEAD/packages/vite/issues/8035"">#8035</a>) (<a href=""https://github.com/vitejs/vite/commit/992aee2"">992aee2</a>), closes <a href=""https://github-redirect.dependabot.com/vitejs/vite/issues/8028"">#8028</a> <a href=""https://github-redirect.dependabot.com/vitejs/vite/issues/8035"">#8035</a></li>; <li>fix: invalidate ssrError when HMR update occurs (<a href=""https://github.com/vitejs/vite/tree/HEAD/packages/vite/issues/8052"">#8052</a>) (<a href=""https://github.com/vitejs/vite/commit/22fa882"">22fa882</a>), closes <a href=""https://github-redirect.dependabot.com/vitejs/vite/issues/8052"">#8052</a></li>; <li>fix: use <code>strip-literal</code> to strip string lterals (<a href=""https://github.com/vitejs/vite/tree/HEAD/packages/vite/issues/8054"">#8054</a>) (<a href=""https://github.com/vitejs/vite/commit/b6fc3cd"">b6fc3cd</a>), closes <a href=""https://github-redirect.dependabot.com/vitejs/vite/issues/8054"">#8054</a></li>; <li>perf(lib): reduce backtrack when injecting esbuild helpers (<a href=""https://github.com/vitejs/vite/tree/HEAD/packages/vite/issues/8110"">#8110</a>) (<a href=""https://github.com/vitejs/vite/commit/e5556ab"">e5556ab</a>), closes <a href=""https://github-redirect.dependabot.com/vitejs/vite/issues/8110"">#8110</a></li>; </ul>; <h2><!-- raw HTML omitted -->2.9.8 (2022-05-04)<!-- raw HTML omitted --></h2>; <ul>; <li>fix: inline js and css paths for virtual html (<a href=""https://github.com/vitejs/vite/tree/HEAD/packages/vite/issues/7993"">#7993</a>) (<a href=""https://github.com/vitejs/vite/commit/d49e3fb"">d49e3fb</a>), closes <a href=""https://github-redirect.dependabot.com/vitejs/vite/issues/7993"">#7993</a></li>; <li>fix: only handle merge ssr.noExternal (<a href=""https://github.com/vitejs/vite/tree/HEAD/packages/vite/issues/8003"">#8003</a>) (<a href=""https://github.com/vitejs/vite/commit/642d65b"">642d65b</a>), closes <a href=""https://github-redirect.dependabot.com/vitejs/vite/issues/8003"">#8003</a></li>; <li>fix",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12142:8153,inject,injecting,8153,https://hail.is,https://github.com/hail-is/hail/pull/12142,2,['inject'],['injecting']
Security,">, <a href=""https://github.com/sarveshr7""><code>@​sarveshr7</code></a>)</li>; <li>Introduction of a new &quot;sync_proxy_rules_no_local_endpoints_total&quot; proxy metric. This metric represents the number of services with no internal endpoints. The &quot;traffic_policy&quot; label will contain both &quot;internal&quot; or &quot;external&quot;. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/108930"">kubernetes/kubernetes#108930</a>, <a href=""https://github.com/MaxRenaud""><code>@​MaxRenaud</code></a>)</li>; <li>JobReadyPods graduates to Beta and it's enabled by default. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/107476"">kubernetes/kubernetes#107476</a>, <a href=""https://github.com/alculquicondor""><code>@​alculquicondor</code></a>)</li>; <li>Kube-apiserver: <code>--audit-log-version</code> and <code>--audit-webhook-version</code> now only support the default value of <code>audit.k8s.io/v1</code>. The v1alpha1 and v1beta1 audit log versions, deprecated since 1.13, have been removed. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/108092"">kubernetes/kubernetes#108092</a>, <a href=""https://github.com/carlory""><code>@​carlory</code></a>)</li>; <li>Kube-apiserver: the <code>metadata.selfLink</code> field can no longer be populated by kube-apiserver; it was deprecated in 1.16 and has not been populated by default since 1.20+. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/107527"">kubernetes/kubernetes#107527</a>, <a href=""https://github.com/wojtek-t""><code>@​wojtek-t</code></a>)</li>; <li>Kubelet external Credential Provider feature is moved to Beta. Credential Provider Plugin and Credential Provider Config API's updated from v1alpha1 to v1beta1 with no API changes. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/108847"">kubernetes/kubernetes#108847</a>, <a href=""https://github.com/adisky""><code>@​adisky</code></a>)</li>; <li>Make ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12196:8468,audit,audit,8468,https://hail.is,https://github.com/hail-is/hail/pull/12196,1,['audit'],['audit']
Security,">. ```; jupyter 1.0.0 requires notebook, which is not installed.; beautifulsoup4 4.12.2 requires soupsieve, which is not installed. ```; </details>. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **531/1000** <br/> **Why?** Proof of Concept exploit, Has a fix available, CVSS 4.2 | Remote Code Execution (RCE) <br/>[SNYK-PYTHON-IPYTHON-3318382](https://snyk.io/vuln/SNYK-PYTHON-IPYTHON-3318382) | `ipython:` <br> `7.34.0 -> 8.10.0` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **/1000** <br/> **Why?** | Access Control Bypass <br/>[SNYK-PYTHON-JUPYTERSERVER-5862881](https://snyk.io/vuln/SNYK-PYTHON-JUPYTERSERVER-5862881) | `jupyter-server:` <br> `1.24.0 -> 2.7.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **/1000** <br/> **Why?** | Open Redirect <br/>[SNYK-PYTHON-JUPYTERSERVER-5862882](https://snyk.io/vuln/SNYK-PYTHON-JUPYTERSERVER-5862882) | `jupyter-server:` <br> `1.24.0 -> 2.7.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **509/1000** <br/> **Why?** Has a fix available, CVSS 5.9 | Regular Expression Denial of Service (ReDoS) <br/>[SNYK-PYTHON-SETUPTOOLS-3180412](https://snyk.io/vuln/SNYK-PYTHON-SETUPTOOLS-3180412) | `setuptools:` <br> `39.0.1 -> 65.5.1` <br> | No | No Known Exploit ; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low sever",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13718:1413,Access,Access,1413,https://hail.is,https://github.com/hail-is/hail/pull/13718,1,['Access'],['Access']
Security,">; </ul>; <h1>Release 5.10.0</h1>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/java-native-access/jna/commit/3705b849892aa3c37e5608e640eff19047811a5c""><code>3705b84</code></a> Release 5.12.1</li>; <li><a href=""https://github.com/java-native-access/jna/commit/2f919e56bad203494fe9589206d6d23f27ef4f26""><code>2f919e5</code></a> Null-check cleanable in Memory#close (<a href=""https://github-redirect.dependabot.com/java-native-access/jna/issues/1447"">#1447</a>)</li>; <li><a href=""https://github.com/java-native-access/jna/commit/1eec7dd76830af97ed64ecb2d8d39a56db104dcd""><code>1eec7dd</code></a> Prepare next development iteration</li>; <li><a href=""https://github.com/java-native-access/jna/commit/0d7499f105e4495bdea15fc21f5b1046e81ca822""><code>0d7499f</code></a> Release 5.12.0</li>; <li><a href=""https://github.com/java-native-access/jna/commit/fa86166d4f75ef4478de7ad9d7d6c0b6b6933ee0""><code>fa86166</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/java-native-access/jna/issues/1445"">#1445</a> from matthiasblaesing/aix</li>; <li><a href=""https://github.com/java-native-access/jna/commit/4cca4405f7f6bc32d2a08495efb81c081b065279""><code>4cca440</code></a> Fix name mapping difference between AIX JDK 8 and Semeru JDK 18</li>; <li><a href=""https://github.com/java-native-access/jna/commit/f58b0f8f6b5c013adfe44a2cfb018ccb6ef6a688""><code>f58b0f8</code></a> Improve test stability on AIX (exclude tests that are expected to fail)</li>; <li><a href=""https://github.com/java-native-access/jna/commit/c1565fb89469cbcba67b1cc305e16d520779b270""><code>c1565fb</code></a> Handle race condition in PdhUtil#PdhEnumObjectItems (<a href=""https://github-redirect.dependabot.com/java-native-access/jna/issues/1442"">#1442</a>)</li>; <li><a href=""https://github.com/java-native-access/jna/commit/99fcfa822db86b1f2ba5823dbf17efeb3d246ad5""><code>99fcfa8</code></a> Merge pull re",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12438:6355,access,access,6355,https://hail.is,https://github.com/hail-is/hail/pull/12438,1,['access'],['access']
Security,">; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/09d1eca91afbf21ace3672be24c68d9028ee1e33""><code>09d1eca</code></a> Document runAsync method</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/800e3df1647c5ce65bffdd25c3240dfa5244e6c5""><code>800e3df</code></a> Add runAsync method to download extension</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/80f04c6a46fe7df053ac55bcfc6f90ff74c4b873""><code>80f04c6</code></a> Bump up version number to 5.1.3</li>; <li>Additional commits viewable in <a href=""https://github.com/michel-kraemer/gradle-download-task/compare/3.2.0...5.2.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=de.undercouch.download&package-manager=gradle&previous-version=3.2.0&new-version=5.2.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12332:5188,secur,security-vulnerabilities,5188,https://hail.is,https://github.com/hail-is/hail/pull/12332,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,">; <li><a href=""https://github.com/pygments/pygments/commit/96a0cdf200ab8a36dc5f6f748f3b9d01c05cb91b""><code>96a0cdf</code></a> PythonTracebackLexer: minor tweak in docstring</li>; <li><a href=""https://github.com/pygments/pygments/commit/569eea6ee85ec4d679bb38a890c167b58ee727dd""><code>569eea6</code></a> Enable Sphinx nitpicky mode and fix warnings (<a href=""https://redirect.github.com/pygments/pygments/issues/2403"">#2403</a>)</li>; <li><a href=""https://github.com/pygments/pygments/commit/b018a65cb6ef51596c2cb8d6c97f0d79d9fa2ae7""><code>b018a65</code></a> Prepare for next release.</li>; <li>See full diff in <a href=""https://github.com/pygments/pygments/compare/2.15.0...2.15.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pygments&package-manager=pip&previous-version=2.15.0&new-version=2.15.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12909:3826,secur,security-vulnerabilities,3826,https://hail.is,https://github.com/hail-is/hail/pull/12909,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,">; <li><code>FormatChecker.cls_checks</code> is deprecated. Use <code>FormatChecker.checks</code> on; an instance of <code>FormatChecker</code> instead.</li>; <li><code>unevaluatedItems</code> has been fixed for draft 2019. It's nonetheless; discouraged to use draft 2019 for any schemas, new or old.</li>; <li>Fix a number of minor annotation issues in <code>protocols.Validator</code></li>; </ul>; <h1>v4.13.0</h1>; <ul>; <li>Add support for creating validator classes whose metaschema uses a different; dialect than its schemas. In other words, they may use draft2020-12 to define; which schemas are valid, but the schemas themselves use draft7 (or a custom; dialect, etc.) to define which <em>instances</em> are valid. Doing this is likely; not something most users, even metaschema authors, may need, but occasionally; will be useful for advanced use cases.</li>; </ul>; <h1>v4.12.1</h1>; <ul>; <li>Fix some stray comments in the README.</li>; </ul>; <h1>v4.12.0</h1>; <ul>; <li>Warn at runtime when subclassing validator classes. Doing so was not; intended to be public API, though it seems some downstream libraries; do so. A future version will make this an error, as it is brittle and; better served by composing validator objects instead. Feel free to reach; out if there are any cases where changing existing code seems difficult; and I can try to provide guidance.</li>; </ul>; <h1>v4.11.0</h1>; <ul>; <li>Make the rendered README in PyPI simpler and fancier. Thanks Hynek (<a href=""https://github-redirect.dependabot.com/python-jsonschema/jsonschema/issues/983"">#983</a>)!</li>; </ul>; <h1>v4.10.3</h1>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/python-jsonschema/jsonschema/commit/420fc6bd9a3ecc4cd637ece97cb4b482b4d0d37e""><code>420fc6b</code></a> Minor verbiage tweak for protocols.</li>; <li><a href=""https://github.com/python-jsonschema/jsonschema/commit/8ce8250897e1b2e9",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12163:5615,validat,validator,5615,https://hail.is,https://github.com/hail-is/hail/pull/12163,1,['validat'],['validator']
Security,">; <summary>⚠️ <b>Warning</b></summary>. ```; msal-extensions 1.0.0 requires portalocker, which is not installed.; aiosignal 1.3.1 requires frozenlist, which is not installed.; aiohttp 3.8.5 requires frozenlist, which is not installed. ```; </details>. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | Insufficient Verification of Data Authenticity <br/>[SNYK-PYTHON-CERTIFI-3164749](https://snyk.io/vuln/SNYK-PYTHON-CERTIFI-3164749) | `certifi:` <br> `2021.10.8 -> 2023.7.22` <br> | No | No Known Exploit ; ![critical severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/c.png ""critical severity"") | Improper Following of a Certificate&#x27;s Chain of Trust <br/>[SNYK-PYTHON-CERTIFI-5805047](https://snyk.io/vuln/SNYK-PYTHON-CERTIFI-5805047) | `certifi:` <br> `2021.10.8 -> 2023.7.22` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3172287](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3172287) | `cryptography:` <br> `3.3.2 -> 41.0.4` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | Expected Behavior Violation <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3314966](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3314966) | `cryptography:` <br> `3.3.2 -> 41.0.4` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | Use After Free <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3315324](https://snyk.io/vuln/SNYK-PY",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13736:1376,Certificate,Certificate,1376,https://hail.is,https://github.com/hail-is/hail/pull/13736,2,['Certificate'],['Certificate']
Security,">; <ul>; <li><a href=""https://github.com/urllib3/urllib3/commit/9c2c2307dd1d6af504e09aac0326d86ee3597a0b""><code>9c2c230</code></a> Release 1.26.18 (<a href=""https://redirect.github.com/urllib3/urllib3/issues/3159"">#3159</a>)</li>; <li><a href=""https://github.com/urllib3/urllib3/commit/b594c5ceaca38e1ac215f916538fb128e3526a36""><code>b594c5c</code></a> Merge pull request from GHSA-g4mx-q9vg-27p4</li>; <li><a href=""https://github.com/urllib3/urllib3/commit/944f0eb134485f41bc531be52de12ba5a37bca73""><code>944f0eb</code></a> [1.26] Use vendored six in urllib3.contrib.securetransport</li>; <li>See full diff in <a href=""https://github.com/urllib3/urllib3/compare/1.26.17...1.26.18"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=urllib3&package-manager=pip&previous-version=1.26.17&new-version=1.26.18)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13842:1857,secur,security-vulnerabilities,1857,https://hail.is,https://github.com/hail-is/hail/pull/13842,10,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"></a>)</li>; </ul>; <h1>v24.2.0</h1>; <p>Kubernetes API Version: v1.24.2</p>; <h3>API Change</h3>; <ul>; <li>Add 2 new options for kube-proxy running in winkernel mode. <code>--forward-healthcheck-vip</code>, if specified as true, health check traffic whose destination is service VIP will be forwarded to kube-proxy's healthcheck service. <code>--root-hnsendpoint-name</code> specifies the name of the hns endpoint for the root network namespace. This option enables the pass-through load balancers like Google's GCLB to correctly health check the backend services. Without this change, the health check packets is dropped, and Windows node will be considered to be unhealthy by those load balancers. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/99287"">kubernetes/kubernetes#99287</a>, <a href=""https://github.com/anfernee""><code>@​anfernee</code></a>)</li>; <li>Added CEL runtime cost calculation into CustomerResource validation. CustomerResource validation will fail if runtime cost exceeds the budget. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/108482"">kubernetes/kubernetes#108482</a>, <a href=""https://github.com/cici37""><code>@​cici37</code></a>)</li>; <li>Added a new metric <code>webhook_fail_open_count</code> to monitor webhooks that fail to open. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/107171"">kubernetes/kubernetes#107171</a>, <a href=""https://github.com/ltagliamonte-dd""><code>@​ltagliamonte-dd</code></a>)</li>; <li>Adds a new Status subresource in Network Policy objects (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/107963"">kubernetes/kubernetes#107963</a>, <a href=""https://github.com/rikatz""><code>@​rikatz</code></a>)</li>; <li>Adds support for <code>InterfaceNamePrefix</code> and <code>BridgeInterface</code> as arguments to <code>--detect-local-mode</code> option and also introduces a new optional <code>--pod-interface-name-prefix</code> and <",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12196:1768,validat,validation,1768,https://hail.is,https://github.com/hail-is/hail/pull/12196,1,['validat'],['validation']
Security,"><a href=""https://github.com/PyCQA/flake8/commit/ff6569b87db8ae28c41b548071454de620ad14d5""><code>ff6569b</code></a> Release 5.0.3</li>; <li><a href=""https://github.com/PyCQA/flake8/commit/e76b59ae44f46f7958d13b28bd2d7d9bdc0f5962""><code>e76b59a</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pycqa/flake8/issues/1648"">#1648</a> from PyCQA/invalid-syntax-partial-parse</li>; <li><a href=""https://github.com/PyCQA/flake8/commit/25e8ff18b30b58f1dabc1d20546ebc20fd775560""><code>25e8ff1</code></a> ignore config files that partially parse as flake8 configs</li>; <li>Additional commits viewable in <a href=""https://github.com/pycqa/flake8/compare/4.0.1...5.0.4"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=flake8&package-manager=pip&previous-version=4.0.1&new-version=5.0.4)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12105:2494,secur,security-vulnerabilities,2494,https://hail.is,https://github.com/hail-is/hail/pull/12105,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"><a href=""https://github.com/elastic/elasticsearch-hadoop/commit/712679f88772fb15184ad7c87dea220a87803f44""><code>712679f</code></a> Upgrade to Gradle 7.5 (<a href=""https://github-redirect.dependabot.com/elastic/elasticsearch-hadoop/issues/1980"">#1980</a>)</li>; <li><a href=""https://github.com/elastic/elasticsearch-hadoop/commit/a4d14077a58ba3272469d48500ce007c725f1c73""><code>a4d1407</code></a> [DOCS] Added 8.3.2 RNs (<a href=""https://github-redirect.dependabot.com/elastic/elasticsearch-hadoop/issues/1978"">#1978</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/elastic/elasticsearch-hadoop/compare/v8.0.0...v8.4.3"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=org.elasticsearch:elasticsearch-spark-30_2.12&package-manager=gradle&previous-version=8.0.0&new-version=8.4.3)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12319:7705,secur,security-vulnerabilities,7705,https://hail.is,https://github.com/hail-is/hail/pull/12319,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"><a href=""https://github.com/python-parsy/parsy/commit/638bec2cd810f85058599b9df93b155c04142a00""><code>638bec2</code></a> Fixed indentation of code in tutorial</li>; <li><a href=""https://github.com/python-parsy/parsy/commit/ebf374ebd9c2736da851d9aeb0500b62f3db074e""><code>ebf374e</code></a> Merge pull request <a href=""https://redirect.github.com/python-parsy/parsy/issues/69"">#69</a> from python-parsy/docstrings-and-types</li>; <li><a href=""https://github.com/python-parsy/parsy/commit/9380385e2bc39f23c1378d66d3105c1f1e1d2713""><code>9380385</code></a> Fixed Python 3.11 tests</li>; <li>Additional commits viewable in <a href=""https://github.com/python-parsy/parsy/compare/v1.1.0...v2.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=parsy&package-manager=pip&previous-version=1.1.0&new-version=2.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). You can trigger a rebase of this PR by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Depe",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12934:4260,secur,security-vulnerabilities,4260,https://hail.is,https://github.com/hail-is/hail/pull/12934,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"><code>e4cba8f</code></a> Support python 3.7 and 3.8 in tests and travis CI</li>; <li><a href=""https://github.com/aio-libs/aiomysql/commit/f9b86aa08576c677afe16caf41aa2ab685b0f995""><code>f9b86aa</code></a> Update dependencies (<a href=""https://github-redirect.dependabot.com/aio-libs/aiomysql/issues/485"">#485</a>)</li>; <li><a href=""https://github.com/aio-libs/aiomysql/commit/e3c1bb808d0af308e21d2488be75a40dfd054b78""><code>e3c1bb8</code></a> chore(flake8): fixed flake8 errors (<a href=""https://github-redirect.dependabot.com/aio-libs/aiomysql/issues/484"">#484</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/aio-libs/aiomysql/compare/v0.0.20...v0.0.22"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=aiomysql&package-manager=pip&previous-version=0.0.20&new-version=0.0.22)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11543:6466,secur,security-vulnerabilities,6466,https://hail.is,https://github.com/hail-is/hail/pull/11543,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,">@​ahg-g</code></a>)</li>; <li>Promote IdentifyPodOS feature to beta. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/107859"">kubernetes/kubernetes#107859</a>, <a href=""https://github.com/ravisantoshgudimetla""><code>@​ravisantoshgudimetla</code></a>)</li>; <li>Remove a v1alpha1 networking API for ClusterCIDRConfig (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/109436"">kubernetes/kubernetes#109436</a>, <a href=""https://github.com/JamesLaverack""><code>@​JamesLaverack</code></a>)</li>; <li>Renamed metrics <code>evictions_number</code> to <code>evictions_total</code> and mark it as stable. The original <code>evictions_number</code> metrics name is marked as &quot;Deprecated&quot; and has been removed in kubernetes 1.23 . (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/106366"">kubernetes/kubernetes#106366</a>, <a href=""https://github.com/cyclinder""><code>@​cyclinder</code></a>)</li>; <li>Skip x-kubernetes-validations rules if having fundamental error against the OpenAPIv3 schema. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/108859"">kubernetes/kubernetes#108859</a>, <a href=""https://github.com/cici37""><code>@​cici37</code></a>)</li>; <li>Support for gRPC probes is now in beta. GRPCContainerProbe feature gate is enabled by default. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/108522"">kubernetes/kubernetes#108522</a>, <a href=""https://github.com/SergeyKanzhelev""><code>@​SergeyKanzhelev</code></a>)</li>; <li>Suspend job to GA. The feature gate <code>SuspendJob</code> is locked and will be removed in 1.26. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/108129"">kubernetes/kubernetes#108129</a>, <a href=""https://github.com/ahg-g""><code>@​ahg-g</code></a>)</li>; <li>The AnyVolumeDataSource feature is now beta, and the feature gate is enabled by default. In order to provide user feedback on PVCs with data s",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12196:12624,validat,validations,12624,https://hail.is,https://github.com/hail-is/hail/pull/12196,1,['validat'],['validations']
Security,">[SNYK-PYTHON-TORNADO-6041512](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-6041512) | `tornado:` <br> `5.1.1 -> 6.3.3` <br> | No | No Known Exploit ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | **589/1000** <br/> **Why?** Has a fix available, CVSS 7.5 | Regular Expression Denial of Service (ReDoS) <br/>[SNYK-PYTHON-WHEEL-3180413](https://snyk.io/vuln/SNYK-PYTHON-WHEEL-3180413) | `wheel:` <br> `0.30.0 -> 0.38.0` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI2NTQzMzZlYi02MmRmLTQ0ODAtOTFkOS0xZDg4N2FmNmQwMTUiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjY1NDMzNmViLTYyZGYtNDQ4MC05MWQ5LTFkODg3YWY2ZDAxNSJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""654336eb-62df-4480-91d9-1d887af6d015"",""pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14205:10913,access,access,10913,https://hail.is,https://github.com/hail-is/hail/pull/14205,2,"['access', 'authoriz']","['access', 'authorized']"
Security,">[SNYK-PYTHON-TORNADO-6041512](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-6041512) | `tornado:` <br> `5.1.1 -> 6.3.3` <br> | No | No Known Exploit ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | **589/1000** <br/> **Why?** Has a fix available, CVSS 7.5 | Regular Expression Denial of Service (ReDoS) <br/>[SNYK-PYTHON-WHEEL-3180413](https://snyk.io/vuln/SNYK-PYTHON-WHEEL-3180413) | `wheel:` <br> `0.30.0 -> 0.38.0` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI3YmFjNzAzOC00ZmQzLTQ3YmItOGUwMy0yNjRmYTUxNDRlNGQiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjdiYWM3MDM4LTRmZDMtNDdiYi04ZTAzLTI2NGZhNTE0NGU0ZCJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/fa47fca0-549b-41a3-8bf7-bcda4ca9a617?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/fa47fca0-549b-41a3-8bf7-bcda4ca9a617?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""7bac7038-4fd3-47bb-8e03-264fa5144e4d"",""pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14108:9897,access,access,9897,https://hail.is,https://github.com/hail-is/hail/pull/14108,2,"['access', 'authoriz']","['access', 'authorized']"
Security,">_</li>; </ul>; <h2>Bugfixes</h2>; <ul>; <li>Raise a ClientResponseError instead of an AssertionError for a blank; HTTP Reason Phrase.; <code>[#3532](https://github.com/aio-libs/aiohttp/issues/3532) &lt;https://github.com/aio-libs/aiohttp/issues/3532&gt;</code>_</li>; <li>Fix <code>web_middlewares.normalize_path_middleware</code> behavior for patch without slash.; <code>[#3669](https://github.com/aio-libs/aiohttp/issues/3669) &lt;https://github.com/aio-libs/aiohttp/issues/3669&gt;</code>_</li>; <li>Fix overshadowing of overlapped sub-applications prefixes.; <code>[#3701](https://github.com/aio-libs/aiohttp/issues/3701) &lt;https://github.com/aio-libs/aiohttp/issues/3701&gt;</code>_</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/0a26acc1de9e1b0244456b7881ec16ba8bb64fc3""><code>0a26acc</code></a> Bump aiohttp to v3.7.4 for a security release</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/021c416c18392a111225bc7326063dc4a99a5138""><code>021c416</code></a> Merge branch 'ghsa-v6wp-4m6f-gcjg' into master</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/4ed7c25b537f71c6245bb74d6b20e5867db243ab""><code>4ed7c25</code></a> Bump chardet from 3.0.4 to 4.0.0 (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp/issues/5333"">#5333</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/b61f0fdffc887df24244ba7bdfe8567c580240ff""><code>b61f0fd</code></a> Fix how pure-Python HTTP parser interprets <code>//</code></li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/5c1efbc32c46820250bd25440bb7ea96cb05abe9""><code>5c1efbc</code></a> Bump pre-commit from 2.9.2 to 2.9.3 (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp/issues/5322"">#5322</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/007507580137efcc0a20391a0792f39b337d9c1a""><code>0075075</code></a> Bump ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10115:6598,secur,security,6598,https://hail.is,https://github.com/hail-is/hail/pull/10115,1,['secur'],['security']
Security,"@armartin is getting (what appears to be) a hang running `import_table` on a table with 3K columns. The problem seems two-fold:; - When you access a tstruct field, it populates the jtype of each field. tstruct.__getitem__ should just get the jtype for the field being accessed. Aside, is there a bug in __getitem__? It isn't adding the type if you index by offset:. ```; def __getitem__(self, item):; if not isinstance(item, str):; item = self._fields[item]; self._add_jtypes(); return self._field_types[item]; ```. - Second, StructExpression.__init__ creates expressions for each field in the constructor. That seems excessive, we should construct the field expressions on demand when they are accessed. It still astounds me how slow py4j is.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4153:140,access,access,140,https://hail.is,https://github.com/hail-is/hail/issues/4153,3,['access'],"['access', 'accessed']"
Security,"@chrisvittal This will fix your define_function issue. I was wrong, the types were the same. @danking Something very strange is going on here. I can verify only one GenomeReference is being constructed, so this and concrete must be the same object, but eq is returning false. I don't see how this can be possible. I some something similar last week which caused me to add ReferenceGenome.hashCode (we were defining one but not the other). However, that shouldn't matter because there was only one reference genome object, but two different pointers captured at different times were returning different values of hashCode. I don't see how that's possible but I don't see an alternate explanation. This fixes the immediate bug. I think ReferenceGenome shouldn't be a case class, and it should only use ref equality (don't override equals, hashCode). That will take a little work because the case class is being used for JSON serialization.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5471:388,hash,hashCode,388,https://hail.is,https://github.com/hail-is/hail/pull/5471,3,['hash'],['hashCode']
Security,"@cseed @tpoterba . this was my solution to wrapping the `registerIR` calls to the function registry as one unit. The `fn` tag at the beginning is more or less just a tag on what the function name was. If this looks ok, maybe we can just expose the ability to create and register these from python (maybe with uids as function names for distinctness) to wrap things like `alt_allele` and other things where the IR gets big and explody.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3538:237,expose,expose,237,https://hail.is,https://github.com/hail-is/hail/pull/3538,1,['expose'],['expose']
Security,@cseed Can you take a look at the last commit and see if this is what you envisioned by securing the api calls with headers instead of cookies?. Stacked on #6288,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6361:88,secur,securing,88,https://hail.is,https://github.com/hail-is/hail/pull/6361,1,['secur'],['securing']
Security,@cseed The part I am stuck on is the authentication for the router resolver. How does the batch2 instance in a test namespace get access to the real encryption key that the router resolver is expecting? Can you also double check the nginx configuration?,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6918:37,authenticat,authentication,37,https://hail.is,https://github.com/hail-is/hail/pull/6918,3,"['access', 'authenticat', 'encrypt']","['access', 'authentication', 'encryption']"
Security,"@cseed This is the IR infrastructure needed for the `groupBy` aggregator. I wrote tests by adding a `KeyedAggregator` so we can use the interpreter. I don't think it is trivial to incorporate `groupBy` into the AST / Parser. Since we're going to rip out the AST soon anyways, I decided to leave the code where it's at and expose it in Python once we can build IRs in Python.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3768:322,expose,expose,322,https://hail.is,https://github.com/hail-is/hail/pull/3768,1,['expose'],['expose']
Security,"@cseed You're really the only one who understands this well enough to review it. resolves #5168 . In order to create a test, we'd have to expose the pod_name to the clients and the tests would have to talk to k8s to ensure said pod was really deleted. Not a terrible test, but maybe more work than I care to do right now given my other commitments. See the [description of the issue in a comment on #5168](; https://github.com/hail-is/hail/issues/5168#issuecomment-456618542). cc: k8s-and-services team: @jigold @tpoterba @akotlar",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5191:138,expose,expose,138,https://hail.is,https://github.com/hail-is/hail/pull/5191,1,['expose'],['expose']
Security,"@nawatts points out that the docs are missing the font-awesome icons. This new website; stuff is confusing! Here is how to think about it going forward:. This PR is the *long-term fix*. It will not resolve the current production issue. The easiest fix; for that is to release a new version of Hail, which will generate a new version of the docs. That; new version will be compatible with the currently released `website`. We have two phases: docs-generation-time and serve-time. Importantly, we always need to support the; *previously released documentation* with the current `main` `website`. This PR makes things work like this:. At docs-generation-time (which happens every time we release a new version of the Hail package to; PyPI), Sphinx uses `dynamic-base.html` to build the docs website. Those HTML files will look like; this:. ```; <!DOCTYPE html>; <html lang=""en"">; <head>; <title>Hail | {% block title %}{% endblock %}</title>. {% include ""base-head.html"" %}. <!-- Sphinx will insert some header stuff here -->; </head>; <body>; {% include ""nav-top.html"" %}; <div id=""main"">; {% raw %}; <!-- Sphinx will insert the actual documentation here -->; {% endraw %}; </div>; {% include ""nav-bottom.html"" %}; {% include ""base-foot.html"" %}; </body>; </html>; ```. Note that this is *still a Jinja2 template!*. At serve-time, `website` will run this through Jinja2 templating *a second time*. At this time,; we'll use the latest `base-head.html`. In particular, suppose I need access to a new CSS file in `nav-top.html`. I can modify; `base-head.html`. Since `base-head.html` is added to the web page *at serve-time*, it will include; all the latest changes. In contrast, everything inside the `#main` `div` *only changes when Hail is released* because it is; only updated at docs-generation-time. cc: @daniel-goldstein",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10278:1480,access,access,1480,https://hail.is,https://github.com/hail-is/hail/pull/10278,1,['access'],['access']
Security,"@tpoterba @jbloom22 a few more things to fix for the workshop. I was using a too powerful kubernetes command to look up worker pods and services for the admin page. I now use a restricted form of it that is permitted by our security policy. We also are missing the non-preemptible node pool (!), so this adds that to our gcp-config. cc: @cseed",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4862:224,secur,security,224,https://hail.is,https://github.com/hail-is/hail/pull/4862,1,['secur'],['security']
Security,"A forthcoming change to the hail ci system will introduce deployment. This change adds `hail-ci-deploy.sh` which replicates the [""Deploy Website""](https://ci.hail.is/admin/editRunType.html?id=buildType:HailSourceCode_HailMainline_DeployWebsite&runnerId=RUNNER_29) and [""Deploy Google Cloud""](https://ci.hail.is/admin/editRunType.html?id=buildType:HailSourceCode_HailMainline_DeployDocsAndGoogleCloudSpark220&runnerId=RUNNER_10) TeamCity jobs. My general thinking for deploy jobs from the CI is that, for the time being, we'll hardcode a mapping from GitHub repository to [Kubernetes Secret](https://kubernetes.io/docs/concepts/configuration/secret/). That's where this `/secret/ci.hail.is-web-updater-rsa-key` will come from. Moreover, the CI will always authorize a gcloud account (again with a baked in mapping from GitHub repository to GCP service account) before calling the deploy script. I did not retest the master branch here. Should we do that even though a PR is only merged to master if it passes the tests? Even after locking down merging, there's still the possibility of CI bugs. cc: @cseed",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4220:755,authoriz,authorize,755,https://hail.is,https://github.com/hail-is/hail/pull/4220,1,['authoriz'],['authorize']
Security,"A job running for five days *could* cause an issue here, so the operator should still be cognizant of that. The; move to access tokens will eliminate that concern anyway. We should not consider system-managed keys because those are managed by Google and not even visible in the; UI. We are not obligated to rotate them (nor are we able, afaik). There are two special secrets which do not conform to the `key.json` naming scheme for their; secret files. I added them as special cases.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13319:121,access,access,121,https://hail.is,https://github.com/hail-is/hail/pull/13319,1,['access'],['access']
Security,"A little chaos testing revealed a database integrity issue. If jobs.state = Running, instance_id must be non-null. I incorrectly had `ON DELETE SET NULL`. Instead, make sure that the instance has been deactivated (which reschedules all jobs, setting state = Ready) before deleting the instance entry. Also, feedback on cancellation.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7443:43,integrity,integrity,43,https://hail.is,https://github.com/hail-is/hail/pull/7443,1,['integrity'],['integrity']
Security,"A long-standing fixme in the LocalBackend was to not rely on HadoopFS, which we use with the SparkBackend for compatibility with dataproc and hdfs urls. By default, the HadoopFS doesn't understand gs urls. Users need to install the gcs-hadoop-connector (preinstalled in dataproc) to communicate with google cloud storage. Spark handles supplying credentials to the connector. Issue #13904 is caused by failing to properly supply the gcs-hadoop-connector with credentials in the LocalBackend. In the absence of config, the connector hangs while trying to fetch a token form a non-existant metadata server. The LocalBackend was designed to be a testing ground for lowered and compiled code that would eventually be run on batch, where we use the RouterFS. I propose a pragmatic fix for #13904 that ditches the HadoopFS for all but local filesystem access in the LocalBackend instead of identifying and fixing the root cause. In doing so, I made a couple of changes to how the RouterFS is configured: In the absence of the `HAIL_CLOUD` environment variable, RouterFS can handle gs and az urls iff credentials are not supplied. If the user supplies creditials, we use `HAIL_CLOUD` to decide which cloud to route to. fixes #13904",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14407:846,access,access,846,https://hail.is,https://github.com/hail-is/hail/pull/14407,1,['access'],['access']
Security,"A summary of major changes:; - The genotype schema has changed from pl to px, where px is an Array[Int] that stores probabilifrom pl to px, where px is an Array[Int] that stores probabilities (phred or linear scaled). g.pl and g.dosage are used for accessing the PLs and/or dosages.; - The VariantMetadata includes information about whether the dataset is dosage data; - Can use indexbgen and importbgen to load BGEN files; - Can use importplink to load PLINK binary files; - Can use importgen to load GEN files and exportgen to export data in GEN format; - Reorganized the VCF import/export scripts to the io folder",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/542:249,access,accessing,249,https://hail.is,https://github.com/hail-is/hail/pull/542,1,['access'],['accessing']
Security,"A summary of major changes:; - The genotype schema has changed from pl to px, where px is an Array[Int] that stores probabilifrom pl to px, where px is an Array[Int] that stores probabilities (phred or linear scaled). g.pl and g.dosage are used for accessing the PLs and/or dosages.; - The VariantMetadata includes information about whether the dataset is dosage data; - Can use indexbgen and importbgen to load BGEN files; - Can use importplink to load PLINK binary files; - Can use importgen to load GEN files and exportgen to export data in GEN format; - Reorganized the VCF import/export scripts to the io folder. Fix indentation.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/573:249,access,accessing,249,https://hail.is,https://github.com/hail-is/hail/pull/573,1,['access'],['accessing']
Security,A use case is to add the `cloud-platform` scope to allow accessing GCP secrets from within a dataproc script.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10633:57,access,accessing,57,https://hail.is,https://github.com/hail-is/hail/pull/10633,1,['access'],['accessing']
Security,"A very small PR but here's the background and context behind this change. When talking to either GCP or Azure, hail chooses credentials in the following order from highest priority to lowest priority:. 1. An explicit `credential_file` argument passed to the relevant credentials class; 2. An environment variable containing the path to the credentials (`GOOGLE_APPLICATION_CREDENTIALS` or `AZURE_APPLICATION_CREDENTIALS`) (from this you can see why the code that was here is totally redundant); 3. The latent credentials present on the machine. This might be `gcloud` or `az` credentials, or the metadata server if you're on a cloud VM. I'm trying to rid the codebase of most explicit providing of credentials file paths, for two reasons:; - Quality of life. I'm already signed into the cloud with `gcloud` and `az`. I shouldn't need to download some file and provide `AZURE_APPLICATION_CREDENTIALS` to run this test. It should just use the latent credentials.; - We are trying to phase out credentials files altogether for security reasons. These files are long-lived secrets that you really don't want to leak and are currently exposed to users in Batch jobs, so they can be easily exfiltrated. Using the latent credentials on a cloud VM (the metadata server) has the benefit of only issuing short-lived access tokens which last for hours not months, so it's basically always better to use the latent credentials when possible.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13981:1024,secur,security,1024,https://hail.is,https://github.com/hail-is/hail/pull/13981,3,"['access', 'expose', 'secur']","['access', 'exposed', 'security']"
Security,"AD/microsoft-authentication-extensions-for-python/issues/107"">#107</a>)</li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/AzureAD/microsoft-authentication-extensions-for-python/commit/a88fa673af3602fe7c8c922314599b0c245e7add""><code>a88fa67</code></a> Merge branch 'release-1.0.0'</li>; <li><a href=""https://github.com/AzureAD/microsoft-authentication-extensions-for-python/commit/bd5b4074dbb7d03c9d91ce6a75378851be92552a""><code>bd5b407</code></a> Update README to reflect the new APIs</li>; <li><a href=""https://github.com/AzureAD/microsoft-authentication-extensions-for-python/commit/6f77b1e70be086aae752dcf7e08d7f06bcabdcd7""><code>6f77b1e</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/AzureAD/microsoft-authentication-extensions-for-python/issues/109"">#109</a> from AzureAD/release-1.0.0</li>; <li><a href=""https://github.com/AzureAD/microsoft-authentication-extensions-for-python/commit/50bf9674f9c65229a1573be39ef4ef507eee17fa""><code>50bf967</code></a> MSAL EX for Python 1.0.0</li>; <li><a href=""https://github.com/AzureAD/microsoft-authentication-extensions-for-python/commit/6b904af1a3d4fc0e28e3f090fa3dd8492f79e6bf""><code>6b904af</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/AzureAD/microsoft-authentication-extensions-for-python/issues/110"">#110</a> from AzureAD/persistence-factory</li>; <li><a href=""https://github.com/AzureAD/microsoft-authentication-extensions-for-python/commit/d0696aeb6f65168b1e0d405cd871b80bb101cd76""><code>d0696ae</code></a> Add build_encrypted_persistence() factory</li>; <li><a href=""https://github.com/AzureAD/microsoft-authentication-extensions-for-python/commit/289a94f694645c642ae67b2d5972d3f9fdadb928""><code>289a94f</code></a> Remove old classes that are deprecated for 2 years</li>; <li><a href=""https://github.com/AzureAD/microsoft-authentication-extensions-for-python/commit/fa1f45b556341b2c34e9bf63c06a5068571cd337""><code>f",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11992:2596,authenticat,authentication-extensions-for-python,2596,https://hail.is,https://github.com/hail-is/hail/pull/11992,1,['authenticat'],['authentication-extensions-for-python']
Security,Add AccessLogger which standardizes access logging across our infrastructure and crucially prints the X-Real-IP header. Also includes a fix for the google auth issue and two missing tables from delete_auth_tables.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8102:4,Access,AccessLogger,4,https://hail.is,https://github.com/hail-is/hail/pull/8102,2,"['Access', 'access']","['AccessLogger', 'access']"
Security,Add HashAggregator[T],MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1947:4,Hash,HashAggregator,4,https://hail.is,https://github.com/hail-is/hail/issues/1947,1,['Hash'],['HashAggregator']
Security,Add Julia Goodrich (@jkgoodrich) to authorized users,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11865:36,authoriz,authorized,36,https://hail.is,https://github.com/hail-is/hail/pull/11865,1,['authoriz'],['authorized']
Security,Add TakeSet aggregator (exposed as a `unique=` flag on `take`),MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7205:24,expose,exposed,24,https://hail.is,https://github.com/hail-is/hail/issues/7205,1,['expose'],['exposed']
Security,"Add a `hailctl auth` subcommand that prints an access token for the hail service, mirroring the behavior of `gcloud auth application-default print-access-token`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13934:47,access,access,47,https://hail.is,https://github.com/hail-is/hail/pull/13934,2,['access'],"['access', 'access-token']"
Security,"Add a code cache. 50 is was chosen somewhat randomly. Normalize incoming IR so name differences don't case a recompile. Move ApplyIR `conversion` since it shouldn't be involved in equality. Add hashCode to GR because you should always define hashCode, equals as a pair (and it was behaving very strangely without it). @chrisvittal I think this resolves the last of the issues you ran into on Friday.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5426:194,hash,hashCode,194,https://hail.is,https://github.com/hail-is/hail/pull/5426,2,['hash'],['hashCode']
Security,Add a number of hash function families,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2288:16,hash,hash,16,https://hail.is,https://github.com/hail-is/hail/pull/2288,1,['hash'],['hash']
Security,Add billing projects. Billing projects are validated once in /batches/create.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7596:43,validat,validated,43,https://hail.is,https://github.com/hail-is/hail/pull/7596,1,['validat'],['validated']
Security,"Add new command to aggregate and export statistics over intervals with; access to a 'variants' aggregator. Takes an interval list as input,; takes an export command (see exportvariants), and an output path. Exposed `Interval` in the expr language, which has `start`, `end`,; and `contains` (all locus-based). Reworked property-based testing for annotation impexes.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/543:72,access,access,72,https://hail.is,https://github.com/hail-is/hail/pull/543,4,"['Expose', 'access']","['Exposed', 'access']"
Security,Add simple- and twisted-tabulation hashes,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2304:35,hash,hashes,35,https://hail.is,https://github.com/hail-is/hail/pull/2304,2,['hash'],['hashes']
Security,Add simplest hash functions,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2303:13,hash,hash,13,https://hail.is,https://github.com/hail-is/hail/pull/2303,2,['hash'],['hash']
Security,Added LDMatrix computation on VDS's. Did not expose any python api yet. Will do that in subsequent PR.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1775:45,expose,expose,45,https://hail.is,https://github.com/hail-is/hail/pull/1775,1,['expose'],['expose']
Security,"Added `AzureBaseClient.get_next_link` and `AzureBaseClient.delete_and_wait`. ## Batch; - Added `batch.azure` which mirrors the functionality of `batch.gcp`; - Renamed `worker_local_ssd_data_disk` to `local_ssd_data_disk` in the PoolConfig; - Renamed `worker_pd_ssd_data_disk_size_gb` to `external_data_disk_size_gb` in the PoolConfig; - Added {Azure,GCP}UserCredentials to the worker to abstract away the names of environment variables and the mount paths of credentials in containers. ## Auth; - Added new fields in the auth database for `azure service principal name` and `azure_credentials_secret_name`; - Made `auth` only create `GSAResource` if CLOUD == 'gcp'. ## Gear; - Added `azure-vm` to the location options for `DeployConfig`. # Assumptions:; - Mapped `{'lowmen': 'F', 'standard': 'D', 'highmem': 'E'}` for machine types in Azure. This corresponds to 2Gi/core, 4Gi/core, and 8Gi/core.; - Spot price is set to -1 for now until we figure out a better billing strategy; - We look for existing network security groups to tell if a VM has been fully cleaned up already in the garbage collection loop. # To-Do:. ## Services. - Use global config and make an `AzureConfig` (@daniel-goldstein not sure if you're already doing this) instead of optional environment variables; - Azure user disks are not implemented; There's a maximum number of disks that can be mounted per machine type with a maximum of 32 along with figuring out the API calls. We'll need a semaphore of some sort.; - No activity logs loop. Not necessary for initial development and preemption billing is not working how intended anyways (will add to the list to fix!). We also don't track vm creation success rates per zone like we do with GCP. It might be good to look for VM deletion events to remove instances that are no longer present and then do a deep delete as then we'll have some redundancy and faster response times.; - Figure out how to do a deep-delete as much as possible for VMs when using the create VM REST API. T",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10970:1226,secur,security,1226,https://hail.is,https://github.com/hail-is/hail/pull/10970,1,['secur'],['security']
Security,"Added functions to make annotations py4j-convertible.; Exposed global and sample annotations in python. This is the start of a long list of changes that need to be made before our interface starts to actually look nice in python. Doing `annotate_global_expr_by_sample` followed by `show_globals` to do aggregations is horrible -- here you can just do . ```; >>> europeans = vds.query_samples('samples.filter(s => sa.pop == ""EUR"").collect()'); ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1255:55,Expose,Exposed,55,https://hail.is,https://github.com/hail-is/hail/pull/1255,1,['Expose'],['Exposed']
Security,Added region value accessors to types.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2093:19,access,accessors,19,https://hail.is,https://github.com/hail-is/hail/pull/2093,1,['access'],['accessors']
Security,Added set_va_attributes to expose setting Field attributes,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1373:27,expose,expose,27,https://hail.is,https://github.com/hail-is/hail/pull/1373,1,['expose'],['expose']
Security,"Adding a new compiler pass (lowering MatrixIR to TableIR) exposed a problem in Simplify. The logic for preventing some simplifications from triggering if they would introduce non-determinism was broken, and fixing it required a pretty complete overhaul. Fortunately, I think it's now a lot simpler. Besides the rewrite of the high level Simplify architecture, I also:; * Changed `testRepartitioningSimplifyRules` to something that failed in the old version.; * Changed the `copy` signature on the IR hierarchy to be more precise (to avoid unnecessary coercions).; * Grouped the Simplify rules into IR, MatrixIR, and TableIR. After the reorganization, a couple of rule redundancies became evident.; * A couple of vals in PruneSuite required running the compiler. When I had a bug in Simplify, this was causing the test runner to fail before any tests were run, on class initialization of PruneSuite, which gives very little help in diagnosing the issue. I made them lazy vals to prevent this in the future.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4564:58,expose,exposed,58,https://hail.is,https://github.com/hail-is/hail/pull/4564,1,['expose'],['exposed']
Security,"Adds BlockMatrix sparsify functions for:; - band matrix; - upper/lower triangle (special case of band); - a collection of rectangles. For diagonal band, I switched GridPartitioner.filterBand to go from lower to upper diagonal index, rather than taking a lower and upper bandwidth. This is more general, e.g. the diagonal itself need not be in the band. Band and triangle zero out elements in partially overlapping blocks by default. Rectangles currently only supports dropping whole blocks. Also adds `export_rectangles` for exporting rectangular regions to TSV in parallel.; I use parameters `path_in` and `path_out`, and switched `BlockMatrix.export` to this convention as well from `input` and `output` to avoid using the reserved word `input`. I have not exposed export methods directly on BlockMatrix for now as it'd be very easy for users to needlessly write and read an already written BlockMatrix. I could add these in a later PR with a warning, or we can wait until we've moved to IR and can optimize read followed by export to export on the file. It'd also be good to add compression options (and float formatting options to `export` and `export_rectanges`). Along the way I fixed NaN checking (due to Double.NaN != Double.NaN) on scalar and vector `/` sparse block ops and added NaN and Infinity checking to scalar and vector `*` sparse ops. Together with `sparsify_row_intervals` in the first sparse matrix PR, this PR exposes all the BlockMatrix functionality needed for big LD applications of Kate/Ran and Jacob/Masa.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3539:759,expose,exposed,759,https://hail.is,https://github.com/hail-is/hail/pull/3539,2,['expose'],"['exposed', 'exposes']"
Security,"Adds dbSNP build 154 Hail Tables to datasets API and annotation DB. . The dataset named `dbSNP` includes all fields, and the one named `dbSNP_rsid` only contains locus, alleles, and rsIDs. The process used to generate the tables is outlined in the notebook. I needed to use the GRCh37/38 assembly reports to map contigs from RefSeq accession numbers to chromosomes, and could then import the VCFs. . To make parsing/formatting strings possible after importing the VCFs as MatrixTables, the following `INFO` fields in the VCF headers were changed from `Number=.` to `Number=1`: FREQ, CLNHGVS, CLNVI, CLNORIGIN, CLNSIG, CLNDISB, CLNDN, CLNREVSTAT, CLNACC. . Biallelic and multiallelic variants were present. The multiallelic variants were first filtered out to be split, and then were unioned back with the biallelic variants to create the final tables.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10473:332,access,accession,332,https://hail.is,https://github.com/hail-is/hail/pull/10473,1,['access'],['accession']
Security,"Adds the [1000 Genomes NYGC 30x on GRCh38](https://www.internationalgenome.org/data-portal/data-collection/30x-grch38) autosomes, chrX, and chrY MatrixTables as `1000_Genomes_HighCov_autosomes`, `1000_Genomes_HighCov_chrX`, and `1000_Genomes_HighCov_chrY`. . The `1000_Genomes_HighCov_autosomes` and `1000_Genomes_HighCov_chrX` datasets have phased calls. . [Due to multiple issues](http://ftp.1000genomes.ebi.ac.uk/vol1/ftp/release/20130502/supporting/GRCh38_positions/README_GRCh38_liftover_20170504.txt), the phase 3 GRCh38 versions of the current `1000_Genomes_autosomes`, `1000_Genomes_chrX`, and `1000_Genomes_chrY` datasets have been retracted. They have been renamed to `1000_Genomes_Retracted_autosomes`, `1000_Genomes_Retracted_chrX`, and `1000_Genomes_Retracted_chrY`, respectively. The phase 3 GRCh37 versions of `1000_Genomes_autosomes`, `1000_Genomes_chrX`, and `1000_Genomes_chrY` are not affected and are still accessible as before.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10413:927,access,accessible,927,https://hail.is,https://github.com/hail-is/hail/pull/10413,1,['access'],['accessible']
Security,"Adds the ability to rerun/retry queries from the nearest `CollectDistributedArray` (`CDA`) IR site. Computes a ""Semantic Hash"" of the top-level IR, which is split and shared among the various constituent `CDA` calls in a query. The `CDA` procedure looks in an execution cache for the results of each partition for that call and uses/updates the cache with successful partition computations. . The nature of the staged- lower and execute model means we don't know how many `CDA` calls that will be generated ahead of time. Thus we treat the ""Semantic Hash"" in a similar way to an RNG state variable and generate a key from the Semantic Hash every time every time we encounter a `CDA`. Since an `ExecutionContext` is re-used for multiple queries in tests while a `SemanticHash` is coupled to one query, the two were kept separate. To minimise the amount of manual state handling, the code was transformed to use a ""State"" monad (abstracted as `MonadLower`). Since the `ExecuteContext` is used nearly everywhere the semantic hash is required, the `ExecuteContext` was absorbed into the `MonadLower` interface. `Lower` is a simple, concrete instance of `MonadLower`, and is used to adapt statements into `MonadLower` expressions.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13194:121,Hash,Hash,121,https://hail.is,https://github.com/hail-is/hail/pull/13194,4,"['Hash', 'hash']","['Hash', 'hash']"
Security,"Adds the ability to rerun/retry queries from the nearest `CollectDistributedArray` (`CDA`) `IR` site. Computes a ""Semantic Hash"" of the top-level `IR` which is used to generate a key for the various constituent `CDA` calls in a query. The implementation for CDA, `BackendUtils.collectDArray`, uses that key to look into an the execution cache for the results of each partition for that call and uses/updates the cache with successful partition computations. The nature of the staged- lower and execute model means we don't know how many `CDA` calls that will be generated ahead of time. Thus we treat the ""Semantic Hash"" in a similar way to an RNG state variable and generate a key from the Semantic Hash every time every time we encounter a `CDA`. The execution cache is implemented on-top of a local or remote filesystem (configurable via the `HAIL_CACHE_DIR` environment variable). This defaults to `{tmpdir}/hail/{pip-version}`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12954:123,Hash,Hash,123,https://hail.is,https://github.com/hail-is/hail/pull/12954,3,['Hash'],['Hash']
Security,"Adds the split `VariantDataset` representation, where reference block data and variant data are contained in separate `MatrixTable` objects. Functions are accessible via the `hail.vds` submodule, e.g. `hl.vds.sample_qc(vds)`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10698:155,access,accessible,155,https://hail.is,https://github.com/hail-is/hail/pull/10698,1,['access'],['accessible']
Security,"All this `HAIL_AZURE_OAUTH_SCOPE` and `HAIL_IDENTITY_PROVIDER_JSON` are now injected by batch workers by default so we don't need to specify them explicitly in `build.yaml`. Unrelatedly, I don't think `create_dummy_oauth2_client_secret` does anything as `auth-oauth2-client-secret` already exists inside new namespaces.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13570:76,inject,injected,76,https://hail.is,https://github.com/hail-is/hail/pull/13570,1,['inject'],['injected']
Security,"Allows the notebook container to have access to the user's gsa secret key, a necessary step in mounting the user's bucket. I modified `delete_worker_pod` to exclude the V1DeleteOptions, because the signature appears to have changed, and no options were actually provided. ```sh; File ""notebook/notebook.py"", line 443, in delete_worker_pod; kube.client.V1DeleteOptions()); TypeError: delete_namespaced_pod() takes 3 positional arguments but 4 were given; ```. Will double check that I have necessary permissions: its the case when running on local, but I think I will need to update vdc to provide broad secret read access for notebook for this to work on the cluster. Checking now. cc @cseed, @danking, @jigold",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5753:38,access,access,38,https://hail.is,https://github.com/hail-is/hail/pull/5753,2,['access'],['access']
Security,"Also may need to add back annotate_global_expr. Either way include these examples which used to be un the FAQ:. **How do I access an annotation name with white-space in the Hail Expression Language?**. Put the annotation name in back ticks. ```; annotateglobal expr -c 'global.`my variable` = global.`lof count`'; ```. **How do I count the number of samples matching a phenotype annotation?**. ```; annotateglobal expr -c '; global.nMales = samples.count(sa.pheno.sex == ""Male""),; global.nFemales = samples.count(sa.pheno.sex == ""Female""),; global.nSamples = samples.count(true)'; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1349:123,access,access,123,https://hail.is,https://github.com/hail-is/hail/issues/1349,1,['access'],['access']
Security,"Appears unrelated to hail version. JAR and ZIP:; ```; gs://hail-common/builds/0.2/jars/hail-0.2-3b1cb0772301-Spark-2.2.0.jar; gs://hail-common/builds/0.2/python/hail-0.2-3b1cb0772301.zip; ```. In Google Chrome we see 404s for; ```; GET http://localhost:8123/spark/api/v1/applications; ```; which happened repeatedly if you try to evaluate a cell. On the leader node of the spark cluster, `journalctl -u jupyter` shows:; ```; -- Logs begin at Fri 2019-03-01 19:54:49 UTC, end at Fri 2019-03-01 20:11:51 UTC. --; Mar 01 19:59:03 dk-m systemd[1]: Started Jupyter Notebook.; Mar 01 19:59:04 dk-m python[5149]: [I 19:59:04.630 NotebookApp] Writing notebook server cookie secret to /root/.local/share/jupyter/runtime/notebook_cookie_secret; Mar 01 19:59:04 dk-m python[5149]: [W 19:59:04.796 NotebookApp] All authentication is disabled. Anyone who can connect to this server will be able to run code.; Mar 01 19:59:04 dk-m python[5149]: [D 19:59:04.802 NotebookApp] Paths used for configuration of jupyter_notebook_config:; Mar 01 19:59:04 dk-m python[5149]: /etc/jupyter/jupyter_notebook_config.json; Mar 01 19:59:04 dk-m python[5149]: [D 19:59:04.803 NotebookApp] Paths used for configuration of jupyter_notebook_config:; Mar 01 19:59:04 dk-m python[5149]: /usr/local/etc/jupyter/jupyter_notebook_config.json; Mar 01 19:59:04 dk-m python[5149]: [D 19:59:04.804 NotebookApp] Paths used for configuration of jupyter_notebook_config:; Mar 01 19:59:04 dk-m python[5149]: /opt/conda/etc/jupyter/jupyter_notebook_config.json; Mar 01 19:59:04 dk-m python[5149]: [D 19:59:04.804 NotebookApp] Paths used for configuration of jupyter_notebook_config:; Mar 01 19:59:04 dk-m python[5149]: /root/.jupyter/jupyter_notebook_config.json; Mar 01 19:59:04 dk-m python[5149]: [W 19:59:04.904 NotebookApp] Error loading server extension jupyter_spark; Mar 01 19:59:04 dk-m python[5149]: Traceback (most recent call last):; Mar 01 19:59:04 dk-m python[5149]: File ""/opt/conda/lib/python3.6/site-packages/notebook/notebookapp.p",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5505:803,authenticat,authentication,803,https://hail.is,https://github.com/hail-is/hail/issues/5505,1,['authenticat'],['authentication']
Security,As mentioned in #5448 admins need to enter a separate admin password (basic auth). This can be solved by implementing account roles and/or scopes.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5475:60,password,password,60,https://hail.is,https://github.com/hail-is/hail/issues/5475,1,['password'],['password']
Security,"As part of the ci2 work, I want to set things up so it is possible (and easy!) to spin up independent copies of the entire stack for development, testing and staging. To that end, I'm breaking apart gateway, into gateway and router. Each publicly accessible namespace will have a router, and gateway will only be responsible for stripping encryption and forwarding requests to these routers. Requests like `...mynamespace.internal.hail.is` will get forwarded to the router for `mynamespace`. All other requests will get forwarded to the default namespace router. I will so modify gateway in another PR.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5867:247,access,accessible,247,https://hail.is,https://github.com/hail-is/hail/pull/5867,2,"['access', 'encrypt']","['accessible', 'encryption']"
Security,"As part of the security POAMs, we'll follow up on this with instructions of making operator devs viewers + ability to assign themselves roles. This is just what I did for Sophie to give access just to the dev namespace.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13347:15,secur,security,15,https://hail.is,https://github.com/hail-is/hail/pull/13347,2,"['access', 'secur']","['access', 'security']"
Security,"Assigning @tpoterba since he (and cotton) have the most context to review this. A few preliminaries:. 1. I noticed the proxy headers were not quite right when you're testing this without SSL or on some non-standard port. `$host` does not include the port, `$http_host` does. `$scheme` returns `http` or `https` depending on how the user connected to gateway; 2. The admin privilege check was too restrictive, if `delete_worker_pod` is called by `/new` there's no need to check admin privs; 3. I realized that the timeout logic wasn't quite right because a misconfigured gateway (I was testing with a broken gateway config) will return 5xx codes, but that doesn't mean the server is alive. We probably should error here, but I'm hesitant to add new error modes so close to a tutorial. Ok, how does this work? Basically, if the gateway cannot connect to the notebook pod, we intercept the error and redirect the user to the ""create new notebook"" webpage. That webpage deletes whatever remains of the users previous notebook pod & service. Here are the pieces:. 1. `recursive_error_pages on;` the internet suggests that without this we cannot use `error_page` with an ""internal"" rule (the `@` rules are internal rules that users cannot directly access); 2. `proxy_connect_timeout` defaults to 60s which is a shit user experience if your pod dies. Honestly, I might set this to 100ms. This is all inside a datacenter.; 3. `proxy_intercept_errors` permits us to use `error_page` with 5xx errors from failing to connect to the proxy. ---. I tested this with a pile of hacks to deploy this into an anonymous namespace in `vdc`. I'm not ready to PR those changes, they need a clean up before others use them. Sometime next week I hope to get that in. Getting it requires some restructuring of `vdc/` and `gateway/` to be more modular.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4974:1242,access,access,1242,https://hail.is,https://github.com/hail-is/hail/pull/4974,1,['access'],['access']
Security,"Assigning to Daniel 2 because the scorecard beacon is tired. This removes the workshop login option (previously agreed upon with Cotton), which makes the login.html page totally useless; so I've converted the login link to hit the old /login POST endpoint, and converted the POST to a GET. I think this is semantically fine, because no credentials (or other data) is actually sent to that endpoint (as workshop password is kaput), making that endpoint solely issue a redirect. Since login.html is gone, I also no longer redirect to it. Instead, unauthorized users are redirected to /error, and I refactored this redirect into a function since it's now used identically in 2 places. I've also imported the jwt library, so that jwt.exceptions.InvalidTokenError is in scope, and made some minor cleanup. cc @cseed",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6078:411,password,password,411,https://hail.is,https://github.com/hail-is/hail/pull/6078,1,['password'],['password']
Security,"At time of writing dependabot doesn't have a great way to bulk update dependencies across unrelated lockfiles in the repo, which often require manual intervention because we assert that we're always using the same package version everywhere. It's also just a lot of noise and hogs CI time. We've decided to move to a periodic bulk-update process + using repo Security alerts.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14504:359,Secur,Security,359,https://hail.is,https://github.com/hail-is/hail/pull/14504,1,['Secur'],['Security']
Security,Audit RegistryFunctions to ensure that IR generators don't need to include Let statements,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4764:0,Audit,Audit,0,https://hail.is,https://github.com/hail-is/hail/issues/4764,1,['Audit'],['Audit']
Security,"Azure already has a Jupyter system in place, so I worked within that. As a result, I took a very different approach from `hailctl dataproc`. I'm not sure how many of the configuration settings done in `hailctl dataproc` are necessary in Azure. I also do not plan to add special support for any special parameters from Azure. If a user wants to, for example, configure auto-scaling, they can use pass through arguments. There are three files that need to be hosted somewhere: two startup scripts and an Azure-specific wheel file. For the startup scripts, I just rely on GitHub tagged raw files. For the wheel file, I placed it in hail common and use the public HTTP endpoint. For development, you have to manually upload the files you want to override and invoke `hailctl hdinsight` like this:; ```; hailctl hdinsight; start \; clustername \; password \; password \; storageaccount \; --install-hail-uri https://raw.githubusercontent.com/danking/hail/dk-hdinsight-test/hail/python/hailtop/hailctl/hdinsight/resources/install-hail.sh \; --install-native-deps-uri https://raw.githubusercontent.com/danking/hail/dk-hdinsight-test/hail/python/hailtop/hailctl/hdinsight/resources/install-native-deps.sh \; --wheel-uri https://storage.googleapis.com/hail-common/dking/hail-0.2.79-py3-none-any.whl; ```; We could make this easier, but I'd rather spend that time on the query service. cc: @jigold",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11180:842,password,password,842,https://hail.is,https://github.com/hail-is/hail/pull/11180,2,['password'],['password']
Security,"BCONVERT-2979829) | `nbconvert:` <br> `5.6.1 -> 6.3.0b0` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **434/1000** <br/> **Why?** Has a fix available, CVSS 4.4 | Open Redirect <br/>[SNYK-PYTHON-NOTEBOOK-1041707](https://snyk.io/vuln/SNYK-PYTHON-NOTEBOOK-1041707) | `notebook:` <br> `5.7.16 -> 6.4.12` <br> | No | No Known Exploit ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | **589/1000** <br/> **Why?** Has a fix available, CVSS 7.5 | Information Exposure <br/>[SNYK-PYTHON-NOTEBOOK-2441824](https://snyk.io/vuln/SNYK-PYTHON-NOTEBOOK-2441824) | `notebook:` <br> `5.7.16 -> 6.4.12` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **449/1000** <br/> **Why?** Has a fix available, CVSS 4.7 | Access Restriction Bypass <br/>[SNYK-PYTHON-NOTEBOOK-2928995](https://snyk.io/vuln/SNYK-PYTHON-NOTEBOOK-2928995) | `notebook:` <br> `5.7.16 -> 6.4.12` <br> | No | No Known Exploit ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | **696/1000** <br/> **Why?** Proof of Concept exploit, Has a fix available, CVSS 7.5 | Regular Expression Denial of Service (ReDoS) <br/>[SNYK-PYTHON-PYGMENTS-1086606](https://snyk.io/vuln/SNYK-PYTHON-PYGMENTS-1086606) | `pygments:` <br> `2.5.2 -> 2.15.0` <br> | No | Proof of Concept ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | **589/1000** <br/> **Why?** Has a fix available, CVSS 7.5 | Denial of Service (DoS) <br/>[SNYK-PYTHON-PYGMENTS-1088505](https://snyk.io/vuln/SNYK-PYTHON-PYGMENTS-1088505) | `pygments:` <br> `2.5.2 -> 2.15.0` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""med",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13717:4405,Access,Access,4405,https://hail.is,https://github.com/hail-is/hail/pull/13717,2,['Access'],['Access']
Security,"BCONVERT-2979829) | `nbconvert:` <br> `5.6.1 -> 6.3.0b0` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **434/1000** <br/> **Why?** Has a fix available, CVSS 4.4 | Open Redirect <br/>[SNYK-PYTHON-NOTEBOOK-1041707](https://snyk.io/vuln/SNYK-PYTHON-NOTEBOOK-1041707) | `notebook:` <br> `5.7.16 -> 6.4.12` <br> | No | No Known Exploit ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | **589/1000** <br/> **Why?** Has a fix available, CVSS 7.5 | Information Exposure <br/>[SNYK-PYTHON-NOTEBOOK-2441824](https://snyk.io/vuln/SNYK-PYTHON-NOTEBOOK-2441824) | `notebook:` <br> `5.7.16 -> 6.4.12` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **449/1000** <br/> **Why?** Has a fix available, CVSS 4.7 | Access Restriction Bypass <br/>[SNYK-PYTHON-NOTEBOOK-2928995](https://snyk.io/vuln/SNYK-PYTHON-NOTEBOOK-2928995) | `notebook:` <br> `5.7.16 -> 6.4.12` <br> | No | No Known Exploit ; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **399/1000** <br/> **Why?** Has a fix available, CVSS 3.7 | Race Condition <br/>[SNYK-PYTHON-PROMPTTOOLKIT-6141120](https://snyk.io/vuln/SNYK-PYTHON-PROMPTTOOLKIT-6141120) | `prompt-toolkit:` <br> `1.0.18 -> 3.0.13` <br> | No | No Known Exploit ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | **696/1000** <br/> **Why?** Proof of Concept exploit, Has a fix available, CVSS 7.5 | Regular Expression Denial of Service (ReDoS) <br/>[SNYK-PYTHON-PYGMENTS-1086606](https://snyk.io/vuln/SNYK-PYTHON-PYGMENTS-1086606) | `pygments:` <br> `2.5.2 -> 2.15.0` <br> | No | Proof of Concept ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14205:5097,Access,Access,5097,https://hail.is,https://github.com/hail-is/hail/pull/14205,1,['Access'],['Access']
Security,"Based on conversation in Zulip: https://hail.zulipchat.com/#narrow/stream/123000-general/topic/Server.20hail.20version.20through.20API/near/226462327. Add version endpoint to ~~auth~~ query API. As suggested, I've added the the `make python-version-info` to generate the `hail_version`, but this requires the git history within the docker, as the short commit hash is added to the end. I've just cherry-picked the [merge commit](https://github.com/populationgenomics/hail/commit/700a0cf9d6e05827feca6bdd9c455e2b261e72db) from our populationgenomics fork.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10085:360,hash,hash,360,https://hail.is,https://github.com/hail-is/hail/pull/10085,1,['hash'],['hash']
Security,"Basically, I had no idea how RBAC worked. Now I have some idea. I now feel a bit uneasy about having the test namespace destroyed and recreated by batch deploy. Maybe when I better understand k8s security, I'll change to that. For now, we just grant the minimal permissions to delete any PVCs (i.e. hard drives, i.e. expensive shit) that are sitting around before we deploy a new batch system. I tested that this will succeed with `kubectl can-i --as system:serviceaccount:batch-pods:deploy-svc delete pvc -n test` and `-n batch-pods`. Don't ask my how I found out that the syntax to refer to the deploy-svc service account was that. I don't even remember where I stumbled across that.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5502:196,secur,security,196,https://hail.is,https://github.com/hail-is/hail/pull/5502,1,['secur'],['security']
Security,"Batch threads are closed after at most 30 minutes (meaning no more jobs may be submitted in that batch; ergo, crucially, no more jobs may depend on the output of jobs in the batch). The user can specify a shorter time-to-live via the `ttl` parameter. The batch server achieves this via a [scheduler](https://docs.python.org/3/library/sched.html) thread which runs scheduled events. When a batch is created a close event is scheduled for its TTL. This also exposes `is_open` in the JSON response to `GET /batches/<batch_id>` which the tests use to verify a batch has been closed.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5233:456,expose,exposes,456,https://hail.is,https://github.com/hail-is/hail/pull/5233,1,['expose'],['exposes']
Security,"Both of these were noted by Bernick as a part of his security review. 1. `local_infile`: if this is on, a client could in theory read any file on the instance by loading it into a table.; 2. `skip_show_database`: this disables `SHOW DATABASES` by default; we can still grant certain users (e.g. the admin-pod) the `SHOW DATABASES` privilege. A bit of security by obscurity, IMO, but it does not bother me much. I can always see the list of databases via the GCP console.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12835:53,secur,security,53,https://hail.is,https://github.com/hail-is/hail/pull/12835,2,['secur'],['security']
Security,"Brought up by TJ in a recent conversation. He wants to not use the browser to work on Jupyter notebooks for performance / IDE convenience reasons. From a brief look, there appear to be two issues in getting this to work. First, VS Code will need to be started with proxy flags. As its runtime is Electron, all Chromium flags will work, so could almost specify HAILCTL_CHROME=code hailctl connect ... , but this doesn't directly work because VS Code also needs a workspace (so the cli invocation will need to be slightly different). Second, password-less may not work without `disable_xsrf_check`. Relevant issue: https://github.com/microsoft/vscode-python/issues/7137. There may be ways to hijack a proxied localhost connection, so unless we fully understand those issues, if disable_xsrf_check is necessary to enable password-less, it would be better to generate a token.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/9067:540,password,password-less,540,https://hail.is,https://github.com/hail-is/hail/issues/9067,2,['password'],['password-less']
Security,"Builds on #3500 . This PR introduces support for sparse block matrices. The only new command exposed in Python is `sparsify_row_intervals`. Matrix product currently always results in a dense block matrix. Sparse block matrices also support transpose, diagonal, and all non-mathematical operations except filtering. Element-wise mathematical operations are currently supported if and only if they cannot transform zeroed blocks to non-zero blocks. For example, all forms of element-wise multiplication are supported,; and element-wise multiplication results in a sparse block matrix with block support equal to the intersection of that of the operands. On the other hand, scalar addition is not supported, and matrix addition is supported only between block matrices with the same block sparsity. Once this is in, I'll expose a couple more sparsifiers (rectangles, band) and also bring in parallel export of many rectangles to TSV from another branch, so that users can proceed with LD / fine mapping applications. Down the line I plan to support for all operations by expanding to union of block support, or to all blocks, for some operations. And matrix multiplication ought to return the minimal number of blocks as well.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3501:93,expose,exposed,93,https://hail.is,https://github.com/hail-is/hail/pull/3501,2,['expose'],"['expose', 'exposed']"
Security,Builds on: https://github.com/hail-is/hail/pull/2825. added RVD (should be UnpartitionedRVD) and OrderedRVD; allows to add new rvd types (HashedRVD); added list of partition files to current specs (to support safe object storage write strategy in presence of failure),MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2828:138,Hash,HashedRVD,138,https://hail.is,https://github.com/hail-is/hail/pull/2828,1,['Hash'],['HashedRVD']
Security,"Bumps [aiohttp-session](https://github.com/aio-libs/aiohttp_session) from 2.7.0 to 2.11.0.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/aio-libs/aiohttp_session/releases"">aiohttp-session's releases</a>.</em></p>; <blockquote>; <h2>v2.11.0</h2>; <ul>; <li>Support initialising <code>EncryptedCookieStorage</code> with <code>Fernet</code> object directly.</li>; <li>Fix an issue where the session would get reset before the cookie expiry.</li>; </ul>; <h2>v2.10.0</h2>; <ul>; <li>Typing support</li>; <li>Add samesite cookie option</li>; <li>Support aioredis 2</li>; </ul>; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/aio-libs/aiohttp-session/blob/master/CHANGES.txt"">aiohttp-session's changelog</a>.</em></p>; <blockquote>; <h1>2.11.0 (2021-01-31)</h1>; <ul>; <li>Support initialising <code>EncryptedCookieStorage</code> with <code>Fernet</code> object directly.</li>; <li>Fix an issue where the session would get reset before the cookie expiry.</li>; </ul>; <h1>2.10.0 (2021-12-30)</h1>; <ul>; <li>Typing support</li>; <li>Add samesite cookie option</li>; <li>Support aioredis 2</li>; </ul>; <h1>2.9.0 (2019-11-04)</h1>; <ul>; <li>Fix memcached expiring time (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_session/issues/398"">#398</a>)</li>; </ul>; <h1>2.8.0 (2019-09-17)</h1>; <ul>; <li>Make this compatible with Python 3.7+. Import from collections.abc, instead; of from collections. (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_session/issues/373"">#373</a>)</li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/aio-libs/aiohttp-session/commit/af0560812d3dc2043565de1108ac41b65caac7d0""><code>af05608</code></a> Release 2.11 (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_session/issues/673"">#673</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11544:331,Encrypt,EncryptedCookieStorage,331,https://hail.is,https://github.com/hail-is/hail/pull/11544,2,['Encrypt'],['EncryptedCookieStorage']
Security,"Bumps [aiohttp-session](https://github.com/aio-libs/aiohttp_session) from 2.7.0 to 2.12.0.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/aio-libs/aiohttp_session/releases"">aiohttp-session's releases</a>.</em></p>; <blockquote>; <h2>v2.12.0</h2>; <ul>; <li>Migrated from <code>aioredis</code> to <code>redis</code> (if using redis without installing; <code>aiohttp-session[aioredis]</code> then it will be necessary to manually install <code>redis</code>).</li>; </ul>; <h2>v2.11.0</h2>; <ul>; <li>Support initialising <code>EncryptedCookieStorage</code> with <code>Fernet</code> object directly.</li>; <li>Fix an issue where the session would get reset before the cookie expiry.</li>; </ul>; <h2>v2.10.0</h2>; <ul>; <li>Typing support</li>; <li>Add samesite cookie option</li>; <li>Support aioredis 2</li>; </ul>; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/aio-libs/aiohttp-session/blob/master/CHANGES.txt"">aiohttp-session's changelog</a>.</em></p>; <blockquote>; <h1>2.12.0 (2022-10-28)</h1>; <ul>; <li>Migrated from <code>aioredis</code> to <code>redis</code> (if using redis without installing; <code>aiohttp-session[aioredis]</code> then it will be necessary to manually install <code>redis</code>).</li>; </ul>; <h1>2.11.0 (2021-01-31)</h1>; <ul>; <li>Support initialising <code>EncryptedCookieStorage</code> with <code>Fernet</code> object directly.</li>; <li>Fix an issue where the session would get reset before the cookie expiry.</li>; </ul>; <h1>2.10.0 (2021-12-30)</h1>; <ul>; <li>Typing support</li>; <li>Add samesite cookie option</li>; <li>Support aioredis 2</li>; </ul>; <h1>2.9.0 (2019-11-04)</h1>; <ul>; <li>Fix memcached expiring time (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_session/issues/398"">#398</a>)</li>; </ul>; <h1>2.8.0 (2019-09-17)</h1>; <ul>; <li>Make this compatible with Python 3.7+. Import from collections.abc, instead; of",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12499:572,Encrypt,EncryptedCookieStorage,572,https://hail.is,https://github.com/hail-is/hail/pull/12499,1,['Encrypt'],['EncryptedCookieStorage']
Security,"Bumps [aiohttp](https://github.com/aio-libs/aiohttp) from 3.8.4 to 3.8.5.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/aio-libs/aiohttp/releases"">aiohttp's releases</a>.</em></p>; <blockquote>; <h2>3.8.5</h2>; <h2>Security bugfixes</h2>; <ul>; <li>; <p>Upgraded the vendored copy of llhttp_ to v8.1.1 -- by :user:<code>webknjaz</code>; and :user:<code>Dreamsorcerer</code>.</p>; <p>Thanks to :user:<code>sethmlarson</code> for reporting this and providing us with; comprehensive reproducer, workarounds and fixing details! For more; information, see; <a href=""https://github.com/aio-libs/aiohttp/security/advisories/GHSA-45c4-8wx5-qw6w"">https://github.com/aio-libs/aiohttp/security/advisories/GHSA-45c4-8wx5-qw6w</a>.</p>; <p>.. _llhttp: <a href=""https://llhttp.org"">https://llhttp.org</a></p>; <p>(<a href=""https://redirect.github.com/aio-libs/aiohttp/issues/7346"">#7346</a>)</p>; </li>; </ul>; <h2>Features</h2>; <ul>; <li>; <p>Added information to C parser exceptions to show which character caused the error. -- by :user:<code>Dreamsorcerer</code></p>; <p>(<a href=""https://redirect.github.com/aio-libs/aiohttp/issues/7366"">#7366</a>)</p>; </li>; </ul>; <h2>Bugfixes</h2>; <ul>; <li>; <p>Fixed a transport is :data:<code>None</code> error -- by :user:<code>Dreamsorcerer</code>.</p>; <p>(<a href=""https://redirect.github.com/aio-libs/aiohttp/issues/3355"">#3355</a>)</p>; </li>; </ul>; <hr />; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/aio-libs/aiohttp/blob/v3.8.5/CHANGES.rst"">aiohttp's changelog</a>.</em></p>; <blockquote>; <h1>3.8.5 (2023-07-19)</h1>; <h2>Security bugfixes</h2>; <ul>; <li>; <p>Upgraded the vendored copy of llhttp_ to v8.1.1 -- by :user:<code>webknjaz</code>; and :user:<code>Dreamsorcerer</code>.</p>; <p>Thanks to :user:<code>sethmlarson</code> for reporting this and providing us with; comprehensive reproducer, workarounds and fixing details! For mo",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13270:263,Secur,Security,263,https://hail.is,https://github.com/hail-is/hail/pull/13270,15,"['Secur', 'secur']","['Security', 'security']"
Security,"Bumps [authlib](https://github.com/lepture/authlib) from 0.11 to 0.15.5.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/lepture/authlib/releases"">authlib's releases</a>.</em></p>; <blockquote>; <h2>Version 0.15.5</h2>; <ul>; <li>Make Authlib compatible with latest httpx</li>; <li>Make Authlib compatible with latest werkzeug</li>; <li>Allow customize RFC7523 <code>alg</code> value</li>; </ul>; <h2>Version 0.15.4</h2>; <p>Security fix when JWT claims is None.</p>; <p>For example, JWT payload has <code>iss=None</code>:</p>; <pre><code>{; &quot;iss&quot;: None,; ...; }; </code></pre>; <p>But we need to decode it with claims:</p>; <pre><code>claims_options = {; 'iss': {'essential': True, 'values': ['required']}; }; jwt.decode(token, key, claims_options=claims_options); </code></pre>; <p>It didn't raise an error before this fix.</p>; <h2>Version 0.15.3</h2>; <p>Fixed <code>.authorize_access_token</code> for OAuth 1.0 services, via <a href=""https://github-redirect.dependabot.com/lepture/authlib/issues/308"">lepture/authlib#308</a></p>; <h2>Version 0.15.2</h2>; <p>Fixed httpx authentication bug via <a href=""https://github-redirect.dependabot.com/lepture/authlib/issues/283"">#283</a></p>; <h2>Version 0.15.1</h2>; <p>Backward compitable fix for using JWKs in JWT, via <a href=""https://github-redirect.dependabot.com/lepture/authlib/issues/280"">#280</a>.</p>; <h2>Version 0.15</h2>; <p>This is the last release before v1.0. In this release, we added more RFCs; implementations and did some refactors for JOSE:</p>; <ul>; <li>RFC8037: CFRG Elliptic Curve Diffie-Hellman (ECDH) and Signatures in JSON Object Signing and Encryption (JOSE)</li>; <li>RFC7638: JSON Web Key (JWK) Thumbprint</li>; </ul>; <p>We also fixed bugs for integrations:</p>; <ul>; <li>Fixed support for HTTPX&gt;=0.14.3</li>; <li>Added OAuth clients of HTTPX back via <a href=""https://github-redirect.dependabot.com/lepture/authlib/issues/270"">#270</a></li>; <li>Fixed parallel t",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11483:471,Secur,Security,471,https://hail.is,https://github.com/hail-is/hail/pull/11483,1,['Secur'],['Security']
Security,"Bumps [avro](https://github.com/apache/avro) from 1.11.0 to 1.11.1.; <details>; <summary>Commits</summary>; <ul>; <li>See full diff in <a href=""https://github.com/apache/avro/compare/release-1.11.0...release-1.11.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=avro&package-manager=pip&previous-version=1.11.0&new-version=1.11.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12069:497,secur,security-vulnerabilities,497,https://hail.is,https://github.com/hail-is/hail/pull/12069,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"Bumps [azure-identity](https://github.com/Azure/azure-sdk-for-python) from 1.6.0 to 1.8.0.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/Azure/azure-sdk-for-python/releases"">azure-identity's releases</a>.</em></p>; <blockquote>; <h2>azure-identity_1.8.0</h2>; <h2>1.8.0 (2022-03-01)</h2>; <h3>Bugs Fixed</h3>; <ul>; <li>; <p>Handle injected &quot;tenant_id&quot; and &quot;claims&quot; (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/23138"">#23138</a>)</p>; <p>&quot;tenant_id&quot; argument in get_token() method is only supported by:</p>; <ul>; <li><code>AuthorizationCodeCredential</code></li>; <li><code>AzureCliCredential</code></li>; <li><code>AzurePowerShellCredential</code></li>; <li><code>InteractiveBrowserCredential</code></li>; <li><code>DeviceCodeCredential</code></li>; <li><code>EnvironmentCredential</code></li>; <li><code>UsernamePasswordCredential</code></li>; </ul>; <p>it is ignored by other types of credentials.</p>; </li>; </ul>; <h3>Other Changes</h3>; <ul>; <li>Python 2.7 is no longer supported. Please use Python version 3.6 or later.</li>; </ul>; <h2>azure-identity_1.8.0b1</h2>; <h2>1.8.0b1 (2022-02-08)</h2>; <h3>Features Added</h3>; <ul>; <li>Added <code>validate_authority</code> support for msal client <a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/22625"">#22625</a></li>; <li>Added <code>resource_id</code> support for user-assigned managed identity <a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/22329"">#22329</a></li>; <li>Added <code>ClientAssertionCredential</code> support <a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/22328"">#22328</a></li>; </ul>; <h3>Other Changes</h3>; <ul>; <li>Python 2.7 is no longer supported. Please use Python version 3.6 or later.</li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11493:380,inject,injected,380,https://hail.is,https://github.com/hail-is/hail/pull/11493,4,"['Authoriz', 'inject']","['AuthorizationCodeCredential', 'injected']"
Security,"Bumps [azure-storage-blob](https://github.com/Azure/azure-sdk-for-python) from 12.11.0 to 12.13.1.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/Azure/azure-sdk-for-python/releases"">azure-storage-blob's releases</a>.</em></p>; <blockquote>; <h2>azure-storage-blob_12.13.1</h2>; <h2>12.13.1 (2022-08-04)</h2>; <h3>Bugs Fixed</h3>; <ul>; <li>Fixed two rare issues with ranged blob download when using client-side encryption V1 or V2.</li>; </ul>; <h2>azure-storage-blob_12.13.0</h2>; <h2>12.13.0 (2022-07-07)</h2>; <h3>Bugs Fixed</h3>; <ul>; <li>Stable release of features from 12.13.0b1.</li>; <li>Added support for deleting versions in <code>delete_blobs</code> by supplying <code>version_id</code>.</li>; </ul>; <h2>azure-storage-blob_12.13.0b1</h2>; <h2>12.13.0b1 (2022-06-15)</h2>; <h3>Features Added</h3>; <ul>; <li>Added support for service version 2021-08-06.</li>; <li>Added a new version of client-side encryption for blobs (version 2.0) which utilizes AES-GCM-256 encryption.; If you are currently using client-side encryption, it is <strong>highly recommended</strong> to switch to a form of server-side; encryption (Customer-Provided Key, Encryption Scope, etc.) or version 2.0 of client-side encryption. The encryption; version can be specified on any client constructor via the <code>encryption_version</code> keyword (<code>encryption_version='2.0'</code>).</li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/13989b5b1253e26f3f3ee24013a3013fea1bdf73""><code>13989b5</code></a> [Storage] Fix ranged download for client-side encryption (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/25522"">#25522</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/e90af4374bfd7c139737ad2888fcd269b3023520""><code>e90af43</code></a> DataLake funny dependency (<a href=""https://github-redirect.depen",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12109:459,encrypt,encryption,459,https://hail.is,https://github.com/hail-is/hail/pull/12109,2,['encrypt'],['encryption']
Security,"Bumps [azure-storage-blob](https://github.com/Azure/azure-sdk-for-python) from 12.8.1 to 12.10.0.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/Azure/azure-sdk-for-python/releases"">azure-storage-blob's releases</a>.</em></p>; <blockquote>; <h2>azure-storage-blob_12.10.0</h2>; <h2>12.10.0 (2022-03-08)</h2>; <p>This version and all future versions will require Python 3.6+. Python 2.7 is no longer supported.</p>; <h3>Stable release of preview features</h3>; <ul>; <li>Added support for service version 2021-02-12, 2021-04-10.</li>; <li>Account level SAS tokens now supports two new permissions:; <ul>; <li><code>permanent_delete</code></li>; <li><code>set_immutability_policy</code></li>; </ul>; </li>; <li>Encryption Scope is now supported for Sync Blob Copy (<code>copy_from_url()</code>).</li>; <li>Encryption Scope is now supported as a SAS permission.</li>; <li>Added support for blob names containing invalid XML characters.; Previously \uFFFE and \uFFFF would fail if present in blob name.</li>; <li>Added support for listing system containers with get_blob_containers().</li>; <li>Added support for <code>find_blobs_by_tags()</code> on a container.</li>; <li>Added support for <code>Find (f)</code> container SAS permission.</li>; </ul>; <h3>Bugs Fixed</h3>; <ul>; <li>Added all missing Service SAS permissions.</li>; <li>Fixed a bug that prevented <code>upload_blob()</code> from working with an OS pipe; reader stream on Linux. (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/23131"">#23131</a>)</li>; </ul>; <h2>azure-storage-blob_12.10.0b4</h2>; <h2>12.10.0b4 (2022-02-24)</h2>; <h3>Features Added</h3>; <ul>; <li>Updated clients to support both SAS and OAuth together.</li>; <li>Updated OAuth implementation to use the AAD scope returned in a Bearer challenge.</li>; </ul>; <h3>Bugs Fixed</h3>; <ul>; <li>Addressed a few <code>mypy</code> typing hint errors.</li>; </ul>; <h2>azure-storage-blob_12.10.0b3<",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11610:756,Encrypt,Encryption,756,https://hail.is,https://github.com/hail-is/hail/pull/11610,2,['Encrypt'],['Encryption']
Security,"Bumps [boto3](https://github.com/boto/boto3) from 1.26.6 to 1.26.8.; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/boto/boto3/blob/develop/CHANGELOG.rst"">boto3's changelog</a>.</em></p>; <blockquote>; <h1>1.26.8</h1>; <ul>; <li>api-change:<code>glue</code>: [<code>botocore</code>] Added links related to enabling job bookmarks.</li>; <li>api-change:<code>iot</code>: [<code>botocore</code>] This release add new api listRelatedResourcesForAuditFinding and new member type IssuerCertificates for Iot device device defender Audit.</li>; <li>api-change:<code>license-manager</code>: [<code>botocore</code>] AWS License Manager now supports onboarded Management Accounts or Delegated Admins to view granted licenses aggregated from all accounts in the organization.</li>; <li>api-change:<code>marketplace-catalog</code>: [<code>botocore</code>] Added three new APIs to support tagging and tag-based authorization: TagResource, UntagResource, and ListTagsForResource. Added optional parameters to the StartChangeSet API to support tagging a resource while making a request to create it.</li>; <li>api-change:<code>rekognition</code>: [<code>botocore</code>] Adding support for ImageProperties feature to detect dominant colors and image brightness, sharpness, and contrast, inclusion and exclusion filters for labels and label categories, new fields to the API response, &quot;aliases&quot; and &quot;categories&quot;</li>; <li>api-change:<code>securityhub</code>: [<code>botocore</code>] Documentation updates for Security Hub</li>; <li>api-change:<code>ssm-incidents</code>: [<code>botocore</code>] RelatedItems now have an ID field which can be used for referencing them else where. Introducing event references in TimelineEvent API and increasing maximum length of &quot;eventData&quot; to 12K characters.</li>; </ul>; <h1>1.26.7</h1>; <ul>; <li>api-change:<code>autoscaling</code>: [<code>botocore</code>] This release adds a new price capacity optimized al",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12458:566,Audit,Audit,566,https://hail.is,https://github.com/hail-is/hail/pull/12458,2,"['Audit', 'authoriz']","['Audit', 'authorization']"
Security,"Bumps [boto3](https://github.com/boto/boto3) from 1.26.7 to 1.26.15.; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/boto/boto3/blob/develop/CHANGELOG.rst"">boto3's changelog</a>.</em></p>; <blockquote>; <h1>1.26.15</h1>; <ul>; <li>bugfix:Endpoints: [<code>botocore</code>] Resolve endpoint with default partition when no region is set</li>; <li>bugfix:s3: [<code>botocore</code>] fixes missing x-amz-content-sha256 header for s3 object lambda</li>; <li>api-change:<code>appflow</code>: [<code>botocore</code>] Adding support for Amazon AppFlow to transfer the data to Amazon Redshift databases through Amazon Redshift Data API service. This feature will support the Redshift destination connector on both public and private accessible Amazon Redshift Clusters and Amazon Redshift Serverless.</li>; <li>api-change:<code>kinesisanalyticsv2</code>: [<code>botocore</code>] Support for Apache Flink 1.15 in Kinesis Data Analytics.</li>; </ul>; <h1>1.26.14</h1>; <ul>; <li>api-change:<code>route53</code>: [<code>botocore</code>] Amazon Route 53 now supports the Asia Pacific (Hyderabad) Region (ap-south-2) for latency records, geoproximity records, and private DNS for Amazon VPCs in that region.</li>; </ul>; <h1>1.26.13</h1>; <ul>; <li>api-change:<code>appflow</code>: [<code>botocore</code>] AppFlow provides a new API called UpdateConnectorRegistration to update a custom connector that customers have previously registered. With this API, customers no longer need to unregister and then register a connector to make an update.</li>; <li>api-change:<code>auditmanager</code>: [<code>botocore</code>] This release introduces a new feature for Audit Manager: Evidence finder. You can now use evidence finder to quickly query your evidence, and add the matching evidence results to an assessment report.</li>; <li>api-change:<code>chime-sdk-voice</code>: [<code>botocore</code>] Amazon Chime Voice Connector, Voice Connector Group and PSTN Audio Service APIs ar",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12498:766,access,accessible,766,https://hail.is,https://github.com/hail-is/hail/pull/12498,1,['access'],['accessible']
Security,"Bumps [boto3](https://github.com/boto/boto3) from 1.26.7 to 1.26.17.; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/boto/boto3/blob/develop/CHANGELOG.rst"">boto3's changelog</a>.</em></p>; <blockquote>; <h1>1.26.17</h1>; <ul>; <li>bugfix:dynamodb: Fixes duplicate serialization issue in DynamoDB BatchWriter</li>; <li>api-change:<code>backup</code>: [<code>botocore</code>] AWS Backup introduces support for legal hold and application stack backups. AWS Backup Audit Manager introduces support for cross-Region, cross-account reports.</li>; <li>api-change:<code>cloudwatch</code>: [<code>botocore</code>] Update cloudwatch client to latest version</li>; <li>api-change:<code>drs</code>: [<code>botocore</code>] Non breaking changes to existing APIs, and additional APIs added to support in-AWS failing back using AWS Elastic Disaster Recovery.</li>; <li>api-change:<code>ecs</code>: [<code>botocore</code>] This release adds support for ECS Service Connect, a new capability that simplifies writing and operating resilient distributed applications. This release updates the TaskDefinition, Cluster, Service mutation APIs with Service connect constructs and also adds a new ListServicesByNamespace API.</li>; <li>api-change:<code>efs</code>: [<code>botocore</code>] Update efs client to latest version</li>; <li>api-change:<code>iot-data</code>: [<code>botocore</code>] This release adds support for MQTT5 properties to AWS IoT HTTP Publish API.</li>; <li>api-change:<code>iot</code>: [<code>botocore</code>] Job scheduling enables the scheduled rollout of a Job with start and end times and a customizable end behavior when end time is reached. This is available for continuous and snapshot jobs. Added support for MQTT5 properties to AWS IoT TopicRule Republish Action.</li>; <li>api-change:<code>iotwireless</code>: [<code>botocore</code>] This release includes a new feature for customers to calculate the position of their devices by adding three new APIs",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12507:503,Audit,Audit,503,https://hail.is,https://github.com/hail-is/hail/pull/12507,1,['Audit'],['Audit']
Security,"Bumps [certifi](https://github.com/certifi/python-certifi) from 2022.9.24 to 2022.12.7.; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/certifi/python-certifi/commit/9e9e840925d7b8e76c76fdac1fab7e6e88c1c3b8""><code>9e9e840</code></a> 2022.12.07</li>; <li>See full diff in <a href=""https://github.com/certifi/python-certifi/compare/2022.09.24...2022.12.07"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=certifi&package-manager=pip&previous-version=2022.9.24&new-version=2022.12.7)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12549:675,secur,security-vulnerabilities,675,https://hail.is,https://github.com/hail-is/hail/pull/12549,6,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"Bumps [certifi](https://github.com/certifi/python-certifi) from 2023.5.7 to 2023.7.22.; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/certifi/python-certifi/commit/8fb96ed81f71e7097ed11bc4d9b19afd7ea5c909""><code>8fb96ed</code></a> 2023.07.22</li>; <li><a href=""https://github.com/certifi/python-certifi/commit/afe77220e0eaa722593fc5d294213ff5275d1b40""><code>afe7722</code></a> Bump actions/setup-python from 4.6.1 to 4.7.0 (<a href=""https://redirect.github.com/certifi/python-certifi/issues/230"">#230</a>)</li>; <li><a href=""https://github.com/certifi/python-certifi/commit/2038739ad56abec7aaddfa90ad2ce6b3ed7f5c7b""><code>2038739</code></a> Bump dessant/lock-threads from 3.0.0 to 4.0.1 (<a href=""https://redirect.github.com/certifi/python-certifi/issues/229"">#229</a>)</li>; <li><a href=""https://github.com/certifi/python-certifi/commit/44df761f4c09d19f32b3cc09208a739043a5e25b""><code>44df761</code></a> Hash pin Actions and enable dependabot (<a href=""https://redirect.github.com/certifi/python-certifi/issues/228"">#228</a>)</li>; <li>See full diff in <a href=""https://github.com/certifi/python-certifi/compare/2023.05.07...2023.07.22"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=certifi&package-manager=pip&previous-version=2023.5.7&new-version=2023.7.22)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will rec",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13298:936,Hash,Hash,936,https://hail.is,https://github.com/hail-is/hail/pull/13298,6,['Hash'],['Hash']
Security,"Bumps [cffi](http://cffi.readthedocs.org) from 1.15.0 to 1.15.1. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=cffi&package-manager=pip&previous-version=1.15.0&new-version=1.15.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself). </details>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12004:296,secur,security-vulnerabilities,296,https://hail.is,https://github.com/hail-is/hail/pull/12004,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"Bumps [cryptography](https://github.com/pyca/cryptography) from 38.0.4 to 39.0.1.; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/pyca/cryptography/blob/main/CHANGELOG.rst"">cryptography's changelog</a>.</em></p>; <blockquote>; <p>39.0.1 - 2023-02-07</p>; <pre><code>; * **SECURITY ISSUE** - Fixed a bug where ``Cipher.update_into`` accepted Python; buffer protocol objects, but allowed immutable buffers. **CVE-2023-23931**; * Updated Windows, macOS, and Linux wheels to be compiled with OpenSSL 3.0.8.; <p>.. _v39-0-0:</p>; <p>39.0.0 - 2023-01-01; </code></pre></p>; <ul>; <li><strong>BACKWARDS INCOMPATIBLE:</strong> Support for OpenSSL 1.1.0 has been removed.; Users on older version of OpenSSL will need to upgrade.</li>; <li><strong>BACKWARDS INCOMPATIBLE:</strong> Dropped support for LibreSSL &lt; 3.5. The new; minimum LibreSSL version is 3.5.0. Going forward our policy is to support; versions of LibreSSL that are available in versions of OpenBSD that are; still receiving security support.</li>; <li><strong>BACKWARDS INCOMPATIBLE:</strong> Removed the <code>encode_point</code> and; <code>from_encoded_point</code> methods on; :class:<code>~cryptography.hazmat.primitives.asymmetric.ec.EllipticCurvePublicNumbers</code>,; which had been deprecated for several years.; :meth:<code>~cryptography.hazmat.primitives.asymmetric.ec.EllipticCurvePublicKey.public_bytes</code>; and; :meth:<code>~cryptography.hazmat.primitives.asymmetric.ec.EllipticCurvePublicKey.from_encoded_point</code>; should be used instead.</li>; <li><strong>BACKWARDS INCOMPATIBLE:</strong> Support for using MD5 or SHA1 in; :class:<code>~cryptography.x509.CertificateBuilder</code>, other X.509 builders, and; PKCS7 has been removed.</li>; <li><strong>BACKWARDS INCOMPATIBLE:</strong> Dropped support for macOS 10.10 and 10.11, macOS; users must upgrade to 10.12 or newer.</li>; <li><strong>ANNOUNCEMENT:</strong> The next version of <code>cryptography</code> (40.0) will change;",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12668:314,SECUR,SECURITY,314,https://hail.is,https://github.com/hail-is/hail/pull/12668,8,"['SECUR', 'secur']","['SECURITY', 'security']"
Security,"Bumps [cryptography](https://github.com/pyca/cryptography) from 40.0.2 to 41.0.0.; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/pyca/cryptography/blob/main/CHANGELOG.rst"">cryptography's changelog</a>.</em></p>; <blockquote>; <p>41.0.0 - 2023-05-30</p>; <pre><code>; * **BACKWARDS INCOMPATIBLE:** Support for OpenSSL less than 1.1.1d has been; removed. Users on older version of OpenSSL will need to upgrade.; * **BACKWARDS INCOMPATIBLE:** Support for Python 3.6 has been removed.; * **BACKWARDS INCOMPATIBLE:** Dropped support for LibreSSL &lt; 3.6.; * Updated the minimum supported Rust version (MSRV) to 1.56.0, from 1.48.0.; * Updated Windows, macOS, and Linux wheels to be compiled with OpenSSL 3.1.1.; * Added support for the :class:`~cryptography.x509.OCSPAcceptableResponses`; OCSP extension.; * Added support for the :class:`~cryptography.x509.MSCertificateTemplate`; proprietary Microsoft certificate extension.; * Implemented support for equality checks on all asymmetric public key types.; * Added support for ``aes256-gcm@openssh.com`` encrypted keys in; :func:`~cryptography.hazmat.primitives.serialization.load_ssh_private_key`.; * Added support for obtaining X.509 certificate signature algorithm parameters; (including PSS) via; :meth:`~cryptography.x509.Certificate.signature_algorithm_parameters`.; * Support signing :class:`~cryptography.hazmat.primitives.asymmetric.padding.PSS`; X.509 certificates via the new keyword-only argument ``rsa_padding`` on; :meth:`~cryptography.x509.CertificateBuilder.sign`.; * Added support for; :class:`~cryptography.hazmat.primitives.ciphers.aead.ChaCha20Poly1305`; on BoringSSL.; <p>.. _v40-0-2:; </code></pre></p>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/pyca/cryptography/commit/c4d494fd3ee907316bd846e90cbf4a8df75a25ac""><code>c4d494f</code></a> 41.0.0 version bump (<a href=""https://redirect.github.com/pyca/cryptography/issues/8991"">#8",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13141:942,certificate,certificate,942,https://hail.is,https://github.com/hail-is/hail/pull/13141,3,['certificate'],['certificate']
Security,"Bumps [cryptography](https://github.com/pyca/cryptography) from 40.0.2 to 41.0.1.; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/pyca/cryptography/blob/main/CHANGELOG.rst"">cryptography's changelog</a>.</em></p>; <blockquote>; <p>41.0.1 - 2023-06-01</p>; <pre><code>; * Temporarily allow invalid ECDSA signature algorithm parameters in X.509; certificates, which are generated by older versions of Java.; * Allow null bytes in pass phrases when serializing private keys.; <p>.. _v41-0-0:</p>; <p>41.0.0 - 2023-05-30; </code></pre></p>; <ul>; <li><strong>BACKWARDS INCOMPATIBLE:</strong> Support for OpenSSL less than 1.1.1d has been; removed. Users on older version of OpenSSL will need to upgrade.</li>; <li><strong>BACKWARDS INCOMPATIBLE:</strong> Support for Python 3.6 has been removed.</li>; <li><strong>BACKWARDS INCOMPATIBLE:</strong> Dropped support for LibreSSL &lt; 3.6.</li>; <li>Updated the minimum supported Rust version (MSRV) to 1.56.0, from 1.48.0.</li>; <li>Updated Windows, macOS, and Linux wheels to be compiled with OpenSSL 3.1.1.</li>; <li>Added support for the :class:<code>~cryptography.x509.OCSPAcceptableResponses</code>; OCSP extension.</li>; <li>Added support for the :class:<code>~cryptography.x509.MSCertificateTemplate</code>; proprietary Microsoft certificate extension.</li>; <li>Implemented support for equality checks on all asymmetric public key types.</li>; <li>Added support for <code>aes256-gcm@openssh.com</code> encrypted keys in; :func:<code>~cryptography.hazmat.primitives.serialization.load_ssh_private_key</code>.</li>; <li>Added support for obtaining X.509 certificate signature algorithm parameters; (including PSS) via; :meth:<code>~cryptography.x509.Certificate.signature_algorithm_parameters</code>.</li>; <li>Support signing :class:<code>~cryptography.hazmat.primitives.asymmetric.padding.PSS</code>; X.509 certificates via the new keyword-only argument <code>rsa_padding</code> on; :meth:<code>~cryptography.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13146:385,certificate,certificates,385,https://hail.is,https://github.com/hail-is/hail/pull/13146,1,['certificate'],['certificates']
Security,"Bumps [cryptography](https://github.com/pyca/cryptography) from 41.0.1 to 41.0.2.; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/pyca/cryptography/blob/main/CHANGELOG.rst"">cryptography's changelog</a>.</em></p>; <blockquote>; <p>41.0.2 - 2023-07-10</p>; <pre><code>; * Fixed bugs in creating and parsing SSH certificates where critical options; with values were handled incorrectly. Certificates are now created correctly; and parsing accepts correct values as well as the previously generated; invalid forms with a warning. In the next release, support for parsing these; invalid forms will be removed.; <p>.. _v41-0-1:; </code></pre></p>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/pyca/cryptography/commit/7431db737cf0407560fac689d24f1d2e5efc349d""><code>7431db7</code></a> bump for 41.0.2 (<a href=""https://redirect.github.com/pyca/cryptography/issues/9215"">#9215</a>)</li>; <li><a href=""https://github.com/pyca/cryptography/commit/e190ef190525999d1f599cf8c3aef5cb7f3a8bc4""><code>e190ef1</code></a> Backport ssh cert fix (<a href=""https://redirect.github.com/pyca/cryptography/issues/9211"">#9211</a>)</li>; <li><a href=""https://github.com/pyca/cryptography/commit/bb204c8ca7bc0df0c24b6f6c1f59ed5f5bee9226""><code>bb204c8</code></a> Backport: Added PyPy 3.10 to CI (<a href=""https://redirect.github.com/pyca/cryptography/issues/8933"">#8933</a>) (<a href=""https://redirect.github.com/pyca/cryptography/issues/9210"">#9210</a>)</li>; <li>See full diff in <a href=""https://github.com/pyca/cryptography/compare/41.0.1...41.0.2"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=cryptography&package-manager=pip&previous-version=41.0.1&new-version=41.0.2)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-score",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13244:351,certificate,certificates,351,https://hail.is,https://github.com/hail-is/hail/pull/13244,6,"['Certificate', 'certificate']","['Certificates', 'certificates']"
Security,"Bumps [cryptography](https://github.com/pyca/cryptography) from 41.0.5 to 41.0.6.; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/pyca/cryptography/blob/main/CHANGELOG.rst"">cryptography's changelog</a>.</em></p>; <blockquote>; <p>41.0.6 - 2023-11-27</p>; <pre><code>; * Fixed a null-pointer-dereference and segfault that could occur when loading; certificates from a PKCS#7 bundle. Credit to **pkuzco** for reporting the; issue. **CVE-2023-49083**; <p>.. _v41-0-5:; </code></pre></p>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/pyca/cryptography/commit/f09c261ca10a31fe41b1262306db7f8f1da0e48a""><code>f09c261</code></a> 41.0.6 release (<a href=""https://redirect.github.com/pyca/cryptography/issues/9927"">#9927</a>)</li>; <li>See full diff in <a href=""https://github.com/pyca/cryptography/compare/41.0.5...41.0.6"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=cryptography&package-manager=pip&previous-version=41.0.5&new-version=41.0.6)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14046:389,certificate,certificates,389,https://hail.is,https://github.com/hail-is/hail/pull/14046,3,['certificate'],['certificates']
Security,"Bumps [docutils](https://docutils.sourceforge.io/) from 0.16 to 0.19. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=docutils&package-manager=pip&previous-version=0.16&new-version=0.19)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself). </details>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12528:301,secur,security-vulnerabilities,301,https://hail.is,https://github.com/hail-is/hail/pull/12528,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"Bumps [flask-cors](https://github.com/corydolphin/flask-cors) from 3.0.8 to 3.0.9.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/corydolphin/flask-cors/releases"">flask-cors's releases</a>.</em></p>; <blockquote>; <h2>Release 3.0.9</h2>; <h3>Security</h3>; <ul>; <li>Escape path before evaluating resource rules (thanks <a href=""https://github.com/praetorian-colby-morgan""><code>@​praetorian-colby-morgan</code></a>). Prior to this, flask-cors incorrectly; evaluated CORS resource matching before path expansion. E.g. &quot;/api/../foo.txt&quot; would incorrectly match resources for; &quot;/api/*&quot; whereas the path actually expands simply to &quot;/foo.txt&quot;</li>; </ul>; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/corydolphin/flask-cors/blob/master/CHANGELOG.md"">flask-cors's changelog</a>.</em></p>; <blockquote>; <h2>3.0.9</h2>; <h3>Security</h3>; <ul>; <li>Escape path before evaluating resource rules (thanks to Colby Morgan). Prior to this, flask-cors incorrectly; evaluated CORS resource matching before path expansion. E.g. &quot;/api/../foo.txt&quot; would incorrectly match resources for; &quot;/api/*&quot; whereas the path actually expands simply to &quot;/foo.txt&quot;</li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/corydolphin/flask-cors/commit/91babb941e07a1f45636bdcb75675f13ce1503a2""><code>91babb9</code></a> Update Api docs for credentialed requests (<a href=""https://github-redirect.dependabot.com/corydolphin/flask-cors/issues/221"">#221</a>)</li>; <li><a href=""https://github.com/corydolphin/flask-cors/commit/522d98936f3995480fe3132b55415d74298d6790""><code>522d989</code></a> Release version 3.0.9 (<a href=""https://github-redirect.dependabot.com/corydolphin/flask-cors/issues/273"">#273</a>)</li>; <li><a href=""https://github.com/corydolphin/flask-cors/commit/67c4b2cc98ae87cf1fa",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10464:289,Secur,Security,289,https://hail.is,https://github.com/hail-is/hail/pull/10464,1,['Secur'],['Security']
Security,"Bumps [follow-redirects](https://github.com/follow-redirects/follow-redirects) from 1.14.7 to 1.14.8.; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/follow-redirects/follow-redirects/commit/3d81dc3237b4ffe8b722bb3d1c70a7866657166e""><code>3d81dc3</code></a> Release version 1.14.8 of the npm package.</li>; <li><a href=""https://github.com/follow-redirects/follow-redirects/commit/62e546a99c07c3ee5e4e0718c84a6ca127c5c445""><code>62e546a</code></a> Drop confidential headers across schemes.</li>; <li>See full diff in <a href=""https://github.com/follow-redirects/follow-redirects/compare/v1.14.7...v1.14.8"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=follow-redirects&package-manager=npm_and_yarn&previous-version=1.14.7&new-version=1.14.8)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependab",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11364:482,confidential,confidential,482,https://hail.is,https://github.com/hail-is/hail/pull/11364,6,"['confidential', 'secur']","['confidential', 'security-updates', 'security-vulnerabilities']"
Security,"Bumps [gidgethub](https://github.com/brettcannon/gidgethub) from 4.2.0 to 5.2.1.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/brettcannon/gidgethub/releases"">gidgethub's releases</a>.</em></p>; <blockquote>; <h2>5.2.1</h2>; <ul>; <li>; <p>Fix cgi and importlib_resources deprecations.; [PR <a href=""https://github-redirect.dependabot.com/brettcannon/gidgethub/issues/185"">#185</a>](<a href=""https://github-redirect.dependabot.com/brettcannon/gidgethub/pull/185"">brettcannon/gidgethub#185</a>)</p>; </li>; <li>; <p>Add support for Python 3.11 and drop EOL Python 3.6; [PR <a href=""https://github-redirect.dependabot.com/brettcannon/gidgethub/issues/184"">#184</a>](<a href=""https://github-redirect.dependabot.com/brettcannon/gidgethub/pull/184"">brettcannon/gidgethub#184</a>)</p>; </li>; </ul>; <h2>5.2.0</h2>; <ul>; <li>Make the minimum version of PyJWT be v2.4.0.</li>; </ul>; <h2>5.1.0</h2>; <ul>; <li>; <p>Use <code>X-Hub-Signature-256</code> header for webhook validation when available.; ([PR <a href=""https://github-redirect.dependabot.com/brettcannon/gidgethub/issues/160"">#160</a>](<a href=""https://github-redirect.dependabot.com/brettcannon/gidgethub/pull/160"">brettcannon/gidgethub#160</a>)).</p>; </li>; <li>; <p>The documentation is now built using Sphinx v&gt;= 4.0.0.; ([Issue <a href=""https://github-redirect.dependabot.com/brettcannon/gidgethub/issues/143"">#143</a>](<a href=""https://github-redirect.dependabot.com/brettcannon/gidgethub/issues/143"">brettcannon/gidgethub#143</a>))</p>; </li>; <li>; <p><code>gidgethub.abc.GitHubAPI.getiter</code> now accepts <code>iterable_key</code> parameter; in order to support the Checks API.; ([Issue <a href=""https://github-redirect.dependabot.com/brettcannon/gidgethub/issues/164"">#164</a>](<a href=""https://github-redirect.dependabot.com/brettcannon/gidgethub/issues/164"">brettcannon/gidgethub#164</a>))</p>; </li>; <li>; <p>Accept HTTP 202 ACCEPTED as successful.; ([PR <a href=""https://github",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12328:1013,validat,validation,1013,https://hail.is,https://github.com/hail-is/hail/pull/12328,1,['validat'],['validation']
Security,"Bumps [htsjdk](https://github.com/samtools/htsjdk) from 2.24.1 to 3.0.1.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/samtools/htsjdk/releases"">htsjdk's releases</a>.</em></p>; <blockquote>; <h2>3.0.1</h2>; <p>Fix for a long standing vulnerability around temporary directory creation which could expose data to malicious users with access to a shared system. See for more information <a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1617"">#1617</a></p>; <p>4a4024a97 Fix temporary directory hijacking or temporary directory information disclosure (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1621"">#1621</a>); 9fd0ecf21 Disable codecov until we can fix the uploader (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1622"">#1622</a>); 347c0ac57 Fix EdgeReadIterator (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1616"">#1616</a>); d15a5bacb Added ULTIMA and ELEMENT as valid value for RG-PL according to SAM spec. (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1619"">#1619</a>)</p>; <h2>3.0.0</h2>; <p>Htsjdk 3.0.0: Revenge of the Simple Allele</p>; <p>This is the first htsjdk with a major version increase in a long time. We bumped it to indicate there are some breaking changes that will potentially require downstream code changes. Notably, <code>Allele</code> became an interface instead of a concrete class. <code>SimpleAllele</code> may be used as a replacement if you have classes which previously subclassed allele.</p>; <p>New Plugin Infrastructure:; 6a60de7c2 Move API marker annotations into new annotation package. (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1558"">#1558</a>); 7ac95d5f7 Plugin framework and interfaces for versioned file format codecs (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1525"">#1525</a>); d40fe5412 Beta implementation of Bundles. (<a hre",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12229:345,expose,expose,345,https://hail.is,https://github.com/hail-is/hail/pull/12229,2,"['access', 'expose']","['access', 'expose']"
Security,"Bumps [jinja2](https://github.com/pallets/jinja) from 3.1.2 to 3.1.3.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/pallets/jinja/releases"">jinja2's releases</a>.</em></p>; <blockquote>; <h2>3.1.3</h2>; <p>This is a fix release for the 3.1.x feature branch.</p>; <ul>; <li>Fix for <a href=""https://github.com/pallets/jinja/security/advisories/GHSA-h5c8-rqwp-cp95"">GHSA-h5c8-rqwp-cp95</a>. You are affected if you are using <code>xmlattr</code> and passing user input as attribute keys.</li>; <li>Changes: <a href=""https://jinja.palletsprojects.com/en/3.1.x/changes/#version-3-1-3"">https://jinja.palletsprojects.com/en/3.1.x/changes/#version-3-1-3</a></li>; <li>Milestone: <a href=""https://github.com/pallets/jinja/milestone/15?closed=1"">https://github.com/pallets/jinja/milestone/15?closed=1</a></li>; </ul>; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/pallets/jinja/blob/main/CHANGES.rst"">jinja2's changelog</a>.</em></p>; <blockquote>; <h2>Version 3.1.3</h2>; <p>Released 2024-01-10</p>; <ul>; <li>Fix compiler error when checking if required blocks in parent templates are; empty. :pr:<code>1858</code></li>; <li><code>xmlattr</code> filter does not allow keys with spaces. GHSA-h5c8-rqwp-cp95</li>; <li>Make error messages stemming from invalid nesting of <code>{% trans %}</code> blocks; more helpful. :pr:<code>1918</code></li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/pallets/jinja/commit/d9de4bb215fd1cc8092a410fb834c7c4060b1fc1""><code>d9de4bb</code></a> release version 3.1.3</li>; <li><a href=""https://github.com/pallets/jinja/commit/50124e16561f17f6c1ec85a692f6551418971cdc""><code>50124e1</code></a> skip test pypi</li>; <li><a href=""https://github.com/pallets/jinja/commit/9ea7222ef3f184480be0d0884e30ccfb4172b17b""><code>9ea7222</code></a> use trusted publishing</li>; <li><a href=""https://github.c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14144:371,secur,security,371,https://hail.is,https://github.com/hail-is/hail/pull/14144,3,['secur'],['security']
Security,"Bumps [jinja2](https://github.com/pallets/jinja) from 3.1.3 to 3.1.4.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/pallets/jinja/releases"">jinja2's releases</a>.</em></p>; <blockquote>; <h2>3.1.4</h2>; <p>This is the Jinja 3.1.4 security release, which fixes security issues and bugs but does not otherwise change behavior and should not result in breaking changes.</p>; <p>PyPI: <a href=""https://pypi.org/project/Jinja2/3.1.4/"">https://pypi.org/project/Jinja2/3.1.4/</a>; Changes: <a href=""https://jinja.palletsprojects.com/en/3.1.x/changes/#version-3-1-4"">https://jinja.palletsprojects.com/en/3.1.x/changes/#version-3-1-4</a></p>; <ul>; <li>The <code>xmlattr</code> filter does not allow keys with <code>/</code> solidus, <code>&gt;</code> greater-than sign, or <code>=</code> equals sign, in addition to disallowing spaces. Regardless of any validation done by Jinja, user input should never be used as keys to this filter, or must be separately validated first. GHSA-h75v-3vvj-5mfj</li>; </ul>; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/pallets/jinja/blob/main/CHANGES.rst"">jinja2's changelog</a>.</em></p>; <blockquote>; <h2>Version 3.1.4</h2>; <p>Released 2024-05-05</p>; <ul>; <li>The <code>xmlattr</code> filter does not allow keys with <code>/</code> solidus, <code>&gt;</code>; greater-than sign, or <code>=</code> equals sign, in addition to disallowing spaces.; Regardless of any validation done by Jinja, user input should never be used; as keys to this filter, or must be separately validated first.; :ghsa:<code>h75v-3vvj-5mfj</code></li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/pallets/jinja/commit/dd4a8b5466d8790540c181590b14db4d4d889d57""><code>dd4a8b5</code></a> release version 3.1.4</li>; <li><a href=""https://github.com/pallets/jinja/commit/0668239dc6b44ef38e7a6c9f91f312fd4ca581cb""><",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14526:278,secur,security,278,https://hail.is,https://github.com/hail-is/hail/pull/14526,12,"['secur', 'validat']","['security', 'validated', 'validation']"
Security,"Bumps [jna](https://github.com/java-native-access/jna) from 5.6.0 to 5.12.1.; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/java-native-access/jna/blob/master/CHANGES.md"">jna's changelog</a>.</em></p>; <blockquote>; <h1>Release 5.12.1</h1>; <h2>Bug Fixes</h2>; <ul>; <li><a href=""https://github-redirect.dependabot.com/java-native-access/jna/issues/1447"">#1447</a>: Null-check cleanable in <code>c.s.j.Memory#close</code> - <a href=""https://github.com/dbwiddis""><code>@​dbwiddis</code></a>.</li>; </ul>; <h1>Release 5.12.0</h1>; <h2>Features</h2>; <ul>; <li><a href=""https://github-redirect.dependabot.com/java-native-access/jna/pull/1433"">#1433</a>: Add <code>CFEqual</code>, <code>CFDictionaryRef.ByReference</code>, <code>CFStringRef.ByReference</code> to <code>c.s.j.p.mac.CoreFoundation</code> - <a href=""https://github.com/shalupov""><code>@​shalupov</code></a></li>; <li><a href=""https://github-redirect.dependabot.com/java-native-access/jna/issues/978"">#978</a>: Remove use of finalizers in JNA and improve concurrency for <code>Memory</code>, <code>CallbackReference</code> and <code>NativeLibrary</code> - <a href=""https://github.com/matthiasblaesing""><code>@​matthiasblaesing</code></a>.</li>; <li><a href=""https://github-redirect.dependabot.com/java-native-access/jna/pull/1440"">#1440</a>: Support for LoongArch64 - <a href=""https://github.com/Panxuefeng-loongson""><code>@​Panxuefeng-loongson</code></a>.</li>; <li><a href=""https://github-redirect.dependabot.com/java-native-access/jna/pull/1444"">#1444</a>: Update embedded libffi to 1f14b3fa92d4442a60233e9596ddec428a985e3c and rebuild native libraries - <a href=""https://github.com/matthiasblaesing""><code>@​matthiasblaesing</code></a>.</li>; </ul>; <h2>Bug Fixes</h2>; <ul>; <li><a href=""https://github-redirect.dependabot.com/java-native-access/jna/pull/1438"">#1438</a>: Handle arrays in structures with differing size - <a href=""https://github.com/matthiasblaesing""><code>@​matthiasblaesing</",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12438:43,access,access,43,https://hail.is,https://github.com/hail-is/hail/pull/12438,4,['access'],['access']
Security,"Bumps [jupyter-lsp](https://github.com/jupyter-lsp/jupyterlab-lsp) from 2.2.1 to 2.2.2.; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/jupyter-lsp/jupyterlab-lsp/blob/main/CHANGELOG.md"">jupyter-lsp's changelog</a>.</em></p>; <blockquote>; <h3><code>jupyter-lsp 2.2.2</code></h3>; <ul>; <li>bug fixes:; <ul>; <li>address warning about renamed <code>extension_points</code> (<a href=""https://redirect.github.com/jupyter-lsp/jupyterlab-lsp/issues/1035"">#1035</a>)</li>; <li>fix compatibility with jupyter server 1.x</li>; <li>fix an authentication-related security vulnerability (see <a href=""https://github.com/jupyter-lsp/jupyterlab-lsp/security/advisories/GHSA-4qhp-652w-c22x"">the advisory</a> for details)</li>; </ul>; </li>; <li>enhancements:; <ul>; <li>add authorization support (<code>lsp</code> resource, jupyter-server v2+ only) - this allows server operators for fine grained access control, e.g. in case if specific users (such as guest or read-only users) should not be allowed to access LSP; this is in addition to authentication fixes</li>; </ul>; </li>; </ul>; <h3><code>@jupyter-lsp/jupyterlab-lsp 5.0.1</code></h3>; <ul>; <li>bug fixes:; <ul>; <li>fix false “undefined name” in <code>%%time</code> and <code>%%capture</code> magics <a href=""https://redirect.github.com/jupyter-lsp/jupyterlab-lsp/issues/1007"">#1007</a> (thanks <a href=""https://github.com/i-aki-y""><code>@​i-aki-y</code></a>!)</li>; <li>fix completion items for paths and other long items being cut off <a href=""https://redirect.github.com/jupyter-lsp/jupyterlab-lsp/issues/1025"">#1025</a></li>; <li>workaround issue with markdown lost on edit <a href=""https://redirect.github.com/jupyter-lsp/jupyterlab-lsp/issues/1016"">#1016</a></li>; <li>fix latex/Greek letters insertion and other completions which do not match prefix (do not pre-filter completions from kernel) <a href=""https://redirect.github.com/jupyter-lsp/jupyterlab-lsp/issues/1022"">#1022</a></li>; <li>fix completion",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14171:573,authenticat,authentication-related,573,https://hail.is,https://github.com/hail-is/hail/pull/14171,5,"['access', 'authenticat', 'authoriz', 'secur']","['access', 'authentication-related', 'authorization', 'security']"
Security,"Bumps [jupyterlab](https://github.com/jupyterlab/jupyterlab) from 4.0.9 to 4.0.11.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/jupyterlab/jupyterlab/releases"">jupyterlab's releases</a>.</em></p>; <blockquote>; <h2>v4.0.11</h2>; <h2>4.0.11</h2>; <p>(<a href=""https://github.com/jupyterlab/jupyterlab/compare/v4.0.10...0708330843fd087134a239d2ad6005b1d543e246"">Full Changelog</a>)</p>; <h3>Security fixes</h3>; <ul>; <li>Potential authentication and CSRF tokens leak in JupyterLab (<a href=""https://github.com/jupyterlab/jupyterlab/security/advisories/GHSA-44cc-43rp-5947"">GHSA-44cc-43rp-5947</a>)</li>; <li>SXSS in Markdown Preview (<a href=""https://github.com/jupyterlab/jupyterlab/security/advisories/GHSA-4m77-cmpx-vjc4"">GHSA-4m77-cmpx-vjc4</a>)</li>; </ul>; <h3>Bugs fixed</h3>; <ul>; <li>Fixes focus indicator on input checkbox for Firefox <a href=""https://redirect.github.com/jupyterlab/jupyterlab/pull/15612"">#15612</a> (<a href=""https://github.com/alden-ilao""><code>@​alden-ilao</code></a>)</li>; </ul>; <h3>Documentation improvements</h3>; <ul>; <li>Fix link to yarn docs in extension migration guide <a href=""https://redirect.github.com/jupyterlab/jupyterlab/pull/15640"">#15640</a> (<a href=""https://github.com/krassowski""><code>@​krassowski</code></a>)</li>; </ul>; <h3>Contributors to this release</h3>; <p>(<a href=""https://github.com/jupyterlab/jupyterlab/graphs/contributors?from=2023-12-29&amp;to=2024-01-19&amp;type=c"">GitHub contributors page for this release</a>)</p>; <p><a href=""https://github.com/search?q=repo%3Ajupyterlab%2Fjupyterlab+involves%3Abrichet+updated%3A2023-12-29..2024-01-19&amp;type=Issues""><code>@​brichet</code></a> | <a href=""https://github.com/search?q=repo%3Ajupyterlab%2Fjupyterlab+involves%3Afcollonval+updated%3A2023-12-29..2024-01-19&amp;type=Issues""><code>@​fcollonval</code></a> | <a href=""https://github.com/search?q=repo%3Ajupyterlab%2Fjupyterlab+involves%3Agithub-actions+updated%3A2023-12-29..2024-01",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14184:438,Secur,Security,438,https://hail.is,https://github.com/hail-is/hail/pull/14184,4,"['Secur', 'authenticat', 'secur']","['Security', 'authentication', 'security']"
Security,"Bumps [keyrings-alt](https://github.com/jaraco/keyrings.alt) from 3.5.2 to 4.2.0.; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/jaraco/keyrings.alt/blob/main/CHANGES.rst"">keyrings-alt's changelog</a>.</em></p>; <blockquote>; <h1>v4.2.0</h1>; <p><a href=""https://github-redirect.dependabot.com/jaraco/keyrings.alt/issues/46"">#46</a>: EncryptedFileKeyring now supports both pycryptodome and; pycryptodomex (preferring the latter).</p>; <h1>v4.1.2</h1>; <p>Updated to work with keyring 23.9+ (no longer depending on properties; module).</p>; <h1>v4.1.1</h1>; <p>Refresh package metadata.</p>; <p>Enrolled with Tidelift.</p>; <h1>v4.1.0</h1>; <p><a href=""https://github-redirect.dependabot.com/jaraco/keyrings.alt/issues/44"">#44</a>: Bump upper bound on pyfs.</p>; <p>Refresh package metadata.</p>; <h1>v4.0.2</h1>; <p><a href=""https://github-redirect.dependabot.com/jaraco/keyrings.alt/issues/43"">#43</a>: Tests are no longer included in the install.</p>; <h1>v4.0.1</h1>; <p>Package refresh and minor cleanup.</p>; <h1>v4.0.0</h1>; <p><a href=""https://github-redirect.dependabot.com/jaraco/keyrings.alt/issues/41"">#41</a>: Instead of PyCrypto or PyCryptodome, the encrypting backend; now relies on PyCryptodomex.</p>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/jaraco/keyrings.alt/commit/a2ef1a8e15859bb90f499e6be88c14468f246f8e""><code>a2ef1a8</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/jaraco/keyrings.alt/issues/46"">#46</a> from TheChymera/cryptodome</li>; <li><a href=""https://github.com/jaraco/keyrings.alt/commit/dfab9b2846f7a19bebe788046b167a19a579fb45""><code>dfab9b2</code></a> 👹 Feed the hobgoblins (delint).</li>; <li><a href=""https://github.com/jaraco/keyrings.alt/commit/757afb5d5f3ada3d954eff981e9279f4e348f1e9""><code>757afb5</code></a> ⚫ Fade to black.</li>; <li><a href=""https://github.com/jaraco/keyrings.alt/commit/1614724e27124672f723735ff208a59a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12448:377,Encrypt,EncryptedFileKeyring,377,https://hail.is,https://github.com/hail-is/hail/pull/12448,1,['Encrypt'],['EncryptedFileKeyring']
Security,"Bumps [minimist](https://github.com/substack/minimist) from 1.2.5 to 1.2.6.; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/substack/minimist/commit/7efb22a518b53b06f5b02a1038a88bd6290c2846""><code>7efb22a</code></a> 1.2.6</li>; <li><a href=""https://github.com/substack/minimist/commit/ef88b9325f77b5ee643ccfc97e2ebda577e4c4e2""><code>ef88b93</code></a> security notice for additional prototype pollution issue</li>; <li><a href=""https://github.com/substack/minimist/commit/c2b981977fa834b223b408cfb860f933c9811e4d""><code>c2b9819</code></a> isConstructorOrProto adapted from PR</li>; <li><a href=""https://github.com/substack/minimist/commit/bc8ecee43875261f4f17eb20b1243d3ed15e70eb""><code>bc8ecee</code></a> test from prototype pollution PR</li>; <li>See full diff in <a href=""https://github.com/substack/minimist/compare/1.2.5...1.2.6"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=minimist&package-manager=npm_and_yarn&previous-version=1.2.5&new-version=1.2.6)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and blo",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11653:382,secur,security,382,https://hail.is,https://github.com/hail-is/hail/pull/11653,1,['secur'],['security']
Security,"Bumps [mistune](https://github.com/lepture/mistune) from 0.8.4 to 2.0.3.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/lepture/mistune/releases"">mistune's releases</a>.</em></p>; <blockquote>; <h2>Version 2.0.2</h2>; <p>Fix <code>escape_url </code> via <a href=""https://github-redirect.dependabot.com/lepture/mistune/pull/295"">lepture/mistune#295</a></p>; <h2>Version 2.0.1</h2>; <p>Fix XSS for image link syntax.</p>; <h2>Version 2.0.0</h2>; <p>First release of Mistune v2.</p>; <h2>Version 2.0.0 RC1</h2>; <p>In this release, we have a <strong>Security Fix</strong> for harmful links.</p>; <h2>Version 2.0.0 Alpha 1</h2>; <p>This is the first release of v2. An alpha version for users to have a preview of the new mistune.</p>; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/lepture/mistune/blob/master/docs/changes.rst"">mistune's changelog</a>.</em></p>; <blockquote>; <h2>Changelog</h2>; <p>Here is the full history of mistune v2.</p>; <p>Version 2.0.4</p>; <pre><code>; Released on Jul 15, 2022; <ul>; <li>Fix <code>url</code> plugin in <code>&amp;lt;a&amp;gt;</code> tag</li>; <li>Fix <code>*</code> formatting</li>; </ul>; <p>Version 2.0.3; </code></pre></p>; <p>Released on Jun 27, 2022</p>; <ul>; <li>Fix <code>table</code> plugin</li>; <li>Security fix for CVE-2022-34749</li>; </ul>; <p>Version 2.0.2</p>; <pre><code>; Released on Jan 14, 2022; <p>Fix <code>escape_url</code></p>; <p>Version 2.0.1; </code></pre></p>; <p>Released on Dec 30, 2021</p>; <p>XSS fix for image link syntax.</p>; <p>Version 2.0.0</p>; <pre><code>; Released on Dec 5, 2021; <p>This is the first non-alpha release of mistune v2.</p>; <p>Version 2.0.0rc1; </code></pre></p>; <p>Released on Feb 16, 2021</p>; <p>Version 2.0.0a6</p>; <pre><code>; &lt;/tr&gt;&lt;/table&gt; ; </code></pre>; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""ht",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12064:435,XSS,XSS,435,https://hail.is,https://github.com/hail-is/hail/pull/12064,2,"['Secur', 'XSS']","['Security', 'XSS']"
Security,"Bumps [mistune](https://github.com/lepture/mistune) from 0.8.4 to 2.0.4.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/lepture/mistune/releases"">mistune's releases</a>.</em></p>; <blockquote>; <h2>Version 2.0.2</h2>; <p>Fix <code>escape_url </code> via <a href=""https://github-redirect.dependabot.com/lepture/mistune/pull/295"">lepture/mistune#295</a></p>; <h2>Version 2.0.1</h2>; <p>Fix XSS for image link syntax.</p>; <h2>Version 2.0.0</h2>; <p>First release of Mistune v2.</p>; <h2>Version 2.0.0 RC1</h2>; <p>In this release, we have a <strong>Security Fix</strong> for harmful links.</p>; <h2>Version 2.0.0 Alpha 1</h2>; <p>This is the first release of v2. An alpha version for users to have a preview of the new mistune.</p>; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/lepture/mistune/blob/master/docs/changes.rst"">mistune's changelog</a>.</em></p>; <blockquote>; <h2>Changelog</h2>; <p>Here is the full history of mistune v2.</p>; <p>Version 2.0.4</p>; <pre><code>; Released on Jul 15, 2022; <ul>; <li>Fix <code>url</code> plugin in <code>&amp;lt;a&amp;gt;</code> tag</li>; <li>Fix <code>*</code> formatting</li>; </ul>; <p>Version 2.0.3; </code></pre></p>; <p>Released on Jun 27, 2022</p>; <ul>; <li>Fix <code>table</code> plugin</li>; <li>Security fix for CVE-2022-34749</li>; </ul>; <p>Version 2.0.2</p>; <pre><code>; Released on Jan 14, 2022; <p>Fix <code>escape_url</code></p>; <p>Version 2.0.1; </code></pre></p>; <p>Released on Dec 30, 2021</p>; <p>XSS fix for image link syntax.</p>; <p>Version 2.0.0</p>; <pre><code>; Released on Dec 5, 2021; <p>This is the first non-alpha release of mistune v2.</p>; <p>Version 2.0.0rc1; </code></pre></p>; <p>Released on Feb 16, 2021</p>; <p>Version 2.0.0a6</p>; <pre><code>; &lt;/tr&gt;&lt;/table&gt; ; </code></pre>; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""ht",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12066:435,XSS,XSS,435,https://hail.is,https://github.com/hail-is/hail/pull/12066,4,"['Secur', 'XSS']","['Security', 'XSS']"
Security,"Bumps [msal-extensions](https://github.com/AzureAD/microsoft-authentication-extensions-for-python) from 0.3.1 to 1.0.0.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/AzureAD/microsoft-authentication-extensions-for-python/releases"">msal-extensions's releases</a>.</em></p>; <blockquote>; <h2>MSAL Extensions for Python, 1.0.0</h2>; <p>This package is now considered stable and production-ready.</p>; <ul>; <li>New: Add a new platform-independent <code>build_encrypted_persistence()</code> API. (<a href=""https://github-redirect.dependabot.com/AzureAD/microsoft-authentication-extensions-for-python/issues/87"">#87</a>, <a href=""https://github-redirect.dependabot.com/AzureAD/microsoft-authentication-extensions-for-python/issues/110"">#110</a>)</li>; <li>Remove: Old TokenCache API which has been deprecated for 2 years. (<a href=""https://github-redirect.dependabot.com/AzureAD/microsoft-authentication-extensions-for-python/issues/110"">#110</a>)</li>; <li>Enhancement: Make all platform-dependent parameters optional (<a href=""https://github-redirect.dependabot.com/AzureAD/microsoft-authentication-extensions-for-python/issues/103"">#103</a>)</li>; <li>Enhancement: Provide <code>PersistenceEncryptError</code> and <code>PersistenceDecryptError</code>, currently raised when encryption on Windows fails. (<a href=""https://github-redirect.dependabot.com/AzureAD/microsoft-authentication-extensions-for-python/issues/108"">#108</a>)</li>; <li>Enhancement: The data file will be created with <code>600</code> permission when running in Unix-like systems. (<a href=""https://github-redirect.dependabot.com/AzureAD/microsoft-authentication-extensions-for-python/issues/107"">#107</a>)</li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/AzureAD/microsoft-authentication-extensions-for-python/commit/a88fa673af3602fe7c8c922314599b0c245e7add""><code>a88fa67</code></a> Merge branch 'release-1.0.0'</li",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11992:61,authenticat,authentication-extensions-for-python,61,https://hail.is,https://github.com/hail-is/hail/pull/11992,4,['authenticat'],['authentication-extensions-for-python']
Security,"Bumps [msrest](https://github.com/Azure/msrest-for-python) from 0.6.21 to 0.7.1.; <details>; <summary>Commits</summary>; <ul>; <li>See full diff in <a href=""https://github.com/Azure/msrest-for-python/commits"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=msrest&package-manager=pip&previous-version=0.6.21&new-version=0.7.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this d",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11965:491,secur,security-vulnerabilities,491,https://hail.is,https://github.com/hail-is/hail/pull/11965,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"Bumps [nbformat]() from 5.6.1 to 5.7.0. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=nbformat&package-manager=pip&previous-version=5.6.1&new-version=5.7.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself). </details>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12306:273,secur,security-vulnerabilities,273,https://hail.is,https://github.com/hail-is/hail/pull/12306,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"Bumps [net.java.dev.jna:jna](https://github.com/java-native-access/jna) from 5.12.1 to 5.13.0.; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/java-native-access/jna/blob/master/CHANGES.md"">net.java.dev.jna:jna's changelog</a>.</em></p>; <blockquote>; <h1>Release (5.13.0)</h1>; <h2>Features</h2>; <ul>; <li><a href=""https://redirect.github.com/java-native-access/jna/pull/1454"">#1454</a>: Add <code>c.s.j.p.win32.Psapi.QueryWorkingSetEx</code> and associated Types - <a href=""https://github.com/Crain-32""><code>@​crain-32</code></a>.</li>; <li><a href=""https://redirect.github.com/java-native-access/jna/pull/1459"">#1459</a>: Add <code>VirtualLock</code> and <code>VirtualUnlock</code> in <code>c.s.j.p.win32.Kernel32</code> - <a href=""https://github.com/matthiasblaesing""><code>@​matthiasblaesing</code></a>.</li>; <li><a href=""https://redirect.github.com/java-native-access/jna/pull/1471"">#1471</a>: Add <code>c.s.j.p.win32.Advapi32Util#isCurrentProcessElevated</code> and associated Types - <a href=""https://github.com/dbwiddis""><code>@​dbwiddis</code></a>.</li>; <li><a href=""https://redirect.github.com/java-native-access/jna/pull/1474"">#1474</a>: Add <code>c.s.j.p.win32.WbemCli#IWbemClassObject.IWbemQualifierSet</code>, <code>IWbemServices.GetObject</code>, <code>IWbemContext.SetValue</code> and associated methods - <a href=""https://github.com/rchateauneu""><code>@​rchateauneu</code></a>.</li>; <li><a href=""https://redirect.github.com/java-native-access/jna/pull/1482"">#1482</a>: Add multilingual support of <code>Kernel32Util.formatMessage</code> - <a href=""https://github.com/overpathz""><code>@​overpathz</code></a>.</li>; <li><a href=""https://redirect.github.com/java-native-access/jna/pull/1490"">#1490</a>: Adds support for a custom <code>SymbolProvider</code> in <code>NativeLibrary</code> &amp; <code>Library</code> - <a href=""https://github.com/soywiz""><code>@​soywiz</code></a>.</li>; <li><a href=""https://redirect.github.com/java-native-a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12886:60,access,access,60,https://hail.is,https://github.com/hail-is/hail/pull/12886,5,['access'],['access']
Security,"Bumps [notebook](http://jupyter.org) from 6.4.11 to 6.4.12. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=notebook&package-manager=pip&previous-version=6.4.11&new-version=6.4.12)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself); You can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/hail-is/hail/network/ale",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11926:295,secur,security-vulnerabilities,295,https://hail.is,https://github.com/hail-is/hail/pull/11926,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"Bumps [org.slf4j:slf4j-api](https://github.com/qos-ch/slf4j) from 1.7.25 to 2.0.7.; <details>; <summary>Commits</summary>; <ul>; <li>See full diff in <a href=""https://github.com/qos-ch/slf4j/commits"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=org.slf4j:slf4j-api&package-manager=gradle&previous-version=1.7.25&new-version=2.0.7)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12804:498,secur,security-vulnerabilities,498,https://hail.is,https://github.com/hail-is/hail/pull/12804,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"Bumps [path-parse](https://github.com/jbgutierrez/path-parse) from 1.0.6 to 1.0.7.; <details>; <summary>Commits</summary>; <ul>; <li>See full diff in <a href=""https://github.com/jbgutierrez/path-parse/commits/v1.0.7"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=path-parse&package-manager=npm_and_yarn&previous-version=1.0.6&new-version=1.0.7)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11288:511,secur,security-vulnerabilities,511,https://hail.is,https://github.com/hail-is/hail/pull/11288,4,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"Bumps [pkginfo](https://code.launchpad.net/~tseaver/pkginfo/trunk) from 1.8.2 to 1.8.3. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pkginfo&package-manager=pip&previous-version=1.8.2&new-version=1.8.3)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself). </details>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11966:320,secur,security-vulnerabilities,320,https://hail.is,https://github.com/hail-is/hail/pull/11966,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"Bumps [prometheus-async](https://github.com/hynek/prometheus-async) from 19.2.0 to 22.1.0.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/hynek/prometheus-async/releases"">prometheus-async's releases</a>.</em></p>; <blockquote>; <h2>22.1.0</h2>; <h2>Highlights</h2>; <p><em>prometheus-async</em> now is fully typed and the optional <em>aiohttp</em> endpoint exposes the metrics in the OpenMetrics format if the client supports it.</p>; <h2>Full Changelog</h2>; <h3>Removed</h3>; <ul>; <li>Support for Python 2.7, 3.5, and 3.6 has been dropped.</li>; <li>The <em>loop</em> argument has been removed from <code>prometheus_async.aio.start_http_server()</code>.</li>; </ul>; <h3>Added</h3>; <ul>; <li>Added type hints for all APIs.; <a href=""https://github-redirect.dependabot.com/hynek/prometheus-async/pull/21"">#21</a></li>; <li>Added support for <a href=""https://openmetrics.io"">OpenMetrics</a> exposition in <code>prometheus_async.aio.web.server_stats()</code> and thus <code>prometheus_async.aio.web.start_http_server_in_thread()</code>.; <a href=""https://github-redirect.dependabot.com/hynek/prometheus-async/issues/23"">#23</a></li>; </ul>; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/hynek/prometheus-async/blob/main/CHANGELOG.md"">prometheus-async's changelog</a>.</em></p>; <blockquote>; <h2><a href=""https://github.com/hynek/prometheus-async/compare/19.2.0...22.1.0"">22.1.0</a> - 2022-02-15</h2>; <h3>Removed</h3>; <ul>; <li>Support for Python 2.7, 3.5, and 3.6 has been dropped.</li>; <li>The <em>loop</em> argument has been removed from <code>prometheus_async.aio.start_http_server()</code>.</li>; </ul>; <h3>Added</h3>; <ul>; <li>Added type hints for all APIs.; <a href=""https://github-redirect.dependabot.com/hynek/prometheus-async/pull/21"">#21</a></li>; <li>Added support for <a href=""https://openmetrics.io"">OpenMetrics</a> exposition in <code>prometheus_async.aio.web.ser",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11536:404,expose,exposes,404,https://hail.is,https://github.com/hail-is/hail/pull/11536,1,['expose'],['exposes']
Security,"Bumps [protobuf](https://github.com/protocolbuffers/protobuf) from 3.20.1 to 3.20.2.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/protocolbuffers/protobuf/releases"">protobuf's releases</a>.</em></p>; <blockquote>; <h2>Protocol Buffers v3.20.2</h2>; <h1>C++</h1>; <ul>; <li>Reduce memory consumption of MessageSet parsing</li>; <li>This release addresses a <a href=""https://github.com/protocolbuffers/protobuf/security/advisories/GHSA-8gq9-2x98-w8hf"">Security Advisory for C++ and Python users</a></li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/protocolbuffers/protobuf/commit/a20c65f2cd549445fda907f7b83894c8eb7427d6""><code>a20c65f</code></a> Updating changelog</li>; <li><a href=""https://github.com/protocolbuffers/protobuf/commit/c49fe79af9c295960477b7568f1765b202093143""><code>c49fe79</code></a> Updating version.json and repo version numbers to: 20.2</li>; <li><a href=""https://github.com/protocolbuffers/protobuf/commit/806d7e4ce6f1fd0545cae226b94cb0249ea495c7""><code>806d7e4</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/protocolbuffers/protobuf/issues/10544"">#10544</a> from deannagarcia/3.20.x</li>; <li><a href=""https://github.com/protocolbuffers/protobuf/commit/ae718b39020ae6e6f8f5568e357d6893fd0fd29c""><code>ae718b3</code></a> Add missing includes</li>; <li><a href=""https://github.com/protocolbuffers/protobuf/commit/b4c395aaedfacb32e2414d361fa85968c0991b34""><code>b4c395a</code></a> Apply patch</li>; <li><a href=""https://github.com/protocolbuffers/protobuf/commit/6439c5c01349e74d4deb57c844a7ad4b7b13a302""><code>6439c5c</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/protocolbuffers/protobuf/issues/10531"">#10531</a> from protocolbuffers/deannagarcia-patch-7</li>; <li><a href=""https://github.com/protocolbuffers/protobuf/commit/22c79e6e4ca8be2bc2f700b2cdddca84d84659ce""><code>22c79e6</code></a> Update v",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12223:458,secur,security,458,https://hail.is,https://github.com/hail-is/hail/pull/12223,6,"['Secur', 'secur']","['Security', 'security']"
Security,"Bumps [protobuf](https://github.com/protocolbuffers/protobuf) from 3.20.1 to 4.21.5.; <details>; <summary>Commits</summary>; <ul>; <li>See full diff in <a href=""https://github.com/protocolbuffers/protobuf/commits"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=protobuf&package-manager=pip&previous-version=3.20.1&new-version=4.21.5)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more fo",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12082:499,secur,security-vulnerabilities,499,https://hail.is,https://github.com/hail-is/hail/pull/12082,4,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"Bumps [protobuf](https://github.com/protocolbuffers/protobuf) from 3.20.1 to 4.21.6.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/protocolbuffers/protobuf/releases"">protobuf's releases</a>.</em></p>; <blockquote>; <h2>Protocol Buffers v3.20.2</h2>; <h1>C++</h1>; <ul>; <li>Reduce memory consumption of MessageSet parsing</li>; <li>This release addresses a <a href=""https://github.com/protocolbuffers/protobuf/security/advisories/GHSA-8gq9-2x98-w8hf"">Security Advisory for C++ and Python users</a></li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li>See full diff in <a href=""https://github.com/protocolbuffers/protobuf/commits"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=protobuf&package-manager=pip&previous-version=3.20.1&new-version=4.21.6)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You ca",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12227:458,secur,security,458,https://hail.is,https://github.com/hail-is/hail/pull/12227,4,"['Secur', 'secur']","['Security', 'security']"
Security,"Bumps [psutil](https://github.com/giampaolo/psutil) from 5.8.0 to 5.9.0.; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/giampaolo/psutil/blob/master/HISTORY.rst"">psutil's changelog</a>.</em></p>; <blockquote>; <h1>5.9.0</h1>; <p>2021-12-29</p>; <p><strong>Enhancements</strong></p>; <ul>; <li>1851_, [Linux]: <code>cpu_freq()</code>_ is slow on systems with many CPUs. Read current; frequency values for all CPUs from <code>/proc/cpuinfo</code> instead of opening many; files in <code>/sys</code> fs. (patch by marxin)</li>; <li>1992_: <code>NoSuchProcess</code>_ message now specifies if the PID has been reused.</li>; <li>1992_: error classes (<code>NoSuchProcess</code><em>, <code>AccessDenied</code></em>, etc.) now have a better; formatted and separated <code>__repr__</code> and <code>__str__</code> implementations.</li>; <li>1996_, [BSD]: add support for MidnightBSD. (patch by Saeed Rasooli)</li>; <li>1999_, [Linux]: <code>disk_partitions()</code>_: convert <code>/dev/root</code> device (an alias; used on some Linux distros) to real root device path.</li>; <li>2005_: <code>PSUTIL_DEBUG</code> mode now prints file name and line number of the debug; messages coming from C extension modules.</li>; <li>2042_: rewrite HISTORY.rst to use hyperlinks pointing to psutil API doc.</li>; </ul>; <p><strong>Bug fixes</strong></p>; <ul>; <li>1456_, [macOS], <strong>[critical]</strong>: <code>cpu_freq()</code>_ <code>min</code> and <code>max</code> are set to; 0 if can't be determined (instead of crashing).</li>; <li>1512_, [macOS]: sometimes <code>Process.connections()</code>_ will crash with; <code>EOPNOTSUPP</code> for one connection; this is now ignored.</li>; <li>1598_, [Windows]: <code>disk_partitions()</code>_ only returns mountpoints on drives; where it first finds one.</li>; <li>1874_, [SunOS]: swap output error due to incorrect range.</li>; <li>1892_, [macOS]: <code>cpu_freq()</code>_ broken on Apple M1.</li>; <li>1901_, [macOS]: diff",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11459:727,Access,AccessDenied,727,https://hail.is,https://github.com/hail-is/hail/pull/11459,1,['Access'],['AccessDenied']
Security,"Bumps [pyjwt](https://github.com/jpadilla/pyjwt) from 1.7.1 to 2.4.0.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/jpadilla/pyjwt/releases"">pyjwt's releases</a>.</em></p>; <blockquote>; <h2>2.4.0</h2>; <h2>Security</h2>; <ul>; <li>[CVE-2022-29217] Prevent key confusion through non-blocklisted public key formats. <a href=""https://github.com/jpadilla/pyjwt/security/advisories/GHSA-ffqj-6fqr-9h24"">https://github.com/jpadilla/pyjwt/security/advisories/GHSA-ffqj-6fqr-9h24</a></li>; </ul>; <h2>What's Changed</h2>; <ul>; <li>Add support for Python 3.10 by <a href=""https://github.com/hugovk""><code>@​hugovk</code></a> in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/699"">jpadilla/pyjwt#699</a></li>; <li>Don't use implicit optionals by <a href=""https://github.com/rekyungmin""><code>@​rekyungmin</code></a> in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/705"">jpadilla/pyjwt#705</a></li>; <li>[pre-commit.ci] pre-commit autoupdate by <a href=""https://github.com/pre-commit-ci""><code>@​pre-commit-ci</code></a> in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/708"">jpadilla/pyjwt#708</a></li>; <li>[pre-commit.ci] pre-commit autoupdate by <a href=""https://github.com/pre-commit-ci""><code>@​pre-commit-ci</code></a> in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/710"">jpadilla/pyjwt#710</a></li>; <li>[pre-commit.ci] pre-commit autoupdate by <a href=""https://github.com/pre-commit-ci""><code>@​pre-commit-ci</code></a> in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/711"">jpadilla/pyjwt#711</a></li>; <li>[pre-commit.ci] pre-commit autoupdate by <a href=""https://github.com/pre-commit-ci""><code>@​pre-commit-ci</code></a> in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/712"">jpadilla/pyjwt#712</a></li>; <li>documentation fix: show correct scope for decode_complete() by <a href=""https://github.com/sseering""><code>@​ss",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11866:255,Secur,Security,255,https://hail.is,https://github.com/hail-is/hail/pull/11866,3,"['Secur', 'secur']","['Security', 'security']"
Security,"Bumps [pymysql](https://github.com/PyMySQL/PyMySQL) from 0.9.2 to 1.0.2.; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/PyMySQL/PyMySQL/blob/main/CHANGELOG.md"">pymysql's changelog</a>.</em></p>; <blockquote>; <h2>v1.0.2</h2>; <p>Release date: 2021-01-09</p>; <ul>; <li>Fix <code>user</code>, <code>password</code>, <code>host</code>, <code>database</code> are still positional arguments.; All arguments of <code>connect()</code> are now keyword-only. (<a href=""https://github-redirect.dependabot.com/PyMySQL/PyMySQL/issues/941"">#941</a>)</li>; </ul>; <h2>v1.0.1</h2>; <p>Release date: 2021-01-08</p>; <ul>; <li>Stop emitting DeprecationWarning for use of <code>db</code> and <code>passwd</code>.; Note that they are still deprecated. (<a href=""https://github-redirect.dependabot.com/PyMySQL/PyMySQL/issues/939"">#939</a>)</li>; <li>Add <code>python_requires=&quot;&gt;=3.6&quot;</code> to setup.py. (<a href=""https://github-redirect.dependabot.com/PyMySQL/PyMySQL/issues/936"">#936</a>)</li>; </ul>; <h2>v1.0.0</h2>; <p>Release date: 2021-01-07</p>; <p>Backward incompatible changes:</p>; <ul>; <li>Python 2.7 and 3.5 are not supported.</li>; <li><code>connect()</code> uses keyword-only arguments. User must use keyword argument.</li>; <li><code>connect()</code> kwargs <code>db</code> and <code>passwd</code> are now deprecated; Use <code>database</code> and <code>password</code> instead.</li>; <li>old_password authentication method (used by MySQL older than 4.1) is not supported.</li>; <li>MySQL 5.5 and MariaDB 5.5 are not officially supported, although it may still works.</li>; <li>Removed <code>escape_dict</code>, <code>escape_sequence</code>, and <code>escape_string</code> from <code>pymysql</code>; module. They are still in <code>pymysql.converters</code>.</li>; </ul>; <p>Other changes:</p>; <ul>; <li>Connection supports context manager API. <code>__exit__</code> closes the connection. (<a href=""https://github-redirect.dependabot.com/PyMySQL",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11595:341,password,password,341,https://hail.is,https://github.com/hail-is/hail/pull/11595,1,['password'],['password']
Security,"Bumps [pymysql](https://github.com/PyMySQL/PyMySQL) from 1.1.0 to 1.1.1.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/PyMySQL/PyMySQL/releases"">pymysql's releases</a>.</em></p>; <blockquote>; <h2>v1.1.1</h2>; <blockquote>; <p>[!WARNING]; This release fixes a vulnerability (CVE-2024-36039).; All users are recommended to update to this version.</p>; <p>If you can not update soon, check the input value from untrusted source has an expected type.; Only dict input from untrusted source can be an attack vector.</p>; </blockquote>; <h2>What's Changed</h2>; <ul>; <li>Prohibit dict parameter for <code>Cursor.execute()</code>. It didn't produce valid SQL; and might cause SQL injection. (CVE-2024-36039)</li>; <li>Added ssl_key_password param by <a href=""https://github.com/svaskov""><code>@​svaskov</code></a> in <a href=""https://redirect.github.com/PyMySQL/PyMySQL/pull/1145"">PyMySQL/PyMySQL#1145</a></li>; </ul>; <h2>Merged PRs</h2>; <ul>; <li>Add support for Python 3.12 by <a href=""https://github.com/hugovk""><code>@​hugovk</code></a> in <a href=""https://redirect.github.com/PyMySQL/PyMySQL/pull/1134"">PyMySQL/PyMySQL#1134</a></li>; <li>chore(deps): update actions/checkout action to v4 by <a href=""https://github.com/renovate""><code>@​renovate</code></a> in <a href=""https://redirect.github.com/PyMySQL/PyMySQL/pull/1136"">PyMySQL/PyMySQL#1136</a></li>; <li>Update codecov/codecov-action action to v4 by <a href=""https://github.com/renovate""><code>@​renovate</code></a> in <a href=""https://redirect.github.com/PyMySQL/PyMySQL/pull/1137"">PyMySQL/PyMySQL#1137</a></li>; <li>ci: use codecov@v3 by <a href=""https://github.com/methane""><code>@​methane</code></a> in <a href=""https://redirect.github.com/PyMySQL/PyMySQL/pull/1142"">PyMySQL/PyMySQL#1142</a></li>; <li>chore(deps): update dessant/lock-threads action to v5 by <a href=""https://github.com/renovate""><code>@​renovate</code></a> in <a href=""https://redirect.github.com/PyMySQL/PyMySQL/pull/1141"">",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14556:545,attack,attack,545,https://hail.is,https://github.com/hail-is/hail/pull/14556,2,"['attack', 'inject']","['attack', 'injection']"
Security,"Bumps [requests](https://github.com/psf/requests) from 2.28.2 to 2.31.0.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/psf/requests/releases"">requests's releases</a>.</em></p>; <blockquote>; <h2>v2.31.0</h2>; <h2>2.31.0 (2023-05-22)</h2>; <p><strong>Security</strong></p>; <ul>; <li>; <p>Versions of Requests between v2.3.0 and v2.30.0 are vulnerable to potential; forwarding of <code>Proxy-Authorization</code> headers to destination servers when; following HTTPS redirects.</p>; <p>When proxies are defined with user info (<a href=""https://user:pass@proxy:8080"">https://user:pass@proxy:8080</a>), Requests; will construct a <code>Proxy-Authorization</code> header that is attached to the request to; authenticate with the proxy.</p>; <p>In cases where Requests receives a redirect response, it previously reattached; the <code>Proxy-Authorization</code> header incorrectly, resulting in the value being; sent through the tunneled connection to the destination server. Users who rely on; defining their proxy credentials in the URL are <em>strongly</em> encouraged to upgrade; to Requests 2.31.0+ to prevent unintentional leakage and rotate their proxy; credentials once the change has been fully deployed.</p>; <p>Users who do not use a proxy or do not supply their proxy credentials through; the user information portion of their proxy URL are not subject to this; vulnerability.</p>; <p>Full details can be read in our <a href=""https://github.com/psf/requests/security/advisories/GHSA-j8r2-6x86-q33q"">Github Security Advisory</a>; and <a href=""https://nvd.nist.gov/vuln/detail/CVE-2023-32681"">CVE-2023-32681</a>.</p>; </li>; </ul>; <h2>v2.30.0</h2>; <h2>2.30.0 (2023-05-03)</h2>; <p><strong>Dependencies</strong></p>; <ul>; <li>; <p>⚠️ Added support for urllib3 2.0. ⚠️</p>; <p>This may contain minor breaking changes so we advise careful testing and; reviewing <a href=""https://urllib3.readthedocs.io/en/latest/v2-migration-guide.html"">https://urll",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13091:298,Secur,Security,298,https://hail.is,https://github.com/hail-is/hail/pull/13091,30,"['Authoriz', 'Secur', 'authenticat']","['Authorization', 'Security', 'authenticate']"
Security,"Bumps [requests](https://github.com/psf/requests) from 2.31.0 to 2.32.0.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/psf/requests/releases"">requests's releases</a>.</em></p>; <blockquote>; <h2>v2.32.0</h2>; <h2>2.32.0 (2024-05-20)</h2>; <h2>🐍 PYCON US 2024 EDITION 🐍</h2>; <p><strong>Security</strong></p>; <ul>; <li>Fixed an issue where setting <code>verify=False</code> on the first request from a; Session will cause subsequent requests to the <em>same origin</em> to also ignore; cert verification, regardless of the value of <code>verify</code>.; (<a href=""https://github.com/psf/requests/security/advisories/GHSA-9wx4-h78v-vm56"">https://github.com/psf/requests/security/advisories/GHSA-9wx4-h78v-vm56</a>)</li>; </ul>; <p><strong>Improvements</strong></p>; <ul>; <li><code>verify=True</code> now reuses a global SSLContext which should improve; request time variance between first and subsequent requests. It should; also minimize certificate load time on Windows systems when using a Python; version built with OpenSSL 3.x. (<a href=""https://redirect.github.com/psf/requests/issues/6667"">#6667</a>)</li>; <li>Requests now supports optional use of character detection; (<code>chardet</code> or <code>charset_normalizer</code>) when repackaged or vendored.; This enables <code>pip</code> and other projects to minimize their vendoring; surface area. The <code>Response.text()</code> and <code>apparent_encoding</code> APIs; will default to <code>utf-8</code> if neither library is present. (<a href=""https://redirect.github.com/psf/requests/issues/6702"">#6702</a>)</li>; </ul>; <p><strong>Bugfixes</strong></p>; <ul>; <li>Fixed bug in length detection where emoji length was incorrectly; calculated in the request content-length. (<a href=""https://redirect.github.com/psf/requests/issues/6589"">#6589</a>)</li>; <li>Fixed deserialization bug in JSONDecodeError. (<a href=""https://redirect.github.com/psf/requests/issues/6629"">#6629</a>)</li>; <li>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14555:334,Secur,Security,334,https://hail.is,https://github.com/hail-is/hail/pull/14555,3,"['Secur', 'secur']","['Security', 'security']"
Security,"Bumps [types-chardet](https://github.com/python/typeshed) from 4.0.4 to 5.0.1.; <details>; <summary>Commits</summary>; <ul>; <li>See full diff in <a href=""https://github.com/python/typeshed/commits"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=types-chardet&package-manager=pip&previous-version=4.0.4&new-version=5.0.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this depen",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12001:487,secur,security-vulnerabilities,487,https://hail.is,https://github.com/hail-is/hail/pull/12001,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"Bumps [types-chardet](https://github.com/python/typeshed) from 5.0.4 to 5.0.4.1.; <details>; <summary>Commits</summary>; <ul>; <li>See full diff in <a href=""https://github.com/python/typeshed/commits"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=types-chardet&package-manager=pip&previous-version=5.0.4&new-version=5.0.4.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this d",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12537:491,secur,security-vulnerabilities,491,https://hail.is,https://github.com/hail-is/hail/pull/12537,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"Bumps [types-chardet](https://github.com/python/typeshed) from 5.0.4.5 to 5.0.4.6.; <details>; <summary>Commits</summary>; <ul>; <li>See full diff in <a href=""https://github.com/python/typeshed/commits"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=types-chardet&package-manager=pip&previous-version=5.0.4.5&new-version=5.0.4.6)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for th",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13034:495,secur,security-vulnerabilities,495,https://hail.is,https://github.com/hail-is/hail/pull/13034,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"Bumps [types-python-dateutil](https://github.com/python/typeshed) from 2.8.17 to 2.8.19.; <details>; <summary>Commits</summary>; <ul>; <li>See full diff in <a href=""https://github.com/python/typeshed/commits"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=types-python-dateutil&package-manager=pip&previous-version=2.8.17&new-version=2.8.19)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12172:507,secur,security-vulnerabilities,507,https://hail.is,https://github.com/hail-is/hail/pull/12172,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"Bumps [types-requests](https://github.com/python/typeshed) from 2.27.30 to 2.28.0.; <details>; <summary>Commits</summary>; <ul>; <li>See full diff in <a href=""https://github.com/python/typeshed/commits"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=types-requests&package-manager=pip&previous-version=2.27.30&new-version=2.28.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for th",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11967:495,secur,security-vulnerabilities,495,https://hail.is,https://github.com/hail-is/hail/pull/11967,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"Bumps [types-requests](https://github.com/python/typeshed) from 2.28.11.1 to 2.28.11.2.; <details>; <summary>Commits</summary>; <ul>; <li>See full diff in <a href=""https://github.com/python/typeshed/commits"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=types-requests&package-manager=pip&previous-version=2.28.11.1&new-version=2.28.11.2)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any m",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12297:505,secur,security-vulnerabilities,505,https://hail.is,https://github.com/hail-is/hail/pull/12297,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"Bumps [types-requests](https://github.com/python/typeshed) from 2.28.11.2 to 2.28.11.3.; <details>; <summary>Commits</summary>; <ul>; <li>See full diff in <a href=""https://github.com/python/typeshed/commits"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=types-requests&package-manager=pip&previous-version=2.28.11.2&new-version=2.28.11.3)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any m",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12437:505,secur,security-vulnerabilities,505,https://hail.is,https://github.com/hail-is/hail/pull/12437,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"Bumps [types-setuptools](https://github.com/python/typeshed) from 57.4.17 to 65.3.0.; <details>; <summary>Commits</summary>; <ul>; <li>See full diff in <a href=""https://github.com/python/typeshed/commits"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=types-setuptools&package-manager=pip&previous-version=57.4.17&new-version=65.3.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more fo",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12181:499,secur,security-vulnerabilities,499,https://hail.is,https://github.com/hail-is/hail/pull/12181,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"Bumps [types-six](https://github.com/python/typeshed) from 1.16.15 to 1.16.18.; <details>; <summary>Commits</summary>; <ul>; <li>See full diff in <a href=""https://github.com/python/typeshed/commits"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=types-six&package-manager=pip&previous-version=1.16.15&new-version=1.16.18)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this depen",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12114:487,secur,security-vulnerabilities,487,https://hail.is,https://github.com/hail-is/hail/pull/12114,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"Bumps [types-six](https://github.com/python/typeshed) from 1.16.15 to 1.16.19.; <details>; <summary>Commits</summary>; <ul>; <li>See full diff in <a href=""https://github.com/python/typeshed/commits"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=types-six&package-manager=pip&previous-version=1.16.15&new-version=1.16.19)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this depen",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12131:487,secur,security-vulnerabilities,487,https://hail.is,https://github.com/hail-is/hail/pull/12131,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"Bumps [types-six](https://github.com/python/typeshed) from 1.16.21.20240301 to 1.16.21.20240311.; <details>; <summary>Commits</summary>; <ul>; <li>See full diff in <a href=""https://github.com/python/typeshed/commits"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=types-six&package-manager=pip&previous-version=1.16.21.20240301&new-version=1.16.21.20240311)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (un",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14491:523,secur,security-vulnerabilities,523,https://hail.is,https://github.com/hail-is/hail/pull/14491,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"Bumps [types-six](https://github.com/python/typeshed) from 1.16.21.20240301 to 1.16.21.20240425.; <details>; <summary>Commits</summary>; <ul>; <li>See full diff in <a href=""https://github.com/python/typeshed/commits"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=types-six&package-manager=pip&previous-version=1.16.21.20240301&new-version=1.16.21.20240425)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (un",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14501:523,secur,security-vulnerabilities,523,https://hail.is,https://github.com/hail-is/hail/pull/14501,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"Bumps [types-urllib3](https://github.com/python/typeshed) from 1.26.15 to 1.26.20.; <details>; <summary>Commits</summary>; <ul>; <li>See full diff in <a href=""https://github.com/python/typeshed/commits"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=types-urllib3&package-manager=pip&previous-version=1.26.15&new-version=1.26.20)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for th",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12068:495,secur,security-vulnerabilities,495,https://hail.is,https://github.com/hail-is/hail/pull/12068,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"Bumps [types-urllib3](https://github.com/python/typeshed) from 1.26.15 to 1.26.21.; <details>; <summary>Commits</summary>; <ul>; <li>See full diff in <a href=""https://github.com/python/typeshed/commits"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=types-urllib3&package-manager=pip&previous-version=1.26.15&new-version=1.26.21)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for th",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12072:495,secur,security-vulnerabilities,495,https://hail.is,https://github.com/hail-is/hail/pull/12072,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"Bumps [types-urllib3](https://github.com/python/typeshed) from 1.26.15 to 1.26.22.; <details>; <summary>Commits</summary>; <ul>; <li>See full diff in <a href=""https://github.com/python/typeshed/commits"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=types-urllib3&package-manager=pip&previous-version=1.26.15&new-version=1.26.22)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for th",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12077:495,secur,security-vulnerabilities,495,https://hail.is,https://github.com/hail-is/hail/pull/12077,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"Bumps [urllib3](https://github.com/urllib3/urllib3) from 1.26.9 to 1.26.12.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/urllib3/urllib3/releases"">urllib3's releases</a>.</em></p>; <blockquote>; <h2>1.26.12</h2>; <ul>; <li>Deprecated the <code>urllib3[secure]</code> extra and the <code>urllib3.contrib.pyopenssl</code> module. Both will be removed in v2.x. See this <a href=""https://github-redirect.dependabot.com/urllib3/urllib3/issues/2680"">GitHub issue</a> for justification and info on how to migrate.</li>; </ul>; <h2>1.26.11</h2>; <p><strong>If you or your organization rely on urllib3 consider supporting us via <a href=""https://github.com/sponsors/urllib3"">GitHub Sponsors</a>.</strong></p>; <p>:warning: <strong>urllib3 v2.0 will drop support for Python 2</strong>: <a href=""https://urllib3.readthedocs.io/en/latest/v2-roadmap.html"">Read more in the v2.0 Roadmap</a></p>; <ul>; <li>Fixed an issue where reading more than 2 GiB in a call to HTTPResponse.read would raise an OverflowError on Python 3.9 and earlier.</li>; </ul>; <h2>1.26.10</h2>; <p><strong>If you or your organization rely on urllib3 consider supporting us via <a href=""https://github.com/sponsors/urllib3"">GitHub Sponsors</a>.</strong></p>; <p>:warning: <strong>urllib3 v2.0 will drop support for Python 2</strong>: <a href=""https://urllib3.readthedocs.io/en/latest/v2-roadmap.html"">Read more in the v2.0 Roadmap</a></p>; <p>:closed_lock_with_key: <strong>This is the first release to be signed with Sigstore!</strong> You can verify the distributables using the <code>.sig</code> and <code>.crt</code> files included on this release.</p>; <ul>; <li>Removed support for Python 3.5</li>; <li>Fixed an issue where a <code>ProxyError</code> recommending configuring the proxy as HTTP instead of HTTPS could appear even when an HTTPS proxy wasn't configured.</li>; </ul>; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://gi",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12140:301,secur,secure,301,https://hail.is,https://github.com/hail-is/hail/pull/12140,1,['secur'],['secure']
Security,"Bumps [werkzeug](https://github.com/pallets/werkzeug) from 2.2.2 to 2.2.3.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/pallets/werkzeug/releases"">werkzeug's releases</a>.</em></p>; <blockquote>; <h2>2.2.3</h2>; <p>This is a fix release for the 2.2.x release branch.</p>; <ul>; <li>Changes: <a href=""https://werkzeug.palletsprojects.com/en/2.2.x/changes/#version-2-2-3"">https://werkzeug.palletsprojects.com/en/2.2.x/changes/#version-2-2-3</a></li>; <li>Milestone: <a href=""https://github.com/pallets/werkzeug/milestone/26?closed=1"">https://github.com/pallets/werkzeug/milestone/26?closed=1</a></li>; </ul>; <p>This release contains security fixes for:</p>; <ul>; <li><a href=""https://github.com/pallets/werkzeug/security/advisories/GHSA-xg9f-g7g7-2323"">https://github.com/pallets/werkzeug/security/advisories/GHSA-xg9f-g7g7-2323</a></li>; <li><a href=""https://github.com/pallets/werkzeug/security/advisories/GHSA-px8h-6qxv-m22q"">https://github.com/pallets/werkzeug/security/advisories/GHSA-px8h-6qxv-m22q</a></li>; </ul>; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/pallets/werkzeug/blob/main/CHANGES.rst"">werkzeug's changelog</a>.</em></p>; <blockquote>; <h2>Version 2.2.3</h2>; <p>Released 2023-02-14</p>; <ul>; <li>Ensure that URL rules using path converters will redirect with strict slashes when; the trailing slash is missing. :issue:<code>2533</code></li>; <li>Type signature for <code>get_json</code> specifies that return type is not optional when; <code>silent=False</code>. :issue:<code>2508</code></li>; <li><code>parse_content_range_header</code> returns <code>None</code> for a value like <code>bytes */-1</code>; where the length is invalid, instead of raising an <code>AssertionError</code>. :issue:<code>2531</code></li>; <li>Address remaining <code>ResourceWarning</code> related to the socket used by <code>run_simple</code>.; Remove <code>prepare_socket</code>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12703:681,secur,security,681,https://hail.is,https://github.com/hail-is/hail/pull/12703,4,['secur'],['security']
Security,"Bumps [widgetsnbextension](http://jupyter.org) from 3.6.0 to 4.0.3. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=widgetsnbextension&package-manager=pip&previous-version=3.6.0&new-version=4.0.3)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself). </details>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12167:311,secur,security-vulnerabilities,311,https://hail.is,https://github.com/hail-is/hail/pull/12167,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"Bumps asm from 7.3.1 to 9.4. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=org.ow2.asm:asm&package-manager=gradle&previous-version=7.3.1&new-version=9.4)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself). </details>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12516:270,secur,security-vulnerabilities,270,https://hail.is,https://github.com/hail-is/hail/pull/12516,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"Bumps com.github.johnrengelman.shadow from 6.1.0 to 7.1.2. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=com.github.johnrengelman.shadow&package-manager=gradle&previous-version=6.1.0&new-version=7.1.2)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself). </details>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12500:318,secur,security-vulnerabilities,318,https://hail.is,https://github.com/hail-is/hail/pull/12500,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"Bumps com.github.johnrengelman.shadow from 6.1.0 to 8.1.1. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=com.github.johnrengelman.shadow&package-manager=gradle&previous-version=6.1.0&new-version=8.1.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). You can trigger a rebase of this PR by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself). </details>> **Note**; > Automatic rebases have been disabled on this pull request as it has been open for over 30 days.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12897:318,secur,security-vulnerabilities,318,https://hail.is,https://github.com/hail-is/hail/pull/12897,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"Bumps commons-io from 2.5 to 2.11.0. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=commons-io:commons-io&package-manager=gradle&previous-version=2.5&new-version=2.11.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself). </details>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12469:285,secur,security-vulnerabilities,285,https://hail.is,https://github.com/hail-is/hail/pull/12469,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"Bumps commons-lang3 from 3.5 to 3.12.0. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=org.apache.commons:commons-lang3&package-manager=gradle&previous-version=3.5&new-version=3.12.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself). </details>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12363:299,secur,security-vulnerabilities,299,https://hail.is,https://github.com/hail-is/hail/pull/12363,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"Bumps freemarker from 2.3.14 to 2.3.31. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=org.freemarker:freemarker&package-manager=gradle&previous-version=2.3.14&new-version=2.3.31)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself). </details>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12443:295,secur,security-vulnerabilities,295,https://hail.is,https://github.com/hail-is/hail/pull/12443,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"Bumps hadoop-client from 2.7.1 to 3.3.4. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=org.apache.hadoop:hadoop-client&package-manager=gradle&previous-version=2.7.1&new-version=3.3.4)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself). </details>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12377:300,secur,security-vulnerabilities,300,https://hail.is,https://github.com/hail-is/hail/pull/12377,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"Bumps org.ow2.asm:asm-util from 7.3.1 to 9.5. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=org.ow2.asm:asm-util&package-manager=gradle&previous-version=7.3.1&new-version=9.5)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself). </details>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13636:292,secur,security-vulnerabilities,292,https://hail.is,https://github.com/hail-is/hail/pull/13636,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"Bumps org.ow2.asm:asm-util from 7.3.1 to 9.6. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=org.ow2.asm:asm-util&package-manager=gradle&previous-version=7.3.1&new-version=9.6)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). You can trigger a rebase of this PR by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself). </details>. > **Note**; > Automatic rebases have been disabled on this pull request as it has been open ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13761:292,secur,security-vulnerabilities,292,https://hail.is,https://github.com/hail-is/hail/pull/13761,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,By setting a secret on the callback in Github and verifying the request hash.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4473:72,hash,hash,72,https://hail.is,https://github.com/hail-is/hail/issues/4473,1,['hash'],['hash']
Security,"BytesReadable=0.00 B, chunks requested=0, cache hits=0; 2023-05-04 01:04:37.601 : INFO: RegionPool: FREE: 0 allocated (0 blocks / 0 chunks), regions.size = 0, 0 current java objects, thread 8: pool-1-thread-1; 2023-05-04 01:04:37.601 : INFO: RegionPool: FREE: 128.0K allocated (128.0K blocks / 0 chunks), regions.size = 2, 0 current java objects, thread 8: pool-1-thread-1; 2023-05-04 01:04:37.603 : ERROR: SocketException: Connection reset; From javax.net.ssl.SSLException: Connection reset; 	at sun.security.ssl.Alert.createSSLException(Alert.java:127); 	at sun.security.ssl.TransportContext.fatal(TransportContext.java:324); 	at sun.security.ssl.TransportContext.fatal(TransportContext.java:267); 	at sun.security.ssl.TransportContext.fatal(TransportContext.java:262); 	at sun.security.ssl.SSLTransport.decode(SSLTransport.java:138); 	at sun.security.ssl.SSLSocketImpl.decode(SSLSocketImpl.java:1400); 	at sun.security.ssl.SSLSocketImpl.readApplicationRecord(SSLSocketImpl.java:1368); 	at sun.security.ssl.SSLSocketImpl.access$300(SSLSocketImpl.java:73); 	at sun.security.ssl.SSLSocketImpl$AppInputStream.read(SSLSocketImpl.java:962); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:284); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.MeteredStream.read(MeteredStream.java:134); 	at java.io.FilterInputStream.read(FilterInputStream.java:133); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3456); 	at com.google.api.client.http.javanet.NetHttpResponse$SizeValidatingInputStream.read(NetHttpResponse.java:164); 	at java.nio.channels.Channels$ReadableByteChannelImpl.read(Channels.java:385); 	at is.hail.relocated.com.google.cloud.storage.StorageByteChannels$ScatteringByteChannelFacade.read(StorageByteChannels.java:226); 	at is.hail.relocated.com.google.cloud.storage.ApiaryUnbufferedReadableByteChannel.read(ApiaryUnbufferedReadableByteChannel.java:104); 	at is.hail.relocated.com.google.cloud.stora",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12983:24141,secur,security,24141,https://hail.is,https://github.com/hail-is/hail/issues/12983,1,['secur'],['security']
Security,"BytesReadable=129.00 KiB, chunks requested=0, cache hits=0; 2023-05-04 01:04:37.560 : INFO: RegionPool: FREE: 129.0K allocated (129.0K blocks / 0 chunks), regions.size = 3, 0 current java objects, thread 8: pool-1-thread-1; 2023-05-04 01:04:37.561 : ERROR: error while applying lowering 'LowerAndExecuteShuffles'; 2023-05-04 01:04:37.600 : INFO: RegionPool: initialized for thread 8: pool-1-thread-1; 2023-05-04 01:04:37.601 : INFO: TaskReport: stage=0, partition=0, attempt=0, peakBytes=0, peakBytesReadable=0.00 B, chunks requested=0, cache hits=0; 2023-05-04 01:04:37.601 : INFO: RegionPool: FREE: 0 allocated (0 blocks / 0 chunks), regions.size = 0, 0 current java objects, thread 8: pool-1-thread-1; 2023-05-04 01:04:37.601 : INFO: RegionPool: FREE: 128.0K allocated (128.0K blocks / 0 chunks), regions.size = 2, 0 current java objects, thread 8: pool-1-thread-1; 2023-05-04 01:04:37.603 : ERROR: SocketException: Connection reset; From javax.net.ssl.SSLException: Connection reset; 	at sun.security.ssl.Alert.createSSLException(Alert.java:127); 	at sun.security.ssl.TransportContext.fatal(TransportContext.java:324); 	at sun.security.ssl.TransportContext.fatal(TransportContext.java:267); 	at sun.security.ssl.TransportContext.fatal(TransportContext.java:262); 	at sun.security.ssl.SSLTransport.decode(SSLTransport.java:138); 	at sun.security.ssl.SSLSocketImpl.decode(SSLSocketImpl.java:1400); 	at sun.security.ssl.SSLSocketImpl.readApplicationRecord(SSLSocketImpl.java:1368); 	at sun.security.ssl.SSLSocketImpl.access$300(SSLSocketImpl.java:73); 	at sun.security.ssl.SSLSocketImpl$AppInputStream.read(SSLSocketImpl.java:962); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:284); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.MeteredStream.read(MeteredStream.java:134); 	at java.io.FilterInputStream.read(FilterInputStream.java:133); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3456); 	at com.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12983:23646,secur,security,23646,https://hail.is,https://github.com/hail-is/hail/issues/12983,1,['secur'],['security']
Security,"C$.apply(SampleQC.scala:221); at is.hail.methods.SampleQC.apply(SampleQC.scala); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); at py4j.Gateway.invoke(Gateway.java:280); at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); at py4j.commands.CallCommand.execute(CallCommand.java:79); at py4j.GatewayConnection.run(GatewayConnection.java:214); at java.lang.Thread.run(Thread.java:745)is.hail.utils.HailException: invalid allele ""<DEL>""; at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:6); at is.hail.utils.package$.fatal(package.scala:26); at is.hail.variant.AltAlleleMethods$.validate(AltAlleleMethods.scala:24); at is.hail.variant.AltAlleleMethods$.altAlleleType(AltAlleleMethods.scala:29); at is.hail.methods.SampleQCCombiner$.alleleIndices(SampleQC.scala:44); at is.hail.methods.SampleQC$$anonfun$results$1$$anonfun$apply$1.apply(SampleQC.scala:178); at is.hail.methods.SampleQC$$anonfun$results$1$$anonfun$apply$1.apply(SampleQC.scala:175); at scala.collection.Iterator$class.foreach(Iterator.scala:893); at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); at is.hail.methods.SampleQC$$anonfun$results$1.apply(SampleQC.scala:175); at is.hail.methods.SampleQC$$anonfun$results$1.apply(SampleQC.scala:170); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:797); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:797); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); at org.apache.spark.rdd.RDD.iterat",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3413:7585,validat,validate,7585,https://hail.is,https://github.com/hail-is/hail/issues/3413,1,['validat'],['validate']
Security,CHANGELOG: Add `hl.die` function that can be used to generate errors. Useful in data validation.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8865:85,validat,validation,85,https://hail.is,https://github.com/hail-is/hail/pull/8865,1,['validat'],['validation']
Security,"CHANGELOG: BatchPoolExecutor now raises an informative error message for a variety of ""system"" errors, such as missing container images. If the main container fails for reasons beyond BatchPoolExecutor's control, such; as a missing container image, we previously did not report these errors. In; fact, we encountered errors when trying to load the output file that cannot; exist if the main container errors. Smaller included changes:; - directly use the asynchronous, low-level client instead of the synchronous,; low-level client; - introduce an `async_cancel` now that we have access to the async client.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9543:580,access,access,580,https://hail.is,https://github.com/hail-is/hail/pull/9543,1,['access'],['access']
Security,"CHANGELOG: Evaluating hail expressions in python will now return `frozendict`, an immutable dictionary type. Sets will return python's `frozenset`. This is necessary because hail supports hashable dicts, but python does not. Same with sets.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10105:188,hash,hashable,188,https://hail.is,https://github.com/hail-is/hail/pull/10105,1,['hash'],['hashable']
Security,"CHANGELOG: Fix #14089, which makes `hailctl dataproc connect` work in Windows Subsystem for Linux. 1. Non 64-bit Windows uses ""Program Files"" not ""Program Files (x86)"". 2. Windows Subsystem for Linux looks like GNU/Linux but will not have chromium on its path. 3. The removed arguments are no longer supported. They produce a warning message in my version of Chrome and appear to not work in the version of Chrome that this user was using. Instead, I bind to 0.0.0.0 and access the Notebook using the machine DNS name. This is how Google recommend accessing the Spark UI anyway.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14090:471,access,access,471,https://hail.is,https://github.com/hail-is/hail/pull/14090,2,['access'],"['access', 'accessing']"
Security,"CHANGELOG: Fix long-standing bug wherein `hl.agg.collect_as_set` and `hl.agg.counter` error when applied to types which, in Python, are unhashable. For example, `hl.agg.counter(t.list_of_genes)` will not error when `t.list_of_genes` is a list. Instead, the counter dictionary will use `FrozenList` keys from the `frozenlist` package. Hey @iris-garden ! I figured this was good reviewing practice for you and also a chance to see how we convert data to/from JSON and to/from the JVM (by way of this ""encoded"" representation which is a binary one). The details of that are not super important to this PR, but you might take a peek to understand the change. The main issue here is that in Python, you can't write:; ```; {[1]}; ```; Because sets must contain ""hashable"" data. Python lists are not hashable because they're mutable. This is transitively a problem. For example, the following also fails with the same error because the list inside the tuple is mutable thus the tuple is not (safely) hashable.; ```; {(""tuples"", ""are"", ""immutable"", [""lists"", ""are"", ""not""])}; ```. Hail's internal language is fully immutable, so every type can be placed inside a set (or used as the keys of a dict). When we convert from Hail's internal representation to Python, we cannot use mutable types in hashable positions. Unfortunately, we also need to maintain backwards compatibility with the way the code currently works. You can see this pretty clearly in the difference between `hl.agg.collect` and `hl.agg.collect_as_set`:; ```; t = hl.utils.range_table(1); t = t.annotate(ls = [1, 2, 3]); collected_ls = t.aggregate(hl.agg.collect(t.ls)); collected_as_set_ls = t.aggregate(hl.agg.collect_as_set(t.ls)); ```; `collected_ls` should be `[[1, 2, 3]]` whereas `collected_as_set_ls` necessarily uses hashable types: `{frozenlist([1, 2, 3])}`. Things are particularly subtle with dictionaries whose keys must always be hashable and whose values need only be hashable if the dictionary itself must be hashable. For exa",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12265:756,hash,hashable,756,https://hail.is,https://github.com/hail-is/hail/pull/12265,3,['hash'],['hashable']
Security,"CHANGELOG: Fixed issue where accessing an element of an ndarray in a call to Table.transmute would fail. Because `_indices` was not being set, transmute would fail when it tried to see which row fields to delete.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8845:29,access,accessing,29,https://hail.is,https://github.com/hail-is/hail/pull/8845,1,['access'],['accessing']
Security,"CHANGELOG: Fixes #13697, a long standing issue with QoB, in which a failing partition job or driver job is not failed in the Batch UI. I am not sure why we did not do this this way in the first place. If a JVMJob raises an exception, Batch will mark the job as failed. Ergo, we should raise an exception when a driver or a worker fails!. Here's an example: I used a simple pipeline that write to a bucket to which I have read-only access. You can see an example Batch (where every partition fails): https://batch.hail.is/batches/8046901. [1]. ```python3; import hail as hl; hl.utils.range_table(3, n_partitions=3).write('gs://neale-bge/foo.ht'); ```. NB: I removed the `log.error` in `handleForPython` because that log is never necessary. That function converts a stack of exceptions into a triplet of the short message, the full exception with stack trace, and a Hail error id (if present). That triplet is always passed along to someone else who logs the exception. (FWIW, the error id indicates a Python source location that is associated with the error. On the Python-side, we can look up that error id and provide a better stack trace.). [1] You'll notice the logs are missing. I noticed this as well, it's a new bug. I fixed it in https://github.com/hail-is/hail/pull/13729.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13715:431,access,access,431,https://hail.is,https://github.com/hail-is/hail/pull/13715,1,['access'],['access']
