quality_attribute,sentence,source,author,repo,version,id,keyword,matched_word,match_idx,wiki,url,total_similar,target_keywords,target_matched_words
Availability,"	at akka.dispatch.Mailbox.run(Mailbox.scala:229); 	at akka.dispatch.Mailbox.exec(Mailbox.scala:241); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107). [2019-10-01 02:53:03,81] [info] WorkflowManagerActor WorkflowActor-c55a06f3-abc1-4db1-8e0f-ea0303caab2c is in a terminal state: WorkflowFailedState; [2019-10-01 02:53:07,42] [info] Not triggering log of token queue status. Effective log interval = None; [2019-10-01 02:53:08,41] [info] SingleWorkflowRunnerActor workflow finished with status 'Failed'.; [2019-10-01 02:53:12,32] [info] Workflow polling stopped; [2019-10-01 02:53:12,33] [info] 0 workflows released by cromid-876ccf5; [2019-10-01 02:53:12,34] [info] Shutting down WorkflowStoreActor - Timeout = 5 seconds; [2019-10-01 02:53:12,34] [info] Shutting down WorkflowLogCopyRouter - Timeout = 5 seconds; [2019-10-01 02:53:12,34] [info] Shutting down JobExecutionTokenDispenser - Timeout = 5 seconds; [2019-10-01 02:53:12,34] [info] Aborting all running workflows.; [2019-10-01 02:53:12,34] [info] JobExecutionTokenDispenser stopped; [2019-10-01 02:53:12,35] [info] WorkflowStoreActor stopped; [2019-10-01 02:53:12,35] [info] WorkflowLogCopyRouter stopped; [2019-10-01 02:53:12,35] [info] Shutting down WorkflowManagerActor - Timeout = 3600 seconds; [2019-10-01 02:53:12,35] [info] WorkflowManagerActor All workflows finished; [2019-10-01 02:53:12,35] [info] WorkflowManagerActor stopped; [2019-10-01 02:53:12,65] [info] Connection pools shut down; [2019-10-01 02:53:12,65] [info] Shutting down SubWorkflowStoreActor - Timeout = 1800 seconds; [2019-10-01 02:53:12,65] [info] Shutting down JobStoreActor - Timeout = 1800 seconds; [2019-10-01 02:53:12,65] [info] Shutting down CallCacheWriteActor - Timeout = 1800 seconds; [2019-10",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6189:9433,down,down,9433,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6189,3,['down'],['down']
Availability, 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); 	at org.broadinstitute.hellbender.engine.VariantWalkerBase.traverse(VariantWalkerBase.java:108); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:893); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:136); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:179); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:198); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:152); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:195); 	at org.broadinstitute.hellbender.Main.main(Main.java:275); Caused by: org.sqlite.SQLiteException: [SQLITE_IOERR_LOCK] I/O error in the advisory file locking logic (disk I/O error); 	at org.sqlite.core.DB.newSQLException(DB.java:909); 	at org.sqlite.core.DB.newSQLException(DB.java:921); 	at org.sqlite.core.DB.throwex(DB.java:886); 	at org.sqlite.core.NativeDB.prepare_utf8(Native Method); 	at org.sqlite.core.NativeDB.prepare(NativeDB.java:127); 	at org.sqlite.core.DB.prepare(DB.java:227); 	at org.sqlite.jdbc3.JDBC3Statement.executeQuery(JDBC3Statement.java:81); 	at org.broadinstitute.hellbender.tools.funcotator.dataSources.cosmic.CosmicFuncotationFactory.createFuncotations(CosmicFuncotationFactory.java:215); 	... 21 more. ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4413:2312,error,error,2312,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4413,2,['error'],['error']
Availability, 	at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58); 	at org.broadinstitute.hellbender.engine.spark.SparkContextFactory.createSparkContext(SparkContextFactory.java:178); 	at org.broadinstitute.hellbender.engine.spark.SparkContextFactory.getSparkContext(SparkContextFactory.java:110); 	at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:28); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:138); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:162); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:205); 	at org.broadinstitute.hellbender.Main.main(Main.java:291); Caused by: java.net.UnknownHostException: bioinfo: bioinfo: unknown error; 	at java.net.InetAddress.getLocalHost(InetAddress.java:1505); 	at org.apache.spark.util.Utils$.findLocalInetAddress(Utils.scala:891); 	at org.apache.spark.util.Utils$.org$apache$spark$util$Utils$$localIpAddress$lzycompute(Utils.scala:884); 	at org.apache.spark.util.Utils$.org$apache$spark$util$Utils$$localIpAddress(Utils.scala:884); 	at org.apache.spark.util.Utils$$anonfun$localHostName$1.apply(Utils.scala:941); 	at org.apache.spark.util.Utils$$anonfun$localHostName$1.apply(Utils.scala:941); 	at scala.Option.getOrElse(Option.scala:121); 	at org.apache.spark.util.Utils$.localHostName(Utils.scala:941); 	at org.apache.spark.internal.config.package$.<init>(package.scala:204); 	at org.apache.spark.internal.config.package$.<clinit>(package.scala); 	... 12 more; Caused by: java.net.UnknownHostException: bioinfo: unknown error; 	at java.net.Inet6AddressImpl.lookupAllHostAddr(Native Method); 	at java.net.InetAddress$2.lookupAllHostAddr(InetAddress.java:928); 	at java.net.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5802:3887,error,error,3887,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5802,1,['error'],['error']
Availability," (surrounded by `_`) as appropriate; - Delete the other template blocks and this header. ----. ## Bug Report. ### Affected tool(s) or class(es); _Tool/class name(s), special parameters?_. After sourcing the tab-completion script, some tools shown cannot be run. Maybe they exist somewhere in an experimental dev version but are not bundled for public release?. ### Affected version(s); - [x ] Latest public release version [4.1.7.0]; - [ ] Latest master branch as of [date of test?]. ### Description ; _Describe the problem below. Provide **screenshots** , **stacktrace** , **logs** where appropriate._. After trying to tab complete the DepthOfCoverage, I saw a few tools not listed in the documentation. I tried running them and sure enough, there were errors:. `A USER ERROR has occurred: '*' is not a valid command.`; (* is one of the tools listed below). #### Steps to reproduce; _Tell us how to reproduce this issue. If possible, include command lines that reproduce the problem. (The support team may follow up to ask you to upload data to reproduce the issue.)_. ```; cd gatk-4.1.7.0; source gatk-completion.sh; ./gatk Depth<tab>; #>DepthOfCoverage DepthPerAlleleBySample DepthPerSampleHC; ./gatk DepthPerSampleHC -h; ...; ***********************************************************************; A USER ERROR has occurred: 'DepthPerSampleHC' is not a valid command.; ***********************************************************************; ./gatk DepthPerAlleleBySample -h; ...; ***********************************************************************; A USER ERROR has occurred: 'DepthPerAlleleBySample' is not a valid command.; ***********************************************************************; ./gatk DepthOfCoverage -h; **BETA FEATURE - WORK IN PROGRESS**; USAGE: DepthOfCoverage [arguments]; Generate coverage summary information for reads data; Version:4.1.7.0; ....; ```. #### Expected behavior; _Tell us what should happen_. Only valid tools should be available for tab completion",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6615:2383,ERROR,ERROR,2383,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6615,3,"['ERROR', 'avail']","['ERROR', 'available']"
Availability," - Fix up FQ and race condition issues with volatile tasks work [VS-478] (#7888); - Use gvs-internal project in integration test (#7901); - Add cost observability BQ table [VS-441] (#7891); - Add preliminary labels to queries [VS-381] (#7902); - Workflow compute costs [VS-472] (#7905); - Fix bug and update images (#7912); - VS 483 Beta user wdl (#7894); - Core storage model cost [VS-473] (#7913); - Update Quickstart & Integration to use re-blocked v2 gVCFs [VS-491] (#7924); - KM GVS documentation (#7903); - Track BigQuery costs of GVS python VS-480 (#7915); - Read cost observability table [VS-475] (#7923); - Fix Race Condition, Add Support for Extract by Array of Sample Names (ie from a Sample Set) (#7917); - Rightsize import batches [VS-486] (#7925); - [AoU DRC] Support uppercase site_ids for reblocking (#7929); - Populate cost metadata for GATK tasks. (#7919); - remove accidentally added input (#7931); - VS_492 - Beta User Jar release (#7934); - Cost WDL should throw on FISS API errors [VS-518] (#7942); - Fix bad check for missing workflow name [VS-520] (#7943); - Remove usage of service account from GvsValidateVAT.wdl (#7937); - refactoring for testablity (#7946); - More import retries [VS-532] (#7953); - A few last doc changes (#7927); - WDL to extract a single callset cost (BQ only, not Terra) (#7940); - Temporarily swap in Corretto for Temurin as we can't download Temurin. (#7969); - GL-548 - Update CreateVat code to handle samples that do not contain all population groups. (#7965); - Restore Temurin 11 [VS-570] (#7972); - Add table size check to quickstart integration test [VS-501] (#7970); - Consolidate various docs for AoU callset generation into one to rule them all [VS-553] (#7971); - VS-567. Removing usage of ServiceAccount from CreateVat related WDLs (#7974); - WDL to extract Avro files for Hail import [VS-579] (#7981); - Removed usage of service account from WDLs (#7985); - Document steps for GVS cleanup for base use case [VS-586] (#7989); - Change bac",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8248:26303,error,errors,26303,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8248,2,['error'],['errors']
Availability," - GCS max retries/reopens: 20; 10:19:39.338 INFO GenomicsDBImport - Requester pays: disabled; 10:19:39.338 INFO GenomicsDBImport - Initializing engine; 10:19:39.489 INFO IntervalArgumentCollection - Processing 100 bp from intervals; 10:19:39.490 INFO GenomicsDBImport - Done initializing engine; 10:19:39.948 INFO GenomicsDBLibLoader - GenomicsDB native library version : 1.4.4-ce4e1b9; 10:19:39.951 INFO GenomicsDBImport - Vid Map JSON file will be written to /home/test/Software/gatk-4.4.0.0/test/./02/vidmap.json; 10:19:39.951 INFO GenomicsDBImport - Callset Map JSON file will be written to /home/test/Software/gatk-4.4.0.0/test/./02/callset.json; 10:19:39.951 INFO GenomicsDBImport - Complete VCF Header will be written to /home/test/Software/gatk-4.4.0.0/test/./02/vcfheader.vcf; 10:19:39.951 INFO GenomicsDBImport - Importing to workspace - /home/test/Software/gatk-4.4.0.0/test/./02; 10:19:40.060 INFO GenomicsDBImport - Importing batch 1 with 2 samples; 10:19:40.075 INFO GenomicsDBImport - Shutting down engine; org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImport done. Elapsed time: 0.01 minutes.; Runtime.totalMemory()=285212672; java.lang.NumberFormatException: For input string: ""G""; 	at java.base/java.lang.NumberFormatException.forInputString(NumberFormatException.java:67); 	at java.base/java.lang.Integer.parseInt(Integer.java:668); 	at java.base/java.lang.Integer.parseInt(Integer.java:786); 	at htsjdk.tribble.readers.TabixReader.getIntv(TabixReader.java:337); 	at htsjdk.tribble.readers.TabixReader.access$500(TabixReader.java:48); 	at htsjdk.tribble.readers.TabixReader$IteratorImpl.next(TabixReader.java:438); 	at htsjdk.tribble.readers.TabixIteratorLineReader.readLine(TabixIteratorLineReader.java:46); 	at htsjdk.tribble.TabixFeatureReader$FeatureIterator.readNextRecord(TabixFeatureReader.java:170); 	at htsjdk.tribble.TabixFeatureReader$FeatureIterator.<init>(TabixFeatureReader.java:159); 	at htsjdk.tribble.TabixFeatureReader.query(TabixFeatureReader.java:13",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8517:3029,down,down,3029,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8517,1,['down'],['down']
Availability," - HTSJDK Defaults.COMPRESSION_LEVEL : 1; 00:48:13.680 INFO MarkDuplicatesSpark - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 00:48:13.680 INFO MarkDuplicatesSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : false; 00:48:13.680 INFO MarkDuplicatesSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 00:48:13.680 INFO MarkDuplicatesSpark - Deflater: IntelDeflater; 00:48:13.680 INFO MarkDuplicatesSpark - Inflater: IntelInflater; 00:48:13.680 INFO MarkDuplicatesSpark - Initializing engine; 00:48:13.680 INFO MarkDuplicatesSpark - Done initializing engine; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@4aa298b7] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@37574691].; log4j:ERROR Could not instantiate appender named ""console"".; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; log4j:WARN No appenders could be found for logger (org.apache.spark.SparkContext).; log4j:WARN Please initialize the log4j system properly.; log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.; 00:48:19.247 INFO MarkDuplicatesSpark - Shutting down engine; [June 7, 2017 12:48:19 AM UTC] org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSpark done. Elapsed time: 0.10 minutes.; Runtime.totalMemory()=1029701632; org.apache.spark.SparkException: Job aborted due to stage failure: Task 15 in stage 0.0 failed 4 times, most recent failure: Lost task 15.3 in stage 0.0 (TID 59, 172.31.77.139, executor 0): java.lang.IllegalStateException: unread block data; at java.io.ObjectInputStream$BlockDataInputStream.setBlockDataMode(ObjectInputStream.java:2722); at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1565); a",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3050:4121,ERROR,ERROR,4121,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3050,1,['ERROR'],['ERROR']
Availability," - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 11:15:57.329 INFO FilterMutectCalls - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 11:15:57.329 INFO FilterMutectCalls - Deflater: IntelDeflater; 11:15:57.329 INFO FilterMutectCalls - Inflater: IntelInflater; 11:15:57.329 INFO FilterMutectCalls - GCS max retries/reopens: 20; 11:15:57.329 INFO FilterMutectCalls - Requester pays: disabled; 11:15:57.329 INFO FilterMutectCalls - Initializing engine; 11:15:57.537 INFO FeatureManager - Using codec VCFCodec to read file file:///tmp/tmp.8lRGFREUhm/MT.vcf.gz; 11:15:57.553 INFO FilterMutectCalls - Done initializing engine; 11:15:57.599 INFO ProgressMeter - Starting traversal; 11:15:57.599 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 11:15:57.599 INFO FilterMutectCalls - Starting pass 0 through the variants; 11:15:57.637 INFO FilterMutectCalls - Finished pass 0 through the variants; 11:15:57.657 INFO FilterMutectCalls - Shutting down engine; [November 7, 2019 11:15:57 AM CET] org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls done. Elapsed time: 0.01 minutes.; Runtime.totalMemory()=2148007936; java.lang.IllegalArgumentException: log10 p: Values must be non-infinite and non-NAN; 	at org.broadinstitute.hellbender.utils.NaturalLogUtils.logSumExp(NaturalLogUtils.java:84); 	at org.broadinstitute.hellbender.utils.NaturalLogUtils.normalizeLog(NaturalLogUtils.java:51); 	at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.clusterProbabilities(SomaticClusteringModel.java:203); 	at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.learnAndClearAccumulatedData(SomaticClusteringModel.java:122); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.learnParameters(Mutect2FilteringEngine.java:156); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls.afterNthPass(FilterMu",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6255:3126,down,down,3126,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6255,1,['down'],['down']
Availability," - Inflater: IntelInflater; 08:33:37.135 INFO FilterAlignmentArtifacts - GCS max retries/reopens: 20; 08:33:37.135 INFO FilterAlignmentArtifacts - Requester pays: disabled; 08:33:37.136 WARN FilterAlignmentArtifacts -. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. Warning: FilterAlignmentArtifacts is an EXPERIMENTAL tool and should not be used for production. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. 08:33:37.136 INFO FilterAlignmentArtifacts - Initializing engine; 08:33:37.531 INFO FeatureManager - Using codec VCFCodec to read file file:///data/filteredVCF/in2510-8.orientationFilter.vcf; 08:33:37.586 INFO FilterAlignmentArtifacts - Done initializing engine; 08:33:37.668 INFO NativeLibraryLoader - Loading libgkl_pairhmm_omp.so from jar:file:/gatk/gatk-package-4.1.9.0-SNAPSHOT-local.jar!/com/intel/gkl/native/libgkl_pairhmm_omp.so; 08:33:37.706 INFO IntelPairHmm - Flush-to-zero (FTZ) is enabled when running PairHMM; 08:33:37.707 INFO IntelPairHmm - Available threads: 8; 08:33:37.707 INFO IntelPairHmm - Requested threads: 4; 08:33:37.707 INFO PairHMM - Using the OpenMP multi-threaded AVX-accelerated native PairHMM implementation; 08:33:37.708 INFO ProgressMeter - Starting traversal; 08:33:37.708 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x00007ff7b7dfe32d, pid=849, tid=0x00007ff82e11d700; #; # JRE version: OpenJDK Runtime Environment (8.0_242-b08) (build 1.8.0_242-8u242-b08-0ubuntu3~18.04-b08); # Java VM: OpenJDK 64-Bit Server VM (25.242-b08 mixed mode linux-amd64 compressed oops); # Problematic frame:; # C [libgkl_smithwaterman5951765478004985534.so+0x132d] smithWatermanBackTrack(dnaSeqPair*, int, int, int, int, int*, int)+0x1bd; #; # Failed to write core dump. Core dumps have been disabled. To enable core dumping, try ""ulimit -c unlimited"" before starting Java again; #; # An error report file w",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7162:5132,Avail,Available,5132,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7162,1,['Avail'],['Available']
Availability," - Started o.s.j.s.ServletContextHandler@6556471b{/jobs,null,AVAILABLE,@Spark}; 10:33:07.349 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@7cdb05aa{/jobs/json,null,AVAILABLE,@Spark}; 10:33:07.351 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@5cb76070{/jobs/job,null,AVAILABLE,@Spark}; 10:33:07.352 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@443ac5b8{/jobs/job/json,null,AVAILABLE,@Spark}; 10:33:07.354 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@753e4eb5{/stages,null,AVAILABLE,@Spark}; 10:33:07.355 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@63318b56{/stages/json,null,AVAILABLE,@Spark}; 10:33:07.357 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@462f8fe9{/stages/stage,null,AVAILABLE,@Spark}; 10:33:07.358 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@b2e1df3{/stages/stage/json,null,AVAILABLE,@Spark}; 10:33:07.359 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@6cf3b3d7{/stages/pool,null,AVAILABLE,@Spark}; 10:33:07.360 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@55c20a91{/stages/pool/json,null,AVAILABLE,@Spark}; 10:33:07.361 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@3ba96967{/storage,null,AVAILABLE,@Spark}; 10:33:07.362 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@1237cade{/storage/json,null,AVAILABLE,@Spark}; 10:33:07.363 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@4509b7{/storage/rdd,null,AVAILABLE,@Spark}; 10:33:07.364 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@5dbc4598{/storage/rdd/json,null,AVAILABLE,@Spark}; 10:33:07.365 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@38a27ace{/environment,null,AVAILABLE,@Spark}; 10:33:07.366 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@7e8783b0{/environment/json,null,AVAILABLE,@Spark}; 10:33:07.367 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@53d2f0ec{/executors,null,AVAILABLE,@Spark}; 10:33:07.36",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8949:45836,AVAIL,AVAILABLE,45836,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8949,1,['AVAIL'],['AVAILABLE']
Availability," ------------------------------------------------------------------------------------------. then I added a name like this:. --variant:VCF $NOW/w-91.raw.g.vcf \; --variant:VCF $NOW/w-92.raw.g.vcf \; --variant:VCF $NOW/w-93.raw.g.vcf \. also met a error like this:. ##### ERROR; ##### ERROR MESSAGE: Your input file has a malformed header: We never saw the required CHROM header line (starting with one #) for the input VCF file; ##### ERROR ------------------------------------------------------------------------------------------. and I change the name like this:. --variant:VCF3 $NOW/w-91.raw.g.vcf \; --variant:VCF3 $NOW/w-92.raw.g.vcf \; --variant:VCF3 $NOW/w-93.raw.g.vcf \. also error:. ##### ERROR MESSAGE: Unable to parse header with error: Your input file has a malformed header: This codec is strictly for VCFv3 and does not support VCFv4.1, for input source: /gss1/home/hjb20181119/panyongpeng/NN1138-2/RIL_genotype/mapping/w-1.raw.g.vcf; ##### ERROR ------------------------------------------------------------------------------------------. I checked my GVCF file and the header is :. ##fileformat=VCFv4.1; ##ALT=<ID=NON_REF,Description=""Represents any possible alternative allele at this location"">; ##FILTER=<ID=LowQual,Description=""Low quality"">; ##FORMAT=<ID=AD,Number=.,Type=Integer,Description=""Allelic depths for the ref and alt alleles in the order listed"">; ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Approximate read depth (reads with MQ=255 or with bad mates are filtered)"">; ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Genotype Quality"">; ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">; ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block"">; ##FORMAT=<ID=PGT,Number=1,Type=String,Description=""Physical phasing haplotype information, describing how the alternate alleles are phased in relation to one another"">; ##FORMAT=<ID=PID,Number=1,Type=String,Description=""Physical phasing ID information, where",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7315:2135,ERROR,ERROR,2135,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7315,1,['ERROR'],['ERROR']
Availability," --MINIMUM_BASE_QUALITY 20 --STOP_AFTER -1 --INCLUDE_BQ_HISTOGRAM false --COUNT_UNPAIRED false --SAMPLE_SIZE 10000 --ALLELE_FRACTION 0.001 --ALLELE_FRACTION 0.005 --ALLELE_FRACTION 0.01 --ALLELE_FRACTION 0.02 --ALLELE_FRACTION 0.05 --ALLELE_FRACTION 0.1 --ALLELE_FRACTION 0.2 --ALLELE_FRACTION 0.3 --ALLELE_FRACTION 0.5 --READ_LENGTH 150 --VERBOSITY INFO --QUIET false --VALIDATION_STRINGENCY STRICT --COMPRESSION_LEVEL 8 --MAX_RECORDS_IN_RAM 500000 --CREATE_INDEX false --CREATE_MD5_FILE false --GA4GH_CLIENT_SECRETS client_secrets.json --help false --version false --showHidden false --USE_JDK_DEFLATER false --USE_JDK_INFLATER false; Sep 16, 2019 2:33:15 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; [Mon Sep 16 02:33:15 UTC 2019] Executing as user@server on Linux 3.10.0-693.21.1.el7.x86_64 amd64; OpenJDK 64-Bit Server VM 1.8.0_192-b01; Deflater: Intel; Inflater: Intel; Provider GCS is available; Picard version: Version:4.1.3.0; [Mon Sep 16 02:33:22 UTC 2019] picard.analysis.CollectWgsMetrics done. Elapsed time: 0.16 minutes.; Runtime.totalMemory()=6996099072; To get help, see http://broadinstitute.github.io/picard/index.html#GettingHelp; java.lang.IllegalArgumentException: The requested position is not covered by this StartEdgingRecordAndOffset object.; at htsjdk.samtools.util.AbstractRecordAndOffset.validateOffset(AbstractRecordAndOffset.java:109); at htsjdk.samtools.util.EdgingRecordAndOffset$StartEdgingRecordAndOffset.getBaseQuality(EdgingRecordAndOffset.java:112); at picard.analysis.FastWgsMetricsCollector.excludeByQuality(FastWgsMetricsCollector.java:189); at picard.analysis.FastWgsMetricsCollector.processRecord(FastWgsMetricsCollector.java:144); at picard.analysis.FastWgsMetricsCollector.addInfo(FastWgsMetricsCollector.java:105); at picard.analysis.WgsMetricsProcessorImpl.processFile(WgsMetricsProcessorImpl.java:93); at picard.analysis.CollectWgsMe",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6163:2078,avail,available,2078,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6163,1,['avail'],['available']
Availability, /work/Analysis/wgs_chr19/callset.json; 15:00:38.849 INFO GenomicsDBImport - Complete VCF Header will be written to /work/Analysis/wgs_chr19/vcfheader.vcf; 15:00:38.850 INFO GenomicsDBImport - Importing to array - /work/Analysis/wgs_chr19/genomicsdb_array; 15:00:38.850 INFO ProgressMeter - Starting traversal; 15:00:38.850 INFO ProgressMeter - Current Locus Elapsed Minutes Batches Processed Batches/Minute; 15:00:39.771 INFO GenomicsDBImport - Importing batch 1 with 5 samples; Buffer resized from 28469bytes to 32688; Buffer resized from 28473bytes to 32630; Buffer resized from 28469bytes to 32745; Buffer resized from 28469bytes to 32717; Buffer resized from 28466bytes to 32648; Buffer resized from 32688bytes to 32758; Buffer resized from 32630bytes to 32726; Buffer resized from 32648bytes to 32703; Buffer resized from 32717bytes to 32751; Buffer resized from 32703bytes to 32765; Buffer resized from 32745bytes to 32768; Buffer resized from 32726bytes to 32763; Buffer resized from 32765bytes to 32767; Buffer resized from 32758bytes to 32765; Buffer resized from 32751bytes to 32762; Buffer resized from 32767bytes to 32769; Buffer resized from 32763bytes to 32768; Buffer resized from 32762bytes to 32768; Buffer resized from 32765bytes to 32767; Buffer resized from 32767bytes to 32769; Buffer resized from 32768bytes to 32769; Buffer resized from 32768bytes to 32769; Buffer resized from 32768bytes to 32769; terminate called after throwing an instance of 'VariantStorageManagerException'; what(): VariantStorageManagerException exception : Error while syncing array chr19$1$58617616 to disk; TileDB error message : [TileDB::utils] Error: Cannot sync file '/work/Analysis/wgs_chr19/chr19$1$58617616/.__a89fdd44-1241-43ba-9072-6fcf116fbc1d139627949156096_1538460040234'; File syncing error. This Issue was generated from your [forums] ; [forums]: https://gatkforums.broadinstitute.org/gatk/discussion/13135/gatk-v4-0-8-1-genomicsdbimport-error-variantstoragemanagerexception-exception/p1,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5342:4336,Error,Error,4336,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5342,5,"['Error', 'error']","['Error', 'error', 'error-variantstoragemanagerexception-exception']"
Availability, 02:07:52.355 INFO IntelPairHmm - Using CPU-supported AVX-512 instructions; 02:07:52.355 INFO IntelPairHmm - Flush-to-zero (FTZ) is enabled when running PairHMM; 02:07:52.356 INFO IntelPairHmm - Available threads: 104; 02:07:52.356 INFO IntelPairHmm - Requested threads: 4; 02:07:52.356 INFO PairHMM - Using the OpenMP multi-threaded AVX-accelerated native PairHMM implementation; 02:07:52.408 INFO ProgressMeter - Starting traversal; 02:07:52.408 INFO ProgressMeter - Current Locus Elapsed Minutes Regions Processed Regions/Minute; 02:07:53.316 WARN InbreedingCoeff - InbreedingCoeff will not be calculated; at least 10 samples must have called genotypes; 02:07:53.598 INFO VectorLoglessPairHMM - Time spent in setup for JNI call : 1.49244E-4; 02:07:53.598 INFO PairHMM - Total compute time in PairHMM computeLogLikelihoods() : 0.007888748000000001; 02:07:53.598 INFO SmithWatermanAligner - Total compute time in java Smith-Waterman : 0.00 sec; 02:07:53.598 INFO HaplotypeCaller - Shutting down engine; [28 November 2019 at 2:07:53 AM IST] org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCaller done. Elapsed time: 0.12 minutes.; Runtime.totalMemory()=8220835840; java.lang.NullPointerException; at org.broadinstitute.hellbender.utils.read.AlignmentUtils.needsConsolidation(AlignmentUtils.java:758); at org.broadinstitute.hellbender.utils.read.AlignmentUtils.consolidateCigar(AlignmentUtils.java:719); at org.broadinstitute.hellbender.utils.read.AlignmentUtils.applyCigarToCigar(AlignmentUtils.java:1290); at org.broadinstitute.hellbender.utils.read.AlignmentUtils.createReadAlignedToRef(AlignmentUtils.java:100); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.AssemblyBasedCallerUtils.realignReadsToTheirBestHaplotype(AssemblyBasedCallerUtils.java:85); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerEngine.callRegion(HaplotypeCallerEngine.java:606); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCaller.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6292:4274,down,down,4274,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6292,1,['down'],['down']
Availability," 02:53:12,34] [info] Aborting all running workflows.; [2019-10-01 02:53:12,34] [info] JobExecutionTokenDispenser stopped; [2019-10-01 02:53:12,35] [info] WorkflowStoreActor stopped; [2019-10-01 02:53:12,35] [info] WorkflowLogCopyRouter stopped; [2019-10-01 02:53:12,35] [info] Shutting down WorkflowManagerActor - Timeout = 3600 seconds; [2019-10-01 02:53:12,35] [info] WorkflowManagerActor All workflows finished; [2019-10-01 02:53:12,35] [info] WorkflowManagerActor stopped; [2019-10-01 02:53:12,65] [info] Connection pools shut down; [2019-10-01 02:53:12,65] [info] Shutting down SubWorkflowStoreActor - Timeout = 1800 seconds; [2019-10-01 02:53:12,65] [info] Shutting down JobStoreActor - Timeout = 1800 seconds; [2019-10-01 02:53:12,65] [info] Shutting down CallCacheWriteActor - Timeout = 1800 seconds; [2019-10-01 02:53:12,65] [info] Shutting down ServiceRegistryActor - Timeout = 1800 seconds; [2019-10-01 02:53:12,65] [info] SubWorkflowStoreActor stopped; [2019-10-01 02:53:12,65] [info] Shutting down DockerHashActor - Timeout = 1800 seconds; [2019-10-01 02:53:12,65] [info] CallCacheWriteActor Shutting down: 0 queued messages to process; [2019-10-01 02:53:12,66] [info] WriteMetadataActor Shutting down: 0 queued messages to process; [2019-10-01 02:53:12,66] [info] KvWriteActor Shutting down: 0 queued messages to process; [2019-10-01 02:53:12,66] [info] JobStoreActor stopped; [2019-10-01 02:53:12,66] [info] Shutting down IoProxy - Timeout = 1800 seconds; [2019-10-01 02:53:12,66] [info] CallCacheWriteActor stopped; [2019-10-01 02:53:12,66] [info] IoProxy stopped; [2019-10-01 02:53:12,66] [info] ServiceRegistryActor stopped; [2019-10-01 02:53:12,67] [info] DockerHashActor stopped; [2019-10-01 02:53:12,69] [info] Database closed; [2019-10-01 02:53:12,69] [info] Stream materializer shut down; [2019-10-01 02:53:12,69] [info] WDL HTTP import resolver closed; Workflow c55a06f3-abc1-4db1-8e0f-ea0303caab2c transitioned to state Failed; ```. Any help will be much appreciated. Thanks.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6189:9964,down,down,9964,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6189,12,['down'],['down']
Availability," 14:25:55.526 INFO Mutect2 - ------------------------------------------------------------; 14:25:55.526 INFO Mutect2 - HTSJDK Version: 2.23.0; 14:25:55.526 INFO Mutect2 - Picard Version: 2.22.8; 14:25:55.526 INFO Mutect2 - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 14:25:55.526 INFO Mutect2 - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 14:25:55.527 INFO Mutect2 - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 14:25:55.527 INFO Mutect2 - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 14:25:55.527 INFO Mutect2 - Deflater: IntelDeflater; 14:25:55.527 INFO Mutect2 - Inflater: IntelInflater; 14:25:55.527 INFO Mutect2 - GCS max retries/reopens: 20; 14:25:55.527 INFO Mutect2 - Requester pays: disabled; 14:25:55.527 INFO Mutect2 - Initializing engine; 14:25:55.994 INFO FeatureManager - Using codec BEDCodec to read file file:///test.bed; 14:25:56.086 INFO IntervalArgumentCollection - Processing 3896357 bp from intervals; 14:25:56.115 INFO Mutect2 - Shutting down engine; [October 7, 2021 2:25:56 PM GMT] org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2 done. Elapsed time: 0.01 minutes.; Runtime.totalMemory()=2102919168; **java.lang.NullPointerException**; at java.util.ComparableTimSort.countRunAndMakeAscending(ComparableTimSort.java:325); at java.util.ComparableTimSort.sort(ComparableTimSort.java:202); at java.util.Arrays.sort(Arrays.java:1312); at java.util.Arrays.sort(Arrays.java:1506); at java.util.ArrayList.sort(ArrayList.java:1462); at java.util.Collections.sort(Collections.java:143); at org.broadinstitute.hellbender.utils.IntervalUtils.sortAndMergeIntervals(IntervalUtils.java:467); at org.broadinstitute.hellbender.utils.IntervalUtils.getIntervalsWithFlanks(IntervalUtils.java:965); at org.broadinstitute.hellbender.utils.IntervalUtils.getIntervalsWithFlanks(IntervalUtils.java:980); at org.broadinstitute.hellbender.engine.MultiIntervalLocalReadShard.(MultiIntervalLocalReadShard.java:59); at org.broadinstitute.hellbender.engine.AssemblyReg",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7496:3046,down,down,3046,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7496,1,['down'],['down']
Availability," 16:25:50 INFO DAGScheduler:54 - Job 4 failed: collect at FindBreakpointEvidenceSpark.java:963, took 30.909355 s; 2019-02-17 16:25:50 INFO AbstractConnector:318 - Stopped Spark@7433ca19{HTTP/1.1,[http/1.1]}{0.0.0.0:4041}; 2019-02-17 16:25:50 INFO SparkUI:54 - Stopped Spark web UI at http://scc-hadoop.bu.edu:4041; 2019-02-17 16:25:50 INFO YarnClientSchedulerBackend:54 - Interrupting monitor thread; 2019-02-17 16:25:50 INFO YarnClientSchedulerBackend:54 - Shutting down all executors; 2019-02-17 16:25:50 INFO YarnSchedulerBackend$YarnDriverEndpoint:54 - Asking each executor to shut down; 2019-02-17 16:25:50 INFO SchedulerExtensionServices:54 - Stopping SchedulerExtensionServices; (serviceOption=None,; services=List(),; started=false); 2019-02-17 16:25:50 INFO YarnClientSchedulerBackend:54 - Stopped; 2019-02-17 16:25:50 INFO BlockManagerInfo:54 - Added taskresult_980 in memory on scc-q04.scc.bu.edu:41981 (size: 4.9 MB, free: 42.5 GB); 2019-02-17 16:25:50 ERROR TransportRequestHandler:210 - Error while invoking RpcHandler#receive() for one-way message.; org.apache.spark.SparkException: Could not find CoarseGrainedScheduler.; at org.apache.spark.rpc.netty.Dispatcher.postMessage(Dispatcher.scala:160); at org.apache.spark.rpc.netty.Dispatcher.postOneWayMessage(Dispatcher.scala:140); at org.apache.spark.rpc.netty.NettyRpcHandler.receive(NettyRpcEnv.scala:655); at org.apache.spark.network.server.TransportRequestHandler.processOneWayMessage(TransportRequestHandler.java:208); at org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:113); at org.apache.spark.network.server.TransportChannelHandler.channelRead(TransportChannelHandler.java:118); at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362); at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348); at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandle",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5685:42920,ERROR,ERROR,42920,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5685,2,"['ERROR', 'Error']","['ERROR', 'Error']"
Availability," 2.21.2; 09:54:54.732 INFO HaplotypeCaller - Picard Version: 2.21.9; 09:54:54.732 INFO HaplotypeCaller - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 09:54:54.732 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 09:54:54.732 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 09:54:54.732 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 09:54:54.732 INFO HaplotypeCaller - Deflater: IntelDeflater; 09:54:54.732 INFO HaplotypeCaller - Inflater: IntelInflater; 09:54:54.732 INFO HaplotypeCaller - GCS max retries/reopens: 20; 09:54:54.732 INFO HaplotypeCaller - Requester pays: disabled; 09:54:54.732 INFO HaplotypeCaller - Initializing engine; 09:55:05.747 INFO HaplotypeCaller - Shutting down engine; [September 11, 2020 9:55:05 AM CEST] org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCaller done. Elapsed time: 0.19 minutes.; Runtime.totalMemory()=5152178176; ***********************************************************************. A USER ERROR has occurred: Fasta dict file file:///home/averdier/test/dna-seq-pipeline/Triticum_aestivum_Claire_EIv1.1.dict for reference file:///home/averdier/test/dna-seq-pipeline/Triticum_aestivum_Claire_EIv1.1.fa.gz does not exist.; Please see http://gatkforums.broadinstitute.org/discussion/1601/how-can-i-prepare-a-fasta-file-to-use-as-reference for help creating it. ***********************************************************************; Set the system property GATK_STACKTRACE_ON_USER_EXCEPTION (--java-options '-DGATK_STACKTRACE_ON_USER_EXCEPTION=true') to print the stack trace. Command 'java -Xmx100G -jar /opt/gatk/gatk-package-4.1.7.0-local.jar HaplotypeCaller -R Triticum_aestivum_Claire_EIv1.1.fa.gz --sequence-dictionary Triticum_aestivum_Claire_EIv1.1.fa.gz.dict -I ClaireTest_MD.bam -O ClaireTest_MD_NoInter; vals_Output.vcf --stand-call-conf 10 --native-pair-hmm-threads 30' failed with 512. ```. I'm using the local gatk of version 4.1.7.0",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6808:2662,ERROR,ERROR,2662,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6808,1,['ERROR'],['ERROR']
Availability," 20:05:41.342 INFO GenomicsDBImport - Importing to array - /tmp/tmp.ceRdvv/GDB/genomicsdb\_array ; ; 20:05:41.342 INFO ProgressMeter - Starting traversal ; ; 20:05:41.342 INFO ProgressMeter - Current Locus Elapsed Minutes Batches Processed Batches/Minute ; ; 20:05:41.890 INFO GenomicsDBImport - Starting batch input file preload ; ; 20:05:42.320 INFO GenomicsDBImport - Finished batch preload ; ; 20:05:42.320 INFO GenomicsDBImport - Importing batch 1 with 100 samples ; ; 20:06:03.127 INFO ProgressMeter - chr1:5149001 0.4 1 2.8. .... 03:37:31.740 INFO GenomicsDBImport - Importing batch 1502 with 19 samples ; ; 03:37:35.318 INFO GenomicsDBImport - Done importing batch 1502/1502 ; ; 03:37:35.318 INFO ProgressMeter - chr1:5149001 451.9 1502 3.3 ; ; 03:37:35.318 INFO ProgressMeter - Traversal complete. Processed 1502 total batches in 451.9 minutes. ; ; 03:37:35.318 INFO GenomicsDBImport - Import of all batches to GenomicsDB completed! ; ; 03:37:35.318 INFO GenomicsDBImport - Shutting down engine ; ; \[July 28, 2020 3:37:35 AM GMT\] org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImport done. Elapsed time: 451.99 minutes. ; ; Runtime.totalMemory()=1351453507584. Running: ; ; java -Dsamjdk.use\_async\_io\_read\_samtools=false -Dsamjdk.use\_async\_io\_write\_samtools=true -Dsamjdk.use\_async\_io\_write\_tribble=false -Dsamjdk.compression\_level=2 -Djava.io.tmpdir=/tmp/tmp.ceRdvv -Xmx71680M -Xms71680M -jar /nfs/fs1/bioinfo/apps-x86\_64/GATK/gatk-4.1.7.0/gatk-package-4.1.7.0-local.jar GenotypeGVCFs --genomicsdb-use-vcf-codec -R /odinn/data/extdata/1000genomes/2019-06-21\_GRCh38/GRCh38\_full\_analysis\_set\_plus\_decoy\_hla.fa -V gendb:///tmp/tmp.ceRdvv/GDB --tmp-dir=/tmp/tmp.ceRdvv --interval-padding 1000 --only-output-calls-starting-in-intervals -L chr1:5161113-5163890 -O /tmp/tmp.ceRdvv/splitdir/reg\_5.padded.vcf.gz ; ; 03:37:53.320 INFO NativeLibraryLoader - Loading libgkl\_compression.so from jar:file:/nfs/fs1/bioinfo/apps-x86\_64/GATK/gatk-4.1.7.0/gatk-package-4.1",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6742:6618,down,down,6618,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6742,1,['down'],['down']
Availability, 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr9_KI270717v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr9_KI270718v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr9_KI270719v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr9_KI270720v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr11_KI270721v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_GL000009v2_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_GL000225v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_KI270722v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_GL000194v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_KI270723v1_ran,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4840:4542,reliab,reliable,4542,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4840,1,['reliab'],['reliable']
Availability," 25, referenceIndex:37. Run the command as follows: ; ```; ./gatk HaplotypeCallerSpark --native-pair-hmm-threads 40 -ERC GVCF -R hg38/fa/GRCh38.fna -I NA12878.sort.dup.BQSR.bam -L random.bed -O NA12878.g.vcf.gz ; ```; The contents of random.bed:; ```; chr1_KI270706v1_random 45744 46286; chr1_KI270706v1_random 69250 69770; chr4_GL000008v2_random 7167 7691; chr4_GL000008v2_random 131611 132154; chr4_GL000008v2_random 155105 155625; chr4_GL000008v2_random 177247 177767; chr4_GL000008v2_random 191280 191800; ```; And the weird thing is that when I removed one of these chromosomes chr1_KI270706v1_random, it works. . ----. ## Bug Report; The following errors were found while running the HaplotypeCallerSpark on WES data; ```; 21/04/13 07:32:24 INFO FileOutputCommitter: File Output Committer Algorithm version is 2; 21/04/13 07:32:24 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false; 21/04/13 07:32:24 INFO FileOutputCommitter: File Output Committer Algorithm version is 2; 21/04/13 07:32:24 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false; 21/04/13 07:32:24 INFO NewHadoopRDD: Input split: file:/data/phoenix-output/LUSH_WES/sz01-huyue-LUSH_WES-2021041210463878ad3/NA12878/LUSH_BQSR/NA12878.sort.dup.BQSR.bam:67108864+29181309; 21/04/13 07:32:24 INFO FileOutputCommitter: Saved output of task 'attempt_20210413073224_0026_r_000001_0' to file:/dev/shm/chr4_GL000008v2_random.g.vcf.gz.parts; 21/04/13 07:32:24 INFO SparkHadoopMapRedUtil: attempt_20210413073224_0026_r_000001_0: Committed; 21/04/13 07:32:24 INFO Executor: Finished task 1.0 in stage 5.0 (TID 106). 762 bytes result sent to driver; 21/04/13 07:32:24 INFO TaskSetManager: Finished task 1.0 in stage 5.0 (TID 106) in 136 ms on localhost (executor driver) (1/3); 21/04/13 07:32:24 INFO FileOutputCommitter: File Output Committer Algorithm version is 2; 21",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7199:989,error,errors,989,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7199,3,"['error', 'failure']","['errors', 'failures']"
Availability," 4:61122642 10.0 19223000 1919197.3; 01:10:04.009 INFO ProgressMeter - 4:77404115 10.2 19546000 1919442.2; 01:10:14.027 INFO ProgressMeter - 4:90982301 10.4 19859000 1918719.2; 01:10:24.037 INFO ProgressMeter - 5:5319910 10.5 20215000 1922132.2; 01:10:34.043 INFO ProgressMeter - 5:13428416 10.7 20557000 1924140.1; 01:10:44.052 INFO ProgressMeter - 5:18554429 10.9 20887000 1924971.5; 01:10:54.053 INFO ProgressMeter - 5:23247594 11.0 21241000 1927979.5; 01:11:04.057 INFO ProgressMeter - 5:25901452 11.2 21588000 1930263.3; 01:11:14.089 INFO ProgressMeter - 5:32482380 11.4 21916000 1930729.5; 01:11:24.106 INFO ProgressMeter - 5:38674297 11.5 22249000 1931652.6; 01:11:34.133 INFO ProgressMeter - 5:49679881 11.7 22573000 1931754.3; 01:11:44.145 INFO ProgressMeter - 5:53234595 11.9 22925000 1934259.1; 04:10:15.659 INFO ProgressMeter - 6:1726401 190.4 23183000 121774.0; 04:10:25.671 INFO ProgressMeter - 6:10206926 190.5 23517000 123420.2; 04:10:31.341 INFO BaseRecalibrator - Shutting down engine; [February 22, 2021 at 4:10:31 AM PST] org.broadinstitute.hellbender.tools.walkers.bqsr.BaseRecalibrator done. Elapsed time: 190.65 minutes.; Runtime.totalMemory()=1268776960; java.lang.IllegalStateException: cigar is completely soft-clipped; at org.broadinstitute.hellbender.utils.Utils.validate(Utils.java:814); at org.broadinstitute.hellbender.utils.read.CigarBuilder.make(CigarBuilder.java:129); at org.broadinstitute.hellbender.utils.read.CigarBuilder.make(CigarBuilder.java:143); at org.broadinstitute.hellbender.utils.recalibration.BaseRecalibrationEngine.consolidateCigar(BaseRecalibrationEngine.java:293); at org.broadinstitute.hellbender.transformers.ReadTransformer.lambda$andThen$f85d1091$1(ReadTransformer.java:20); at org.broadinstitute.hellbender.transformers.ReadTransformer.lambda$andThen$f85d1091$1(ReadTransformer.java:20); at org.broadinstitute.hellbender.transformers.ReadTransformer.lambda$andThen$f85d1091$1(ReadTransformer.java:20); at org.broadinstitute.hellbender.transfo",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7092:8487,down,down,8487,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7092,1,['down'],['down']
Availability," 5740000 672351.6; 13:53:40.253 INFO ProgressMeter - chr19:40111935 8.7 5871000 674471.0; 13:53:50.326 INFO ProgressMeter - chr20:33030731 8.9 5993000 675459.1; 13:54:00.362 INFO ProgressMeter - chr21:27087627 9.0 6111000 676013.0; 13:54:10.423 INFO ProgressMeter - chr22:41712333 9.2 6226000 676191.6; 13:54:20.447 INFO ProgressMeter - chrX:39799780 9.4 6342000 676514.9; 13:54:30.520 INFO ProgressMeter - chrX:91818371 9.5 6453000 676246.2; 13:54:40.591 INFO ProgressMeter - chrX:143619069 9.7 6568000 676399.8; 13:54:50.640 INFO ProgressMeter - chrUn_KI270743v1:125398 9.9 6674000 675662.2; 13:55:00.673 INFO ProgressMeter - chr20_KI270869v1_alt:62679 10.0 6792000 676161.8; 13:55:10.679 INFO ProgressMeter - chr19_GL949752v1_alt:485077 10.2 6910000 676673.7; 13:55:26.149 INFO ProgressMeter - HLA-DRB1*11:01:02:3272 10.5 6938356 662718.7; 13:55:26.149 INFO ProgressMeter - Traversal complete. Processed 6938356 total records in 10.5 minutes.; 13:55:26.149 INFO ComposeSTRTableFile - Shutting down engine; [April 4, 2021 1:55:26 PM EDT] org.broadinstitute.hellbender.tools.dragstr.ComposeSTRTableFile done. Elapsed time: 10.52 minutes.; Runtime.totalMemory()=1128792064; Using GATK jar /share/pkg.7/gatk/4.2.0.0/install/bin/gatk-package-4.2.0.0-local.jar defined in environment variable GATK_LOCAL_JAR; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx16G -jar /share/pkg.7/gatk/4.2.0.0/install/bin/gatk-package-4.2.0.0-local.jar CalibrateDragstrModel -R /restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa --str-table-path gvcf.STR/ADNI_002_S_0413.hg38.realign.bqsr/ADNI_002_S_0413.hg38.realign.bqsr.STR.table -O gvcf.STR/ADNI_002_S_0413.hg38.realign.bqsr/ADNI_002_S_0413.hg38.realign.bqsr.Dragstr.model -I /restricted/projectnb/casa/wgs.hg38/adni/cram/ADNI_002_S_0413.hg38.realign.bqsr.cram; 13:55:30.890 INFO NativeLibraryLoader - Loading libgkl_c",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7182:10993,down,down,10993,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7182,1,['down'],['down']
Availability," 7, 2017 12:48:13 AM UTC] Executing as tianj@ip-xxx-xx-xx-xxx on Linux 4.4.41-36.55.amzn1.x86_64 amd64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_131-b11; Version: 4.alpha.2-1100-g04dbeb2-SNAPSHOT; 00:48:13.680 INFO MarkDuplicatesSpark - HTSJDK Defaults.COMPRESSION_LEVEL : 1; 00:48:13.680 INFO MarkDuplicatesSpark - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 00:48:13.680 INFO MarkDuplicatesSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : false; 00:48:13.680 INFO MarkDuplicatesSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 00:48:13.680 INFO MarkDuplicatesSpark - Deflater: IntelDeflater; 00:48:13.680 INFO MarkDuplicatesSpark - Inflater: IntelInflater; 00:48:13.680 INFO MarkDuplicatesSpark - Initializing engine; 00:48:13.680 INFO MarkDuplicatesSpark - Done initializing engine; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@4aa298b7] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@37574691].; log4j:ERROR Could not instantiate appender named ""console"".; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; log4j:WARN No appenders could be found for logger (org.apache.spark.SparkContext).; log4j:WARN Please initialize the log4j system properly.; log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.; 00:48:19.247 INFO MarkDuplicatesSpark - Shutting down engine; [June 7, 2017 12:48:19 AM UTC] org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSpark done. Elapsed time: 0.10 minutes.; Runtime.totalMemory()=1029701632; org.apache.spark.SparkException: Job aborted due to stage failure: Task 15 in stage 0.0 failed 4 times, most recent failure: Lost task 15.3 in stage 0.0 (TID 59, 172.31.77.139, ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3050:3920,ERROR,ERROR,3920,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3050,1,['ERROR'],['ERROR']
Availability," : false; 16:46:49.700 INFO Mutect2 - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 16:46:49.700 INFO Mutect2 - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 16:46:49.700 INFO Mutect2 - Deflater: IntelDeflater; 16:46:49.700 INFO Mutect2 - Inflater: IntelInflater; 16:46:49.700 INFO Mutect2 - GCS max retries/reopens: 20; 16:46:49.700 INFO Mutect2 - Using google-cloud-java patch 6d11bef1c81f885c26b2b56c8616b7a705171e4f from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 16:46:49.700 INFO Mutect2 - Initializing engine; 16:46:49.995 INFO FeatureManager - Using codec VCFCodec to read file file:///home/vip/data/Mutect2/af-only-gnomad.raw.sites.hg19.vcf.gz; 16:46:50.064 INFO Mutect2 - Shutting down engine; [November 6, 2019 4:46:50 PM CST] org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2 done. Elapsed time: 0.01 minutes.; Runtime.totalMemory()=2394947584; org.broadinstitute.hellbender.exceptions.GATKException: Error initializing feature reader for path /home/vip/data/Mutect2/af-only-gnomad.raw.sites.hg19.vcf.gz; 	at org.broadinstitute.hellbender.engine.FeatureDataSource.getTribbleFeatureReader(FeatureDataSource.java:357); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.getFeatureReader(FeatureDataSource.java:308); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:255); 	at org.broadinstitute.hellbender.engine.FeatureManager.addToFeatureSources(FeatureManager.java:202); 	at org.broadinstitute.hellbender.engine.FeatureManager.initializeFeatureSources(FeatureManager.java:182); 	at org.broadinstitute.hellbender.engine.FeatureManager.<init>(FeatureManager.java:153); 	at org.broadinstitute.hellbender.engine.GATKTool.initializeFeatures(GATKTool.java:415); 	at org.broadinstitute.hellbender.engine.GATKTool.onStartup(GATKTool.java:636); 	at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.onStartup(AssemblyRegionWalker.java:160); 	at org.broadinstitute.hellbender.cmdline.Comm",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6248:3073,Error,Error,3073,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6248,1,['Error'],['Error']
Availability," ; **20/03/05 09:28:58 INFO Executor: Executor is trying to kill task 6.0 in stage 0.0 (TID 6), reason: Stage cancelled** ; **20/03/05 09:28:58 INFO Executor: Executor is trying to kill task 36.0 in stage 0.0 (TID 36), reason: Stage cancelled** ; **20/03/05 09:28:58 INFO Executor: Executor is trying to kill task 28.0 in stage 0.0 (TID 28), reason: Stage cancelled** ; **20/03/05 09:28:58 INFO Executor: Executor is trying to kill task 7.0 in stage 0.0 (TID 7), reason: Stage cancelled** ; **20/03/05 09:28:58 INFO Executor: Executor is trying to kill task 29.0 in stage 0.0 (TID 29), reason: Stage cancelled** ; **20/03/05 09:28:58 INFO Executor: Executor is trying to kill task 8.0 in stage 0.0 (TID 8), reason: Stage cancelled** ; **20/03/05 09:28:58 INFO TaskSchedulerImpl: Stage 0 was cancelled** ; **20/03/05 09:28:58 INFO DAGScheduler: ShuffleMapStage 0 (mapToPair at PSFilter.java:125) failed in 63.548 s due to Job aborted due to stage failure: Task 34 in stage 0.0 failed 1 times, most recent failure: Lost task 34.0 in stage 0.0 (TID 34, localhost, executor driver): com.esotericsoftware.kryo.KryoException: Buffer underflow.** ; **at com.esotericsoftware.kryo.io.Input.require(Input.java:199)** ; **at com.esotericsoftware.kryo.io.Input.readLong(Input.java:686)** ; **at org.broadinstitute.hellbender.tools.spark.utils.LongHopscotchSet.<init>(LongHopscotchSet.java:83)** ; **at org.broadinstitute.hellbender.tools.spark.utils.LongHopscotchSet$Serializer.read(LongHopscotchSet.java:527)** ; **at org.broadinstitute.hellbender.tools.spark.utils.LongHopscotchSet$Serializer.read(LongHopscotchSet.java:519)** ; **at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:712)** ; **at org.broadinstitute.hellbender.tools.spark.utils.LargeLongHopscotchSet.<init>(LargeLongHopscotchSet.java:55)** ; **at org.broadinstitute.hellbender.tools.spark.utils.LargeLongHopscotchSet$Serializer.read(LargeLongHopscotchSet.java:172)** ; **at org.broadinstitute.hellbender.tools.spark.utils.LargeLongHopscotc",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6493:38092,failure,failure,38092,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6493,1,['failure'],['failure']
Availability," = main_function(); File ""${INSTALLDIRGATK}/lib/python3.6/site-packages/bin/theano_nose.py"", line 45, in main_function; from theano import config; File ""${INSTALLDIRGATK}/lib/python3.6/site-packages/theano/__init__.py"", line 110, in <module>; from theano.compile import (; File ""${INSTALLDIRGATK}/lib/python3.6/site-packages/theano/compile/__init__.py"", line 12, in <module>; from theano.compile.mode import *; File ""${INSTALLDIRGATK}/lib/python3.6/site-packages/theano/compile/mode.py"", line 11, in <module>; import theano.gof.vm; File ""${INSTALLDIRGATK}/lib/python3.6/site-packages/theano/gof/vm.py"", line 674, in <module>; from . import lazylinker_c; File ""${INSTALLDIRGATK}/lib/python3.6/site-packages/theano/gof/lazylinker_c.py"", line 140, in <module>; preargs=args); File ${INSTALLDIRGATK}/lib/python3.6/site-packages/theano/gof/cmodule.py"", line 2396, in compile_str; (status, compile_stderr.replace('\n', '. '))); Exception: Compilation failed (return status=1): /usr/bin/ld.gold: error: ${INSTALLDIRGCC}/bin/../lib/gcc/x86_64-pc-linux-gnu/7.3.0/crtbeginS.o: unsupported reloc 42 against global symbol _ITM_deregisterTMCloneTable. /usr/bin/ld.gold: error: ${INSTALLDIRGCC}/bin/../lib/gcc/x86_64-pc-linux-gnu/7.3.0/crtbeginS.o: unsupported reloc 42 against global symbol _ITM_registerTMCloneTable. ${INSTALLDIRGCC}/bin/../lib/gcc/x86_64-pc-linux-gnu/7.3.0/crtbeginS.o(.text+0x1a): error: unsupported reloc 42. ${INSTALLDIRGCC}/bin/../lib/gcc/x86_64-pc-linux-gnu/7.3.0/crtbeginS.o(.text+0x6b): error: unsupported reloc 42. collect2: error: ld returned 1 exit status. ```. Then I have installed theano with python 3.6.6 which is compiled with gcc 5.4.0, and it was giving me no errors. ```sh. $ theano-nose . ----------------------------------------------------------------------; Ran 0 tests in 0.012s. OK; ```. The Theano toolchain issue might be caused by theano not being actively developed anymore. Probably they never tested it with newer toolchains.; See this message that is also on the T",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5766:2942,error,error,2942,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5766,1,['error'],['error']
Availability, > 894 expanding to 1790; > 21:14:17.874 DEBUG MathUtils$Log10Cache - cache miss 1791 > 1790 expanding to 3582; > 21:14:17.894 DEBUG GenotypeLikelihoodCalculators - Expanding capacity ploidy:2->2 allele:1->2; > 21:14:17.930 DEBUG GenotypeLikelihoodCalculators - Expanding capacity ploidy:2->2 allele:1->2; > 21:14:17.937 DEBUG GenotypeLikelihoodCalculators - Expanding capacity ploidy:2->2 allele:1->2; > 21:14:18.507 DEBUG GenotypeLikelihoodCalculators - Expanding capacity ploidy:2->2 allele:3->4; > 21:14:18.510 DEBUG GenotypeLikelihoodCalculators - Expanding capacity ploidy:2->2 allele:2->3; > 21:27:38.720 DEBUG GenotypeLikelihoodCalculators - Expanding capacity ploidy:2->2 allele:2->3; > 21:28:26.332 DEBUG GenotypeLikelihoodCalculators - Expanding capacity ploidy:2->2 allele:2->3; > 21:30:24.296 DEBUG GenotypeLikelihoodCalculators - Expanding capacity ploidy:2->2 allele:4->5; > 21:30:24.299 DEBUG GenotypeLikelihoodCalculators - Expanding capacity ploidy:2->2 allele:3->4; > . Here's standard error:. > WARNING: No valid combination operation found for INFO field DS - the field will NOT be part of INFO fields in the generated VCF records; > WARNING: No valid combination operation found for INFO field InbreedingCoeff - the field will NOT be part of INFO fields in the generated VCF records; > WARNING: No valid combination operation found for INFO field MLEAC - the field will NOT be part of INFO fields in the generated VCF records; > WARNING: No valid combination operation found for INFO field MLEAF - the field will NOT be part of INFO fields in the generated VCF records; > WARNING: No valid combination operation found for INFO field DS - the field will NOT be part of INFO fields in the generated VCF records; > WARNING: No valid combination operation found for INFO field InbreedingCoeff - the field will NOT be part of INFO fields in the generated VCF records; > WARNING: No valid combination operation found for INFO field MLEAC - the field will NOT be part of INFO fields in,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4161:7136,error,error,7136,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4161,1,['error'],['error']
Availability," > Execution of ""git lfs pull --include src/main/resources/large"" failed with exit code: 2. git-lfs is required to build GATK but may not be installed. See https://github.com/broadinstitute/gatk#building for information on how to build GATK.; 22:05:55.967 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] ; 22:05:55.968 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] * Exception is:; 22:05:55.969 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] org.gradle.api.GradleScriptException: A problem occurred evaluating root project 'gatk'.; 22:05:55.969 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.groovy.scripts.internal.DefaultScriptRunnerFactory$ScriptRunnerImpl.run(DefaultScriptRunnerFactory.java:92); 22:05:55.969 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.DefaultScriptPluginFactory$ScriptPluginImpl$2.run(DefaultScriptPluginFactory.java:176); 22:05:55.970 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.ProjectScriptTarget.addConfiguration(ProjectScriptTarget.java:77); 22:05:55.970 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.DefaultScriptPluginFactory$ScriptPluginImpl.apply(DefaultScriptPluginFactory.java:181); 22:05:55.970 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.project.BuildScriptProcessor.execute(BuildScriptProcessor.java:38); 22:05:55.970 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.project.BuildScriptProcessor.execute(BuildScriptProcessor.java:25); 22:05:55.970 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.project.ConfigureActionsProjectEvaluator.evaluate(ConfigureActionsProjectEvaluator.java:34); 22:05:55.970 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.config",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4687:2389,ERROR,ERROR,2389,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4687,1,['ERROR'],['ERROR']
Availability," @ronlevine commented on [Mon Nov 28 2016](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-263280085). That's exactly what I did in https://github.com/samtools/htsjdk/pull/759. I can expand this to all INFO field annotations. ---. @ldgauthier commented on [Tue Dec 06 2016](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-265221057). Expanding to all INFO annotations would be wonderful, but that can be a separate issue. ---. @ronlevine commented on [Tue Dec 06 2016](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-265223581). That's not the only one, @magicDGS requested validating the `AF` values (which can be a separate issue). . ---. @vdauwera commented on [Tue Dec 06 2016](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-265226356). I think this one requires some additional discussion, so let's hold off for now -- it's not essential for 3.7 and we can't wait any longer to release. ---. @vdauwera commented on [Mon Mar 20 2017](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-287824654). @ldgauthier Would it be ok to kick this down the road to whenever ValidateVariants gets ported to GATK4?. ---. @ldgauthier commented on [Tue Mar 21 2017](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-288223822). Yeah, this isn't critical for any production pipelines - pass that buck. On Mar 20, 2017 12:56 PM, ""Geraldine Van der Auwera"" <; notifications@github.com> wrote:. > @ldgauthier <https://github.com/ldgauthier> Would it be ok to kick this; > down the road to whenever ValidateVariants gets ported to GATK4?; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-287824654>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AGRhdLPwS6I5nu9TQiw4BFqRojmTiL0aks5rnq_OgaJpZM4FaLwX>; > .; >",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2507:7806,down,down,7806,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2507,2,['down'],['down']
Availability," Affected tool(s) or class(es); - Tool/class name(s), special parameters: GenomicsDBImport. ### Affected version(s); - Version: gatk4-4.4.0.0-0. ### Description ; Hello,. I have been having an issue come up when utilizing `GenomicsDBImport`. This issue has happened when using a range of samples and shard counts (8 - 1000 samples, shard count of up to 2000). My current example is an attempt to joint call 1000 samples together. I will submit the jobs and 1-2 of the shards (of the ~100 concurrently running) will throw a `malloc(): unaligned tcache chunk detected`. When I resubmit that shard, it will usually rerun without a problem. Or if I kill all jobs and resubmit, a different shard will throw the malloc error. . I have run approximately 20 tests and I seem to get this failure 2/3 times. However, it only arises on the initial submission and not when additional jobs are submitted as previous shards complete. Please note that the 1000 samples have successfully been imported into the GenomicsDB but this error seems to persist somewhat randomly across multiple machines. . Thank you for your assistance! . #### Steps to reproduce. - Command used (omitting paths to 1000 samples for brevity) for one of the failed shards. ```; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx8g -jar /gpfs/gpfs_de6000/home/dalegre/miniconda3/envs/GOASTv4.0/share/gatk4-4.4.0.0-0/gatk-package-4.4.0.0-local.jar GenomicsDBImport -V [samples 1-1002] --genomicsdb-workspace-path results/jointcalling/genomicsDB/temp_0882_of_2000_DB --merge-input-intervals false --bypass-feature-reader --tmp-dir temp --max-num-intervals-to-import-in-parallel 10 --batch-size 50 --intervals results/germline/interval/temp_0882_of_2000/scattered.interval_list --genomicsdb-shared-posixfs-optimizations true; ```. #### Expected behavior; All shards are imported into the GenomicsDB successfully. . #### Actual beha",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8683:1039,error,error,1039,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8683,1,['error'],['error']
Availability," ContextHandler - Stopped o.s.j.s.ServletContextHandler@7074da1d{/,null,STOPPED,@Spark}; 10:33:07.347 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@6556471b{/jobs,null,AVAILABLE,@Spark}; 10:33:07.349 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@7cdb05aa{/jobs/json,null,AVAILABLE,@Spark}; 10:33:07.351 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@5cb76070{/jobs/job,null,AVAILABLE,@Spark}; 10:33:07.352 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@443ac5b8{/jobs/job/json,null,AVAILABLE,@Spark}; 10:33:07.354 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@753e4eb5{/stages,null,AVAILABLE,@Spark}; 10:33:07.355 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@63318b56{/stages/json,null,AVAILABLE,@Spark}; 10:33:07.357 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@462f8fe9{/stages/stage,null,AVAILABLE,@Spark}; 10:33:07.358 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@b2e1df3{/stages/stage/json,null,AVAILABLE,@Spark}; 10:33:07.359 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@6cf3b3d7{/stages/pool,null,AVAILABLE,@Spark}; 10:33:07.360 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@55c20a91{/stages/pool/json,null,AVAILABLE,@Spark}; 10:33:07.361 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@3ba96967{/storage,null,AVAILABLE,@Spark}; 10:33:07.362 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@1237cade{/storage/json,null,AVAILABLE,@Spark}; 10:33:07.363 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@4509b7{/storage/rdd,null,AVAILABLE,@Spark}; 10:33:07.364 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@5dbc4598{/storage/rdd/json,null,AVAILABLE,@Spark}; 10:33:07.365 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@38a27ace{/environment,null,AVAILABLE,@Spark}; 10:33:07.366 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@7e8783b0{/environment/json,null,AVAILABLE,@Spark}; 10:33:",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8949:45717,AVAIL,AVAILABLE,45717,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8949,1,['AVAIL'],['AVAILABLE']
Availability, DEBUG Mutect2 - Processing assembly region at chrM:13321-13620 isActive: false numReads: 55070; 12:09:01.757 DEBUG Mutect2 - Processing assembly region at chrM:13621-13636 isActive: false numReads: 55240; 12:09:02.341 DEBUG Mutect2 - Processing assembly region at chrM:13637-13936 isActive: true numReads: 110273; 12:09:09.957 DEBUG ReadThreadingGraph - Recovered 24 of 26 dangling tails; 12:09:10.041 DEBUG ReadThreadingGraph - Recovered 6 of 14 dangling heads; 12:09:10.602 DEBUG Mutect2Engine - Active Region chrM:13637-13936; 12:09:10.608 DEBUG Mutect2Engine - Extended Act Region chrM:13537-14036; 12:09:10.613 DEBUG Mutect2Engine - Ref haplotype coords chrM:13537-14036; 12:09:10.617 DEBUG Mutect2Engine - Haplotype count 128; 12:09:10.621 DEBUG Mutect2Engine - Kmer sizes count 0; 12:09:10.625 DEBUG Mutect2Engine - Kmer sizes values []; 12:13:51.290 DEBUG Mutect2 - Processing assembly region at chrM:13937-13944 isActive: true numReads: 54773; 12:13:53.989 DEBUG ReadThreadingGraph - Recovered 29 of 59 dangling tails; 12:13:54.004 DEBUG ReadThreadingGraph - Recovered 0 of 35 dangling heads; 12:13:54.432 DEBUG Mutect2Engine - Active Region chrM:13937-13944; 12:13:54.440 DEBUG Mutect2Engine - Extended Act Region chrM:13837-14044; 12:13:54.447 DEBUG Mutect2Engine - Ref haplotype coords chrM:13837-14044; 12:13:54.452 DEBUG Mutect2Engine - Haplotype count 128; 12:13:54.456 DEBUG Mutect2Engine - Kmer sizes count 0; 12:13:54.462 DEBUG Mutect2Engine - Kmer sizes values []; 12:13:55.715 DEBUG Mutect2 - Processing assembly region at chrM:13945-14244 isActive: false numReads: 54745; 12:13:56.962 DEBUG Mutect2 - Processing assembly region at chrM:14245-14544 isActive: false numReads: 0; 12:13:56.973 DEBUG Mutect2 - Processing assembly region at chrM:14545-14844 isActive: false numReads: 0; 12:13:56.984 DEBUG Mutect2 - Processing assembly region at chrM:14845-15144 isActive: false numReads: 0; 12:13:56.995 DEBUG Mutect2 - Processing assembly region at chrM:15145-15444 isActive: false ,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7281:20767,Recover,Recovered,20767,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7281,1,['Recover'],['Recovered']
Availability, DEBUG ReadThreadingGraph - Recovered 2 of 24 dangling heads; 11:41:57.286 DEBUG IntToDoubleFunctionCache - cache miss 136737 > 53234 expanding to 136747; 11:41:57.301 DEBUG IntToDoubleFunctionCache - cache miss 136976 > 136747 expanding to 273496; 11:41:57.935 DEBUG Mutect2Engine - Active Region chrM:8830-9129; 11:41:57.937 DEBUG Mutect2Engine - Extended Act Region chrM:8730-9229; 11:41:57.939 DEBUG Mutect2Engine - Ref haplotype coords chrM:8730-9229; 11:41:57.940 DEBUG Mutect2Engine - Haplotype count 128; 11:41:57.941 DEBUG Mutect2Engine - Kmer sizes count 0; 11:41:57.942 DEBUG Mutect2Engine - Kmer sizes values []; 11:53:42.116 DEBUG Mutect2 - Processing assembly region at chrM:9130-9143 isActive: true numReads: 148251; 11:53:58.336 DEBUG ReadThreadingGraph - Recovered 4 of 9 dangling tails; 11:53:58.398 DEBUG ReadThreadingGraph - Recovered 0 of 20 dangling heads; 11:54:11.645 DEBUG ReadThreadingGraph - Recovered 20 of 23 dangling tails; 11:54:11.670 DEBUG ReadThreadingGraph - Recovered 0 of 60 dangling heads; 11:54:11.843 DEBUG Mutect2Engine - Active Region chrM:9130-9143; 11:54:11.852 DEBUG Mutect2Engine - Extended Act Region chrM:9030-9243; 11:54:11.861 DEBUG Mutect2Engine - Ref haplotype coords chrM:9030-9243; 11:54:11.870 DEBUG Mutect2Engine - Haplotype count 232; 11:54:11.879 DEBUG Mutect2Engine - Kmer sizes count 0; 11:54:11.889 DEBUG Mutect2Engine - Kmer sizes values []; 11:54:21.878 DEBUG IntToDoubleFunctionCache - cache miss 96632 > 95278 expanding to 190558; 11:54:22.252 DEBUG Mutect2 - Processing assembly region at chrM:9144-9301 isActive: false numReads: 273760; 11:54:28.421 DEBUG Mutect2 - Processing assembly region at chrM:9302-9584 isActive: true numReads: 250870; 11:55:47.246 DEBUG ReadThreadingGraph - Recovered 13 of 14 dangling tails; 11:55:47.346 DEBUG ReadThreadingGraph - Recovered 6 of 47 dangling heads; 11:55:47.787 DEBUG Mutect2Engine - Active Region chrM:9302-9584; 11:55:47.792 DEBUG Mutect2Engine - Extended Act Region chrM:9202-9684; 11:5,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7281:16494,Recover,Recovered,16494,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7281,1,['Recover'],['Recovered']
Availability," Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 05:06:55.412 INFO SelectVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 05:06:55.412 INFO SelectVariants - Deflater: IntelDeflater; 05:06:55.412 INFO SelectVariants - Inflater: IntelInflater; 05:06:55.412 INFO SelectVariants - GCS max retries/reopens: 20; 05:06:55.412 INFO SelectVariants - Using google-cloud-java patch 6d11bef1c81f885c26b2b56c8616b7a705171e4f from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 05:06:55.412 INFO SelectVariants - Initializing engine; 05:06:55.796 INFO FeatureManager - Using codec VCFCodec to read file file:///disk/juntong/huada/V300029595_results/mutect_outputs/V300029595.merged.vcf.gatk.somatic.vcf.gz; 05:06:55.962 INFO SelectVariants - Done initializing engine; 05:06:56.099 INFO ProgressMeter - Starting traversal; 05:06:56.099 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 06:39:06.894 INFO SelectVariants - Shutting down engine; [November 6, 2019 6:39:06 AM EST] org.broadinstitute.hellbender.tools.walkers.variantutils.SelectVariants done. Elapsed time: 92.20 minutes.; Runtime.totalMemory()=29215424512; Exception in thread ""main"" java.lang.OutOfMemoryError: Java heap space; at java.util.Arrays.copyOf(Arrays.java:3181); at java.util.ArrayList.grow(ArrayList.java:265); at java.util.ArrayList.ensureExplicitCapacity(ArrayList.java:239); at java.util.ArrayList.ensureCapacityInternal(ArrayList.java:231); at java.util.ArrayList.add(ArrayList.java:462); at htsjdk.variant.variantcontext.GenotypeLikelihoods.calculatePLIndexToAlleleIndices(GenotypeLikelihoods.java:392); at htsjdk.variant.variantcontext.GenotypeLikelihoods.calculatePLIndexToAlleleIndices(GenotypeLikelihoods.java:394); at htsjdk.variant.variantcontext.GenotypeLikelihoods.calculatePLIndexToAlleleIndices(GenotypeLikelihoods.java:394); at htsjdk.variant.variantcontext.GenotypeLikelihoods.calculatePLIndexToAlleleIndices(GenotypeLikelihoods.java:394); at ht",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6254:3562,down,down,3562,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6254,1,['down'],['down']
Availability, FilterMutectCalls - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 22:09:03.377 INFO FilterMutectCalls - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 22:09:03.377 INFO FilterMutectCalls - Deflater: IntelDeflater; 22:09:03.377 INFO FilterMutectCalls - Inflater: IntelInflater; 22:09:03.377 INFO FilterMutectCalls - GCS max retries/reopens: 20; 22:09:03.377 INFO FilterMutectCalls - Requester pays: disabled; 22:09:03.378 INFO FilterMutectCalls - Initializing engine; 22:09:04.031 INFO FeatureManager - Using codec VCFCodec to read file file:///data/nws/WES/GenomicsDBImport/200924_A00679_0401_AHKGKKDSXY/Set13-3_L3_379X79.somatic.vcf.gz; 22:09:04.071 INFO FilterMutectCalls - Shutting down engine; [2021年2月28日 下午10时09分04秒] org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls done. Elapsed time: 0.52 minutes.; Runtime.totalMemory()=1552416768; org.broadinstitute.hellbender.exceptions.GATKException: Error initializing feature reader for path /data/nws/WES/GenomicsDBImport/200924_A00679_0401_AHKGKKDSXY/Set13-3_L3_379X79.somatic.vcf.gz; 	at org.broadinstitute.hellbender.engine.FeatureDataSource.getTribbleFeatureReader(FeatureDataSource.java:375); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.getFeatureReader(FeatureDataSource.java:327); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:277); 	at org.broadinstitute.hellbender.engine.VariantWalker.initializeDrivingVariants(VariantWalker.java:58); 	at org.broadinstitute.hellbender.engine.VariantWalkerBase.initializeFeatures(VariantWalkerBase.java:67); 	at org.broadinstitute.hellbender.engine.GATKTool.onStartup(GATKTool.java:706); 	at org.broadinstitute.hellbender.engine.VariantWalker.onStartup(VariantWalker.java:45); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:137); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); 	at org.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7114:2963,Error,Error,2963,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7114,1,['Error'],['Error']
Availability," HaplotypeCaller - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 12:55:36.414 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 12:55:36.414 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 12:55:36.414 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 12:55:36.415 INFO HaplotypeCaller - Deflater: IntelDeflater; 12:55:36.415 INFO HaplotypeCaller - Inflater: IntelInflater; 12:55:36.415 INFO HaplotypeCaller - GCS max retries/reopens: 20; 12:55:36.415 INFO HaplotypeCaller - Requester pays: disabled; 12:55:36.415 INFO HaplotypeCaller - Initializing engine; 12:55:36.508 INFO IntervalArgumentCollection - Processing 1 bp from intervals; 12:55:36.511 INFO HaplotypeCaller - Done initializing engine; 12:55:36.515 INFO HaplotypeCallerEngine - Disabling physical phasing, which is supported only for reference-model confidence output; 12:55:36.523 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/home/linux/Downloads/SNP/gatk-4.2.0.0/gatk-package-4.2.0.0-local.jar!/com/intel/gkl/native/libgkl_utils.so; 12:55:36.524 INFO NativeLibraryLoader - Loading libgkl_pairhmm_omp.so from jar:file:/home/linux/Downloads/SNP/gatk-4.2.0.0/gatk-package-4.2.0.0-local.jar!/com/intel/gkl/native/libgkl_pairhmm_omp.so; 12:55:36.552 INFO IntelPairHmm - Flush-to-zero (FTZ) is enabled when running PairHMM; 12:55:36.553 INFO IntelPairHmm - Available threads: 12; 12:55:36.553 INFO IntelPairHmm - Requested threads: 4; 12:55:36.553 INFO PairHMM - Using the OpenMP multi-threaded AVX-accelerated native PairHMM implementation; 12:55:36.569 INFO ProgressMeter - Starting traversal; 12:55:36.569 INFO ProgressMeter - Current Locus Elapsed Minutes Regions Processed Regions/Minute; 12:55:36.587 INFO HaplotypeCaller - 0 read(s) filtered by: MappingQualityReadFilter ; 0 read(s) filtered by: MappingQualityAvailableReadFilter ; 0 read(s) filtered by: MappedReadFilter ; 0 read(s) filtered by: NotSecondaryAlignmentReadFilter ; ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7229:2162,Down,Downloads,2162,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7229,1,['Down'],['Downloads']
Availability," I am running GATK via a docker container as described here: https://gatk.broadinstitute.org/hc/en-us/articles/360035889991--How-to-Run-GATK-in-a-Docker-container. ``` bash; ./gatk Mutect2 -I:tumor 1st.chr1.bam -I:normal 2nd.chr1.bam -O variants.vcf.gz --min-pruning 8 -R reference.chr1.fa; ```; I repeated this three times, the last time to make sure whether the .vcf.stats is being generated or not. This was a test run using the input filtered for chr1 using `samtools view -b`. I though this was the reason for getting the error message about Contig 2 not being present. ```bash; ...; 18:39:03.207 INFO ProgressMeter - 1:282722440 448.7 1529870 3409.8; 18:39:06.592 INFO VectorLoglessPairHMM - Time spent in setup for JNI call : 19.218222963000002; 18:39:06.592 INFO PairHMM - Total compute time in PairHMM computeLogLikelihoods() : 5376.604473962; 18:39:06.593 INFO SmithWatermanAligner - Total compute time in java Smith-Waterman : 12201.77 sec; 18:39:06.594 INFO Mutect2 - Shutting down engine; [August 25, 2020 6:39:06 PM GMT] org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2 done. Elapsed time: 448.75 minutes.; Runtime.totalMemory()=12349079552; ***********************************************************************. A USER ERROR has occurred: Contig 2 not present in the sequence dictionary [1]. ***********************************************************************; Set the system property GATK_STACKTRACE_ON_USER_EXCEPTION (--java-options '-DGATK_STACKTRACE_ON_USER_EXCEPTION=true') to print the stack trace.; ```; Is there any way of getting around this and generating .vcf.stats without repeating a lengthy variant calling `Mutect2`? Is this a problem introduced by running the truncated input files?. Looking up online, it seems this seemed to be an issue in the previous versions of GATK:https://github.com/broadinstitute/gatk/issues/6102. Thanks!. #### Expected behavior; I would expect .vcf.stats to be automatically generated with the output. #### Actual behavior; N",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6768:1302,down,down,1302,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6768,1,['down'],['down']
Availability," I failed to find hg19 host reference in the GATK resource bundle, first I created a BWA image file and a Kmer file originated from hg19 reference fasta with the command below. But for microbe-related files, I used ones that were contained in the bundle.  . **'''** ; ; **gatk --java-options ""-Xmx50G"" BwaMemIndexImageCreator -I ./ref.fasta** ; **gatk --java-options ""-Xmx50G"" PathSeqBuildKmers --reference ./ref.fasta -O ref.hss** ; ; **'''**.  . And then I ran PathSeq with the following command.  . **'''** ; ; **gatk --java-options ""-Xmx200G"" PathSeqPipelineSpark \** ; **--input sample.bam \** ; **--filter-bwa-image ref.fasta.img \** ; **--kmer-file ref.hss \** ; **--is-host-aligned true \** ; **--min-clipped-read-length 70 \** ; **--microbe-fasta pathseq\_microbe.fa \** ; **--microbe-bwa-image pathseq\_microbe.fa.img \** ; **--taxonomy-file pathseq\_taxonomy.db \** ; **--output sample.pathseq.bam \** ; **--scores-output sample.pathseq.txt** ; ; ; **'''**.  . and unfortunately it was shut down by this error message. **09:27:43.974 INFO NativeLibraryLoader - Loading libgkl\_compression.so from jar:file:/mnt/clinix1/Analysis/mongol/phenomata/Tools/Anaconda3/envs/gatk4/share/gatk4-4.1.4.1-1/gatk-package-4.1.4.1-local.jar!/com/intel/gkl/native/libgkl\_compression.so** ; **Mar 05, 2020 9:27:44 AM shaded.cloud\_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine** ; **INFO: Failed to detect whether we are running on Google Compute Engine.** ; **09:27:44.733 INFO PathSeqPipelineSpark - ------------------------------------------------------------** ; **09:27:44.733 INFO PathSeqPipelineSpark - The Genome Analysis Toolkit (GATK) v4.1.4.1** ; **09:27:44.734 INFO PathSeqPipelineSpark - For support and documentation go to [https://software.broadinstitute.org/gatk/](https://software.broadinstitute.org/gatk/)** ; **09:27:44.734 INFO PathSeqPipelineSpark - Executing as phenomata@cm132 on Linux v2.6.32-573.18.1.el6.x86\_64 amd64** ; **09:27:44.734 INFO PathSeqPi",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6493:1699,down,down,1699,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6493,2,"['down', 'error']","['down', 'error']"
Availability," INFO --QUIET false --use_jdk_deflater false --use_jdk_inflater false --gcs_max_retries 20 --disableToolDefaultReadFilters false; [October 3, 2017 5:27:51 AM UTC] Executing as centos@master.novalocal on Linux 3.10.0-514.10.2.el7.x86_64 amd64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_131-b11; Version: 4.beta.5; 05:27:52.642 INFO PrintReadsSpark - HTSJDK Defaults.COMPRESSION_LEVEL : 1; 05:27:52.642 INFO PrintReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 05:27:52.642 INFO PrintReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : false; 05:27:52.642 INFO PrintReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 05:27:52.642 INFO PrintReadsSpark - Deflater: IntelDeflater; 05:27:52.642 INFO PrintReadsSpark - Inflater: IntelInflater; 05:27:52.643 INFO PrintReadsSpark - GCS max retries/reopens: 20; 05:27:52.643 INFO PrintReadsSpark - Using google-cloud-java patch c035098b5e62cb4fe9155eff07ce88449a361f5d from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 05:27:52.643 INFO PrintReadsSpark - Initializing engine; 05:27:52.643 INFO PrintReadsSpark - Done initializing engine; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@dcf3e99] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@61df66b6].; log4j:ERROR Could not instantiate appender named ""console"".; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; log4j:WARN No appenders could be found for logger (org.apache.spark.SparkContext).; log4j:WARN Please initialize the log4j system properly.; log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.; ```; I can run command using the spark-shell but somehow GATK4 fails. Any idea?. thank you very much",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3651:3435,ERROR,ERROR,3435,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3651,5,['ERROR'],['ERROR']
Availability," INFO GenomicsDBImport - Initializing engine; 10:49:12.577 WARN GenomicsDBImport - genomicsdb-update-workspace-path was set, so ignoring specified intervals.The tool will use the intervals specified by the initial import; 10:49:12.938 INFO GenomicsDBLibLoader - GenomicsDB native library version : 1.3.0-e701905; 10:49:13.163 INFO IntervalArgumentCollection - Processing 51304566 bp from intervals; 10:49:13.163 INFO GenomicsDBImport - Done initializing engine; 10:49:13.164 INFO GenomicsDBImport - Callset Map JSON file will be re-written to /mnt/mone/OMICS/Project/Joint_call/GATK_GenomicDB/test_database/test_overwrite_1/callset.json; 10:49:13.164 INFO GenomicsDBImport - Incrementally importing to workspace - /mnt/mone/OMICS/Project/Joint_call/GATK_GenomicDB/test_database/test_overwrite_1; 10:49:13.164 INFO ProgressMeter - Starting traversal; 10:49:13.164 INFO ProgressMeter - Current Locus Elapsed Minutes Batches Processed Batches/Minute; 10:49:13.231 INFO GenomicsDBImport - Shutting down engine; [June 18, 2021 10:49:13 AM KST] org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImport done. Elapsed time: 0.02 minutes.; Runtime.totalMemory()=2194669568; org.genomicsdb.exception.GenomicsDBException: Duplicate sample name found: 4762. Sample was originally in /mnt/mone/OMICS/Project/Asian_Genome/Korea/4762/bwa-gatk4/VARIANT/ForEachChr/chr22.g.vcf; at org.genomicsdb.importer.extensions.CallSetMapExtensions.checkDuplicateCallsetsForIncrementalImport(CallSetMapExtensions.java:270); at org.genomicsdb.importer.extensions.CallSetMapExtensions.mergeCallsetsForIncrementalImport(CallSetMapExtensions.java:241); at org.genomicsdb.importer.GenomicsDBImporter.<init>(GenomicsDBImporter.java:252); at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImport.traverse(GenomicsDBImport.java:745); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1049); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); at org.broa",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7324:4064,down,down,4064,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7324,1,['down'],['down']
Availability," INFO GermlineCNVCaller - Aggregating read-count file output/gCNV/bulkDNAseq_BGI/F20FTSAPHT0350_MUSyfqR/count_tsv/713.mkdup.sort.rg.tsv (40 / 323); 06:49:07.999 INFO GermlineCNVCaller - Aggregating read-count file output/gCNV/bulkDNAseq_BGI/F20FTSAPHT0350_MUSyfqR/count_tsv/252.mkdup.sort.rg.tsv (41 / 323); 06:49:10.433 INFO GermlineCNVCaller - Aggregating read-count file output/gCNV/bulkDNAseq_BGI/F20FTSAPHT0350_MUSyfqR/count_tsv/547.mkdup.sort.rg.tsv (42 / 323); 06:49:13.341 INFO GermlineCNVCaller - Aggregating read-count file output/gCNV/bulkDNAseq_BGI/F20FTSAPHT0350_MUSyfqR/count_tsv/154.mkdup.sort.rg.tsv (43 / 323); 06:49:15.782 INFO GermlineCNVCaller - Aggregating read-count file output/gCNV/bulkDNAseq_BGI/F20FTSAPHT0350_MUSyfqR/count_tsv/651.mkdup.sort.rg.tsv (44 / 323); 06:49:18.251 INFO GermlineCNVCaller - Aggregating read-count file output/gCNV/bulkDNAseq_BGI/F20FTSAPHT0350_MUSyfqR/count_tsv/94.mkdup.sort.rg.tsv (45 / 323); 06:49:20.605 INFO GermlineCNVCaller - Shutting down engine; [August 13, 2021 6:49:20 AM GMT] org.broadinstitute.hellbender.tools.copynumber.GermlineCNVCaller done. Elapsed time: 2.27 minutes.; Runtime.totalMemory()=2076049408; java.lang.IllegalArgumentException: Prefix string too short; at java.io.File.createTempFile(File.java:2001); at org.broadinstitute.hellbender.utils.io.IOUtils.createTempFileInDirectory(IOUtils.java:685); at org.broadinstitute.hellbender.utils.io.IOUtils.createTempFile(IOUtils.java:666); at org.broadinstitute.hellbender.tools.copynumber.GermlineCNVCaller.lambda$writeIntervalSubsetReadCountFiles$1(GermlineCNVCaller.java:434); at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.stream.IntPipeline$4$1.accept(IntPipeline.java:250); at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110); at java.util.Spliterator$OfInt.forEachRemaining(Spliterator.java:693); at java.util.stream.Abs",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7410:1424,down,down,1424,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7410,1,['down'],['down']
Availability," INFO NativeLibraryLoader - Loading libgkl_pairhmm_omp.so from jar:file:/home/alcalan/.conda/mutect2-cd161e2f51ff2240ce6390abc942bbdd/share/gatk4-4.1.5.0-1/gatk-package-4.1.5.0-local.jar!/com/intel/gkl/native/libgkl_pairhmm_omp.so; 10:34:26.264 INFO IntelPairHmm - Flush-to-zero (FTZ) is enabled when running PairHMM; 10:34:26.267 INFO IntelPairHmm - Available threads: 8; 10:34:26.267 INFO IntelPairHmm - Requested threads: 4; 10:34:26.267 INFO PairHMM - Using the OpenMP multi-threaded AVX-accelerated native PairHMM implementation; 10:34:26.375 INFO ProgressMeter - Starting traversal; 10:34:26.375 INFO ProgressMeter - Current Locus Elapsed Minutes Regions Processed Regions/Minute; 10:34:26.950 INFO VectorLoglessPairHMM - Time spent in setup for JNI call : 0.0; 10:34:26.950 INFO PairHMM - Total compute time in PairHMM computeLogLikelihoods() : 0.0; 10:34:26.950 INFO SmithWatermanAligner - Total compute time in java Smith-Waterman : 0.03 sec; 10:34:26.951 INFO Mutect2 - Shutting down engine; [March 23, 2020 10:34:26 AM CET] org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2 done. Elapsed time: 0.04 minutes.; Runtime.totalMemory()=1214251008; java.lang.StringIndexOutOfBoundsException: String index out of range: -1; 	at java.lang.String.substring(String.java:1927); 	at org.broadinstitute.hellbender.tools.walkers.annotator.TandemRepeat.getNumTandemRepeatUnits(TandemRepeat.java:54); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.AssemblyRegionTrimmer.trim(AssemblyRegionTrimmer.java:175); 	at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2Engine.callRegion(Mutect2Engine.java:229); 	at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2.apply(Mutect2.java:299); 	at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.processReadShard(AssemblyRegionWalker.java:200); 	at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.traverse(AssemblyRegionWalker.java:173); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKToo",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6516:4843,down,down,4843,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6516,1,['down'],['down']
Availability," INFO TaskSetManager: Starting task 0.2 in stage 0.0 (TID 2, xx.xx.xx.xx, executor 0, partition 0, PROCESS_LOCAL, 4956 bytes); 18/04/23 20:42:02 INFO TaskSetManager: Lost task 0.2 in stage 0.0 (TID 2) on xx.xx.xx.xx, executor 0: java.lang.IllegalStateException (unread block data) [duplicate 2]; 18/04/23 20:42:02 INFO TaskSetManager: Starting task 0.3 in stage 0.0 (TID 3, xx.xx.xx.xx, executor 0, partition 0, PROCESS_LOCAL, 4956 bytes); 18/04/23 20:42:02 INFO TaskSetManager: Lost task 0.3 in stage 0.0 (TID 3) on xx.xx.xx.xx, executor 0: java.lang.IllegalStateException (unread block data) [duplicate 3]; 18/04/23 20:42:02 ERROR TaskSetManager: Task 0 in stage 0.0 failed 4 times; aborting job; 18/04/23 20:42:02 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool; 18/04/23 20:42:02 INFO TaskSchedulerImpl: Cancelling stage 0; 18/04/23 20:42:02 INFO DAGScheduler: ResultStage 0 (first at ReadsSparkSource.java:221) failed in 11.519 s due to Job aborted due to stage failure: Task 0 in stage 0.0 failed 4 times, most recent failure: Lost task 0.3 in stage 0.0 (TID 3, xx.xx.xx.xx, executor 0): java.lang.IllegalStateException: unread block data; at java.io.ObjectInputStream$BlockDataInputStream.setBlockDataMode(ObjectInputStream.java:2740); at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1567); at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245); at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169); at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027); at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535); at java.io.ObjectInputStream.readObject(ObjectInputStream.java:422); at org.apache.spark.serializer.JavaDeserializationStream.readObject(JavaSerializer.scala:75); at org.apache.spark.serializer.JavaSerializerInstance.deserialize(JavaSerializer.scala:114); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:309); at java.util.concu",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694:15256,failure,failure,15256,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694,1,['failure'],['failure']
Availability," INFO  GenomicsDBLibLoader - GenomicsDB native library version : 1.4.4-ce4e1b9; 12:01:33.262 INFO  NativeGenomicsDB - pid=1923139 tid=1923140 No valid combination operation found for INFO field InbreedingCoeff  - the field will NOT be part of INFO fields in the generated VCF records; 12:01:33.262 INFO  NativeGenomicsDB - pid=1923139 tid=1923140 No valid combination operation found for INFO field MLEAC  - the field will NOT be part of INFO fields in the generated VCF records; 12:01:33.262 INFO  NativeGenomicsDB - pid=1923139 tid=1923140 No valid combination operation found for INFO field MLEAF  - the field will NOT be part of INFO fields in the generated VCF records; 12:01:33.288 INFO  GenotypeGVCFs - Shutting down engine; [March 1, 2024 at 12:01:33 PM UTC] org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs done. Elapsed time: 0.25 minutes.; Runtime.totalMemory()=1130364928; ***********************************************************************. A USER ERROR has occurred: Couldn't create GenomicsDBFeatureReader. ***********************************************************************; Set the system property GATK_STACKTRACE_ON_USER_EXCEPTION (--java-options '-DGATK_STACKTRACE_ON_USER_EXCEPTION=true') to print the stack trace.  ; content of my callset.json file:. {""callsets"": [{""sample_name"": ""ERR318225"",""row_idx"": 223,""idx_in_file"": 0,""stream_name"": ""ERR318225_stream""},{""sample_name"": ""ERR318226"",""row_idx"": 224,""idx_in_file"": 0,""stream_name"": ""ERR318226_stream""},{""sample_name"": ""ERR4133262"",""row_idx"": 225,""idx_in_file"": 0,""stream_name"": ""ERR4133262_stream""},{""sample_name"": ""ERR4133361"",""row_idx"": 226,""idx_in_file"": 0,""stream_name"": ""ERR4133361_stream""},{""sample_name"": ""ERR4133400"",""row_idx"": 227,""idx_in_file"": 0,""stream_name"": ""ERR4133400_stream""},{""sample_name"": ""ERR4133407"",""row_idx"": 228,""idx_in_file"": 0,""stream_name"": ""ERR4133407_stream""},{""sample_name"": ""ERR4133418"",""row_idx"": 229,""idx_in_file"": 0,""stream_name"": ""ERR4133418_stream""},{""sample_name"": ""ERR41",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8709:5241,ERROR,ERROR,5241,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8709,1,['ERROR'],['ERROR']
Availability," Importing to array - /home/WangBS/Analyses/vcf/test/chr02/genomicsdb_array; 23:42:44.276 INFO ProgressMeter - Starting traversal; 23:42:44.276 INFO ProgressMeter - Current Locus Elapsed Minutes Batches Processed Batches/Minute; 23:42:45.830 INFO GenomicsDBImport - Importing batch 1 with 63 samples; Buffer resized from 37294 bytes to 65464; Buffer resized from 37294 bytes to 65511; Buffer resized from 37293 bytes to 65539; Buffer resized from 37294 bytes to 65447; .....; .....; Buffer resized from 65538 bytes to 65539; Buffer resized from 65538 bytes to 65539; Buffer resized from 65538 bytes to 65539; 06:50:14.219 INFO ProgressMeter - Qrob_Chr02:1 427.5 1 0.0; 06:50:14.220 INFO GenomicsDBImport - Done importing batch 1/1; 06:50:14.221 INFO ProgressMeter - Qrob_Chr02:1 427.5 1 0.0; 06:50:14.229 INFO ProgressMeter - Traversal complete. Processed 1 total batches in 427.5 minutes.; 06:50:14.236 INFO GenomicsDBImport - Import completed!; 06:50:14.236 INFO GenomicsDBImport - Shutting down engine; [January 27, 2019 6:50:14 AM CST] org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImport done. Elapsed time: 428.57 minutes.; Runtime.totalMemory()=8988393472; Tool returned:; true; Using GATK jar /home/WangBS/software/GATK/gatk/build/libs/gatk-package-4.0.11.0-56-g2c0e9b0-SNAPSHOT-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx24g -jar /home/WangBS/software/GATK/gatk/build/libs/gatk-package-4.0.11.0-56-g2c0e9b0-SNAPSHOT-local.jar GenotypeGVCFs -R /home/WangBS/Reference/Qrobur/Qrob_PM1N.fa -V gendb:///home/WangBS/Analyses/vcf/test/chr02 -all-sites -O /home/WangBS/Analyses/vcf/test/chr02.vcf; 06:50:19.236 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/WangBS/software/GATK/gatk/build/libs/gatk-package-4.0.11.0-56-g2c0e9b0-SNAPSHOT-local.jar!/com/intel/gkl/native/libgkl_compression.so; 06:51:21.116 INFO Genot",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5865:4194,down,down,4194,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5865,1,['down'],['down']
Availability," IndexFeatureFile - GCS max retries/reopens: 20; 09:28:39.196 INFO IndexFeatureFile - Requester pays: disabled; 09:28:39.196 INFO IndexFeatureFile - Initializing engine; 09:28:39.196 INFO IndexFeatureFile - Done initializing engine; 09:28:39.696 INFO FeatureManager - Using codec VCFCodec to read file file:///storage/ppl/yifang/20190327_David_rampseq_Ehsan/data/samtools_sorted_out/SNPs_candidates.g.vcf; 09:28:39.708 INFO ProgressMeter - Starting traversal; 09:28:39.708 INFO ProgressMeter - Current Locus Elapsed Minutes Records Processed Records/Minute; =========This is the indexed chromosome ===================; 09:28:41.968 INFO ProgressMeter - **chr7B_part2:295520629** 0.0 925631 24596040.7. 09:28:41.968 INFO ProgressMeter - Traversal complete. Processed 925631 total records in 0.0 minutes.; 09:28:42.006 INFO IndexFeatureFile - Successfully wrote index to /storage/ppl/yifang/20190327/data/samtools_sorted_out/SNPs_candidates.g.vcf.idx; 09:28:42.006 INFO IndexFeatureFile - Shutting down engine; [May 6, 2019 9:28:42 CST AM] org.broadinstitute.hellbender.tools.IndexFeatureFile done. Elapsed time: 0.05 minutes.; Runtime.totalMemory()=2434269184). ```; This is my command line:; `java -DGATK_STACKTRACE_ON_USER_EXCEPTION=true -jar ${gatk4_jar} IndexFeatureFile --feature-file ${gvcf} --output ${gvcf}.idx 2>${LOGDIR}/index_candidates.log`. I tried this exact command line with another genome, which worked just fine with output progress report as following for a comparison of the multiple chromosomes processed:; ```; 12:50:38.871 INFO ProgressMeter - Starting traversal; 12:50:38.873 INFO ProgressMeter - Current Locus Elapsed Minutes Records Processed Records/Minute; 12:50:48.876 INFO ProgressMeter - N1:21408210 0.2 5669000 34010598.9; 12:50:58.876 INFO ProgressMeter - N2:13383863 0.3 11960000 35874618.8. ...... 12:55:58.884 INFO ProgressMeter - N19:50063133 5.3 208660000 39122405.2; 12:56:02.409 INFO ProgressMeter - N19:55994806 5.4 210940859 39119265.4; 12:56:02.409 INFO Progr",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5917:4395,down,down,4395,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5917,1,['down'],['down']
Availability," Inflater: IntelInflater; 22:30:25.478 INFO BaseRecalibrator - GCS max retries/reopens: 20; 22:30:25.479 INFO BaseRecalibrator - Requester pays: disabled; 22:30:25.479 INFO BaseRecalibrator - Initializing engine; WARNING 2024-03-08 22:30:25 SamFiles The index file /mnt/storage/users/dockworker/mpedersen/work/RNAseq_variant_call/work/d6/362957b6215ad2e8193c27c895d42d/VR0024SA.withoutERCCs.withRG.markedDup.splitNcigar.bai was found by resolving the canonical path of a symlink: VR0024SA.withoutERCCs.withRG.markedDup.splitNcigar.bam -> /mnt/storage/users/dockworker/mpedersen/work/RNAseq_variant_call/work/d6/362957b6215ad2e8193c27c895d42d/VR0024SA.withoutERCCs.withRG.markedDup.splitNcigar.bam; 22:30:25.631 INFO FeatureManager - Using codec VCFCodec to read file file://1000G_phase1.snps.high_confidence.hg38.vcf.gz; 22:30:25.754 INFO FeatureManager - Using codec VCFCodec to read file file://Mills_and_1000G_gold_standard.indels.hg38.vcf.gz; 23:39:21.541 INFO BaseRecalibrator - Shutting down engine; [March 8, 2024 at 11:39:21 PM GMT] org.broadinstitute.hellbender.tools.walkers.bqsr.BaseRecalibrator done. Elapsed time: 68.94 minutes.; Runtime.totalMemory()=214748364800; java.lang.OutOfMemoryError: Java heap space; at htsjdk.tribble.readers.TabixReader.readInt(TabixReader.java:189); at htsjdk.tribble.readers.TabixReader.readIndex(TabixReader.java:274); at htsjdk.tribble.readers.TabixReader.readIndex(TabixReader.java:287); at htsjdk.tribble.readers.TabixReader.<init>(TabixReader.java:165); at htsjdk.tribble.readers.TabixReader.<init>(TabixReader.java:129); at htsjdk.tribble.TabixFeatureReader.<init>(TabixFeatureReader.java:80); at htsjdk.tribble.AbstractFeatureReader.getFeatureReader(AbstractFeatureReader.java:117); at org.broadinstitute.hellbender.engine.FeatureDataSource.getTribbleFeatureReader(FeatureDataSource.java:433); at org.broadinstitute.hellbender.engine.FeatureDataSource.getFeatureReader(FeatureDataSource.java:377); at org.broadinstitute.hellbender.engine.FeatureDataS",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8726:2110,down,down,2110,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8726,1,['down'],['down']
Availability," IntelGKLUtils - Trying to load Intel GKL library from:; jar:file:/Users/daniel/workspaces/gatk4test/build/libs/shadowJar-0.0.1-SNAPSHOT-all.jar!/com/intel/gkl/native/libIntelGKL.dylib; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGILL (0x4) at pc=0x0000000128c014d0, pid=31197, tid=5891; #; # JRE version: Java(TM) SE Runtime Environment (8.0_60-b27) (build 1.8.0_60-b27); # Java VM: Java HotSpot(TM) 64-Bit Server VM (25.60-b23 mixed mode bsd-amd64 compressed oops); # Problematic frame:; # C [libIntelGKL8818190486223479934.dylib+0xe4d0] _ZN7ContextIfEC2Ev+0x30; #; # Core dump written. Default location: /cores/core or core.31197; #; # An error report file with more information is saved as:; # /Users/daniel/workspaces/gatk4test/hs_err_pid31197.log; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; # The crash happened outside the Java Virtual Machine in native code.; # See problematic frame for where to report the bug.; #; Abort trap: 6 (core dumped); ```. To fix it, I tried by excluding `com.intel.gkl` from GATK and add it as a dependency to my program, but it blows up anyway. In addition, I tried a sample program to load the PairHMM fastest implementation by `PairHMM.Implementation.FASTEST_AVAILABLE.makeNewHMM()`, and it also blows up. If I remove completely the dependency in my shadow jar, the command line blows up because the gkl `IntelDeflaterFactory` is not found. I guess that the error in the library is GKL-related, but in the case of the GATK framework I would like to have a way of using the library without assuming that the final user will have support for the native code or not. Could this be done? I prefer not to remove the faster code by intel because I know that some users will benefit from it. Just in case it is needed, my system is a Mac OS X (10.11.5) with Darwin Kernel Version 15.5.0 (root:xnu-3248.50.21~8/RELEASE_X86_64 x86_64). Thank you very much in advance.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1985:1887,error,error,1887,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1985,1,['error'],['error']
Availability," MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!** ; **20/03/05 09:28:58 INFO NewHadoopRDD: Input split: file:/clinix1/Analysis/mongol/phenomata/04.GC\_CC/01.Alignment/Aligned/17039\_N.bam:1342177280+33554432** ; **20/03/05 09:28:58 INFO MemoryStore: MemoryStore cleared** ; **20/03/05 09:28:58 INFO BlockManager: BlockManager stopped** ; **20/03/05 09:28:58 INFO BlockManagerMaster: BlockManagerMaster stopped** ; **20/03/05 09:28:58 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!** ; **20/03/05 09:28:58 INFO SparkContext: Successfully stopped SparkContext** ; **09:28:58.889 INFO PathSeqPipelineSpark - Shutting down engine** ; **[2020년 3월 5일 (목) 오전 9시 28분 58초] org.broadinstitute.hellbender.tools.spark.pathseq.PathSeqPipelineSpark done. Elapsed time: 1.25 minutes.** ; **Runtime.totalMemory()=19560660992** ; **org.apache.spark.SparkException: Job aborted due to stage failure: Task 34 in stage 0.0 failed 1 times, most recent failure: Lost task 34.0 in stage 0.0 (TID 34, localhost, executor driver): com.esotericsoftware.kryo.KryoException: Buffer underflow.** ; **at com.esotericsoftware.kryo.io.Input.require(Input.java:199)** ; **at com.esotericsoftware.kryo.io.Input.readLong(Input.java:686)** ; **at org.broadinstitute.hellbender.tools.spark.utils.LongHopscotchSet.<init>(LongHopscotchSet.java:83)** ; **at org.broadinstitute.hellbender.tools.spark.utils.LongHopscotchSet$Serializer.read(LongHopscotchSet.java:527)** ; **at org.broadinstitute.hellbender.tools.spark.utils.LongHopscotchSet$Serializer.read(LongHopscotchSet.java:519)** ; **at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:712)** ; **at org.broadinstitute.hellbender.tools.spark.utils.LargeLongHopscotchSet.<init>(LargeLongHopscotchSet.java:55)** ; **at org.broadinstitute.hellbender.tools.spark.utils.LargeLongHopscotchSet$Serializer.read(LargeLongHopscotchSet.java:172)** ; **at org.broadinstitute.hellbender.tools.spark.utils.LargeLongHopscotc",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6493:42519,failure,failure,42519,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6493,1,['failure'],['failure']
Availability," MarkDuplicatesSpark - ------------------------------------------------------------; 21:47:48.271 INFO MarkDuplicatesSpark - ------------------------------------------------------------; 21:47:48.271 INFO MarkDuplicatesSpark - HTSJDK Version: 2.14.3; 21:47:48.271 INFO MarkDuplicatesSpark - Picard Version: 2.18.2; 21:47:48.271 INFO MarkDuplicatesSpark - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 21:47:48.271 INFO MarkDuplicatesSpark - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 21:47:48.272 INFO MarkDuplicatesSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 21:47:48.272 INFO MarkDuplicatesSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 21:47:48.272 INFO MarkDuplicatesSpark - Deflater: IntelDeflater; 21:47:48.272 INFO MarkDuplicatesSpark - Inflater: IntelInflater; 21:47:48.272 INFO MarkDuplicatesSpark - GCS max retries/reopens: 20; 21:47:48.272 INFO MarkDuplicatesSpark - Using google-cloud-java patch 6d11bef1c81f885c26b2b56c8616b7a705171e4f from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 21:47:48.272 WARN MarkDuplicatesSpark -. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. Warning: MarkDuplicatesSpark is a BETA tool and is not yet ready for use in production. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. 21:47:48.273 INFO MarkDuplicatesSpark - Initializing engine; 21:47:48.273 INFO MarkDuplicatesSpark - Done initializing engine; 22:29:27.746 INFO ReadsSparkSink - Finished sorting the bam file and dumping read shards to disk, proceeding to merge the shards into a single file using the master thread; 22:43:29.758 INFO ReadsSparkSink - Finished merging shards into a single output bam; 22:43:36.475 INFO MarkDuplicatesSpark - Shutting down engine; [May 7, 2018 10:43:36 PM EDT] org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSpark done. Elapsed time: 55.82 minutes.; Runtime.totalMemory()=12430868480; ```. Created after discussion with @lbergelson",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4746:7985,down,down,7985,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4746,1,['down'],['down']
Availability," MarkDuplicatesSpark - Using google-cloud-java patch 6d11bef1c81f885c26b2b56c8616b7a705171e4f from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 14:40:21.994 WARN MarkDuplicatesSpark -. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. Warning: MarkDuplicatesSpark is a BETA tool and is not yet ready for use in production. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. 14:40:21.994 INFO MarkDuplicatesSpark - Initializing engine; 14:40:21.994 INFO MarkDuplicatesSpark - Done initializing engine; 14:40:22.338 WARN NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 15:24:12.735 INFO ReadsSparkSink - Finished sorting the bam file and dumping read shards to disk, proceeding to merge the shards into a single file using the master thread; 15:41:27.766 INFO ReadsSparkSink - Finished merging shards into a single output bam; 15:41:34.351 INFO MarkDuplicatesSpark - Shutting down engine; [May 7, 2018 3:41:34 PM EDT] org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSpark done. Elapsed time: 61.21 minutes.; Runtime.totalMemory()=13635682304; ```. With native libraries (note the lack of the usual warning):. ```; $ ${GATK_DIR}/gatk MarkDuplicatesSpark --java-options ""-Djava.library.path=${HADOOP_DIR}/hadoop-2.6.5-src/hadoop-common-project/hadoop-common/target/hadoop-common-2.6.5/lib/native"" -I CEUTrio.HiSeq.WEx.b37.NA12892.readnamesort.bam -O CEUTrio.HiSeq.WEx.b37.NA12892.readnamesort.dupmarked_native.bam -- --spark-runner LOCAL --spark-master local[8]; Using GATK wrapper script ${GATK_DIR}/gatk/build/install/gatk/bin/gatk; Running:; ${GATK_DIR}/gatk/build/install/gatk/bin/gatk MarkDuplicatesSpark -I CEUTrio.HiSeq.WEx.b37.NA12892.readnamesort.bam -O CEUTrio.HiSeq.WEx.b37.NA12892.readnamesort.dupmarked_native.bam --spark-master local[8]; 21:47:47.494 WARN SparkContextFactory - Environment variables HELLBENDER_TEST_PROJECT and HELLB",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4746:4282,down,down,4282,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4746,1,['down'],['down']
Availability, Mutect2Engine - Active Region chrM:1154-1397; 11:35:45.413 DEBUG Mutect2Engine - Extended Act Region chrM:1054-1497; 11:35:45.413 DEBUG Mutect2Engine - Ref haplotype coords chrM:1054-1497; 11:35:45.413 DEBUG Mutect2Engine - Haplotype count 1; 11:35:45.413 DEBUG Mutect2Engine - Kmer sizes count 0; 11:35:45.414 DEBUG Mutect2Engine - Kmer sizes values []; 11:35:45.737 DEBUG Mutect2 - Processing assembly region at chrM:1398-1697 isActive: false numReads: 2722; 11:35:45.837 DEBUG Mutect2 - Processing assembly region at chrM:1698-1997 isActive: false numReads: 0; 11:35:45.999 DEBUG Mutect2 - Processing assembly region at chrM:1998-2297 isActive: false numReads: 0; 11:35:46.219 DEBUG Mutect2 - Processing assembly region at chrM:2298-2543 isActive: false numReads: 2555; 11:35:46.674 DEBUG Mutect2 - Processing assembly region at chrM:2544-2841 isActive: true numReads: 5108; 11:35:48.094 DEBUG ReadThreadingGraph - Recovered 17 of 20 dangling tails; 11:35:48.198 DEBUG ReadThreadingGraph - Recovered 16 of 50 dangling heads; 11:35:48.511 DEBUG IntToDoubleFunctionCache - cache miss 2389 > 10 expanding to 2399; 11:35:48.874 DEBUG Mutect2Engine - Active Region chrM:2544-2841; 11:35:48.874 DEBUG Mutect2Engine - Extended Act Region chrM:2444-2941; 11:35:48.875 DEBUG Mutect2Engine - Ref haplotype coords chrM:2444-2941; 11:35:48.875 DEBUG Mutect2Engine - Haplotype count 128; 11:35:48.875 DEBUG Mutect2Engine - Kmer sizes count 0; 11:35:48.875 DEBUG Mutect2Engine - Kmer sizes values []; 11:36:08.907 INFO ProgressMeter - chrM:2544 0.4 10 22.3; 11:36:08.954 DEBUG Mutect2 - Processing assembly region at chrM:2842-2920 isActive: false numReads: 4726; 11:36:09.094 DEBUG Mutect2 - Processing assembly region at chrM:2921-3202 isActive: true numReads: 4600; 11:36:09.663 DEBUG ReadThreadingGraph - Recovered 1 of 2 dangling tails; 11:36:09.671 DEBUG ReadThreadingGraph - Recovered 4 of 7 dangling heads; 11:36:09.750 DEBUG Mutect2Engine - Active Region chrM:2921-3202; 11:36:09.750 DEBUG Mutect2Engin,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7281:9267,Recover,Recovered,9267,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7281,1,['Recover'],['Recovered']
Availability," The class ""org.apache.log4j.Appender"" was loaded by ; log4j:ERROR [sun.misc.Launcher$AppClassLoader@7506e922] whereas object of type ; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@28c4711c].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.FileAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by ; log4j:ERROR [sun.misc.Launcher$AppClassLoader@7506e922] whereas object of type ; log4j:ERROR ""org.apache.log4j.FileAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@28c4711c].; log4j:ERROR Could not instantiate appender named ""file"".; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by ; log4j:ERROR [sun.misc.Launcher$AppClassLoader@7506e922] whereas object of type ; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@28c4711c].; log4j:ERROR Could not instantiate appender named ""console"".; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; log4j:WARN No appenders could be found for logger (org.apache.spark.SparkContext).; log4j:WARN Please initialize the log4j system properly.; log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.; ```. By backtracking, the problem goes away at commit d827adc81266c788482c9cb4f119f2e3c1e152b8. Since spark-submmit was broken after 8af8bcc920ee5f393562e3e632d9ccd4acd9a638, the bug could be anywhere between commit 8af8bcc920ee5f393562e3e632d9ccd4acd9a638 and d25894b3bc80e450210cf8a9124c4171e65f3717. The log4j.property file is below:; ```; # Set everything to be logged to the console; log4j.rootCategory=WARN,console; log4j.appender.console=org.apache.log4j.ConsoleAppender; log4j.appen",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2734:1285,ERROR,ERROR,1285,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2734,1,['ERROR'],['ERROR']
Availability," ValidateSamFile NM validation cannot be performed without the reference. All other validations will still occur.; INFO 2019-03-07 16:10:25 SamFileValidator Validated Read 10,000,000 records. Elapsed time: 00:02:00s. Time for last 10,000,000: 120s. Last read position: chr9:32,633,613; INFO 2019-03-07 16:12:22 SamFileValidator Validated Read 20,000,000 records. Elapsed time: 00:03:58s. Time for last 10,000,000: 117s. Last read position: chrM:11,340; No errors found; [Thu Mar 07 16:13:05 UTC 2019] picard.sam.ValidateSamFile done. Elapsed time: 4.79 minutes.; Runtime.totalMemory()=2602041344; Tool returned:; 0; ```. But when run BaseRecalibrator got the _fromIndex toIndex_ error:; `gatk BaseRecalibrator --input sorted.bam --output sorted.baserecalibrator_report.txt --reference GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.bowtie_index.fasta --use-original-qualities true --known-sites snp151common_tablebrowser.bed.bgz --known-sites snp151flagged_tablebrowser.bed.bgz`; ```; ERROR: return code 3; STDERR:; 15:46:35.795 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/gatk/gatk-package-4.1.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; 15:46:42.808 INFO BaseRecalibrator - ------------------------------------------------------------; 15:46:42.810 INFO BaseRecalibrator - The Genome Analysis Toolkit (GATK) v4.1.0.0; 15:46:42.810 INFO BaseRecalibrator - For support and documentation go to https://software.broadinstitute.org/gatk/; 15:46:42.813 INFO BaseRecalibrator - Executing as mpmachado@lx-bioinfo02 on Linux v2.6.32-696.23.1.el6.x86_64 amd64; 15:46:42.814 INFO BaseRecalibrator - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_191-8u191-b12-0ubuntu0.16.04.1-b12; 15:46:42.814 INFO BaseRecalibrator - Start Date/Time: March 7, 2019 3:46:35 PM UTC; 15:46:42.815 INFO BaseRecalibrator - ------------------------------------------------------------; 15:46:42.815 INFO BaseRecalibrator - ------------------------------------------------------------; 15:",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5807:2736,ERROR,ERROR,2736,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5807,1,['ERROR'],['ERROR']
Availability, [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.DefaultBuildExecuter.execute(DefaultBuildExecuter.java:37); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.DefaultBuildExecuter.access$000(DefaultBuildExecuter.java:23); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.DefaultBuildExecuter$1.proceed(DefaultBuildExecuter.java:43); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.DryRunBuildExecutionAction.execute(DryRunBuildExecutionAction.java:32); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.DefaultBuildExecuter.execute(DefaultBuildExecuter.java:37); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.DefaultBuildExecuter.execute(DefaultBuildExecuter.java:30); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.initialization.DefaultGradleLauncher$RunTasksAction.execute(DefaultGradleLauncher.java:230); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.initialization.DefaultGradleLauncher$RunTasksAction.execute(DefaultGradleLauncher.java:227); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.Transformers$4.transform(Transformers.java:169); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:106); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:56); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.initialization.DefaultGradleLau,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2802:5702,ERROR,ERROR,5702,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2802,1,['ERROR'],['ERROR']
Availability," [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] A problem occurred evaluating root project 'gatk'.; 22:05:55.966 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] > Execution of ""git lfs pull --include src/main/resources/large"" failed with exit code: 2. git-lfs is required to build GATK but may not be installed. See https://github.com/broadinstitute/gatk#building for information on how to build GATK.; 22:05:55.967 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] ; 22:05:55.968 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] * Exception is:; 22:05:55.969 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] org.gradle.api.GradleScriptException: A problem occurred evaluating root project 'gatk'.; 22:05:55.969 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.groovy.scripts.internal.DefaultScriptRunnerFactory$ScriptRunnerImpl.run(DefaultScriptRunnerFactory.java:92); 22:05:55.969 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.DefaultScriptPluginFactory$ScriptPluginImpl$2.run(DefaultScriptPluginFactory.java:176); 22:05:55.970 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.ProjectScriptTarget.addConfiguration(ProjectScriptTarget.java:77); 22:05:55.970 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.DefaultScriptPluginFactory$ScriptPluginImpl.apply(DefaultScriptPluginFactory.java:181); 22:05:55.970 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.project.BuildScriptProcessor.execute(BuildScriptProcessor.java:38); 22:05:55.970 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.project.BuildScriptProcessor.execute(BuildScriptProcessor.java:25); 22:05:55.970 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configurati",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4687:2194,ERROR,ERROR,2194,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4687,1,['ERROR'],['ERROR']
Availability," [VS-472] (#7905); - Fix bug and update images (#7912); - VS 483 Beta user wdl (#7894); - Core storage model cost [VS-473] (#7913); - Update Quickstart & Integration to use re-blocked v2 gVCFs [VS-491] (#7924); - KM GVS documentation (#7903); - Track BigQuery costs of GVS python VS-480 (#7915); - Read cost observability table [VS-475] (#7923); - Fix Race Condition, Add Support for Extract by Array of Sample Names (ie from a Sample Set) (#7917); - Rightsize import batches [VS-486] (#7925); - [AoU DRC] Support uppercase site_ids for reblocking (#7929); - Populate cost metadata for GATK tasks. (#7919); - remove accidentally added input (#7931); - VS_492 - Beta User Jar release (#7934); - Cost WDL should throw on FISS API errors [VS-518] (#7942); - Fix bad check for missing workflow name [VS-520] (#7943); - Remove usage of service account from GvsValidateVAT.wdl (#7937); - refactoring for testablity (#7946); - More import retries [VS-532] (#7953); - A few last doc changes (#7927); - WDL to extract a single callset cost (BQ only, not Terra) (#7940); - Temporarily swap in Corretto for Temurin as we can't download Temurin. (#7969); - GL-548 - Update CreateVat code to handle samples that do not contain all population groups. (#7965); - Restore Temurin 11 [VS-570] (#7972); - Add table size check to quickstart integration test [VS-501] (#7970); - Consolidate various docs for AoU callset generation into one to rule them all [VS-553] (#7971); - VS-567. Removing usage of ServiceAccount from CreateVat related WDLs (#7974); - WDL to extract Avro files for Hail import [VS-579] (#7981); - Removed usage of service account from WDLs (#7985); - Document steps for GVS cleanup for base use case [VS-586] (#7989); - Change backticks to single quotes in several error messages - causing shell to attempt to execute. (#7995); - VS-598 - Minor update to AoU Documentation. (#7994); - Allow for incremental addition of data to alt_allele [VS-52] (#7993); - Minor AoU Documentation Update (#7999); -",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8248:26691,down,download,26691,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8248,2,['down'],['download']
Availability," [hs_err_pid100.log](https://github.com/broadinstitute/gatk/files/6203288/hs_err_pid100.log); [hs_err_pid164.log](https://github.com/broadinstitute/gatk/files/6203289/hs_err_pid164.log); [hs_err_pid274.log](https://github.com/broadinstitute/gatk/files/6203290/hs_err_pid274.log); [hs_err_pid400.log](https://github.com/broadinstitute/gatk/files/6203291/hs_err_pid400.log); [hs_err_pid482.log](https://github.com/broadinstitute/gatk/files/6203292/hs_err_pid482.log); [hs_err_pid711.log](https://github.com/broadinstitute/gatk/files/6203293/hs_err_pid711.log); [hs_err_pid735.log](https://github.com/broadinstitute/gatk/files/6203294/hs_err_pid735.log); [hs_err_pid801.log](https://github.com/broadinstitute/gatk/files/6203295/hs_err_pid801.log); [hs_err_pid825.log](https://github.com/broadinstitute/gatk/files/6203296/hs_err_pid825.log); [hs_err_pid849.log](https://github.com/broadinstitute/gatk/files/6203297/hs_err_pid849.log); [otherFiles.zip](https://github.com/broadinstitute/gatk/files/6203305/otherFiles.zip); [in2510-8.orientationFilter.vcf.txt](https://github.com/broadinstitute/gatk/files/6203356/in2510-8.orientationFilter.vcf.txt); *VCF extension appended with .txt to satisfy GitHub's upload requirements*. #### Expected behavior; Worked on 7 other files generated with the same pipeline. . #### Actual behavior; Unsure why this last one is causing a segfault. The VCF included is not the whole VCF submitted originally. I went cutting out lines from the original until I could isolate it down to a minimal set required to reproduce the crash (I included all of the crash logs generated in case it can help). I was expecting to find a single line or maybe two that were required to reproduce this issue, but that range appears to be needed. Eliminating either the first or last line from the range will make the program work again. Did not attempt to remove lines from the middle of the range yet to see if they're necessary to cause the fault, but it's 2am and I should probably sleep.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7162:7969,down,down,7969,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7162,2,"['down', 'fault']","['down', 'fault']"
Availability," \; -L /home/nguyen/RB1/RB1.cohort.gc.filtered.interval_list \; --interval-merging-rule OVERLAPPING_ONLY \; -I ... (63 tsv files output from CollectReadCounts); ```. ### Affected version(s); - GATK 4.1.6.1; ### Description ; Full error log:; ```; Traceback (most recent call last):; File ""/tmp/cohort_determine_ploidy_and_depth.380621677219090732.py"", line 119, in <module>; ploidy_task.engage(); File ""/home/nguyen/anaconda3/envs/gatk/lib/python3.6/site-packages/gcnvkernel/tasks/inference_task_base.py"", line 339, in engage; converged_continuous = self._update_continuous_posteriors(); File ""/home/nguyen/anaconda3/envs/gatk/lib/python3.6/site-packages/gcnvkernel/tasks/inference_task_base.py"", line 395, in _update_continuous_posteriors; assert not np.isnan(loss), ""The optimization step for ELBO update returned a NaN""; AssertionError: The optimization step for ELBO update returned a NaN; 11:09:59.446 DEBUG ScriptExecutor - Result: 1; 11:09:59.447 INFO DetermineGermlineContigPloidy - Shutting down engine; [April 28, 2020 11:09:59 AM ICT] org.broadinstitute.hellbender.tools.copynumber.DetermineGermlineContigPloidy done. Elapsed time: 0.17 minutes.; Runtime.totalMemory()=623902720; org.broadinstitute.hellbender.utils.python.PythonScriptExecutorException: ; python exited with 1; Command Line: python /tmp/cohort_determine_ploidy_and_depth.380621677219090732.py --sample_coverage_metadata=/tmp/samples-by-coverage-per-contig8606344533091962323.tsv --output_calls_path=/home/nguyen/Exec/gatk-4.1.6.0/ploidy-calls --mapping_error_rate=1.000000e-02 --psi_s_scale=1.000000e-04 --mean_bias_sd=1.000000e-02 --psi_j_scale=1.000000e-03 --learning_rate=5.000000e-02 --adamax_beta1=9.000000e-01 --adamax_beta2=9.990000e-01 --log_emission_samples_per_round=2000 --log_emission_sampling_rounds=100 --log_emission_sampling_median_rel_error=5.000000e-04 --max_advi_iter_first_epoch=1000 --max_advi_iter_subsequent_epochs=1000 --min_training_epochs=20 --max_training_epochs=100 --initial_temperature=2.0000",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6573:1345,down,down,1345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6573,1,['down'],['down']
Availability," ```; private static JavaSparkContext createTestSparkContext(Map<String, String> overridingProperties) {; determineSparkMaster();; final SparkConf sparkConf = setupSparkConf(""TestContext"", DEFAULT_SPARK_MASTER, DEFAULT_TEST_PROPERTIES, overridingProperties);; return new JavaSparkContext(sparkConf);; }. /**; * Determine the number of cores Spark master should use. Only used in Spark Test; * Read the specification from the environmental variable GATK_TEST_SPARK_CORES; * If the value is a valid positive integer, use it; * If the value is bogus (strings, etc), or the env. var. is not set, use all available cores, as in ""local[*]""; */. private static void determineSparkMaster() {; int foo = 0;; try {; foo = Integer.parseInt( System.getenv(""GATK_TEST_SPARK_CORES"") );; } catch ( NumberFormatException e ) {}; String numSparkCores;; if ( foo > 0 ) {; numSparkCores = String.format(""[%d]"", foo);; } else {; numSparkCores = ""[*]"";; }; DEFAULT_SPARK_MASTER = ""local"" + numSparkCores;; }. ```. Error messages:. ```; java.lang.NullPointerException at org.broadinstitute.hellbender.engine.spark.SparkContextFactory.getSparkContext(SparkContextFactory.java:77); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:36); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:102); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:155); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:174); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:67); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:74); at org.broadinstitute.hellbender.CommandLineProgramTest.runCommandLine(CommandLineProgramTest.java:65); at org.broadinstitute.hellbender.utils.test.testers.SamFileTester.runTest(SamFileTester.java:263); at org.broadinstitute.hellbender.utils.test.testers.AbstractMarkDuplicatesComman",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1768:1320,Error,Error,1320,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1768,1,['Error'],['Error']
Availability," already exists, you may comment there to inquire about the progress.; - Determine whether your issue is a **bug report**, a **feature request**, or a **documentation request** (for tool/class javadoc only -- for forum docs please post there); - Consider if your ""issue"" is better addressed on the GATK forum: http://gatkforums.broadinstitute.org/gatk Post there if you have questions about expected tool behavior, output format, unexpected results, or generally any question that does not fit into the categories above; - Use a **concise** yet **descriptive** title; - Choose the corresponding template block below and fill it in, replacing or deleting text in italics (surrounded by `_`) as appropriate; - Delete the other template blocks and this header. ----. ## Bug Report. ### Affected tool(s) or class(es); GenotypeGVCF. ### Affected version(s); 4.1.7; 4.1.8; 4.1.9. ### Description ; Starting with GATK4.1.7, the AF annotation in the changed from '0' to '.'. This change is cause downstream issues with our processing pipeline. #### Steps to reproduce; CMD using 4.1.6:; gatk GenotypeGVCFs --variant proband_mother_duo.HC.g.vcf.gz -R hs38DH.fa --dbsnp dbsnp151_common.hg38.vcf.gz -O proband_mother_duo_GATK4.1.6.HC.vcf.gz. Looking at one of the sites causing this downstream issue:; CMD; gzcat proband_mother_duo_GATK4.1.6.HC.vcf.gz | grep 83598622; OUTPUT:; chr4 83598622 . AT ATT,A 1337.45 . AC=1,1;AF=0.250,0.250;AN=4;BaseQRankSum=1.26;ClippingRankSum=0.074;DP=145;ExcessHet=4.7712;FS=5.235;GQ_MEAN=625.00;LikelihoodRankSum=1.34;MLEAC=1,1;MLEAF=0.250,0.250;MQ=60.00;MQ0=0;MQRankSum=0.00;NCC=0;NCount=0;QD=10.06;ReadPosRankSum=1.56;SOR=0.375 GT:AD:AF:DP:F1R2:F2R1:GQ:PL 0/2:33,0,35:0.515,0:68:12,15,0:21,18,0:99:713,812,1542,0,731,625 0/1:32,33,0:0.493,0.00:67:9,23,0:19,8,0:99:640,0,588,728,747,1569. CMD using 4.1.7:; gatk GenotypeGVCFs --variant proband_mother_duo.HC.g.vcf.gz -R hs38DH.fa --dbsnp dbsnp151_common.hg38.vcf.gz -O proband_mother_duo_GATK4.1.7.HC.vcf.gz. Looking at one of t",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6938:1392,down,downstream,1392,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6938,1,['down'],['downstream']
Availability," and reading the right arrays. For example, if you wish to read (""chr2"", [ 50, 50M] ), then only the second array is queried.; - In the previous version of the tool, the array name was a constant - _genomicsdb_array_. The new version will be backward compatible with respect to reads. Hence, if a directory named _genomicsdb_array_ is found in the workspace directory, it's passed as the array for the _GenomicsDBFeatureReader_ otherwise the array names are generated from the directory entry names.; - Parallel import based on chromosome intervals. The number of threads to use can be specified as an integer argument to the [executeImport call](https://github.com/francares/gatk/blob/fmc_GenomicsDB_parallel_import/src/main/java/org/broadinstitute/hellbender/tools/genomicsdb/GenomicsDBImport.java#L535). If no argument is specified, the number of threads is determined by Java's ForkJoinPool (typically equal to the \#cores in the system). ; - The max number of intervals to import in parallel can be controlled by the command line argument --max-num-intervals-to-import-in-parallel (default 1); - Note that increasing parallelism increases the number of FeatureReaders opened to feed data to the importer. So, if you are using _N_ threads and your batch size is _B_, you will have _N*B_ feature readers open.; - Protobuf based API for import and read; - [Import](https://github.com/francares/gatk/blob/fmc_GenomicsDB_parallel_import/src/main/java/org/broadinstitute/hellbender/tools/genomicsdb/GenomicsDBImport.java#L522); - [Read](https://github.com/francares/gatk/blob/fmc_GenomicsDB_parallel_import/src/main/java/org/broadinstitute/hellbender/engine/FeatureDataSource.java#L405); - #3688 ; - Option to produce GT field; - [Option to produce GT for spanning deletion based on min PL value](https://github.com/Intel-HLS/GenomicsDB/issues/161); - https://github.com/broadinstitute/gatk/issues/2687; - Doesn't support #4541 or #3689 yet - next version; - Bug fixes; - #4716 ; - More error messages",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4645:2650,error,error,2650,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4645,1,['error'],['error']
Availability," at org.apache.spark.scheduler.TaskSchedulerImpl.start(TaskSchedulerImpl.scala:144); at org.apache.spark.SparkContext.<init>(SparkContext.scala:530); at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59); at org.broadinstitute.hellbender.engine.spark.SparkContextFactory.createSparkContext(SparkContextFactory.java:149); at org.broadinstitute.hellbender.engine.spark.SparkContextFactory.getSparkContext(SparkContextFactory.java:81); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:36); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:102); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:155); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:174); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:67); at org.broadinstitute.hellbender.Main.main(Main.java:82); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:731); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:181); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:206); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:121); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); ERROR: (gcloud.dataproc.jobs.submit.spark) Job [828b3d22-2109-4128-b4af-427a9d410db0] entered state [ERROR] while waiting for [DONE].; ```. Likely because of . ```; ""--conf"", ""spark.yarn.dist.files="" + script + ""/build/libIntelDeflater.so"",; ```. in gatk-launch. This likely needs special handling for dataproc.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1780:9643,ERROR,ERROR,9643,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1780,2,['ERROR'],['ERROR']
Availability," at the coverage mode (~ 100 fragments/bin), and a mode that bifurcates to lower values. **I conjecture that the bimodality results from heterogeneity of mappability scores at different positions in the same bin. The bins are 1k wide and it is feasible that some positions are highly mappable and other positions are not. This conjecture can be tested by collecting coverage on smaller bins and to check whether the bimodality weakens. If it does, I suggest filtering based on read position, similar to Genome STRiP, as opposed to filtering bins.**. Also, there is little sample-to-sample variation in coverage-mappability scatter plots (as opposed to, let's say, GC). **Therefore, there is no reason to consider mappability as a bias covariate**. The mappability coverage bias can be captured by a cohort-wide mean bias. Finally, let us study the NB overdispersion of different samples for different contigs:; ![image](https://user-images.githubusercontent.com/15305869/37785938-c47b4e38-2dd1-11e8-85f5-6e82764afbde.png). There's a clear structure here: some samples have higher overdispersion than the others. This could be due to degraded samples, less even GC curve, different chemistry, etc. In any event, we can regress the residual variance $psi_sj$ (for sample s, contig j) with a linear model:. psi_sj ~ N(a_s * psi_j + b_s, \beta). Here's how the regression looks like:; ![image](https://user-images.githubusercontent.com/15305869/37786020-fec1fccc-2dd1-11e8-9751-92e38979f120.png). Pretty much everything is explained by the linear model. This provides support for our choice of linear-NB model in gCNV. Finally, let us examine whether there is a correlation between $a_s$, $b_s$, and depth of coverage:. ![image](https://user-images.githubusercontent.com/15305869/37786095-26b08384-2dd2-11e8-9aed-8adff8995ac5.png); ![image](https://user-images.githubusercontent.com/15305869/37786101-2a6d4be2-2dd2-11e8-85c5-5c6754d42d52.png). There is absolutely no correlation, which is again expected.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4558:4033,degraded,degraded,4033,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4558,1,['degraded'],['degraded']
Availability," but I'm also attaching the full error output.; [pathseq_TCGA.slurm.1619078_1.err.txt](https://github.com/broadinstitute/gatk/files/1965063/pathseq_TCGA.slurm.1619078_1.err.txt). Thanks so much for any help you can provide!. `; 18/05/01 14:20:59 ERROR LiveListenerBus: SparkListenerBus has already stopped! Dropping event SparkListenerBlockUpdated(BlockUpdatedInfo(BlockManagerId(driver, 10.12.137.46, 39719, None),broadcast_1_piece0,StorageLevel(memory, 1 replicas),127561,0)); 18/05/01 14:21:18 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 18/05/01 14:23:29 INFO MemoryStore: MemoryStore cleared; 18/05/01 14:23:29 INFO BlockManager: BlockManager stopped; 18/05/01 14:23:29 INFO BlockManagerMaster: BlockManagerMaster stopped; 18/05/01 14:24:38 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 18/05/01 14:25:36 INFO SparkContext: Successfully stopped SparkContext; 14:25:37.027 INFO PathSeqPipelineSpark - Shutting down engine; [May 1, 2018 2:25:37 PM EDT] org.broadinstitute.hellbender.tools.spark.pathseq.PathSeqPipelineSpark done. Elapsed time: 37.98 minutes.; Runtime.totalMemory()=23999283200; org.apache.spark.SparkException: Job aborted due to stage failure: Task 20 in stage 1.0 failed 1 times, most recent failure: Lost task 20.0 in stage 1.0 (TID 891, localhost, executor driver): ExecutorLostFailure (executor driver exited caused by one of the running tasks) Reason: Executor heartbeat timed out after 131031 ms; Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(Array",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4725:1709,down,down,1709,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4725,1,['down'],['down']
Availability, chrM:14245-14544 isActive: false numReads: 0; 12:13:56.973 DEBUG Mutect2 - Processing assembly region at chrM:14545-14844 isActive: false numReads: 0; 12:13:56.984 DEBUG Mutect2 - Processing assembly region at chrM:14845-15144 isActive: false numReads: 0; 12:13:56.995 DEBUG Mutect2 - Processing assembly region at chrM:15145-15444 isActive: false numReads: 0; 12:13:57.009 DEBUG Mutect2 - Processing assembly region at chrM:15445-15744 isActive: false numReads: 0; 12:13:57.027 INFO ProgressMeter - chrM:15445 38.3 60 1.6; 12:13:57.035 DEBUG Mutect2 - Processing assembly region at chrM:15745-15960 isActive: false numReads: 14; 12:13:57.047 DEBUG Mutect2 - Processing assembly region at chrM:15961-16230 isActive: true numReads: 30; 12:13:57.055 DEBUG ReadThreadingGraph - Recovered 1 of 1 dangling tails; 12:13:57.063 DEBUG ReadThreadingGraph - Recovered 0 of 1 dangling heads; 12:13:57.096 DEBUG ReadThreadingGraph - Recovered 3 of 3 dangling tails; 12:13:57.106 DEBUG ReadThreadingGraph - Recovered 3 of 5 dangling heads; 12:13:57.464 DEBUG Mutect2Engine - Active Region chrM:15961-16230; 12:13:57.469 DEBUG Mutect2Engine - Extended Act Region chrM:15861-16299; 12:13:57.472 DEBUG Mutect2Engine - Ref haplotype coords chrM:15861-16299; 12:13:57.476 DEBUG Mutect2Engine - Haplotype count 111; 12:13:57.479 DEBUG Mutect2Engine - Kmer sizes count 0; 12:13:57.482 DEBUG Mutect2Engine - Kmer sizes values []; 12:13:58.821 DEBUG Mutect2 - Processing assembly region at chrM:16231-16299 isActive: false numReads: 15; 12:13:58.938 INFO Mutect2 - 0 read(s) filtered by: MappingQualityReadFilter ; 0 read(s) filtered by: MappingQualityNotZeroReadFilter ; 0 read(s) filtered by: MappedReadFilter ; 0 read(s) filtered by: NotSecondaryAlignmentReadFilter ; 0 read(s) filtered by: PassesVendorQualityCheckReadFilter ; 0 read(s) filtered by: NonChimericOriginalAlignmentReadFilter ; 0 read(s) filtered by: NonZeroReferenceLengthAlignmentReadFilter ; 0 read(s) filtered by: GoodCigarReadFilter ; 0 read(s) filte,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7281:22420,Recover,Recovered,22420,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7281,1,['Recover'],['Recovered']
Availability," class(es); MarkDuplicatesSpark . ### Affected version(s); - Latest public release version [4.4.0.0]. ### Description . I am working on 40X human WGS data, running MarkDuplicatesSpark on the computation node of a cluster with 40 cores and 192GB RAM. MarkDuplicatesSpark usually hangs and never finish (even after few days) with log as below:. ```; 11:26:29.511 INFO FileOutputCommitter - File Output Committer Algorithm version is 1; 11:26:29.511 INFO FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false; 11:26:29.512 INFO FileOutputCommitter - File Output Committer Algorithm version is 1; 11:26:29.512 INFO FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false; 11:26:30.738 INFO FileOutputCommitter - File Output Committer Algorithm version is 1; 11:26:30.738 INFO FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false; 11:26:30.738 INFO FileOutputCommitter - File Output Committer Algorithm version is 1; 11:26:30.738 INFO FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false; 11:26:45.830 INFO FileOutputCommitter - File Output Committer Algorithm version is 1; 11:26:45.830 INFO FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false; 11:26:45.831 INFO FileOutputCommitter - File Output Committer Algorithm version is 1; 11:26:45.831 INFO FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false; 11:26:55.475 INFO FileOutputCommitter - File Output Committer Algorithm version is 1; 11:26:55.475 INFO FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, igno",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8555:1089,failure,failures,1089,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8555,1,['failure'],['failures']
Availability," confidence mode and the annotation, the following changes will be made to any specified annotations: 'StrandBiasBySample' will be enabled. 'ChromosomeCounts', 'FisherStrand', 'StrandOddsRatio' and 'QualByDepth' annotations have been disabled; 17:08:13.200 INFO HaplotypeCallerEngine - Standard Emitting and Calling confidence set to 0.0 for reference-model confidence output; 17:08:13.206 INFO HaplotypeCallerEngine - All sites annotated with PLs forced to true for reference-model confidence output; 17:08:13.227 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/home/zepengmu/tools/gatk-4.1.8.0/gatk-package-4.1.8.0-local.jar!/com/intel/gkl/native/libgkl_utils.so; 17:08:13.228 INFO NativeLibraryLoader - Loading libgkl_pairhmm_omp.so from jar:file:/home/zepengmu/tools/gatk-4.1.8.0/gatk-package-4.1.8.0-local.jar!/com/intel/gkl/native/libgkl_pairhmm_omp.so; 17:08:13.260 INFO IntelPairHmm - Flush-to-zero (FTZ) is enabled when running PairHMM; 17:08:13.260 INFO IntelPairHmm - Available threads: 1; 17:08:13.260 INFO IntelPairHmm - Requested threads: 4; 17:08:13.261 WARN IntelPairHmm - Using 1 available threads, but 4 were requested; 17:08:13.261 INFO PairHMM - Using the OpenMP multi-threaded AVX-accelerated native PairHMM implementation; 17:08:13.346 INFO ProgressMeter - Starting traversal; 17:08:13.346 INFO ProgressMeter - Current Locus Elapsed Minutes Regions Processed Regions/Minute; 17:08:17.401 WARN InbreedingCoeff - InbreedingCoeff will not be calculated; at least 10 samples must have called genotypes. 17:08:43.866 INFO ProgressMeter - chr1:1053465 0.5 3780 7431.7. ...Many lines in between and then... 19:11:09.189 INFO VectorLoglessPairHMM - Time spent in setup for JNI call : 1.190328316; 19:11:09.189 INFO PairHMM - Total compute time in PairHMM computeLogLikelihoods() : 398.5135636; 19:11:09.190 INFO SmithWatermanAligner - Total compute time in java Smith-Waterman : 258.73 sec; 19:11:09.190 INFO HaplotypeCaller - Shutting down engine; [August 27, 2020 7:1",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6783:3490,Avail,Available,3490,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6783,1,['Avail'],['Available']
Availability, depth metadata...; 22:01:54.381 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chrM). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.381 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr1_KI270706v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.381 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr1_KI270707v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.381 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr1_KI270708v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.381 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr1_KI270709v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr1_KI270710v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr1_KI270711v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr1_KI270712v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr1_KI270713v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr1_KI270714v1_random).,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4840:1406,reliab,reliable,1406,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4840,1,['reliab'],['reliable']
Availability," dropbox link: https://www.dropbox.com/sh/xae79hanumpireu/AABKo1l4Y-z5G5YLBqSpylRva?dl=0. Then the following code will reproduce the issue:; ```; wget https://github.com/broadinstitute/picard/releases/download/2.19.0/picard.jar. wget https://github.com/broadinstitute/gatk/releases/download/4.1.2.0/gatk-4.1.2.0.zip; unzip gatk-4.1.2.0.zip. wget -O- ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/000/001/405/GCA_000001405.15_GRCh38/seqs_for_alignment_pipelines.ucsc_ids/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz | \; gzip -d > GCA_000001405.15_GRCh38_no_alt_analysis_set.fna. samtools faidx GCA_000001405.15_GRCh38_no_alt_analysis_set.fna. java -jar picard.jar \; CreateSequenceDictionary \; R=GCA_000001405.15_GRCh38_no_alt_analysis_set.fna \; O=GCA_000001405.15_GRCh38_no_alt_analysis_set.dict. (echo ""##fileformat=VCFv4.2""; \; echo ""##contig=<ID=chrX,length=156040895>""; \; echo -e ""#CHROM\tPOS\tID\tREF\tALT\tQUAL\tFILTER\tINFO""; \; echo -e ""chr1\t97329945\t.\tT\tA\t.\t.\t.""; \; echo -e ""chr1\t97329967\t.\tC\tT\t.\t.\t."") | bgzip > input.vcf.gz && \; tabix -f input.vcf.gz. for score in 11 12; do; gatk-4.1.2.0/gatk HaplotypeCaller \; -R GCA_000001405.15_GRCh38_no_alt_analysis_set.fna \; -I input.bam \; -O output.$score.vcf.gz \; --genotyping-mode GENOTYPE_GIVEN_ALLELES \; --alleles input.vcf.gz \; -L chr1:97329945-97329967 \; --min-base-quality-score $score && \; bcftools query \; -f ""[%CHROM\t%POS\t%REF\t%ALT\t%GT\t%AD\n]"" \; output.$score.vcf.gz \; -r chr1:97329945-97329967; done; ```. When the parameter `--min-base-quality-score 11` is used, the GT/AD output is this:; ```; chr1	97329945	T	A	1/1	0,35; chr1	97329967	C	T	1/1	0,33; ```; When the parameter `--min-base-quality-score 12` is used, the GT/AD output is this:; ```; chr1	97329945	T	A	0/1	9,10; chr1	97329967	C	T	0/1	6,11; ```; The first output is the output that makes sense. When `--min-base-quality-score 12` is used, it is as if HaplotypeCaller invents some reference allele reads and then uses them to genotype th",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6045:1131,echo,echo,1131,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6045,1,['echo'],['echo']
Availability," file that reproduces the issue. First of all, you have to download the mini input.bam file from this dropbox link: https://www.dropbox.com/sh/xae79hanumpireu/AABKo1l4Y-z5G5YLBqSpylRva?dl=0. Then the following code will reproduce the issue:; ```; wget https://github.com/broadinstitute/picard/releases/download/2.19.0/picard.jar. wget https://github.com/broadinstitute/gatk/releases/download/4.1.2.0/gatk-4.1.2.0.zip; unzip gatk-4.1.2.0.zip. wget -O- ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/000/001/405/GCA_000001405.15_GRCh38/seqs_for_alignment_pipelines.ucsc_ids/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz | \; gzip -d > GCA_000001405.15_GRCh38_no_alt_analysis_set.fna. samtools faidx GCA_000001405.15_GRCh38_no_alt_analysis_set.fna. java -jar picard.jar \; CreateSequenceDictionary \; R=GCA_000001405.15_GRCh38_no_alt_analysis_set.fna \; O=GCA_000001405.15_GRCh38_no_alt_analysis_set.dict. (echo ""##fileformat=VCFv4.2""; \; echo ""##contig=<ID=chrX,length=156040895>""; \; echo -e ""#CHROM\tPOS\tID\tREF\tALT\tQUAL\tFILTER\tINFO""; \; echo -e ""chr1\t97329945\t.\tT\tA\t.\t.\t.""; \; echo -e ""chr1\t97329967\t.\tC\tT\t.\t.\t."") | bgzip > input.vcf.gz && \; tabix -f input.vcf.gz. for score in 11 12; do; gatk-4.1.2.0/gatk HaplotypeCaller \; -R GCA_000001405.15_GRCh38_no_alt_analysis_set.fna \; -I input.bam \; -O output.$score.vcf.gz \; --genotyping-mode GENOTYPE_GIVEN_ALLELES \; --alleles input.vcf.gz \; -L chr1:97329945-97329967 \; --min-base-quality-score $score && \; bcftools query \; -f ""[%CHROM\t%POS\t%REF\t%ALT\t%GT\t%AD\n]"" \; output.$score.vcf.gz \; -r chr1:97329945-97329967; done; ```. When the parameter `--min-base-quality-score 11` is used, the GT/AD output is this:; ```; chr1	97329945	T	A	1/1	0,35; chr1	97329967	C	T	1/1	0,33; ```; When the parameter `--min-base-quality-score 12` is used, the GT/AD output is this:; ```; chr1	97329945	T	A	0/1	9,10; chr1	97329967	C	T	0/1	6,11; ```; The first output is the output that makes sense. When `--min-base-quality-score 12` is us",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6045:977,echo,echo,977,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6045,3,['echo'],['echo']
Availability, for this subset of the data. Error is; ```; Stdout: 22:01:54.365 INFO segment_gcnv_calls - Loading ploidy calls...; 22:01:54.366 INFO gcnvkernel.io.io_metadata - Loading germline contig ploidy and global read depth metadata...; 22:01:54.381 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chrM). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.381 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr1_KI270706v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.381 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr1_KI270707v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.381 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr1_KI270708v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.381 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr1_KI270709v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr1_KI270710v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr1_KI270711v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr1_KI270712v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr1_KI270713v1_random).,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4840:1197,reliab,reliable,1197,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4840,1,['reliab'],['reliable']
Availability," found for INFO field MLEAC - the field will NOT be part of INFO fields in the generated VCF records ; ; 14:17:39.941 info NativeGenomicsDB - pid=12231 tid=12232 No valid combination operation found for INFO field MLEAF - the field will NOT be part of INFO fields in the generated VCF records ; ; 14:17:41.513 INFO FeatureManager - Using codec IntervalListCodec to read file file:///shared/projects/gentaumix/Ressources/interval\_genomicsdbi/temp\_6/interval.interval\_list ; ; 14:17:41.628 INFO IntervalArgumentCollection - Processing 62000000 bp from intervals ; ; 14:17:41.743 INFO GenotypeGVCFs - Done initializing engine ; ; 14:17:41.897 INFO ProgressMeter - Starting traversal ; ; 14:17:41.898 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute ; ; 14:17:52.020 INFO ProgressMeter - chr2:60009645 0.2 9000 53349.1 ; ; 14:18:02.071 INFO ProgressMeter - chr2:60039632 0.3 37000 110048.1 ; ; 14:18:02.683 INFO GenotypeGVCFs - Shutting down engine ; ; GENOMICSDB\_TIMER,GenomicsDB iterator next() timer,Wall-clock time(s),5.257768857000008,Cpu time(s),5.221303873999989 ; ; \[10 septembre 2021 14:18:02 CEST\] org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs done. Elapsed time: 0.46 minutes. ; ; Runtime.totalMemory()=7034372096 ; ; java.lang.IndexOutOfBoundsException: Index: 0, Size: 0 ; ; at java.util.ArrayList.rangeCheck(ArrayList.java:659) ; ; at java.util.ArrayList.get(ArrayList.java:435) ; ; at org.broadinstitute.hellbender.tools.walkers.annotator.allelespecific.StrandBiasUtils.combineAttributeMap(StrandBiasUtils.java:120) ; ; at org.broadinstitute.hellbender.tools.walkers.annotator.allelespecific.AS\_StrandBiasTest.combineRawData(AS\_StrandBiasTest.java:118) ; ; at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorEngine.combineAnnotations(VariantAnnotatorEngine.java:234) ; ; at org.broadinstitute.hellbender.tools.walkers.ReferenceConfidenceVariantContextMerger.mergeAttributes(ReferenceConfidenceVariantContextMer",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7465:6820,down,down,6820,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7465,1,['down'],['down']
Availability," from this workspace (https://app.terra.bio/#workspaces/help-gatk/Germline-CNVs-GATK4), and the workflow is keep failing at the ""CollectCounts"" step with the following error; in multiple shards. --------------------------------------------------------------------------------------------------------------------; A USER ERROR has occurred: Traversal by intervals was requested but some input files are not indexed.; Please index all input files:. samtools index /cromwell_root/dg.4DFC_3615e55e-6aa3-43e7-8d7b-6f2824071971/C345.TCGA-A3-3373-11A-01D-1421-08.5.bam; --------------------------------------------------------------------------------------------------------------------. This was weird since I set a correct index file as an input, but after some investigation, I realized that ; the error seemed to be occurring when the bucket path where BAM index was located was different from that of BAM file ; For example, if you look at this log below, . `Attempting to download gs://gdc-tcga-phs000178-controlled/KIRC/DNA/WXS/BI/ILLUMINA/C345.TCGA-A3-3373-11A-01D-1421-08.5.bam to /cromwell_root/dg.4DFC_3615e55e-6aa3-43e7-8d7b-6f2824071971/C345.TCGA-A3-3373-11A-01D-1421-08.5.bam; Successfully activated service account; Will continue with download. Activated service account credentials for: [kd5mqbpsed8lzz0kyz9tvkht-3274@dcf-prod.iam.gserviceaccount.com]; Download complete!; 2021/09/29 15:46:14 Localizing input drs://dg.4DFC:ab4d57fa-bfff-4a48-bd96-f2866ecfe0e1 -> /cromwell_root/dg.4DFC_ab4d57fa-bfff-4a48-bd96-f2866ecfe0e1/C345.TCGA-A3-3373-11A-01D-1421-08.5.bam.bai; Requester Pays project ID is Some(vanallen-firecloud-nih); Attempting to download gs://gdc-tcga-phs000178-controlled/KIRC/DNA/WXS/BI/ILLUMINA/C345.TCGA-A3-3373-11A-01D-1421-08.5.bam.bai to /cromwell_root/dg.4DFC_ab4d57fa-bfff-4a48-bd96-f2866ecfe0e1/C345.TCGA-A3-3373-11A-01D-1421-08.5.bam.bai; Successfully activated service account; Will continue with download. Activated service account credentials for: [kd5mqbpsed8lzz0",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7487:1025,down,download,1025,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7487,1,['down'],['download']
Availability," htsjdk.samtools.BAMFileWriter.writeAlignment(BAMFileWriter.java:134); ... 12 more; Caused by: java.io.IOException: Stale file handle; at java.base/sun.nio.ch.FileDispatcherImpl.write0(Native Method); at java.base/sun.nio.ch.FileDispatcherImpl.write(FileDispatcherImpl.java:62); at java.base/sun.nio.ch.IOUtil.writeFromNativeBuffer(IOUtil.java:115); at java.base/sun.nio.ch.IOUtil.write(IOUtil.java:80); at java.base/sun.nio.ch.FileChannelImpl.write(FileChannelImpl.java:280); at java.base/java.nio.channels.Channels.writeFullyImpl(Channels.java:74); at java.base/java.nio.channels.Channels.writeFully(Channels.java:97); at java.base/java.nio.channels.Channels.access$000(Channels.java:62); at java.base/java.nio.channels.Channels$1.write(Channels.java:172); at java.base/java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:81); at java.base/java.io.BufferedOutputStream.write(BufferedOutputStream.java:127); at htsjdk.samtools.util.BinaryCodec.writeBytes(BinaryCodec.java:220). Error type2:. gatk --java-options ""-Xmx32G -XX:ParallelGCThreads=8 -Djava.io.tmpdir=/group/zhougrp2/dguan/tmp"" SplitNCigarReads --spark-runner LOCAL -I 10_mkdup/SAMN05828173_mkdup.bam -R /group/zhougrp2/dguan/00_ref/Gallus_gallus.GRCg6a.dna.toplevel.fa -L /group/zhougrp2/dguan/00_ref/chicken_chr.list -O 11_cigar/SAMN05828173_cigar.bam --create-output-bam-index true --max-reads-in-memory 5000. 00:01:27.003 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/dguan/anaconda3/envs/Chicken_GTEx/share/gatk4-4.1.9.0-0/gatk-package-4.1.9.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Feb 21, 2021 12:01:27 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 00:01:27.275 INFO SplitNCigarReads - ------------------------------------------------------------; 00:01:27.276 INFO SplitNCigarReads - The Genome Analysis Toolkit (GATK) v4.1.9.0; 00:01:27.276 INFO Sp",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7091:61843,Error,Error,61843,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7091,1,['Error'],['Error']
Availability," id: container_1507683879816_0006_01_000003; Exit code: 50; Stack trace: ExitCodeException exitCode=50: ; 	at org.apache.hadoop.util.Shell.runCommand(Shell.java:601); 	at org.apache.hadoop.util.Shell.run(Shell.java:504); 	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:786); 	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:213); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Container exited with a non-zero exit code 50. 17/10/11 14:19:38 ERROR scheduler.TaskSetManager: Task 0 in stage 1.0 failed 4 times; aborting job; 17/10/11 14:19:38 INFO cluster.YarnScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool ; 17/10/11 14:19:38 INFO storage.BlockManagerMasterEndpoint: Trying to remove executor 2 from BlockManagerMaster.; 17/10/11 14:19:38 INFO storage.BlockManagerMaster: Removal of executor 2 requested; 17/10/11 14:19:38 INFO cluster.YarnClientSchedulerBackend: Asked to remove non-existent executor 2; 17/10/11 14:19:38 INFO cluster.YarnScheduler: Cancelling stage 1; 17/10/11 14:19:38 INFO scheduler.DAGScheduler: ResultStage 1 (saveAsNewAPIHadoopFile at ReadsSparkSink.java:203) failed in 10.702 s due to Job aborted due to stage failure: Task 0 in stage 1.0 failed 4 times, most recent failure: Lost task 0.3 in stage 1.0 (TID 4, com2, executor 2): ExecutorLostFailure (executor 2 exited caused by one of the running tasks) Reason: Container marked as failed: container_1507683879816_0006_01_000003 on host: ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686:28431,ERROR,ERROR,28431,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686,1,['ERROR'],['ERROR']
Availability," if true, annotate the M2 VCFs using oncotator (to produce a TCGA MAF); ##; ## ** Primary inputs **; ## ref_fasta, ref_fasta_index, ref_dict: reference genome, index, and dictionary; ## tumor_bam, tumor_bam_index, and tumor_sample_name: BAM, index and sample name for the tumor sample (sample name used for output naming); ## normal_bam, normal_bam_index, and normal_sample_name: BAM, index and sample name for the normal sample (optional if running tumor-only); ##; ## ** Primary resources ** (optional but strongly recommended); ## pon, pon_index: optional panel of normals in VCF format containing probable technical artifacts (false positves); ## gnomad, gnomad_index: optional database of known germline variants (see http://gnomad.broadinstitute.org/downloads); ## variants_for_contamination, variants_for_contamination_index: VCF of common variants with allele frequencies fo calculating contamination; ##; ## ** Secondary resources ** (for optional tasks); ## onco_ds_tar_gz, default_config_file: Oncotator datasources and config file; ## sequencing_center, sequence_source: metadata for Oncotator; ##; ## Outputs :; ## - One VCF file and its index with primary filtering applied; secondary filtering and functional annotation if requested.; ##; ## Cromwell version support ; ## - Successfully tested on v27; ##; ## LICENSING : ; ## This script is released under the WDL source code license (BSD-3) (see LICENSE in ; ## https://github.com/broadinstitute/wdl). Note however that the programs it calls may ; ## be subject to different licenses. Users are responsible for checking that they are; ## authorized to run all programs before running this script. Please see the docker ; ## pages at https://hub.docker.com/r/broadinstitute/* for detailed licensing information ; ## pertaining to the included programs. workflow Mutect2 {; # Runtime; String gatk4_jar; File picard_jar; String m2_docker; String oncotator_docker; Int preemptible_attempts; # Workflow options; Int scatter_count; File? in",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3341:2253,down,downloads,2253,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3341,1,['down'],['downloads']
Availability," in GenotypeGVCFs when using GenomicsDB. ----------. This request was created from a contribution made by Zane Swaydan on June 30, 2022 11:13 UTC. Link: [https://gatk.broadinstitute.org/hc/en-us/community/posts/6972994559643-java-lang-IllegalStateException-in-GenotypeGVCFs-after-GenomicsDBImport-GATK-4-2-6-1](https://gatk.broadinstitute.org/hc/en-us/community/posts/6972994559643-java-lang-IllegalStateException-in-GenotypeGVCFs-after-GenomicsDBImport-GATK-4-2-6-1). \--. I'm using the GenotypeGVCFs function based on GenomicsDBImport database. I've divided the reference into 50 intervals. Some intervals seems ok, but some reports error as following. I used a VCF file in ""--force-output-intervals"" for down stream analysis. I've never seen this error without ""--force-output-intervals"". I've searched for the error message and changed my GATK version to 4.2.6.1 since similar error has been solved as a bug in recent update, but it still not works on my dataset... REQUIRED for all errors and issues: ; ; a) GATK version used:. GenomicsDBImport: GATK 4.2.4.0. GenotypeGVCFs: GATK 4.2.6.1. b) Exact command used:. java -Dsamjdk.use\_async\_io\_read\_samtools=false -Dsamjdk.use\_async\_io\_write\_samtools=true -Dsamjdk.use\_async\_io\_write\_tribble=false -Dsamjdk.compression\_level=2 -Xms4G -Xmx16G -XX:+UseParallelGC -XX:ParallelGCThreads=2 -jar MySoftwares/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar GenotypeGVCFs -R PigeonBatch5/000\_DataLinks/000\_RefSeq/Cliv2.1\_genomic.fasta --intervals 006\_IntervalsSplit\_DBImport\_VCFref/interval\_9.list --force-output-intervals PigeonBatch4/008\_RawVcfGz/MergeVcf/pigeonBatch1234\_filtered.vcf.gz -V gendb://007\_Database\_DBImport\_VCFref/database\_interval\_9 -O 008\_RawVcfGz\_DBImport\_VCFref/001\_DividedIntervals/interval\_9.vcf.gz --tmp-dir TMPDIR --allow-old-rms-mapping-quality-annotation-data --only-output-calls-starting-in-intervals --verbosity ERROR.   ; ; c) Entire program log:. Using GATK jar MySoftwares/gatk-4.2.6.1/gatk-package-",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7966:1061,error,errors,1061,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7966,1,['error'],['errors']
Availability," in Travis CI. These usually manifest as a simple ""exited with code 137"" (ie., killed by signal 9) error, but sometimes we get an explicit segfault or out-of-memory error. Examples:. ```; �[31mFAILURE: �[39m�[31mBuild failed with an exception.�[39m; * What went wrong:; Execution failed for task ':test'.; �[33m> �[39mProcess 'Gradle Test Executor 1' finished with non-zero exit value 137; ```. ```; :test[M::bwa_idx_load_from_disk] read 0 ALT contigs; OpenJDK 64-Bit Server VM warning: INFO: os::commit_memory(0x0000000715180000, 719847424, 0) failed; error='Cannot allocate memory' (errno=12). #; # There is insufficient memory for the Java Runtime Environment to continue.; # Native memory allocation (mmap) failed to map 719847424 bytes for committing reserved memory.; # An error report file with more information is saved as:; # /home/travis/build/broadinstitute/gatk/hs_err_pid11513.log; ```. ```; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x00007f27ebfe7d9a, pid=11455, tid=0x00007f27e87e5700; #; # JRE version: OpenJDK Runtime Environment (8.0_111-b14) (build 1.8.0_111-8u111-b14-3~14.04.1-b14); # Java VM: OpenJDK 64-Bit Server VM (25.111-b14 mixed mode linux-amd64 compressed oops); # Problematic frame:; # C [libfml.6198146539708364717.jnilib+0xed9a] rld_itr_init+0x4a; ```. ```; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x00007fd2680a350c, pid=11685, tid=0x00007fd2b02bf700; #; # JRE version: OpenJDK Runtime Environment (8.0_111-b14) (build 1.8.0_111-8u111-b14-3~14.04.1-b14); # Java VM: OpenJDK 64-Bit Server VM (25.111-b14 mixed mode linux-amd64 compressed oops); # Problematic frame:; # C [libbwa.5694772191018335324.jnilib+0x850c] bwa_mem2idx+0xcc; ```. The underlying issue in these cases is likely either ""out of memory"" or, perhaps in the case of the seg faults, ""file not found"" or ""malformed file"", but we could greatly improve our ability to interpret Travis failures if we ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3209:1011,error,error,1011,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3209,1,['error'],['error']
Availability, inconsistency: seq_len is not the same. Abort!; ... 11:54:40.433 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] org.gradle.api.tasks.TaskExecutionException: Execution failed for task ':test'.; 11:54:40.433 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.executeActions(ExecuteActionsTaskExecuter.java:98); 11:54:40.433 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.execute(ExecuteActionsTaskExecuter.java:68); 11:54:40.433 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.SkipUpToDateTaskExecuter.execute(SkipUpToDateTaskExecuter.java:62); 11:54:40.433 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.ValidatingTaskExecuter.execute(ValidatingTaskExecuter.java:58); 11:54:40.433 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.SkipEmptySourceFilesTaskExecuter.execute(SkipEmptySourceFilesTaskExecuter.java:88); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.ResolveTaskArtifactStateTaskExecuter.execute(ResolveTaskArtifactStateTaskExecuter.java:46); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.SkipTaskWithNoActionsExecuter.execute(SkipTaskWithNoActionsExecuter.java:51); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.SkipOnlyIfTaskExecuter.execute(SkipOnlyIfTaskExecuter.java:54); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.ExecuteAtMostOnceTaskExecuter.execute(ExecuteAtMostOnceTaskExecuter.java:43); 11:54:40.434,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2802:1227,ERROR,ERROR,1227,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2802,1,['ERROR'],['ERROR']
Availability," initialized @4976ms; 17/11/15 19:43:11 INFO org.spark_project.jetty.server.Server: jetty-9.3.z-SNAPSHOT; 17/11/15 19:43:11 INFO org.spark_project.jetty.server.Server: Started @5092ms; 17/11/15 19:43:11 INFO org.spark_project.jetty.server.AbstractConnector: Started ServerConnector@5917b44d{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 17/11/15 19:43:12 INFO com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase: GHFS version: 1.6.1-hadoop2; 17/11/15 19:43:13 INFO org.apache.hadoop.yarn.client.RMProxy: Connecting to ResourceManager at gatk-test-8875b999-b609-4a3f-86ea-973b929fe662-m/10.240.0.18:8032; 17/11/15 19:43:17 INFO org.apache.hadoop.yarn.client.api.impl.YarnClientImpl: Submitted application application_1510774921124_0001; 17/11/15 19:43:28 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input files to process : 1; 17/11/15 19:43:35 ERROR org.apache.spark.scheduler.TaskResultGetter: Exception while getting task result; com.esotericsoftware.kryo.KryoException: Error during Java deserialization.; Serialization trace:; genotypes (org.seqdoop.hadoop_bam.VariantContextWithHeader); interval (org.broadinstitute.hellbender.engine.spark.SparkSharder$PartitionLocatable); 	at com.esotericsoftware.kryo.serializers.JavaSerializer.read(JavaSerializer.java:65); 	at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:708); 	at com.esotericsoftware.kryo.serializers.ObjectField.read(ObjectField.java:125); 	at com.esotericsoftware.kryo.serializers.FieldSerializer.read(FieldSerializer.java:551); 	at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:708); 	at com.esotericsoftware.kryo.serializers.ObjectField.read(ObjectField.java:125); 	at com.esotericsoftware.kryo.serializers.FieldSerializer.read(FieldSerializer.java:551); 	at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:708); 	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.read(DefaultArraySerializers.java:396); 	at com.esotericsoftware.kryo.serializers.DefaultArraySeria",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3840:4669,Error,Error,4669,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3840,1,['Error'],['Error']
Availability," intervals that had >1000x coverage.; 16:59:33.036 INFO StructuralVariationDiscoveryPipelineSpark - Discovered 8773016 mapped template names.; 17:00:07.058 INFO StructuralVariationDiscoveryPipelineSpark - Ignoring 19200460 genomically common kmers.; 17:05:25.896 INFO StructuralVariationDiscoveryPipelineSpark - Discovered 34752266 kmers.; 17:10:46.253 INFO StructuralVariationDiscoveryPipelineSpark - Discovered 31945322 unique template names for assembly.; 17:45:06.748 INFO StructuralVariationDiscoveryPipelineSpark - Wrote SAM file of aligned contigs.; 17:45:26.199 INFO StructuralVariationDiscoveryPipelineSpark - Discovered 5716 variants.; 17:45:26.210 INFO StructuralVariationDiscoveryPipelineSpark - INV: 231; 17:45:26.210 INFO StructuralVariationDiscoveryPipelineSpark - DEL: 3262; 17:45:26.210 INFO StructuralVariationDiscoveryPipelineSpark - DUP: 1065; 17:45:26.210 INFO StructuralVariationDiscoveryPipelineSpark - INS: 1158; 17:45:26.397 INFO StructuralVariationDiscoveryPipelineSpark - Shutting down engine; [May 8, 2017 5:45:26 PM UTC] org.broadinstitute.hellbender.tools.spark.sv.StructuralVariationDiscoveryPipelineSpark done. Elapsed time: 48.71 minutes.; Runtime.totalMemory()=17815830528; ```. This branch with `minCoherentEvidence` set to 7 (and `minEvidenceCount` remaining at 15):. ```; 18:55:30.222 INFO StructuralVariationDiscoveryPipelineSpark - Metadata retrieved.; 18:56:15.451 INFO StructuralVariationDiscoveryPipelineSpark - Discovered 30678 intervals.; 18:56:15.547 INFO StructuralVariationDiscoveryPipelineSpark - Killed 387 intervals that were near reference gaps.; 18:56:45.252 INFO StructuralVariationDiscoveryPipelineSpark - Killed 174 intervals that had >1000x coverage.; 18:57:27.031 INFO StructuralVariationDiscoveryPipelineSpark - Discovered 9424481 mapped template names.; 18:58:07.742 INFO StructuralVariationDiscoveryPipelineSpark - Ignoring 19200460 genomically common kmers.; 19:03:21.960 INFO StructuralVariationDiscoveryPipelineSpark - Discovered 3930956",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2684:1892,down,down,1892,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2684,1,['down'],['down']
Availability," intervals that had >1000x coverage.; 18:57:27.031 INFO StructuralVariationDiscoveryPipelineSpark - Discovered 9424481 mapped template names.; 18:58:07.742 INFO StructuralVariationDiscoveryPipelineSpark - Ignoring 19200460 genomically common kmers.; 19:03:21.960 INFO StructuralVariationDiscoveryPipelineSpark - Discovered 39309565 kmers.; 19:08:31.990 INFO StructuralVariationDiscoveryPipelineSpark - Discovered 34034345 unique template names for assembly.; 19:40:40.149 INFO StructuralVariationDiscoveryPipelineSpark - Wrote SAM file of aligned contigs.; 19:41:00.570 INFO StructuralVariationDiscoveryPipelineSpark - Discovered 6239 variants.; 19:41:00.582 INFO StructuralVariationDiscoveryPipelineSpark - INV: 238; 19:41:00.582 INFO StructuralVariationDiscoveryPipelineSpark - DEL: 3639; 19:41:00.582 INFO StructuralVariationDiscoveryPipelineSpark - DUP: 1119; 19:41:00.582 INFO StructuralVariationDiscoveryPipelineSpark - INS: 1243; 19:41:00.767 INFO StructuralVariationDiscoveryPipelineSpark - Shutting down engine; [May 8, 2017 7:41:00 PM UTC] org.broadinstitute.hellbender.tools.spark.sv.StructuralVariationDiscoveryPipelineSpark done. Elapsed time: 46.37 minutes.; ```. This branch with `minCoherentEvidenceCount` set to 4:. ```; 19:48:13.982 INFO StructuralVariationDiscoveryPipelineSpark - Metadata retrieved.; 19:48:57.930 INFO StructuralVariationDiscoveryPipelineSpark - Discovered 52918 intervals.; 19:48:58.053 INFO StructuralVariationDiscoveryPipelineSpark - Killed 417 intervals that were near reference gaps.; 19:49:27.873 INFO StructuralVariationDiscoveryPipelineSpark - Killed 177 intervals that had >1000x coverage.; 19:50:09.183 INFO StructuralVariationDiscoveryPipelineSpark - Discovered 12444440 mapped template names.; 19:50:59.411 INFO StructuralVariationDiscoveryPipelineSpark - Ignoring 19200460 genomically common kmers.; 19:57:19.267 INFO StructuralVariationDiscoveryPipelineSpark - Discovered 62077256 kmers.; 20:03:43.231 INFO StructuralVariationDiscoveryPipelineSpark ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2684:3562,down,down,3562,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2684,1,['down'],['down']
Availability," is in reference confidence mode and the annotation, the following changes will be made to any specified annotations: 'StrandBiasBySample' will be enabled. 'ChromosomeCounts', 'FisherStrand', 'StrandOddsRatio' and 'QualByDepth' annotations have been disabled; 20/08/15 09:38:13 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 11.8 MB, free 15.8 GB); 20/08/15 09:38:13 INFO SparkUI: Stopped Spark web UI at http://amarel2.amarel.rutgers.edu:4040; 20/08/15 09:38:13 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 20/08/15 09:38:13 INFO MemoryStore: MemoryStore cleared; 20/08/15 09:38:13 INFO BlockManager: BlockManager stopped; 20/08/15 09:38:13 INFO BlockManagerMaster: BlockManagerMaster stopped; 20/08/15 09:38:13 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 20/08/15 09:38:13 INFO SparkContext: Successfully stopped SparkContext; 09:38:13.271 INFO HaplotypeCallerSpark - Shutting down engine; [August 15, 2020 9:38:13 AM EDT] org.broadinstitute.hellbender.tools.HaplotypeCallerSpark done. Elapsed time: 0.13 minutes.; Runtime.totalMemory()=15164506112; Exception in thread ""main"" java.lang.StackOverflowError; at com.esotericsoftware.kryo.util.DefaultClassResolver.writeName(DefaultClassResolver.java:108); at com.esotericsoftware.kryo.util.DefaultClassResolver.writeClass(DefaultClassResolver.java:99); at com.esotericsoftware.kryo.Kryo.writeClass(Kryo.java:540); at com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectField.java:76); at com.esotericsoftware.kryo.serializers.FieldSerializer.write(FieldSerializer.java:505); at com.esotericsoftware.kryo.Kryo.writeObject(Kryo.java:575); at com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectField.java:80); at com.esotericsoftware.kryo.serializers.FieldSerializer.write(FieldSerializer.java:505); at com.esotericsoftware.kryo.Kryo.writeObject(Kryo.java:575). 20/08/15 09:38:13 INFO ShutdownHookManager: Shutdown h",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6750:11574,down,down,11574,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6750,1,['down'],['down']
Availability," is my command line:; `java -DGATK_STACKTRACE_ON_USER_EXCEPTION=true -jar ${gatk4_jar} IndexFeatureFile --feature-file ${gvcf} --output ${gvcf}.idx 2>${LOGDIR}/index_candidates.log`. I tried this exact command line with another genome, which worked just fine with output progress report as following for a comparison of the multiple chromosomes processed:; ```; 12:50:38.871 INFO ProgressMeter - Starting traversal; 12:50:38.873 INFO ProgressMeter - Current Locus Elapsed Minutes Records Processed Records/Minute; 12:50:48.876 INFO ProgressMeter - N1:21408210 0.2 5669000 34010598.9; 12:50:58.876 INFO ProgressMeter - N2:13383863 0.3 11960000 35874618.8. ...... 12:55:58.884 INFO ProgressMeter - N19:50063133 5.3 208660000 39122405.2; 12:56:02.409 INFO ProgressMeter - N19:55994806 5.4 210940859 39119265.4; 12:56:02.409 INFO ProgressMeter - Traversal complete. Processed 210940859 total records in 5.4 minutes.; 12:56:02.429 INFO IndexFeatureFile - Successfully wrote index to /storage/ppl/yifang/20190225/data3/samtools_sorted_out/SNPs_candidates.g.vcf.idx; 12:56:02.429 INFO IndexFeatureFile - Shutting down engine; [April 25, 2019 12:56:02 PM CST] org.broadinstitute.hellbender.tools.IndexFeatureFile done. Elapsed time: 5.42 minutes.; Runtime.totalMemory()=5618270208; ```; Althought no warning/error messages was issued for the indexing of this big genome, I have tried to debug on 3 things I could think of:. 1. The chromosome and the coordinate are sorted ascendandly, although the chromosome names are not simply numeric continuous because of the A/B subgroup for each chromosome.; 2. The genome size difference, for which no clue was aboserved about the chromosome length limits. ; 3. The chromosome names for this big genome is quite long, but I tried the shorter names as A11 for chr1A_part1, A12 for chr1A_part2, ... B72 for chr7B_part2 (42 chromosomes in total), and the problem stayed exactly the same. Not sure what I may have missed. I appreciate any insight of this problem.; Yifang",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5917:5675,down,down,5675,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5917,2,"['down', 'error']","['down', 'error']"
Availability," like this:. ##### ERROR MESSAGE: Invalid command line: No tribble type was provided on the command line and the type of the file could not be determined dynamically. Please add an explicit type tag :NAME listing the correct type from among the supported types:; ##### ERROR Name FeatureType Documentation; ##### ERROR BCF2 VariantContext (this is an external codec and is not documented within GATK); ##### ERROR VCF VariantContext (this is an external codec and is not documented within GATK); ##### ERROR VCF3 VariantContext (this is an external codec and is not documented within GATK); ##### ERROR ------------------------------------------------------------------------------------------. then I added a name like this:. --variant:VCF $NOW/w-91.raw.g.vcf \; --variant:VCF $NOW/w-92.raw.g.vcf \; --variant:VCF $NOW/w-93.raw.g.vcf \. also met a error like this:. ##### ERROR; ##### ERROR MESSAGE: Your input file has a malformed header: We never saw the required CHROM header line (starting with one #) for the input VCF file; ##### ERROR ------------------------------------------------------------------------------------------. and I change the name like this:. --variant:VCF3 $NOW/w-91.raw.g.vcf \; --variant:VCF3 $NOW/w-92.raw.g.vcf \; --variant:VCF3 $NOW/w-93.raw.g.vcf \. also error:. ##### ERROR MESSAGE: Unable to parse header with error: Your input file has a malformed header: This codec is strictly for VCFv3 and does not support VCFv4.1, for input source: /gss1/home/hjb20181119/panyongpeng/NN1138-2/RIL_genotype/mapping/w-1.raw.g.vcf; ##### ERROR ------------------------------------------------------------------------------------------. I checked my GVCF file and the header is :. ##fileformat=VCFv4.1; ##ALT=<ID=NON_REF,Description=""Represents any possible alternative allele at this location"">; ##FILTER=<ID=LowQual,Description=""Low quality"">; ##FORMAT=<ID=AD,Number=.,Type=Integer,Description=""Allelic depths for the ref and alt alleles in the order listed"">; ##FORMAT=<ID=DP,N",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7315:1449,ERROR,ERROR,1449,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7315,3,['ERROR'],['ERROR']
Availability," line: 102; 22:05:55.964 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] ; 22:05:55.964 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] * What went wrong:; 22:05:55.966 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] A problem occurred evaluating root project 'gatk'.; 22:05:55.966 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] > Execution of ""git lfs pull --include src/main/resources/large"" failed with exit code: 2. git-lfs is required to build GATK but may not be installed. See https://github.com/broadinstitute/gatk#building for information on how to build GATK.; 22:05:55.967 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] ; 22:05:55.968 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] * Exception is:; 22:05:55.969 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] org.gradle.api.GradleScriptException: A problem occurred evaluating root project 'gatk'.; 22:05:55.969 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.groovy.scripts.internal.DefaultScriptRunnerFactory$ScriptRunnerImpl.run(DefaultScriptRunnerFactory.java:92); 22:05:55.969 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.DefaultScriptPluginFactory$ScriptPluginImpl$2.run(DefaultScriptPluginFactory.java:176); 22:05:55.970 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.ProjectScriptTarget.addConfiguration(ProjectScriptTarget.java:77); 22:05:55.970 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.DefaultScriptPluginFactory$ScriptPluginImpl.apply(DefaultScriptPluginFactory.java:181); 22:05:55.970 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.project.BuildScriptProcessor.execute(BuildScriptProcessor.java:38); 22:05:55.970 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter]",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4687:1992,ERROR,ERROR,1992,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4687,1,['ERROR'],['ERROR']
Availability," not strict about the state of the cache.; - Currently in order to lower the mapping quality threshold for HaplotypeCaller two separate arguments must be called. This is because the mapping-quality threshold is checked twice, once for the read filter plugin `getToolDefaultArgumentCollections()` which gets instantiated before the HaplotypeCaller arguments are populated, and again before assembly. While the functionality to be stricter about mapping quality for assembly compared to active region discovery might be important it is unclear if this matters and perhaps the latter check can be done away with? ; - I have added a genotype debugging stream that closely matches the debug output stream from DRAGEN (which itself was a reflection of the GATK3 debug out stream). This involved a lot of threading output writers through the codebase and perhaps this is better handled by the ""--debug"" argument like it used to? Thoughts? . Notes: ; - It should be noted that by design all of the added changes to HaplotypeCaller are opt-in, barring errors in implementation.; - This code is measurably slower than vanilla HaplotypeCaller. In particular FRD is a very expensive step that corresponds to ~5-7% of the runtime. This is in part because it has to duplicate many of the steps in the genotyper based on the number of unique mapping qualities present at a site as well as the fact that it performs an O(n^2) number of operations at sites with many possible alleles. There are options to cut down on the cost of this algorithm that moderately impact the results relative to DRAGEN. . This implementation is intended to produce results close to the results on DRAGEN 3.4.12 without stripping away the major improvements made in GATK4, as a result there are a number of areas in which we know we are producing different results: ; - In GATK4 variants that overlap with an upstream deletion will have added to their alleles list a sybmolic '*' deletion alleles which are genotyped as part of the allele ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6634:3909,error,errors,3909,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6634,1,['error'],['errors']
Availability," o.s.j.s.ServletContextHandler@7cdb05aa{/jobs/json,null,AVAILABLE,@Spark}; 10:33:07.351 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@5cb76070{/jobs/job,null,AVAILABLE,@Spark}; 10:33:07.352 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@443ac5b8{/jobs/job/json,null,AVAILABLE,@Spark}; 10:33:07.354 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@753e4eb5{/stages,null,AVAILABLE,@Spark}; 10:33:07.355 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@63318b56{/stages/json,null,AVAILABLE,@Spark}; 10:33:07.357 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@462f8fe9{/stages/stage,null,AVAILABLE,@Spark}; 10:33:07.358 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@b2e1df3{/stages/stage/json,null,AVAILABLE,@Spark}; 10:33:07.359 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@6cf3b3d7{/stages/pool,null,AVAILABLE,@Spark}; 10:33:07.360 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@55c20a91{/stages/pool/json,null,AVAILABLE,@Spark}; 10:33:07.361 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@3ba96967{/storage,null,AVAILABLE,@Spark}; 10:33:07.362 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@1237cade{/storage/json,null,AVAILABLE,@Spark}; 10:33:07.363 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@4509b7{/storage/rdd,null,AVAILABLE,@Spark}; 10:33:07.364 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@5dbc4598{/storage/rdd/json,null,AVAILABLE,@Spark}; 10:33:07.365 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@38a27ace{/environment,null,AVAILABLE,@Spark}; 10:33:07.366 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@7e8783b0{/environment/json,null,AVAILABLE,@Spark}; 10:33:07.367 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@53d2f0ec{/executors,null,AVAILABLE,@Spark}; 10:33:07.369 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@14d36bb2{/executors/json,null,AVAILABLE,@Spark}; 10:33:07.3",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8949:45960,AVAIL,AVAILABLE,45960,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8949,1,['AVAIL'],['AVAILABLE']
Availability," of genotypes will NOT be added for this location. Chromosome chr2L position 19311 (TileDB column 19310) has too many alleles in the combined VCF record : 16 : current limit : 6. Fields, such as PL, with length equal to the number of genotypes will NOT be added for this location. 19:44:17.535 INFO ProgressMeter - chr2L:19364 2.8 15000 5324.0; Chromosome chr2L position 19835 (TileDB column 19834) has too many alleles in the combined VCF record : 11 : current limit : 6. Fields, such as PL, with length equal to the number of genotypes will NOT be added for this location. 19:44:34.904 INFO ProgressMeter - chr2L:21364 3.1 17000 5471.6; 19:44:47.867 INFO ProgressMeter - chr2L:23364 3.3 19000 5717.8; Chromosome chr2L position 25349 (TileDB column 25348) has too many alleles in the combined VCF record : 7 : current limit : 6. Fields, such as PL, with length equal to the number of genotypes will NOT be added for this location. 19:45:00.952 INFO GenotypeGVCFs - Shutting down engine; GENOMICSDB_TIMER,GenomicsDB iterator next() timer,Wall-clock time(s),57.82864317899994,Cpu time(s),49.25545264700008; [January 13, 2022 7:45:01 PM EST] org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs done. Elapsed time: 4.22 minutes.; Runtime.totalMemory()=2076049408; java.lang.IllegalStateException: Genotype [Ark CTTT/CTTT GQ 24 DP 8 AD 0,8,0,0,0,0,0,0 {SB=0,0,4,4}] does not contain likelihoods necessary to calculate posteriors.; at org.broadinstitute.hellbender.tools.walkers.genotyper.afcalc.AlleleFrequencyCalculator.log10NormalizedGenotypePosteriors(AlleleFrequencyCalculator.java:89); at org.broadinstitute.hellbender.tools.walkers.genotyper.afcalc.AlleleFrequencyCalculator.effectiveAlleleCounts(AlleleFrequencyCalculator.java:258); at org.broadinstitute.hellbender.tools.walkers.genotyper.afcalc.AlleleFrequencyCalculator.calculate(AlleleFrequencyCalculator.java:141); at org.broadinstitute.hellbender.tools.walkers.genotyper.GenotypingEngine.calculateGenotypes(GenotypingEngine.java:147); a",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7639:6593,down,down,6593,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7639,1,['down'],['down']
Availability," of the read before the first unique (and existing) k-mer in each sequence is found. This is partly fixed by the approach taken when we recover dangling heads yet it seems to have other problems downstream when selecting or pruning haplotypes:. ```; https://www.pivotaltracker.com/story/show/67601310; ```. B. Low support chain pruning might not be longer needed. Now we have a newer approach to select best haplotypes that can handle complex graph we might well not need to prune low supported hap early as they seemly they won't be selected if the are not amongst the best haplotypes. . B.1 Now that still would produce a considerable number of unlikely haplotypes that would cause a CPU burden. That can be changed by imposing another kinds of limit, For example we include all haplotypes with scores (likelihoods) that are Q0 - Q40 or we include haplotypes until the sum of their likelihoods is larger than the 99.99% probability mass. . B.2 This could provide a downstream solution to the problem caused by ranging heads recovery (explained above in A.2). B.3 If pruning is to be maintained, it makes more sense to do it at the very end after all dangling ends hav been recovered and the edges supports are finalized. Of course I assuming here that dangling end recovery does the sensible think of updating those supports are the graphs is modified. C. The use of Smith-Waterman in dangling end recovery does not seem totally optimal or even needed. . C.1 Recovering tails quite often this finish with the same sequence as the reference path because in fact they are supposed to end like that by construction (reads are trimmed by AR coordinates). For example, this can be cause because due to the k-mer size there is not enough based after variation for the paths to merge back. In this case you can simply merge the last vertices of the tail and the reference, faster and potentially more accurate. . C.2 Similarly dangling heads, at least part of the sequence of those dangling heads are clear",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/264:1602,down,downstream,1602,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/264,2,"['down', 'recover']","['downstream', 'recovery']"
Availability," on the input files I'm using and its difficult for me to interpret the error message. What I'm seeing is,. 1. ERROR LiveListenerBus: SparkListenerBus has already stopped!; 2. Job aborted due to stage failure: Task 20 in stage 1.0 failed 1 times; 3. WARN ShutdownHookManager: ShutdownHook '$anon$2' timeout; 4. WARN ShutdownHookManager: ShutdownHook 'ClientFinalizer' timeout; 5. ERROR ShutdownHookManager: ShutdownHookManger shutdown forcefully.; 6. /var/spool/slurmd/job1619084/slurm_script: line 126: syntax error: unexpected end of file. In that order. I'm running this script in parallel on a SLURM scheduler (four cpus with 8Gb mem/cpu). Here is a sample of the last few lines of STDERR, but I'm also attaching the full error output.; [pathseq_TCGA.slurm.1619078_1.err.txt](https://github.com/broadinstitute/gatk/files/1965063/pathseq_TCGA.slurm.1619078_1.err.txt). Thanks so much for any help you can provide!. `; 18/05/01 14:20:59 ERROR LiveListenerBus: SparkListenerBus has already stopped! Dropping event SparkListenerBlockUpdated(BlockUpdatedInfo(BlockManagerId(driver, 10.12.137.46, 39719, None),broadcast_1_piece0,StorageLevel(memory, 1 replicas),127561,0)); 18/05/01 14:21:18 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 18/05/01 14:23:29 INFO MemoryStore: MemoryStore cleared; 18/05/01 14:23:29 INFO BlockManager: BlockManager stopped; 18/05/01 14:23:29 INFO BlockManagerMaster: BlockManagerMaster stopped; 18/05/01 14:24:38 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 18/05/01 14:25:36 INFO SparkContext: Successfully stopped SparkContext; 14:25:37.027 INFO PathSeqPipelineSpark - Shutting down engine; [May 1, 2018 2:25:37 PM EDT] org.broadinstitute.hellbender.tools.spark.pathseq.PathSeqPipelineSpark done. Elapsed time: 37.98 minutes.; Runtime.totalMemory()=23999283200; org.apache.spark.SparkException: Job aborted due to stage failure: Task 20 in stage 1.0 failed 1 times, most recent failure: L",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4725:957,ERROR,ERROR,957,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4725,1,['ERROR'],['ERROR']
Availability," opened a bugreport to add a feature to ValidateVariants: https://github.com/broadinstitute/gatk/issues/6553. However, it would be nice if you could actually investigate the formatting error. Unfortunately my formatting error isn't the same as reported in the other post. I have 105 error in which the 1st alternative allele is a spanning deletion and the 2nd (and 3rd) is either an indel or snp. It's true that the 2nd and 3rd allele is actually not found in my samples. I even have 7 occurances in which the 1st allele (spanning deletion) has allele frequency 1.00. my code is the following for GenotypeGVCFs:. java -Xms32G -Xmx32G -jar ${gatk4} GenotypeGVCFs -R ${ref} -V ${pipeline}/${name}\_v4.1.6.0.g.vcf.gz -O ${vcf}/${name}\_v4.1.6.0.vcf.gz -L ${pipeline}/${name}\_intervals.list 2> ${log}/${name}\_v4.1.6.0\_genotype.log. for ValidateVariants:. java -Xms10G -Xmx10G -jar ${gatk4} ValidateVariants -R ${ref} -V ${name}\_v4.1.6.0.vcf.gz -L ${pipeline}/${name}\_intervals.list --warn-on-errors 2> ${log}/${name}\_v4.1.6.0\_genotype\_valivar.log. the warning in ValidateVariants and the site look like this:. 14:12:15.126 WARN ValidateVariants - \*\*\*\*\* Input 1st\_v4.1.6.0.vcf.gz fails strict validation of type ALL: one or more of the ALT allele(s) for the record at position chr\_1:1088200 are not observed at all in the sample genotypes \*\*\*\*\* ; ; chr\_1 1088200 . T \*,TAAAAAAAAAAAA 64.39 . AC=8,0;AF=0.667,0.00;AN=12;DP=118;ExcessHet=3.0103;FS=0.000;InbreedingCoeff=0.4286;MLEAC=7,7;MLEAF=0.583,0.583;MQ=58.73;QD=32.19;SOR=2.303 GT:AD:DP:GQ:PL ./.:9,0,0:9:.:0,0,0,0,0,0 0/0:9,0,0:9:0:0,0,113,0,113,113 ./.:10,0,0:10:.:0,0,0,0,0,0 ./.:5,0,0:5:.:0,0,0,0,0,0 1/1:0,0,1:1:0:225,15,0,15,0,0 ./.:0,0,0:0:.:0,0,0,0,0,0 ./.:12,0,0:12:.:0,0,0,0,0,0 ./.:8,0,0:8:.:0,0,0,0,0,0 0/0:3,0,0:3:0:0,0,43,0,43,43 ./.:7,0,0:7:.:0,0,0,0,0,0 ./.:1,0,0:1:.:0,0,0,0,0,0 ./.:0,0,0:0:.:0,0,0,0,0,0 ./.:3,0,0:3:.:0,0,0,0,0,0 ./.:7,0,0:7:.:0,0,0,0,0,0 1/1:0,0,0:0:0:45,3,0,3,0,0 ./.:0,0,0 1/1:0,0,1:1:0:45,3,0",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6630:1766,error,errors,1766,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6630,1,['error'],['errors']
Availability," org.apache.logging.log4j.core.LoggerContext.start(LoggerContext.java:270); at org.apache.logging.log4j.core.impl.Log4jContextFactory.getContext(Log4jContextFactory.java:155); at org.apache.logging.log4j.core.impl.Log4jContextFactory.getContext(Log4jContextFactory.java:47); at org.apache.logging.log4j.LogManager.getContext(LogManager.java:196); at org.apache.logging.log4j.LogManager.getLogger(LogManager.java:599); at org.broadinstitute.hellbender.utils.Utils.<clinit>(Utils.java:72); at org.broadinstitute.hellbender.Main.<clinit>(Main.java:45); Caused by: java.net.UnknownHostException: de2c81c88ddc: Temporary failure in name resolution; at java.net.Inet4AddressImpl.lookupAllHostAddr(Native Method); at java.net.InetAddress$2.lookupAllHostAddr(InetAddress.java:929); at java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1324); at java.net.InetAddress.getLocalHost(InetAddress.java:1501); ...13 more. The Genome Analysis Toolkit (GATK) v4.2.6.1; HTSJDK Version: 2.24.1; Picard Version: 2.27.1; Using GATK jar /gatk/gatk-package-4.2.6.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /gatk/gatk-package-4.2.6.1-local.jar -version; ```. This request was created from a contribution made by Pryce Turner on July 29, 2022 03:44 UTC. Link: [https://gatk.broadinstitute.org/hc/en-us/community/posts/360078378372--Could-not-determine-local-host-name-#community\_comment\_7692552841755](https://gatk.broadinstitute.org/hc/en-us/community/posts/360078378372--Could-not-determine-local-host-name-#community_comment_7692552841755). \--. Hey 417227834892,. Were you ever able to solve this? I'm running into the same issue with HaplotypeCaller. It still runs, but the error output is potentially disruptive. Thanks!<br><br><i>(created from <a href='https://broadinstitute.zendesk.com/agent/tickets/292152'>Zendesk ticket #292152</a>)<br> gz#292152</i>",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7983:2816,error,error,2816,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7983,1,['error'],['error']
Availability," org.broadinstitute.hellbender.Main.mainEntry(Main.java:209); at org.broadinstitute.hellbender.Main.main(Main.java:306). real 481m24.418s; user 581m54.752s; sys 2m49.965s. ```. This run did not complete successfully - the Exception caused it to fail prematurely. . Previously I had seen HaplotypeCaller run out of memory and fail in almost as much time, so I think this and the OOM error are related. The only difference in invocation was that with the OOM failure, I was running with the default for `--max-reads-per-alignment-start` (`50`). This also works just fine with that setting at 15. The failure seems to occur around the same place in the data each time (the end of `chr13`). At that point in the data, there is a very large pileup which is probably instigating this. Additionally, if I remove the `--linked-de-bruijn-graph` argument, this runs just fine with the default setting of `--max-reads-per-alignment-start`. I have a minimally reproductive dataset that I can share which reproduces the OOM error for sure (I'm 99% sure it reproduces this one as well). For the OOM failures, the final logs from HaplotypeCaller look like this:. ```; ./gatk HaplotypeCaller ...; ...; 15:56:23.205 INFO ProgressMeter - Pf3D7_13_v3:2603234 100.5 114070 1134.5; 15:56:33.443 INFO ProgressMeter - Pf3D7_13_v3:2661462 100.7 114420 1136.1; Dangling End recovery killed because of a loop (getReferencePathForwardFromKmer); 15:56:43.998 INFO ProgressMeter - Pf3D7_13_v3:2730055 100.9 114840 1138.3; 15:56:59.911 INFO ProgressMeter - Pf3D7_13_v3:2798281 101.2 115210 1139.0; 15:59:27.062 INFO ProgressMeter - Pf3D7_13_v3:2861780 103.6 115460 1114.4; Dangling End recovery killed because of a loop (getReferencePathForwardFromKmer); Dangling End recovery killed because of a loop (getReferencePathForwardFromKmer); 15:59:37.457 INFO ProgressMeter - Pf3D7_13_v3:2869697 103.8 115500 1112.9. real 671m24.770s; user 777m30.923s; sys 6m13.682s. $ echo $?; 247; ```. Here is my command-line invocation:; ```; ./ga",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8440:4956,error,error,4956,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8440,1,['error'],['error']
Availability, org.gradle.configuration.project.BuildScriptProcessor.execute(BuildScriptProcessor.java:38); 22:05:55.970 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.project.BuildScriptProcessor.execute(BuildScriptProcessor.java:25); 22:05:55.970 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.project.ConfigureActionsProjectEvaluator.evaluate(ConfigureActionsProjectEvaluator.java:34); 22:05:55.970 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.project.LifecycleProjectEvaluator.evaluate(LifecycleProjectEvaluator.java:55); 22:05:55.970 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.project.DefaultProject.evaluate(DefaultProject.java:573); 22:05:55.971 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.project.DefaultProject.evaluate(DefaultProject.java:125); 22:05:55.971 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.TaskPathProjectEvaluator.configureHierarchy(TaskPathProjectEvaluator.java:42); 22:05:55.971 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.DefaultBuildConfigurer.configure(DefaultBuildConfigurer.java:38); 22:05:55.971 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.initialization.DefaultGradleLauncher$2.run(DefaultGradleLauncher.java:151); 22:05:55.971 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.Factories$1.create(Factories.java:22); 22:05:55.971 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:91); 22:05:55.971 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationEx,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4687:3822,ERROR,ERROR,3822,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4687,1,['ERROR'],['ERROR']
Availability, org.gradle.initialization.DefaultGradleLauncher.doBuildStages(DefaultGradleLauncher.java:148); 22:05:55.972 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.initialization.DefaultGradleLauncher.access$200(DefaultGradleLauncher.java:33); 22:05:55.973 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.initialization.DefaultGradleLauncher$1.create(DefaultGradleLauncher.java:112); 22:05:55.973 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.initialization.DefaultGradleLauncher$1.create(DefaultGradleLauncher.java:106); 22:05:55.973 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:91); 22:05:55.976 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:63); 22:05:55.976 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.initialization.DefaultGradleLauncher.doBuild(DefaultGradleLauncher.java:106); 22:05:55.976 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.initialization.DefaultGradleLauncher.run(DefaultGradleLauncher.java:92); 22:05:55.976 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.exec.GradleBuildController.run(GradleBuildController.java:66); 22:05:55.977 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.tooling.internal.provider.ExecuteBuildActionRunner.run(ExecuteBuildActionRunner.java:28); 22:05:55.978 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.exec.ChainingBuildActionRunner.run(ChainingBuildActionRunner.java:35); 22:05:55.978 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.exec.InProcessBuildActionExecuter.execute(InProcessBuildAc,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4687:5921,ERROR,ERROR,5921,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4687,1,['ERROR'],['ERROR']
Availability, org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:53); 22:05:55.972 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.initialization.DefaultGradleLauncher.doBuildStages(DefaultGradleLauncher.java:148); 22:05:55.972 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.initialization.DefaultGradleLauncher.access$200(DefaultGradleLauncher.java:33); 22:05:55.973 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.initialization.DefaultGradleLauncher$1.create(DefaultGradleLauncher.java:112); 22:05:55.973 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.initialization.DefaultGradleLauncher$1.create(DefaultGradleLauncher.java:106); 22:05:55.973 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:91); 22:05:55.976 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:63); 22:05:55.976 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.initialization.DefaultGradleLauncher.doBuild(DefaultGradleLauncher.java:106); 22:05:55.976 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.initialization.DefaultGradleLauncher.run(DefaultGradleLauncher.java:92); 22:05:55.976 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.exec.GradleBuildController.run(GradleBuildController.java:66); 22:05:55.977 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.tooling.internal.provider.ExecuteBuildActionRunner.run(ExecuteBuildActionRunner.java:28); 22:05:55.978 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.exec.ChainingBuildActionRunner.run(ChainingBui,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4687:5736,ERROR,ERROR,5736,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4687,1,['ERROR'],['ERROR']
Availability, org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:91); 22:05:55.971 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:53); 22:05:55.972 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.initialization.DefaultGradleLauncher.doBuildStages(DefaultGradleLauncher.java:148); 22:05:55.972 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.initialization.DefaultGradleLauncher.access$200(DefaultGradleLauncher.java:33); 22:05:55.973 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.initialization.DefaultGradleLauncher$1.create(DefaultGradleLauncher.java:112); 22:05:55.973 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.initialization.DefaultGradleLauncher$1.create(DefaultGradleLauncher.java:106); 22:05:55.973 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:91); 22:05:55.976 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:63); 22:05:55.976 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.initialization.DefaultGradleLauncher.doBuild(DefaultGradleLauncher.java:106); 22:05:55.976 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.initialization.DefaultGradleLauncher.run(DefaultGradleLauncher.java:92); 22:05:55.976 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.exec.GradleBuildController.run(GradleBuildController.java:66); 22:05:55.977 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.tooling.internal.provider.ExecuteBuildActionRunner.ru,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4687:5551,ERROR,ERROR,5551,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4687,1,['ERROR'],['ERROR']
Availability," program; 3) read in the alignments in a GATK tool and filter accordingly. The ambitious version is to write our own simple aligner, eg a kmer-based method like BLAT or BBMap but with all the messy parts for handling big indels, RNA, and proteins removed. Writing our own BWA aligner would be wildly impractical. @takutosato @LeeTL1220 keeping you in the loop. ---. @davidbenjamin commented on [Thu Jan 26 2017](https://github.com/broadinstitute/gatk-protected/issues/844#issuecomment-275483449). *Even better*: rely on someone else in the group, such as Ted, to write a Java binding for BWA in memory. See broadinstitute/gatk#2367. ---. @davidbenjamin commented on [Sun Apr 23 2017](https://github.com/broadinstitute/gatk-protected/issues/844#issuecomment-296515266). So. . . given that our pipeline aligns with BWA, it might seem like this is just a redundant and laborious rehashing of the mapping quality score. *However*, the mapping quality only considers multi-mapping within the reference, and therefore doesn't account for mapping errors due to incompleteness of the reference. That is, reads from genomic regions that are not part of the reference (because they're hard to assemble, like centromeres etc) might map well to a unique regions within the reference, and therefore will have fine mapping quality even though they are artifacts. There are published ""decoy genomes"" -- essentially pseudo-contigs of regions missing from the reference, and mapping with BWA in memory to *those* might be very helpful. So, we need to: 1) get our hands on a decoy genome that will play nicely with BWA, and 2) talk to the SV team. ---. @ldgauthier commented on [Mon Apr 24 2017](https://github.com/broadinstitute/gatk-protected/issues/844#issuecomment-296675311). To be pedantic, the mapping quality also considers how well the read aligns; to its best mapping. In places where a sample has a lot of nearby SNPs; compared to the reference the mapping qualities of the reads are low; compared to reads t",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2930:1578,error,errors,1578,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2930,1,['error'],['errors']
Availability," pseudochromosome_1:1 21.4 3 0.1; 08:17:48.471 INFO GenomicsDBImport - Done importing batch 3/6; 08:17:48.510 INFO GenomicsDBImport - Importing batch 4 with 6 samples; 08:23:17.675 INFO ProgressMeter - pseudochromosome_1:1 26.9 4 0.1; 08:23:17.675 INFO GenomicsDBImport - Done importing batch 4/6; 08:23:17.709 INFO GenomicsDBImport - Importing batch 5 with 6 samples; 08:31:44.254 INFO ProgressMeter - pseudochromosome_1:1 35.3 5 0.1; 08:31:44.255 INFO GenomicsDBImport - Done importing batch 5/6; 08:31:44.286 INFO GenomicsDBImport - Importing batch 6 with 6 samples; 08:38:39.554 INFO ProgressMeter - pseudochromosome_1:1 42.2 6 0.1; 08:38:39.554 INFO GenomicsDBImport - Done importing batch 6/6; 08:38:39.556 INFO ProgressMeter - pseudochromosome_1:1 42.2 6 0.1; 08:38:39.556 INFO ProgressMeter - Traversal complete. Processed 6 total batches in 42.2 minutes.; 08:38:39.556 INFO GenomicsDBImport - Import of all batches to GenomicsDB completed!; 08:38:39.556 INFO GenomicsDBImport - Shutting down engine; [27 May 2020 08:38:39 CEST] oAB.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImport done. Elapsed time: 42.25 minutes.; Runtime.totalMemory()=2545942528; Tool returned:; true. (base) xxxxxx@galaxy:~$ gatk --java-options ""-Xmx30g -DGATK_STACKTRACE_ON_USER_EXCEPTION=true"" GenotypeGVCFs -R Reference/File_S16_uT_3_Pseudochromosomes.fasta -V gendb://ABchroneALL -O ABchroneALL.vcf.gz; Using GATK jar /data/xxxxxx/miniconda3/share/gatk4-4.1.6.0-0/gatk-package-4.1.6.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx30g -DGATK_STACKTRACE_ON_USER_EXCEPTION=true -jar /data/xxxxxx/miniconda3/share/gatk4-4.1.6.0-0/gatk-package-4.1.6.0-local.jar GenotypeGVCFs -R Reference/File_S16_uT_3_Pseudochromosomes.fasta -V gendb://ABchroneALL -O ABchroneALL.vcf.gz; 09:48:14.426 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/data/xxxxxx",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6616:7380,down,down,7380,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6616,1,['down'],['down']
Availability," request was created from a contribution made by ABours on May 29, 2020 18:23 UTC. Link: https://gatk.broadinstitute.org/hc/en-us/community/posts/360067695771-GenotypeGvcfs-has-formatting-issues-in-both-v4-1-6-0-as-v4-1-7-0. --. Hi,. I'm using v4.1.6.0 of GenotypeGvcfs to make a vcf, out of whole genome data from 19 samples (following your recommendations). When I run ValidateVariants to check the output of GenotypeGvcfs I get a error message, which states that one or more of the ALT allele are actually not in the samples provided. A previous user already found a similar error in ValidateVariants (https://gatk.broadinstitute.org/hc/en-us/community/posts/360061452132-GATK4-RNAseq-short-variant-discovery-SNPs-Indels-), but then for Haplotypecaller, and you have opened a bugreport to add a feature to ValidateVariants: https://github.com/broadinstitute/gatk/issues/6553. However, it would be nice if you could actually investigate the formatting error. Unfortunately my formatting error isn't the same as reported in the other post. I have 105 error in which the 1st alternative allele is a spanning deletion and the 2nd (and 3rd) is either an indel or snp. It's true that the 2nd and 3rd allele is actually not found in my samples. I even have 7 occurances in which the 1st allele (spanning deletion) has allele frequency 1.00. my code is the following for GenotypeGVCFs:. java -Xms32G -Xmx32G -jar ${gatk4} GenotypeGVCFs -R ${ref} -V ${pipeline}/${name}\_v4.1.6.0.g.vcf.gz -O ${vcf}/${name}\_v4.1.6.0.vcf.gz -L ${pipeline}/${name}\_intervals.list 2> ${log}/${name}\_v4.1.6.0\_genotype.log. for ValidateVariants:. java -Xms10G -Xmx10G -jar ${gatk4} ValidateVariants -R ${ref} -V ${name}\_v4.1.6.0.vcf.gz -L ${pipeline}/${name}\_intervals.list --warn-on-errors 2> ${log}/${name}\_v4.1.6.0\_genotype\_valivar.log. the warning in ValidateVariants and the site look like this:. 14:12:15.126 WARN ValidateVariants - \*\*\*\*\* Input 1st\_v4.1.6.0.vcf.gz fails strict validation of type ALL: one o",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6630:993,error,error,993,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6630,1,['error'],['error']
Availability, runs of these tools) when using NIO:. > java.lang.RuntimeException: java.util.concurrent.ExecutionException: com.google.cloud.storage.StorageException: All 20 reopens failed. Waited a total of 1918000 ms between attempts; at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher.read(SeekableByteChannelPrefetcher.java:318); at htsjdk.samtools.seekablestream.SeekablePathStream.read(SeekablePathStream.java:86); at htsjdk.samtools.util.BlockCompressedInputStream.readBytes(BlockCompressedInputStream.java:571); at htsjdk.samtools.util.BlockCompressedInputStream.readBytes(BlockCompressedInputStream.java:560); at htsjdk.samtools.util.BlockCompressedInputStream.processNextBlock(BlockCompressedInputStream.java:525); at htsjdk.samtools.util.BlockCompressedInputStream.nextBlock(BlockCompressedInputStream.java:468); at htsjdk.samtools.util.BlockCompressedInputStream.readBlock(BlockCompressedInputStream.java:458); at htsjdk.samtools.util.BlockCompressedInputStream.available(BlockCompressedInputStream.java:196); at htsjdk.samtools.util.BlockCompressedInputStream.read(BlockCompressedInputStream.java:331); at java.io.DataInputStream.read(DataInputStream.java:149); at htsjdk.samtools.util.BinaryCodec.readBytesOrFewer(BinaryCodec.java:421); at htsjdk.samtools.util.BinaryCodec.readBytes(BinaryCodec.java:394); at htsjdk.samtools.util.BinaryCodec.readBytes(BinaryCodec.java:380); at htsjdk.samtools.BAMRecordCodec.decode(BAMRecordCodec.java:268); at htsjdk.samtools.BAMFileReader$BAMFileIterator.getNextRecord(BAMFileReader.java:829); at htsjdk.samtools.BAMFileReader$BAMFileIndexIterator.getNextRecord(BAMFileReader.java:981); at htsjdk.samtools.BAMFileReader$BAMFileIterator.advance(BAMFileReader.java:803); at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:797); at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:765); at htsjdk.samtools.BAMFileReader$BAMQueryFilteringIterator.advance(BAMFileReader.java:1034); at htsjdk.samtools.BAMF,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5631:1254,avail,available,1254,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5631,1,['avail'],['available']
Availability," same result. Java version is ``` OpenJDK Runtime Environment (build 1.8.0_252-b09) ```; ```; /gatk-4.0.11.0/gatk --java-options ""-Xmx4G"" HaplotypeCaller \; -R GRCh38.p2.fa \; -I RT4_STD.bam \; -ERC GVCF \; -L chr16 \; -O RT4_STD.g.vcf \; -new-qual; ```; - Error message is also different; - First one is :; ```; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x00002aaad9f1e54a, pid=7818, tid=0x00002aaaabdce700; #; # JRE version: Java(TM) SE Runtime Environment (8.0_111-b14) (build 1.8.0_111-b14); # Java VM: Java HotSpot(TM) 64-Bit Server VM (25.111-b14 mixed mode linux-amd64 compressed oops); # Problematic frame:; # C [libgkl_pairhmm_omp1890484777463615571.so+0x6954a] double compute_full_prob_avxd<double>(testcase*)+0x34a; #; # Core dump written. Default location: core or core.7818; #; # An error report file with more information is saved as:; # hs_err_pid7818.log; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; # The crash happened outside the Java Virtual Machine in native code.; # See problematic frame for where to report the bug.; ```. -Second one is ; ```; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x00000035dfe84364, pid=160107, tid=0x00002aaaabdce700; #; # JRE version: Java(TM) SE Runtime Environment (8.0_111-b14) (build 1.8.0_111-b14); # Java VM: Java HotSpot(TM) 64-Bit Server VM (25.111-b14 mixed mode linux-amd64 ); # Problematic frame:; # C [libc.so.6+0x84364]; #; # Core dump written. Default location: core or core.160107; #; # An error report file with more information is saved as:; # hs_err_pid160107.log; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; # The crash happened outside the Java Virtual Machine in native code.; # See problematic frame for where to report the bug. ```. Could this be a bug of problem with my data?. Thanks, ; Wen",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7515:1437,error,error,1437,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7515,2,['error'],['error']
Availability, scala.collection.Iterator$class.foreach(Iterator.scala:893); at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59); at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104); at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48); at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310); at scala.collection.AbstractIterator.to(Iterator.scala:1336); at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302); at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1336); at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289); at scala.collection.AbstractIterator.toArray(Iterator.scala:1336); at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:936); at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:936); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2062); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2062); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:108); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); 18/08/29 10:20:49 ERROR Executor: Exception in task 12.0 in stage 12.0 (TID 3228); ```. I am running version 4.0.8.1 of GATK using openjdk version 1.8.0_212.; The command I am using is:. ```; gatk StructuralVariationDiscoveryPipelineSpark \; --aligner-index-image refrance.fasta.img \; --contig-sam-file contigs-aligned.sam \; --spark-master local[30] \; --kmers-to-ignore kmers_to_ignore.txt \; -R $fasta \; -I $sample.bam \; -O $sample.vcf; ```. Thanks for taking a look!,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5145:2742,ERROR,ERROR,2742,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5145,1,['ERROR'],['ERROR']
Availability," screenshot of the bamout file from 3.1. <img width=""1440"" alt=""screen shot 2016-05-31 at 4 56 20 pm"" src=""https://cloud.githubusercontent.com/assets/6998669/15690232/9dfc6992-2750-11e6-94c4-0c055b3ad1bc.png"">; The first green SNP on the left is the one in question. ---. @chandrans commented on [Tue Jun 14 2016](https://github.com/broadinstitute/gsa-unstable/issues/1360#issuecomment-225999879). Figured out at Support meeting that the variant SNP is called when you include -allowNonUniqueKmersInRef in the command. . It seems the kmer including the SNP is quite common the region. I am going to tell the user about using the flag. However, I think David will take a look into the code to see what exactly is going on and whether it is a good idea to recommend using the flag in repeat regions. ---. @ldgauthier commented on [Wed Jun 15 2016](https://github.com/broadinstitute/gsa-unstable/issues/1360#issuecomment-226191676). Valentin has found that that arg is able to recover a lot of our missed; indels in the pseudo-diploid truth data, so it's worth investigating.; However, I believe when I tried it for MuTect2 against the LUAD data I; introduced a not insignificant number of additional variants, likely false; positives. On Tue, Jun 14, 2016 at 4:06 PM, chandrans <notifications@github.com> wrote:. > Figured out at Support meeting that the variant SNP is called when you; > include -allowNonUniqueKmersInRef in the command.; >; > It seems the kmer including the SNP is quite common the region.; >; > I am going to tell the user about using the flag. However, I think David; > will take a look into the code to see what exactly is going on and whether; > it is a good idea to recommend using the flag in repeat regions.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gsa-unstable/issues/1360#issuecomment-225999879>,; > or mute the thread; > <https://github.com/notifications/unsubscri",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2916:11712,recover,recover,11712,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2916,1,['recover'],['recover']
Availability," shard 4 / 8...; 14:27:24.879 INFO PostprocessGermlineCNVCalls - Analyzing shard 5 / 8...; 14:27:26.062 INFO PostprocessGermlineCNVCalls - Analyzing shard 6 / 8...; 14:27:26.849 INFO PostprocessGermlineCNVCalls - Analyzing shard 7 / 8...; 14:27:27.893 INFO PostprocessGermlineCNVCalls - Analyzing shard 8 / 8...; 14:27:28.412 INFO PostprocessGermlineCNVCalls - Generating segments...; 14:29:52.532 INFO PostprocessGermlineCNVCalls - Parsing Python output...; 14:29:52.537 INFO PostprocessGermlineCNVCalls - Writing segments VCF file to /bettik/tintest/CNV_Hyperexome/segments/genotyped-segments-SAMPLE_6.vcf.gz...; 14:29:52.703 INFO PostprocessGermlineCNVCalls - Generating denoised copy ratios...; 14:29:53.592 INFO PostprocessGermlineCNVCalls - Writing denoised copy ratios to /bettik/tintest/CNV_Hyperexome/ratios/denoised-copy-ratios-SAMPLE_6.tsv...; 14:29:55.274 INFO PostprocessGermlineCNVCalls - PostprocessGermlineCNVCalls complete.; 14:29:55.275 INFO PostprocessGermlineCNVCalls - Shutting down engine; [December 2, 2022 2:29:55 PM GMT] org.broadinstitute.hellbender.tools.copynumber.PostprocessGermlineCNVCalls done. Elapsed time: 6.03 minutes.; Runtime.totalMemory()=2820145152; Using GATK jar /gatk/gatk-package-4.3.0.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /gatk/gatk-package-4.3.0.0-local.jar PostprocessGermlineCNVCalls --model-shard-path GermlineCNVCaller/GermlineCNVCaller_1_of_8-model/ --model-shard-path GermlineCNVCaller/GermlineCNVCaller_2_of_8-model/ --model-shard-path GermlineCNVCaller/GermlineCNVCaller_3_of_8-model/ --model-shard-path GermlineCNVCaller/GermlineCNVCaller_4_of_8-model/ --model-shard-path GermlineCNVCaller/GermlineCNVCaller_5_of_8-model/ --model-shard-path GermlineCNVCaller/GermlineCNVCaller_6_of_8-model/ --model-shard-path GermlineCNVCaller/GermlineCNVCaller_7_of_8-model/ --model-shard-path GermlineCNVCalle",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8183:5061,down,down,5061,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8183,1,['down'],['down']
Availability," size (119 KB). The maximum recommended task size is 100 KB.; > Test: Test method testAllTargetsHDF5PoNCreationSpark[0](null, src/test/resources/org/broadinstitute/hellbender/tools/exome/create-pon-control-full.pcov)(org.broadinstitute.hellbender.tools.exome.CreatePanelOfNormalsIntegrationTest) produced standard out/err: 18:03:07.612 WARN TaskSetManager:70 - Stage 182 contains a task of very large size (119 KB). The maximum recommended task size is 100 KB.; > ; > ```; > 18:03:07.612 WARN TaskSetManager:70 - Stage 182 contains a task of very large size (119 KB). The maximum recommended task size is 100 KB.; > ```; > ; > #; > ; > # A fatal error has been detected by the Java Runtime Environment:; > ; > #; > ; > # SIGSEGV (0xb) at pc=0x000000010a5a9401, pid=2425, tid=8963; > ; > #; > ; > # JRE version: Java(TM) SE Runtime Environment (8.0_91-b14) (build 1.8.0_91-b14); > ; > # Java VM: Java HotSpot(TM) 64-Bit Server VM (25.91-b14 mixed mode bsd-amd64 compressed oops); > ; > # Problematic frame:; > ; > # V [libjvm.dylib+0x1a9401]; > ; > #; > ; > # Failed to write core dump. Core dumps have been disabled. To enable core dumping, try ""ulimit -c unlimited"" before starting Java again; > ; > #; > ; > # An error report file with more information is saved as:; > ; > # /Users/louisb/Workspace/gatk-protected/hs_err_pid2425.log; > ; > #; > ; > # If you would like to submit a bug report, please visit:; > ; > # http://bugreport.java.com/bugreport/crash.jsp; > ; > #; > ; > hs_err_pid2425.log.txt; > https://github.com/broadinstitute/gatk-protected/files/448383/hs_err_pid2425.log.txt; > ; > @yfarjoun https://github.com/yfarjoun Is this similar to the crash you; > saw a while back?; > ; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > https://github.com/broadinstitute/gatk-protected/issues/659, or mute; > the thread; > https://github.com/notifications/unsubscribe-auth/ACnk0h0xGA8ntZ_9wd53IUeIqTIfWye0ks5qlf_YgaJpZM4JyIZS; > .",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2883:3476,error,error,3476,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2883,1,['error'],['error']
Availability," started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43279.; 10:33:07.208 INFO NettyBlockTransferService - Server created on 172.20.19.130:43279; 10:33:07.210 INFO BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy; 10:33:07.214 INFO BlockManagerMaster - Registering BlockManager BlockManagerId(driver, 172.20.19.130, 43279, None); 10:33:07.221 INFO BlockManagerMasterEndpoint - Registering block manager 172.20.19.130:43279 with 1076.2 GiB RAM, BlockManagerId(driver, 172.20.19.130, 43279, None); 10:33:07.225 INFO BlockManagerMaster - Registered BlockManager BlockManagerId(driver, 172.20.19.130, 43279, None); 10:33:07.226 INFO BlockManager - Initialized BlockManager: BlockManagerId(driver, 172.20.19.130, 43279, None); 10:33:07.345 INFO ContextHandler - Stopped o.s.j.s.ServletContextHandler@7074da1d{/,null,STOPPED,@Spark}; 10:33:07.347 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@6556471b{/jobs,null,AVAILABLE,@Spark}; 10:33:07.349 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@7cdb05aa{/jobs/json,null,AVAILABLE,@Spark}; 10:33:07.351 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@5cb76070{/jobs/job,null,AVAILABLE,@Spark}; 10:33:07.352 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@443ac5b8{/jobs/job/json,null,AVAILABLE,@Spark}; 10:33:07.354 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@753e4eb5{/stages,null,AVAILABLE,@Spark}; 10:33:07.355 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@63318b56{/stages/json,null,AVAILABLE,@Spark}; 10:33:07.357 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@462f8fe9{/stages/stage,null,AVAILABLE,@Spark}; 10:33:07.358 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@b2e1df3{/stages/stage/json,null,AVAILABLE,@Spark}; 10:33:07.359 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@6cf3b3d7{/stages/pool,null,AVAILABLE,@Spark}; 10:33:07.360 INFO Contex",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8949:44886,AVAIL,AVAILABLE,44886,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8949,1,['AVAIL'],['AVAILABLE']
Availability," subsp. enterica serovar Typhimurium str. SL1344, Salmonella eneterica subsp. enterica serovar Typhimurium str. LT2, Fusobacterium nucleatum subsp. nucleatum ATCC 25586). I generate six datasets with 100,000 unpaired reads of length 75 bp (2 datasets from each genome) using Rsubread with simulate.sequencing.error=TRUE and ran them through PathSeq. I generated an identical six datasets using Rsubread with simulate.sequencing.error=FALSE. . #### Expected behavior; For the six datasets with simulate.sequencing.error=TRUE, I would expect a small number of reads to be filtered for each step. For the six datasets with simulate.sequencing.error=FALSE, I would expect similar results but with even fewer reads to be filtered for the low-quality or low complexity read filter. #### Actual behavior; For the six datasets with simulate.sequencing.error=TRUE, 8,496 - 18,103 reads were filtered by the low complexity or low quality filter (the Salmonella datasets were on the lower end and the Fusobacterium datasets were on the higher end), 115 - 311 reads were filtered by the host k-mer filter and 886 - 1822 reads were filtered by the duplicate read filter. . The number of reads filtered by the low complexity or low quality filter seemed high to me so I repeated the analysis with simulate.sequencing.error=FALSE. For these six datasets, all 100,000 reads are filtered by the low-quality or low complexity read filter. . #### Steps to reproduce; I wrote the workflow using snakemake and conda. In theory, you should be able to reproduce the error using `snakemake --use-conda`; Snakefile; ```; from os.path import join; import pandas as pd. ATCC25586_CDS_URL = ""ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/000/007/325/GCF_000007325.1_ASM732v1/GCF_000007325.1_ASM732v1_cds_from_genomic.fna.gz""; SL1344_CDS_URL = ""ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/000/210/855/GCF_000210855.2_ASM21085v2/GCF_000210855.2_ASM21085v2_cds_from_genomic.fna.gz""; LT2_CDS_URL = ""ftp://ftp.ncbi.nlm.nih.gov/genomes/all",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6705:1141,error,error,1141,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6705,1,['error'],['error']
Availability," table creation and data loading in LoadData (#7056); - WIP; - tieout scripts; - notes files; - updated diff scripts; - fixed bug...; - add wdl and inputs file for warp pipeline; - reverting logging; - included top level WDL; - use gnarly with BQ extract cohort; - remove unused file; - cleaning up; - tidy; - tidy up before PR; - tidy up before PR; - PR comments; - merge conflict misfires; - added example SQL to create alt allele table from VET; - option to remove PLs; - fixed and enhanced unit test; - removing unused config, causing travis to fail; - add CreateVariantIngestFiles integration test (#7071); - add sampleName (instead of NULL) to error message (#7074); - Update To handle if no data error (#7084); - Memory improvement when writing missing positions to pet (#7098); - added support for loading QUALapprox into VET (#7101); - Add -m flag to gsutil step; add dockstore branch filters to facilitate development (#7104); - updates to ImportGenomes and LoadBigQueryData (#7112); - Add ngs to cohort extract Dockerfile; remove exception catching in extract python script (#7113); - remove problematic storage_location imports (#7119); - Reduce memory and CPU for CreateImportTsvs task, check for files before attempting load (#7121); - add -m flag to gsutil mv step (#7129); - ah_var_store : Add sample file argument to cohort extract (#7117); - Perform full WGS cohort extract scientific tieout for 35 ACMG59 samples (#7106); - Enable Read/Execution Project for BQ Queries (#7136); - ah - optional service account (#7140); - Add load lock file to prevent accidental re-loading of data to BQ (#7138); - #251 Address gvcf no-calls missing QUALapprox and other features (#7146); - Job Add labels to BQ operations from GATK (Issues-199) (#7115); - parse map to list to avoid brackets and spaces in vcf output (#7168); - #259 Inline schema for importgenomes.wdl (#7171); - Created AvroFileReader and unittest, Update ExtractCohort and ExtractCohortEngine (#7174); - #224 Import WDL: handle ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8248:11236,error,error,11236,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8248,4,['error'],['error']
Availability," task 35.0 in stage 0.0 (TID 35), reason: Stage cancelled** ; **20/03/05 09:28:58 INFO Executor: Executor is trying to kill task 6.0 in stage 0.0 (TID 6), reason: Stage cancelled** ; **20/03/05 09:28:58 INFO Executor: Executor is trying to kill task 36.0 in stage 0.0 (TID 36), reason: Stage cancelled** ; **20/03/05 09:28:58 INFO Executor: Executor is trying to kill task 28.0 in stage 0.0 (TID 28), reason: Stage cancelled** ; **20/03/05 09:28:58 INFO Executor: Executor is trying to kill task 7.0 in stage 0.0 (TID 7), reason: Stage cancelled** ; **20/03/05 09:28:58 INFO Executor: Executor is trying to kill task 29.0 in stage 0.0 (TID 29), reason: Stage cancelled** ; **20/03/05 09:28:58 INFO Executor: Executor is trying to kill task 8.0 in stage 0.0 (TID 8), reason: Stage cancelled** ; **20/03/05 09:28:58 INFO TaskSchedulerImpl: Stage 0 was cancelled** ; **20/03/05 09:28:58 INFO DAGScheduler: ShuffleMapStage 0 (mapToPair at PSFilter.java:125) failed in 63.548 s due to Job aborted due to stage failure: Task 34 in stage 0.0 failed 1 times, most recent failure: Lost task 34.0 in stage 0.0 (TID 34, localhost, executor driver): com.esotericsoftware.kryo.KryoException: Buffer underflow.** ; **at com.esotericsoftware.kryo.io.Input.require(Input.java:199)** ; **at com.esotericsoftware.kryo.io.Input.readLong(Input.java:686)** ; **at org.broadinstitute.hellbender.tools.spark.utils.LongHopscotchSet.<init>(LongHopscotchSet.java:83)** ; **at org.broadinstitute.hellbender.tools.spark.utils.LongHopscotchSet$Serializer.read(LongHopscotchSet.java:527)** ; **at org.broadinstitute.hellbender.tools.spark.utils.LongHopscotchSet$Serializer.read(LongHopscotchSet.java:519)** ; **at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:712)** ; **at org.broadinstitute.hellbender.tools.spark.utils.LargeLongHopscotchSet.<init>(LargeLongHopscotchSet.java:55)** ; **at org.broadinstitute.hellbender.tools.spark.utils.LargeLongHopscotchSet$Serializer.read(LargeLongHopscotchSet.java:172)** ; **at org.br",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6493:38034,failure,failure,38034,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6493,1,['failure'],['failure']
Availability," the annotation, the following changes will be made to any specified annotations: 'StrandBiasBySample' will be enabled. 'ChromosomeCounts', 'FisherStrand', 'StrandOddsRatio' and 'QualByDepth' annotations have been disabled ; ; 14:14:36.866 INFO HaplotypeCallerEngine - Standard Emitting and Calling confidence set to 0.0 for reference-model confidence output ; ; 14:14:36.866 INFO HaplotypeCallerEngine - All sites annotated with PLs forced to true for reference-model confidence output ; ; 14:14:36.876 INFO NativeLibraryLoader - Loading libgkl\_utils.so from jar:file:/home/ngs/biosoft/gatk-4.2.0.0/gatk-package-4.2.0.0-local.jar!/com/intel/gkl/native/libgkl\_utils.so ; ; 14:14:36.878 INFO NativeLibraryLoader - Loading libgkl\_pairhmm\_omp.so from jar:file:/home/ngs/biosoft/gatk-4.2.0.0/gatk-package-4.2.0.0-local.jar!/com/intel/gkl/native/libgkl\_pairhmm\_omp.so ; ; 14:14:36.927 INFO IntelPairHmm - Flush-to-zero (FTZ) is enabled when running PairHMM ; ; 14:14:36.928 INFO IntelPairHmm - Available threads: 8 ; ; 14:14:36.928 INFO IntelPairHmm - Requested threads: 4 ; ; 14:14:36.928 INFO PairHMM - Using the OpenMP multi-threaded AVX-accelerated native PairHMM implementation ; ; 14:14:37.228 INFO ProgressMeter - Starting traversal ; ; 14:14:37.228 INFO ProgressMeter - Current Locus Elapsed Minutes Regions Processed Regions/Minute ; ; 14:14:38.715 WARN InbreedingCoeff - InbreedingCoeff will not be calculated at position chr1:10439 and possibly subsequent; at least 10 samples must have called genotypes ; ; 14:14:47.243 INFO ProgressMeter - chr1:186172 0.2 920 5511.7 ; ; 14:14:57.278 INFO ProgressMeter - chr1:830665 0.3 3650 10922.7 ; ; 14:15:05.692 WARN DepthPerSampleHC - Annotation will not be calculated at position chr1:977935 and possibly subsequent; genotype for sample 8939{JXM}-3 is not called ; ; 14:15:05.692 WARN StrandBiasBySample - Annotation will not be calculated at position chr1:977935 and possibly subsequent; genotype for sample 8939{JXM}-3 is not called ; ; 14:15:",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7582:4677,Avail,Available,4677,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7582,1,['Avail'],['Available']
Availability," variants, I noticed an inconsistency in how artificial reads are counted towards the AD. Details:. For the variant at position chr15:93002203 with the reference allele G and alternate allele GA, the VCF output shows:; AD=24,6. `chr15	93002203	.	G	GA	73.60	.	AC=1;AF=0.500;AN=2;BaseQRankSum=0.000;DP=34;ExcessHet=3.0103;FS=21.417;MLEAC=1;MLEAF=0.500;MQ=60.00;MQRankSum=0.000;QD=2.45;ReadPosRankSum=1.481;SOR=1.028	GT:AD:DP:GQ:PL:SB	0/1:24,6:30:81:81,0,597:22,2,2,4; `. Upon reviewing the bamout IGV image, I confirmed that the artificial reads were not considered informative and were therefore not included in the AD calculation, which aligns with the expected behavior. ![image](https://github.com/user-attachments/assets/06117f01-3a9d-41eb-9296-dbd807b067aa). This behavior, where artificial reads are excluded from the AD calculation, is something I have observed across multiple variants, not just the example provided above. However, a different behavior was observed with another variant at position chr1:31662674 with the reference allele G and alternate allele GGGC. The VCF output for this variant shows:; AD=22,4. `chr1	31662674	.	G	GGGC	52.60	.	AC=1;AF=0.500;AN=2;BaseQRankSum=0.692;DP=30;ExcessHet=3.0103;FS=41.746;MLEAC=1;MLEAF=0.500;MQ=60.00;MQRankSum=0.000;QD=2.02;ReadPosRankSum=-2.529;SOR=3.219	GT:AD:DP:GQ:PL:SB	0/1:22,4:26:60:60,0,911:0,22,4,0`. In this case, the bamout IGV image shows only 2 insertions excluding the artificial reads, yet the AD includes 4, suggesting that the artificial reads were counted. This is contrary to the behavior observed with the first variant, where artificial reads were not counted. ![image](https://github.com/user-attachments/assets/f9fd5325-06ab-4480-99f9-6f56b60a29b7). Why are artificial reads being included in the AD calculation for some variants but not for others? This inconsistency can lead to confusion and potentially affect downstream analyses. I would appreciate any insights or guidance on this issue. Thank you for your support.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8959:2370,down,downstream,2370,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8959,1,['down'],['downstream']
Availability," workflows.; [2019-02-22 23:50:02,53] [info] JobExecutionTokenDispenser stopped; [2019-02-22 23:50:02,53] [info] WorkflowStoreActor stopped; [2019-02-22 23:50:02,61] [info] WorkflowLogCopyRouter stopped; [2019-02-22 23:50:02,61] [info] Shutting down WorkflowManagerActor - Timeout = 3600 seconds; [2019-02-22 23:50:02,61] [info] WorkflowManagerActor All workflows finished; [2019-02-22 23:50:02,61] [info] WorkflowManagerActor stopped; [2019-02-22 23:50:02,61] [info] Connection pools shut down; [2019-02-22 23:50:02,61] [info] Shutting down SubWorkflowStoreActor - Timeout = 1800 seconds; [2019-02-22 23:50:02,61] [info] Shutting down JobStoreActor - Timeout = 1800 seconds; [2019-02-22 23:50:02,61] [info] Shutting down CallCacheWriteActor - Timeout = 1800 seconds; [2019-02-22 23:50:02,61] [info] Shutting down ServiceRegistryActor - Timeout = 1800 seconds; [2019-02-22 23:50:02,61] [info] SubWorkflowStoreActor stopped; [2019-02-22 23:50:02,61] [info] Shutting down DockerHashActor - Timeout = 1800 seconds; [2019-02-22 23:50:02,61] [info] Shutting down IoProxy - Timeout = 1800 seconds; [2019-02-22 23:50:02,61] [info] CallCacheWriteActor Shutting down: 0 queued messages to process; [2019-02-22 23:50:02,61] [info] JobStoreActor stopped; [2019-02-22 23:50:02,61] [info] CallCacheWriteActor stopped; [2019-02-22 23:50:02,61] [info] KvWriteActor Shutting down: 0 queued messages to process; [2019-02-22 23:50:02,61] [info] WriteMetadataActor Shutting down: 0 queued messages to process; [2019-02-22 23:50:02,62] [info] DockerHashActor stopped; [2019-02-22 23:50:02,62] [info] IoProxy stopped; [2019-02-22 23:50:02,62] [info] ServiceRegistryActor stopped; [2019-02-22 23:50:02,65] [info] Database closed; [2019-02-22 23:50:02,65] [info] Stream materializer shut down; Workflow 098a389e-b298-4324-8a8c-9f46f05708b5 transitioned to state Failed; [2019-02-22 23:50:02,75] [info] Automatic shutdown of the async connection; [2019-02-22 23:50:02,75] [info] Gracefully shutdown sentry threads.; [2019-02-",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5714:31220,down,down,31220,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5714,12,['down'],['down']
Availability," your ""issue"" is better addressed on the GATK forum: http://gatkforums.broadinstitute.org/gatk Post there if you have questions about expected tool behavior, output format, unexpected results, or generally any question that does not fit into the categories above; - Use a **concise** yet **descriptive** title; - Choose the corresponding template block below and fill it in, replacing or deleting text in italics (surrounded by `_`) as appropriate; - Delete the other template blocks and this header. ----. ## Bug Report. ### Affected tool(s) or class(es); GATK GenotypeGVCFs. ### Affected version(s); - [ ] Latest public release version [version?]; - [ ] Latest master branch as of [date of test?]. ### Description ; I conducted joint-call with GATK GenotypeGVCfs for two samples (proband, and mother). I have identified the maternal variant information filled with ""."" in jointcall.vcf which is the output file of GTAK GenotypeGVCfs (see, figure 1). For chromosome MT, all variant information field values were fileld with ""."", instead of mother's g.vcf. . ; ![image](https://user-images.githubusercontent.com/45510932/207542098-cd4af866-c209-405f-9553-3810275f7d8e.png); Figure 1. Jointcall.vcf of proband, and mother. redbox refers to maternal variant information. . . Except for chromosomes X, Y, and MT, these issues did not occur. In addition, I suspected the false positive variants filtering which is the advantage of GATK jointcall. however, the variants which have ""."" values do not seem to be false positive variants considering AD, DP, and variant allele frequency (VAF). #### Steps to reproduce; GATK version used: 3.8.1; ```; java -jar GenomeAnalysisTK-3.8-1-0-gf15c1c3ef/GenomeAnalysisTK.jar \ ; -T GenotypeGVCFs \; -R Homo_sapiens_assembly38.main_chr.fasta \; --variant proband.hg38.g.vcf.gz \; --variant mother.hg38.g.vcf.gz \; -o output_jointcall.vcf \; --logging_level ERROR; ```. #### Expected behavior; variant info (field_value ) not ""."" . #### Actual behavior; filled with "".""",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8129:2550,ERROR,ERROR,2550,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8129,1,['ERROR'],['ERROR']
Availability,"              4.5                 21980           4841.3 ; ; 22:11:23.401 INFO  ProgressMeter -       chr5:115188609              4.7                 23170           4914.9 ; ; 22:11:33.498 INFO  ProgressMeter -       chr5:127089898              4.9                 24050           4925.7 ; ; 22:11:33.815 INFO  HaplotypeCaller - 69572 read(s) filtered by: MappingQualityReadFilter   ; ; 0 read(s) filtered by: MappingQualityAvailableReadFilter   ; ; 0 read(s) filtered by: MappedReadFilter   ; ; 380 read(s) filtered by: NotSecondaryAlignmentReadFilter   ; ; 0 read(s) filtered by: NotDuplicateReadFilter   ; ; 0 read(s) filtered by: PassesVendorQualityCheckReadFilter   ; ; 0 read(s) filtered by: NonZeroReferenceLengthAlignmentReadFilter   ; ; 0 read(s) filtered by: GoodCigarReadFilter   ; ; 0 read(s) filtered by: WellformedReadFilter   ; ; 69952 total reads filtered ; ; 22:11:33.816 INFO  ProgressMeter -       chr5:127488298              4.9                 24105           4931.6 ; ; 22:11:33.816 INFO  ProgressMeter - Traversal complete. Processed 24105 total regions in 4.9 minutes. ; ; 22:11:33.891 INFO  VectorLoglessPairHMM - Time spent in setup for JNI call : 2.883281574 ; ; 22:11:33.891 INFO  PairHMM - Total compute time in PairHMM computeLogLikelihoods() : 66.287158269 ; ; 22:11:33.891 INFO  SmithWatermanAligner - Total compute time in java Smith-Waterman : 81.56 sec ; ; 22:11:35.558 INFO  HaplotypeCaller - Shutting down engine ; ; \[March 12, 2022 10:11:35 PM CET\] org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCaller done. Elapsed time: 4.94 minutes. ; ; Runtime.totalMemory()=1998061568. \===========. See forum topic details at forum guidelines page: [https://gatk.broadinstitute.org/hc/en-us/articles/360053845952-Forum-Guidelines](https://gatk.broadinstitute.org/hc/en-us/articles/360053845952-Forum-Guidelines)<br><br><i>(created from <a href='https://broadinstitute.zendesk.com/agent/tickets/276551'>Zendesk ticket #276551</a>)<br> gz#276551</i>",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7741:15408,down,down,15408,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7741,1,['down'],['down']
Availability,"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! Warning: VariantEval is a BETA tool and is not yet ready for use in production !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\[0m 19:35:29.411 INFO VariantEval - Initializing engine 19:35:29.755 INFO FeatureManager - Using codec VCFCodec to read file file:///cromwell\_root/fc-47de7dae-e8e6-429c-b760-b4ba49136eee/joint\_vcfs/recalibrated/PASS/1kgp.chrX.recalibrated.snp\_indel.pass.vcf.gz 19:35:29.835 INFO VariantEval - Done initializing engine 19:35:29.836 INFO PedReader - Reading PED file /cromwell\_root/fc-47de7dae-e8e6-429c-b760-b4ba49136eee/resources/1kgp/1kgp\_trios.ped with missing fields: \[\] 19:35:29.854 INFO PedReader - Phenotype is other? true 19:35:32.686 INFO VariantEval - Creating 1881 combinatorial stratification states 19:35:32.742 INFO ProgressMeter - Starting traversal 19:35:32.742 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute 19:36:01.819 INFO VariantEval - Shutting down engine \[May 27, 2021 7:36:01 PM UTC\] org.broadinstitute.hellbender.tools.walkers.varianteval.VariantEval done. Elapsed time: 0.54 minutes. Runtime.totalMemory()=4964483072 java.lang.IndexOutOfBoundsException: Index: 1, Size: 1 at java.util.ArrayList.rangeCheck(ArrayList.java:653) at java.util.ArrayList.get(ArrayList.java:429) at org.broadinstitute.hellbender.utils.samples.MendelianViolation.isViolation(MendelianViolation.java:180) at org.broadinstitute.hellbender.utils.samples.MendelianViolation.updateViolations(MendelianViolation.java:122) at org.broadinstitute.hellbender.utils.samples.MendelianViolation.countFamilyViolations(MendelianViolation.java:148) at org.broadinstitute.hellbender.tools.walkers.varianteval.evaluators.MendelianViolationEvaluator.update1(MendelianViolationEvaluator.java:122) at org.broadinstitute.hellbender.tools.walkers.varianteval.util.EvaluationContext.apply(EvaluationContext.java:74) at org.broadinstitute.hellbender.tools.walkers.varianteval.VariantEval.process",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7304:3626,down,down,3626,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7304,1,['down'],['down']
Availability,"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. 08:33:37.136 INFO FilterAlignmentArtifacts - Initializing engine; 08:33:37.531 INFO FeatureManager - Using codec VCFCodec to read file file:///data/filteredVCF/in2510-8.orientationFilter.vcf; 08:33:37.586 INFO FilterAlignmentArtifacts - Done initializing engine; 08:33:37.668 INFO NativeLibraryLoader - Loading libgkl_pairhmm_omp.so from jar:file:/gatk/gatk-package-4.1.9.0-SNAPSHOT-local.jar!/com/intel/gkl/native/libgkl_pairhmm_omp.so; 08:33:37.706 INFO IntelPairHmm - Flush-to-zero (FTZ) is enabled when running PairHMM; 08:33:37.707 INFO IntelPairHmm - Available threads: 8; 08:33:37.707 INFO IntelPairHmm - Requested threads: 4; 08:33:37.707 INFO PairHMM - Using the OpenMP multi-threaded AVX-accelerated native PairHMM implementation; 08:33:37.708 INFO ProgressMeter - Starting traversal; 08:33:37.708 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x00007ff7b7dfe32d, pid=849, tid=0x00007ff82e11d700; #; # JRE version: OpenJDK Runtime Environment (8.0_242-b08) (build 1.8.0_242-8u242-b08-0ubuntu3~18.04-b08); # Java VM: OpenJDK 64-Bit Server VM (25.242-b08 mixed mode linux-amd64 compressed oops); # Problematic frame:; # C [libgkl_smithwaterman5951765478004985534.so+0x132d] smithWatermanBackTrack(dnaSeqPair*, int, int, int, int, int*, int)+0x1bd; #; # Failed to write core dump. Core dumps have been disabled. To enable core dumping, try ""ulimit -c unlimited"" before starting Java again; #; # An error report file with more information is saved as:; # /home/gatk/hs_err_pid849.log; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; # The crash happened outside the Java Virtual Machine in native code.; # See problematic frame for where to report the bug.; #; ```. **RELEVANT FILES**; [hs_err_pid100.log](https://github.com/broadinstitute/gat",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7162:5483,error,error,5483,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7162,1,['error'],['error']
Availability,"""""""""; gatk]# ./gradlew; Downloading https://services.gradle.org/distributions/gradle-3.1-bin.zip; ............................................; Download https://repo1.maven.org/maven2/commons-codec/commons-codec/1.6/commons-codec-1.6.jar; Executing: git lfs pull --include src/main/resources/large. FAILURE: Build failed with an exception. * Where:; Build file '/data/md1/zhouyajun/biotools/gatk/gatk/build.gradle' line: 102. * What went wrong:; A problem occurred evaluating root project 'gatk'.; > Execution of ""git lfs pull --include src/main/resources/large"" failed with exit code: 1. * Try:; Run with --stacktrace option to get the stack trace. Run with --info or --debug option to get more log output. BUILD FAILED; """"""; what should I do ?; How can I install GATK4 successful?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4669:24,Down,Downloading,24,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4669,3,"['Down', 'FAILURE']","['Download', 'Downloading', 'FAILURE']"
Availability,"""Partition boundaries are not coordinate sorted"" error when running SV tool in local mode on a full BAM with external evidence",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3717:49,error,error,49,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3717,1,['error'],['error']
Availability,"# Bug Report . ### Affected tool(s) or class(es); PathSeq. ### Affected version(s); - 4.1.6.0. ### Description . I wanted to better understand the PathSeq pipeline (and in particular, the Host Filter step) so I simulated RNA-seq reads from three microbial genomes of interest (Salmonella eneterica subsp. enterica serovar Typhimurium str. SL1344, Salmonella eneterica subsp. enterica serovar Typhimurium str. LT2, Fusobacterium nucleatum subsp. nucleatum ATCC 25586). I generate six datasets with 100,000 unpaired reads of length 75 bp (2 datasets from each genome) using Rsubread with simulate.sequencing.error=TRUE and ran them through PathSeq. I generated an identical six datasets using Rsubread with simulate.sequencing.error=FALSE. . #### Expected behavior; For the six datasets with simulate.sequencing.error=TRUE, I would expect a small number of reads to be filtered for each step. For the six datasets with simulate.sequencing.error=FALSE, I would expect similar results but with even fewer reads to be filtered for the low-quality or low complexity read filter. #### Actual behavior; For the six datasets with simulate.sequencing.error=TRUE, 8,496 - 18,103 reads were filtered by the low complexity or low quality filter (the Salmonella datasets were on the lower end and the Fusobacterium datasets were on the higher end), 115 - 311 reads were filtered by the host k-mer filter and 886 - 1822 reads were filtered by the duplicate read filter. . The number of reads filtered by the low complexity or low quality filter seemed high to me so I repeated the analysis with simulate.sequencing.error=FALSE. For these six datasets, all 100,000 reads are filtered by the low-quality or low complexity read filter. . #### Steps to reproduce; I wrote the workflow using snakemake and conda. In theory, you should be able to reproduce the error using `snakemake --use-conda`; Snakefile; ```; from os.path import join; import pandas as pd. ATCC25586_CDS_URL = ""ftp://ftp.ncbi.nlm.nih.gov/genomes/all/G",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6705:606,error,error,606,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6705,3,['error'],['error']
Availability,"# Bug Report. ## Affected tool(s) or class(es); gatk `GenomicsDBImport ` `GenotypeGVCFs`; ## Affected version(s); The Genome Analysis Toolkit (GATK) v4.5.0.0; ## Description; Hi,; Here is my situation, I'm testing the feasibility of incremental GenomicsDB，I have total 400 samples to joint calling, I have no problem directly using `GenomicsDBImport `and `GenotypeGVCFs `for joint calling of all 400 samples. The configuration used is 4c32g for `GenomicsDBImport `and 2c16g for `GenotypeGVCFs`. But when I first built a GenomicsDB of 200 samples using `GenomicsDBImport `successfully, and then use GenomicsDB `--genomicsdb-update-workspace-path` increment 200 samples into the GenomicsDB , use this incremental imported GenomicsDB to `GenotypeGVCFs`. The error happend and report GENOMICSDB_TIMER,Exception in thread ""main"" java.lang.OutOfMemoryError: Java heap space; Here are my code; ```; gatk --java-options ""-Xms8000m -Xmx~{max_mem}m"" \; GenomicsDBImport \; --tmp-dir $PWD \; --genomicsdb-workspace-path ~{workspace_dir_name}~{prefix}.~{index} \; --batch-size 50 \; -L ~{intervals} \; --reader-threads 5 \; --merge-input-intervals \; --consolidate \; -V ~{sep = "" -V "" single_sample_gvcfs}. gatk --java-options ""-Xms8000m -Xmx~{max_mem}m"" \; GenomicsDBImport \; --tmp-dir $PWD \; --genomicsdb-update-workspace-path ~{workspace_dir_name} \; --batch-size 50 \; --reader-threads 5 \; --merge-input-intervals \; --consolidate \; -V ~{sep = "" -V "" single_sample_gvcfs}. gatk --java-options ""-Xms8000m -Xmx~{max_mem}m"" \; GenotypeGVCFs \; --tmp-dir $PWD \; -R ~{ref} \; -O ~{workspace_dir_name}.vcf.gz \; -G StandardAnnotation \; --only-output-calls-starting-in-intervals \; -V gendb://~{workspace_dir_name} \; -L ~{intervals} \; --merge-input-intervals \; -all-sites; ```; And I found that before report error the number of threads used by GATK increased, but the memory usage did not exceed the maximum limit of the server.; I also cheched `--max-alternate-alleles` and `--genomicsdb-max-alternate-al",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8777:755,error,error,755,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8777,1,['error'],['error']
Availability,"# Bug Report. ### Affected tool(s) or class(es); _Mutect2_. ### Affected version(s); - [x] 4.1.5.0 ~ 4.1.8.1. ### Description ; _Mutation with AF ~2.5% missed by Mutect2 paired-calling. It may be related to M2's active region selection module_. #### Steps to reproduce. * Default (both `--force_active` and `--alleles` are OFF) → **No call**; ```; gatk Mutect2 -I cancer.bam -I normal.bam -R /opt/dat/hs37d5.fa -normal normal -O no_call.vcf.gz -L interval.bed --force-active false -verbosity ERROR; ```. * With force_active ON → **Correct call**; ```; gatk Mutect2 -I cancer.bam -I normal.bam -R /opt/dat/hs37d5.fa -normal normal -O force_active.vcf.gz -L interval.bed --force-active true -verbosity ERROR; ```. * With `--alleles` ON (make use of the above force_active results) → **Correct call**; ```; gatk Mutect2 -I cancer.bam -I normal.bam -R /opt/dat/hs37d5.fa -normal normal -O force_alleles.vcf.gz -L interval.bed --force-active false -verbosity ERROR --alleles force_active.vcf.gz; ```. #### Expected behavior. ```; bcftools query -s cancer -f '%CHROM\t%POS\t%REF\t%ALT\t[%AF{0}]\n' force_alleles.vcf.gz; 12	25378562	C	T	0.024; 12	25378660	A	G	0.014; ```. #### Actual behavior; _Empty output_. #### Other information. <details><summary> IGV screen shot of the mutation <code>12:g.25378562C>T</code></summary>; <img width=""1131"" alt=""igv"" src=""https://user-images.githubusercontent.com/4134899/88393449-3861cc80-cdf0-11ea-8e31-1a99b3b21ed9.png"">; </details>. We used the 1000genomes Phase2 Reference Genome Sequence (hs37d5).; ![ftp://ftp-trace.ncbi.nih.gov/1000genomes/ftp/technical/reference/phase2_reference_assembly_sequence/hs37d5.fa.gz](ftp://ftp-trace.ncbi.nih.gov/1000genomes/ftp/technical/reference/phase2_reference_assembly_sequence/hs37d5.fa.gz). The cancer and matched normal bams (aligned to hs37d5) to reproduce the above behaviors ([data.zip](https://github.com/broadinstitute/gatk/files/4971930/data.zip)). Thanks,; Richard",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6724:492,ERROR,ERROR,492,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6724,3,['ERROR'],['ERROR']
Availability,"# Feature request . ### Tool(s) or class(es) involved; HaplotypeCaller, CombineGVCFs, GenotypeGVCFs. ### Description; New capability to go backward from a multi-sample vcf generated by CombineGVCFs or GenotypeGVCFs to individual gvcfs so that a user can joint-call again with another cohort.; This request came about because a [user posted on the forum](https://gatk.broadinstitute.org/hc/en-us/community/posts/360060957571-Empty-vcf-after-GenotypeVCFs-when-combining-already-genotyped-samples) the following scenario:. 1. Cohort: VCF with SNPs called with HC per sample and CombineGVCFs, GATK 3.5 (older samples, no bams available.; 2. Cohort: VCF/gVCF/BAM/fastq available (new samples). GATK 4.1.2.0.; Ideally, combine using joint genotype calling from genotype likelihoods (annotations are available in both VCFs - mixed ploidy.). HOWEVER when using CombineGVCFs to combine the two files the result looked incorrect.; `gatk CombineGVCFs -R ref.fasta -V tetra.vcf.gz -V mixed.vcf.gz -O merged.vcf --tmp-dir $TMPDIR`; Result: For ALT alleles it removes the known allele and replaces it with <NON-REF> for all loci. Even if I run CombineGVCFs with just one of the files `gatk CombineGVCFs -R ref.fasta -V tetra.vcf.gz -O foo.vcf`.; When I then run GenotypeGVCFs only the header of the new, called vcf but nothing below the #CHROM line.; `gatk GenotypeGVCFs -R ref.fasta -V merged.vcf -O merged_GT.vcf --tmp-dir $TMPDIR`. The user came up with this approach, but it is not ideal:. grep -vE ""NON_REF"" mixed.vcf > mixed.mod.vcf # removes all loci with NON_REF as ALT; grep -vE ""NON_REF"" tetra.vcf > tetra.mod.vcf; GATK 3.7 CombineVariants; SelectVariants -select 'set == ""Intersection""'. ----",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6596:622,avail,available,622,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6596,3,['avail'],['available']
Availability,"## Bug Report . ### Affected tool(s) or class(es); PathSeq. ### Affected version(s); version 4.1.6.0. ### Description ; I am pre-aligning a paired-end RNA-seq dataset to the human host genome using STAR. I get a `Uniquely mapped reads %` of 83.24%. Next, I run PathSeqPipelineSpark using `--is-host-aligned true` and the default options. When I look at the filter-metrics file, I see `PRIMARY_READS` = 1,057,098 and `READS_AFTER_PREALIGNED_HOST_FILTER` = 543,664. #### Steps to reproduce; This is on a dataset that I can't share but I'm happy to reproduce this on a publicly available dataset if you need that. . #### Expected behavior; I would expect >= 83.24% of reads to be filtered by the PREALIGNED_HOST_FILTER step. . #### Actual behavior; < 50% of the reads are filtered by the PREALIGNED_HOST_FILTER step. . Do you have any insight into what's going on? Should I be using an aligner other than STAR? Are there RNA-seq specific instructions for running PathSeq?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6687:575,avail,available,575,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6687,1,['avail'],['available']
Availability,"## Bug Report. ### Affected tool(s) or class(es). All Spark tools that takes parameter `-L`. ### Affected version(s); - [x] Latest public release version [4.0.4.0]; - [x] Latest master branch as of [2018-06-30]. ### Description . When running a Spark tool and passing in interval arguments via the standard `-L` argument, if the interval file (only BED file is tested) is stored in HDFS, we see errors like below. ```; org.broadinstitute.hellbender.exceptions.UserException$MalformedGenomeLoc: Badly formed genome unclippedLoc: Query interval ""hdfs://shuang-g94794-chmi-chmi3-wgs1-cram-bam-feature-m:8020/data/merged_commonFPDel.bed"" is not valid for this input.; 	at org.broadinstitute.hellbender.utils.GenomeLocParser.getUnambiguousInterval(GenomeLocParser.java:350); 	at org.broadinstitute.hellbender.utils.GenomeLocParser.parseGenomeLoc(GenomeLocParser.java:309); 	at org.broadinstitute.hellbender.utils.IntervalUtils.parseIntervalArguments(IntervalUtils.java:300); 	at org.broadinstitute.hellbender.utils.IntervalUtils.loadIntervals(IntervalUtils.java:226); 	at org.broadinstitute.hellbender.cmdline.argumentcollections.IntervalArgumentCollection.parseIntervals(IntervalArgumentCollection.java:174); 	at org.broadinstitute.hellbender.cmdline.argumentcollections.IntervalArgumentCollection.getTraversalParameters(IntervalArgumentCollection.java:155); 	at org.broadinstitute.hellbender.cmdline.argumentcollections.IntervalArgumentCollection.getIntervals(IntervalArgumentCollection.java:111); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.initializeIntervals(GATKSparkTool.java:514); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.initializeToolInputs(GATKSparkTool.java:451); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:439); 	at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:30); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLinePro",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4852:395,error,errors,395,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4852,1,['error'],['errors']
Availability,"## Bug Report. ### Affected tool(s) or class(es). FastaAlternateReferenceMaker. ### Affected version(s); - [x] Latest public release version 4.1.4.1; - [ ] Latest master branch as of [date of test?]. ### Description . A null pointer exception in . #### Steps to reproduce. We called variants with HaplotypeCaller & use resulting VCF with FastaAlternateReferenceMaker. See command below, but only reference fasta & HC vcf are given as input (no snp masking or interval list, though error also occurs when using interval list with multiple -L calls). #### Expected behavior. Alternate-adjusted reference file or at least a helpful error message. #### Actual behavior. ```; + latest-gatk/gatk-4.1.4.1/gatk FastaAlternateReferenceMaker -R /g/data/xe2/references/eucalyptus/emel_scott/Emelliodora_CSIROg1_SISH00000000.1.fasta -O consensus_sequences_gatk//CCA0704.fasta.tmp -V pergene_gatk/CCA0704/CCA0704.vcf.gz; Using GATK jar /g/data/xe2/users/stephen-rodgers/latest-gatk/gatk-4.1.4.1/gatk-package-4.1.4.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /g/data/xe2/users/stephen-rodgers/latest-gatk/gatk-4.1.4.1/gatk-package-4.1.4.1-local.jar FastaAlternateReferenceMaker -R /g/data/xe2/references/eucalyptus/emel_scott/Emelliodora_CSIROg1_SISH00000000.1.fasta -O consensus_sequences_gatk//CCA0704.fasta.tmp -V pergene_gatk/CCA0704/CCA0704.vcf.gz; 15:43:14.276 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/g/data/xe2/users/stephen-rodgers/latest-gatk/gatk-4.1.4.1/gatk-package-4.1.4.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Feb 03, 2020 3:43:15 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 15:43:15.230 INFO FastaAlternateReferenceMaker - ------------------------------------------------------------; 1",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6434:448,mask,masking,448,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6434,3,"['error', 'mask']","['error', 'masking']"
Availability,## Bug Report. ### Affected tool(s) or class(es). GermlineCNVCaller. ### Affected version(s). - [x] Latest public release version gatk 4.2.0.0; - [ ] Latest master branch as of [date of test?]. ### Description . The same set of hdf5 works fine with another annotated_intervals.tsv . the stack trace:; ```; 11:52:33.788 INFO GermlineCNVCaller - Aggregating read-count file /SCRATCH-BIRD/users/lindenbaum-p/work/NEXTFLOW/; 20210411.GRCh37.gatkcnv.brs/work/92/579e5a48aa9e52cd0e1df603266809/B00HOTD.counts.hdf5 (229 / 347); HDF5-DIAG: Error detected in HDF5 (1.8.14) thread 0:; #000: /mnt/scr1/abyrne/HDFJava-platypus-2.11/native/HDF5-prefix/src/HDF5/src/H5Dio.c line 173 in H5Dread(): can'; t read data; major: Dataset; minor: Read failed; #001: /mnt/scr1/abyrne/HDFJava-platypus-2.11/native/HDF5-prefix/src/HDF5/src/H5Dio.c line 550 in H5D__read(): ca; n't read data; major: Dataset; minor: Read failed; #002: /mnt/scr1/abyrne/HDFJava-platypus-2.11/native/HDF5-prefix/src/HDF5/src/H5Dcontig.c line 543 in H5D__contig; _read(): contiguous read failed; major: Dataset; minor: Read failed; #003: /mnt/scr1/abyrne/HDFJava-platypus-2.11/native/HDF5-prefix/src/HDF5/src/H5Dscatgath.c line 517 in H5D__scat; gath_read(): file gather failed; major: Low-level I/O; minor: Read failed; #004: /mnt/scr1/abyrne/HDFJava-platypus-2.11/native/HDF5-prefix/src/HDF5/src/H5Dscatgath.c line 253 in H5D__gath; er_file(): read error; major: Dataspace; minor: Read failed; #005: /mnt/scr1/abyrne/HDFJava-platypus-2.11/native/HDF5-prefix/src/HDF5/src/H5Dcontig.c line 873 in H5D__contig; _readvv(): can't perform vectorized sieve buffer read; major: Dataset; minor: Can't operate on object; #006: /mnt/scr1/abyrne/HDFJava-platypus-2.11/native/HDF5-prefix/src/HDF5/src/H5VM.c line 1457 in H5VM_opvv(): ca; n't perform operation; major: Internal error (too specific to document in detail); minor: Can't operate on object; #007: /mnt/scr1/abyrne/HDFJava-platypus-2.11/native/HDF5-prefix/src/HDF5/src/H5Dcontig.c line 696 in H5D_,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7202:532,Error,Error,532,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7202,1,['Error'],['Error']
Availability,"## Bug Report. ### Affected tool(s) or class(es). Mutect2; `; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx130g -jar /gatk/gatk-package-4.1.8.1-local.jar Mutect2 -R /ucsc.hg19.fasta -I my.bam -L /test.bed --f1r2-tar-gz DD.f1r2.tar.gz --force-active --genotype-germline-sites --kmer-size 10 --kmer-size 20 --recover-all-dangling-branches --max-reads-per-alignment-start 0 --native-pair-hmm-threads 33 -O DD.vcf.gz; `. ### Affected version(s); Using GATK jar /gatk/gatk-package-4.1.8.1-local.jar. ### Description ; When bed is created with a reference genome that is not the same as the bam file, an null pointer can occurs. The error is not catched by GATK, and the error is difficult to understand. Here a discussion about it.; https://gatk.broadinstitute.org/hc/en-us/community/posts/360077477391-Haplotype-caller-fails-to-run-GATK-4-1-8-0-and-GATK-4-2-0-0-. The case below occurs when provided bed has been made with the wrong genome reference.; `; 14:25:55.254 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/gatk/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Oct 07, 2021 2:25:55 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 14:25:55.525 INFO Mutect2 - ------------------------------------------------------------; 14:25:55.525 INFO Mutect2 - The Genome Analysis Toolkit (GATK) v4.1.8.1; 14:25:55.525 INFO Mutect2 - For support and documentation go to https://software.broadinstitute.org/gatk/; 14:25:55.525 INFO Mutect2 - Executing as toto on Linux v5.4.123-1.el7.elrepo.x86_64 amd64; 14:25:55.525 INFO Mutect2 - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_242-8u242-b08-0ubuntu3~18.04-b08; 14:25:55.526 INFO Mutect2 - Start Date/Time: October 7, 2021 2:25:55 PM GMT; 14:25:55.526 INFO Mutect2 - -----",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7496:426,recover,recover-all-dangling-branches,426,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7496,3,"['error', 'recover']","['error', 'recover-all-dangling-branches']"
Availability,"## Bug Report. ### Affected tool(s) or class(es). The Genome Analysis Toolkit (GATK) v4.0.7.0. ### Description . I ran the command line below and get an oom error. I've got the same error when i set the heap memory larger using the param ""--java-option Xmx24g"" . This procedure only crashed when I tried to select INDEL. I've uploaded the vcf file for you to test. command line:; ```shell; disk/juntong/software/gatk-4.0.7.0/gatk SelectVariants -V /disk/juntong/huada/V300029595_results/mutect_outputs/V300029595.merged.vcf.gatk.somatic.vcf.gz -O /disk/juntong/huada/V300029595_results/mutect_outputs/V300029595.merged.vcf.gatk.somatic.vcf.gatk.somatic.indel.vcf.gz -select-type INDEL; ```. log:; ```; Using GATK jar /disk/juntong/software/gatk-4.0.7.0/gatk-package-4.0.7.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /disk/juntong/software/gatk-4.0.7.0/gatk-package-4.0.7.0-local.jar SelectVariants -V /disk/juntong/huada/V300029595_results/mutect_outputs/V300029595.merged.vcf.gatk.somatic.vcf.gz -O /disk/juntong/huada/V300029595_results/mutect_outputs/V300029595.merged.vcf.gatk.somatic.vcf.gatk.somatic.indel.vcf.gz -select-type INDEL; 05:06:54.800 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/disk/juntong/software/gatk-4.0.7.0/gatk-package-4.0.7.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; 05:06:55.409 INFO SelectVariants - ------------------------------------------------------------; 05:06:55.409 INFO SelectVariants - The Genome Analysis Toolkit (GATK) v4.0.7.0; 05:06:55.409 INFO SelectVariants - For support and documentation go to https://software.broadinstitute.org/gatk/; 05:06:55.410 INFO SelectVariants - Executing as juntong@train1 on Linux v3.10.0-1062.1.1.el7.x86_64 amd64; 05:06:55.410 INFO SelectVariants - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_222-b10; 05:06:55.410 INFO SelectVariants -",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6254:157,error,error,157,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6254,2,['error'],['error']
Availability,"## Bug Report. ### Affected tool(s) or class(es). ValidateVariants: `--fail-gvcf-on-overlap` / `-no-overlaps`. ### Affected version(s); - [x] Latest public release version: 4.2.6.1; - [ ] ~Latest master branch as of~ [did not test, but affected file hasn't changed since August 2021]. ### Description . If there are overlapping reference blocks when running ValidateVariants with the `-no-overlaps` option, a USER ERROR is outputted after the entire tool finishes running, as shown below:. ```; ***********************************************************************. A USER ERROR has occurred: This GVCF contained overlapping reference blocks. The first overlapping interval is [genomic coordinates here]. ***********************************************************************; ```. This error should be generally helpful, but it appears that the interval that is reported in the error message is the _last_ overlapping interval, not the _first_. I'm not super familiar with java, but I'm guessing that `firstOverlap` might be continuously replaced by `refInterval` if there are multiple overlaps, which is inconsistent with expected behavior. . Potentially relevant lines of code: ; - `-no-overlaps` argument description ([lines 192-201](; https://github.com/broadinstitute/gatk/blob/ca33bc953abfa7050b791f049285f5262675cf84/src/main/java/org/broadinstitute/hellbender/tools/walkers/variantutils/ValidateVariants.java#L192-L201)); - `firstOverlap = refInterval` ([line 275](https://github.com/broadinstitute/gatk/blob/ca33bc953abfa7050b791f049285f5262675cf84/src/main/java/org/broadinstitute/hellbender/tools/walkers/variantutils/ValidateVariants.java#L275)). #### Steps to reproduce. Running ValidateVariants with the `-no-overlaps` flag on a .g.vcf with overlapping intervals will cause this error. More specifically, we're running this within WARP's Exome Germline Single Sample v.3.1.7 WDL release. Our command is as follows:. ```; gatk --java-options ""-Xms6000m -Xmx6500m"" \; ValidateVariants ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8103:414,ERROR,ERROR,414,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8103,4,"['ERROR', 'error']","['ERROR', 'error']"
Availability,"## Bug Report. ### Affected tool(s) or class(es): Mutect2. ### Affected version(s); gatk 4.2.5. ### Description ; Like most use cases, I acquired a high-confidence, ""consensus"" VCF from a large batch of samples, and I run force-calling on each individual sample again to:; (1) rescue rare variants.; (2) for variants that are not called in a sample, get the REF/ALT counts for them for downstream analysis. However, compared to the first pass (where Mutect2 is in simple germline calling mode), the second pass (force-calling) is extremely slow. Sorry I have not done any precise measurement, but the difference is quite significant. Given my use case, do you still recommend using force-calling? Or is there any alternative, more efficient method? I tried using bcftools call, but that tool has several issues as well such as omitting indels, not supporting multiallelic force-calling etc. #### Steps to reproduce. My command for force-calling is:; ```; ""gatk Mutect2 ""; ""-alleles {input.q_vcf} ""; ""-L {input.q_vcf} ""; ""--genotype-filtered-alleles ""; ""--max-reads-per-alignment-start {params.mrpas} ""; ""-R {params.REF} ""; ""-I {input.sc_bam} ""; ""-O {output.sc_vcf}; ""; ```. I can upload some BAMs for testing if needed. Thanks in advance!",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7825:386,down,downstream,386,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7825,1,['down'],['downstream']
Availability,"## Bug Report. ### Affected tool(s) or class(es); ""gatk PostprocessGermlineCNVCalls"". ### Affected version(s); - docker (broadinstitute/gatk, 4.1.9.0 version). ### Description ; #### Steps to reproduce. This is my command line. ; gatk PostprocessGermlineCNVCalls \; --calls-shard-path CALLS_01 \; --model-shard-path MODEL_01 \; --allosomal-contig chrX \; --allosomal-contig chrY \; --autosomal-ref-copy-number 2 \; --contig-ploidy-calls contig-ploidy-calls \; --sample-index 9 \; --output-genotyped-intervals genotyped-intervals-2016001038.vcf.gz \; --output-genotyped-segments genotyped-segments-2016001038.vcf.gz \; --output-denoised-copy-ratios denoised_copy_ratios-2016001038.tsv. #### Error message ; ![image](https://user-images.githubusercontent.com/33537478/119120932-cab21b80-ba67-11eb-9cd3-bb0af7192799.png). #### Expected behavior; generation of following files; genotyped-intervals-2016001038.vcf.gz, genotyped-segments-2016001038.vcf.gz, denoised_copy_ratios-2016001038.tsv . #### Actual behavior; when making a ""genotyped-segments-2016001038.vcf.gz"" file, tool emits this error message. . ![image](https://user-images.githubusercontent.com/33537478/119120932-cab21b80-ba67-11eb-9cd3-bb0af7192799.png)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7266:690,Error,Error,690,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7266,2,"['Error', 'error']","['Error', 'error']"
Availability,"## Bug Report. ### Affected tool(s) or class(es); - gatk/scripts/cnv_wdl/germline/cnv_germline_case_workflow.wdl; - gatk/scripts/cnv_wdl/germline/cnv_getmline_cohort_workflow.wdl. ### Affected version(s); - **WDL** file from GATK latest release (4.2.5.0); - **GATK Docker** - latest (4.2.5.0). ### Description ; Accoridng to [GATK Germline CNV WDL instructions](https://github.com/broadinstitute/gatk/blob/master/scripts/cnv_wdl/germline/README.md), I ran cnv_getmline_cohort_workflow.wdl and got data to run cnv_germline_case_workflow.wdl. (contig_ploidy_model_tar file and 40 gcnv_model_tars files). Then I tried to run cnv_germline_case_workflow.wdl with one sample and got an error: ; ```; java.lang.IllegalArgumentException: The number of input call shards must match the number of input model shards.; 	at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:798); 	at org.broadinstitute.hellbender.tools.copynumber.PostprocessGermlineCNVCalls.validateArgum; ```. PostprocessGermlineCNVCalls only completes correctly if I use only one of the gcnv_model_tars files, but it only produces results for the iterval_list file that is included in the used gcnv_model_tars. #### Case mode files; [case.log](https://github.com/broadinstitute/gatk/files/8186658/case.log); [case-inputs.json.txt](https://github.com/broadinstitute/gatk/files/8186662/case-inputs.json.txt). #### Cohort mode files; [cohort.log](https://github.com/broadinstitute/gatk/files/8186665/cohort.log); [cohort-inputs.json.txt](https://github.com/broadinstitute/gatk/files/8186667/cohort-inputs.json.txt)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7706:680,error,error,680,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7706,1,['error'],['error']
Availability,"## Bug Report. ### Affected tool(s) or class(es); ApplyBQSRSpark. ### Affected version(s); gatk-4.1.9.0. ### Description ; After roughly 1h of running ApplyBQSRSpark on my WGS BAM, it throws the error `java.io.IOException: Bad file descriptor`.; I then used `samtools quickcheck` to validate the integrity of my BAM file and everything seems fine. The BAM file is coordinate sorted and the duplicates are marked. The size of the BAM file is 142GB. #### Steps to reproduce; This is the command I used:. ```bash; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar gatk-package-4.1.9.0-local.jar ApplyBQSRSpark -R ref-genome.fa -I buffy_coat.sorted.markdup.bam --spark-master local[45] --tmp-dirtmp --bqsr-recal-file buffy_coat_recal_bqsr.table -O buffy_coat.recal.bam; ```. Any help is much appreciated!. Cheers",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7139:195,error,error,195,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7139,1,['error'],['error']
Availability,"## Bug Report. ### Affected tool(s) or class(es); ApplyVQSR . ### Affected version(s); gatk-4.2.6.1. ### Description . Getting the following error. However, the chr6.raw.excessHet.vcf.gz does not contain that multiallelic variant site. This variant is the nearest at that location but the error is for a variant at chr6:26914009 with different alleles =[G*, GTGTA, GTGTATA, GTGTGTA] . . `chr6 26914005 . A ATG,G 15390.7 PASS AC=278,2;AF=0.04,0.0002879;AN=6948;AS_BaseQRankSum=-0.2,0.4;AS_FS=0.522,0;AS_InbreedingCoeff=-0.0012,0.1805;AS_MQ=58.75,59.2;AS_MQRankSum=0,-3.2;AS_QD=2.56,0.02;AS_ReadPosRankSum=0.1,0.3;AS_SOR=0.652,0.724;BaseQRankSum=-0.152;DP=118313;ExcessHet=2.9774;FS=0.518;InbreedingCoeff=0.0016;MLEAC=278,2;MLEAF=0.04,0.0002879;MQ=56.9;MQRankSum=-0.962;QD=2.57;ReadPosRankSum=0.193;SOR=0.712; `. ```; org.broadinstitute.hellbender.exceptions.GATKException: Exception thrown at chr6:26914009 [VC chr6.raw.excessHet.vcf.gz @ chr6:26914009 Q276902.75 of type=INDEL alleles=[G*, GTGTA, GTGTATA, GTGTGTA] attr={AC=[4269, 29, 5], AF=[0.620, 4.209e-03, ; #### Steps to reproduce; /share/pkg.7/gatk/4.2.6.1/install/gatk-4.2.6.1/gatk --java-options -Xms5g ApplyVQSR -O indel.recalibrated.vcf.gz -V chr6.raw.excessHet.vcf.gz -AS --recal-file /restricted/projectnb/kageproj/gatk/pVCF.vqsr/indels.recal --use-allele-specific-annotations --tranches-file /restricted/projectnb/kageproj/gatk/pVCF.vqsr/indels.tranches --truth-sensitivity-filter-level 99.0 --create-output-variant-index true -mode INDEL; ```. #### Expected behavior; Create recalibrated vcf file. #### Actual behavior; ```; Caused by:; Process `ApplyRecalibrationIndels` terminated with an error exit status (3). Command executed:. #!/bin/bash; /share/pkg.7/gatk/4.2.6.1/install/gatk-4.2.6.1/gatk --java-options -Xms5g ApplyVQSR -O indel.recalibrated.vcf.gz -V chr6.raw.excessHet.vcf.gz -AS --recal-file /restricted/projectnb/kageproj/gatk/pVCF.vqsr/indels.recal --use-allele-specific-annotations --tranches-file /restricted/projectnb/",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8054:141,error,error,141,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8054,2,['error'],['error']
Availability,"## Bug Report. ### Affected tool(s) or class(es); BaseRecalibratorSpark; BQSRPipelineSpark. ### Affected version(s); 4.1.0.0. ### Description ; We are running into a problem using BaseRecalibratorSpark. The tool fails soon after starting. The same error appears with the same bam file on different machines. Additionally, vanilla BaseRecalibrator works just fine on these bams (so I don't think the issue is with the bam). They are all suffering from the same/similar stacktrace. We've had BaseRecalibratorSpark work fine on other bam files. Additionally, changing the number of threads still results in the same stacktrace. I've also tried running the BQSRPipelineSpark to see if that would suffer the same issue and it fails in the same manner. Additionally, I've run ValidateSamFile. There are some reads missing their mates, but this hasn't presented an issue in other tools (including vanilla BaseRecalibrator). Searching thru the forum, I found an old issue with a similar stacktrace, but that issue appears to occur in GATK 2.4: https://gatkforums.broadinstitute.org/gatk/discussion/3265/bqsrgatherer-exception. In the below stacktrace, I've bolded the error message that seems to occur in each of these samples. `Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(D",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5854:248,error,error,248,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5854,1,['error'],['error']
Availability,"## Bug Report. ### Affected tool(s) or class(es); Build. ### Affected version(s); - [X] Latest public release version [version?]; - [ ] Latest master branch as of [date of test?]. ### Description ; ```; =======================<phase: build >============================; ===> Building for gatk-4.2.6.1_1. Welcome to Gradle 7.5.1!. Here are the highlights of this release:; - Support for Java 18; - Support for building with Groovy 4; - Much more responsive continuous builds; - Improved diagnostics for dependency resolution. For more details see https://docs.gradle.org/7.5.1/release-notes.html. Starting a Gradle Daemon (subsequent builds will be faster). FAILURE: Build failed with an exception. * Where:; Build file '/wrkdirs/usr/ports/biology/gatk/work/gatk-4.2.6.1/build.gradle' line: 15. * What went wrong:; Plugin [id: 'de.undercouch.download', version: '4.1.2'] was not found in any of the following sources:. - Gradle Core Plugins (plugin is not in 'org.gradle' namespace); - Plugin Repositories (could not resolve plugin artifact 'de.undercouch.download:de.undercouch.download.gradle.plugin:4.1.2'); Searched in the following repositories:; Gradle Central Plugin Repository; ```. #### Steps to reproduce; regular build. Version: 4.2.6.1; Java-17; FreeBSD 13.1",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7984:658,FAILURE,FAILURE,658,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7984,4,"['FAILURE', 'down']","['FAILURE', 'download']"
Availability,"## Bug Report. ### Affected tool(s) or class(es); CalculateContamination. ### Affected version(s); - [x] Latest public release version 4.1.8.1. ### Description . There appears to be an error mode where if not a lot of sites are provided, the contamination estimation tool will estimate the error on contamination as 0.0. We should change this to either error out if enough sites are not provided, or modify the calculation to correctly reflect the uncertainty in contamination.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6727:185,error,error,185,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6727,3,['error'],['error']
Availability,"## Bug Report. ### Affected tool(s) or class(es); CollectMultipleMetrics. ### Affected version(s); 4.1.2.0. ### Description ; CollectMultipleMetrics performs Percent-encoding of input paths. When running this tool as a step of a packed CWL workflow with Cromwell, this causes a `No such file or directory` error. The input file; ```; /cromwell-executions/transform_pack.cwl#main/0cd8a732-b482-4b8e-ba6e-34d244620ded/call-picard_collectmultiplemetrics/inputs/-733038737/dbsnp_144.hg38.vcf.gz; ```; becomes; ```; file:///cromwell-executions/transform_pack.cwl%23main/0cd8a732-b482-4b8e-ba6e-34d244620ded/call-picard_collectmultiplemetrics/inputs/-733038737/dbsnp_144.hg38.vcf.gz; ```; and can not be found. #### Expected behavior; The tool should collect metrics without error. #### Actual behavior; `CollectMultipleMetrics`; ```; Job main.metrics.metrics.cwl.gatk_collectmultiplemetrics:NA:1 exited with return code 3 which has not been declared as a valid return code. See 'continueOnReturnCode' runtime attribute for more details.; Check the content of stderr for potential additional information: /mnt/scratch/runpack/cromwell-executions/transform_pack.cwl#main/8f58079f-1b94-40a9-873f-41e8d765644d/call-metrics/transform_pack.cwl#metrics.cwl/2a15d912-9a75-44dc-a723-b9f2dba439b3/call-gatk_collectmultiplemetrics/execution/stderr.; Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/cromwell-executions/transform_pack.cwl#main/8f58079f-1b94-40a9-873f-41e8d765644d/call-metrics/transform_pack.cwl#metrics.cwl/2a15d912-9a75-44dc-a723-b9f2dba439b3/call-gatk_collectmultiplemetrics/tmp.a2640a46; 20:19:59.771 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/usr/local/bin/gatk-package-4.1.2.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; [Thu May 09 20:20:00 UTC 2019] CollectMultipleMetrics --INPUT /cromwell-executions/transform_pack.cwl#main/8f58079f-1b94-40a9-873f-41e8d765644d/call-metrics/transform_pack.cwl#metrics.cwl/2a15d912-9a75-44dc-a723-b9f2dba439b3/call-gatk_colle",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5931:306,error,error,306,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5931,2,['error'],['error']
Availability,"## Bug Report. ### Affected tool(s) or class(es); CollectReadCounts . ### Affected version(s); - [x] Latest public release version [4.1.8.1]; - [x] Latest master branch as of [10/6/2020]. ### Description ; GATK CollectReadCounts successfully processes some reads but then throws an ArrayIndexOutOfBoundsException in the middle of the file. Console output below. I was able to successfully run CollectReadCounts on ~16k other crams, but received the same error on 3 of them (although the last coordinate reported by ProgressMeter was different for each). The error does not occur if I subset out chromosome 6 reads from the main cram file and run CollectReadCounts on each file separately. I don't see any obvious formatting issue with my crams from a quick skim over lines immediately following the last reported coordinate. ; ```; > java -jar gatk-package-4.1.8.1-local.jar CollectReadCounts \; -I input.cram \; --read-index input.cram.crai \; -L my_intervals.bed \; --interval-merging-rule OVERLAPPING_ONLY \; --reference hg38.fa \; --format TSV \; -O output.tsv. 16:56:30.581 INFO CollectReadCounts - ------------------------------------------------------------; 16:56:30.581 INFO CollectReadCounts - The Genome Analysis Toolkit (GATK) v4.1.8.1; 16:56:30.581 INFO CollectReadCounts - For support and documentation go to https://software.broadinstitute.org/gatk/; 16:56:30.582 INFO CollectReadCounts - Executing as isaac@LAPTOP-K5UOQS3A on Linux v4.19.104-microsoft-standard amd64; 16:56:30.582 INFO CollectReadCounts - Java runtime: Java HotSpot(TM) 64-Bit Server VM v14.0.1+7; 16:56:30.582 INFO CollectReadCounts - Start Date/Time: October 6, 2020 at 4:56:30 PM EDT; 16:56:30.582 INFO CollectReadCounts - ------------------------------------------------------------; 16:56:30.582 INFO CollectReadCounts - ------------------------------------------------------------; 16:56:30.583 INFO CollectReadCounts - HTSJDK Version: 2.23.0; 16:56:30.584 INFO CollectReadCounts - Picard Version: 2.22.8; 16:56:",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6865:454,error,error,454,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6865,2,['error'],['error']
Availability,"## Bug Report. ### Affected tool(s) or class(es); CombineGVCFs. ### Affected version(s); - GATK 4.1.8.1 (Latest release as of 08/24/20). ### Description ; User is running CombineGVCFs and getting a java error java.lang.NullPointerException; at org.broadinstitute.hellbender.tools.walkers.annotator.allelespecific.StrandBiasUtils.encode(StrandBiasUtils.java:52). This issue was discussed at the GATK Office Hours meeting. ### Associated forum post; https://gatk.broadinstitute.org/hc/en-us/community/posts/360072644931-Combine-GVCF-generate-java-lang-NullPointerException. Command:; time ""$gatk"" CombineGVCFs \; -G StandardAnnotation \; -G AS_StandardAnnotation \; -R ""$ref_gen""/ucsc.hg19.fasta \; -V /paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/A200272.HC.g.vcf.gz \; -V /paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/A200273.HC.g.vcf.gz \; -V /paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/A200274.HC.g.vcf.gz \; -V /paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/A200313.HC.g.vcf.gz \; -V /paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/A200314.HC.g.vcf.gz \; -V /paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/A200315.HC.g.vcf.gz \; -V /paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/PID20-006.HC.g.vcf.gz \; -V /paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/PID20-007.HC.g.vcf.gz \; -V /paedwy/disk1/yangyxt/wes/backup_gvcfs/all_wes_samples.g.vcf \; -O /paedwy/disk1/yangyxt/wes/backup_gvcfs/all_wes_samples_plus_${sample_batch}.g.vcf.gz && echo ""Combine_gvcfs done"". Error Log:; ```; 12:01:36.798 WARN GATKAnnotationPluginDescriptor - Redundant enabled annotation group (StandardAnnotation) is enabled for this tool by default; 12:01:36.824 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/yangyxt/software/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Aug 24, 2020 12:01:37 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect wheth",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6766:203,error,error,203,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6766,1,['error'],['error']
Availability,"## Bug Report. ### Affected tool(s) or class(es); CombineGVCFs. ### Affected version(s); - [X] Latest public release version [4.2.5.0]; - [ ] Latest master branch as of [date of test?]. ### Description ; The auto-generated wdl for CombineGVCFs on dockstore won't work because it doesn't have any inputs for the indices of the input vcfs. This means GATK cannot access the vcf indices because they never get localized, so the workflow fails. . #### Steps to reproduce; Take any vcfs and run them through the workflow to get an error about missing indices. . #### Expected behavior; Including the indices in the task inputs will allow them to get localized along with the vcfs so GATK can operate normally. . #### Actual behavior; You get an error saying it requires index files to proceed.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7681:526,error,error,526,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7681,2,['error'],['error']
Availability,## Bug Report. ### Affected tool(s) or class(es); CountReadsSpark. ### Affected version(s); gatk-4.0.12.0. ### Description ; Reading cram generates the following error when running CountReadsSpark on yarn. . ```; ./gatk-4.0.12.0/gatk CountReadsSpark --input /project/casa/gcad/adsp.cc/cram/A-ADC-AD010072-BL-NCR-11AD44210.hg38.realign.bqsr.cram --reference file:///restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa -- --spark-runner SPARK --spark-master yarn; Using GATK jar /restricted/projectnb/casa/wgs.hg38/sv/gatk.sv/gatk-4.0.12.0/gatk-package-4.0.12.0-spark.jar; Running:; /share/pkg/spark/2.1.0/install/bin/spark-submit --master yarn --conf spark.kryoserializer.buffer.max=512m --conf spark.driver.maxResultSize=0 --conf spark.driver.userClassPathFirst=false --conf spark.io.compression.codec=lzf --conf spark.yarn.executor.memoryOverhead=600 --conf spark.driver.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 --conf spark.executor.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 /restricted/projectnb/casa/wgs.hg38/sv/gatk.sv/gatk-4.0.12.0/gatk-package-4.0.12.0-spark.jar CountReadsSpark --input /project/casa/gcad/adsp.cc/cram/A-ADC-AD010072-BL-NCR-11AD44210.hg38.realign.bqsr.cram --reference file:///restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa --spark-master yarn; 13:13:11.050 WARN SparkContextFactory - Environment variables HELLBENDER_TEST_PROJECT and HELLBENDER_JSON_SERVICE_ACCOUNT_KEY must be set or the GCS hadoop connector will not be configured properly; 13:13:11.275 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/restricted/projectnb/casa/wgs.hg38/sv/gatk.sv/gatk-4.0.1,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547:162,error,error,162,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547,1,['error'],['error']
Availability,"## Bug Report. ### Affected tool(s) or class(es); FilterMutectCalls and possibly Mutect2. ### Affected version(s); GATK 4.1.7.0, still occurs in 4.1.8.1. ### Description ; User running Mutect2 in mitochondrial mode and ERC BP_RESOLUTION. Mutect2 is successful, however filter mutect calls has error message; `java.lang.IllegalArgumentException: alpha must be greater than 0 but got NaN`. Possible similar issue: #6202 ; Complete stack trace:. ```; Running:. java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx22G -Djava.io.tmpdir=/nobackup/lnsingh/MTRNA/tmp -jar /nobackupp16/swbuild/hsp/COVID19/anaconda3/envs/COVIRT_GATK/share/gatk4-4.1.7.0-0/gatk-package-4.1.7.0-local.jar FilterMutectCalls --disable-read-filter MappingQualityReadFilter --disable-read-filter MappingQualityNotZeroReadFilter --disable-read-filter MappingQualityAvailableReadFilter --mitochondria-mode true -R /nobackup/lnsingh/MTRNA/lib/rCRS.fa -V /nobackup/lnsingh/MTRNA/out/COVSUBJ_0121_1_N_HA_filtered.humanspliced.gvcf.gz -L MT -O /nobackup/lnsingh/MTRNA/out/COVSUBJ_0121_1_N_HA_filtered.humanspliced.filtered.gvcf.gz. 07:33:14.927 WARN GATKReadFilterPluginDescriptor - Disabled filter (MappingQualityReadFilter) is not enabled by this tool. 07:33:14.928 WARN GATKReadFilterPluginDescriptor - Disabled filter (MappingQualityNotZeroReadFilter) is not enabled by this tool. 07:33:14.928 WARN GATKReadFilterPluginDescriptor - Disabled filter (MappingQualityAvailableReadFilter) is not enabled by this tool. 07:33:15.003 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/nobackupp16/swbuild/hsp/COVID19/anaconda3/envs/COVIRT_GATK/share/gatk4-4.1.7.0-0/gatk-package-4.1.7.0-local.jar!/com/intel/gkl/native/libgkl_compression.so. Sep 20, 2020 7:33:15 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine. INFO: Failed to detect whether we are running on Google",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6850:293,error,error,293,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6850,1,['error'],['error']
Availability,"## Bug Report. ### Affected tool(s) or class(es); Funcotator. ### Affected version(s); - [ ] Latest master branch as of [June 22, 2018]. ### Description ; If there are no variants in the input VCF that are rendered in the MAF, the MAF file is blank. It should contain a header. This will cause problems in downstream tools expecting a valid MAF. #### Expected behavior; A MAF that is empty except for a header. #### Actual behavior; A zero-byte file. #### Possible solution; MafOutputRenderer can use the metadata to create a header.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4937:306,down,downstream,306,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4937,1,['down'],['downstream']
Availability,"## Bug Report. ### Affected tool(s) or class(es); Funcotator. ### Affected version(s); - [ ] Latest master branch as of [June 26, 2018]. ### Description ; This happens when there are transcripts with different gene names that overlap a variant. Error is in `createFuncotationsOnVariant` ... . #### Expected behavior; One transcript is selected. #### Actual behavior; One transcript per overlapping gene name is selected.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4952:245,Error,Error,245,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4952,1,['Error'],['Error']
Availability,"## Bug Report. ### Affected tool(s) or class(es); Funcotator. ### Affected version(s); - [x] Latest public release version [4.2.1.0]; - [ ] Latest master branch as of [date of test?]. ### Description ; When processing a VCF with tumor and matched normal into a MAF, the `Match_Norm_Seq_Allele1` and `Match_Norm_Seq_Allele2` fields are not populated. #### Steps to reproduce. `gatk --java-options -Xmx2048m Funcotator --data-sources-path /cromwell_root/datasources_dir --ref-version hg38 --output-file-format MAF -R /cromwell_root/getzlab-workflows-reference_files-oa/hg38/gdc/GRCh38.d1.vd1.fa -V` [`C3N-02729.vcf.gz`](https://github.com/broadinstitute/gatk/files/6977700/C3N-02729.vcf.gz) `-O C3N-02729.maf --annotation-default normal_barcode:C3N-02729_N --annotation-default tumor_barcode:C3N-02729_T --annotation-default Center:broadinstitute.org --annotation-default source:Unknown --transcript-selection-mode BEST_EFFECT`. (NOTE: reference files available at `gs://getzlab-workflows-reference_files-oa/hg38/gdc`). #### Expected behavior; `Match_Norm_Seq_Allele1` and `Match_Norm_Seq_Allele2` fields should be populated as appropriate based on the `GT` field for the matched normal in the VCF. #### Actual behavior; `Match_Norm_Seq_Allele1` and `Match_Norm_Seq_Allele2` are populated with `__UNKNOWN__`",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7408:950,avail,available,950,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7408,1,['avail'],['available']
Availability,"## Bug Report. ### Affected tool(s) or class(es); Funcotator. ### Affected version(s); All. ### Description ; Since we expect users to write config files manually, we need to have some enforcement of naming rules. At the least, to disallow spaces in the name and version fields. There are many places throughout the code where we assume that there will be no spaces. Additionally, I hear from users that they want any Funcotator tsv outputs to never have spaces (or tabs or other special characters -- ""_"", ""-"" are obviously okay). . We can solicit users about which special characters are okay, but definitely disallow spaces and tabs. #### Steps to reproduce; Add a space to the Gencode datasource config (name or version field) and try to funcotate a segment file. #### Expected behavior; No errors and no spaces in the field names. #### Actual behavior; Exception in gene list output renderer.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5937:795,error,errors,795,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5937,1,['error'],['errors']
Availability,"## Bug Report. ### Affected tool(s) or class(es); Funcotator. ### Affected version(s); GATK 4.1.0.0. ### Description ; Funcotator does not perform any annotation on a minimal VCF with canonical cancer variants and returns the following error:. ```; 23:28:30.519 INFO Funcotator - Initializing Funcotator Engine...; 23:28:30.523 INFO Funcotator - Creating a VCF file for output: file:xxx/sandbox/idh.funcotated.vcf; 23:28:30.541 INFO ProgressMeter - Starting traversal; 23:28:30.541 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 23:28:30.652 INFO ProgressMeter - unmapped 0.0 15 8108.1; 23:28:30.652 INFO ProgressMeter - Traversal complete. Processed 15 total variants in 0.0 minutes.; 23:28:30.652 WARN Funcotator - ================================================================================; 23:28:30.652 WARN Funcotator - _ _ _ __ __ _ _ _ _; 23:28:30.652 WARN Funcotator - | || || | \ \ / /_ _ _ __ _ __ (_)_ __ __ _ | || || |; 23:28:30.652 WARN Funcotator - | || || | \ \ /\ / / _` | '__| '_ \| | '_ \ / _` | | || || |; 23:28:30.653 WARN Funcotator - |_||_||_| \ \V V / (_| | | | | | | | | | | (_| | |_||_||_|; 23:28:30.653 WARN Funcotator - (_)(_)(_) \_/\_/ \__,_|_| |_| |_|_|_| |_|\__, | (_)(_)(_); 23:28:30.653 WARN Funcotator - |___/; 23:28:30.653 WARN Funcotator - --------------------------------------------------------------------------------; 23:28:30.653 WARN Funcotator - Only IGRs were produced for this dataset. This STRONGLY indicates that this; 23:28:30.653 WARN Funcotator - run was misconfigured.; 23:28:30.653 WARN Funcotator - You MUST check your data sources to make sure they are correct for these data.; 23:28:30.653 WARN Funcotator - ================================================================================; ```. There is no reason to assume that there is any issue with the data sources or run parameters. They have worked fine using a different VCF that had completed INFO tags. #### Steps to reproduce; Run Funcotator",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5777:236,error,error,236,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5777,1,['error'],['error']
Availability,"## Bug Report. ### Affected tool(s) or class(es); Funcotator. ### Affected version(s); gatk-4.1.8.0; funcotator_dataSources.v1.7.20200521s. ### Description . I am trying to use Funcotator to annotate the variants that I have already detected. Unfortunatelly, after a few seconds Funcotator stops with the error:. > java.lang.IllegalArgumentException: Unexpected value: lncRNA. I have no idea what is wrong and I did not find this error in the internet. Can it be a problem with JRE?. Full log below. #### Steps to reproduce. `~/programs/gatk-4.1.8.0/gatk Funcotator --variant filtered_variants/P1.vcf.gz --reference ~/resources/hg38_for_bwa/hs38DH.fa --ref-version hg38 --data-sources-path ~/resources/gatk/funcotator2/funcotator_dataSources.v1.7.20200521s --output filtered_variants/P1.avcf.gz --output-file-format VCF`. #### Expected behavior. Foncotator annotates my variants. #### Actual behavior. > (base) [pkus@master1 mutect_test]$ ~/programs/gatk-4.1.8.0/gatk Funcotator --variant filtered_variants/P1.vcf.gz --reference ~/resources/hg38_for_bwa/hs38DH.fa --ref-version hg38 --data-sources-path ~/resources/gatk/funcotator2/funcotator_dataSources.v1.7.20200521s --output filtered_variants/P1.avcf.gz --output-file-format VCF; > Using GATK jar /home/pkus/programs/gatk-4.1.8.0/gatk-package-4.1.8.0-local.jar; > Running:; > java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /home/pkus/programs/gatk-4.1.8.0/gatk-package-4.1.8.0-local.jar Funcotator --variant filtered_variants/P1.vcf.gz --reference /home/pkus/resources/hg38_for_bwa/hs38DH.fa --ref-version hg38 --data-sources-path /home/pkus/resources/gatk/funcotator2/funcotator_dataSources.v1.7.20200521s --output filtered_variants/P1.avcf.gz --output-file-format VCF; > 15:16:39.460 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/pkus/programs/gatk-4.1.8.0/gatk-package-4.1.8.0-local.jar!/com/int",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6708:305,error,error,305,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6708,2,['error'],['error']
Availability,"## Bug Report. ### Affected tool(s) or class(es); GATK 4.1.0.0 AnalyzeCovariates. ### Affected version(s); - [x] Latest public release version [version?]; - [ ] Latest master branch as of [date of test?]. ### Description ; The csv produced by AnalyzeCovariates is invalid. It doesn't escape commas in fields, resulting in an error in the R script. #### Steps to reproduce; If you have a comma in the readgroup in a BAM, this will happen. #### Expected behavior; It should produce valid csv files, and then be able to properly produce the plots. #### Actual behavior; Commas in read group names result in malformed (unescaped) csv where it's impossible to parse fields properly. This results in the following R script error:; ```; Error in read.table(file = file, header = header, sep = sep, quote = quote, :; more columns than column names; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5739:325,error,error,325,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5739,3,"['Error', 'error']","['Error', 'error']"
Availability,"## Bug Report. ### Affected tool(s) or class(es); GATK Haplotype caller. ### Affected version(s); - [x] Latest public release version [4.1.0.0]; - [ ] Latest master branch as of [date of test?]. The Genome Analysis Toolkit (GATK) v4.1.0.0; HTSJDK Version: 2.18.2; Picard Version: 2.18.25. ### Description ; HaplotypeCaller is outputting variants which have a no-call as the ALT, which breaks a bunch of downstream tools, this is new behavior in 4.1, AFAICT. ```; #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	s1564	s1741	s1851	s1852	s1862	s1901	s1912	s1971	s2017	s2021	s2026	s2056	s2100	s2102	s2104	s2122	s2124	s2151	s2157; 1	937796	.	T	.	179.65	.	AN=38;DP=31;MMQ=60;MQ=60.00	GT:AD:DP	0/0:0:0	0/0:0:0	0/0:4:4	0/0:0:0	0/0:1:1	0/0:1:1	0/0:0:0	0/0:0:0	0/0:2:2	0/0:0:0	0/0:1:1	0/0:3:3	0/0:1:1	0/0:8:8	0/0:1:1	0/0:0:0	0/0:2:2	0/0:7:7	0/0:0:0; ```. #### Steps to reproduce; I'm not doing anything special, so I suspect these variants should exist in other projects as well. I'm doing batch calling on several samples simultaneously; an example:. ```; unset JAVA_HOME && export PATH=/home/rdk4/local/share/bcbio/anaconda/bin:$PATH && gatk --java-options '-Xms4g -Xmx5000m -XX:+UseSerialGC -Djava.io.tmpdir=/n/data1/cores/bcbio/PIs/rudy_tanzi/tau-exome/tau-variants/work/bcbiotx/tmpTSg0hJ' HaplotypeCaller -R /n/app/bcbio/dev/genomes/Hsapiens/GRCh37/seq/GRCh37.fa --annotation MappingQualityRankSumTest --annotation MappingQualityZero --annotation QualByDepth --annotation ReadPosRankSumTest --annotation RMSMappingQuality --annotation BaseQualityRankSumTest --annotation FisherStrand --annotation MappingQuality --annotation DepthPerAlleleBySample --annotation Coverage -I /n/data1/cores/bcbio/PIs/rudy_tanzi/tau-exome/tau-variants/work/align/s2017/s2017-sort.bam -I /n/data1/cores/bcbio/PIs/rudy_tanzi/tau-exome/tau-variants/work/align/s2056/s2056-sort.bam -I /n/data1/cores/bcbio/PIs/rudy_tanzi/tau-exome/tau-variants/work/align/s2122/s2122-sort.bam -I /n/data1/cores/bcbio/PIs/rudy_tanzi/tau-exome/tau-var",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5650:403,down,downstream,403,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5650,1,['down'],['downstream']
Availability,"## Bug Report. ### Affected tool(s) or class(es); GATK Haplotypecaller . ### Affected version(s); (4.3.0.0 and 4.2.6.1). ### Description ; We used Haplotypecaller in GVCF mode (initially in 4.2.6.1, then again with 4.3.0.0) for one of our human samples. These samples were joint-genotyped with ~2.7k exomes. The exact command used was - . ```gatk HaplotypeCaller -R ""$ref_hg38"" -I input.bam -L twist.bed -ERC GVCF -ip 50 -O test_latest.gvcf.gz -bamout test_bamout_latest.bam --tmp-dir /mnt/exome/tmp/```. Below is a screenshot of the bamout file (top track) and the recalibrated BAM file (bottom track). . ![image](https://user-images.githubusercontent.com/32951653/224249117-ab13800f-5b3c-42f1-b349-993ae182620f.png). As shown in screenshot, there are only 2 reads supporting the alternate allele, however the gvcf.gz file has the below entry for the variant - . ```chr5 176530208 . T C,<NON_REF> 2717.64 . BaseQRankSum=0.975;DP=179;ExcessHet=0.0000;MLEAC=1,0;MLEAF=0.500,0.00;MQRankSum=0.000;RAW_MQandDP=644400,179;ReadPosRankSum=10.927 GT:AD:DP:GQ:PGT:PID:PL:PS:SB 0|1:68,102,0:170:99:0|1:176530208_T_C:2725,0,1279,2928,1584,4512:176530208:38,30,37,65```. This variant is called as a heterozygous variant ```0|1``` with read frequency of ```68,102,0```, which would mean 68 reads supporting the ref allele, 102 reads supporting the alt C allele and 0 reads supporting the <NON_REF> allele. After joint-genotyping, the variant was classified as LOW_VQSLOD. #### Steps to reproduce; Let us know how to share the BAM file subset and let us know if the error is reproducible. #### Expected behavior; Ideally, if the variant had been called, its read frequency should have been represented more accurately. #### Actual behavior; The read frequencies are not matching up.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8238:1552,error,error,1552,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8238,1,['error'],['error']
Availability,"## Bug Report. ### Affected tool(s) or class(es); GATK PostprocessGermlineCNVCalls. ### Affected version(s); v4.4.0.0. ### Description ; Run GTAK on a batch of WES samples with `PostprocessGermlineCNVCalls` encountered: ""Records were not strictly sorted in dictionary order.""; I tried to detect germline CNV in cohort mode on 25 WES samples by the official tutorial. At first, I didn't perform scatter and the step `PostprocessGermlineCNVCalls` was very time-consuming but eventually worked. So I split the reference genome into 45 parts to save time. It's OK for the first sample but there was an error ""Records were not strictly sorted in dictionary order."" from the second sample. I was really annoyed by it. `03:12:39.275 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/data/xiangxd/project/software/callers/gatk_4.4/gatk-package-4.4.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; 03:12:39.467 INFO PostprocessGermlineCNVCalls - ------------------------------------------------------------; 03:12:39.473 INFO PostprocessGermlineCNVCalls - The Genome Analysis Toolkit (GATK) v4.4.0.0; 03:12:39.474 INFO PostprocessGermlineCNVCalls - For support and documentation go to https://software.broadinstitute.org/gatk/; 03:12:39.475 INFO PostprocessGermlineCNVCalls - Executing as xiangxd@cu07 on Linux v3.10.0-327.el7.x86_64 amd64; 03:12:39.475 INFO PostprocessGermlineCNVCalls - Java runtime: Java HotSpot(TM) 64-Bit Server VM v20.0.2+9-78; 03:12:39.477 INFO PostprocessGermlineCNVCalls - Start Date/Time: April 15, 2024, 3:12:39 AM CST; 03:12:39.477 INFO PostprocessGermlineCNVCalls - ------------------------------------------------------------; 03:12:39.478 INFO PostprocessGermlineCNVCalls - ------------------------------------------------------------; 03:12:39.495 INFO PostprocessGermlineCNVCalls - HTSJDK Version: 3.0.5; 03:12:39.496 INFO PostprocessGermlineCNVCalls - Picard Version: 3.0.0; 03:12:39.497 INFO PostprocessGermlineCNVCalls - Built for Spark Vers",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8776:598,error,error,598,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8776,1,['error'],['error']
Availability,## Bug Report. ### Affected tool(s) or class(es); GATK ReblockGVCF. ### Affected version(s); - 4.2.5.0 and 4.2.6.1. ### Description ; I am running ReblockGVCF on GVCF's that are haplotyped on version 4.0.1.4. About 1 out of 500 samples crash with the following error:; `ReblockGVCF fails by an exception:No shortest ALT at 464564654 across alleles: [*]`. Complete error message:. ```; org.broadinstitute.hellbender.exceptions.GATKException: Exception thrown at chr4::464564654[VC /bug.g.vcf.gz @ ; ```; redacted; ```. ] filters=; at org.broadinstitute.hellbender.engine.MultiVariantWalker.lambda$traverse$1(MultiVariantWalker.java:145); at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183); at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195); at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:177); at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195); at java.base/java.util.Iterator.forEachRemaining(Iterator.java:133); at java.base/java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484); at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474); at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150); at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173); at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:497); at org.broadinstitute.hellbender.engine.MultiVariantWalker.traverse(MultiVariantWalker.java:136); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1085); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); at org.broadinstitute.hellbender.cmdline,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7961:261,error,error,261,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7961,2,['error'],['error']
Availability,"## Bug Report. ### Affected tool(s) or class(es); GATK v4.1.4.0 using FilterMutectCalls. ### Affected version(s); - [x] Latest public release version `4.1.4.0` installed from conda release `gatk4-4.1.4.0-1`; - [ ] Latest master branch as of [date of test?]. ### Description ; This issue reports the same error that is reported in #6237, but on the latest release, and in a mitochondrial calling setting. My command is:; ```bash; gatk FilterMutectCalls -V MT.vcf.gz\; -R human_g1k_v37.main.fasta\; -O MT.filtered.vcf.gz\; --stats MT.vcf.gz.stats\; --mitochondria-mode; ```. I get the following output to STDERR:; ```; 11:15:57.152 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/warkre/miniconda3/envs/gatk4.1.4.0/share/gatk4-4.1.4.0-1/gatk-package-4.1.4.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Nov 07, 2019 11:15:57 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 11:15:57.328 INFO FilterMutectCalls - ------------------------------------------------------------; 11:15:57.328 INFO FilterMutectCalls - The Genome Analysis Toolkit (GATK) v4.1.4.0; 11:15:57.328 INFO FilterMutectCalls - For support and documentation go to https://software.broadinstitute.org/gatk/; 11:15:57.328 INFO FilterMutectCalls - Executing as warkre@fuji on Linux v4.9.0-9-amd64 amd64; 11:15:57.328 INFO FilterMutectCalls - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_192-b01; 11:15:57.329 INFO FilterMutectCalls - Start Date/Time: November 7, 2019 11:15:57 AM CET; 11:15:57.329 INFO FilterMutectCalls - ------------------------------------------------------------; 11:15:57.329 INFO FilterMutectCalls - ------------------------------------------------------------; 11:15:57.329 INFO FilterMutectCalls - HTSJDK Version: 2.20.3; 11:15:57.329 INFO FilterMutectCalls - Picard Version: 2.21.1; 11:15:57.329 INFO FilterMutectCalls - HTSJDK Defaults.COMPRESSION_LEVEL : ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6255:304,error,error,304,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6255,1,['error'],['error']
Availability,"## Bug Report. ### Affected tool(s) or class(es); GatherTranches. ### Affected version(s); Latest public release version 4.2.6.1. ### Description ; I ran `VariantRecalibrator` in scattered (using intervals) mode and now trying to gather the scattered tranches into a single file but somehow the number of novel variants is < 0. This is the exact error:; `Invalid tranche - no. variants is < 0 : known 90357410 novel -1894637320`. #### Steps to reproduce; ```; inputs_cmdl = ' '.join([f'--input {t}' for t in tranches]); j.command(; f""""""set -euo pipefail; gatk --java-options -Xms6g \\; GatherTranches \\; --mode SNP \\; {inputs_cmdl} \\; --output {j.out_tranches}""""""; ); ```. #### Expected behavior; Gathered scattered VQSLOD tranches into a single file. #### Actual behavior; Fails because of what seems like an integer overflow according to @ldgauthier; ```; org.broadinstitute.hellbender.exceptions.GATKException: Invalid tranche - no. variants is < 0 : known 90357410 novel -1894637320; 	at org.broadinstitute.hellbender.tools.walkers.vqsr.Tranche.<init>(Tranche.java:37); 	at org.broadinstitute.hellbender.tools.walkers.vqsr.VQSLODTranche.<init>(VQSLODTranche.java:37); 	at org.broadinstitute.hellbender.tools.walkers.vqsr.VQSLODTranche.mergeAndConvertTranches(VQSLODTranche.java:205); 	at org.broadinstitute.hellbender.tools.walkers.vqsr.VQSLODTranche.mergeAndConvertTranches(VQSLODTranche.java:139); 	at org.broadinstitute.hellbender.tools.walkers.vqsr.GatherTranches.doWork(GatherTranches.java:80); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); 	at org.broadinstitute.hellbende",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7859:346,error,error,346,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7859,1,['error'],['error']
Availability,"## Bug Report. ### Affected tool(s) or class(es); GenomeDBImport. ### Affected version(s); ```; 01:22:35.395 INFO GenomicsDBImport - The Genome Analysis Toolkit (GATK) v4.2.0.0; 01:22:35.395 INFO GenomicsDBImport - For support and documentation go to https://software.broadinstitute.org/gatk/; 01:22:35.481 INFO GenomicsDBImport - Executing as vr6@node-14-20 on Linux v5.4.0-90-generic amd64; 01:22:35.481 INFO GenomicsDBImport - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_282-b08; 01:22:35.482 INFO GenomicsDBImport - Start Date/Time: 10 December 2021 01:22:34 UTC. ```. ### Description . It seems that is possible for some IO error affecting the production of the output tile-db file/folder that is ignored by the reslt of the tool run resulting in a falsely succesful completion. One won't realize of it unil tries to use that db with genotype-gvcfs. STDERR: . ```; Dec 10, 2021 1:22:35 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 01:22:35.395 INFO GenomicsDBImport - ------------------------------------------------------------; 01:22:35.395 INFO GenomicsDBImport - The Genome Analysis Toolkit (GATK) v4.2.0.0; 01:22:35.395 INFO GenomicsDBImport - For support and documentation go to https://software.broadinstitute.org/gatk/; 01:22:35.481 INFO GenomicsDBImport - Executing as vr6@node-14-20 on Linux v5.4.0-90-generic amd64; 01:22:35.481 INFO GenomicsDBImport - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_282-b08; 01:22:35.482 INFO GenomicsDBImport - Start Date/Time: 10 December 2021 01:22:34 UTC; 01:22:35.482 INFO GenomicsDBImport - ------------------------------------------------------------; 01:22:35.482 INFO GenomicsDBImport - ------------------------------------------------------------; 01:22:35.483 INFO GenomicsDBImport - HTSJDK Version: 2.24.0; 01:22:35.483 INFO GenomicsDBImport - Picard Version: 2.25.0; 01:22:35.483 INFO GenomicsDBImport - Built for Spa",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7598:631,error,error,631,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7598,1,['error'],['error']
Availability,"## Bug Report. ### Affected tool(s) or class(es); GenomicsDBImport / GenotypeGVCFs. ### Affected version(s); 4.3.0.0. ### Description ; When creating a GenomicsDB datastore, the created folder has permissions set to 700 (recursivelly).; As such, when trying to jointly calling genotypes using the GenotypeGVCFs, one encounters error:; ERROR: Couldn't create GenomicsDBFeatureReader. #### Steps to reproduce; - Create a datastore using GenomicsDBImport, e.g. ; gatk ... --genomicsdb-workspace-path IWANNAKILLYOU. - Recursively change access permission to the thus created genomicsdb; chmod 700 -R ./IWANNAKILLYOU. - Run the GenotypeGVCFs; gatk ... --variant gendb://IWANNAKILLYOU. #### Expected behavior; GenotypeGVCFs should initialize the engine normally and start processing the intervals as expected. #### Actual behavior; GenotypeGVCFs intializes the engine and throws out and error; ERROR: Couldn't create GenomicsDBFeatureReader. #### Proposed solution; Mention anywhere in the docs the genomicsdb datastore should be made readable to other users, i.e., change permissions to at least 744 if not do a 766.; Or just make sure the ./IWANNAKILLYOU has proper permissions from the get go. Much obliged",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8233:327,error,error,327,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8233,4,"['ERROR', 'error']","['ERROR', 'error']"
Availability,"## Bug Report. ### Affected tool(s) or class(es); GenomicsDBImport. ### Affected version(s); -4.1.8.1, 4.1.6.0. ### Description ; Two users are running GenomicsDBImport and getting a Duplicate Sample Name Error and both have reported that they do not have duplicate sample names in their map files. @nalinigans @mlathara does this look like a user issue or bug with GenomicsDBImport?. ### First Example; Please see this link for more info: https://gatk.broadinstitute.org/hc/en-us/community/posts/360072797951--GenomicsDBException-Duplicate-sample-name-found-?page=1#community_comment_360012681791. `gatk --java-options ""-Xmx16g -Xms16g"" GenomicsDBImport --batch-size 24 --reader-threads 12 --genomicsdb-update-workspace-path /rooted3/langley/work/home/chuck/rad/SFARI/SSC_hg38/WGS/CPRs_100_proto/DB_chr1 --intervals chr1:118739963-147510543 --verbosity DEBUG -V /rooted3/langley/work/home/chuck/rad/SFARI/SSC_hg38/WGS/phase2_CPRs/SSC00007_CPR/SSC00007.haplotypeCalls.CPR.er.raw.vcf.gz`. ```; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx16g -Xms16g -jar /afs/genomecenter.ucdavis.edu/software/gatk/4.1.6.0/lssc0-linux/gatk-package-4.1.6.0-local.jar GenomicsDBImport --batch-size 24 --reader-threads 12 --genomicsdb-update-workspace-path /rooted3/langley/work/home/chuck/rad/SFARI/SSC_hg38/WGS/CPRs_100_proto/DB_chr1 --intervals chr1:118739963-147510543 --verbosity DEBUG -V /rooted3/langley/work/home/chuck/rad/SFARI/SSC_hg38/WGS/phase2_CPRs/SSC00007_CPR/SSC00007.haplotypeCalls.CPR.er.raw.vcf.gz; 16:16:35.954 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/afs/genomecenter.ucdavis.edu/software/gatk/4.1.6.0/lssc0-linux/gatk-package-4.1.6.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; 16:16:36.003 DEBUG NativeLibraryLoader - Extracting libgkl_compression.so to /tmp/libgkl_compression5245166187604030095.so; Aug 28, 2020 4:16:36 PM s",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6793:205,Error,Error,205,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6793,1,['Error'],['Error']
Availability,"## Bug Report. ### Affected tool(s) or class(es); GenotypeGVCFs. ### Affected version(s); - [x] Latest public release version [version?]; - [x] Latest master branch as of [date of test?]. ### Description ; GenotypeGVCFs won't joint call DRAGEN mitochondrial data because of the DRAGEN somatic output format. We should be able to use the DRAGEN SQ in place of Mutect2's TLOD (see line 279 in GenotypeGVCFsEngine); Note that DRAGEN SQ is a Phred-scaled double. #### Steps to reproduce; DRAGEN somatic GVCF entries from version 3.8.4 look like:; chrM 1 . G <NON_REF> . weak_evidence END=1 GT:AD:DP:SQ:MIN_DP 0/0:112,1579:1691:0:1691. Run GenotypeGVCFs with -V to a file like that (reference GenotypeGVCFsIntegrationTest::testGenotypingForSomaticGVCFs() for more details); Must include `--input-is-somatic` as of now. #### Expected behavior; The task should run to completion, calculating a site quality store using the DRAGEN SQ value. #### Actual behavior; Error from AlleleFrequencyCalculator about not having PLs or GQ.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7840:955,Error,Error,955,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7840,1,['Error'],['Error']
Availability,"## Bug Report. ### Affected tool(s) or class(es); GermlineCNVCaller. ### Affected version(s); - GATK4 4.0.5.1. ### Description ; I'm trying to do a germline CNV calling with 387 exomes samples (I know it's a lot). The CollectReadCounts and DetermineGermlineContigPloidy were successfull. But for the GermlineCNVCaller I got what I think is a Python ""cannot allocate memory"" error. I tried to specify to the JVM a max memory to allocate ``` --java-options ""-Xmx192G"" ``` , but no improvements. The machine I'm working on got 32 threads and 192 Gb RAM. #### Steps to reproduce; I guess try to do a CNV calling with a large cohort. #### Output; ```10:56:25.124 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/tintest/miniconda2/share/gatk4-4.0.5.1-0/gatk-package-4.0.5.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; 10:56:25.342 INFO GermlineCNVCaller - ------------------------------------------------------------; 10:56:25.343 INFO GermlineCNVCaller - The Genome Analysis Toolkit (GATK) v4.0.5.1; 10:56:25.344 INFO GermlineCNVCaller - For support and documentation go to https://software.broadinstitute.org/gatk/; 10:56:25.345 INFO GermlineCNVCaller - Executing as tintest@dahu39 on Linux v4.9.0-6-amd64 amd64; 10:56:25.346 INFO GermlineCNVCaller - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_121-b15; 10:56:25.347 INFO GermlineCNVCaller - Start Date/Time: July 25, 2018 10:56:24 AM CEST; 10:56:25.348 INFO GermlineCNVCaller - ------------------------------------------------------------; 10:56:25.349 INFO GermlineCNVCaller - ------------------------------------------------------------; 10:56:25.350 INFO GermlineCNVCaller - HTSJDK Version: 2.15.1; 10:56:25.351 INFO GermlineCNVCaller - Picard Version: 2.18.2; 10:56:25.352 INFO GermlineCNVCaller - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 10:56:25.353 INFO GermlineCNVCaller - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 10:56:25.354 INFO GermlineCNVCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5053:374,error,error,374,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5053,1,['error'],['error']
Availability,## Bug Report. ### Affected tool(s) or class(es); GetSampleName. ### Affected version(s); 4.2.6.1. ### Description ; when running gatk GetSampleName on a cram file you get the following error:. > A USER ERROR has occurred: A reference file is required when using CRAM files. A reference is specified with the -R command line argument. however the command does work and it does output the sample name without requiring a reference genome. #### Steps to reproduce; gatk GetSampleName -I $input_cram_path -O GetSampleName.txt. #### Expected behavior; no USER ERROR. #### Actual behavior; USER ERROR outputted to STDOUT,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8059:186,error,error,186,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8059,4,"['ERROR', 'error']","['ERROR', 'error']"
Availability,"## Bug Report. ### Affected tool(s) or class(es); GnarlyGenotyper. ### Affected version(s); - [ ] Latest public release version [version?]; - [ ] Latest master branch as of [date of test?]; - [x] 4.2.3 - snapshot -> https://console.cloud.google.com/gcr/images/broad-dsde-methods/US/gatk_subset_dragen_allele_frac@sha256:f5e93bda2278f1c999bd9def027c6851eeb098736b47a93469c524863b46c21f/details. ### Description ; WDL joint genotyping using GnarlyGenotyper after ReblockGVCF (fixed on the snapshot above). #### Steps to reproduce; Joint Genotyper wdl pipeline with ""GatkJointGenotyping.useGnarlyGenotyper"": true , **samples from DRAGEN 3.8+**. #### Expected behavior; Complete the pipeline. #### Actual behavior; Failing with diploid error on Sexual Chromosomes. Hello again everyone.; First of all, thank you @ldgauthier to send us that snapshot docker. It kind of solved reblock problem. As feedback here, I tried with the newest GATK version (4.2.5) as it modified ReblockGVCF, but it didn`t work.; Anyway, I have another issue here...; While I was using only one or few chromosomes, the pipeline with reblock + gnarly was working fine. Once I added all chromosomes I started to get this type of error (GnarlyGenotyper):. ```; A USER ERROR has occurred: Bad input: This tool assumes diploid genotypes, but sample NA18668 has ploidy 1 at position chrY:2789135. or. A USER ERROR has occurred: Bad input: This tool assumes diploid genotypes, but sample NA14734 has ploidy 1 at position chrX:36667858. ```; I checked every failed log, and it's all related to the sexual chromosomes. Any thought/tip about that? ; ps.: From chr1 to chr22 it worked fine!",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7690:732,error,error,732,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7690,4,"['ERROR', 'error']","['ERROR', 'error']"
Availability,"## Bug Report. ### Affected tool(s) or class(es); HaplotypeCaller 4.1 with -ERC GVCF. ### Affected version(s); - [x] Latest public release version [version?]; - [ ] Latest master branch as of [date of test?]. ### Description ; It would appear that variants covered by a spanning deletion are not output with phasing information even when surrounded by phased variants on either side. Since one of the alleles is covered by an upstream deletion phase is known, but the genotype itself is not phased and no phase set is attached. The following is a cut-down example from a gVCF:. ```; chr6 51618169 . GT G,<NON_REF> 948.60 . DP=94 GT:AD:DP:F1R2:F2R1:GQ:PGT:PID:PL:PS:SB 0|1:32,39,0:71:3,4,0:29,35,0:99:0|1:51618169_GT_G:956,0,808,1054,926,1980:51618169:3,29,4,35; chr6 51618170 . T *,G,<NON_REF> 776.01 . DP=92 GT:AD:DP:F1R2:F2R1:GQ:PL:SB 1/2:2,39,30,0:71:1,4,2,0:1,35,28,0:99:3533,786,723,1141,0,956,2837,916,1206,2757:1,1,6,63; chr6 51618171 . G <NON_REF> . . END=51618173 GT:DP:GQ:MIN_DP:PL 0/0:90:99:90:0,120,1800; chr6 51618174 . A G,<NON_REF> 1001.60 . DP=89 GT:AD:DP:F1R2:F2R1:GQ:PGT:PID:PL:PS:SB 0|1:33,41,0:74:3,4,0:30,37,0:99:0|1:51618169_GT_G:1009,0,803,1108,926,2034:51618169:3,30,4,37; ```. You can see that the SNP at 51618170 is flanked by phased variants at 51618169 and 51618174, but is output with unphased genotype and no `PS` (or `PID/PGT`). I'm not entirely sure if this is on purpose for some reason I don't understand, or simply an edge case in the phasing code that's handled incorrectly. #### Steps to reproduce; Run HC on reads with three variants, starting with a deletion, a variant spanned by the deletion and a variant just beyond the deletion. FWIW I've requested permission to share an example case from real data and am awaiting an answer. #### Expected behavior; I think the spanned variant should be output with phasing information, e.g. in the above case I would expect (abbreviated):. ```; chr6 51618169 . GT G,<NON_REF> ... GT:DP:PS 0|1:71:51618169; chr6 51618170 .",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5651:551,down,down,551,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5651,1,['down'],['down']
Availability,"## Bug Report. ### Affected tool(s) or class(es); HaplotypeCaller GVCF mode. ### Affected version(s); GATK 4.1.8.0 . ### Description ; Discussed on the GATK forum: https://gatk.broadinstitute.org/hc/en-us/community/posts/360072760032-HaplotypeCaller-NullPointerException-Error. Command: ; `gatk --java-options ""-Xmx4g"" HaplotypeCaller -R hg19.fa.gz -I test.bam -O test.g.vcf.gz -ERC GVCF`. #### Stack Trace. ```; 17:08:11.229 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/zepengmu/tools/gatk-4.1.8.0/gatk-package-4.1.8.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Aug 27, 2020 5:08:12 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 17:08:12.021 INFO HaplotypeCaller - ------------------------------------------------------------; 17:08:12.028 INFO HaplotypeCaller - The Genome Analysis Toolkit (GATK) v4.1.8.0; 17:08:12.028 INFO HaplotypeCaller - For support and documentation go to https://software.broadinstitute.org/gatk/; 17:08:12.038 INFO HaplotypeCaller - Executing as zepengmu@midway2-0243.rcc.local on Linux v3.10.0-1127.8.2.el7.x86_64 amd64; 17:08:12.038 INFO HaplotypeCaller - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_45-b14; 17:08:12.039 INFO HaplotypeCaller - Start Date/Time: August 27, 2020 5:08:11 PM CDT; 17:08:12.039 INFO HaplotypeCaller - ------------------------------------------------------------; 17:08:12.039 INFO HaplotypeCaller - ------------------------------------------------------------; 17:08:12.039 INFO HaplotypeCaller - HTSJDK Version: 2.22.0; 17:08:12.039 INFO HaplotypeCaller - Picard Version: 2.22.8; 17:08:12.039 INFO HaplotypeCaller - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 17:08:12.040 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 17:08:12.040 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 17:08:12.040 INFO HaplotypeCal",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6783:271,Error,Error,271,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6783,1,['Error'],['Error']
Availability,"## Bug Report. ### Affected tool(s) or class(es); HaplotypeCaller. ### Affected version(s); - [4.3.0.0 ] Latest public release version . ### Description ; I'm attempting to run HaplotypeCaller on Ultima flow based bams with the ""--flow-mode STANDARD"" and ""--likelihood-calculation-engine FlowBasedHMM"" arguments. However, I'm getting the following error ""java.lang.IllegalArgumentException: read must be flow based: 180652-BC94-0022826568 chr1:14585-14703"". The bams were created from fastqs provided directly from Ultima, so they are definitely flow-based. One question I have: how does HaplotypeCaller determine if a read is flow-based or not? Is this specified in the Read Groups?. #### Steps to reproduce; gatk --java-options ""-Xmx4g"" HaplotypeCaller -R hg38.fa --flow-mode STANDARD --likelihood-calculation-engine FlowBasedHMM -I [bam] -O [bam%.BQSRapplied.bam].GATK.vcf.gz. #### Expected behavior; HaplotypeCaller should complete successfully. #### Actual behavior; HaplotypeCaller fails, expecting flow-based reads",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8112:348,error,error,348,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8112,1,['error'],['error']
Availability,"## Bug Report. ### Affected tool(s) or class(es); HaplotypeCaller. ### Affected version(s); - [?] Latest public release version [version?]; - [x] Latest master branch as of Sept 10, 2019. ### Description ; Contamination estimate doesn't appear to be taken into account for reference blocks in GVCFs. #### Steps to reproduce; I'm looking at expected integration test results with uncontaminated (src/test/resources/org/broadinstitute/hellbender/tools/haplotypecaller/expected.CEUTrio.HiSeq.WGS.b37.NA12878.calls.20.10100000-10150000.vcf) vs. 15% contaminated (src/test/resources/org/broadinstitute/hellbender/tools/haplotypecaller/expected.CEUTrio.HiSeq.WGS.b37.NA12878.CONTAMINATED.WITH.HCC1143.NORMALS.15PCT.20.10100000-10150000.postIndelRefConfUpdate.g.vcf). #### Expected behavior; Contaminated calls should have lower depth because the reads are being downsampled (in a biased way) by the contamination fraction. #### Actual behavior; In the expected HC integration test results I'm seeing for 0 contamination; 20 10132770 . A <NON_REF> . . END=10132770 GT:DP:GQ:MIN_DP:PL 0/0:57:99:57:0,120,1800. For 15% contamination:; 20 10132770 . A <NON_REF> . . END=10132770 GT:DP:GQ:MIN_DP:PL 0/0:56:99:56:0,120,1800. The pileup has 55 (I'm not going down the rabbit hole of the bonus reads), so I would expect the contaminated GVCF to have < 55 DP. The variants look good in some places and less good in others. Looking through the code, I don't see anywhere the contamination estimate would be used for reference confidence. I suspect @davidbenjamin has been harboring a desire to update the contamination model anyway.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6152:856,down,downsampled,856,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6152,2,['down'],"['down', 'downsampled']"
Availability,## Bug Report. ### Affected tool(s) or class(es); HaplotypeCaller. ### Affected version(s); - [x] Latest public release version [4.2.0.0]. ### Description ; HaplotypeCaller fails with the following java error:. ```*** Error in `java': munmap_chunk(): invalid pointer: 0x00007f1da5980f00 ***; ======= Backtrace: =========; /lib64/libc.so.6(+0x7f3e4)[0x7f1daaec73e4]; /var/tmp/rwilton/libgkl_smithwaterman14257239252565866950.so(_Z21runSWOnePairBT_avx512iiiiPhS_iiaPcPs+0x338)[0x7f05b3b50f48]; /var/tmp/rwilton/libgkl_smithwaterman14257239252565866950.so(Java_com_intel_gkl_smithwaterman_IntelSmithWaterman_alignNative+0xd8)```. #### Steps to reproduce; Using properly-aligned paired-end reads from GIAB reference sample HG002 (NA24385) with GRCh38.p12. Please see the attached log file for parameterization and stderr log:; [vcall.swbug.log](https://github.com/broadinstitute/gatk/files/6275740/vcall.swbug.log). #### Expected behavior; No error. #### Actual behavior; See above and attached log file. Thank you in advance for having a look at this!. Richard Wilton; Johns Hopkins University,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7187:203,error,error,203,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7187,3,"['Error', 'error']","['Error', 'error']"
Availability,"## Bug Report. ### Affected tool(s) or class(es); HaplotypeCaller. ### Affected version(s); No version information yet, [here is the forum link](https://gatk.broadinstitute.org/hc/en-us/community/posts/360075181171-HaplotypeCaller-Shutting-down-engine-Encountering-a-large-genome) for information. ### Description ; A user wrote into the forum with an error message while HaplotypeCaller was creating the output variant index with an issue of how many bins needed to be created. They have a large genome with long contig(s). We discussed at the GATK Office Hours meeting about adding a check to find this issue so that there is an error or warning before running HaplotypeCaller instead of at the end of the process. A snippet of the error message can be found at the forum post.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6992:240,down,down-engine-Encountering-a-large-genome,240,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6992,4,"['down', 'error']","['down-engine-Encountering-a-large-genome', 'error']"
Availability,"## Bug Report. ### Affected tool(s) or class(es); HaplotypeCaller. ### Affected version(s); gatk-package-4.1.9.0-33-g31df35b-SNAPSHOT-local.jar. ### Description . When run on the 30x 1000 genomes samples, I am getting this error. Not an issue on other crams we have. ```; /restricted/projectnb/genpro/github/gatk/gatk HaplotypeCaller -L chr22 -R /restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa -I cram/HG00096.final.cram -O test.g.vcf.gz; Using GATK jar /rprojectnb2/genpro/github/gatk/build/libs/gatk-package-4.1.9.0-33-g31df35b-SNAPSHOT-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /rprojectnb2/genpro/github/gatk/build/libs/gatk-package-4.1.9.0-33-g31df35b-SNAPSHOT-local.jar HaplotypeCaller -L chr22 -R /restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa -I cram/HG00096.final.cram -O test.g.vcf.gz; 14:39:56.283 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/rprojectnb2/genpro/github/gatk/build/libs/gatk-package-4.1.9.0-33-g31df35b-SNAPSHOT-local.jar!/com/intel/gkl/native/libgkl_compression.so; Feb 10, 2021 2:39:56 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 14:39:56.484 INFO HaplotypeCaller - ------------------------------------------------------------; 14:39:56.484 INFO HaplotypeCaller - The Genome Analysis Toolkit (GATK) v4.1.9.0-33-g31df35b-SNAPSHOT; 14:39:56.484 INFO HaplotypeCaller - For support and documentation go to https://software.broadinstitute.org/gatk/; 14:39:56.485 INFO HaplotypeCaller - Executing as farrell@scc-hadoop.bu.edu on Linux v3.10.0-1160.6.1.el7.x86_64 amd64; 14:39:56.485 INFO HaplotypeCaller - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_121-b13; 14:39:56.485 INFO HaplotypeCaller - Start Date/Time: February 10",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7076:223,error,error,223,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7076,1,['error'],['error']
Availability,"## Bug Report. ### Affected tool(s) or class(es); In the tutorial ""[(How to part I) Sensitively detect copy ratio alterations and allelic segments](https://gatk.broadinstitute.org/hc/en-us/articles/360035531092)"", users are asked to install R components using [install_R_packages.R](https://github.com/broadinstitute/gatk/blob/4.0.1.1/scripts/docker/gatkbase/install_R_packages.R). . ### Affected version(s); Latest public release version [4.5.0.0]. ### Description ; Running the script with `Rscript install_R_packages.R` results in the following error:. `Error in download.file(p, destfile, method, mode = ""wb"", ...) : ; cannot open URL 'http://cran.r-project.org/src/contrib/HMM_1.0.tar.gz'; In addition: Warning message:; In download.file(p, destfile, method, mode = ""wb"", ...) :; cannot open URL 'http://cran.r-project.org/src/contrib/HMM_1.0.tar.gz': HTTP status was '404 Not Found'`. This can be fixed by changing line [35 of install_R_packages.R](https://github.com/broadinstitute/gatk/blob/4.0.1.1/scripts/docker/gatkbase/install_R_packages.R#L35) from `hmmUrl = ""http://cran.r-project.org/src/contrib/HMM_1.0.tar.gz""` to `hmmUrl = ""http://cran.r-project.org/src/contrib/HMM_1.0.1.tar.gz""`. . The script runs as expected once this change is made. #### Steps to reproduce; Run `Rscript install_R_packages.R`. #### Expected behavior; Successfully installs all necessary R packages with the correct versions. #### Actual behavior; Fails to install the 'HMM' package.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8638:548,error,error,548,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8638,4,"['Error', 'down', 'error']","['Error', 'download', 'error']"
Availability,"## Bug Report. ### Affected tool(s) or class(es); IndexFeatureFile. ### Affected version(s); - [x] Latest master branch as of [1/6/2020]. ### Description ; When running IndexFeatureFile on a compressed vcf stored on GCS, tool fails, error message:. ```; A USER ERROR has occurred: Error while trying to create index for dir/file.vcf.gz. Error was: ; htsjdk.tribble.TribbleException.FeatureFileDoesntExist: Unable to open the input file, most ; likely the file doesn't exist., for input source: /dir/file.vcf.gz; ```; When running on an uncompressed vcf on GCS, the tool succeeds. I've traced the issue to `SeekableStreamFactory.getStreamFor` in htsjdk, which gets called from `IndexFactory.initIndexableBlockCompressedStream` (also in htsdjk), and doesn't appear to handle GCS paths correctly.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6348:233,error,error,233,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6348,4,"['ERROR', 'Error', 'error']","['ERROR', 'Error', 'error']"
Availability,"## Bug Report. ### Affected tool(s) or class(es); LeftAlignAndTrimVariants. ### Affected version(s); I've only tested with v4.2.2.0. ### Description ; When running LeftAlignAndTrimVariants the program exited with a message that said:; ""A USER ERROR has occurred: Input files reference and features have incompatible contigs: No overlapping contigs found.; reference contigs = [chr1, chr2, chr3, chr4, chr5, chr6, chr7, chr8, chr9, chr10, chr11, chr12, chr13, chr14, chr15, chr16, chr17, chr18, chr19, chr20, chr21, chr22, chrX, chrY, chrM, chr1_KI270706v1_random, chr1_KI270707v1_random, chr1_KI270708v1_random, chr1_KI270709v1_random, chr1_KI270710v1_random, chr1_KI270711v1_random, chr1_KI270712v1_random, chr1_KI270713v1_random, chr1_KI270714v1_random, chr2_KI270715v1_random, chr2_KI270716v1_random, chr3_GL000221v1_random, chr4_GL000008v2_random, chr5_GL000208v1_random, chr9_KI270717v1_random, chr9_KI270718v1_random, chr9_KI270719v1_random, chr9_KI270720v1_random, chr11_KI270721v1_random, chr14_GL000009v2_random, chr14_GL000225v1_random, chr14_KI270722v1_random, chr14_GL000194v1_random, chr14_KI270723v1_random, chr14_KI270724v1_random, chr14_KI270725v1_random, chr14_KI270726v1_random, chr15_KI270727v1_random, chr16_KI270728v1_random, chr17_GL000205v2_random, chr17_KI270729v1_random, chr17_KI270730v1_random, chr22_KI270731v1_random, chr22_KI270732v1_random, chr22_KI270733v1_random, chr22_KI270734v1_random, chr22_KI270735v1_random, chr22_KI270736v1_random, chr22_KI270737v1_random, chr22_KI270738v1_random, chr22_KI270739v1_random, chrY_KI270740v1_random, chrUn_KI270302v1, chrUn_KI270304v1, chrUn_KI270303v1, chrUn_KI270305v1, chrUn_KI270322v1, chrUn_KI270320v1, chrUn_KI270310v1, chrUn_KI270316v1, chrUn_KI270315v1, chrUn_KI270312v1, chrUn_KI270311v1, chrUn_KI270317v1, chrUn_KI270412v1, chrUn_KI270411v1, chrUn_KI270414v1, chrUn_KI270419v1, chrUn_KI270418v1, chrUn_KI270420v1, chrUn_KI270424v1, chrUn_KI270417v1, chrUn_KI270422v1, chrUn_KI270423v1, chrUn_KI270425v1, chrUn_KI270429v1",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7538:243,ERROR,ERROR,243,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7538,1,['ERROR'],['ERROR']
Availability,"## Bug Report. ### Affected tool(s) or class(es); M2 WDL. ### Description ; If you pass an empty array for artifact_modes (i.e. artifact_modes = []) to the `FilterByOrientationBias` task when `run_orientation_bias_filter` is true, it will create an erroneous command line. #### Expected behavior; The orientation bias filter should not run, or should not do anything. #### Actual behavior; UNCONFIRMED: The tool will crash due to erroneous command line invocation (`... -AM -P ...`) which should yield an error that `""-P""` is not a valid artifact mode.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5025:505,error,error,505,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5025,1,['error'],['error']
Availability,"## Bug Report. ### Affected tool(s) or class(es); MarkDuplicatesSpark . ### Affected version(s); - Latest public release version [4.4.0.0]. ### Description . I am working on 40X human WGS data, running MarkDuplicatesSpark on the computation node of a cluster with 40 cores and 192GB RAM. MarkDuplicatesSpark usually hangs and never finish (even after few days) with log as below:. ```; 11:26:29.511 INFO FileOutputCommitter - File Output Committer Algorithm version is 1; 11:26:29.511 INFO FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false; 11:26:29.512 INFO FileOutputCommitter - File Output Committer Algorithm version is 1; 11:26:29.512 INFO FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false; 11:26:30.738 INFO FileOutputCommitter - File Output Committer Algorithm version is 1; 11:26:30.738 INFO FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false; 11:26:30.738 INFO FileOutputCommitter - File Output Committer Algorithm version is 1; 11:26:30.738 INFO FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false; 11:26:45.830 INFO FileOutputCommitter - File Output Committer Algorithm version is 1; 11:26:45.830 INFO FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false; 11:26:45.831 INFO FileOutputCommitter - File Output Committer Algorithm version is 1; 11:26:45.831 INFO FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false; 11:26:55.475 INFO FileOutputCommitter - File Output Committer Algorithm version is 1; 11:26:55.475 INFO FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folde",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8555:609,failure,failures,609,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8555,2,['failure'],['failures']
Availability,"## Bug Report. ### Affected tool(s) or class(es); Mutect2 `--max-mnp-distance 0`. ### Affected version(s); - [X] Latest public release version [4.2.6.1]. ### Description; Same issue than described here: https://github.com/broadinstitute/gatk/issues/6473; ```; singularity exec docker://broadinstitute/gatk:4.2.6.1 gatk Mutect2 \; -R NC_000962.3.fa \; -I input.bam \; -O output.vcf \; --annotation StrandBiasBySample \; --num-matching-bases-in-dangling-end-to-recover 1 \; --max-reads-per-alignment-start 75 \; --max-mnp-distance 0; ```. And a MNP remains:; ```; grep -P ""NC_000962.3\t761155"" output.vcf; NC_000962.3 761155 . C T,G . . AS_SB_TABLE=0,0|9,9|0,2;DP=20;ECNT=1;MBQ=0,17,23;MFRL=0,311,334;MMQ=60,60,60;MPOS=31,40;POPAF=7.30,7.30;TLOD=44.10,3.01GT:AD:AF:DP:F1R2:F2R1:FAD:SB 0/1/2:0,18,2:0.807,0.143:20:0,5,0:0,4,1:0,15,2:0,0,9,11; ```. #### Expected behavior; ```; grep -P ""NC_000962.3\t761155"" output.vcf; NC_000962.3 761155 . C T [...]; NC_000962.3 761155 . C G [...]; ```. BAM, BAI, and VCF here: [files.zip](https://github.com/broadinstitute/gatk/files/8488204/files.zip). Cheers!",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7782:459,recover,recover,459,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7782,1,['recover'],['recover']
Availability,## Bug Report. ### Affected tool(s) or class(es); Mutect2 in tumour-normal mode. ### Affected version(s); - 4.2.6.1; - 4.2.0.0. ### Description ; Mutect2 crashes with an error:; ```; 16:53:19.984 INFO Mutect2 - Shutting down engine; [25 May 2022 16:53:19 BST] org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2 done. Elapsed time: 0.04 minutes.; Runtime.totalMemory()=1632632832; java.lang.NullPointerException; 	at htsjdk.samtools.ComparableSamRecordIterator.compareTo(ComparableSamRecordIterator.java:68); 	at htsjdk.samtools.ComparableSamRecordIterator.compareTo(ComparableSamRecordIterator.java:36); 	at java.util.PriorityQueue.siftUpComparable(PriorityQueue.java:656); 	at java.util.PriorityQueue.siftUp(PriorityQueue.java:647); 	at java.util.PriorityQueue.offer(PriorityQueue.java:344); 	at htsjdk.samtools.MergingSamRecordIterator.addIfNotEmpty(MergingSamRecordIterator.java:161); 	at htsjdk.samtools.MergingSamRecordIterator.<init>(MergingSamRecordIterator.java:94); 	at org.broadinstitute.hellbender.engine.ReadsPathDataSource.prepareIteratorsForTraversal(ReadsPathDataSource.java:429); 	at org.broadinstitute.hellbender.engine.ReadsPathDataSource.iterator(ReadsPathDataSource.java:336); 	at org.broadinstitute.hellbender.engine.MultiIntervalLocalReadShard.iterator(MultiIntervalLocalReadShard.java:134); 	at org.broadinstitute.hellbender.engine.AssemblyRegionIterator.<init>(AssemblyRegionIterator.java:86); 	at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.processReadShard(AssemblyRegionWalker.java:188); 	at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.traverse(AssemblyRegionWalker.java:173); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1085); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instan,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7872:170,error,error,170,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7872,2,"['down', 'error']","['down', 'error']"
Availability,"## Bug Report. ### Affected tool(s) or class(es); Mutect2, HaplotypeCaller; ./gatk Mutect2 -I scripts/microbial/mtb/samples/D1CLVACXX.1.Solexa-125092.aligned.bam -R scripts/microbial/mtb/Mycobacterium_tuberculosis_H37Rv.fasta -O test.vcf --num-matching-bases-in-dangling-end-to-recover 1 --max-reads-per-alignment-start 75. ### Affected version(s); Latest master branch as of 2/18/21. ### Description ; java.lang.ArrayIndexOutOfBoundsException: Index 25 out of bounds for length 25; 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.readthreading.AbstractReadThreadingGraph.extendDanglingPathAgainstReference(AbstractReadThreadingGraph.java:913); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.readthreading.AbstractReadThreadingGraph.mergeDanglingHead(AbstractReadThreadingGraph.java:646); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.readthreading.AbstractReadThreadingGraph.recoverDanglingHead(AbstractReadThreadingGraph.java:542); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.readthreading.AbstractReadThreadingGraph.recoverDanglingHeads(AbstractReadThreadingGraph.java:447); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.readthreading.ReadThreadingAssembler.getAssemblyResult(ReadThreadingAssembler.java:685); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.readthreading.ReadThreadingAssembler.createGraph(ReadThreadingAssembler.java:664); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.readthreading.ReadThreadingAssembler.assemble(ReadThreadingAssembler.java:549); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.readthreading.ReadThreadingAssembler.assembleKmerGraphsAndHaplotypeCall(ReadThreadingAssembler.java:195); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.readthreading.ReadThreadingAssembler.runLocalAssembly(ReadThreadingAssembler.java:160); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.AssemblyBasedCallerUti",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7085:278,recover,recover,278,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7085,2,['recover'],"['recover', 'recoverDanglingHead']"
Availability,"## Bug Report. ### Affected tool(s) or class(es); Mutect2, multi-sample (2 samples) in Tumor-only mode. ### Affected version(s); - version 4.1.5.0, works fine on 4.1.4.1 and 4.1.4.0. ### Description ; Among my cohort of ~100 samples, mutect2 calling using reference genome hg38+alt+decoy (e.g. as provided in the gatk bundle) fails for one sample at a very specific location (chrUn_KI270748v1:61595-61748), returning an index out of range error. Slightly reducing the range removes the issue (e.g., calling on chrUn_KI270748v1:61596-61748), so it looks like an issue with the estimation of the number of repeats. This is not the most important location, but the error could affect more important calls for other people. The log is the following: ; ```gatk Mutect2 --java-options ""-Xmx15G"" -R /data/references/Homo_sapiens/GATK/hg38/Homo_sapiens_assembly38.fasta -I test1.bam -I test2.bam -O tests.vcf -L test_err.bed ; Using GATK jar /home/alcalan/.conda/mutect2-cd161e2f51ff2240ce6390abc942bbdd/share/gatk4-4.1.5.0-1/gatk-package-4.1.5.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx15G -jar /home/alcalan/.conda/mutect2-cd161e2f51ff2240ce6390abc942bbdd/share/gatk4-4.1.5.0-1/gatk-package-4.1.5.0-local.jar Mutect2 -R /data/references/Homo_sapiens/GATK/hg38/Homo_sapiens_assembly38.fasta -I test1.bam -I test2.bam -O tests.vcf -L test_err.bed; 10:34:24.578 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/alcalan/.conda/mutect2-cd161e2f51ff2240ce6390abc942bbdd/share/gatk4-4.1.5.0-1/gatk-package-4.1.5.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Mar 23, 2020 10:34:24 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 10:34:24.819 INFO Mutect2 - ---------------------------------------------------------",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6516:439,error,error,439,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6516,2,['error'],['error']
Availability,"## Bug Report. ### Affected tool(s) or class(es); Mutect2. ### Affected version(s); - GATK v4.1.8.1. ### Description ; Hi, ; I am new to GATK so I hope this is not something trivial I overlooked. I called somatic variants using `Mutect2` (GATK v4.1.8.1) and wished to filter the results using `FilterMutectCalls`. I am running GATK via a docker container as described here: https://gatk.broadinstitute.org/hc/en-us/articles/360035889991--How-to-Run-GATK-in-a-Docker-container. ``` bash; ./gatk Mutect2 -I:tumor 1st.chr1.bam -I:normal 2nd.chr1.bam -O variants.vcf.gz --min-pruning 8 -R reference.chr1.fa; ```; I repeated this three times, the last time to make sure whether the .vcf.stats is being generated or not. This was a test run using the input filtered for chr1 using `samtools view -b`. I though this was the reason for getting the error message about Contig 2 not being present. ```bash; ...; 18:39:03.207 INFO ProgressMeter - 1:282722440 448.7 1529870 3409.8; 18:39:06.592 INFO VectorLoglessPairHMM - Time spent in setup for JNI call : 19.218222963000002; 18:39:06.592 INFO PairHMM - Total compute time in PairHMM computeLogLikelihoods() : 5376.604473962; 18:39:06.593 INFO SmithWatermanAligner - Total compute time in java Smith-Waterman : 12201.77 sec; 18:39:06.594 INFO Mutect2 - Shutting down engine; [August 25, 2020 6:39:06 PM GMT] org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2 done. Elapsed time: 448.75 minutes.; Runtime.totalMemory()=12349079552; ***********************************************************************. A USER ERROR has occurred: Contig 2 not present in the sequence dictionary [1]. ***********************************************************************; Set the system property GATK_STACKTRACE_ON_USER_EXCEPTION (--java-options '-DGATK_STACKTRACE_ON_USER_EXCEPTION=true') to print the stack trace.; ```; Is there any way of getting around this and generating .vcf.stats without repeating a lengthy variant calling `Mutect2`? Is this a problem introdu",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6768:840,error,error,840,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6768,1,['error'],['error']
Availability,## Bug Report. ### Affected tool(s) or class(es); Mutect2. ### Affected version(s); - [ ] Latest public release version [version?]; - [x] Latest master branch as of 7/18/18. ### Description ; When running Mutect yesterday on Mitochondrial data I got the following error:; ```; java.lang.IllegalArgumentException: Invalid interval. Contig:chrM start:-4 end:65. 	at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:728); 	at org.broadinstitute.hellbender.utils.SimpleInterval.validatePositions(SimpleInterval.java:61); 	at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:37); 	at org.broadinstitute.hellbender.transformers.PalindromeArtifactClipReadTransformer.apply(PalindromeArtifactClipReadTransformer.java:86); 	at org.broadinstitute.hellbender.transformers.PalindromeArtifactClipReadTransformer.apply(PalindromeArtifactClipReadTransformer.java:48); 	at org.broadinstitute.hellbender.transformers.ReadTransformer.lambda$andThen$f85d1091$1(ReadTransformer.java:20); 	at org.broadinstitute.hellbender.transformers.ReadTransformer$$Lambda$107/1786040872.apply(Unknown Source); 	at org.broadinstitute.hellbender.utils.iterators.ReadTransformingIterator.next(ReadTransformingIterator.java:42); 	at org.broadinstitute.hellbender.utils.iterators.ReadTransformingIterator.next(ReadTransformingIterator.java:14); 	at org.broadinstitute.hellbender.utils.downsampling.ReadsDownsamplingIterator.fillDownsampledReadsCache(ReadsDownsamplingIterator.java:69); 	at org.broadinstitute.hellbender.utils.downsampling.ReadsDownsamplingIterator.advanceToNextRead(ReadsDownsamplingIterator.java:55); 	at org.broadinstitute.hellbender.utils.downsampling.ReadsDownsamplingIterator.<init>(ReadsDownsamplingIterator.java:34); 	at org.broadinstitute.hellbender.engine.MultiIntervalLocalReadShard.iterator(MultiIntervalLocalReadShard.java:149); 	at org.broadinstitute.hellbender.engine.AssemblyRegionIterator.<init>(AssemblyRegionIterator.java:109); 	at org.broadinstitute.hellbend,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5036:264,error,error,264,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5036,1,['error'],['error']
Availability,"## Bug Report. ### Affected tool(s) or class(es); Mutect2. ### Affected version(s); - [x] Latest public release version [2.1]; - [x] Latest master branch as of [2018-09-13]. ### Description ; The VCF header line; ""##Mutect Version=x.y""; causes problems for some VCF readers. Each header line is required to be a key-value pair and a space character is not expected in the key. (The VCF specification is not clear on this matter, but I've never encountered a space character in a VCF header key before.); Making VCF files that are easily readable by downstream tools should be in the interest of Mutect2. #### Steps to reproduce; Create a VCF file using Mutect2 and look at the header. #### Expected behavior; output; ""##MutectVersion=2.1"". #### Actual behavior; output; ""##Mutect Version=2.1""",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5183:549,down,downstream,549,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5183,1,['down'],['downstream']
Availability,"## Bug Report. ### Affected tool(s) or class(es); Mutect2. ### Affected version(s); 4.1.8.1. ### Description ; A user is getting a java.lang.NullPointerException when running Mutect2. As discussed at GATK Office Hours 09/28/20, it seems to be an issue where the BAM contigs are not present in the reference sequence dictionary. We discussed an improvement with either the filter for this problem or the error message. Complete stack trace:; ```; Using GATK jar GATK/4.1.8.1-GCCcore-9.3.0-Java-1.8/gatk-package-4.1.8.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx16g -jar /GATK/4.1.8.1-GCCcore-9.3.0-Java-1.8/gatk-package-4.1.8.1-local.jar Mutect2 -R ref/Homo_sapiens_assembly38.fasta -I SRR_MM10_2pass_recal.bam --germline-resource /af-only-gnomad.hg38.vcf.gz --panel-of-normals ref/1000g_pon.hg38.vcf.gz -O SRR_somatic_mutect.vcf.gz; 13:24:08.400 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/GATK/4.1.8.1-GCCcore-9.3.0-Java-1.8/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Sep 25, 2020 1:24:08 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 13:24:08.556 INFO Mutect2 - ------------------------------------------------------------; 13:24:08.557 INFO Mutect2 - The Genome Analysis Toolkit (GATK) v4.1.8.1; 13:24:08.557 INFO Mutect2 - For support and documentation go to https://software.broadinstitute.org/gatk/; 13:24:08.557 INFO Mutect2 - Executing as xxx on Linux v3.10.0-1127.18.2.el7.x86_64 amd64; 13:24:08.557 INFO Mutect2 - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_192-b12; 13:24:08.557 INFO Mutect2 - Start Date/Time: September 25, 2020 1:24:08 PM BST; 13:24:08.557 INFO Mutect2 - ------------------------------------------------------------; 13:24:08.557 INFO Mu",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6851:403,error,error,403,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6851,1,['error'],['error']
Availability,"## Bug Report. ### Affected tool(s) or class(es); Mutect2. ### Affected version(s); GATK version 4.2.5.0, run from the `us.gcr.io/broad-gatk/gatk:4.2.5.0` docker image. ### Description ; Rarely (~0.1%) within exomes that were sequenced at Broad (by GP), we encounter the error message whose stack trace is shown below. This occurs during batch processing, but it is specific to the .CRAM files: running Mutect2 on the same file produces the same error, and running Mutect2 on other files with the same arguments works fine. The files that trigger this error have contents that match the Broad GP-produced .md5 checksum, and they also pass `samtools quickcheck`. #### Steps to reproduce; (The variables are filled in as one might reasonably expect.); ```sh; /gatk/gatk --java-options ""-Xmx${RAM}G"" \; Mutect2 \; --input ${cram} \; --reference ${REFERENCE_FASTA} \; --panel-of-normals ${PON} \; --germline-resource ${GNOMAD} \; --intervals ${INTERVALS} \; --output ${unfiltered}; ```. #### Expected behavior; In all other cases, somatic variant calling proceeds successfully. #### Actual behavior; ```; 00:17:31.944 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/gatk/gatk-package-4.2.5.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; 00:17:32.225 INFO Mutect2 - ------------------------------------------------------------; 00:17:32.226 INFO Mutect2 - The Genome Analysis Toolkit (GATK) v4.2.5.0; 00:17:32.226 INFO Mutect2 - For support and documentation go to https://software.broadinstitute.org/gatk/; 00:17:32.227 INFO Mutect2 - Executing as root@8d398eecd56e on Linux v5.10.90+ amd64; 00:17:32.227 INFO Mutect2 - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_242-8u242-b08-0ubuntu3~18.04-b08; 00:17:32.228 INFO Mutect2 - Start Date/Time: April 5, 2022 12:17:31 AM GMT; 00:17:32.228 INFO Mutect2 - ------------------------------------------------------------; 00:17:32.228 INFO Mutect2 - ------------------------------------------------------------; 00:17:32.229 IN",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7755:271,error,error,271,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7755,3,['error'],['error']
Availability,"## Bug Report. ### Affected tool(s) or class(es); PlotModeledSegments. ### Affected version(s); Confirmed with 4.1.3, but also any version before this that uses optparse. ### Description ; The R package `optparse` is used in the R script `PlotModeledSegments.R` for plotting. The latest version of `optparse` (1.6.4) has been updated to include a check that the short-name of an option is only 1 character. ; See here: https://github.com/trevorld/r-optparse/commit/66acec58645f7401fc365bb769a72751671c2114; The `PlotModeledSegments.R` script in gatk has this line:; ```make_option(c(""--sample_name"", ""-sample_name""), dest=""sample_name"", action=""store""),```; which will now make `optparse` throw an error. #### Steps to reproduce; Install `optparse 1.6.4` and run `gatk PlotModeledSegments`. #### Expected behavior; The Rscript should parse the inputs and run. #### Actual behavior; PlotModeledSegments.R gives an error",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6207:698,error,error,698,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6207,2,['error'],['error']
Availability,"## Bug Report. ### Affected tool(s) or class(es); PrintReads, and probably most other ROD-based tools. ### Affected version(s); GATK v4.1.0. ### Description ; I downloaded a .bam from SRA (https://www.ncbi.nlm.nih.gov/sra/SRX4114173[accn]); and ran gatk PrintReads to extract subregions based on a picard-style interval list. . The bug is that PrintReads ran without any warnings or errors and silently dropped some (though not all) reads that it should have included based on the interval list. It does include these reads if I run it with an interval list that just contains that one interval I'm interested in, but not if I include it among many other intervals. The interval list is sorted based on the .bam's sequence dictionary (by running ; `picard BedToIntervalList --SEQUENCE_DICTIONARY ../SRR7205167.1.bam --SORT -I GRCh38_intervals.bed -O GRCh38_intervals.sorted.list`). . The underlying issue as far as I can tell, is that the .bam reads are sorted, but not in the same order as its sequence dictionary. . This might be related to https://github.com/broadinstitute/gatk/issues/101. #### Expected behavior; I think GATK should fail with an error when this occurs. Otherwise it's easy for users to miss the data loss and end up with incorrect analyses. #### Actual behavior; Silently drops data.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6065:161,down,downloaded,161,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6065,3,"['down', 'error']","['downloaded', 'error', 'errors']"
Availability,"## Bug Report. ### Affected tool(s) or class(es); Reblock | JointGenotype. ### Affected version(s); - [x] Latest public release version [version?]; - [ ] Latest master branch as of [date of test?]. ### Description ; We found a bug while running the latest JointGenotype pipeline (2.0.2). We are working with Dragen data (version 3.6.3); The error:. <details><summary>OPEN ERROR HERE</summary>; <p>. + gatk --java-options -Xms8g GenomicsDBImport --genomicsdb-workspace-path genomicsdb --batch-size 50 -L /tmp/scratch/cromwell-dragen-us-west-2/cromwell-execution/GatkJointGenotyping/7dd18ebe-29ca-47b1-b71a-56b99c362789/call-SplitIntervalList/glob-d928cd0f5fb17b6bd5e635f48c18ccfb/0073-scattered.interval_list --sample-name-map sample_name_map --reader-threads 5 --merge-input-intervals --consolidate; --; Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/tmp/scratch/cromwell-dragen-us-west-2/cromwell-execution/GatkJointGenotyping/7dd18ebe-29ca-47b1-b71a-56b99c362789/call-ImportGVCFs/shard-73/tmp.9a65c1fc; 18:46:55.750 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/gatk/gatk-package-4.2.3.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Dec 01, 2021 6:46:55 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 18:46:55.894 INFO GenomicsDBImport - ------------------------------------------------------------; 18:46:55.894 INFO GenomicsDBImport - The Genome Analysis Toolkit (GATK) v4.2.3.0; 18:46:55.895 INFO GenomicsDBImport - For support and documentation go to https://software.broadinstitute.org/gatk/; 18:46:55.895 INFO GenomicsDBImport - Executing as root@ip-10-10-156-13.us-west-2.compute.internal on Linux v4.14.243-185.433.amzn2.x86_64 amd64; 18:46:55.895 INFO GenomicsDBImport - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_242-8u242-b08-0ubuntu3~18.04-b08; 18:46:55.895 INFO GenomicsDBImport - Start Date/Time: December 1, 2021 6:46:55 PM GMT; 18",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7589:341,error,error,341,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7589,2,"['ERROR', 'error']","['ERROR', 'error']"
Availability,"## Bug Report. ### Affected tool(s) or class(es); ReblockGVCF. ### Affected version(s); - [x ] Latest public release version [version?] _**GATK 4.2.6.1**_; - [ ] Latest master branch as of [date of test?]. ### Description ; We ran ReblockGVCF in 549 samples with the newest GATK (4.2.6.1). 8 of them returned the error similar to the message below . `org.broadinstitute.hellbender.exceptions.GATKException: Exception thrown at chrM:1 [VC /tmp/scratch/prs-sabe-files/GRAR/2031812880_AJ.hard-filtered.gvcf.gz @ chrM:1 Q. of type=SYMBOLIC alleles=[G*, <NON_REF>] attr={END=1} GT=[[2031812880_AJ G*/G* DP 1691 AD 112,1579 {MIN_DP=1691, SQ=0}]] filters=weak_evidence`. and right below, we could find in all of them; `Caused by: org.broadinstitute.hellbender.exceptions.UserException$BadInput: Bad input: Homozygous reference genotypes must contain GQ or PL. Both are missing for hom ref genotype at chrM:1`. All the ""failed samples"" produced a broken output, in this case, missing the chrM (and the alt chr, such as HLA, chr1_alt etc)... It was weird because on WDL it returned as **_Success_** job... We need all the samples with a proper output to run the JointGenotype pipeline with the Reblocked Dragen samples output. #### Steps to reproduce; I'll share with you the chrM:1 from GVCF from a sample with no error; `chrM	1	.	G	<NON_REF>	.	PASS	END=72	GT:AD:DP:GQ:MIN_DP:PL:SPL:ICNT	0/0:2441,2:2443:99:1613:0,120,1800:0,255,255:40,13`. And now, the chrM:1 from a sample with the error; `chrM	1	.	G	<NON_REF>	.	weak_evidence	END=1	GT:AD:DP:SQ:MIN_DP	0/0:112,1579:1691:0:1691`. #### Expected behavior; No broken output. #### Actual behavior; Failing in a few samples, breaking the expected output.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7797:313,error,error,313,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7797,3,['error'],['error']
Availability,"## Bug Report. ### Affected tool(s) or class(es); StructuralVariationDiscoveryPipelineSpark . ### Affected version(s); GATK 4.1.2.0. ### Description . At end of run on a Hadoop cluster, the job aborts.... services=List(),; started=false); 2019-05-14 17:07:05 INFO YarnClientSchedulerBackend:54 - Stopped; 2019-05-14 17:07:05 INFO MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!; 2019-05-14 17:07:05 INFO MemoryStore:54 - MemoryStore cleared; 2019-05-14 17:07:05 INFO BlockManager:54 - BlockManager stopped; 2019-05-14 17:07:05 INFO BlockManagerMaster:54 - BlockManagerMaster stopped; 2019-05-14 17:07:05 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!; 2019-05-14 17:07:05 INFO SparkContext:54 - Successfully stopped SparkContext; 17:07:05.631 INFO StructuralVariationDiscoveryPipelineSpark - Shutting down engine; [May 14, 2019 5:07:05 PM EDT] org.broadinstitute.hellbender.tools.spark.sv.StructuralVariationDiscoveryPipelineSpark done. Elapsed time: 41.02 minutes.; Runtime.totalMemory()=23321378816; java.lang.IllegalArgumentException: Wrong FS: hdfs://scc:-1/project/casa/gcad/adsp.cc/sv/A-ACT-AC000014-BL-NCR-15AD78694.hg38.realign.bqsr.contig-sam-file.sam, expected: hdfs://scc; at org.apache.hadoop.fs.FileSystem.checkPath(FileSystem.java:645); at org.apache.hadoop.hdfs.DistributedFileSystem.getPathName(DistributedFileSystem.java:193); at org.apache.hadoop.hdfs.DistributedFileSystem.access$000(DistributedFileSystem.java:105); at org.apache.hadoop.hdfs.DistributedFileSystem$6.doCall(DistributedFileSystem.java:397); at org.apache.hadoop.hdfs.DistributedFileSystem$6.doCall(DistributedFileSystem.java:393); at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81); at org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:393); at org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:337); at org.apache.hadoop.fs.FileSystem.create",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5942:881,down,down,881,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5942,1,['down'],['down']
Availability,"## Bug Report. ### Affected tool(s) or class(es); TransferReadTags. ### Affected version(s); - [X] Latest public release version [gatk-4.3.0.0]. ### Description ; When traversing the reads in both aligned (target) and unaligned (the one with the desired tag) BAMs an error is thrown complaining about a read `found in the aligned bam is not found in the unmapped bam`. However the reads exists. It looks like the `traverse` function that uses the lexicographic order difference between both query names will find a _negative_ `diff` and assume that the read in the aligned BAM is missing in the uBAM. However, with Illumina read headers it seems almost guaranteed that this is going to be an issue since the y-coord (the last colon-separated field in the header) often has numbers with different number of digits. The lexicographical comparison will fail to adjust when comparing two read names where the length of the read in the target BAM is larger than the length of the read in the uBAM. . This is the `traverse` function that throws the error:; https://github.com/broadinstitute/gatk/blob/2b0a558fdb9fdf654e796d5d69a092e26345583b/src/main/java/org/broadinstitute/hellbender/tools/walkers/qc/TransferReadTags.java#L109-L145 . #### Steps to reproduce; Run `TransferReadTags` with an Illumina sequenced aligned BAM. I can provide dummy files if needed, but should be easy to reproduce. The following example should help illustrate the issue:. ```sh; $ /data/reddylab/software/gatk/gatk-4.3.0.0/gatk TransferReadTags \; --output /data/reddylab/Alex/tmp/TEST_BAM.with_umis.bam \; --read-tags RX \; --unmapped-sam /data/reddylab/Alex/tmp/TEST_BAM.umi.nsorted.ubam \; --input /data/reddylab/Alex/tmp/TEST_BAM.nsorted.bam; ```. Produces the following output:; ```; Using GATK jar /gpfs/fs1/data/reddylab/software/gatk/gatk-4.3.0.0/gatk-package-4.3.0.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8147:267,error,error,267,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8147,1,['error'],['error']
Availability,"## Bug Report. ### Affected tool(s) or class(es); VariantRecalibrator. ### Affected version(s); - [X] Latest public release version [4.5.0.0]; - [ ] Latest master branch as of [date of test?]. ### Description ; As of v1.3.0 the `scales` R package turns the use of deprecated values for the `space` parameter into a hard error, resulting in the VariantRecalibrator R-script terminating with the following message:. > The `space` argument of `pal_gradient_n()` only supports be ""Lab"" as of scales 0.3.0. This parameter is used repeatedly in the generated R-script via. ```R; scale_fill_gradient(high=""green"", low=""red"", space=""rgb""); ```. #### Steps to reproduce. ```shell; $ R --version; R version 4.1.2 (2021-11-01) -- ""Bird Hippie""; $ rm -rf ~/R; $ R; > install.packages(""ggplot2"", repos=""https://cloud.r-project.org/""); > packageVersion(""scales""); [1] ‘1.3.0’; > quit(); $ gatk --version; The Genome Analysis Toolkit (GATK) v4.5.0.0; HTSJDK Version: 4.1.0; Picard Version: 3.1.1; $ gatk VariantRecalibrator [arguments omitted for brevity]; org.broadinstitute.hellbender.utils.R.RScriptExecutorException: ; Rscript exited with 1; Command Line: Rscript -e tempLibDir = '/tmp/Rlib.9339186078473502558';source('/path/to/rscript.r');; Stdout: ; Stderr: Error:; ! The `space` argument of `pal_gradient_n()` only supports be ""Lab"" as; of scales 0.3.0.; Backtrace:; ▆; 1. ├─base::source(""/path/to/rscript.r""); 2. │ ├─base::withVisible(eval(ei, envir)); 3. │ └─base::eval(ei, envir); 4. │ └─base::eval(ei, envir); 5. └─ggplot2::scale_fill_gradient(high = ""green"", low = ""red"", space = ""rgb""); 6. ├─ggplot2::continuous_scale(...); 7. │ └─ggplot2::ggproto(...); 8. │ └─rlang::list2(...); 9. └─scales::seq_gradient_pal(low, high, space); 10. └─scales::pal_gradient_n(c(low, high), space = space); 11. └─lifecycle::deprecate_stop(""0.3.0"", ""pal_gradient_n(space = 'only supports be \""Lab\""')""); 12. └─lifecycle:::deprecate_stop0(msg); 13. └─rlang::cnd_signal(...); Execution halted; $ R; > install.packages(""remot",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8664:320,error,error,320,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8664,1,['error'],['error']
Availability,"## Bug Report. ### Affected tool(s) or class(es); VariantRecalibrator; ; ### Affected version(s); -All versions after 4.1.4.1, including 4.1.9.0. ### Description ; A user on the forum reported an error message that does not give position information when reporting an allele problem in the reference. A similar issue in FilterVariantTranches was previously discussed at #6701 however the fix only changed FilterVariantTranches. We discussed adding a change with VariantRecalibrator that would also fix other GATK tools when this issue comes up. ; Forum Link: https://gatk.broadinstitute.org/hc/en-us/community/posts/360074618292-New-version-of-GATK-leads-to-VariantRecalibrator-error-. #### Command; `~/bin/gatk-4.1.9.0/gatk --java-options -Xms24g VariantRecalibrator -V temp/vartiant_germline/sites.only.vcf.gz -O temp/vartiant_germline/recaliberation.indel.vcf --tranches-file temp/vartiant_germline/tranches.indel.txt --trust-all-polymorphic -tranche 100.0 -tranche 99.95 -tranche 99.9 -tranche 99.5 -tranche 99.0 -tranche 97.0 -tranche 96.0 -tranche 95.0 -tranche 94.0 -tranche 93.5 -tranche 93.0 -tranche 92.0 -tranche 91.0 -tranche 90.0 -an DP -an FS -an MQRankSum -an QD -an ReadPosRankSum -an SOR -mode INDEL --max-gaussians 4 -resource:mills,known=false,training=true,truth=true,prior=12 ~/db/mutect2_support/b37/Mills_and_1000G_gold_standard.indels.b37.sites.vcf.gz -resource:dbsnp,known=true,training=false,truth=false,prior=2 ~/db/mutect2_support/b37/hg19_v0_dbsnp_138.b37.vcf.gz -resource:axiomPoly,known=false,training=true,truth=false,prior=10 ~/db/mutect2_support/b37/Axiom_Exome_Plus.genotypes.all_populations.poly.b37.vcf.gz --use-allele-specific-annotations`. #### Error Message; ```; Using GATK jar ~/bin/gatk-4.1.9.0/gatk-package-4.1.9.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xms24g -jar ~/bin/gatk-4.1.9.0/gatk-package-4.1.9.0-local.ja",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6963:196,error,error,196,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6963,2,['error'],['error']
Availability,"## Bug Report. ### Affected tool(s) or class(es); VariantRecalibrator; Resource Bundle. ### Affected version(s); Resource Bundle downloaded 21. July 2020 (ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/ OR https://console.cloud.google.com/storage/browser/genomics-public-data/resources/broad/hg38/v0;tab=objects?prefix=). ### Description ; The available dataset lack information for FS, SOR etc. but this parameter are necessary for the best practice workflow of the VariantRecalibrator and cannot be added with the VariantAnnotator as the individual information is not included. #### Steps to reproduce; Run VariantRecalibrator with the publicly available reference files. And the recommended parameter settings. gatk --java-options ""-Xmx24g -Xms24g"" VariantRecalibrator \; -V ${inputfile} \; --trust-all-polymorphic \; -tranche 100.0 -tranche 99.95 -tranche 99.9 -tranche 99.5 -tranche 99.0 -tranche 97.0 -tranche 96.0 -tranche 95.0 -tranche 94.0 -tranche 93.5 -tranche 93.0 -tranche 92.0 -tranche 91.0 -tranche 90.0 \; -an FS -an ReadPosRankSum -an MQRankSum -an QD -an SOR \; -mode INDEL \; --max-gaussians 4 \; -resource:mills,known=false,training=true,truth=true,prior=12 ${gatk_ref}Mills_and_1000G_gold_standard.indels.hg38.vcf.gz \; -resource:axiomPoly,known=false,training=true,truth=false,prior=10 ${gatk_ref}Axiom_Exome_Plus.genotypes.all_populations.poly.hg38.vcf.gz \; -resource:dbsnp,known=true,training=false,truth=false,prior=2 ${gatk_ref}/Homo_sapiens_assembly38.dbsnp138.vcf \; -O ${fileprefix}_indels.recal \; --tranches-file ${fileprefix}_indels.tranches. #### Expected behavior; Calculation of VQSLOD tranches. #### Actual behavior; A USER ERROR has occurred: Bad input: Values for FS annotation not detected for ANY training variant in the input callset. VariantAnnotator may be used to add these annotations.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6715:129,down,downloaded,129,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6715,4,"['ERROR', 'avail', 'down']","['ERROR', 'available', 'downloaded']"
Availability,"## Bug Report. ### Affected tool(s) or class(es); _FilterAlignmentArtifacts_. ### Affected version(s); - [x] Latest public release version [4.1.4.1]. ### Description ; FilterAlignmentArtifacts consistently errors out with segmentation faults or IllegalArgumentExceptions. I've attached the log files for each of these errors below.; [invalid_interval.log](https://github.com/broadinstitute/gatk/files/4017907/invalid_interval.log); [seg_fault.log](https://github.com/broadinstitute/gatk/files/4017908/seg_fault.log). #### Steps to reproduce; The command to reproduce both errors is the same, and I have attached it below.; [realignment_filter.txt](https://github.com/broadinstitute/gatk/files/4017918/realignment_filter.txt); The BWA mem index I'm using is hg38, however the BAM that I am realigning from is hg19; thus, the reference argument is the hg19 fasta. I am happy to transfer zip files containing the other files need to reproduce this. Just let me know where to send them. #### Expected behavior; _FilterAlignmentArtifacts_. #### Actual behavior; _Errors_",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6344:206,error,errors,206,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6344,4,"['error', 'fault']","['errors', 'faults']"
Availability,"## Bug Report. ### Affected tool(s) or class(es); _FilterMutectCalls_. ### Affected version(s); - gatk-4.1.0.0 (_latest_). ### Description . Hi,. I am using _Mutect2_ (v4.1.0.0) and similar to a previous bug reported on `AF=.`, _FilterMutectCalls_ seems to complain about MPOS fields having a value of `.`. No intermediate processing was done between _Mutect2_ and _FilterMutectCalls_. Below the error stack trace :. ```; 17:13:28.491 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/data-ddn/home/anthony/sbx/mutect2/work/conda/gatk4-mutect2-nf-bcf605d6af4c0524a368d3d105898641/share/gatk4-4.1.0.0-0/gatk-package-4.1.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; 17:13:30.503 INFO FilterMutectCalls - ------------------------------------------------------------; 17:13:30.503 INFO FilterMutectCalls - The Genome Analysis Toolkit (GATK) v4.1.0.0; 17:13:30.504 INFO FilterMutectCalls - For support and documentation go to https://software.broadinstitute.org/gatk/; 17:13:30.504 INFO FilterMutectCalls - Executing as anthony@node063 on Linux v2.6.32-220.el6.x86_64 amd64; 17:13:30.504 INFO FilterMutectCalls - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_152-release-1056-b12; 17:13:30.504 INFO FilterMutectCalls - Start Date/Time: February 17, 2019 5:13:28 PM CET; 17:13:30.504 INFO FilterMutectCalls - ------------------------------------------------------------; 17:13:30.505 INFO FilterMutectCalls - ------------------------------------------------------------; 17:13:30.505 INFO FilterMutectCalls - HTSJDK Version: 2.18.2; 17:13:30.505 INFO FilterMutectCalls - Picard Version: 2.18.25; 17:13:30.505 INFO FilterMutectCalls - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 17:13:30.505 INFO FilterMutectCalls - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 17:13:30.505 INFO FilterMutectCalls - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 17:13:30.506 INFO FilterMutectCalls - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 17:13:30.506 INF",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5684:396,error,error,396,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5684,1,['error'],['error']
Availability,"## Bug Report. ### Affected tool(s) or class(es); _Funcotator_. ### Affected version(s); - [ ] Latest public release version GATK 4.1.9.0 with data version funcotator_dataSources.v1.7.20200521g. ### Description . #### Steps to reproduce. I'm trying to run GATK Funcotator using the funcotator_dataSources.v1.7.20200521g data download. The command line that I'm using is:; ```; gatk Funcotator \; --variant cohort.vcf.gz \; --reference GRCh38.d1.vd1/GRCh38.d1.vd1.fa \; --ref-version hg38 \; --data-sources-path funcotator_dataSources.v1.7.20200521g \; --output cohort.funcotator.vcf.gz \; --output-file-format VCF; ```. If I run that command line without the `gnomad_*.tar.gz`'s expanded, it works fine and annotates my `cohort.vcf.gz` into `cohort.funcotator.vcf.gz`. . Following the directions at [Funcotator Information and Tutorial - 1.1.2.2.1: enabling gnomAD](https://gatk.broadinstitute.org/hc/en-us/articles/360035889931-Funcotator-Information-and-Tutorial#1.1.2.2.1), if I expand both `gnomAD_exome.tar.gz` and `gnomAD_genome.tar.gz`, funcotator dies at startup with a `400 Bad Request` error. This also happens if I expand either one of the `gnomad_*.tar.gz` files individually. . #### Expected behavior; Funcotator annotates my VCF and includes gnomAD annotations in the output VCF. . #### Actual behavior. Crash with 400 Bad Request:. ```; Using GATK jar /opt/conda/share/gatk4-4.1.9.0-0/gatk-package-4.1.9.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /opt/conda/share/gatk4-4.1.9.0-0/gatk-package-4.1.9.0-local.jar Funcotator --variant cohort.vcf.gz --reference GRCh38.d1.vd1/GRCh38.d1.vd1.fa --ref-version hg38 --data-sources-path funcotator_dataSources.v1.7.20200521g --output cohort.funcotator.vcf.gz --output-file-format VCF; 14:24:33.589 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/opt/conda/share/gatk4-4.1.9.0-",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6926:325,down,download,325,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6926,1,['down'],['download']
Availability,"## Bug Report. ### Affected tool(s) or class(es); _Funcotator_. ### Affected version(s); - [x] Latest public release version [version v4.1.4.1]; - [ ] Latest master branch as of [date of test?]. ### Description . Hi @jonn-smith , I saw you often address Funcotator related issues, so I thought this might be of interest to you. I ran funcotator on a vcf created by mutect2 from RNA-seq data. The vcf includes a large deletion in the GABARAP gene, and when Funcotator processes this annotation, it dies with an error about a query that extends past the end of a contig:. > htsjdk.samtools.SAMException: Query asks for data past end of contig. Query contig ENST00000571253.1|ENS; G00000170296.9|OTTHUMG00000102156.3|OTTHUMT00000440082.2|AC120057.8-003|GABARAP|837|UTR5:1-753|CDS:754-8; 37| start:1 stop:895 contigLength:837; at org.broadinstitute.hellbender.utils.fasta.CachingIndexedFastaSequenceFile.getSubsequenceAt(Ca; chingIndexedFastaSequenceFile.java:316); at org.broadinstitute.hellbender.engine.ReferenceFileSource.queryAndPrefetch(ReferenceFileSource; .java:78); at org.broadinstitute.hellbender.engine.ReferenceDataSource.queryAndPrefetch(ReferenceDataSource; .java:64); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.; getFivePrimeUtrSequenceFromTranscriptFasta(GencodeFuncotationFactory.java:744); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createUtrFuncotation(GencodeFuncotationFactory.java:1568); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createGencodeFuncotationOnSingleTranscript(GencodeFuncotationFactory.java:983); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsHelper(GencodeFuncotationFactory.java:805); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsHelper(GencodeFuncotationFactory.java:78",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6345:510,error,error,510,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6345,1,['error'],['error']
Availability,"## Bug Report. ### Affected tool(s) or class(es); _Mutect2_. ### Affected version(s); - GATK 4.1.4.1. ### Description ; When running Mutect2 (from GATK v4.1.4.1) using the following command:. `gatk Mutect2 -R [path to grch37-1kg.fa] -I testcase.bam -O pon.vcf`. to create a PoN on NovaSeq WGS-data processed through the best practice pipeline (with the BQSR-steps run through the Spark-enabled tools, and bwa mem with -Y flag) I get the following error in multiple regions:. [Stacktrace](https://www.dropbox.com/s/d2n5zflj9u11oj8/stacktrace.png?dl=0). AFAIK this is related to the new code path introduced in #6240 and seem to be triggered when there are more than 2 reads supporting a fragment but all of them are either duplicate reads or supplemntary/secondary alignments. Any input is greatly appreciated. I guess a temporary fix is to use the --independent-mates flag (although haven't tried it yet -- how much worse mutation calling performance do one incur when using that flag?). #### Steps to reproduce; Use the following small test case .bam-file as input to the command specified above:. [Testcase](https://www.dropbox.com/s/hilcj3aj0jnjdmh/testcase.bam?dl=0). #### Expected behavior; Completion of mutect2 without Exception. #### Actual behavior; Early termination of the mutect2 run due to raising an exception when trying to create a fragment with no read data to back it up. ----",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6310:447,error,error,447,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6310,1,['error'],['error']
Availability,"## Bug Report. ### Affected tool(s) or class(es); _ReadsPipelineSpark_ with --spark-runner SPARK. ### Affected version(s); - 4.1.4. ### Description ; @tomwhite I was asked to tag you, please let me know if you think anyone else should look at this. This issue is created from a forum bug report (https://gatkforums.broadinstitute.org/gatk/discussion/24511/error-in-readspipelinespark-version-4-1-4/p1). More information can be requested if necessary. Stack trace copied below:; > A USER ERROR has occurred: Couldn't write file hdfs://cloudera08/gatk-test2/WES2019-022_S4_out.vcf because writing failed with exception concat: target file /gatk-test2/WES2019-022_S4_out.vcf.parts/output is empty; > at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.concatInternal(FSNamesystem.java:2303); > at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.concatInt(FSNamesystem.java:2257); > at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.concat(FSNamesystem.java:2219); > at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.concat(NameNodeRpcServer.java:829); > at org.apache.hadoop.hdfs.server.namenode.AuthorizationProviderProxyClientProtocol.concat(AuthorizationProviderProxyClientProtocol.java:285); > at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.concat(ClientNamenodeProtocolServerSideTranslatorPB.java:580); > at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java); > at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:617); > at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1073); > at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2278); > at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2274); > at java.security.AccessController.doPrivileged(Native Method); > at javax.security.auth.Subject.doAs(Subject.java:422); > at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroup",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6218:356,error,error-in-readspipelinespark-version-,356,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6218,2,"['ERROR', 'error']","['ERROR', 'error-in-readspipelinespark-version-']"
Availability,"## Bug Report. ### Affected tool(s) or class(es); _Tool/class name(s), special parameters?_. ### Affected version(s); - [x] Latest public release version 4.1.7.0. ### Description . The following error message is output:. A USER ERROR has occurred: Bad input: Is the input a file of segment variant contexts? Variant context does not represent a copy number segment: [VC null @ 6:4130448-4130544 Q. of type=SYMBOLIC alleles=[C*, <DEL>] attr={END=4130544, Num_Probes=1, Segment_Call=-, Segment_Mean=-30.018694} GT=[] filters=. The local info in the segment file is:; 5 176563624 180687750 618 -0.053122 0; 6 203183 4128317 205 0.046724 0; 6 4130448 4130544 1 -30.018694 -; 6 4130545 6168103 42 -0.085445 0; 6 6174562 17463556 490 0.022415 0; 6 17493361 25510885 347 0.080520 0. This is a bad error message. The minimum size for a segment to be processed is 150 bases and that variant is only 96 bases, so it's failing that validation. #### Expected behavior; Should process variant without producing error. Hat tip: @jonn-smith for figuring out the problem.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6575:195,error,error,195,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6575,4,"['ERROR', 'error']","['ERROR', 'error']"
Availability,"## Bug Report. ### Affected tool(s) or class(es); _Tool/class name(s), special parameters?_. ### Affected version(s); - [x] Latest public release version 4.2.2.0. ### Description . Running apt-get inside docker image fails. #### Steps to reproduce. (base) fleharty@wm3b9-dfa docker % docker run -it broadinstitute/gatk:4.2.2.0; Unable to find image 'broadinstitute/gatk:4.2.2.0' locally; 4.2.2.0: Pulling from broadinstitute/gatk; a7fe112a8303: Already exists ; Digest: sha256:32175c3c7c1fb9f5bd6650183c9c5cf26fb822dddb0cad0123d48c33124b6065; Status: Downloaded newer image for broadinstitute/gatk:4.2.2.0; (gatk) root@bc90fdaf700c:/gatk# ; (gatk) root@bc90fdaf700c:/gatk# ; (gatk) root@bc90fdaf700c:/gatk# apt-get update; Get:1 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]; Get:2 http://archive.ubuntu.com/ubuntu bionic InRelease [242 kB] ; Get:3 http://security.ubuntu.com/ubuntu bionic-security/multiverse amd64 Packages [26.7 kB] ; Get:4 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [543 kB] ; Get:5 http://packages.cloud.google.com/apt cloud-sdk-bionic InRelease [6786 B] ; Get:6 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1426 kB] ; Err:5 http://packages.cloud.google.com/apt cloud-sdk-bionic InRelease ; The following signatures couldn't be verified because the public key is not available: NO_PUBKEY FEEA9169307EA071 NO_PUBKEY 8B57C5C2836F4BEB; Get:7 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2295 kB] ; Get:8 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB] ; Get:9 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB] ; Get:10 http://archive.ubuntu.com/ubuntu bionic/restricted amd64 Packages [13.5 kB] ; Get:11 http://archive.ubuntu.com/ubuntu bionic/multiverse amd64 Packages [186 kB]; Get:12 http://archive.ubuntu.com/ubuntu bionic/universe amd64 Packages [11.3 MB] ; Get:13 http://archive.ubuntu.com/ubuntu bionic/main amd64 Packages ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7447:551,Down,Downloaded,551,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7447,1,['Down'],['Downloaded']
Availability,"## Bug Report. ### Affected tool(s) or class(es); _Tool/class name(s), special parameters?_. ### Affected version(s); - any version with basename(basename()) function call. (e.g. latest version on master). ### Description ; ```; ""Failed to evaluate 'output_basename' (reason 1 of 1): Evaluating basename(basename(tumor_reads, "".bam""), "".cram"") failed: Failed to interpret 'CDS-00rz9N.hg38' as a file path input for basename (reason 1 of 1): java.lang.IllegalArgumentException: Could not build the path ""CDS-00rz9N.hg38"". It may refer to a filesystem not supported by this instance of Cromwell. Supported filesystems are: HTTP, Google Cloud Storage, DRS. Failures: ; HTTP: CDS-00rz9N.hg38 does not have an http or https scheme (IllegalArgumentException); Google Cloud Storage: Path ""CDS-00rz9N.hg38"" does not have a gcs scheme (IllegalArgumentException); DRS: CDS-00rz9N.hg38 does not have a drs scheme. (IllegalArgumentException); Please refer to the documentation for more information on how to configure filesystems: http://cromwell.readthedocs.io/en/develop/backends/HPC/#filesystems""; ```; #### Steps to reproduce; Just run the mutect2.wdl on terra it seems create the issue (maybe using a bam filepath with a name in ""gs://[path]/[NAME].hg38.bam"". #### Expected behavior; I think using basename(basename( is not working with the new version of terra, I would expect another solution with an if on the name end or something.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7485:654,Failure,Failures,654,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7485,1,['Failure'],['Failures']
Availability,"## Bug Report. ### Affected tool(s) or class(es); _Tool/class name(s), special parameters?_. /gatk/src/main/java/org/broadinstitute/hellbender/tools/walkers/contamination/CalculateContamination.java; /gatk/src/main/java/org/broadinstitute/hellbender/tools/walkers/contamination/ContaminationModel.java. ### Affected version(s); - [x] Latest public release version - v4.2.0.0 (also detected on previous versions) ; - [x] Latest master branch as of 03/30/2021. ### Description ; **ContaminationModel**; **Problem:**; Where errorDepth is greater than oppositeDepth, the output contamination is reported as **’0’ contamination** , which can be misinterpreted by the end user. calculateContaminationFromHoms receives the list of pileups PileupSummary; It iterates from 0.4 INITIAL_MAF_THRESHOLD down to zero. In each iteration pileups are selected using multiple, different strategies.; When the stdError exit condition is met (i.e., stdError < (contamination* MIN_RELATIVE_ERROR +MIN_ABSOLUTE_ERROR)), it reports out the contamination and stdError values. The issue is that this stdError exit condition is also met when contamination = 0, because in this case, stdError is also equal to 0, and thus is always less than the minimum value for (contamination * MIN_RELATIVE_ERROR [0.2] + MIN_ABSOLUTE_ERROR [0.001]), which cannot be less than 0.001. . final double stdError = homs.isEmpty() ? 1 : Math.sqrt(homs.stream().mapToDouble(ps -> {; final double d = ps.getTotalCount();; final double f = 1 - oppositeAlleleFrequency.applyAsDouble(ps);; return (1 - f) * d * contamination * ((1 - contamination) + f * d * contamination);; }).sum()) / totalDepthWeightedByOppositeFrequency;. ** return (1 - f) * d * contamination * ((1 - contamination) + f * d * contamination);**. Root cause:; At the first MAF iteration where errorDepth is greater than oppositeDepth, contamination is set to “0” (according to the code logic shown below), the function exits the iteration process, and no further MAF thresholds are t",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7177:521,error,errorDepth,521,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7177,2,"['down', 'error']","['down', 'errorDepth']"
Availability,"## Bug Report. ### Affected tool(s) or class(es); _Tool/class name(s), special parameters?_. `SortSamSpark --sort-order coordinate`. ### Affected version(s); - [ ] Latest public release version [version?]; - [ ] Latest master branch as of [date of test?]. `4.4.0.0`. ### Description ; _Describe the problem below. Provide **screenshots** , **stacktrace** , **logs** where appropriate._. An error occurs when using SortSamSpark to sort the large BAM file that contain long reads only (90x human wgs, min. read length>10kbp).; However, if the large BAM file contains short reads, it executes normally. #### Steps to reproduce; _Tell us how to reproduce this issue. If possible, include command lines that reproduce the problem. (The support team may follow up to ask you to upload data to reproduce the issue.)_. ```shell; sysctl -w vm.max_map_count=2147483642; gatk SortSamSpark \; --input HG002-NA24385-GM24385.bam \; --output HG002-NA24385-GM24385.sorted.bam \; --sort-order coordinate \; --java-options ""-XX:+UnlockDiagnosticVMOptions -XX:GCLockerRetryAllocationCount=96 -XX:+UseNUMA -XX:+UseZGC -Xmx1794G"" \; --tmp-dir . \; -- \; --spark-runner LOCAL --spark-master local[96] --conf spark.local.dir=./tmp --conf spark.port.maxRetries=61495; ```. #### Expected behavior; _Tell us what should happen_. Output a sorted BAM file. #### Actual behavior; _Tell us what happens instead_. `java.lang.OutOfMemoryError: Required array length ? is too large`. The last lines of the log file.; ```; 11:00:42.884 INFO BlockManagerInfo - Removed taskresult_15758 on 172.20.19.130:43279 in memory (size: 10.5 MiB, free: 1076.2 GiB); 11:00:42.888 INFO TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool; 11:00:42.902 INFO DAGScheduler - ResultStage 0 (sortByKey at SparkUtils.java:165) finished in 1652.742 s; 11:00:42.915 INFO DAGScheduler - Job 0 is finished. Cancelling potential speculative or zombie tasks for this job; 11:00:42.916 INFO TaskSchedulerImpl - Killing all running ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8949:390,error,error,390,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8949,1,['error'],['error']
Availability,"## Bug Report. ### Affected tool(s) or class(es); _Tool/class name(s), special parameters?_; CalibrateDragstrModel; ### Affected version(s); - [ ] Latest public release version [gatk/4.2.0.0]. ### Description . gatk 4.2.0.0 CalibrateDragstrModel produces the following stacktrace.... ```; 13:55:31.187 INFO CalibrateDragstrModel - Initializing engine; 13:55:33.395 INFO CalibrateDragstrModel - Done initializing engine; 13:55:33.396 INFO ProgressMeter - Starting traversal; 13:55:33.396 INFO ProgressMeter - Current Locus Elapsed Minutes Records Processed Records/Minute; 13:55:42.364 INFO CalibrateDragstrModel - Shutting down engine; [April 4, 2021 1:55:42 PM EDT] org.broadinstitute.hellbender.tools.dragstr.CalibrateDragstrModel done. Elapsed time: 0.19 minutes.; Runtime.totalMemory()=2384986112; java.lang.IllegalArgumentException: Start cannot exceed end.; at htsjdk.samtools.util.IntervalTree.put(IntervalTree.java:74); at htsjdk.samtools.util.IntervalTree.merge(IntervalTree.java:137); at org.broadinstitute.hellbender.tools.dragstr.CalibrateDragstrModel$ShardReadBuffer.add(CalibrateDragstrModel.java:949); at org.broadinstitute.hellbender.tools.dragstr.CalibrateDragstrModel$1.tryAdvance(CalibrateDragstrModel.java:798); at java.util.Spliterator.forEachRemaining(Spliterator.java:326); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); at org.broadinstitute.hellbender.tools.dragstr.CalibrateDragstrModel.collectCaseStatsSequencial(CalibrateDragstrModel.java:459); at org.broadinstitute.hellbender.tools.dragstr.CalibrateDragstrModel.traverse(CalibrateDragstrModel.j",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7182:623,down,down,623,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7182,1,['down'],['down']
Availability,"## Bug Report. ### Affected tool(s) or class(es); _VariantEval, -O, --output_. ### Affected version(s); - [X] Latest public release version [4.1.0.0]; - [ ] Latest master branch as of [date of test?]. ### Description ; Program starts then terminates with error:; `***********************************************************************`; `A USER ERROR has occurred: Couldn't read file file:///[.....]/X034.eval.grp. Error was: It doesn't exist.`; `***********************************************************************`. Note: The error is not thrown, and VariantEval completes successfully, if a zero-byte file with the name passed with the `-o` or `--output` arguments is created before executing VariantEval; For this example: `touch X034.eval.grp`. #### Steps to reproduce; Command line:; `gatk VariantEval -R $ref -L autosomes.list --eval W034.raw.annotated.vcf.gz --dbsnp dbsnp.vcf.gz -O X034.eval.grp`. #### Expected behavior; Expect the program to create its own output file (as other GATK tools do). #### Actual behavior; Terminates with error (above). ----",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5674:255,error,error,255,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5674,5,"['ERROR', 'Error', 'error']","['ERROR', 'Error', 'error']"
Availability,"## Bug Report. ### Affected tool(s) or class(es); `Funcotator`. ### Affected version(s); GATK 4.1.0.0 release. ### Description . Functotator MAF output does not properly show genotypes from somatic multi-tumor VCF files produced using M2. It looks like only genotypes from the first tumor sample are shown, but there are no errors or messages to point the user to this fact. Only a single `tumor_sample` and `normal_sample` are reported in the MAF header:. ```; ##normal_sample=xxx; ##source=FilterMutectCalls; ##source=Funcotator; ##source=Mutect2; ##tumor_sample=xxx; ```. Conversely, instructing `Funcotator` to output VCF format properly adds the annotation to the INFO field while retaining the FORMAT-level genotypes works well. However, in this case the VCF header also only lists a single tumor_sample (take note: this is a separate bug, though mostly aesthetics) despite all tumor genotypes being included. #### Steps to reproduce; Run Funcotator with output format set to MAF on any multi-tumor VCF file. #### Expected behavior; Either one of:; 1. `Funcotator` should return an error when trying to process multi-tumor VCF to MAF output; 2. `Funcotator` MAF should output multiple lines per funcotation for each tumor sample, indicating the comparison in the `Tumor_Sample_Barcode` and `Normal_Sample_Barcode` columns.; 3. `Funcotator` should not output genotype information when processing multi-tumor VCF to MAF (this could also be an additional Funcotator parameter that must be switched on when requesting MAF output). #### Actual behavior; Funcotator runs without errors or warnings and the output file is missing genotypes for the other tumor samples",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5687:324,error,errors,324,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5687,3,['error'],"['error', 'errors']"
Availability,"## Bug Report. ### Affected tool(s) or class(es); `Funcotator`. ### Affected version(s); GATK 4.1.0.0 release. ### Description ; Funcotator returns a `NullPointerException` when trying to output compressed VCF:. ```; 15:35:26.085 INFO Funcotator - Creating a VCF file for output: XXXX; 15:35:26.125 INFO ProgressMeter - Starting traversal; 15:35:26.125 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; log4j:WARN No appenders could be found for logger (org.broadinstitute.hellbender.tools.funcotator.dataSources.vcf.VcfFuncotationFactory).; log4j:WARN Please initialize the log4j system properly.; log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.; 15:35:26.328 INFO Funcotator - Shutting down engine; [February 15, 2019 3:35:26 PM EST] org.broadinstitute.hellbender.tools.funcotator.Funcotator done. Elapsed time: 0.18 minutes.; Runtime.totalMemory()=3391094784; java.lang.NullPointerException; at htsjdk.tribble.index.tabix.TabixIndexCreator.finalizeFeature(TabixIndexCreator.java:106); at htsjdk.tribble.index.tabix.TabixIndexCreator.finalizeIndex(TabixIndexCreator.java:129); at htsjdk.variant.variantcontext.writer.IndexingVariantContextWriter.close(IndexingVariantContextWriter.java:177); at htsjdk.variant.variantcontext.writer.VCFWriter.close(VCFWriter.java:231); at org.broadinstitute.hellbender.tools.funcotator.vcfOutput.VcfOutputRenderer.close(VcfOutputRenderer.java:137); at org.broadinstitute.hellbender.tools.funcotator.Funcotator.closeTool(Funcotator.java:883); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:970); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:138); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); at org.broadinstitute.hellbender.Main.runCommandLineProgra",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5683:761,down,down,761,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5683,1,['down'],['down']
Availability,"## Bug Report. ### Affected tool(s) or class(es); `GenomicsDBImport` (writing to a GCS bucket). ### Affected version(s). `4.2.3.0`. ### Description . Running `GenomicsDBImport` on 264 whole genome GVCFs, each of ~1GB size (called with HaplotypeCaller and blocked with only one bin threshold `-GQB 20`). Doing that on 50 genome intervals generated by `SplitIntervals`, so 50 `GenomicsDBImport` jobs write 50 DBs to a GCS bucket. 49 of them worked successfully, however one have failed with the following error:. ```sh; [TileDB::FileSystem] Error: (write_to_file) GCS: Only the last of the uploadable parts can be less than 5MB, try increasing TILEDB_UPLOAD_BUFFER_SIZE to at least 5MB ; ```. #### Steps to reproduce. Can't produce a small reproducible examples because it only happens with the full dataset. However, below is the command that I ran. . ```sh; gatk --java-options -Xms16g GenomicsDBImport \; --genomicsdb-workspace-path gs://cpg-seqr-main-analysis/seqr_loader/v0/genomicsdbs/interval_0_outof_50 \; --batch-size 50 -L 0000-scattered.interval_list \; --sample-name-map sample_map.csv \; --reader-threads 16 \; --merge-input-intervals \; --consolidate; ```. * `sample_map.csv` contains GCS paths to the GVCFs.; * `0000-scattered.interval_list` is one interval generated by calling SplitIntervals to make 50 intervals. #### Expected behavior. Finish without an error, write DB to the specified bucket. #### Actual behavior. Throws a TileDB error. . Does it have to do with the `--consolidate` flag? I couldn't find what `TILEDB_UPLOAD_BUFFER_SIZE` means, but the [TileDB docs](https://docs.tiledb.com/main/how-to/configuration) reference ""sm.consolidation.buffer_size"" with the default size of 50000000 (50MB?). I'll try rerunning without consolidation. Full log:. ```sh; Using GATK jar /root/micromamba/share/gatk4-4.2.3.0-1/gatk-package-4.2.3.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribbl",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7653:503,error,error,503,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7653,2,"['Error', 'error']","['Error', 'error']"
Availability,"## Bug Report. ### Affected tool(s) or class(es); `PrintReadsSpark`. ### Affected version(s); - [x] Latest public release version [version?]; - [x] Latest master branch as of [date of test?]. ### Description . I first encountered this type of error in a prototype tool I'm writing, so to dig further about what's happening, I run our simplest Spark tool&mdash;`PrintReadsSpark`. `PrintReadsSpark` reports errors when intervals are specified in a BED file (see command given in the stack trace). * Scenario 1: run with a WGS bam and give intervals via `-L PATH_TO_BED_FILE`, error is reported; * Scenario 2: run with the WGS bam and give intervals via `-L chrX:[0-9]+-[0-9]+`, no error; * Scenario 3: run with bam that is shrunk from the WGS bam by including reads only in the union of intervals, then with `-L PATH_TO_BED_FILE`, no error; * Scenario 4: run with bam that is shrunk from the WGS bam by including reads only in the union of intervals, then with `-L chrX:[0-9]+-[0-9]+`, no error; * Scenario 5: download the shrunken bam to local machine and run `PrintReadsSpark` with `-L PATH_TO_BED_FILE`, no error. Stack trace from scenario 1:; ```; ./gatk PrintReadsSpark \; -I hdfs://shuang-small-m:8020/data/HG00512.cram.samtools1_9.bam \; -O hdfs://shuang-small-m:8020/results/temp.bam \; -L hdfs://shuang-small-m:8020/data/intervals.bed \; -- \; --spark-runner GCS \; --cluster shuang-small \; --project broad-dsde-methods. Using GATK jar /Users/shuang/GATK/gatk/build/libs/gatk-spark.jar; found cached jar: gs://broad-dsde-methods/shuang/tmp/gatk-jars/gatk-spark_5710525a8758807e46bbb660ac998e63.jar. Replacing spark-submit style args with dataproc style args. --cluster shuang-small --project broad-dsde-methods -> --cluster shuang-small --project broad-dsde-methods --properties spark.kryoserializer.buffer.max=512m,spark.driver.maxResultSize=0,spark.driver.userClassPathFirst=false,spark.io.compression.codec=lzf,spark.yarn.executor.memoryOverhead=600,spark.driver.extraJavaOptions=-DGATK_STA",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5051:243,error,error,243,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5051,8,"['down', 'error']","['download', 'error', 'errors']"
Availability,"## Bug Report. ### Affected tool(s) or class(es); gatk GenotypeGVCFs. ### Affected version(s); - [X] Latest public release version [GATK 4.1.9.0]; - [ ] Latest master branch as of [date of test?]. ### Description ; Files generated by 'gatk GenotypeGVCFs' with french locale in February (Février in french) August (Août) or December (Décembre) have ISO-8859-1 encoding instead of UTF-8 encoding. Indeed, the output files have this line:. `##GATKCommandLine=<ID=GenotypeGVCFs,CommandLine=""GenotypeGVCFs --output /volumes/vol002/COVID/GenomicDB/vcf/COVID.05022021.int00.vcf.gz --variant gendb://dbtot/int00 --reference /volumes/vol002/reference/human_g1k_v37.fasta --tmp-dir /volumes/vol002/COVID/GenomicDB/tmp/tmpint00 --include-non-variant-sites false --merge-input-intervals false --input-is-somatic false --tumor-lod-to-emit 3.5 --allele-fraction-error 0.001 --keep-combined-raw-annotations false --annotate-with-num-discovered-alleles false --heterozygosity 0.001 --indel-heterozygosity 1.25E-4 --heterozygosity-stdev 0.01 --standard-min-confidence-threshold-for-calling 30.0 --max-alternate-alleles 6 --max-genotype-count 1024 --sample-ploidy 2 --num-reference-samples-if-no-call 0 --genomicsdb-use-bcf-codec false --genomicsdb-shared-posixfs-optimizations false --only-output-calls-starting-in-intervals false --interval-set-rule UNION --interval-padding 0 --interval-exclusion-padding 0 --interval-merging-rule ALL --read-validation-stringency SILENT --seconds-between-progress-updates 10.0 --disable-sequence-dictionary-validation false --create-output-bam-index true --create-output-bam-md5 false --create-output-variant-index true --create-output-variant-md5 false --lenient false --add-output-sam-program-record true --add-output-vcf-command-line true --cloud-prefetch-buffer 40 --cloud-index-prefetch-buffer -1 --disable-bam-index-caching false --sites-only-vcf-output false --help false --version false --showHidden false --verbosity INFO --QUIET false --use-jdk-deflater false --use-jdk-in",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7081:848,error,error,848,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7081,1,['error'],['error']
Availability,"## Bug Report. ### Affected tool(s) or class(es); gatk MarkDuplicatesSpark. ### Affected version(s); - GATK 4.2.6.1; - Spark 3.2.1. ### Description ; File sizes are different between MarkDuplicates and MarkDuplicatesSpark (run locally). file sizes:; input cram: 1094584927; output bam (MarkDuplicates): 2839215419; output bam (MarkDuplicatesSpark): 3536690732. #### Steps to reproduce; command:. `java -Xmx200G -jar /opt/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar MarkDuplicatesSpark \; -I file.cram \; -O file_sorted_markduplicates.bam \; -M file_markduplicates_metrics.txt \; -R homo_sapiens.fa`. #### Expected behavior; output bam should be the same size (or very similar) between MarkDuplicates and MarkDuplicatesSpark. Note: this is when using the local version of the gatk package, using the spark version I get the following error:. `Exception in thread ""main"" java.lang.NoClassDefFoundError: org/apache/spark/Partitioner; 	at java.lang.Class.getDeclaredConstructors0(Native Method); 	at java.lang.Class.privateGetDeclaredConstructors(Class.java:2671); 	at java.lang.Class.getConstructors(Class.java:1651); 	at org.broadinstitute.hellbender.utils.ClassUtils.canMakeInstances(ClassUtils.java:31); 	at org.broadinstitute.hellbender.Main.extractCommandLineProgram(Main.java:319); 	at org.broadinstitute.hellbender.Main.setupConfigAndExtractProgram(Main.java:180); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:202); 	at org.broadinstitute.hellbender.Main.main(Main.java:289); Caused by: java.lang.ClassNotFoundException: org.apache.spark.Partitioner; 	at java.net.URLClassLoader.findClass(URLClassLoader.java:387); 	at java.lang.ClassLoader.loadClass(ClassLoader.java:418); 	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:352); 	at java.lang.ClassLoader.loadClass(ClassLoader.java:351); 	... 8 more`",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8007:833,error,error,833,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8007,1,['error'],['error']
Availability,"## Bug Report. ### Affected tool(s) or class(es); gatk SortVcf. ### Affected version(s); Mac OS X 10.16 x86_64; OpenJDK 64-Bit Server VM 1.8.0_322-b06; Deflater: Intel; Inflater: Intel; Provider GCS is available; Picard version: Version:4.1.4.1. ### Description ; SortVcf finishes sorting and writes out a VCF, but then fails with java.lang.ArrayIndexOutOfBoundsException when generating the tabix index. To work around this, I can run with --CREATE_INDEX false and then run `tabix` to generate the index.; ```; INFO	2022-05-06 12:14:45	SortVcf	wrote 675,000 records. Elapsed time: 00:00:03s. Time for last 25,000: 0s. Last read position: chr3:41,521,469; INFO	2022-05-06 12:14:45	SortVcf	wrote 700,000 records. Elapsed time: 00:00:03s. Time for last 25,000: 0s. Last read position: chr3:61,833,861; INFO	2022-05-06 12:14:45	SortVcf	wrote 725,000 records. Elapsed time: 00:00:03s. Time for last 25,000: 0s. Last read position: chr3:78,534,676; INFO	2022-05-06 12:14:45	SortVcf	wrote 750,000 records. Elapsed time: 00:00:03s. Time for last 25,000: 0s. Last read position: chr3:100,707,682; INFO	2022-05-06 12:14:45	SortVcf	wrote 775,000 records. Elapsed time: 00:00:03s. Time for last 25,000: 0s. Last read position: chr3:117,527,190; INFO	2022-05-06 12:14:45	SortVcf	wrote 800,000 records. Elapsed time: 00:00:03s. Time for last 25,000: 0s. Last read position: chr3:134,613,380; INFO	2022-05-06 12:14:45	SortVcf	wrote 825,000 records. Elapsed time: 00:00:03s. Time for last 25,000: 0s. Last read position: chr3:153,780,108; INFO	2022-05-06 12:14:45	SortVcf	wrote 850,000 records. Elapsed time: 00:00:03s. Time for last 25,000: 0s. Last read position: chr3:173,329,831; INFO	2022-05-06 12:14:46	SortVcf	wrote 875,000 records. Elapsed time: 00:00:03s. Time for last 25,000: 0s. Last read position: chr3:192,133,262; [Fri May 06 12:14:46 EDT 2022] picard.vcf.SortVcf done. Elapsed time: 0.36 minutes.; Runtime.totalMemory()=2855272448; To get help, see http://broadinstitute.github.io/picard/index.html#G",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7838:202,avail,available,202,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7838,1,['avail'],['available']
Availability,"## Bug Report. ### Affected tool(s) or class(es); gatkcondaenv.yml from gatk-4.3.0.0.zip downloaded from https://github.com/broadinstitute/gatk/releases. ### Affected version(s); - [ ] Latest public release version [4.3.0.0]. ### Description ; I downloaded gatk-4.3.0.0.zip from https://github.com/broadinstitute/gatk/releases, unzip it on my linux server, and installed gatk by runnimg command line:; conda env create -n gatk -f gatkcondaenv.yml; After installing ended, I checked my installed gatk version and found it be 3.8-1-0-gf15c1c3ef but not installed 4.3.0.0. Any solution?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8120:89,down,downloaded,89,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8120,2,['down'],['downloaded']
Availability,"## Bug Report. ### Affected tool(s) or class(es); mutect2. ### Affected version(s); 4.1.7.0. ### Description ; I several times now observed an IndexOutOfBoundException in Mutect2. ; Seems to be file specific.; I run this in nextflow 19.10.0. I am open for hints. ; Kind regards!. ```; Command error:; 14:15:19.210 INFO ProgressMeter - 17:44868376 34.1 8548240 250606.9; 14:15:29.214 INFO ProgressMeter - 17:57594001 34.3 8591020 250636.0; 14:15:39.219 INFO ProgressMeter - 17:70805091 34.4 8635430 250711.9; 14:15:49.219 INFO ProgressMeter - 17:79595935 34.6 8665160 250363.6; 14:15:59.220 INFO ProgressMeter - 18:8951018 34.8 8700660 250184.4; 14:16:09.220 INFO ProgressMeter - 18:18750419 34.9 8733540 249932.1; 14:16:19.220 INFO ProgressMeter - 18:33362396 35.1 8782590 250142.7; 14:16:29.221 INFO ProgressMeter - 18:47557520 35.3 8830240 250311.5; 14:16:39.224 INFO ProgressMeter - 18:61732084 35.4 8877870 250478.0; 14:16:49.230 INFO ProgressMeter - 18:75390202 35.6 8923700 250591.9; 14:16:59.238 INFO ProgressMeter - 19:4254509 35.8 8947170 250079.8; 14:17:09.252 INFO ProgressMeter - 19:13499637 35.9 8978420 249787.8; 14:17:19.268 INFO ProgressMeter - 19:23216815 36.1 9011160 249539.8; 14:17:29.278 INFO ProgressMeter - 19:31344990 36.3 9038470 249145.0; 14:17:39.298 INFO ProgressMeter - 19:41157554 36.4 9071590 248912.2; 14:17:49.867 INFO ProgressMeter - 19:42798895 36.6 9077130 247866.1; 14:17:59.042 INFO VectorLoglessPairHMM - Time spent in setup for JNI call : 0.15517662000000002; 14:17:59.043 INFO PairHMM - Total compute time in PairHMM computeLogLikelihoods() : 13.012444101000002; 14:17:59.043 INFO SmithWatermanAligner - Total compute time in java Smith-Waterman : 45.65 sec; 14:17:59.043 INFO Mutect2 - Shutting down engine; [May 15, 2020 2:17:59 PM UTC] org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2 done. Elapsed time: 36.79 minutes.; Runtime.totalMemory()=3793223680; java.lang.IndexOutOfBoundsException: Index: 0, Size: 0; at java.util.ArrayList.rangeCheck(Ar",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6605:293,error,error,293,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6605,1,['error'],['error']
Availability,"## Bug Report. ### Affected tool; CreateSomaticPanelOfNormals. ### Affected version; Tested on version 4.1.8.0 (likely commit 3e921c6, GenomicsDB 1.3.0 #6654). ### Description ; Panel of normals generated from version 4.1.8.0 has some ~28% less records (~52% less ALT alleles) than one created with 4.1.7.0 (tested at commit 9cc92e3) with all input data and arguments unchanged. The GenomicsDB version does not seem to matter as PoN created running CreateSomaticPanelOfNormals on 4.1.8.0 has the result is about the same regardless of whether GenomicsDBImport was run on 4.1.7.0 or 4.1.8.0. CreateSomaticPanelOfNormals on 4.1.7.0 fails to run on the new GenomicsDBs. |Mutect2|GenomicsDB|CreateSomaticPanelOfNormals|Output|; |---|---|---|---|; |4.1.7.0|4.1.7.0|4.1.7.0|100% alleles (reference)|; |4.1.8.0|4.1.8.0|4.1.7.0|expected error|; |4.1.7.0|4.1.7.0|4.1.8.0|48% alleles|; |4.1.8.0|4.1.8.0|4.1.8.0|48% alleles|. #### Steps to reproduce; The PoN was created with GRCh38, scattered over chromosomes. Mutect command:; ```; $gatk/gatk --java-options ""-Xmx4G"" Mutect2 \; 	-R $reference -L $chr \; 	-I $bam --max-mnp-distance 0 \; 	-O @out1@; ```. GenomicsDBImport command:; ```; $gatk/gatk --java-options ""-Xms8G -Xmx8G"" GenomicsDBImport \; 	-R $reference -L $chr \; 	--sample-name-map ${inputGenomicsDB.out1} \; 	--genomicsdb-workspace-path @folder1@; ```. CreateSomaticPanelOfNormals:; ```; $gatk/gatk --java-options ""-Xms8G"" CreateSomaticPanelOfNormals \; 	-R $reference -V gendb://@folder1@ -O @out1@ \; 	--germline-resource $gnomad \; 	--max-germline-probability 0.5; ```. #### Expected behavior; Based on description of the GenomicsDB 1.3.0 update, CreateSomaticPanelOfNormals is expected to behave similarly in 4.1.8.0 as before with the output PoN containing a similar number of variants. #### Actual behavior; 28% of PoN records (52% alleles) are missing in 4.1.8.0 compared to 4.1.7.0. Although all spanning deletions are dropped in the new version, they account for only a small portion of th",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6744:829,error,error,829,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6744,1,['error'],['error']
Availability,"## Bug Report. ### Affected version(s); - Latest master branch as of 1/12/2022. ### Description ; When I tried to build from the github repo, I received the following error:. FAILURE: Build failed with an exception. * Where:; Build file '/gatk/build.gradle' line: 688. * What went wrong:; A problem occurred evaluating root project 'gatk'.; > Could not resolve all files for configuration ':runtimeClasspath'.; > Could not find biz.k11i:xgboost-predictor:0.3.0.; Searched in the following locations:; - https://repo.maven.apache.org/maven2/biz/k11i/xgboost-predictor/0.3.0/xgboost-predictor-0.3.0.pom; - https://broadinstitute.jfrog.io/broadinstitute/libs-snapshot/biz/k11i/xgboost-predictor/0.3.0/xgboost-predictor-0.3.0.pom; - https://oss.sonatype.org/content/repositories/snapshots/biz/k11i/xgboost-predictor/0.3.0/xgboost-predictor-0.3.0.pom; - file:/root/.m2/repository/biz/k11i/xgboost-predictor/0.3.0/xgboost-predictor-0.3.0.pom; Required by:; project :. * Try:; > Run with --stacktrace option to get the stack trace.; > Run with --info or --debug option to get more log output.; > Run with --scan to get full insights. * Get more help at https://help.gradle.org. #### Steps to reproduce; `git clone https://github.com/broadinstitute/gatk.git`; `cd gatk/`; `./gradlew bundle`",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7636:167,error,error,167,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7636,2,"['FAILURE', 'error']","['FAILURE', 'error']"
Availability,"## Bug Report. ### Description . When using the ""latest"" tag on the docker, it points to 4.1.2.0 which is an earlier version. wm462-624:resources fleharty$ docker run -it broadinstitute/gatk:latest; (gatk) root@3b6ada003edd:/gatk# java -jar gatk.jar -version; The Genome Analysis Toolkit (GATK) v4.1.2.0; HTSJDK Version: 2.19.0; Picard Version: 2.19.0; (gatk) root@3b6ada003edd:/gatk# . A docker with version 4.1.3.0 exists when the tag is specified directly.; wm462-624:resources fleharty$ docker run -it broadinstitute/gatk:4.1.3.0; Unable to find image 'broadinstitute/gatk:4.1.3.0' locally; 4.1.3.0: Pulling from broadinstitute/gatk; Digest: sha256:e37193b61536cf21a2e1bcbdb71eac3d50dcb4917f4d7362b09f8d07e7c2ae50; Status: Downloaded newer image for broadinstitute/gatk:4.1.3.0; (gatk) root@efd300ea536a:/gatk# java -jar gatk.jar -version; The Genome Analysis Toolkit (GATK) v4.1.3.0; HTSJDK Version: 2.20.1; Picard Version: 2.20.5",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6132:727,Down,Downloaded,727,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6132,1,['Down'],['Downloaded']
Availability,"## Bug Report. ### GermlineCNVCaller. ### Affected version(s); - [ ] (GATK) v4.2.1.0. ### Description ; Java exception raised when aggregating counts for samples with a name shorter than 3 characters. For example, in the pasted logs, it errors out when processing sample with interval read counts in `94.mkdup.sort.rg.tsv`. And I found removing the sample from the list of files would avoid the error. . ### Logs:. `; 06:49:05.526 INFO GermlineCNVCaller - Aggregating read-count file output/gCNV/bulkDNAseq_BGI/F20FTSAPHT0350_MUSyfqR/count_tsv/713.mkdup.sort.rg.tsv (40 / 323); 06:49:07.999 INFO GermlineCNVCaller - Aggregating read-count file output/gCNV/bulkDNAseq_BGI/F20FTSAPHT0350_MUSyfqR/count_tsv/252.mkdup.sort.rg.tsv (41 / 323); 06:49:10.433 INFO GermlineCNVCaller - Aggregating read-count file output/gCNV/bulkDNAseq_BGI/F20FTSAPHT0350_MUSyfqR/count_tsv/547.mkdup.sort.rg.tsv (42 / 323); 06:49:13.341 INFO GermlineCNVCaller - Aggregating read-count file output/gCNV/bulkDNAseq_BGI/F20FTSAPHT0350_MUSyfqR/count_tsv/154.mkdup.sort.rg.tsv (43 / 323); 06:49:15.782 INFO GermlineCNVCaller - Aggregating read-count file output/gCNV/bulkDNAseq_BGI/F20FTSAPHT0350_MUSyfqR/count_tsv/651.mkdup.sort.rg.tsv (44 / 323); 06:49:18.251 INFO GermlineCNVCaller - Aggregating read-count file output/gCNV/bulkDNAseq_BGI/F20FTSAPHT0350_MUSyfqR/count_tsv/94.mkdup.sort.rg.tsv (45 / 323); 06:49:20.605 INFO GermlineCNVCaller - Shutting down engine; [August 13, 2021 6:49:20 AM GMT] org.broadinstitute.hellbender.tools.copynumber.GermlineCNVCaller done. Elapsed time: 2.27 minutes.; Runtime.totalMemory()=2076049408; java.lang.IllegalArgumentException: Prefix string too short; at java.io.File.createTempFile(File.java:2001); at org.broadinstitute.hellbender.utils.io.IOUtils.createTempFileInDirectory(IOUtils.java:685); at org.broadinstitute.hellbender.utils.io.IOUtils.createTempFile(IOUtils.java:666); at org.broadinstitute.hellbender.tools.copynumber.GermlineCNVCaller.lambda$writeIntervalSubsetReadCountFiles$",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7410:237,error,errors,237,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7410,2,['error'],"['error', 'errors']"
Availability,"## Bug Report. ### Tool; FilterAlignmentArtifacts. ### Affected version(s); 4.2.0.0 and 4.1.9.0, run from local jar or docker. ### Description ; FilterAlignmentArtifacts crushes repetitively in the same position of the input mutect2 vcf `m2.vcf.gz` (chrX:63457865). But, it finishes task successfully when only the last variant from the output file is present in the input vcf file. ; I cut the input vcf around the troublesome variant to reproduce the error on a smaller input and: ; 1. Error did not occur when the input was very small ; 2. FilterAlignmentArtifacts finished run at different variant (chrX:73769127) when analyzing the smaller input (`test.vcf.gz`) . The log issue looks very similar to that described here [#7162)](https://github.com/broadinstitute/gatk/issues/7162), but the *Problematic frame* information is different. ; As suggested in this issue [#5690](https://github.com/broadinstitute/gatk/issues/5690), the problem disappears when using gatk 4.1.3.0 on the same inputs. . log:; ```bash; 17:37:20.674 INFO ProgressMeter - chr20:43968267 10.6 44000 4132.2; 17:37:38.646 INFO ProgressMeter - chr22:22736335 10.9 45000 4110.5; 17:37:52.672 INFO ProgressMeter - chrX:7000139 11.2 46000 4113.9; 17:38:05.421 INFO ProgressMeter - chrX:26360893 11.4 47000 4125.0; 17:38:17.207 INFO ProgressMeter - chrX:44917184 11.6 48000 4141.4; 17:38:29.312 INFO ProgressMeter - chrX:77681733 11.8 49000 4155.3; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x00007fc0ccec5cdb, pid=15987, tid=15988; #; # JRE version: OpenJDK Runtime Environment (11.0.11+9) (build 11.0.11+9-Ubuntu-0ubuntu2.18.04); # Java VM: OpenJDK 64-Bit Server VM (11.0.11+9-Ubuntu-0ubuntu2.18.04, mixed mode, sharing, tiered, compressed oops, g1 gc, linux-amd64); # Problematic frame:; # C [libc.so.6+0x97cdb] cfree+0x31b; #; # Core dump will be written. Default location: Core dumps may be processed with ""/usr/share/apport/apport %p %s %c %d %P %E"" (or dumping to /home/k",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7247:453,error,error,453,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7247,2,"['Error', 'error']","['Error', 'error']"
Availability,"## Bug Report. - OS: Arch Linux; - Java: 17. ### Affected version(s); - [x] Latest public release version [version?]. ### Description . Firstly, I run `./gradle localJar`. ```; Downloading https://services.gradle.org/distributions/gradle-7.5.1-bin.zip; ...........10%............20%...........30%............40%...........50%............60%...........70%............80%...........90%............100%. Welcome to Gradle 7.5.1!. Here are the highlights of this release:; - Support for Java 18; - Support for building with Groovy 4; - Much more responsive continuous builds; - Improved diagnostics for dependency resolution. For more details see https://docs.gradle.org/7.5.1/release-notes.html. Starting a Gradle Daemon (subsequent builds will be faster). > Configure project :; Executing: git lfs pull --include src/main/resources/large. FAILURE: Build failed with an exception. * Where:; Build file '/build/gatk/src/gatk/build.gradle' line: 104. * What went wrong:; A problem occurred evaluating root project 'gatk'.; > Execution of ""git lfs pull --include src/main/resources/large"" failed with exit code: 2. git-lfs is required to build GATK but may not be installed. See https://github.com/broadinstitute/gatk#building for information on how to build GATK. * Try:; > Run with --stacktrace option to get the stack trace.; > Run with --info or --debug option to get more log output.; > Run with --scan to get full insights. * Get more help at https://help.gradle.org. BUILD FAILED in 17s; ```; However, I already install git-lfs; ```; git-lfs usr/; git-lfs usr/bin/; git-lfs usr/bin/git-lfs; git-lfs usr/share/; git-lfs usr/share/licenses/; git-lfs usr/share/licenses/git-lfs/; git-lfs usr/share/licenses/git-lfs/LICENSE; git-lfs usr/share/man/; git-lfs usr/share/man/man1/; git-lfs usr/share/man/man1/git-lfs-checkout.1.gz; git-lfs usr/share/man/man1/git-lfs-clean.1.gz; git-lfs usr/share/man/man1/git-lfs-clone.1.gz; git-lfs usr/share/man/man1/git-lfs-dedup.1.gz; git-lfs usr/share/man/man1/git-lfs-",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8320:177,Down,Downloading,177,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8320,2,"['Down', 'FAILURE']","['Downloading', 'FAILURE']"
Availability,"## Bug Report. Hi @jamesemery and @sooheelee ,. Thanks very much for looking into: https://github.com/broadinstitute/gatk/issues/5230. I am running into one additional error. Reads that contain an insert spanning the full length of the read are causing an exception in SplitNCigarReads. ### Affected tool(s) or class(es); SplitNCigarReads. ### Affected version(s); - Tested on 4.0.3.0 and also branch: je_splitNCigarReadsSplitError (gatk-4.0.10.0-4-gb0f0ab3). ### Description ; SplitNCigarReads gives an Exception when a read that is entirely an insertion is encountered. By contrast, HaplotypeCaller does not seem to have a problem with these reads. Example read:; ```; seq.1028598	163	chr20	3146413	60	100I	=	3146307	-106	CCAATAATTCGACCCTATAAATGATGACCTCCGTTATCGGAAGGGCACAGAACCGTCAGCCGCAACACCAGCAGCTGTAGGCCCTGCTGGGCGCGCTGGG	8;72442435768::8443224764768:84:7534457962;99:787;628:7557;::7:72878:7;:7;:8754;9:::87:8799:7:7:87::	YA:Z:chr20:3145675:600M138N208I599M	MC:Z:100M	PG:Z:MarkDuplicates	RG:Z:1	NH:i:1	HI:i:1	YM:i:0	nM:i:100	YO:Z:chr20:3146278:+:56S44M	MQ:i:60	AS:i:140	YX:i:49	mc:i:3146406	ms:i:2300; ```. #### Steps to reproduce; Command line:; ```; gatk \; --java-options '-DGATK_STACKTRACE_ON_USER_EXCEPTION=true' \; SplitNCigarReads \; --reference $REF \; --input 100I_rna.bam \; --output gatk.split.bam \; > split.log 2>&1; ```. A tiny BAM file illustrating the problem is attached (it is gzipped to allow Github upload).; [100I_rna.bam.gz](https://github.com/broadinstitute/gatk/files/2456955/100I_rna.bam.gz). #### Actual behavior; Here is the stacktrace:; ```; ***********************************************************************. A USER ERROR has occurred: Badly formed genome unclippedLoc: Parameters to GenomeLocParser are incorrect:The stop position 3146412 is less than start 3146413 in contig chr20. ***********************************************************************; org.broadinstitute.hellbender.exceptions.UserException$MalformedGenomeLoc: Badly formed genome unclippedLo",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5293:168,error,error,168,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5293,1,['error'],['error']
Availability,"## Bug Report. Hi there,; So I downloaded the gatk-4.4-0.0.zip and unzipped it for using gatk. I also created the conda env using the gatkcondaenv.yml and used conda to install java ""1.7.0_91"". But when I run ./gatk --list I got this error message: . `; ./gatk --list; Using GATK jar /home/athchu/bin/gatk-4.4.0.0/gatk-package-4.4.0.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /home/athchu/bin/gatk-4.4.0.0/gatk-package-4.4.0.0-local.jar --help; Error: Invalid or corrupt jarfile /home/athchu/bin/gatk-4.4.0.0/gatk-package-4.4.0.0-local.jar; `; Next, I moved on to git clone the gatk repository, trying to build gatk. Again, I stay in the java ""1.7.0_91"" gatk env that I already created. But I got this error msg this time:; `; ./gradlew localJar; Gradle 7.5.1 requires Java 1.8 or later to run. You are currently using Java 1.7.; `; When I switch back to the server default java (1.8.0_292-b10), i got another error msg.; `; java -version; openjdk version ""1.8.0_292""; OpenJDK Runtime Environment (build 1.8.0_292-b10); OpenJDK 64-Bit Server VM (build 25.292-b10, mixed mode). ./gradlew localJar. > Configure project :; Warning: using Java 1.8 but only Java 17 has been tested. FAILURE: Build failed with an exception. * Where:; Build file '/home/athchu/bin/gatk/build.gradle' line: 141. * What went wrong:; A problem occurred evaluating root project 'gatk'.; > A Java 17 compatible (Java 17 or later) version is required to build GATK, but 1.8 was found. See https://github.com/broadinstitute/gatk#building for information on how to build GATK. * Try:; > Run with --stacktrace option to get the stack trace.; > Run with --info or --debug option to get more log output.; > Run with --scan to get full insights. * Get more help at https://help.gradle.org; `; So to sum up, my issues are :; 1) downloaded gatk-4.4.0.0 but it contained invalid jar file and i ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8432:31,down,downloaded,31,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8432,4,"['Error', 'down', 'error']","['Error', 'downloaded', 'error']"
Availability,"## Bug Report. Not a bug, but a question. See **Description section** below. It could also be related to things not being labelled correctly in this repository. ### Affected tool(s) or class(es); Funcotator. ### Affected version(s); - 4. ### Description . Looking around at https://github.com/broadinstitute/gatk/issues?q=label%3AFuncotator+is%3Aclosed I noticed that not much happened since April 2022. Is there no more active development/maintenance planned for Funcotator? Or are the labels misleading? I am planning on writing a generic parser for Funcotator output, but would like to know a bit more about this project's status before investing in this. Thanks. #### Steps to reproduce; See https://github.com/broadinstitute/gatk/issues?q=label%3AFuncotator+is%3Aclosed",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8154:440,mainten,maintenance,440,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8154,1,['mainten'],['maintenance']
Availability,"## Bug Report. Originally reported by @ldgauthier via slack. ### Affected tool(s) or class(es); CalibrateDragstrModel. ### Affected version(s); - [X ] Latest public release version [4.2.0.0]. ### Description ; An out-of-memory exception when running the aforementioned tool in at least one of many samples. Location where the error occur does not seem to be always the same but it was fixable by increasing memory over 15Gb. #### Steps to reproduce. Since I'm not sure the data is public I won't disclose its location nor ID in this issue. Let's call it the ""SAMPLE"" in ""SAMPLE.cram"":. ```; gatk --java-options ""-Dsamjdk.reference_fasta=Homo_sapiens_assembly38.fasta -Xmx2g -DGATK_STACKTRACE_ON_USER_EXCEPTION=true"" \; CalibrateDragstrModel \; -R Homo_sapiens_assembly38.fasta \; -I SAMPLE.cram \; -str Homo_sapiens_assembly38.str \; -O SAMPLE.final.cram.dragstr \; --parallel \; --verbosity DEBUG; ```. ```Homo_sapiens_assembly38.str``` depends only on the reference and ca be composed using this:. ```; gatk ComposeSTRFile -R Homo_sapiens_assembly38.fasta -O Homo_sapiens_assembly38.str; ```. #### Expected behavior; Completes without issues. #### Actual behavior; a Java Out-of-Memory error is throw and the execution finished without results.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7189:326,error,error,326,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7189,2,['error'],['error']
Availability,"## Bug Report; ### Affected tool(s) or class(es); CombineGVCFs. ### Affected version(s); - version 4.1.0.8. ### Description ; I know this issue has been brought up before but I still cannot find a solution. When I run CombineGVCFs, the error indicates the first locus where there is a NON_REF allele. For example:. HiC_scaffold_2 12497 . T TC,* . My full process is as follows:; I run HaplotypeCaller on individual sample files using the -ERC GVCF command.; I combine the individual g.vcf files using CombineGVCFs. I do this separately for the three species I ultimately want to merge, although they are all mapped to the same reference genome.; I call multisample genotypes with GenotypeGVCFs, again for each species separately. At this point a sample that will fail the process in the future will look like:; HiC_scaffold_2 12497 . T TC,<NON_REF>. I now merge the multispecies genotyped files together using CombineGVCFs.; But then when I go to run GenotypeGVCFs, there is an error wherever there are more than two alleles. And as shown at the top of the message what was a <NON_REF> becomes a * and I get the message: ERROR input alleles must contain <NON_REF>. #### Expected behavior; I expected the g.vcf files to genotype across multiple samples so I can move forward with analyses. Is the problem that I'm running CombineGVCFs and GenotypeGVCFs twice? And somehow that is changing <NON_REF> into * ?. I appreciate any advice.; With thanks,; Emily",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7737:236,error,error,236,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7737,3,"['ERROR', 'error']","['ERROR', 'error']"
Availability,"## Bug Report; ### Affected tool(s). MuTect2; ### Affected version(s). version 3.6; ### Description. A user reported that when he input a BAM file that has multiple sample names to MuTect2, the tool mseems to run fine but outputs an empty VCF. Because MuTect2 cannot run on multiple samples, there should be an error message that lets the user know he/she cannot have multiple samples in the BAM file.; #### Expected behavior. There should be an error message telling the user to input only single sample BAM files, and the run should fail.; #### Actual behavior. The tool runs to completion but outputs an empty VCF. [Original Forum Post](http://gatkforums.broadinstitute.org/gatk/discussion/comment/33336#Comment_33336). ---",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2203:311,error,error,311,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2203,2,['error'],['error']
Availability,"## Bug Report; ### Version Information; GenomicsDBImport 4.1.9.0. ### Summary; A user posted on the forum with an error from GenomicsDBImport. @nalinigans @mlathara Can you determine what is causing this java.lang.IndexOutOfBoundsException?. This request was created from a contribution made by vivekruhela on January 12, 2021 19:16 UTC. Link: [https://gatk.broadinstitute.org/hc/en-us/community/posts/360076396392-No-Output-from-GenomicsDBImport](https://gatk.broadinstitute.org/hc/en-us/community/posts/360076396392-No-Output-from-GenomicsDBImport). \--. Dear GATK Team,. I am using GATK version 4.1.9.0 for my WES data pipeline. In order to get accurate somatic call, I am trying to generate the Panel of Normal (PON) using GenomicsDBImport module of GATK. While using GenomicsDBImport for PON generation, I am not getting any output from my command. Here is the command I used to print the stack trace:. ```; gatk GenomicsDBImport \\ ; ; \-R /gatk\_bundle/hg19\_v0\_Homo\_sapiens\_assembly19.fasta \\ ; ; \--variant normal1.vcf \\ ; ; \--variant normal2.vcf \\ ; ; \--variant normal3.vcf \\ ; ; \--variant normal4.vcf \\ ; ; \--variant normal5.vcf \\ ; ; \--variant normal6.vcf \\ ; ; \--variant normal7.vcf \\ ; ; \--variant normal8.vcf \\ ; ; \--variant normal9.vcf \\ ; ; \--variant normal10.vcf \\ ; ; \--variant normal11.vcf \\ ; ; \--variant normal12.vcf \\ ; ; \--variant normal13.vcf \\ ; ; \--variant normal14.vcf \\ ; ; \--variant normal15.vcf \\ ; ; \--variant normal16.vcf \\ ; ; \--variant normal17.vcf \\ ; ; .... ; ; \--variant normal80.vcf \\ ; ; \--genomicsdb-workspace-path pon\_db \\ ; ; \--tmp-dir /tmp1 \\ ; ; \-L /gatk\_bundle/hglft\_genome\_3bc14\_d6f440.bed \\ ; ; \--sequence-dictionary /gatk\_bundle/hg19\_v0\_Homo\_sapiens\_assembly19.dict \\ ; ; \--reader-threads 15 \\ ; ; \--java-options '-DGATK\_STACKTRACE\_ON\_USER\_EXCEPTION=true'; ```. Here For interval list, I have downloaded the hg38 target interval from GATK resource bundle and converted into hg19 format us",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7037:114,error,error,114,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7037,1,['error'],['error']
Availability,"## Bug Report; 18:47:11.757 INFO Funcotator - Shutting down engine; [September 19, 2021 6:47:11 PM CST] org.broadinstitute.hellbender.tools; .funcotator.Funcotator done. Elapsed time: 0.13 minutes.; Runtime.totalMemory()=1885339648; **org.broadinstitute.hellbender.exceptions.GATKException: Unable to query; the database for geneName: WASH7P**; ....; at org.broadinstitute.hellbender.cmdline.CommandLineProgram.ins; tanceMainPostParseArgs(CommandLineProgram.java:192); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.ins; tanceMain(CommandLineProgram.java:211); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Mai; n.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289); **Caused by: org.sqlite.SQLiteException: [SQLITE_IOERR_LOCK] I/O error i; n the advisory file locking logic (disk I/O error)**; at org.sqlite.core.DB.newSQLException(DB.java:909); ### Affected version(s); GATK 4.1.9.0. ### Description ; GATK Funcotator [SQLITE_IOERR_LOCK] I/O error in the advisory file locking logic (disk I/O error). I downloaded the data-sources by ""gsutil cp gs://broad-public-datasets/funcotator/funcotator_dataSources.v1.7.20200521s.tar.gz ."". I can't find useful information for this error. Thank you. #### Steps to reproduce; Using GATK jar /lustre1/ruibinxi_pkuhpc/ljx/software/gatk-4.1.9.0/gatk-; package-4.1.9.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_i; o_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjd; k.compression_level=2 -jar /lustre1/ruibinxi_pkuhpc/ljx/software/gatk-4; .1.9.0/gatk-package-4.1.9.0-local.jar Funcotator -R /home/ruibinxi_pkuh; pc/lustre1/ljx/reference_genomes/hg38_bwa/hg38.fa -V /home/ruibinxi_pku; hpc/lustre1/ljx/data/raodn/WES/GATK/P14P_filtered.vcf.gz -O /home/ruibi; nxi_pkuhpc/lustre1/ljx/data/raodn/WES/GATK/P14P_filtered_funcotator.maf; --output-file-format MAF --data-sources-path /home/ruibinx",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7474:55,down,down,55,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7474,3,"['down', 'error']","['down', 'error']"
Availability,"## Bug Report; GenotypeGVCFs stuck indefinitely at ""Initializing engine"" step. ### Affected tool(s) or class(es); gatk GenotypeGVCFs; ### Affected version(s); GATK v4.1.4.1 (installed in a `conda` convironment from the bioconda channel), on a RHEL server 7.6 (Maipo). ### Description ; Following the recommended pipeline of HaplotypeCaller, GenomicsDBImport and then GenotypeGVCFs, the last command hangs indefinitely and from the log file, it seems like it doesn't get past the ""Initialize engine"" step. This is an example of the standard error stream (after the `GenotypeGVCFs` job reached 20 hours wall time and was killed) :; ```; 22:28:44.293 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/export/user/home/miniconda3/envs/aDNA/share/gatk4-4.1.4.1-1/gatk-package-4.1.4.1-local.; jar!/com/intel/gkl/native/libgkl_compression.so; Dec 17, 2020 10:28:44 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 22:28:44.639 INFO GenotypeGVCFs - ------------------------------------------------------------; 22:28:44.640 INFO GenotypeGVCFs - The Genome Analysis Toolkit (GATK) v4.1.4.1; 22:28:44.640 INFO GenotypeGVCFs - For support and documentation go to https://software.broadinstitute.org/gatk/; 22:28:44.640 INFO GenotypeGVCFs - Executing as user@gc-prd-hpcn002 on Linux v3.10.0-957.27.2.el7.x86_64 amd64; 22:28:44.640 INFO GenotypeGVCFs - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_192-b01; 22:28:44.640 INFO GenotypeGVCFs - Start Date/Time: December 17, 2020 10:28:44 PM AEST; 22:28:44.640 INFO GenotypeGVCFs - ------------------------------------------------------------; 22:28:44.640 INFO GenotypeGVCFs - ------------------------------------------------------------; 22:28:44.640 INFO GenotypeGVCFs - HTSJDK Version: 2.21.0; 22:28:44.640 INFO GenotypeGVCFs - Picard Version: 2.21.2; 22:28:44.640 INFO GenotypeGVCFs - HTSJDK Defaults.COMPRESSION_LEVEL : 2; ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7007:540,error,error,540,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7007,1,['error'],['error']
Availability,"## Bug Report; HaplotypeCaller. ### Affected version(s); 4.3.0. ### Description ; A plot of the frequency distribution of GQ values associated with variants reported by HaplotypeCaller demonstrates ""periodicity"". The following counts GQ values for TP variant calls (data from HG002, aligned to GRCh38 with three different read aligners, chr14 only):. ![GQdist HC](https://user-images.githubusercontent.com/8249753/215591505-06b76118-cdbf-4b04-ae70-55acaaf8fce9.png). Most of the distribution is periodic on GQ values that are even multiples of 3. This is seen in the data for this plot: [GCdist.xlsx](https://github.com/broadinstitute/gatk/files/10540627/GCdist.xlsx). In addition, about 80% of the reported variants were associated with GQ=99 (not plotted here). This kind of thing might be an artifact of the algorithm used to compute GQ. For example, underlying data such as MAPQ might be manifesting the same periodicity, which is then ""passed through"" to GQ. It might also be an implementation error. For example, premature rounding or the use of an integer variable instead of a floating point variable might lead to inadvertent quantization of a result. But this is just speculation, given only that the distribution would be expected to be smooth, not periodic. #### Steps to reproduce; A little bit of awk should suffice to pull GQ values from a plain-text VCF file. #### Expected behavior; No periodicity in the frequency distribution of GQ values. For example, here is the distribution of GQ values for the same three sets of read mappings but with variants called with DeepVariant:. ![GQdist DV](https://user-images.githubusercontent.com/8249753/215611788-9372cec8-7841-4d90-b137-b3f950902fba.png). In addition, about 15% of the reported variants were associated with GQ=99 (not plotted here). #### Actual behavior; (As above.). Thanks for any insight you can provide on this!",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8179:999,error,error,999,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8179,1,['error'],['error']
Availability,"## Bug Report; Hi, we are using the dockstore version of the GATK variant calling pipeline that leverages mutect 2:; [github.com/broadinstitute/gatk/mutect2:4.1.8.1](https://dockstore.org/workflows/github.com/broadinstitute/gatk/mutect2:4.1.8.1). We're processing human glioma data, and currently we are making it through much of the pipeline, but failing on `GetPileupSummaries`. There's a thread about it on the discussion board [here] (https://gatk.broadinstitute.org/hc/en-us/community/posts/6179012337819-No-Pileup-Tables). . We are specifying a file for `variants_for_contamination`, and a file for `variants_for_contamination_idx` in the workflow, but the index is never passed to `GetPileupSummaries`, and it fails with this enigmatic error message:. ```; A USER ERROR has occurred: An index is required but was not found for file gs://bruce-processed-data/Prins_Cloughesy_Neoadjuvant/terra_reference_files/small_exac_common_3.hg38.vcf.gz. Support for unindexed block-compressed files has been temporarily disabled. Try running IndexFeatureFile on the input.; ```. If you check out the source code in [mutect2.wdl](https://github.com/broadinstitute/gatk/blob/4.1.8.1/scripts/mutect2_wdl/mutect2.wdl), you can see that that input variable `variants_for_contamination_idx`, which we have thoughtfully set and passed into the workflow, is never actually used in `GetPileupSummaries`. I'm not even sure there is an option to pass the index, from reading the [docs](https://gatk.broadinstitute.org/hc/en-us/articles/360037593451-GetPileupSummaries). Here is an example of how the command is being called within our workflow:. ```; gatk --java-options ""-Xmx149500m"" GetPileupSummaries -R gs://gcp-public-data--broad-references/hg38/v0/Homo_sapiens_assembly38.fasta -I gs://fc-d31bc4e7-6d10-4dc4-a585-5895ab2346f3/cfce2061-efd6-449e-bdc9-a7ff2b633644/PreProcessingForVariantDiscovery_GATK4/b4adf777-4f97-425c-b3e2-b37c9d927667/call-GatherBamFiles/SRR7588418.hg38.bam --interval-set-rule INTERSECTION ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7935:743,error,error,743,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7935,2,"['ERROR', 'error']","['ERROR', 'error']"
Availability,"## Bug Report; I run the CNNScoreVariants as tutorial, but it can't continue and always stuck as the following picture, and the programme isn't stop by any error. By the way I can't find gatkcondaenv.yml in anywhere. Can you upload it in the github, so that I can check ; whether the bug is caused by loss of some python dependencies. ### Affected tool(s) or class(es); CNNScoreVariants. ### Affected version(s); GATK4.3.0.0. ### Description ; ![image](https://github.com/broadinstitute/gatk/assets/92069388/be7c63ca-d64f-4689-86ad-b06f867cfd45)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8827:156,error,error,156,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8827,1,['error'],['error']
Availability,"## Bug Report; I was running the JointDiscovery pipeline as a part of the GATK Best Practices pipeline. I am running this on many vcf files (~150) called by the HaplotypeCaller. I am getting this error: . ```; 19:01:58.009 WARN VariantDataManager - WARNING: Very large training set detected. Downsampling to 2500000 training variants.; 19:04:18.918 INFO VariantRecalibrator - Shutting down engine; [September 16, 2019 7:04:18 PM EDT] org.broadinstitute.hellbender.tools.walkers.vqsr.VariantRecalibrator done. Elapsed time: 912.93 minutes.; Runtime.totalMemory()=3204972544; Exception in thread ""main"" java.lang.OutOfMemoryError: Java heap space; 	at org.broadinstitute.hellbender.tools.walkers.vqsr.MultivariateGaussian.<init>(MultivariateGaussian.java:31); 	at org.broadinstitute.hellbender.tools.walkers.vqsr.GaussianMixtureModel.<init>(GaussianMixtureModel.java:34); 	at org.broadinstitute.hellbender.tools.walkers.vqsr.VariantRecalibratorEngine.generateModel(VariantRecalibratorEngine.java:43); 	at org.broadinstitute.hellbender.tools.walkers.vqsr.VariantRecalibrator.onTraversalSuccess(VariantRecalibrator.java:625); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:895); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:134); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:179); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:198); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); 	at org.broadinstitute.hellbender.Main.main(Main.java:289); ```. I believe this is derived from an error earlier in the log, since the `stderr` gives the same Java heap space error: ; ```; [2019-09-16 19:05:59,50] [error] WorkflowManagerActor Workflow 9f7a01a4-0632-4817-8622-aa51e520abf1 failed (during ExecutingWorkflowState): Job JointGe",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6165:196,error,error,196,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6165,3,"['Down', 'down', 'error']","['Downsampling', 'down', 'error']"
Availability,"## Bug Report; JDK8 is no longer available for the current stable Debian release (buster). Trying to run gatk with an OpenJDK11 install fails. I anticipate a WONTFIX since this is dependency related, but I figured it would be good to let people know. ### Affected tool(s) or class(es); GATKRead, probably others too. ### Affected version(s); - [x] Latest public release version [4.1.2.0]; - [ ] Latest master branch as of [didn't test]. ### Description ; ```; Exception in thread ""main"" java.lang.IncompatibleClassChangeError: Inconsistent constant pool data in classfile for class org/broadinstitute/hellbender/transformers/ReadTransformer. Method 'org.broadinstitute.hellbender.utils.read.GATKRead lambda$identity$d67512bf$1(org.broadinstitute.hellbender.utils.read.GATKRead)' at index 65 is CONSTANT_MethodRef and should be CONSTANT_InterfaceMethodRef; 	at org.broadinstitute.hellbender.transformers.ReadTransformer.identity(ReadTransformer.java:30); 	at org.broadinstitute.hellbender.engine.GATKTool.makePreReadFilterTransformer(GATKTool.java:345); 	at org.broadinstitute.hellbender.engine.GATKTool.getTransformedReadStream(GATKTool.java:374); 	at org.broadinstitute.hellbender.engine.ReadWalker.traverse(ReadWalker.java:93); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1039); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:162); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:205); 	at org.broadinstitute.hellbender.Main.main(Main.java:291); ```. This error seems related to the JRE version. You can still install JDK8 manually but that's not ideal for many users. #### Steps to reproduce; Run GATK on OpenJDK11. ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6053:33,avail,available,33,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6053,1,['avail'],['available']
Availability,"## Bug Report; When I use output files of CombineGVCFs to run GenotypeGVCFs, it seems no problem at beginning. However, several hours later, it suddenly shot down. The fatal error occur. ### Affected tool(s) or class(es); GenotypeGVCFs, only use arguments: -R, -V, -O, -all-sites. ### Affected version(s); GATK4 v4.1.9.0. ### Description . A fatal error has been detected by the Java Runtime Environment:. SIGBUS (0x7) at pc=0x00002acb0aee41d3, pid=14508, tid=0x00002acb0f80b700. JRE version: OpenJDK Runtime Environment (8.0_152-b12) (build 1.8.0_152-release-1056-b12); Java VM: OpenJDK 64-Bit Server VM (25.152-b12 mixed mode linux-amd64 compressed oops); Problematic frame:; C [libc.so.6+0x1501d3] __memmove_ssse3_back+0x1a13. Failed to write core dump. Core dumps have been disabled. To enable core dumping, try ""ulimit -c unlimited"" before starting Java again. If you would like to submit a bug report, please visit:; http://bugreport.java.com/bugreport/crash.jsp. --------------- T H R E A D ---------------. Current thread (0x00002acb10021800): GCTaskThread [stack: 0x00002acb0f70b000,0x00002acb0f80c000] [id=14511]. siginfo: si_signo: 7 (SIGBUS), si_code: 2 (BUS_ADRERR), si_addr: 0x00000003ea598000. Registers:; RAX=0x00000003ea593600, RBX=0x00002acb0f80aa00, RCX=0x00000000000059c8, RDX=0x0000000000000f48; RSP=0x00002acb0f80a928, RBP=0x00002acb0f80a950, RSI=0x000000044246f290, RDI=0x00000003ea597fa0; R8 =0x00000003ea593600, R9 =0x0000000057ed72f0, R10=0x00000003c0000000, R11=0x00002acb0af16b50; R12=0x0000000000000b3d, R13=0x00000000000059e8, R14=0x00002acb0f80aa00, R15=0x0000000010490000; RIP=0x00002acb0aee41d3, EFLAGS=0x0000000000010206, CSGSFS=0x0000000000000033, ERR=0x0000000000000006; TRAPNO=0x000000000000000e. Top of Stack: (sp=0x00002acb0f80a928); 0x00002acb0f80a928: 00002acb0ba575c6 00000003c5a14ae8; 0x00002acb0f80a938: 0000000000412400 000000001048e05a; 0x00002acb0f80a948: 00002acb0c077d00 00002acb0f80a9a0; 0x00002acb0f80a958: 00002acb0ba155e8 00002acb0c03f148; 0x00002a",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7008:158,down,down,158,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7008,3,"['down', 'error']","['down', 'error']"
Availability,"## Bug Report; when I run the MarkDuplicatesSpark, it throws me an error: basically it shows the spark engine stopped when run this function. ; the part of the error log is here:; WARNING: An illegal reflective access operation has occurred; WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/rnaseq_pipeline_app/Apps/GATK/gatk-4.1.9.0/gatk-package-4.1.9.0-local.jar) to method java.nio.Bits.unaligned(); WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform; WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations; WARNING: All illegal access operations will be denied in a future release; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; 21/01/12 15:50:31 INFO SparkContext: Running Spark version 2.4.5; 21/01/12 15:50:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 21/01/12 15:50:31 INFO SparkContext: Submitted application: MarkDuplicatesSpark; 21/01/12 15:50:31 INFO SecurityManager: Changing view acls to: root; 21/01/12 15:50:31 INFO SecurityManager: Changing modify acls to: root; 21/01/12 15:50:31 INFO SecurityManager: Changing view acls groups to: ; 21/01/12 15:50:31 INFO SecurityManager: Changing modify acls groups to: ; 21/01/12 15:50:31 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); groups with view permissions: Set(); users with modify permissions: Set(root); groups with modify permissions: Set(); 21/01/12 15:50:31 INFO Utils: Successfully started service 'sparkDriver' on port 36657.; 21/01/12 15:50:31 INFO SparkEnv: Registering MapOutputTracker; 21/01/12 15:50:31 INFO SparkEnv: Registering BlockManagerMaster; 21/01/12 15:50:31 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information; 21/01/12 15:50:31 INFO B",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7035:67,error,error,67,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7035,2,['error'],['error']
Availability,"## Description; A user wants to run Funcotator with a mouse sample but has an issue running IndexFeatureFile. The GencodeGTF parser is specific to human data. Funcotator could be useful for users with non-human data if there is a workaround for these errors. ### GATK Information; GATK 4.1.9.0; gatk IndexFeatureFile -I gencode.vM25.annotation.gtf; This request was created from a contribution made by T. Li on January 25, 2021 04:37 UTC. Link: [https://gatk.broadinstitute.org/hc/en-us/community/posts/360076815852-Error-Running-IndexFeatureFile-on-Ensembl-Mouse-GTF-file-](https://gatk.broadinstitute.org/hc/en-us/community/posts/360076815852-Error-Running-IndexFeatureFile-on-Ensembl-Mouse-GTF-file-). #### Error Log. ```; Using GATK jar /gatk/gatk-package-4.1.9.0-SNAPSHOT-local.jar ; ; Running: ; ; java -Dsamjdk.use\_async\_io\_read\_samtools=false -Dsamjdk.use\_async\_io\_write\_samtools=true -Dsamjdk.use\_async\_io\_write\_tribble=false -Dsamjdk.compression\_level=2 -jar /gatk/gatk-package-4.1.9.0-SNAPSHOT-local.jar IndexFeatureFile -I gencode/mm10/gencode.vM25.annotation.gtf ; ; 04:33:13.081 INFO NativeLibraryLoader - Loading libgkl\_compression.so from jar:file:/gatk/gatk-package-4.1.9.0-SNAPSHOT-local.jar!/com/intel/gkl/native/libgkl\_compression.so ; ; Jan 25, 2021 4:33:13 AM shaded.cloud\_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine ; ; INFO: Failed to detect whether we are running on Google Compute Engine. ; ; 04:33:13.195 INFO IndexFeatureFile - ------------------------------------------------------------ ; ; 04:33:13.195 INFO IndexFeatureFile - The Genome Analysis Toolkit (GATK) v4.1.9.0-SNAPSHOT ; ; 04:33:13.195 INFO IndexFeatureFile - For support and documentation go to [https://software.broadinstitute.org/gatk/](https://software.broadinstitute.org/gatk/) ; ; 04:33:13.195 INFO IndexFeatureFile - Executing as root@b4c480938d0d on Linux v5.4.0-1029-aws amd64 ; ; 04:33:13.195 INFO IndexFeatureFile - Java runtime: OpenJDK 64-Bit Server",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7054:251,error,errors,251,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7054,4,"['Error', 'error']","['Error', 'Error-Running-IndexFeatureFile-on-Ensembl-Mouse-GTF-file', 'errors']"
Availability,"## Documentation request. ### Description ; I propose that installation of gcc be added to the instructions on the GATK Github README.md. If gcc is not installed, HaplotypeCaller complains that the AVX instruction set is not available, even when it is. It falls back to slower LOGLESS_CACHING PairHMM. The fault is missing libgomp1, which is a required dependency of gcc. Since this documentation request is related to a ""bug"" that comes about from not installing necessary libraries, I'll include the bug report format below, in case someone else searches for solutions to this problem, as suggested by @lbergelson. ### Affected tool(s) or class(es); _HaplotypeCaller_, or any other tool that uses _PairHMM_. ### Affected version(s); -I think all as of _2019-06-20_. I tested on release version _4.1.2.0_. #### Steps to reproduce; Run HaplotypeCaller from a released jar on an Ubuntu VM that supports the AVX instruction set. Critically, do *NOT* install gcc on the VM. Installing gcc fixes this problem. #### Expected behavior; If you install gcc, that results in the installation of libgomp1, which allows the Intel library to load and use AVX acceleration. You could probably install libgomp1 on its own, but I did not test that.; > 14:51:01.013 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/home/ubuntu/gatk-4.1.2.0/gatk-package-4.1.2.0-local.jar!/com/intel/gkl/native/libgkl_utils.so; > 14:51:01.015 INFO NativeLibraryLoader - Loading libgkl_pairhmm_omp.so from jar:file:/home/ubuntu/gatk-4.1.2.0/gatk-package-4.1.2.0-local.jar!/com/intel/gkl/native/libgkl_pairhmm_omp.so; > 14:51:01.053 INFO IntelPairHmm - Using CPU-supported AVX-512 instructions; > 14:51:01.053 INFO IntelPairHmm - Flush-to-zero (FTZ) is enabled when running PairHMM; > 14:51:01.054 INFO IntelPairHmm - Available threads: 16; > 14:51:01.054 INFO IntelPairHmm - Requested threads: 8; > 14:51:01.054 INFO PairHMM - Using the OpenMP multi-threaded AVX-accelerated native PairHMM implementation. #### Actual b",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6012:225,avail,available,225,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6012,2,"['avail', 'fault']","['available', 'fault']"
Availability,"## Documentation request. ### Description ; I was unable to successfully follow the R setup instructions required to run integration tests locally. I don't know whether this is a general concern regarding initial setup on Mac OS X High Sierra 10.13.6, or the problem is specific to my system. . #### R installation itself; Expected: `brew install R` would install R with all necessary core functionality.; Actual: `brew install R` installed a version of R without X11 support. The binary I downloaded from [CRAN](https://cran.r-project.org/bin/macosx/) had the proper support. #### R package installation; Expected `sudo Rscript scripts/docker/gatkbase/install_R_packages.R` would install the necessary packages for R scripts needed.; Actual: Failure to compile source packages, with an error like `clang: error: unsupported option '-fopenmp'`. I made some attempts to update my local `clang` but was unsuccessful. Instead, I installed the packages at the R prompt:; ```; $ R; > install.packages('ggplot2'); > install.packages('reshape'); > install.packages('gplots'); > install.packages('gridExtra'); > install.packages('gsalib'); > install.packages('data.table'); > quit(); ```. After doing so, my test run `TEST_TYPE=integration ./gradlew shadowJar test` succeeded.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5389:490,down,downloaded,490,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5389,4,"['Failure', 'down', 'error']","['Failure', 'downloaded', 'error']"
Availability,"## Documentation request. ### Tool(s) or class(es) involved; GermlineCNVCaller. ### Description ; I'm trying to get a pipeline running to call germline CNVs on small cohorts (20-40) PCR free whole genome samples sequenced to ~45X depth. I'm running into problems figuring out how wide to scatter the analysis, and how to allocate resources. It would be incredibly helpful to have some very clear guidelines about how number of samples and the number of intervals within each scatter affect both runtime and memory usage. Here's what I've been able to infer from the WDL pipelines, tool docs and experimentation (though I suspect some of it is wrong):. 1. Memory usage is approximately proportional to number of samples, number of intervals, number of bias covariates and max copy number. What the docs don't say is what the default is for the number of bias covariates _and_ how to take these numbers and project an approximate memory usage. 2. It would appear that GermlineCNVCaller will, by default, attempt to use all CPU cores available on the machine. From the WDL I see that setting environment variables `MKL_NUM_THREADS` and `OMP_NUM_THREADS` seems to control the parallelism? It would be nice if `GermlineCNVCaller` took a `--threads` and then set these before spawning the python process. 3. Runtime? This would be really nice to have some guidelines around as I get wildly varying results depending on how I'm running. My experimentation is with a) 20 45X WGS samples, b) bin size = 500bp, c) running on a 96-core general purpose machine at AWS with 384GB of memory. My first attempt a) scattered the genome into 48 shards of approximately 115k bins each, representing ~50mb of genome and b) ran 24 jobs concurrently but failed to set the environment variables to control parallelism. In that attempt the first wave of jobs were still running after 24 hours and getting close to finishing up the initial de-noising epoch, with 3/24 having failed due to memory allocation failures. My secon",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6166:1031,avail,available,1031,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6166,1,['avail'],['available']
Availability,"## Documentation request. ### Tool(s) or class(es) involved; Mutect2 and FilterMutectCalls. ### Description ; Because both `M2ArgumentCollection` and `M2FiltersArgumentCollection` extend `AssemblyBasedCallerArgumentCollection`, both `Mutect2` and `FilterMutectCalls` display all assembly and caller arguments in the documentation/help even if those arguments don't actually do anything. For example both tools have the argument `--contamination-fraction-to-filter` which has the description:. ```; Fraction of contamination in sequencing data (for all samples) to aggressively remove. If this fraction is greater is than zero, the caller will aggressively attempt to remove contamination ; through biased down-sampling of reads. Basically, it will ignore the contamination fraction of reads for ; each alternate allele. So if the pileup contains N total bases, then we will try to remove ; (N * contamination fraction) bases for each alternate allele.; ```. This argument definitely doesn't do anything in `FilteMutectCalls` but I also don't think it's hooked up to do anything in `Mutect2` either (at least when I tried giving it a high value I still got the same calls). This is by design because Mutect has other ways of handling contamination, but the argument is still displayed in both tools' documentation which is confusing. There are other arguments that have the same issue where it's unclear if they do anything in Mutect or not.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5352:705,down,down-sampling,705,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5352,1,['down'],['down-sampling']
Availability,"## Documentation request. ### Tool(s) or class(es) involved; Readme for M2 in https://github.com/broadinstitute/gatk/tree/master/scripts/mutect2_wdl. ### Description ; This is the text currently in the readme, it needs to be updated to feature Funcotator instead of Oncotator:. > Functional annotation (Oncotator); > ; > The M2 WDL can optionally run oncotator for functional annotation and produce a TCGA MAF from the M2 VCF. Oncotator is not a GATK4 tool and is provided in the M2 WDL as a convenience. There are several notes and caveats; > ; > Several parameters should be passed in to populate the TCGA MAF metadata fields. Default values are provided, though we recommend that you specify the values. These parameters are ignored if you do not run oncotator.; > ; > Several fields in a TCGA MAF cannot be generated by M2 and oncotator, such as all fields relating to validation alleles. These will need to be populated by a downstream process created by the user.; > ; > Oncotator does not enforce the TCGA MAF controlled vocabulary, since it is often too restrictive for general use. This is up to the user to specify correctly. Therefore, we cannot guarantee that a TCGA MAF generated here will pass the TCGA Validator. If you are unsure about the ramifications of this statement, then it probably does not concern you.; > ; > More information about Oncotator can be found at: http://archive.broadinstitute.org/cancer/cga/oncotator",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5889:930,down,downstream,930,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5889,1,['down'],['downstream']
Availability,"## Documentation request. There are multiple statistical terminology errors, especially misuses of the term ""likelihood,"" in [Assigning per-sample genotypes (HaplotypeCaller)](https://gatk.broadinstitute.org/hc/en-us/articles/360035890511). The statistics are difficult enough without pervasive misuse of statistical terminology in the documentation of software considered a _de facto_ standard, which IMO makes this fairly serious. This is a follow-on report to #7577 . ----. 1. The heading ""Calculating genotype likelihoods using Bayes' Theorem"" should read ""Calculating genotype **posteriors** using Bayes' Theorem"" The Contents section needs corresponding correction, of course.; 2. The quote: ""...when we used the PairHMM to produce the likelihoods of each read against each haplotype, and then marginalized them to find the likelihoods of each read for each allele under consideration"" **should read** ""...when we used the PairHMM to produce **P(read|haplotype),** and then marginalized them to find the **likelihoods of each allele** under consideration.""; 3. The quote: ""...the point of calculating this likelihood is to determine..."" **should read** ""...the point of calculating this **posterior** is to determine..."". ----",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7581:69,error,errors,69,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7581,1,['error'],['errors']
Availability,"## Documentation system request. Currently, the tooldoc generation system does not separate arguments that relate to deployment decisions like compute platform (eg `--gcs-project-for-requester-pays`) from the ones that modify the analytical or processing behavior of the tools. This adds to the cognitive burden involved in sorting through all the options available for a given tool. We'd like to have a separate category for these arguments so that they would be isolated from the rest. . In addition, there are a bunch of convenience arguments in the common args section that have more to do with how we're running the tool than its analysis behavior, and could also be consolidated into this separate category (or their own category but that might be too granular). Examples below are from the popular tool [SelectVariants](https://software.broadinstitute.org/gatk/documentation/tooldocs/current/org_broadinstitute_hellbender_tools_walkers_variantutils_SelectVariants.php):. #### Arguments that would be stratified as platform args. `--cloud-index-prefetch-buffer`; `--cloud-prefetch-buffer`; `--disable-bam-index-caching`; `--gcs-max-retries`; `--gcs-project-for-requester-pays`. #### Arguments that would be stratified as convenience args. `--arguments_file` ; `--help` ; `--version` ; `--create-output-bam-index` ; `--create-output-bam-md5`; `--create-output-variant-index`; `--create-output-variant-md5`; `--gatk-config-file`; `--QUIET`; `--seconds-between-progress-updates`; `--tmp-dir`; `--use-jdk-deflater`; `--use-jdk-inflater`; `--verbosity`; `--showHidden` -> I thought we had got rid of hidden args??. These could also be stratified as convenience but one could argue they affect tool behavior qualitatively:. `--disable-sequence-dictionary-validation`; `--lenient`; `--read-validation-stringency`",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5234:356,avail,available,356,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5234,1,['avail'],['available']
Availability,"## Feature request / documentation request. ### Tool(s) or class(es) involved; Reading files from non-public GCS paths. ### Description; I did not have Application Default Credentials set up when I tried to read from a private bucket. This failed, as expected. Could we add a comment explaining that running `gcloud auth application-default login` is the necessary step to making this work? I didn't see anything on the forum about how to solve this. The solution was in the comments to #2394. ### Observed; GATK errored out with a stack trace:; ```; code: 401; message: Anonymous caller does not have storage.objects.get access to joel-cram/SAM24339124.cram.; reason: required; location: Authorization; retryable: false; com.google.cloud.storage.StorageException: Anonymous caller does not have storage.objects.get access to joel-cram/SAM24339124.cram.; at com.google.cloud.storage.spi.v1.HttpStorageRpc.translate(HttpStorageRpc.java:220); at com.google.cloud.storage.spi.v1.HttpStorageRpc.get(HttpStorageRpc.java:415); at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:198); at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:195); at shaded.cloud_nio.com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:89); at com.google.cloud.RetryHelper.run(RetryHelper.java:74); at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:51); at com.google.cloud.storage.StorageImpl.get(StorageImpl.java:195); at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.checkAccess(CloudStorageFileSystemProvider.java:673); at java.nio.file.Files.exists(Files.java:2385); at htsjdk.samtools.util.IOUtil.assertFileIsReadable(IOUtil.java:429); at org.broadinstitute.hellbender.engine.ReadsDataSource.<init>(ReadsDataSource.java:206); ```. ```; Caused by: shaded.cloud_nio.com.google.api.client.googleapis.json.GoogleJsonResponseException: 401 Unauthorized; {; ""code"" : 401,; ""errors"" : [ {; ""domain"" : ""global"",; ""location"" : ""Authoriza",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5468:513,error,errored,513,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5468,1,['error'],['errored']
Availability,"## Feature request and Question. Original question was posted in GATK forum https://gatkforums.broadinstitute.org/gatk/discussion/12026/how-to-do-downsampling,; but it seems to me that the question should be posted here to ask the developer team. ### Tool(s) or class(es) involved; PrintReads. ### Description. In GATK4, printReads doesn't have an option to do downsample to coverage anymore. Is there any reason for that ? Or is there any update suggestions to do the same thing but migrating it from GATK3 to GATK4 ? The forum maintainer told me in original discussion that there is a `DownsampleSam` function in picard, but it can't be used to downsample to coverage directly.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5075:146,down,downsampling,146,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5075,4,"['Down', 'down']","['DownsampleSam', 'downsample', 'downsampling']"
Availability,"## Feature request. ### DRAGEN-GATK release?!!; Hello GATK team, ; - When will the DRAGEN-GATK version will be release officially? I have seen the online forum of Eric brans and Illumina head explaining GATK and DRAGEN about the open source version, a month back! I searched for DRAGEN-GATK update release in both the illumina website and GATK, couldn't find it? can anyone help me to get updated GATK.. and do I need dragen 3.4 for that? till 3.4.12 I haven't seen any mention of GATK in that.. which version I should download?. - Is there any feature in upcoming GATK to find STR variants.. If its in progress when it will get release?; ----",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6912:519,down,download,519,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6912,1,['down'],['download']
Availability,"## Feature request. ### Mutect2. ### Description ; In general, Mutet2 can correctly determine whether a mutation is located in the STR region, but if a mutation is not in the str region strictly, it will not be labeled as STR or any other meaningful label. In practical use, we hope that a mutation located next to the str region can also be labeled as STR, or other labels that can be used to judge, as this is crucial for correctly determining the reliability of the mutation. ; In the following example, if the mutation is determined to be STR, our filtering script will filter it out because it is obvious that the mutation is located after a series of T, which may be caused by sequencing errors. But Mutect2 did not determine it as STR, and it was determined as PASS. Eventually, the mutation was reported in our product report, and we manually deleted the site after discovering it.; ![image](https://github.com/broadinstitute/gatk/assets/66426093/4264e2a0-cefd-4a9d-92e0-69a45f26857c); ![a1d7589a482f73dfa528dd11bb24a305](https://github.com/broadinstitute/gatk/assets/66426093/f1e72d0b-eec7-4cfb-aa88-4b3077cdeab5). #### Steps to reproduce; Here are the bam, bed, shell and output files:; [chr11_108121426.zip](https://github.com/broadinstitute/gatk/files/11549460/chr11_108121426.zip). #### Expected behavior; We hope that a mutation located next to the str region can also be labeled as STR, or other labels that can be used to determine it.; Please evaluate whether it can be implemented in a later version, which is very important for us. Thank you very much!",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8340:450,reliab,reliability,450,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8340,2,"['error', 'reliab']","['errors', 'reliability']"
Availability,"## Feature request. ### Tool involved - GATK cnv_somatic_pair_workflow version 4.2.0.0; Link to main wdl - https://dockstore.org/workflows/github.com/broadinstitute/gatk/cnv_somatic_pair_workflow:4.2.0.0?tab=files. ### Description; Requesting for addition of a new feature called the `IndexFeatureFile` to be added as initial step in the `Funcotate_Segment` task of the `cnv_somatic_pair_workflow` wdl . **Detailed description:** ; An error was encountered while running the CNVSomaticPairWorkflow: `“A USER ERROR has occurred: Input /cromwell_root/fc-a21facc8-da03-4987-bb5b-dfadbfda2747/a923baec-ddd9-429a-b046-1f03c5ebda64/CNVSomaticPairWorkflow/42ba0311-ba93-4fdd-9b5e-bd7348c0ad42/call-CallCopyRatioSegmentsTumor/AMP-18-003-TIS.called.seg must support random access to enable traversal by intervals. If it's a file, please index it using the bundled tool IndexFeatureFile”`. - The FuncotateSegments task is asking an index file for the seg file, which is unusual to create an index for seg; - The same command from the cnv wdl was tested on-prem (Broad server using ish) by transferring all required files on-prem, this was done to replicate the error and find a solution without wasting compute money or resources on Terra; - To fix the issue, we initially ran Indexfilefeature tool (on-prem) for creating index file for the seg file, using the following command. ; `gatk IndexFeatureFile -I seg file`; - And then ran the main command `./gatk --java-options -Xmx2000m FuncotateSegments --data-sources-path data_sources_directory --ref-version hg19 --output-file-format SEG -R fasta_file_path --segments seg_file_path -O output_file_path/{basename}.seg.funcotated.tsv -L interval_list_path --transcript-selection-mode CANONICAL`. After this was complete, annotated file was generated correctly. In conclusion - the error identified is that `Indexfilefeature` tool had to be run as the first step. Requesting this change to be incorporated into `cnv_somatic_funcotate_seg_workflow.wdl`.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7294:435,error,error,435,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7294,4,"['ERROR', 'error']","['ERROR', 'error']"
Availability,"## Feature request. ### Tool(s) or class(es) involved. (sv) VCF producing tool(s). ### Description. The VCF spec allows `POS` column to take value 0, when the suspected event is at a telomere.; The given example is in section 5.4.5 (see example event illustrated in Figure 6 and VCF records below the figure).; However, currently GATK writes VCF via `VariantContext`'s, which defines coordinate 0 as illegal.; I can of course push this feature request to htsjdk, if that is deemed more appropriate. **UPDATE**; Looking back at the error message, it is actually the `SimpleInterval` that I use for constructing the `VariantContext` throwing the error message.; Temporary workaround would be to ""hack"" the POS to be 1 or N, and warn using an INFO annotation.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5915:531,error,error,531,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5915,2,['error'],['error']
Availability,"## Feature request. ### Tool(s) or class(es) involved. CreateSomaticPanelOfNormals. ### Description. Currently, CreateSomaticPanelOfNormals emits sites-only VCFs. Some downstream tools require full VCFs, as could be created previously in the PON CombineVariants workflow. Perhaps this feature will be covered when CombineVariants becomes available, but I believe it may still be desirable if CreateSomaticPanelOfNormals could pass `--sites-only-vcf-output=false` to allow full VCFs to be returned. This would permit calculation of mapping bias using allele frequencies of the normal samples. Thank you for your tremendous service developing this tool. Sincerely,. Andrew",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5649:168,down,downstream,168,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5649,2,"['avail', 'down']","['available', 'downstream']"
Availability,"## Feature request. ### Tool(s) or class(es) involved. Mutect2. ### Description. Currently the AD tag reports read depth, but most downstream tools expect this flag to report fragment dept. ; Add flag to M2 to modify behavior of AD and AF tags to reflect fragment counts.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7490:131,down,downstream,131,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7490,1,['down'],['downstream']
Availability,"## Feature request. ### Tool(s) or class(es) involved. SV pipeline, Funcotator, etc. ### Description. In trying to build test data for SV, time and time again we face the problem of not being able to find actual desired events on the two chromosomes 20 and 21, hence end up having to painfully perform all kinds of coordinate hacks in order to have enough test coverage. It seems that the Funcotator team is also facing a similar issue. Therefore it will be great if the whole reference genome for HG38, and maybe HG19 as well, can be included in the tests, so that tool developers spend less time worrying about hassles in moving real events to chr20 and chr21. One of the potential downside is obvious: it increases the repo size and time for running tests (downloading a bigger file) on Travis.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5111:684,down,downside,684,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5111,2,['down'],"['downloading', 'downside']"
Availability,"## Feature request. ### Tool(s) or class(es) involved. [ReferenceConfidenceVariantContextMerger](https://github.com/broadinstitute/gatk/blob/master/src/main/java/org/broadinstitute/hellbender/tools/walkers/ReferenceConfidenceVariantContextMerger.java). ### Description. In the case that VariantContexts with too many alternate alleles are passed to the joint genotyper, the genotype calculator used in the merger can experience an OOM:; ```; java.lang.OutOfMemoryError: Java heap space at org.broadinstitute.hellbender.tools.walkers.genotyper.GenotypeLikelihoodCalculator.genotypeIndexMap(GenotypeLikelihoodCalculator.java:522); at org.broadinstitute.hellbender.tools.walkers.ReferenceConfidenceVariantContextMerger.mergeRefConfidenceGenotypes(ReferenceConfidenceVariantContextMerger.java:541); at org.broadinstitute.hellbender.tools.walkers.ReferenceConfidenceVariantContextMerger.merge(ReferenceConfidenceVariantContextMerger.java:130); at org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFsEngine.callRegion(GenotypeGVCFsEngine.java:116); ```. For a ~ reasonable number of alternate alleles, this site is filtered by the [genotyping engine](https://github.com/broadinstitute/gatk/blob/48afe160c9cfba5a82e40a6be9c8a555066271d1/src/main/java/org/broadinstitute/hellbender/tools/walkers/genotyper/GenotypingEngine.java#L380-L388), but it would be helpful if the merger also had a limit to avoid fatal errors.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6962:1407,error,errors,1407,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6962,1,['error'],['errors']
Availability,"## Feature request. ### Tool(s) or class(es) involved; All WDL tests (Mutect2, CNV, Mitochondria pipeline, etc). ### Description; I'd like to be able to include tasks in GATK WDLs that use NIO (tasks with `String input_file` rather than `File input_file`). When I tried this with local git lfs files I got an error saying that the file could not be found (even though the file was being downloaded correctly). I then tried putting the file in `gs://hellbender/test/resources/large`, but when the tool tried to run on travis I got a permission error (see below). It would be great if the WDL tests all ran in the cloud since that's the main way we expect to run these WDLs. It would also be great it the local tests could account for NIO tasks (especially as we want to make more tasks use NIO in the future). ```; com.google.cloud.storage.StorageException: Error code 404 trying to get security access token from Compute Engine metadata for the default service account. This may be because the virtual machine instance does not have permission scopes specified. It is possible to skip checking for Compute Engine metadata by specifying the environment variable NO_GCE_CHECK=true.; at com.google.cloud.storage.spi.v1.HttpStorageRpc.translate(HttpStorageRpc.java:227); at com.google.cloud.storage.spi.v1.HttpStorageRpc.get(HttpStorageRpc.java:438); at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:239); at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:236); at shaded.cloud_nio.com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:105); at com.google.cloud.RetryHelper.run(RetryHelper.java:76); at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:50); at com.google.cloud.storage.StorageImpl.get(StorageImpl.java:235); at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.checkAccess(CloudStorageFileSystemProvider.java:687); at java.nio.file.Files.exists(Files.java:2385); at htsjdk.samtools.util.IOUtil.asse",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5855:309,error,error,309,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5855,4,"['Error', 'down', 'error']","['Error', 'downloaded', 'error']"
Availability,"## Feature request. ### Tool(s) or class(es) involved; CNNScoreVariants and perhaps other tools. ### Description; It would be nice to take stdout as the input. For example, when it is necessary to pass raw VCF from caller to CNNScoreVariants. In the current version, an error is produced. ```; zcat /home/platon/Dissertation/Exp/ngs_test/no_filtered.vcf.gz | gatk CNNScoreVariants \; -V /dev/stdin \; -R /home/platon/Dissertation/Exp/ngs_test/homo_sapiens/Homo_sapiens.GRCh38.dna.primary_assembly.fa.gz \; -O /home/platon/Dissertation/Exp/Output; ```. ```; Using GATK jar /home/platon/miniconda3/share/gatk4-4.1.8.1-0/gatk-package-4.1.8.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /home/platon/miniconda3/share/gatk4-4.1.8.1-0/gatk-package-4.1.8.1-local.jar CNNScoreVariants -V /dev/stdin -R /home/platon/Dissertation/Exp/ngs_test/homo_sapiens/Homo_sapiens.GRCh38.dna.primary_assembly.fa.gz -O /home/platon/Dissertation/Exp/Output; 18:04:27.033 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/platon/miniconda3/share/gatk4-4.1.8.1-0/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Aug 26, 2020 6:04:27 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 18:04:27.246 INFO CNNScoreVariants - ------------------------------------------------------------; 18:04:27.246 INFO CNNScoreVariants - The Genome Analysis Toolkit (GATK) v4.1.8.1; 18:04:27.246 INFO CNNScoreVariants - For support and documentation go to https://software.broadinstitute.org/gatk/; 18:04:27.246 INFO CNNScoreVariants - Executing as platon@platon-VivoBook-ASUSLaptop-X712FA-X712FA on Linux v5.4.0-42-generic amd64; 18:04:27.246 INFO CNNScoreVariants - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_192-b01; 18:04:27.247",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6749:270,error,error,270,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6749,1,['error'],['error']
Availability,"## Feature request. ### Tool(s) or class(es) involved; DepthOfCoverage --intervals parameter. ### Description; Please supply an example of how intervals should be used. I just want to run DepthOfCoverage over the entire reference sequence (imho this should be the default and make --include optional), but cant work out how to do this. I tried. DepthOfCoverage other_parameters --intervals 1-30000; DepthOfCoverage other_parameters --intervals 1:30000. Both gave errors.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7155:463,error,errors,463,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7155,1,['error'],['errors']
Availability,"## Feature request. ### Tool(s) or class(es) involved; Docker image. ### Description; We've been using this function in the GATK-SV WDLs to estimate the appropriate `-XmX` Java parameter for GATK tools:; ```; function getJavaMem() {; # get JVM memory in MiB by getting total memory from /proc/meminfo; # and multiplying by java_mem_fraction; cat /proc/meminfo \; | awk -v MEM_FIELD=""$1"" '{; f[substr($1, 1, length($1)-1)] = $2; } END {; printf ""%dM"", f[MEM_FIELD] * ~{default=""0.85"" java_mem_fraction} / 1024; }'; }; JVM_MAX_MEM=$(getJavaMem MemTotal); echo ""JVM memory: $JVM_MAX_MEM""; gatk --java-options ""-Xmx${JVM_MAX_MEM}"" …; ```; We've found this to be a reliable method because it uses the VM's actual memory rather than what was requested, which can be less than what is actually provided. This would be a generally useful utility function to build into the Docker for use across GATK WDLs.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7941:553,echo,echo,553,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7941,2,"['echo', 'reliab']","['echo', 'reliable']"
Availability,"## Feature request. ### Tool(s) or class(es) involved; Funcotator (auxiliary file). ### Description; We have a preferred transcript list for hg19 (i.e. GENCODE v19), but we do not have one for hg38 (latest version supported by Funcotator -- currently v29). There is a script in the oncotator repository for helping to create this list, but it does not have the manual curation. Please see @LeeTL1220 for details on this process. The oncotator datasource download page has the automatically-generated transcript list for gencode v19 alongside the automatically-generated+manual curation list. That can be used to suss out differences. Automatically-generated list was obtained by aligning transcripts to uniprot. I am not sure how the transcript IDs changed between GENCODE v19 and v29. So the complexity of this issue is still a bit unknown.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5914:454,down,download,454,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5914,1,['down'],['download']
Availability,"## Feature request. ### Tool(s) or class(es) involved; Funcotator. ### Description; Currently, the location of config files that specify the formats for SEG file output are hardcoded in the FuncotatorEngine. These should be available to to override via parameters to the FuncotatorEngine during initialization.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5962:224,avail,available,224,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5962,1,['avail'],['available']
Availability,"## Feature request. ### Tool(s) or class(es) involved; GATK PrintReads. ### Description; - Currently, this tool appears to consider reads independently of their mate, therefore if one partner is filtered and the other is not the SAM flags for the remaining read will be incorrect (indeed resulting BAMs from this tool fail GATK ValidateSamReads with error MATE_NOT_FOUND). ; - Here is a flagstat of one of these BAMs produced from this tool (note that there are no singleton reads listed, but they actually present -- you can even see this in the read1 and read2 counts; these counts should be equal if there are no supplementary, secondary, and/or singleton reads):. ```; 179466279 + 0 in total (QC-passed reads + QC-failed reads); 0 + 0 secondary; 0 + 0 supplementary; 0 + 0 duplicates; 179466279 + 0 mapped (100.00% : N/A); 179466279 + 0 paired in sequencing; 89740338 + 0 read1; 89725941 + 0 read2; 179466279 + 0 properly paired (100.00% : N/A); 179466279 + 0 with itself and mate mapped; 0 + 0 singletons (0.00% : N/A); 0 + 0 with mate mapped to a different chr; 0 + 0 with mate mapped to a different chr (mapQ>=5); ```. - I have two suggestions:; - Add a `--remove-mates` option that would ensure that if one read in a pair does not pass the read filters, the read pair will be filtered.; - Alternatively, add an `--update-flags` option that would update the filtered-in mate's SAM flags to be technically correct (i.e. if the read's partner was filtered, remove the 0x1, 0x2, 0x8, 0x20, 0x40, and 0x80 flags if they were present)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6839:350,error,error,350,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6839,1,['error'],['error']
Availability,"## Feature request. ### Tool(s) or class(es) involved; GenomicsDBImport(v4.1.8.1). ### Description; Hello, I was construct to genomicdb using GenomicDBImport and import gvcf file for update genomicdb(Command). but since my server was shut down, during GenomicDBImport process, process is broke down. After I tried to GenomicDBImport same command for overwrite genomicdb and encounter to error message(error message).; ; In this case, should genomicdb be recreated from scratch? How to update the gvcf file I want to update? what should I do?. ### Command. java -jar $GATK GenomicsDBImport \; -L chr${1} \; -V $File_PATH/4762/bwa-gatk4/VARIANT/ForEachChr/chr22.g.vcf \; -V $File_PATH/4763/bwa-gatk4/VARIANT/ForEachChr/chr22.g.vcf \; -V $File_PATH/4764/bwa-gatk4/VARIANT/ForEachChr/chr22.g.vcf \; -V $File_PATH/4765/bwa-gatk4/VARIANT/ForEachChr/chr22.g.vcf \; -V $File_PATH/4767/bwa-gatk4/VARIANT/ForEachChr/chr22.g.vcf \; --genomicsdb-update-workspace-path $DB_PATH/test_database \; --genomicsdb-shared-posixfs-optimizations true \; --max-num-intervals-to-import-in-parallel 5 \; --reader-threads 10 \; --tmp-dir $Script_PATH/tmp. ### Error message. 10:49:12.018 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/mnt/mone/OMICS/Tools/Programs/gatk/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Jun 18, 2021 10:49:12 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 10:49:12.231 INFO GenomicsDBImport - ------------------------------------------------------------; 10:49:12.232 INFO GenomicsDBImport - The Genome Analysis Toolkit (GATK) v4.1.8.1; 10:49:12.232 INFO GenomicsDBImport - For support and documentation go to https://software.broadinstitute.org/gatk/; 10:49:12.232 INFO GenomicsDBImport - Executing as chowoo1023@bdcm04 on Linux v3.10.0-514.2.2.el7.x86_64 amd64; 10:49:12.232 INFO GenomicsDBImport - Java runtim",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7324:239,down,down,239,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7324,4,"['down', 'error']","['down', 'error']"
Availability,"## Feature request. ### Tool(s) or class(es) involved; GenomicsDBImport. ### Description; Users get confused by this error message: `A USER ERROR has occurred: Couldn't create GenomicsDBFeatureReader`; `Caused by: java.io.IOException: GenomicsDB JNI Error: VariantQueryProcessorException : Could not open array 1$1$249250621 at workspace: ...; TileDB error message : [TileDB::BookKeeping] Error: Cannot load book-keeping; Reading tile offsets failed`. In one of our [docs](https://gatk.broadinstitute.org/hc/en-us/articles/360035889971--How-to-Consolidate-GVCFs-for-joint-calling-with-GenotypeGVCFs), we offer this advice, but this is not a proper argument in the GATK tool docs yet:; _If you’re working on a POSIX filesystem (e.g. Lustre, NFS, xfs, ext4 etc), you must set the environment variable TILEDB_DISABLE_FILE_LOCKING=1 before running any GenomicsDB tool. If you don’t, you will likely see an error like Could not open array genomicsdb_array at workspace:[...]_. **This request is to add a proper argument to deal with this scenario in GenomicsDBImport and to document it in the tool docs.**",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6519:117,error,error,117,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6519,6,"['ERROR', 'Error', 'error']","['ERROR', 'Error', 'error']"
Availability,"## Feature request. ### Tool(s) or class(es) involved; GermlineCNVCaller / PostprocessGermlineCNVCalls. ### Description; The VCF produced by the germline CNV calling workflow could be nicer. TBH the VCF output feels like a bit of an afterthought compared to the other outputs. This seems common for CNV callers, but I was hoping the VCF produced by the GATK would be more complete. Things that would make the VCF easier to use/interpret with downstream tooling:. 1. `##contig` lines in the header. `PostprocessGermlineCNVCalls` takes in a sequence dictionary, and I was surprised that isn't used in generating the VCF.; 2. Every record in the VCF has both `<DUP>` and `<DEL>` as alts even though the VCF is single-sample and a given sample can only be duplicated _or_ deleted. This makes quick text-searching of the VCF difficult and means one has to parse the genotypes to determine if the record represents a duplication or deletion in the sample.; 3. QUAL is `.` for all events. There are various quality scores in the FORMAT/GENOTYPE fields. It would be nice if either the preferred one of those or some other quality measure could be emitted into the QUAL field.; 4. There's nothing in the VCF that gives any indication of the observed read depth or correlated measures, only the called CN. Having either the mean depth over the segment or the raw & denoised copy ratios for the segment etc. would be helpful for manual review.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6167:442,down,downstream,442,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6167,1,['down'],['downstream']
Availability,"## Feature request. ### Tool(s) or class(es) involved; LearnReadOrientation (& others I believe). ### Description; Wondering if you would consider modifying the exit status for 'java.lang.OutOfMemoryError` to reflect it being a memory-related error, perhaps `137`? This would help with pipelines that will retry with more memory in response to a memory-related error. The exit status is currently a generic `1`:. ```; Command exit status:; 1. ...; [March 23, 2023 at 5:50:17 AM GMT] org.broadinstitute.hellbender.tools.walkers.readorientation.LearnReadOrientationModel done. Elapsed time: 2,210.83 minutes.; Runtime.totalMemory()=7796817920; Exception in thread ""main"" java.lang.OutOfMemoryError: Java heap space; at org.apache.commons.math3.linear.Array2DRowRealMatrix.<init>(Array2DRowRealMatrix.java:61); at org.broadinstitute.hellbender.tools.walkers.readorientation.LearnReadOrientationModelEngine.<init>(LearnReadOrientationModelEngine.java:131); at org.broadinstitute.hellbender.tools.walkers.readorientation.LearnReadOrientationModel.doWork(LearnReadOrientationModel.java:163); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:149); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:198); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:217); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289); Using GATK jar /gatk/gatk-package-4.4.0.0-local.jar; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8264:243,error,error,243,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8264,2,['error'],['error']
Availability,"## Feature request. ### Tool(s) or class(es) involved; M2 WDL and FC deployment of M2. ### Description; We should specify the same file listed in the GATK forum (https://gatkforums.broadinstitute.org/gatk/discussion/4154/howto-install-and-run-oncotator-for-the-first-time), which can be downloaded from: https://personal.broadinstitute.org/lichtens/oncobeta/tx_exact_uniprot_matches.AKT1_CRLF2_FGFR1.txt; This should be used as the default transcript selection list for funcotator (@jonn-smith I assume that funcotator and oncotator use the same format for this file. Please confirm.). The only time you would not want this file is if you are not running on hg19. For other references, ideally, we would want different lists. - This list needs to be put into a bucket (gatk-best-practices?); - Please notify @bshifaw for deployment in the FC featured workspace in the appropriate funcotator parameter.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5841:287,down,downloaded,287,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5841,1,['down'],['downloaded']
Availability,"## Feature request. ### Tool(s) or class(es) involved; MuTect2 wdl (mutect2.wdl), task Funcotate. ### Description; May I know if it sounds like a good idea to add a option to skip the ""Extract our data sources"" part in mutect2.wdl. I am using mutect2.wdl in HPC system and all the data sources and gnomad for Funcotate were unzipped and ready to use. So there is no need to ""Extract data sources"" every time (and save time and resources). I can change it and make a pull request if it sounds like a good idea. The code in mutect2.wdl that I'm going to make an option to skip listed below:. # Extract our data sources:; echo ""Extracting data sources zip file...""; mkdir datasources_dir; tar zxvf ~{data_sources_tar_gz} -C datasources_dir --strip-components 1; DATA_SOURCES_FOLDER=""$PWD/datasources_dir"". # Handle gnomAD:; if ~{use_gnomad} ; then; echo ""Enabling gnomAD...""; for potential_gnomad_gz in gnomAD_exome.tar.gz gnomAD_genome.tar.gz ; do; if [[ -f ~{dollar}{DATA_SOURCES_FOLDER}/~{dollar}{potential_gnomad_gz} ]] ; then; cd ~{dollar}{DATA_SOURCES_FOLDER}; tar -zvxf ~{dollar}{potential_gnomad_gz}; cd -; else; echo ""ERROR: Cannot find gnomAD folder: ~{dollar}{potential_gnomad_gz}"" 1>&2; false; fi; done; fi. ----",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6731:619,echo,echo,619,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6731,4,"['ERROR', 'echo']","['ERROR', 'echo']"
Availability,"## Feature request. ### Tool(s) or class(es) involved; SelectVariants/GenotypeGVCFs/GnarlyGenotyper. ### Description; GenomicsDBExportConfiguration allows for the following to be configured - currently they are mostly hardcoded - `produceGTField`, `produceGTWithMinPLValueForSpanningDeletions`, `setSitesOnlyQuery`, `maxDiploidAltAllelesThatCanBeGenotyped` and `maxGenotypeCount`. Most of this functionality was implemented to support various use cases at some point. Look at the current arguments for subsetting/downsampling/filtering/joint genotyping in the tools and hook existing tool arguments with GenomicsDBExportConfiguration as needed.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6456:513,down,downsampling,513,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6456,1,['down'],['downsampling']
Availability,"## Feature request. ### Tool(s) or class(es) involved; ValidateBasicSomaticShortMutations . ### Description; It turns out that this tool is doing a subset of the CGA tool, MutationValidator. Originally, the understanding (by both DSP and CGA) was the the GATK tool was doing a different algorithm, but this turned out to be incorrect. We should rename the GATK tool perhaps to SomaticShortMutationValidator and cite MutationValidator. Any relevant WDL should be updated to prevent unnecessary workflow failures. @davidbenjamin . (citation does not exist as per last offline meeting with CGA)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5871:502,failure,failures,502,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5871,1,['failure'],['failures']
Availability,"## Feature request. ### Tool(s) or class(es) involved; VariantFiltration. ### Description; While running variantFiltration, I have encountered the following error:; ```; java.lang.NumberFormatException: For input string: ""nan""; at sun.misc.FloatingDecimal.readJavaFormatString(FloatingDecimal.java:2043); at sun.misc.FloatingDecimal.parseDouble(FloatingDecimal.java:110); at java.lang.Double.parseDouble(Double.java:538); at org.apache.commons.jexl2.JexlArithmetic.toDouble(JexlArithmetic.java:1016); at org.apache.commons.jexl2.JexlArithmetic.compare(JexlArithmetic.java:699); at org.apache.commons.jexl2.JexlArithmetic.lessThan(JexlArithmetic.java:774); at org.apache.commons.jexl2.Interpreter.visit(Interpreter.java:967); at org.apache.commons.jexl2.parser.ASTLTNode.jjtAccept(ASTLTNode.java:18); at org.apache.commons.jexl2.Interpreter.interpret(Interpreter.java:232); at org.apache.commons.jexl2.ExpressionImpl.evaluate(ExpressionImpl.java:65); at htsjdk.variant.variantcontext.JEXLMap.evaluateExpression(JEXLMap.java:186); at htsjdk.variant.variantcontext.JEXLMap.get(JEXLMap.java:95); at htsjdk.variant.variantcontext.JEXLMap.get(JEXLMap.java:15); at htsjdk.variant.variantcontext.VariantContextUtils.match(VariantContextUtils.java:338); at org.broadinstitute.hellbender.tools.walkers.filters.VariantFiltration.matchesFilter(VariantFiltration.java:379); at org.broadinstitute.hellbender.tools.walkers.filters.VariantFiltration.filter(VariantFiltration.java:338); at org.broadinstitute.hellbender.tools.walkers.filters.VariantFiltration.apply(VariantFiltration.java:298); at org.broadinstitute.hellbender.engine.VariantWalkerBase.lambda$traverse$0(VariantWalkerBase.java:153); at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5582:157,error,error,157,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5582,1,['error'],['error']
Availability,"## Feature request. ### Tool(s) or class(es) involved; _Funcotator_, _DataSourceFuncotationFactory_. ### Description; Funcotator should support NIO for data sources and data sources backing files.; In addition, the data source readers should be updated to support multiple backing files to support the `gnomAD` case (http://gnomad.broadinstitute.org/downloads).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5348:350,down,downloads,350,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5348,1,['down'],['downloads']
Availability,"## Feature request. ### Tool(s) or class(es) involved; _Funcotator_. ### Description; Currently the data sources for the clinical pipeline work contain ExAC. This must be updated to use gnomAD. The change will require a new release of the data sources which must be connected to the data source downloader tool. Additionally, these new data sources must be validated in four ways:; - By visually inspecting the gnomAD source file for correctness.; - By verifying that the source file for gnomAD does not contain special characters.; - By validating that the source file for gnomAD is a valid VCF (assuming it is used VCF format).; - By running a large file and spot checking at least 10 variants for correctness. ----",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5259:295,down,downloader,295,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5259,1,['down'],['downloader']
Availability,"## Feature request. ### Tool(s) or class(es) involved; _Funcotator_. ### Description; When running Funcotator on a large VCF, it can take several hours to complete, but each variant row is handled separately, row 1 and row 5 million are equally likely to have problems. Currently, a sufficiently malformed variant row causes it to crash and leave partial output. . It would be much friendlier if the true crash problems (e.g. something like ""invalid interval"") were saved and the crash-causing variant lines reported in bulk at completion, sending an OS exit code/error then. . It might even be a configurable option to exit immediately or save until end. . I do think it is appropriate to crash if a problem is encountered while parsing the header lines.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7097:564,error,error,564,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7097,1,['error'],['error']
Availability,"## Feature request. ### Tool(s) or class(es) involved; _GATK VariantEval_. ### Description; Currently, if I provide a VCF to VariantEval together with a dbSNP file, but the input VCF does not variants on all chromosomes or contigs from the dbSNP, the tool will fail. ; The current solution is to always check the input VCF for all chromosomes/contigs where mutations exist, and then filter the dbSNP file to keep only the entries with those some chromosomes. ; Would it be possible to allow for the use of a full dbSNP file with GATK VariantEval, regardless of whether the input VCF has variants on all chromosomes that exist in the dbSNP or not?. More info on a forum post as well: ; https://gatk.broadinstitute.org/hc/en-us/community/posts/360072397571-VariatEval-ERROR-",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6855:766,ERROR,ERROR,766,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6855,1,['ERROR'],['ERROR']
Availability,## Feature request. ### Tool(s) or class(es) involved; _GencodeFuncotationFactory_. ### Description; Currently the mitochondrial contig is determined using a simple string comparison by contig name. ; This determination is then used to decode the mitochondrial protein sequence (which gets decoded differently than the normal gene sequences). Make this more robust by detecting the mito contig based on the reference used.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5364:358,robust,robust,358,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5364,1,['robust'],['robust']
Availability,"## Feature request. ### Tool(s) or class(es) involved; `SelectVariants`. ### Description; In order to run SelectVariants with VCF inputs that are in separate locations from their index files or to stream SelectVariants using https from Azure blob storage, we need a way to provide the index file in a separate argument from the `-V` input. @jamesemery started thinking this through (copying this from slack):. > In `featureDataSource.getTribbleFeatureReader()` we currently initialize the datasources in `getFeatureReader()` which gets called by `VariantWalker.initializeDrivingVariants()` . You could stick an override into that where you thread down the path for the index source through that path and optionally (only if the index is explicitly supplied by the user) push it down into the `getTribbleFeatureReader()` calls at the bottom of the stack there. @droazen any thoughts on this? @VJalili Would adding this feature to `SelectVariants` be useful for your pipelines at all?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8568:647,down,down,647,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8568,2,['down'],['down']
Availability,"## Feature request. Make joint genotyping functionality available as a publicly accessible function to another class/program without passing through the GATK command line interface. ### Tool(s) or class(es) involved; VariantContext; GenotypeGVCFs; Underlying engine classes. ### Description; For various use cases where our pipelines produce in-memory VariantContext objects it would be faster and easier to pass these directly to a joint genotyping function and extract the results back into memory rather than writing to VCF, running the GenotypeGVCFs pipeline via the command line interface and then re-ingesting the resultant VCFs. From discussions during the GATK Working Group meetings it appears this request is similar in principle to existing functionality for the HaplotypeCaller that was implemented by ""extracting the engine"" from the HaplotypeCaller walkers so that it can be instantiated outside the command line utility. Ideally, this implementation should make it possible to instantiate any necessary engine classes pass VariantContext objects directly to the GenotypeGVCFs.apply or GenotypeGVCFs.regenotypeVC and receive the re-genotyped VariantContext objects back for further processing from Java code. . ----",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5910:56,avail,available,56,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5910,1,['avail'],['available']
Availability,## Feature request. The mitochondria pipeline should have new annotations and filters in Mutect2 and FilterMutectCalls. This is being addressed in #5193. An accompanying best practices WDL should also be developed and eventually be available in Firecloud. I'll update here once the PR is merged and has been released.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5310:232,avail,available,232,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5310,1,['avail'],['available']
Availability,"## Feature request; ### HaplotypeCaller; When running HaplotypeCaller, I get tens of thousands of lines like the following:; ```; 13:02:04.113 WARN DepthPerSampleHC - Annotation will not be calculated, genotype is not called or alleleLikelihoodMap is null; 13:02:04.113 WARN StrandBiasBySample - Annotation will not be calculated, genotype is not called or alleleLikelihoodMap is null; 13:02:04.113 WARN DepthPerSampleHC - Annotation will not be calculated, genotype is not called or alleleLikelihoodMap is null; 13:02:04.113 WARN StrandBiasBySample - Annotation will not be calculated, genotype is not called or alleleLikelihoodMap is null; ```; The problem is they are not informative: you can't tell what position/region caused them. Resulting repetitive messages are redundant.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5912:771,redundant,redundant,771,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5912,1,['redundant'],['redundant']
Availability,"## Feature request; ### Tool(s) involved. Engine; ### Description. An ENUM with several levels of minimalism. Main use case: keeping down the lines of SQ. As put by @eitanbanks . > One thing that option would do would be to _not_ print out all of the reference contigs. While it's not terrible in b37, you should know that hg38 has thousands upon thousands of contigs and it's such a pain to have them all in the header. Simplest way to do this imho (and I would advocate making it the default GATK behavior): write to VCF header SQ lines representing only the contigs for which we have calls. More discussion needed to define exactly what options should distinguished.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2233:133,down,down,133,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2233,1,['down'],['down']
Availability,## Feature request; ### Tool(s) involved. VariantRecalibrator; ### Description. A user reported he gets an `##### ERROR MESSAGE: No data found.` from VariantRecalibrator when running with -an MQ twice. There should be a check for this and an error message letting the user know he/she has specified the same annotation twice. . [Original Forum Post](http://gatkforums.broadinstitute.org/gatk/discussion/comment/33592#Comment_33592). ---,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2221:114,ERROR,ERROR,114,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2221,2,"['ERROR', 'error']","['ERROR', 'error']"
Availability,"## System. * GATK4 a1eee32e84c21c2f265d248c5f47789ae0ba2b37; * Mac OS X 10.11.6 x86_64; * machdep.cpu.features: FPU VME DE PSE TSC MSR PAE MCE CX8 APIC SEP MTRR PGE MCA CMOV PAT PSE36 CLFSH DS ACPI MMX FXSR SSE SSE2 SS HTT TM PBE SSE3 DTES64 MON DSCPL VMX SMX EST TM2 SSSE3 CX16 TPR PDCM SSE4.1 SSE4.2 POPCNT; * machdep.cpu.extfeatures: SYSCALL XD EM64T LAHF RDTSCP TSCI; * java version ""1.8.0_60""; * Java(TM) SE Runtime Environment (build 1.8.0_60-b27); * Java HotSpot(TM) 64-Bit Server VM (build 25.60-b23, mixed mode). ## Error. When updating a downstream project with the latest master and running the integration/unit tests with gradle, it generates the following error. ```; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGILL (0x4) at pc=0x00000001236427f4, pid=4010, tid=20739; #; # JRE version: Java(TM) SE Runtime Environment (8.0_60-b27) (build 1.8.0_60-b27); # Java VM: Java HotSpot(TM) 64-Bit Server VM (25.60-b23 mixed mode bsd-amd64 compressed oops); # Problematic frame:; # C [libgkl_compression7227189416687158431.dylib+0x17f4] Java_com_intel_gkl_compression_IntelDeflater_resetNative+0x164; #; # Failed to write core dump. Core dumps have been disabled. To enable core dumping, try ""ulimit -c unlimited"" before starting Java again; #; # An error report file with more information is saved as:; # /Users/daniel/workspaces/ReadTools/hs_err_pid4010.log; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; # The crash happened outside the Java Virtual Machine in native code.; # See problematic frame for where to report the bug.; #; ```. Error report file: [hs_err_pid4010.log.txt](https://github.com/broadinstitute/gatk/files/1259963/hs_err_pid4010.log.txt). ## Forcing other GKL versions. * 0.5.2 (working); * 0.5.3 (failing); * 0.5.5 (failing); * 0.5.6 (failing); * 0.5.7 (failing); * 0.5.8 (failing)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3532:525,Error,Error,525,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3532,6,"['Error', 'down', 'error']","['Error', 'downstream', 'error']"
Availability,"## System; * Mac OS X 10.11.6 x86_64; * Java HotSpot(TM) 64-Bit Server VM 1.8.0_60-b27. ## Problem; I'm trying to update my project ([ReadTools](https://github.com/magicDGS/ReadTools)) to the latest version of GATK and this dependency throws the following error with some of my gradle tests and while running an uber-jar (using `--use_jdk_deflater false`):. ```; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGILL (0x4) at pc=0x000000011d925644, pid=7088, tid=20739; #; # JRE version: Java(TM) SE Runtime Environment (8.0_60-b27) (build 1.8.0_60-b27); # Java VM: Java HotSpot(TM) 64-Bit Server VM (25.60-b23 mixed mode bsd-amd64 compressed oops); # Problematic frame:; # C [libgkl_compression8215566221555962564.dylib+0x1644] Java_com_intel_gkl_compression_IntelDeflater_resetNative+0x164; #; # Failed to write core dump. Core dumps have been disabled. To enable core dumping, try ""ulimit -c unlimited"" before starting Java again; #; # An error report file with more information is saved as:; # /Users/daniel/workspaces/ReadTools/hs_err_pid7088.log; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; # The crash happened outside the Java Virtual Machine in native code.; # See problematic frame for where to report the bug.; #; ```. Find attached the log: [hs_err_pid7088.log.txt](https://github.com/broadinstitute/gatk/files/652421/hs_err_pid7088.log.txt)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2315:256,error,error,256,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2315,3,['error'],['error']
Availability,"### Affected class(es); All test classes in GATK (and downstream projects) extending `BaseTest`. ### Affected version(s); - [x] Latest public release version; - [x] Latest master branch. ### Description ; The GATK toolkit assumes `US` locale (set in a `Main` static method), which in turn produces all the test files using the `US` locale; if the test suite is run in a different locale, it might fail unexpectedly. For example, if the locale has a comma-separated decimals instead of dot-separated, comparing the expected file output with `US` locale against the generated by the tests fail. . #### Expected behavior; `BaseTest` should set the locale in a `@BeforeSuite` method (or static method) to set the assumptions of the toolkit to all tests (also for downstream toolkits). #### Actual behavior; `BaseTest` picks default locale.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5012:54,down,downstream,54,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5012,2,['down'],['downstream']
Availability,"### Affected tool(s) or class(es). VariantFiltration. ### Affected version(s). Master 2021-01 onwards. ### Description . VariantFiltration's --invalidate-previous-filters prevent any output variant to be marked as PASS even if it passes the filters that are passed to that run of the filtration tool. What I would expect is that variants that pass the current set of filters will be marked as PASS regarless whether they were filtered or not filtered (PASS, or '.') in the input. . Perhaps the case is that this option is not meant.to be used with current/new filters being specified as to provide a way to revert previous filtration, but in that case it should fail if new filters are specified. #### Steps to reproduce. Just try it out with a VCF with some filters already applied and run VF with additional filters that will not result in all variants to be filtered. . You will see that no output variant is set To PASS but rather are kept as unknown '.' . #### Expected behavior. Either it does fail if a new filter is applied in the same tool run or passing variants filter are setlp to Pw. #### Actual behavior. Described above, no error message and no pass variants only ""."" ones.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7608:1139,error,error,1139,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7608,1,['error'],['error']
Availability,"### Affected tool(s) or class(es); GenotypeGVCFs is reporting:; ```. [TileDB::ArrayIterator] Error: Cannot advance iterator; Buffer overflow.; terminate called after throwing an instance of 'VariantStorageManagerException'; what(): VariantStorageManagerException exception : VariantArrayCellIterator increment failed; TileDB error message : [TileDB::ArrayIterator] Error: Cannot advance iterator; Buffer overflow; ```. ### Affected version(s); ```; Using GATK jar /home/xuql/miniconda3/share/gatk4-4.2.6.1-1/gatk-package-4.2.6.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /home/xuql/miniconda3/share/gatk4-4.2.6.1-1/gatk-package-4.2.6.1-local.jar --version; The Genome Analysis Toolkit (GATK) v4.2.6.1; HTSJDK Version: 2.24.1; Picard Version: 2.27.1. ```. ### Description ; Hi, I developed AnchorWave to call long indels(could be a couple of Mb). We are trying to connect the AnchorWave variant calling result with GATK to generate VCF files. We generated whole genome alignments for 26 maize accession via AnchorWave. And we wrote out own code to generate GVCF files from the outputs of AnchorWave. Those GVCF files works well with GATK GenomicsDBImport. While, the `GenotypeGVCFs` function is reporting `Buffer overflow` errors and could generate the complete VCF files. . Here is the command we used:. ```; gatk --java-options ""-Xmx100g"" GenotypeGVCFs -R Zm-B73-REFERENCE-NAM-5.0.fa -stand-call-conf 0 -ploidy 1 -V gendb:///home/xuql/NAM_anchorwave_song/NAM_out_gatk9 -O gatk9.vcf.gz --cloud-prefetch-buffer 10000 --cloud-index-prefetch-buffer 10000 --genomicsdb-max-alternate-alleles 110 --max-alternate-alleles 100 --tmp-dir /home/xuql/NAM_anchorwave_song/temp9 --gcs-max-retries 1000; ```; ----",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7976:93,Error,Error,93,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7976,4,"['Error', 'error']","['Error', 'error', 'errors']"
Availability,"### Affected tool(s) or class(es); HaplotypeCallerSpark. gatk HaplotypeCallerSpark -R GRCh38_full_analysis_set_plus_decoy_hla.fa -I GatherBamFiles.bam -O g.vcf.gz. The HaplotypeCaller works, but not HaplotypeCallerSpark.; Tried to use the docker image, and different server; tried to build the newest gatk, same error message. ### Affected version(s); - [ x ] Latest public release version 4.1.8.1; java version ; ```; openjdk version ""1.8.0_152-release""; OpenJDK Runtime Environment (build 1.8.0_152-release-1056-b12); OpenJDK 64-Bit Server VM (build 25.152-b12, mixed mode); ```. ### Description ; keep get the error message like below. ```; Using GATK jar /cache/home/xc278/p/GATK/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Dsamjdk.compression_level=5 -Xms10G -jar /cache/home/xc278/p/GATK/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar HaplotypeCallerSpark -R GRCh38_full_analysis_set_plus_decoy_hla.fa -I SRR1573206.GatherBamFiles.bam -O SRR1573206.g.vcf.gz -G StandardAnnotation -G StandardHCAnnotation -G AS_StandardAnnotation -GQB 10 -GQB 20 -GQB 30 -GQB 40 -GQB 50 -GQB 60 -GQB 70 -GQB 80 -GQB 90 -ERC GVCF; 09:38:05.617 WARN GATKAnnotationPluginDescriptor - Redundant enabled annotation group (StandardAnnotation) is enabled for this tool by default; 09:38:05.617 WARN GATKAnnotationPluginDescriptor - Redundant enabled annotation group (StandardHCAnnotation) is enabled for this tool by default; 09:38:05.655 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/cache/home/xc278/p/GATK/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Aug 15, 2020 9:38:05 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 09:38:05.911 INFO HaplotypeCallerSpark -",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6750:312,error,error,312,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6750,2,['error'],['error']
Availability,"### Affected tool(s) or class(es); docker version GATK:4.1.1.0. ### Affected version(s); ; latest release. ### Description ; Funcotator shuts down part way through job. A configuration problem @ google?; [funcotator_crash.txt](https://github.com/broadinstitute/gatk/files/3652568/funcotator_crash.txt). RuntimeException: java.util.concurrent.ExecutionException: com.google.cloud.storage.StorageException: www.googleapis.com; ; ### Description . 04:13:19.667 INFO ProgressMeter - 15:85753672 1834.2 199000 108.5; 04:17:42.593 INFO VcfFuncotationFactory - dbSNP 9606_b150 cache hits/total: 0/0; 04:17:42.593 INFO VcfFuncotationFactory - gnomAD_exome 2.1 cache hits/total: 0/1402; 04:17:42.593 INFO VcfFuncotationFactory - gnomAD_genome 2.1 cache hits/total: 0/162233; 04:17:42.665 INFO Funcotator - Shutting down engine; [September 25, 2019 4:17:42 AM UTC] org.broadinstitute.hellbender.tools.funcotator.Funcotator done. Elapsed time: 1,845.78 minutes.; Runtime.totalMemory()=4523032576; java.lang.RuntimeException: java.util.concurrent.ExecutionException: com.google.cloud.storage.StorageException: www.googleapis.com; at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher.read(SeekableByteChannelPrefetcher.java:318); at htsjdk.samtools.seekablestream.SeekablePathStream.read(SeekablePathStream.java:86); at java.io.BufferedInputStream.fill(BufferedInputStream.java:246); at java.io.BufferedInputStream.read1(BufferedInputStream.java:286)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6182:142,down,down,142,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6182,2,['down'],['down']
Availability,"### Affected tool(s) or class(es); gatk DownsampleSam. ### Affected version(s); GATK v4.3.0.0. ### Description ; Input cram file (gs://broad-public-datasets/CHM1_CHM13_WGS2/CHM1_CHM13_WGS2.cram) ; has NM tags, but the downsampled output file no longer has them. My command-line is ; ```; gatk DownsampleSam REFERENCE_SEQUENCE=/hg38.fa I=CHM1_CHM13_WGS2.cram P=0.5 CREATE_INDEX=true O=CHM1_CHM13_WGS2.downsampled.bam ; ```. Some downstream tools require NM tags, so I have to run . `samtools calmd CHM1_CHM13_WGS2.downsampled.bam /hg38.fa`. to re-add it.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8558:40,Down,DownsampleSam,40,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8558,6,"['Down', 'down']","['DownsampleSam', 'downsampled', 'downstream']"
Availability,"### Affected tool(s) or class(es); gatk PrintReads. ### Affected version(s); v4.1.4.1. ### Description ; Command like; ```; java -Xms2g -Xmx3g -jar gatk.jar PrintReads --gcs-project-for-requester-pays my-project -R hg38.fa -I gs://some-bucket/data.cram -L loci.interval_list -L UNMAPPED -O data.loci.bam; ```; crashes near the end with this error:; ```. 05:03:04.672 INFO PrintReads - Shutting down engine; [March 1, 2020 5:03:04 AM EST] org.broadinstitute.hellbender.tools.PrintReads done. Elapsed time: 18.22 minutes.; Runtime.totalMemory()=3094872064; htsjdk.samtools.util.RuntimeEOFException: java.nio.channels.ClosedChannelException; 	at htsjdk.samtools.CRAMFileReader.queryUnmapped(CRAMFileReader.java:413); 	at htsjdk.samtools.SamReader$PrimitiveSamReaderToSamReaderAdapter.queryUnmapped(SamReader.java:543); 	at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.loadNextIterator(SamReaderQueryingIterator.java:129); 	at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.loadNextRecord(SamReaderQueryingIterator.java:111); 	at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.next(SamReaderQueryingIterator.java:151); 	at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.next(SamReaderQueryingIterator.java:29); 	at org.broadinstitute.hellbender.utils.iterators.SAMRecordToReadIterator.next(SAMRecordToReadIterator.java:27); 	at org.broadinstitute.hellbender.utils.iterators.SAMRecordToReadIterator.next(SAMRecordToReadIterator.java:13); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6475:341,error,error,341,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6475,2,"['down', 'error']","['down', 'error']"
Availability,"### Affected tool(s); IntervalListTools. ### Affected version(s); GATK 4.0.3.0. ### Description; I’ve been getting the following error when executing IntervalListTools in gatk4 . `SECOND_LIST must be null when ACTION is CONCAT, found []. Please put all the inputs in INPUT for this ACTION.`. I can replicate the error when manually executing the command on gatk4 docker but the same command works fine on gitc using picard. COMMANDS; latest gatk4 docker; `/gatk/gatk IntervalListTools --SCATTER_COUNT 6 --SUBDIVISION_MODE BALANCING_WITHOUT_INTERVAL_SUBDIVISION_WITH_OVERFLOW --UNIQUE true --SORT true --INPUT /gatk/interval/Homo_sapiens_assembly19_1000genomes_decoy.whole_genome.interval_list`; gitc 2.3.3-1513176735; `java -Xms1g -jar /usr/gitc/picard.jar IntervalListTools SCATTER_COUNT=6 SUBDIVISION_MODE=BALANCING_WITHOUT_INTERVAL_SUBDIVISION_WITH_OVERFLOW UNIQUE=true SORT=true INPUT=/gatk/interval/Homo_sapiens_assembly19_1000genomes_decoy.whole_genome.interval_list`. INPUT:; gs://broad-references/Homo_sapiens_assembly19_1000genomes_decoy/Homo_sapiens_assembly19_1000genomes_decoy.whole_genome.interval_list",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4619:129,error,error,129,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4619,2,['error'],['error']
Availability,"### Affected tool; - CollectReadCounts. ### Affected version; - The Genome Analysis Toolkit (GATK) v4.2.3.0; - HTSJDK Version: 2.24.1. Downloaded from https://github.com/broadinstitute/gatk/releases/download/4.2.3.0/gatk-4.2.3.0.zip. ### Description ; When calling `CollectReadCounts` tool with symlink as input BAM-file, `java.lang.IllegalArgumentException: Size exceeds Integer.MAX_VALUE` occurs. Symlinks seem to work fine with Picard BAM-tools as well as `HaplotypeCaller` and `Mutect2`. Probably HTSJDK level issue, but popped up exception is kind of misleading. #### Stacktrace:; ```; java.lang.IllegalArgumentException: Size exceeds Integer.MAX_VALUE; at sun.nio.ch.FileChannelImpl.map(FileChannelImpl.java:863); at htsjdk.samtools.MemoryMappedFileBuffer.<init>(MemoryMappedFileBuffer.java:23); at htsjdk.samtools.AbstractBAMFileIndex.<init>(AbstractBAMFileIndex.java:64); at htsjdk.samtools.CachingBAMFileIndex.<init>(CachingBAMFileIndex.java:56); at htsjdk.samtools.BAMFileReader.getIndex(BAMFileReader.java:418); at htsjdk.samtools.BAMFileReader.createIndexIterator(BAMFileReader.java:931); at htsjdk.samtools.BAMFileReader.query(BAMFileReader.java:612); at htsjdk.samtools.SamReader$PrimitiveSamReaderToSamReaderAdapter.query(SamReader.java:550); at htsjdk.samtools.SamReader$PrimitiveSamReaderToSamReaderAdapter.queryOverlapping(SamReader.java:417); at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.loadNextIterator(SamReaderQueryingIterator.java:130); at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.<init>(SamReaderQueryingIterator.java:69); at org.broadinstitute.hellbender.engine.ReadsPathDataSource.prepareIteratorsForTraversal(ReadsPathDataSource.java:412); at org.broadinstitute.hellbender.engine.ReadsPathDataSource.iterator(ReadsPathDataSource.java:336); at java.lang.Iterable.spliterator(Iterable.java:101); at org.broadinstitute.hellbender.utils.Utils.stream(Utils.java:1176); at org.broadinstitute.hellbender.engine.GATKTool",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7579:135,Down,Downloaded,135,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7579,2,"['Down', 'down']","['Downloaded', 'download']"
Availability,"### Background: jar dependency hell. Getting GATK to compile with the gcloud-java-nio dependency is already a little bit of a struggle because of conflicting versions of the com.google.protobuf class (see #2013). Running it on Dataproc results in a version conflict somewhere else, probably linked to the jars that are automatically included on Dataproc. Getting gcloud-java-nio to work on vanilla Spark runs into the exact same category of problems (dependency conflicts), see eg. [this question on StackOverflow](http://stackoverflow.com/questions/38536004/spark-java-noclassdeffounderror-when-adding-dependency/38575957#38575957). The root of the problem is that both Hadoop and GCloud-Java rely on the same core Google libraries (Guava, Protobuf), but they use different versions that are incompatible. Java is not currently able to have two different versions of the same library at once, so instead you end up forcing one version of the other. Neither version appears to work for all of our dependencies, so we have a problem.; ### Workaround. Barring improvements in Java, our only way forward may be to use a shaded ""fat jar"" version of gcloud-java-nio that (i) includes all of its dependencies in a single jar and (ii) renames the shared dependencies so they won't conflict with what eg. Hadoop brings in. Luckily, gcloud-java-nio already builds such a jar by default. However that jar is not published on Maven Central. So the solution is to download the gcloud-java-nio source code, compile it ourselves (without any modification), and use the resulting jar (target/gcloud-java-nio-0.2.7-SNAPSHOT-shaded.jar). . This solution works for both vanilla Spark and GATK. I suspect it would be acceptable for us to directly include that jar in our source tree so that our own users wouldn't have to take any special steps to use GATK: just compile and run, as usual. Let's discuss. CC: @droazen @lbergelson",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2044:1452,down,download,1452,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2044,1,['down'],['download']
Availability,"### Bug Report. Hi, after installing the conda environment and running `conda activate gatk` without errors, I seem to still have a problem importing the gcnvkernel module. Is there a way I can install it through pip or what is something I may have done wrong? I already went over the README and standard documentation, and don't think I missed a step. ### Affected tool(s) or class(es); gvnvkernel, other expected modules. #### Expected behavior; Generate output file from my VCF. #### Actual behavior; ```; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -DGATK_STACKTRACE_ON_USER_EXCEPTION=true -jar /home/gamer456148/gatk-4.1.4.1/gatk-package-4.1.4.1-local.jar GermlineCNVCaller --input var.vcf --run-mode CASE --contig-ploidy-calls X/prefix-calls --output-prefix regular.vcf --output testfile.vcf; 21:21:12.277 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/gamer456148/gatk-4.1.4.1/gatk-package-4.1.4.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Feb 23, 2020 9:21:12 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 21:21:12.543 INFO GermlineCNVCaller - ------------------------------------------------------------; 21:21:12.544 INFO GermlineCNVCaller - The Genome Analysis Toolkit (GATK) v4.1.4.1; 21:21:12.544 INFO GermlineCNVCaller - For support and documentation go to https://software.broadinstitute.org/gatk/; 21:21:12.544 INFO GermlineCNVCaller - Executing as gamer456148@gamer456148-Inspiron-15-7579 on Linux v4.15.0-88-generic amd64; 21:21:12.544 INFO GermlineCNVCaller - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_191-b12; 21:21:12.544 INFO GermlineCNVCaller - Start Date/Time: February 23, 2020 9:21:12 PM EST; 21:21:12.544 INFO GermlineCNVCaller - -------------------------------------------",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6467:101,error,errors,101,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6467,1,['error'],['errors']
Availability,"### Bug Report; When running the StructuralVariationDiscoveryPipelineSpark, I am getting the following error:. ```; java.lang.UnsatisfiedLinkError:`/tmp/jp102/libfml.833188020007107749.jnilib: /lib64/libc.so.6: version `GLIBC_2.14' not found (required by /tmp/jp102/libfml.833188020007107749.jnilib); at java.lang.ClassLoader$NativeLibrary.load(Native Method); at java.lang.ClassLoader.loadLibrary0(ClassLoader.java:1941); at java.lang.ClassLoader.loadLibrary(ClassLoader.java:1824); at java.lang.Runtime.load0(Runtime.java:809); at java.lang.System.load(System.java:1086); at org.broadinstitute.hellbender.utils.fermi.FermiLiteAssembler.loadNativeLibrary(FermiLiteAssembler.java:157); at org.broadinstitute.hellbender.utils.fermi.FermiLiteAssembler.<init>(FermiLiteAssembler.java:24); at org.broadinstitute.hellbender.tools.spark.sv.evidence.FermiLiteAssemblyHandler.apply(FermiLiteAssemblyHandler.java:72); at org.broadinstitute.hellbender.tools.spark.sv.evidence.FermiLiteAssemblyHandler.apply(FermiLiteAssemblyHandler.java:23); at org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction$1.apply(JavaPairRDD.scala:1040); at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); at scala.collection.Iterator$class.foreach(Iterator.scala:893); at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59); at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104); at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48); at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310); at scala.collection.AbstractIterator.to(Iterator.scala:1336); at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302); at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1336); at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289); at scala.collection.AbstractIterator.toArray(Iterator.scala:1336); at org.apache.sp",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5145:103,error,error,103,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5145,1,['error'],['error']
Availability,"### Goal; Our team try to explore the usage of GATK Spark tool for our internal WES and WGS data. ## Bug Report. ### Affected tool(s) or class(es); BwaSpark and ReadsPipelineSpark. ### Affected version(s); - [ X ] Latest public release version [gatk 4.0.11.0]. ### Description ; For both tools, we encountered an issue when the driver shutdown the command as the screenshot. However, for the bwaspark, the alignment ratio seems to be unaffected by the error, but the lines number of the VCF file from ReadsPipelineSpark varies randomly, and quite different from the non-spark version of GATK 4.0.5.2. #### Steps to reproduce; Before running the tool, we generated the image index for whole genome by using the fasta file from GATK official ftp site, and uploaded the reference file to Hadoop HDFS. ``` bash; gatk-4.0.11.0/gatk BwaMemIndexImageCreator -I Homo_sapiens_assembly38.fasta -O Homo_sapiens_assembly38.fasta.img; ```. and then, we preprocess our pair end fastq files into unaligned ubam file as, ; ``` bash; java -jar picard.jar FastqToSam \; F1=R1.fastq.gz; F2=R2.fastq.gz; O=unaligned_reads.bam \; SM=sample001 \; PL=illumina \; RG=rg001; ```. For BwaSpark, we used,; ``` {bash}; ../gatk-4.0.11.0/gatk --java-options ""-Dgatk.spark.debug=true -XX:+PrintGCDetails"" BwaSpark -I hdfs://ns/user/root/test/unaligned_reads.bam -O hdfs://ns/user/root/test/test3.bam -R hdfs://ns/user/root/Homo_sapiens_assembly38.fasta --spark-runner SPARK --spark-master spark://master:7077 -- --num-executors 4 --driver-memory 4g --executor-cores 10 --executor-memory 20g; ```. For ReadsPipelineSpark, we used, ; ``` {bash}; time_gatk ""ReadsPipelineSpark --tmp-dir /tmp --align true -I hdfs://ns/user/root/test/unaligned_reads.bam -O hdfs://ns/user/root/test/test10.vcf -R hdfs://ns/user/root/Homo_sapiens_assembly38.fasta --known-sites hdfs://ns/user/root/Homo_sapiens_assembly38.dbsnp138.vcf -pairHMM AVX_LOGLESS_CACHING --max-reads-per-alignment-start 50"" 4 44 88g 12g; ```. #### Expected behavior; Both tool s",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5481:452,error,error,452,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5481,1,['error'],['error']
Availability,"### Instructions. ## Bug Report. ### Affected tool(s) or class(es); FilterMutectCalls. ### Affected version(s); - [ ] Latest public release version [4.1.4.1]. ### Description ; Header is missing description for ""##FILTER=<ID=PASS"" , it causes inaccurate parsing of VCF . #### Steps to reproduce; Run the FilterMutectCalls on any mutect2 VCF available . Thanks, ; Nick",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6426:341,avail,available,341,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6426,1,['avail'],['available']
Availability,"### Instructions. ## Bug Report; ### Affected tool(s) or class(es); - tools: HaplotypeCaller perhaps Mutec. ; - classes: AlleleLikelihoods. ### Affected version(s); - [ X] Latest public release version [version?]; - [ X] Latest master branch as of [date of test?]. ### Description ; Right before calling annotators HC engine adds filtered reads as additional evidence in the AlleleLikelihoods instance that is passed down to the annotators. The code requests the new evidence to have 0.0 likelihoods so label them as uninformative. However due to an error in how the lk arrays are ""extended"" inside the AlleleLikelihoods these reads inherit past reads (removed) zombie likelihoods instead. Fix is easy. as simple as remove this enclosing ```if``` in AlleleLikelihoods, and simply executed its body; always:. ```; line 793:; if (initialLikelihood != 0.0) // the default array new value.; {; for (int a = 0; a < alleleCount; a++) {; Arrays.fill(sampleValues[a], sampleEvidenceCount, newSampleEvidenceCount, initialLikelihood);; }; }; ```. #### Steps to reproduce. Debug and active region with filtered reads. . #### Expected behavior. Those reads won't contribute to AD or DP. #### Actual behavior. They do contribute, at random, to those count annotations.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7153:417,down,down,417,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7153,2,"['down', 'error']","['down', 'error']"
Availability,"### Instructions. Dear GATK team,. I am encountering an error when using the mutect2 function in ""gatk-4.2.6.1"". Whenever I enable the ""--disable-tool-default-read-filters"" option, I receive a java.lang.ArrayIndexOutOfBoundsException error. Since I need to call SNVs for RNA-seq data, I first split the bam file by chromosome, and then perform markduplicate and splitNcigar in two steps. I found that when I use the bam file obtained after using the splitNcigar function to run mutect2, the same error still occurs, even if I don't disable the -read-filters. Therefore, I suspect that the error may be introduced by splitNcigar. Thus, I tried running mutect2 directly on the bam file after markduplicate. If the --disable-tool-default-read-filters option is not set, the command runs successfully. However, once it is set, the same error occurs. ----. ## Bug Report; [February 28, 2023 10:46:30 AM CST] org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2 done. Elapsed time: 0.03 minutes.; Runtime.totalMemory()=2394947584; java.lang.ArrayIndexOutOfBoundsException; at java.lang.System.arraycopy(Native Method); at org.broadinstitute.hellbender.utils.clipping.ClippingOp.applyHardClipBases(ClippingOp.java:216); at org.broadinstitute.hellbender.utils.clipping.ClippingOp.apply(ClippingOp.java:69); at org.broadinstitute.hellbender.utils.clipping.ReadClipper.clipRead(ReadClipper.java:142); at org.broadinstitute.hellbender.utils.clipping.ReadClipper.clipLowQualEnds(ReadClipper.java:251); at org.broadinstitute.hellbender.utils.clipping.ReadClipper.hardClipLowQualEnds(ReadClipper.java:255); at org.broadinstitute.hellbender.utils.clipping.ReadClipper.hardClipLowQualEnds(ReadClipper.java:263); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.AssemblyBasedCallerUtils.finalizeRegion(AssemblyBasedCallerUtils.java:132); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.AssemblyBasedCallerUtils.assembleReads(AssemblyBasedCallerUtils.java:270); at org.broadinstitute.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8224:56,error,error,56,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8224,5,['error'],['error']
Availability,"### Instructions. I'm running on :; gatk 4.3.0.0. ; 88 cpu ; 128G mem ; 538 samples. Chrom 11-22 don't have problems, but 1-11 don't work.; What should I do?; thanks. ```; java -DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /home/solivehong/miniconda3/envs/bio_base/share/gatk4-4.3.0.0-0/gatk-package-4.3.0.0-local.jar GenotypeGVCFs -R /data/reference/update_gatk_v0/Homo_sapiens_assembly38.fasta -V gendb://Genomicsdb.2 -O /storage/project/collaborators/UH_Burdentest/1.running/genotypeGvcf/UH_Burdentest2222.vcf --tmp-dir /storage/GenomesDbimport/Agilent_WES/tmp -L chr2 -G StandardAnnotation --only-output-calls-starting-in-intervals --use-new-qual-calculator -D /data/reference/update_gatk_v0//Homo_sapiens_assembly38.dbsnp138.vcf; 20:09:21.335 WARN GATKAnnotationPluginDescriptor - Redundant enabled annotation group (StandardAnnotation) is enabled for this tool by default; 20:09:21.383 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/solivehong/miniconda3/envs/bio_base/share/gatk4-4.3.0.0-0/gatk-package-4.3.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; 20:09:21.521 INFO GenotypeGVCFs - ------------------------------------------------------------; 20:09:21.521 INFO GenotypeGVCFs - The Genome Analysis Toolkit (GATK) v4.3.0.0; 20:09:21.521 INFO GenotypeGVCFs - For support and documentation go to https://software.broadinstitute.org/gatk/; 20:09:21.521 INFO GenotypeGVCFs - Executing as solivehong@solivehong on Linux v5.10.0-25-amd64 amd64; 20:09:21.521 INFO GenotypeGVCFs - Java runtime: OpenJDK 64-Bit Server VM v11.0.13+7-b1751.21; 20:09:21.522 INFO GenotypeGVCFs - Start Date/Time: September 23, 2023 at 8:09:21 PM CST; 20:09:21.522 INFO GenotypeGVCFs - ------------------------------------------------------------; 20:09:21.522 INFO GenotypeGVCFs - ----------------------------------------",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8527:941,Redundant,Redundant,941,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8527,1,['Redundant'],['Redundant']
Availability,"### Instructions. The github issue tracker is for bug reports, feature requests, and API documentation requests. General questions about how to use the GATK, how to interpret the output, etc. should be asked on the [official support forum](http://gatkforums.broadinstitute.org/gatk).; - Search the existing github issues to see if your issue (or something similar) has already been reported. If the issue already exists, you may comment there to inquire about the progress.; - Determine whether your issue is a **bug report**, a **feature request**, or a **documentation request** (for tool/class javadoc only -- for forum docs please post there); - Consider if your ""issue"" is better addressed on the GATK forum: http://gatkforums.broadinstitute.org/gatk Post there if you have questions about expected tool behavior, output format, unexpected results, or generally any question that does not fit into the categories above; - Use a **concise** yet **descriptive** title; - Choose the corresponding template block below and fill it in, replacing or deleting text in italics (surrounded by `_`) as appropriate; - Delete the other template blocks and this header. ----. ## Feature request. ### Tool(s) or class(es) involved; `SplitIntervals`. ### Description; Just tried changes from #7157 and they work perfectly. However:. - `SplitIntervals` starts the scatter files counting from 0. Would it be possible to allow the user to specify the starting value (e.g. 1 instead of 0)?; - Also noted that if I have a `bed` file with 3 intervals and ask `SplitIntervals` to scatter it into 6 files, it just creates 3 files. I think it would be nice if `SplitIntervals` would check it and complain if more scatters were requested than intervals are available.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7548:1737,avail,available,1737,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7548,1,['avail'],['available']
Availability,"### Instructions. gatk version 4.4.0.0. When I run gatk GenotypeGVCFs, it shows this error：; ; A USER ERROR has occurred: Bad input: Presence of '-RAW_MQ' annotation is detected. This GATK version expects key RAW_MQandDP with a tuple of sum of squared MQ values and total reads over variant genotypes as the value. This could indicate that the provided input was produced with an older version of GATK. Use the argument '--allow-old-rms-mapping-quality-annotation-data' to override and attempt the deprecated MQ calculation. There may be differences in how newer GATK versions calculate DP and MQ that may result in worse MQ results. Use at your own risk. ----. ##; I use gatk 4.2 and gatk 4.4 to run gatk HaplotypeCaller,respectively. And then use gatk CombineGVCFs (4.4) to combine all ""gvcf.gz"" files. . Please tell me how to solve the above problem.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8574:85,error,error,85,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8574,2,"['ERROR', 'error']","['ERROR', 'error']"
Availability,"### Instructions; I use PathSeqPipelineSpark to analyze 10x Visium spatial transcribed data.; I did not download the data from the database on the GATK official website. But I prepared the database according to the tutorial [https://gatk.broadinstitute.org/hc/en-us/articles/360035889911--How-to-Run-the-Pathseq-pipeline] by myself.; The analysis has no results, and I don't know the reason for the lack of results. ## software / environment / log file informations; Using GATK jar /mnt/icfs/work/singlecelldevelopment/software/gatk-4.3.0.0/gatk-package-4.3.0.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx750g -jar /mnt/icfs/work/singlecelldevelopment/software/gatk-4.3.0.0/gatk-package-4.3.0.0-local.jar PathSeqPipelineSpark --input CRC_16/outs/possorted_genome_bam.bam --filter-bwa-image hsa_GRCh38/genome.fa.img --kmer-file hsa_GRCh38/genome.hss --min-clipped-read-length 60 --microbe-dict 16SrRNA/bacteria.16SrRNA.dict --microbe-bwa-image 16SrRNA/bacteria.16SrRNA.fa.img --taxonomy-file 16SrRNA/16SrRNA.db --output pathseq/CRC_16.pathseq.complete.bam --scores-output pathseq/CRC_16.pathseq.complete.csv --is-host-aligned false --filter-duplicates false --min-score-identity .7 --tmp-dir pathseq/tmp; 13:19:23.776 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/mnt/icfs/work/singlecelldevelopment/software/gatk-4.3.0.0/gatk-package-4.3.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; 13:19:28.982 INFO PathSeqPipelineSpark - ------------------------------------------------------------; 13:19:28.982 INFO PathSeqPipelineSpark - The Genome Analysis Toolkit (GATK) v4.3.0.0; 13:19:28.982 INFO PathSeqPipelineSpark - For support and documentation go to https://software.broadinstitute.org/gatk/; 13:19:28.983 INFO PathSeqPipelineSpark - Executing as singlecellproject@d01.capitalbiotech.local on Linux v3.10.0-514.16.1.el7.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8339:104,down,download,104,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8339,1,['down'],['download']
Availability,"### Summary ; A user wrote in to the forum regarding running FilterSamReads through GATK and the output bam file has formatting issues. After they sent in a bug report, I found that the exit code is getting written to the bam file, causing this issue. . This request was created from a contribution made by rcorbett on February 03, 2021 23:47 UTC. Link: [https://gatk.broadinstitute.org/hc/en-us/community/posts/360076905711-filterSamReads-stdout-format-error](https://gatk.broadinstitute.org/hc/en-us/community/posts/360076905711-filterSamReads-stdout-format-error). #### GATK Info; FilterSamReads 4.1.9.0 and 4.0.10.0; Command to stdout:; `gatk FilterSamReads -I subsampled.bam -O /dev/stdout --READ_LIST_FILE read_names.txt --FILTER excludeReadList --VALIDATION_STRINGENCY SILENT --QUIET > test_stdout.bam`; Log:; ```; Using GATK jar /gatk/gatk-package-4.1.9.0-SNAPSHOT-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /gatk/gatk-package-4.1.9.0-SNAPSHOT-local.jar FilterSamReads -I subsampled.bam -O /dev/stdout --READ_LIST_FILE read_names.txt --FILTER excludeReadList --VALIDATION_STRINGENCY SILENT --QUIET; 20:54:45.405 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/gatk/gatk-package-4.1.9.0-SNAPSHOT-local.jar!/com/intel/gkl/native/libgkl_compression.so; INFO	2021-02-12 20:54:45	FilterSamReads	Filtering [presorted=true] subsampled.bam -> OUTPUT=stdout [sortorder=coordinate]; INFO	2021-02-12 20:54:45	SAMFileWriterFactory	Unknown file extension, assuming BAM format when writing file: file:///dev/stdout; INFO	2021-02-12 20:54:45	FilterSamReads	6 SAMRecords written to stdout. ```; Check file:; `gunzip -c -d -f test_stdout.bam | head -n 5`; ```; Tool returned:; 0. ?[[lW?m?$?^?q???k????zg?x}?s???mE?ޖ?r#U???ԑ/Qm'܄dkUM???????zCBB?!*?V*?#; <Q!QU?; ```; Bam file using -0; `gunzip -c -d -f test_outbam.bam | head -n 5`; ```; BAM?2@",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7080:454,error,error,454,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7080,2,['error'],['error']
Availability,"### Summary; A user running Mutect2 in GATK 4.1.9.0 was inputting an interval list using the -XL option and received an error message that did not illuminate the problem. Their intervals file was made using BedToIntervalList and was a picard-style interval list. The final solution they found was the [correct extension](https://gatk.broadinstitute.org/hc/en-us/articles/360035531852-Intervals-and-interval-lists), .interval_list. ### Example 1; Using .intervallist extension, the error message said the interval was not valid; `A USER ERROR has occurred: Badly formed genome unclippedLoc: Query interval ""combinedblacklist.intervallist"" is not valid for this input`. ### Example 2; Using .intervals extension, the error message said the interval list was badly formed and not valid; `A USER ERROR has occurred: Badly formed genome unclippedLoc: Query interval ""@HD VN:1.6 SO:coordinate"" is not valid for this input.`. <br><br><i>(created from <a href='https://broadinstitute.zendesk.com/agent/tickets/113538'>Zendesk ticket #113538</a>)<br>gz#113538</i>",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7095:120,error,error,120,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7095,5,"['ERROR', 'error']","['ERROR', 'error']"
Availability,"### Summary; In the AnalyzeCovariates documentation, there is mention of the previous GATK3 method to obtain recalibration tables before and after BQSR. There does not seem to be that functionality in GATK4. If there is, it is not well documented. ### User Request. This request was created from a contribution made by ISmolicz on February 17, 2021 12:03 UTC. Link: [https://gatk.broadinstitute.org/hc/en-us/community/posts/360077098031-Error-when-trying-to-generate-the-second-recalibration-table-for-AnalyzeCovariates](https://gatk.broadinstitute.org/hc/en-us/community/posts/360077098031-Error-when-trying-to-generate-the-second-recalibration-table-for-AnalyzeCovariates). \--. Dear GATK Team,. In previous GATK4 versions, I understand there was a -bqsr option to use with BaseRecalibrator so that a second recalibration table could be generated and then submitted to AnalyzeCovariates. However, it appears this option is longer available as I receive the following error with GATK version 4.1.9.0:. A USER ERROR has occurred: -bqsr is not a recognized option. The command used:. gatk BaseRecalibrator \\ ; \--input input.bam \\ ; \-R ucsc.hg19.fasta \\ ; \--known-sites dbsnp\_138.hg19.vcf \\ ; \--known-sites Mills\_and\_1000G\_gold\_standard.indels.hg19.sites.vcf \\ ; \--known-sites 1000G\_phase1.indels.hg19.sites.vcf \\ ; \-bqsr sample.recal\_data.grp \\ ; \--output sample.recal\_data\_2.grp \\ ; \--tmp-dir $TMPDIR. Please could you confirm the current method used to generate the second recalibration table with GATK 4.1.9.0?. Unfortunately I could not identify the current method, including in the \[Base Quality Score Recalibration (BQSR)\](/hc/en-us/articles/360035890531-Base-Quality-Score-Recalibration-BQSR- ""Base Quality Score Recalibration (BQSR)"") documentation. Thank you for your time and help.<br><br><i>(created from <a href='https://broadinstitute.zendesk.com/agent/tickets/113534'>Zendesk ticket #113534</a>)<br>gz#113534</i>",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7096:437,Error,Error-when-trying-to-generate-the-second-recalibration-table-for-AnalyzeCovariates,437,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7096,5,"['ERROR', 'Error', 'avail', 'error']","['ERROR', 'Error-when-trying-to-generate-the-second-recalibration-table-for-AnalyzeCovariates', 'available', 'error']"
Availability,"### bug reports. hi guys :; ; Hi all, when I run gatk (version: 4.5.0.0) CombineGVCFs to combine 240 8 ploidy samples gvcf, it reports the error as below; ![image](https://github.com/broadinstitute/gatk/assets/48479509/4b2e42bb-f8f1-487b-9c06-ce513d94aef7). how call i solve it? ，replace CombineGVCFs with GenomicsDBimport ?; I think even though I got the merged gvcf file ， this error is also will be reported when I run GenotypeGVCF?; I look forward to your suggestions; have a good day!",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8842:139,error,error,139,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8842,2,['error'],['error']
Availability,"#3925 introduced a conda dependency on libgcc-ng=7.2.0, which works in Travis since its available or Ubuntu, but fails to resolve for osx. Its not clear to me what the options are, but we need to resolve this one way or another.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4074:88,avail,available,88,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4074,1,['avail'],['available']
Availability,"#6055 Bug Report. ### Affected tool(s) or class(es); PostprocessGermlineCNVCalls. ### Affected version(s); 4.1.8.1. ### Description ; Process of calling copy number segments and consolidate sample results with PostprocessGermlineCNVCalls aborts with error : ""Records were not strictly sorted in dictionary order.""; I tried to detect germline copy number in cohort mode on 73 wgs samples by [this](https://gatk.broadinstitute.org/hc/en-us/articles/360035531152--How-to-Call-common-and-rare-germline-copy-number-variants) tutorial.To do this, i split genome into 10 parts.At the last stage PostprocessGermlineCNVCalls aborts with error : ""Records were not strictly sorted in dictionary order"", when i use all parts.; [scattered.1-10.interval_list.txt](https://github.com/broadinstitute/gatk/files/5457466/scattered.1-10.interval_list.txt); [scattered.2-10.interval_list.txt](https://github.com/broadinstitute/gatk/files/5457467/scattered.2-10.interval_list.txt); [scattered.3-10.interval_list.txt](https://github.com/broadinstitute/gatk/files/5457468/scattered.3-10.interval_list.txt); [scattered.4-10.interval_list.txt](https://github.com/broadinstitute/gatk/files/5457469/scattered.4-10.interval_list.txt); [hg19.dict.txt](https://github.com/broadinstitute/gatk/files/5457474/hg19.dict.txt). But if you use the first three, the program works out. - ; `12:43:27.310 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/lmbs02/bio/biosoft/gatk/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Oct 29, 2020 12:43:27 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 12:43:27.439 INFO PostprocessGermlineCNVCalls - ------------------------------------------------------------; 12:43:27.439 INFO PostprocessGermlineCNVCalls - The Genome Analysis Toolkit (GATK) v4.1.8.1; 12:43:27.439 INFO PostprocessGermlineCNVCalls - For supp",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6924:250,error,error,250,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6924,2,['error'],['error']
Availability,"#7931); - VS_492 - Beta User Jar release (#7934); - Cost WDL should throw on FISS API errors [VS-518] (#7942); - Fix bad check for missing workflow name [VS-520] (#7943); - Remove usage of service account from GvsValidateVAT.wdl (#7937); - refactoring for testablity (#7946); - More import retries [VS-532] (#7953); - A few last doc changes (#7927); - WDL to extract a single callset cost (BQ only, not Terra) (#7940); - Temporarily swap in Corretto for Temurin as we can't download Temurin. (#7969); - GL-548 - Update CreateVat code to handle samples that do not contain all population groups. (#7965); - Restore Temurin 11 [VS-570] (#7972); - Add table size check to quickstart integration test [VS-501] (#7970); - Consolidate various docs for AoU callset generation into one to rule them all [VS-553] (#7971); - VS-567. Removing usage of ServiceAccount from CreateVat related WDLs (#7974); - WDL to extract Avro files for Hail import [VS-579] (#7981); - Removed usage of service account from WDLs (#7985); - Document steps for GVS cleanup for base use case [VS-586] (#7989); - Change backticks to single quotes in several error messages - causing shell to attempt to execute. (#7995); - VS-598 - Minor update to AoU Documentation. (#7994); - Allow for incremental addition of data to alt_allele [VS-52] (#7993); - Minor AoU Documentation Update (#7999); - Batch population of alt_allele table from vet_ tables [VS-265] (#7998); - Change drop_state to NONE for Ingest/Extract [VS-607] (#8000); - python -> python3 (#8001); - Generate Hail import/export script [VS-605] (#8002); - clearer error when values are missing (#7939); - Ah [VS-565] output intervals and sample list (#8010); - make CreateAltAlleleTable task volatile (#8011); - Restore withdrawn [VS-581] (#8006); - Km gvs add storage cost and cleanup doc (#8012); - Updating documentation to reflect the changed outputs [VS-565] (#8014); - File of callset samples -> samples marked as 'withdrawn' in GVS [VS-436] (#8009); - fix quota guide",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8248:27342,error,error,27342,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8248,2,['error'],['error']
Availability,"$1.apply(JavaRDD.scala:78)** ; **at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:464)** ; **at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)** ; **at org.apache.spark.shuffle.sort.UnsafeShuffleWriter.write(UnsafeShuffleWriter.java:187)** ; **at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)** ; **at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)** ; **at org.apache.spark.scheduler.Task.run(Task.scala:121)** ; **at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)** ; **at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)** ; **at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)** ; **at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)** ; **at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)** ; **at java.lang.Thread.run(Thread.java:745)**. **20/03/05 09:28:58 ERROR TaskSetManager: Task 34 in stage 0.0 failed 1 times; aborting job** ; **20/03/05 09:28:58 INFO TaskSchedulerImpl: Cancelling stage 0** ; **20/03/05 09:28:58 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage cancelled** ; **20/03/05 09:28:58 INFO Executor: Executor is trying to kill task 0.0 in stage 0.0 (TID 0), reason: Stage cancelled** ; **20/03/05 09:28:58 INFO Executor: Executor is trying to kill task 30.0 in stage 0.0 (TID 30), reason: Stage cancelled** ; **20/03/05 09:28:58 INFO Executor: Executor is trying to kill task 9.0 in stage 0.0 (TID 9), reason: Stage cancelled** ; **20/03/05 09:28:58 INFO Executor: Executor is trying to kill task 1.0 in stage 0.0 (TID 1), reason: Stage cancelled** ; **20/03/05 09:28:58 INFO Executor: Executor is trying to kill task 31.0 in stage 0.0 (TID 31), reason: Stage cancelled** ; **20/03/05 09:28:58 INFO Executor: Executor is trying to kill task 2.0 in stage 0.0 (TID 2), reason: Stage cancelled** ; **20/03/05 09:28:58 INFO Executor: ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6493:32678,ERROR,ERROR,32678,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6493,1,['ERROR'],['ERROR']
Availability,"$20.apply(RDD.scala:710); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$20.apply(RDD.scala:710); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66); 	at org.apache.spark.scheduler.Task.run(Task.scala:89); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:227); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745); 16/11/16 23:25:11 ERROR SparkUncaughtExceptionHandler: Uncaught exception in thread Thread[Executor task launch worker-0,5,main]; java.lang.AbstractMethodError: org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSink$$Lambda$78/237665701.call(Ljava/lang/Object;)Ljava/lang/Iterable;; 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:159); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:159); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$20.apply(RDD.scala:710); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$20.apply(RDD.scala:710); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2268:13222,ERROR,ERROR,13222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2268,1,['ERROR'],['ERROR']
Availability,(HardAlleleFilter.java:16) ; ; at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2AlleleFilter.errorProbabilities(Mutect2AlleleFilter.java:86) ; ; at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.lambda$new$0(ErrorProbabilities.java:27) ; ; at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1321) ; ; at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169) ; ; at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382) ; ; at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481) ; ; at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471) ; ; at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708) ; ; at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234) ; ; at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499) ; ; at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.<init>(ErrorProbabilities.java:25) ; ; at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.accumulateData(Mutect2FilteringEngine.java:138) ; ; at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls.nthPassApply(FilterMutectCalls.java:154) ; ; at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverse$0(MultiplePassVariantWalker.java:40) ; ; at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverseVariants$1(MultiplePassVariantWalker.java:77) ; ; at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184) ; ; at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175) ; ; at java.util.Iterator.forEachRemaining(Iterator.java:116) ; ; at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801) ; ; at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481) ; ; at java.util.stream.AbstractPipeline.wrapA,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7298:8298,Error,ErrorProbabilities,8298,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7298,1,['Error'],['ErrorProbabilities']
Availability,(RDD.scala:324); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96); 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53); 	at org.apache.spark.scheduler.Task.run(Task.scala:109); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); 18/10/17 19:23:59 ERROR Executor: Exception in task 518.0 in stage 0.0 (TID 518); java.io.FileNotFoundException: /home/data/WGS/F002/F002.sort.bam (Too many open files); 	at java.io.FileInputStream.open0(Native Method); 	at java.io.FileInputStream.open(FileInputStream.java:195); 	at java.io.FileInputStream.<init>(FileInputStream.java:138); 	at org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileInputStream.<init>(RawLocalFileSystem.java:106); 	at org.apache.hadoop.fs.RawLocalFileSystem.open(RawLocalFileSystem.java:202); 	at org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:349); 	at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:769); 	at org.seqdoop.hadoop_bam.util.WrapSeekable.openPath(WrapSeekable.java:60); 	at org.seqdoop.hadoop_bam.BAMRecordReader.initialize(BAMRecordReader.java:147); 	at org.seqdoop.hadoop_bam.BAMInputFormat.createRecordReader(BAMInputFormat.java:222); 	at org.seqdoop.hadoop_bam.AnySAMInputFormat.createRecordReader(AnySAMInputFormat.java:190); 	at org.apache.spa,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5316:4767,ERROR,ERROR,4767,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5316,1,['ERROR'],['ERROR']
Availability,"(Reported in #5130). We had a user report that when a variant is within 10 base pairs from the end of the chromosome (as defined by the reference dictionary), `ReferenceBases` throws a String index out of range error. This bug was in the annotation prior to #4895. What #4895 did was that it made the `ReferenceBases` annotation part of `StandardMutectAnnotation,` which turned on `RefernceBases` by default, and that led to the user getting the error.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5151:211,error,error,211,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5151,2,['error'],['error']
Availability,(SV) slim down REF column for CPX variants,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4970:10,down,down,10,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4970,1,['down'],['down']
Availability,(SparkSubmit.scala:736); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.io.IOException: Error code 404 trying to get security access token from Compute Engine metadata for the default service account. This may be because the virtual machine instance does not have permission scopes specified.; 	at shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials.refreshAccessToken(ComputeEngineCredentials.java:137); 	at shaded.cloud_nio.com.google.auth.oauth2.OAuth2Credentials.refresh(OAuth2Credentials.java:160); 	at shaded.cloud_nio.com.google.auth.oauth2.OAuth2Credentials.getRequestMetadata(OAuth2Credentials.java:146); 	at shaded.cloud_nio.com.google.auth.http.HttpCredentialsAdapter.initialize(HttpCredentialsAdapter.java:96); 	at com.google.cloud.http.HttpTransportOptions$1.initialize(HttpTransportOptions.java:157); 	at shaded.cloud_nio.com.google.api.client.http.HttpRequestFactory.buildRequest(HttpRequestFactory.java:93); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.buildHttpRequest(AbstractGoogleClientRequest.java:300); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.execute(AbstractGoogleClientRequest.java:469); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.get(HttpStorageRpc.java:337); 	... 32 more; ERROR: (gcloud.dataproc.jobs.submit.spark) Job [cb87810a-0133-42b3-a954-363b62adce39] entered state [ERROR] while waiting for [DONE].; ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3591:5141,ERROR,ERROR,5141,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3591,2,['ERROR'],['ERROR']
Availability,"(assumes that #2457 is already complete); Currently, the docker image creation will grab all the local files, which is prone to error. The github hash/tag parameters are simply to determine how to tag the image in docker hub. In gatk-protected, we used to actually grab the source code from github in the Dockerfile. I'm not suggesting we go back to this model. What we might want to consider:; The build_docker.sh script could download the github hash/tag to a temp dir and then build the docker image from the temp dir. This solution would be more robust and would decrease errors.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2700:128,error,error,128,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2700,4,"['down', 'error', 'robust']","['download', 'error', 'errors', 'robust']"
Availability,"(https://github.com/samtools/htsjdk/issues/1115); I am getting an error using gatk's VariantRecalibrator:. `htsjdk.tribble.TribbleException: Line 104: there aren't enough columns for line entrainScore=0.7203;HW=4.306476E-6 (we expected 9 tokens, and saw 1 ), for input source: file:///share/ScratchGeneral/evaben/cromwell/cromwell-executions/JointGenotyping/2ce78a09-433b-48eb-83d0-1fa1771d1181/call-SNPsVariantRecalibratorCreateModel/inputs/share/ClusterShare/biodata/contrib/evaben/hs37d5x/vcf/1000G_omni2.5.b37.vcf`. I am having trouble getting to the bottom of the issue. I cannot find the string 'entrainScore=0.7203;HW=4.306476E-6' in the vcf file, and Line 104 is part of the header (I think Line 104 refers to tribble source though). Gatks ValidateVariants does not have any issues with the vcf file, and looking visually with bcftools I cannot see an issue either. . Can anyone suggest further diagnosis steps? Should I take this to GATK issue tracker?. The VCF file is here: ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/b37/1000G_omni2.5.b37.vcf. Here is the gatk command line: ; ```; gatk --java-options ""-Xmx100g -Xms100g"" \; VariantRecalibrator \; -V /share/ScratchGeneral/evaben/cromwell/cromwell-executions/JointGenotyping/2ce78a09-433b-48eb-83d0-1fa1771d1181/call-SNPsVariantRecalibratorCreateModel/inputs/share/ScratchGeneral/evaben/cromwell/cromwell-executions/JointGenotyping/2ce78a09-433b-48eb-83d0-1fa1771d1181/call-SitesOnlyGatherVcf/execution/NA12878.sites_only.vcf.gz \; -O NA12878.snps.recal \; --tranches-file NA12878.snps.tranches \; -trust-all-polymorphic \; -tranche 100.0 -tranche 99.95 -tranche 99.9 -tranche 99.8 -tranche 99.6 -tranche 99.5 -tranche 99.4 -tranche 99.3 -tranche 99.0 -tranche 98.0 -tranche 97.0 -tranche 90.0 \; -an QD -an MQRankSum -an ReadPosRankSum -an FS -an MQ -an SOR -an DP \; -mode SNP \; -sample-every 10 \; --output-model NA12878.snps.model.report \; --max-gaussians 6 \; -resource hapmap,known=false,training=true,truth=true,prior=",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4761:66,error,error,66,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4761,1,['error'],['error']
Availability,"(this is mainly relevant for Picard tools, which often have lots of log.info() calls). CommandLineProgram's VERBOSITY is set to INFO by default, which is reasonable when you're actually interacting with a tool, but quickly gets spammy when running unit tests. I propose injecting VERBOSITY=ERROR (the strictest setting) into CommandLineProgramTest to avoid this. This would fix https://github.com/broadinstitute/hellbender/issues/134",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/147:290,ERROR,ERROR,290,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/147,1,['ERROR'],['ERROR']
Availability,") + ln(0.2385) ??? ln(0.7559) = 1.7454427755 + (-1.433) ??? (-0.2798) = 0.592; ^; /usr/ports/biology/gatk/work/gatk-4.1.2.0/src/main/java/org/broadinstitute/hellbender/tools/walkers/mutect/Mutect2.java:137: error: unmappable character for encoding ASCII; * Specifically, the mode sets <nobr>???-initial-tumor-lod</nobr> to 0, <nobr>???-tumor-lod-to-emit</nobr> to 0, <nobr>--af-of-alleles-not-in-resource</nobr> to; ^; /usr/ports/biology/gatk/work/gatk-4.1.2.0/src/main/java/org/broadinstitute/hellbender/tools/walkers/mutect/Mutect2.java:137: error: unmappable character for encoding ASCII; * Specifically, the mode sets <nobr>???-initial-tumor-lod</nobr> to 0, <nobr>???-tumor-lod-to-emit</nobr> to 0, <nobr>--af-of-alleles-not-in-resource</nobr> to; ^; /usr/ports/biology/gatk/work/gatk-4.1.2.0/src/main/java/org/broadinstitute/hellbender/tools/walkers/mutect/Mutect2.java:137: error: unmappable character for encoding ASCII; * Specifically, the mode sets <nobr>???-initial-tumor-lod</nobr> to 0, <nobr>???-tumor-lod-to-emit</nobr> to 0, <nobr>--af-of-alleles-not-in-resource</nobr> to; ^; /usr/ports/biology/gatk/work/gatk-4.1.2.0/src/main/java/org/broadinstitute/hellbender/tools/walkers/mutect/Mutect2.java:137: error: unmappable character for encoding ASCII; * Specifically, the mode sets <nobr>???-initial-tumor-lod</nobr> to 0, <nobr>???-tumor-lod-to-emit</nobr> to 0, <nobr>--af-of-alleles-not-in-resource</nobr> to; ^; /usr/ports/biology/gatk/work/gatk-4.1.2.0/src/main/java/org/broadinstitute/hellbender/tools/walkers/mutect/Mutect2.java:137: error: unmappable character for encoding ASCII; * Specifically, the mode sets <nobr>???-initial-tumor-lod</nobr> to 0, <nobr>???-tumor-lod-to-emit</nobr> to 0, <nobr>--af-of-alleles-not-in-resource</nobr> to; ^; /usr/ports/biology/gatk/work/gatk-4.1.2.0/src/main/java/org/broadinstitute/hellbender/tools/walkers/mutect/Mutect2.java:137: error: unmappable character for encoding ASCII; * Specifically, the mode sets <nobr>???-initial-tumor-lod</n",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5934:2514,error,error,2514,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5934,1,['error'],['error']
Availability,) ; ; at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471) ; ; at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708) ; ; at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234) ; ; at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499) ; ; at htsjdk.variant.variantcontext.CommonInfo.getAttributeAsList(CommonInfo.java:274) ; ; at htsjdk.variant.variantcontext.CommonInfo.getAttributeAsIntList(CommonInfo.java:282) ; ; at htsjdk.variant.variantcontext.VariantContext.getAttributeAsIntList(VariantContext.java:827) ; ; at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.DuplicatedAltReadFilter.areAllelesArtifacts(DuplicatedAltReadFilter.java:26) ; ; at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.HardAlleleFilter.calculateErrorProbabilityForAlleles(HardAlleleFilter.java:16) ; ; at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2AlleleFilter.errorProbabilities(Mutect2AlleleFilter.java:86) ; ; at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.lambda$new$0(ErrorProbabilities.java:27) ; ; at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1321) ; ; at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169) ; ; at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382) ; ; at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481) ; ; at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471) ; ; at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708) ; ; at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234) ; ; at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499) ; ; at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.<init>(ErrorProbabilities.java:25) ; ; at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7298:7422,error,errorProbabilities,7422,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7298,1,['error'],['errorProbabilities']
Availability,"); 	at org.apache.spark.RangePartitioner$$anonfun$13.apply(Partitioner.scala:303); 	at org.apache.spark.RangePartitioner$$anonfun$13.apply(Partitioner.scala:301); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$26.apply(RDD.scala:847); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$26.apply(RDD.scala:847); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:109); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). 18/07/24 21:02:27 ERROR org.apache.spark.scheduler.TaskSetManager: Task 1 in stage 0.0 failed 4 times; aborting job; 18/07/24 21:02:27 INFO org.spark_project.jetty.server.AbstractConnector: Stopped Spark@42ecc554{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 21:02:27.703 INFO PrintReadsSpark - Shutting down engine; [July 24, 2018 9:02:27 PM UTC] org.broadinstitute.hellbender.tools.spark.pipelines.PrintReadsSpark done. Elapsed time: 0.32 minutes.; Runtime.totalMemory()=2463629312; org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 0.0 failed 4 times, most recent failure: Lost task 1.3 in stage 0.0 (TID 7, shuang-small-m.c.broad-dsde-methods.internal, executor 2): htsjdk.samtools.SAMFormatException: Invalid GZIP header; 	at htsjdk.samtools.util.BlockGunzipper.unzipBlock(BlockGunzipper.java:121); 	at htsjdk.samtools.util.BlockGunzipper.unzipBlock(BlockGunzipper.java:96); 	at htsjdk.samtools.util.BlockCompressedInputStream.inflateBlock(BlockCompressedInputStream.java:550); 	at htsj",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5051:11106,ERROR,ERROR,11106,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5051,1,['ERROR'],['ERROR']
Availability,"); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:109); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). 18/07/24 21:02:27 ERROR org.apache.spark.scheduler.TaskSetManager: Task 1 in stage 0.0 failed 4 times; aborting job; 18/07/24 21:02:27 INFO org.spark_project.jetty.server.AbstractConnector: Stopped Spark@42ecc554{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 21:02:27.703 INFO PrintReadsSpark - Shutting down engine; [July 24, 2018 9:02:27 PM UTC] org.broadinstitute.hellbender.tools.spark.pipelines.PrintReadsSpark done. Elapsed time: 0.32 minutes.; Runtime.totalMemory()=2463629312; org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 0.0 failed 4 times, most recent failure: Lost task 1.3 in stage 0.0 (TID 7, shuang-small-m.c.broad-dsde-methods.internal, executor 2): htsjdk.samtools.SAMFormatException: Invalid GZIP header; 	at htsjdk.samtools.util.BlockGunzipper.unzipBlock(BlockGunzipper.java:121); 	at htsjdk.samtools.util.BlockGunzipper.unzipBlock(BlockGunzipper.java:96); 	at htsjdk.samtools.util.BlockCompressedInputStream.inflateBlock(BlockCompressedInputStream.java:550); 	at htsjdk.samtools.util.BlockCompressedInputStream.processNextBlock(BlockCompressedInputStream.java:532); 	at htsjdk.samtools.util.BlockCompressedInputStream.nextBlock(BlockCompressedInputStream.java:468); 	at htsjdk.samtools.util.BlockCompressedInputStream.seek(BlockCompressedInputStream.java:380); 	at htsjdk.samtools.BAMFileReader$BAMFileIndexIterator.getNextRecord(BAMFileReader.java:977); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.advance(BAMFileReader.java:803); 	at htsjdk.samtools.BAMFileReader$BAMFile",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5051:11621,failure,failure,11621,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5051,1,['failure'],['failure']
Availability,"); 	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63); 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96); 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53); 	at org.apache.spark.scheduler.Task.run(Task.scala:109); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). #### Steps to reproduce; Run the MarkDuplicatesSpark in a local SPARK cluster. The following function return a null, which cause the exception. public static String getLibrary( final GATKRead read, final SAMFileHeader header, String defaultLibrary) {; final SAMReadGroupRecord readGroup = getSAMReadGroupRecord(read, header);; String library = readGroup != null ? readGroup.getLibrary() : null;; return library==null? defaultLibrary : library;; }. public EmptyFragment(GATKRead read, SAMFileHeader header, Map<String, Byte> headerLibraryMap) {; super(0, null);; this.R1R = read.isReverseStrand();; this.key = ReadsKey.getKeyForFragment(ReadUtils.getStrandedUnclippedStart(read),; isRead1ReverseStrand(),; ReadUtils.getReferenceIndex(read, header),; headerLibraryMap.get(ReadUtils.getLibrary(read, header, LibraryIdGenerator.UNKNOWN_LIBRARY)));; }. #### Expected behavior; MarkDuplicatesSpark should success finish. #### Actual behavior; The MarkDuplicatesSpark run failure. ----. ## Feature request. ### Tool(s) or class(es) involved; SPARK, Hadoop HDFS. ### Description; _Specify whether you want a modification of an existing behavior or addition of a new capability._; _Provide **examples**, **screenshots**, where appropriate._. ----. ## Documentation request. ### Tool(s) or class(es) involved; _Tool/class name(s), parameters?_. ### Description ; _Describe what needs to be added or modified._. ----",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5169:5400,failure,failure,5400,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5169,1,['failure'],['failure']
Availability,"); 	at org.broadinstitute.hellbender.tools.walkers.vqsr.VariantRecalibratorEngine.generateModel(VariantRecalibratorEngine.java:43); 	at org.broadinstitute.hellbender.tools.walkers.vqsr.VariantRecalibrator.onTraversalSuccess(VariantRecalibrator.java:625); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:895); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:134); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:179); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:198); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); 	at org.broadinstitute.hellbender.Main.main(Main.java:289); ```. I believe this is derived from an error earlier in the log, since the `stderr` gives the same Java heap space error: ; ```; [2019-09-16 19:05:59,50] [error] WorkflowManagerActor Workflow 9f7a01a4-0632-4817-8622-aa51e520abf1 failed (during ExecutingWorkflowState): Job JointGenotyping.SNPsVariantRecalibratorClassic:NA:1 exited with return code 1 which has not been declared as a valid return code. See 'continueOnReturnCode' runtime attribute for more details.; Check the content of stderr for potential additional information: /path/to/stderr.; ```. I have read past issues (https://gatkforums.broadinstitute.org/gatk/discussion/23880/java-heap-space) regarding this that may suggest it is a bug. It has pointed me to increasing the available heap memory through the primary command of -Xmx. Is this the way to do it? ; ```; java -Xmx600G -Dconfig.file=' + re.sub('input.json', 'overrides.conf', input_json) + ' -jar ' + args.cromwell_path + ' run ' + re.sub('input.json', 'joint-discovery-gatk4.wdl', input_json) + ' -i ' + input_json; ```; where I substitute in the corresponding config, json, and wdl files. . Is 600G enough? Each vcf is ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6165:1760,error,error,1760,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6165,3,['error'],['error']
Availability,* A previouus change left a reference to an uninitialized property in build.gradle.; This caused a crash when trying to produce an error message warning that the JDK was not found. Ex: Caused by: groovy.lang.MissingPropertyException: Could not get unknown property 'requiredJavaVersion' for root project 'gatk' of type org.gradle.api.Project; * Fix the crash by removing the reference to the missing property.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6676:131,error,error,131,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6676,1,['error'],['error']
Availability,* Add a table of contents.; * Update out-of-date information.; * Merge in information from the old gatk-protected README; * Add section on git-lfs; * Add section on downloading GATK4; * Add section on documentation generation; * Add section on zenhub; * Remove no-longer-needed protected-root directory. Resolves #2775; Resolves #2978; Resolves #2487; Resolves #2461,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3158:165,down,downloading,165,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3158,1,['down'],['downloading']
Availability,* Add contig and start position to error message in setMatePosition; * Extract the check to a shared method with setPosition so it's not inconsistent; * Improves the unhelpful error reported in https://github.com/broadinstitute/gatk/issues/6776,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6779:35,error,error,35,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6779,2,['error'],['error']
Availability,"* Added MinGqVariantFilterBase; * * loads VCF, pedigree, UCSC genome tract, and truth data; * * calculates variant overlap with genome tracts; * * forms matrices, tensors, and other helping data for machine learning; * * provides for TRAIN and FILTER modes; * * provides functions for calculating loss given assigned min GQ values; * * computes best estimate of truth data used for training xgboost model; * Added XGBoostMinGqVariantFilter; * * calculates new GQ based on gradient boosting; * Added PropertiesTable for loading VCF properties into tensors; * Added TractOverlapDetector for computing overlap properties with; UCSC genome tracts. Training loss is based on weighted combination of heredity and truth; data, broken down by variant category.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7705:727,down,down,727,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7705,1,['down'],['down']
Availability,* Adding a beta version of http-nio which allows streaming http files and seeking within them.; * This allows using https urls including signed urls to access remote files.; * Bams/crams can be read by specifying the index manually. Automatic index resolution does not work correctly at the moment.; * known caveats; * some methods are not implement in the nio filesystem library yet; * failures are not retryied. I'm currently fighting with sonatype to get a real release pushed out... it seems close...,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6526:387,failure,failures,387,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6526,1,['failure'],['failures']
Availability,"* Adding a new GATKTool level argument `--variant-output-interval-filtering-mode` which allows filtering output variants according to the input interval list. This replaces `--only-output-calls-starting-in-intervals` which was available in GenotypeGvcfs and GnarlyGenotyper. It works by adding a filtering decorator to the vcf writers created through `GATKTool.createVCFWriter`. ; There are several different filtering modes:; `STARTS_IN`, `ENDS_IN`, `OVERLAPS`, `CONTAINED`, and `ANYWHERE`. The default for tools is not to apply the decorator, but they may optionally change that behavior by overriding the new `getDefaultVariantOutputFilterMode`. `--variant-output-interval-filtering-mode STARTS_IN` is equivalent to the previous behavior of `--only-output-calls-starting-in-intervals true`. MockVcfWriter is now a testUtils class. The naming is a bit awkward so improvements would be helpful. This doesn't fix the weird behavior in HaplotypeCaller but does allow subsetting unique shards with SelectVariants and other variant outputting tools. We could adapt this to apply to bam outputs as well if that seems useful.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6388:227,avail,available,227,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6388,1,['avail'],['available']
Availability,* Fixed cost calculation to ignore duplicate rows caused by preemption.; * Resetting tolerances to 5% across the board.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8813:85,toler,tolerances,85,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8813,1,['toler'],['tolerances']
Availability,* Fixing an obscure error in an error message in GATKAnnotationPluginDescription.; * entrySet was called instead of values as a result everything was always filtered from the error message. Noticed this one completely by chance.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5444:20,error,error,20,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5444,3,['error'],['error']
Availability,* Have GvsCreateVATfromVDS.wdl take sites-only-vcf as an optional input.; * Added logic to allow/disallow CopyFile to overwrite. [Here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Quickstart%20v3%20ggrant/job_history/bb8906d4-7111-4fd1-a723-b5616b354c23) is a passing run using an existing sites-only VCF.; [Here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Quickstart%20v3%20ggrant/job_history/9c8be4d5-f707-4c54-bde5-18d9d23cde66) is a run where it tried to generate the sites-only VCF. Failing because of Echo issues with creating VDS.; [Here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/8f8cc493-b0ff-4d8c-8813-6c463dbf17c0) is an integration test. It's failing in ValidateVDS on two paths (the ones that create VDSes) since this is based off of EchoCallset branch - this is expected,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8866:516,Echo,Echo,516,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8866,2,['Echo'],"['Echo', 'EchoCallset']"
Availability,* I introduced a compile error because my branch wasn't rebased on the changes to ArgumentsBuilder,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6483:25,error,error,25,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6483,1,['error'],['error']
Availability,* Implemented a suggestion from an ancient TODO in ApplyBQSRArgumentCollection which was waiting for a now available barclay feature,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6438:107,avail,available,107,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6438,1,['avail'],['available']
Availability,* Java 8 doesn't come by default on many machines now. Updating the; README with advice about where to download a java8 jdk.; * Part of https://github.com/broadinstitute/gatk/issues/6024,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6025:103,down,download,103,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6025,1,['down'],['download']
Availability,* PrintWriter doesn't throw exceptions on write failures and might therefore lead to unexpectedly trunacated data being produced without any notification; * replacing it's use in MetricsUtils and MafOutputRenderer where it might cause problems; * partial fix for https://github.com/broadinstitute/gatk/issues/5458,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5461:48,failure,failures,48,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5461,1,['failure'],['failures']
Availability,* Removing 2 redundant abstract methods by pulling them up to the base class,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6560:13,redundant,redundant,13,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6560,1,['redundant'],['redundant']
Availability,"* Should be runnable on-demand using a convenient mechanism (eg., reviewer types a command on a github PR). * Should be robust enough to provide confidence that a substantial change to a stable variant-calling tool is safe to merge. * Should cover performance as well as correctness. * Output may be a report that a human has to read (do not need automated pass/fail). * Implement for `HaplotypeCaller` and CNV tools first (with help of @LeeTL1220), then work with other teams to get test coverage for their tools.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4630:120,robust,robust,120,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4630,1,['robust'],['robust']
Availability,* When running recursive deletion file hooks we now catch all exceptions and log them at DEBUG level instead of letting them propagate.; * This should reduce confusion when test have deletion failures.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6125:192,failure,failures,192,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6125,1,['failure'],['failures']
Availability,"* added a reference parameter to FeatureData source and FeatureManager methods; * genomicsDB requires a reference, previously this was being passed; through by hardcoding it in the required json files; * json files are now autogenerated by the importer tool, but the; reference wasn't being handled correctly. * updated the various walkers to pass the reference through if available. * gendb:// paths now point to the workspace directory instead of a; directory of jsons. * removed the ability to specify array, vidmap.json, and; callset.json paths in the importer tool since we now rely on the; structure and naming of the files when loading; moved some constants to GenomicsDBConstants. * updated GenomicsDBIntegration tests to use the new importer instead of a; prepackaged and very brittle set of json files. fixed a bug in GenomicsDBImporterIntegrationTests that made both tests; write to the same workspace",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2626:373,avail,available,373,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2626,1,['avail'],['available']
Availability,"* changing the key hash we use to download R package keys on travis from an insecure 32 bit hash that has been compromised to a more secure longer hash; * we will no longer be installing the ""Totally Legit Signing Key""; * see https://evil32.com/ for a summary of the problem",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5214:34,down,download,34,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5214,1,['down'],['download']
Availability,* creating utils to spin up a Dataproc cluster which will shut itself down after a brief interval of inactivity (10 minutes idle or 30 minutes total); * adding tests which spin up a cluster and run PrintReadsSpark on them; * updating gatk-launch to be aware of new GCLOUD_HOME environment variable. first round of #2298,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3767:70,down,down,70,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3767,1,['down'],['down']
Availability,* update gradle wrapper 8.2.1 -> 8.10.2; * remove 'versions' plugin because we don't use it; * update gradle plugins to new versions; * shadow plugin changed maintainers and coordinates com.github.johnrengelman.shadow:8.1.1 -> com.gradleup.shadow:8.3.3; * git-version 0.5.1 -> 3.1.0; * sonatype scan 2.6.1 -> 2.8.3; * download 5.4.0 -> 5.6.0; * use tasks.register() which is the newer style,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8998:318,down,download,318,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8998,1,['down'],['download']
Availability,* updating google-cloud-java 0.59.0 -> 0.62.0; * this includes retries on 502 errors see https://github.com/GoogleCloudPlatform/google-cloud-java/pull/3557,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5194:78,error,errors,78,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5194,1,['error'],['errors']
Availability,"**. Note this has been renamed from PathSeqKmerSpark. Input:; 1) Host reference FASTA; 2) False positive probability (0 create a hash set, >0 to create a Bloom filter); 3) Kmer length (1-31); 4) Kmer base indices to mask (optional). Output:; 1) Serialized kmer Hopscotch set (.hss) or Bloom filter (.bfi) file. For each reference record, the tool generates a list of long's containing the canonicalized/masked kmers. The result is a Collection<long[]> variable, which is then converted to either a PSKmerSet (Hopscotch set) or PSKmerBloomFilter, depending on the desired false positive probability. . The PSKmerSet/BloomFilter classes are basically wrappers for LargeLongHopscotchSet and LongBloomFilter, respectively. They both inherit PSKmerCollection, which provides a contains() function for querying new kmers for set membership and makes loading the kmers for filtering more convenient. These classes also store the kmer size, mask, and false positive probability. They also handle canonicalization/masking on queried kmers. **PathSeqFilterSpark tool**. Input:; 1) Input BAM; 2) Host kmer set file (optional); 3) Host reference bwa image (optional). Output:; 1) BAM containing paired reads that still have mates; 2) BAM containing unpaired reads / reads whose mates were filtered out; 3) Metrics file containing read counts and elapsed wall time at each step (optional). Filtering steps performed on each read:; - If the user sets the --isHostAligned, the read will first be filtered if it is aligned sufficiently well ; - Alignment info is stripped; - A series of quality filters (same as in the previous version of this tool); - Kmerized and filtered out if at least a threshold number of kmers are in the host set (default 1); - Aligned to the host reference and filtered if it maps sufficiently well; - Sequence duplicates are removed. Other:; -Fixed bugginess in very large LongBloomFilters by changing a size variable from int to long. ; - Also realized we can't get away with using just ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3115:1259,mask,masking,1259,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3115,1,['mask'],['masking']
Availability,"**;BQHIST=5,1,0,0,1,11,2,0,0,0,14,2,0,0,1,15,1,0,0,0,16,1,0,0,0,17,0,2,0,0,18,2,0,0,1,19,6,0,1,0,20,25,0,2,2,21,13,0,1,2,22,20,0,3,3,23,2,1,2,1,24,6,0,2,0,25,21,1,4,7,26,33,0,5,6,27,18,0,0,7,28,29,0,0,4,29,26,2,4,8,30,161,4,5,51,31,263,2,3,51,32,129,2,3,22,33,41,0,0,0,34,15,0,0,0,35,20,0,0,0,36,19,0,0,0,37,12,0,0,0,38,1,0,0,0,39,9,0,0,0,41,18,0,0,0,44,26,0,0,0;BaseQRankSum=-6.431;ClippingRankSum=-7.714;DP=1323;ECNT=1;FS=0.000;LikelihoodRankSum=-7.886;MBQ=31,30,26,30;MFRL=6590,6585,4819,6586;MMQ=60,60,60,60;MPOS=16,15,7;MQ=59.98;MQ0=0;MQRankSum=0.000;NALOD=0.569,1.49,1.49;NCC=0;NCount=0;NLOD=27.80,30.51,30.97;OCM=0;POPAF=6.00,6.00,6.00;REF\_BASES=GAACTTGCTTCTTTTTTTTGC;RPA=8,9,10,11;RU=T;ReadPosRankSum=5.751;SOR=1.152;STR;Samples=TCGA-NJ-A55R-01A-11R-A262-07;TLOD=284.47,51.82,3.50 GT:AD:AF:DP:F1R2:F2R1:SB 0/1/2/3:819,166,35,14:0.161,0.034,0.014:1034:365,76,17,4:440,87,17,8:16,803,6,209 0/0:103,1,0,0:0.017,8.250e-03,8.221e-03:104:50,1,0,0:52,0,0,0:26,77,0,1. The error log that FilterMutectCalls emited was listed below:. Using GATK jar /home/lqh/software/GATK-4.2.0.0/gatk-package-4.2.0.0-local.jar ; ; Running: ; ; java -Dsamjdk.use\_async\_io\_read\_samtools=false -Dsamjdk.use\_async\_io\_write\_samtools=true -Dsamjdk.use\_async\_io\_write\_tribble=false -Dsamjdk.compression\_level=2 -jar /home/lqh/software/GATK-4.2.0.0/gatk-package-4.2.0.0-local.jar FilterMutectCalls -R /public1/data/resources/ref\_genome/GRCh38/GRCh38.d1.vd1.fa -V somatic\_mutation/Mutect2/test.vcf.gz -O somatic\_mutation/FilterMutectCalls/test.vcf.gz ; ; 11:03:39.517 INFO NativeLibraryLoader - Loading libgkl\_compression.so from jar:file:/home/lqh/software/GATK-4.2.0.0/gatk-package-4.2.0.0-local.jar!/com/intel/gkl/native/libgkl\_compression.so ; ; Jun 04, 2021 11:03:49 AM shaded.cloud\_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine ; ; INFO: Failed to detect whether we are running on Google Compute Engine. ; ; 11:03:49.968 INFO FilterMutectCalls - --------------------------",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7298:2363,error,error,2363,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7298,1,['error'],['error']
Availability,"**Command**; `gatk VariantEval -eval SimpleExample.vcf.gz -O output_gatk_variantEval.txt`. I got the following error; ```; !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. Warning: VariantEval is a BETA tool and is not yet ready for use in production. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. 14:37:10.767 INFO VariantEval - Initializing engine; 14:37:11.138 INFO FeatureManager - Using codec VCFCodec to read file file:///Users/justinzhang/daiichi/SimpleExample.vcf.gz; 14:37:11.268 INFO VariantEval - Done initializing engine; 14:37:11.278 INFO VariantEval - Creating 3 combinatorial stratification states; 14:37:11.281 INFO ProgressMeter - Starting traversal; 14:37:11.282 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 14:37:11.454 INFO ProgressMeter - unmapped 0.0 250 87719.3; 14:37:11.454 INFO ProgressMeter - Traversal complete. Processed 250 total variants in 0.0 minutes.; 14:37:11.454 INFO VariantEval - Finalizing variant report; 14:37:11.455 INFO VariantEval - Shutting down engine; [October 11, 2019 2:37:11 PM EDT] org.broadinstitute.hellbender.tools.walkers.varianteval.VariantEval done. Elapsed time: 0.02 minutes.; Runtime.totalMemory()=386924544; **java.lang.NullPointerException**; 	at org.broadinstitute.hellbender.tools.walkers.varianteval.VariantEval.getnProcessedLoci(VariantEval.java:822); 	at org.broadinstitute.hellbender.tools.walkers.varianteval.evaluators.CountVariants.finalizeEvaluation(CountVariants.java:184); 	at org.broadinstitute.hellbender.tools.walkers.varianteval.VariantEval.onTraversalSuccess(VariantEval.java:709); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1050); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(C",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6212:111,error,error,111,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6212,1,['error'],['error']
Availability,"**Problem:**; Looking at the runtime block for the funcotator task in the Mutect2 WDL workflow, it doesn't look like `default_disk_space_gb` or `default_ram_mb` has any role in changing the VM resource settings. I don’t see them being used at all in the rest of the task block. The correct parameters to change to adjust the memory and disk space for this task are `small_task_mem` and `small_task_disk`. **Suggestion**; Remove `default_disk_space_gb` or `default_ram_mb` variables since they are not being used in the task. This makes it less confusing when users need to adjust the resources being used, they can simply use the `small_task_mem` and `small_task_disk` variables; or ; Have the `default_disk_space_gb` and `default_ram_mb` variables be used in the runtime block with the `select_first` function that way users have the option to adjust the resources being used, and if not the task can use the default runtime_params dictionary values. This allows funcotator its own separate variables for adjusting resources. Workflow Link: ; https://github.com/broadinstitute/gatk/blob/79a4cda5e045a7f62cc7ed61d102fabc3637fafb/scripts/mutect2_wdl/mutect2.wdl#L1101. User Question Link:; https://gatk.broadinstitute.org/hc/en-us/community/posts/360068111052-Mutect2-Funcotator-error-?page=1#community_comment_360011181392",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6680:1278,error,error,1278,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6680,1,['error'],['error']
Availability,"**Summary**: ; A user reported `java.io.IOException: Stream closed` error with ApplyBQSRSpark. GATK 4.0.9.0 runs fine but when the user upgraded to gatk 4.1.1.0 version, they see his error. **User Report**:; I am getting the below error when running gatk-variant pipeline of bcbio. Bcbio using gatk 4.1.1.0 version. ; When I run ApplyBQSRSpark using GATK 4.0.9.0, it runs fine without any issues. Here is the command; **; gatk ApplyBQSRSpark --input test-sort.bam --output test-sort-recal.bam --bqsr-recal-file test-sort-recal.grp --static-quantized-quals 10 --static-quantized-quals 20 --static-quantized-quals 30 --spark-master local[8] --conf spark.local.dir=scratch/ --conf spark.driver.host=localhost --conf spark.network.timeout=800 --jdk-deflater --jdk-inflater**. Here is the error. [April 28, 2019 10:11:25 AM AST] org.broadinstitute.hellbender.tools.spark.ApplyBQSRSpark done. Elapsed time: 0.15 minutes.; Runtime.totalMemory()=874512384; **htsjdk.samtools.util.RuntimeIOException: java.io.IOException: Stream closed**; at htsjdk.samtools.IndexStreamBuffer.readFully(IndexStreamBuffer.java:23); at htsjdk.samtools.IndexStreamBuffer.readLong(IndexStreamBuffer.java:62); at htsjdk.samtools.AbstractBAMFileIndex.readLong(AbstractBAMFileIndex.java:436); at htsjdk.samtools.AbstractBAMFileIndex.query(AbstractBAMFileIndex.java:311); at htsjdk.samtools.CachingBAMFileIndex.getQueryResults(CachingBAMFileIndex.java:159); at htsjdk.samtools.BAMIndexMerger.processIndex(BAMIndexMerger.java:43); at htsjdk.samtools.BAMIndexMerger.processIndex(BAMIndexMerger.java:16); at org.disq_bio.disq.impl.file.IndexFileMerger.mergeParts(IndexFileMerger.java:90); at org.disq_bio.disq.impl.formats.bam.BamSink.save(BamSink.java:132); at org.disq_bio.disq.HtsjdkReadsRddStorage.write(HtsjdkReadsRddStorage.java:225); at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSink.writeReads(ReadsSparkSink.java:155); at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSink.writeReads(Rea",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5919:68,error,error,68,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5919,4,['error'],['error']
Availability,**UPDATE**; Add proposed heuristic alignment filtering/picking of long reads for later cpx SV resolving.; Solves #3221 . . Changed `AlignedContig` by adding a boolean field to signal if several equally good alignment configurations exist for downstream analysis.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3432:242,down,downstream,242,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3432,1,['down'],['downstream']
Availability,"**changes in this PR:**; - resolves specops issue #247 - ImportGenomes.wdl takes Array[File] from data table as vcf input; - refactor LoadBigQueryData.wdl back into ImportGenomes; - returns an error if the `bq load` step fails (workflow was silently succeeding when this step failed); - checks existence of tables using `bq show` rather than the csv file - this should still be safe against a race condition because of @ericsong 's refactoring to prevent the `CreateTables` step from being scattered; - run CreateTables at the start (don't wait for CreateImportTsvs); - does NOT use a preemptible VM for the LoadTables step, to minimize (though not eliminate) the possibility of loading a duplicate set of data (see specops issue #248 for further discussion). **testing:**; - these changes were tested in Terra, BQ outputs checked and verified",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7112:193,error,error,193,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7112,1,['error'],['error']
Availability,"*before*: GATK crashes with a stack trace. The stack trace contains useful; info, but:; * it's hard to read; * it doesn't include the name of the file we cannot access. *now*, a better message that addresses both issues:; > A USER ERROR has occurred: Couldn't read file gs://(...). Error was:; > 401: Anonymous users does not have storage.objects.get access to object (...). Additional information (including a stack trace) is displayed if the; user specifies `--verbosity=DEBUG`",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2417:231,ERROR,ERROR,231,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2417,2,"['ERROR', 'Error']","['ERROR', 'Error']"
Availability,"+ blaunch -no-wait -z hpcgenomicn24 /spark-1.6.2-bin-hadoop2.6//bin/spark-class org.apache.spark.deploy.worker.Worker spark://hpcgenomicn24:6311 -c 16; + echo --conf spark.executor.memory=2g --conf spark.driver.memory=2g --conf spark.local.dir=/gpfs/ngsdata/sparkcache --class org.broadinstitute.hellbender.Main /gpfs/software/spark/gatk4onspark.jar PrintReadsSpark -I /gpfs/home/tpathare/gatk/src/test/resources/NA12878.chr17_69k_70k.dictFix.bam -O /gpfs/home/tpathare/test/; --conf spark.executor.memory=2g --conf spark.driver.memory=2g --conf spark.local.dir=/gpfs/ngsdata/sparkcache --class org.broadinstitute.hellbender.Main /gpfs/software/spark/gatk4onspark.jar PrintReadsSpark -I /gpfs/home/tpathare/gatk/src/test/resources/NA12878.chr17_69k_70k.dictFix.bam -O /gpfs/home/tpathare/test/; + /spark-1.6.2-bin-hadoop2.6//bin/spark-submit --master spark://hpcgenomicn24:6311 --conf spark.executor.memory=2g --conf spark.driver.memory=2g --conf spark.local.dir=/gpfs/ngsdata/sparkcache --class org.broadinstitute.hellbender.Main /gpfs/software/spark/gatk4onspark.jar PrintReadsSpark -I /gpfs/home/tpathare/gatk/src/test/resources/NA12878.chr17_69k_70k.dictFix.bam -O /gpfs/home/tpathare/test/; 23:25:07.475 INFO IntelGKLUtils - Trying to load Intel GKL library from:; 	jar:file:/gpfs/software/spark/gatk4onspark.jar!/com/intel/gkl/native/libIntelGKL.so; 23:25:07.552 INFO IntelGKLUtils - Intel GKL library loaded from classpath.; [November 16, 2016 11:25:07 PM AST] org.broadinstitute.hellbender.tools.spark.pipelines.PrintReadsSpark --output /gpfs/home/tpathare/test/ --input /gpfs/home/tpathare/gatk/src/test/resources/NA12878.chr17_69k_70k.dictFix.bam --readValidationStringency SILENT --interval_set_rule UNION --interval_padding 0 --interval_exclusion_padding 0 --bamPartitionSize 0 --disableSequenceDictionaryValidation false --shardedOutput false --numReducers 0 --sparkMaster local[*] --help false --version false --verbosity INFO --QUIET false --use_jdk_deflater false --disableAllReadFilte",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2268:154,echo,echo,154,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2268,1,['echo'],['echo']
Availability,", 2016 at 3:27 PM, Louis Bergelson notifications@github.com; wrote:. > I got a segfault while running CreatePanelOfNormalsIntegrationTest.; > Subsequent runs were unable to reproduce it.; > ; > 18:03:07.573 WARN TaskSetManager:70 - Stage 181 contains a task of very large size (119 KB). The maximum recommended task size is 100 KB.; > Test: Test method testAllTargetsHDF5PoNCreationSpark[0](null, src/test/resources/org/broadinstitute/hellbender/tools/exome/create-pon-control-full.pcov)(org.broadinstitute.hellbender.tools.exome.CreatePanelOfNormalsIntegrationTest) produced standard out/err: 18:03:07.612 WARN TaskSetManager:70 - Stage 182 contains a task of very large size (119 KB). The maximum recommended task size is 100 KB.; > ; > ```; > 18:03:07.612 WARN TaskSetManager:70 - Stage 182 contains a task of very large size (119 KB). The maximum recommended task size is 100 KB.; > ```; > ; > #; > ; > # A fatal error has been detected by the Java Runtime Environment:; > ; > #; > ; > # SIGSEGV (0xb) at pc=0x000000010a5a9401, pid=2425, tid=8963; > ; > #; > ; > # JRE version: Java(TM) SE Runtime Environment (8.0_91-b14) (build 1.8.0_91-b14); > ; > # Java VM: Java HotSpot(TM) 64-Bit Server VM (25.91-b14 mixed mode bsd-amd64 compressed oops); > ; > # Problematic frame:; > ; > # V [libjvm.dylib+0x1a9401]; > ; > #; > ; > # Failed to write core dump. Core dumps have been disabled. To enable core dumping, try ""ulimit -c unlimited"" before starting Java again; > ; > #; > ; > # An error report file with more information is saved as:; > ; > # /Users/louisb/Workspace/gatk-protected/hs_err_pid2425.log; > ; > #; > ; > # If you would like to submit a bug report, please visit:; > ; > # http://bugreport.java.com/bugreport/crash.jsp; > ; > #; > ; > hs_err_pid2425.log.txt; > https://github.com/broadinstitute/gatk-protected/files/448383/hs_err_pid2425.log.txt; > ; > @yfarjoun https://github.com/yfarjoun Is this similar to the crash you; > saw a while back?; > ; > —; > You are receiving this beca",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2883:2907,error,error,2907,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2883,1,['error'],['error']
Availability,", 2022 12:17:31 AM GMT; 00:17:32.228 INFO Mutect2 - ------------------------------------------------------------; 00:17:32.228 INFO Mutect2 - ------------------------------------------------------------; 00:17:32.229 INFO Mutect2 - HTSJDK Version: 2.24.1; 00:17:32.230 INFO Mutect2 - Picard Version: 2.25.4; 00:17:32.230 INFO Mutect2 - Built for Spark Version: 2.4.5; 00:17:32.231 INFO Mutect2 - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 00:17:32.231 INFO Mutect2 - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 00:17:32.231 INFO Mutect2 - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 00:17:32.232 INFO Mutect2 - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 00:17:32.232 INFO Mutect2 - Deflater: IntelDeflater; 00:17:32.232 INFO Mutect2 - Inflater: IntelInflater; 00:17:32.233 INFO Mutect2 - GCS max retries/reopens: 20; 00:17:32.233 INFO Mutect2 - Requester pays: disabled; 00:17:32.233 INFO Mutect2 - Initializing engine; 00:17:33.373 INFO Mutect2 - Shutting down engine; [April 5, 2022 12:17:33 AM GMT] org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2 done. Elapsed time: 0.02 minutes.; Runtime.totalMemory()=361234432; htsjdk.samtools.cram.CRAMException: Attempt to create a bai entry for an unmapped slice with unexpected alignment start (0) or span (-2147483647) values; 	at htsjdk.samtools.cram.BAIEntry.<init>(BAIEntry.java:60); 	at htsjdk.samtools.cram.BAIEntry.<init>(BAIEntry.java:83); 	at htsjdk.samtools.cram.CRAIIndex.openCraiFileAsBaiStream(CRAIIndex.java:89); 	at htsjdk.samtools.SamIndexes.asBaiSeekableStreamOrNull(SamIndexes.java:91); 	at htsjdk.samtools.CRAMFileReader.initWithStreams(CRAMFileReader.java:203); 	at htsjdk.samtools.CRAMFileReader.<init>(CRAMFileReader.java:194); 	at htsjdk.samtools.SamReaderFactory$SamReaderFactoryImpl.open(SamReaderFactory.java:432); 	at htsjdk.samtools.SamReaderFactory.open(SamReaderFactory.java:106); 	at org.broadinstitute.hellbender.engine.ReadsPathDataSource.<init>(ReadsPathDataSource.java:245); 	at",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7755:2772,down,down,2772,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7755,1,['down'],['down']
Availability,", I experience some issues with GenotypeGVCFs in GATK version 4.0.3.0. It cannot open ""genomicsdb\_array"" although the directory of genomicsdb\_array does exist. I found someone else has reported this issue here: [https://sites.google.com/a/broadinstitute.org/legacy-gatk-forum-discussions/2018-04-11-2017-12-02/11184-Could-not-open-array-genomicsdbarray-at-workspace-from-GenotypeGVCFs-in-GATK-4000](https://sites.google.com/a/broadinstitute.org/legacy-gatk-forum-discussions/2018-04-11-2017-12-02/11184-Could-not-open-array-genomicsdbarray-at-workspace-from-GenotypeGVCFs-in-GATK-4000) , but except for using the latest version of GATK, it seems like there are no other solutions. I was wondering that how do I fix the issues with GATK 4.0.3.0? Does anyone have a better solution?. I also tried GenotypeGVCFs in GATK 4.2.1.0, but there is a problem in terms of MQ calculation. So I think it's better to stick to the same GATK version in the whole workflow. A USER ERROR has occurred: Bad input: Presence of '-RAW\_MQ' annotation is detected. ; ; This GATK version expects key RAW\_MQandDP with a tuple of sum of squared MQ values and total reads over variant genotypes as the value. ; ; This could indicate that the provided input was produced with an older version of GATK. ; ; Use the argument '--allow-old-rms-mapping-quality-annotation-data' to override and attempt the deprecated MQ calculation. ; ; There may be differences in how newer GATK versions calculate DP and MQ that may result in worse MQ results. Use at your own risk. Another question is related to the fasta file:. I downloaded the reference data in the link of [https://console.cloud.google.com/storage/browser/gatk-legacy-bundles/b37](https://console.cloud.google.com/storage/browser/gatk-legacy-bundles/b37) , when I noticed that this is an old database, I have already generated GVCF files. It seems like GenotypeGVCFs does not understand the FAI index file. error informaion; ================. \[E::fai\_read\] Could not unde",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7442:5935,ERROR,ERROR,5935,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7442,1,['ERROR'],['ERROR']
Availability,", line 674, in exec_module; File ""<frozen importlib._bootstrap_external>"", line 780, in get_code; File ""<frozen importlib._bootstrap_external>"", line 832, in get_data; OSError: [Errno 23] Too many open files in system: '/gatk/local_mnt/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-debian-stretch-sid-x86_64-3.6.2-64/tmp_yxu5we5/__init__.py'; Error in atexit._run_exitfuncs:; Traceback (most recent call last):; File ""/opt/miniconda/envs/gatk/lib/python3.6/site-packages/theano/gof/cmodule.py"", line 1492, in _on_atexit; File ""/opt/miniconda/envs/gatk/lib/python3.6/site-packages/theano/gof/cmodule.py"", line 1295, in clear_old; File ""/opt/miniconda/envs/gatk/lib/python3.6/site-packages/theano/gof/cmodule.py"", line 746, in refresh; OSError: [Errno 23] Too many open files in system: '/gatk/local_mnt/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-debian-stretch-sid-x86_64-3.6.2-64'; 23:39:07.445 DEBUG ScriptExecutor - Result: 1; 23:39:07.447 INFO GermlineCNVCaller - Shutting down engine; [February 22, 2019 11:39:07 PM UTC] org.broadinstitute.hellbender.tools.copynumber.GermlineCNVCaller done. Elapsed time: 2.14 minutes.; Runtime.totalMemory()=2305818624; org.broadinstitute.hellbender.utils.python.PythonScriptExecutorException: ; python exited with 1; Command Line: python /gatk/local_mnt/cromwell-executions/CNVGermlineCohortWorkflow/098a389e-b298-4324-8a8c-9f46f05708b5/call-GermlineCNVCallerCohortMode/shard-12910/tmp.cd408023/cohort_denoising_calling.1650827882847090378.py --ploidy_calls_path=/gatk/local_mnt/cromwell-executions/CNVGermlineCohortWorkflow/098a389e-b298-4324-8a8c-9f46f05708b5/call-GermlineCNVCallerCohortMode/shard-12910/execution/contig-ploidy-calls-dir --output_calls_path=/gatk/local_mnt/cromwell-executions/CNVGermlineCohortWorkflow/098a389e-b298-4324-8a8c-9f46f05708b5/call-GermlineCNVCallerCohortMode/shard-12910/execution/out/csi_batch1-4_wes_gcnv_pon-calls --output_tracking_path=/gatk/local_mnt/cromwell-executions/CNVGermlineCohortWorkflow/098a389e",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5714:22280,down,down,22280,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5714,1,['down'],['down']
Availability,"- 18:33362396 35.1 8782590 250142.7; 14:16:29.221 INFO ProgressMeter - 18:47557520 35.3 8830240 250311.5; 14:16:39.224 INFO ProgressMeter - 18:61732084 35.4 8877870 250478.0; 14:16:49.230 INFO ProgressMeter - 18:75390202 35.6 8923700 250591.9; 14:16:59.238 INFO ProgressMeter - 19:4254509 35.8 8947170 250079.8; 14:17:09.252 INFO ProgressMeter - 19:13499637 35.9 8978420 249787.8; 14:17:19.268 INFO ProgressMeter - 19:23216815 36.1 9011160 249539.8; 14:17:29.278 INFO ProgressMeter - 19:31344990 36.3 9038470 249145.0; 14:17:39.298 INFO ProgressMeter - 19:41157554 36.4 9071590 248912.2; 14:17:49.867 INFO ProgressMeter - 19:42798895 36.6 9077130 247866.1; 14:17:59.042 INFO VectorLoglessPairHMM - Time spent in setup for JNI call : 0.15517662000000002; 14:17:59.043 INFO PairHMM - Total compute time in PairHMM computeLogLikelihoods() : 13.012444101000002; 14:17:59.043 INFO SmithWatermanAligner - Total compute time in java Smith-Waterman : 45.65 sec; 14:17:59.043 INFO Mutect2 - Shutting down engine; [May 15, 2020 2:17:59 PM UTC] org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2 done. Elapsed time: 36.79 minutes.; Runtime.totalMemory()=3793223680; java.lang.IndexOutOfBoundsException: Index: 0, Size: 0; at java.util.ArrayList.rangeCheck(ArrayList.java:657); at java.util.ArrayList.get(ArrayList.java:433); at org.broadinstitute.hellbender.tools.walkers.mutect.SomaticGenotypingEngine.lambda$getGermlineAltAlleleFrequencies$27(SomaticGenotypingEngine.java:351); at java.util.stream.ReferencePipeline$6$1.accept(ReferencePipeline.java:244); at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:546); at java.util.stream.AbstractPipeline.evaluateToArrayNode(AbstractPipeline.java:260); at java.util.stream.DoublePipeline.toArray(Double",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6605:1737,down,down,1737,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6605,1,['down'],['down']
Availability,- Add more detail to error message so that it will be more usful for …,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4498:21,error,error,21,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4498,1,['error'],['error']
Availability,"- Adds size similarity criterion to SVConcordance and SVCluster tools. This is particularly useful for accurately matching smaller SVs that have a high degree of breakpoint uncertainty, in which case reciprocal overlap does not work well. PESR/mixed variant types must have size similarity, reciprocal overlap, and breakend window criteria met. Depth-only variants may have either size similarity + reciprocal overlap OR breakend window criteria met (or both).; - Rewrites some of the linkage logic to be simpler to read.; - Fixes a rare bug with `SortedMultiset` in `SVClusterEngine` that sometimes caused records with identical start positions to get lost.; - Removes null record attributes to avoid `.` INFO/FORMAT fields, which cause a parsing error with Integer types.; - Add check that the vcf header contigs are sorted in the same order.; - Retain FILTER and QUAL fields in output.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8257:748,error,error,748,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8257,1,['error'],['error']
Availability,"- Appears in `VCFOutputRenderer`... not sure if this is an issue in the `MAFOutputRenderer`. I am not sure what the exact error is here, but how can I have multiple IGR funcotations for a single variant? I believe that a single variant can be IGR only or not IGR at all, even when looking at multiple transcripts. Perhaps the error is that the variant is being queried by largest gene footprint and then being rendered for transcripts that do not overlap the variant?. For example:; ```; |hg19|chr19|9091811|9091811|IGR||SNP|G|G|A|||+||||||0.5286783042394015|GAGGGTTTCAGCATGGACAGG|||hg19|chr19|9091811|9091811|IGR||SNP|G|G|A|||+||||||0.5286783042394015|GAGGGTTTCAGCATGGACAGG||MUC16|hg19|chr19|9091811|9091811|SILENT||SNP|G|G|A|g.chr19:9091811G>A|ENST00000397910.4|-|1|208|c.4C>T|c.(4-6)Ctg>Ttg|p.L2L|0.5286783042394015|GAGGGTTTCAGCATGGACAGG|IGR_ANNOTATON_%3B_IGR_ANNOTATON||hg19|chr19|9091811|9091811|IGR||SNP|G|G|A|||+||||||0.5286783042394015|GAGGGTTTCAGCATGGACAGG|||hg19|chr19|9091811|9091811|IGR||SNP|G|G|A|||+||||||0.5286783042394015|GAGGGTTTCAGCATGGACAGG||MUC16|hg19|chr19|9091811|9091811|SILENT||SNP|G|G|A|g.chr19:9091811G>A|ENST00000397910.4|-|1|208|c.4C>T|c.(4-6)Ctg>Ttg|p.L2L|0.5286783042394015|GAGGGTTTCAGCATGGACAGG|IGR_ANNOTATON_%3B_IGR_ANNOTATON; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4810:122,error,error,122,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4810,2,['error'],['error']
Availability,- Deprecated FuncotatorUtils.getCodingSequence (until its fixed).; - Added a more descriptive error message when the reference does not contain sequence information for a given position.; - Fixed all args to be kabob case.; - Fixed high-level Funcotator documentation. Fixes #4021,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4063:94,error,error,94,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4063,1,['error'],['error']
Availability,- Error that was missed in testing.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4045:2,Error,Error,2,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4045,1,['Error'],['Error']
Availability,- For support and documentation go to https://software.broadinstitute.org/gatk/; 18:04:27.246 INFO CNNScoreVariants - Executing as platon@platon-VivoBook-ASUSLaptop-X712FA-X712FA on Linux v5.4.0-42-generic amd64; 18:04:27.246 INFO CNNScoreVariants - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_192-b01; 18:04:27.247 INFO CNNScoreVariants - Start Date/Time: 26 августа 2020 г. 18:04:27 MSK; 18:04:27.247 INFO CNNScoreVariants - ------------------------------------------------------------; 18:04:27.247 INFO CNNScoreVariants - ------------------------------------------------------------; 18:04:27.247 INFO CNNScoreVariants - HTSJDK Version: 2.23.0; 18:04:27.247 INFO CNNScoreVariants - Picard Version: 2.22.8; 18:04:27.247 INFO CNNScoreVariants - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 18:04:27.247 INFO CNNScoreVariants - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 18:04:27.247 INFO CNNScoreVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 18:04:27.247 INFO CNNScoreVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 18:04:27.247 INFO CNNScoreVariants - Deflater: IntelDeflater; 18:04:27.247 INFO CNNScoreVariants - Inflater: IntelInflater; 18:04:27.247 INFO CNNScoreVariants - GCS max retries/reopens: 20; 18:04:27.247 INFO CNNScoreVariants - Requester pays: disabled; 18:04:27.247 INFO CNNScoreVariants - Initializing engine; 18:04:27.481 INFO CNNScoreVariants - Shutting down engine; [26 августа 2020 г. 18:04:27 MSK] org.broadinstitute.hellbender.tools.walkers.vqsr.CNNScoreVariants done. Elapsed time: 0.01 minutes.; Runtime.totalMemory()=362807296; ***********************************************************************. A USER ERROR has occurred: Couldn't read file file:///dev/stdin. Error was: It isn't a regular file. ***********************************************************************; Set the system property GATK_STACKTRACE_ON_USER_EXCEPTION (--java-options '-DGATK_STACKTRACE_ON_USER_EXCEPTION=true') to print the stack trace.; ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6749:3108,down,down,3108,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6749,3,"['ERROR', 'Error', 'down']","['ERROR', 'Error', 'down']"
Availability,"- I sneaked in another change where I pass in a single file containing a list of input_vcfs instead of an array of input_vcfs. I made this because Terra couldn't save my inputs when I passed in 700 samples.; - Most of the logic was moved into `CreateTables`, including the determination for what files to load. It would have been cleaner to move all of the file loading logic into `LoadTable` but the current approach cuts down the on the number of `gsutil ls` calls made and more importantly, only spins up a shard if there are files to load.; - I pushed the logic into a separate workflow because I wanted to refactor it as two tasks and I couldn't find a way to get a Task to call another Task without wrapping it in a workflow.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7056:423,down,down,423,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7056,1,['down'],['down']
Availability,"- Loading libgkl_pairhmm.dylib from jar:file:/Users/loeblabm11/bioinformatics/programs/GATK/gatk-4.0.3.0/gatk-package-4.0.3.0-local.jar!/com/intel/gkl/native/libgkl_pairhmm.dylib; 12:18:12.368 WARN IntelPairHmm - Flush-to-zero (FTZ) is enabled when running PairHMM; 12:18:12.368 WARN IntelPairHmm - Ignoring request for 4 threads; not using OpenMP implementation; 12:18:12.369 INFO PairHMM - Using the AVX-accelerated native PairHMM implementation; 12:18:12.403 INFO ProgressMeter - Starting traversal; 12:18:12.403 INFO ProgressMeter - Current Locus Elapsed Minutes Regions Processed Regions/Minute; 12:18:22.403 INFO ProgressMeter - chr1:75065650 0.2 250240 1501440.0; 12:18:29.713 INFO VectorLoglessPairHMM - Time spent in setup for JNI call : 0.009098343; 12:18:29.713 INFO PairHMM - Total compute time in PairHMM computeLogLikelihoods() : 0.121747383; 12:18:29.713 INFO SmithWatermanAligner - Total compute time in java Smith-Waterman : 0.42 sec; 12:18:29.763 INFO Mutect2 - Shutting down engine; [April 11, 2018 12:18:29 PM PDT] org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2 done. Elapsed time: 0.31 minutes.; Runtime.totalMemory()=1781006336; java.lang.NullPointerException; 	at org.broadinstitute.hellbender.utils.locusiterator.ReadStateManager.readStartsAtCurrentPosition(ReadStateManager.java:132); 	at org.broadinstitute.hellbender.utils.locusiterator.ReadStateManager.collectPendingReads(ReadStateManager.java:159); 	at org.broadinstitute.hellbender.utils.locusiterator.LocusIteratorByState.lazyLoadNextAlignmentContext(LocusIteratorByState.java:315); 	at org.broadinstitute.hellbender.utils.locusiterator.LocusIteratorByState.hasNext(LocusIteratorByState.java:252); 	at org.broadinstitute.hellbender.utils.locusiterator.IntervalAlignmentContextIterator.advanceAlignmentContext(IntervalAlignmentContextIterator.java:104); 	at org.broadinstitute.hellbender.utils.locusiterator.IntervalAlignmentContextIterator.advanceAlignmentContextToCurrentInterval(IntervalAlignmentContextI",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4665:4069,down,down,4069,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4665,1,['down'],['down']
Availability,- M2 WDL will now default to having the orientation bias filter (`FilterByOrientationBias`) turned on. Closes #5016 ; - Empty artifact modes parameter will no longer cause failure in `FilterByOrientationBias`. Instead the task `FilterByOrientationBias` will not run. Closes #5025,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5019:172,failure,failure,172,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5019,1,['failure'],['failure']
Availability,- Modified the files so that we can build libVectorLoglessPairHMM.so on Ubuntu/ppc64le platform; - Restored and modified the files for 128-bit vector that are on GATK3; - Added a new file to replace AVX with POWER8 vector instructions; - [Question] Is any unit test included in the repository to test the library?; - Confirmed that the library was built on Ubuntu 15.10/ppc64le. ```; ./gradlew installAll; :downloadGsaLibFile UP-TO-DATE; :extractIntelDeflater; :compileJava; :processResources; :classes; :compileVectorLoglessPairHMMSharedLibraryVectorLoglessPairHMMCpp; :linkVectorLoglessPairHMMSharedLibrary; :copySharedLib; :jar; :startScripts; :installDist; :sparkJar; :installSpark; :installAll. BUILD SUCCESSFUL; ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1748:407,down,downloadGsaLibFile,407,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1748,1,['down'],['downloadGsaLibFile']
Availability,- Moved `OutputSortingBuffer` class used by `SVCluster` into `SVClusterEngine` to unify clustering code across tools; - Fixes an issue where no-call genotypes caused an error in `JointGermlineCNVSegmentation`,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7779:169,error,error,169,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7779,1,['error'],['error']
Availability,- Now will count downloads of all artifacts in github releases instead of just the first one.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8418:17,down,downloads,17,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8418,1,['down'],['downloads']
Availability,"- Processing 29268134 bp from intervals; 19:13:26.834 WARN IndexUtils - Feature file ""/cga/bass/Chunyang/ref/hg19/1000G_phase1.snps.high_confidence.b37.vcf.gz"" appears to contain no sequence dictionary. Attempting to retrieve a sequence dictionary from the associated index file; 19:13:26.973 INFO ASEReadCounter - Done initializing engine; 19:13:26.977 INFO ProgressMeter - Starting traversal; 19:13:26.977 INFO ProgressMeter - Current Locus Elapsed Minutes Loci Processed Loci/Minute; 19:13:27.118 WARN ASEReadCounter - Ignoring site: variant is not het at postion: 1:835092; 19:13:27.118 WARN ASEReadCounter - Ignoring site: variant is not het at postion: 1:835132; 19:13:27.118 WARN ASEReadCounter - Ignoring site: variant is not het at postion: 1:835133; ... ; ...; ...; 19:13:28.229 WARN ASEReadCounter - Ignoring site: variant is not het at postion: 1:29617944; 19:13:28.230 WARN ASEReadCounter - Ignoring site: variant is not het at postion: 1:29618025; 19:13:28.231 INFO ASEReadCounter - 0 read(s) filtered by: ValidAlignmentStartReadFilter; 0 read(s) filtered by: ValidAlignmentEndReadFilter; 0 read(s) filtered by: HasReadGroupReadFilter; 0 read(s) filtered by: MatchingBasesAndQualsReadFilter; 0 read(s) filtered by: SeqIsStoredReadFilter; 51 read(s) filtered by: NotDuplicateReadFilter; 63 read(s) filtered by: NotSecondaryAlignmentReadFilter; 3 read(s) filtered by: MappedReadFilter; 117 total reads filtered; 19:13:28.231 INFO ProgressMeter - 1:29618022 0.0 110019 5264067.0; 19:13:28.231 INFO ProgressMeter - Traversal complete. Processed 110019 total loci in 0.0 minutes.; 19:13:28.233 INFO ASEReadCounter - Shutting down engine; [June 14, 2021 7:13:28 PM UTC] org.broadinstitute.hellbender.tools.walkers.rnaseq.ASEReadCounter done. Elapsed time: 0.04 minutes.; Runtime.totalMemory()=2303197184; ; . output.txt:. contig position variantID refAllele altAllele refCount altCount totalCount lowMAPQDepth lowBaseQDepth rawDepth otherBases improperPairs. . Thanks for your help!. Chunyang",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7314:4993,down,down,4993,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7314,1,['down'],['down']
Availability,- Relaxes restrictions for allowed samples in SVConcordance: the tool can now accept eval/truth VCFs with arbitrary sample sets and will have genotype concordance metrics computed on the intersection of the sample sets. All available samples are still used for AF/AC annotations. Integration tests added for cases when the samples sets are overlapping but not equal.; - Small additional improvements for sites-only VCFs: concordance annotations will now be `.` instead of `NaN` for example. Integration test added for this case.; - Improved behavior for eval AF annotations: these will not be recalculated if they already exist.; - Improved behavior for truth AF annotations: these will now only be recalculated if they don't exist in the input truth VCF.; - Updated tool doc,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8211:224,avail,available,224,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8211,1,['avail'],['available']
Availability,"- Released new data sources to google bucket and FTP site for both somatic and germline (clinical pipeline); - Updated data source download URL to point to the bucket for v1.6.20190124; - Updated minimum version of data sources to v1.6.20190124. With the release and these changes, the following issues are addressed:. Fixes #5259 ; Fixes #5428 ; Fixes #5429",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5614:131,down,download,131,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5614,1,['down'],['download']
Availability,- Updated data sources to include variant sites for symbolic alleles.; - Fixed tests to be correct for new logic.; - Now has tests for symbollic alternate alleles and masked alleles. Fixes #5402,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5406:167,mask,masked,167,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5406,1,['mask'],['masked']
Availability,- Using codec VCFCodec to read file file:///SCRATCH-BIRD/users/lindenbaum-p/work/NEXTFLOW/20221123.hs38me.NTS299.ultrares/work/34/f4[0/1667]a7bb49eaece47a172e2d/TMP/jeter.vcf.gz ; 18:15:23.374 WARN IntelInflater - Zero Bytes Written : 0 ; 18:15:23.385 WARN IntelInflater - Zero Bytes Written : 0 ; 18:15:23.403 INFO IntervalArgumentCollection - Processing 1028 bp from intervals ; 18:15:23.411 INFO HaplotypeCaller - Done initializing engine ; 18:15:23.430 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/LAB-DATA/BiRD/users/lindenbaum-p/packages/gatk/gatk-4.3.0.0/gatk-package-4.3.0.0-local.jar!/com/intel/gkl/native/libgkl_utils.so ; 18:15:23.475 INFO NativeLibraryLoader - Loading libgkl_pairhmm_omp.so from jar:file:/LAB-DATA/BiRD/users/lindenbaum-p/packages/gatk/gatk-4.3.0.0/gatk-package-4.3.0.0-local.jar!/com/intel/gkl/native/libgkl_pairhmm_omp.so ; 18:15:23.651 INFO IntelPairHmm - Flush-to-zero (FTZ) is enabled when running PairHMM ; 18:15:23.651 INFO IntelPairHmm - Available threads: 4 ; 18:15:23.651 INFO IntelPairHmm - Requested threads: 4 ; 18:15:23.651 INFO PairHMM - Using the OpenMP multi-threaded AVX-accelerated native PairHMM implementation ; 18:15:23.671 INFO ProgressMeter - Starting traversal ; 18:15:23.671 INFO ProgressMeter - Current Locus Elapsed Minutes Regions Processed Regions/Minute ; 18:15:26.788 WARN InbreedingCoeff - InbreedingCoeff will not be calculated at position chr1:30191420 and possibly subsequent; at least 10 samples must have called genotypes ; 18:15:27.190 WARN DepthPerSampleHC - Annotation will not be calculated at position chr1:30477350 and possibly subsequent; genotype for sample B00I9EL is not called; 18:15:35.547 INFO ProgressMeter - chr1:32128426 0.2 40 202.1 ; 18:15:48.416 INFO ProgressMeter - chr1:36398656 0.4 80 194.0 ; 18:15:51.025 INFO VectorLoglessPairHMM - Time spent in setup for JNI call : 0.012874514 ; 18:15:51.026 INFO PairHMM - Total compute time in PairHMM computeLogLikelihoods() : 5.818477527000001; 18:1,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8106:4949,Avail,Available,4949,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8106,1,['Avail'],['Available']
Availability,"- added custom classes `ExtractCohortRecord` and `ExtractCohortFilterRecord` that implement `Locatable`; - refactored attribute building from these records; - now that the records are `Locatable`s, can use `OverlapDetector` to filter locations down to only desired intervals (including excluded sites); - removed queryMode `QUERY` and associated querying from options",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7181:244,down,down,244,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7181,1,['down'],['down']
Availability,"- chrM:8920 58.4 62766000 1073951.1 ; ; 12:07:04.855 INFO ProgressMeter - chrM:9385 58.6 62814000 1071582.7 ; ; 12:07:14.867 INFO ProgressMeter - chrM:10083 58.8 62865000 1069408.5 ; ; 12:07:24.914 INFO ProgressMeter - chrM:10943 59.0 62904000 1067032.5 ; ; 12:07:34.942 INFO ProgressMeter - chrX:12975129 59.1 63028000 1066113.4 ; ; 12:07:44.971 INFO ProgressMeter - chrX:41349821 59.3 63179000 1065654.6 ; ; 12:07:54.982 INFO ProgressMeter - chrX:48923158 59.5 63296000 1064631.8 ; ; 12:08:05.013 INFO ProgressMeter - chrX:68535195 59.6 63444000 1064128.8 ; ; 12:08:15.047 INFO ProgressMeter - chrX:102632989 59.8 63592000 1063627.8 ; ; 12:08:25.159 INFO ProgressMeter - chrX:111294586 60.0 63723000 1062822.9 ; ; 12:08:35.207 INFO ProgressMeter - chrX:129516349 60.1 63932000 1063338.7 ; ; 12:08:45.361 INFO ProgressMeter - chrX:153743608 60.3 64037000 1062095.6 ; ; 12:08:56.075 INFO ProgressMeter - chrY:302910 60.5 64182000 1061357.1 ; ; 12:13:04.075 INFO SplitNCigarReads - Shutting down engine ; ; \[August 19, 2020 12:13:04 PM CEST\] org.broadinstitute.hellbender.tools.walkers.rnaseq.SplitNCigarReads done. Elapsed time: 64.67 minutes. ; ; Runtime.totalMemory()=11648630784 ; ; java.lang.IllegalArgumentException: contig must be non-null and not equal to \*, and start must be >= 1 ; ; at org.broadinstitute.hellbender.utils.read.SAMRecordToGATKReadAdapter.setMatePosition(SAMRecordToGATKReadAdapter.java:197) ; ; at org.broadinstitute.hellbender.tools.walkers.rnaseq.OverhangFixingManager.setPredictedMateInformation(OverhangFixingManager.java:445) ; ; at org.broadinstitute.hellbender.tools.walkers.rnaseq.SplitNCigarReads.splitNCigarRead(SplitNCigarReads.java:212) ; ; at org.broadinstitute.hellbender.tools.walkers.rnaseq.SplitNCigarReads.lambda$traverseReads$1(SplitNCigarReads.java:181) ; ; at org.broadinstitute.hellbender.engine.MultiplePassReadWalker.lambda$forEachRead$0(MultiplePassReadWalker.java:60) ; ; at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6776:30972,down,down,30972,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6776,1,['down'],['down']
Availability,- error message was not updated when arguments were changed....,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5969:2,error,error,2,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5969,1,['error'],['error']
Availability,"- error messages will now include all the missing arguments when applicable; - error messages should be more readable; old style:. ```; $ hellbender PrintReads; ***********************************************************************. A USER ERROR has occurred: Invalid command line: Argument output was missing: Argument 'output' is required. ***********************************************************************; ```. new style:. ```; $ hellbender PrintReads; ***********************************************************************. A USER ERROR has occurred:. Invalid command line:; required argument --input was not specified; required argument --output was not specified. Rerun with --help to see more information on available options. ***********************************************************************; ```; - fixed a bug in CommandLineParser; - collection arguments that had a mutual exclusion field would be reported as missing even if one of the mutex arguments was present; - adding tests for this case; - some refactoring on CommandLineParser. fixes #418. <!-- Reviewable:start -->. [<img src=""https://reviewable.io/review_button.png"" height=40 alt=""Review on Reviewable""/>](https://reviewable.io/reviews/broadinstitute/gatk/1144). <!-- Reviewable:end -->",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1144:2,error,error,2,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1144,5,"['ERROR', 'avail', 'error']","['ERROR', 'available', 'error']"
Availability,- expanding unit tests to actually replicate the error if we have a regression.; - applied fix that sorts the output.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3795:49,error,error,49,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3795,1,['error'],['error']
Availability,- fixup for problem with fully specified `file:///` names that I introduced in #1450 ; - adding test for fully specified `file:///` url; - adding additional tests to `ReadSparkSink` for HDFS; - tests for writing to HDFS using `MiniDFSCluster`; - tests for overwriting existing HDFS paths; - fixed instance of Wrong FileSystem exception in `ReadSparkSink`; - refactored `ReadSparkSink` to remove duplication; - adding `MiniClusterUtils`; - revising existing code using `MiniDFSCluster` to go through `MiniClusterUtils`; - had to make the minicluster dependency a compile time instead of test dependency so downstream projects can make use of MiniClusterUtils.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1461:605,down,downstream,605,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1461,1,['down'],['downstream']
Availability,"- improved baits count annotator (""lazy"" post processing); - included bait counts as a multiplicative bias in TargetCoverageSexGenotypeCalculator; - improved info and warn log messages in TargetCoverageSexGenotyper; - interval exclusion via CLI args for TargetCoverageSexGenotyper; - soft target filtering using masks; - more extensive unit/integration tests for TargetCoverageSexGenotyper; - integration test for annotate targets w/ bait counts; - missing test resource files from gatk-protected repo; - address PR review",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3183:312,mask,masks,312,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3183,1,['mask'],['masks']
Availability,"- new ""lazy"" annotation mode in TargetAnnotator (a hack for generating annotations that can not be done with a state-less FeatureWalker); - baits count target annotation; - included bait count as a multiplicative bias in TargetCoverageSexGenotypeCalculator; - improved info and warn log messages in TargetCoverageSexGenotyper; - interval exclusion via CLI args for TargetCoverageSexGenotyper (PAR regions can not be blacklisted via CLI arguments); - soft target filtering using masks; - more extensive unit/integration tests for TargetCoverageSexGenotyper; - integration test for annotate targets w/ bait counts",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2813:478,mask,masks,478,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2813,1,['mask'],['masks']
Availability,"- reduced retries for task calling write API because if it fails more than once, chances are it will continue to fail because the import process was stopped before completion; - hopefully made the error message less scary, also included table number for easier cleanup. Closes https://broadworkbench.atlassian.net/browse/VS-267",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7680:197,error,error,197,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7680,1,['error'],['error']
Availability,"- version; GATK4.2.6.1. Hi, ; When I use the following command to genotype a single g vcf file, the output **alt depth**(ref depth is ok) in the FORMAT column ; are missing. ```; gatk GenotypeGVCFs -R ucsc.hg19.fasta -verbosity ERROR -all-sites true -stand-call-conf 0 --dbsnp dbsnp_138.hg19.vcf -V 0003.g.vcf -O 0003.4.2.6.1.vcf ; ```; For example, `AD:DP 2,1013:1116`, `1116` is for the total depth(DP), and `2,1013` is for the ref depth, however, the **alt allele depth** is missing. is this a bug? Or did I miss something?. ```; ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Allelic depths for the ref and alt alleles in the order listed"">. #input ; chr19	45923653	.	A	G,<NON_REF>	31988.06	.	BaseQRankSum=-1.361;DP=1149;ExcessHet=3.0103;MLEAC=2,0;MLEAF=1.00,0.00;MQRankSum=0.000;RAW_MQandDP=4136400,1149;ReadPosRankSum=-1.250	GT:AD:DP:GQ:PL:SB	1/1:2,1013,101:1116:99:32002,2966,0,32008,3040,32082:1,1,538,576. #output ; chr19	45923653	rs11615	A	G	31988.06	.	AC=2;AF=1.00;AN=2;BaseQRankSum=-1.361e+00;DB;DP=1149;ExcessHet=0.0000;FS=0.000;MLEAC=2;MLEAF=1.00;MQ=60.00;MQRankSum=0.00;QD=31.52;ReadPosRankSum=-1.250e+00;SOR=0.764	GT:AD:DP:GQ:PL	1/1:2,1013:1116:99:32002,2966,0. ```; Best,; xiucz",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7980:228,ERROR,ERROR,228,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7980,1,['ERROR'],['ERROR']
Availability,"---------------------------------------------------------------------------------- ; ERROR StatusLogger Unable to create class org.apache.logging.log4j.core.impl.Log4jContextFactory specified in jar:file:/Users/mac/Desktop/GenomeAnalysisTK-3.8-0-ge9d806836%204/GenomeAnalysisTK.jar!/META-INF/log4j-provider.properties; ERROR StatusLogger Log4j2 could not find a logging implementation. Please add log4j-core to the classpath. Using SimpleLogger to log to the console...; INFO 10:47:55,875 GenomeAnalysisEngine - Deflater: IntelDeflater ; INFO 10:47:55,876 GenomeAnalysisEngine - Inflater: IntelInflater ; INFO 10:47:55,876 GenomeAnalysisEngine - Strictness is SILENT ; INFO 10:47:56,246 GenomeAnalysisEngine - Downsampling Settings: No downsampling ; INFO 10:47:56,255 SAMDataSource$SAMReaders - Initializing SAMRecords in serial ; INFO 10:47:56,333 SAMDataSource$SAMReaders - Done initializing BAM readers: total time 0.07 ; ##### ERROR ------------------------------------------------------------------------------------------; ##### ERROR A USER ERROR has occurred (version 3.8-0-ge9d806836): ; ##### ERROR; ##### ERROR This means that one or more arguments or inputs in your command are incorrect.; ##### ERROR The error message below tells you what is the problem.; ##### ERROR; ##### ERROR If the problem is an invalid argument, please check the online documentation guide; ##### ERROR (or rerun your command with --help) to view allowable command-line arguments for this tool.; ##### ERROR; ##### ERROR Visit our website and forum for extensive documentation and answers to ; ##### ERROR commonly asked questions https://software.broadinstitute.org/gatk; ##### ERROR; ##### ERROR Please do NOT post this error to the GATK forum unless you have really tried to fix it yourself.; ##### ERROR; ##### ERROR MESSAGE: Input files reads and reference have incompatible contigs. Please see https://software.broadinstitute.org/gatk/documentation/article?id=63for more information. Error details: No ove",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6798:2630,ERROR,ERROR,2630,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6798,3,['ERROR'],['ERROR']
Availability,"------------------------------------------------------------------------------------------------; A USER ERROR has occurred: Traversal by intervals was requested but some input files are not indexed.; Please index all input files:. samtools index /cromwell_root/dg.4DFC_3615e55e-6aa3-43e7-8d7b-6f2824071971/C345.TCGA-A3-3373-11A-01D-1421-08.5.bam; --------------------------------------------------------------------------------------------------------------------. This was weird since I set a correct index file as an input, but after some investigation, I realized that ; the error seemed to be occurring when the bucket path where BAM index was located was different from that of BAM file ; For example, if you look at this log below, . `Attempting to download gs://gdc-tcga-phs000178-controlled/KIRC/DNA/WXS/BI/ILLUMINA/C345.TCGA-A3-3373-11A-01D-1421-08.5.bam to /cromwell_root/dg.4DFC_3615e55e-6aa3-43e7-8d7b-6f2824071971/C345.TCGA-A3-3373-11A-01D-1421-08.5.bam; Successfully activated service account; Will continue with download. Activated service account credentials for: [kd5mqbpsed8lzz0kyz9tvkht-3274@dcf-prod.iam.gserviceaccount.com]; Download complete!; 2021/09/29 15:46:14 Localizing input drs://dg.4DFC:ab4d57fa-bfff-4a48-bd96-f2866ecfe0e1 -> /cromwell_root/dg.4DFC_ab4d57fa-bfff-4a48-bd96-f2866ecfe0e1/C345.TCGA-A3-3373-11A-01D-1421-08.5.bam.bai; Requester Pays project ID is Some(vanallen-firecloud-nih); Attempting to download gs://gdc-tcga-phs000178-controlled/KIRC/DNA/WXS/BI/ILLUMINA/C345.TCGA-A3-3373-11A-01D-1421-08.5.bam.bai to /cromwell_root/dg.4DFC_ab4d57fa-bfff-4a48-bd96-f2866ecfe0e1/C345.TCGA-A3-3373-11A-01D-1421-08.5.bam.bai; Successfully activated service account; Will continue with download. Activated service account credentials for: [kd5mqbpsed8lzz0kyz9tvkht-3274@dcf-prod.iam.gserviceaccount.com]; Download complete!`. C345.TCGA-A3-3373-11A-01D-1421-08.5.bam and C345.TCGA-A3-3373-11A-01D-1421-08.5.bam.bai; were successfully downloaded, but since these TCGA files",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7487:1297,down,download,1297,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7487,1,['down'],['download']
Availability,----------------------------------------------------------; 16:46:04.318 INFO VariantsToTable - ------------------------------------------------------------; 16:46:04.320 INFO VariantsToTable - HTSJDK Version: 2.23.0; 16:46:04.320 INFO VariantsToTable - Picard Version: 2.23.3; 16:46:04.320 INFO VariantsToTable - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 16:46:04.321 INFO VariantsToTable - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 16:46:04.321 INFO VariantsToTable - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 16:46:04.321 INFO VariantsToTable - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 16:46:04.321 INFO VariantsToTable - Deflater: IntelDeflater; 16:46:04.322 INFO VariantsToTable - Inflater: IntelInflater; 16:46:04.322 INFO VariantsToTable - GCS max retries/reopens: 20; 16:46:04.322 INFO VariantsToTable - Requester pays: disabled; 16:46:04.322 INFO VariantsToTable - Initializing engine; 16:46:04.805 INFO FeatureManager - Using codec VCFCodec to read file file:///home/india/Downloads/Galaxy57-%5BMerged_file.vcf%5D.vcf; 16:46:04.896 INFO VariantsToTable - Done initializing engine; 16:46:04.917 WARN VariantsToTable - Allele-specific fields will only be split if splitting multi-allelic variants is specified (`--split-multi-allelic` or `-SMA`; 16:46:04.918 INFO ProgressMeter - Starting traversal; 16:46:04.918 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 16:46:05.217 INFO VariantsToTable - Shutting down engine; [16 October 2020 at 4:46:05 PM IST] org.broadinstitute.hellbender.tools.walkers.variantutils.VariantsToTable done. Elapsed time: 0.04 minutes.; Runtime.totalMemory()=132120576; htsjdk.tribble.TribbleException: partial missing values for GL field; 	at htsjdk.variant.variantcontext.GenotypeLikelihoods.parseDeprecatedGLString(GenotypeLikelihoods.java:269); 	at htsjdk.variant.variantcontext.GenotypeLikelihoods.fromGLField(GenotypeLikelihoods.java:78); 	at htsjdk.variant.vcf.AbstractVCFCodec.cre,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6897:3016,Down,Downloads,3016,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6897,1,['Down'],['Downloads']
Availability,"---------------------------------------------------; 01:13:16.077 INFO HaplotypeCaller - HTSJDK Version: 2.13.2; 01:13:16.077 INFO HaplotypeCaller - Picard Version: 2.17.2; 01:13:16.077 INFO HaplotypeCaller - HTSJDK Defaults.COMPRESSION_LEVEL : 1; 01:13:16.078 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 01:13:16.078 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 01:13:16.078 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 01:13:16.078 INFO HaplotypeCaller - Deflater: IntelDeflater; 01:13:16.078 INFO HaplotypeCaller - Inflater: IntelInflater; 01:13:16.078 INFO HaplotypeCaller - GCS max retries/reopens: 20; 01:13:16.078 INFO HaplotypeCaller - Using google-cloud-java patch 6d11bef1c81f885c26b2b56c8616b7a705171e4f from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 01:13:16.078 INFO HaplotypeCaller - Initializing engine; 01:13:17.087 INFO HaplotypeCaller - Shutting down engine; [January 18, 2020 1:13:17 AM IST] org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCaller done. Elapsed time: 0.02 minutes.; Runtime.totalMemory()=2216689664; java.lang.NullPointerException; at org.broadinstitute.hellbender.utils.SequenceDictionaryUtils.getContigNames(SequenceDictionaryUtils.java:463); at org.broadinstitute.hellbender.utils.SequenceDictionaryUtils.getCommonContigsByName(SequenceDictionaryUtils.java:457); at org.broadinstitute.hellbender.utils.SequenceDictionaryUtils.compareDictionaries(SequenceDictionaryUtils.java:234); at org.broadinstitute.hellbender.utils.SequenceDictionaryUtils.validateDictionaries(SequenceDictionaryUtils.java:150); at org.broadinstitute.hellbender.utils.SequenceDictionaryUtils.validateDictionaries(SequenceDictionaryUtils.java:98); at org.broadinstitute.hellbender.engine.GATKTool.validateSequenceDictionaries(GATKTool.java:621); at org.broadinstitute.hellbender.engine.GATKTool.onStartup(GATKTool.java:563); at org.broadinstit",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6384:2030,down,down,2030,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6384,1,['down'],['down']
Availability,"---------------------------------------------; 21:21:12.544 INFO GermlineCNVCaller - ------------------------------------------------------------; 21:21:12.544 INFO GermlineCNVCaller - HTSJDK Version: 2.21.0; 21:21:12.544 INFO GermlineCNVCaller - Picard Version: 2.21.2; 21:21:12.544 INFO GermlineCNVCaller - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 21:21:12.544 INFO GermlineCNVCaller - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 21:21:12.544 INFO GermlineCNVCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 21:21:12.545 INFO GermlineCNVCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 21:21:12.545 INFO GermlineCNVCaller - Deflater: IntelDeflater; 21:21:12.545 INFO GermlineCNVCaller - Inflater: IntelInflater; 21:21:12.545 INFO GermlineCNVCaller - GCS max retries/reopens: 20; 21:21:12.545 INFO GermlineCNVCaller - Requester pays: disabled; 21:21:12.545 INFO GermlineCNVCaller - Initializing engine; 21:21:14.339 INFO GermlineCNVCaller - Shutting down engine; [February 23, 2020 9:21:14 PM EST] org.broadinstitute.hellbender.tools.copynumber.GermlineCNVCaller done. Elapsed time: 0.03 minutes.; Runtime.totalMemory()=281542656; java.lang.RuntimeException: A required Python package (""gcnvkernel"") could not be imported into the Python environment. This tool requires that the GATK Python environment is properly established and activated. Please refer to GATK README.md file for instructions on setting up the GATK Python environment.; 	at org.broadinstitute.hellbender.utils.python.PythonScriptExecutor.checkPythonEnvironmentForPackage(PythonScriptExecutor.java:205); 	at org.broadinstitute.hellbender.tools.copynumber.GermlineCNVCaller.onStartup(GermlineCNVCaller.java:286); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:137); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6467:2966,down,down,2966,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6467,1,['down'],['down']
Availability,"---------------------------------------; 13:56:52.187 INFO GenotypeGVCFs - HTSJDK Version: 2.23.0; 13:56:52.187 INFO GenotypeGVCFs - Picard Version: 2.22.8; 13:56:52.187 INFO GenotypeGVCFs - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 13:56:52.187 INFO GenotypeGVCFs - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 13:56:52.187 INFO GenotypeGVCFs - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 13:56:52.187 INFO GenotypeGVCFs - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 13:56:52.187 INFO GenotypeGVCFs - Deflater: IntelDeflater; 13:56:52.188 INFO GenotypeGVCFs - Inflater: IntelInflater; 13:56:52.188 INFO GenotypeGVCFs - GCS max retries/reopens: 20; 13:56:52.188 INFO GenotypeGVCFs - Requester pays: disabled; 13:56:52.188 INFO GenotypeGVCFs - Initializing engine; 13:56:53.115 INFO GenomicsDBLibLoader - GenomicsDB native library version : 1.3.0-e701905; [TileDB::Buffer] Error: Cannot read from buffer; End of buffer reached.; [TileDB::BookKeeping] Error: Cannot load book-keeping; Reading tile offsets failed.; 13:57:15.762 INFO GenotypeGVCFs - Shutting down engine; [December 21, 2020 1:57:15 PM CST] org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs done. Elapsed time: 0.40 minutes.; Runtime.totalMemory()=2119696384; ***********************************************************************. A USER ERROR has occurred: Couldn't create GenomicsDBFeatureReader. ***********************************************************************; org.broadinstitute.hellbender.exceptions.UserException: Couldn't create GenomicsDBFeatureReader; 	at org.broadinstitute.hellbender.engine.FeatureDataSource.getGenomicsDBFeatureReader(FeatureDataSource.java:410); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.getFeatureReader(FeatureDataSource.java:326); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:282); 	at org.broadinstitute.hellbender.engine.VariantLocusWalker.initializeDrivingVariants(VariantLocusWalker.java:76",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7012:3198,Error,Error,3198,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7012,1,['Error'],['Error']
Availability,"------------------------------. This was weird since I set a correct index file as an input, but after some investigation, I realized that ; the error seemed to be occurring when the bucket path where BAM index was located was different from that of BAM file ; For example, if you look at this log below, . `Attempting to download gs://gdc-tcga-phs000178-controlled/KIRC/DNA/WXS/BI/ILLUMINA/C345.TCGA-A3-3373-11A-01D-1421-08.5.bam to /cromwell_root/dg.4DFC_3615e55e-6aa3-43e7-8d7b-6f2824071971/C345.TCGA-A3-3373-11A-01D-1421-08.5.bam; Successfully activated service account; Will continue with download. Activated service account credentials for: [kd5mqbpsed8lzz0kyz9tvkht-3274@dcf-prod.iam.gserviceaccount.com]; Download complete!; 2021/09/29 15:46:14 Localizing input drs://dg.4DFC:ab4d57fa-bfff-4a48-bd96-f2866ecfe0e1 -> /cromwell_root/dg.4DFC_ab4d57fa-bfff-4a48-bd96-f2866ecfe0e1/C345.TCGA-A3-3373-11A-01D-1421-08.5.bam.bai; Requester Pays project ID is Some(vanallen-firecloud-nih); Attempting to download gs://gdc-tcga-phs000178-controlled/KIRC/DNA/WXS/BI/ILLUMINA/C345.TCGA-A3-3373-11A-01D-1421-08.5.bam.bai to /cromwell_root/dg.4DFC_ab4d57fa-bfff-4a48-bd96-f2866ecfe0e1/C345.TCGA-A3-3373-11A-01D-1421-08.5.bam.bai; Successfully activated service account; Will continue with download. Activated service account credentials for: [kd5mqbpsed8lzz0kyz9tvkht-3274@dcf-prod.iam.gserviceaccount.com]; Download complete!`. C345.TCGA-A3-3373-11A-01D-1421-08.5.bam and C345.TCGA-A3-3373-11A-01D-1421-08.5.bam.bai; were successfully downloaded, but since these TCGA files use DRS URI, they were copied to two separate cromwell folders. /cromwell_root/dg.4DFC_3615e55e-6aa3-43e7-8d7b-6f2824071971/C345.TCGA-A3-3373-11A-01D-1421-08.5.bam; /cromwell_root/dg.4DFC_ab4d57fa-bfff-4a48-bd96-f2866ecfe0e1/C345.TCGA-A3-3373-11A-01D-1421-08.5.bam.bai. And GATK doesn't seem to recognize BAM index when it is not inside a same folder. ; Could you maybe add symlink for the BAM and BAI files in the WDL script? . Tha",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7487:1705,down,download,1705,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7487,1,['down'],['download']
Availability,"----------------------------; ##### ERROR A USER ERROR has occurred (version 3.8-0-ge9d806836): ; ##### ERROR; ##### ERROR This means that one or more arguments or inputs in your command are incorrect.; ##### ERROR The error message below tells you what is the problem.; ##### ERROR; ##### ERROR If the problem is an invalid argument, please check the online documentation guide; ##### ERROR (or rerun your command with --help) to view allowable command-line arguments for this tool.; ##### ERROR; ##### ERROR Visit our website and forum for extensive documentation and answers to ; ##### ERROR commonly asked questions https://software.broadinstitute.org/gatk; ##### ERROR; ##### ERROR Please do NOT post this error to the GATK forum unless you have really tried to fix it yourself.; ##### ERROR; ##### ERROR MESSAGE: Input files reads and reference have incompatible contigs. Please see https://software.broadinstitute.org/gatk/documentation/article?id=63for more information. Error details: No overlapping contigs found.; ##### ERROR reads contigs = [LmjF04_01_20050601_V5.2, LmjF05_01_20050601_V5.2, LmjF24_01_20050601_V5.2, LmjF01_01_20050601_V5.2, LmjF03_01_20050601_V5.2, LmjF13_01_20050601_V5.2, LmjF14_01_20050601_V5.2, LmjF19_01_20050601_V5.2, LmjF21_01_20050601_V5.2, LmjF23_01_20050601_V5.2, LmjF10_01_20050601_V5.2, LmjF11_01_20050601_V5.2, LmjF15_01_20050601_V5.2, LmjF18_01_20050601_V5.2, LmjF02_01_20050601_V5.2, LmjF25_01_20050601_V5.2, LmjF27_01_20050601_V5.2, LmjF28_01_20050601_V5.2, LmjF29_01_20050601_V5.2, LmjF30_01_20050601_V5.2, LmjF31_01_20050601_V5.2, LmjF32_01_20050601_V5.3, LmjF33_01_20050601_V5.2, LmjF34_01_20050601_V5.2, LmjF35_01_20050601_V5.2, LmjF36_01_20050601_V5.2, LmjF07_01_20050601_V5.2, LmjF08_01_20050601_V5.2, LmjF09_01_20050601_V5.2, LmjF06_01_20050601_V5.2, LmjF12_01_20050601_V5.2, LmjF16_01_20050601_V5.2, LmjF17_01_20050601_V5.2, LmjF20_01_20050601_V5.2, LmjF22_01_20050601_V5.2, LmjF26_01_20050601_V5.2]; ##### ERROR reference contigs = [LmjLV39_01, L",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6798:3677,Error,Error,3677,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6798,1,['Error'],['Error']
Availability,"--------------------------; 13:56:52.186 INFO GenotypeGVCFs - ------------------------------------------------------------; 13:56:52.187 INFO GenotypeGVCFs - HTSJDK Version: 2.23.0; 13:56:52.187 INFO GenotypeGVCFs - Picard Version: 2.22.8; 13:56:52.187 INFO GenotypeGVCFs - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 13:56:52.187 INFO GenotypeGVCFs - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 13:56:52.187 INFO GenotypeGVCFs - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 13:56:52.187 INFO GenotypeGVCFs - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 13:56:52.187 INFO GenotypeGVCFs - Deflater: IntelDeflater; 13:56:52.188 INFO GenotypeGVCFs - Inflater: IntelInflater; 13:56:52.188 INFO GenotypeGVCFs - GCS max retries/reopens: 20; 13:56:52.188 INFO GenotypeGVCFs - Requester pays: disabled; 13:56:52.188 INFO GenotypeGVCFs - Initializing engine; 13:56:53.115 INFO GenomicsDBLibLoader - GenomicsDB native library version : 1.3.0-e701905; [TileDB::Buffer] Error: Cannot read from buffer; End of buffer reached.; [TileDB::BookKeeping] Error: Cannot load book-keeping; Reading tile offsets failed.; 13:57:15.762 INFO GenotypeGVCFs - Shutting down engine; [December 21, 2020 1:57:15 PM CST] org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs done. Elapsed time: 0.40 minutes.; Runtime.totalMemory()=2119696384; ***********************************************************************. A USER ERROR has occurred: Couldn't create GenomicsDBFeatureReader. ***********************************************************************; org.broadinstitute.hellbender.exceptions.UserException: Couldn't create GenomicsDBFeatureReader; 	at org.broadinstitute.hellbender.engine.FeatureDataSource.getGenomicsDBFeatureReader(FeatureDataSource.java:410); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.getFeatureReader(FeatureDataSource.java:326); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:282); 	at org.broadinstitute.hellb",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7012:3120,Error,Error,3120,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7012,1,['Error'],['Error']
Availability,"----------------. This was weird since I set a correct index file as an input, but after some investigation, I realized that ; the error seemed to be occurring when the bucket path where BAM index was located was different from that of BAM file ; For example, if you look at this log below, . `Attempting to download gs://gdc-tcga-phs000178-controlled/KIRC/DNA/WXS/BI/ILLUMINA/C345.TCGA-A3-3373-11A-01D-1421-08.5.bam to /cromwell_root/dg.4DFC_3615e55e-6aa3-43e7-8d7b-6f2824071971/C345.TCGA-A3-3373-11A-01D-1421-08.5.bam; Successfully activated service account; Will continue with download. Activated service account credentials for: [kd5mqbpsed8lzz0kyz9tvkht-3274@dcf-prod.iam.gserviceaccount.com]; Download complete!; 2021/09/29 15:46:14 Localizing input drs://dg.4DFC:ab4d57fa-bfff-4a48-bd96-f2866ecfe0e1 -> /cromwell_root/dg.4DFC_ab4d57fa-bfff-4a48-bd96-f2866ecfe0e1/C345.TCGA-A3-3373-11A-01D-1421-08.5.bam.bai; Requester Pays project ID is Some(vanallen-firecloud-nih); Attempting to download gs://gdc-tcga-phs000178-controlled/KIRC/DNA/WXS/BI/ILLUMINA/C345.TCGA-A3-3373-11A-01D-1421-08.5.bam.bai to /cromwell_root/dg.4DFC_ab4d57fa-bfff-4a48-bd96-f2866ecfe0e1/C345.TCGA-A3-3373-11A-01D-1421-08.5.bam.bai; Successfully activated service account; Will continue with download. Activated service account credentials for: [kd5mqbpsed8lzz0kyz9tvkht-3274@dcf-prod.iam.gserviceaccount.com]; Download complete!`. C345.TCGA-A3-3373-11A-01D-1421-08.5.bam and C345.TCGA-A3-3373-11A-01D-1421-08.5.bam.bai; were successfully downloaded, but since these TCGA files use DRS URI, they were copied to two separate cromwell folders. /cromwell_root/dg.4DFC_3615e55e-6aa3-43e7-8d7b-6f2824071971/C345.TCGA-A3-3373-11A-01D-1421-08.5.bam; /cromwell_root/dg.4DFC_ab4d57fa-bfff-4a48-bd96-f2866ecfe0e1/C345.TCGA-A3-3373-11A-01D-1421-08.5.bam.bai. And GATK doesn't seem to recognize BAM index when it is not inside a same folder. ; Could you maybe add symlink for the BAM and BAI files in the WDL script? . Thanks,; Seunghun",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7487:1985,down,download,1985,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7487,3,"['Down', 'down']","['Download', 'download', 'downloaded']"
Availability,"-----------; 20:11:35.530 INFO CombineGVCFs - HTSJDK Version: 2.24.0; 20:11:35.530 INFO CombineGVCFs - Picard Version: 2.25.0; 20:11:35.530 INFO CombineGVCFs - Built for Spark Version: 2.4.5; 20:11:35.530 INFO CombineGVCFs - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 20:11:35.530 INFO CombineGVCFs - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 20:11:35.531 INFO CombineGVCFs - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 20:11:35.531 INFO CombineGVCFs - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 20:11:35.531 INFO CombineGVCFs - Deflater: IntelDeflater; 20:11:35.531 INFO CombineGVCFs - Inflater: IntelInflater; 20:11:35.531 INFO CombineGVCFs - GCS max retries/reopens: 20; 20:11:35.531 INFO CombineGVCFs - Requester pays: disabled; 20:11:35.531 INFO CombineGVCFs - Initializing engine; 20:11:35.957 INFO FeatureManager - Using codec VCFCodec to read file file:///fs/scratch/PHS0338/appz/elprep-v5.0.2/PA113.vcf.gz; 20:11:35.969 INFO CombineGVCFs - Shutting down engine; [June 13, 2021 8:11:35 PM GMT] org.broadinstitute.hellbender.tools.walkers.CombineGVCFs done. Elapsed time: 0.03 minutes.; Runtime.totalMemory()=1772093440; ***********************************************************************; A USER ERROR has occurred: An index is required but was not found for file /fs/scratch/PHS0338/appz/elprep-v5.0.2/PA113.vcf.gz. Support for unindexed block-compressed files has been temporarily disabled. Try running IndexFeatureFile on the input. ***********************************************************************. Set the system property GATK_STACKTRACE_ON_USER_EXCEPTION (--java-options '-DGATK_STACKTRACE_ON_USER_EXCEPTION=true') to print the stack trace.; Using GATK jar /gatk/gatk-package-4.2.0.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /gatk/gatk-package-4.2.0.0-local.jar CombineGVCFs -R /users/PHS0338/jpac",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7311:3587,down,down,3587,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7311,1,['down'],['down']
Availability,"------; 16:46:49.699 INFO Mutect2 - HTSJDK Version: 2.15.1; 16:46:49.699 INFO Mutect2 - Picard Version: 2.18.2; 16:46:49.699 INFO Mutect2 - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 16:46:49.699 INFO Mutect2 - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 16:46:49.700 INFO Mutect2 - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 16:46:49.700 INFO Mutect2 - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 16:46:49.700 INFO Mutect2 - Deflater: IntelDeflater; 16:46:49.700 INFO Mutect2 - Inflater: IntelInflater; 16:46:49.700 INFO Mutect2 - GCS max retries/reopens: 20; 16:46:49.700 INFO Mutect2 - Using google-cloud-java patch 6d11bef1c81f885c26b2b56c8616b7a705171e4f from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 16:46:49.700 INFO Mutect2 - Initializing engine; 16:46:49.995 INFO FeatureManager - Using codec VCFCodec to read file file:///home/vip/data/Mutect2/af-only-gnomad.raw.sites.hg19.vcf.gz; 16:46:50.064 INFO Mutect2 - Shutting down engine; [November 6, 2019 4:46:50 PM CST] org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2 done. Elapsed time: 0.01 minutes.; Runtime.totalMemory()=2394947584; org.broadinstitute.hellbender.exceptions.GATKException: Error initializing feature reader for path /home/vip/data/Mutect2/af-only-gnomad.raw.sites.hg19.vcf.gz; 	at org.broadinstitute.hellbender.engine.FeatureDataSource.getTribbleFeatureReader(FeatureDataSource.java:357); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.getFeatureReader(FeatureDataSource.java:308); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:255); 	at org.broadinstitute.hellbender.engine.FeatureManager.addToFeatureSources(FeatureManager.java:202); 	at org.broadinstitute.hellbender.engine.FeatureManager.initializeFeatureSources(FeatureManager.java:182); 	at org.broadinstitute.hellbender.engine.FeatureManager.<init>(FeatureManager.java:153); 	at org.broadinstitute.hellbender.engine.GATKTool.initializeFeature",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6248:2842,down,down,2842,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6248,1,['down'],['down']
Availability,"----. ## Bug Report. ### Affected tool(s) or class(es); - GATK; - gcnvkernel ; - theano. ### Affected version(s); - GATK 4.1.0.0; - gcnvkernel 0.0.7; - theano 0.9.0; - GCC 7.3.0. ### Description ; I have installed the python package theano(which is a requirement of gcnvkernel) with python 3.6.6 which is compiled with gcc 7.3.0. I am not using the conda environment to install these packages.; Then i tried to run theano-nose, but is giving me the following error:. ```sh. $ theano-nose; --; ; You can find the C code in this temporary file: /tmp/theano_compilation_error_gp0ar1kx; library inux-gnu/7.3.0/crtbeginS.o: is not found.; library inux-gnu/7.3.0/crtbeginS.o: is not found.; library inux-gnu/7.3.0/crtbeginS.o(.text+0x1a): is not found.; library inux-gnu/7.3.0/crtbeginS.o(.text+0x6b): is not found.; Traceback (most recent call last):; File ""${INSTALLDIRGATK}/lib/python3.6/site-packages/theano/gof/lazylinker_c.py"", line 81, in <module>; actual_version, force_compile, _need_reload)); ImportError: Version check of the existing lazylinker compiled file. Looking for version 0.211, but found None. Extra debug information: force_compile=False, _need_reload=True; ; During handling of the above exception, another exception occurred:; ; Traceback (most recent call last):; File ""${INSTALLDIRGATK}/lib/python3.6/site-packages/theano/gof/lazylinker_c.py"", line 105, in <module>; actual_version, force_compile, _need_reload)); ImportError: Version check of the existing lazylinker compiled file. Looking for version 0.211, but found None. Extra debug information: force_compile=False, _need_reload=True; ; During handling of the above exception, another exception occurred:; ; Traceback (most recent call last):; File ""${INSTALLDIRGATK}/bin/theano-nose"", line 11, in <module>; load_entry_point('Theano==1.0.4', 'console_scripts', 'theano-nose')(); File ""${INSTALLDIRGATK}/lib/python3.6/site-packages/bin/theano_nose.py"", line 207, in main; result = main_function(); File ""${INSTALLDIRGATK}/lib/",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5766:459,error,error,459,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5766,1,['error'],['error']
Availability,"----. ## Bug Report. ### Affected tool(s) or class(es); - Tool/class name(s), special parameters: GenomicsDBImport. ### Affected version(s); - Version: gatk4-4.4.0.0-0. ### Description ; Hello,. I have been having an issue come up when utilizing `GenomicsDBImport`. This issue has happened when using a range of samples and shard counts (8 - 1000 samples, shard count of up to 2000). My current example is an attempt to joint call 1000 samples together. I will submit the jobs and 1-2 of the shards (of the ~100 concurrently running) will throw a `malloc(): unaligned tcache chunk detected`. When I resubmit that shard, it will usually rerun without a problem. Or if I kill all jobs and resubmit, a different shard will throw the malloc error. . I have run approximately 20 tests and I seem to get this failure 2/3 times. However, it only arises on the initial submission and not when additional jobs are submitted as previous shards complete. Please note that the 1000 samples have successfully been imported into the GenomicsDB but this error seems to persist somewhat randomly across multiple machines. . Thank you for your assistance! . #### Steps to reproduce. - Command used (omitting paths to 1000 samples for brevity) for one of the failed shards. ```; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx8g -jar /gpfs/gpfs_de6000/home/dalegre/miniconda3/envs/GOASTv4.0/share/gatk4-4.4.0.0-0/gatk-package-4.4.0.0-local.jar GenomicsDBImport -V [samples 1-1002] --genomicsdb-workspace-path results/jointcalling/genomicsDB/temp_0882_of_2000_DB --merge-input-intervals false --bypass-feature-reader --tmp-dir temp --max-num-intervals-to-import-in-parallel 10 --batch-size 50 --intervals results/germline/interval/temp_0882_of_2000/scattered.interval_list --genomicsdb-shared-posixfs-optimizations true; ```. #### Expected behavior; All shards are imported into the GenomicsDB successfu",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8683:737,error,error,737,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8683,2,"['error', 'failure']","['error', 'failure']"
Availability,----. ## Bug Report. ### Affected tool(s) or class(es); GATK LiftoverVcf. ### Affected version(s); gatk/4.1.7.0. ### Description . The LiftoverVcf generates the following error. The error occurs with SVs where the INFO/END is not also lifted over. This results in INFO/END before the site start position which triggers the error.; ```; Using GATK jar /share/pkg.7/gatk/4.1.7.0/install/bin/gatk-package-4.1.7.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /share/pkg.7/gatk/4.1.7.0/install/bin/gatk-package-4.1.7.0-local.jar LiftoverVcf -I b37/HG002_SVs_Tier1_v0.6.vcf.gz -O b38/HG002_SVs_Tier1_v0.6.hg38.vcf.gz -CHAIN grch37_to_grch38.over.chain.gz --REJECT b38/HG002_SVs_Tier1_v0.6.rejected.vcf.gz -R /restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa; 10:20:35.165 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/share/pkg.7/gatk/4.1.7.0/install/bin/gatk-package-4.1.7.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; [Sun Jul 26 10:20:35 EDT 2020] LiftoverVcf --INPUT b37/HG002_SVs_Tier1_v0.6.vcf.gz --OUTPUT b38/HG002_SVs_Tier1_v0.6.hg38.vcf.gz --CHAIN grch37_to_grch38.over.chain.gz --REJECT b38/HG002_SVs_Tier1_v0.6.rejected.vcf.gz --REFERENCE_SEQUENCE /restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa --WARN_ON_MISSING_CONTIG false --LOG_FAILED_INTERVALS true --WRITE_ORIGINAL_POSITION false --WRITE_ORIGINAL_ALLELES false --LIFTOVER_MIN_MATCH 1.0 --ALLOW_MISSING_FIELDS_IN_HEADER false --RECOVER_SWAPPED_REF_ALT false --TAGS_TO_REVERSE AF --TAGS_TO_DROP MAX_AF --DISABLE_SORT false --VERBOSITY INFO --QUIET false --VALIDATION_STRINGENCY STRICT --COMPRESSION_LEVEL 2 --MAX_RECORDS_IN_RAM 500000 --CREATE_INDEX false --CREATE_MD5_FILE false --GA4GH_CLIENT_SECRETS client_secrets.json --help false --version false --showHidden false --USE_JDK_DEFLATER false --USE_JDK_INFLATE,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6725:171,error,error,171,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6725,3,['error'],['error']
Availability,----. ## Bug Report. ### Affected tool(s) or class(es); GenomicsDBImport. ### Affected version(s); - [X] Latest public release version [4.1.9.0]; - [ ] Latest master branch as of [date of test?]. ### Description ; [TileDB::FileSystem] Error: (write_to_file) Cannot write to file; File opening error; path=/storage/home/data/gendb/chr13/.__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/RAW_MQandDP.tdb; errno=122(Disk quota exceede; d); [TileDB::WriteState] Error: Cannot write segment to file.; [TileDB::FileSystem] Error: (write_to_file) Cannot write to file; File opening error; path=/storage/home/data/gendb/chr13/chr13$32310639$32310731/.__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/__book_keeping.tdb.gz; errno=122(Disk quota e; xceeded); [TileDB::utils] Error: (write_to_file_after_compression) Could not write compressed bytes to internal buffer; path=/storage/home/data/gendb/chr13/chr13$32310639$32310731/.__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/__book_keeping.tdb.gz; ; errno=122(Disk quota exceeded); [TileDB::BookKeeping] Error: Cannot finalize book-keeping; Failure to write to file /storage/home/data/gendb/chr13/chr13$32310639$32310731/.__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/__book_keeping.tdb.gz.; [TileDB::FileSystem] Error: (create_file) Failed to create file; path=/storage/home/data/gendb/chr13/chr13$32310639$32310731/__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/__tiledb_fragment.tdb; errno=122(Disk quota exceeded); [TileDB::utils] Error: (create_fragment_file) Failed to create fragment file; path=/storage/home/data/gendb/chr13/chr13$32310639$32310731/__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087; errno=122(Disk quota exceeded); 11:23:52.390 erro NativeGenomicsDB - pid=57964 tid=57984 VariantStorageManagerException exception : Error while finalizing TileDB array chr13$32310639$32310731; TileDB error message : [TileDB::WriteState] ,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6950:235,Error,Error,235,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6950,6,"['Error', 'error']","['Error', 'error']"
Availability,"----. ## Bug Report. ### Affected tool(s) or class(es); gatk CombineGVCFs. ### Affected version(s); - [v4.1.8.1]. ### Description ; When I am using CombineGVCFs to join the two raw_variants.vcf files derived from HaplotypeCaller, it throws an error: KEY END found in VariantContext field INFO at chr1:20094 but this key isn't defined in the VCFHeader. However, when I checked original files, there is no KEY END in INFO. #### Steps to reproduce; The command line I used is:; `~/biosoft/gatk-4.1.8.1/gatk --jave-options ""-Xmx30G"" CombineGVCFs -R ${REF} -V first_raw_variants.vcf -V second_variants.vcf -O cohort.g.vcf.gz`; In which, ${REF} refers to the human reference file. #### Expected behavior; It should return a combined gvcf file. #### Actual behavior; An error happened, as described in above. ----",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7728:243,error,error,243,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7728,2,['error'],['error']
Availability,"----. ## Bug Report; Hi, I'm trying the CNV detection pipeline from GATK: https://gatk.broadinstitute.org/hc/en-us/categories/360002310591; However, when running the Determine Germline Contig Ploidy step, I stumble upon this error. Please guide me to solve this problem. ### Affected tool(s) or class(es); ```; gatk DetermineGermlineContigPloidy \; -L /home/nguyen/RB1/RB1.cohort.gc.filtered.interval_list \; --interval-merging-rule OVERLAPPING_ONLY \; -I ... (63 tsv files output from CollectReadCounts); ```. ### Affected version(s); - GATK 4.1.6.1; ### Description ; Full error log:; ```; Traceback (most recent call last):; File ""/tmp/cohort_determine_ploidy_and_depth.380621677219090732.py"", line 119, in <module>; ploidy_task.engage(); File ""/home/nguyen/anaconda3/envs/gatk/lib/python3.6/site-packages/gcnvkernel/tasks/inference_task_base.py"", line 339, in engage; converged_continuous = self._update_continuous_posteriors(); File ""/home/nguyen/anaconda3/envs/gatk/lib/python3.6/site-packages/gcnvkernel/tasks/inference_task_base.py"", line 395, in _update_continuous_posteriors; assert not np.isnan(loss), ""The optimization step for ELBO update returned a NaN""; AssertionError: The optimization step for ELBO update returned a NaN; 11:09:59.446 DEBUG ScriptExecutor - Result: 1; 11:09:59.447 INFO DetermineGermlineContigPloidy - Shutting down engine; [April 28, 2020 11:09:59 AM ICT] org.broadinstitute.hellbender.tools.copynumber.DetermineGermlineContigPloidy done. Elapsed time: 0.17 minutes.; Runtime.totalMemory()=623902720; org.broadinstitute.hellbender.utils.python.PythonScriptExecutorException: ; python exited with 1; Command Line: python /tmp/cohort_determine_ploidy_and_depth.380621677219090732.py --sample_coverage_metadata=/tmp/samples-by-coverage-per-contig8606344533091962323.tsv --output_calls_path=/home/nguyen/Exec/gatk-4.1.6.0/ploidy-calls --mapping_error_rate=1.000000e-02 --psi_s_scale=1.000000e-04 --mean_bias_sd=1.000000e-02 --psi_j_scale=1.000000e-03 --learning_rate=5.0",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6573:225,error,error,225,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6573,2,['error'],['error']
Availability,"----; User Report; ----. We are also experiencing a problem wherein GATK 4.0.5.1 GenotypeGVCFs processes hang for many hours. . The last thing our processes logged was the same as reported here:; ```; 08:48:23.075 INFO GenotypeGVCFs - Shutting down engine; GENOMICSDB_TIMER,GenomicsDB iterator next() timer,Wall-clock time(s),0.044110324,Cpu time(s),0.026897973000000006; ```. This particular job ran for about 3m before outputting this line, then stayed running (but apparently doing nothing) for 8 hours before we killed it. . It is one of 1996 jobs that all did pretty much exactly the same thing in a similar time frame - in all cases these were the last two lines logged but GATK failed to terminate afterwards. At the same time, we did have about 8k jobs finish successfully and exit 0, so it appears that the rate at which this happens is (at least for our workload) is around 20%. Don't know yet whether or not this behaviour is deterministic. More on that later. . This Issue was generated from your [forums] ; [forums]: https://gatkforums.broadinstitute.org/gatk/discussion/comment/50019#Comment_50019",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4973:244,down,down,244,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4973,1,['down'],['down']
Availability,"-873f-41e8d765644d/call-metrics/transform_pack.cwl#metrics.cwl/2a15d912-9a75-44dc-a723-b9f2dba439b3/call-gatk_collectmultiplemetrics/inputs/-733038737/dbsnp_144.hg38.vcf.gz --TMP_DIR . --REFERENCE_SEQUENCE /cromwell-executions/transform_pack.cwl#main/8f58079f-1b94-40a9-873f-41e8d765644d/call-metrics/transform_pack.cwl#metrics.cwl/2a15d912-9a75-44dc-a723-b9f2dba439b3/call-gatk_collectmultiplemetrics/inputs/-733038737/GRCh38.d1.vd1.fa --ASSUME_SORTED true --STOP_AFTER 0 --INCLUDE_UNPAIRED false --VERBOSITY INFO --QUIET false --VALIDATION_STRINGENCY STRICT --COMPRESSION_LEVEL 2 --MAX_RECORDS_IN_RAM 500000 --CREATE_INDEX false --CREATE_MD5_FILE false --GA4GH_CLIENT_SECRETS client_secrets.json --help false --version false --showHidden false --USE_JDK_DEFLATER false --USE_JDK_INFLATER false; [Thu May 09 20:20:00 UTC 2019] Executing as root@6b3fc2da5b97 on Linux 4.15.0-48-generic amd64; OpenJDK 64-Bit Server VM 1.8.0_191-8u191-b12-2ubuntu0.18.04.1-b12; Deflater: Intel; Inflater: Intel; Provider GCS is available; Picard version: Version:4.1.2.0; WARNING 2019-05-09 20:20:00 CollectMultipleMetrics The CollectBaseDistributionByCycle program does not support a metric accumulation level, but METRIC_ACCUMULATION_LEVEL was overridden in the command line. CollectBaseDistributionByCycle will be run against the entire input.; WARNING 2019-05-09 20:20:00 CollectMultipleMetrics The MeanQualityByCycle program does not support a metric accumulation level, but METRIC_ACCUMULATION_LEVEL was overridden in the command line. MeanQualityByCycle will be run against the entire input.; WARNING 2019-05-09 20:20:00 CollectMultipleMetrics The QualityScoreDistribution program does not support a metric accumulation level, but METRIC_ACCUMULATION_LEVEL was overridden in the command line. QualityScoreDistribution will be run against the entire input.; WARNING 2019-05-09 20:20:00 CollectMultipleMetrics The CollectQualityYieldMetrics program does not support a metric accumulation level, but METRIC_ACCUMUL",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5931:3647,avail,available,3647,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5931,1,['avail'],['available']
Availability,"-Created a new class of tool, IntervalWalker, that processes a single interval at a time,; with the ability to query optional overlapping sources of reads, reference data, and/or; features/variants. Current implementation is simple/naive with no special caching;; performance issues will be addressed once we port this traversal type to dataflow. -Added the ability for VariantWalkers to access contextual reads/reference/feature data. -To enable the above changes, migrated most of the engine to use SimpleIntervals rather; than GenomeLocs. This allows for the creation of Context objects in traversals where there; is not necessarily a sequence dictionary available (eg., VariantWalker). -Moved shared arguments/code from Walker classes up into GATKTool. Still some issues; related to marking engine-wide arguments as optional/required on a per-traversal or; per-tool basis, but tickets have been created for these. -Since there isn't yet an htsjdk release that contains SimpleInterval, temporarily; checked a copy of it into our repo, which we can remove the next time we; rev htsjdk. TODOs:. -We currently still require a sequence dictionary to actually parse intervals in; IntervalArgumentCollection. This is due entirely to our support of intervals without; specific stop positions (eg., ""chr1"" and ""chr1:1+"") -- for these intervals we must; look up the stop position in a sequence dictionary. This means that IntervalWalkers; currently require at least one input that contains a sequence dictionary (although; VariantWalkers do not). We should look into ways of relaxing this restriction. Resolves #109",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/297:658,avail,available,658,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/297,1,['avail'],['available']
Availability,"-DRB1*15:01:01:04 (11056 bp); 16:16:37.524 DEBUG GenomeLocParser - HLA-DRB1*15:02:01 (10313 bp); 16:16:37.524 DEBUG GenomeLocParser - HLA-DRB1*15:03:01:01 (11567 bp); 16:16:37.524 DEBUG GenomeLocParser - HLA-DRB1*15:03:01:02 (11569 bp); 16:16:37.524 DEBUG GenomeLocParser - HLA-DRB1*16:02:01 (11005 bp); 16:16:37.546 INFO IntervalArgumentCollection - Processing 28770581 bp from intervals; 16:16:37.548 INFO GenomicsDBImport - Done initializing engine; 16:16:37.548 INFO GenomicsDBImport - Callset Map JSON file will be re-written to /rooted3/langley/work/home/chuck/rad/SFARI/SSC_hg38/WGS/CPRs_100_proto/DB_chr1/callset.json; 16:16:37.548 INFO GenomicsDBImport - Incrementally importing to array - /rooted3/langley/work/home/chuck/rad/SFARI/SSC_hg38/WGS/CPRs_100_proto/DB_chr1/genomicsdb_array; 16:16:37.549 INFO ProgressMeter - Starting traversal; 16:16:37.550 INFO ProgressMeter - Current Locus Elapsed Minutes Batches Processed Batches/Minute; 16:16:38.061 INFO GenomicsDBImport - Shutting down engine; [August 28, 2020 4:16:38 PM PDT] org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImport done. Elapsed time: 0.04 minutes.; Runtime.totalMemory()=16464216064; org.genomicsdb.exception.GenomicsDBException: Duplicate sample name found: SSC00007. Sample was originally in /rooted3/langley/work/home/chuck/rad/SFARI/SSC_hg38/WGS/phase2_CPRs/SSC00007_CPR/SSC00007.haplotypeCalls.CPR.er.raw.vcf.gz; at org.genomicsdb.importer.extensions.CallSetMapExtensions.checkDuplicateCallsetsForIncrementalImport(CallSetMapExtensions.java:270); at org.genomicsdb.importer.extensions.CallSetMapExtensions.mergeCallsetsForIncrementalImport(CallSetMapExtensions.java:241); at org.genomicsdb.importer.GenomicsDBImporter.<init>(GenomicsDBImporter.java:222); at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImport.traverse(GenomicsDBImport.java:743); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1048); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(Co",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6793:8122,down,down,8122,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6793,1,['down'],['down']
Availability,"-Dsamjdk.use\_async\_io\_read\_samtools=false -Dsamjdk.use\_async\_io\_write\_samtools=true -Dsamjdk.use\_async\_io\_write\_tribble=false -Dsamjdk.compression\_level=2 -Djava.io.tmpdir=/tmp -Xmx3g -jar /home/gvandeweyer/miniconda3/envs/ELPREP/share/gatk4-4.2.5.0-0/gatk-packa ; ; ge-4.2.5.0-local.jar HaplotypeCaller -R /home/gvandeweyer/elprep\_streaming/reference/hg19.fasta -I /home/gvandeweyer/elprep\_streaming/results/wesep-229191-f.bam -O results/wesep-229191-f.vcf --alleles ../wesid-226998-m.haplotypecaller.final.vcf.gz -L 0005-scattered.inter ; ; val\_list -bamout results/wesep-229191-f.variants.bam -G StandardAnnotation -G StandardHCAnnotation --dragen-mode --dragstr-params-path /home/gvandeweyer/elprep\_streaming/results/wesep-229191-f.bam.params ; ; 22:06:39.332 WARN  GATKAnnotationPluginDescriptor - Redundant enabled annotation group (StandardAnnotation) is enabled for this tool by default ; ; 22:06:39.337 WARN  GATKAnnotationPluginDescriptor - Redundant enabled annotation group (StandardHCAnnotation) is enabled for this tool by default ; ; 22:06:39.383 INFO  NativeLibraryLoader - Loading libgkl\_compression.so from jar:file:/home/gvandeweyer/miniconda3/envs/ELPREP/share/gatk4-4.2.5.0-0/gatk-package-4.2.5.0-local.jar!/com/intel/gkl/native/libgkl\_compression.so ; ; Mar 12, 2022 10:06:39 PM shaded.cloud\_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine ; ; INFO: Failed to detect whether we are running on Google Compute Engine. ; ; 22:06:39.543 INFO  HaplotypeCaller - ------------------------------------------------------------ ; ; 22:06:39.543 INFO  HaplotypeCaller - The Genome Analysis Toolkit (GATK) v4.2.5.0 ; ; 22:06:39.543 INFO  HaplotypeCaller - For support and documentation go to [https://software.broadinstitute.org/gatk/](https://software.broadinstitute.org/gatk/) ; ; 22:06:39.543 INFO  HaplotypeCaller - Executing as [gvandeweyer@ngsvm-pipelines.uza.be](mailto:gvandeweyer@ngsvm-pipelines.uza.be) on Linux v4.4.0-210-generic am",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7741:4281,Redundant,Redundant,4281,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7741,1,['Redundant'],['Redundant']
Availability,"-SORTING_COLLECTION_SIZE_RATIO 0.25 --TAG_DUPLICATE_SET_MEMBERS false --REMOVE_SEQUENCING_DUPLICATES false --TAGGING_POLICY DontTag --CLEAR_DT true --DUPLEX_UMI false --ADD_PG_TAG_TO_READS true --ASSUME_SORTED false --DUPLICATE_SCORING_STRATEGY SUM_OF_BASE_QUALITIES --PROGRAM_RECORD_ID MarkDuplicates --PROGRAM_GROUP_NAME MarkDuplicates --READ_NAME_REGEX <optimized capture of last three ':' separated fields as numeric values> --OPTICAL_DUPLICATE_PIXEL_DISTANCE 100 --MAX_OPTICAL_DUPLICATE_SET_SIZE 300000 --VERBOSITY INFO --QUIET false --COMPRESSION_LEVEL 2 --MAX_RECORDS_IN_RAM 500000 --CREATE_INDEX false --CREATE_MD5_FILE false --GA4GH_CLIENT_SECRETS client_secrets.json --help false --version false --showHidden false --USE_JDK_DEFLATER false --USE_JDK_INFLATER false; Sep 14, 2023 1:41:23 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; [Thu Sep 14 01:41:23 PDT 2023] Executing as ionadmin@proton-torrent-server on Linux 2.6.32-21-server amd64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_201-b09; Deflater: Intel; Inflater: Intel; Provider GCS is available; Picard version: Version:4.1.2.0; INFO 2023-09-14 01:41:23 MarkDuplicates Start of doWork freeMemory: 2396610552; totalMemory: 2423259136; maxMemory: 61084270592; INFO 2023-09-14 01:41:23 MarkDuplicates Reading input file and constructing read end information.; INFO 2023-09-14 01:41:23 MarkDuplicates Will retain up to 221319820 data points before spilling to disk. ### Affected version(s); gatk 4.1.2.0. ### Description ; the output information is just stopped at ""INFO 2023-09-14 01:41:23 MarkDuplicates Will retain up to 221319820 data points before spilling to disk."", it should runs more information out. and there is no output for the rmdup bam. #### Expected behavior; it should finish it running and output the result. ## Feature request. ### Tool(s) or class(es) involved; JAVA_HOME = /usr/lib/jvm/jdk1.8.0_201/",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8520:2708,avail,available,2708,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8520,1,['avail'],['available']
Availability,"-b12) (build 1.8.0_151-b12); # Java VM: OpenJDK 64-Bit Server VM (25.151-b12 mixed mode linux-amd64 compressed oops); # Derivative: IcedTea 3.6.0; # Distribution: Custom build (Tue Nov 21 11:22:36 GMT 2017); # Problematic frame:; # C [libgomp.so.1+0x7fab] omp_get_max_threads+0xb; #; # Failed to write core dump. Core dumps have been disabled. To enable core dumping, try ""ulimit -c unlimited"" before starting Java again; #; # An error report file with more information is saved as:; # /beegfs/work/iiipe01/Exome-Test/work/1e/fc972c6b14c8006857230849630a49/hs_err_pid85482.log; #; # If you would like to submit a bug report, please include; # instructions on how to reproduce the bug and visit:; # http://icedtea.classpath.org/bugzilla; # The crash happened outside the Java Virtual Machine in native code.; # See problematic frame for where to report the bug.; #. ``` . Here's the `hs_err` file:. ```; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x00002b5f92e39fab, pid=85482, tid=0x00002b5f56e60ae8; #; # JRE version: OpenJDK Runtime Environment (8.0_151-b12) (build 1.8.0_151-b12); # Java VM: OpenJDK 64-Bit Server VM (25.151-b12 mixed mode linux-amd64 compressed oops); # Derivative: IcedTea 3.6.0; # Distribution: Custom build (Tue Nov 21 11:22:36 GMT 2017); # Problematic frame:; # C [libgomp.so.1+0x7fab] omp_get_max_threads+0xb; #; # Failed to write core dump. Core dumps have been disabled. To enable core dumping, try ""ulimit -c unlimited"" before starting Java again; #; # If you would like to submit a bug report, please include; # instructions on how to reproduce the bug and visit:; # http://icedtea.classpath.org/bugzilla; # The crash happened outside the Java Virtual Machine in native code.; # See problematic frame for where to report the bug.; #. --------------- T H R E A D ---------------. Current thread (0x00005648765c2000): JavaThread ""main"" [_thread_in_native, id=85483, stack(0x00002b5f56d60000,0x00002b5f56e60aa8)]. siginf",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4158:4933,error,error,4933,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4158,1,['error'],['error']
Availability,"-b12); OpenJDK 64-Bit Server VM (build 25.152-b12, mixed mode); ```. ### Description ; keep get the error message like below. ```; Using GATK jar /cache/home/xc278/p/GATK/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Dsamjdk.compression_level=5 -Xms10G -jar /cache/home/xc278/p/GATK/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar HaplotypeCallerSpark -R GRCh38_full_analysis_set_plus_decoy_hla.fa -I SRR1573206.GatherBamFiles.bam -O SRR1573206.g.vcf.gz -G StandardAnnotation -G StandardHCAnnotation -G AS_StandardAnnotation -GQB 10 -GQB 20 -GQB 30 -GQB 40 -GQB 50 -GQB 60 -GQB 70 -GQB 80 -GQB 90 -ERC GVCF; 09:38:05.617 WARN GATKAnnotationPluginDescriptor - Redundant enabled annotation group (StandardAnnotation) is enabled for this tool by default; 09:38:05.617 WARN GATKAnnotationPluginDescriptor - Redundant enabled annotation group (StandardHCAnnotation) is enabled for this tool by default; 09:38:05.655 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/cache/home/xc278/p/GATK/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Aug 15, 2020 9:38:05 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 09:38:05.911 INFO HaplotypeCallerSpark - ------------------------------------------------------------; 09:38:05.912 INFO HaplotypeCallerSpark - The Genome Analysis Toolkit (GATK) v4.1.8.1; 09:38:05.912 INFO HaplotypeCallerSpark - For support and documentation go to https://software.broadinstitute.org/gatk/; 09:38:05.912 INFO HaplotypeCallerSpark - Executing as xc278@amarel2.amarel.rutgers.edu on Linux v3.10.0-1062.9.1.el7.x86_64 amd64; 09:38:05.912 INFO HaplotypeCallerSpark - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_232-b09; 09:38:05.913 INF",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6750:1482,Redundant,Redundant,1482,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6750,1,['Redundant'],['Redundant']
Availability,-biology/gatk-9999/work/gatk-9999/build.gradle:143); 22:05:55.985 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.groovy.scripts.internal.DefaultScriptRunnerFactory$ScriptRunnerImpl.run(DefaultScriptRunnerFactory.java:90); 22:05:55.986 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	... 58 more; 22:05:55.986 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] ; 22:05:55.986 [LIFECYCLE] [org.gradle.internal.buildevents.BuildResultLogger] ; 22:05:55.986 [LIFECYCLE] [org.gradle.internal.buildevents.BuildResultLogger] BUILD FAILED; 22:05:55.986 [LIFECYCLE] [org.gradle.internal.buildevents.BuildResultLogger] ; 22:05:55.987 [LIFECYCLE] [org.gradle.internal.buildevents.BuildResultLogger] Total time: 29.153 secs; ```. ```; root# su - portage; portage$ cd /scratch/var/tmp/portage/sci-biology/gatk-9999/work/gatk-9999/; portage$ git lfs pull --include src/main/resources/large; No default remote. Errors logged to /scratch/var/tmp/portage/sci-biology/gatk-9999/work/gatk-9999/.git/lfs/objects/logs/20180420T221032.955218097.log; Use `git lfs logs last` to view the log.; portage$ cat /scratch/var/tmp/portage/sci-biology/gatk-9999/work/gatk-9999/.git/lfs/objects/logs/20180420T221032.955218097.log; git-lfs/2.3.4 (GitHub; linux amd64; go 1.10); git version 2.16.3. $ git-lfs pull --include src/main/resources/large; No default remote. No remotes defined. Current time in UTC: ; 2018-04-20 20:10:32. ENV:; LocalWorkingDir=/scratch/var/tmp/portage/sci-biology/gatk-9999/work/gatk-9999; LocalGitDir=/scratch/var/tmp/portage/sci-biology/gatk-9999/work/gatk-9999/.git; LocalGitStorageDir=/scratch/var/tmp/portage/sci-biology/gatk-9999/work/gatk-9999/.git; LocalMediaDir=/scratch/var/tmp/portage/sci-biology/gatk-9999/work/gatk-9999/.git/lfs/objects; LocalReferenceDir=; TempDir=/scratch/var/tmp/portage/sci-biology/gatk-9999/work/gatk-9999/.git/lfs/tmp; ConcurrentTransfers=3; TusTransfers=false; BasicTransfersOnly=false; SkipDownloadErrors=,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4687:15031,Error,Errors,15031,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4687,1,['Error'],['Errors']
Availability,"-disable_sampler=false --disable_annealing=false --interval_list=/tmp/die9s/intervals671187352630642175.tsv --contig_ploidy_prior_table=/media/Berechnungen/CNV_analysis/GATK4/ploidy_priors.tsv --output_model_path=/media/Berechnungen/CNV_analysis/GATK4/normal_cohort-model; Stdout:; Stderr: File ""/tmp/die9s/cohort_determine_ploidy_and_depth.9149389425697869853.py"", line 84; sample_metadata_collection: gcnvkernel.SampleMetadataCollection = gcnvkernel.SampleMetadataCollection(); ^; SyntaxError: invalid syntax. at org.broadinstitute.hellbender.utils.python.PythonExecutorBase.getScriptException(PythonExecutorBase.java:75); at org.broadinstitute.hellbender.utils.runtime.ScriptExecutor.executeCuratedArgs(ScriptExecutor.java:126); at org.broadinstitute.hellbender.utils.python.PythonScriptExecutor.executeArgs(PythonScriptExecutor.java:170); at org.broadinstitute.hellbender.utils.python.PythonScriptExecutor.executeScript(PythonScriptExecutor.java:151); at org.broadinstitute.hellbender.utils.python.PythonScriptExecutor.executeScript(PythonScriptExecutor.java:121); at org.broadinstitute.hellbender.tools.copynumber.DetermineGermlineContigPloidy.executeDeterminePloidyAndDepthPythonScript(DetermineGermlineContigPloidy.java:316); at org.broadinstitute.hellbender.tools.copynumber.DetermineGermlineContigPloidy.doWork(DetermineGermlineContigPloidy.java:215); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:136); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:179); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:198); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:152); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:195); at org.broadinstitute.hellbender.Main.main(Main.java:275); ```. Have you seen an error like this before? Do you have an idea where it is coming from?. Thanks a lot in advance; Stefan",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4125:3650,error,error,3650,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4125,1,['error'],['error']
Availability,"-dont-trim-active-regions true`:. ```; chr11 6411935 rs3838786 TGCTGGC CGCTGGC,T,<NON_REF> 4029.06 . DB;DP=118;ExcessHet=3.0103;MLEAC=1,1,0;MLEAF=0.500,0.500,0.00;RAW_MQandDP=424800,118;REF_BASES=ATGGGCCTGGTGCTGGCGCTG GT:AD:DP:F1R2:F2R1:GQ:PL:SB 1/2:0,62,40,0:102:0,31,23,0:0,31,17,0:99:4046,1646,1982,2435,0,2437,4113,1933,2560,4431:0,0,54,48; ```. and the second one didn't:. ```; chr11 6411935 rs3838786 TGCTGGC T,CGCTGGC,<NON_REF> 2308.64 . BaseQRankSum=-1.312;ClippingRankSum=0.877;DB;DP=119;ExcessHet=3.0103;MLEAC=0,1,0;MLEAF=0.00,0.500,0.00;MQRankSum=0.000;RAW_MQandDP=428400,119;REF_BASES=ATGGGCCTGGTGCTGGCGCTG;ReadPosRankSum=0.255 GT:AD:DP:F1R2:F2R1:GQ:PL:SB 0/2:7,0,65,0:72:1,0,34,0:6,0,31,0:99:2316,2364,2996,0,269,1897,2506,2977,1274,3798:1,6,34,31; ```. Note how in the second case, there are two alts in the gVCF, but only one of them has depth!. The only way to recover these cases is to run with `--dont-trim-active-regions`, but that make the HC run approximately 5 times slower, which is obviously not ideal. What I'd like to suggest is that the HC have some automated way to detect when this kind of error is likely to happen or has happened, and work around it. My suggestion(s) would be:. 1. I _think_ this really only happens in repetitive regions. I wonder if it would be possible to have the HC automatically trim active regions when assembly at kmer size 10 works, and disable it when it has to escalate to a higher kmer size? . 2. Trim the active region, but retain the untrimmed active region also. Genotype using the trimmed region. If any allele receives count=0, re-genotype using the untrimmed regions. My thought here is that I think not trimming the active regions really only makes a difference at a small fraction of sites, on the order of 1/1000, but to rescue those sites we have to pay a 5x performance penalty at every site. It would be great if trimming could be auto-disabled at only those sites that are problematic, so we could have our cake and eat it too.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5791:2174,error,error,2174,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5791,1,['error'],['error']
Availability,"-imr OVERLAPPING\_ONLY \\ ; ; \--contig-ploidy-calls ploidy-calls \\ ; ; \--annotated-intervals Twist\_Exome\_Target\_hg38\_preprocessed\_annotated.interval\_list \\ ; ; \-I 13-20.counts.hd5 \\ ; ; \-I 722.counts.hd5 \\ ; ; \-I D19047.counts.hd5 \\ ; ; \-I F24F1.counts.hd5 \\ ; ; \-I NS.counts.hd5 \\ ; ; \-I TBC039.counts.hd5 \\ ; ; \-I VP.counts.hd5 \\ ; ; \-I WES002.counts.hd5 \\ ; ; \-I WES02.counts.hd5 \\ ; ; \-I 17062-T1-.counts.hd5 \\ ; ; \-I 18001-M1-.counts.hd5 \\ ; ; \-I 516.counts.hd5 \\ ; ; \-I 533.counts.hd5 \\ ; ; \-I NBH.counts.hd5 \\ ; ; \-I ADN492.counts.hd5 \\ ; ; \-I WES607.counts.hd5 \\ ; ; \--class-coherence-length 1000.0 \\ ; ; \--cnv-coherence-length 1000.0 \\ ; ; \--enable-bias-factors true \\ ; ; \--interval-psi-scale 1.0E-6 \\ ; ; \--log-mean-bias-standard-deviation 0.01 \\ ; ; \--sample-psi-scale 1.0E-6 \\ ; ; \--output cohort16 \\ ; ; \--output-prefix cohort16 \\ ; ; \--verbosity DEBUG \\ ; ; \--java-options '-DGATK\_STACKTRACE\_ON\_USER\_EXCEPTION=true'. Error:. java.lang.IllegalArgumentException: Prefix string ""NS"" too short: length must be at least 3 ; ; at java.base/java.io.File.createTempFile(File.java:2104) ; ; at org.broadinstitute.hellbender.utils.io.IOUtils.createTempFileInDirectory(IOUtils.java:685) ; ; at org.broadinstitute.hellbender.utils.io.IOUtils.createTempFile(IOUtils.java:666) ; ; at org.broadinstitute.hellbender.tools.copynumber.GermlineCNVCaller.lambda$writeIntervalSubsetReadCountFiles$1(GermlineCNVCaller.java:430) ; ; at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183) ; ; at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195) ; ; at java.base/java.util.stream.IntPipeline$1$1.accept(IntPipeline.java:180) ; ; at java.base/java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:104) ; ; at java.base/java.util.Spliterator$OfInt.forEachRemaining(Spliterator.java:699) ; ; at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeli",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7591:2289,Error,Error,2289,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7591,1,['Error'],['Error']
Availability,-jdk-deflater true -R ref.rename.fa -V test.vcf.gz -O test_geno.vcf.gz. ### Error log 1. 21:12:43.028 INFO GenotypeGVCFs - Shutting down engine; [2021年12月20日 下午09时12分43秒] org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs done. Elapsed time: 6.12 minutes.; Runtime.totalMemory()=4856479744; htsjdk.samtools.SAMFormatException: Did not inflate expected amount; 	at htsjdk.samtools.util.BlockGunzipper.unzipBlock(BlockGunzipper.java:147); 	at htsjdk.samtools.util.BlockGunzipper.unzipBlock(BlockGunzipper.java:96); 	at htsjdk.samtools.util.BlockCompressedInputStream.inflateBlock(BlockCompressedInputStream.java:550); 	at htsjdk.samtools.util.BlockCompressedInputStream.processNextBlock(BlockCompressedInputStream.java:532); 	at htsjdk.samtools.util.BlockCompressedInputStream.nextBlock(BlockCompressedInputStream.java:468); 	at htsjdk.samtools.util.BlockCompressedInputStream.readBlock(BlockCompressedInputStream.java:458); 	at htsjdk.samtools.util.BlockCompressedInputStream.available(BlockCompressedInputStream.java:196); 	at htsjdk.samtools.util.BlockCompressedInputStream.read(BlockCompressedInputStream.java:331); 	at htsjdk.samtools.util.BlockCompressedInputStream.read(BlockCompressedInputStream.java:257); 	at htsjdk.tribble.readers.PositionalBufferedStream.fill(PositionalBufferedStream.java:132); 	at htsjdk.tribble.readers.PositionalBufferedStream.read(PositionalBufferedStream.java:84); 	at sun.nio.cs.StreamDecoder.readBytes(StreamDecoder.java:284); 	at sun.nio.cs.StreamDecoder.implRead(StreamDecoder.java:326); 	at sun.nio.cs.StreamDecoder.read(StreamDecoder.java:178); 	at java.io.InputStreamReader.read(InputStreamReader.java:184); 	at htsjdk.tribble.readers.LongLineBufferedReader.fill(LongLineBufferedReader.java:140); 	at htsjdk.tribble.readers.LongLineBufferedReader.readLine(LongLineBufferedReader.java:300); 	at htsjdk.tribble.readers.LongLineBufferedReader.readLine(LongLineBufferedReader.java:356); 	at htsjdk.tribble.readers.SynchronousLineReader.readLine(SynchronousLi,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7614:1671,avail,available,1671,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7614,1,['avail'],['available']
Availability,-new-qual error issue,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5000:10,error,error,10,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5000,1,['error'],['error']
Availability,"-seqr-main-analysis/seqr_loader/v0/genomicsdbs/interval_0_outof_50/callset.json; 14:26:53.640 INFO GenomicsDBImport - Complete VCF Header will be written to gs://cpg-seqr-main-analysis/seqr_loader/v0/genomicsdbs/interval_0_outof_50/vcfheader.vcf; 14:26:53.640 INFO GenomicsDBImport - Importing to workspace - gs://cpg-seqr-main-analysis/seqr_loader/v0/genomicsdbs/interval_0_outof_50; 14:26:56.113 INFO GenomicsDBImport - Starting batch input file preload; 14:26:57.968 INFO GenomicsDBImport - Finished batch preload; 14:26:57.968 INFO GenomicsDBImport - Importing batch 1 with 50 samples; 15:59:12.833 INFO GenomicsDBImport - Done importing batch 5/6; 15:59:12.833 INFO GenomicsDBImport - Starting batch input file preload; 15:59:13.218 INFO GenomicsDBImport - Finished batch preload; 15:59:13.218 INFO GenomicsDBImport - Importing batch 6 with 14 samples; [TileDB::FileSystem] Error: (write_to_file) GCS: Only the last of the uploadable parts can be less than 5MB, try increasing TILEDB_UPLOAD_BUFFER_SIZE to at least 5MB path=seqr_loader/v0/genomicsdbs/interval_0_outof_50/chr1$1$61698845/__64761969-0f52-4be1-a7c5-264d6dd36465140686419941120_1643299495929/__book_keeping.tdb.gz; [TileDB::StorageBuffer] Error: (gzip_write_buffer) Cannot write bytes path=seqr_loader/v0/genomicsdbs/interval_0_outof_50/chr1$1$61698845/__64761969-0f52-4be1-a7c5-264d6dd36465140686419941120_1643299495929/__book_keeping.tdb.gz; [TileDB::StorageBuffer] Error: (write_buffer) Cannot compress and/or write bytes path=seqr_loader/v0/genomicsdbs/interval_0_outof_50/chr1$1$61698845/__64761969-0f52-4be1-a7c5-264d6dd36465140686419941120_1643299495929/__book_keeping.tdb.gz; 16:39:59.490 INFO GenomicsDBImport - Done importing batch 6/6; 16:40:00.293 INFO GenomicsDBImport - Import of all batches to GenomicsDB completed!; 16:40:00.293 INFO GenomicsDBImport - Shutting down engine; [January 27, 2022 at 4:40:00 PM UTC] org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImport done. Elapsed time: 133.15 minutes.; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7653:6139,Error,Error,6139,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7653,3,"['Error', 'down']","['Error', 'down']"
Availability,"-us/community/posts/360072644931-Combine-GVCF-generate-java-lang-NullPointerException. Command:; time ""$gatk"" CombineGVCFs \; -G StandardAnnotation \; -G AS_StandardAnnotation \; -R ""$ref_gen""/ucsc.hg19.fasta \; -V /paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/A200272.HC.g.vcf.gz \; -V /paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/A200273.HC.g.vcf.gz \; -V /paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/A200274.HC.g.vcf.gz \; -V /paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/A200313.HC.g.vcf.gz \; -V /paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/A200314.HC.g.vcf.gz \; -V /paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/A200315.HC.g.vcf.gz \; -V /paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/PID20-006.HC.g.vcf.gz \; -V /paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/PID20-007.HC.g.vcf.gz \; -V /paedwy/disk1/yangyxt/wes/backup_gvcfs/all_wes_samples.g.vcf \; -O /paedwy/disk1/yangyxt/wes/backup_gvcfs/all_wes_samples_plus_${sample_batch}.g.vcf.gz && echo ""Combine_gvcfs done"". Error Log:; ```; 12:01:36.798 WARN GATKAnnotationPluginDescriptor - Redundant enabled annotation group (StandardAnnotation) is enabled for this tool by default; 12:01:36.824 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/yangyxt/software/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Aug 24, 2020 12:01:37 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 12:01:37.108 INFO CombineGVCFs - ------------------------------------------------------------; 12:01:37.108 INFO CombineGVCFs - The Genome Analysis Toolkit (GATK) v4.1.8.1; 12:01:37.108 INFO CombineGVCFs - For support and documentation go to https://software.broadinstitute.org/gatk/; 12:01:37.108 INFO CombineGVCFs - Executing as yangyxt@paedyl01 on Linux v3.10.0-1062.18.1.el7.x86_64 amd64; 12:01:37.108 INFO CombineGVCFs - Java runtime:",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6766:1475,echo,echo,1475,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6766,1,['echo'],['echo']
Availability,". As @pdexheimer pointed out: . > I think the bug here is in HaplotypeCaller. It technically generated a malformed (g)VCF by using an ambiguous allele for the reference. I don't know what the fix is, though. You can't have an ActiveRegionWalker skip over the ambiguous bases since it operates on a whole region. And a post hoc check in HC would be simple enough for SNVs, but what happens when the ambiguous site is part of a larger deletion?. Needs advice on what the behavior / solution should be by @akiezun @vruano . This Issue was generated from your [forums](http://gatkforums.broadinstitute.org/discussion/4858/reference-bases-with-ambiguity-codes-in-dbsnp/p1) . ---. @vruano commented on [Mon Mar 23 2015](https://github.com/broadinstitute/gsa-unstable/issues/829#issuecomment-85093784). In general, don't know how HC behaves with ambiguous reference bases at all.... I would not be surprised if it just crashes or outputs garbage. Perhaps this should be part of a larger effort to make sure HC, Combine- and GenotypeGVCFs are robust on ambiguous calls. To start, currently GATK/Picard handles bases as uppercase single `byte' representation of the corresponding character. Since we are investing (a mostly wasting) 8 bits already, we could change into a bit mask representation that would allow for quick comparison of ambiguous and non-ambigous base call using bit-wise operations. NO_CALL = 0, A = 1, C = 2, G = 4, T/U = 8, N = 15, etc... . Handling ambiguous reference base calls... IMO the easiest and clearest is to disambiguate using a standard alphabetical priority, A, C, G or T whichever is the first compatible base is the reference. Then we just generate non-ambigous output accordingly to this choice. . We can provide separate tools to re-ambiguate the output or reselect the reference allele as the population major allele, so making the user very aware of this. For example he/she should have an decision-making input as to how we are supposed to handle het calls where both a",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2914:1237,robust,robust,1237,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2914,1,['robust'],['robust']
Availability,". Out of curiosity, we tried building the docker again without samtools, so in theory, the only possible change is that when each docker is built, apt update is run. The differences are small, but is that expected? That with and without samtools, and if `apt` packages change, mutect2 could be influenced?. #### Steps to reproduce; _Tell us how to reproduce this issue. If possible, include command lines that reproduce the problem. (The support team may follow up to ask you to upload data to reproduce the issue.)_; I can't replicate scenario 1 in the table because it was built in 2019, so apt packages were different then.; Scenario 2 dockerPull: `docker pull kfdrc/gatk:4.1.1.0`; Scenario 3 dockerPull: `docker pull pgc-images.sbgenomics.com/d3b-bixu/gatk:4.1.1.0`; Scenario 4 dockerPull: `docker pull migbro/gatk:4.1.1.0L`. No samtools Dockerfile:; ```; FROM ubuntu:18.04; LABEL maintainer=""Miguel Brown (brownm28@email.chop.edu)"". ENV GATK4_VERSION 4.1.1.0. RUN apt update && apt install -y openjdk-8-jdk python wget unzip libgomp1; \; wget -q https://github.com/broadinstitute/gatk/releases/download/${GATK4_VERSION}/gatk-${GATK4_VERSION}.zip; \; unzip gatk-${GATK4_VERSION}.zip; \; mv gatk-${GATK4_VERSION}/gatk* . && rm -rf gatk-${GATK4_VERSION}*; \; apt remove -y wget; ```. Yes samtools Dockerfile:; ```; FROM ubuntu:18.04; LABEL maintainer=""Miguel Brown (brownm28@email.chop.edu)"". ENV GATK4_VERSION 4.1.1.0. RUN apt update && apt install -y openjdk-8-jdk python wget unzip libgomp1 tabix samtools; \; wget -q https://github.com/broadinstitute/gatk/releases/download/${GATK4_VERSION}/gatk-${GATK4_VERSION}.zip; \; unzip gatk-${GATK4_VERSION}.zip; \; mv gatk-${GATK4_VERSION}/gatk* . && rm -rf gatk-${GATK4_VERSION}*; \; apt remove -y wget; ```. #### Expected behavior; _Tell us what should happen_; All `PASS` var counts are the same; #### Actual behavior; _Tell us what happens instead_; `PASS` var counts vary slightly +/- samtools and year docker built; ----; Thank you for your time!",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7269:2014,down,download,2014,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7269,2,['down'],['download']
Availability,"...and test, naturally. Issue #3735 reports that transient errors can cause the auth server to return ""403 Forbidden"" and, in turn, cause us to fail. This PR attempts to work around this situation by retrying a few times on these errors.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3739:59,error,errors,59,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3739,2,['error'],['errors']
Availability,"./gatk-launch --help prints ""A USER ERROR has occurred: '--help' is not a valid command.""",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1301:36,ERROR,ERROR,36,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1301,1,['ERROR'],['ERROR']
Availability,".0.4.0/bin/gatk"" --java-options ""-Xmx8g -Xms8g"" \; GenotypeGVCFs \; -R ""/share/ScratchGeneral/evaben/cromwell/cromwell-executions/JointGenotyping/e64f393e-2ac6-43e6-9b20-cbfa905e7c33/call-GenotypeGVCFs/shard-17/inputs/1017648146/Homo_sapiens_assembly38.fasta"" \; -O ""$tmp_vcf"" \; -D ""/share/ScratchGeneral/evaben/cromwell/cromwell-executions/JointGenotyping/e64f393e-2ac6-43e6-9b20-cbfa905e7c33/call-GenotypeGVCFs/shard-17/inputs/1017648146/Homo_sapiens_assembly38.dbsnp138.vcf"" \; -G StandardAnnotation \; --only-output-calls-starting-in-intervals \; --use-new-qual-calculator \; -V gendb://""$genomicsdb"" \; -L ""chr18:1-80373285"". ""/share/ClusterShare/software/contrib/evaben/gatk/prebuilt/4.0.4.0/bin/gatk"" --java-options ""-Xmx8g -Xms8g"" \; VariantFiltration \; --filter-expression ""ExcessHet > 54.69"" \; --filter-name ExcessHet \; -O ""output.vcf.gz"" \; -V ""$tmp_vcf""; ```. And a SGE hard memory limit of 40G (GenotypeGVCFs has -Xmx8g).; On gatk 4.0.4.0 I see peak memory usage of 15.7G, while with gatk 4.0.6.0 I get:. ```; ...; 19:06:23.757 INFO GenotypeGVCFs - Initializing engine; 19:06:24.785 INFO FeatureManager - Using codec VCFCodec to read file file:///share/ScratchGeneral/evaben/cromwell/cromwell-executions/JointGenotyping/e9bf8c5e-3e70-476a-99a2-833f9d38cb2f/call-GenotypeGVCFs/shard-0/inputs/1017648146/Homo_sapiens_assembly38.dbsnp138.vcf; terminate called after throwing an instance of 'std::length_error'; what(): vector::_M_default_append; ```. It seems unlikely to be just a performance regression, maybe something is wrong with my commandline/inputs that only the new version is revealing. This may be in the genomicsdb part of the codebase, as that is the input file I am reading. . [stderr of failure (4.0.6.0) ](https://github.com/broadinstitute/gatk/files/2204252/gengvcferr.txt); [stderr of success (4.0.4.0) ](https://github.com/broadinstitute/gatk/files/2204253/gengvcfgood.txt); [script of failure](https://github.com/broadinstitute/gatk/files/2204254/gengvcfscript.txt)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5024:2461,failure,failure,2461,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5024,2,['failure'],['failure']
Availability,".1 KB, free: 530.0 MB); 17/10/11 14:19:18 INFO spark.SparkContext: Created broadcast 0 from newAPIHadoopFile at ReadsSparkSource.java:112; 17/10/11 14:19:18 INFO storage.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 14.5 KB, free 529.7 MB); 17/10/11 14:19:18 INFO storage.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.1 KB, free 529.7 MB); 17/10/11 14:19:18 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on 10.131.101.159:34044 (size: 2.1 KB, free: 530.0 MB); 17/10/11 14:19:18 INFO spark.SparkContext: Created broadcast 1 from broadcast at ReadsSparkSink.java:195; 17/10/11 14:19:18 INFO Configuration.deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir; 17/10/11 14:19:18 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1; 17/10/11 14:19:18 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false; 17/10/11 14:19:18 INFO spark.SparkContext: Starting job: saveAsNewAPIHadoopFile at ReadsSparkSink.java:203; 17/10/11 14:19:18 INFO input.FileInputFormat: Total input paths to process : 1; 17/10/11 14:19:18 INFO scheduler.DAGScheduler: Registering RDD 5 (mapToPair at SparkUtils.java:157); 17/10/11 14:19:18 INFO scheduler.DAGScheduler: Got job 0 (saveAsNewAPIHadoopFile at ReadsSparkSink.java:203) with 1 output partitions; 17/10/11 14:19:18 INFO scheduler.DAGScheduler: Final stage: ResultStage 1 (saveAsNewAPIHadoopFile at ReadsSparkSink.java:203); 17/10/11 14:19:18 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 0); 17/10/11 14:19:18 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 0); 17/10/11 14:19:18 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[5] at mapToPair at SparkUtils.java:157), which has no missing parents; 17/10/11 14:19:18 INFO storage.MemoryStore: Bl",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686:10831,failure,failures,10831,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686,1,['failure'],['failures']
Availability,".2 14260000 4500268.2. 10:46:40.543 INFO ProgressMeter - chr1:178147829 3.3 14969000 4487827.8. 10:46:50.551 INFO ProgressMeter - chr1:186125500 3.5 15636000 4464516.0. 10:47:00.555 INFO ProgressMeter - chr1:194986011 3.7 16297000 4441809.8. 10:47:10.565 INFO ProgressMeter - chr1:203560084 3.8 17001000 4432191.5. 10:47:20.577 INFO ProgressMeter - chr1:211951736 4.0 17700000 4421996.7. 10:47:30.580 INFO ProgressMeter - chr1:220837654 4.2 18418000 4417386.9. 10:47:40.592 INFO ProgressMeter - chr1:229536819 4.3 19156000 4417642.0. 10:47:50.595 INFO ProgressMeter - chr1:237917173 4.5 19861000 4410598.8. 10:48:00.598 INFO ProgressMeter - chr1:246682719 4.7 20561000 4403066.6. 10:48:10.604 INFO ProgressMeter - chr2:6733404 4.8 21270000 4397838.6. 10:48:20.605 INFO ProgressMeter - chr2:15144861 5.0 21942000 4385607.8. 10:48:30.607 INFO ProgressMeter - chr2:24131740 5.2 22650000 4381143.4. 10:48:40.610 INFO ProgressMeter - chr2:32916253 5.3 23467000 4397382.8. 10:48:43.217 INFO LeftAlignIndels - Shutting down engine. [August 18, 2020 10:48:43 AM EDT] org.broadinstitute.hellbender.tools.LeftAlignIndels done. Elapsed time: 5.40 minutes. Runtime.totalMemory()=2076049408. java.lang.IllegalArgumentException: the range cannot contain negative indices. at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:727). at org.broadinstitute.hellbender.utils.IndexRange.validate(IndexRange.java:108). at org.broadinstitute.hellbender.utils.IndexRange.shift(IndexRange.java:73). at org.broadinstitute.hellbender.utils.IndexRange.shiftLeft(IndexRange.java:77). at org.broadinstitute.hellbender.utils.read.AlignmentUtils.leftAlignIndels(AlignmentUtils.java:735). at org.broadinstitute.hellbender.tools.LeftAlignIndels.apply(LeftAlignIndels.java:78). at org.broadinstitute.hellbender.engine.ReadWalker.lambda$traverse$0(ReadWalker.java:96). at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184). at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6765:5817,down,down,5817,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6765,1,['down'],['down']
Availability,.21.2; 15:43:15.241 INFO FastaAlternateReferenceMaker - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 15:43:15.241 INFO FastaAlternateReferenceMaker - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 15:43:15.241 INFO FastaAlternateReferenceMaker - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 15:43:15.241 INFO FastaAlternateReferenceMaker - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 15:43:15.241 INFO FastaAlternateReferenceMaker - Deflater: IntelDeflater; 15:43:15.241 INFO FastaAlternateReferenceMaker - Inflater: IntelInflater; 15:43:15.241 INFO FastaAlternateReferenceMaker - GCS max retries/reopens: 20; 15:43:15.241 INFO FastaAlternateReferenceMaker - Requester pays: disabled; 15:43:15.241 INFO FastaAlternateReferenceMaker - Initializing engine; 15:43:17.851 INFO FeatureManager - Using codec VCFCodec to read file file:///g/data/xe2/users/stephen-rodgers/pergene_gatk/CCA0704/CCA0704.vcf.gz; 15:43:17.912 INFO FastaAlternateReferenceMaker - Done initializing engine; 15:43:17.913 INFO FastaAlternateReferenceMaker - Shutting down engine; [3 February 2020 at 3:43:17 pm AEDT] org.broadinstitute.hellbender.tools.walkers.fasta.FastaAlternateReferenceMaker done. Elapsed time: 0.06 minutes.; Runtime.totalMemory()=118489088; java.lang.NullPointerException; at org.broadinstitute.hellbender.tools.walkers.fasta.FastaReferenceMaker.closeTool(FastaReferenceMaker.java:141); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1052); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:163); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:206); at org.broadinstitute.hellbender.Main.main(Main.java:292). ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6434:3986,down,down,3986,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6434,1,['down'],['down']
Availability,".277 INFO DiscoverVariantsFromContigAlignmentsSAMSpark - DEL: 3680; 10:28:46.277 INFO DiscoverVariantsFromContigAlignmentsSAMSpark - DUP: 1141; 10:28:46.277 INFO DiscoverVariantsFromContigAlignmentsSAMSpark - INS: 1266; 10:28:46.483 INFO DiscoverVariantsFromContigAlignmentsSAMSpark - Shutting down engine; [October 4, 2017 10:28:46 AM EDT] org.broadinstitute.hellbender.tools.spark.sv.discovery.DiscoverVariantsFromContigAlignmentsSAMSpark done. Elapsed time: 0.53 minutes.; Runtime.totalMemory()=3954180096. ==============. feature.vcf. 13:51:48.490 INFO DiscoverVariantsFromContigAlignmentsSAMSpark - Discovered 6543 variants.; 13:51:48.502 INFO DiscoverVariantsFromContigAlignmentsSAMSpark - INV: 229; 13:51:48.502 INFO DiscoverVariantsFromContigAlignmentsSAMSpark - DEL: 3679; 13:51:48.502 INFO DiscoverVariantsFromContigAlignmentsSAMSpark - DUP: 1365; 13:51:48.502 INFO DiscoverVariantsFromContigAlignmentsSAMSpark - INS: 1270; 13:51:48.770 INFO DiscoverVariantsFromContigAlignmentsSAMSpark - Shutting down engine; [October 5, 2017 1:51:48 PM EDT] org.broadinstitute.hellbender.tools.spark.sv.discovery.DiscoverVariantsFromContigAlignmentsSAMSpark done. Elapsed time: 0.49 minutes.; Runtime.totalMemory()=4026531840; ```. No variants that were dropped are simple variants, and they are expected to be brought back with the correct interpretation once complex sv PR series are fully coded. __Two known issues__:; 1. Arguably, these calls may not have high confidence since we are likely NOT having the duplicated region fully assembled. But we could develop a filter later and be less stringent in the discovery stage.; 2. The inserted sequence mapping annotation is still an issue we need to iron out, in the sense that when one ref span is a completely enclosed in the other with some bases in the larger ref span uncovered by the the smaller ref span (i.e. a true containment from both boundaries instead of a one-boundary coincidence), there's actually insert sequence between the two copies ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3668:1601,down,down,1601,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3668,1,['down'],['down']
Availability,".38;HWP=1.0000;InbreedingCoeff=-0.0030;MLEAC=80;MLEAF=1.064e-03;MQ=59.45;MQ0=0;MQRankSum=0.306;NCC=2;QD=0.50;ReadPosRankSum=-1.290e-01;VQSLOD=2.18;culprit=QD; 14 45369723 . T TG 12376.8 PASS AC=182;AF=2.420e-03;AN=75210;BaseQRankSum=-1.810e-01;CCC=75210;ClippingRankSum=0.00;DP=1041458;FS=0.000;GQ_MEAN=67.78;GQ_STDDEV=20.59;HWP=1.0000;InbreedingCoeff=-0.0033;MLEAC=121;MLEAF=1.609e-03;MQ=59.77;MQ0=0;MQRankSum=0.410;NCC=2;QD=1.24;ReadPosRankSum=-1.100e-01;VQSLOD=2.08;culprit=QD; 19 8193948 . C CG 2846.04 PASS AC=102;AF=1.356e-03;AN=75204;BaseQRankSum=0.337;CCC=75204;ClippingRankSum=0.513;DP=1255955;FS=0.000;GQ_MEAN=76.78;GQ_STDDEV=24.97;HWP=1.0000;InbreedingCoeff=-0.0017;MLEAC=65;MLEAF=8.643e-04;MQ=59.81;MQ0=0;MQRankSum=0.514;NCC=5;QD=0.69;ReadPosRankSum=-1.050e-01;VQSLOD=2.07;culprit=QD. ---. @ldgauthier commented on [Thu Mar 12 2015](https://github.com/broadinstitute/gsa-unstable/issues/868#issuecomment-78600061). Are the VQSR output graphs for the ExAC dataset available anywhere? I really want to know what the QD distribution and fit for the indels look like. ---. @eitanbanks commented on [Fri Mar 13 2015](https://github.com/broadinstitute/gsa-unstable/issues/868#issuecomment-78798219). Thanks for looking into this. It's definitely a problem. ---. @ldgauthier commented on [Tue Mar 17 2015](https://github.com/broadinstitute/gsa-unstable/issues/868#issuecomment-82372578). A lot of the training data for ExAC INDELs are low QD; ![image](https://cloud.githubusercontent.com/assets/6578548/6687531/218c719c-cc82-11e4-8e76-5fd6e9b09f9e.png); About 35% of these training INDELs are multiallelic, compared with 47% of training INDELs with QD <= 2. QD for SNPs has much smaller variance (and a lot more data); ![image](https://cloud.githubusercontent.com/assets/6578548/6688722/0696c90a-cc8c-11e4-8b61-7c812246abb2.png); For SNPs 14% overall are multiallelic with 13% of QD <= 2.0 SNPs being multiallelic. So it's not a huge surprise that low QD indels pass because there's a fair amount",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2508:5128,avail,available,5128,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2508,1,['avail'],['available']
Availability,".455:0.025,0.025,0.950; WMCF9-CB5:working shlee$ gzcat 2_normalforpon.vcf.gz | grep 'chrX\t153909841'; chrX	153909841	.	C	A	.	.	DP=11;ECNT=1;POP_AF=1.000e-03;P_GERMLINE=-2.169e-04;TLOD=14.94	GT:AD:AF:ALT_F1R2:ALT_F2R1:FOXOG:MBQ:MCL:MFRL:MMQ:MPOS:REF_F1R2:REF_F2R1:SA_MAP_AF:SA_POST_PROB	0/1:6,5:0.455:3:2:0.400:30,33:0,0:191,278:60,60:11,20:1:5:0.404,0.444,0.455:0.025,0.025,0.950; WMCF9-CB5:working shlee$ gzcat 3_discard_practice_pon.vcf.gz | grep 'chrX'; ##contig=<ID=chrX,length=156040895>; ##contig=<ID=chrX_KI270880v1_alt,length=284869>; ##contig=<ID=chrX_KI270881v1_alt,length=144206>; ##contig=<ID=chrX_KI270913v1_alt,length=274009>; chrX	132097402	.	TACAC	T,TAC	.	.	.; ```; This site should have been called in the PoN. Finally, for the `-vcfs` parameter, if I provide a list of files, one per line, the tool errors with; ```; htsjdk.tribble.TribbleException$MalformedFeatureFile: Unable to parse header with error: Your input file has a malformed header: We never saw the required CHROM header line (starting with one #) for the input VCF file, for input source: /Users/shlee/Desktop/August2017_tutorial_dev/working/list_of_normals_for_pon.txt; 	at htsjdk.tribble.TribbleIndexedFeatureReader.readHeader(TribbleIndexedFeatureReader.java:253); 	at htsjdk.tribble.TribbleIndexedFeatureReader.<init>(TribbleIndexedFeatureReader.java:101); 	at htsjdk.tribble.TribbleIndexedFeatureReader.<init>(TribbleIndexedFeatureReader.java:126); 	at htsjdk.tribble.AbstractFeatureReader.getFeatureReader(AbstractFeatureReader.java:110); 	at htsjdk.tribble.AbstractFeatureReader.getFeatureReader(AbstractFeatureReader.java:74); 	at htsjdk.variant.vcf.VCFFileReader.<init>(VCFFileReader.java:58); 	at org.broadinstitute.hellbender.tools.walkers.mutect.CreateSomaticPanelOfNormals.doWork(CreateSomaticPanelOfNormals.java:122); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:116); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3510:2723,error,error,2723,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3510,1,['error'],['error']
Availability,".652,0.724;BaseQRankSum=-0.152;DP=118313;ExcessHet=2.9774;FS=0.518;InbreedingCoeff=0.0016;MLEAC=278,2;MLEAF=0.04,0.0002879;MQ=56.9;MQRankSum=-0.962;QD=2.57;ReadPosRankSum=0.193;SOR=0.712; `. ```; org.broadinstitute.hellbender.exceptions.GATKException: Exception thrown at chr6:26914009 [VC chr6.raw.excessHet.vcf.gz @ chr6:26914009 Q276902.75 of type=INDEL alleles=[G*, GTGTA, GTGTATA, GTGTGTA] attr={AC=[4269, 29, 5], AF=[0.620, 4.209e-03, ; #### Steps to reproduce; /share/pkg.7/gatk/4.2.6.1/install/gatk-4.2.6.1/gatk --java-options -Xms5g ApplyVQSR -O indel.recalibrated.vcf.gz -V chr6.raw.excessHet.vcf.gz -AS --recal-file /restricted/projectnb/kageproj/gatk/pVCF.vqsr/indels.recal --use-allele-specific-annotations --tranches-file /restricted/projectnb/kageproj/gatk/pVCF.vqsr/indels.tranches --truth-sensitivity-filter-level 99.0 --create-output-variant-index true -mode INDEL; ```. #### Expected behavior; Create recalibrated vcf file. #### Actual behavior; ```; Caused by:; Process `ApplyRecalibrationIndels` terminated with an error exit status (3). Command executed:. #!/bin/bash; /share/pkg.7/gatk/4.2.6.1/install/gatk-4.2.6.1/gatk --java-options -Xms5g ApplyVQSR -O indel.recalibrated.vcf.gz -V chr6.raw.excessHet.vcf.gz -AS --recal-file /restricted/projectnb/kageproj/gatk/pVCF.vqsr/indels.recal --use-allele-specific-annotations --tranches-file /restricted/projectnb/kageproj/gatk/pVCF.vqsr/indels.tranches --truth-sensitivity-filter-level 99.0 --create-output-variant-index true -mode INDEL. Command exit status:; 3. Command output:; (empty). Command error:; 23:21:52.354 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 23:22:02.735 INFO ProgressMeter - chr6:1162012 0.2 25000 144494.8; 23:22:12.789 INFO ProgressMeter - chr6:2449556 0.3 53000 155623.0; 23:22:23.019 INFO ProgressMeter - chr6:3663394 0.5 82000 160448.7; 23:22:33.257 INFO ProgressMeter - chr6:4991347 0.7 112000 164291.1; 23:22:43.683 INFO ProgressMeter - chr6:6325045 0.9 141000",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8054:1656,error,error,1656,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8054,1,['error'],['error']
Availability,".670 INFO  CNNScoreVariants - Inflater: IntelInflater ; ; 11:17:58.671 INFO  CNNScoreVariants - GCS max retries/reopens: 20 ; ; 11:17:58.671 INFO  CNNScoreVariants - Requester pays: disabled ; ; 11:17:58.671 INFO  CNNScoreVariants - Initializing engine ; ; WARNING: BAM index file /media/analyst/Data/WES/73318/73318\_WES\_hg19\_recalibrated.sorted.bai is older than BAM /media/analyst/Data/WES/73318/73318\_WES\_hg19\_recalibrated.sorted.bam ; ; 11:17:58.969 INFO  FeatureManager - Using codec VCFCodec to read file file:///media/analyst/Data/WES/73318/73318\_80\_IDTv1.vcf.gz ; ; 11:17:59.079 INFO  CNNScoreVariants - Done initializing engine ; ; 11:17:59.081 INFO  NativeLibraryLoader - Loading libgkl\_utils.so from jar:file:/home/analyst/anaconda3/envs/snakemake\_env/share/gatk4-4.2.5.0-0/gatk-package-4.2.5.0-local.jar!/com/intel/gkl/native/libgkl\_utils.so ; ; 11:17:59.187 INFO  CNNScoreVariants - Done scoring variants with CNN. ; ; 11:17:59.187 INFO  CNNScoreVariants - Shutting down engine ; ; \[April 25, 2022 at 11:17:59 AM CEST\] org.broadinstitute.hellbender.tools.walkers.vqsr.CNNScoreVariants done. Elapsed time: 0.01 minutes. ; ; Runtime.totalMemory()=1895825408 ; ; java.lang.NullPointerException ; ;     at org.broadinstitute.hellbender.utils.runtime.ProcessControllerAckResult.hasMessage(ProcessControllerAckResult.java:49) ; ;     at org.broadinstitute.hellbender.utils.runtime.ProcessControllerAckResult.getDisplayMessage(ProcessControllerAckResult.java:69) ; ;     at org.broadinstitute.hellbender.utils.runtime.StreamingProcessController.waitForAck(StreamingProcessController.java:229) ; ;     at org.broadinstitute.hellbender.utils.python.StreamingPythonScriptExecutor.waitForAck(StreamingPythonScriptExecutor.java:216) ; ;     at org.broadinstitute.hellbender.utils.python.StreamingPythonScriptExecutor.sendSynchronousCommand(StreamingPythonScriptExecutor.java:183) ; ;     at org.broadinstitute.hellbender.tools.walkers.vqsr.CNNScoreVariants.onTraversalStart(CNNScoreVaria",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7811:5316,down,down,5316,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7811,1,['down'],['down']
Availability,".981 INFO HaplotypeCaller - Inflater: JdkInflater; 15:47:00.981 INFO HaplotypeCaller - GCS max retries/reopens: 20; 15:47:00.981 INFO HaplotypeCaller - Requester pays: disabled; 15:47:00.981 INFO HaplotypeCaller - Initializing engine; 15:47:15.632 INFO HaplotypeCaller - Done initializing engine; 15:47:20.372 INFO HaplotypeCallerEngine - Disabling physical phasing, which is supported only for reference-model confidence output; 15:47:20.380 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/home/glier_ubuntu/gatk-4.1.1.0/gatk-package-4.1.1.0-local.jar!/com/intel/gkl/native/libgkl_utils.so; 15:47:20.391 INFO NativeLibraryLoader - Loading libgkl_pairhmm_omp.so from jar:file:/home/glier_ubuntu/gatk-4.1.1.0/gatk-package-4.1.1.0-local.jar!/com/intel/gkl/native/libgkl_pairhmm_omp.so; 15:47:20.423 INFO IntelPairHmm - Using CPU-supported AVX-512 instructions; 15:47:20.423 INFO IntelPairHmm - Flush-to-zero (FTZ) is enabled when running PairHMM; 15:47:20.423 INFO IntelPairHmm - Available threads: 40; 15:47:20.423 INFO IntelPairHmm - Requested threads: 4; 15:47:20.423 INFO PairHMM - Using the OpenMP multi-threaded AVX-accelerated native PairHMM implementation; 15:47:22.213 INFO ProgressMeter - Starting traversal; 15:47:22.213 INFO ProgressMeter - Current Locus Elapsed Minutes Regions Processed Regions/Minute; 15:47:22.231 INFO VectorLoglessPairHMM - Time spent in setup for JNI call : 0.0; 15:47:22.231 INFO PairHMM - Total compute time in PairHMM computeLogLikelihoods() : 0.0; 15:47:22.239 INFO SmithWatermanAligner - Total compute time in java Smith-Waterman : 0.00 sec; 15:47:22.240 INFO HaplotypeCaller - Shutting down engine; [May 13, 2020 at 3:47:22 p.m. EDT] org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCaller done. Elapsed time: 0.38 minutes.; Runtime.totalMemory()=3212836864; Exception in thread ""main"" java.lang.IncompatibleClassChangeError: Inconsistent constant pool data in classfile for class org/broadinstitute/hellbender/transformers",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6604:6250,Avail,Available,6250,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6604,1,['Avail'],['Available']
Availability,.BuildExceptionReporter] 	at org.gradle.internal.Transformers$4.transform(Transformers.java:169); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:106); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:56); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.initialization.DefaultGradleLauncher.doBuildStages(DefaultGradleLauncher.java:161); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.initialization.DefaultGradleLauncher.doBuild(DefaultGradleLauncher.java:112); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.initialization.DefaultGradleLauncher.run(DefaultGradleLauncher.java:95); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.exec.GradleBuildController.run(GradleBuildController.java:66); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.tooling.internal.provider.ExecuteBuildActionRunner.run(ExecuteBuildActionRunner.java:28); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.exec.ChainingBuildActionRunner.run(ChainingBuildActionRunner.java:35); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.exec.InProcessBuildActionExecuter.execute(InProcessBuildActionExecuter.java:41); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.exec.InProcessBuildActionExecuter.execute(InProcessBuildActionExecuter.java:26); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.tooling.internal.provider.ContinuousBu,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2802:7110,ERROR,ERROR,7110,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2802,1,['ERROR'],['ERROR']
Availability,".CommandLineProgram.instanceMain(CommandLineProgram.java:198); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); 	at org.broadinstitute.hellbender.Main.main(Main.java:289); 18/05/01 14:30:35 WARN ShutdownHookManager: ShutdownHook '$anon$2' timeout, java.util.concurrent.TimeoutException; java.util.concurrent.TimeoutException; 	at java.util.concurrent.FutureTask.get(FutureTask.java:205); 	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:67); 18/05/01 14:31:09 WARN ShutdownHookManager: ShutdownHook 'ClientFinalizer' timeout, java.util.concurrent.TimeoutException; java.util.concurrent.TimeoutException; 	at java.util.concurrent.FutureTask.get(FutureTask.java:205); 	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:67); 18/05/01 14:31:10 INFO ShutdownHookManager: Shutdown hook called; 18/05/01 14:31:15 INFO ShutdownHookManager: Deleting directory /tmp/abd30/spark-3f28d2e3-59d7-40f9-bba3-42d61eff6c6a; 18/05/01 14:31:20 ERROR ShutdownHookManager: ShutdownHookManger shutdown forcefully.; Using GATK jar /gpfs/fs0/home/abd30/gatk-4.0.3.0/gatk-package-4.0.3.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /gpfs/fs0/home/abd30/gatk-4.0.3.0/gatk-package-4.0.3.0-local.jar PathSeqPipelineSpark --input /data/shenlab/abd/TCGA_microbiome/tmp_WXS_colorectal_all/TCGA-AH-6643-11A-01D-1826-10_hg19_Illumina_gdc_realn.bam --kmer-file /data/shenlab/abd/TCGA_microbiome/pathseq_bundle/host_ref/pathseq_host.bfi --filter-bwa-image /data/shenlab/abd/TCGA_microbiome/pathseq_bundle/host_ref/pathseq_host.fa.img --microbe-bwa-image /data/shenlab/abd/TCGA_microbiome/pathseq_bundle/pathogen_ref/pathseq_microbe.fa.img --microbe-fasta /data/shenlab/abd/TCGA_microbiome/pathseq_bundle/pathogen_ref/pathseq_microbe.fa --taxonom",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4725:5723,ERROR,ERROR,5723,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4725,1,['ERROR'],['ERROR']
Availability,.ExceptionInInitializerError; 	at org.genomicsdb.GenomicsDBUtils.createTileDBWorkspace(GenomicsDBUtils.java:37); 	at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImport.overwriteCreateOrCheckWorkspace(GenomicsDBImport.java:883); 	at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImport.onTraversalStart(GenomicsDBImport.java:605); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1046); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:162); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:205); 	at org.broadinstitute.hellbender.Main.main(Main.java:291); Caused by: org.genomicsdb.exception.GenomicsDBException: Could not load genomicsdb native library; 	at org.genomicsdb.GenomicsDBUtilsJni.<clinit>(GenomicsDBUtilsJni.java:33); 	... 10 more; Caused by: java.lang.UnsatisfiedLinkError: /tmp/libtiledbgenomicsdb8918780584607909502.so: libcurl.so.4: cannot open shared object file: No such file or directory; 	at java.lang.ClassLoader$NativeLibrary.load(Native Method); 	at java.lang.ClassLoader.loadLibrary0(ClassLoader.java:1941); 	at java.lang.ClassLoader.loadLibrary(ClassLoader.java:1824); 	at java.lang.Runtime.load0(Runtime.java:809); 	at java.lang.System.load(System.java:1086); 	at org.genomicsdb.GenomicsDBLibLoader.loadLibraryFromJar(GenomicsDBLibLoader.java:147); 	at org.genomicsdb.GenomicsDBLibLoader.loadLibrary(GenomicsDBLibLoader.java:47); 	at org.genomicsdb.GenomicsDBUtilsJni.<clinit>(GenomicsDBUtilsJni.java:30); 	... 10 more. This Issue was generated from your [forums] ; [forums]: https://gatkforums.broadinstitute.org/gatk/discussion/24378/error-while-running-genomicsdbimport/p1,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6122:2901,error,error-while-running-genomicsdbimport,2901,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6122,1,['error'],['error-while-running-genomicsdbimport']
Availability,".ServletContextHandler@63318b56{/stages/json,null,AVAILABLE,@Spark}; 10:33:07.357 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@462f8fe9{/stages/stage,null,AVAILABLE,@Spark}; 10:33:07.358 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@b2e1df3{/stages/stage/json,null,AVAILABLE,@Spark}; 10:33:07.359 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@6cf3b3d7{/stages/pool,null,AVAILABLE,@Spark}; 10:33:07.360 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@55c20a91{/stages/pool/json,null,AVAILABLE,@Spark}; 10:33:07.361 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@3ba96967{/storage,null,AVAILABLE,@Spark}; 10:33:07.362 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@1237cade{/storage/json,null,AVAILABLE,@Spark}; 10:33:07.363 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@4509b7{/storage/rdd,null,AVAILABLE,@Spark}; 10:33:07.364 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@5dbc4598{/storage/rdd/json,null,AVAILABLE,@Spark}; 10:33:07.365 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@38a27ace{/environment,null,AVAILABLE,@Spark}; 10:33:07.366 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@7e8783b0{/environment/json,null,AVAILABLE,@Spark}; 10:33:07.367 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@53d2f0ec{/executors,null,AVAILABLE,@Spark}; 10:33:07.369 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@14d36bb2{/executors/json,null,AVAILABLE,@Spark}; 10:33:07.370 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@4452e13c{/executors/threadDump,null,AVAILABLE,@Spark}; 10:33:07.371 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@42172065{/executors/threadDump/json,null,AVAILABLE,@Spark}; 10:33:07.380 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@8e77c5b{/static,null,AVAILABLE,@Spark}; 10:33:07.380 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@49741274{/,null,AVAILABLE,@Spark}; 10:3",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8949:46436,AVAIL,AVAILABLE,46436,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8949,1,['AVAIL'],['AVAILABLE']
Availability,".ServletContextHandler@6cf3b3d7{/stages/pool,null,AVAILABLE,@Spark}; 10:33:07.360 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@55c20a91{/stages/pool/json,null,AVAILABLE,@Spark}; 10:33:07.361 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@3ba96967{/storage,null,AVAILABLE,@Spark}; 10:33:07.362 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@1237cade{/storage/json,null,AVAILABLE,@Spark}; 10:33:07.363 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@4509b7{/storage/rdd,null,AVAILABLE,@Spark}; 10:33:07.364 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@5dbc4598{/storage/rdd/json,null,AVAILABLE,@Spark}; 10:33:07.365 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@38a27ace{/environment,null,AVAILABLE,@Spark}; 10:33:07.366 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@7e8783b0{/environment/json,null,AVAILABLE,@Spark}; 10:33:07.367 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@53d2f0ec{/executors,null,AVAILABLE,@Spark}; 10:33:07.369 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@14d36bb2{/executors/json,null,AVAILABLE,@Spark}; 10:33:07.370 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@4452e13c{/executors/threadDump,null,AVAILABLE,@Spark}; 10:33:07.371 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@42172065{/executors/threadDump/json,null,AVAILABLE,@Spark}; 10:33:07.380 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@8e77c5b{/static,null,AVAILABLE,@Spark}; 10:33:07.380 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@49741274{/,null,AVAILABLE,@Spark}; 10:33:07.382 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@3e5b2630{/api,null,AVAILABLE,@Spark}; 10:33:07.383 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@1b6e4761{/jobs/job/kill,null,AVAILABLE,@Spark}; 10:33:07.384 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@642ec6{/stages/stage/kill,null,AVAILABLE,@Spark}; 10:33:07.389 ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8949:46796,AVAIL,AVAILABLE,46796,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8949,1,['AVAIL'],['AVAILABLE']
Availability,".USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 13:56:52.187 INFO GenotypeGVCFs - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 13:56:52.187 INFO GenotypeGVCFs - Deflater: IntelDeflater; 13:56:52.188 INFO GenotypeGVCFs - Inflater: IntelInflater; 13:56:52.188 INFO GenotypeGVCFs - GCS max retries/reopens: 20; 13:56:52.188 INFO GenotypeGVCFs - Requester pays: disabled; 13:56:52.188 INFO GenotypeGVCFs - Initializing engine; 13:56:53.115 INFO GenomicsDBLibLoader - GenomicsDB native library version : 1.3.0-e701905; [TileDB::Buffer] Error: Cannot read from buffer; End of buffer reached.; [TileDB::BookKeeping] Error: Cannot load book-keeping; Reading tile offsets failed.; 13:57:15.762 INFO GenotypeGVCFs - Shutting down engine; [December 21, 2020 1:57:15 PM CST] org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs done. Elapsed time: 0.40 minutes.; Runtime.totalMemory()=2119696384; ***********************************************************************. A USER ERROR has occurred: Couldn't create GenomicsDBFeatureReader. ***********************************************************************; org.broadinstitute.hellbender.exceptions.UserException: Couldn't create GenomicsDBFeatureReader; 	at org.broadinstitute.hellbender.engine.FeatureDataSource.getGenomicsDBFeatureReader(FeatureDataSource.java:410); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.getFeatureReader(FeatureDataSource.java:326); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:282); 	at org.broadinstitute.hellbender.engine.VariantLocusWalker.initializeDrivingVariants(VariantLocusWalker.java:76); 	at org.broadinstitute.hellbender.engine.VariantWalkerBase.initializeFeatures(VariantWalkerBase.java:67); 	at org.broadinstitute.hellbender.engine.GATKTool.onStartup(GATKTool.java:709); 	at org.broadinstitute.hellbender.engine.VariantLocusWalker.onStartup(VariantLocusWalker.java:63); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLine",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7012:3559,ERROR,ERROR,3559,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7012,1,['ERROR'],['ERROR']
Availability,.apache.spark.SparkContext$.org$apache$spark$SparkContext$$createTaskScheduler(SparkContext.scala:2735); 	at org.apache.spark.SparkContext.<init>(SparkContext.scala:522); 	at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59); 	at org.broadinstitute.hellbender.engine.spark.SparkContextFactory.createSparkContext(SparkContextFactory.java:150); 	at org.broadinstitute.hellbender.engine.spark.SparkContextFactory.getSparkContext(SparkContextFactory.java:82); 	at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:36); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:109); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:167); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:186); 	at org.broadinstitute.hellbender.Main.instanceMain(Main.java:95); 	at org.broadinstitute.hellbender.Main.instanceMain(Main.java:102); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:115); 	at org.broadinstitute.hellbender.Main.main(Main.java:157); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:731); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:181); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:206); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:121); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); ERROR: (gcloud.dataproc.jobs.submit.spark) Job [42925293-731b-47bb-8e5e-7f375d9c3490] entered state [ERROR] while waiting for [DONE].; ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2289:6934,ERROR,ERROR,6934,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2289,2,['ERROR'],['ERROR']
Availability,".broadinstitute.org/hc/en-us/community/posts/4409429876123--Did-not-inflate-expected-amount-Error). \--. Hi! I'm doing WGS analysis of a pedigree of three individuals using GATK 4.2.0.0. Everything went on well for the first individual. However, in the step of generating gvcf file from bam file, I encountered the error \[htsjdk.samtools.SAMFormatException: Did not inflate expected amount\] in the other two of the individuals. Please help me! Thank you in advance!. a) GATK version used:. GATK 4.2.0.0. b) Exact command used:. java -jar /home/ngs/biosoft/gatk-4.2.0.0/gatk-package-4.2.0.0-local.jar \\ ; ; HaplotypeCaller \\ ; ; \-R /media/ngs/NGS0/Database/RefSeq/Homo\_sapiens\_NCBI\_GRCh38Decoy/Homo\_sapiens/NCBI/GRCh38Decoy/Sequence/WholeGenomeFasta/NewIndex/genome.fa \\ ; ; \-I /media/ngs/BAM5T/WGS\_analysis/Data/9\_BQSRBam/Ped-San-3\_merged\_realigned\_bqsr.bam \\ ; ; \-ERC GVCF \\ ; ; \-O /media/ngs/BAM5T/WGS\_analysis/Data/10\_gvcf/Ped-San-3\_merged\_realigned\_bqsr.g.vcf. c) Entire error log:. 14:14:32.075 INFO NativeLibraryLoader - Loading libgkl\_compression.so from jar:file:/home/ngs/biosoft/gatk-4.2.0.0/gatk-package-4.2.0.0-local.jar!/com/intel/gkl/native/libgkl\_compression.so ; ; Nov 01, 2021 2:14:32 PM shaded.cloud\_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine ; ; INFO: Failed to detect whether we are running on Google Compute Engine. ; ; 14:14:32.573 INFO HaplotypeCaller - ------------------------------------------------------------ ; ; 14:14:32.573 INFO HaplotypeCaller - The Genome Analysis Toolkit (GATK) v4.2.0.0 ; ; 14:14:32.573 INFO HaplotypeCaller - For support and documentation go to [https://software.broadinstitute.org/gatk/](https://software.broadinstitute.org/gatk/) ; ; 14:14:32.573 INFO HaplotypeCaller - Executing as ngs@ngs-linux on Linux v5.8.0-59-generic amd64 ; ; 14:14:32.573 INFO HaplotypeCaller - Java runtime: OpenJDK 64-Bit Server VM v1.8.0\_292-8u292-b10-0ubuntu1~20.04-b10 ; ; 14:14:32.573 INFO HaplotypeCall",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7582:1387,error,error,1387,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7582,1,['error'],['error']
Availability,.buildevents.BuildExceptionReporter] 	at org.gradle.execution.DryRunBuildExecutionAction.execute(DryRunBuildExecutionAction.java:32); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.DefaultBuildExecuter.execute(DefaultBuildExecuter.java:37); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.DefaultBuildExecuter.execute(DefaultBuildExecuter.java:30); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.initialization.DefaultGradleLauncher$RunTasksAction.execute(DefaultGradleLauncher.java:230); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.initialization.DefaultGradleLauncher$RunTasksAction.execute(DefaultGradleLauncher.java:227); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.Transformers$4.transform(Transformers.java:169); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:106); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:56); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.initialization.DefaultGradleLauncher.doBuildStages(DefaultGradleLauncher.java:161); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.initialization.DefaultGradleLauncher.doBuild(DefaultGradleLauncher.java:112); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.initialization.DefaultGradleLauncher.run(DefaultGradleLauncher.java:95); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.exec.GradleBuildController.run(,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2802:6225,ERROR,ERROR,6225,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2802,1,['ERROR'],['ERROR']
Availability,".collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191); 	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63); 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96); 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748). 18/01/12 20:38:37 ERROR org.apache.spark.scheduler.TaskSetManager: Task 284 in stage 25.0 failed 4 times; aborting job; 18/01/12 20:38:37 INFO org.spark_project.jetty.server.AbstractConnector: Stopped Spark@23007ed{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 18/01/12 20:38:37 ERROR org.apache.spark.scheduler.LiveListenerBus: SparkListenerBus has already stopped! Dropping event SparkListenerExecutorMetricsUpdate(50,WrappedArray()); 18/01/12 20:38:37 ERROR org.apache.spark.scheduler.LiveListenerBus: SparkListenerBus has already stopped! Dropping event SparkListenerExecutorMetricsUpdate(52,WrappedArray()); 18/01/12 20:38:37 ERROR org.apache.spark.scheduler.LiveListenerBus: SparkListenerBus has already stopped! Dropping event SparkListenerExecutorMetricsUpdate(34,WrappedArray()); 18/01/12 20:38:37 ERROR org.apache.spark.scheduler.LiveListenerBus: SparkListenerBus has already stopped! Dropping event SparkListenerExecutorMetricsUpdate(60,WrappedArray()); 20:38:37.897 INFO StructuralVariationDiscoveryPipelineSpark - Shutting down engine; [January 12, 2018 8:38:37 PM UTC] org.broadinstitute.hellbender.tools.spark.sv.StructuralVariationDiscoveryPipelineSpark done. Elapsed time: 42.74 minutes.; Runtime.totalMemory()=16692805632; org.apache.spark.SparkExceptio",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4141:5216,ERROR,ERROR,5216,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4141,1,['ERROR'],['ERROR']
Availability,".copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.LongPipeline.reduce(LongPipeline.java:438); 	at java.util.stream.LongPipeline.sum(LongPipeline.java:396); 	at java.util.stream.ReferencePipeline.count(ReferencePipeline.java:526); 	at org.broadinstitute.hellbender.tools.walkers.annotator.CountNs.annotate(CountNs.java:46); 	at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorEngine.annotateContext(VariantAnnotatorEngine.java:268); 	at org.broadinstitute.hellbender.tools.walkers.mutect.SomaticGenotypingEngine.callMutations(SomaticGenotypingEngine.java:192); 	at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2Engine.callRegion(Mutect2Engine.java:233); 	at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2.apply(Mutect2.java:232); 	at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.processReadShard(AssemblyRegionWalker.java:291); 	at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.traverse(AssemblyRegionWalker.java:267); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:966); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:138); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:162); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:205); 	at org.broadinstitute.hellbender.Main.main(Main.java:291). #### Steps to reproduce. There is a clinical sample that results in this error. For that reason I cannot provide the data here, but I can work with the team to debug.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6336:3177,error,error,3177,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6336,1,['error'],['error']
Availability,.exec.GradleBuildController.run(GradleBuildController.java:66); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.tooling.internal.provider.ExecuteBuildActionRunner.run(ExecuteBuildActionRunner.java:28); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.exec.ChainingBuildActionRunner.run(ChainingBuildActionRunner.java:35); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.exec.InProcessBuildActionExecuter.execute(InProcessBuildActionExecuter.java:41); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.exec.InProcessBuildActionExecuter.execute(InProcessBuildActionExecuter.java:26); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.tooling.internal.provider.ContinuousBuildActionExecuter.execute(ContinuousBuildActionExecuter.java:75); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.tooling.internal.provider.ContinuousBuildActionExecuter.execute(ContinuousBuildActionExecuter.java:49); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.tooling.internal.provider.ServicesSetupBuildActionExecuter.execute(ServicesSetupBuildActionExecuter.java:49); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.tooling.internal.provider.ServicesSetupBuildActionExecuter.execute(ServicesSetupBuildActionExecuter.java:31); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.ExecuteBuild.doBuild(ExecuteBuild.java:67); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.BuildCommandOnly.execute(BuildCommandOnly.java:36); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter],MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2802:8194,ERROR,ERROR,8194,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2802,1,['ERROR'],['ERROR']
Availability,.exec.GradleBuildController.run(GradleBuildController.java:66); 22:05:55.977 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.tooling.internal.provider.ExecuteBuildActionRunner.run(ExecuteBuildActionRunner.java:28); 22:05:55.978 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.exec.ChainingBuildActionRunner.run(ChainingBuildActionRunner.java:35); 22:05:55.978 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.exec.InProcessBuildActionExecuter.execute(InProcessBuildActionExecuter.java:41); 22:05:55.978 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.exec.InProcessBuildActionExecuter.execute(InProcessBuildActionExecuter.java:26); 22:05:55.978 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.tooling.internal.provider.ContinuousBuildActionExecuter.execute(ContinuousBuildActionExecuter.java:79); 22:05:55.978 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.tooling.internal.provider.ContinuousBuildActionExecuter.execute(ContinuousBuildActionExecuter.java:51); 22:05:55.978 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.ExecuteBuild.doBuild(ExecuteBuild.java:59); 22:05:55.979 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.BuildCommandOnly.execute(BuildCommandOnly.java:36); 22:05:55.979 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); 22:05:55.979 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.WatchForDisconnection.execute(WatchForDisconnection.java:47); 22:05:55.979 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4687:7342,ERROR,ERROR,7342,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4687,1,['ERROR'],['ERROR']
Availability,.execute(DefaultTaskGraphExecuter.java:215); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.taskgraph.AbstractTaskPlanExecutor$TaskExecutorWorker.processTask(AbstractTaskPlanExecutor.java:77); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.taskgraph.AbstractTaskPlanExecutor$TaskExecutorWorker.run(AbstractTaskPlanExecutor.java:58); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.taskgraph.DefaultTaskPlanExecutor.process(DefaultTaskPlanExecutor.java:32); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.taskgraph.DefaultTaskGraphExecuter.execute(DefaultTaskGraphExecuter.java:113); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.SelectedTaskExecutionAction.execute(SelectedTaskExecutionAction.java:37); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.DefaultBuildExecuter.execute(DefaultBuildExecuter.java:37); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.DefaultBuildExecuter.access$000(DefaultBuildExecuter.java:23); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.DefaultBuildExecuter$1.proceed(DefaultBuildExecuter.java:43); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.DryRunBuildExecutionAction.execute(DryRunBuildExecutionAction.java:32); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.DefaultBuildExecuter.execute(DefaultBuildExecuter.java:37); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.DefaultBuildExecuter.execute(DefaultBuildExecuter.java:30); 11:54:40.434 [ERROR] [o,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2802:4707,ERROR,ERROR,4707,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2802,1,['ERROR'],['ERROR']
Availability,".fasta \; -I ""$MASTER_NODE""/data/smallCram.cram \; -O ""$MASTER_NODE""/""$PROJECT_DIR""/fastq \; --exclusionIntervals gs://sv-data-dsde-dev/reference/GRCh38.kill.intervals \; --kmersToIgnore gs://sv-data-dsde-dev/reference/Homo_sapiens_assembly38.dups \; --kmerIntervals ""$MASTER_NODE""/""$PROJECT_DIR""/kmerIntervals \; --breakpointEvidenceDir ""$MASTER_NODE""/""$PROJECT_DIR""/evidence \; --breakpointIntervals ""$MASTER_NODE""/""$PROJECT_DIR""/intervals \; --qnameIntervalsMapped ""$MASTER_NODE""/""$PROJECT_DIR""/qnameIntervalsMapped \; --qnameIntervalsForAssembly ""$MASTER_NODE""/""$PROJECT_DIR""/qnameIntervalsForAssembly \; --maxFASTQSize 10000000 \; -- \; --sparkRunner GCS \; --cluster svdev-caller; ```. ========================. On the other hand, we see a similar error if the input is changed to the same file but stored in a google bucket (although the cited cause is different):. ```; ***********************************************************************. A USER ERROR has occurred: Failed to read bam header from gs://sv-data-dsde-dev/test_data/smallCram.cram; Caused by:null. ***********************************************************************; org.broadinstitute.hellbender.exceptions.UserException: A USER ERROR has occurred: Failed to read bam header from gs://sv-data-dsde-dev/test_data/smallCram.cram; Caused by:null; 	at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSource.getHeader(ReadsSparkSource.java:182); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.initializeReads(GATKSparkTool.java:381); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.initializeToolInputs(GATKSparkTool.java:361); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:351); 	at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:38); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:112); 	at org.broadinstitute.hellbender.cmdline.Com",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2382:5472,ERROR,ERROR,5472,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2382,1,['ERROR'],['ERROR']
Availability,".j.s.ServletContextHandler@443ac5b8{/jobs/job/json,null,AVAILABLE,@Spark}; 10:33:07.354 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@753e4eb5{/stages,null,AVAILABLE,@Spark}; 10:33:07.355 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@63318b56{/stages/json,null,AVAILABLE,@Spark}; 10:33:07.357 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@462f8fe9{/stages/stage,null,AVAILABLE,@Spark}; 10:33:07.358 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@b2e1df3{/stages/stage/json,null,AVAILABLE,@Spark}; 10:33:07.359 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@6cf3b3d7{/stages/pool,null,AVAILABLE,@Spark}; 10:33:07.360 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@55c20a91{/stages/pool/json,null,AVAILABLE,@Spark}; 10:33:07.361 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@3ba96967{/storage,null,AVAILABLE,@Spark}; 10:33:07.362 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@1237cade{/storage/json,null,AVAILABLE,@Spark}; 10:33:07.363 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@4509b7{/storage/rdd,null,AVAILABLE,@Spark}; 10:33:07.364 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@5dbc4598{/storage/rdd/json,null,AVAILABLE,@Spark}; 10:33:07.365 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@38a27ace{/environment,null,AVAILABLE,@Spark}; 10:33:07.366 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@7e8783b0{/environment/json,null,AVAILABLE,@Spark}; 10:33:07.367 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@53d2f0ec{/executors,null,AVAILABLE,@Spark}; 10:33:07.369 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@14d36bb2{/executors/json,null,AVAILABLE,@Spark}; 10:33:07.370 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@4452e13c{/executors/threadDump,null,AVAILABLE,@Spark}; 10:33:07.371 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@42172065{/executors/threadDump/json,null,AVAIL",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8949:46195,AVAIL,AVAILABLE,46195,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8949,1,['AVAIL'],['AVAILABLE']
Availability,".j.s.ServletContextHandler@7e8783b0{/environment/json,null,AVAILABLE,@Spark}; 10:33:07.367 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@53d2f0ec{/executors,null,AVAILABLE,@Spark}; 10:33:07.369 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@14d36bb2{/executors/json,null,AVAILABLE,@Spark}; 10:33:07.370 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@4452e13c{/executors/threadDump,null,AVAILABLE,@Spark}; 10:33:07.371 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@42172065{/executors/threadDump/json,null,AVAILABLE,@Spark}; 10:33:07.380 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@8e77c5b{/static,null,AVAILABLE,@Spark}; 10:33:07.380 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@49741274{/,null,AVAILABLE,@Spark}; 10:33:07.382 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@3e5b2630{/api,null,AVAILABLE,@Spark}; 10:33:07.383 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@1b6e4761{/jobs/job/kill,null,AVAILABLE,@Spark}; 10:33:07.384 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@642ec6{/stages/stage/kill,null,AVAILABLE,@Spark}; 10:33:07.389 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@3fe5ad73{/metrics/json,null,AVAILABLE,@Spark}; 10:33:07.397 INFO SortSamSpark - Spark verbosity set to INFO (see --spark-verbosity argument); 10:33:07.450 INFO GoogleHadoopFileSystemBase - GHFS version: 1.9.4-hadoop3; 10:33:08.183 INFO MemoryStore - Block broadcast_0 stored as values in memory (estimated size 268.7 KiB, free 1076.2 GiB); 10:33:08.581 INFO MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 41.8 KiB, free 1076.2 GiB); 10:33:08.585 INFO BlockManagerInfo - Added broadcast_0_piece0 in memory on 172.20.19.130:43279 (size: 41.8 KiB, free: 1076.2 GiB); 10:33:08.591 INFO SparkContext - Created broadcast 0 from newAPIHadoopFile at PathSplitSource.java:96; 10:33:09.126 INFO MemoryStore - Block broadcast_1 stored as values in mem",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8949:47632,AVAIL,AVAILABLE,47632,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8949,1,['AVAIL'],['AVAILABLE']
Availability,".jar /. RUN curl -s https://packagecloud.io/install/repositories/github/git-lfs/script.deb.sh | bash; RUN apt-get install -y git-lfs; RUN git lfs install; RUN apt-get install unzip; RUN apt-get install wget; RUN apt-get install git. RUN mkdir /gatk; RUN apt-get update && apt-get install -y python git mlocate htop && export JAVA_TOOL_OPTIONS=-Dfile.encoding=UTF8 && \; wget https://github.com/broadinstitute/gatk/releases/download/4.0.4.0/gatk-4.0.4.0.zip && unzip gatk-4.0.4.0.zip -d tmp && mv tmp/gatk-4.0.4.0/* /gatk && cp /spark/conf/spark-defaults.conf.template /spark/conf/spark-defaults.conf && \; echo ""spark.eventLog.enabled true"" >> /spark/conf/spark-defaults.conf && \; echo ""spark.eventLog.dir file:///spark/logs/"" >> /spark/conf/spark-defaults.conf. ENV PATH=""$PATH:/spark/bin""; ```; I have this configurations for docker-compose:; - Spark. ```; version: '3'; services:; spark-master:; image: atahualpa/spark-master:GATK4.0.4; networks:; - workbench; deploy:; replicas: 1; mode: replicated; restart_policy:; condition: on-failure; labels:; traefik.docker.network: workbench; traefik.port: 8080; env_file:; - ./hadoop.env; ports:; - 8333:8080; - 4040:4040; - 6066:6066; - 7077:7077; volumes:; - /data0/reference/hg19-ucsc/:/reference/hg19-ucsc/; - /data0/fastq/:/fastq/; - /data0/NGS-SparkGATK/NGS-SparkGATK/:/NGS-SparkGATK/; - /data/ngs/:/ngs/; - /data0/output/:/output/; spark-worker:; image: bde2020/spark-worker:2.2.0-hadoop2.8-hive-java8; networks:; - workbench; environment:; - SPARK_MASTER=spark://spark-master:7077; deploy:; mode: global; restart_policy:; condition: on-failure; labels:; traefik.docker.network: workbench; traefik.port: 8081. env_file:; - ./hadoop.env; volumes:; - reference-image:/reference_image. reference:; image: vzzarr/reference:hg19_img; networks:; - workbench; deploy:; mode: global; restart_policy:; condition: on-failure; tty: true #keeps the container alive; volumes:; - reference-image:/reference_image. volumes:; reference-image:. networks:; workben",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4820:1327,failure,failure,1327,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4820,1,['failure'],['failure']
Availability,".java:306). real 481m24.418s; user 581m54.752s; sys 2m49.965s. ```. This run did not complete successfully - the Exception caused it to fail prematurely. . Previously I had seen HaplotypeCaller run out of memory and fail in almost as much time, so I think this and the OOM error are related. The only difference in invocation was that with the OOM failure, I was running with the default for `--max-reads-per-alignment-start` (`50`). This also works just fine with that setting at 15. The failure seems to occur around the same place in the data each time (the end of `chr13`). At that point in the data, there is a very large pileup which is probably instigating this. Additionally, if I remove the `--linked-de-bruijn-graph` argument, this runs just fine with the default setting of `--max-reads-per-alignment-start`. I have a minimally reproductive dataset that I can share which reproduces the OOM error for sure (I'm 99% sure it reproduces this one as well). For the OOM failures, the final logs from HaplotypeCaller look like this:. ```; ./gatk HaplotypeCaller ...; ...; 15:56:23.205 INFO ProgressMeter - Pf3D7_13_v3:2603234 100.5 114070 1134.5; 15:56:33.443 INFO ProgressMeter - Pf3D7_13_v3:2661462 100.7 114420 1136.1; Dangling End recovery killed because of a loop (getReferencePathForwardFromKmer); 15:56:43.998 INFO ProgressMeter - Pf3D7_13_v3:2730055 100.9 114840 1138.3; 15:56:59.911 INFO ProgressMeter - Pf3D7_13_v3:2798281 101.2 115210 1139.0; 15:59:27.062 INFO ProgressMeter - Pf3D7_13_v3:2861780 103.6 115460 1114.4; Dangling End recovery killed because of a loop (getReferencePathForwardFromKmer); Dangling End recovery killed because of a loop (getReferencePathForwardFromKmer); 15:59:37.457 INFO ProgressMeter - Pf3D7_13_v3:2869697 103.8 115500 1112.9. real 671m24.770s; user 777m30.923s; sys 6m13.682s. $ echo $?; 247; ```. Here is my command-line invocation:; ```; ./gatk --java-options ""-Xmx100000m -Xms25000m"" \; HaplotypeCaller \; -R /juffowup2/malaria/references/PlasmoDB-61_",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8440:5030,failure,failures,5030,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8440,1,['failure'],['failures']
Availability,".java:36); at htsjdk.samtools.AsyncSAMFileWriter.synchronouslyWrite(AsyncSAMFileWriter.java:16); at htsjdk.samtools.util.AbstractAsyncWriter$WriterRunnable.run(AbstractAsyncWriter.java:117); at java.lang.Thread.run(Thread.java:745); Caused by: java.lang.ClassNotFoundException: org.xerial.snappy.LoadSnappy; at java.net.URLClassLoader.findClass(URLClassLoader.java:381); at java.lang.ClassLoader.loadClass(ClassLoader.java:424); at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331); at java.lang.ClassLoader.loadClass(ClassLoader.java:357); ... 11 more. We can find snappy-java in <INST_DIR>/build/install/gatk/lib/snappy-java-1.1.1.7.jar, but it does not have a LoadSnappy class. Renaming the snappy-java jar file so gatk cannot find it allows FastqToSam to run through. ---. @akiezun commented on [Thu Jun 30 2016](https://github.com/broadinstitute/gatk-protected/issues/587#issuecomment-229843043). thanks for the report. Can you provide the whole commandline you used?. ---. @huangk3 commented on [Thu Sep 15 2016](https://github.com/broadinstitute/gatk-protected/issues/587#issuecomment-247467619). Hi @akiezun I experience the same error when running gate-launch FastqToSam. My command line is:; ""./gatk_launch FastqToSam -SM ""test"" -F1 $fq1 -F2 $fq2 -O test.spark.sam -SO coordinate -R $ref --STRIP_UNPAIRED_MATE_NUMBER true --VALIDATION_STRINGENCY LENIENT -PL ILLUMINA --CREATE_INDEX true"". My Spark version is 2.0.0; Thanks!. ---. @lbergelson commented on [Mon Sep 19 2016](https://github.com/broadinstitute/gatk-protected/issues/587#issuecomment-248086238). @huangk3 Unfortunately Adam moved on to a different job so he's longer working on GATK. . I believe this is the same problem as https://github.com/broadinstitute/gatk/issues/2026 and has been patched in gatk public with https://github.com/broadinstitute/gatk/pull/2028. You might try using FastqToSam in the public repo, or wait and try a new version of protected that incorporates an updated gatk public (coming soon..)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2868:2685,error,error,2685,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2868,1,['error'],['error']
Availability,".local on Mac OS X 10.15.6 x86_64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_65-b17. ; INFO 10:47:54,493 HelpFormatter - Date/Time: 2020/09/08 10:47:54 ; INFO 10:47:54,494 HelpFormatter - ---------------------------------------------------------------------------------- ; INFO 10:47:54,494 HelpFormatter - ---------------------------------------------------------------------------------- ; ERROR StatusLogger Unable to create class org.apache.logging.log4j.core.impl.Log4jContextFactory specified in jar:file:/Users/mac/Desktop/GenomeAnalysisTK-3.8-0-ge9d806836%204/GenomeAnalysisTK.jar!/META-INF/log4j-provider.properties; ERROR StatusLogger Log4j2 could not find a logging implementation. Please add log4j-core to the classpath. Using SimpleLogger to log to the console...; INFO 10:47:55,875 GenomeAnalysisEngine - Deflater: IntelDeflater ; INFO 10:47:55,876 GenomeAnalysisEngine - Inflater: IntelInflater ; INFO 10:47:55,876 GenomeAnalysisEngine - Strictness is SILENT ; INFO 10:47:56,246 GenomeAnalysisEngine - Downsampling Settings: No downsampling ; INFO 10:47:56,255 SAMDataSource$SAMReaders - Initializing SAMRecords in serial ; INFO 10:47:56,333 SAMDataSource$SAMReaders - Done initializing BAM readers: total time 0.07 ; ##### ERROR ------------------------------------------------------------------------------------------; ##### ERROR A USER ERROR has occurred (version 3.8-0-ge9d806836): ; ##### ERROR; ##### ERROR This means that one or more arguments or inputs in your command are incorrect.; ##### ERROR The error message below tells you what is the problem.; ##### ERROR; ##### ERROR If the problem is an invalid argument, please check the online documentation guide; ##### ERROR (or rerun your command with --help) to view allowable command-line arguments for this tool.; ##### ERROR; ##### ERROR Visit our website and forum for extensive documentation and answers to ; ##### ERROR commonly asked questions https://software.broadinstitute.org/gatk; ##### ERROR; ##### ERROR Please d",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6798:2408,Down,Downsampling,2408,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6798,2,"['Down', 'down']","['Downsampling', 'downsampling']"
Availability,".onReceive(DAGScheduler.scala:2802) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2791) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; 11:00:54.078 INFO AbstractConnector - Stopped Spark@2f829853{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}; 11:00:54.091 INFO SparkUI - Stopped Spark web UI at http://172.20.19.130:4040; 11:00:54.122 INFO MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!; 11:00:54.175 INFO MemoryStore - MemoryStore cleared; 11:00:54.175 INFO BlockManager - BlockManager stopped; 11:00:54.193 INFO BlockManagerMaster - BlockManagerMaster stopped; 11:00:54.211 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!; 11:00:54.302 INFO SparkContext - Successfully stopped SparkContext; 11:00:54.303 INFO SortSamSpark - Shutting down engine; [August 11, 2024 at 11:00:54 AM CST] org.broadinstitute.hellbender.tools.spark.pipelines.SortSamSpark done. Elapsed time: 27.81 minutes.; Runtime.totalMemory()=1926292832256; org.apache.spark.SparkException: Job aborted.; at org.apache.spark.internal.io.SparkHadoopWriter$.write(SparkHadoopWriter.scala:106); at org.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsNewAPIHadoopDataset$1(PairRDDFunctions.scala:1078); at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); at org.apache.spark.rdd.RDD.withScope(RDD.scala:406); at org.apache.spark.rdd.PairRDDFunctions.saveAsNewAPIHadoopDataset(PairRDDFunctions.scala:1076); at org.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsNewAPIHadoopFile$2(PairRDDFunctions.scala:995); at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23); at org.apa",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8949:24605,down,down,24605,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8949,1,['down'],['down']
Availability,".py#L215); [gcnvkernel model_denoising_calling.py](https://github.com/broadinstitute/gatk/blob/4e1741896bcd04d70493f94b082dd0d27023f14c/src/main/python/org/broadinstitute/hellbender/gcnvkernel/models/model_denoising_calling.py); [gcnvkernel io_metadata.py write_sample_coverage_metadata function](https://github.com/broadinstitute/gatk/blob/4e1741896bcd04d70493f94b082dd0d27023f14c/src/main/python/org/broadinstitute/hellbender/gcnvkernel/io/io_metadata.py#L16); [theano scan_op.py](https://github.com/Theano/Theano/blob/master/theano/scan_module/scan_op.py). ### Affected version(s); - [x] Latest public release version [version?]; - [ ] Latest master branch as of [date of test?]. ### Description ; I'm getting a strange error (see below) when running a nf-core module test. I am using test files, which are obviously smaller as for short testing times i.e. the provided bam file only provides mapped reads for a small section of the genome. #### Steps to reproduce; Run the following to create and interactive container and mount the required zip folder ([gatk_test.tar.gz](https://github.com/broadinstitute/gatk/files/10022295/gatk_test.tar.gz)):; ```docker run -it -v /path/to/gatk_test_dir:/mnt/gatk_test broadinstitute/gatk bash```; If you bash the `gatk_germlinecnvcaller.sh` within the provided zip folder in a gatk4 Docker container. #### Expected behavior; gatk GermlineCNVCaller should run as expected. #### Actual behavior; ```TypeError: ('The following error happened while compiling the node', forall_inplace,cpu,scan_fn}(Elemwise{Maximum}[(0, 0)].0, Subtensor{int64:int64:int8}.0, Subtensor{int64:int64:int8}.0, IncSubtensor{InplaceSet;:int64:}.0, Elemwise{mul,no_inplace}.0, Subtensor{int64::}.0, Elemwise{sub,no_inplace}.0), '\n', ""Inconsistency in the inner graph of scan 'scan_fn' : an input and an output are associated with the same recurrent state and should have the same type but have type 'TensorType(float64, row)' and 'TensorType(float64, matrix)' respectively."")```. ----",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8097:1955,error,error,1955,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8097,1,['error'],['error']
Availability,".s.ServletContextHandler@b506ed0{/storage/rdd/json,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@65f3e805{/environment,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@10618775{/environment/json,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@20a3e10c{/executors,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5e2a6991{/executors/json,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6f96dd64{/executors/threadDump,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@409732fb{/executors/threadDump/json,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5e99e2cb{/static,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@478967eb{/,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@7f2b39a{/api,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@18c880ea{/jobs/job/kill,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6afbe6a1{/stages/stage/kill,null,AVAILABLE,@Spark}; 18/01/09 18:30:56 INFO ui.SparkUI: Bound SparkUI to 0.0.0.0, and started at http://192.168.1.4:4040; 18/01/09 18:30:56 INFO spark.SparkContext: Added JAR file:/opt/NfsDir/BioDir/GATK4/gatk/build/libs/gatk-package-4.beta.5-50-g8d666b6-SNAPSHOT-spark.jar at spark://192.168.1.4:38793/jars/gatk-package-4.beta.5-50-g8d666b6-SNAPSHOT-spark.jar with timestamp 1515493856032; 18/01/09 18:30:56 INFO gcs.GoogleHadoopFileSystemBase: GHFS version: 1.6.1-hadoop2; 18/01/09 18:30:57 ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4112:9816,AVAIL,AVAILABLE,9816,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4112,1,['AVAIL'],['AVAILABLE']
Availability,".s.j.s.ServletContextHandler@53d2f0ec{/executors,null,AVAILABLE,@Spark}; 10:33:07.369 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@14d36bb2{/executors/json,null,AVAILABLE,@Spark}; 10:33:07.370 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@4452e13c{/executors/threadDump,null,AVAILABLE,@Spark}; 10:33:07.371 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@42172065{/executors/threadDump/json,null,AVAILABLE,@Spark}; 10:33:07.380 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@8e77c5b{/static,null,AVAILABLE,@Spark}; 10:33:07.380 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@49741274{/,null,AVAILABLE,@Spark}; 10:33:07.382 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@3e5b2630{/api,null,AVAILABLE,@Spark}; 10:33:07.383 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@1b6e4761{/jobs/job/kill,null,AVAILABLE,@Spark}; 10:33:07.384 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@642ec6{/stages/stage/kill,null,AVAILABLE,@Spark}; 10:33:07.389 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@3fe5ad73{/metrics/json,null,AVAILABLE,@Spark}; 10:33:07.397 INFO SortSamSpark - Spark verbosity set to INFO (see --spark-verbosity argument); 10:33:07.450 INFO GoogleHadoopFileSystemBase - GHFS version: 1.9.4-hadoop3; 10:33:08.183 INFO MemoryStore - Block broadcast_0 stored as values in memory (estimated size 268.7 KiB, free 1076.2 GiB); 10:33:08.581 INFO MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 41.8 KiB, free 1076.2 GiB); 10:33:08.585 INFO BlockManagerInfo - Added broadcast_0_piece0 in memory on 172.20.19.130:43279 (size: 41.8 KiB, free: 1076.2 GiB); 10:33:08.591 INFO SparkContext - Created broadcast 0 from newAPIHadoopFile at PathSplitSource.java:96; 10:33:09.126 INFO MemoryStore - Block broadcast_1 stored as values in memory (estimated size 268.7 KiB, free 1076.2 GiB); 10:33:09.142 INFO MemoryStore - Block broadcast_1_piece0 stored as bytes ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8949:47755,AVAIL,AVAILABLE,47755,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8949,1,['AVAIL'],['AVAILABLE']
Availability,".s.j.s.ServletContextHandler@5cb76070{/jobs/job,null,AVAILABLE,@Spark}; 10:33:07.352 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@443ac5b8{/jobs/job/json,null,AVAILABLE,@Spark}; 10:33:07.354 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@753e4eb5{/stages,null,AVAILABLE,@Spark}; 10:33:07.355 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@63318b56{/stages/json,null,AVAILABLE,@Spark}; 10:33:07.357 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@462f8fe9{/stages/stage,null,AVAILABLE,@Spark}; 10:33:07.358 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@b2e1df3{/stages/stage/json,null,AVAILABLE,@Spark}; 10:33:07.359 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@6cf3b3d7{/stages/pool,null,AVAILABLE,@Spark}; 10:33:07.360 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@55c20a91{/stages/pool/json,null,AVAILABLE,@Spark}; 10:33:07.361 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@3ba96967{/storage,null,AVAILABLE,@Spark}; 10:33:07.362 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@1237cade{/storage/json,null,AVAILABLE,@Spark}; 10:33:07.363 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@4509b7{/storage/rdd,null,AVAILABLE,@Spark}; 10:33:07.364 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@5dbc4598{/storage/rdd/json,null,AVAILABLE,@Spark}; 10:33:07.365 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@38a27ace{/environment,null,AVAILABLE,@Spark}; 10:33:07.366 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@7e8783b0{/environment/json,null,AVAILABLE,@Spark}; 10:33:07.367 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@53d2f0ec{/executors,null,AVAILABLE,@Spark}; 10:33:07.369 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@14d36bb2{/executors/json,null,AVAILABLE,@Spark}; 10:33:07.370 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@4452e13c{/executors/threadDump,null,AVAILABLE,@Spark}; 10",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8949:46075,AVAIL,AVAILABLE,46075,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8949,1,['AVAIL'],['AVAILABLE']
Availability,".setPosition(SAMRecordToGATKReadAdapter.java:89); at org.broadinstitute.hellbender.utils.clipping.ClippingOp.applyHARDCLIP_BASES(ClippingOp.java:381); at org.broadinstitute.hellbender.utils.clipping.ClippingOp.apply(ClippingOp.java:73); at org.broadinstitute.hellbender.utils.clipping.ReadClipper.clipRead(ReadClipper.java:147); at org.broadinstitute.hellbender.utils.clipping.ReadClipper.clipRead(ReadClipper.java:128); at org.broadinstitute.hellbender.utils.clipping.ReadClipper.hardClipSoftClippedBases(ReadClipper.java:332); at org.broadinstitute.hellbender.utils.clipping.ReadClipper.hardClipSoftClippedBases(ReadClipper.java:335); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.AssemblyBasedCallerUtils.finalizeRegion(AssemblyBasedCallerUtils.java:84); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.AssemblyBasedCallerUtils.assembleReads(AssemblyBasedCallerUtils.java:238); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerEngine.callRegion(HaplotypeCallerEngine.java:478); at org.broadinstitute.hellbender.tools.HaplotypeCallerSpark.lambda$regionToVariants$580(HaplotypeCallerSpark.java:203) ; ```. At first glance this looks like a problem with unmapped reads, but these are filtered out by the tool. So it's more likely to be in the clipping logic. It's hard to diagnose since it doesn't say which read caused it, and it's slow to reproduce as it is running on a large input. Any thoughts @lbergelson, @droazen?. ---. @lbergelson commented on [Sat May 27 2017](https://github.com/broadinstitute/gatk-protected/issues/1091#issuecomment-304466112). @tomwhite Is it possible you could upload the bam file somewhere on google cloud along with the command line you used? It's not obvious to me where the error is being caused. It's painful to debug anything on a 160GB file, but I think we can probably do a binary search on the file and find the bad location pretty quickly. I.e. throw compute at the problem instead of human time...",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3013:2089,error,error,2089,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3013,1,['error'],['error']
Availability,".soohee1k.hdf5 (15 / 24); 21:55:02.822 INFO GermlineCNVCaller - Aggregating read-count file /home/shlee/gcnv/low_coverage_1k/HG03642.lc.soohee1k.hdf5 (16 / 24); 21:55:04.931 INFO GermlineCNVCaller - Aggregating read-count file /home/shlee/gcnv/low_coverage_1k/HG03742.lc.soohee1k.hdf5 (17 / 24); 21:55:06.457 INFO GermlineCNVCaller - Aggregating read-count file /home/shlee/gcnv/low_coverage_1k/NA18525.lc.soohee1k.hdf5 (18 / 24); 21:55:07.933 INFO GermlineCNVCaller - Aggregating read-count file /home/shlee/gcnv/low_coverage_1k/NA18939.lc.soohee1k.hdf5 (19 / 24); 21:55:09.347 INFO GermlineCNVCaller - Aggregating read-count file /home/shlee/gcnv/low_coverage_1k/NA19017.lc.soohee1k.hdf5 (20 / 24); 21:55:11.068 INFO GermlineCNVCaller - Aggregating read-count file /home/shlee/gcnv/low_coverage_1k/NA19625.lc.soohee1k.hdf5 (21 / 24); 21:55:13.479 INFO GermlineCNVCaller - Aggregating read-count file /home/shlee/gcnv/low_coverage_1k/NA19648.lc.soohee1k.hdf5 (22 / 24); 21:55:15.323 INFO GermlineCNVCaller - Aggregating read-count file /home/shlee/gcnv/low_coverage_1k/NA20502.lc.soohee1k.hdf5 (23 / 24); 21:55:17.219 INFO GermlineCNVCaller - Aggregating read-count file /home/shlee/gcnv/low_coverage_1k/NA20845.lc.soohee1k.hdf5 (24 / 24); 01:27:10.674 INFO GermlineCNVCaller - Germline denoising and CNV calling complete.; 01:27:10.676 INFO GermlineCNVCaller - Shutting down engine; [May 29, 2018 1:27:10 AM UTC] org.broadinstitute.hellbender.tools.copynumber.GermlineCNVCaller done. Elapsed time: 212.70 minutes.; Runtime.totalMemory()=5764022272; Tool returned:; SUCCESS; ```. Would be great to have a summary of useful information, e.g. (but not limited to):. - Total number of epochs (INFO level); - ELBO value and SNR value etc for the final epochs (INFO level); - Whether convergence was achieved or not (WARN if not). Currently, the only way to get all three pieces of information is through setting `--verbosity DEBUG`, which makes for very long stdouts that go well beyond what tmux saves.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4826:6339,down,down,6339,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4826,1,['down'],['down']
Availability,".tdb; errno=122(Disk quota exceede; d); [TileDB::WriteState] Error: Cannot write segment to file.; [TileDB::FileSystem] Error: (write_to_file) Cannot write to file; File opening error; path=/storage/home/data/gendb/chr13/chr13$32310639$32310731/.__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/__book_keeping.tdb.gz; errno=122(Disk quota e; xceeded); [TileDB::utils] Error: (write_to_file_after_compression) Could not write compressed bytes to internal buffer; path=/storage/home/data/gendb/chr13/chr13$32310639$32310731/.__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/__book_keeping.tdb.gz; ; errno=122(Disk quota exceeded); [TileDB::BookKeeping] Error: Cannot finalize book-keeping; Failure to write to file /storage/home/data/gendb/chr13/chr13$32310639$32310731/.__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/__book_keeping.tdb.gz.; [TileDB::FileSystem] Error: (create_file) Failed to create file; path=/storage/home/data/gendb/chr13/chr13$32310639$32310731/__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/__tiledb_fragment.tdb; errno=122(Disk quota exceeded); [TileDB::utils] Error: (create_fragment_file) Failed to create fragment file; path=/storage/home/data/gendb/chr13/chr13$32310639$32310731/__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087; errno=122(Disk quota exceeded); 11:23:52.390 erro NativeGenomicsDB - pid=57964 tid=57984 VariantStorageManagerException exception : Error while finalizing TileDB array chr13$32310639$32310731; TileDB error message : [TileDB::WriteState] Error: Cannot write segment to file; [TileDB::FileSystem] Error: (write_to_file) Cannot write to file; File opening error; path=/storage/home/data/gendb/chr13/chr13$32310639$32310731/.__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/RAW_MQandDP.tdb; errno=122(Disk quota exceede; d); #### Steps to reproduce; Below code ran on a cluster; ```; gatk --java-options ""-Xmx100g -Xms100g"" GenomicsDBImp",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6950:1332,Error,Error,1332,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6950,1,['Error'],['Error']
Availability,".tsv -> file:///home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s/gencode_xrefseq/hg19/gencode_xrefseq_v75_37.tsv; 15:41:54.798 INFO Funcotator - Initializing Funcotator Engine...; 15:41:54.811 INFO Funcotator - Creating a MAF file for output: file:/home/shiyang/Project/BGB900_101/TSO_result/test.maf; 15:41:54.826 INFO ProgressMeter - Starting traversal; 15:41:54.827 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 15:41:54.853 INFO VcfFuncotationFactory - ClinVar_VCF 20180401 cache hits/total: 0/0; 15:41:54.854 INFO VcfFuncotationFactory - dbSNP 9606_b151 cache hits/total: 0/0; 15:41:54.860 INFO Funcotator - Shutting down engine; [August 19, 2020 3:41:54 PM CST] org.broadinstitute.hellbender.tools.funcotator.Funcotator done. Elapsed time: 0.10 minutes.; Runtime.totalMemory()=2588409856; htsjdk.tribble.TribbleException$MalformedFeatureFile: Error parsing LineIteratorImpl(SynchronousLineReader) at the first queried after chr1:2489658, for input source: file:///home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s/gencode/hg19/gencode.v34lift37.annotation.REORDERED.gtf; at htsjdk.tribble.TribbleIndexedFeatureReader$QueryIterator.readNextRecord(TribbleIndexedFeatureReader.java:532); at htsjdk.tribble.TribbleIndexedFeatureReader$QueryIterator.<init>(TribbleIndexedFeatureReader.java:441); at htsjdk.tribble.TribbleIndexedFeatureReader.query(TribbleIndexedFeatureReader.java:297); at org.broadinstitute.hellbender.engine.FeatureDataSource.refillQueryCache(FeatureDataSource.java:567); at org.broadinstitute.hellbender.engine.FeatureDataSource.queryAndPrefetch(FeatureDataSource.java:536); at org.broadinstitute.hellbender.engine.FeatureManager.getFeatures(FeatureManager.java:352); at org.broadinstitute.hellbender.engine.FeatureContext.getValues(FeatureContext.java:173); at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.queryFeaturesFromFeatureContext(",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6758:20542,Error,Error,20542,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6758,1,['Error'],['Error']
Availability,"/01 14:20:59 ERROR LiveListenerBus: SparkListenerBus has already stopped! Dropping event SparkListenerBlockUpdated(BlockUpdatedInfo(BlockManagerId(driver, 10.12.137.46, 39719, None),broadcast_1_piece0,StorageLevel(memory, 1 replicas),127561,0)); 18/05/01 14:21:18 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 18/05/01 14:23:29 INFO MemoryStore: MemoryStore cleared; 18/05/01 14:23:29 INFO BlockManager: BlockManager stopped; 18/05/01 14:23:29 INFO BlockManagerMaster: BlockManagerMaster stopped; 18/05/01 14:24:38 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 18/05/01 14:25:36 INFO SparkContext: Successfully stopped SparkContext; 14:25:37.027 INFO PathSeqPipelineSpark - Shutting down engine; [May 1, 2018 2:25:37 PM EDT] org.broadinstitute.hellbender.tools.spark.pathseq.PathSeqPipelineSpark done. Elapsed time: 37.98 minutes.; Runtime.totalMemory()=23999283200; org.apache.spark.SparkException: Job aborted due to stage failure: Task 20 in stage 1.0 failed 1 times, most recent failure: Lost task 20.0 in stage 1.0 (TID 891, localhost, executor driver): ExecutorLostFailure (executor driver exited caused by one of the running tasks) Reason: Executor heartbeat timed out after 131031 ms; Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.schedul",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4725:1951,failure,failure,1951,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4725,1,['failure'],['failure']
Availability,"/05/23 13:20:18 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1163; 23/05/23 13:20:18 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 30 (MapPartitionsRDD[73] at mapToPair at BamSink.java:91) (first 15 tasks are for partitions Vector(0)); 23/05/23 13:20:18 INFO TaskSchedulerImpl: Adding task set 30.0 with 1 tasks; 23/05/23 13:20:18 INFO TaskSetManager: Starting task 0.0 in stage 30.0 (TID 1973, localhost, executor driver, partition 0, PROCESS_LOCAL, 7662 bytes); 23/05/23 13:20:18 INFO Executor: Running task 0.0 in stage 30.0 (TID 1973); 23/05/23 13:20:18 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks; 23/05/23 13:20:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms; 23/05/23 13:20:18 INFO FileOutputCommitter: File Output Committer Algorithm version is 2; 23/05/23 13:20:18 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false; 23/05/23 13:20:18 INFO FileOutputCommitter: File Output Committer Algorithm version is 2; 23/05/23 13:20:18 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false; 23/05/23 13:20:18 INFO FileOutputCommitter: Saved output of task 'attempt_20230523132018_0073_r_000000_0' to file:pathseq/CRC_16.pathseq.complete.bam.parts; 23/05/23 13:20:18 INFO SparkHadoopMapRedUtil: attempt_20230523132018_0073_r_000000_0: Committed; 23/05/23 13:20:18 INFO Executor: Finished task 0.0 in stage 30.0 (TID 1973). 1149 bytes result sent to driver; 23/05/23 13:20:18 INFO TaskSetManager: Finished task 0.0 in stage 30.0 (TID 1973) in 184 ms on localhost (executor driver) (1/1); 23/05/23 13:20:18 INFO TaskSchedulerImpl: Removed TaskSet 30.0, whose tasks have all completed, from pool ; 23/05/23 13:20:18 INFO DAGScheduler: ResultStage 30 (runJob at SparkHadoopWriter.scala:78) finished i",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8339:52464,failure,failures,52464,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8339,2,['failure'],['failures']
Availability,"/biology/gatk/work/gatk-4.1.2.0/src/main/java/org/broadinstitute/hellbender/tools/walkers/annotator/StrandOddsRatio.java:106: error: unmappable character for encoding ASCII; * SOR = ln(5.7284) + ln(0.2385) ??? ln(0.7559) = 1.7454427755 + (-1.433) ??? (-0.2798) = 0.592; ^; /usr/ports/biology/gatk/work/gatk-4.1.2.0/src/main/java/org/broadinstitute/hellbender/tools/walkers/annotator/StrandOddsRatio.java:106: error: unmappable character for encoding ASCII; * SOR = ln(5.7284) + ln(0.2385) ??? ln(0.7559) = 1.7454427755 + (-1.433) ??? (-0.2798) = 0.592; ^; /usr/ports/biology/gatk/work/gatk-4.1.2.0/src/main/java/org/broadinstitute/hellbender/tools/walkers/annotator/StrandOddsRatio.java:106: error: unmappable character for encoding ASCII; * SOR = ln(5.7284) + ln(0.2385) ??? ln(0.7559) = 1.7454427755 + (-1.433) ??? (-0.2798) = 0.592; ^; /usr/ports/biology/gatk/work/gatk-4.1.2.0/src/main/java/org/broadinstitute/hellbender/tools/walkers/annotator/StrandOddsRatio.java:106: error: unmappable character for encoding ASCII; * SOR = ln(5.7284) + ln(0.2385) ??? ln(0.7559) = 1.7454427755 + (-1.433) ??? (-0.2798) = 0.592; ^; /usr/ports/biology/gatk/work/gatk-4.1.2.0/src/main/java/org/broadinstitute/hellbender/tools/walkers/annotator/StrandOddsRatio.java:106: error: unmappable character for encoding ASCII; * SOR = ln(5.7284) + ln(0.2385) ??? ln(0.7559) = 1.7454427755 + (-1.433) ??? (-0.2798) = 0.592; ^; /usr/ports/biology/gatk/work/gatk-4.1.2.0/src/main/java/org/broadinstitute/hellbender/tools/walkers/annotator/StrandOddsRatio.java:106: error: unmappable character for encoding ASCII; * SOR = ln(5.7284) + ln(0.2385) ??? ln(0.7559) = 1.7454427755 + (-1.433) ??? (-0.2798) = 0.592; ^; /usr/ports/biology/gatk/work/gatk-4.1.2.0/src/main/java/org/broadinstitute/hellbender/tools/walkers/mutect/Mutect2.java:137: error: unmappable character for encoding ASCII; * Specifically, the mode sets <nobr>???-initial-tumor-lod</nobr> to 0, <nobr>???-tumor-lod-to-emit</nobr> to 0, <nobr>--af-of-alleles-not-in",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5934:1002,error,error,1002,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5934,1,['error'],['error']
Availability,"/biology/gatk/work/gatk-4.1.2.0/src/main/java/org/broadinstitute/hellbender/tools/walkers/annotator/StrandOddsRatio.java:106: error: unmappable character for encoding ASCII; * SOR = ln(5.7284) + ln(0.2385) ??? ln(0.7559) = 1.7454427755 + (-1.433) ??? (-0.2798) = 0.592; ^; /usr/ports/biology/gatk/work/gatk-4.1.2.0/src/main/java/org/broadinstitute/hellbender/tools/walkers/annotator/StrandOddsRatio.java:106: error: unmappable character for encoding ASCII; * SOR = ln(5.7284) + ln(0.2385) ??? ln(0.7559) = 1.7454427755 + (-1.433) ??? (-0.2798) = 0.592; ^; /usr/ports/biology/gatk/work/gatk-4.1.2.0/src/main/java/org/broadinstitute/hellbender/tools/walkers/annotator/StrandOddsRatio.java:106: error: unmappable character for encoding ASCII; * SOR = ln(5.7284) + ln(0.2385) ??? ln(0.7559) = 1.7454427755 + (-1.433) ??? (-0.2798) = 0.592; ^; /usr/ports/biology/gatk/work/gatk-4.1.2.0/src/main/java/org/broadinstitute/hellbender/tools/walkers/annotator/StrandOddsRatio.java:106: error: unmappable character for encoding ASCII; * SOR = ln(5.7284) + ln(0.2385) ??? ln(0.7559) = 1.7454427755 + (-1.433) ??? (-0.2798) = 0.592; ^; /usr/ports/biology/gatk/work/gatk-4.1.2.0/src/main/java/org/broadinstitute/hellbender/tools/walkers/annotator/StrandOddsRatio.java:106: error: unmappable character for encoding ASCII; * SOR = ln(5.7284) + ln(0.2385) ??? ln(0.7559) = 1.7454427755 + (-1.433) ??? (-0.2798) = 0.592; ^; /usr/ports/biology/gatk/work/gatk-4.1.2.0/src/main/java/org/broadinstitute/hellbender/tools/walkers/mutect/Mutect2.java:137: error: unmappable character for encoding ASCII; * Specifically, the mode sets <nobr>???-initial-tumor-lod</nobr> to 0, <nobr>???-tumor-lod-to-emit</nobr> to 0, <nobr>--af-of-alleles-not-in-resource</nobr> to; ^; /usr/ports/biology/gatk/work/gatk-4.1.2.0/src/main/java/org/broadinstitute/hellbender/tools/walkers/mutect/Mutect2.java:137: error: unmappable character for encoding ASCII; * Specifically, the mode sets <nobr>???-initial-tumor-lod</nobr> to 0, <nobr>???-tumor",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5934:1285,error,error,1285,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5934,1,['error'],['error']
Availability,"/biology/gatk/work/gatk-4.1.2.0/src/main/java/org/broadinstitute/hellbender/tools/walkers/annotator/StrandOddsRatio.java:106: error: unmappable character for encoding ASCII; * SOR = ln(5.7284) + ln(0.2385) ??? ln(0.7559) = 1.7454427755 + (-1.433) ??? (-0.2798) = 0.592; ^; /usr/ports/biology/gatk/work/gatk-4.1.2.0/src/main/java/org/broadinstitute/hellbender/tools/walkers/annotator/StrandOddsRatio.java:106: error: unmappable character for encoding ASCII; * SOR = ln(5.7284) + ln(0.2385) ??? ln(0.7559) = 1.7454427755 + (-1.433) ??? (-0.2798) = 0.592; ^; /usr/ports/biology/gatk/work/gatk-4.1.2.0/src/main/java/org/broadinstitute/hellbender/tools/walkers/annotator/StrandOddsRatio.java:106: error: unmappable character for encoding ASCII; * SOR = ln(5.7284) + ln(0.2385) ??? ln(0.7559) = 1.7454427755 + (-1.433) ??? (-0.2798) = 0.592; ^; /usr/ports/biology/gatk/work/gatk-4.1.2.0/src/main/java/org/broadinstitute/hellbender/tools/walkers/annotator/StrandOddsRatio.java:106: error: unmappable character for encoding ASCII; * SOR = ln(5.7284) + ln(0.2385) ??? ln(0.7559) = 1.7454427755 + (-1.433) ??? (-0.2798) = 0.592; ^; /usr/ports/biology/gatk/work/gatk-4.1.2.0/src/main/java/org/broadinstitute/hellbender/tools/walkers/mutect/Mutect2.java:137: error: unmappable character for encoding ASCII; * Specifically, the mode sets <nobr>???-initial-tumor-lod</nobr> to 0, <nobr>???-tumor-lod-to-emit</nobr> to 0, <nobr>--af-of-alleles-not-in-resource</nobr> to; ^; /usr/ports/biology/gatk/work/gatk-4.1.2.0/src/main/java/org/broadinstitute/hellbender/tools/walkers/mutect/Mutect2.java:137: error: unmappable character for encoding ASCII; * Specifically, the mode sets <nobr>???-initial-tumor-lod</nobr> to 0, <nobr>???-tumor-lod-to-emit</nobr> to 0, <nobr>--af-of-alleles-not-in-resource</nobr> to; ^; /usr/ports/biology/gatk/work/gatk-4.1.2.0/src/main/java/org/broadinstitute/hellbender/tools/walkers/mutect/Mutect2.java:137: error: unmappable character for encoding ASCII; * Specifically, the mode sets <n",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5934:1568,error,error,1568,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5934,1,['error'],['error']
Availability,/broadinstitute/gatk#building for information on how to build GATK.; 22:05:55.967 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] ; 22:05:55.968 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] * Exception is:; 22:05:55.969 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] org.gradle.api.GradleScriptException: A problem occurred evaluating root project 'gatk'.; 22:05:55.969 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.groovy.scripts.internal.DefaultScriptRunnerFactory$ScriptRunnerImpl.run(DefaultScriptRunnerFactory.java:92); 22:05:55.969 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.DefaultScriptPluginFactory$ScriptPluginImpl$2.run(DefaultScriptPluginFactory.java:176); 22:05:55.970 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.ProjectScriptTarget.addConfiguration(ProjectScriptTarget.java:77); 22:05:55.970 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.DefaultScriptPluginFactory$ScriptPluginImpl.apply(DefaultScriptPluginFactory.java:181); 22:05:55.970 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.project.BuildScriptProcessor.execute(BuildScriptProcessor.java:38); 22:05:55.970 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.project.BuildScriptProcessor.execute(BuildScriptProcessor.java:25); 22:05:55.970 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.project.ConfigureActionsProjectEvaluator.evaluate(ConfigureActionsProjectEvaluator.java:34); 22:05:55.970 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.project.LifecycleProjectEvaluator.evaluate(LifecycleProjectEvaluator.java:55); 22:05:55.970 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.g,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4687:2563,ERROR,ERROR,2563,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4687,1,['ERROR'],['ERROR']
Availability,/cw-test-m:8020/output/variants/inv_del_ins.vcf -R hdfs://cw-test-m:8020/reference/Homo_sapiens_assembly38.2bit --aligner-index-image /mnt/1/reference/Homo_sapiens_assembly38.fasta.img --exclusion-intervals hdfs://cw-test-m:8020/reference/Homo_sapiens_assembly38.kill.intervals --kmers-to-ignore hdfs://cw-test-m:8020/reference/Homo_sapiens_assembly38.kill.kmers --cross-contigs-to-ignore hdfs://cw-test-m:8020/reference/Homo_sapiens_assembly38.kill.alts --breakpoint-intervals hdfs://cw-test-m:8020/output/intervals --fastq-dir hdfs://cw-test-m:8020/output/fastq --contig-sam-file hdfs://cw-test-m:8020/output/assemblies.sam --target-link-file hdfs://cw-test-m:8020/output/target_links.bedpe --exp-variants-out-dir hdfs://cw-test-m:8020/output/experimentalVariantInterpretations -- --spark-runner GCS --cluster cw-test --num-executors 20 --driver-memory 30G --executor-memory 30G --conf spark.yarn.executor.memoryOverhead=5000 --conf spark.network.timeout=600 --conf spark.executor.heartbeatInterval=120 --conf spark.driver.userClassPathFirst=false; ```. It failed near the end of the pipeline. Here is the tail of the log:. ```; 20:38:14.368 INFO StructuralVariationDiscoveryPipelineSpark - Used 3549 evidence target links to annotate assembled breakpoints; 20:38:14.462 INFO StructuralVariationDiscoveryPipelineSpark - Called 662 imprecise deletion variants; 20:38:14.492 INFO StructuralVariationDiscoveryPipelineSpark - Discovered 7234 variants.; 20:38:14.506 INFO StructuralVariationDiscoveryPipelineSpark - INV: 184; 20:38:14.506 INFO StructuralVariationDiscoveryPipelineSpark - DEL: 4486; 20:38:14.506 INFO StructuralVariationDiscoveryPipelineSpark - DUP: 1170; 20:38:14.506 INFO StructuralVariationDiscoveryPipelineSpark - INS: 1394; 18/01/12 20:38:16 WARN org.apache.spark.scheduler.TaskSetManager: Stage 17 contains a task of very large size (2518 KB). The maximum recommended task size is 100 KB.; 18/01/12 20:38:22 WARN org.apache.spark.scheduler.TaskSetManager: Stage 18 contains a task o,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4141:1230,heartbeat,heartbeatInterval,1230,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4141,1,['heartbeat'],['heartbeatInterval']
Availability,"/data/project/naangda_panel_20230228/output/mutect/probe/normal_mutect/sssss4.filtered.mutect2.vcf -O /data/project/naangda_panel_20230228/output/mutect/Funcotator/sssss4.funcocator.maf --output-file-format MAF --data-sources-path /data/Homo_sapiens/Homo_sapiens_38/funcotator/funcotator_dataSources.v1.7.20200521s/ --ref-version hg38. code2; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /root/software/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar Funcotator -R /data/Homo_sapiens/Homo_sapiens_38/Homo_sapiens_assembly38.fasta -V /data/project/naangda_panel_20230228/output/mutect/probe/normal_mutect/sssss4.filtered.mutect2.vcf -O /data/project/naangda_panel_20230228/output/mutect/Funcotator/sssss4.funcocator.maf --output-file-format MAF --data-sources-path /data/Homo_sapiens/Homo_sapiens_38/funcotator/funcotator_dataSources.v1.7.20200521s/ --ref-version hg38. what's the problem with the program?; 1. I had download database, why error ""com.google.cloud.storage.StorageException: Connection reset"" happened?; 2. why I got only a file with title but no records like this, what should I do to solve this problem？. ## Funcotator 4.1.8.1 | Date 20233731T033757 | Gencode 34 CANONICAL | Achilles 110303 | ClinVar_VCF 20180429_hg38 | Cosmic v84 | CosmicFusion v84 | CosmicTissue v83 | Familial_Cancer_Genes 20110905 | Gencode_XHGNC 90_38 | Gencode_XRefSeq 90_38 | HGNC Nov302017 | Oreganno 20160119 | Simple_Uniprot 2014_12 | dbSNP 9606_b151; Hugo_Symbol	Entrez_Gene_Id	Center	NCBI_Build	Chromosome	Start_Position	End_Position	Strand	Variant_Classification	Variant_Type	Reference_Allele	Tumor_Seq_Allele1	Tumor_Seq_Allele2	dbSNP_RSdbSNP_Val_Status	Tumor_Sample_Barcode	Matched_Norm_Sample_Barcode	Match_Norm_Seq_Allele1	Match_Norm_Seq_Allele2	Tumor_Validation_Allele1	Tumor_Validation_Allele2	Match_Norm_Validation_Allele1	Match_Norm_Valida",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8275:2366,down,download,2366,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8275,2,"['down', 'error']","['download', 'error']"
Availability,"/hg19.fa.gz). Any feedback leading to resolving the issue is greatly appreciated. a) Picard version:. 2.21.6-SNAPSHOT. b) Command script:. java -jar picard.jar CollectGcBiasMetrics \\ ; ; I=sorted.sam \\ ; ; O=gc\_bias\_metrics.txt \\ ; ; CHART=gc\_bias\_metrics.pdf \\ ; ; S=summary\_metrics.txt \\ ; ; R=hg19.fa \\ ; ; SCAN\_WINDOW\_SIZE=1000. c) Error log:. MINIMUM\_GENOME\_FRACTION=1.0E-5 IS\_BISULFITE\_SEQUENCED=false METRIC\_ACCUMULATION\_LEVEL=\[ALL\_READS\] ALSO\_IGNORE\_DUPLICATES=false ASSUME\_SORTED=true STOP\_AFTER=0 VERBOSITY=INFO QUIET=false VALIDATION\_STRINGENCY=STRICT COMPRESSION\_LEVEL=5 MAX\_RECORDS\_IN\_RAM=500000 CREATE\_INDEX=false CREATE\_MD5\_FILE=false GA4GH\_CLIENT\_SECRETS=client\_secrets.json USE\_JDK\_DEFLATER=false USE\_JDK\_INFLATER=false ; ; \[Tue Jan 07 16:48:19 PST 2020\] Executing as [akoch@hpc5-0-3.local](mailto:akoch@hpc5-0-3.local) on Linux 2.6.32-431.11.2.el6.x86\_64 amd64; OpenJDK 64-Bit Server VM 1.8.0\_181-b13; Deflater: Intel; Inflater: Intel; Provider GCS is not available; Picard version: 2.21.6-SNAPSHOT ; ; INFO 2020-01-07 16:51:24 SinglePassSamProgram Processed 1,000,000 records. Elapsed time: 00:00:33s. Time for last 1,000,000: 27s. Last read position: chr5:92,832,908 ; ; INFO 2020-01-07 16:51:53 SinglePassSamProgram Processed 2,000,000 records. Elapsed time: 00:01:01s. Time for last 1,000,000: 28s. Last read position: chr11:121,228,669 ; ; \[Tue Jan 07 16:52:25 PST 2020\] picard.analysis.CollectGcBiasMetrics done. Elapsed time: 4.10 minutes. ; ; Runtime.totalMemory()=4236247040 ; ; To get help, see [http://broadinstitute.github.io/picard/index.html#GettingHelp](http://broadinstitute.github.io/picard/index.html#GettingHelp) ; ; Exception in thread ""main"" htsjdk.samtools.SAMException: Exception counting mismatches for read XXXXXXXX0434501/1 32b aligned to chrX:51305151-51305182. ; ; at htsjdk.samtools.util.SequenceUtil.countMismatches(SequenceUtil.java:490) ; ; at htsjdk.samtools.util.SequenceUtil.countMismatches(SequenceUt",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6372:1950,avail,available,1950,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6372,1,['avail'],['available']
Availability,"/home/vlad/bcbio/anaconda/share/gatk4-4.0b5-0/gatk-package-4.beta.5-local.jar!/com/intel/gkl/native/libgkl_utils.so; 16:51:51.764 INFO NativeLibraryLoader - Loading libgkl_pairhmm_omp.so from jar:file:/home/vlad/bcbio/anaconda/share/gatk4-4.0b5-0/gatk-package-4.beta.5-local.jar!/com/intel/gkl/native/libgkl_pairhmm_omp.so; 16:51:51.795 WARN IntelPairHmm - Flush-to-zero (FTZ) is enabled when running PairHMM; 16:51:51.796 INFO IntelPairHmm - Available threads: 32; 16:51:51.796 INFO IntelPairHmm - Requested threads: 4; 16:51:51.796 INFO PairHMM - Using the OpenMP multi-threaded AVX-accelerated native PairHMM implementation; 16:51:51.815 INFO ProgressMeter - Starting traversal; 16:51:51.815 INFO ProgressMeter - Current Locus Elapsed Minutes Regions Processed Regions/Minute; 16:51:51.881 INFO VectorLoglessPairHMM - Time spent in setup for JNI call : 0.0; 16:51:51.881 INFO PairHMM - Total compute time in PairHMM computeLogLikelihoods() : 0.0; 16:51:51.881 INFO HaplotypeCaller - Shutting down engine; [16 November 2017 4:51:51 PM] org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCaller done. Elapsed time: 0.02 minutes.; Runtime.totalMemory()=1640497152; java.lang.IllegalArgumentException: contig must be non-null and not equal to *, and start must be >= 1; at org.broadinstitute.hellbender.utils.read.SAMRecordToGATKReadAdapter.setPosition(SAMRecordToGATKReadAdapter.java:92); at org.broadinstitute.hellbender.utils.clipping.ClippingOp.applyHARDCLIP_BASES(ClippingOp.java:381); at org.broadinstitute.hellbender.utils.clipping.ClippingOp.apply(ClippingOp.java:73); at org.broadinstitute.hellbender.utils.clipping.ReadClipper.clipRead(ReadClipper.java:145); at org.broadinstitute.hellbender.utils.clipping.ReadClipper.clipRead(ReadClipper.java:126); at org.broadinstitute.hellbender.utils.clipping.ReadClipper.hardClipSoftClippedBases(ReadClipper.java:330); at org.broadinstitute.hellbender.utils.clipping.ReadClipper.hardClipSoftClippedBases(ReadClipper.java:333); at org.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3845:9365,down,down,9365,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3845,1,['down'],['down']
Availability,"/io_commons.py"", line 98, in assert_output_path_writable; filehandle = open(filename, 'w'); PermissionError: [Errno 13] Permission denied: '/home/shlee/gcc/hc24_soohee1k_chr1-model/write_tester'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/tmp/shlee/cohort_denoising_calling.7832183760446168530.py"", line 151, in <module>; args.output_model_path)(); File ""/home/shlee/anaconda3/envs/gatk/lib/python3.6/site-packages/gcnvkernel/io/io_denoising_calling.py"", line 28, in __init__; io_commons.assert_output_path_writable(output_path); File ""/home/shlee/anaconda3/envs/gatk/lib/python3.6/site-packages/gcnvkernel/io/io_commons.py"", line 102, in assert_output_path_writable; raise IOError(""The output path \""{0}\"" is not writeable"".format(output_path)); OSError: The output path ""/home/shlee/gcc/hc24_soohee1k_chr1-model"" is not writeable; 16:26:00.659 DEBUG ScriptExecutor - Result: 1; 16:26:00.662 INFO GermlineCNVCaller - Shutting down engine; [May 27, 2018 4:26:00 PM UTC] org.broadinstitute.hellbender.tools.copynumber.GermlineCNVCaller done. Elapsed time: 2,255.34 minutes.; Runtime.totalMemory()=8207728640; org.broadinstitute.hellbender.utils.python.PythonScriptExecutorException: ; python exited with 1; Command Line: python /tmp/shlee/cohort_denoising_calling.7832183760446168530.py --ploidy_calls_path=/home/shlee/gcnv/coverage_1k/hc24_soohee1kall_ploidy-calls --output_calls_path=/home/shlee/gcc/hc24_soohee1k_chr1-calls --modeling_interval_list=/tmp/shlee/intervals1147946183347323472.tsv --output_model_path=/home/shlee/gcc/hc24_soohee1k_chr1-model --enable_explicit_gc_bias_modeling=False --read_count_tsv_files /tmp/shlee/sample-04516283083315244626.tsv /tmp/shlee/sample-17497576995757363646.tsv /tmp/shlee/sample-21271002324475135098.tsv /tmp/shlee/sample-36985602309924438312.tsv /tmp/shlee/sample-44773997237633003175.tsv /tmp/shlee/sample-55563425618633690228.tsv /tmp/shlee/sample-66588087553393228850.tsv /tmp/shlee/",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4825:1135,down,down,1135,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4825,1,['down'],['down']
Availability,"/native/HDF5-prefix/src/HDF5/src/H5Fio.c line 120 in H5F_block_read(; ): read through metadata accumulator failed; major: Low-level I/O; minor: Read failed; #009: /mnt/scr1/abyrne/HDFJava-platypus-2.11/native/HDF5-prefix/src/HDF5/src/H5Faccum.c line 263 in H5F__accum_r; ead(): driver read request failed; major: Low-level I/O; minor: Read failed; #010: /mnt/scr1/abyrne/HDFJava-platypus-2.11/native/HDF5-prefix/src/HDF5/src/H5FDint.c line 204 in H5FD_read(): ; driver read request failed; major: Virtual File Layer; minor: Read failed; #011: /mnt/scr1/abyrne/HDFJava-platypus-2.11/native/HDF5-prefix/src/HDF5/src/H5FDsec2.c line 725 in H5FD_sec2_re; ad(): file read failed: time = Wed Apr 14 11:52:33 2021; , filename = '/SCRATCH-BIRD/users/lindenbaum-p/work/NEXTFLOW/20210411.GRCh37.gatkcnv.brs/work/92/579e5a48aa9e52cd0; e1df603266809/B00HOTD.counts.hdf5', file descriptor = 250, errno = 121, error message = 'Remote I/O error', buf = ; 0x2b6ebddf38e8, total read size = 384, bytes this sub-read = 384, bytes actually read = 18446744073709551615, offs; et = 712120; major: Low-level I/O; minor: Read failed; HDF5-DIAG: Error detected in HDF5 (1.8.14) thread 0:; #000: /mnt/scr1/abyrne/HDFJava-platypus-2.11/native/HDF5-prefix/src/HDF5/src/H5D.c line 826 in H5Dvlen_reclaim(); : invalid dataspace; major: Invalid arguments to routine; minor: Inappropriate type; 11:52:33.796 INFO GermlineCNVCaller - Shutting down engine; [April 14, 2021 11:52:33 AM CEST] org.broadinstitute.hellbender.tools.copynumber.GermlineCNVCaller done. Elapsed t; ime: 0.90 minutes.; Runtime.totalMemory()=2374500352; Exception in thread ""main"" java.lang.InternalError: H5DreadVL_str: failed to read variable length strings; 	at ncsa.hdf.hdf5lib.H5.H5DreadVL(Native Method); 	at org.broadinstitute.hdf5.HDF5File.lambda$readStringArray$0(HDF5File.java:161); 	at org.broadinstitute.hdf5.HDF5File.readDataset(HDF5File.java:349); 	at org.broadinstitute.hdf5.HDF5File.readStringArray(HDF5File.java:150); 	at org.broadinstitute.hel",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7202:3025,error,error,3025,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7202,3,"['Error', 'error']","['Error', 'error']"
Availability,"/warkre/miniconda3/envs/gatk4.1.4.0/bin/gatk:80: SyntaxWarning: ""is"" with a literal. Did you mean ""==""?; if len(args) is 0 or (len(args) is 1 and (args[0] == ""--help"" or args[0] == ""-h"")):; /home/warkre/miniconda3/envs/gatk4.1.4.0/bin/gatk:80: SyntaxWarning: ""is"" with a literal. Did you mean ""==""?; if len(args) is 0 or (len(args) is 1 and (args[0] == ""--help"" or args[0] == ""-h"")):; /home/warkre/miniconda3/envs/gatk4.1.4.0/bin/gatk:117: SyntaxWarning: ""is"" with a literal. Did you mean ""==""?; if len(args) is 1 and args[0] == ""--list"":; /home/warkre/miniconda3/envs/gatk4.1.4.0/bin/gatk:308: SyntaxWarning: ""is"" with a literal. Did you mean ""==""?; if call([""gsutil"", ""-q"", ""stat"", gcsjar]) is 0:; /home/warkre/miniconda3/envs/gatk4.1.4.0/bin/gatk:312: SyntaxWarning: ""is"" with a literal. Did you mean ""==""?; if call([""gsutil"", ""cp"", jar, gcsjar]) is 0:; /home/warkre/miniconda3/envs/gatk4.1.4.0/bin/gatk:467: SyntaxWarning: ""is not"" with a literal. Did you mean ""!=""?; if not len(properties) is 0:; /home/warkre/miniconda3/envs/gatk4.1.4.0/bin/gatk:471: SyntaxWarning: ""is not"" with a literal. Did you mean ""!=""?; if not len(filesToAdd) is 0:; Using GATK jar /home/warkre/miniconda3/envs/gatk4.1.4.0/share/gatk4-4.1.4.0-1/gatk-package-4.1.4.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /home/warkre/miniconda3/envs/gatk4.1.4.0/share/gatk4-4.1.4.0-1/gatk-package-4.1.4.0-local.jar FilterMutectCalls -V mu.2.vcf -R human_g1k_v37.main.fasta -O MT.filtered.vcf.gz --stats MT.vcf.gz.stats --mitochondria-mode; ```. The made-up VCF contains a single variant:; ```; MT 100 . G C . . DP=3;ECNT=3;MBQ=0,10;MFRL=0,10;MMQ=10,10;MPOS=10;OCM=0;POPAF=3.40;RPA=5,6;RU=C;STR;TLOD=5.88 GT:AD:AF:DP:F1R2:F2R1:SB 0/1:0,2:0.750:2:0,1:0,1:0,0,0,2; ```. The stats file contains the lines:; ```; statistic	value; callable	0.0; ```. I hope this is enough to reproduce the error.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6255:15492,error,error,15492,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6255,1,['error'],['error']
Availability,"0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|1	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0; ```; Running `$HOME/gatk-4.0.11.0/gatk --java-options ""-Xmx4g"" HaplotypeCaller -R $HOME/GRCh37files/hs37d5.fa -I /mnt/fast/test.bam -O test.out.vcf.gz -L 22 --genotyping-mode GENOTYPE_GIVEN_ALLELES --alleles test.vcf.gz`, the resulting error is:; ```; java.lang.IllegalStateException: Allele in genotype GGTTTGTTT not in the variant context [GGTTTGTTT*, GGTTTGTTTGTTT, GGTTTGTTTGTTTGTTT, G]; at htsjdk.variant.variantcontext.VariantContext.validateGenotypes(VariantContext.java:1360); at htsjdk.variant.variantcontext.VariantContext.validate(VariantContext.java:1298); at htsjdk.variant.variantcontext.VariantContext.<init>(VariantContext.java:401); at htsjdk.variant.variantcontext.VariantContextBuilder.make(VariantContextBuilder.java:494); at htsjdk.variant.variantcontext.VariantContextBuilder.make(VariantContextBuilder.java:488); at org.broadinstitute.hellbender.utils.variant.GATKVariantContextUtils.simpleMerge(GATKVariantContextUtils.java:864); at org.broadinstitute.hellbender.utils.variant.GATKVariantContextUtils.simpleMerge(GATKVariantContextUtils.java:646); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.AssemblyBasedCallerUtils.makeMergedVariantContext(AssemblyBasedCallerUtils.java:228); at org.broadinst",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5355:40982,error,error,40982,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5355,1,['error'],['error']
Availability,"0 ALT contigs; OpenJDK 64-Bit Server VM warning: INFO: os::commit_memory(0x0000000715180000, 719847424, 0) failed; error='Cannot allocate memory' (errno=12). #; # There is insufficient memory for the Java Runtime Environment to continue.; # Native memory allocation (mmap) failed to map 719847424 bytes for committing reserved memory.; # An error report file with more information is saved as:; # /home/travis/build/broadinstitute/gatk/hs_err_pid11513.log; ```. ```; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x00007f27ebfe7d9a, pid=11455, tid=0x00007f27e87e5700; #; # JRE version: OpenJDK Runtime Environment (8.0_111-b14) (build 1.8.0_111-8u111-b14-3~14.04.1-b14); # Java VM: OpenJDK 64-Bit Server VM (25.111-b14 mixed mode linux-amd64 compressed oops); # Problematic frame:; # C [libfml.6198146539708364717.jnilib+0xed9a] rld_itr_init+0x4a; ```. ```; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x00007fd2680a350c, pid=11685, tid=0x00007fd2b02bf700; #; # JRE version: OpenJDK Runtime Environment (8.0_111-b14) (build 1.8.0_111-8u111-b14-3~14.04.1-b14); # Java VM: OpenJDK 64-Bit Server VM (25.111-b14 mixed mode linux-amd64 compressed oops); # Problematic frame:; # C [libbwa.5694772191018335324.jnilib+0x850c] bwa_mem2idx+0xcc; ```. The underlying issue in these cases is likely either ""out of memory"" or, perhaps in the case of the seg faults, ""file not found"" or ""malformed file"", but we could greatly improve our ability to interpret Travis failures if we were more careful about checking return values from system calls. Eg., in the function below from the BWA bindings we could check the return values of the `mmap()` and `calloc()` calls, and die with an appropriate error message if they fail:. ```; bwaidx_t* jnibwa_openIndex( int fd ) {; struct stat statBuf;; if ( fstat(fd, &statBuf) == -1 ) return 0;; uint8_t* mem = mmap(0, statBuf.st_size, PROT_READ, MAP_SHARED, fd, 0);; close(fd);; ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3209:1449,error,error,1449,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3209,1,['error'],['error']
Availability,"0 INFO IntelPairHmm - Available threads: 1; 17:08:13.260 INFO IntelPairHmm - Requested threads: 4; 17:08:13.261 WARN IntelPairHmm - Using 1 available threads, but 4 were requested; 17:08:13.261 INFO PairHMM - Using the OpenMP multi-threaded AVX-accelerated native PairHMM implementation; 17:08:13.346 INFO ProgressMeter - Starting traversal; 17:08:13.346 INFO ProgressMeter - Current Locus Elapsed Minutes Regions Processed Regions/Minute; 17:08:17.401 WARN InbreedingCoeff - InbreedingCoeff will not be calculated; at least 10 samples must have called genotypes. 17:08:43.866 INFO ProgressMeter - chr1:1053465 0.5 3780 7431.7. ...Many lines in between and then... 19:11:09.189 INFO VectorLoglessPairHMM - Time spent in setup for JNI call : 1.190328316; 19:11:09.189 INFO PairHMM - Total compute time in PairHMM computeLogLikelihoods() : 398.5135636; 19:11:09.190 INFO SmithWatermanAligner - Total compute time in java Smith-Waterman : 258.73 sec; 19:11:09.190 INFO HaplotypeCaller - Shutting down engine; [August 27, 2020 7:11:09 PM CDT] org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCaller done. Elapsed time: 122.97 minutes.; Runtime.totalMemory()=2764046336; java.lang.NullPointerException; at org.broadinstitute.hellbender.engine.AssemblyRegion.getReference(AssemblyRegion.java:309); at org.broadinstitute.hellbender.engine.AssemblyRegion.getAssemblyRegionReference(AssemblyRegion.java:330); at org.broadinstitute.hellbender.engine.AssemblyRegion.getAssemblyRegionReference(AssemblyRegion.java:316); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.AssemblyBasedCallerUtils.createReferenceHaplotype(AssemblyBasedCallerUtils.java:175); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerEngine.referenceModelForNoVariation(HaplotypeCallerEngine.java:688); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerEngine.callRegion(HaplotypeCallerEngine.java:522); at org.broadinstitute.hellbender.tools.walkers.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6783:4461,down,down,4461,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6783,1,['down'],['down']
Availability,"0-All.vcf.gz.tbi is out of date (index older than input file). Use IndexFeatureFile to make a new index. ; ; 14:50:13.556 WARN IndexUtils - Feature file ""/mnt/d/GenLab/WES/db/00-common\_all.vcf.gz"" appears to contain no sequence dictionary. Attempting to retrieve a sequence dictionary from the associated index file ; ; 14:50:13.609 WARN IndexUtils - Index file /mnt/d/GenLab/WES/db/00-common\_all.vcf.gz.tbi is out of date (index older than input file). Use IndexFeatureFile to make a new index. ; ; 14:50:13.615 INFO FilterVariantTranches - Done initializing engine ; ; 14:50:13.638 INFO ProgressMeter - Starting traversal ; ; 14:50:13.639 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute ; ; 14:50:13.642 INFO FilterVariantTranches - Starting pass 0 through the variants ; ; 14:50:13.857 INFO FilterVariantTranches - Filtered 0 SNPs out of 4 and filtered 0 indels out of 0 with INFO score: CNN\_2D. ; ; 14:50:13.871 INFO FilterVariantTranches - Shutting down engine ; ; \[July 6, 2020 2:50:13 PM MSK\] org.broadinstitute.hellbender.tools.walkers.vqsr.FilterVariantTranches done. Elapsed time: 0.02 minutes. ; ; Runtime.totalMemory()=721944576 ; ; htsjdk.tribble.TribbleException: The provided reference alleles do not appear to represent the same position, C\* vs. T\* ; ; at org.broadinstitute.hellbender.utils.variant.GATKVariantContextUtils.determineReferenceAllele(GATKVariantContextUtils.java:209) ; ; at org.broadinstitute.hellbender.utils.variant.GATKVariantContextUtils.isAlleleInList(GATKVariantContextUtils.java:164) ; ; at org.broadinstitute.hellbender.tools.walkers.vqsr.FilterVariantTranches.firstPassApply(FilterVariantTranches.java:187) ; ; at org.broadinstitute.hellbender.engine.TwoPassVariantWalker.nthPassApply(TwoPassVariantWalker.java:17) ; ; at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverse$0(MultiplePassVariantWalker.java:40) ; ; at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6701:6596,down,down,6596,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6701,1,['down'],['down']
Availability,"0.100;MQ=60.00;MQRankSum=0.000;QD=0.46;ReadPosRankSum=-0.300;SOR=2.792 GT:AD:DP:GQ:PL 0/0/0/0/0/0/0/0/0/1:85,3:88:34:66,0,34,78,132,196,276,380,528,782,6199; contig00001 8244 . T C 43.68 . AC=1;AF=0.100;AN=10;BaseQRankSum=-0.838;ClippingRankSum=0.000;DP=80;FS=15.529;MLEAC=1;MLEAF=0.100;MQ=60.00;MQRankSum=0.000;QD=0.55;ReadPosRankSum=-1.716;SOR=2.783 GT:AD:DP:GQ:PL 0/0/0/0/0/0/0/0/0/1:77,3:80:31:69,0,31,71,119,178,251,347,482,716,5872; contig00001 8846 . C T 72.68 . AC=1;AF=0.100;AN=10;BaseQRankSum=0.659;ClippingRankSum=0.000;DP=88;FS=2.385;MLEAC=1;MLEAF=0.100;MQ=59.93;MQRankSum=0.273;QD=0.83;ReadPosRankSum=-4.696;SOR=1.102 GT:AD:DP:GQ:PL 0/0/0/0/0/0/0/0/0/1:84,4:88:31:98,0,31,72,124,186,264,366,510,759,3392; contig00001 9854 . A G 42.69 . AC=1;AF=0.100;AN=10;BaseQRankSum=0.463;ClippingRankSum=0.000;DP=79;FS=11.687;MLEAC=1;MLEAF=0.100;MQ=60.00;MQRankSum=0.000;QD=0.55;ReadPosRankSum=1.267;SOR=2.799 GT:AD:DP:GQ:PL 0/0/0/0/0/0/0/0/0/1:74,3:77:29:68,0,29,66,111,166,235,324,450,665,2970; contig00001 19796 . A G 34.70 . AC=1;AF=0.100;AN=10;BaseQRankSum=-2.543;ClippingRankSum=0.000;DP=66;FS=10.825;MLEAC=1;MLEAF=0.100;MQ=60.00;MQRankSum=0.000;QD=0.53;ReadPosRankSum=-0.600;SOR=0.829 GT:AD:DP:GQ:PL 0/0/0/0/0/0/0/0/0/1:63,3:66:23:60,0,23,54,93,140,199,275,384,572,2745; contig00001 20699 . T C 47.70 . AC=1;AF=0.100;AN=10;BaseQRankSum=0.326;ClippingRankSum=0.000;DP=66;FS=2.442;MLEAC=1;MLEAF=0.1; ```. When I run . ```gatk VariantFiltration -V GenomeA.rawSNPs.vcf -filter ""QD < 20.0"" --filter-name ""snp_def"" -O test.vcf```. or. ```gatk VariantFiltration -R ../GenomeA_contigs.fa -V GenomeA.rawSNPs.vcf -filter ""QD < 20.0"" --filter-name ""snp_def"" -O test.vcf```. I get the following error:. ```A USER ERROR has occurred: Invalid argument '>'.```. I tried to use different operators and style ```""""``` rather than ```''``` but the error is still the same.; I was hoping that there is a mistake in my code but it seems to be a bug to me.; I run on a HPC with a slurm managing system. ; Thank you",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6241:1975,error,error,1975,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6241,3,"['ERROR', 'error']","['ERROR', 'error']"
Availability,0.433 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.execute(ExecuteActionsTaskExecuter.java:68); 11:54:40.433 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.SkipUpToDateTaskExecuter.execute(SkipUpToDateTaskExecuter.java:62); 11:54:40.433 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.ValidatingTaskExecuter.execute(ValidatingTaskExecuter.java:58); 11:54:40.433 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.SkipEmptySourceFilesTaskExecuter.execute(SkipEmptySourceFilesTaskExecuter.java:88); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.ResolveTaskArtifactStateTaskExecuter.execute(ResolveTaskArtifactStateTaskExecuter.java:46); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.SkipTaskWithNoActionsExecuter.execute(SkipTaskWithNoActionsExecuter.java:51); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.SkipOnlyIfTaskExecuter.execute(SkipOnlyIfTaskExecuter.java:54); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.ExecuteAtMostOnceTaskExecuter.execute(ExecuteAtMostOnceTaskExecuter.java:43); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.CatchExceptionTaskExecuter.execute(CatchExceptionTaskExecuter.java:34); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.taskgraph.DefaultTaskGraphExecuter$EventFiringTaskWorker$1.execute(DefaultTaskGraphExecuter.java:236); 11:54:40.434 [ERROR] [org.gradle,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2802:1647,ERROR,ERROR,1647,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2802,1,['ERROR'],['ERROR']
Availability,"0.805 INFO GenomicsDBImport - Callset Map JSON file will be written to /lustre/data_single_cell/sperm1/mydatabase/callset.json; > 21:21:20.805 INFO GenomicsDBImport - Complete VCF Header will be written to /lustre/data_single_cell/sperm1/mydatabase/vcfheader.vcf; > 21:21:20.805 INFO GenomicsDBImport - Importing to array - /lustre/data_single_cell/sperm1/mydatabase/genomicsdb_array; > 21:21:20.805 INFO ProgressMeter - Starting traversal; > 21:21:20.805 INFO ProgressMeter - Current Locus Elapsed Minutes Batches Processed Batches/Minute; > 21:21:22.001 INFO GenomicsDBImport - Importing batch 1 with 2 samples; > 21:22:18.128 INFO ProgressMeter - chr22:1 1.0 1 1.0; > 21:22:18.128 INFO GenomicsDBImport - Done importing batch 1/1; > 21:22:18.129 INFO ProgressMeter - chr22:1 1.0 1 1.0; > 21:22:18.129 INFO ProgressMeter - Traversal complete. Processed 1 total batches in 1.0 minutes.; > 21:22:18.129 INFO GenomicsDBImport - Import completed!; > 21:22:18.129 INFO GenomicsDBImport - Shutting down engine; > [May 25, 2020 9:22:18 PM CST] org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImport done. Elapsed time: 1.01 minutes.; > Runtime.totalMemory()=1821900800; > Tool returned:; > true. This is the result of GenomicsDBImport. -[ 201] callset.json; -[4.0K] chr22$1$50818468; |-[4.0K] __3d7b0c29-9d8b-4748-a08a-c1e0a9136cf647572466251520_1590412882146; ||-[133K] AD.tdb; ||-[ 54K] AD_var.tdb; ||-[3.2M] ALT.tdb; ||-[ 77K] ALT_var.tdb; ||-[ 85K] BaseQRankSum.tdb; ||-[192K] __book_keeping.tdb.gz; ||-[4.1M] __coords.tdb; ||-[1011K] DP_FORMAT.tdb; ||-[114K] DP.tdb; ||-[3.5M] END.tdb; ||-[108K] ExcessHet.tdb; ||-[ 64K] FILTER.tdb; ||-[ 0] FILTER_var.tdb; ||-[1.1M] GQ.tdb; ||-[2.9M] GT.tdb; ||-[120K] GT_var.tdb; ||-[ 64K] ID.tdb; ||-[ 0] ID_var.tdb; ||-[ 64K] InbreedingCoeff.tdb; ||-[1.0M] MIN_DP.tdb; ||-[128K] MLEAC.tdb; ||-[ 32K] MLEAC_var.tdb; ||-[128K] MLEAF.tdb; ||-[ 36K] MLEAF_var.tdb; ||-[ 82K] MQRankSum.tdb; ||-[ 98K] PGT.tdb; ||-[5.8K] PGT_var.tdb; ||-[ 99K] PID.tdb; ||-[ 15",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6627:7285,down,down,7285,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6627,1,['down'],['down']
Availability,0.bam --reference /Users/shlee/Documents/ref/hg38/Homo_sapiens_assembly38.fasta --genotypePonSites false --af_of_alleles_not_in_resource 0.001 --log_somatic_prior -6.0 --tumor_lod_to_emit 3.0 --initial_tumor_lod 2.0 --max_population_af 0.01 --normal_lod 2.2 --annotation Coverage --annotation DepthPerAlleleBySample --annotation TandemRepeat --annotation OxoGReadCounts --annotation ClippedBases --annotation ReadPosition --annotation BaseQuality --annotation MappingQuality --annotation FragmentLength --annotation StrandArtifact --dontTrimActiveRegions false --maxDiscARExtension 25 --maxGGAARExtension 300 --paddingAroundIndels 150 --paddingAroundSNPs 20 --kmerSize 10 --kmerSize 25 --dontIncreaseKmerSizesForCycles false --allowNonUniqueKmersInRef false --numPruningSamples 1 --recoverDanglingHeads false --doNotRecoverDanglingBranches false --minDanglingBranchLength 4 --consensus false --maxNumHaplotypesInPopulation 128 --errorCorrectKmers false --minPruning 2 --debugGraphTransformations false --kmerLengthForReadErrorCorrection 25 --minObservationsForKmerToBeSolid 20 --likelihoodCalculationEngine PairHMM --base_quality_score_threshold 18 --gcpHMM 10 --pair_hmm_implementation FASTEST_AVAILABLE --pcr_indel_model CONSERVATIVE --phredScaledGlobalReadMismappingRate 45 --nativePairHmmThreads 4 --useDoublePrecision false --debug false --useFilteredReadsForAnnotations false --emitRefConfidence NONE --bamWriterType CALLED_HAPLOTYPES --disableOptimizations false --justDetermineActiveRegions false --dontGenotype false --dontUseSoftClippedBases false --captureAssemblyFailureBAM false --errorCorrectReads false --doNotRunPhysicalPhasing false --min_base_quality_score 10 --useNewAFCalculator false --annotateNDA false --heterozygosity 0.001 --indel_heterozygosity 1.25E-4 --heterozygosity_stdev 0.01 --standard_min_confidence_threshold_for_calling 10.0 --max_alternate_alleles 6 --max_genotype_count 1024 --sample_ploidy 2 --genotyping_mode DISCOVERY --contamination_fraction_to_filter 0.0 --o,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3514:2857,recover,recoverDanglingHeads,2857,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3514,3,"['error', 'recover']","['errorCorrectKmers', 'errorCorrectReads', 'recoverDanglingHeads']"
Availability,"00 --conf spark.driver.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Djava.io.tmpdir=tmp --conf spark.executor.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Djava.io.tmpdir=tmp --deploy-mode client --executor-memory 80G --driver-memory 30g --num-executors 40 --executor-cores 4 --conf spark.yarn.submit.waitAppCompletion=false --name A-ACT-AC000014-BL-NCR-15AD78694.hg38.realign.bqsr --files file:///restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa.img,file:///restricted/projectnb/casa/ref/GRCh38_ignored_kmers.txt --conf spark.yarn.executor.memoryOverhead=5000 --conf spark.network.timeout=600 --conf spark.executor.heartbeatInterval=120 /share/pkg/gatk/4.1.0.0/install/bin/gatk-package-4.1.0.0-spark.jar StructuralVariationDiscoveryPipelineSpark -R file:///restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa --aligner-index-image GRCh38_full_analysis_set_plus_decoy_hla.fa.img --kmers-to-ignore GRCh38_ignored_kmers.txt --contig-sam-file hdfs:///project/casa/gcad/adsp.cc/sv//A-ACT-AC000014-BL-NCR-15AD78694.hg38.realign.bqsr.contig-sam-file -I hdfs:///project/casa/gcad/adsp.cc/cram/A-ACT-AC000014-BL-NCR-15AD78694.hg38.realign.bqsr.cram -O hdfs:///project/casa/gcad/adsp.cc/sv/A-ACT-AC000014-BL-NCR-15AD78694.hg38.realign.bqsr.sv.vcf --spark-master yarn. ```. #### Expected behavior. Run to completion with SV vcf output. #### Actual behavior. ```; 2019-02-17 16:25:48 INFO TaskSetManager:54 - Finished task 85.0 in stage 5.0 (TID 1031) in 28293 ms on scc-q09.scc.bu.edu (executor 30) (74/189); 2019-02-17 16:25:48 INFO BlockManagerInfo:54 - Removed taskresult_1031 on scc-q09.scc.bu.edu:40204 in memory (size: ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5685:2339,heartbeat,heartbeatInterval,2339,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5685,1,['heartbeat'],['heartbeatInterval']
Availability,"00     GT:AD:DP        0/0:37:37 ; ; chr5    125895106       .       G       .       73.78   .       AN=2;DP=28;MQ=60.00     GT:AD:DP        0/0:28:28 ; ; chr5    125895113       .       G       .       68.78   .       AN=2;DP=25;MQ=60.00     GT:AD:DP        0/0:25:25. Position 125894866 is present in the --alleles file, and is genotyped correctrly as homozygous reference in the current sample. The following three positions are not present in the --alleles file, and do not contain an ALT allele in the output file ( dot for ALT).   without '--alleles', these positions are not outputted. . Is this expected behaviour, and if so, why are they emitted ?. notes : ; ; \- same output is observed without threading , ; ; \- same output is observed without dragen mode.  ; ; \-  --alleles is taken from a normal HC run.  ; ; \-  roughly the same heterozygous calls & hom.ALT calls are made with/without --alleles (which is expected behaviour). \=======================. REQUIRED for all errors and issues: ; ; a) GATK version used: 4.2.5.0. b) Exact command used:. gatk --java-options ""-Djava.io.tmpdir=/tmp -Xmx3g"" HaplotypeCaller \\ ; ;   -R /home/gvandeweyer/elprep\_streaming/reference/hg19.fasta \\ ; ;   -I /home/gvandeweyer/elprep\_streaming/results/wesep-229191-f.bam \\ ; ;   -O results/wesep-229191-f.vcf \\ ; ;   --alleles affected\_alleles.vcf \\ ; ;   -L 0005-scattered.interval\_list \\ ; ;   -bamout results/wesep-229191-f.variants.bam \\ ; ;   -G StandardAnnotation -G StandardHCAnnotation \\ ; ;   --dragen-mode \\ ; ;   --dragstr-params-path /home/gvandeweyer/elprep\_streaming/results/wesep-229191-f.bam.params \\ ; ;   --native-pair-hmm-threads 2.   ; ; c) Entire program log:. (ELPREP) gvandeweyer@ngsvm-pipelines:~/elprep\_streaming/VariantCalling\_Test/scattered$ gatk --java-options ""-Djava.io.tmpdir=/tmp -Xmx3g"" HaplotypeCaller    -R /home/gvandeweyer/elprep\_streaming/reference/hg19.fasta    -I /home/gvandeweyer/elprep\_streaming/results/wesep- ; ; 229191-f.bam    -O resul",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7741:1805,error,errors,1805,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7741,1,['error'],['errors']
Availability,"008v2_random:7168-7691 Q. of type=SYMBOLIC alleles=[T*, <NON_REF>] attr={END=7691} GT=[[NA12878 T*/T* GQ 0 DP 0 PL 0,0,0 {MIN_DP=0}]] filters= added out of order currentReferenceIndex: 25, referenceIndex:37; at htsjdk.tribble.index.tabix.AllRefsTabixIndexCreator.addFeature(AllRefsTabixIndexCreator.java:79); at htsjdk.variant.variantcontext.writer.IndexingVariantContextWriter.add(IndexingVariantContextWriter.java:203); at htsjdk.variant.variantcontext.writer.VCFWriter.add(VCFWriter.java:242); at org.disq_bio.disq.impl.formats.vcf.HeaderlessVcfOutputFormat$VcfRecordWriter.write(HeaderlessVcfOutputFormat.java:93); at org.disq_bio.disq.impl.formats.vcf.HeaderlessVcfOutputFormat$VcfRecordWriter.write(HeaderlessVcfOutputFormat.java:56); at org.apache.spark.internal.io.HadoopMapReduceWriteConfigUtil.write(SparkHadoopWriter.scala:358); at org.apache.spark.internal.io.SparkHadoopWriter$$anonfun$4.apply(SparkHadoopWriter.scala:132); at org.apache.spark.internal.io.SparkHadoopWriter$$anonfun$4.apply(SparkHadoopWriter.scala:129); at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1394); at org.apache.spark.internal.io.SparkHadoopWriter$.org$apache$spark$internal$io$SparkHadoopWriter$$executeTask(SparkHadoopWriter.scala:141); ... 10 more; 21/04/13 07:32:25 INFO SparkUI: Stopped Spark web UI at http://wgs-cntech-online-it:4040; 21/04/13 07:32:25 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 21/04/13 07:32:25 INFO MemoryStore: MemoryStore cleared; 21/04/13 07:32:25 INFO BlockManager: BlockManager stopped; 21/04/13 07:32:25 INFO BlockManagerMaster: BlockManagerMaster stopped; 21/04/13 07:32:25 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 21/04/13 07:32:25 INFO SparkContext: Successfully stopped SparkContext; 07:32:25.095 INFO HaplotypeCallerSpark - Shutting down engine; ```. ### Affected tool(s) or class(es); HaplotypeCallerSpark. ### Affected version(s); - gatk-4.1.9.0",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7199:24005,down,down,24005,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7199,1,['down'],['down']
Availability,"00:05:56.230 info NativeGenomicsDB - pid=40375 tid=40376 No valid combination operation found for INFO field SOR - the field will NOT be part of INFO fields in the generated VCF records; 00:05:56.776 INFO IntervalArgumentCollection - Processing 105581 bp from intervals; 00:05:56.847 INFO GenotypeGVCFs - Done initializing engine; 00:05:57.036 INFO ProgressMeter - Starting traversal; 00:05:57.036 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 00:07:26.967 WARN ReferenceConfidenceVariantContextMerger - Detected invalid annotations: When trying to merge variant contexts at location chr16:10185 the annotation AS_VarDP=59|115|0 was not a numerical value and was ignored; 00:07:26.967 WARN ReferenceConfidenceVariantContextMerger - Reducible annotation 'AS_VarDP' detected, add -G StandardAnnotation -G AS_StandardAnnotation to the command to annotate in the final VC with this annotation.; 00:07:26.991 INFO GenotypeGVCFs - Shutting down engine; GENOMICSDB_TIMER,GenomicsDB iterator next() timer,Wall-clock time(s),0.02938786500000001,Cpu time(s),0.029037034000000003; [August 25, 2021 12:07:27 AM EDT] org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs done. Elapsed time: 1.55 minutes.; Runtime.totalMemory()=1807745024; java.lang.NullPointerException; at java.util.HashMap.putMapEntries(HashMap.java:500); at java.util.HashMap.putAll(HashMap.java:784); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorEngine.combineAnnotations(VariantAnnotatorEngine.java:211); at org.broadinstitute.hellbender.tools.walkers.ReferenceConfidenceVariantContextMerger.mergeAttributes(ReferenceConfidenceVariantContextMerger.java:318); at org.broadinstitute.hellbender.tools.walkers.ReferenceConfidenceVariantContextMerger.merge(ReferenceConfidenceVariantContextMerger.java:142); at org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFsEngine.callRegion(GenotypeGVCFsEngine.java:130); at org.broadinstitute.hellbender.tools.walkers.Genotype",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7437:7691,down,down,7691,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7437,1,['down'],['down']
Availability,"01405.15_GRCh38/seqs_for_alignment_pipelines.ucsc_ids/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz | \; gzip -d > GCA_000001405.15_GRCh38_no_alt_analysis_set.fna. samtools faidx GCA_000001405.15_GRCh38_no_alt_analysis_set.fna. java -jar picard.jar \; CreateSequenceDictionary \; R=GCA_000001405.15_GRCh38_no_alt_analysis_set.fna \; O=GCA_000001405.15_GRCh38_no_alt_analysis_set.dict. (echo ""##fileformat=VCFv4.2""; \; echo ""##contig=<ID=chrX,length=156040895>""; \; echo -e ""#CHROM\tPOS\tID\tREF\tALT\tQUAL\tFILTER\tINFO""; \; echo -e ""chrX\t1052617\t.\tC\tCAAAGGCTGCAATGTGAATGAATTTTTGGAAATAGCCCTAATGCTCATCTATGAAGGAGTGATAAACACAGCATCCTTTATCCATGCAATGGAATATTATGCAGTCTAGAAAAGGAATAAGGCTCTGACAAAAGACTGCAATATGTATGAATTTTGGAAACAGCCCTACTGCCCATCTATAAAGGAATGGATAAACACAGCATAGTTCATCTATACAATGCAATATTATAATGGAATATTATGCAGCCTGGAACAGGAACAAGGCTCTGAG\t.\t.\t."") | \; bgzip > input.vcf.gz; \; tabix -f input.vcf.gz. (echo -e ""@HD\tVN:1.6\tGO:none\tSO:coordinate""; \; echo -e ""@SQ\tSN:chrX\tLN:156040895""; \; echo -e ""@RG\tID:ID\tPL:ILLUMINA\tPU:ID\tLB:LIBRARY\tSM:SAMPLE"") | \; samtools view -Sb -o input.bam; \; samtools index input.bam. gatk-4.1.2.0/gatk HaplotypeCaller \; -R GCA_000001405.15_GRCh38_no_alt_analysis_set.fna \; -I input.bam \; -O output.vcf.gz \; --genotyping-mode GENOTYPE_GIVEN_ALLELES \; --alleles input.vcf.gz; ```. I get the following error:. ```; java.lang.IllegalArgumentException: Cigar cannot be null; 	at org.broadinstitute.hellbender.utils.read.AlignmentUtils.consolidateCigar(AlignmentUtils.java:716); 	at org.broadinstitute.hellbender.utils.haplotype.Haplotype.setCigar(Haplotype.java:193); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.AssemblyBasedCallerUtils.addGivenAlleles(AssemblyBasedCallerUtils.java:350); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.AssemblyBasedCallerUtils.assembleReads(AssemblyBasedCallerUtils.java:291); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerEngine.callRegion(HaplotypeCallerEngine",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6037:1299,echo,echo,1299,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6037,2,['echo'],['echo']
Availability,01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr11_KI270721v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_GL000009v2_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_GL000225v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_KI270722v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_GL000194v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_KI270723v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_KI270724v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_KI270725v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_KI270726v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr15_KI270727v1_ran,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4840:5382,reliab,reliable,5382,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4840,1,['reliab'],['reliable']
Availability,01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_GL000009v2_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_GL000225v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_KI270722v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_GL000194v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_KI270723v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_KI270724v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_KI270725v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_KI270726v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr15_KI270727v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr16_KI270728v1_ran,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4840:5592,reliab,reliable,5592,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4840,1,['reliab'],['reliable']
Availability,01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_GL000194v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_KI270723v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_KI270724v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_KI270725v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_KI270726v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr15_KI270727v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr16_KI270728v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr17_GL000205v2_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr17_KI270729v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr17_KI270730v1_ran,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4840:6222,reliab,reliable,6222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4840,1,['reliab'],['reliable']
Availability,01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_GL000225v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_KI270722v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_GL000194v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_KI270723v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_KI270724v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_KI270725v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_KI270726v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr15_KI270727v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr16_KI270728v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr17_GL000205v2_ran,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4840:5802,reliab,reliable,5802,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4840,1,['reliab'],['reliable']
Availability,01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_KI270722v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_GL000194v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_KI270723v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_KI270724v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_KI270725v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_KI270726v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr15_KI270727v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr16_KI270728v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr17_GL000205v2_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr17_KI270729v1_ran,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4840:6012,reliab,reliable,6012,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4840,1,['reliab'],['reliable']
Availability,01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_KI270723v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_KI270724v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_KI270725v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_KI270726v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr15_KI270727v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr16_KI270728v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr17_GL000205v2_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr17_KI270729v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr17_KI270730v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.384 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr22_KI270731v1_ran,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4840:6432,reliab,reliable,6432,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4840,1,['reliab'],['reliable']
Availability,01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_KI270724v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_KI270725v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_KI270726v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr15_KI270727v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr16_KI270728v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr17_GL000205v2_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr17_KI270729v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr17_KI270730v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.384 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr22_KI270731v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.384 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr22_KI270732v1_ran,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4840:6642,reliab,reliable,6642,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4840,1,['reliab'],['reliable']
Availability,01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_KI270725v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_KI270726v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr15_KI270727v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr16_KI270728v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr17_GL000205v2_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr17_KI270729v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr17_KI270730v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.384 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr22_KI270731v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.384 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr22_KI270732v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.384 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr22_KI270733v1_ran,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4840:6852,reliab,reliable,6852,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4840,1,['reliab'],['reliable']
Availability,01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_KI270726v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr15_KI270727v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr16_KI270728v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr17_GL000205v2_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr17_KI270729v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr17_KI270730v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.384 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr22_KI270731v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.384 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr22_KI270732v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.384 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr22_KI270733v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.384 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr22_KI270734v1_ran,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4840:7062,reliab,reliable,7062,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4840,1,['reliab'],['reliable']
Availability,01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr15_KI270727v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr16_KI270728v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr17_GL000205v2_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr17_KI270729v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr17_KI270730v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.384 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr22_KI270731v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.384 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr22_KI270732v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.384 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr22_KI270733v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.384 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr22_KI270734v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.384 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr22_KI270735v1_ran,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4840:7272,reliab,reliable,7272,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4840,1,['reliab'],['reliable']
Availability,01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr16_KI270728v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr17_GL000205v2_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr17_KI270729v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr17_KI270730v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.384 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr22_KI270731v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.384 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr22_KI270732v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.384 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr22_KI270733v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.384 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr22_KI270734v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.384 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr22_KI270735v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.384 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr22_KI270736v1_ra;,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4840:7482,reliab,reliable,7482,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4840,1,['reliab'],['reliable']
Availability,"01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr17_GL000205v2_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr17_KI270729v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr17_KI270730v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.384 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr22_KI270731v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.384 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr22_KI270732v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.384 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr22_KI270733v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.384 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr22_KI270734v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.384 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr22_KI270735v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.384 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr22_KI270736v1_ra; Stderr: Traceback (most recent call last):; File ""/home/shlee/anaconda3/envs/gatk/lib/python3.6/site-packages/theano/compile/function_module.py"", line 884, in __call__; self.fn() if output_subset is None else\",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4840:7692,reliab,reliable,7692,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4840,1,['reliab'],['reliable']
Availability,"01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr17_KI270729v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr17_KI270730v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.384 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr22_KI270731v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.384 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr22_KI270732v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.384 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr22_KI270733v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.384 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr22_KI270734v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.384 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr22_KI270735v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.384 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr22_KI270736v1_ra; Stderr: Traceback (most recent call last):; File ""/home/shlee/anaconda3/envs/gatk/lib/python3.6/site-packages/theano/compile/function_module.py"", line 884, in __call__; self.fn() if output_subset is None else\; File ""/home/shlee/anaconda3/envs/gatk/lib/python3.6/site-packages/theano/scan_module/scan_op.py"", line 989, in rval; r = p(n, [x[0] for x in i], o); File ""/home/shlee/anaconda3/envs/gatk/lib/python3.6/site-pa",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4840:7902,reliab,reliable,7902,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4840,1,['reliab'],['reliable']
Availability,"01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr17_KI270730v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.384 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr22_KI270731v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.384 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr22_KI270732v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.384 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr22_KI270733v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.384 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr22_KI270734v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.384 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr22_KI270735v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.384 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr22_KI270736v1_ra; Stderr: Traceback (most recent call last):; File ""/home/shlee/anaconda3/envs/gatk/lib/python3.6/site-packages/theano/compile/function_module.py"", line 884, in __call__; self.fn() if output_subset is None else\; File ""/home/shlee/anaconda3/envs/gatk/lib/python3.6/site-packages/theano/scan_module/scan_op.py"", line 989, in rval; r = p(n, [x[0] for x in i], o); File ""/home/shlee/anaconda3/envs/gatk/lib/python3.6/site-packages/theano/scan_module/scan_op.py"", line 978, in p; self, node); File ""theano/scan_module/scan_perform.pyx"", line 215, in theano.scan_module.scan_perform.perform (/home/shlee/.theano/compiledir_Linux-4.13--g",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4840:8112,reliab,reliable,8112,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4840,1,['reliab'],['reliable']
Availability,"01:54.384 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr22_KI270731v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.384 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr22_KI270732v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.384 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr22_KI270733v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.384 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr22_KI270734v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.384 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr22_KI270735v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.384 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr22_KI270736v1_ra; Stderr: Traceback (most recent call last):; File ""/home/shlee/anaconda3/envs/gatk/lib/python3.6/site-packages/theano/compile/function_module.py"", line 884, in __call__; self.fn() if output_subset is None else\; File ""/home/shlee/anaconda3/envs/gatk/lib/python3.6/site-packages/theano/scan_module/scan_op.py"", line 989, in rval; r = p(n, [x[0] for x in i], o); File ""/home/shlee/anaconda3/envs/gatk/lib/python3.6/site-packages/theano/scan_module/scan_op.py"", line 978, in p; self, node); File ""theano/scan_module/scan_perform.pyx"", line 215, in theano.scan_module.scan_perform.perform (/home/shlee/.theano/compiledir_Linux-4.13--gcp-x86_64-with-debian-stretch-sid-x86_64-3.6.2-64/scan_perform/mod.cpp:2628); NotImplementedError: We didn't implemented yet the case where scan do 0 iteration. During handling of the above exception, another e",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4840:8322,reliab,reliable,8322,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4840,1,['reliab'],['reliable']
Availability,"02 59335904 target_189887_IL9R NaN; Y 59335905 59336289 target_189888_IL9R NaN; Y 59336290 59336776 target_189889_IL9R NaN; Y 59336840 59337486 target_189890_IL9R NaN; Y 59337698 59338400 target_189891_IL9R NaN; Y 59338503 59339109 target_189892_IL9R NaN; Y 59339943 59340528 target_189893_IL9R NaN; Y 59342236 59343330 target_189894_IL9R NaN. ---. @mbabadi commented on [Fri Aug 26 2016](https://github.com/broadinstitute/gatk-protected/issues/651#issuecomment-242767764). @davidbenjamin could you please take a look? it sounds like it could be a problem with the reference missing these regions. ---. @mbabadi commented on [Fri Aug 26 2016](https://github.com/broadinstitute/gatk-protected/issues/651#issuecomment-242774747). OK it turns out that the reference is hard masked and has ""N"" in that region. Nevertheless, we shouldn't get NaNs. In my opinion, the correct behavior is to drop targets on which GC percentage can not be defined + emit informative error messages. ---. @davidbenjamin commented on [Sun Sep 11 2016](https://github.com/broadinstitute/gatk-protected/issues/651#issuecomment-246177779). I will address this. ---. @mbabadi commented on [Tue Sep 27 2016](https://github.com/broadinstitute/gatk-protected/issues/651#issuecomment-250018497). @davidbenjamin also, CorrectGCBias produces NaNs when a sample has very low coverage. I think the correct behavior is this:. (1) when annotating targets, it is OK to produce NaNs on targets whose GC bias can not be determined. When correcting for GC bias, those targets must be removed altogether. (2) if the bias curve can not be determined (let's say because of low coverage), the tool should remove that sample from the collection and emit appropriate warning messages. If all samples are removed, the tool should produce a bad input error. ---. @mbabadi commented on [Thu May 18 2017](https://github.com/broadinstitute/gatk-protected/issues/651#issuecomment-302466279). @asmirnov239 can you review and if the issue is resolved, close?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2882:4836,error,error,4836,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2882,1,['error'],['error']
Availability,"03:15:02.578 INFO IntervalArgumentCollection - Processing <redacted> bp from intervals; 03:15:02.588 INFO HaplotypeCaller - Done initializing engine; 03:15:02.590 INFO HaplotypeCallerEngine - Tool is in reference confidence mode and the annotation, the following changes will be made to any specified annotations: 'StrandBiasBySample' will be enabled. 'ChromosomeCounts', 'FisherStrand', 'StrandOddsRatio' and 'QualByDepth' annotations have been disabled; 03:15:02.593 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/conda/share/gatk4-4.1.4.1-1/gatk-package-4.1.4.1-local.jar!/com/intel/gkl/native/libgkl_utils.so; 03:15:02.598 INFO NativeLibraryLoader - Loading libgkl_smithwaterman.so from jar:file:/conda/share/gatk4-4.1.4.1-1/gatk-package-4.1.4.1-local.jar!/com/intel/gkl/native/libgkl_smithwaterman.so; 03:15:02.599 INFO IntelSmithWaterman - Using CPU-supported AVX-512 instructions; 03:15:02.599 INFO SmithWatermanAligner - Using AVX accelerated SmithWaterman implementation; 03:15:02.601 INFO HaplotypeCallerEngine - Standard Emitting and Calling confidence set to 0.0 for reference-model confidence output; 03:15:02.601 INFO HaplotypeCallerEngine - All sites annotated with PLs forced to true for reference-model confidence output; 03:15:02.623 INFO NativeLibraryLoader - Loading libgkl_pairhmm_omp.so from jar:file:conda/share/gatk4-4.1.4.1-1/gatk-package-4.1.4.1-local.jar!/com/intel/gkl/native/libgkl_pairhmm_omp.so; 03:15:02.667 INFO IntelPairHmm - Using CPU-supported AVX-512 instructions; 03:15:02.667 INFO IntelPairHmm - Flush-to-zero (FTZ) is enabled when running PairHMM; 03:15:02.667 INFO IntelPairHmm - Available threads: 16; 03:15:02.667 INFO IntelPairHmm - Requested threads: 32; 03:15:02.667 WARN IntelPairHmm - Using 16 available threads, but 32 were requested; 03:15:02.667 INFO PairHMM - Using the OpenMP multi-threaded AVX-accelerated native PairHMM implementation; ```. Any insight into what's going on and how to diagnose it would be greatly appreciated.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6889:6459,Avail,Available,6459,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6889,2,"['Avail', 'avail']","['Available', 'available']"
Availability,"03:51:59.222 INFO GenotypeGVCFs - Initializing engine; 03:51:59.571 INFO GenomicsDBLibLoader - GenomicsDB native library version : 1.3.2-e18fa63; 11:51:59.957 info NativeGenomicsDB - pid=1480681 tid=1480682 No valid combination operation found for INFO field InbreedingCoeff - the field will NOT be part of INFO fields in the generated VCF records; 11:51:59.957 info NativeGenomicsDB - pid=1480681 tid=1480682 No valid combination operation found for INFO field MLEAC - the field will NOT be part of INFO fields in the generated VCF records; 11:51:59.957 info NativeGenomicsDB - pid=1480681 tid=1480682 No valid combination operation found for INFO field MLEAF - the field will NOT be part of INFO fields in the generated VCF records; 03:52:00.341 INFO GenotypeGVCFs - Done initializing engine; 03:52:00.369 INFO ProgressMeter - Starting traversal; 03:52:00.369 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 03:52:00.377 INFO GenotypeGVCFs - Shutting down engine; [July 13, 2023 at 3:52:00 AM UTC] org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs done. Elapsed time: 0.02 minutes.; Runtime.totalMemory()=2583691264; java.lang.IllegalStateException: There are no sources based on those query parameters; at org.genomicsdb.reader.GenomicsDBFeatureIterator.<init>(GenomicsDBFeatureIterator.java:167); at org.genomicsdb.reader.GenomicsDBFeatureReader.query(GenomicsDBFeatureReader.java:152); at org.broadinstitute.hellbender.engine.FeatureDataSource.refillQueryCache(FeatureDataSource.java:569); at org.broadinstitute.hellbender.engine.FeatureDataSource.queryAndPrefetch(FeatureDataSource.java:538); at org.broadinstitute.hellbender.engine.FeatureDataSource.query(FeatureDataSource.java:504); at org.broadinstitute.hellbender.engine.VariantLocusWalker.lambda$traverse$2(VariantLocusWalker.java:149); at java.base/java.util.Iterator.forEachRemaining(Iterator.java:133); at java.base/java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8415:4097,down,down,4097,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8415,1,['down'],['down']
Availability,"065741193890473.csv'; 22:13:30.002 INFO AnalyzeCovariates - Generating plots file './sample_analysis/SRR25308851/SRR25308851_recalibration_plots.pdf'; 22:13:30.518 INFO AnalyzeCovariates - Shutting down engine; [August 7, 2023 at 10:13:30 PM UTC] org.broadinstitute.hellbender.tools.walkers.bqsr.AnalyzeCovariates done. Elapsed time: 0.01 minutes.; Runtime.totalMemory()=113246208; org.broadinstitute.hellbender.utils.R.RScriptExecutorException:; Rscript exited with 1; Command Line: Rscript -e tempLibDir = '/tmp/Rlib.10708586791705723928';source('/tmp/BQSR.12372590345390592260.R'); /tmp/AnalyzeCovariates13996065741193890473.csv /attach/data/vinit/human_exome/test/./sample_analysis/SRR25308851/SRR25308851_before_recal_data.table /attach/data/vinit/human_exome/test/./sample_analysis/SRR25308851/SRR25308851_recalibration_plots.pdf; Stdout:; Stderr:; Attaching package: ‘gplots’. The following object is masked from ‘package:stats’:. lowess. Error in names(x) <- value :; 'names' attribute [6] must be the same length as the vector [1]; Calls: source ... finishTable -> .gsa.assignGATKTableToEnvironment -> colnames<-; In addition: Warning messages:; 1: In type.convert.default(d[, i]) :; 'as.is' should be specified by the caller; using TRUE; 2: In type.convert.default(d[, i]) :; 'as.is' should be specified by the caller; using TRUE; 3: In type.convert.default(d[, i]) :; 'as.is' should be specified by the caller; using TRUE; 4: In type.convert.default(d[, i]) :; 'as.is' should be specified by the caller; using TRUE; 5: In type.convert.default(d[, i]) :; 'as.is' should be specified by the caller; using TRUE; Execution halted. at org.broadinstitute.hellbender.utils.R.RScriptExecutor.getScriptException(RScriptExecutor.java:79); at org.broadinstitute.hellbender.utils.R.RScriptExecutor.getScriptException(RScriptExecutor.java:18); at org.broadinstitute.hellbender.utils.runtime.ScriptExecutor.executeCuratedArgs(ScriptExecutor.java:112); at org.broadinstitute.hellbender.utils.R.RScriptExec",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8456:3572,Error,Error,3572,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8456,1,['Error'],['Error']
Availability,"07, 2021 12:21 UTC. . Link: [https://gatk.broadinstitute.org/hc/en-us/community/posts/4403256366107--java-lang-ArrayIndexOutOfBoundsException-32772-while-running-GenotypeGVCFs](https://gatk.broadinstitute.org/hc/en-us/community/posts/4403256366107--java-lang-ArrayIndexOutOfBoundsException-32772-while-running-GenotypeGVCFs). \--. i don't get an error but the massge  java.lang.ArrayIndexOutOfBoundsException: 32772 ; ; i use : GATK version used: 4.2.0 ; ; b) Exact command used  this line for Geomics DBImport. gatk GenomicsDBImport -V MA1.g.vcf -V MA2.g.vcf -V MA3.g.vcf -V MH1.g.vcf -V MH2.g.vcf -V MH3.g.vcf -V F4\_1.g.vcf -V F4\_2.g.vcf -V F4\_3.g.vcf --genomicsdb-workspace-path my\_database1AB -L 1A -L 1B -L 2A -L 2B -L 3A -L 3B -L 4A -L 4B -L 5A -L 5B -L 6A -L 6B -L 7A -L 7B. and this for GenotypeGVCFs. gatk --java-options ""-Xmx12g -Xms12g"" GenotypeGVCFs -R Triticum\_dicoccoides.WEWSeq\_v.1.0.dna.toplevel.fa -V gendb://my\_database -O output.vcf.gz --new-qual --tmp-dir temp/. c) Entire error log:. Using GATK jar /home/alonzi/miniconda3/envs/rna-seq/share/gatk4-4.2.0.0-1/gatk-package-4.2.0.0-local.jar ; ; Running: ; ; java -Dsamjdk.use\_async\_io\_read\_samtools=false -Dsamjdk.use\_async\_io\_write\_samtools=true -Dsamjdk.use\_async\_io\_write\_tribble=false -Dsamjdk.compression\_level=2 -Xmx12g -Xms12g -jar /home/alonzi/miniconda3/envs/rna-seq/share/gatk4-4.2.0.0-1/gatk-package-4.2.0.0-local.jar GenotypeGVCFs -R Triticum\_dicoccoides.WEWSeq\_v.1.0.dna.toplevel.fa -V gendb://my\_database -O output.vcf.gz --new-qual --tmp-dir temp/ ; ; 14:28:22.448 INFO NativeLibraryLoader - Loading libgkl\_compression.so from jar:file:/home/alonzi/miniconda3/envs/rna-seq/share/gatk4-4.2.0.0-1/gatk-package-4.2.0.0-local.jar!/com/intel/gkl/native/libgkl\_compression.so ; ; Jul 07, 2021 2:28:22 PM shaded.cloud\_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine ; ; INFO: Failed to detect whether we are running on Google Compute Engine. ; ; 14:28:22.617 INFO Genoty",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7348:1555,error,error,1555,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7348,1,['error'],['error']
Availability,"07.226 INFO BlockManager - Initialized BlockManager: BlockManagerId(driver, 172.20.19.130, 43279, None); 10:33:07.345 INFO ContextHandler - Stopped o.s.j.s.ServletContextHandler@7074da1d{/,null,STOPPED,@Spark}; 10:33:07.347 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@6556471b{/jobs,null,AVAILABLE,@Spark}; 10:33:07.349 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@7cdb05aa{/jobs/json,null,AVAILABLE,@Spark}; 10:33:07.351 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@5cb76070{/jobs/job,null,AVAILABLE,@Spark}; 10:33:07.352 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@443ac5b8{/jobs/job/json,null,AVAILABLE,@Spark}; 10:33:07.354 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@753e4eb5{/stages,null,AVAILABLE,@Spark}; 10:33:07.355 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@63318b56{/stages/json,null,AVAILABLE,@Spark}; 10:33:07.357 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@462f8fe9{/stages/stage,null,AVAILABLE,@Spark}; 10:33:07.358 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@b2e1df3{/stages/stage/json,null,AVAILABLE,@Spark}; 10:33:07.359 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@6cf3b3d7{/stages/pool,null,AVAILABLE,@Spark}; 10:33:07.360 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@55c20a91{/stages/pool/json,null,AVAILABLE,@Spark}; 10:33:07.361 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@3ba96967{/storage,null,AVAILABLE,@Spark}; 10:33:07.362 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@1237cade{/storage/json,null,AVAILABLE,@Spark}; 10:33:07.363 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@4509b7{/storage/rdd,null,AVAILABLE,@Spark}; 10:33:07.364 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@5dbc4598{/storage/rdd/json,null,AVAILABLE,@Spark}; 10:33:07.365 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@38a27ace{/environment,null,AVAILABLE,@Spark}; 10:33:07",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8949:45593,AVAIL,AVAILABLE,45593,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8949,1,['AVAIL'],['AVAILABLE']
Availability,"09:15:51.135 INFO SelectVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 09:15:51.135 INFO SelectVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 09:15:51.135 INFO SelectVariants - Deflater: IntelDeflater; 09:15:51.135 INFO SelectVariants - Inflater: IntelInflater; 09:15:51.135 INFO SelectVariants - GCS max retries/reopens: 20; 09:15:51.135 INFO SelectVariants - Requester pays: disabled; 09:15:51.136 INFO SelectVariants - Initializing engine; 09:15:52.547 INFO FeatureManager - Using codec VCFCodec to read file file:///dsgmnt/seq5_llfs/work/xhong/v4100/ApplyVQSR/ExcessHet_joint525_c1_22.SNP.VQSR.g.vcf.gz; 09:15:53.171 INFO IntervalArgumentCollection - Processing 248956422 bp from intervals; 09:15:53.221 INFO SelectVariants - Done initializing engine; 09:15:53.390 INFO ProgressMeter - Starting traversal; 09:15:53.390 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 09:15:53.479 INFO SelectVariants - Shutting down engine; [June 27, 2019 9:15:53 AM CDT] org.broadinstitute.hellbender.tools.walkers.variantutils.SelectVariants done. Elapsed time: 0.07 minutes.; Runtime.totalMemory()=2131755008; htsjdk.tribble.TribbleException: The provided VCF file is malformed at approximately line number 3433: The VCF specification does not allow for whitespace in the INFO field; . Offending field value was ""AC=1;AF=9.671e-04;AN=1034;AS_BaseQRankSum=-1.550;AS_FS=8.334;AS_InbreedingCoeff=-0.3147;AS_MQ=31.69;AS_MQRankSum=-0.200;AS_QD=28.73;AS_ReadPosR; ankSum=nul;AS_SOR=2.235;BaseQRankSum=-1.381e+00;DP=40368;ExcessHet=160.0000;FS=8.334;InbreedingCoeff=-0.3147;MLEAC=7;MLEAF=6.770e-03;MQ=37.13;MQRankSum=0.126;QD=2.46;SOR=2.; 235 GT:AD:DP:GQ:PGT:PID:PL:PS 0/0:75,0:75:0:.:.:0,0,1525; `. However, from the error message I cannot see any whitespace in the INFO field. The /dsgmnt/seq5_llfs/work/xhong/v4100/ApplyVQSR/ExcessHet_joint525_c1_22.SNP.VQSR.g.vcf.gz is the output of following command:. `gatk4.1.0.0 --java-options '-X",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6021:2998,down,down,2998,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6021,1,['down'],['down']
Availability,"0:33 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on fdbd4e9f571c4f8489ec11d570585d56000000.internal.cloudapp.net:46619 (size: 35.5 KB, free: 9.2 GB); 21/01/12 15:50:33 INFO SparkContext: Created broadcast 1 from newAPIHadoopFile at PathSplitSource.java:96; 21/01/12 15:50:33 INFO FileInputFormat: Total input files to process : 1; 21/01/12 15:50:33 INFO SparkUI: Stopped Spark web UI at http://fdbd4e9f571c4f8489ec11d570585d56000000.internal.cloudapp.net:4040; 21/01/12 15:50:33 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 21/01/12 15:50:33 INFO MemoryStore: MemoryStore cleared; 21/01/12 15:50:33 INFO BlockManager: BlockManager stopped; 21/01/12 15:50:33 INFO BlockManagerMaster: BlockManagerMaster stopped; 21/01/12 15:50:33 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 21/01/12 15:50:33 INFO SparkContext: Successfully stopped SparkContext; 15:50:33.855 INFO MarkDuplicatesSpark - Shutting down engine; [January 12, 2021 at 3:50:33 PM EST] org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSpark done. Elapsed time: 0.06 minutes.; Runtime.totalMemory()=1065353216; java.lang.IllegalArgumentException: Unsupported class file major version 55; 	at org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:166); 	at org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:148); 	at org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:136); 	at org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:237); 	at org.apache.spark.util.ClosureCleaner$.getClassReader(ClosureCleaner.scala:49); 	at org.apache.spark.util.FieldAccessFinder$$anon$3$$anonfun$visitMethodInsn$2.apply(ClosureCleaner.scala:517); 	at org.apache.spark.util.FieldAccessFinder$$anon$3$$anonfun$visitMethodInsn$2.apply(ClosureCleaner.scala:500); 	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733); 	at scala.collection.mutable.HashMap$$anon$",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7035:5756,down,down,5756,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7035,1,['down'],['down']
Availability,"0:33:07.225 INFO BlockManagerMaster - Registered BlockManager BlockManagerId(driver, 172.20.19.130, 43279, None); 10:33:07.226 INFO BlockManager - Initialized BlockManager: BlockManagerId(driver, 172.20.19.130, 43279, None); 10:33:07.345 INFO ContextHandler - Stopped o.s.j.s.ServletContextHandler@7074da1d{/,null,STOPPED,@Spark}; 10:33:07.347 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@6556471b{/jobs,null,AVAILABLE,@Spark}; 10:33:07.349 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@7cdb05aa{/jobs/json,null,AVAILABLE,@Spark}; 10:33:07.351 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@5cb76070{/jobs/job,null,AVAILABLE,@Spark}; 10:33:07.352 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@443ac5b8{/jobs/job/json,null,AVAILABLE,@Spark}; 10:33:07.354 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@753e4eb5{/stages,null,AVAILABLE,@Spark}; 10:33:07.355 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@63318b56{/stages/json,null,AVAILABLE,@Spark}; 10:33:07.357 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@462f8fe9{/stages/stage,null,AVAILABLE,@Spark}; 10:33:07.358 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@b2e1df3{/stages/stage/json,null,AVAILABLE,@Spark}; 10:33:07.359 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@6cf3b3d7{/stages/pool,null,AVAILABLE,@Spark}; 10:33:07.360 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@55c20a91{/stages/pool/json,null,AVAILABLE,@Spark}; 10:33:07.361 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@3ba96967{/storage,null,AVAILABLE,@Spark}; 10:33:07.362 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@1237cade{/storage/json,null,AVAILABLE,@Spark}; 10:33:07.363 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@4509b7{/storage/rdd,null,AVAILABLE,@Spark}; 10:33:07.364 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@5dbc4598{/storage/rdd/json,null,AVAILABLE,@Spark}; 10:33:07",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8949:45473,AVAIL,AVAILABLE,45473,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8949,1,['AVAIL'],['AVAILABLE']
Availability,"0:38:16.247 INFO MarkDuplicatesSpark - For support and documentation go to https://software.broadinstitute.org/gatk/; 10:38:16.247 INFO MarkDuplicatesSpark - Executing as hcaoad@hhnode-ib-16 on Linux v3.10.0-1062.el7.x86_64 amd64; 10:38:16.247 INFO MarkDuplicatesSpark - Java runtime: OpenJDK 64-Bit Server VM v17.0.8-internal+0-adhoc..src; 10:38:16.247 INFO MarkDuplicatesSpark - Start Date/Time: October 18, 2023 at 10:38:16 AM HKT; 10:38:16.247 INFO MarkDuplicatesSpark - ------------------------------------------------------------; 10:38:16.247 INFO MarkDuplicatesSpark - ------------------------------------------------------------; 10:38:16.248 INFO MarkDuplicatesSpark - HTSJDK Version: 3.0.5; 10:38:16.248 INFO MarkDuplicatesSpark - Picard Version: 3.0.0; 10:38:16.248 INFO MarkDuplicatesSpark - Built for Spark Version: 3.3.1; 10:38:16.249 INFO MarkDuplicatesSpark - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 10:38:16.249 INFO MarkDuplicatesSpark - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 10:38:16.249 INFO MarkDuplicatesSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 10:38:16.249 INFO MarkDuplicatesSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 10:38:16.249 INFO MarkDuplicatesSpark - Deflater: IntelDeflater; 10:38:16.249 INFO MarkDuplicatesSpark - Inflater: IntelInflater; 10:38:16.250 INFO MarkDuplicatesSpark - GCS max retries/reopens: 20; 10:38:16.250 INFO MarkDuplicatesSpark - Requester pays: disabled; 10:38:16.250 INFO MarkDuplicatesSpark - Initializing engine; 10:38:16.250 INFO MarkDuplicatesSpark - Done initializing engine; 10:38:17.179 INFO SparkContext - Running Spark version 3.3.0; ```. #### Steps to reproduce; The most wired thing is that this issue is very hard to reproduce. When running the command for hundreds of samples, this always happens to a few samples. However, if I re-submit my job for the failed sample, this error may just disappear. As the whole log file is too big, I can upload it later if need. Thanks.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8555:5491,error,error,5491,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8555,1,['error'],['error']
Availability,"0:50.177 INFO SparkContext - Starting job: runJob at SparkHadoopWriter.scala:83; 11:00:50.278 INFO DAGScheduler - Registering RDD 14 (mapToPair at SparkUtils.java:161) as input to shuffle 0; 11:00:50.291 INFO DAGScheduler - Got job 1 (runJob at SparkHadoopWriter.scala:83) with 44262 output partitions; 11:00:50.291 INFO DAGScheduler - Final stage: ResultStage 2 (runJob at SparkHadoopWriter.scala:83); 11:00:50.291 INFO DAGScheduler - Parents of final stage: List(ShuffleMapStage 1); 11:00:50.296 INFO DAGScheduler - Missing parents: List(ShuffleMapStage 1); 11:00:50.300 INFO DAGScheduler - Submitting ShuffleMapStage 1 (MapPartitionsRDD[14] at mapToPair at SparkUtils.java:161), which has no missing parents; 11:00:53.974 INFO TaskSchedulerImpl - Cancelling stage 1; 11:00:53.974 INFO TaskSchedulerImpl - Killing all running tasks in stage 1: Stage cancelled; 11:00:53.975 INFO DAGScheduler - ShuffleMapStage 1 (mapToPair at SparkUtils.java:161) failed in 3.609 s due to Job aborted due to stage failure: Task serialization failed: java.lang.OutOfMemoryError: Required array length 2147483639 + 798 is too large; java.lang.OutOfMemoryError: Required array length 2147483639 + 798 is too large; at java.base/jdk.internal.util.ArraysSupport.hugeLength(ArraysSupport.java:649); at java.base/jdk.internal.util.ArraysSupport.newLength(ArraysSupport.java:642); at java.base/java.io.ByteArrayOutputStream.ensureCapacity(ByteArrayOutputStream.java:100); at java.base/java.io.ByteArrayOutputStream.write(ByteArrayOutputStream.java:130); at org.apache.spark.util.ByteBufferOutputStream.write(ByteBufferOutputStream.scala:41); at java.base/java.io.ObjectOutputStream$BlockDataOutputStream.write(ObjectOutputStream.java:1862); at java.base/java.io.ObjectOutputStream.write(ObjectOutputStream.java:714); at org.apache.spark.util.Utils$$anon$2.write(Utils.scala:160); at com.esotericsoftware.kryo.io.Output.flush(Output.java:185); at com.esotericsoftware.kryo.io.Output.close(Output.java:196); at org.apache.spar",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8949:4324,failure,failure,4324,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8949,1,['failure'],['failure']
Availability,"0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|1	1|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	3|0	0|0	3|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|1	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	1|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|1	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	1|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|1	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	1|0	0|0	0|0	0|0	0|0	1|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	2|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	1|0	0|0	0|0	0|0	0|0	1|0	1|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|3	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	1|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|3	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	1|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	1|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|1	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0; ```; And indeed, with that `--alleles` input with a single condensed record, HaplotypeCaller runs without error.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5355:73921,error,error,73921,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5355,1,['error'],['error']
Availability,"1 2016](https://github.com/broadinstitute/gatk-protected/issues/806). An issue encountered with gatk-protected ""SparkGenomeReadCounts"" tool is a non-helpful ""null"" error message. A non-helpful error ""null"" message was printed by gatk-protected with the command-line below; during the course of trying to use it on/in FireCloud:. ```; + java -Xmx48g -jar fc-7ac504fc-7fe4-4bc1-89d3-7f16317b8ff4/eddie.jar SparkGenomeReadCounts --outputFile this.entity_id.coverage.tsv --reference fc-e2421839-93d5-4ed5-8861-593f00364e54/Homo_sapiens_assembly19.fasta --input firecloud-tcga-open-access/tutorial/bams/C835.HCC1143_BL.4.bam --binsize 5000; Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/cromwell_root/tmp; .....; ......; ......; proceeding with flushing remote transports.; ***********************************************************************. null. ***********************************************************************; ```. To try to make a more helpful error message appear I added a ""catch"" block after a call to runTool in instanceMainPostParseArgs in file CommandLineProgram.java and got a more helpful message about a missing dictionary file: . try {; return runTool();; } ; catch(Exception e) {; e.getStackTrace();; }. java.lang.RuntimeException: org.broadinstitute.hellbender.exceptions.UserException$MissingReferenceDictFile; 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:179); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:204); 	at org.broadinstitute.hellbender.Main.instanceMain(Main.java:95); 	at org.broadinstitute.hellbender.Main.instanceMain(Main.java:103); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:115); 	at org.broadinstitute.hellbender.Main.main(Main.java:152); Caused by: org.broadinstitute.hellbender.exceptions.UserException$MissingReferenceDictFile; 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.initializeReference(GATKSparkTool",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2922:988,error,error,988,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2922,1,['error'],['error']
Availability,"1 INFO  BaseRecalibrator - HTSJDK Defaults.USE\_ASYNC\_IO\_READ\_FOR\_SAMTOOLS : false ; ; 00:09:41.681 INFO  BaseRecalibrator - HTSJDK Defaults.USE\_ASYNC\_IO\_WRITE\_FOR\_SAMTOOLS : true ; ; 00:09:41.681 INFO  BaseRecalibrator - HTSJDK Defaults.USE\_ASYNC\_IO\_WRITE\_FOR\_TRIBBLE : false ; ; 00:09:41.682 INFO  BaseRecalibrator - Deflater: JdkDeflater ; ; 00:09:41.682 INFO  BaseRecalibrator - Inflater: JdkInflater ; ; 00:09:41.682 INFO  BaseRecalibrator - GCS max retries/reopens: 20 ; ; 00:09:41.682 INFO  BaseRecalibrator - Requester pays: disabled ; ; 00:09:41.682 INFO  BaseRecalibrator - Initializing engine ; ; 00:09:41.884 WARN  IntelInflaterFactory - IntelInflater is not supported, using Java.util.zip.Inflater ; ; 00:09:41.888 WARN  IntelInflaterFactory - IntelInflater is not supported, using Java.util.zip.Inflater ; ; 00:09:42.030 WARN  IntelInflaterFactory - IntelInflater is not supported, using Java.util.zip.Inflater ; ; 00:09:42.036 INFO  BaseRecalibrator - Shutting down engine ; ; \[August 21, 2022 at 12:09:42 AM CST\] org.broadinstitute.hellbender.tools.walkers.bqsr.BaseRecalibrator done. Elapsed time: 0.01 minutes. ; ; Runtime.totalMemory()=1140850688 ; ; org.broadinstitute.hellbender.exceptions.GATKException: Unable to automatically instantiate codec org.broadinstitute.hellbender.utils.codecs.AnnotatedIntervalCodec ; ;     at org.broadinstitute.hellbender.engine.FeatureManager.getCandidateCodecsForFile(FeatureManager.java:535) ; ;     at org.broadinstitute.hellbender.engine.FeatureManager.getCodecForFile(FeatureManager.java:482) ; ;     at org.broadinstitute.hellbender.engine.FeatureDataSource.getCodecForFeatureInput(FeatureDataSource.java:397) ; ;     at org.broadinstitute.hellbender.engine.FeatureDataSource.getFeatureReader(FeatureDataSource.java:373) ; ;     at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:319) ; ;     at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:291) ; ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8005:5164,down,down,5164,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8005,1,['down'],['down']
Availability,1(ErrorProbabilities.java:19); 2019-10-29T18:18:04.002140012Z 	at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1321); 2019-10-29T18:18:04.002232542Z 	at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); 2019-10-29T18:18:04.002242727Z 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); 2019-10-29T18:18:04.002292461Z 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 2019-10-29T18:18:04.002301667Z 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 2019-10-29T18:18:04.002307019Z 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 2019-10-29T18:18:04.002311722Z 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 2019-10-29T18:18:04.002316449Z 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 2019-10-29T18:18:04.002321526Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.<init>(ErrorProbabilities.java:19); 2019-10-29T18:18:04.002358113Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.accumulateData(Mutect2FilteringEngine.java:141); 2019-10-29T18:18:04.002377342Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls.nthPassApply(FilterMutectCalls.java:146); 2019-10-29T18:18:04.002383406Z 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverse$0(MultiplePassVariantWalker.java:40); 2019-10-29T18:18:04.002431769Z 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverseVariants$1(MultiplePassVariantWalker.java:77); 2019-10-29T18:18:04.002441351Z 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); 2019-10-29T18:18:04.002446409Z 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 2019-10-29T18:18:04.002493533Z 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 2019-10-29,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6237:2264,Error,ErrorProbabilities,2264,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6237,1,['Error'],['ErrorProbabilities']
Availability,1); 	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at org.apache.spark.util.random.SamplingUtils$.reservoirSampleAndCount(SamplingUtils.scala:41); 	at org.apache.spark.RangePartitioner$$anonfun$13.apply(Partitioner.scala:303); 	at org.apache.spark.RangePartitioner$$anonfun$13.apply(Partitioner.scala:301); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$26.apply(RDD.scala:847); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$26.apply(RDD.scala:847); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:109); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); ERROR: (gcloud.dataproc.jobs.submit.spark) Job [5838bd7dec2d4533ad090ce03ecc7c0c] entered state [ERROR] while waiting for [DONE].; ```. #### Steps to reproduce. See command given in stack trace above.; WGS bam is available at ; `gs://broad-dsde-methods/shuang/tmp/HG00512.cram.samtools1_9.bam` ; and ; `gs://broad-dsde-methods/shuang/tmp/HG00512.cram.samtools1_9.bam.bai`. Interval list BED file content given below. ```; chrX	67113957	67114130; chrX	71903370	71903687; chrX	74330484	74330552; chrX	75379902	75379965; chrX	78441355	78441953; ```. #### Expected behavior; Pass. #### Actual behavior; Error! This could be related to ticket #2722,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5051:22761,ERROR,ERROR,22761,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5051,4,"['ERROR', 'Error', 'avail']","['ERROR', 'Error', 'available']"
Availability,"1. Add new arg `genomicsdb-shared-posixfs-optimizations` to help with shared posix filesystems like NFS and Lustre. This turns on `disable file locking` and for GenomicsDB import it minimizes writes to disks. The performance on some of the gatk datasets for the import of about 10 samples went from 23.72m to 6.34m on NFS which was comparable to importing to a local filesystem. Hopefully this helps with Issue #6487 and #6627. Also, fixes Issue #6519.; 2. This version of GenomicsDB also uses pre-compression filters for offset and compression files for new workspaces and genomicsdb arrays. The total sizes for a GenomicsDB workspace using the same dataset as above and the 10 samples went from 313MB to 170MB with no change in import and query times. Smaller GenomicsDB arrays also help with performance on distributed and cloud file systems.; 3. This version has added support to handle MNVs similar to deletions as described in Issue #6500. See [GenomicsDB PR 88](https://github.com/GenomicsDB/GenomicsDB/pull/88). Thanks @kgururaj.; 4. There is added support in the GenomicsDBImporter to have multiple contigs in the same GenomicsDB partition/array. This will hopefully help import times in cases where users have many thousands of contigs. See [GenomicsDB PR 91](https://github.com/GenomicsDB/GenomicsDB/pull/91). Changes will be needed from the gatk side to avail this support. Thanks @mlathara.; 5. Logging has been improved somewhat with the native C/C++ code using [spdlog](https://github.com/gabime/spdlog) and [fmt](https://github.com/fmtlib/fmt) and the Java layer using apache log4j and log4j.properties provided by the application. Also, info messages like `No valid combination operation found for INFO field AA - the field will NOT be part of INFO fields in the generated VCF records` will only be output once for the operation. Also see open PR #6514 for code to actually suppress these warnings for known fields.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6654:1366,avail,avail,1366,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6654,1,['avail'],['avail']
Availability,"1. We need a script to take snapshots of the [GATK total downloads page](https://somsubhra.com/github-release-stats/?username=broadinstitute&repository=gatk) every month and report the number of times each release was downloaded.; 2. We should change the GATK download link on [this page of the GATK website](https://gatk.broadinstitute.org/hc/en-us) and have it point at a script that records the IP addresses of users before redirecting to github. That way we can have another source of GATK downloads metrics.; 3. Github reports the traffic on GATK repo [here](https://github.com/broadinstitute/gatk/graphs/traffic). It tracks the number of clones and the number of visitors. However, github saves this data only for one week, so we will need an automated script to take snapshots of the page and store the metrics.; 4. In the same way track the total number of download from bioconda from [this](https://anaconda.org/bioconda/gatk4) page.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6946:57,down,downloads,57,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6946,5,['down'],"['download', 'downloaded', 'downloads']"
Availability,"1. Wrap `SeekablePathStream` in the tribble feature readers with a `Function<SeekableByteChannel, SeekableByteChannel>`. 2. Mirror what was done in https://github.com/broadinstitute/gatk/pull/2331 for `FeatureDataSource`: propagate cloud prefetching buffer sizes from `GATKTool` down to `FeatureDataSource`, create wrapper functions within `FeatureDataSource`, and pass down to htsjdk.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2375:279,down,down,279,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2375,2,['down'],['down']
Availability,1.457 INFO FeatureManager - Using codec VCFCodec to read file file:///local/scratch/rieder/spark-bb59423b-0368-4de5-85e0-e6641fb25380/userFiles-a91d5958-33f5-4685-bf9d-c8fc0924f7c6/Homo_sapiens_assembly38.dbsnp138.vcf; 01:51:51.507 INFO BaseRecalibrationEngine - The covariates being used here: ; 01:51:51.507 INFO BaseRecalibrationEngine - ReadGroupCovariate; 01:51:51.507 INFO BaseRecalibrationEngine - QualityScoreCovariate; 01:51:51.507 INFO BaseRecalibrationEngine - ContextCovariate; 01:51:51.507 INFO BaseRecalibrationEngine - CycleCovariate; 01:51:51.517 INFO FeatureManager - Using codec VCFCodec to read file file:///local/scratch/rieder/spark-bb59423b-0368-4de5-85e0-e6641fb25380/userFiles-a91d5958-33f5-4685-bf9d-c8fc0924f7c6/Homo_sapiens_assembly38.known_indels.vcf; 20/04/29 01:51:51 ERROR Executor: Exception in task 581.0 in stage 0.0 (TID 581); org.broadinstitute.hellbender.exceptions.GATKException: Error initializing feature reader for path /local/scratch/rieder/spark-bb59423b-0368-4de5-85e0-e6641fb25380/userFiles-a91d5958-33f5-4685-bf9d-c8fc0924f7c6/Homo_sapiens_assembly38.known_indels.vcf; at org.broadinstitute.hellbender.engine.FeatureDataSource.getTribbleFeatureReader(FeatureDataSource.java:383); at org.broadinstitute.hellbender.engine.FeatureDataSource.getFeatureReader(FeatureDataSource.java:335); at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:282); at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:238); at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:222); at org.broadinstitute.hellbender.utils.spark.JoinReadsWithVariants.openFeatureSource(JoinReadsWithVariants.java:63); at org.broadinstitute.hellbender.utils.spark.JoinReadsWithVariants.lambda$null$0(JoinReadsWithVariants.java:44); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6578:2697,Error,Error,2697,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6578,1,['Error'],['Error']
Availability,"1.9. ### Description ; Starting with GATK4.1.7, the AF annotation in the changed from '0' to '.'. This change is cause downstream issues with our processing pipeline. #### Steps to reproduce; CMD using 4.1.6:; gatk GenotypeGVCFs --variant proband_mother_duo.HC.g.vcf.gz -R hs38DH.fa --dbsnp dbsnp151_common.hg38.vcf.gz -O proband_mother_duo_GATK4.1.6.HC.vcf.gz. Looking at one of the sites causing this downstream issue:; CMD; gzcat proband_mother_duo_GATK4.1.6.HC.vcf.gz | grep 83598622; OUTPUT:; chr4 83598622 . AT ATT,A 1337.45 . AC=1,1;AF=0.250,0.250;AN=4;BaseQRankSum=1.26;ClippingRankSum=0.074;DP=145;ExcessHet=4.7712;FS=5.235;GQ_MEAN=625.00;LikelihoodRankSum=1.34;MLEAC=1,1;MLEAF=0.250,0.250;MQ=60.00;MQ0=0;MQRankSum=0.00;NCC=0;NCount=0;QD=10.06;ReadPosRankSum=1.56;SOR=0.375 GT:AD:AF:DP:F1R2:F2R1:GQ:PL 0/2:33,0,35:0.515,0:68:12,15,0:21,18,0:99:713,812,1542,0,731,625 0/1:32,33,0:0.493,0.00:67:9,23,0:19,8,0:99:640,0,588,728,747,1569. CMD using 4.1.7:; gatk GenotypeGVCFs --variant proband_mother_duo.HC.g.vcf.gz -R hs38DH.fa --dbsnp dbsnp151_common.hg38.vcf.gz -O proband_mother_duo_GATK4.1.7.HC.vcf.gz. Looking at one of the sites causing this downstream issue:; CMD; gzcat proband_mother_duo_GATK4.1.7.HC.vcf.gz | grep 83598622; OUTPUT:; chr4 83598622 . AT ATT,A 1337.45 . AC=1,1;AF=0.250,0.250;AN=4;BaseQRankSum=1.26;ClippingRankSum=0.074;DP=145;ExcessHet=4.7712;FS=5.235;GQ_MEAN=625.00;LikelihoodRankSum=1.34;MLEAC=1,1;MLEAF=0.250,0.250;MQ=60.00;MQ0=0;MQRankSum=0.00;NCC=0;NCount=0;QD=10.06;ReadPosRankSum=1.56;SOR=0.375 GT:AD:AF:DP:F1R2:F2R1:GQ:PL 0/2:33,0,35:0.515,.:68:12,15,.:21,18,.:99:713,812,1542,0,731,625 0/1:32,33,0:0.493,0.00:67:9,23,0:19,8,0:99:640,0,588,728,747,1569. The above 4.1.7 site matches 4.1.8 and 4.1.9. For 4.1.7, The first sample in the VCF lists the 'AF' as ""0.515,."", while in version 4.1.6, AF is represented as ""0.515,0""; ----. ## Feature request. Can the most recent build of 4.1.9 be changed to represent these AF annotations with '0' instead of '.'?. ----",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6938:2427,down,downstream,2427,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6938,1,['down'],['downstream']
Availability,1.GRCh37.gatkcnv.brs/work/92/579e5a48aa9e52cd0e1df603266809/B00HOTD.counts.hdf5 (229 / 347); HDF5-DIAG: Error detected in HDF5 (1.8.14) thread 0:; #000: /mnt/scr1/abyrne/HDFJava-platypus-2.11/native/HDF5-prefix/src/HDF5/src/H5Dio.c line 173 in H5Dread(): can'; t read data; major: Dataset; minor: Read failed; #001: /mnt/scr1/abyrne/HDFJava-platypus-2.11/native/HDF5-prefix/src/HDF5/src/H5Dio.c line 550 in H5D__read(): ca; n't read data; major: Dataset; minor: Read failed; #002: /mnt/scr1/abyrne/HDFJava-platypus-2.11/native/HDF5-prefix/src/HDF5/src/H5Dcontig.c line 543 in H5D__contig; _read(): contiguous read failed; major: Dataset; minor: Read failed; #003: /mnt/scr1/abyrne/HDFJava-platypus-2.11/native/HDF5-prefix/src/HDF5/src/H5Dscatgath.c line 517 in H5D__scat; gath_read(): file gather failed; major: Low-level I/O; minor: Read failed; #004: /mnt/scr1/abyrne/HDFJava-platypus-2.11/native/HDF5-prefix/src/HDF5/src/H5Dscatgath.c line 253 in H5D__gath; er_file(): read error; major: Dataspace; minor: Read failed; #005: /mnt/scr1/abyrne/HDFJava-platypus-2.11/native/HDF5-prefix/src/HDF5/src/H5Dcontig.c line 873 in H5D__contig; _readvv(): can't perform vectorized sieve buffer read; major: Dataset; minor: Can't operate on object; #006: /mnt/scr1/abyrne/HDFJava-platypus-2.11/native/HDF5-prefix/src/HDF5/src/H5VM.c line 1457 in H5VM_opvv(): ca; n't perform operation; major: Internal error (too specific to document in detail); minor: Can't operate on object; #007: /mnt/scr1/abyrne/HDFJava-platypus-2.11/native/HDF5-prefix/src/HDF5/src/H5Dcontig.c line 696 in H5D__contig; _readvv_sieve_cb(): block read failed; major: Dataset; minor: Read failed; #008: /mnt/scr1/abyrne/HDFJava-platypus-2.11/native/HDF5-prefix/src/HDF5/src/H5Fio.c line 120 in H5F_block_read(; ): read through metadata accumulator failed; major: Low-level I/O; minor: Read failed; #009: /mnt/scr1/abyrne/HDFJava-platypus-2.11/native/HDF5-prefix/src/HDF5/src/H5Faccum.c line 263 in H5F__accum_r; ead(): driver read request f,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7202:1405,error,error,1405,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7202,1,['error'],['error']
Availability,"1/Cosmic.db -> file:///home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s/cosmic/hg19/Cosmic.db; 15:41:51.190 INFO DataSourceUtils - Resolved data source file path: file:///home/shiyang/softwares/gatk-4.1.8.1/gencode.v34lift37.annotation.REORDERED.gtf -> file:///home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s/gencode/hg19/gencode.v34lift37.annotation.REORDERED.gtf; 15:41:51.190 INFO DataSourceUtils - Setting lookahead cache for data source: Gencode : 100000; 15:41:51.191 WARN GencodeGtfCodec - GENCODE GTF Header line 1 has a version number that is above maximum tested version (v 28) (given: 34): ##description: evidence-based annotation of the human genome (GRCh38), version 34 (Ensembl 100), mapped to GRCh37 with gencode-backmap Continuing, but errors may occur.; 15:41:51.192 WARN GencodeGtfCodec - GENCODE GTF Header line 1 has a version number that is above maximum tested version (v 28) (given: 34): ##description: evidence-based annotation of the human genome (GRCh38), version 34 (Ensembl 100), mapped to GRCh37 with gencode-backmap Continuing, but errors may occur.; 15:41:51.192 INFO FeatureManager - Using codec GencodeGtfCodec to read file file:///home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s/gencode/hg19/gencode.v34lift37.annotation.REORDERED.gtf; 15:41:51.193 WARN GencodeGtfCodec - GENCODE GTF Header line 1 has a version number that is above maximum tested version (v 28) (given: 34): ##description: evidence-based annotation of the human genome (GRCh38), version 34 (Ensembl 100), mapped to GRCh37 with gencode-backmap Continuing, but errors may occur.; 15:41:51.201 INFO DataSourceUtils - Resolved data source file path: file:///home/shiyang/softwares/gatk-4.1.8.1/gencode.v34lift37.pc_transcripts.fa -> file:///home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s/gencode/hg19/gencode.v34lift37.pc_transcripts.fa; 15:41:54.713 INFO Dat",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6758:18350,error,errors,18350,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6758,1,['error'],['errors']
Availability,"10:33:37.508 INFO Mutect2 - Start Date/Time: August 28, 2019 at 10:33:35 AM GMT; 10:33:37.509 INFO Mutect2 - ------------------------------------------------------------; 10:33:37.509 INFO Mutect2 - ------------------------------------------------------------; 10:33:37.510 INFO Mutect2 - HTSJDK Version: 2.20.1; 10:33:37.510 INFO Mutect2 - Picard Version: 2.20.5; 10:33:37.510 INFO Mutect2 - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 10:33:37.511 INFO Mutect2 - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 10:33:37.511 INFO Mutect2 - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 10:33:37.511 INFO Mutect2 - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 10:33:37.513 INFO Mutect2 - Deflater: IntelDeflater; 10:33:37.513 INFO Mutect2 - Inflater: IntelInflater; 10:33:37.514 INFO Mutect2 - GCS max retries/reopens: 20; 10:33:37.514 INFO Mutect2 - Requester pays: disabled; 10:33:37.514 INFO Mutect2 - Initializing engine; 10:33:37.874 INFO Mutect2 - Shutting down engine; [August 28, 2019 at 10:33:37 AM GMT] org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2 done. Elapsed time: 0.05 minutes.; Runtime.totalMemory()=161480704; java.lang.NullPointerException; at org.broadinstitute.hellbender.utils.SequenceDictionaryUtils.getContigNames(SequenceDictionaryUtils.java:463); at org.broadinstitute.hellbender.utils.SequenceDictionaryUtils.getCommonContigsByName(SequenceDictionaryUtils.java:457); at org.broadinstitute.hellbender.utils.SequenceDictionaryUtils.compareDictionaries(SequenceDictionaryUtils.java:234); at org.broadinstitute.hellbender.utils.SequenceDictionaryUtils.validateDictionaries(SequenceDictionaryUtils.java:150); at org.broadinstitute.hellbender.utils.SequenceDictionaryUtils.validateDictionaries(SequenceDictionaryUtils.java:98); at org.broadinstitute.hellbender.engine.GATKTool.validateSequenceDictionaries(GATKTool.java:769); at org.broadinstitute.hellbender.engine.GATKTool.onStartup(GATKTool.java:711); at org.broadinstitute.hellbender.engin",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6142:2758,down,down,2758,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6142,1,['down'],['down']
Availability,"11:05:38.056 INFO CountVariantsSpark - Shutting down engine; [May 12, 2016 11:05:38 AM AST] org.broadinstitute.hellbender.tools.spark.pipelines.CountVariantsSpark done. Elapsed time: 0.08 minutes.; Runtime.totalMemory()=3114270720; htsjdk.tribble.TribbleException: Input stream does not contain a BCF encoded file; BCF magic header info not found, at record 0 with position 0:; at htsjdk.variant.bcf2.BCF2Codec.error(BCF2Codec.java:492); at htsjdk.variant.bcf2.BCF2Codec.readHeader(BCF2Codec.java:153); at org.seqdoop.hadoop_bam.BCFSplitGuesser.<init>(BCFSplitGuesser.java:109); at org.seqdoop.hadoop_bam.BCFSplitGuesser.<init>(BCFSplitGuesser.java:89); at org.seqdoop.hadoop_bam.VCFInputFormat.addGuessedSplits(VCFInputFormat.java:254); at org.seqdoop.hadoop_bam.VCFInputFormat.fixBCFSplits(VCFInputFormat.java:242); at org.seqdoop.hadoop_bam.VCFInputFormat.getSplits(VCFInputFormat.java:221); at org.apache.spark.rdd.NewHadoopRDD.getPartitions(NewHadoopRDD.scala:95); at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239); at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237); at scala.Option.getOrElse(Option.scala:120); at org.apache.spark.rdd.RDD.partitions(RDD.scala:237); at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35); at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239); at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237); at scala.Option.getOrElse(Option.scala:120); at org.apache.spark.rdd.RDD.partitions(RDD.scala:237); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1910); at org.apache.spark.rdd.RDD.count(RDD.scala:1121); at org.apache.spark.api.java.JavaRDDLike$class.count(JavaRDDLike.scala:445); at org.apache.spark.api.java.AbstractJavaRDDLike.count(JavaRDDLike.scala:47); at org.broadinstitute.hellbender.tools.spark.pipelines.CountVariantsSpark.runTool(CountVariantsSpark.java:39); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKS",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1815:48,down,down,48,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1815,2,"['down', 'error']","['down', 'error']"
Availability,11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:106); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:61); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.taskgraph.DefaultTaskGraphExecuter$EventFiringTaskWorker.execute(DefaultTaskGraphExecuter.java:228); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.taskgraph.DefaultTaskGraphExecuter$EventFiringTaskWorker.execute(DefaultTaskGraphExecuter.java:215); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.taskgraph.AbstractTaskPlanExecutor$TaskExecutorWorker.processTask(AbstractTaskPlanExecutor.java:77); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.taskgraph.AbstractTaskPlanExecutor$TaskExecutorWorker.run(AbstractTaskPlanExecutor.java:58); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.taskgraph.DefaultTaskPlanExecutor.process(DefaultTaskPlanExecutor.java:32); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.taskgraph.DefaultTaskGraphExecuter.execute(DefaultTaskGraphExecuter.java:113); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.SelectedTaskExecutionAction.execute(SelectedTaskExecutionAction.java:37); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.DefaultBuildExecuter.execute(DefaultBuildExecuter.java:37); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.DefaultBuildExecut,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2802:3973,ERROR,ERROR,3973,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2802,1,['ERROR'],['ERROR']
Availability,11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.exec.InProcessBuildActionExecuter.execute(InProcessBuildActionExecuter.java:26); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.tooling.internal.provider.ContinuousBuildActionExecuter.execute(ContinuousBuildActionExecuter.java:75); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.tooling.internal.provider.ContinuousBuildActionExecuter.execute(ContinuousBuildActionExecuter.java:49); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.tooling.internal.provider.ServicesSetupBuildActionExecuter.execute(ServicesSetupBuildActionExecuter.java:49); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.tooling.internal.provider.ServicesSetupBuildActionExecuter.execute(ServicesSetupBuildActionExecuter.java:31); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.ExecuteBuild.doBuild(ExecuteBuild.java:67); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.BuildCommandOnly.execute(BuildCommandOnly.java:36); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.WatchForDisconnection.execute(WatchForDisconnection.java:37); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.ResetD,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2802:8797,ERROR,ERROR,8797,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2802,1,['ERROR'],['ERROR']
Availability,"1209008209559916471805773_0002_m_000000_3: Committed. Elapsed time: 3 ms.; 23/11/16 12:09:10 INFO Executor: Finished task 0.0 in stage 2.0 (TID 3). 4103 bytes result sent to driver; 23/11/16 12:09:10 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 3) in 10327 ms on SRINIVASiNDRARAVI (executor driver) (2/2); 23/11/16 12:09:10 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool ; 23/11/16 12:09:10 INFO DAGScheduler: ResultStage 2 (parquet at StudentAws.scala:36) finished in 10.361 s; 23/11/16 12:09:10 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job; 23/11/16 12:09:10 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished; 23/11/16 12:09:10 INFO DAGScheduler: Job 2 finished: parquet at StudentAws.scala:36, took 10.369237 s; 23/11/16 12:09:10 INFO FileFormatWriter: Start to commit write Job b17a4b92-9ee1-46cc-858a-08ed0b22fb8b.; 23/11/16 12:09:10 ERROR FileFormatWriter: Aborting job b17a4b92-9ee1-46cc-858a-08ed0b22fb8b.; java.lang.UnsatisfiedLinkError: org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Ljava/lang/String;I)Z; 	at org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Native Method); 	at org.apache.hadoop.io.nativeio.NativeIO$Windows.access(NativeIO.java:793); 	at org.apache.hadoop.fs.FileUtil.canRead(FileUtil.java:1249); 	at org.apache.hadoop.fs.FileUtil.list(FileUtil.java:1454); 	at org.apache.hadoop.fs.RawLocalFileSystem.listStatus(RawLocalFileSystem.java:601); 	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1972); 	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:2014); 	at org.apache.hadoop.fs.ChecksumFileSystem.listStatus(ChecksumFileSystem.java:761); 	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1972); 	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:2014); 	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.getAllCommittedTaskPaths(FileOutputCommitter.java:33",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8587:1891,ERROR,ERROR,1891,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8587,1,['ERROR'],['ERROR']
Availability,"13 15:46:56 EDT 2020] CreateSequenceDictionary --OUTPUT /media/glier_ubuntu/4TB/Javad_Final/5-trinity/Fastajavad_Trinity/Trinity.dict --REFERENCE /media/glier_ubuntu/4TB/Javad_Final/5-trinity/Fastajavad_Trinity/Trinity.fasta --TRUNCATE_NAMES_AT_WHITESPACE true --NUM_SEQUENCES 2147483647 --VERBOSITY INFO --QUIET false --VALIDATION_STRINGENCY STRICT --COMPRESSION_LEVEL 2 --MAX_RECORDS_IN_RAM 500000 --CREATE_INDEX false --CREATE_MD5_FILE false --GA4GH_CLIENT_SECRETS client_secrets.json --help false --version false --showHidden false --USE_JDK_DEFLATER false --USE_JDK_INFLATER false; May 13, 2020 3:46:57 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; [Wed May 13 15:46:57 EDT 2020] Executing as glier_ubuntu@glierubuntu-Precision-7920-Tower on Linux 4.15.0-99-generic amd64; OpenJDK 64-Bit Server VM 11.0.7+10-post-Ubuntu-2ubuntu218.04; Deflater: Intel; Inflater: Intel; Provider GCS is available; Picard version: Version:4.1.1.0; [Wed May 13 15:46:57 EDT 2020] picard.sam.CreateSequenceDictionary done. Elapsed time: 0.03 minutes.; Runtime.totalMemory()=2107637760; To get help, see http://broadinstitute.github.io/picard/index.html#GettingHelp; picard.PicardException: /media/glier_ubuntu/4TB/Javad_Final/5-trinity/Fastajavad_Trinity/Trinity.dict already exists. Delete this file and try again, or specify a different output file.; 	at picard.sam.CreateSequenceDictionary.doWork(CreateSequenceDictionary.java:209); 	at picard.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:295); 	at org.broadinstitute.hellbender.cmdline.PicardCommandLineProgramExecutor.instanceMain(PicardCommandLineProgramExecutor.java:25); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:162); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:205); 	at org.broadinstitute.hellbender.Main.main(Main.java:291); Using GATK jar /home/glier_ubuntu/gatk-4.1.1.0/g",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6604:2118,avail,available,2118,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6604,1,['avail'],['available']
Availability,"132 INFO PostprocessGermlineCNVCalls - Analyzing shard 5 / 8...; 23:46:11.901 INFO PostprocessGermlineCNVCalls - Analyzing shard 6 / 8...; 23:46:12.730 INFO PostprocessGermlineCNVCalls - Analyzing shard 7 / 8...; 23:46:14.288 INFO PostprocessGermlineCNVCalls - Analyzing shard 8 / 8...; 23:46:15.617 INFO PostprocessGermlineCNVCalls - Generating segments...; 01:48:30.792 INFO PostprocessGermlineCNVCalls - Parsing Python output...; 01:48:30.875 INFO PostprocessGermlineCNVCalls - Writing segments VCF file to /srv/scratch/testardqu/CNV_Hyperexome/segments_joint/genotyped-segments-SAMPLE_6.vcf.gz...; 01:48:46.860 INFO PostprocessGermlineCNVCalls - Generating denoised copy ratios...; 01:48:47.487 INFO PostprocessGermlineCNVCalls - Writing denoised copy ratios to /srv/scratch/testardqu/CNV_Hyperexome/ratios_joint/denoised-copy-ratios-SAMPLE_6.tsv...; 01:48:47.773 INFO PostprocessGermlineCNVCalls - PostprocessGermlineCNVCalls complete.; 01:48:47.773 INFO PostprocessGermlineCNVCalls - Shutting down engine; [December 6, 2022 1:48:47 AM GMT] org.broadinstitute.hellbender.tools.copynumber.PostprocessGermlineCNVCalls done. Elapsed time: 123.29 minutes.; Runtime.totalMemory()=7257194496; Using GATK jar /gatk/gatk-package-4.3.0.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xms4g -Djava.io.tmpdir=/srv/scratch/testardqu/CNV_Hyperexome/tmp/ -jar /gatk/gatk-package-4.3.0.0-local.jar PostprocessGermlineCNVCalls --model-shard-path /srv/scratch/testardqu/CNV_Hyperexome/GermlineCNVCaller/GermlineCNVCaller_1_of_8-model/ --model-shard-path /srv/scratch/testardqu/CNV_Hyperexome/GermlineCNVCaller/GermlineCNVCaller_2_of_8-model/ --model-shard-path /srv/scratch/testardqu/CNV_Hyperexome/GermlineCNVCaller/GermlineCNVCaller_3_of_8-model/ --model-shard-path /srv/scratch/testardqu/CNV_Hyperexome/GermlineCNVCaller/GermlineCNVCaller_4_of_8-model/ --model-shard-path /s",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8183:11131,down,down,11131,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8183,1,['down'],['down']
Availability,"13:24:09.472 INFO IntelPairHmm - Flush-to-zero (FTZ) is enabled when running PairHMM; 13:24:09.473 INFO IntelPairHmm - Available threads: 24; 13:24:09.473 INFO IntelPairHmm - Requested threads: 4; 13:24:09.473 INFO PairHMM - Using the OpenMP multi-threaded AVX-accelerated native PairHMM implementation; 13:24:09.501 INFO ProgressMeter - Starting traversal; 13:24:09.502 INFO ProgressMeter - Current Locus Elapsed Minutes Regions Processed Regions/Minute; 13:24:19.721 INFO ProgressMeter - chr1:634040 0.2 2460 14443.7; 13:24:29.736 INFO ProgressMeter - chr1:1564703 0.3 7220 21409.5; .; .; .; 15:28:55.286 INFO ProgressMeter - chrM:12891 124.8 11474080 91967.0; 15:29:08.985 INFO VectorLoglessPairHMM - Time spent in setup for JNI call : 10.162159898; 15:29:08.986 INFO PairHMM - Total compute time in PairHMM computeLogLikelihoods() : 1047.646162184; 15:29:08.986 INFO SmithWatermanAligner - Total compute time in java Smith-Waterman : 1077.35 sec; 15:29:08.986 INFO Mutect2 - Shutting down engine; [September 25, 2020 3:29:08 PM BST] org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2 done. Elapsed time: 125.01 minutes.; Runtime.totalMemory()=7713325056; java.lang.NullPointerException; at org.broadinstitute.hellbender.transformers.PalindromeArtifactClipReadTransformer.apply(PalindromeArtifactClipReadTransformer.java:98); at org.broadinstitute.hellbender.transformers.PalindromeArtifactClipReadTransformer.apply(PalindromeArtifactClipReadTransformer.java:49); at org.broadinstitute.hellbender.transformers.ReadTransformer.lambda$andThen$f85d1091$1(ReadTransformer.java:20); at org.broadinstitute.hellbender.utils.iterators.ReadTransformingIterator.next(ReadTransformingIterator.java:42); at org.broadinstitute.hellbender.utils.iterators.ReadTransformingIterator.next(ReadTransformingIterator.java:14); at org.broadinstitute.hellbender.utils.iterators.PushToPullIterator.fillCache(PushToPullIterator.java:72); at org.broadinstitute.hellbender.utils.iterators.PushToPullIterator.advanceTo",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6851:4470,down,down,4470,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6851,1,['down'],['down']
Availability,16) ; ; at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2AlleleFilter.errorProbabilities(Mutect2AlleleFilter.java:86) ; ; at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.lambda$new$0(ErrorProbabilities.java:27) ; ; at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1321) ; ; at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169) ; ; at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382) ; ; at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481) ; ; at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471) ; ; at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708) ; ; at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234) ; ; at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499) ; ; at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.<init>(ErrorProbabilities.java:25) ; ; at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.accumulateData(Mutect2FilteringEngine.java:138) ; ; at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls.nthPassApply(FilterMutectCalls.java:154) ; ; at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverse$0(MultiplePassVariantWalker.java:40) ; ; at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverseVariants$1(MultiplePassVariantWalker.java:77) ; ; at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184) ; ; at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175) ; ; at java.util.Iterator.forEachRemaining(Iterator.java:116) ; ; at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801) ; ; at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481) ; ; at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPip,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7298:8324,Error,ErrorProbabilities,8324,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7298,1,['Error'],['ErrorProbabilities']
Availability,"17.402 INFO ProgressMeter - chr20:26553705 51.1 64000 1252.3; 12:17:04.504 INFO ProgressMeter - chr20:29573718 52.9 65000 1228.9; 12:18:23.620 INFO ProgressMeter - chr20:30705782 54.2 66000 1217.5; 12:20:09.590 INFO ProgressMeter - chr21:5249184 56.0 67000 1196.9; 12:22:03.446 INFO ProgressMeter - chr21:10481328 57.9 68000 1175.0; 12:23:03.667 INFO ProgressMeter - chr22:11316842 58.9 69000 1171.9; 12:24:57.983 INFO ProgressMeter - chr22:16127710 60.8 70000 1151.6; 12:26:31.457 INFO ProgressMeter - chr22:25997978 62.3 71000 1138.9; 12:27:09.230 INFO ProgressMeter - chrX:29806474 63.0 72000 1143.4; 12:27:53.073 INFO ProgressMeter - chrX:67820874 63.7 73000 1146.0; 12:29:03.144 INFO ProgressMeter - chrX:86707912 64.9 74000 1140.8; 12:30:07.160 INFO ProgressMeter - chrX:114791793 65.9 75000 1137.5; 12:30:59.264 INFO ProgressMeter - chrX:141227354 66.8 76000 1137.6; 12:31:52.052 INFO ProgressMeter - chrX:153138333 67.7 77000 1137.6; 12:33:18.782 INFO FilterAlignmentArtifacts - Shutting down engine; [February 24, 2023 12:33:18 PM CST] org.broadinstitute.hellbender.tools.walkers.realignmentfilter.FilterAlignmentArtifacts done. Elapsed time: 69.15 minutes.; Runtime.totalMemory()=12185501696; org.broadinstitute.hellbender.exceptions.GATKException: Exception thrown at chr1_KI270708v1_random:2666 [VC /raid/tmp/82/68cd46b704bab21cb8661465e5c2b8/WGS-NA12878.filtered.vcf @ chr1_KI270708v1_random:2666 Q. of type=SNP alleles=[T*, A] attr={AS_FilterStatus=SITE, AS_SB_TABLE=[7, 9|3, 11], DP=30, ECNT=2, GERMQ=13, MBQ=[33, 37], MFRL=[317, 323], MMQ=[48, 47], MPOS=47, POPAF=7.30, ROQ=83, TLOD=47.80} GT=GT:AD:AF:DP:F1R2:F2R1:FAD:SB 0/1:16,14:0.486:30:8,9:5,4:15,14:7,9,3,11 filters=; at org.broadinstitute.hellbender.engine.MultiVariantWalker.lambda$traverse$1(MultiVariantWalker.java:145); at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.stream.ReferencePipeline$2$1.accept(",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8221:9875,down,down,9875,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8221,1,['down'],['down']
Availability,"18:02:08.659 INFO ProgressMeter - chr1:189989846 6.2 11368000 1838773.1; 18:02:18.685 INFO ProgressMeter - chr1:196788442 6.3 11527000 1815428.1; 18:02:28.690 INFO ProgressMeter - chr1:201317675 6.5 11862000 1820376.8; 18:02:38.693 INFO ProgressMeter - chr1:204176575 6.7 12290000 1839012.8; 18:02:48.701 INFO ProgressMeter - chr1:207325661 6.8 12708000 1855250.2; 18:02:58.737 INFO ProgressMeter - chr1:211941783 7.0 13001000 1852781.7; 18:03:08.789 INFO ProgressMeter - chr1:217052843 7.2 13270000 1847019.0; 18:03:18.840 INFO ProgressMeter - chr1:222942848 7.4 13509000 1837446.7; 18:03:28.843 INFO ProgressMeter - chr1:227016956 7.5 13856000 1842855.4; 18:03:38.858 INFO ProgressMeter - chr1:230704130 7.7 14213000 1849294.6; 18:03:48.900 INFO ProgressMeter - chr1:235326795 7.9 14501000 1846539.8; 18:03:58.915 INFO ProgressMeter - chr1:239911899 8.0 14790000 1844143.5; 18:04:08.930 INFO ProgressMeter - chr1:246522306 8.2 15003000 1832561.8; 18:04:17.556 INFO BaseRecalibrator - Shutting down engine; [May 24, 2019 6:04:17 PM EDT] org.broadinstitute.hellbender.tools.walkers.bqsr.BaseRecalibrator done. Elapsed time: 8.39 minutes.; Runtime.totalMemory()=4407164928; htsjdk.samtools.SAMFormatException: Invalid GZIP header; 	at htsjdk.samtools.util.BlockGunzipper.unzipBlock(BlockGunzipper.java:121); 	at htsjdk.samtools.util.BlockGunzipper.unzipBlock(BlockGunzipper.java:96); 	at htsjdk.samtools.util.BlockCompressedInputStream.inflateBlock(BlockCompressedInputStream.java:550); 	at htsjdk.samtools.util.BlockCompressedInputStream.processNextBlock(BlockCompressedInputStream.java:532); 	at htsjdk.samtools.util.BlockCompressedInputStream.nextBlock(BlockCompressedInputStream.java:468); 	at htsjdk.samtools.util.BlockCompressedInputStream.seek(BlockCompressedInputStream.java:380); 	at htsjdk.tribble.readers.TabixReader$IteratorImpl.next(TabixReader.java:427); 	at htsjdk.tribble.readers.TabixIteratorLineReader.readLine(TabixIteratorLineReader.java:46); 	at htsjdk.tribble.TabixFeatureReader$",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5968:7745,down,down,7745,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5968,1,['down'],['down']
Availability,"1:644:1:1; chr22	19895477	CNV_chr22_19895477_19901476	N	<DUP>	2.30	.	END=19901476	GT:CN:NP:QA:QS:QSE:QSS	./.:3:6:1:2:1:0; chr22	19901477	CNV_chr22_19901477_19946476	N	<DEL>	123.62	.	END=19946476	GT:CN:NP:QA:QS:QSE:QSS	1/1:0:45:0:124:1:1; chr22	19946477	CNV_chr22_19946477_19971476	N	<DUP>	6.86	.	END=19971476	GT:CN:NP:QA:QS:QSE:QSS	./.:3:25:0:7:2:1; chr22	19971477	CNV_chr22_19971477_20003000	N	<DEL>	198.68	.	END=20003000	GT:CN:NP:QA:QS:QSE:QSS	1/1:0:32:0:199:2:2. ```. #### Actual behavior. - `gatkgermlinecnvcaller_genotyped-intervals-COHORT_0.woTimestamp.vcf` (`##contig` cut from header and only first 5 `chr22` CNVs present). ```; ##fileformat=VCFv4.2; ##FORMAT=<ID=CN,Number=1,Type=Integer,Description=""Copy number maximum a posteriori value"">; ##FORMAT=<ID=CNLP,Number=.,Type=Integer,Description=""Copy number log posterior (in Phred-scale) rounded down"">; ##FORMAT=<ID=CNQ,Number=1,Type=Integer,Description=""Genotype call quality as the difference between the best and second best phred-scaled log posterior scores"">; ##FORMAT=<ID=GT,Number=1,Type=Integer,Description=""Genotype"">; ##INFO=<ID=END,Number=1,Type=Integer,Description=""End coordinate of the variant"">; ##contig=<ID=chr1,length=248956422,assembly=GRCh38.d1.vd1>; ...; ##contig=<ID=HPV-mSD2,length=7300,assembly=GRCh38.d1.vd1>; ##source=PostprocessGermlineCNVCalls; #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	E07002_normal; chr1	10000	CNV_chr1_10000_10999	N	<DEL>,<DUP>	.	.	END=10999	GT:CN:CNLP:CNQ	1:0:0,78,88,96,104,111:78; chr1	11000	CNV_chr1_11000_11999	N	<DEL>,<DUP>	.	.	END=11999	GT:CN:CNLP:CNQ	1:0:0,80,85,88,90,93:80; chr1	12000	CNV_chr1_12000_12999	N	<DEL>,<DUP>	.	.	END=12999	GT:CN:CNLP:CNQ	1:0:0,89,101,110,119,126:89; chr1	13000	CNV_chr1_13000_13999	N	<DEL>,<DUP>	.	.	END=13999	GT:CN:CNLP:CNQ	1:0:0,89,96,101,105,108:89; chr1	14000	CNV_chr1_14000_14999	N	<DEL>,<DUP>	.	.	END=14999	GT:CN:CNLP:CNQ	1:0:0,86,91,94,96,98:86; chr1	15000	CNV_chr1_15000_15999	N	<DEL>,<DUP>	.	.	END=15999	GT:CN:CNLP:CNQ	1:0:0,83,89,94,99,103:",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8619:19664,down,down,19664,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8619,1,['down'],['down']
Availability,1bef1c81f885c26b2b56c8616b7a705171e4f from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 2018-03-09T13:13:41.330127806Z 13:13:41.329 INFO GenotypeGVCFs - Initializing engine; 2018-03-09T13:13:44.528605497Z 13:13:44.528 INFO GenotypeGVCFs - Done initializing engine; 2018-03-09T13:13:45.237843760Z 13:13:45.235 INFO ProgressMeter - Starting traversal; 2018-03-09T13:13:45.237903383Z 13:13:45.235 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 2018-03-09T13:13:56.665869885Z 13:13:56.662 INFO ProgressMeter - chr13:82078938 0.2 13000 68265.4; 2018-03-09T13:14:07.517952300Z 13:14:07.517 INFO ProgressMeter - chr13:82096938 0.4 31000 83475.5; 2018-03-09T13:14:17.546110604Z 13:14:17.545 INFO ProgressMeter - chr13:82123938 0.5 58000 107706.6; 2018-03-09T13:14:28.760222694Z 13:14:28.759 INFO ProgressMeter - chr13:82144938 0.7 79000 108905.4; 2018-03-09T13:14:39.292149466Z 13:14:39.289 INFO ProgressMeter - chr13:82169938 0.9 104000 115440.1; 2018-03-09T13:14:49.877851947Z 13:14:49.873 INFO ProgressMeter - chr13:82193938 1.1 128000 118815.6; 2018-03-09T13:15:01.109839332Z 13:15:01.106 INFO ProgressMeter - chr13:82224938 1.3 159000 125741.4; 2018-03-09T13:15:11.237868051Z 13:15:11.234 INFO ProgressMeter - chr13:82250938 1.4 185000 129071.3; 2018-03-09T13:15:22.457899462Z 13:15:22.455 INFO ProgressMeter - chr13:82284938 1.6 219000 135157.4; 2018-03-09T13:15:32.561846058Z 13:15:32.556 INFO ProgressMeter - chr13:82319938 1.8 254000 142003.9; 2018-03-09T13:15:42.624917849Z 13:15:42.624 INFO ProgressMeter - chr13:82348938 2.0 283000 144647.3; 2018-03-09T13:32:20.050317641Z 13:32:20.049 INFO ProgressMeter - chr13:82369938 18.6 304000 16361.5; 2018-03-09T13:47:24.213333084Z 13:47:24.212 INFO ProgressMeter - chr13:82373938 33.6 308000 9153.2; 2018-03-09T14:21:34.139657997Z 14:21:34.139 INFO ProgressMeter - chr13:82377938 67.8 312000 4600.7; 2018-03-10T07:14:27.162870189Z 07:14:27.161 INFO GenotypeGVCFs - Shutting down engine; ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4518:4759,down,down,4759,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4518,1,['down'],['down']
Availability,1cb8661465e5c2b8/WGS-NA12878.filtered.vcf; 11:24:10.814 INFO FilterAlignmentArtifacts - Done initializing engine; 11:24:10.816 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/gatk-4.3.0.0/gatk-package-4.3.0.0-local.jar!/com/intel/gkl/native/libgkl_utils.so; 11:24:10.817 INFO NativeLibraryLoader - Loading libgkl_smithwaterman.so from jar:file:/gatk-4.3.0.0/gatk-package-4.3.0.0-local.jar!/com/intel/gkl/native/libgkl_smithwaterman.so; 11:24:10.818 INFO IntelSmithWaterman - Using CPU-supported AVX-512 instructions; 11:24:10.818 INFO SmithWatermanAligner - Using AVX accelerated SmithWaterman implementation; 11:24:10.957 INFO NativeLibraryLoader - Loading libgkl_pairhmm_omp.so from jar:file:/gatk-4.3.0.0/gatk-package-4.3.0.0-local.jar!/com/intel/gkl/native/libgkl_pairhmm_omp.so; 11:24:10.980 INFO IntelPairHmm - Using CPU-supported AVX-512 instructions; 11:24:10.980 INFO IntelPairHmm - Flush-to-zero (FTZ) is enabled when running PairHMM; 11:24:10.981 INFO IntelPairHmm - Available threads: 80; 11:24:10.981 INFO IntelPairHmm - Requested threads: 4; 11:24:10.981 INFO PairHMM - Using the OpenMP multi-threaded AVX-accelerated native PairHMM implementation; 11:24:10.981 INFO ProgressMeter - Starting traversal; 11:24:10.981 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 11:25:26.222 INFO ProgressMeter - chr1:32527418 1.3 1000 797.5; 11:26:14.235 INFO ProgressMeter - chr1:103944651 2.1 2000 973.6; 11:26:59.367 INFO ProgressMeter - chr1:121884881 2.8 3000 1069.0; 11:28:22.595 INFO ProgressMeter - chr1:124412677 4.2 4000 953.8; 11:30:27.936 INFO ProgressMeter - chr1:146326436 6.3 5000 795.9; 11:31:16.814 INFO ProgressMeter - chr1:151781328 7.1 6000 845.4; 11:31:47.039 INFO ProgressMeter - chr1:222591703 7.6 7000 920.9; 11:32:23.165 INFO ProgressMeter - chr2:33832294 8.2 8000 975.2; 11:32:57.177 INFO ProgressMeter - chr2:90283356 8.8 9000 1026.2; 11:34:06.535 INFO ProgressMeter - chr2:93744700 9.9 10000 1007.5; 11:34:46.020 IN,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8221:4295,Avail,Available,4295,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8221,1,['Avail'],['Available']
Availability,2 --GVCFGQBands 23 --GVCFGQBands 24 --GVCFGQBands 25 --GVCFGQBands 26 --GVCFGQBands 27 --GVCFGQBands 28 --GVCFGQBands 29 --GVCFGQBands 30 --GVCFGQBands 31 --GVCFGQBands 32 --GVCFGQBands 33 --GVCFGQBands 34 --; GVCFGQBands 35 --GVCFGQBands 36 --GVCFGQBands 37 --GVCFGQBands 38 --GVCFGQBands 39 --GVCFGQBands 40 --GVCFGQBands 41 --GVCFGQBands 42 --GVCFGQBands 43 --GVCFGQBands 44 --GVCFGQBands 45 --GVCFGQBands 46 --GVCFGQBands 47 --GVCFGQBands 48 --GVCFGQBands 49 --GVCFGQBands 50 --GVCFGQBands 51 --GVCFGQBands 52 --GVCFGQBands 53 --GVCFGQBands 54 --GVCFGQBands 55 --GVCFGQBands 56 --GVCFGQBands 57 --GVCFGQBands 58 --GVCFGQBands 59 --GVC; FGQBands 60 --GVCFGQBands 70 --GVCFGQBands 80 --GVCFGQBands 90 --GVCFGQBands 99 --indelSizeToEliminateInRefModel 10 --useAllelesTrigger false --dontTrimActiveRegions false --maxDiscARExtension 25 --maxGGAARExtension 300 --paddingAroundIndels 150 --paddingAroundSNPs 20 --kmerSize 10 --kmerSize 25 --dontIncreaseKmerSizesForCycles false --allowNonUniqueKmersInRef false --numPruningSamples 1 --recoverDanglingHeads false --doNotR; ecoverDanglingBranches false --minDanglingBranchLength 4 --consensus false --maxNumHaplotypesInPopulation 128 --errorCorrectKmers false --minPruning 2 --debugGraphTransformations false --kmerLengthForReadErrorCorrection 25 --minObservationsForKmerToBeSolid 20 --likelihoodCalculationEngine PairHMM --base_quality_score_threshold 18 --gcpHMM 10 --pair_hmm_implementation FASTEST_AVAILABLE --pcr_indel_model CONSERVATIVE --phredSc; aledGlobalReadMismappingRate 45 --nativePairHmmThreads 4 --useDoublePrecision false --debug false --useFilteredReadsForAnnotations false --emitRefConfidence NONE --bamWriterType CALLED_HAPLOTYPES --disableOptimizations false --justDetermineActiveRegions false --dontGenotype false --dontUseSoftClippedBases false --captureAssemblyFailureBAM false --errorCorrectReads false --doNotRunPhysicalPhasing false --min_base_quality_scor; e 10 --useNewAFCalculator false --annotateNDA false --heterozygosity 0.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3845:4463,recover,recoverDanglingHeads,4463,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3845,3,"['error', 'recover']","['errorCorrectKmers', 'errorCorrectReads', 'recoverDanglingHeads']"
Availability,"2 GiB); 11:00:49.999 INFO MemoryStore - Block broadcast_3_piece0 stored as bytes in memory (estimated size 56.6 KiB, free 1076.2 GiB); 11:00:49.999 INFO BlockManagerInfo - Added broadcast_3_piece0 in memory on 172.20.19.130:43279 (size: 56.6 KiB, free: 1076.2 GiB); 11:00:50.000 INFO SparkContext - Created broadcast 3 from broadcast at ReadsSparkSink.java:146; 11:00:50.033 INFO MemoryStore - Block broadcast_4 stored as values in memory (estimated size 2.1 MiB, free 1076.2 GiB); 11:00:50.045 INFO MemoryStore - Block broadcast_4_piece0 stored as bytes in memory (estimated size 56.6 KiB, free 1076.2 GiB); 11:00:50.045 INFO BlockManagerInfo - Added broadcast_4_piece0 in memory on 172.20.19.130:43279 (size: 56.6 KiB, free: 1076.2 GiB); 11:00:50.045 INFO SparkContext - Created broadcast 4 from broadcast at BamSink.java:76; 11:00:50.120 INFO FileOutputCommitter - File Output Committer Algorithm version is 1; 11:00:50.120 INFO FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false; 11:00:50.177 INFO SparkContext - Starting job: runJob at SparkHadoopWriter.scala:83; 11:00:50.278 INFO DAGScheduler - Registering RDD 14 (mapToPair at SparkUtils.java:161) as input to shuffle 0; 11:00:50.291 INFO DAGScheduler - Got job 1 (runJob at SparkHadoopWriter.scala:83) with 44262 output partitions; 11:00:50.291 INFO DAGScheduler - Final stage: ResultStage 2 (runJob at SparkHadoopWriter.scala:83); 11:00:50.291 INFO DAGScheduler - Parents of final stage: List(ShuffleMapStage 1); 11:00:50.296 INFO DAGScheduler - Missing parents: List(ShuffleMapStage 1); 11:00:50.300 INFO DAGScheduler - Submitting ShuffleMapStage 1 (MapPartitionsRDD[14] at mapToPair at SparkUtils.java:161), which has no missing parents; 11:00:53.974 INFO TaskSchedulerImpl - Cancelling stage 1; 11:00:53.974 INFO TaskSchedulerImpl - Killing all running tasks in stage 1: Stage cancelled; 11:00:53.975 INFO DAGScheduler - ShuffleMapStage 1 (mapToPair at ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8949:3304,failure,failures,3304,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8949,1,['failure'],['failures']
Availability,"2); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1760); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1157); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1157); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1944); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1944); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:99); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). 18/12/21 13:14:09 ERROR scheduler.TaskSetManager: Task 16 in stage 0.0 failed 4 times; aborting job; 13:14:09.675 INFO CountReadsSpark - Shutting down engine; [December 21, 2018 1:14:09 PM EST] org.broadinstitute.hellbender.tools.spark.pipelines.CountReadsSpark done. Elapsed time: 0.97 minutes.; Runtime.totalMemory()=937426944; org.apache.spark.SparkException: Job aborted due to stage failure: Task 16 in stage 0.0 failed 4 times, most recent failure: Lost task 16.3 in stage 0.0 (TID 11, scc-q16.scc.bu.edu, executor 2): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 1, start 146479558, span 42247, expected MD5 8e364a33b9a9350f9ebfac1db38af647; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at s",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547:12366,ERROR,ERROR,12366,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547,1,['ERROR'],['ERROR']
Availability,"2, xx.xx.xx.xx, executor 0, partition 0, PROCESS_LOCAL, 4956 bytes); 18/04/23 20:42:02 INFO TaskSetManager: Lost task 0.2 in stage 0.0 (TID 2) on xx.xx.xx.xx, executor 0: java.lang.IllegalStateException (unread block data) [duplicate 2]; 18/04/23 20:42:02 INFO TaskSetManager: Starting task 0.3 in stage 0.0 (TID 3, xx.xx.xx.xx, executor 0, partition 0, PROCESS_LOCAL, 4956 bytes); 18/04/23 20:42:02 INFO TaskSetManager: Lost task 0.3 in stage 0.0 (TID 3) on xx.xx.xx.xx, executor 0: java.lang.IllegalStateException (unread block data) [duplicate 3]; 18/04/23 20:42:02 ERROR TaskSetManager: Task 0 in stage 0.0 failed 4 times; aborting job; 18/04/23 20:42:02 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool; 18/04/23 20:42:02 INFO TaskSchedulerImpl: Cancelling stage 0; 18/04/23 20:42:02 INFO DAGScheduler: ResultStage 0 (first at ReadsSparkSource.java:221) failed in 11.519 s due to Job aborted due to stage failure: Task 0 in stage 0.0 failed 4 times, most recent failure: Lost task 0.3 in stage 0.0 (TID 3, xx.xx.xx.xx, executor 0): java.lang.IllegalStateException: unread block data; at java.io.ObjectInputStream$BlockDataInputStream.setBlockDataMode(ObjectInputStream.java:2740); at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1567); at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245); at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169); at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027); at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535); at java.io.ObjectInputStream.readObject(ObjectInputStream.java:422); at org.apache.spark.serializer.JavaDeserializationStream.readObject(JavaSerializer.scala:75); at org.apache.spark.serializer.JavaSerializerInstance.deserialize(JavaSerializer.scala:114); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:309); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694:15313,failure,failure,15313,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694,1,['failure'],['failure']
Availability,"2.23.0; 14:50:59.204 INFO FilterMutectCalls - Picard Version: 2.23.3; 14:50:59.204 INFO FilterMutectCalls - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 14:50:59.204 INFO FilterMutectCalls - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 14:50:59.204 INFO FilterMutectCalls - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 14:50:59.205 INFO FilterMutectCalls - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 14:50:59.205 INFO FilterMutectCalls - Deflater: IntelDeflater; 14:50:59.205 INFO FilterMutectCalls - Inflater: IntelInflater; 14:50:59.205 INFO FilterMutectCalls - GCS max retries/reopens: 20; 14:50:59.205 INFO FilterMutectCalls - Requester pays: disabled; 14:50:59.205 INFO FilterMutectCalls - Initializing engine; 14:51:00.692 INFO FeatureManager - Using codec VCFCodec to read file file:///workdir/mparment/data/process/A2683/PTC2_unfiltered.vcf.gz; 14:51:01.406 INFO FilterMutectCalls - Done initializing engine; 14:51:02.360 INFO FilterMutectCalls - Shutting down engine; [December 12, 2020 2:51:02 PM CET] org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls done. Elapsed time: 0.07 minutes.; Runtime.totalMemory()=2385510400; java.lang.IllegalStateException: Duplicate key 7.395307178412063E-4; at java.util.stream.Collectors.lambda$throwingMerger$138(Collectors.java:133); at java.util.stream.Collectors$$Lambda$67/403388441.apply(Unknown Source); at java.util.HashMap.merge(HashMap.java:1245); at java.util.stream.Collectors.lambda$toMap$196(Collectors.java:1320); at java.util.stream.Collectors$$Lambda$69/854719230.accept(Unknown Source); at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:512); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:502); at jav",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6996:3242,down,down,3242,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6996,1,['down'],['down']
Availability,"200 # sigle interval from 100-200 on chr1.; chr1 { 100-200 } # same; chr1 { # same; 100-200; }; * 100-200 # 100-200 at every contig.; chr1,chr2 100-200 # only on chr1 and chr2; chr1 *200 # from 1-200 i.e. start to 200.; chr1 4000* # from 4000 to the end of chr1.; chr1 4000 # only position 4000; chr1 4M # only position 4 million. M=10^6, k/K=10^3 ; chr1 10000-99 # from 10000 to 10099... ; # perhaps is best not to accept this as it might silence user input errors.; # but what about instead?; chr1 100[00-99]; chr1 10000+100 # 100 bps starting at 10000 so 10000-10099; chr1 4k # only poistion 4000.; chr20 1M+32K # from position 1 million extending to the following 32Kbps.; chr20 1M1+32K # from position 1 million and 1 instead. (avoiding all those 0s). chr1 *:200 # consecutive 200bp intervals for the entire chromosome; chr1 *:200(100) # 200bp intervals with 100 gaps; chr1 *:200/20 # 200bp intervals with an overlap of 20bp.; chr1 *:20/200 # 200bp starting every 20 positions (so 180bp overlap); chr1 *:200~20 # 200bp intervals truncating down to 20bp if necessary. ; chr1 { # we can combine interval specs in blocks if they apply to the same contig(s).; 1M-2M:150(20) # from 1 to 2Mbp 150 intervals with 20bp gap; 20M-25M # a big interval from 20 to 25M.; 40012451-40023451 # another standalone interval ; } . ```; ## Interval exclusion; We could specify the exclused interval in the same file:; ```; chr20 *:200 exclude *10000 11000000+10000 32510000* # 200bp intervals except telomere and centromere regions. chr20 { # another way using blocks.; *:200; } excl {; *10000 ; 11000000+10000 ; 32510000*; }. ```. ## Arbitrary interval list. Some other tools cannot specify intervals if these are very specific... for example in exome analysis targets do not fall at regular intervals and are tailor to the capture used. In this case explicit listing is not avoidable. However there are ways to gain. For one thing the language above allows to pack intervals on the same contig on the block so savi",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5702:2005,down,down,2005,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5702,1,['down'],['down']
Availability,"2021/05/27 19:36:04 Delocalizing output /cromwell\_root/memory\_retry\_rc -> gs://fc-51aefb1c-4e8e-4dcb-a59c-62e318ea351a/b4b25c64-84dc-4902-ae53-89bff2091e92/mendelian\_analysis/fd25ef2c-8ed6-4b2a-9df9-b7287511aee8/call-mendelian\_analysis/memory\_retry\_rc 2021/05/27 19:36:04 Delocalizing output /cromwell\_root/rc -> gs://fc-51aefb1c-4e8e-4dcb-a59c-62e318ea351a/b4b25c64-84dc-4902-ae53-89bff2091e92/mendelian\_analysis/fd25ef2c-8ed6-4b2a-9df9-b7287511aee8/call-mendelian\_analysis/rc 2021/05/27 19:36:05 Delocalizing output /cromwell\_root/stdout -> gs://fc-51aefb1c-4e8e-4dcb-a59c-62e318ea351a/b4b25c64-84dc-4902-ae53-89bff2091e92/mendelian\_analysis/fd25ef2c-8ed6-4b2a-9df9-b7287511aee8/call-mendelian\_analysis/stdout 2021/05/27 19:36:06 Delocalizing output /cromwell\_root/stderr -> gs://fc-51aefb1c-4e8e-4dcb-a59c-62e318ea351a/b4b25c64-84dc-4902-ae53-89bff2091e92/mendelian\_analysis/fd25ef2c-8ed6-4b2a-9df9-b7287511aee8/call-mendelian\_analysis/stderr 2021/05/27 19:36:08 Delocalizing output /cromwell\_root/1kgp.chrX.recalibrated.snp\_indel.pass.MVs.byFamily.table -> gs://fc-51aefb1c-4e8e-4dcb-a59c-62e318ea351a/b4b25c64-84dc-4902-ae53-89bff2091e92/mendelian\_analysis/fd25ef2c-8ed6-4b2a-9df9-b7287511aee8/call-mendelian\_analysis/1kgp.chrX.recalibrated.snp\_indel.pass.MVs.byFamily.table Required file output '/cromwell\_root/1kgp.chrX.recalibrated.snp\_indel.pass.MVs.byFamily.table' does not exist. I am running VariantEval to detect Mendelian violations in large joint genotyped VCF files, so I'm running it on a per-chromosome basis. This error only occurs for the chromosome X file, and it only occurs with this FASTA file (GRCh38 on chrX does not cause this issue). IndexFeatureFile is run just before this error, which has also led to successful runs in other chromosomes, so that's not the issue. Any insight on this issue would be appreciated.<br><br><i>(created from <a href='https://broadinstitute.zendesk.com/agent/tickets/161363'>Zendesk ticket #161363</a>)<br>gz#161363</i>",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7304:8603,error,error,8603,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7304,2,['error'],['error']
Availability,"204e+01,0.0000e+00,4.5000e+02,8.5278e+01,1.3828e+02,4.5000e+02,1.3246e+02,4.5000e+02,4.5000e+02:0.00,2.00,5.00,2.00,4.00,5.00,34.77,36.77,36.77,37.77:1,0,18,17:1,0,22,13; ```; * ReblockGVCF (4.2.3.0) output; ```; chr14 60604048 . TCACACA T,<NON_REF> 135.20 . AS_QUALapprox=|140|0;AS_VarDP=1|34|0;DP=44;MQ=250.00;MQRankSum=1.636;QUALapprox=140;RAW_GT_COUNT=0,0,1;RAW_MQandDP=2750000,44;ReadPosRankSum=1.540;VarDP=35 GT:AD:AF:DP:F1R2:F2R1:GQ:ICNT:MB:PL:PRI:SB:SPL 1/1:1,34,0:0.944,0.028,0.000:36:1,20,1,0:0,14,0,0:88:0,29:1,0,22,13:140,88,0,935,101,948:0.00,2.00,5.00,2.00,4.00,5.00,34.77,36.77,36.77,37.77:1,0,18,17:255,0,220; ```. As you can see above, there are small issues related to ReblockGVCF output. First, as you do some kind of ""LeftAlignment"" normalization on the data, you are dropping one of the Alt Variants (in this case, variant ""TCACACA"") but, unfortunately, the FORMAT information is not following this change. The AF still has 3 values from the Dragen output when it was supposed to be 2 (This is the main reason for the GenomicsDBImport error shown here). AD drops one of the reads count, but DP don't follow it (dragen AD = 1,34,1,0 ; DP = 36 ---- reblock AD = 1,34,0 ; DP = 36 <-- it was supposed to be 35). Plus, I'm not sure why, but Reblock doesn't keep the GP format information from dragen. <br>-- Second; * dragen; ```; chrX 25031465 . G GTT,GTTT,<NON_REF> 73.68 PASS DP=9;MQ=241.99;FractionInformativeReads=0.667 GT:AD:AF:DP:F1R2:F2R1:GQ:PL:SPL:ICNT:GP:PRI:SB:MB 1:0,5,1,0:0.833,0.167,0.000:6:0,4,0,0:0,1,1,0:57:78,0,57,73:119,0:0,6:7.3684e+01,8.0247e-06,5.7494e+01,1.0405e+02:0.00,4.00,4.00,34.77:0,0,2,4:0,0,2,4; ```; * ReblockGVCF; ```; chrX 25031465 . G GTT,<NON_REF> 73.68 . AS_QUALapprox=|78|0;AS_VarDP=0|5|0;DP=9;MQ=241.99;QUALapprox=78;RAW_GT_COUNT=0,0,1;RAW_MQandDP=527032,9;VarDP=5 GT:AD:AF:DP:F1R2:F2R1:GQ:ICNT:MB:PL:PRI:SB:SPL 1:0,5,0:0.833,0.167,0.000:6:0,4,0,0:0,1,1,0:73:0,6:0,0,2,4:78,0,73:0.00,4.00,4.00,34.77:0,0,2,4:119,0; ```. Mostly the same happens in",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7589:6908,error,error,6908,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7589,1,['error'],['error']
Availability,"21.683 INFO Concordance - HTSJDK Defaults.USE\_ASYNC\_IO\_WRITE\_FOR\_TRIBBLE : false ; ; 11:26:21.683 INFO Concordance - Deflater: IntelDeflater ; ; 11:26:21.684 INFO Concordance - Inflater: IntelInflater ; ; 11:26:21.684 INFO Concordance - GCS max retries/reopens: 20 ; ; 11:26:21.684 INFO Concordance - Requester pays: disabled ; ; 11:26:21.684 INFO Concordance - Initializing engine ; ; 11:26:22.217 INFO FeatureManager - Using codec VCFCodec to read file file:///scicore/home/cichon/GROUP/memory\_optimization/variants/filtered/NA12878.vcf.gz ; ; 11:26:22.497 INFO FeatureManager - Using codec VCFCodec to read file file:///scicore/home/cichon/GROUP/memory\_optimization/variants/filtered/sample1\_affect.filtered.vcf ; ; 11:26:22.663 INFO Concordance - Done initializing engine ; ; 11:26:22.672 INFO ProgressMeter - Starting traversal ; ; 11:26:22.672 INFO ProgressMeter - Current Locus Elapsed Minutes Records Processed Records/Minute ; ; 11:26:22.682 INFO Concordance - Shutting down engine ; ; \[November 11, 2021 11:26:22 AM CET\] org.broadinstitute.hellbender.tools.walkers.validation.Concordance done. Elapsed time: 0.02 minutes. ; ; Runtime.totalMemory()=559939584 ; ; java.lang.NullPointerException ; ; at htsjdk.variant.variantcontext.VariantContextComparator.compare(VariantContextComparator.java:87) ; ; at org.broadinstitute.hellbender.engine.AbstractConcordanceWalker$ConcordanceIterator.next(AbstractConcordanceWalker.java:192) ; ; at org.broadinstitute.hellbender.engine.AbstractConcordanceWalker$ConcordanceIterator.next(AbstractConcordanceWalker.java:174) ; ; at java.util.Iterator.forEachRemaining(Iterator.java:116) ; ; at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801) ; ; at java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:580) ; ; at org.broadinstitute.hellbender.engine.AbstractConcordanceWalker.traverse(AbstractConcordanceWalker.java:132) ; ; at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.j",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7562:4293,down,down,4293,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7562,1,['down'],['down']
Availability,"210,177,182; chr13	32944609	.	T	A,*,TAAAA,<NON_REF>	0	.	BaseQRankSum=4.278;DP=787;ExcessHet=3.0103;MLEAC=0,1,0,0;MLEAF=0.00,0.500,0.00,0.00;MQRankSum=0.000;RAW_MQandDP=2833200,787;ReadPosRankSum=0.252	GT:AD:DP:GQ:PL:SB	0/2:411,2,357,0,0:770:99:14840,11462,50871,0,41338,45112,17297,53328,47568,2147483647,16108,52933,46273,64838,62381:201,210,177,182; chr13	32944610	.	T	<NON_REF>	.	.	END=32944794	GT:DP:GQ:MIN_DP:PL	0/0:627:99:265:0,120,1800; ```. #### Steps to reproduce; * init; ```; hg19=pipeline/hg19/hg19_chM_male_mask.fa; ```; * reproduce of 4.0.8.1; ```; github.com/broadinstitute/gatk/releases/download/4.0.8.1/gatk-4.0.8.1/gatk HaplotypeCaller -R $hg19 -I target.1k.bam -L target.bed -O target.4.0.8.1.gvcf -ERC GVCF && tail target.4.0.8.1.gvcf; github.com/broadinstitute/gatk/releases/download/4.0.8.1/gatk-4.0.8.1/gatk HaplotypeCaller -R $hg19 -I target.1k.bam -L target.bed -O target.4.0.8.1.vcf && tail target.4.0.8.1.vcf; ```; * reproduce of 4.0.9.0; ```; github.com/broadinstitute/gatk/releases/download/4.0.9.0/gatk-4.0.9.0/gatk HaplotypeCaller -R $hg19 -I target.1k.bam -L target.bed -O target.4.0.9.0.gvcf -ERC GVCF && tail target.4.0.9.0.gvcf; github.com/broadinstitute/gatk/releases/download/4.0.9.0/gatk-4.0.9.0/gatk HaplotypeCaller -R $hg19 -I target.1k.bam -L target.bed -O target.4.0.9.0.vcf && tail target.4.0.9.0.vcf; ```; * reproduce of 4.1.2.0; ```; github.com/broadinstitute/gatk/releases/download/4.1.2.0/gatk-4.1.2.0/gatk HaplotypeCaller -R $hg19 -I target.1k.bam -L target.bed -O target.4.1.2.0.gvcf -ERC GVCF && tail target.4.1.2.0.gvcf; github.com/broadinstitute/gatk/releases/download/4.1.2.0/gatk-4.1.2.0/gatk HaplotypeCaller -R $hg19 -I target.1k.bam -L target.bed -O target.4.1.2.0.vcf && tail target.4.1.2.0.vcf; ```. #### Expected behavior; 1. expose the rule that the second variant (T>TAAAA) filtered (especially for version 4.0.9.0).; 2. give the right QUAL of the second variant; 3. then this type of variant can be retain in VCF as default operation or w",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5975:6358,down,download,6358,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5975,1,['down'],['download']
Availability,22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr9_KI270718v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr9_KI270719v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr9_KI270720v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr11_KI270721v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_GL000009v2_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_GL000225v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_KI270722v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_GL000194v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_KI270723v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_KI270724v1_ran,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4840:4752,reliab,reliable,4752,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4840,1,['reliab'],['reliable']
Availability,"27, 2019 9:15:53 AM CDT] org.broadinstitute.hellbender.tools.walkers.variantutils.SelectVariants done. Elapsed time: 0.07 minutes.; Runtime.totalMemory()=2131755008; htsjdk.tribble.TribbleException: The provided VCF file is malformed at approximately line number 3433: The VCF specification does not allow for whitespace in the INFO field; . Offending field value was ""AC=1;AF=9.671e-04;AN=1034;AS_BaseQRankSum=-1.550;AS_FS=8.334;AS_InbreedingCoeff=-0.3147;AS_MQ=31.69;AS_MQRankSum=-0.200;AS_QD=28.73;AS_ReadPosR; ankSum=nul;AS_SOR=2.235;BaseQRankSum=-1.381e+00;DP=40368;ExcessHet=160.0000;FS=8.334;InbreedingCoeff=-0.3147;MLEAC=7;MLEAF=6.770e-03;MQ=37.13;MQRankSum=0.126;QD=2.46;SOR=2.; 235 GT:AD:DP:GQ:PGT:PID:PL:PS 0/0:75,0:75:0:.:.:0,0,1525; `. However, from the error message I cannot see any whitespace in the INFO field. The /dsgmnt/seq5_llfs/work/xhong/v4100/ApplyVQSR/ExcessHet_joint525_c1_22.SNP.VQSR.g.vcf.gz is the output of following command:. `gatk4.1.0.0 --java-options '-Xmx100g -Xmx100g' ApplyVQSR \; -R /dsgmnt/llfs2/masterdata/geno/hg38/resources_broad_hg38_v0_Homo_sapiens_assembly38.fasta \; -V ${SNPPath}/joint525_chr1_ExcessHet_filter.SNP.g.vcf.gz \; -V ${SNPPath}/joint525_chr2_ExcessHet_filter.SNP.g.vcf.gz \; ....; -V ${SNPPath}/joint525_chr22_ExcessHet_filter.SNP.g.vcf.gz \; -O /dsgmnt/seq5_llfs/work/xhong/v4100/ApplyVQSR//ExcessHet_joint525_c1_22.SNP.VQSR.g.vcf.g; z \; --truth-sensitivity-filter-level 97 \; --tranches-file /dsgmnt/seq5_llfs/work/xhong/v4100/VQSR//ExcessHet_joint525_c1_22.snp.tranches \; --recal-file /dsgmnt/seq5_llfs/work/xho; ng/v4100/VQSR//ExcessHet_joint525_c1_22.snp.recal \; -mode SNP`. There is no error or warning in the standard error and standard output of this step. I have tried to apply VQSR SNP model to ${SNPPath}/joint525_chr1_ExcessHet_filter.SNP.g.vcf.gz. It works well. When I select BISNPs from the output, I could not repeat the error. . I would like to get suggestion on how to narrow down the problem. Any input is appreciated.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6021:4672,error,error,4672,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6021,4,"['down', 'error']","['down', 'error']"
Availability,"2833200,787;ReadPosRankSum=0.252	GT:AD:DP:GQ:PL:SB	0/2:411,2,357,0,0:770:99:14840,11462,50871,0,41338,45112,17297,53328,47568,2147483647,16108,52933,46273,64838,62381:201,210,177,182; chr13	32944610	.	T	<NON_REF>	.	.	END=32944794	GT:DP:GQ:MIN_DP:PL	0/0:627:99:265:0,120,1800; ```. #### Steps to reproduce; * init; ```; hg19=pipeline/hg19/hg19_chM_male_mask.fa; ```; * reproduce of 4.0.8.1; ```; github.com/broadinstitute/gatk/releases/download/4.0.8.1/gatk-4.0.8.1/gatk HaplotypeCaller -R $hg19 -I target.1k.bam -L target.bed -O target.4.0.8.1.gvcf -ERC GVCF && tail target.4.0.8.1.gvcf; github.com/broadinstitute/gatk/releases/download/4.0.8.1/gatk-4.0.8.1/gatk HaplotypeCaller -R $hg19 -I target.1k.bam -L target.bed -O target.4.0.8.1.vcf && tail target.4.0.8.1.vcf; ```; * reproduce of 4.0.9.0; ```; github.com/broadinstitute/gatk/releases/download/4.0.9.0/gatk-4.0.9.0/gatk HaplotypeCaller -R $hg19 -I target.1k.bam -L target.bed -O target.4.0.9.0.gvcf -ERC GVCF && tail target.4.0.9.0.gvcf; github.com/broadinstitute/gatk/releases/download/4.0.9.0/gatk-4.0.9.0/gatk HaplotypeCaller -R $hg19 -I target.1k.bam -L target.bed -O target.4.0.9.0.vcf && tail target.4.0.9.0.vcf; ```; * reproduce of 4.1.2.0; ```; github.com/broadinstitute/gatk/releases/download/4.1.2.0/gatk-4.1.2.0/gatk HaplotypeCaller -R $hg19 -I target.1k.bam -L target.bed -O target.4.1.2.0.gvcf -ERC GVCF && tail target.4.1.2.0.gvcf; github.com/broadinstitute/gatk/releases/download/4.1.2.0/gatk-4.1.2.0/gatk HaplotypeCaller -R $hg19 -I target.1k.bam -L target.bed -O target.4.1.2.0.vcf && tail target.4.1.2.0.vcf; ```. #### Expected behavior; 1. expose the rule that the second variant (T>TAAAA) filtered (especially for version 4.0.9.0).; 2. give the right QUAL of the second variant; 3. then this type of variant can be retain in VCF as default operation or with some addition parameters.; 4. can GATK have ability to detect the `real` variant such as TTT>AAAA. #### Actual behavior; ~~_Tell us what happens instead_~~; unknown",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5975:6551,down,download,6551,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5975,3,['down'],['download']
Availability,"2921719a343/hdfs:/svdev-caller-m:8020/reference/Homo_sapiens_assembly38.fasta is not a valid DFS filename.; 	at org.apache.hadoop.hdfs.DistributedFileSystem.getPathName(DistributedFileSystem.java:213); 	at org.apache.hadoop.hdfs.DistributedFileSystem$27.doCall(DistributedFileSystem.java:1436); 	at org.apache.hadoop.hdfs.DistributedFileSystem$27.doCall(DistributedFileSystem.java:1433); 	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81); 	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1448); 	at org.apache.hadoop.fs.FileSystem.exists(FileSystem.java:1436); 	at org.broadinstitute.hellbender.utils.spark.SparkUtils.pathExists(SparkUtils.java:100); 	at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSource.setHadoopBAMConfigurationProperties(ReadsSparkSource.java:241); 	at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSource.getHeader(ReadsSparkSource.java:203); 	... 20 more; ERROR: (gcloud.dataproc.jobs.submit.spark) Job [da63aa3c-e3bc-4893-9f40-42921719a343] entered state [ERROR] while waiting for [DONE].; ```. to reproduce this error, . ```bash; cd /Users/shuang/GATK/gatk. CLUSTER_NAME=""svdev-caller""; MASTER_NODE=""hdfs://svdev-caller-m:8020""; PROJECT_DIR=""user/shuang/NA12878_PCR-_30X"". ./gatk-launch FindBreakpointEvidenceSpark \; -R ""$MASTER_NODE""/reference/Homo_sapiens_assembly38.fasta \; -I ""$MASTER_NODE""/data/smallCram.cram \; -O ""$MASTER_NODE""/""$PROJECT_DIR""/fastq \; --exclusionIntervals gs://sv-data-dsde-dev/reference/GRCh38.kill.intervals \; --kmersToIgnore gs://sv-data-dsde-dev/reference/Homo_sapiens_assembly38.dups \; --kmerIntervals ""$MASTER_NODE""/""$PROJECT_DIR""/kmerIntervals \; --breakpointEvidenceDir ""$MASTER_NODE""/""$PROJECT_DIR""/evidence \; --breakpointIntervals ""$MASTER_NODE""/""$PROJECT_DIR""/intervals \; --qnameIntervalsMapped ""$MASTER_NODE""/""$PROJECT_DIR""/qnameIntervalsMapped \; --qnameIntervalsForAssembly ""$MASTER_NODE""/""$PROJECT_DIR""/qnameInt",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2382:4099,ERROR,ERROR,4099,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2382,1,['ERROR'],['ERROR']
Availability,2:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr9_KI270719v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr9_KI270720v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr11_KI270721v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_GL000009v2_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_GL000225v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_KI270722v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_GL000194v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_KI270723v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_KI270724v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_KI270725v1_ran,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4840:4962,reliab,reliable,4962,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4840,1,['reliab'],['reliable']
Availability,"2_KI270894v1_alt:207863; skipping that record. Set --reference_window_stop >= 262 ; 0 variants were aligned; INFO 21:38:54,554 ProgressMeter - done 3.31246907E8 31.8 m 5.0 s 99.7% 31.8 m 5.0 s ; INFO 21:38:54,554 ProgressMeter - Total runtime 1905.29 secs, 31.75 min, 0.53 hours ; ------------------------------------------------------------------------------------------; Done. There were 4 WARN messages, the first 4 are repeated below.; WARN 17:39:57,688 IndexDictionaryUtils - Track variant doesn't have a sequence dictionary built in, skipping dictionary validation ; WARN 18:13:42,039 SimpleTimer - Clock drift of -1,503,348,737,016,211,299 - -1,503,346,772,578,127,937 = 1,964,438,083,362 nanoseconds detected, vs. max allowable drift of 5,000,000,000. Assuming checkpoint/restart event. ; WARN 20:14:18,043 SimpleTimer - Clock drift of -1,503,355,916,564,964,097 - -1,503,348,737,015,111,124 = 7,179,549,852,973 nanoseconds detected, vs. max allowable drift of 5,000,000,000. Assuming checkpoint/restart event. ; WARN 21:10:35,064 SimpleTimer - Clock drift of -1,503,359,203,412,549,926 - -1,503,355,916,564,817,209 = 3,286,847,732,717 nanoseconds detected, vs. max allowable drift of 5,000,000,000. Assuming checkpoint/restart event. ; ------------------------------------------------------------------------------------------; WMCF9-CB5:Mutect2 shlee$ ; ```. ### Notice the following line from above. > 0 variants were aligned. Also, it would be great if the tool, which appears to keep track of the lengths of reference alleles that are too long, could give me the **maximum length** reference allele so that I can go back and set the `--reference_window_stop` argument appropriately in a second round so that I can left-align _all_ of my variants. . ### MD5 and looking into the files, we see input and output are different and in fact the tool did change allele representations:; ```; WMCF9-CB5:Mutect2 shlee$ gzcat zeta_af-only-gnomad_Hg19toGRCh38.vcf.gz | grep -v '##' > zeta_headless.t",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3487:7901,checkpoint,checkpoint,7901,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3487,1,['checkpoint'],['checkpoint']
Availability,3); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.concurrent.StoppableExecutorImpl$1.run(StoppableExecutorImpl.java:46); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] Caused by: org.gradle.process.internal.ExecException: Process 'Gradle Test Executor 1' finished with non-zero exit value 134; 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.process.internal.DefaultExecHandle$ExecResultImpl.assertNormalExitValue(DefaultExecHandle.java:369); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.process.internal.worker.DefaultWorkerProcess.waitForStop(DefaultWorkerProcess.java:190); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.process.internal.worker.DefaultWorkerProcessBuilder$MemoryRequestingWorkerProcess.waitForStop(DefaultWorkerProcessBuilder.java:228); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.testing.worker.ForkingTestClassProcessor.stop(ForkingTestClassProcessor.java:122); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.testing.processors.RestartEveryNTestClassProcessor.endBatch(RestartEveryNTestClassProcessor.java:63); 11:54:40.437 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.testing.processors.RestartEveryNTestClassProcessor.stop(RestartEveryNTestClassProcessor.java:57); 11:54:40.437 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35); 11:54:40.437 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 11:54:40.437 [ERROR] [org.gradle.internal.buildevents.BuildExce,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2802:14252,ERROR,ERROR,14252,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2802,1,['ERROR'],['ERROR']
Availability,"3); at org.broadinstitute.hellbender.utils.codecs.gtf.GencodeGtfFeature.<init>(GencodeGtfFeature.java:224); at org.broadinstitute.hellbender.utils.codecs.gtf.GencodeGtfExonFeature.<init>(GencodeGtfExonFeature.java:19); at org.broadinstitute.hellbender.utils.codecs.gtf.GencodeGtfExonFeature.create(GencodeGtfExonFeature.java:23); at org.broadinstitute.hellbender.utils.codecs.gtf.GencodeGtfFeature$FeatureType$4.create(GencodeGtfFeature.java:777); at org.broadinstitute.hellbender.utils.codecs.gtf.GencodeGtfFeature.create(GencodeGtfFeature.java:320); at org.broadinstitute.hellbender.utils.codecs.gtf.AbstractGtfCodec.decode(AbstractGtfCodec.java:138); at org.broadinstitute.hellbender.utils.codecs.gtf.AbstractGtfCodec.decode(AbstractGtfCodec.java:23); at htsjdk.tribble.TribbleIndexedFeatureReader$QueryIterator.readNextRecord(TribbleIndexedFeatureReader.java:501); ... 43 more; `; #### Steps to reproduce. [test.somatic.vcf.gz](https://github.com/broadinstitute/gatk/files/5094900/test.somatic.vcf.gz). I upload my VCF file here. The reference is hg19 downloaded from UCSC. The data sources is downloaded from funcotator official website (somatic). You can simply run this command to reproduce this error:; `gatk Funcotator --variant test.somatic.vcf --reference ucsc.hg19.fasta --ref-version hg19 --data-sources-path funcotator_dataSources.v1.7.20200521s --output test.maf --output-file-format MAF; `; #### Expected behavior; Successfully run and output a MAF file. #### Actual behavior; Throw out an error and an MAF file with only header; ----. ## Feature request. ### Tool(s) or class(es) involved; _Tool/class name(s), special parameters?_. ### Description; _Specify whether you want a modification of an existing behavior or addition of a new capability._; _Provide **examples**, **screenshots**, where appropriate._. ----. ## Documentation request. ### Tool(s) or class(es) involved; _Tool/class name(s), parameters?_. ### Description ; _Describe what needs to be added or modified._. ----",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6758:26177,down,downloaded,26177,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6758,4,"['down', 'error']","['downloaded', 'error']"
Availability,"3.797 INFO CreateReadCountPanelOfNormals - Done initializing engine; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; 19/02/18 12:33:53 INFO SparkContext: Running Spark version 2.2.0; WARNING: An illegal reflective access operation has occurred; WARNING: Illegal reflective access by org.apache.hadoop.security.authentication.util.KerberosUtil (file:/share/FGI2017B/pub/gatk-4.1.0.0/gatk-package-4.1.0.0-local.jar) to method sun.security.krb5.Config.getInstance(); WARNING: Please consider reporting this to the maintainers of org.apache.hadoop.security.authentication.util.KerberosUtil; WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations; WARNING: All illegal access operations will be denied in a future release; 12:33:54.187 WARN NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 12:33:54.263 INFO CreateReadCountPanelOfNormals - Shutting down engine; [February 18, 2019 at 12:33:54 PM CST] org.broadinstitute.hellbender.tools.copynumber.CreateReadCountPanelOfNormals done. Elapsed time: 0.04 minutes.; Runtime.totalMemory()=2147483648; Exception in thread ""main"" java.lang.ExceptionInInitializerError; 	at org.apache.spark.SparkConf.validateSettings(SparkConf.scala:546); 	at org.apache.spark.SparkContext.<init>(SparkContext.scala:373); 	at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58); 	at org.broadinstitute.hellbender.engine.spark.SparkContextFactory.createSparkContext(SparkContextFactory.java:178); 	at org.broadinstitute.hellbender.engine.spark.SparkContextFactory.getSparkContext(SparkContextFactory.java:110); 	at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:28); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:138); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostPa",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5686:2174,down,down,2174,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5686,1,['down'],['down']
Availability,"330180 59330708 target_189885_IL9R NaN; Y 59333828 59334429 target_189886_IL9R NaN; Y 59335302 59335904 target_189887_IL9R NaN; Y 59335905 59336289 target_189888_IL9R NaN; Y 59336290 59336776 target_189889_IL9R NaN; Y 59336840 59337486 target_189890_IL9R NaN; Y 59337698 59338400 target_189891_IL9R NaN; Y 59338503 59339109 target_189892_IL9R NaN; Y 59339943 59340528 target_189893_IL9R NaN; Y 59342236 59343330 target_189894_IL9R NaN. ---. @mbabadi commented on [Fri Aug 26 2016](https://github.com/broadinstitute/gatk-protected/issues/651#issuecomment-242767764). @davidbenjamin could you please take a look? it sounds like it could be a problem with the reference missing these regions. ---. @mbabadi commented on [Fri Aug 26 2016](https://github.com/broadinstitute/gatk-protected/issues/651#issuecomment-242774747). OK it turns out that the reference is hard masked and has ""N"" in that region. Nevertheless, we shouldn't get NaNs. In my opinion, the correct behavior is to drop targets on which GC percentage can not be defined + emit informative error messages. ---. @davidbenjamin commented on [Sun Sep 11 2016](https://github.com/broadinstitute/gatk-protected/issues/651#issuecomment-246177779). I will address this. ---. @mbabadi commented on [Tue Sep 27 2016](https://github.com/broadinstitute/gatk-protected/issues/651#issuecomment-250018497). @davidbenjamin also, CorrectGCBias produces NaNs when a sample has very low coverage. I think the correct behavior is this:. (1) when annotating targets, it is OK to produce NaNs on targets whose GC bias can not be determined. When correcting for GC bias, those targets must be removed altogether. (2) if the bias curve can not be determined (let's say because of low coverage), the tool should remove that sample from the collection and emit appropriate warning messages. If all samples are removed, the tool should produce a bad input error. ---. @mbabadi commented on [Thu May 18 2017](https://github.com/broadinstitute/gatk-protected/issues/6",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2882:3996,error,error,3996,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2882,1,['error'],['error']
Availability,34 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:61); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.taskgraph.DefaultTaskGraphExecuter$EventFiringTaskWorker.execute(DefaultTaskGraphExecuter.java:228); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.taskgraph.DefaultTaskGraphExecuter$EventFiringTaskWorker.execute(DefaultTaskGraphExecuter.java:215); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.taskgraph.AbstractTaskPlanExecutor$TaskExecutorWorker.processTask(AbstractTaskPlanExecutor.java:77); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.taskgraph.AbstractTaskPlanExecutor$TaskExecutorWorker.run(AbstractTaskPlanExecutor.java:58); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.taskgraph.DefaultTaskPlanExecutor.process(DefaultTaskPlanExecutor.java:32); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.taskgraph.DefaultTaskGraphExecuter.execute(DefaultTaskGraphExecuter.java:113); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.SelectedTaskExecutionAction.execute(SelectedTaskExecutionAction.java:37); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.DefaultBuildExecuter.execute(DefaultBuildExecuter.java:37); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.DefaultBuildExecuter.access$000(DefaultBuildExecuter.java:23); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.DefaultBuildExecuter$1.proceed(DefaultBuildExecu,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2802:4169,ERROR,ERROR,4169,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2802,1,['ERROR'],['ERROR']
Availability,36 > 47638 expanding to 95278; 11:40:02.830 DEBUG Mutect2 - Processing assembly region at chrM:8830-9129 isActive: true numReads: 296990; 11:41:56.997 DEBUG ReadThreadingGraph - Recovered 7 of 8 dangling tails; 11:41:57.047 DEBUG ReadThreadingGraph - Recovered 2 of 24 dangling heads; 11:41:57.286 DEBUG IntToDoubleFunctionCache - cache miss 136737 > 53234 expanding to 136747; 11:41:57.301 DEBUG IntToDoubleFunctionCache - cache miss 136976 > 136747 expanding to 273496; 11:41:57.935 DEBUG Mutect2Engine - Active Region chrM:8830-9129; 11:41:57.937 DEBUG Mutect2Engine - Extended Act Region chrM:8730-9229; 11:41:57.939 DEBUG Mutect2Engine - Ref haplotype coords chrM:8730-9229; 11:41:57.940 DEBUG Mutect2Engine - Haplotype count 128; 11:41:57.941 DEBUG Mutect2Engine - Kmer sizes count 0; 11:41:57.942 DEBUG Mutect2Engine - Kmer sizes values []; 11:53:42.116 DEBUG Mutect2 - Processing assembly region at chrM:9130-9143 isActive: true numReads: 148251; 11:53:58.336 DEBUG ReadThreadingGraph - Recovered 4 of 9 dangling tails; 11:53:58.398 DEBUG ReadThreadingGraph - Recovered 0 of 20 dangling heads; 11:54:11.645 DEBUG ReadThreadingGraph - Recovered 20 of 23 dangling tails; 11:54:11.670 DEBUG ReadThreadingGraph - Recovered 0 of 60 dangling heads; 11:54:11.843 DEBUG Mutect2Engine - Active Region chrM:9130-9143; 11:54:11.852 DEBUG Mutect2Engine - Extended Act Region chrM:9030-9243; 11:54:11.861 DEBUG Mutect2Engine - Ref haplotype coords chrM:9030-9243; 11:54:11.870 DEBUG Mutect2Engine - Haplotype count 232; 11:54:11.879 DEBUG Mutect2Engine - Kmer sizes count 0; 11:54:11.889 DEBUG Mutect2Engine - Kmer sizes values []; 11:54:21.878 DEBUG IntToDoubleFunctionCache - cache miss 96632 > 95278 expanding to 190558; 11:54:22.252 DEBUG Mutect2 - Processing assembly region at chrM:9144-9301 isActive: false numReads: 273760; 11:54:28.421 DEBUG Mutect2 - Processing assembly region at chrM:9302-9584 isActive: true numReads: 250870; 11:55:47.246 DEBUG ReadThreadingGraph - Recovered 13 of 14 dangling,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7281:16272,Recover,Recovered,16272,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7281,1,['Recover'],['Recovered']
Availability,"362); 	at org.apache.spark.rdd.PairRDDFunctions.saveAsNewAPIHadoopDataset(PairRDDFunctions.scala:1084); 	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsNewAPIHadoopFile$2.apply$mcV$sp(PairRDDFunctions.scala:1003); 	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsNewAPIHadoopFile$2.apply(PairRDDFunctions.scala:994); 	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsNewAPIHadoopFile$2.apply(PairRDDFunctions.scala:994); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); 	at org.apache.spark.rdd.RDD.withScope(RDD.scala:362); 	at org.apache.spark.rdd.PairRDDFunctions.saveAsNewAPIHadoopFile(PairRDDFunctions.scala:994); 	at org.apache.spark.api.java.JavaPairRDD.saveAsNewAPIHadoopFile(JavaPairRDD.scala:823); 	at org.disq_bio.disq.impl.formats.sam.AnySamSinkMultiple.save(AnySamSinkMultiple.java:96); 	at org.disq_bio.disq.HtsjdkReadsRddStorage.write(HtsjdkReadsRddStorage.java:206); 	at org.broadinstitute.hellbender.engine.sp...; ```. here’s the command line; bamIn=gs://broad-gatk-test-jenkins-robust/CEUTrio.HiSeq.WEx.b37.NA12892.readnamesort.bam; refIn=gs://broad-gatk-test-jenkins-robust/human_g1k_v37.fasta; bamOut=gs://broad-gatk-test-jenkins-write-robust/CEUTrio.HiSeq.WEx.b37.NA12892.readnamesort.bam.md.bqsr; knownIn=gs://broad-gatk-test-jenkins-robust/dbsnp_138.b37.excluding_sites_after_129.vcf; vcfOut=gs://broad-gatk-test-jenkins-write-robust/CEUTrio.HiSeq.WEx.b37.NA12892.vcf; ./gatk ReadsPipelineSpark \; -I $bamIn \; -R $refIn \; --output-bam $bamOut \; -O $vcfOut \; --known-sites $knownIn \; --sharded-output true \; --emit-original-quals \; --duplicate-scoring-strategy SUM_OF_BASE_QUALITIES \; --num-reducers 0 \; -- \; --spark-runner GCS \; --cluster $CLUSTERNAME \; --driver-memory 8G \; --conf 'spark.yarn.executor.memoryOverhead=2000' \; --executor-memory 18g \; --executor-cores 6 \; --conf spark.yarn.executor.memoryOverhead=2000""",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5545:12902,robust,robust,12902,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5545,5,['robust'],['robust']
Availability,"37/Axiom_Exome_Plus.genotypes.all_populations.poly.b37.vcf.gz; 14:58:11.090 INFO FeatureManager - Using codec VCFCodec to read file file://~/projects/test2/temp/vatiant_germline/sites.only.vcf.gz; 14:58:11.139 INFO VariantRecalibrator - Done initializing engine; 14:58:11.142 INFO TrainingSet - Found mills track: Known = false Training = true Truth = true Prior = Q12.0; 14:58:11.142 INFO TrainingSet - Found dbsnp track: Known = true Training = false Truth = false Prior = Q2.0; 14:58:11.142 INFO TrainingSet - Found axiomPoly track: Known = false Training = true Truth = false Prior = Q10.0; 14:58:11.167 INFO ProgressMeter - Starting traversal; 14:58:11.168 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 14:58:21.182 INFO ProgressMeter - 2:23974966 0.2 22000 131828.6; 14:58:31.703 INFO ProgressMeter - 3:171904490 0.3 46000 134404.7; 14:58:41.753 INFO ProgressMeter - 6:18264210 0.5 67000 131441.3; 14:58:42.144 INFO VariantRecalibrator - Shutting down engine; [November 12, 2020 2:58:42 PM CST] org.broadinstitute.hellbender.tools.walkers.vqsr.VariantRecalibrator done. Elapsed time: 0.53 minutes.; Runtime.totalMemory()=29244260352; java.lang.IllegalStateException: The provided reference alleles do not appear to represent the same position, AC* vs. AA*; at org.broadinstitute.hellbender.utils.variant.GATKVariantContextUtils.determineReferenceAllele(GATKVariantContextUtils.java:209); at org.broadinstitute.hellbender.utils.variant.GATKVariantContextUtils.isAlleleInList(GATKVariantContextUtils.java:164); at org.broadinstitute.hellbender.tools.walkers.vqsr.VariantDataManager.doAllelesMatch(VariantDataManager.java:424); at org.broadinstitute.hellbender.tools.walkers.vqsr.VariantDataManager.parseTrainingSets(VariantDataManager.java:399); at org.broadinstitute.hellbender.tools.walkers.vqsr.VariantRecalibrator.addDatum(VariantRecalibrator.java:614); at org.broadinstitute.hellbender.tools.walkers.vqsr.VariantRecalibrator.addVariantDatum(VariantRe",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6963:6303,down,down,6303,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6963,1,['down'],['down']
Availability,"38 INFO cluster.YarnClientSchedulerBackend: Asking each executor to shut down; 17/10/11 14:19:38 INFO cluster.YarnClientSchedulerBackend: Stopped; 17/10/11 14:19:38 INFO spark.MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 17/10/11 14:19:38 INFO storage.MemoryStore: MemoryStore cleared; 17/10/11 14:19:38 INFO storage.BlockManager: BlockManager stopped; 17/10/11 14:19:38 INFO storage.BlockManagerMaster: BlockManagerMaster stopped; 17/10/11 14:19:38 INFO scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 17/10/11 14:19:38 INFO spark.SparkContext: Successfully stopped SparkContext; 14:19:38.600 INFO PrintReadsSpark - Shutting down engine; [October 11, 2017 2:19:38 PM CST] org.broadinstitute.hellbender.tools.spark.pipelines.PrintReadsSpark done. Elapsed time: 0.48 minutes.; Runtime.totalMemory()=986185728; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 1.0 failed 4 times, most recent failure: Lost task 0.3 in stage 1.0 (TID 4, com2, executor 2): ExecutorLostFailure (executor 2 exited caused by one of the running tasks) Reason: Container marked as failed: container_1507683879816_0006_01_000003 on host: com2. Exit status: 50. Diagnostics: Exception from container-launch.; Container id: container_1507683879816_0006_01_000003; Exit code: 50; Stack trace: ExitCodeException exitCode=50: ; 	at org.apache.hadoop.util.Shell.runCommand(Shell.java:601); 	at org.apache.hadoop.util.Shell.run(Shell.java:504); 	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:786); 	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:213); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82); 	at java.util.concurrent.FutureTa",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686:32037,failure,failure,32037,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686,1,['failure'],['failure']
Availability,"3:13:14.515 INFO PostprocessGermlineCNVCalls - Analyzing shard 43 / 45...; 03:13:14.652 INFO PostprocessGermlineCNVCalls - Analyzing shard 44 / 45...; 03:13:14.843 INFO PostprocessGermlineCNVCalls - Analyzing shard 45 / 45...; 03:13:15.144 INFO PostprocessGermlineCNVCalls - Generating segments...; 03:14:44.578 INFO PostprocessGermlineCNVCalls - Parsing Python output...; 03:14:44.593 INFO PostprocessGermlineCNVCalls - Writing segments VCF file to /data/xiangxd/project/test/PD_WES_50/cnv_calling/GATK_gCNV/infos/output/R18002110LU01-XG3351_combined_segment_cohort.vcf...; 03:14:46.272 INFO PostprocessGermlineCNVCalls - Generating denoised copy ratios...; 03:14:47.231 INFO PostprocessGermlineCNVCalls - Writing denoised copy ratios to /data/xiangxd/project/test/PD_WES_50/cnv_calling/GATK_gCNV/infos/output/R18002110LU01-XG3351_combined_ratio.txt...; 03:14:58.266 INFO PostprocessGermlineCNVCalls - PostprocessGermlineCNVCalls complete.; 03:14:58.268 INFO PostprocessGermlineCNVCalls - Shutting down engine; [April 15, 2024, 3:14:58 AM CST] org.broadinstitute.hellbender.tools.copynumber.PostprocessGermlineCNVCalls done. Elapsed time: 2.32 minutes.; Runtime.totalMemory()=1207959552; Using GATK jar /data/xiangxd/project/software/callers/gatk_4.4/gatk-package-4.4.0.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /data/xiangxd/project/software/callers/gatk_4.4/gatk-package-4.4.0.0-local.jar PostprocessGermlineCNVCalls --model-shard-path /data/xiangxd/project/test/PD_WES_50/cnv_calling/GATK_gCNV/infos/cohort_all/cohort_1-model --model-shard-path /data/xiangxd/project/test/PD_WES_50/cnv_calling/GATK_gCNV/infos/cohort_all/cohort_2-model --model-shard-path /data/xiangxd/project/test/PD_WES_50/cnv_calling/GATK_gCNV/infos/cohort_all/cohort_3-model --model-shard-path /data/xiangxd/project/test/PD_WES_50/cnv_calling/GATK_gCNV/infos/cohort_all/cohort_4-",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8776:7615,down,down,7615,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8776,1,['down'],['down']
Availability,"4 05:09:55,53] [info] Shutting down SubWorkflowStoreActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,53] [info] Shutting down JobStoreActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,53] [info] SubWorkflowStoreActor stopped; [2020-07-14 05:09:55,54] [info] JobStoreActor stopped; [2020-07-14 05:09:55,53] [info] Shutting down CallCacheWriteActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,54] [info] Shutting down ServiceRegistryActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,54] [info] CallCacheWriteActor Shutting down: 0 queued messages to process; [2020-07-14 05:09:55,54] [info] CallCacheWriteActor stopped; [2020-07-14 05:09:55,54] [info] Shutting down DockerHashActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,54] [info] Shutting down IoProxy - Timeout = 1800 seconds; [2020-07-14 05:09:55,54] [info] IoProxy stopped; [2020-07-14 05:09:55,54] [info] DockerHashActor stopped; [2020-07-14 05:09:55,55] [info] Shutting down connection pool: curAllocated=1 idleQueues.size=1 waitQueue.size=0 maxWaitQueueLimit=256 closed=false; [2020-07-14 05:09:55,55] [info] Shutting down connection pool: curAllocated=0 idleQueues.size=0 waitQueue.size=0 maxWaitQueueLimit=256 closed=false; [2020-07-14 05:09:55,55] [info] WriteMetadataActor Shutting down: 0 queued messages to process; [2020-07-14 05:09:55,55] [info] Shutting down connection pool: curAllocated=0 idleQueues.size=0 waitQueue.size=0 maxWaitQueueLimit=256 closed=false; [2020-07-14 05:09:55,55] [info] KvWriteActor Shutting down: 0 queued messages to process; [2020-07-14 05:09:55,55] [info] Shutting down connection pool: curAllocated=0 idleQueues.size=0 waitQueue.size=0 maxWaitQueueLimit=256 closed=false; [2020-07-14 05:09:55,55] [info] ServiceRegistryActor stopped; [2020-07-14 05:09:55,58] [info] Database closed; [2020-07-14 05:09:55,58] [info] Stream materializer shut down; [2020-07-14 05:09:55,58] [info] WDL HTTP import resolver closed; Workflow 968be82c-eef3-4bdb-a1ab-3d4e2ca70674 transitioned to state Failed",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6710:9901,down,down,9901,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710,6,['down'],['down']
Availability,"4 HelpFormatter - Copyright (c) 2010-2016 The Broad Institute ; INFO 10:47:54,224 HelpFormatter - For support and documentation go to https://software.broadinstitute.org/gatk ; INFO 10:47:54,225 HelpFormatter - [Tue Sep 08 10:47:54 WEST 2020] Executing on Mac OS X 10.15.6 x86_64 ; INFO 10:47:54,225 HelpFormatter - Java HotSpot(TM) 64-Bit Server VM 1.8.0_65-b17 ; INFO 10:47:54,229 HelpFormatter - Program Args: -T IndelRealigner -R /Users/mac/Desktop/NGS-/TriTrypDB-47_LmajorLV39c5_Genome.fasta -I /Users/mac/Desktop/NGS-/marked_duplicates42-pe.bam -targetIntervals /Users/mac/Desktop/NGS-/42-pe-realigner.intervals -o /Users/mac/Desktop/NGS-/42-pe-idelsrealigner.bam ; INFO 10:47:54,492 HelpFormatter - Executing as mac@MacBook-Air-de-mac.local on Mac OS X 10.15.6 x86_64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_65-b17. ; INFO 10:47:54,493 HelpFormatter - Date/Time: 2020/09/08 10:47:54 ; INFO 10:47:54,494 HelpFormatter - ---------------------------------------------------------------------------------- ; INFO 10:47:54,494 HelpFormatter - ---------------------------------------------------------------------------------- ; ERROR StatusLogger Unable to create class org.apache.logging.log4j.core.impl.Log4jContextFactory specified in jar:file:/Users/mac/Desktop/GenomeAnalysisTK-3.8-0-ge9d806836%204/GenomeAnalysisTK.jar!/META-INF/log4j-provider.properties; ERROR StatusLogger Log4j2 could not find a logging implementation. Please add log4j-core to the classpath. Using SimpleLogger to log to the console...; INFO 10:47:55,875 GenomeAnalysisEngine - Deflater: IntelDeflater ; INFO 10:47:55,876 GenomeAnalysisEngine - Inflater: IntelInflater ; INFO 10:47:55,876 GenomeAnalysisEngine - Strictness is SILENT ; INFO 10:47:56,246 GenomeAnalysisEngine - Downsampling Settings: No downsampling ; INFO 10:47:56,255 SAMDataSource$SAMReaders - Initializing SAMRecords in serial ; INFO 10:47:56,333 SAMDataSource$SAMReaders - Done initializing BAM readers: total time 0.07 ; ##### ERROR ----------------",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6798:1783,ERROR,ERROR,1783,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6798,1,['ERROR'],['ERROR']
Availability,"4 INFO  BaseRecalibrator - HTSJDK Defaults.USE\_ASYNC\_IO\_READ\_FOR\_SAMTOOLS : false ; ; 00:11:11.814 INFO  BaseRecalibrator - HTSJDK Defaults.USE\_ASYNC\_IO\_WRITE\_FOR\_SAMTOOLS : true ; ; 00:11:11.814 INFO  BaseRecalibrator - HTSJDK Defaults.USE\_ASYNC\_IO\_WRITE\_FOR\_TRIBBLE : false ; ; 00:11:11.814 INFO  BaseRecalibrator - Deflater: JdkDeflater ; ; 00:11:11.815 INFO  BaseRecalibrator - Inflater: JdkInflater ; ; 00:11:11.815 INFO  BaseRecalibrator - GCS max retries/reopens: 20 ; ; 00:11:11.815 INFO  BaseRecalibrator - Requester pays: disabled ; ; 00:11:11.815 INFO  BaseRecalibrator - Initializing engine ; ; 00:11:12.005 WARN  IntelInflaterFactory - IntelInflater is not supported, using Java.util.zip.Inflater ; ; 00:11:12.009 WARN  IntelInflaterFactory - IntelInflater is not supported, using Java.util.zip.Inflater ; ; 00:11:12.127 WARN  IntelInflaterFactory - IntelInflater is not supported, using Java.util.zip.Inflater ; ; 00:11:12.134 INFO  BaseRecalibrator - Shutting down engine ; ; \[August 21, 2022 at 12:11:12 AM CST\] org.broadinstitute.hellbender.tools.walkers.bqsr.BaseRecalibrator done. Elapsed time: 0.01 minutes. ; ; Runtime.totalMemory()=285212672 ; ; org.broadinstitute.hellbender.exceptions.GATKException: Unable to automatically instantiate codec org.broadinstitute.hellbender.utils.codecs.AnnotatedIntervalCodec ; ;     at org.broadinstitute.hellbender.engine.FeatureManager.getCandidateCodecsForFile(FeatureManager.java:535) ; ;     at org.broadinstitute.hellbender.engine.FeatureManager.getCodecForFile(FeatureManager.java:482) ; ;     at org.broadinstitute.hellbender.engine.FeatureDataSource.getCodecForFeatureInput(FeatureDataSource.java:397) ; ;     at org.broadinstitute.hellbender.engine.FeatureDataSource.getFeatureReader(FeatureDataSource.java:373) ; ;     at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:319) ; ;     at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:291) ; ;",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8005:11942,down,down,11942,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8005,1,['down'],['down']
Availability,"4 MLEAF.tdb; -rwx------ 1 hcaoad boip 80M Apr 20 13:34 MLEAF_var.tdb; -rwx------ 1 hcaoad boip 236M Apr 20 13:34 MQRankSum.tdb; -rwx------ 1 hcaoad boip 204M Apr 20 13:34 PGT.tdb; -rwx------ 1 hcaoad boip 6.8M Apr 20 13:34 PGT_var.tdb; -rwx------ 1 hcaoad boip 208M Apr 20 13:34 PID.tdb; -rwx------ 1 hcaoad boip 15M Apr 20 13:34 PID_var.tdb; -rwx------ 1 hcaoad boip 315M Apr 20 13:34 PL.tdb; -rwx------ 1 hcaoad boip 14G Apr 20 13:34 PL_var.tdb; -rwx------ 1 hcaoad boip 173M Apr 20 13:34 PS.tdb; -rwx------ 1 hcaoad boip 496M Apr 20 13:34 QUAL.tdb; -rwx------ 1 hcaoad boip 412M Apr 20 13:34 RAW_MQandDP.tdb; -rwx------ 1 hcaoad boip 358M Apr 20 13:34 ReadPosRankSum.tdb; -rwx------ 1 hcaoad boip 254M Apr 20 13:34 REF.tdb; -rwx------ 1 hcaoad boip 1.5G Apr 20 13:34 REF_var.tdb; -rwx------ 1 hcaoad boip 278M Apr 20 13:34 Samples.tdb; -rwx------ 1 hcaoad boip 256M Apr 20 13:34 Samples_var.tdb; -rwx------ 1 hcaoad boip 510M Apr 20 13:34 SB.tdb; </pre>; Log file for chr1, no error reported:; <pre>Using GATK jar /home/hcaoad/miniconda2/share/gatk4-4.2.0.0-0/gatk-package-4.2.0.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx80G -Xms80G -jar /home/hcaoad/miniconda2/share/gatk4-4.2.0.0-0/gatk-package-4.2.0.0-local.jar GenomicsDBImport --genomicsdb-workspace-path /scratch/PI/boip/Han/WGS/HK_WGS_5X/GenomicsDB//chr1 -L 1 --sample-name-map input/sample.map -R /scratch/PI/boip/Reference/Human_genome/GRCh37/hs37d5.fa --batch-size 400 --reader-threads 5; 14:48:08.923 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/hcaoad/miniconda2/share/gatk4-4.2.0.0-0/gatk-package-4.2.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Apr 16, 2021 2:48:09 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 14:48:09.08",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7218:4170,error,error,4170,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7218,1,['error'],['error']
Availability,4 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.ResolveTaskArtifactStateTaskExecuter.execute(ResolveTaskArtifactStateTaskExecuter.java:46); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.SkipTaskWithNoActionsExecuter.execute(SkipTaskWithNoActionsExecuter.java:51); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.SkipOnlyIfTaskExecuter.execute(SkipOnlyIfTaskExecuter.java:54); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.ExecuteAtMostOnceTaskExecuter.execute(ExecuteAtMostOnceTaskExecuter.java:43); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.CatchExceptionTaskExecuter.execute(CatchExceptionTaskExecuter.java:34); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.taskgraph.DefaultTaskGraphExecuter$EventFiringTaskWorker$1.execute(DefaultTaskGraphExecuter.java:236); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.taskgraph.DefaultTaskGraphExecuter$EventFiringTaskWorker$1.execute(DefaultTaskGraphExecuter.java:228); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.Transformers$4.transform(Transformers.java:169); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:106); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:61); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at or,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2802:2427,ERROR,ERROR,2427,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2802,1,['ERROR'],['ERROR']
Availability,4.4.0.0 compile: git lfs error transferring ; Failed to fetch some objects from 'file:///startdir/gatk',MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8320:25,error,error,25,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8320,1,['error'],['error']
Availability,4068.tsv /tmp/tintest/sample-3734484951576950052743.tsv /tmp/tintest/sample-3745007638909244994571.tsv /tmp/tintest/sample-3758817480300622528681.tsv /tmp/tintest/sample-3765561422653477541111.tsv /tmp/tintest/sample-377681127346074691924.tsv /tmp/tintest/sample-3788006936711929575536.tsv /tmp/tintest/sample-3794598448303416401276.tsv /tmp/tintest/sample-380910670101098136635.tsv /tmp/tintest/sample-3815864583095389374312.tsv /tmp/tintest/sample-3821063008346821202582.tsv /tmp/tintest/sample-3836550848258521825191.tsv /tmp/tintest/sample-3842488752532231097400.tsv /tmp/tintest/sample-3855124216409092357090.tsv /tmp/tintest/sample-3866989755460133829309.tsv ; Stdout: 10:58:52.820 INFO cohort_denoising_calling - Loading 387 read counts file(s)...; 11:01:01.618 INFO gcnvkernel.io.io_metadata - Loading germline contig ploidy and global read depth metadata...; 11:02:11.422 INFO gcnvkernel.tasks.task_cohort_denoising_calling - Instantiating the denoising model (warm-up)...; 11:04:53.672 ERROR theano.gof.cmodule - [Errno 12] Cannot allocate memory. Stderr: Problem occurred during compilation with the command line below:; /usr/bin/g++ -shared -g -O3 -fno-math-errno -Wno-unused-label -Wno-unused-variable -Wno-write-strings -fopenmp -march=knl -mmmx -mno-3dnow -msse -msse2 -msse3 -mssse3 -mno-sse4a -mcx16 -msahf -mmovbe -maes -mno-sha -mpclmul -mpopcnt -mabm -mno-lwp -mfma -mno-fma4 -mno-xop -mbmi -mbmi2 -mno-tbm -mavx -mavx2 -msse4.2 -msse4.1 -mlzcnt -mrtm -mhle -mrdrnd -mf16c -mfsgsbase -mrdseed -mprfchw -madx -mfxsr -mxsave -mxsaveopt -mavx512f -mno-avx512er -mavx512cd -mno-avx512pf -mno-prefetchwt1 -mclflushopt -mxsavec -mxsaves -mavx512dq -mavx512bw -mno-avx512vl -mno-avx512ifma -mno-avx512vbmi -mclwb -mno-mwaitx -mno-clzero -mpku --param l1-cache-size=32 --param l1-cache-line-size=64 --param l2-cache-size=22528 -mtune=generic -DNPY_NO_DEPRECATED_API=NPY_1_7_API_VERSION -m64 -fPIC -I/home/tintest/miniconda2/envs/aurexome/lib/python3.6/site-packages/numpy/core/include -I/h,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5053:61691,ERROR,ERROR,61691,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5053,1,['ERROR'],['ERROR']
Availability,"41:51.191 WARN GencodeGtfCodec - GENCODE GTF Header line 1 has a version number that is above maximum tested version (v 28) (given: 34): ##description: evidence-based annotation of the human genome (GRCh38), version 34 (Ensembl 100), mapped to GRCh37 with gencode-backmap Continuing, but errors may occur.; 15:41:51.192 WARN GencodeGtfCodec - GENCODE GTF Header line 1 has a version number that is above maximum tested version (v 28) (given: 34): ##description: evidence-based annotation of the human genome (GRCh38), version 34 (Ensembl 100), mapped to GRCh37 with gencode-backmap Continuing, but errors may occur.; 15:41:51.192 INFO FeatureManager - Using codec GencodeGtfCodec to read file file:///home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s/gencode/hg19/gencode.v34lift37.annotation.REORDERED.gtf; 15:41:51.193 WARN GencodeGtfCodec - GENCODE GTF Header line 1 has a version number that is above maximum tested version (v 28) (given: 34): ##description: evidence-based annotation of the human genome (GRCh38), version 34 (Ensembl 100), mapped to GRCh37 with gencode-backmap Continuing, but errors may occur.; 15:41:51.201 INFO DataSourceUtils - Resolved data source file path: file:///home/shiyang/softwares/gatk-4.1.8.1/gencode.v34lift37.pc_transcripts.fa -> file:///home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s/gencode/hg19/gencode.v34lift37.pc_transcripts.fa; 15:41:54.713 INFO DataSourceUtils - Resolved data source file path: file:///home/shiyang/softwares/gatk-4.1.8.1/simple_uniprot_Dec012014.tsv -> file:///home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s/simple_uniprot/hg19/simple_uniprot_Dec012014.tsv; 15:41:54.747 INFO DataSourceUtils - Resolved data source file path: file:///home/shiyang/softwares/gatk-4.1.8.1/gencode_xrefseq_v75_37.tsv -> file:///home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s/gencode_xrefseq/hg19/gencode_xrefseq",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6758:18885,error,errors,18885,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6758,1,['error'],['errors']
Availability,433 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.ValidatingTaskExecuter.execute(ValidatingTaskExecuter.java:58); 11:54:40.433 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.SkipEmptySourceFilesTaskExecuter.execute(SkipEmptySourceFilesTaskExecuter.java:88); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.ResolveTaskArtifactStateTaskExecuter.execute(ResolveTaskArtifactStateTaskExecuter.java:46); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.SkipTaskWithNoActionsExecuter.execute(SkipTaskWithNoActionsExecuter.java:51); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.SkipOnlyIfTaskExecuter.execute(SkipOnlyIfTaskExecuter.java:54); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.ExecuteAtMostOnceTaskExecuter.execute(ExecuteAtMostOnceTaskExecuter.java:43); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.CatchExceptionTaskExecuter.execute(CatchExceptionTaskExecuter.java:34); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.taskgraph.DefaultTaskGraphExecuter$EventFiringTaskWorker$1.execute(DefaultTaskGraphExecuter.java:236); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.taskgraph.DefaultTaskGraphExecuter$EventFiringTaskWorker$1.execute(DefaultTaskGraphExecuter.java:228); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.Transformers$4.transform(Transformers.java:169); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildEx,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2802:2033,ERROR,ERROR,2033,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2802,1,['ERROR'],['ERROR']
Availability,434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.SkipOnlyIfTaskExecuter.execute(SkipOnlyIfTaskExecuter.java:54); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.ExecuteAtMostOnceTaskExecuter.execute(ExecuteAtMostOnceTaskExecuter.java:43); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.CatchExceptionTaskExecuter.execute(CatchExceptionTaskExecuter.java:34); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.taskgraph.DefaultTaskGraphExecuter$EventFiringTaskWorker$1.execute(DefaultTaskGraphExecuter.java:236); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.taskgraph.DefaultTaskGraphExecuter$EventFiringTaskWorker$1.execute(DefaultTaskGraphExecuter.java:228); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.Transformers$4.transform(Transformers.java:169); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:106); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:61); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.taskgraph.DefaultTaskGraphExecuter$EventFiringTaskWorker.execute(DefaultTaskGraphExecuter.java:228); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.taskgraph.DefaultTaskGraphExecuter$EventFiringTaskWorker.execute(DefaultTaskGraphExecuter.java:215); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gr,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2802:2839,ERROR,ERROR,2839,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2802,1,['ERROR'],['ERROR']
Availability,"44139c5-3371-4a67-a2c8-e054e46f814f/ReblockGVCF/601ea396-b6cf-4baa-95c7-83e88b92c194/call-GenotypeGVCF/09C97227.c9cd4496-b4ed-4686-babd-177c66168178.vcf.gz.tbi.; 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.translate(HttpStorageRpc.java:189); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.get(HttpStorageRpc.java:335); 	at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:191); 	at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:188); 	at shaded.cloud_nio.com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:94); 	at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:54); 	at com.google.cloud.storage.StorageImpl.get(StorageImpl.java:188); 	at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.checkAccess(CloudStorageFileSystemProvider.java:614); 	... 15 more; Caused by: shaded.cloud_nio.com.google.api.client.googleapis.json.GoogleJsonResponseException: 403 Forbidden; {; ""code"" : 403,; ""errors"" : [ {; ""domain"" : ""global"",; ""message"" : ""443301511749-compute@developer.gserviceaccount.com does not have storage.objects.get access to fc-50c768b1-a285-4c95-8d8c-8ce209f1fda8/744139c5-3371-4a67-a2c8-e054e46f814f/ReblockGVCF/601ea396-b6cf-4baa-95c7-83e88b92c194/call-GenotypeGVCF/09C97227.c9cd4496-b4ed-4686-babd-177c66168178.vcf.gz.tbi."",; ""reason"" : ""forbidden""; } ],; ""message"" : ""443301511749-compute@developer.gserviceaccount.com does not have storage.objects.get access to fc-50c768b1-a285-4c95-8d8c-8ce209f1fda8/744139c5-3371-4a67-a2c8-e054e46f814f/ReblockGVCF/601ea396-b6cf-4baa-95c7-83e88b92c194/call-GenotypeGVCF/09C97227.c9cd4496-b4ed-4686-babd-177c66168178.vcf.gz.tbi.""; }; 	at shaded.cloud_nio.com.google.api.client.googleapis.json.GoogleJsonResponseException.from(GoogleJsonResponseException.java:145); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:113); 	at shaded.cloud_nio",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4592:3667,error,errors,3667,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4592,1,['error'],['errors']
Availability,"46 INFO CNNVariantWriteTensors - Picard Version: 3.0.0; 02:02:31.346 INFO CNNVariantWriteTensors - Built for Spark Version: 3.3.1; 02:02:31.346 INFO CNNVariantWriteTensors - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 02:02:31.346 INFO CNNVariantWriteTensors - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 02:02:31.346 INFO CNNVariantWriteTensors - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 02:02:31.347 INFO CNNVariantWriteTensors - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 02:02:31.347 INFO CNNVariantWriteTensors - Deflater: IntelDeflater; 02:02:31.347 INFO CNNVariantWriteTensors - Inflater: IntelInflater; 02:02:31.347 INFO CNNVariantWriteTensors - GCS max retries/reopens: 20; 02:02:31.347 INFO CNNVariantWriteTensors - Requester pays: disabled; 02:02:31.347 WARN CNNVariantWriteTensors - . !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. Warning: CNNVariantWriteTensors is an EXPERIMENTAL tool and should not be used for production. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. 02:02:31.347 INFO CNNVariantWriteTensors - Initializing engine; 02:02:33.899 INFO CNNVariantWriteTensors - Done initializing engine; 02:02:33.899 INFO CNNVariantWriteTensors - Args are:[--reference_fasta, /data2/example/1/hg19.fa, --input_vcf, /data2/example/NA12877.vcf.gz, --bam_file, , --train_vcf, /data2/example/hg19.hybrid.vcf.gz, --bed_file, /data2/example/hg19.hybrid.bed, --tensor_name, reference, --annotation_set, best_practices, --samples, 1000000, --downsample_snps, 0.05, --downsample_indels, 0.5, --data_dir, /data2/example/results, --channels_last, --mode, write_reference_and_annotation_tensors]; 02:38:41.806 INFO CNNVariantWriteTensors - Shutting down engine; [August 30, 2023 at 2:38:41 AM GMT] org.broadinstitute.hellbender.tools.walkers.vqsr.CNNVariantWriteTensors done. Elapsed time: 36.18 minutes.; Runtime.totalMemory()=285212672; Tool returned:; true. ####issue:; /data2/example/results is empty, and no file was generated.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8506:3342,down,down,3342,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8506,1,['down'],['down']
Availability,"463); - formatting on sample QC README; - formatting change #2 to sample QC README; - address VS-152, remove extra headers from extract (#7466); - Update GvsExtractCallset.example.inputs.json (#7469); - Add ability to copy interval list files to gs directory [VS-191] (#7467); - add an expiration date to the temp tables (#7455); - fix the check for duplicates in import genomes (#7470); - added job ID to alt_allele population call output [VS-194] (#7473); - added steps and deliverables to GVS README [VS-181] (#7452); - Ah check the is loaded field in feature extract (#7475); - changes to put pet data directly into data table (#7478); - added override for ExtractTasks' preemptible value (#7477); - bcftools to the rescue (#7456); - execute_with_retry() refactor and error handling improvements [VS-159] (#7480); - Small updates to GvsExtractCallset from beta callset, new workflow for re-scattered shards (#7493); - add flag in prepare to print out sql instead of executing (#7501); - Workflow to re-scatter and then merge ""problematic"" intervals from ExtractCallset [VS-209] (#7495); - changed README to reflect comments from Lee [VS-210] (#7502); - Export the VAT into GCS (#7472); - addresses VS-219 (#7508); - small fix to MergeVCFs (#7517); - small fixes to GVS pipeline (#7522); - make sure ExtractTask is run on all interval files; - Revert ""make sure ExtractTask is run on all interval files""; - make sure ExtractTask is run on all interval files (#7527); - Remove Sites only step from the VAT creation WDL (#7510); - fix bad argument processing for bool (#7529); - Support for TDR DRS URIs in Import (#7528); - Match format of filename output in GvsRescatterCallsetInterval (#7539); - Reference block storage and query support (#7498); - update docs (#7540); - Kc fix rr load bug (#7550); - Update .dockstore.yml (#7553); - Ah add reblocking wdl (#7544); - Scatter over all interval files, not just scatter count (#7551); - fixed docker (#7558); - take advantage of fixed version of Spl",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8248:19018,error,error,19018,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8248,2,['error'],['error']
Availability,"46:05.153 INFO CNNScoreVariants - Inflater: IntelInflater; 10:46:05.153 INFO CNNScoreVariants - GCS max retries/reopens: 20; 10:46:05.153 INFO CNNScoreVariants - Requester pays: disabled; 10:46:05.153 INFO CNNScoreVariants - Initializing engine; 10:46:05.598 INFO FeatureManager - Using codec VCFCodec to read file file:///lustre/scratch/scratch/regmova/tmp/TEST_DATA/TR017_GERMLINE_VARIANTS/TR017.GL.vcf.gz; 10:46:05.638 INFO CNNScoreVariants - Done initializing engine; 10:46:05.639 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/lustre/home/regmova/tools/gatk/build/libs/gatk-package-4.2.0.0-19-ge60cdf8-SNAPSHOT-local.jar!/com/intel/gkl/native/libgkl_utils.so; 10:46:35.436 INFO CNNScoreVariants - Using key:CNN_1D for CNN architecture:/tmp/1d_cnn_mix_train_full_bn.8208762367402959162.json and weights:/tmp/1d_cnn_mix_train_full_bn.2787226329292768726.hd5; 10:46:35.438 INFO CNNScoreVariants - Done scoring variants with CNN.; 10:46:35.438 INFO CNNScoreVariants - Shutting down engine; [12 May 2021 10:46:35 BST] org.broadinstitute.hellbender.tools.walkers.vqsr.CNNScoreVariants done. Elapsed time: 0.51 minutes.; Runtime.totalMemory()=2132279296; org.broadinstitute.hellbender.utils.python.PythonScriptExecutorException: A nack was received from the Python process (most likely caused by a raised exception caused by): nkm received. ```; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/home/regmova/miniconda3/envs/gatk/lib/python3.6/site-packages/vqsr_cnn/vqsr_cnn/models.py"", line 22, in start_session_get_args_and_model; K.clear_session(). AttributeError: module 'keras.backend' has no attribute 'clear_session'; 	at org.broadinstitute.hellbender.utils.python.StreamingPythonScriptExecutor.waitForAck(StreamingPythonScriptExecutor.java:222); 	at org.broadinstitute.hellbender.utils.python.StreamingPythonScriptExecutor.sendSynchronousCommand(StreamingPythonScriptExecutor.java:183); at org.broadinstitute.hellbender.tools.walkers.vqsr.CNNSco",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7250:3551,down,down,3551,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7250,1,['down'],['down']
Availability,4:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.taskgraph.DefaultTaskGraphExecuter$EventFiringTaskWorker.execute(DefaultTaskGraphExecuter.java:228); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.taskgraph.DefaultTaskGraphExecuter$EventFiringTaskWorker.execute(DefaultTaskGraphExecuter.java:215); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.taskgraph.AbstractTaskPlanExecutor$TaskExecutorWorker.processTask(AbstractTaskPlanExecutor.java:77); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.taskgraph.AbstractTaskPlanExecutor$TaskExecutorWorker.run(AbstractTaskPlanExecutor.java:58); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.taskgraph.DefaultTaskPlanExecutor.process(DefaultTaskPlanExecutor.java:32); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.taskgraph.DefaultTaskGraphExecuter.execute(DefaultTaskGraphExecuter.java:113); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.SelectedTaskExecutionAction.execute(SelectedTaskExecutionAction.java:37); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.DefaultBuildExecuter.execute(DefaultBuildExecuter.java:37); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.DefaultBuildExecuter.access$000(DefaultBuildExecuter.java:23); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.DefaultBuildExecuter$1.proceed(DefaultBuildExecuter.java:43); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.DryRunBuildExecutionAction.execute(DryRunBuildExecutionAction.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2802:4348,ERROR,ERROR,4348,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2802,1,['ERROR'],['ERROR']
Availability,"4\_transcriptExon, Gencode\_34\_transcriptPos, Gencode\_34\_cDnaChange, Gencode\_34\_codonChange, Gencode\_34\_proteinChange, Gencode\_34\_gcContent, Gencode\_34\_referenceContext, Gencode\_34\_otherTranscripts, ACMGLMMLof\_LOF\_Mechanism, ACMGLMMLof\_Mode\_of\_Inheritance, ACMGLMMLof\_Notes, ACMG\_recommendation\_Disease\_Name, ClinVar\_VCF\_AF\_ESP, ClinVar\_VCF\_AF\_EXAC, ClinVar\_VCF\_AF\_TGP, ClinVar\_VCF\_ALLELEID, ClinVar\_VCF\_CLNDISDB, ClinVar\_VCF\_CLNDISDBINCL, ClinVar\_VCF\_CLNDN, ClinVar\_VCF\_CLNDNINCL, ClinVar\_VCF\_CLNHGVS, ClinVar\_VCF\_CLNREVSTAT, ClinVar\_VCF\_CLNSIG, ClinVar\_VCF\_CLNSIGCONF, ClinVar\_VCF\_CLNSIGINCL, ClinVar\_VCF\_CLNVC, ClinVar\_VCF\_CLNVCSO, ClinVar\_VCF\_CLNVI, ClinVar\_VCF\_DBVARID, ClinVar\_VCF\_GENEINFO, ClinVar\_VCF\_MC, ClinVar\_VCF\_ORIGIN, ClinVar\_VCF\_RS, ClinVar\_VCF\_SSR, ClinVar\_VCF\_ID, ClinVar\_VCF\_FILTER, LMMKnown\_LMM\_FLAGGED, LMMKnown\_ID, LMMKnown\_FILTER ; ; 02:00:35.778 ERROR FuncotationMap - Values:  , , , , , , , , , , , , , , , , , , , , , , , , , , , , false, ,  ; ; 02:00:35.793 INFO  FilterFuncotations - Shutting down engine ; ; \[April 25, 2022 at 2:00:35 AM EDT\] org.broadinstitute.hellbender.tools.funcotator.FilterFuncotations done. Elapsed time: 0.03 minutes. ; ; Runtime.totalMemory()=319815680 ; ; org.broadinstitute.hellbender.exceptions.GATKException$ShouldNeverReachHereException: Cannot parse the funcotation attribute.  Num values: 31   Num keys: 53 ; ;     at org.broadinstitute.hellbender.tools.funcotator.FuncotationMap.createAsAllTableFuncotationsFromVcf(FuncotationMap.java:224) ; ;     at org.broadinstitute.hellbender.tools.funcotator.FuncotatorUtils.lambda$createAlleleToFuncotationMapFromFuncotationVcfAttribute$5(FuncotatorUtils.java:2256) ; ;     at java.base/java.util.stream.Collectors.lambda$uniqKeysMapAccumulator$1(Collectors.java:178) ; ;     at java.base/java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169) ; ;     at java.base/java.util.stream.IntPipeline$1$1.accept(I",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7865:6525,ERROR,ERROR,6525,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7865,1,['ERROR'],['ERROR']
Availability,"5); 	at java.lang.ClassLoader.loadClass(ClassLoader.java:357); 	at java.lang.Class.forName0(Native Method); 	at java.lang.Class.forName(Class.java:348); 	at java.io.ObjectInputStream.resolveClass(ObjectInputStream.java:677); 	at java.io.ObjectInputStream.readNonProxyDesc(ObjectInputStream.java:1826); 	at java.io.ObjectInputStream.readClassDesc(ObjectInputStream.java:1713); 	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2000); 	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535); 	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:422); 	at com.esotericsoftware.kryo.serializers.JavaSerializer.read(JavaSerializer.java:63); 	... 20 more; 17/11/15 19:43:35 INFO org.spark_project.jetty.server.AbstractConnector: Stopped Spark@5917b44d{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 17/11/15 19:43:35 WARN org.apache.spark.ExecutorAllocationManager: No stages are running, but numRunningTasks != 0; 19:43:35.858 INFO PrintVariantsSpark - Shutting down engine; [November 15, 2017 7:43:35 PM UTC] org.broadinstitute.hellbender.tools.spark.pipelines.PrintVariantsSpark done. Elapsed time: 0.43 minutes.; Runtime.totalMemory()=823132160; org.apache.spark.SparkException: Job aborted due to stage failure: Exception while getting task result: com.esotericsoftware.kryo.KryoException: Error during Java deserialization.; Serialization trace:; genotypes (org.seqdoop.hadoop_bam.VariantContextWithHeader); interval (org.broadinstitute.hellbender.engine.spark.SparkSharder$PartitionLocatable); 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(A",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3840:7962,down,down,7962,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3840,1,['down'],['down']
Availability,"5); at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.onStartup(AssemblyRegionWalker.java:79); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:138); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289); ```; #### Steps to reproduce; `gatk HaplotypeCaller -L chr22 -R /restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa -I cram/HG00096.final.cram -O test.g.vcf.gz`. The cram is HG0096.final.cram found here:. https://www.internationalgenome.org/data-portal/data-collection/30x-grch38. #### Expected behavior; When I run an earlier version v4.1.7.0, it runs without an error.... ```; gatk HaplotypeCaller -L chr22 -R /restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa -I cram/HG00096.final.cram -O test.g.vcf.gz; Using GATK jar /share/pkg.7/gatk/4.1.7.0/install/bin/gatk-package-4.1.7.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /share/pkg.7/gatk/4.1.7.0/install/bin/gatk-package-4.1.7.0-local.jar HaplotypeCaller -L chr22 -R /restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa -I cram/HG00096.final.cram -O test.g.vcf.gz; 14:40:45.497 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/share/pkg.7/gatk/4.1.7.0/install/bin/gatk-package-4.1.7.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Feb 10, 2021 2:40:45 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7076:5279,error,error,5279,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7076,1,['error'],['error']
Availability,"5.033 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:$HOME/local/pckg/python/miniconda3/envs/test/share/gatk4-4.1.7.0-0/gatk-package-4.1.7.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; [Tue Jun 16 23:25:05 CDT 2020] MergeVcfs --INPUT data/calling/a.vcf.gz --INPUT data/calling/b.vcf.gz --OUTPUT c.vcf.gz --VERBOSITY INFO --QUIET false --VALIDATION_STRINGENCY STRICT --COMPRESSION_LEVEL 2 --MAX_RECORDS_IN_RAM 500000 --CREATE_INDEX true --CREATE_MD5_FILE false --GA4GH_CLIENT_SECRETS client_secrets.json --help false --version false --showHidden false --USE_JDK_DEFLATER false --USE_JDK_INFLATER false; Jun 16, 2020 11:25:05 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; [Tue Jun 16 23:25:05 CDT 2020] Executing as xxxx on Linux 3.10.0-693.11.1.el7.x86_64 amd64; OpenJDK 64-Bit Server VM 1.8.0_152-release-1056-b12; Deflater: Intel; Inflater: Intel; Provider GCS is available; Picard version: Version:4.1.7.0; [Tue Jun 16 23:25:05 CDT 2020] picard.vcf.MergeVcfs done. Elapsed time: 0.01 minutes.; Runtime.totalMemory()=605028352; To get help, see http://broadinstitute.github.io/picard/index.html#GettingHelp; htsjdk.tribble.TribbleException$MalformedFeatureFile: Unable to create BasicFeatureReader using feature file , for input source: file:///tmp/test%20a/data/calling/a.vcf.gz; at htsjdk.tribble.AbstractFeatureReader.getFeatureReader(AbstractFeatureReader.java:124); at htsjdk.tribble.AbstractFeatureReader.getFeatureReader(AbstractFeatureReader.java:81); at htsjdk.variant.vcf.VCFFileReader.<init>(VCFFileReader.java:148); at htsjdk.variant.vcf.VCFFileReader.<init>(VCFFileReader.java:98); at picard.vcf.MergeVcfs.doWork(MergeVcfs.java:174); at picard.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:305); at org.broadinstitute.hellbender.cmdline.PicardCommandLineProgramExecutor.instanceMain(PicardCommandLineProgramExecutor",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6664:2350,avail,available,2350,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6664,1,['avail'],['available']
Availability,5.741 DEBUG IntToDoubleFunctionCache - cache miss 26873 > 26616 expanding to 53234; 11:36:56.119 DEBUG Mutect2Engine - Active Region chrM:6354-6629; 11:36:56.119 DEBUG Mutect2Engine - Extended Act Region chrM:6254-6729; 11:36:56.119 DEBUG Mutect2Engine - Ref haplotype coords chrM:6254-6729; 11:36:56.119 DEBUG Mutect2Engine - Haplotype count 128; 11:36:56.119 DEBUG Mutect2Engine - Kmer sizes count 0; 11:36:56.120 DEBUG Mutect2Engine - Kmer sizes values []; 11:39:06.762 DEBUG Mutect2 - Processing assembly region at chrM:6630-6929 isActive: false numReads: 30053; 11:39:07.547 DEBUG Mutect2 - Processing assembly region at chrM:6930-7229 isActive: false numReads: 0; 11:39:07.574 DEBUG Mutect2 - Processing assembly region at chrM:7230-7493 isActive: false numReads: 359; 11:39:07.584 DEBUG Mutect2 - Processing assembly region at chrM:7494-7771 isActive: true numReads: 718; 11:39:07.668 DEBUG ReadThreadingGraph - Recovered 32 of 33 dangling tails; 11:39:07.713 DEBUG ReadThreadingGraph - Recovered 31 of 50 dangling heads; 11:39:07.996 DEBUG Mutect2Engine - Active Region chrM:7494-7771; 11:39:07.998 DEBUG Mutect2Engine - Extended Act Region chrM:7394-7871; 11:39:07.999 DEBUG Mutect2Engine - Ref haplotype coords chrM:7394-7871; 11:39:08.000 DEBUG Mutect2Engine - Haplotype count 128; 11:39:08.001 DEBUG Mutect2Engine - Kmer sizes count 0; 11:39:08.002 DEBUG Mutect2Engine - Kmer sizes values []; 11:39:12.623 DEBUG Mutect2 - Processing assembly region at chrM:7772-8071 isActive: false numReads: 359; 11:39:12.636 INFO ProgressMeter - chrM:7772 3.5 30 8.5; 11:39:12.638 DEBUG Mutect2 - Processing assembly region at chrM:8072-8371 isActive: false numReads: 0; 11:39:27.522 DEBUG IntToDoubleFunctionCache - cache miss 9173 > 5354 expanding to 10710; 11:39:31.241 DEBUG Mutect2 - Processing assembly region at chrM:8372-8671 isActive: false numReads: 0; 11:39:43.892 DEBUG Mutect2 - Processing assembly region at chrM:8672-8829 isActive: false numReads: 148658; 11:39:47.277 DEBUG IntToDoubleFu,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7281:14242,Recover,Recovered,14242,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7281,1,['Recover'],['Recovered']
Availability,"503 (Service Unavailable) errors are transient and should be retried. Saw this today running GenomicsDBImport. `htsjdk.tribble.TribbleException$MalformedFeatureFile: Unable to parse header with error: 503 Service Unavailable; Service Unavailable, for input source: gs://fc-4c1c7765-2de2-4214-ac41-dc10bbcbb55b/1e300bb3-6990-4342-8959-118826efb3dd/PairedEndSingleSampleWorkflow/d0aac891-4d32-43b9-8adb-edb6b5204af9/call-GatherVCFs/S76-1-2.g.vcf.gz; 	at htsjdk.tribble.TabixFeatureReader.readHeader(TabixFeatureReader.java:102); 	at htsjdk.tribble.TabixFeatureReader.<init>(TabixFeatureReader.java:86); 	at htsjdk.tribble.AbstractFeatureReader.getFeatureReader(AbstractFeatureReader.java:106); 	at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImport.getReaderFromVCFUri(GenomicsDBImport.java:443); 	at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImport.getFeatureReaders(GenomicsDBImport.java:425); 	at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImport.traverse(GenomicsDBImport.java:349); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:747); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:116); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:174); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:193); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:121); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:142); 	at org.broadinstitute.hellbender.Main.main(Main.java:220); Caused by: com.google.cloud.storage.StorageException: 503 Service Unavailable; Service Unavailable; 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.translate(HttpStorageRpc.java:186); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.get(HttpStorageRpc.java:332); 	at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:186); 	at com.google.cloud.storage.Storage",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2749:26,error,errors,26,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2749,2,['error'],"['error', 'errors']"
Availability,"51Z 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.traverse(MultiplePassVariantWalker.java:40); 2019-10-29T18:18:04.002731707Z 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1048); 2019-10-29T18:18:04.002740306Z 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); 2019-10-29T18:18:04.002745164Z 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); 2019-10-29T18:18:04.002777218Z 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); 2019-10-29T18:18:04.002785268Z 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:162); 2019-10-29T18:18:04.002855927Z 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:205); 2019-10-29T18:18:04.002867030Z 	at org.broadinstitute.hellbender.Main.main(Main.java:291); ```; I am using ExAC lifted to hg38 as a germline resource in mutect2 with only a tumor sample, and getting the above error in filtermutectcalls. I recently updated to v4.1.3.0 to have the latest changes to mutect2. I was not having this issue with v4.0.5.1. Here is extracted information from the VCF which caused the issue. . ```; DP=1;ECNT=2;FS=0.000;MBQ=0,20;MFRL=0,91;MMQ=60,46;MPOS=6;MQ=46.00;POPAF=5.08;TLOD=4.20	GT:AD:AF:DP:F1R2:F2R1:PGT:PID:PS:SB	0|1:0,1:0.667:1:0,1:0,0:0|1:11155815_C_T:11155815:0,0,1,0; DP=1;ECNT=2;FS=0.000;MBQ=0,20;MFRL=0,91;MMQ=60,46;MPOS=16;MQ=46.00;POPAF=5.08;TLOD=4.20	GT:AD:AF:DP:F1R2:F2R1:PGT:PID:PS:SB	0|1:0,1:0.667:1:0,1:0,0:0|1:11155815_C_T:11155815:0,0,1,0; DP=1;ECNT=2;FS=0.000;MBQ=0,34;MFRL=0,272;MMQ=60,30;MPOS=25;MQ=30.00;POPAF=4.13;TLOD=4.20	GT:AD:AF:DP:F1R2:F2R1:PGT:PID:PS:SB	0|1:0,1:0.667:1:0,1:0,0:0|1:11350899_C_T:11350899:0,0,1,0; DP=1;ECNT=2;FS=0.000;MBQ=0,32;MFRL=0,272;MMQ=60,30;MPOS=15;MQ=30.00;POPAF=4.23;TLOD=4.20	GT:AD:AF:DP:F1R2:F2R1:PGT:PID:PS:SB	0|1:0,1:0.667:1:0,1:0,0:0|1:11350899_C_T:11350899:0,0,1,0; `",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6237:5279,error,error,5279,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6237,1,['error'],['error']
Availability,54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.SkipTaskWithNoActionsExecuter.execute(SkipTaskWithNoActionsExecuter.java:51); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.SkipOnlyIfTaskExecuter.execute(SkipOnlyIfTaskExecuter.java:54); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.ExecuteAtMostOnceTaskExecuter.execute(ExecuteAtMostOnceTaskExecuter.java:43); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.CatchExceptionTaskExecuter.execute(CatchExceptionTaskExecuter.java:34); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.taskgraph.DefaultTaskGraphExecuter$EventFiringTaskWorker$1.execute(DefaultTaskGraphExecuter.java:236); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.taskgraph.DefaultTaskGraphExecuter$EventFiringTaskWorker$1.execute(DefaultTaskGraphExecuter.java:228); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.Transformers$4.transform(Transformers.java:169); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:106); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:61); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.taskgraph.DefaultTaskGraphExecuter$EventFiringTaskWorker.execute(DefaultTaskGraphExecuter.java:228); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2802:2633,ERROR,ERROR,2633,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2802,1,['ERROR'],['ERROR']
Availability,"55 INFO server.Server: Started @25495ms; 18/01/09 18:30:55 INFO server.AbstractConnector: Started ServerConnector@283ab206{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 18/01/09 18:30:55 INFO util.Utils: Successfully started service 'SparkUI' on port 4040.; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@418f0534{/jobs,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@134a8ead{/jobs/json,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@54247647{/jobs/job,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5463f035{/jobs/job/json,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@44fd7ba4{/stages,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@69d103f0{/stages/json,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@74fb5b59{/stages/stage,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@26fadd98{/stages/stage/json,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@3db6dd52{/stages/pool,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6ef4cbe1{/stages/pool/json,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2baac4a7{/storage,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6bce4140{/storage/json,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5882b202{/storage/rdd,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4112:7814,AVAIL,AVAILABLE,7814,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4112,1,['AVAIL'],['AVAILABLE']
Availability,"559423		8560126; chr3	64547471	64549936; chr3	90414457	90415989; ````. I tried the following, running `ModelSegments` using fairly sensitive parameters (`--number-of-changepoints-penalty-factor 0.1 --maximum-number-of-segments-per-chromosome 10000 --window-size 16 --window-size 32 --maximum-number-of-smoothing-iterations 0` in copy-ratio-only mode:. 1) CollectFragmentCounts. This only recovered event 2.; 2) CollectReadCounts - same as CollectFragmentCounts, but removing the properly-paired and first-of-pair filters and adding a count for each read to the bin containing its start. This recovered all 3 events.; 3) CollectFragmentOverlaps - same filters as CollectFragmentCounts, but adding counts to all bins overlapping each fragment. Note that we need to implement a filter on maximum fragment length, otherwise we get some strange artifacts from (incorrectly mapped?) extremely long fragments; I arbitrarily chose a cutoff of 10000bp. This recovered events 1 and 2. Event 3 seemed to be the most difficult to recover. Plotting the copy ratios surrounding this event (which spans ~15 100bp bins) yields some insights:. CollectFragmentCounts:; ![image](https://user-images.githubusercontent.com/11076296/37244188-317a7f1e-2453-11e8-937d-f7239354316e.png). CollectReadCounts:; ![image](https://user-images.githubusercontent.com/11076296/37244228-ad24908c-2453-11e8-91dd-a978578e77f4.png). CollectFragmentOverlaps:; ![image](https://user-images.githubusercontent.com/11076296/37244230-b25b9cee-2453-11e8-8646-f9c95365b355.png). The increased statistical noise in the CollectFragmentCounts result (due to the lower overall count because of the pairing of reads) probably causes us to miss this event. Also, although CollectFragmentOverlaps initially looks pretty good, I think the bin-to-bin correlations that are evident here negatively affect segmentation. This is not an extremely rigorous evaluation, but it suggests that we should consider switching over to a CollectReadCounts-like strategy",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4519:2364,recover,recover,2364,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4519,1,['recover'],['recover']
Availability,"57:17.333 INFO AnalyzeCovariates - Generating csv file '/tmp/AnalyzeCovariates17353441228865531235.csv'; 12:57:17.414 INFO AnalyzeCovariates - Generating plots file '/home/detagen/Desktop/pipeline/playground/NECESSARY/FMF-248/AnalyzeCovariates.FMF-248.pdf'; 12:57:17.829 INFO AnalyzeCovariates - Shutting down engine; [December 17, 2020 at 12:57:17 PM TRT] org.broadinstitute.hellbender.tools.walkers.bqsr.AnalyzeCovariates done. Elapsed time: 0.02 minutes.; Runtime.totalMemory()=633339904; org.broadinstitute.hellbender.utils.R.RScriptExecutorException: ; Rscript exited with 1; Command Line: Rscript -e tempLibDir = '/tmp/Rlib.10272183847736955081';source('/tmp/BQSR.16251220439562120273.R'); /tmp/AnalyzeCovariates17353441228865531235.csv /home/detagen/Desktop/pipeline/playground/BACKUP/FMF-248_Backup/before.recal.FMF-248.table /home/detagen/Desktop/pipeline/playground/NECESSARY/FMF-248/AnalyzeCovariates.FMF-248.pdf; Stdout: ; Stderr: Error in library(gplots) : there is no package called ‘gplots’; Calls: source -> withVisible -> eval -> eval -> library; Execution halted. 	at org.broadinstitute.hellbender.utils.R.RScriptExecutor.getScriptException(RScriptExecutor.java:80); 	at org.broadinstitute.hellbender.utils.R.RScriptExecutor.getScriptException(RScriptExecutor.java:19); 	at org.broadinstitute.hellbender.utils.runtime.ScriptExecutor.executeCuratedArgs(ScriptExecutor.java:130); 	at org.broadinstitute.hellbender.utils.R.RScriptExecutor.exec(RScriptExecutor.java:126); 	at org.broadinstitute.hellbender.utils.recalibration.RecalUtils.generatePlots(RecalUtils.java:360); 	at org.broadinstitute.hellbender.tools.walkers.bqsr.AnalyzeCovariates.generatePlots(AnalyzeCovariates.java:329); 	at org.broadinstitute.hellbender.tools.walkers.bqsr.AnalyzeCovariates.doWork(AnalyzeCovariates.java:341); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(Command",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7006:4112,Error,Error,4112,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7006,1,['Error'],['Error']
Availability,"5:53.390 INFO ProgressMeter - Starting traversal; 09:15:53.390 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 09:15:53.479 INFO SelectVariants - Shutting down engine; [June 27, 2019 9:15:53 AM CDT] org.broadinstitute.hellbender.tools.walkers.variantutils.SelectVariants done. Elapsed time: 0.07 minutes.; Runtime.totalMemory()=2131755008; htsjdk.tribble.TribbleException: The provided VCF file is malformed at approximately line number 3433: The VCF specification does not allow for whitespace in the INFO field; . Offending field value was ""AC=1;AF=9.671e-04;AN=1034;AS_BaseQRankSum=-1.550;AS_FS=8.334;AS_InbreedingCoeff=-0.3147;AS_MQ=31.69;AS_MQRankSum=-0.200;AS_QD=28.73;AS_ReadPosR; ankSum=nul;AS_SOR=2.235;BaseQRankSum=-1.381e+00;DP=40368;ExcessHet=160.0000;FS=8.334;InbreedingCoeff=-0.3147;MLEAC=7;MLEAF=6.770e-03;MQ=37.13;MQRankSum=0.126;QD=2.46;SOR=2.; 235 GT:AD:DP:GQ:PGT:PID:PL:PS 0/0:75,0:75:0:.:.:0,0,1525; `. However, from the error message I cannot see any whitespace in the INFO field. The /dsgmnt/seq5_llfs/work/xhong/v4100/ApplyVQSR/ExcessHet_joint525_c1_22.SNP.VQSR.g.vcf.gz is the output of following command:. `gatk4.1.0.0 --java-options '-Xmx100g -Xmx100g' ApplyVQSR \; -R /dsgmnt/llfs2/masterdata/geno/hg38/resources_broad_hg38_v0_Homo_sapiens_assembly38.fasta \; -V ${SNPPath}/joint525_chr1_ExcessHet_filter.SNP.g.vcf.gz \; -V ${SNPPath}/joint525_chr2_ExcessHet_filter.SNP.g.vcf.gz \; ....; -V ${SNPPath}/joint525_chr22_ExcessHet_filter.SNP.g.vcf.gz \; -O /dsgmnt/seq5_llfs/work/xhong/v4100/ApplyVQSR//ExcessHet_joint525_c1_22.SNP.VQSR.g.vcf.g; z \; --truth-sensitivity-filter-level 97 \; --tranches-file /dsgmnt/seq5_llfs/work/xhong/v4100/VQSR//ExcessHet_joint525_c1_22.snp.tranches \; --recal-file /dsgmnt/seq5_llfs/work/xho; ng/v4100/VQSR//ExcessHet_joint525_c1_22.snp.recal \; -mode SNP`. There is no error or warning in the standard error and standard output of this step. I have tried to apply VQSR SNP model to ${SNPPath}/joint525_",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6021:3784,error,error,3784,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6021,1,['error'],['error']
Availability,5:55.985 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at build_2s1dokgyqm2mnf3n5hcv2kf17.resolveLargeResourceStubFiles(/scratch/var/tmp/portage/sci-biology/gatk-9999/work/gatk-9999/build.gradle:116); 22:05:55.985 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at build_2s1dokgyqm2mnf3n5hcv2kf17$resolveLargeResourceStubFiles$0.callCurrent(Unknown Source); 22:05:55.985 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at build_2s1dokgyqm2mnf3n5hcv2kf17.ensureBuildPrerequisites(/scratch/var/tmp/portage/sci-biology/gatk-9999/work/gatk-9999/build.gradle:140); 22:05:55.985 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at build_2s1dokgyqm2mnf3n5hcv2kf17$ensureBuildPrerequisites.callCurrent(Unknown Source); 22:05:55.985 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at build_2s1dokgyqm2mnf3n5hcv2kf17.run(/scratch/var/tmp/portage/sci-biology/gatk-9999/work/gatk-9999/build.gradle:143); 22:05:55.985 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.groovy.scripts.internal.DefaultScriptRunnerFactory$ScriptRunnerImpl.run(DefaultScriptRunnerFactory.java:90); 22:05:55.986 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	... 58 more; 22:05:55.986 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] ; 22:05:55.986 [LIFECYCLE] [org.gradle.internal.buildevents.BuildResultLogger] ; 22:05:55.986 [LIFECYCLE] [org.gradle.internal.buildevents.BuildResultLogger] BUILD FAILED; 22:05:55.986 [LIFECYCLE] [org.gradle.internal.buildevents.BuildResultLogger] ; 22:05:55.987 [LIFECYCLE] [org.gradle.internal.buildevents.BuildResultLogger] Total time: 29.153 secs; ```. ```; root# su - portage; portage$ cd /scratch/var/tmp/portage/sci-biology/gatk-9999/work/gatk-9999/; portage$ git lfs pull --include src/main/resources/large; No default remote. Errors logged to /scratch/var/tmp/portage/sci-biology/gatk-9999/work/gatk-9999/.git/lfs/objects/logs/20180420T,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4687:14137,ERROR,ERROR,14137,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4687,1,['ERROR'],['ERROR']
Availability,"5g -Xms85g"" GenomicsDBImport \\ ; ; \-R ${dir\_refdata}/b37\_human\_g1k\_v37\_decoy.fasta \\ ; ; \--sample-name-map ${dir\_CombineGVCFs}/S2\_cohort.sample\_map \\ ; ; \--genomicsdb-workspace-path ${dir\_CombineGVCFs}/temporary/tmp4 \\ ; ; \--TMP\_DIR ${dir\_CombineGVCFs}/temporary \\ ; ; \--intervals ${dir\_CombineGVCFs}/intervals/bed3\_tmp.intervals \\ ; ; \--reader-threads 5 \\ ; ; \--batch-size 50. **\[output\]**:. folders and files in; ====================. \--genomicsdb-workspace-path ${dir\_CombineGVCFs}/temporary/tmp4; ================================================================. callset.json ; ; genomicsdb\_array ; ; \_\_tiledb\_workspace.tdb ; ; vcfheader.vcf ; ; vidmap.json. **\[Tool\]: GenotypeGVCFs**. export TILEDB\_DISABLE\_FILE\_LOCKING=1. time ${dir\_tool\_gatk}/gatk --java-options ""-Xmx4g"" GenotypeGVCFs \\ ; ; \-R ${dir\_refdata}/b37\_human\_g1k\_v37\_decoy.fasta \\ ; ; \-V gendb://${dir\_GenomicsDBImport}/tmp4 \\ ; ; \-O ${dir\_GenotypeVCFs}/tmp4.vcf.gz. c) Entire error log:. Using GATK jar /home/projects/bin/gatk-4.0.3.0/gatk-package-4.0.3.0-local.jar ; ; Running: ; ; java -Dsamjdk.use\_async\_io\_read\_samtools=false ; ; \-Dsamjdk.use\_async\_io\_write\_samtools=true ; ; \-Dsamjdk.use\_async\_io\_write\_tribble=false ; ; \-Dsamjdk.compression\_level=2 ; ; \-Xmx4g -jar /home/projects/bin/gatk-4.0.3.0/gatk-package-4.0.3.0-local.jar ; ; GenotypeGVCFs -R /home/reference\_hg19/b37\_human\_g1k\_v37\_decoy.fasta ; ; \-V gendb:///home/WES-VCFQC/S2\_GenomicsDBImport/temporary/tmp4 ; ; \-O /home/WES-VCFQC/S2\_GenomicsDBImport/VCF/tmp4.vcf.gz ; ; 12:52:15.187 INFO NativeLibraryLoader - Loading libgkl\_compression.so from jar:file:/home/projects/bin/gatk-4.0.3.0/gatk-package-4.0.3.0-local.jar!/com/intel/gkl/native/libgkl\_compression.so ; ; 12:52:16.266 INFO GenotypeGVCFs - ------------------------------------------------------------ ; ; 12:52:16.267 INFO GenotypeGVCFs - The Genome Analysis Toolkit (GATK) v4.0.3.0 ; ; 12:52:16.267 INFO GenotypeGVCFs - For",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7442:1856,error,error,1856,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7442,1,['error'],['error']
Availability,"6 more**. 00:59 DEBUG: [kryo] Write: WrappedArray(null); 18/04/24 17:55:54 INFO TaskSetManager: Starting task 1.1 in stage 2.0 (TID 5, xx.xx.xx.24, executor 1, partition 1, PROCESS_LOCAL, 5371 bytes); 18/04/24 17:55:54 INFO TaskSetManager: Lost task 0.0 in stage 2.0 (TID 3) on xx.xx.xx.25, executor 2: org.broadinstitute.hellbender.exceptions.UserException$CouldNotReadInputFile (Couldn't read file. Error was: hg19mini.hss with exception: hg19mini.hss (No such file or directory)) [duplicate 1]; 01:00 DEBUG: [kryo] Write: WrappedArray([NC_000913.3_127443_127875_0:0:0_0:0:0_a507 UNMAPPED, NC_000913.3_127443_127875_0:0:0_0:0:0_a507 UNMAPPED]); 18/04/24 17:55:54 INFO TaskSetManager: Starting task 0.1 in stage 2.0 (TID 6, xx.xx.xx.16, executor 3, partition 0, PROCESS_LOCAL, 6010 bytes); 18/04/24 17:55:55 INFO TaskSetManager: Lost task 0.1 in stage 2.0 (TID 6) on xx.xx.xx.16, executor 3: org.broadinstitute.hellbender.exceptions.UserException$CouldNotReadInputFile (Couldn't read file. Error was: hg19mini.hss with exception: hg19mini.hss (No such file or directory)) [duplicate 2]; 01:00 DEBUG: [kryo] Write: WrappedArray([NC_000913.3_127443_127875_0:0:0_0:0:0_a507 UNMAPPED, NC_000913.3_127443_127875_0:0:0_0:0:0_a507 UNMAPPED]); 18/04/24 17:55:55 INFO TaskSetManager: Starting task 0.2 in stage 2.0 (TID 7, xx.xx.xx.23, executor 5, partition 0, PROCESS_LOCAL, 6010 bytes); 18/04/24 17:55:55 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on xx.xx.xx.23:42535 (size: 6.4 KB, free: 366.3 MB); 18/04/24 17:55:55 INFO TaskSetManager: Lost task 0.2 in stage 2.0 (TID 7) on xx.xx.xx.23, executor 5: org.broadinstitute.hellbender.exceptions.UserException$CouldNotReadInputFile (Couldn't read file. Error was: hg19mini.hss with exception: hg19mini.hss (No such file or directory)) [duplicate 3]; 01:00 DEBUG: [kryo] Write: WrappedArray([NC_000913.3_127443_127875_0:0:0_0:0:0_a507 UNMAPPED, NC_000913.3_127443_127875_0:0:0_0:0:0_a507 UNMAPPED]); 18/04/24 17:55:55 INFO TaskSetManager: Starti",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4699:27909,Error,Error,27909,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4699,1,['Error'],['Error']
Availability,"67); 	at org.broadinstitute.hellbender.tools.walkers.fasta.FastaAlternateReferenceMaker.handlePosition(FastaAlternateReferenceMaker.java:176); 	at org.broadinstitute.hellbender.tools.walkers.fasta.FastaAlternateReferenceMaker.apply(FastaAlternateReferenceMaker.java:141); 	at org.broadinstitute.hellbender.engine.ReferenceWalker.traverse(ReferenceWalker.java:55); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1085); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); 	at org.broadinstitute.hellbender.Main.main(Main.java:289); ```. By narrowing down on where this happens I find it happens here:. ```; chrom	16798	.	TAGC	*	41.94	.	AC=1;AF=1.00;AN=1;BaseQRankSum=-5.240e-01;DP=29;FS=3.663;MQ=36.43;MQRankSum=-1.282e+00;QD=1.40;ReadPosRankSum=0.00;SOR=0.446	GT:AD:DP:GQ:PL	1:0,6:29:99:810,0. chrom	16799	.	A	*	0	LowQual	AC=1;AF=1.00;AN=1;DP=29;FS=3.663;QD=0.00;SOR=0.446	GT:AD:DP:GQ:PL	1:0,6:29:99:810,0. chrom	16800	.	G	*	3727.44	.	AC=1;AF=1.00;AN=1;BaseQRankSum=0.00;DP=29;FS=2.256;MQ=42.17;MQRankSum=1.88;QD=21.42;ReadPosRankSum=-6.100e-02;SOR=0.920	GT:AD:DP:GQ:PL	1:0,6:29:99:810,0. chrom	16801	.	C	*	0	LowQual	AC=1;AF=1.00;AN=1;DP=29;FS=3.663;QD=0.00;SOR=0.446	GT:AD:DP:GQ:PL	1:0,6:29:99:810,0. chrom	16802	.	A	*	0	LowQual	AC=1;AF=1.00;AN=1;DP=29;FS=4.509;QD=0.00;SOR=0.378	GT:AD:DP:GQ:PL	1:0,6:29:99:810,0. chrom	16804	.	CAGA	.	379.83	.	AN=1;BaseQRankSum=0.00;DP=48;FS=0.000;MQ=42.50;MQRankSum=-6.740e-01;QD=29.22;ReadPosRankSum=0.524;SOR=0.836	GT:AD:DP:PL	0:48:48:0; ```. The problem is at position 16800. I have gotten this error again in similar positions w",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7433:1918,down,down,1918,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7433,1,['down'],['down']
Availability,"6913384130304_1605025432087/__book_keeping.tdb.gz; ; errno=122(Disk quota exceeded); [TileDB::BookKeeping] Error: Cannot finalize book-keeping; Failure to write to file /storage/home/data/gendb/chr13/chr13$32310639$32310731/.__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/__book_keeping.tdb.gz.; [TileDB::FileSystem] Error: (create_file) Failed to create file; path=/storage/home/data/gendb/chr13/chr13$32310639$32310731/__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/__tiledb_fragment.tdb; errno=122(Disk quota exceeded); [TileDB::utils] Error: (create_fragment_file) Failed to create fragment file; path=/storage/home/data/gendb/chr13/chr13$32310639$32310731/__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087; errno=122(Disk quota exceeded); 11:23:52.390 erro NativeGenomicsDB - pid=57964 tid=57984 VariantStorageManagerException exception : Error while finalizing TileDB array chr13$32310639$32310731; TileDB error message : [TileDB::WriteState] Error: Cannot write segment to file; [TileDB::FileSystem] Error: (write_to_file) Cannot write to file; File opening error; path=/storage/home/data/gendb/chr13/chr13$32310639$32310731/.__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/RAW_MQandDP.tdb; errno=122(Disk quota exceede; d); #### Steps to reproduce; Below code ran on a cluster; ```; gatk --java-options ""-Xmx100g -Xms100g"" GenomicsDBImport \; -V sample1.g.vcf.gz -V sample2.g.vcf.gz -V sample3.g.vcf.gz -V sample4.g.vcf.gz \; -L chr13.bed \; --genomicsdb-workspace-path /storage/home/data/gendb/chr13\; --tmp-dir /storage/home/scratch/tmp; ```. #### Expected behavior; Over 1TB of scratch space available for temporary directory and around 500GB of storage space available to hold outputs of GenomicsDBImport outputs. #### Actual behavior; Above error message indicating that disk quota has exceeded. I'm not exactly sure what's going on here as I am directing the outputs of the GenomicsDBImport runs to directories",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6950:1896,Error,Error,1896,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6950,5,"['Error', 'error']","['Error', 'error']"
Availability,6:40.765 DEBUG Mutect2 - Processing assembly region at chrM:5144-5443 isActive: false numReads: 0; 11:36:40.771 INFO ProgressMeter - chrM:5144 1.0 20 20.4; 11:36:40.774 DEBUG Mutect2 - Processing assembly region at chrM:5444-5743 isActive: false numReads: 0; 11:36:41.211 DEBUG IntToDoubleFunctionCache - cache miss 11898 > 5320 expanding to 11908; 11:36:41.213 DEBUG IntToDoubleFunctionCache - cache miss 17632 > 11908 expanding to 23818; 11:36:41.254 DEBUG IntToDoubleFunctionCache - cache miss 29537 > 23818 expanding to 47638; 11:36:42.578 DEBUG Mutect2 - Processing assembly region at chrM:5744-6043 isActive: false numReads: 0; 11:36:47.533 DEBUG Mutect2 - Processing assembly region at chrM:6044-6343 isActive: false numReads: 30078; 11:36:47.979 DEBUG Mutect2 - Processing assembly region at chrM:6344-6353 isActive: false numReads: 30081; 11:36:48.322 DEBUG Mutect2 - Processing assembly region at chrM:6354-6629 isActive: true numReads: 60135; 11:36:55.630 DEBUG ReadThreadingGraph - Recovered 8 of 11 dangling tails; 11:36:55.645 DEBUG ReadThreadingGraph - Recovered 7 of 16 dangling heads; 11:36:55.737 DEBUG IntToDoubleFunctionCache - cache miss 26606 > 4800 expanding to 26616; 11:36:55.741 DEBUG IntToDoubleFunctionCache - cache miss 26873 > 26616 expanding to 53234; 11:36:56.119 DEBUG Mutect2Engine - Active Region chrM:6354-6629; 11:36:56.119 DEBUG Mutect2Engine - Extended Act Region chrM:6254-6729; 11:36:56.119 DEBUG Mutect2Engine - Ref haplotype coords chrM:6254-6729; 11:36:56.119 DEBUG Mutect2Engine - Haplotype count 128; 11:36:56.119 DEBUG Mutect2Engine - Kmer sizes count 0; 11:36:56.120 DEBUG Mutect2Engine - Kmer sizes values []; 11:39:06.762 DEBUG Mutect2 - Processing assembly region at chrM:6630-6929 isActive: false numReads: 30053; 11:39:07.547 DEBUG Mutect2 - Processing assembly region at chrM:6930-7229 isActive: false numReads: 0; 11:39:07.574 DEBUG Mutect2 - Processing assembly region at chrM:7230-7493 isActive: false numReads: 359; 11:39:07.584 DEBUG Mutect2,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7281:13043,Recover,Recovered,13043,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7281,1,['Recover'],['Recovered']
Availability,"7 9:14:13 AM CST] Executing as yaron@dn1 on Linux 4.4.0-31-generic amd64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_121-b13; Version: 4.alpha.2-281-g752d020-SNAPSHOT; 09:14:13.567 INFO PrintReadsSpark - HTSJDK Defaults.COMPRESSION_LEVEL : 1; 09:14:13.567 INFO PrintReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 09:14:13.567 INFO PrintReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : false; 09:14:13.567 INFO PrintReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 09:14:13.567 INFO PrintReadsSpark - Deflater: IntelDeflater; 09:14:13.567 INFO PrintReadsSpark - Inflater: IntelInflater; 09:14:13.567 INFO PrintReadsSpark - Initializing engine; 09:14:13.567 INFO PrintReadsSpark - Done initializing engine; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@6d21714c] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@6ee12bac].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@6d21714c] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@6ee12bac].; log4j:ERROR Could not instantiate appender named ""console"".; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; log4j:WARN No appenders could be found for logger (org.apache.spark.SparkContext).; log4j:WARN Please initialize the log4j system properly.; log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.; 09:14:26.202 INFO PrintReadsSpark - Shutting d",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3066:3109,ERROR,ERROR,3109,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3066,1,['ERROR'],['ERROR']
Availability,"7.554 INFO GenomicsDBImport - Callset Map JSON file will be written to CDL-164-04P-1_0_249250621_genomicsdb/callset.json; 10:24:57.554 INFO GenomicsDBImport - Complete VCF Header will be written to CDL-164-04P-1_0_249250621_genomicsdb/vcfheader.vcf; 10:24:57.554 INFO GenomicsDBImport - Importing to array - CDL-164-04P-1_0_249250621_genomicsdb/genomicsdb_array; 10:24:57.554 INFO ProgressMeter - Starting traversal; 10:24:57.554 INFO ProgressMeter - Current Locus Elapsed Minutes Batches Processed Batches/Minute; 10:24:57.971 INFO GenomicsDBImport - Importing batch 1 with 1 samples; Buffer resized from 22726bytes to 32529; Buffer resized from 32529bytes to 32693; Buffer resized from 32693bytes to 32738; Buffer resized from 32738bytes to 32741; Buffer resized from 32741bytes to 32756; Buffer resized from 32756bytes to 32768; Buffer resized from 32768bytes to 32769; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x00007f7288295359, pid=68672, tid=0x00007f72dc187700; #; # JRE version: OpenJDK Runtime Environment (8.0_171-b10) (build 1.8.0_171-b10); # Java VM: OpenJDK 64-Bit Server VM (25.171-b10 mixed mode linux-amd64 compressed oops); # Problematic frame:; # C [libtiledbgenomicsdb8064358042335455262.so+0x155359] BufferVariantCell::set_cell(void const*)+0x99; #; # Core dump written. Default location: /mnt/isilon/cbmi/variome/rathik/mendelian_rnaseq/gatk_output/CDL-164-04P/core or core.68672; #; # An error report file with more information is saved as:; # /mnt/isilon/cbmi/variome/rathik/mendelian_rnaseq/gatk_output/CDL-164-04P/hs_err_pid68672.log; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; # The crash happened outside the Java Virtual Machine in native code.; # See problematic frame for where to report the bug.; #. ```. And here is the `hs_err_pid68672.log` file: ; [hs_err_pid68672.log](https://github.com/broadinstitute/gatk/files/2219689/hs_err_pid68672.log)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5045:11348,error,error,11348,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5045,1,['error'],['error']
Availability,70 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.project.DefaultProject.evaluate(DefaultProject.java:573); 22:05:55.971 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.project.DefaultProject.evaluate(DefaultProject.java:125); 22:05:55.971 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.TaskPathProjectEvaluator.configureHierarchy(TaskPathProjectEvaluator.java:42); 22:05:55.971 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.DefaultBuildConfigurer.configure(DefaultBuildConfigurer.java:38); 22:05:55.971 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.initialization.DefaultGradleLauncher$2.run(DefaultGradleLauncher.java:151); 22:05:55.971 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.Factories$1.create(Factories.java:22); 22:05:55.971 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:91); 22:05:55.971 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:53); 22:05:55.972 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.initialization.DefaultGradleLauncher.doBuildStages(DefaultGradleLauncher.java:148); 22:05:55.972 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.initialization.DefaultGradleLauncher.access$200(DefaultGradleLauncher.java:33); 22:05:55.973 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.initialization.DefaultGradleLauncher$1.create(DefaultGradleLauncher.java:112); 22:05:55.973 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.initialization.DefaultGradleLaunc,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4687:4487,ERROR,ERROR,4487,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4687,1,['ERROR'],['ERROR']
Availability,"709859-185537688(G* -> <DEL>): Variant overlaps transcript but is not completely contained ; within it. Funcotator cannot currently handle this case. Transcript: ENST00000378191.5 Variant: [VC Unknown @ chr1:4709859-185537688 Q. of type=SYMBOLIC alleles=[G*, <DEL>] attr={CIEND=[0, 4], CIPOS=[0, 4], END=185537688, HOML; EN=4, HOMSEQ=TCCT, SOMATIC=true, SOMATICSCORE=141, SVLEN=-180827829, SVTYPE=DEL} GT=PR:SR 68,0:94,0 38,23:94,24 filters=; 17:07:32.003 WARN GencodeFuncotationFactory - Creating default GencodeFuncotation on transcript ENST00000378191.5 for problem variant: chr1:4709859-185537688(G* -> <DEL>); 17:07:32.009 INFO VcfFuncotationFactory - ClinVar_VCF 20180429_hg38 cache hits/total: 0/0; 17:07:32.010 INFO VcfFuncotationFactory - dbSNP 9606_b151 cache hits/total: 0/0; 17:07:32.010 INFO VcfFuncotationFactory - gnomAD_exome 2.1 cache hits/total: 0/0; 17:07:32.010 INFO VcfFuncotationFactory - gnomAD_genome 2.1 cache hits/total: 0/0; 17:07:32.136 INFO Funcotator - Shutting down engine; [14 January 2021 17:07:32 GMT] org.broadinstitute.hellbender.tools.funcotator.Funcotator done. Elapsed time: 0.77 minutes.; Runtime.totalMemory()=1426182144; java.lang.ArrayIndexOutOfBoundsException: 0; at org.broadinstitute.hellbender.tools.funcotator.FuncotatorUtils.getNonOverlappingAltAlleleBaseString(FuncotatorUtils.java:294); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.getGenomeChangeString(GencodeFuncotationFactory.java:2346); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createGencodeFuncotationBuilderWithTrivialFieldsPopulated(GencodeFuncotationFactory.java:2214); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createDefaultFuncotationsOnProblemVariant(GencodeFuncotationFactory.java:923); [...]; ```. I've seen that FuncotateSegments works for segment files with CNVs, but I was wondering if there is (or there are plans to add) ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7040:1365,down,down,1365,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7040,1,['down'],['down']
Availability,"72a59dfab47a87afe4f3/funcotator_dataSources.v1.7.20200521g/lmm_known/hg38/LMM_Path_LP_VUS5-variants-6-12-18.sorted_liftover_b38.corrected.vcf; 14:24:34.617 INFO DataSourceUtils - Resolved data source file path: file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/acmg_lof.tsv -> file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/funcotator_dataSources.v1.7.20200521g/acmg_lof/hg38/acmg_lof.tsv; 14:24:35.311 INFO Funcotator - Shutting down engine; [October 29, 2020 2:24:35 PM UTC] org.broadinstitute.hellbender.tools.funcotator.Funcotator done. Elapsed time: 0.03 minutes.; Runtime.totalMemory()=2055733248; code: 400; message: 400 Bad Request; {; ""error"": ""invalid_grant"",; ""error_description"": ""Bad Request""; }; reason: null; location: null; retryable: false; com.google.cloud.storage.StorageException: 400 Bad Request; {; ""error"": ""invalid_grant"",; ""error_description"": ""Bad Request""; }; 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.translate(HttpStorageRpc.java:229); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.get(HttpStorageRpc.java:439); 	at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:244); 	at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:241); 	at shaded.cloud_nio.com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:105); 	at shaded.cloud_nio.com.google.cloud.RetryHelper.run(RetryHelper.java:76); 	at shaded.cloud_nio.com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:50); 	at com.google.cloud.storage.StorageImpl.get(StorageImpl.java:240); 	at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.checkAccess(CloudStorageFileSystemProvider.java:736); 	at java.nio.file.Files.exists(Files.java:2385); 	at org.broadinstitute.hellbender.tools.funcotator.dataSources.DataSourceUtils.assertPathFilePropertiesField(DataSourceUtil",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6926:7646,error,error,7646,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6926,1,['error'],['error']
Availability,78 INFO ProgressMeter - Starting traversal; 01:25:02.078 INFO ProgressMeter - Current Locus Elapsed Minutes Batches Processed Batches/Minute; [TileDB::FileSystem] Error: (write_to_file) Cannot write to file; File writing error; path=/lustre/scratch118/malaria/team112/personal/vr6/pf8-update/work/8e/c9ed494e9cd5d45835890fff4fa34c/Pf3D7_08_v3_33.bed.gdb/vidmap.json; errno=5(Input/output error); [TileDB::FileSystem] Error: (write_to_file) Cannot write to file; File writing error; path=/lustre/scratch118/malaria/team112/personal/vr6/pf8-update/work/8e/c9ed494e9cd5d45835890fff4fa34c/Pf3D7_08_v3_33.bed.gdb/vidmap.json; errno=5(Input/output error); 01:25:43.661 INFO GenomicsDBImport - Starting batch input file preload; 01:26:19.244 INFO GenomicsDBImport - Finished batch preload; 01:26:19.244 INFO GenomicsDBImport - Importing batch 1 with 2 samples; 01:30:20.226 INFO ProgressMeter - unmapped 5.3 1 0.2; 01:30:20.226 INFO GenomicsDBImport - Done importing batch 1/1; 01:30:20.227 INFO ProgressMeter - unmapped 5.3 1 0.2; 01:30:20.227 INFO ProgressMeter - Traversal complete. Processed 1 total batches in 5.3 minutes.; 01:30:20.227 INFO GenomicsDBImport - Import of all batches to GenomicsDB completed!; 01:30:20.227 INFO GenomicsDBImport - Shutting down engine; [10 December 2021 01:30:20 UTC] org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImport done. Elapsed time: 7.76 minutes.; Runtime.totalMemory()=16078340096; ```. #### Steps to reproduce. Not sure if it reproducible with any particular imput... it seems that one has to simulate the IO errors for example by using a nearly full storage for the output or create some read-only conflicting file s. #### Expected behavior. No low-level error messages as the ones above... and that the output can be use for genotype-gvcfs without issue . #### Actual behavior. Error messages coming from the jni dependency. The tool finishes succesfully in apperance but the output file is missing some content render it unusable for VCF calling.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7598:5192,down,down,5192,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7598,4,"['Error', 'down', 'error']","['Error', 'down', 'error', 'errors']"
Availability,"7:24:16.220 INFO ProgressMeter - NC_016854.1:138000 6.0 138000 23062.5; 07:24:29.116 INFO ProgressMeter - NC_016854.1:175000 6.2 175000 28231.8; 07:43:58.742 INFO GenotypeGVCFs - Shutting down engine; GENOMICSDB_TIMER,GenomicsDB iterator next() timer,Wall-clock time(s),29.644886145999088,Cpu time(s),29.480321756000397; Using GATK jar /opt/conda/envs/789546e2/share/gatk4-4.0.1.1-0/gatk-package-4.0.1.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -jar /opt/conda/envs/789546e2/share/gatk4-4.0.1.1-0/gatk-package-4.0.1.1-local.jar GenotypeGVCFs -ploidy 1 -R references/359488/genome_fasta.fasta --annotate-with-num-discovered-alleles true --annotations-to-exclude InbreedingCoeff -V gendb://typing/gatk_gvcfs/full_genome/359488/bwa/genomics_db -O typing/gatk_gvcfs/full_genome/359488/bwa/all_samples.vcf; ```; In between the last ProgressMeter and the Shutting down of the engine, I see the java process still running with top. Do you know what could be causing the problem ? Could it be related to -ERC BP_RESOLUTION ? I used to use -ERC GVCF before but I would rather keep the information of the coverage for post filtering, and I am not sure how to use --GVCFGQBands to match my criteria for coverage filtering. Thanks a lot for your help !. Edit: sorry with the latest version of gatk I get a new message error :; ```; 08:22:54.446 INFO ProgressMeter - NC_016854.1:20000 0.2 20000 87450.8; 08:23:04.942 INFO ProgressMeter - NC_016854.1:58000 0.4 58000 143694.8; 08:25:25.155 INFO ProgressMeter - NC_016854.1:82000 2.7 82000 29921.4; 08:25:35.161 INFO ProgressMeter - NC_016854.1:100000 2.9 100000 34396.6; 08:28:02.395 INFO ProgressMeter - NC_016854.1:102000 5.4 102000 19025.7; 08:28:13.248 INFO ProgressMeter - NC_016854.1:140000 5.5 140000 25261.3; 08:28:24.027 INFO ProgressMeter - NC_016854.1:175000 5.7 175000 30585.2; 08:46:13.574 INFO GenotypeGVCFs - S",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4467:1690,down,down,1690,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4467,1,['down'],['down']
Availability,"7:30.677 INFO GenomicsDBImport - Vid Map JSON file will be written to genomicsdb/vidmap.json; 04:37:30.677 INFO GenomicsDBImport - Callset Map JSON file will be written to genomicsdb/callset.json; 04:37:30.677 INFO GenomicsDBImport - Complete VCF Header will be written to genomicsdb/vcfheader.vcf; 04:37:30.678 INFO GenomicsDBImport - Importing to array - genomicsdb/genomicsdb_array; 04:37:30.680 INFO ProgressMeter - Starting traversal; 04:37:30.680 INFO ProgressMeter - Current Locus Elapsed Minutes Batches Processed Batches/Minute; 04:37:33.253 INFO GenomicsDBImport - Starting batch input file preload; 04:37:35.079 INFO GenomicsDBImport - Finished batch preload; 04:37:35.079 INFO GenomicsDBImport - Importing batch 1 with 50 samples; 04:37:37.079 INFO GenomicsDBImport - Starting batch input file preload; 04:37:38.712 INFO GenomicsDBImport - Finished batch preload; 04:37:38.712 INFO GenomicsDBImport - Importing batch 1 with 50 samples; 04:37:39.162 INFO GenomicsDBImport - Shutting down engine; [October 8, 2018 4:37:39 AM UTC] org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImport done. Elapsed time: 0.17 minutes.; Runtime.totalMemory()=4116185088; java.util.concurrent.CompletionException: org.broadinstitute.hellbender.exceptions.GATKException: Cannot call query with different interval, expected:1:29867-31003 queried with: 1:68590-70510; at java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:273); at java.util.concurrent.CompletableFuture.completeThrowable(CompletableFuture.java:280); at java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1592); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); at java.lang.Thread.run(Thread.java:748); Caused by: org.broadinstitute.hellbender.exceptions.GATKException: Cannot call query with different interval, expected:1:29867-31003 queried with: 1:68590-70510;",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5300:3966,down,down,3966,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5300,1,['down'],['down']
Availability,"7;ExcessHet=3.0103;MLEAC=0,1,0;MLEAF=0.00,0.500,0.00;MQRankSum=0.000;RAW_MQandDP=2869200,797;ReadPosRankSum=0.386	GT:AD:DP:GQ:PL:SB	0/2:413,2,357,0:772:99:14840,11462,50871,0,41338,45112,14111,52486,44158,56658:203,210,177,182; chr13	32944609	.	T	A,*,TAAAA,<NON_REF>	0	.	BaseQRankSum=4.278;DP=787;ExcessHet=3.0103;MLEAC=0,1,0,0;MLEAF=0.00,0.500,0.00,0.00;MQRankSum=0.000;RAW_MQandDP=2833200,787;ReadPosRankSum=0.252	GT:AD:DP:GQ:PL:SB	0/2:411,2,357,0,0:770:99:14840,11462,50871,0,41338,45112,17297,53328,47568,2147483647,16108,52933,46273,64838,62381:201,210,177,182; chr13	32944610	.	T	<NON_REF>	.	.	END=32944794	GT:DP:GQ:MIN_DP:PL	0/0:627:99:265:0,120,1800; ```. #### Steps to reproduce; * init; ```; hg19=pipeline/hg19/hg19_chM_male_mask.fa; ```; * reproduce of 4.0.8.1; ```; github.com/broadinstitute/gatk/releases/download/4.0.8.1/gatk-4.0.8.1/gatk HaplotypeCaller -R $hg19 -I target.1k.bam -L target.bed -O target.4.0.8.1.gvcf -ERC GVCF && tail target.4.0.8.1.gvcf; github.com/broadinstitute/gatk/releases/download/4.0.8.1/gatk-4.0.8.1/gatk HaplotypeCaller -R $hg19 -I target.1k.bam -L target.bed -O target.4.0.8.1.vcf && tail target.4.0.8.1.vcf; ```; * reproduce of 4.0.9.0; ```; github.com/broadinstitute/gatk/releases/download/4.0.9.0/gatk-4.0.9.0/gatk HaplotypeCaller -R $hg19 -I target.1k.bam -L target.bed -O target.4.0.9.0.gvcf -ERC GVCF && tail target.4.0.9.0.gvcf; github.com/broadinstitute/gatk/releases/download/4.0.9.0/gatk-4.0.9.0/gatk HaplotypeCaller -R $hg19 -I target.1k.bam -L target.bed -O target.4.0.9.0.vcf && tail target.4.0.9.0.vcf; ```; * reproduce of 4.1.2.0; ```; github.com/broadinstitute/gatk/releases/download/4.1.2.0/gatk-4.1.2.0/gatk HaplotypeCaller -R $hg19 -I target.1k.bam -L target.bed -O target.4.1.2.0.gvcf -ERC GVCF && tail target.4.1.2.0.gvcf; github.com/broadinstitute/gatk/releases/download/4.1.2.0/gatk-4.1.2.0/gatk HaplotypeCaller -R $hg19 -I target.1k.bam -L target.bed -O target.4.1.2.0.vcf && tail target.4.1.2.0.vcf; ```. #### Expected behavior; 1. ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5975:6143,down,download,6143,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5975,1,['down'],['download']
Availability,"7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/__book_keeping.tdb.gz; errno=122(Disk quota e; xceeded); [TileDB::utils] Error: (write_to_file_after_compression) Could not write compressed bytes to internal buffer; path=/storage/home/data/gendb/chr13/chr13$32310639$32310731/.__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/__book_keeping.tdb.gz; ; errno=122(Disk quota exceeded); [TileDB::BookKeeping] Error: Cannot finalize book-keeping; Failure to write to file /storage/home/data/gendb/chr13/chr13$32310639$32310731/.__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/__book_keeping.tdb.gz.; [TileDB::FileSystem] Error: (create_file) Failed to create file; path=/storage/home/data/gendb/chr13/chr13$32310639$32310731/__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/__tiledb_fragment.tdb; errno=122(Disk quota exceeded); [TileDB::utils] Error: (create_fragment_file) Failed to create fragment file; path=/storage/home/data/gendb/chr13/chr13$32310639$32310731/__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087; errno=122(Disk quota exceeded); 11:23:52.390 erro NativeGenomicsDB - pid=57964 tid=57984 VariantStorageManagerException exception : Error while finalizing TileDB array chr13$32310639$32310731; TileDB error message : [TileDB::WriteState] Error: Cannot write segment to file; [TileDB::FileSystem] Error: (write_to_file) Cannot write to file; File opening error; path=/storage/home/data/gendb/chr13/chr13$32310639$32310731/.__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/RAW_MQandDP.tdb; errno=122(Disk quota exceede; d); #### Steps to reproduce; Below code ran on a cluster; ```; gatk --java-options ""-Xmx100g -Xms100g"" GenomicsDBImport \; -V sample1.g.vcf.gz -V sample2.g.vcf.gz -V sample3.g.vcf.gz -V sample4.g.vcf.gz \; -L chr13.bed \; --genomicsdb-workspace-path /storage/home/data/gendb/chr13\; --tmp-dir /storage/home/scratch/tmp; ```. #### Expected behavior; Over 1TB of scr",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6950:1574,Error,Error,1574,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6950,1,['Error'],['Error']
Availability,"8); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); at org.apache.spark.scheduler.Task.run(Task.scala:86); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748); Caused by: java.lang.NullPointerException; at org.apache.spark.MapOutputTracker.askTracker(MapOutputTracker.scala:100); ... 24 more; 05:12:04.045 INFO HaplotypeCallerSpark - Shutting down engine; [May 18, 2017 5:12:04 AM UTC] org.broadinstitute.hellbender.tools.HaplotypeCallerSpark done. Elapsed time: 131.63 minutes.; Runtime.totalMemory()=16201547776; org.apache.spark.SparkException: Job aborted due to stage failure: Task 8 in stage 1.0 failed 1 times, most recent failure: Lost task 8.0 in stage 1.0 (TID 345, localhost): java.lang.ArrayI; ndexOutOfBoundsException: 16777215; at com.esotericsoftware.kryo.util.IdentityObjectIntMap.clear(IdentityObjectIntMap.java:382); at com.esotericsoftware.kryo.util.MapReferenceResolver.reset(MapReferenceResolver.java:65); at com.esotericsoftware.kryo.Kryo.reset(Kryo.java:865); at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:630); at org.apache.spark.serializer.KryoSerializerInstance.serialize(KryoSerializer.scala:297); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:313); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); at org.apache.spark.scheduler.DAGSchedul",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3019:6422,failure,failure,6422,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3019,1,['failure'],['failure']
Availability,84 isActive: false numReads: 0; 12:05:51.476 DEBUG Mutect2 - Processing assembly region at chrM:10785-11084 isActive: false numReads: 0; 12:05:51.489 DEBUG Mutect2 - Processing assembly region at chrM:11085-11384 isActive: false numReads: 0; 12:05:51.501 DEBUG Mutect2 - Processing assembly region at chrM:11385-11684 isActive: false numReads: 0; 12:05:51.513 DEBUG Mutect2 - Processing assembly region at chrM:11685-11984 isActive: false numReads: 0; 12:05:51.526 DEBUG Mutect2 - Processing assembly region at chrM:11985-12284 isActive: false numReads: 0; 12:06:02.022 DEBUG Mutect2 - Processing assembly region at chrM:12285-12584 isActive: false numReads: 0; 12:06:03.941 DEBUG Mutect2 - Processing assembly region at chrM:12585-12729 isActive: false numReads: 44205; 12:06:04.330 DEBUG Mutect2 - Processing assembly region at chrM:12730-13020 isActive: true numReads: 88386; 12:06:10.995 DEBUG ReadThreadingGraph - Recovered 11 of 15 dangling tails; 12:06:11.087 DEBUG ReadThreadingGraph - Recovered 7 of 36 dangling heads; 12:06:11.465 DEBUG Mutect2Engine - Active Region chrM:12730-13020; 12:06:11.470 DEBUG Mutect2Engine - Extended Act Region chrM:12630-13120; 12:06:11.474 DEBUG Mutect2Engine - Ref haplotype coords chrM:12630-13120; 12:06:11.478 DEBUG Mutect2Engine - Haplotype count 128; 12:06:11.481 DEBUG Mutect2Engine - Kmer sizes count 0; 12:06:11.485 DEBUG Mutect2Engine - Kmer sizes values []; 12:08:48.420 DEBUG Mutect2 - Processing assembly region at chrM:13021-13320 isActive: false numReads: 44155; 12:08:49.628 INFO ProgressMeter - chrM:13021 33.1 50 1.5; 12:09:01.241 DEBUG Mutect2 - Processing assembly region at chrM:13321-13620 isActive: false numReads: 55070; 12:09:01.757 DEBUG Mutect2 - Processing assembly region at chrM:13621-13636 isActive: false numReads: 55240; 12:09:02.341 DEBUG Mutect2 - Processing assembly region at chrM:13637-13936 isActive: true numReads: 110273; 12:09:09.957 DEBUG ReadThreadingGraph - Recovered 24 of 26 dangling tails; 12:09:10.041 DEBUG Re,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7281:19178,Recover,Recovered,19178,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7281,1,['Recover'],['Recovered']
Availability,"864+29181309; 21/04/13 07:32:24 INFO FileOutputCommitter: Saved output of task 'attempt_20210413073224_0026_r_000001_0' to file:/dev/shm/chr4_GL000008v2_random.g.vcf.gz.parts; 21/04/13 07:32:24 INFO SparkHadoopMapRedUtil: attempt_20210413073224_0026_r_000001_0: Committed; 21/04/13 07:32:24 INFO Executor: Finished task 1.0 in stage 5.0 (TID 106). 762 bytes result sent to driver; 21/04/13 07:32:24 INFO TaskSetManager: Finished task 1.0 in stage 5.0 (TID 106) in 136 ms on localhost (executor driver) (1/3); 21/04/13 07:32:24 INFO FileOutputCommitter: File Output Committer Algorithm version is 2; 21/04/13 07:32:24 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false; 21/04/13 07:32:24 INFO FileOutputCommitter: File Output Committer Algorithm version is 2; 21/04/13 07:32:24 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false; 21/04/13 07:32:24 INFO FileOutputCommitter: File Output Committer Algorithm version is 2; 21/04/13 07:32:24 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false; 21/04/13 07:32:24 INFO FileOutputCommitter: File Output Committer Algorithm version is 2; 21/04/13 07:32:24 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false; 21/04/13 07:32:24 ERROR Utils: Aborting task; java.lang.IllegalArgumentException: Sequence [VC HC @ chr4_GL000008v2_random:7168-7691 Q. of type=SYMBOLIC alleles=[T*, <NON_REF>] attr={END=7691} GT=[[NA12878 T*/T* GQ 0 DP 0 PL 0,0,0 {MIN_DP=0}]] filters= added out of order currentReferenceIndex: 25, referenceIndex:37; at htsjdk.tribble.index.tabix.AllRefsTabixIndexCreator.addFeature(AllRefsTabixIndexCreator.java:79); at htsjdk.variant.variantcontext.writer.IndexingVariantContextWriter.add(Indexing",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7199:2474,failure,failures,2474,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7199,5,"['ERROR', 'failure']","['ERROR', 'failures']"
Availability,"89); - Pinned typing_extensions python package to 4.1.1 to fix conda environment. (#7802); - WeightedSplitInterval fixes [VS-384] [VS-332] (#7795); - Replace Travis with GithubActions (#7754); - Docker build only lfs pulls main/src/resources/large (#7727); - Clean up gatk jars -- looks like we are not passing them properly in the extract (#7788); - Fix typo that broke git lfs pull (#7806); - Document AoU SOP (up to the VAT) [VS-63] (#7807); - Incident VS 365 clinvar classification fix (#7769); - VS-390. Add precision and sensitivity wdl (#7813); - Quickstart based integration test [VS-357] (#7812); - 365 vat python testing additions (#7756); - VS 396 clinvar grabs too many values (#7823); - Added a test to validate WDLs in the scripts directory. (#7826) (#7829); - VAT Performance / Reliability Improvements (#7828); - VAT naming conventions [VS-410] (#7827); - Rc remove ad from vat (#7832); - bugfix, we were trying to grep a binary file (#7837); - Cleanup scripts/variantstore [VS-414] (#7834); - Merge VAT TSV files into single bgzipped file [VS-304] (#7848); - Handle fully and partially loaded samples [VS-262] [VS-258] (#7843); - Ingest Error Handling Fixes [VS-261] (#7841); - First cut at a python notebook to validate inputs. (#7845); - Compute filter scatter [VS-392] (#7852); - remove withdrawn req (#7844); - Improve import error message [VS-437] (#7855); - Fix Input Validation python notebook (#7853); - Add VAT Validation check that aa_change and exon_number are consistently set. (#7850); - Ingest 10K [VS-344] (#7860); - X/Y chromosome reweighting for better extract shard runtime balance [VS-389] (#7868); - VET Ingest Validation / Allow Ingest of non-VQSR'ed data (#7870); - Fix AoU workflow bugs (#7874); - Curate input arrays to skip already ingested sample data [VS-246] (#7862); - KM upload GVS product sheet (#7883); - Default extract scatter width [VS-415] (#7878); - Volatile tasks review [VS-447] (#7880); - Update Quickstart Integration for X/Y scaling changes ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8248:24019,Reliab,Reliability,24019,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8248,4,"['Error', 'Reliab']","['Error', 'Reliability']"
Availability,"8:30:55 INFO util.log: Logging initialized @25356ms; 18/01/09 18:30:55 INFO server.Server: jetty-9.3.z-SNAPSHOT; 18/01/09 18:30:55 INFO server.Server: Started @25495ms; 18/01/09 18:30:55 INFO server.AbstractConnector: Started ServerConnector@283ab206{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 18/01/09 18:30:55 INFO util.Utils: Successfully started service 'SparkUI' on port 4040.; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@418f0534{/jobs,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@134a8ead{/jobs/json,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@54247647{/jobs/job,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5463f035{/jobs/job/json,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@44fd7ba4{/stages,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@69d103f0{/stages/json,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@74fb5b59{/stages/stage,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@26fadd98{/stages/stage/json,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@3db6dd52{/stages/pool,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6ef4cbe1{/stages/pool/json,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2baac4a7{/storage,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6bce4140{/storage/json,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4112:7683,AVAIL,AVAILABLE,7683,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4112,1,['AVAIL'],['AVAILABLE']
Availability,"9 18:30:55 INFO storage.BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up; 18/01/09 18:30:55 INFO storage.DiskBlockManager: Created local directory at /tmp/sun/blockmgr-b03058dc-763a-449c-bd05-18f3304c01ea; 18/01/09 18:30:55 INFO memory.MemoryStore: MemoryStore started with capacity 2004.6 MB; 18/01/09 18:30:55 INFO spark.SparkEnv: Registering OutputCommitCoordinator; 18/01/09 18:30:55 INFO util.log: Logging initialized @25356ms; 18/01/09 18:30:55 INFO server.Server: jetty-9.3.z-SNAPSHOT; 18/01/09 18:30:55 INFO server.Server: Started @25495ms; 18/01/09 18:30:55 INFO server.AbstractConnector: Started ServerConnector@283ab206{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 18/01/09 18:30:55 INFO util.Utils: Successfully started service 'SparkUI' on port 4040.; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@418f0534{/jobs,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@134a8ead{/jobs/json,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@54247647{/jobs/job,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5463f035{/jobs/job/json,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@44fd7ba4{/stages,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@69d103f0{/stages/json,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@74fb5b59{/stages/stage,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@26fadd98{/stages/stage/json,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@3db6dd52{/stages/pool,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.Se",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4112:7296,AVAIL,AVAILABLE,7296,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4112,1,['AVAIL'],['AVAILABLE']
Availability,"9 Jul 2022 14:35:24,720 DEBUG: 		at org.broadinstitute.hellbender.engine.VariantLocusWalker.lambda$null$1(VariantLocusWalker.java:161); 09 Jul 2022 14:35:24,726 DEBUG: 		at java.util.Iterator.forEachRemaining(Iterator.java:116); 09 Jul 2022 14:35:24,731 DEBUG: 		at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 09 Jul 2022 14:35:24,738 DEBUG: 		at java.util.stream.ReferencePipeline$Head.forEachOrdered(ReferencePipeline.java:590); 09 Jul 2022 14:35:24,743 DEBUG: 		at org.broadinstitute.hellbender.engine.VariantLocusWalker.lambda$traverse$2(VariantLocusWalker.java:151); 09 Jul 2022 14:35:24,749 DEBUG: 		at java.util.Iterator.forEachRemaining(Iterator.java:116); 09 Jul 2022 14:35:24,755 DEBUG: 		at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 09 Jul 2022 14:35:24,761 DEBUG: 		at java.util.stream.ReferencePipeline$Head.forEachOrdered(ReferencePipeline.java:590); 09 Jul 2022 14:35:24,767 DEBUG: 		at org.broadinstitute.hellbender.engine.VariantLocusWalker.traverse(VariantLocusWalker.java:148); 09 Jul 2022 14:35:24,773 DEBUG: 		at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1085); 09 Jul 2022 14:35:24,780 DEBUG: 		at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); 09 Jul 2022 14:35:24,786 DEBUG: 		at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); 09 Jul 2022 14:35:24,792 DEBUG: 		at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); 09 Jul 2022 14:35:24,798 DEBUG: 		at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); 09 Jul 2022 14:35:24,804 DEBUG: 		at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); 09 Jul 2022 14:35:24,813 DEBUG: 		at org.broadinstitute.hellbender.Main.main(Main.java:289); ```. I thought this was fixed in the prior version. Is this a new error or a regression?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7933:4330,error,error,4330,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7933,1,['error'],['error']
Availability,"9); at htsjdk.variant.variantcontext.writer.IndexingVariantContextWriter.add(IndexingVariantContextWriter.java:203); at htsjdk.variant.variantcontext.writer.VCFWriter.add(VCFWriter.java:242); at org.disq_bio.disq.impl.formats.vcf.HeaderlessVcfOutputFormat$VcfRecordWriter.write(HeaderlessVcfOutputFormat.java:93); at org.disq_bio.disq.impl.formats.vcf.HeaderlessVcfOutputFormat$VcfRecordWriter.write(HeaderlessVcfOutputFormat.java:56); at org.apache.spark.internal.io.HadoopMapReduceWriteConfigUtil.write(SparkHadoopWriter.scala:358); at org.apache.spark.internal.io.SparkHadoopWriter$$anonfun$4.apply(SparkHadoopWriter.scala:132); at org.apache.spark.internal.io.SparkHadoopWriter$$anonfun$4.apply(SparkHadoopWriter.scala:129); at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1394); at org.apache.spark.internal.io.SparkHadoopWriter$.org$apache$spark$internal$io$SparkHadoopWriter$$executeTask(SparkHadoopWriter.scala:141); ... 10 more. 21/04/13 07:32:25 ERROR TaskSetManager: Task 0 in stage 5.0 failed 1 times; aborting job; 21/04/13 07:32:25 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool; 21/04/13 07:32:25 INFO TaskSchedulerImpl: Cancelling stage 5; 21/04/13 07:32:25 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage cancelled; 21/04/13 07:32:25 INFO DAGScheduler: ResultStage 5 (runJob at SparkHadoopWriter.scala:78) failed in 0.353 s due to Job aborted due to stage failure: Task 0 in stage 5.0 failed 1 times, most recent failure: Lost task 0.0 in stage 5.0 (TID 105, localhost, executor driver): org.apache.spark.SparkException: Task failed while writing rows; at org.apache.spark.internal.io.SparkHadoopWriter$.org$apache$spark$internal$io$SparkHadoopWriter$$executeTask(SparkHadoopWriter.scala:157); at org.apache.spark.internal.io.SparkHadoopWriter$$anonfun$3.apply(SparkHadoopWriter.scala:83); at org.apache.spark.internal.io.SparkHadoopWriter$$anonfun$3.apply(SparkHadoopWriter.scala:78); at o",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7199:10803,ERROR,ERROR,10803,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7199,1,['ERROR'],['ERROR']
Availability,"9.8             114664000        5778139.5; 06:46:23.072 INFO  ProgressMeter - NC_038255.2:25849821             20.0             115712000        5782366.7; 06:46:33.076 INFO  ProgressMeter - NC_038255.2:26067132             20.2             116682000        5782658.4; 06:46:43.076 INFO  ProgressMeter - NC_038255.2:26257373             20.3             117691000        5784881.3; 06:46:53.083 INFO  ProgressMeter - NC_038255.2:26457381             20.5             118693000        5786693.9; 06:47:03.088 INFO  ProgressMeter - NC_038255.2:26643575             20.7             119720000        5789695.5; 06:47:13.106 INFO  ProgressMeter - NC_038255.2:26850339             20.8             120726000        5791581.5; 06:47:23.111 INFO  ProgressMeter - NC_038255.2:27050560             21.0             121742000        5793973.2; 06:47:33.116 INFO  ProgressMeter - NC_038255.2:27256247             21.2             122736000        5795288.5; 06:47:42.432 INFO  CombineGVCFs - Shutting down engine; [March 13, 2024 at 6:47:42 AM GMT] org.broadinstitute.hellbender.tools.walkers.CombineGVCFs done. Elapsed time: 21.46 minutes.; Runtime.totalMemory()=920649728; htsjdk.samtools.util.RuntimeIOException: java.io.IOException: Transport endpoint is not connected; at htsjdk.tribble.readers.TabixIteratorLineReader.readLine(TabixIteratorLineReader.java:48); at htsjdk.tribble.TabixFeatureReader$FeatureIterator.readNextRecord(TabixFeatureReader.java:170); at htsjdk.tribble.TabixFeatureReader$FeatureIterator.next(TabixFeatureReader.java:205); at htsjdk.tribble.TabixFeatureReader$FeatureIterator.next(TabixFeatureReader.java:149); at org.broadinstitute.hellbender.engine.FeatureIntervalIterator.loadNextFeature(FeatureIntervalIterator.java:98); at org.broadinstitute.hellbender.engine.FeatureIntervalIterator.loadNextNovelFeature(FeatureIntervalIterator.java:74); at org.broadinstitute.hellbender.engine.FeatureIntervalIterator.next(FeatureIntervalIterator.java:62); at org.broadinstitute.hellbender.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8735:21979,down,down,21979,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8735,1,['down'],['down']
Availability,"9238 s; 17/10/11 14:19:38 INFO ui.SparkUI: Stopped Spark web UI at http://10.131.101.159:4040; 17/10/11 14:19:38 INFO cluster.YarnClientSchedulerBackend: Interrupting monitor thread; 17/10/11 14:19:38 INFO cluster.YarnClientSchedulerBackend: Shutting down all executors; 17/10/11 14:19:38 INFO cluster.YarnClientSchedulerBackend: Asking each executor to shut down; 17/10/11 14:19:38 INFO cluster.YarnClientSchedulerBackend: Stopped; 17/10/11 14:19:38 INFO spark.MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 17/10/11 14:19:38 INFO storage.MemoryStore: MemoryStore cleared; 17/10/11 14:19:38 INFO storage.BlockManager: BlockManager stopped; 17/10/11 14:19:38 INFO storage.BlockManagerMaster: BlockManagerMaster stopped; 17/10/11 14:19:38 INFO scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 17/10/11 14:19:38 INFO spark.SparkContext: Successfully stopped SparkContext; 14:19:38.600 INFO PrintReadsSpark - Shutting down engine; [October 11, 2017 2:19:38 PM CST] org.broadinstitute.hellbender.tools.spark.pipelines.PrintReadsSpark done. Elapsed time: 0.48 minutes.; Runtime.totalMemory()=986185728; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 1.0 failed 4 times, most recent failure: Lost task 0.3 in stage 1.0 (TID 4, com2, executor 2): ExecutorLostFailure (executor 2 exited caused by one of the running tasks) Reason: Container marked as failed: container_1507683879816_0006_01_000003 on host: com2. Exit status: 50. Diagnostics: Exception from container-launch.; Container id: container_1507683879816_0006_01_000003; Exit code: 50; Stack trace: ExitCodeException exitCode=50: ; 	at org.apache.hadoop.util.Shell.runCommand(Shell.java:601); 	at org.apache.hadoop.util.Shell.run(Shell.java:504); 	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:786); 	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecut",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686:31739,down,down,31739,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686,1,['down'],['down']
Availability,"92GB RAM. MarkDuplicatesSpark usually hangs and never finish (even after few days) with log as below:. ```; 11:26:29.511 INFO FileOutputCommitter - File Output Committer Algorithm version is 1; 11:26:29.511 INFO FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false; 11:26:29.512 INFO FileOutputCommitter - File Output Committer Algorithm version is 1; 11:26:29.512 INFO FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false; 11:26:30.738 INFO FileOutputCommitter - File Output Committer Algorithm version is 1; 11:26:30.738 INFO FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false; 11:26:30.738 INFO FileOutputCommitter - File Output Committer Algorithm version is 1; 11:26:30.738 INFO FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false; 11:26:45.830 INFO FileOutputCommitter - File Output Committer Algorithm version is 1; 11:26:45.830 INFO FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false; 11:26:45.831 INFO FileOutputCommitter - File Output Committer Algorithm version is 1; 11:26:45.831 INFO FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false; 11:26:55.475 INFO FileOutputCommitter - File Output Committer Algorithm version is 1; 11:26:55.475 INFO FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false; 11:26:55.475 INFO FileOutputCommitter - File Output Committer Algorithm version is 1; 11:26:55.475 INFO FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, igno",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8555:1329,failure,failures,1329,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8555,1,['failure'],['failures']
Availability,"931-Combine-GVCF-generate-java-lang-NullPointerException. Command:; time ""$gatk"" CombineGVCFs \; -G StandardAnnotation \; -G AS_StandardAnnotation \; -R ""$ref_gen""/ucsc.hg19.fasta \; -V /paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/A200272.HC.g.vcf.gz \; -V /paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/A200273.HC.g.vcf.gz \; -V /paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/A200274.HC.g.vcf.gz \; -V /paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/A200313.HC.g.vcf.gz \; -V /paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/A200314.HC.g.vcf.gz \; -V /paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/A200315.HC.g.vcf.gz \; -V /paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/PID20-006.HC.g.vcf.gz \; -V /paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/PID20-007.HC.g.vcf.gz \; -V /paedwy/disk1/yangyxt/wes/backup_gvcfs/all_wes_samples.g.vcf \; -O /paedwy/disk1/yangyxt/wes/backup_gvcfs/all_wes_samples_plus_${sample_batch}.g.vcf.gz && echo ""Combine_gvcfs done"". Error Log:; ```; 12:01:36.798 WARN GATKAnnotationPluginDescriptor - Redundant enabled annotation group (StandardAnnotation) is enabled for this tool by default; 12:01:36.824 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/yangyxt/software/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Aug 24, 2020 12:01:37 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 12:01:37.108 INFO CombineGVCFs - ------------------------------------------------------------; 12:01:37.108 INFO CombineGVCFs - The Genome Analysis Toolkit (GATK) v4.1.8.1; 12:01:37.108 INFO CombineGVCFs - For support and documentation go to https://software.broadinstitute.org/gatk/; 12:01:37.108 INFO CombineGVCFs - Executing as yangyxt@paedyl01 on Linux v3.10.0-1062.18.1.el7.x86_64 amd64; 12:01:37.108 INFO CombineGVCFs - Java runtime: Java HotSpot(TM) 64-Bit Serve",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6766:1502,Error,Error,1502,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6766,1,['Error'],['Error']
Availability,"933:HG2MVDSX5:1:1101:1045:5306 A00257:933:HG2MVDSX5:1:1101:1045:5306; A00257:933:HG2MVDSX5:1:1101:1045:5306 A00257:933:HG2MVDSX5:1:1101:1045:6277; A00257:933:HG2MVDSX5:1:1101:1045:6277 A00257:933:HG2MVDSX5:1:1101:1045:7717; A00257:933:HG2MVDSX5:1:1101:1045:6277 A00257:933:HG2MVDSX5:1:1101:1045:8375; A00257:933:HG2MVDSX5:1:1101:1045:7717 A00257:933:HG2MVDSX5:1:1101:1045:8531; A00257:933:HG2MVDSX5:1:1101:1045:7717 A00257:933:HG2MVDSX5:1:1101:1045:9283; A00257:933:HG2MVDSX5:1:1101:1045:8531 A00257:933:HG2MVDSX5:1:1101:1045:10316; A00257:933:HG2MVDSX5:1:1101:1045:8531 A00257:933:HG2MVDSX5:1:1101:1045:11130; A00257:933:HG2MVDSX5:1:1101:1045:11130 A00257:933:HG2MVDSX5:1:1101:1045:11882; A00257:933:HG2MVDSX5:1:1101:1045:11130 A00257:933:HG2MVDSX5:1:1101:1045:12007; A00257:933:HG2MVDSX5:1:1101:1045:12007 A00257:933:HG2MVDSX5:1:1101:1045:12665; A00257:933:HG2MVDSX5:1:1101:1045:12007 A00257:933:HG2MVDSX5:1:1101:1045:12727; A00257:933:HG2MVDSX5:1:1101:1045:12665 A00257:933:HG2MVDSX5:1:1101:1045:13260; A00257:933:HG2MVDSX5:1:1101:1045:12665 A00257:933:HG2MVDSX5:1:1101:1045:13322; ```. The error above makes sense since the lexicographic difference between `A00257:933:HG2MVDSX5:1:1101:1045:11130` and `A00257:933:HG2MVDSX5:1:1101:1045:8531` is `-7`, the result of `ord(""1"") - ord(""8"")`. #### Expected behavior; The `traverse` function above should keep advancing through the uBAM. Assuming the BAMs to be queryname sorted, the `traverse` function could check the lengths of the names when the `diff` is not zero in https://github.com/broadinstitute/gatk/blob/2b0a558fdb9fdf654e796d5d69a092e26345583b/src/main/java/org/broadinstitute/hellbender/tools/walkers/qc/TransferReadTags.java#L121, advancing the `unmappedSamIterator` if the name of the `currentTargetRead` is larger than the name of `currentUnmappedRead`. . #### Actual behavior; An `java.lang.IllegalStateException: A read found in the aligned bam is not found in the unmapped bam.` exception is raised when in fact the read might exist",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8147:7960,error,error,7960,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8147,1,['error'],['error']
Availability,97 DEBUG ReadThreadingGraph - Recovered 7 of 8 dangling tails; 11:41:57.047 DEBUG ReadThreadingGraph - Recovered 2 of 24 dangling heads; 11:41:57.286 DEBUG IntToDoubleFunctionCache - cache miss 136737 > 53234 expanding to 136747; 11:41:57.301 DEBUG IntToDoubleFunctionCache - cache miss 136976 > 136747 expanding to 273496; 11:41:57.935 DEBUG Mutect2Engine - Active Region chrM:8830-9129; 11:41:57.937 DEBUG Mutect2Engine - Extended Act Region chrM:8730-9229; 11:41:57.939 DEBUG Mutect2Engine - Ref haplotype coords chrM:8730-9229; 11:41:57.940 DEBUG Mutect2Engine - Haplotype count 128; 11:41:57.941 DEBUG Mutect2Engine - Kmer sizes count 0; 11:41:57.942 DEBUG Mutect2Engine - Kmer sizes values []; 11:53:42.116 DEBUG Mutect2 - Processing assembly region at chrM:9130-9143 isActive: true numReads: 148251; 11:53:58.336 DEBUG ReadThreadingGraph - Recovered 4 of 9 dangling tails; 11:53:58.398 DEBUG ReadThreadingGraph - Recovered 0 of 20 dangling heads; 11:54:11.645 DEBUG ReadThreadingGraph - Recovered 20 of 23 dangling tails; 11:54:11.670 DEBUG ReadThreadingGraph - Recovered 0 of 60 dangling heads; 11:54:11.843 DEBUG Mutect2Engine - Active Region chrM:9130-9143; 11:54:11.852 DEBUG Mutect2Engine - Extended Act Region chrM:9030-9243; 11:54:11.861 DEBUG Mutect2Engine - Ref haplotype coords chrM:9030-9243; 11:54:11.870 DEBUG Mutect2Engine - Haplotype count 232; 11:54:11.879 DEBUG Mutect2Engine - Kmer sizes count 0; 11:54:11.889 DEBUG Mutect2Engine - Kmer sizes values []; 11:54:21.878 DEBUG IntToDoubleFunctionCache - cache miss 96632 > 95278 expanding to 190558; 11:54:22.252 DEBUG Mutect2 - Processing assembly region at chrM:9144-9301 isActive: false numReads: 273760; 11:54:28.421 DEBUG Mutect2 - Processing assembly region at chrM:9302-9584 isActive: true numReads: 250870; 11:55:47.246 DEBUG ReadThreadingGraph - Recovered 13 of 14 dangling tails; 11:55:47.346 DEBUG ReadThreadingGraph - Recovered 6 of 47 dangling heads; 11:55:47.787 DEBUG Mutect2Engine - Active Region chrM:9302-9584; 1,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7281:16419,Recover,Recovered,16419,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7281,1,['Recover'],['Recovered']
Availability,98); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:755); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:119); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: org.broadinstitute.hellbender.exceptions.UserException$CouldNotReadInputFile: Couldn't read file. Error was: hg19mini.hss with exception: hg19mini.hss (No such file or directory); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:112); at org.broadinstitute.hellbender.tools.spark.pathseq.PSKmerUtils.readKmerFilter(PSKmerUtils.java:131); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilter.<init>(ContainsKmerReadFilter.java:27); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:35); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:15); at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78); at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:463); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeS,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4699:43954,Error,Error,43954,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4699,1,['Error'],['Error']
Availability,"9:14:13.567 INFO PrintReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : false; 09:14:13.567 INFO PrintReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 09:14:13.567 INFO PrintReadsSpark - Deflater: IntelDeflater; 09:14:13.567 INFO PrintReadsSpark - Inflater: IntelInflater; 09:14:13.567 INFO PrintReadsSpark - Initializing engine; 09:14:13.567 INFO PrintReadsSpark - Done initializing engine; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@6d21714c] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@6ee12bac].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@6d21714c] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@6ee12bac].; log4j:ERROR Could not instantiate appender named ""console"".; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; log4j:WARN No appenders could be found for logger (org.apache.spark.SparkContext).; log4j:WARN Please initialize the log4j system properly.; log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.; 09:14:26.202 INFO PrintReadsSpark - Shutting down engine; [June 8, 2017 9:14:26 AM CST] org.broadinstitute.hellbender.tools.spark.pipelines.PrintReadsSpark done. Elapsed time: 0.21 minutes.; Runtime.totalMemory()=494927872; ***********************************************************************. A USER ERROR has occurred: Couldn't write file /user/yaron/output.bam because writ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3066:3409,ERROR,ERROR,3409,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3066,1,['ERROR'],['ERROR']
Availability,": ...working... done. Downloading and Extracting Packages. keras-preprocessing- | 36 KB | ########## | 100%; astor-0.8.0 | 46 KB | ########## | 100%; setuptools-36.4.0 | 563 KB | ########## | 100%; termcolor-1.1.0 | 8 KB | ########## | 100%; protobuf-3.11.2 | 635 KB | ########## | 100%; keras-applications-1 | 33 KB | ########## | 100%; readline-6.2 | 606 KB | ########## | 100%; libgfortran-ng-7.3.0 | 1006 KB | ########## | 100%; numpy-1.13.3 | 3.1 MB | ########## | 100%; ```. numpy-1.13.3 is corectly installed . but then . ```; Collecting numpy (from biopython==1.70->-r /root/gatk-4.1.4.0/condaenv.g1uyq0ce.requirements.txt (line 1)); Downloading https://files.pythonhosted.org/packages/62/20/4d43e141b5bc426ba38274933ef8e76e85c7adea2c321ecf9ebf7421cedf/numpy-1.18.1-cp36-cp36m-manylinux1_x86_64.whl (20.1MB); ```. that does . ```; Found existing installation: numpy 1.13.3; Uninstalling numpy-1.13.3:; Successfully uninstalled numpy-1.13.3; ```. this causes ```gatk DetermineGermlineContigPloidy ```; to exit with an error related to numpy.testing.decorators which is deprecated since numpy 1.15.0 see https://docs.scipy.org/doc/numpy-1.15.0/release.html. ```; Deprecations. Aliases of builtin pickle functions are deprecated, in favor of their unaliased pickle.<func> names:; numpy.loads; numpy.core.numeric.load; numpy.core.numeric.loads; numpy.ma.loads, numpy.ma.dumps; numpy.ma.load, numpy.ma.dump - these functions already failed on python 3 when called with a string.; Multidimensional indexing with anything but a tuple is deprecated. This means that the index list in ind = [slice(None), 0]; arr[ind] should be changed to a tuple, e.g., ind = [slice(None), 0]; arr[tuple(ind)] or arr[(slice(None), 0)]. That change is necessary to avoid ambiguity in expressions such as arr[[[0, 1], [0, 1]]], currently interpreted as arr[array([0, 1]), array([0, 1])], that will be interpreted as arr[array([[0, 1], [0, 1]])] in the future.; Imports from the following sub-modules are deprecated, they",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6396:1552,error,error,1552,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6396,1,['error'],['error']
Availability,": Started o.s.j.s.ServletContextHandler@6bce4140{/storage/json,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5882b202{/storage/rdd,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@b506ed0{/storage/rdd/json,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@65f3e805{/environment,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@10618775{/environment/json,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@20a3e10c{/executors,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5e2a6991{/executors/json,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6f96dd64{/executors/threadDump,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@409732fb{/executors/threadDump/json,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5e99e2cb{/static,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@478967eb{/,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@7f2b39a{/api,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@18c880ea{/jobs/job/kill,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6afbe6a1{/stages/stage/kill,null,AVAILABLE,@Spark}; 18/01/09 18:30:56 INFO ui.SparkUI: Bound SparkUI to 0.0.0.0, and started at http://192.168.1.4:4040; 18/01/09 18:30:56 INFO spark.SparkContext: Added JAR file:/opt/NfsDir/BioDir/GATK4/gatk/build",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4112:9545,AVAIL,AVAILABLE,9545,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4112,1,['AVAIL'],['AVAILABLE']
Availability,:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr9_KI270720v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr11_KI270721v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_GL000009v2_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_GL000225v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_KI270722v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_GL000194v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_KI270723v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_KI270724v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_KI270725v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_KI270726v1_ran,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4840:5172,reliab,reliable,5172,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4840,1,['reliab'],['reliable']
Availability,":06:29.368 INFO ProgressMeter - Lama-PacBio.Chr08:1676524 1.6 4676000 2883156.9; 17:06:39.369 INFO ProgressMeter - Lama-PacBio.Chr17:545310 1.8 9925000 5549291.3; 17:06:49.558 INFO ProgressMeter - Lama-PacBio.Chr20:3003652 2.0 14424000 7365509.5; 17:06:59.558 INFO ProgressMeter - Lama-PacBio.Chr26:426929 2.1 19191000 9031058.8; 17:07:09.558 INFO ProgressMeter - Lama-PacBio.Chr30:1051399 2.3 24396000 10645527.3; 17:07:19.559 INFO ProgressMeter - Lama-PacBio.Chr34:95733 2.5 29543000 12017410.1; 17:07:23.141 INFO DepthOfCoverage - 1031666 read(s) filtered by: WellformedReadFilter ; 0 read(s) filtered by: NotDuplicateReadFilter ; 0 read(s) filtered by: NotSecondaryAlignmentReadFilter ; 0 read(s) filtered by: MappedReadFilter ; 1031666 total reads filtered; 17:07:23.142 INFO ProgressMeter - Lama-PacBio.Chr34:1982733 2.5 31430935 12482169.5; 17:07:23.142 INFO ProgressMeter - Traversal complete. Processed 31430935 total loci in 2.5 minutes.; 17:07:23.142 INFO DepthOfCoverage - Shutting down engine; [June 29, 2021 5:07:23 PM GMT] org.broadinstitute.hellbender.tools.walkers.coverage.DepthOfCoverage done. Elapsed time: 2.54 minutes.; Runtime.totalMemory()=244318208; java.lang.ArrayIndexOutOfBoundsException: 0; 	at org.broadinstitute.hellbender.tools.walkers.coverage.CoverageOutputWriter.printIntervalTable(CoverageOutputWriter.java:616); 		at org.broadinstitute.hellbender.tools.walkers.coverage.CoverageOutputWriter.writeOutputIntervalStatistics(CoverageOutputWriter.java:364); 	at org.broadinstitute.hellbender.tools.walkers.coverage.DepthOfCoverage.onTraversalSuccess(DepthOfCoverage.java:397); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1062); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7332:4279,down,down,4279,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7332,1,['down'],['down']
Availability,":08.558 INFO Mutect2 - GCS max retries/reopens: 20; 13:24:08.558 INFO Mutect2 - Requester pays: disabled; 13:24:08.558 INFO Mutect2 - Initializing engine; 13:24:09.048 INFO FeatureManager - Using codec VCFCodec to read file file://ref/1000g_pon.hg38.vcf.gz; 13:24:09.207 INFO FeatureManager - Using codec VCFCodec to read file file://ref/af-only-gnomad.hg38.vcf.gz; 13:24:09.374 INFO Mutect2 - Done initializing engine; 13:24:09.435 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/GATK/4.1.8.1-GCCcore-9.3.0-Java-1.8/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_utils.so; 13:24:09.438 INFO NativeLibraryLoader - Loading libgkl_pairhmm_omp.so from jar:file:/GATK/4.1.8.1-GCCcore-9.3.0-Java-1.8/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_pairhmm_omp.so; 13:24:09.472 INFO IntelPairHmm - Using CPU-supported AVX-512 instructions; 13:24:09.472 INFO IntelPairHmm - Flush-to-zero (FTZ) is enabled when running PairHMM; 13:24:09.473 INFO IntelPairHmm - Available threads: 24; 13:24:09.473 INFO IntelPairHmm - Requested threads: 4; 13:24:09.473 INFO PairHMM - Using the OpenMP multi-threaded AVX-accelerated native PairHMM implementation; 13:24:09.501 INFO ProgressMeter - Starting traversal; 13:24:09.502 INFO ProgressMeter - Current Locus Elapsed Minutes Regions Processed Regions/Minute; 13:24:19.721 INFO ProgressMeter - chr1:634040 0.2 2460 14443.7; 13:24:29.736 INFO ProgressMeter - chr1:1564703 0.3 7220 21409.5; .; .; .; 15:28:55.286 INFO ProgressMeter - chrM:12891 124.8 11474080 91967.0; 15:29:08.985 INFO VectorLoglessPairHMM - Time spent in setup for JNI call : 10.162159898; 15:29:08.986 INFO PairHMM - Total compute time in PairHMM computeLogLikelihoods() : 1047.646162184; 15:29:08.986 INFO SmithWatermanAligner - Total compute time in java Smith-Waterman : 1077.35 sec; 15:29:08.986 INFO Mutect2 - Shutting down engine; [September 25, 2020 3:29:08 PM BST] org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2 done. Elapsed time: 125.01 ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6851:3601,Avail,Available,3601,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6851,1,['Avail'],['Available']
Availability,":13.567 INFO PrintReadsSpark - HTSJDK Defaults.COMPRESSION_LEVEL : 1; 09:14:13.567 INFO PrintReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 09:14:13.567 INFO PrintReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : false; 09:14:13.567 INFO PrintReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 09:14:13.567 INFO PrintReadsSpark - Deflater: IntelDeflater; 09:14:13.567 INFO PrintReadsSpark - Inflater: IntelInflater; 09:14:13.567 INFO PrintReadsSpark - Initializing engine; 09:14:13.567 INFO PrintReadsSpark - Done initializing engine; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@6d21714c] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@6ee12bac].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@6d21714c] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@6ee12bac].; log4j:ERROR Could not instantiate appender named ""console"".; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; log4j:WARN No appenders could be found for logger (org.apache.spark.SparkContext).; log4j:WARN Please initialize the log4j system properly.; log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.; 09:14:26.202 INFO PrintReadsSpark - Shutting down engine; [June 8, 2017 9:14:26 AM CST] org.broadinstitute.hellbender.tools.spark.pipelines.PrintReadsSpark done. Elapsed time: 0.21 minutes.; Runtime.totalMemory()=494",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3066:3230,ERROR,ERROR,3230,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3066,1,['ERROR'],['ERROR']
Availability,":16.216 INFO TransferReadTags - Deflater: IntelDeflater; 13:08:16.216 INFO TransferReadTags - Inflater: IntelInflater; 13:08:16.216 INFO TransferReadTags - GCS max retries/reopens: 20; 13:08:16.216 INFO TransferReadTags - Requester pays: disabled; 13:08:16.216 WARN TransferReadTags -. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. Warning: TransferReadTags is an EXPERIMENTAL tool and should not be used for production. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. 13:08:16.217 INFO TransferReadTags - Initializing engine; 13:08:16.658 INFO TransferReadTags - Done initializing engine; 13:08:16.710 WARN ReadUtils - Skipping index file creation for: /data/reddylab/Alex/tmp/TEST_BAM.with_umis.bam. Index file creation requires reads in coordinate sorted order.; 13:08:16.739 INFO ProgressMeter - Starting traversal; 13:08:16.739 INFO ProgressMeter - Current Locus Elapsed Minutes Records Processed Records/Minute; 13:08:16.741 INFO TransferReadTags - Shutting down engine; [January 5, 2023 1:08:16 PM EST] org.broadinstitute.hellbender.tools.walkers.qc.TransferReadTags done. Elapsed time: 0.01 minutes.; Runtime.totalMemory()=2612002816; java.lang.IllegalStateException: A read found in the aligned bam is not found in the unmapped bam. This tool assumes reads in both input files are query-name sorted lexicographically (i.e. by Picard SortSam but not by samtools sort): aligned read = A00257:933:HG2MVDSX5:1:1101:1045:11130, unmapped read = A00257:933:HG2MVDSX5:1:1101:1045:8531; at org.broadinstitute.hellbender.tools.walkers.qc.TransferReadTags.traverse(TransferReadTags.java:142); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1095); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgr",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8147:4877,down,down,4877,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8147,1,['down'],['down']
Availability,":16:21.553 INFO GenomicsDBLibLoader - GenomicsDB native library version : 1.3.2-e18fa63 ; ; 17:16:21.554 INFO GenomicsDBImport - Vid Map JSON file will be written to /home/akansha/vivekruhela/pon\_db/vidmap.json ; ; 17:16:21.554 INFO GenomicsDBImport - Callset Map JSON file will be written to /home/akansha/vivekruhela/pon\_db/callset.json ; ; 17:16:21.554 INFO GenomicsDBImport - Complete VCF Header will be written to /home/akansha/vivekruhela/pon\_db/vcfheader.vcf ; ; 17:16:21.554 INFO GenomicsDBImport - Importing to workspace - /home/akansha/vivekruhela/pon\_db ; ; 17:16:21.554 WARN GenomicsDBImport - GenomicsDBImport cannot use multiple VCF reader threads for initialization when the number of intervals is greater than 1. Falling back to serial VCF reader initialization. ; ; 17:16:21.554 INFO ProgressMeter - Starting traversal ; ; 17:16:21.554 INFO ProgressMeter - Current Locus Elapsed Minutes Batches Processed Batches/Minute ; ; 17:16:21.590 INFO GenomicsDBImport - Shutting down engine ; ; \[January 12, 2021 5:16:21 PM IST\] org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImport done. Elapsed time: 0.09 minutes. ; ; Runtime.totalMemory()=2761949184 ; ; java.lang.IndexOutOfBoundsException: Index: 0 ; ; at java.util.Collections$EmptyList.get(Collections.java:4456) ; ; at org.genomicsdb.model.GenomicsDBImportConfiguration$ImportConfiguration.getColumnPartitions(GenomicsDBImportConfiguration.java:2083) ; ; at org.genomicsdb.importer.GenomicsDBImporter.<init>(GenomicsDBImporter.java:203) ; ; at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImport.traverse(GenomicsDBImport.java:745) ; ; at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1049) ; ; at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140) ; ; at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192) ; ; at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMai",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7037:5582,down,down,5582,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7037,1,['down'],['down']
Availability,":17.382 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/gatk/gatk-package-4.1.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; [Thu Mar 07 16:08:17 UTC 2019] ValidateSamFile --INPUT CQ-NEQAS-2018.ILLUMINA.library.000000000-BCFDC.1.1.sorted.bam --MODE SUMMARY --MAX_OUTPUT 100 --IGNORE_WARNINGS false --VALIDATE_INDEX true --INDEX_VALIDATION_STRINGENCY EXHAUSTIVE --IS_BISULFITE_SEQUENCED false --MAX_OPEN_TEMP_FILES 8000 --SKIP_MATE_VALIDATION false --VERBOSITY INFO --QUIET false --VALIDATION_STRINGENCY STRICT --COMPRESSION_LEVEL 2 --MAX_RECORDS_IN_RAM 500000 --CREATE_INDEX false --CREATE_MD5_FILE false --GA4GH_CLIENT_SECRETS client_secrets.json --help false --version false --showHidden false --USE_JDK_DEFLATER false --USE_JDK_INFLATER false; [Thu Mar 07 16:08:24 UTC 2019] Executing as mpmachado@lx-bioinfo02 on Linux 2.6.32-696.23.1.el6.x86_64 amd64; OpenJDK 64-Bit Server VM 1.8.0_191-8u191-b12-0ubuntu0.16.04.1-b12; Deflater: Intel; Inflater: Intel; Provider GCS is available; Picard version: Version:4.1.0.0; WARNING 2019-03-07 16:08:24 ValidateSamFile NM validation cannot be performed without the reference. All other validations will still occur.; INFO 2019-03-07 16:10:25 SamFileValidator Validated Read 10,000,000 records. Elapsed time: 00:02:00s. Time for last 10,000,000: 120s. Last read position: chr9:32,633,613; INFO 2019-03-07 16:12:22 SamFileValidator Validated Read 20,000,000 records. Elapsed time: 00:03:58s. Time for last 10,000,000: 117s. Last read position: chrM:11,340; No errors found; [Thu Mar 07 16:13:05 UTC 2019] picard.sam.ValidateSamFile done. Elapsed time: 4.79 minutes.; Runtime.totalMemory()=2602041344; Tool returned:; 0; ```. But when run BaseRecalibrator got the _fromIndex toIndex_ error:; `gatk BaseRecalibrator --input sorted.bam --output sorted.baserecalibrator_report.txt --reference GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.bowtie_index.fasta --use-original-qualities true --known-sites snp151common_tablebrows",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5807:1679,avail,available,1679,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5807,1,['avail'],['available']
Availability,":189445 131.2 141330000 1077550.0; 02:12:47.714 INFO ProgressMeter - 33:3337674 131.3 141488000 1077385.4; 02:12:57.758 INFO ProgressMeter - 33:4894812 131.5 141812000 1078478.0; 02:13:07.778 INFO ProgressMeter - 33:5541459 131.7 141930000 1078006.1; 02:13:17.801 INFO ProgressMeter - 33:6552319 131.8 142090000 1077853.8; 02:13:29.312 INFO ProgressMeter - 33:6897003 132.0 142231000 1077355.5; 02:13:39.368 INFO ProgressMeter - 33:7093963 132.2 142374000 1077071.3; 02:13:49.368 INFO ProgressMeter - 33:7125494 132.4 142594000 1077377.2; 02:13:59.416 INFO ProgressMeter - 33:7127107 132.5 142752000 1077208.0; 02:14:09.424 INFO ProgressMeter - 33:7726380 132.7 142902000 1076984.3; 02:14:11.026 INFO SplitNCigarReads - 0 read(s) filtered by: AllowAllReadsReadFilter. 02:14:11.026 INFO ProgressMeter - 33:7774932 132.7 142924170 1076934.7; 02:14:11.026 INFO ProgressMeter - Traversal complete. Processed 142924170 total reads in 132.7 minutes.; 02:14:55.471 INFO SplitNCigarReads - Shutting down engine; [February 21, 2021 at 2:14:55 AM PST] org.broadinstitute.hellbender.tools.walkers.rnaseq.SplitNCigarReads done. Elapsed time: 133.47 minutes.; Runtime.totalMemory()=1283457024; htsjdk.samtools.SAMException: Exception when processing alignment for BAM index DRR029822.14231344 1/2 94b aligned to 1:68375-68468.; at htsjdk.samtools.BAMFileWriter.writeAlignment(BAMFileWriter.java:141); at htsjdk.samtools.SAMFileWriterImpl.close(SAMFileWriterImpl.java:212); at htsjdk.samtools.AsyncSAMFileWriter.synchronouslyClose(AsyncSAMFileWriter.java:38); at htsjdk.samtools.util.AbstractAsyncWriter.close(AbstractAsyncWriter.java:89); at org.broadinstitute.hellbender.utils.read.SAMFileGATKReadWriter.close(SAMFileGATKReadWriter.java:26); at org.broadinstitute.hellbender.tools.walkers.rnaseq.SplitNCigarReads.closeTool(SplitNCigarReads.java:193); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1053); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgr",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7091:58691,down,down,58691,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7091,1,['down'],['down']
Availability,":25:11 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 71.1 KB, free 331.9 KB); 16/11/16 23:25:11 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 26.0 KB, free 357.9 KB); 16/11/16 23:25:11 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on localhost:40833 (size: 26.0 KB, free: 1247.2 MB); 16/11/16 23:25:11 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1006; 16/11/16 23:25:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at mapToPair at ReadsSparkSink.java:273); 16/11/16 23:25:11 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks; 16/11/16 23:25:11 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0,NODE_LOCAL, 1951 bytes); 16/11/16 23:25:11 INFO Executor: Running task 0.0 in stage 1.0 (TID 1); 16/11/16 23:25:11 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks; 16/11/16 23:25:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms; 16/11/16 23:25:11 ERROR Executor: Exception in task 0.0 in stage 1.0 (TID 1); java.lang.AbstractMethodError: org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSink$$Lambda$78/237665701.call(Ljava/lang/Object;)Ljava/lang/Iterable;; 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:159); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:159); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$20.apply(RDD.scala:710); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$20.apply(RDD.scala:710); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrRead",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2268:11794,ERROR,ERROR,11794,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2268,1,['ERROR'],['ERROR']
Availability,":308); at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:294); at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:846); at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:131); at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:511); at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:468); at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:382); at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:354); at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:111); at java.lang.Thread.run(Thread.java:744); ```. And then warnings about lost tasks:. ```; 16/02/16 11:45:59 WARN TaskSetManager: Lost task 42.1 in stage 0.0 (TID 364, dataflow03.broadinstitute.org): java.io.IOException: Connection from /69.173.65.227:56014 closed; ```. Then errors like this:. ```; 16/02/16 11:47:37 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@69.173.65.227:47043] -> [akka.tcp://sparkExecutor@dataflow05.broadinstitute.org:36695]: Error [Association failed with [akka.tcp://sparkExecutor@dataflow05.broadinstitute.org:36695]] [; ```. akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkExecutor@dataflow05.broadinstitute.org:36695]; Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: dataflow05.broadinstitute.org/69.173.65.230:36695; ]; akka.event.Logging$Error$NoCause$. ```; 16/02/16 11:47:39 ERROR YarnScheduler: Lost executor 37 on dataflow02.broadinstitute.org: remote Rpc client disassociated; ```. This seems to be causing tasks to be re-queued and executed, which hurts performance. The command line I'm using is:. ```; gatk-launch FindBadGenomicKmersSpark --reference hdfs:///user/cwhelan/reference/Homo_sapiens_assembly19.2bit --output bad_kmers_v5_cl",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1491:5461,error,errors,5461,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1491,1,['error'],['errors']
Availability,":33:06.617 INFO FastaAlternateReferenceMaker - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 15:33:06.618 INFO FastaAlternateReferenceMaker - Deflater: IntelDeflater; 15:33:06.618 INFO FastaAlternateReferenceMaker - Inflater: IntelInflater; 15:33:06.618 INFO FastaAlternateReferenceMaker - GCS max retries/reopens: 20; 15:33:06.619 INFO FastaAlternateReferenceMaker - Requester pays: disabled; 15:33:06.619 INFO FastaAlternateReferenceMaker - Initializing engine; 15:33:06.870 INFO FeatureManager - Using codec VCFCodec to read file file:///mnt/research/Hausbeck_group/Lukasko/BotrytisDNASeq/CCR7/ConservedGenes/VCFs/AI7.vcf; 15:33:06.936 INFO IntervalArgumentCollection - Processing 4444 bp from intervals; 15:33:06.939 INFO FastaAlternateReferenceMaker - Done initializing engine; 15:33:06.949 INFO ProgressMeter - Starting traversal; 15:33:06.949 INFO ProgressMeter - Current Locus Elapsed Minutes Bases Processed Bases/Minute; 15:33:07.194 INFO FastaAlternateReferenceMaker - Shutting down engine; [July 18, 2023 at 3:33:07 PM EDT] org.broadinstitute.hellbender.tools.walkers.fasta.FastaAlternateReferenceMaker done. Elapsed time: 0.02 minutes.; Runtime.totalMemory()=2076049408; java.lang.IllegalArgumentException: Illegal base [ ] seen in the allele; at htsjdk.variant.variantcontext.Allele.create(Allele.java:251); at htsjdk.variant.variantcontext.Allele.create(Allele.java:402); at org.broadinstitute.hellbender.tools.walkers.fasta.FastaAlternateReferenceMaker.lambda$handlePosition$0(FastaAlternateReferenceMaker.java:176); at java.base/java.util.Optional.orElseGet(Optional.java:369); at org.broadinstitute.hellbender.tools.walkers.fasta.FastaAlternateReferenceMaker.handlePosition(FastaAlternateReferenceMaker.java:176); at org.broadinstitute.hellbender.tools.walkers.fasta.FastaAlternateReferenceMaker.apply(FastaAlternateReferenceMaker.java:141); at org.broadinstitute.hellbender.engine.ReferenceWalker.traverse(ReferenceWalker.java:55); at org.broadinstitute.hellbender.engine",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8427:4633,down,down,4633,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8427,1,['down'],['down']
Availability,":43:34.915 INFO PostprocessGermlineCNVCalls - Writing intervals VCF file to /home/lmbs02/bio/work/gatk_cnv/genomed_genome_hg19/vcfs/sample.vcf...; 12:43:34.916 INFO PostprocessGermlineCNVCalls - Analyzing shard 1 / 3...; 12:43:37.965 INFO PostprocessGermlineCNVCalls - Analyzing shard 2 / 3...; 12:43:40.679 INFO PostprocessGermlineCNVCalls - Analyzing shard 3 / 3...; 12:43:43.248 INFO PostprocessGermlineCNVCalls - Generating segments VCF file...; 12:44:50.045 INFO PostprocessGermlineCNVCalls - Writing segments VCF file to /home/lmbs02/bio/work/gatk_cnv/genomed_genome_hg19/vcfs/sample.segments.vcf...; 12:44:50.129 INFO PostprocessGermlineCNVCalls - Generating denoised copy ratios...; 12:44:50.928 INFO PostprocessGermlineCNVCalls - Writing denoised copy ratios to /home/lmbs02/bio/work/gatk_cnv/genomed_genome_hg19/vcfs/sample.copy_ratios.tsv...; 12:44:51.493 INFO PostprocessGermlineCNVCalls - PostprocessGermlineCNVCalls complete.; 12:44:51.493 INFO PostprocessGermlineCNVCalls - Shutting down engine; [October 29, 2020 12:44:51 PM MSK] org.broadinstitute.hellbender.tools.copynumber.PostprocessGermlineCNVCalls done. Elapsed time: 1.40 minutes.; Runtime.totalMemory()=4294443008; Using GATK jar /home/lmbs02/bio/biosoft/gatk/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /home/lmbs02/bio/biosoft/gatk/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar PostprocessGermlineCNVCalls --model-shard-path /home/lmbs02/bio/work/gatk_cnv/genomed_genome_hg19//cohort_calls//temp_0001_of_10/cohort-model/ --model-shard-path /home/lmbs02/bio/work/gatk_cnv/genomed_genome_hg19//cohort_calls//temp_0002_of_10/cohort-model/ --model-shard-path /home/lmbs02/bio/work/gatk_cnv/genomed_genome_hg19//cohort_calls//temp_0003_of_10/cohort-model/ --calls-shard-path /home/lmbs02/bio/work/gatk_cnv/genomed_genome_hg19//cohort_calls//temp_0001_of_",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6924:4996,down,down,4996,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6924,1,['down'],['down']
Availability,":44:1:689:1:1; chr22	19895477	CNV_chr22_19895477_19901476	N	<DUP>	2.39	.	END=19901476	GT:CN:NP:QA:QS:QSE:QSS	./.:3:6:1:2:1:0; chr22	19901477	CNV_chr22_19901477_19946476	N	<DEL>	114.12	.	END=19946476	GT:CN:NP:QA:QS:QSE:QSS	1/1:0:45:0:114:1:1; chr22	19946477	CNV_chr22_19946477_19971476	N	<DUP>	4.69	.	END=19971476	GT:CN:NP:QA:QS:QSE:QSS	./.:3:25:0:5:2:0; chr22	19971477	CNV_chr22_19971477_20003000	N	<DEL>	96.55	.	END=20003000	GT:CN:NP:QA:QS:QSE:QSS	1/1:0:32:0:97:2:2. ```. #### Actual behavior. - `gatkgermlinecnvcaller_genotyped-intervals-COHORT_0.woTimestamp.vcf` (`##contig` cut from header and only first 5 chr22 CNVs present). ```; ##fileformat=VCFv4.2; ##FORMAT=<ID=CN,Number=1,Type=Integer,Description=""Copy number maximum a posteriori value"">; ##FORMAT=<ID=CNLP,Number=.,Type=Integer,Description=""Copy number log posterior (in Phred-scale) rounded down"">; ##FORMAT=<ID=CNQ,Number=1,Type=Integer,Description=""Genotype call quality as the difference between the best and second best phred-scaled log posterior scores"">; ##FORMAT=<ID=GT,Number=1,Type=Integer,Description=""Genotype"">; ##INFO=<ID=END,Number=1,Type=Integer,Description=""End coordinate of the variant"">; ##contig=<ID=chr1,length=248956422,assembly=GRCh38.d1.vd1>; ...; ##contig=<ID=HPV-mSD2,length=7300,assembly=GRCh38.d1.vd1>; ##source=PostprocessGermlineCNVCalls; #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	E07002_normal; chr1	10000	CNV_chr1_10000_10999	N	<DEL>,<DUP>	.	.	END=10999	GT:CN:CNLP:CNQ	0:2:30,32,0,33,33,33:30; chr1	11000	CNV_chr1_11000_11999	N	<DEL>,<DUP>	.	.	END=11999	GT:CN:CNLP:CNQ	0:2:30,32,0,33,33,33:30; chr1	12000	CNV_chr1_12000_12999	N	<DEL>,<DUP>	.	.	END=12999	GT:CN:CNLP:CNQ	0:2:30,32,0,33,33,33:30; chr1	13000	CNV_chr1_13000_13999	N	<DEL>,<DUP>	.	.	END=13999	GT:CN:CNLP:CNQ	0:2:30,32,0,33,33,33:30; chr1	14000	CNV_chr1_14000_14999	N	<DEL>,<DUP>	.	.	END=14999	GT:CN:CNLP:CNQ	0:2:29,32,0,33,33,33:29; chr1	15000	CNV_chr1_15000_15999	N	<DEL>,<DUP>	.	.	END=15999	GT:CN:CNLP:CNQ	0:2:29,32,0,33,33,33:29; chr1	1",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8628:19661,down,down,19661,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8628,1,['down'],['down']
Availability,:54.462 DEBUG Mutect2Engine - Kmer sizes values []; 12:13:55.715 DEBUG Mutect2 - Processing assembly region at chrM:13945-14244 isActive: false numReads: 54745; 12:13:56.962 DEBUG Mutect2 - Processing assembly region at chrM:14245-14544 isActive: false numReads: 0; 12:13:56.973 DEBUG Mutect2 - Processing assembly region at chrM:14545-14844 isActive: false numReads: 0; 12:13:56.984 DEBUG Mutect2 - Processing assembly region at chrM:14845-15144 isActive: false numReads: 0; 12:13:56.995 DEBUG Mutect2 - Processing assembly region at chrM:15145-15444 isActive: false numReads: 0; 12:13:57.009 DEBUG Mutect2 - Processing assembly region at chrM:15445-15744 isActive: false numReads: 0; 12:13:57.027 INFO ProgressMeter - chrM:15445 38.3 60 1.6; 12:13:57.035 DEBUG Mutect2 - Processing assembly region at chrM:15745-15960 isActive: false numReads: 14; 12:13:57.047 DEBUG Mutect2 - Processing assembly region at chrM:15961-16230 isActive: true numReads: 30; 12:13:57.055 DEBUG ReadThreadingGraph - Recovered 1 of 1 dangling tails; 12:13:57.063 DEBUG ReadThreadingGraph - Recovered 0 of 1 dangling heads; 12:13:57.096 DEBUG ReadThreadingGraph - Recovered 3 of 3 dangling tails; 12:13:57.106 DEBUG ReadThreadingGraph - Recovered 3 of 5 dangling heads; 12:13:57.464 DEBUG Mutect2Engine - Active Region chrM:15961-16230; 12:13:57.469 DEBUG Mutect2Engine - Extended Act Region chrM:15861-16299; 12:13:57.472 DEBUG Mutect2Engine - Ref haplotype coords chrM:15861-16299; 12:13:57.476 DEBUG Mutect2Engine - Haplotype count 111; 12:13:57.479 DEBUG Mutect2Engine - Kmer sizes count 0; 12:13:57.482 DEBUG Mutect2Engine - Kmer sizes values []; 12:13:58.821 DEBUG Mutect2 - Processing assembly region at chrM:16231-16299 isActive: false numReads: 15; 12:13:58.938 INFO Mutect2 - 0 read(s) filtered by: MappingQualityReadFilter ; 0 read(s) filtered by: MappingQualityNotZeroReadFilter ; 0 read(s) filtered by: MappedReadFilter ; 0 read(s) filtered by: NotSecondaryAlignmentReadFilter ; 0 read(s) filtered by: PassesVen,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7281:22201,Recover,Recovered,22201,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7281,1,['Recover'],['Recovered']
Availability,":56:44.709 INFO HaplotypeCaller - GCS max retries/reopens: 20; 03:56:44.709 INFO HaplotypeCaller - Requester pays: disabled; 03:56:44.709 INFO HaplotypeCaller - Initializing engine; 03:56:45.204 INFO FeatureManager - Using codec BEDCodec to read file file:///data/b37.chr13.bed; 03:56:45.276 INFO IntervalArgumentCollection - Processing 595907 bp from intervals; 03:56:45.305 INFO HaplotypeCaller - Done initializing engine; 03:56:45.324 INFO HaplotypeCallerEngine - Disabling physical phasing, which is supported only for reference-model confidence output; 03:56:45.349 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/gatk/gatk-package-4.2.2.0-local.jar!/com/intel/gkl/native/libgkl_utils.so; 03:56:45.351 INFO NativeLibraryLoader - Loading libgkl_pairhmm_omp.so from jar:file:/gatk/gatk-package-4.2.2.0-local.jar!/com/intel/gkl/native/libgkl_pairhmm_omp.so; 03:56:45.373 INFO IntelPairHmm - Flush-to-zero (FTZ) is enabled when running PairHMM; 03:56:45.375 INFO IntelPairHmm - Available threads: 8; 03:56:45.375 INFO IntelPairHmm - Requested threads: 4; 03:56:45.375 INFO PairHMM - Using the OpenMP multi-threaded AVX-accelerated native PairHMM implementation; 03:56:45.415 INFO ProgressMeter - Starting traversal; 03:56:45.416 INFO ProgressMeter - Current Locus Elapsed Minutes Regions Processed Regions/Minute; 03:56:46.180 WARN VariantAnnotatorEngine - Jumbo genotype annotations requested but fragment likelihoods or haplotype likelihoods were not given.; 03:56:46.210 WARN InbreedingCoeff - InbreedingCoeff will not be calculated at position 13:32911888 and possibly subsequent; at least 10 samples must have called genotypes; 03:56:46.621 INFO HaplotypeCaller - 1 read(s) filtered by: MappingQualityReadFilter ; 0 read(s) filtered by: MappingQualityAvailableReadFilter ; 0 read(s) filtered by: MappedReadFilter ; 0 read(s) filtered by: NotSecondaryAlignmentReadFilter ; 57 read(s) filtered by: NotDuplicateReadFilter ; 0 read(s) filtered by: PassesVendorQualityCheckReadFilte",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8149:5331,Avail,Available,5331,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8149,1,['Avail'],['Available']
Availability,":58:33.933 INFO HaplotypeCaller - GCS max retries/reopens: 20; 03:58:33.933 INFO HaplotypeCaller - Requester pays: disabled; 03:58:33.934 INFO HaplotypeCaller - Initializing engine; 03:58:34.384 INFO FeatureManager - Using codec BEDCodec to read file file:///data/b37.chr13.bed; 03:58:34.461 INFO IntervalArgumentCollection - Processing 595907 bp from intervals; 03:58:34.491 INFO HaplotypeCaller - Done initializing engine; 03:58:34.509 INFO HaplotypeCallerEngine - Disabling physical phasing, which is supported only for reference-model confidence output; 03:58:34.532 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/gatk/gatk-package-4.1.1.0-local.jar!/com/intel/gkl/native/libgkl_utils.so; 03:58:34.536 INFO NativeLibraryLoader - Loading libgkl_pairhmm_omp.so from jar:file:/gatk/gatk-package-4.1.1.0-local.jar!/com/intel/gkl/native/libgkl_pairhmm_omp.so; 03:58:34.580 INFO IntelPairHmm - Flush-to-zero (FTZ) is enabled when running PairHMM; 03:58:34.582 INFO IntelPairHmm - Available threads: 8; 03:58:34.582 INFO IntelPairHmm - Requested threads: 4; 03:58:34.582 INFO PairHMM - Using the OpenMP multi-threaded AVX-accelerated native PairHMM implementation; 03:58:34.623 INFO ProgressMeter - Starting traversal; 03:58:34.623 INFO ProgressMeter - Current Locus Elapsed Minutes Regions Processed Regions/Minute; 03:58:35.812 INFO HaplotypeCaller - 58 read(s) filtered by: ((((((((MappingQualityReadFilter AND MappingQualityAvailableReadFilter) AND MappedReadFilter) AND NotSecondaryAlignmentReadFilter) AND NotDuplicateReadFilter) AND PassesVendorQualityCheckReadFilter) AND NonZeroReferenceLengthAlignmentReadFilter) AND GoodCigarReadFilter) AND WellformedReadFilter); 58 read(s) filtered by: (((((((MappingQualityReadFilter AND MappingQualityAvailableReadFilter) AND MappedReadFilter) AND NotSecondaryAlignmentReadFilter) AND NotDuplicateReadFilter) AND PassesVendorQualityCheckReadFilter) AND NonZeroReferenceLengthAlignmentReadFilter) AND GoodCigarReadFilter); 58 read(s) filt",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8149:11643,Avail,Available,11643,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8149,1,['Avail'],['Available']
Availability,":; 22:05:55.956 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] Build file '/scratch/var/tmp/portage/sci-biology/gatk-9999/work/gatk-9999/build.gradle' line: 102; 22:05:55.964 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] ; 22:05:55.964 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] * What went wrong:; 22:05:55.966 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] A problem occurred evaluating root project 'gatk'.; 22:05:55.966 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] > Execution of ""git lfs pull --include src/main/resources/large"" failed with exit code: 2. git-lfs is required to build GATK but may not be installed. See https://github.com/broadinstitute/gatk#building for information on how to build GATK.; 22:05:55.967 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] ; 22:05:55.968 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] * Exception is:; 22:05:55.969 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] org.gradle.api.GradleScriptException: A problem occurred evaluating root project 'gatk'.; 22:05:55.969 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.groovy.scripts.internal.DefaultScriptRunnerFactory$ScriptRunnerImpl.run(DefaultScriptRunnerFactory.java:92); 22:05:55.969 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.DefaultScriptPluginFactory$ScriptPluginImpl$2.run(DefaultScriptPluginFactory.java:176); 22:05:55.970 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.ProjectScriptTarget.addConfiguration(ProjectScriptTarget.java:77); 22:05:55.970 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.DefaultScriptPluginFactory$ScriptPluginImpl.apply(DefaultScriptPluginFactory.java:181); 22:05:55.970 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at or",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4687:1824,ERROR,ERROR,1824,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4687,1,['ERROR'],['ERROR']
Availability,":; mode: global; restart_policy:; condition: on-failure; tty: true #keeps the container alive; volumes:; - reference-image:/reference_image. volumes:; reference-image:. networks:; workbench:; external: true; ```; - Hadoop:; ```; version: '3'; services:; namenode:; image: bde2020/hadoop-namenode:2.0.0-hadoop2.7.4-java8; networks:; - workbench; volumes:; - namenode:/hadoop/dfs/name; environment:; - CLUSTER_NAME=test; env_file:; - ./hadoop.env; deploy:; mode: replicated; replicas: 1; restart_policy:; condition: on-failure; labels:; traefik.docker.network: workbench; traefik.port: 50070; ports:; - 8334:50070; volumes:; - /data0/reference/hg19-ucsc/:/reference/hg19-ucsc/; - /data0/output/:/output/; - /data/ngs/:/ngs/; datanode:; image: bde2020/hadoop-datanode:2.0.0-hadoop2.7.4-java8; networks:; - workbench; volumes:; - datanode:/hadoop/dfs/data; environment:; SERVICE_PRECONDITION: ""namenode:50070""; # depends_on:; # - namenode; env_file:; - ./hadoop.env; deploy:; mode: global; restart_policy:; condition: on-failure; labels:; traefik.docker.network: workbench; traefik.port: 50075. volumes:; datanode:; namenode:. networks:; workbench:; external: true; ```; the datanodes and namenode and spark master and workers are all working.; My hardware resources are:; 16 core and 1Tb memory ssd and 56Gb ram for 3 machines. I have this problem when I launch the version(GATK) v4.0.4.0 but not with this version v4.0.2.0-4-gb59d863-SNAPSHOT:. >java.lang.IllegalStateException: Duplicate key -1; 	at java.util.stream.Collectors.lambda$throwingMerger$0(Collectors.java:133); 	at java.util.HashMap.merge(HashMap.java:1253); 	at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1320); 	at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.uti",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4820:3121,failure,failure,3121,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4820,1,['failure'],['failure']
Availability,"; - Spark. ```; version: '3'; services:; spark-master:; image: atahualpa/spark-master:GATK4.0.4; networks:; - workbench; deploy:; replicas: 1; mode: replicated; restart_policy:; condition: on-failure; labels:; traefik.docker.network: workbench; traefik.port: 8080; env_file:; - ./hadoop.env; ports:; - 8333:8080; - 4040:4040; - 6066:6066; - 7077:7077; volumes:; - /data0/reference/hg19-ucsc/:/reference/hg19-ucsc/; - /data0/fastq/:/fastq/; - /data0/NGS-SparkGATK/NGS-SparkGATK/:/NGS-SparkGATK/; - /data/ngs/:/ngs/; - /data0/output/:/output/; spark-worker:; image: bde2020/spark-worker:2.2.0-hadoop2.8-hive-java8; networks:; - workbench; environment:; - SPARK_MASTER=spark://spark-master:7077; deploy:; mode: global; restart_policy:; condition: on-failure; labels:; traefik.docker.network: workbench; traefik.port: 8081. env_file:; - ./hadoop.env; volumes:; - reference-image:/reference_image. reference:; image: vzzarr/reference:hg19_img; networks:; - workbench; deploy:; mode: global; restart_policy:; condition: on-failure; tty: true #keeps the container alive; volumes:; - reference-image:/reference_image. volumes:; reference-image:. networks:; workbench:; external: true; ```; - Hadoop:; ```; version: '3'; services:; namenode:; image: bde2020/hadoop-namenode:2.0.0-hadoop2.7.4-java8; networks:; - workbench; volumes:; - namenode:/hadoop/dfs/name; environment:; - CLUSTER_NAME=test; env_file:; - ./hadoop.env; deploy:; mode: replicated; replicas: 1; restart_policy:; condition: on-failure; labels:; traefik.docker.network: workbench; traefik.port: 50070; ports:; - 8334:50070; volumes:; - /data0/reference/hg19-ucsc/:/reference/hg19-ucsc/; - /data0/output/:/output/; - /data/ngs/:/ngs/; datanode:; image: bde2020/hadoop-datanode:2.0.0-hadoop2.7.4-java8; networks:; - workbench; volumes:; - datanode:/hadoop/dfs/data; environment:; SERVICE_PRECONDITION: ""namenode:50070""; # depends_on:; # - namenode; env_file:; - ./hadoop.env; deploy:; mode: global; restart_policy:; condition: on-failure; labels",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4820:2152,failure,failure,2152,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4820,2,"['alive', 'failure']","['alive', 'failure']"
Availability,"; --spark-verbosity DEBUG \; -- --spark-runner SPARK --spark-master yarn-cluster \; # --conf 'spark.submit.deployMode=cluster'; ```. #### Expected behavior. ReadsPipelineSpark should be able to resolve the hdfs file path: `hdfs://cromwellhadooptest:8020/user/hadoop/gatk/common/human_g1k_v37.20.21.fasta`. #### Actual behavior; The tool tries to access: `file:///user/hadoop/gatk/common/human_g1k_v37.20.21.fasta` even when the input is: `hdfs://cromwellhadooptest:8020/user/hadoop/gatk/common/human_g1k_v37.20.21.fasta`. Verified that the file is accesible through hdfs:; ```; (gatk) root@2e738717b9c1:/gatk/mnt# $HADOOP_HOME/bin/hdfs dfs -ls hdfs://cromwellhadooptest:8020/user/hadoop/gatk/common/human_g1k_v37.20.21.fasta; -rw-r--r-- 3 hadoop supergroup 113008112 2020-07-29 15:54 hdfs://cromwellhadooptest:8020/user/hadoop/gatk/common/human_g1k_v37.20.21.fasta; ```; When I specify input as: `hdfs://cromwellhadooptest/user/hadoop/gatk/common/human_g1k_v37.20.21.fasta`, (i.e. without the port) I get the same error. **Stack trace for this**:; ```; ***********************************************************************; A USER ERROR has occurred: The specified fasta file (file:///user/hadoop/gatk/common/human_g1k_v37.20.21.fasta) does not exist.; ***********************************************************************; org.broadinstitute.hellbender.exceptions.UserException$MissingReference: The specified fasta file (file:///user/hadoop/gatk/common/human_g1k_v37.20.21.fasta) does not exist.; at org.broadinstitute.hellbender.utils.fasta.CachingIndexedFastaSequenceFile.checkFastaPath(CachingIndexedFastaSequenceFile.java:173); at org.broadinstitute.hellbender.utils.fasta.CachingIndexedFastaSequenceFile.<init>(CachingIndexedFastaSequenceFile.java:143); at org.broadinstitute.hellbender.utils.fasta.CachingIndexedFastaSequenceFile.<init>(CachingIndexedFastaSequenceFile.java:125); at org.broadinstitute.hellbender.utils.fasta.CachingIndexedFastaSequenceFile.<init>(CachingIndexedFastaSeque",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6730:2321,error,error,2321,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6730,1,['error'],['error']
Availability,; 11:35:48.094 DEBUG ReadThreadingGraph - Recovered 17 of 20 dangling tails; 11:35:48.198 DEBUG ReadThreadingGraph - Recovered 16 of 50 dangling heads; 11:35:48.511 DEBUG IntToDoubleFunctionCache - cache miss 2389 > 10 expanding to 2399; 11:35:48.874 DEBUG Mutect2Engine - Active Region chrM:2544-2841; 11:35:48.874 DEBUG Mutect2Engine - Extended Act Region chrM:2444-2941; 11:35:48.875 DEBUG Mutect2Engine - Ref haplotype coords chrM:2444-2941; 11:35:48.875 DEBUG Mutect2Engine - Haplotype count 128; 11:35:48.875 DEBUG Mutect2Engine - Kmer sizes count 0; 11:35:48.875 DEBUG Mutect2Engine - Kmer sizes values []; 11:36:08.907 INFO ProgressMeter - chrM:2544 0.4 10 22.3; 11:36:08.954 DEBUG Mutect2 - Processing assembly region at chrM:2842-2920 isActive: false numReads: 4726; 11:36:09.094 DEBUG Mutect2 - Processing assembly region at chrM:2921-3202 isActive: true numReads: 4600; 11:36:09.663 DEBUG ReadThreadingGraph - Recovered 1 of 2 dangling tails; 11:36:09.671 DEBUG ReadThreadingGraph - Recovered 4 of 7 dangling heads; 11:36:09.750 DEBUG Mutect2Engine - Active Region chrM:2921-3202; 11:36:09.750 DEBUG Mutect2Engine - Extended Act Region chrM:2821-3302; 11:36:09.750 DEBUG Mutect2Engine - Ref haplotype coords chrM:2821-3302; 11:36:09.751 DEBUG Mutect2Engine - Haplotype count 32; 11:36:09.751 DEBUG Mutect2Engine - Kmer sizes count 0; 11:36:09.751 DEBUG Mutect2Engine - Kmer sizes values []; 11:36:14.909 DEBUG Mutect2 - Processing assembly region at chrM:3203-3502 isActive: false numReads: 2398; 11:36:15.137 DEBUG Mutect2 - Processing assembly region at chrM:3503-3702 isActive: false numReads: 2587; 11:36:15.184 DEBUG Mutect2 - Processing assembly region at chrM:3703-3943 isActive: true numReads: 5164; 11:36:15.511 DEBUG ReadThreadingGraph - Recovered 3 of 5 dangling tails; 11:36:15.517 DEBUG ReadThreadingGraph - Recovered 1 of 5 dangling heads; 11:36:15.911 DEBUG ReadThreadingGraph - Recovered 34 of 41 dangling tails; 11:36:15.932 DEBUG ReadThreadingGraph - Recovered 13 of 31 d,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7281:10145,Recover,Recovered,10145,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7281,1,['Recover'],['Recovered']
Availability,; 12:05:51.465 DEBUG Mutect2 - Processing assembly region at chrM:10485-10784 isActive: false numReads: 0; 12:05:51.476 DEBUG Mutect2 - Processing assembly region at chrM:10785-11084 isActive: false numReads: 0; 12:05:51.489 DEBUG Mutect2 - Processing assembly region at chrM:11085-11384 isActive: false numReads: 0; 12:05:51.501 DEBUG Mutect2 - Processing assembly region at chrM:11385-11684 isActive: false numReads: 0; 12:05:51.513 DEBUG Mutect2 - Processing assembly region at chrM:11685-11984 isActive: false numReads: 0; 12:05:51.526 DEBUG Mutect2 - Processing assembly region at chrM:11985-12284 isActive: false numReads: 0; 12:06:02.022 DEBUG Mutect2 - Processing assembly region at chrM:12285-12584 isActive: false numReads: 0; 12:06:03.941 DEBUG Mutect2 - Processing assembly region at chrM:12585-12729 isActive: false numReads: 44205; 12:06:04.330 DEBUG Mutect2 - Processing assembly region at chrM:12730-13020 isActive: true numReads: 88386; 12:06:10.995 DEBUG ReadThreadingGraph - Recovered 11 of 15 dangling tails; 12:06:11.087 DEBUG ReadThreadingGraph - Recovered 7 of 36 dangling heads; 12:06:11.465 DEBUG Mutect2Engine - Active Region chrM:12730-13020; 12:06:11.470 DEBUG Mutect2Engine - Extended Act Region chrM:12630-13120; 12:06:11.474 DEBUG Mutect2Engine - Ref haplotype coords chrM:12630-13120; 12:06:11.478 DEBUG Mutect2Engine - Haplotype count 128; 12:06:11.481 DEBUG Mutect2Engine - Kmer sizes count 0; 12:06:11.485 DEBUG Mutect2Engine - Kmer sizes values []; 12:08:48.420 DEBUG Mutect2 - Processing assembly region at chrM:13021-13320 isActive: false numReads: 44155; 12:08:49.628 INFO ProgressMeter - chrM:13021 33.1 50 1.5; 12:09:01.241 DEBUG Mutect2 - Processing assembly region at chrM:13321-13620 isActive: false numReads: 55070; 12:09:01.757 DEBUG Mutect2 - Processing assembly region at chrM:13621-13636 isActive: false numReads: 55240; 12:09:02.341 DEBUG Mutect2 - Processing assembly region at chrM:13637-13936 isActive: true numReads: 110273; 12:09:09.957 DEBUG Rea,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7281:19103,Recover,Recovered,19103,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7281,1,['Recover'],['Recovered']
Availability,"; 13:16:10.652 INFO gcnvkernel.tasks.inference_task_base -; Stderr: Traceback (most recent call last):; File ""/tmp/die9s/cohort_determine_ploidy_and_depth.861556744637254264.py"", line 106, in <module>; gcnvkernel.io_ploidy.PloidyModelWriter(ploidy_config, ploidy_workspace,; AttributeError: module 'gcnvkernel.io.io_ploidy' has no attribute 'PloidyModelWriter'. at org.broadinstitute.hellbender.utils.python.PythonExecutorBase.getScriptException(PythonExecutorBase.java:75); at org.broadinstitute.hellbender.utils.runtime.ScriptExecutor.executeCuratedArgs(ScriptExecutor.java:126); at org.broadinstitute.hellbender.utils.python.PythonScriptExecutor.executeArgs(PythonScriptExecutor.java:170); at org.broadinstitute.hellbender.utils.python.PythonScriptExecutor.executeScript(PythonScriptExecutor.java:151); at org.broadinstitute.hellbender.utils.python.PythonScriptExecutor.executeScript(PythonScriptExecutor.java:121); at org.broadinstitute.hellbender.tools.copynumber.DetermineGermlineContigPloidy.executeDeterminePloidyAndDepthPythonScript(DetermineGermlineContigPloidy.java:365); at org.broadinstitute.hellbender.tools.copynumber.DetermineGermlineContigPloidy.doWork(DetermineGermlineContigPloidy.java:263); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:134); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:179); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:198); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289); ```. I also know that I should post errors in the GATK forum, but when I do this I get the following error message :; ``` { ""Code"": 403, ""Exception"": ""You need the Garden.Community.Manage permission to do that."", ""Class"": ""Gdn_UserException"" }```. Thanks in advance; Stefan",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4679:2185,error,errors,2185,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4679,2,['error'],"['error', 'errors']"
Availability,"; 13:56:52.187 INFO GenotypeGVCFs - Picard Version: 2.22.8; 13:56:52.187 INFO GenotypeGVCFs - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 13:56:52.187 INFO GenotypeGVCFs - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 13:56:52.187 INFO GenotypeGVCFs - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 13:56:52.187 INFO GenotypeGVCFs - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 13:56:52.187 INFO GenotypeGVCFs - Deflater: IntelDeflater; 13:56:52.188 INFO GenotypeGVCFs - Inflater: IntelInflater; 13:56:52.188 INFO GenotypeGVCFs - GCS max retries/reopens: 20; 13:56:52.188 INFO GenotypeGVCFs - Requester pays: disabled; 13:56:52.188 INFO GenotypeGVCFs - Initializing engine; 13:56:53.115 INFO GenomicsDBLibLoader - GenomicsDB native library version : 1.3.0-e701905; [TileDB::Buffer] Error: Cannot read from buffer; End of buffer reached.; [TileDB::BookKeeping] Error: Cannot load book-keeping; Reading tile offsets failed.; 13:57:15.762 INFO GenotypeGVCFs - Shutting down engine; [December 21, 2020 1:57:15 PM CST] org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs done. Elapsed time: 0.40 minutes.; Runtime.totalMemory()=2119696384; ***********************************************************************. A USER ERROR has occurred: Couldn't create GenomicsDBFeatureReader. ***********************************************************************; org.broadinstitute.hellbender.exceptions.UserException: Couldn't create GenomicsDBFeatureReader; 	at org.broadinstitute.hellbender.engine.FeatureDataSource.getGenomicsDBFeatureReader(FeatureDataSource.java:410); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.getFeatureReader(FeatureDataSource.java:326); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:282); 	at org.broadinstitute.hellbender.engine.VariantLocusWalker.initializeDrivingVariants(VariantLocusWalker.java:76); 	at org.broadinstitute.hellbender.engine.VariantWalkerBase.initializeFeatures(VariantWalkerBa",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7012:3304,down,down,3304,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7012,1,['down'],['down']
Availability,"; 18/04/23 20:42:02 INFO StandaloneSchedulerBackend: Shutting down all executors; 18/04/23 20:42:02 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down; 18/04/23 20:42:03 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 18/04/23 20:42:03 INFO MemoryStore: MemoryStore cleared; 18/04/23 20:42:03 INFO BlockManager: BlockManager stopped; 18/04/23 20:42:03 INFO BlockManagerMaster: BlockManagerMaster stopped; 18/04/23 20:42:03 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 18/04/23 20:42:03 INFO SparkContext: Successfully stopped SparkContext; 20:42:03.045 INFO PathSeqPipelineSpark - Shutting down engine; [April 23, 2018 8:42:03 PM CEST] org.broadinstitute.hellbender.tools.spark.pathseq.PathSeqPipelineSpark done. Elapsed time: 0.43 minutes.; Runtime.totalMemory()=793247744; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 0.0 failed 4 times, most recent failure: Lost task 0.3 in stage 0.0 (TID 3, xx.xx.xx.xx, executor 0): java.lang.IllegalStateException: unread block data; at java.io.ObjectInputStream$BlockDataInputStream.setBlockDataMode(ObjectInputStream.java:2740); at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1567); at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245); at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169); at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027); at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535); at java.io.ObjectInputStream.readObject(ObjectInputStream.java:422); at org.apache.spark.serializer.JavaDeserializationStream.readObject(JavaSerializer.scala:75); at org.apache.spark.serializer.JavaSerializerInstance.deserialize(JavaSerializer.scala:114); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:309); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694:17652,failure,failure,17652,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694,1,['failure'],['failure']
Availability,"; 18/04/24 17:56:39 INFO StandaloneSchedulerBackend: Shutting down all executors; 18/04/24 17:56:39 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down; 18/04/24 17:56:39 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 18/04/24 17:56:39 INFO MemoryStore: MemoryStore cleared; 18/04/24 17:56:39 INFO BlockManager: BlockManager stopped; 18/04/24 17:56:39 INFO BlockManagerMaster: BlockManagerMaster stopped; 18/04/24 17:56:39 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 18/04/24 17:56:39 INFO SparkContext: Successfully stopped SparkContext; 17:56:39.758 INFO PathSeqPipelineSpark - Shutting down engine; [April 24, 2018 5:56:39 PM CEST] org.broadinstitute.hellbender.tools.spark.pathseq.PathSeqPipelineSpark done. Elapsed time: 1.75 minutes.; Runtime.totalMemory()=821559296; org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 2.0 failed 4 times, most recent failure: Lost task 1.3 in stage 2.0 (TID 10, xx.xx.xx.16, executor 3): org.broadinstitute.hellbender.exceptions.UserException$CouldNotReadInputFile: Couldn't read file. Error was: hg19mini.hss with exception: hg19mini.hss (No such file or directory); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:112); at org.broadinstitute.hellbender.tools.spark.pathseq.PSKmerUtils.readKmerFilter(PSKmerUtils.java:131); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilter.<init>(ContainsKmerReadFilter.java:27); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:35); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:15); at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78); at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78); at scala.collection.Iterator$$a",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4699:38384,failure,failure,38384,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4699,1,['failure'],['failure']
Availability,"; 2019-10-29T18:18:04.002740306Z 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); 2019-10-29T18:18:04.002745164Z 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); 2019-10-29T18:18:04.002777218Z 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); 2019-10-29T18:18:04.002785268Z 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:162); 2019-10-29T18:18:04.002855927Z 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:205); 2019-10-29T18:18:04.002867030Z 	at org.broadinstitute.hellbender.Main.main(Main.java:291); ```; I am using ExAC lifted to hg38 as a germline resource in mutect2 with only a tumor sample, and getting the above error in filtermutectcalls. I recently updated to v4.1.3.0 to have the latest changes to mutect2. I was not having this issue with v4.0.5.1. Here is extracted information from the VCF which caused the issue. . ```; DP=1;ECNT=2;FS=0.000;MBQ=0,20;MFRL=0,91;MMQ=60,46;MPOS=6;MQ=46.00;POPAF=5.08;TLOD=4.20	GT:AD:AF:DP:F1R2:F2R1:PGT:PID:PS:SB	0|1:0,1:0.667:1:0,1:0,0:0|1:11155815_C_T:11155815:0,0,1,0; DP=1;ECNT=2;FS=0.000;MBQ=0,20;MFRL=0,91;MMQ=60,46;MPOS=16;MQ=46.00;POPAF=5.08;TLOD=4.20	GT:AD:AF:DP:F1R2:F2R1:PGT:PID:PS:SB	0|1:0,1:0.667:1:0,1:0,0:0|1:11155815_C_T:11155815:0,0,1,0; DP=1;ECNT=2;FS=0.000;MBQ=0,34;MFRL=0,272;MMQ=60,30;MPOS=25;MQ=30.00;POPAF=4.13;TLOD=4.20	GT:AD:AF:DP:F1R2:F2R1:PGT:PID:PS:SB	0|1:0,1:0.667:1:0,1:0,0:0|1:11350899_C_T:11350899:0,0,1,0; DP=1;ECNT=2;FS=0.000;MBQ=0,32;MFRL=0,272;MMQ=60,30;MPOS=15;MQ=30.00;POPAF=4.23;TLOD=4.20	GT:AD:AF:DP:F1R2:F2R1:PGT:PID:PS:SB	0|1:0,1:0.667:1:0,1:0,0:0|1:11350899_C_T:11350899:0,0,1,0; ```. Additionally, I tried to re-run this sample without the germline resource and encountered the same error. . _Originally posted by @MikeWLloyd in https://github.com/broadinstitute/gatk/issues/5821#issuecomment-547566300_",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6237:6331,error,error,6331,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6237,1,['error'],['error']
Availability,; 22:01:54.381 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr1_KI270706v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.381 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr1_KI270707v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.381 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr1_KI270708v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.381 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr1_KI270709v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr1_KI270710v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr1_KI270711v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr1_KI270712v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr1_KI270713v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr1_KI270714v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr2_KI270715v1_random).,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4840:1615,reliab,reliable,1615,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4840,1,['reliab'],['reliable']
Availability,; 22:01:54.381 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr1_KI270707v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.381 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr1_KI270708v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.381 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr1_KI270709v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr1_KI270710v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr1_KI270711v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr1_KI270712v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr1_KI270713v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr1_KI270714v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr2_KI270715v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr2_KI270716v1_random).,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4840:1824,reliab,reliable,1824,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4840,1,['reliab'],['reliable']
Availability,; 22:01:54.381 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr1_KI270708v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.381 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr1_KI270709v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr1_KI270710v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr1_KI270711v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr1_KI270712v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr1_KI270713v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr1_KI270714v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr2_KI270715v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr2_KI270716v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr3_GL000221v1_random).,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4840:2033,reliab,reliable,2033,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4840,1,['reliab'],['reliable']
Availability,; 22:01:54.381 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr1_KI270709v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr1_KI270710v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr1_KI270711v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr1_KI270712v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr1_KI270713v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr1_KI270714v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr2_KI270715v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr2_KI270716v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr3_GL000221v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr4_GL000008v2_random).,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4840:2242,reliab,reliable,2242,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4840,1,['reliab'],['reliable']
Availability,; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr1_KI270710v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr1_KI270711v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr1_KI270712v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr1_KI270713v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr1_KI270714v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr2_KI270715v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr2_KI270716v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr3_GL000221v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr4_GL000008v2_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr5_GL000208v1_random).,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4840:2451,reliab,reliable,2451,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4840,1,['reliab'],['reliable']
Availability,; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr1_KI270711v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr1_KI270712v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr1_KI270713v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr1_KI270714v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr2_KI270715v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr2_KI270716v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr3_GL000221v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr4_GL000008v2_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr5_GL000208v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr9_KI270717v1_random).,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4840:2660,reliab,reliable,2660,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4840,1,['reliab'],['reliable']
Availability,; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr1_KI270712v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr1_KI270713v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr1_KI270714v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr2_KI270715v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr2_KI270716v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr3_GL000221v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr4_GL000008v2_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr5_GL000208v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr9_KI270717v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr9_KI270718v1_random).,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4840:2869,reliab,reliable,2869,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4840,1,['reliab'],['reliable']
Availability,; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr1_KI270713v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr1_KI270714v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr2_KI270715v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr2_KI270716v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr3_GL000221v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr4_GL000008v2_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr5_GL000208v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr9_KI270717v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr9_KI270718v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr9_KI270719v1_random).,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4840:3078,reliab,reliable,3078,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4840,1,['reliab'],['reliable']
Availability,; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr1_KI270714v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr2_KI270715v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr2_KI270716v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr3_GL000221v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr4_GL000008v2_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr5_GL000208v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr9_KI270717v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr9_KI270718v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr9_KI270719v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr9_KI270720v1_random).,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4840:3287,reliab,reliable,3287,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4840,1,['reliab'],['reliable']
Availability,; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr2_KI270715v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr2_KI270716v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr3_GL000221v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr4_GL000008v2_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr5_GL000208v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr9_KI270717v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr9_KI270718v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr9_KI270719v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr9_KI270720v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr11_KI270721v1_random),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4840:3496,reliab,reliable,3496,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4840,1,['reliab'],['reliable']
Availability,; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr2_KI270716v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr3_GL000221v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr4_GL000008v2_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr5_GL000208v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr9_KI270717v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr9_KI270718v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr9_KI270719v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr9_KI270720v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr11_KI270721v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_GL000009v2_random,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4840:3705,reliab,reliable,3705,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4840,1,['reliab'],['reliable']
Availability,; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr3_GL000221v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr4_GL000008v2_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr5_GL000208v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr9_KI270717v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr9_KI270718v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr9_KI270719v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr9_KI270720v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr11_KI270721v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_GL000009v2_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_GL000225v1_rando,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4840:3914,reliab,reliable,3914,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4840,1,['reliab'],['reliable']
Availability,; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr4_GL000008v2_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr5_GL000208v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr9_KI270717v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr9_KI270718v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr9_KI270719v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr9_KI270720v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr11_KI270721v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_GL000009v2_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_GL000225v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_KI270722v1_rand,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4840:4123,reliab,reliable,4123,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4840,1,['reliab'],['reliable']
Availability,; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr5_GL000208v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr9_KI270717v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr9_KI270718v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr9_KI270719v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr9_KI270720v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr11_KI270721v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_GL000009v2_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_GL000225v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_KI270722v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_GL000194v1_ran,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4840:4332,reliab,reliable,4332,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4840,1,['reliab'],['reliable']
Availability,"; 22:05:55.943 [DEBUG] [org.gradle.configuration.project.BuildScriptProcessor] Timing: Running the build script took 12.879 secs; 22:05:55.952 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] ; 22:05:55.954 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] FAILURE: Build failed with an exception.; 22:05:55.955 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] ; 22:05:55.956 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] * Where:; 22:05:55.956 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] Build file '/scratch/var/tmp/portage/sci-biology/gatk-9999/work/gatk-9999/build.gradle' line: 102; 22:05:55.964 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] ; 22:05:55.964 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] * What went wrong:; 22:05:55.966 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] A problem occurred evaluating root project 'gatk'.; 22:05:55.966 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] > Execution of ""git lfs pull --include src/main/resources/large"" failed with exit code: 2. git-lfs is required to build GATK but may not be installed. See https://github.com/broadinstitute/gatk#building for information on how to build GATK.; 22:05:55.967 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] ; 22:05:55.968 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] * Exception is:; 22:05:55.969 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] org.gradle.api.GradleScriptException: A problem occurred evaluating root project 'gatk'.; 22:05:55.969 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.groovy.scripts.internal.DefaultScriptRunnerFactory$ScriptRunnerImpl.run(DefaultScriptRunnerFactory.java:92); 22:05:55.969 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.DefaultScriptPluginFactory$ScriptPluginImpl$2.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4687:1329,ERROR,ERROR,1329,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4687,1,['ERROR'],['ERROR']
Availability,"; INFO 10:47:56,333 SAMDataSource$SAMReaders - Done initializing BAM readers: total time 0.07 ; ##### ERROR ------------------------------------------------------------------------------------------; ##### ERROR A USER ERROR has occurred (version 3.8-0-ge9d806836): ; ##### ERROR; ##### ERROR This means that one or more arguments or inputs in your command are incorrect.; ##### ERROR The error message below tells you what is the problem.; ##### ERROR; ##### ERROR If the problem is an invalid argument, please check the online documentation guide; ##### ERROR (or rerun your command with --help) to view allowable command-line arguments for this tool.; ##### ERROR; ##### ERROR Visit our website and forum for extensive documentation and answers to ; ##### ERROR commonly asked questions https://software.broadinstitute.org/gatk; ##### ERROR; ##### ERROR Please do NOT post this error to the GATK forum unless you have really tried to fix it yourself.; ##### ERROR; ##### ERROR MESSAGE: Input files reads and reference have incompatible contigs. Please see https://software.broadinstitute.org/gatk/documentation/article?id=63for more information. Error details: No overlapping contigs found.; ##### ERROR reads contigs = [LmjF04_01_20050601_V5.2, LmjF05_01_20050601_V5.2, LmjF24_01_20050601_V5.2, LmjF01_01_20050601_V5.2, LmjF03_01_20050601_V5.2, LmjF13_01_20050601_V5.2, LmjF14_01_20050601_V5.2, LmjF19_01_20050601_V5.2, LmjF21_01_20050601_V5.2, LmjF23_01_20050601_V5.2, LmjF10_01_20050601_V5.2, LmjF11_01_20050601_V5.2, LmjF15_01_20050601_V5.2, LmjF18_01_20050601_V5.2, LmjF02_01_20050601_V5.2, LmjF25_01_20050601_V5.2, LmjF27_01_20050601_V5.2, LmjF28_01_20050601_V5.2, LmjF29_01_20050601_V5.2, LmjF30_01_20050601_V5.2, LmjF31_01_20050601_V5.2, LmjF32_01_20050601_V5.3, LmjF33_01_20050601_V5.2, LmjF34_01_20050601_V5.2, LmjF35_01_20050601_V5.2, LmjF36_01_20050601_V5.2, LmjF07_01_20050601_V5.2, LmjF08_01_20050601_V5.2, LmjF09_01_20050601_V5.2, LmjF06_01_20050601_V5.2, LmjF12_01_20050601_V5.2, L",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6798:3489,ERROR,ERROR,3489,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6798,2,['ERROR'],['ERROR']
Availability,"; [September 3, 2024 at 9:55:50 AM CST] org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs done. Elapsed time: 0.02 minutes.; Runtime.totalMemory()=1241513984; java.lang.RuntimeException: Invalid deflate block found.; at com.intel.gkl.compression.IntelInflater.inflateNative(Native Method); at com.intel.gkl.compression.IntelInflater.inflate(IntelInflater.java:176); at htsjdk.samtools.util.BlockGunzipper.unzipBlock(BlockGunzipper.java:145); at htsjdk.samtools.util.BlockGunzipper.unzipBlock(BlockGunzipper.java:96); at htsjdk.samtools.util.BlockCompressedInputStream.inflateBlock(BlockCompressedInputStream.java:561); at htsjdk.samtools.util.BlockCompressedInputStream.processNextBlock(BlockCompressedInputStream.java:543); at htsjdk.samtools.util.BlockCompressedInputStream.nextBlock(BlockCompressedInputStream.java:479); at htsjdk.samtools.util.BlockCompressedInputStream.readBlock(BlockCompressedInputStream.java:469); at htsjdk.samtools.util.BlockCompressedInputStream.available(BlockCompressedInputStream.java:207); at htsjdk.samtools.util.BlockCompressedInputStream.read(BlockCompressedInputStream.java:342); at htsjdk.samtools.util.BlockCompressedInputStream.read(BlockCompressedInputStream.java:268); at htsjdk.tribble.readers.PositionalBufferedStream.fill(PositionalBufferedStream.java:132); at htsjdk.tribble.readers.PositionalBufferedStream.read(PositionalBufferedStream.java:84); at java.base/sun.nio.cs.StreamDecoder.readBytes(StreamDecoder.java:270); at java.base/sun.nio.cs.StreamDecoder.implRead(StreamDecoder.java:313); at java.base/sun.nio.cs.StreamDecoder.read(StreamDecoder.java:188); at java.base/java.io.InputStreamReader.read(InputStreamReader.java:177); at htsjdk.tribble.readers.LongLineBufferedReader.fill(LongLineBufferedReader.java:140); at htsjdk.tribble.readers.LongLineBufferedReader.readLine(LongLineBufferedReader.java:300); at htsjdk.tribble.readers.LongLineBufferedReader.readLine(LongLineBufferedReader.java:356); at htsjdk.tribble.readers.SynchronousLineR",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8969:4280,avail,available,4280,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8969,1,['avail'],['available']
Availability,"; at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); 16/01/21 14:55:33 INFO ShutdownHookManager: Shutdown hook called; ```. Attached is a small BAM file that I used to reproduce the error (If memory serves, I've seen this issue on other BAM files as well):. [NA12878.chrom20.100kb.ILLUMINA.bwa.CEU.exome.20121211.bam.zip](https://github.com/broadinstitute/gatk/files/101575/NA12878.chrom20.100kb.ILLUMINA.bwa.CEU.exome.20121211.bam.zip). (This issue may be related to one posted here: https://github.com/broadinstitute/gatk/issues/1417.). Here is some information on what I installed:. ```; echo ""Installing Java""; sudo add-apt-repository -y ppa:webupd8team/java; sudo apt-get -qq update; echo debconf shared/accepted-oracle-license-v1-1 select true | sudo debconf-set-selections; echo debconf shared/accepted-oracle-license-v1-1 seen true | sudo debconf-set-selections; sudo apt-get -qq install -y oracle-java8-installer. java -version. echo ""Installing Gradle""; sudo add-apt-repository -y ppa:cwchien/gradle; sudo apt-get -qq update > /dev/null; sudo apt-get -qq install -y gradle. echo ""Downloading binaries for Spark""; wget http://d3kbcqa49mib13.cloudfront.net/spark-1.5.1-bin-hadoop2.6.tgz; tar -xzf spark-1.5.1-bin-hadoop2.6.tgz; export SPARK_HOME=spark-1.5.1-bin-hadoop2.6. echo ""Set up Spark for standalone mode processing""; $SPARK_HOME/sbin/start-master.sh -h localhost; $SPARK_HOME/sbin/start-slave.sh spark://localhost:7077. echo ""Downloading source for GATK4""; wget https://github.com/broadinstitute/gatk/archive/4.alpha.tar.gz; tar -xvzf 4.alpha.tar.gz; export GATK_DIR=gatk-4.alpha. echo ""Building GATK4""; cd $GATK_DIR; gradle installAll; cd .. ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1444:3876,echo,echo,3876,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1444,10,"['Down', 'echo']","['Downloading', 'echo']"
Availability,"> Gradle test org.broadinstitute.hellbender.transformers.MisencodedBaseQualityReadTransformerUnitTest.testFixBadQuals FAILED; > ; > ```; > java.lang.AssertionError: arrays differ firstly at element [0]; expected value is <28> but was <-3>. ; > at org.testng.Assert.fail(Assert.java:94); > at org.testng.Assert.assertEquals(Assert.java:772); > at org.testng.Assert.assertEquals(Assert.java:746); > at org.broadinstitute.hellbender.transformers.MisencodedBaseQualityReadTransformerUnitTest.testFixBadQuals(MisencodedBaseQualityReadTransformerUnitTest.java:73); > ```; > ; > 180309 tests completed, 1 failed; > :test FAILED; > ; > FAILURE: Build failed with an exception. This was running on the current master without parallelism. . @droazen Is this the same failure you saw before?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/311:628,FAILURE,FAILURE,628,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/311,2,"['FAILURE', 'failure']","['FAILURE', 'failure']"
Availability,"@LeeTL1220 This consists of a lot of trivial changes where the commit message is self-explanatory, most of which (eg indentation) yield big diffs. Basically it comes down to:; * M2 wdls have better formatting; * autoval works in the cloud; * gatk launch script and docker jar are used properly in all M2 wdls, including the unsupported ones.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4132:166,down,down,166,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4132,1,['down'],['down']
Availability,"@LeeTL1220 commented on [Mon Feb 01 2016](https://github.com/broadinstitute/gatk-protected/issues/343). In `CreatePanelOfNormals` make anonymize a flag that defaults to `false`. (i.e. `--anonymize`) In other words, by default, we do _not_ produce an anonymized PoN. We could also use a separate tool that takes a pre-existing PoN and anonymizes it. . To anonymize a PoN:; - [ ] Determine which fields are private. At the very least: `fnt_control_matrix`, `log_normals`, and `log_normals_pinv`. _There may be others -- please investigate as part of this issue_; - [ ] Have `CreatePanelOfNormals` delete the fields as the last step.; - [ ] Make sure that `HDF5PoN` produces reasonable error messages if one of these fields is accessed in an anonymized PoN.; - [ ] Create CLI that can take existing PoN and delete the fields. ---. @LeeTL1220 commented on [Mon Feb 01 2016](https://github.com/broadinstitute/gatk-protected/issues/343#issuecomment-178022285). This is necessary since we may want to share PoNs and the PoN files cannot have any private data. ---. @LeeTL1220 commented on [Wed Mar 02 2016](https://github.com/broadinstitute/gatk-protected/issues/343#issuecomment-191420153). Moving this to later milestone, unless it becomes more urgent.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2835:683,error,error,683,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2835,1,['error'],['error']
Availability,"@LeeTL1220 commented on [Tue Mar 14 2017](https://github.com/broadinstitute/gatk-protected/issues/937). By grabbing the gatk-protected docker image (or whichever is being used for M2), this task commits to a ~2GB download. However, the task does basic bash commands, which could easily be performed using one of the ``ubuntu:14.04`` images or maybe even one smaller.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2952:213,down,download,213,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2952,1,['down'],['download']
Availability,"@LeeTL1220 mentioned having difficulty running gCNV on REBC WGS normals. As far as I can tell, other than runs failing due to quota or FC issues, there were some runs that failed because the WDL version and the Docker version were not in sync. Specifically, these runs failed because the WDL was more recent than the Docker, causing the ScatterIntervals task (which was running an out-of-date IntervalListTools in the latter) to ""fail silently"". The behavior upon failure, for reasons due to the somewhat awkward format of the IntervalListTools output, is to output just a single shard by simply copying the original intervals list; this is handled in bash. This single-shard run then failed due to OOM in the gCNV step. Just to be clear, everything typically works fine when the versions are in sync. But you could imagine that even then IntervalListTools could fail for other reasons, in which case we'd probably fail misleadingly at the gCNV step again. So let's modify the WDL so we fail at the appropriate place. Apologies to @asmirnov239, who I think pointed this weirdness out in the original PR review.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5744:464,failure,failure,464,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5744,1,['failure'],['failure']
Availability,"@SHuang-Broad reports having problems running spark tests when his machine is connected to the broad vpn. Errors seem to occur with any tests that start a spark context. They all seem to be caused by `java.net.BindException`. ```; 23:59:49.200 ERROR NettyTransport:65 - failed to bind to /10.1.2.144:0, shutting down Netty transport; 23:59:49.200 WARN Utils:71 - Service 'sparkDriver' could not bind on port 0. Attempting port 1.; 23:59:49.200 ERROR Remoting:65 - Remoting system has been terminated abrubtly. Attempting to shut down transports; 23:59:49.206 ERROR NettyTransport:65 - failed to bind to /10.1.2.144:0, shutting down Netty transport; 23:59:49.206 ERROR SparkContext:96 - Error initializing SparkContext.; java.net.BindException: Failed to bind to: /10.1.2.144:0: Service 'sparkDriver' failed after 16 retries!; at org.jboss.netty.bootstrap.ServerBootstrap.bind(ServerBootstrap.java:272); at akka.remote.transport.netty.NettyTransport$$anonfun$listen$1.apply(NettyTransport.scala:393); at akka.remote.transport.netty.NettyTransport$$anonfun$listen$1.apply(NettyTransport.scala:389); at scala.util.Success$$anonfun$map$1.apply(Try.scala:206); at scala.util.Try$.apply(Try.scala:161); at scala.util.Success.map(Try.scala:206); at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:235); at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:235); at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32); at akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55); at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply$mcV$sp(BatchingExecutor.scala:91); at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply(BatchingExecutor.scala:91); at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply(BatchingExecutor.scala:91); at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:72); at akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:90); at akka.dispatch.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1534:106,Error,Errors,106,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1534,9,"['ERROR', 'Error', 'down']","['ERROR', 'Error', 'Errors', 'down']"
Availability,"@TianJin297 commented on [Fri May 26 2017](https://github.com/broadinstitute/gatk-protected/issues/1107). When I was running HaplotypeCallorSpark with one of my samples, I got an error as ""Duplicate key"". . The command I used is ""/gatk-protected HaplotypeCallerSpark -I XX_BQSRappliedspark.bam -O XX_525.gvcf -R /curr/data/humann_g1k_v37.2bit --emitRefConfidence BP_RESOLUTION --TMP_DIR tmp"". And it runs on Amazon instance m4.2xlarge. 00:10:41.089 WARN StrandBiasBySample - Annotation will not be calculated, genotype is not called or alleleLikelihoodMap is null; 00:10:41.089 WARN DepthPerSampleHC - Annotation will not be calculated, genotype is not called or alleleLikelihoodMap is null; 00:10:41.089 WARN StrandBiasBySample - Annotation will not be calculated, genotype is not called or alleleLikelihoodMap is null; 00:10:45.460 WARN DepthPerSampleHC - Annotation will not be calculated, genotype is not called or alleleLikelihoodMap is null; 00:10:45.460 WARN StrandBiasBySample - Annotation will not be calculated, genotype is not called or alleleLikelihoodMap is null; 00:11:09.609 WARN TaskMemoryManager:381 - leak 166.6 MB memory from org.apache.spark.util.collection.ExternalAppendOnlyMap@60a3c432; 00:11:09.611 ERROR Executor:91 - Exception in task 15.0 in stage 1.0 (TID 519); java.lang.IllegalStateException: Duplicate key [B@4e233a3c; at java.util.stream.Collectors.lambda$throwingMerger$0(Collectors.java:133); at java.util.HashMap.merge(HashMap.java:1253); at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1320); at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3018:179,error,error,179,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3018,1,['error'],['error']
Availability,"@TianJin297 commented on [Fri May 26 2017](https://github.com/broadinstitute/gatk-protected/issues/1108). The command is gatk-protected HaplotypeCallerSpark -I XX_BQSRappliedspark.bam -O XX_spark.vcf -R /curr/data/humann_g1k_v37.2bit --emitRefConfidence GVCF --TMP_DIR tmp. And it is run on an Amazon m4.2xlarge instance. The error messages are like below.; 04:39:06.415 WARN StrandBiasBySample - Annotation will not be calculated, genotype is not called or alleleLikelihoodMap is null; 05:09:00.269 ERROR Executor:91 - Exception in task 8.0 in stage 1.0 (TID 345); java.lang.ArrayIndexOutOfBoundsException: 16777215; at com.esotericsoftware.kryo.util.IdentityObjectIntMap.clear(IdentityObjectIntMap.java:382); at com.esotericsoftware.kryo.util.MapReferenceResolver.reset(MapReferenceResolver.java:65); at com.esotericsoftware.kryo.Kryo.reset(Kryo.java:865); at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:630); at org.apache.spark.serializer.KryoSerializerInstance.serialize(KryoSerializer.scala:297); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:313); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748); 05:09:00.455 WARN TaskSetManager:66 - Lost task 8.0 in stage 1.0 (TID 345, localhost): java.lang.ArrayIndexOutOfBoundsException: 16777215; at com.esotericsoftware.kryo.util.IdentityObjectIntMap.clear(IdentityObjectIntMap.java:382); at com.esotericsoftware.kryo.util.MapReferenceResolver.reset(MapReferenceResolver.java:65); at com.esotericsoftware.kryo.Kryo.reset(Kryo.java:865); at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:630); at org.apache.spark.serializer.KryoSerializerInstance.serialize(KryoSerializer.scala:297); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:313); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3019:326,error,error,326,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3019,2,"['ERROR', 'error']","['ERROR', 'error']"
Availability,@ahaessly Could you please take a look at this? I'd appreciate it if you would also look at the expected output and make sure those intervals make sense since I don't think that aspect of the code was previously tested and I want to be sure there are no off by one style errors.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8070:271,error,errors,271,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8070,1,['error'],['errors']
Availability,"@akiezun @lbergelson Changed the Spark context configuration from ""local[*]"" to ""local[N]"", where N is specified by a environmental variable. Ran gradle test with ""--tests _SparkIntegration_"". Out of 203 tests, one failed: "" testBulkFragmentsNoDuplicates"", the rest passed. Here is the snippet of code change. Any suggestions?. ```; private static JavaSparkContext createTestSparkContext(Map<String, String> overridingProperties) {; determineSparkMaster();; final SparkConf sparkConf = setupSparkConf(""TestContext"", DEFAULT_SPARK_MASTER, DEFAULT_TEST_PROPERTIES, overridingProperties);; return new JavaSparkContext(sparkConf);; }. /**; * Determine the number of cores Spark master should use. Only used in Spark Test; * Read the specification from the environmental variable GATK_TEST_SPARK_CORES; * If the value is a valid positive integer, use it; * If the value is bogus (strings, etc), or the env. var. is not set, use all available cores, as in ""local[*]""; */. private static void determineSparkMaster() {; int foo = 0;; try {; foo = Integer.parseInt( System.getenv(""GATK_TEST_SPARK_CORES"") );; } catch ( NumberFormatException e ) {}; String numSparkCores;; if ( foo > 0 ) {; numSparkCores = String.format(""[%d]"", foo);; } else {; numSparkCores = ""[*]"";; }; DEFAULT_SPARK_MASTER = ""local"" + numSparkCores;; }. ```. Error messages:. ```; java.lang.NullPointerException at org.broadinstitute.hellbender.engine.spark.SparkContextFactory.getSparkContext(SparkContextFactory.java:77); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:36); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:102); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:155); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:174); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:67); at org.broadinstitute.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1768:927,avail,available,927,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1768,1,['avail'],['available']
Availability,"@akiezun commented on [Wed Oct 28 2015](https://github.com/broadinstitute/gatk-protected/issues/169). all parts that are a) mature enough b) shared between germline and somatic CNVs should be moved to the public gatk repo. . OK to do past alpha. ---. @akiezun commented on [Wed Nov 04 2015](https://github.com/broadinstitute/gatk-protected/issues/169#issuecomment-153783985). @LeeTL1220 @vruano can you list here the name of the subcomponents that would be pushed down to gatk public?; A lot of code would qualify I think: Targets, Segments, etc.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2827:464,down,down,464,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2827,1,['down'],['down']
Availability,"@bshifaw found this bug in the M2 wdl where it requests eg 3500 GB of RAM instead of 3500 MB, causing disastrous ""no machines available"" errors. @LeeTL1220 any way to get this into a release?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4321:126,avail,available,126,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4321,2,"['avail', 'error']","['available', 'errors']"
Availability,"@chandrans commented on [Mon May 23 2016](https://github.com/broadinstitute/gsa-unstable/issues/1382). ## Feature request. A user has reported ASEReadCounter counts homozygous sites as having potential ASE. This should not be the case, as only heterozygous sites should be counted. The user should input a VCF sites file with only heterozygous sites, but sometimes that doesn't happen, so there should be an error message when he or she does not. ; ### Tool(s) involved. ASEReadCounter; ### Description. There needs to be an error message telling the user he/she needs to subset the sites VCF to only heterozygous sites. ---. @vdauwera commented on [Mon Nov 14 2016](https://github.com/broadinstitute/gsa-unstable/issues/1382#issuecomment-260490723). May want to move this to GATK4, waiting for @meganshand to opine. . ---. @meganshand commented on [Tue Nov 15 2016](https://github.com/broadinstitute/gsa-unstable/issues/1382#issuecomment-260648100). Yeah, let's move it to GATK4 and incorporate porting it in the first place.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2265:408,error,error,408,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2265,2,['error'],['error']
Availability,"@chandrans commented on [Tue Feb 20 2018](https://github.com/broadinstitute/gsaweb/issues/89). ## Feature request. ### Tool(s) involved; CollectRnaSeqMetrics. ### Description; In Picard standalone version 2.16.0, --IGNORE_SEQUENCE is not required, but in GATK4 version, it is required and fails with an error if not provided. This should be an optional argument. This Issue was generated from your [forums] ; [forums]: https://gatkforums.broadinstitute.org/gatk/discussion/comment/46016#Comment_46016",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4427:303,error,error,303,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4427,1,['error'],['error']
Availability,"@cmnbroad @droazen Didn't realize that I accidentally omitted the `fullName` when specifying the sequence-dictionary argument for PlotModeledSegments:. @Argument(; doc = PlottingUtils.SEQUENCE_DICTIONARY_DOC_STRING,; shortName = StandardArgumentDefinitions.SEQUENCE_DICTIONARY_NAME; ); private File inputSequenceDictionaryFile;. This works when called in WDL tests using the fullName `--sequenceDictionary` (which is why it slipped by me--I would've thought this should fail):. java -Xmx${command_mem}m -jar $GATK_JAR PlotModeledSegments \; --denoised-copy-ratios ${denoised_copy_ratios} \; --allelic-counts ${het_allelic_counts} \; --segments ${modeled_segments} \; --sequence-dictionary ${ref_fasta_dict} \; --minimum-contig-length ${default=""1000000"" minimum_contig_length} \; --output ${output_dir_} \; --output-prefix ${entity_id}. However, the argument names appear in the documentation as:. --inputSequenceDictionaryFile,-sequence-dictionary:File. And if the argument is not specified, this gives the error message:. A USER ERROR has occurred: Argument inputSequenceDictionaryFile was missing: Argument 'inputSequenceDictionaryFile' is required. Is this intended behavior? If so, please close, but it seems a little unexpected to me.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4049:1008,error,error,1008,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4049,2,"['ERROR', 'error']","['ERROR', 'error']"
Availability,@cmnbroad reports that he's seeing out-of-memory errors when running the test suite locally. He says it could be a recently-introduced regression -- we should narrow it down to a single commit.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2484:49,error,errors,49,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2484,2,"['down', 'error']","['down', 'errors']"
Availability,"@cmnbroad, [a researcher has pointed out](https://gatkforums.broadinstitute.org/gatk/discussion/1319/collected-faqs-about-interval-lists#latest) that although GATK accepts both types of intervals lists (Picard-style & BED), Picard tools called through the GATK errors with a BED intervals list. Is it possible to amend this behavior so any intervals list GATK accepts, Picard-called-through-GATK also accepts? If not, please let us know (myself and @rcmajovski) so that we can update documentation. . Given BED is the more widely-used intervals format, it would be great if we enabled its use consistently in our tools. The downside is the lack of reference match checking. However, it seems the decision has already been made with GATK's acceptance of BED intervals. Let me know your thoughts.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5472:261,error,errors,261,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5472,2,"['down', 'error']","['downside', 'errors']"
Availability,"@cwhelan @tedsharpe please review. The pipeline tools are:; 1. PathSeqFilterSpark : quality/low-complexity/host read filtering; 2. PathSeqPathogenAlignSpark : bwa-mem aligner; 3. PathSeqClassifyReadsSpark : quantifies pathogen abundance. These are supported by utilities:; 4. PathSeqKmerSpark - creates kmer library (either a Hopscotch set or Bloom filter) used by Filter tool; 5. PathSeqBuildReferenceTaxonomy - creates a file containing taxonomic information for a given reference, required by ClassifyReads. tools.spark.pathseq package:; Contains all the tools. Static helper functions were put into PS<ToolName>Utils classes, eg PSFilterUtils contains functions used by PathSeqFilterSpark. PSUtils contains mostly functions that are used by more than one tool. There are a number of other ""PS"" classes for doing Bwa, taxonomy bookkeeping, and read classification. Also has the kmer and host alignment read filters. tools.spark.sv package:; Added base masking to SVKmerShort class. tools.spark.utils package:; Hopscotch set and Bloom filter for long primitives. Each type has a ""Large"" class for sets exceeding the maximum JVM array size (~2B).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2646:955,mask,masking,955,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2646,1,['mask'],['masking']
Availability,@cwhelan mentioned at @jamesemery's presentation last week that there are more efficient options available for getting data into HDFS. It's worth exploring these.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2014:97,avail,available,97,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2014,1,['avail'],['available']
Availability,"@davidbenjamin Discovered that importing hellbender as a dependency fails now that we have add spark dependencies. This is easily fixed by including the following (or it's non-gradle equivalent) in your build file, but it shouldn't be necessary. ```; maven {; url ""https://repository.cloudera.com/artifactory/cloudera-repos/"" // spark-dataflow; }; ```. We should update our artifact so that it includes the necessary information to download the spark dependencies.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/779:432,down,download,432,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/779,1,['down'],['download']
Availability,"@davidbenjamin Intellij pointed out this if statement to me as suspicious and I think it is. There are two arms of the second if statement that are guarded by `includeNonVariants`. However the second one can never be hit because if `includeNonVariants` you will already have chosen the first clause. Seems suspicious...; ```; if (regenotypedVC == null || (!GATKVariantContextUtils.isProperlyPolymorphic(regenotypedVC) && !includeNonVariants)) {; return null;; }; if (GATKVariantContextUtils.isProperlyPolymorphic(regenotypedVC) || includeNonVariants) {; // Note that reversetrimAlleles must be performed after the annotations are finalized because the reducible annotation data maps; // were generated and keyed on the un reverseTrimmed alleles from the starting VariantContexts. Thus reversing the order will make; // it difficult to recover the data mapping due to the keyed alleles no longer being present in the variant context.; final VariantContext withGenotypingAnnotations = addGenotypingAnnotations(originalVC.getAttributes(), regenotypedVC);; final VariantContext withAnnotations = annotationEngine.finalizeAnnotations(withGenotypingAnnotations, originalVC);; final int[] relevantIndices = regenotypedVC.getAlleles().stream().mapToInt(a -> originalVC.getAlleles().indexOf(a)).toArray();; final VariantContext trimmed = GATKVariantContextUtils.reverseTrimAlleles(withAnnotations);; final GenotypesContext updatedGTs = subsetAlleleSpecificFormatFields(outputHeader, trimmed.getGenotypes(), relevantIndices);; result = new VariantContextBuilder(trimmed).genotypes(updatedGTs).make();; } else if (includeNonVariants) {; result = originalVC;; } else {; return null;; }; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6109:835,recover,recover,835,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6109,1,['recover'],['recover']
Availability,@davidbenjamin Was familiarizing myself with `KBestHaplotypeFinder` and decided to take a crack at this issue. . I have no idea how much of a performance hit this will end up being at extreme sites. At worst it involves adding more paths into the priority queues than existed before which could slow down the whole search algorithm. . Fixes #5907,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5952:300,down,down,300,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5952,1,['down'],['down']
Availability,"@davidbenjamin commented on [Fri Sep 09 2016](https://github.com/broadinstitute/gatk-protected/issues/700). Currently, `Mutect2` hard filters a candidate somatic variant if any event occurs at the same locus in the panel of normal samples. The idea is to avoid false positive calls at inherently noisy sites. This approach is reasonable but perhaps we can improve it. Some thoughts:; - Asymptotically, as the size of the PoN goes to infinity eventually every site will have some event and we will filter out every variant. Obviously this is an unrealistic limit, but a model should always perform better with more data.; - It might be good to use the PoN to learn a probabilistic model of error at each site, similar to the tool EBCall which has been noted to perform quite well on indels.; - regardless of our model, we should consider alternatives to hard filtering, such as perhaps using the PoN to penalize a somatic quality score.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2891:689,error,error,689,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2891,1,['error'],['error']
Availability,"@davidbenjamin commented on [Sun May 28 2017](https://github.com/broadinstitute/gatk-protected/issues/1114). HaplotypeCaller and Mutect by default assemble reads with kmer sizes of 10 and 25. 10 seems extremely small given the low error rates of Illumina sequencing. It's worth investigating how the Mutect validations are affected by increasing these values. ---. @ldgauthier commented on [Tue May 30 2017](https://github.com/broadinstitute/gatk-protected/issues/1114#issuecomment-305032024). Investigate away, but keep in mind bigger kmers introduce more ""dangling tails"", which may end up dropping evidence at the ends of reads. If you end up diving into the assembly graphs, I'm happy to consult. It's a deep, dark rabbit hole, but I've been there before and I know the way. ;)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3024:231,error,error,231,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3024,1,['error'],['error']
Availability,"@davidbenjamin commented on [Thu Apr 20 2017](https://github.com/broadinstitute/gatk-protected/issues/994). The simplest idea is to take kmers (k = 5, 7, 10?) centered at variant positions and fit a distribution (beta distribution?) of artifact allele fractions for each kmer. . Back of the envelope: with k = 10 we have 4^10 ~ 1 million different kmers, so each kmer appears ~ 3000 times per genome or about 1 million times in our panel of normals. This is easily enough to fit the distribution of artifact fractions very precisely. In addition to beta distributions, we may wish to fit different distributions for artifact allele fractions, such as a mixture of no artifacts (other than base errors as expected from the base quals) and a beta.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2973:694,error,errors,694,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2973,1,['error'],['errors']
Availability,"@davidbenjamin commented on [Tue May 23 2017](https://github.com/broadinstitute/gatk-protected/issues/1094). In active region determination for Mutect, and I believe also HaplotypeCaller, we count soft clips as a potential sign of a variant. This is because the aligner might soft clip the last few bases of a read that follow a deletion rather than call the deletion. For example, if the reference and read are:. TTCCAGAGTGTGTCAC (reference); TTC____________GTCAC (read). the alignment might choose to soft clip the GTCAC rather than call a deletion on the CAGAGTGT. In somatic calling it is expensive to call too many active regions, so perhaps we should only count eg the soft-clipped bases GTCAC as evidence of variation if that kmer appears downstream in the reference. @fleharty is this understanding of soft-clips being possible deletions (but not insertions or SNVs) correct?. ---. @fleharty commented on [Wed May 24 2017](https://github.com/broadinstitute/gatk-protected/issues/1094#issuecomment-303733706). @davidbenjamin . I certainly agree with you that soft-clips can be due to deletions. It's not at all clear to me that they wouldn't happen with an insertion. Consider:. ---ATGAACAGATATAACAGAT (reference); ---ATGAA(AGGTAA)CAGATATAACAGAT (read). I don't see why a soft clip might not show up on this read after ATGAA.; I'm not really sure I understand why some things are soft-clipped to be honest. I've seen plenty of things that were soft-clipped, but appear to match the reference perfectly (maybe I'm remembering this incorrectly). I suspect that soft-clips are hardly ever correctly associated with SNVs though. ---. @davidbenjamin commented on [Wed May 24 2017](https://github.com/broadinstitute/gatk-protected/issues/1094#issuecomment-303771734). @fleharty Thanks for the input!. ---. @ldgauthier commented on [Thu May 25 2017](https://github.com/broadinstitute/gatk-protected/issues/1094#issuecomment-303996178). You'll also likely see a difference in behavior for exomes vs gen",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3014:746,down,downstream,746,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3014,1,['down'],['downstream']
Availability,"@davidbenjamin commented on [Wed May 24 2017](https://github.com/broadinstitute/gatk-protected/issues/1098). The telltale sign of a substitution error occurring on a single strand of DNA is that supporting evidence is all on forward strand read 1 and reverse strand read 2, or vice versa. This lends itself to a graphical model, the hyperparameters of which can be learned from the data. Further down the road, we might use a neural network to learn the context-specific risk of such artifacts and attach it to the Bayesian model for forward/reverse and read 1/read 2. This would be our first experience with a deep generative model.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3016:145,error,error,145,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3016,2,"['down', 'error']","['down', 'error']"
Availability,"@davidbenjamin what I was talking about earlier. It comes with the very nice side effect of pasting this to the command line output: ; ![Screenshot 2024-09-23 at 3 44 08 PM](https://github.com/user-attachments/assets/cbe824d1-755a-41d2-9647-31a14ae8a402); It also generally makes it much easier to track down ""what does mito mode change exactly again?""",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8986:304,down,down,304,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8986,1,['down'],['down']
Availability,"@dpmccabe commented on [Mon Apr 24 2017](https://github.com/broadinstitute/gatk-protected/issues/1008). (Very low-priority enhancement request). Allow GetBayesianHetCoverage's matched tumor-normal mode to run on multiple tumor samples matched to a single normal. The normal coverage pulldown and likelihood calculations really only need to be calculated and written to a file once. Alternatively, allow the user to specify a `normalHets` file instead of a BAM if one has already been generated. Thanks!. ---. @samuelklee commented on [Thu Apr 27 2017](https://github.com/broadinstitute/gatk-protected/issues/1008#issuecomment-297704915). We're slowly rebuilding the entire somatic pipeline. One change on the allelic side will be to simply collect allelic counts at all specified sites, rather than performing genotyping on all sites in matched normals and then collecting the corresponding tumor counts at het sites. . The CLI tool to do this (CollectAllelicCounts) is already merged, if you'd like to start using it. You'd only have to run this once on each BAM. The ultimate idea is that resulting allelic count files, along with the corresponding coverage files, could then be passed to a SomaticCNVCaller tool, along with the necessary annotations denoting whether they are tumor or normal. For now, you could probably insert a simple script that performs the genotyping step if you still want to use the rest of the old pipeline but avoid pulling down the normal multiple times.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2977:1453,down,down,1453,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2977,1,['down'],['down']
Availability,"@eddiebroad commented on [Thu Dec 01 2016](https://github.com/broadinstitute/gatk-protected/issues/806). An issue encountered with gatk-protected ""SparkGenomeReadCounts"" tool is a non-helpful ""null"" error message. A non-helpful error ""null"" message was printed by gatk-protected with the command-line below; during the course of trying to use it on/in FireCloud:. ```; + java -Xmx48g -jar fc-7ac504fc-7fe4-4bc1-89d3-7f16317b8ff4/eddie.jar SparkGenomeReadCounts --outputFile this.entity_id.coverage.tsv --reference fc-e2421839-93d5-4ed5-8861-593f00364e54/Homo_sapiens_assembly19.fasta --input firecloud-tcga-open-access/tutorial/bams/C835.HCC1143_BL.4.bam --binsize 5000; Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/cromwell_root/tmp; .....; ......; ......; proceeding with flushing remote transports.; ***********************************************************************. null. ***********************************************************************; ```. To try to make a more helpful error message appear I added a ""catch"" block after a call to runTool in instanceMainPostParseArgs in file CommandLineProgram.java and got a more helpful message about a missing dictionary file: . try {; return runTool();; } ; catch(Exception e) {; e.getStackTrace();; }. java.lang.RuntimeException: org.broadinstitute.hellbender.exceptions.UserException$MissingReferenceDictFile; 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:179); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:204); 	at org.broadinstitute.hellbender.Main.instanceMain(Main.java:95); 	at org.broadinstitute.hellbender.Main.instanceMain(Main.java:103); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:115); 	at org.broadinstitute.hellbender.Main.main(Main.java:152); Caused by: org.broadinstitute.hellbender.exceptions.UserException$MissingReferenceDictFile; 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2922:199,error,error,199,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2922,2,['error'],['error']
Availability,@gspowley can you review and/or delegate to Eric and Lucy?. I confirmed the speedup on MarkDuplicatesSpark - from 9:23 down to 8:54 seconds,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1874:119,down,down,119,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1874,1,['down'],['down']
Availability,"@jamesemery Could you review this? I think you may appreciate it. It took several tries, but I was finally able to write a stripped-down version of the code that actually slightly outperforms the old version. What I realized after a lot of profiling the old code and various failed rewrites was that cache-friendliness is the critical thing here. It turns out that this can be achieved without too many buffers, without precomputing the log frequencies, and without storing 2D and 3D arrays as flattened 1D arrays.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6351:132,down,down,132,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6351,1,['down'],['down']
Availability,"@jamesemery Here is the bug fix. It's working on a lot of bams. It all comes down to keeping anything ref-consuming in an alt haplotype's cigar, even leading/trailing deletions. My mistake earlier was to treat haplotype cigars like read cigars.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6544:77,down,down,77,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6544,1,['down'],['down']
Availability,"@jamesemery The fun begins. No change in output yet, but a non-trivial change in implementation. Instead of making preliminary event groups according to overlap, then merging them according to mutually excluded events, this PR does it all in one step while automatically handling transitivity by treating as a matter of finding connected components of a graph whose vertices are events and whose edges are reasons (overlap and mutex) for events to be in the same event group. All the failures are from WDL tests. I assume those are not related.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8366:484,failure,failures,484,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8366,1,['failure'],['failures']
Availability,"@kcibul encountered the following transient error when running GenomicsDBImport with vcfs in GCS. ```; [May 9, 2017 1:35:47 PM UTC] org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImport done. Elapsed time: 2.44 minutes.; Runtime.totalMemory()=2436366336; htsjdk.samtools.FileTruncatedException: Premature end of file: /temp/10C102545.5783b88e-6d16-4da7-be0e-590811cd6d2f.g.vcf.gz; at htsjdk.samtools.util.BlockCompressedInputStream.processNextBlock(BlockCompressedInputStream.java:513); at htsjdk.samtools.util.BlockCompressedInputStream.nextBlock(BlockCompressedInputStream.java:451); at htsjdk.samtools.util.BlockCompressedInputStream.readBlock(BlockCompressedInputStream.java:441); at htsjdk.samtools.util.BlockCompressedInputStream.available(BlockCompressedInputStream.java:194); at htsjdk.samtools.util.BlockCompressedInputStream.read(BlockCompressedInputStream.java:234); at htsjdk.tribble.readers.TabixReader.readLine(TabixReader.java:199); at htsjdk.tribble.readers.TabixReader$IteratorImpl.next(TabixReader.java:416); at htsjdk.tribble.readers.TabixIteratorLineReader.readLine(TabixIteratorLineReader.java:45); at htsjdk.tribble.TabixFeatureReader$FeatureIterator.readNextRecord(TabixFeatureReader.java:178); at htsjdk.tribble.TabixFeatureReader$FeatureIterator.next(TabixFeatureReader.java:216); at htsjdk.tribble.TabixFeatureReader$FeatureIterator.next(TabixFeatureReader.java:156); at com.intel.genomicsdb.GenomicsDBImporterStreamWrapper.next(GenomicsDBImporterStreamWrapper.java:100); at com.intel.genomicsdb.GenomicsDBImporter.importBatch(GenomicsDBImporter.java:1313); at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImport.traverse(GenomicsDBImport.java:361); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:740); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:116); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:179); at org.broadi",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2686:44,error,error,44,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2686,2,"['avail', 'error']","['available', 'error']"
Availability,"@kcibul reports getting the following error while running `GenotypeGVCFs`:. ```; New error coming out of GenotypeGVCFs when running 1000 shards:. [11:20] ; ***********************************************************************. A USER ERROR has occurred: Bad input: Cannot calculate Root Mean Square Mapping Quality if there are 0 or less reads.; Number of reads recorded as :0; In VariantContext: [VC UG_call @ chr1:143249103 Q38.86 of type=SNP alleles=[C*, T] attr={DP=14, ExcessHet=3.0102999210357666, MLEAC=[2], MLEAF=[0.25], RAW_MQ=0.0} GT=[[09C81377 C*/C* GQ 6 DP 5 PL 0,6,90 {MIN_DP=4}],[09C83237 C*/C* GQ 3 DP 6 PL 0,3,45 {MIN_DP=6}],[09C97255 ./. DP 0 PL 0,0,0 {MIN_DP=0}],[09C98651 ./. DP 0 PL 0,0,0 {MIN_DP=0}],[09C99383 T/T GQ 3 PL 45,3,0 {PGT=0|1, PID=143249097_C_T, SB=[0, 0, 0, 0]}],[09C99677 ./. DP 0 PL 0,0,0 {MIN_DP=0}],[10C100868 C*/C* GQ 3 DP 7 PL 0,3,45 {MIN_DP=4}],[10C101312 ./. DP 0 PL 0,0,0 {MIN_DP=0}],[10C102545 ./. DP 1 PL 0,0,0 {MIN_DP=0}],[10C102782 ./. DP 0 PL 0,0,0 {MIN_DP=0}]]. [11:21] ; ```. I think this might be a bug, or at least a case of over-aggressive error checking. We have an extra check in our version of `RMSMappingQuality` that is not present in the GATK3 version:. ```; if (numOfReads <= 0){; throw new UserException.BadInput(""Cannot calculate Root Mean Square Mapping Quality if there are 0 or less reads."" +; ""\nNumber of reads recorded as :"" +numOfReads +; ""\nIn VariantContext: ""+ vc.toStringDecodeGenotypes());; }; ```. We should match the GATK3 behavior in this case, unless we can **prove** (and not merely infer) that GATK3 also explodes. @lbergelson Since you are git blamed here, can you give your thoughts on this?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2658:38,error,error,38,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2658,4,"['ERROR', 'error']","['ERROR', 'error']"
Availability,"@kcibul reports the following issue while trying to use `SelectVariants` to read a VCF from GCS using the latest master:. ```; I was trying this out today, and ran into some problems. I built GATK4 from the latest master and ran:. VCF=gs://fc-4c1c7765-2de2-4214-ac41-dc10bbcbb55b/e11051c9-27ce-4ff1-ba70-de73bf11f312/PairedEndSingleSampleWorkflow/326f24b8-9158-4120-8df3-7fc4b928589c/call-GatherVCFs/S1-1.g.vcf.gz; ; ./gatk-launch SelectVariants -V $VCF -L 1:1000-2000 -O foo.vcf; and I get an error about token being expired (see below). However, I can run. gsutil cat $VCF | zcat | head; without a problem, so I don't think my gcloud credentials are the problem. com.google.cloud.storage.StorageException: 400 Bad Request; {; ""error"" : ""invalid_grant"",; ""error_description"" : ""Token has been expired or revoked.""; }; 	at com.google.cloud.storage.spi.DefaultStorageRpc.translate(DefaultStorageRpc.java:202); 	at com.google.cloud.storage.spi.DefaultStorageRpc.get(DefaultStorageRpc.java:348); 	at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:186); 	at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:183); 	at com.google.cloud.RetryHelper.doRetry(RetryHelper.java:179); 	at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:244); 	at com.google.cloud.storage.StorageImpl.get(StorageImpl.java:183); 	at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.checkAccess(CloudStorageFileSystemProvider.java:531); 	at java.nio.file.Files.exists(Files.java:2385); 	at org.broadinstitute.hellbender.utils.io.IOUtils.assertFileIsReadable(IOUtils.java:567); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.getFeatureReader(FeatureDataSource.java:248); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:209); 	at org.broadinstitute.hellbender.engine.VariantWalker.initializeDrivingVariants(VariantWalker.java:54); 	at org.broadinstitute.hellbender.engine.VariantWalkerBase.initializeFeatures(VariantWalkerB",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2415:494,error,error,494,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2415,2,['error'],['error']
Availability,"@kgururaj @francesperry There's a [thread on the GATK forum](https://gatkforums.broadinstitute.org/gatk/discussion/comment/48287) where people are reporting a number of issues running GenomicsDB. There are a few different issues but they all seem to be edge cases with the file system. . 1. Report of the following error when trying to read from a GenomicsDB that is marked as read only. Is there a reason that the workspace must be writeable in order to read it? Can we avoid that requirement?; ```; terminate called after throwing an instance of 'VariantQueryProcessorException'; 2018-01-10T12:15:04.154547266Z what(): VariantQueryProcessorException : Could not open array genomicsdb_array at workspace: /keep/d22f668d4f44631d98bc650d582975ca+1399/chr22_db; ```. 2. `Could not open array genomicsdb_array at workspace` when working with a small disk. Changing to a larger disk fixed the problem. Possibly we need a better error message for the case where we are out of disk space?. 3. Reports of similar errors using a Lustre filesystem with file locking disabled. Can GenomicsDB run without file locking? If not, can we emit a clear error message when we hit that problem?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4753:315,error,error,315,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4753,4,['error'],"['error', 'errors']"
Availability,"@kgururaj We got this issue report in the forum, could you please look into it? Thanks!. https://gatkforums.broadinstitute.org/gatk/discussion/12388/how-to-use-multi-interval-in-genomicsdbimport-with-gatk-4-0-6-0. ----. I used the GenomicsDBImport with a interval list file and got a error like below.; So what is the correct way to use Multi-interval in GenomicsDBImport?. gatk version: 4.0.6.0. Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx4g -Xms4g -jar /mnt/gatk/gatk-4.0.6.0/gatk-package-4.0.6.0-local.jar GenomicsDBImport -L test.intervals --genomicsdb-workspace-path ../RAW_VCF/my_database -V file1 -V file2 -V file3. 02:57:15.591 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/mnt/workshop/xinchen.pan/test/gatk/gatk-4.0.6.0/gatk-package-4.0.6.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; 02:57:15.772 INFO GenomicsDBImport - ------------------------------------------------------------; 02:57:15.772 INFO GenomicsDBImport - The Genome Analysis Toolkit (GATK) v4.0.6.0; 02:57:15.772 INFO GenomicsDBImport - For support and documentation go to https://software.broadinstitute.org/gatk/; 02:57:15.772 INFO GenomicsDBImport - Executing as on Linux v3.10.0-514.6.1.el7.x86_64 amd64; 02:57:15.772 INFO GenomicsDBImport - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_121-b13; 02:57:15.773 INFO GenomicsDBImport - Start Date/Time: July 10, 2018 2:57:15 AM EDT; 02:57:15.773 INFO GenomicsDBImport - ------------------------------------------------------------; 02:57:15.773 INFO GenomicsDBImport - ------------------------------------------------------------; 02:57:15.773 INFO GenomicsDBImport - HTSJDK Version: 2.16.0; 02:57:15.773 INFO GenomicsDBImport - Picard Version: 2.18.7; 02:57:15.773 INFO GenomicsDBImport - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 02:57:15.773 INFO GenomicsDBImport - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_S",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4994:284,error,error,284,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4994,1,['error'],['error']
Availability,"@kvg reports that running the Intel deflater via GATK on long reads data intermittently produces corrupt bam outputs. His specific use case is sharding a single unaligned bam file into multiple smaller bams. Running with the JDK deflater (`--use-jdk-deflater`) appears to resolve the issue. Example error when trying to read a corrupt shard (reading with htsjdk produces the same error):. ```; $ java -jar gatk.jar SplitSubreadsByZmw -I sharding_test.bam -O intel_compression/v1/ -nr 100000; $ java -jar gatk.jar SplitSubreadsByZmw -I sharding_test.bam -O intel_compression/v2/ -nr 100000; $ java -jar gatk.jar SplitSubreadsByZmw -I sharding_test.bam -O intel_compression/v3/ -nr 100000; $ java -jar gatk.jar SplitSubreadsByZmw -I sharding_test.bam -O intel_compression/v4/ -nr 100000; $ java -jar gatk.jar SplitSubreadsByZmw -I sharding_test.bam -O intel_compression/v5/ -nr 100000. $ samtools view intel_compression/v1/sharding_test.000002.bam > /dev/null; $ samtools view intel_compression/v2/sharding_test.000002.bam > /dev/null; [E::bgzf_read] Read block operation failed with error 2 after 30675 of 72043 bytes; [main_samview] truncated file.; $ samtools view intel_compression/v3/sharding_test.000002.bam > /dev/null; $ samtools view intel_compression/v4/sharding_test.000002.bam > /dev/null; $ samtools view intel_compression/v5/sharding_test.000002.bam > /dev/null. (Only the second attempt yields a corrupted file; runs before and after appear to be correct, despite nothing changing between steps.); ```. There may be a bug in https://github.com/Intel-HLS/GKL/blob/master/src/main/native/compression/IntelDeflater.cc, perhaps triggered when a read spans many compressed blocks.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5798:299,error,error,299,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5798,3,['error'],['error']
Availability,"@lbergelson commented on [Wed Aug 31 2016](https://github.com/broadinstitute/gatk-protected/issues/659). I got a segfault while running CreatePanelOfNormalsIntegrationTest. Subsequent runs were unable to reproduce it. ```; 18:03:07.573 WARN TaskSetManager:70 - Stage 181 contains a task of very large size (119 KB). The maximum recommended task size is 100 KB.; Test: Test method testAllTargetsHDF5PoNCreationSpark[0](null, src/test/resources/org/broadinstitute/hellbender/tools/exome/create-pon-control-full.pcov)(org.broadinstitute.hellbender.tools.exome.CreatePanelOfNormalsIntegrationTest) produced standard out/err: 18:03:07.612 WARN TaskSetManager:70 - Stage 182 contains a task of very large size (119 KB). The maximum recommended task size is 100 KB. 18:03:07.612 WARN TaskSetManager:70 - Stage 182 contains a task of very large size (119 KB). The maximum recommended task size is 100 KB.; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x000000010a5a9401, pid=2425, tid=8963; #; # JRE version: Java(TM) SE Runtime Environment (8.0_91-b14) (build 1.8.0_91-b14); # Java VM: Java HotSpot(TM) 64-Bit Server VM (25.91-b14 mixed mode bsd-amd64 compressed oops); # Problematic frame:; # V [libjvm.dylib+0x1a9401]; #; # Failed to write core dump. Core dumps have been disabled. To enable core dumping, try ""ulimit -c unlimited"" before starting Java again; #; # An error report file with more information is saved as:; # /Users/louisb/Workspace/gatk-protected/hs_err_pid2425.log; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; #; ```. [hs_err_pid2425.log.txt](https://github.com/broadinstitute/gatk-protected/files/448383/hs_err_pid2425.log.txt). @yfarjoun Is this similar to the crash you saw a while back?. ---. @yfarjoun commented on [Wed Aug 31 2016](https://github.com/broadinstitute/gatk-protected/issues/659#issuecomment-243946864). no. this is different. On Wed, Aug 31, 2016 at 3",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2883:911,error,error,911,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2883,1,['error'],['error']
Availability,"@lbergelson, just want to discuss some issues here-. 1. We currently have to use `--avoid-nio` with `--sample-name-map` and `--bypass-feature-reader` to get `GenomicsDBImport` to work with azure URIs. Why don't we just merge the `--avoid-nio` functionality with `--bypass-feauture-reader`, that is allow GenomicsDB to process the URIs by default?; 2. Noticed that the only way to use azure URIs for vcf names is by using `--sample-name-map`. Directly specifying vcfs with the `-V` option is not possible because `--avoid-nio` cannot be used in conjunction. Should this be supported?; 3. @lbergelson, w.r.t malformed Azure URIs, GenomicsDB does put out an error -; ```; 11:10:12.658 error NativeGenomicsDB - pid=30608 tid=2980282 htslib_plugin could not open file az://genomicsdb@oda/vcfs/t0.vcf.gz [TileDB::StorageManagerConfig] Error: Azure Storage Blob initialization failed for home=az://genomicsdb@container/vcfs/sample.vcf.gz; ; Azure Blob URI does not seem to have either an account or a container: Protocol error; [E::hts_open_format] Failed to open file ""az://genomicsdb@container/vcfs/sample.vcf.gz"" : Input/output error; ```; Is this not sufficient? These are the acceptable azure URIs currently; ```; az://<container_name>@<account_name>.blob/<folder>/<file> # for default endpoints; az://<container_name>@<account_name>.blob.core.windows.net/<folder>/<file> # if the endpoint is blob.core.windows.net; azb://<container_name>/<folder>/<file> # following java.nio for azure URIs; azb://<container_name>/<folder>/<file>?account=<account_name>&endpoint=<endpoint>; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8632:655,error,error,655,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8632,5,"['Error', 'error']","['Error', 'error']"
Availability,"@lindenb commented on [Mon Feb 06 2017](https://github.com/broadinstitute/gatk-protected/issues/891). Hi GATK team,. In my VCF I've got a variant that was called but it's only the consequence of a set of soft-clipped reads (it's a Haloplex assay, that's why I've got the 'bars' / high depth below). ![jeter](https://cloud.githubusercontent.com/assets/33838/22643385/885096d0-ec5e-11e6-91ae-7331affafc36.png). I was playing with the GATK 3.7 API to find the soft clipped reads overlapping my variation. ```java. @Downsample(by= DownsampleType.BY_SAMPLE, toCoverage=1000000); public class MyWalker ; 	extends RodWalker<Integer, Integer> implements TreeReducible<Integer> {; (...); public Integer map(RefMetaDataTracker tracker, ReferenceContext ref, AlignmentContext context) {; {; (...); final Genotype g=variantContext.getGenotype(i);; 		final ReadBackedPileup sampleReadBackedPileup =rbp.getPileupForSample(g.getSampleName());; 		 final List<GATKSAMRecord> recs= sampleReadBackedPileup.getReads();. (...); }. (...); }; ```. unfortunately **, I cannot find any GATKSAMRecord containing the soft clipping segment**. So my question is: does GATK cannot find my reads because it only considers **start/end** but not **unclippedStart/unclippedEnd** ? Is there any parameter to get those clipped reads ?. Many thanks in advance,. Pierre",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2938:512,Down,Downsample,512,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2938,2,['Down'],"['Downsample', 'DownsampleType']"
Availability,"@mbabadi commented on [Thu May 18 2017](https://github.com/broadinstitute/gatk-protected/issues/1055). At the moment, we:; - Remove targets with possibly bad (NaN, infinity, negative) values; - Remove targets that have uniformly low coverage across all samples. Perhaps we should consider adding more filters:; - Remove targets with very high and very low GC content (can be done in the CalculateTargetCoverage step); - Remove targets with lots of repeats and anomalously low mappability (can be done in the CalculateTargetCoverage step); - In the learning mode, remove a target if _too many_ are masked across the samples (in that case, max likelihood parameter estimation is unreliable). This must be done after careful evaluations, i.e. only if certain features makes a target prone to bad calls no matter what.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2991:597,mask,masked,597,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2991,2,['mask'],['masked']
Availability,"@mbabadi commented on [Thu May 18 2017](https://github.com/broadinstitute/gatk-protected/issues/1058). - [ ] good choice of default parameters; - [ ] double-check assertion coverage in `CoverageModelArgumentCollection.validate()`; - [ ] if a model is provided, ARD and number of PCs must be overridden (currently, an exception is thrown if there is a discrepancy between model parameters and arguments). Relevant discussion:; **Mehrtash**: We may be able to get rid of a number of these parameters. Though, generally speaking, I'd rather expose more than less, with good default values and bold advanced disclaimers w/ proper documentation as you suggested. This is the case with sophisticated tools like HaplotypeCaller, StarAligner, etc. Soon enough, we will get strange errors from various users many of which can be resolved by changing a certain advanced parameter. Without exposing them, we will have to create patches for them and/or build custom jars.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2995:773,error,errors,773,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2995,1,['error'],['errors']
Availability,@mbabadi commented on [Wed Apr 19 2017](https://github.com/broadinstitute/gatk-protected/issues/990). `RobustBrentSolver` is a univariate solver developed as a part of GATK coverage model. It has a Brent solver at the core but tries to avoid spurious non-bracketing conditions by creating a collection of refined sub-brackets. The implementation needs to be made more flexible:; - Allow the user to specify how sub-brackets are generated. The default grid is a logarithmic grid concentrated about the leftmost endpoint followed by uniform refinement of each grid element.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2971:103,Robust,RobustBrentSolver,103,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2971,1,['Robust'],['RobustBrentSolver']
Availability,"@mbabadi commented on [Wed Oct 19 2016](https://github.com/broadinstitute/gatk-protected/issues/748). At the moment, CalculateTargetCoverage simply counts the number of overlapping reads with each target. Optionally, low quality calls are hard filtered. Here, we propose a probabilistic approach that avoids the usage of hard filters and fits well with the new probabilistic target coverage modeler. By definition, mapping quality MAPQ = -10 \log_10{mapping position is wrong} (see http://samtools.github.io/hts-specs/SAMv1.pdf, pg 5, item 5). It is defined in the range [0, 2^8-1]. The specific value 255 is reserved for when MAPQ is not available. Most MAPQs are well below 255. We consider the following process for assigning reads to each target. Pick a read ""k"" aligned to target ""t"" with a given MAPQ_k. By definition, it maps to the genomic position ""x"" with p_x = 1 - 10^{-MAPQ_k/10}, and to some other position with probability 1 - p_x. We refer to the alignment genomic position of read k as x_k, and the exome target(s) it overlaps with T_k. Let's assume we have T exome targets, and let z_{kt} be a 1-of-#T indicator variable for a read where t is a target and #T is the number of all exome targets. \pi_{kq} = P(z_{kq} = 1) =. p_k x O_{kq} if q \in T_k; (1 - p_k) / (#T - #T_k) if q \notin T_k. Here, O_{kq} is the fractional overlap of the read to an exome target q. Note that since we don't have the information about the next best alignment position, we take a flat prior. Finally, the number of reads belonging to target t, n_t, reads as:. n_t = \sum_k z_{kt}. Since there are many reads, n_t will be approximately Gaussian. It is an elementary calculation to calculate coverage mean E[n_t] and coverage variance var[n_t] in terms of \pi_{kq}. In the probabilistic target coverage model, var[n_t] will be added to the statistical noise. So, the read count collection will have two entries for each target: coverage mean, and coverage variance. ---. @mbabadi commented on [Wed Oct 19 2",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2908:639,avail,available,639,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2908,1,['avail'],['available']
Availability,"@meganshand Could you review this? It fixes most of the homoplasmic missed calls in broadinstitute/dsp-spec-ops#116. I reviewed all of the false positive that were introduced to our somatic validations when attempting to make this the default in non-mitochondria mode. Everything was due to mapping error, which I do not expect to be an issue in mitochondria, and not an inherent problem with recovering more dangling ends. You will still want to run this branch through some of your validations, however. In mitochondria mode it's the same as the dangling-1-29.jar that I shared earlier with you and Sarah.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5693:299,error,error,299,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5693,2,"['error', 'recover']","['error', 'recovering']"
Availability,"@meganshand commented on [Thu Feb 16 2017](https://github.com/broadinstitute/gatk-protected/issues/907). Using a tiny bam file that I typically use for testing while running the CNV wdl on the cloud, I got the following errors (the tiny file is here: `gs://broad-dsde-methods/takuto/test_files/small_NA12878_hg19.bam`):. 1. The output tsv from TumorNormalizeSomaticReadCounts contained NaNs; 2. TumorPerformSeg threw the following error:. ```; Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/cromwell_root/tmp; [February 16, 2017 3:23:02 PM UTC] org.broadinstitute.hellbender.tools.exome.PerformSegmentation --tangentNormalized /cromwell_root/broad-dsde-methods/cromwell-execution-24/TumorOnly/f30dd8c6-eec3-45ba-b7f2-f845d308d59d/call-TumorNormalizeSomaticReadCounts/small_NA12878.tn.tsv --output small_NA12878.seg --log2Input true --alpha 0.01 --nperm 10000 --pmethod hybrid --minWidth 2 --kmax 25 --nmin 200 --eta 0.05 --trim 0.025 --undoSplits none --undoPrune 0.05 --undoSD 3 --help false --version false --verbosity INFO --QUIET false --use_jdk_deflater false; [February 16, 2017 3:23:02 PM UTC] Executing as root@3addd2d7b373 on Linux 3.16.0-0.bpo.4-amd64 amd64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_121-b13; Version: Version:c17c8ed-SNAPSHOT; [February 16, 2017 3:23:04 PM UTC] org.broadinstitute.hellbender.tools.exome.PerformSegmentation done. Elapsed time: 0.04 minutes.; Runtime.totalMemory()=185597952; org.broadinstitute.hellbender.utils.R.RScriptExecutorException: ; Rscript exited with 1; Command Line: Rscript -e tempLibDir = '/cromwell_root/tmp/root/Rlib.5210694187065743072';source('/cromwell_root/tmp/root/CBS.8616708738798684646.R'); --args --sample_name=NA12878 --targets_file=/cromwell_root/broad-dsde-methods/cromwell-execution-24/TumorOnly/f30dd8c6-eec3-45ba-b7f2-f845d308d59d/call-TumorNormalizeSomaticReadCounts/small_NA12878.tn.tsv --output_file=small_NA12878.seg --log2_input=TRUE --min_width=2 --alpha=0.01 --nperm=10000 --pmethod=hybrid --kmax=25 --nmin=200 --eta=0.05 --t",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2944:220,error,errors,220,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2944,2,['error'],"['error', 'errors']"
Availability,"@nalinigans @droazen @mlathara I posted a while ago about an odd difference between data aggregated using CombineGVCFs and data aggregated using GenomicsDBImport. We created a minimal repro case to illustrate it. The basic idea is this:. - Run either CombineGVCFs or GenomicsDBImport on a set of gVCFs; - Run SelectVariants on the output. The data processed using GenomicsDBImport will contain a bunch of lines like these, with ambiguous REF alleles:. 19	75166	.	N	*,<NON_REF>	.	.	DP=3	GT:AD:DP:GQ:MIN_DP:PGT:PID:PL:PS:SB	./.:.:2:6:2:.:.:0,6,57,6,57,57	.|.:0,1,0:1:3:.:0|1:75165_AGCGGAGGGGAGCGGCGCGGAGGGGCGCGGAGGGGC_A:45,3,0,45,3,45:75165:0,0,1,0	./.:.:0:0:0:.:.:0,0,0,0,0,0	./.:.:0:0:0:.:.:0,0,0,0,0,0. the data processed through CombineGVCFs shows the proper REF:. 19	75166	.	G	*,<NON_REF>	.	.	DP=3	GT:AD:DP:GQ:MIN_DP:PGT:PID:PL:PS:SB	./.:.:2:6:2:.:.:0,6,57,6,57,57	.|.:0,1,0:1:3:.:0|1:75165_AGCGGAGGGGAGCGGCGCGGAGGGGCGCGGAGGGGC_A:45,3,0,45,3,45:75165:0,0,1,0	./.:.:0:0:0:.:.:0,0,0,0,0,0	./.:.:0:0:0:.:.:0,0,0,0,0,0. I dont fully understand the data format in a GenomicsDB Workspace, but it would suggest either a) it's storing the wrong REF, or b) the codec is somehow not properly re-adding the REF at read time. Here is a public, downloadable set of repro data. It's large mostly b/c it has our reference genome. The included bash script takes just a few minutes to run, should you want to repro the whole thing. I bundled our actual GATK JAR as well. You can view/download through the browser here:. https://prime-seq.ohsu.edu/project/Labs/Bimber/Collaborations/GATK/begin.view?. or download on the command line:. wget https://prime-seq.ohsu.edu/_webdav/Labs/Bimber/Collaborations/GATK/%40files/ambigRefRepro.tar.gz. Please let me know if there's anything we can check locally. We have a test case set up in intellij if there's something useful we could try through there. . These incorrect REF alleles become a problem downstream when genotyping. Thanks for any help.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7089:1235,down,downloadable,1235,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7089,4,['down'],"['download', 'downloadable', 'downstream']"
Availability,@personalis commented on [Thu Jun 23 2016](https://github.com/broadinstitute/gatk-protected/issues/587). We got the following error when running gatk-launch FastqToSam:. java.lang.IllegalArgumentException: Self-suppression not permitted; at java.lang.Throwable.addSuppressed(Throwable.java:1043); at org.broadinstitute.hellbender.tools.picard.sam.FastqToSam.doWork(FastqToSam.java:163); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:102); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:155); at org.broadinstitute.hellbender.cmdline.PicardCommandLineProgram.instanceMain(PicardCommandLineProgram.java:61); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:67); at org.broadinstitute.hellbender.Main.main(Main.java:82); Caused by: java.lang.NoClassDefFoundError: org/xerial/snappy/LoadSnappy; at htsjdk.samtools.util.SnappyLoader.<init>(SnappyLoader.java:86); at htsjdk.samtools.util.SnappyLoader.<init>(SnappyLoader.java:52); at htsjdk.samtools.util.TempStreamFactory.getSnappyLoader(TempStreamFactory.java:42); at htsjdk.samtools.util.TempStreamFactory.wrapTempOutputStream(TempStreamFactory.java:74); at htsjdk.samtools.util.SortingCollection.spillToDisk(SortingCollection.java:223); at htsjdk.samtools.util.SortingCollection.add(SortingCollection.java:166); at htsjdk.samtools.SAMFileWriterImpl.addAlignment(SAMFileWriterImpl.java:192); at htsjdk.samtools.AsyncSAMFileWriter.synchronouslyWrite(AsyncSAMFileWriter.java:36); at htsjdk.samtools.AsyncSAMFileWriter.synchronouslyWrite(AsyncSAMFileWriter.java:16); at htsjdk.samtools.util.AbstractAsyncWriter$WriterRunnable.run(AbstractAsyncWriter.java:117); at java.lang.Thread.run(Thread.java:745); Caused by: java.lang.ClassNotFoundException: org.xerial.snappy.LoadSnappy; at java.net.URLClassLoader.findClass(URLClassLoader.java:381); at java.lang.ClassLoader.loadClass(ClassLoader.java:424); at sun.misc.Launcher$AppClassLoader.l,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2868:126,error,error,126,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2868,1,['error'],['error']
Availability,"@samuelklee @asmirnov239 @mbabadi I tried to run a 30-sample cohort through gCNV on all canonical chromosomes with 250bp bins sharded in 10k-interval blocks, but PostprocessGermlineCNVCalls gave the following error:. ```...; 19:26:14.967 INFO PostprocessGermlineCNVCalls - Analyzing shard 223...; 19:26:15.107 INFO PostprocessGermlineCNVCalls - Analyzing shard 224...; 19:26:15.259 INFO PostprocessGermlineCNVCalls - Analyzing shard 225...; 19:26:15.260 INFO PostprocessGermlineCNVCalls - Shutting down engine; [May 29, 2018 7:26:15 PM UTC] org.broadinstitute.hellbender.tools.copynumber.PostprocessGermlineCNVCalls done. Elapsed time: 3.34 minutes.; Runtime.totalMemory()=39753089024; ***********************************************************************. A USER ERROR has occurred: Bad input: Validation error occurred on line %d of the posterior file: Posterior probabilities for at at least one posterior record do not sum up to one.; ```. After inspecting the output from shard 225, it seems that the model starts producing nan values after ~1600 warmup iterations (looking at the ELBO log). This shard corresponds to a pericentromeric region chr3:91540501-94090250. . It would be nice to have the option to bypass this error in PostprocessGermlineCNVCalls. Here is the model config for the shard:. ```""p_alt"": 1e-06,; ""p_active"": 0.01,; ""cnv_coherence_length"": 10000.0,; ""class_coherence_length"": 10000.0,; ""max_copy_number"": 5,; ""num_calling_processes"": 1,; ""num_copy_number_states"": 6,; ""num_copy_number_classes"": 2; ""max_bias_factors"": 5,; ""mapping_error_rate"": 0.01,; ""psi_t_scale"": 0.001,; ""psi_s_scale"": 0.0001,; ""depth_correction_tau"": 10000.0,; ""log_mean_bias_std"": 0.1,; ""init_ard_rel_unexplained_variance"": 0.1,; ""num_gc_bins"": 20,; ""gc_curve_sd"": 1.0,; ""q_c_expectation_mode"": ""hybrid"",; ""active_class_padding_hybrid_mode"": 50000,; ""enable_bias_factors"": false,; ""enable_explicit_gc_bias_modeling"": false,; ""disable_bias_factors_in_active_class"": false; ""version"": ""0.7""; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4824:209,error,error,209,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4824,5,"['ERROR', 'down', 'error']","['ERROR', 'down', 'error']"
Availability,"@samuelklee I'm running into an error for the `cnv_germline_case_scattered_workflow` WDL pipeline to create a Panel of Normals. It seems during the _GermlineCNVCallerCohortMode_ step, the pipeline opens up tens-of-thousands of files that it doesn't close, causing the system to crash. This seems to happen for me both with the Docker image and Standalone GATK4.1.0.0 jar. It reminds me [of this issue mentioned on the forums from GATK3.8](https://gatkforums.broadinstitute.org/gatk/discussion/12791/too-many-open-files) but the error still occurs even if I limit that step to a single thread. I'm running on a Red Had HPC with 16 threads and 200GB of RAM available and using Cromwell v34. After checked with the manager for my cluster it seems the error occurred when over 60K files were opened simultaneously so this looks to me more like a memory leak than a ulimit issue. Here's the output from a typical error file:. ```Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/gatk/local_mnt/cromwell-executions/CNVGermlineCohortWorkflow/098a389e-b298-4324-8a8c-9f46f05708b5/call-GermlineCNVCallerCohortMode/shard-12910/tmp.cd408023; 23:36:58.837 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/gatk/gatk-package-4.1.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; 23:36:58.940 DEBUG NativeLibraryLoader - Extracting libgkl_compression.so to /gatk/local_mnt/cromwell-executions/CNVGermlineCohortWorkflow/098a389e-b298-4324-8a8c-9f46f05708b5/call-GermlineCNVCallerCohortMode/shard-12910/tmp.cd408023/libgkl_compression7867300459324040837.so; 23:37:00.969 INFO GermlineCNVCaller - ------------------------------------------------------------; 23:37:00.970 INFO GermlineCNVCaller - The Genome Analysis Toolkit (GATK) v4.1.0.0; 23:37:00.970 INFO GermlineCNVCaller - For support and documentation go to https://software.broadinstitute.org/gatk/; 23:37:00.970 INFO GermlineCNVCaller - Executing as user@e15b680c0241 on Linux v3.10.0-327.36.1.el7.x86_64 amd64; 23:37:00.970 INFO Germ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5714:32,error,error,32,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5714,5,"['avail', 'error']","['available', 'error']"
Availability,"@samuelklee commented on [Fri May 06 2016](https://github.com/broadinstitute/gatk-protected/issues/498). Specifically, a scatter plot of ACNV segments in 2D MAF-CR space + histograms for their 1D projections. This will be useful for downstream tools. ---. @samuelklee commented on [Wed May 11 2016](https://github.com/broadinstitute/gatk-protected/issues/498#issuecomment-218528591). as an example:; ![maf-cr-purity-deciles](https://cloud.githubusercontent.com/assets/11076296/15189893/24556cd6-177b-11e6-8374-78d9a9b0e9a6.png). ---. @samuelklee commented on [Wed May 11 2016](https://github.com/broadinstitute/gatk-protected/issues/498#issuecomment-218528764). Would be great to have this per chromosome as well.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2855:233,down,downstream,233,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2855,1,['down'],['downstream']
Availability,"@samuelklee commented on [Mon Oct 05 2015](https://github.com/broadinstitute/gatk-protected/issues/126). Some possible enhancements/improvements, in no particular order and of varying scope:. -Change SliceSampler to be able to handle multimodal univariate distributions. Should just be a matter of implementing the pseudocode in Neal 2003 http://projecteuclid.org/download/pdf_1/euclid.aos/1056562461. -Add Metropolis-Hastings univariate sampler as alternative to SliceSampler. -Add Metropolis-Hastings/nested/etc. multivariate samplers as alternatives to GibbsSampler. This should only be tackled if a model/dataset necessitates it. -Implement hierarchical/multilevel models in an OOP way. Currently, the samplers operate on lists of global parameters and lists of lists of ""local"" parameters (i.e., segment-level or site-level parameters), which is a bit clunky. -Add convergence diagnostics (e.g., autocorrelation time). -Add ability to make trace plots and corner plots. -Implement more flexible discarding of burn-in. Currently, samples from all iterations are aggregated in memory. Depending on the maximum number of iterations we want to allow, it might be better to write samples to disk, only store samples in memory after burn-in, etc. so we don't run into memory issues. -Parallelization (again, only if a model/dataset necessitates it). ---. @LeeTL1220 commented on [Tue Nov 03 2015](https://github.com/broadinstitute/gatk-protected/issues/126#issuecomment-153466956). @samuelklee Do we need this for the beta release?. ---. @samuelklee commented on [Tue Nov 03 2015](https://github.com/broadinstitute/gatk-protected/issues/126#issuecomment-153471237). I'd say no to pretty much all of the points, except for whatever @davidbenjamin ends up needing to implement for the allele-fraction model (David, last time I looked at your branch there was some MH sampling going on?). Some of them will probably be relatively easy to address before beta (e.g., the first point about fixing up the Slic",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2824:364,down,download,364,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2824,1,['down'],['download']
Availability,"@samuelklee commented on [Thu Aug 11 2016](https://github.com/broadinstitute/gatk-protected/issues/644). We currently have some recommendations for coverage collection that were based on recapseg, but it would be good to revisit them with GATK CNV and the new coverage model/HMM segmentation. In addition, GC bias correction has been implemented in the workflow, but it is not yet evaluated. Documentation and and scripts to generate evaluations and plots showing the effects on GATK CNV, the new coverage model, and downstream tools (e.g., ACNV) are needed.; - [ ] target padding; - [ ] keeping duplicates; - [ ] GC bias correction; - [ ] sequence repeat correction; - [ ] target filtering. ---. @samuelklee commented on [Wed Apr 19 2017](https://github.com/broadinstitute/gatk-protected/issues/644#issuecomment-295360224). I am planning on removing sequence repeat correction to close #645. We can reimplement and reevaluate in the future.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2881:517,down,downstream,517,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2881,1,['down'],['downstream']
Availability,"@samuelklee commented on [Wed Oct 19 2016](https://github.com/broadinstitute/gatk-protected/issues/750). Tool for inferring mixture of CNV subclones from ACNV output.; - [x] Develop resources for simulating tumor phylogenies/mixtures; - Wrote python code for simulating phylogenies and generating corresponding truth tables for CN profiles, ACNV segment files (with varying noise---i.e., CR and MAF credible-interval sizes---and purity levels), and plots.; - [x] Design basic algorithm; - Gibbs sampling MCMC of Dirichlet mixture of CNV subclones, to start. Graphical model is written down.; - [x] Implement basic algorithm; - CLI roughly implemented in sl_purity_ploidy_mcmc branch. Could stand some refactoring and code cleanup before it is PR ready and needs tests.; - [x] Algorithm improvements; - Currently, the model is initialized assuming a 50-50 normal-tumor split and only a clonal population. This is run for ~100 MCMC iterations, and the result is used to initialize a second run that expands the number of populations. This tends to work reasonably well, but there are situations where the model can get stuck in incorrect, degenerate solutions. Going to try adding some MH steps that will swap populations to see if these can help get the model unstuck.; - Need to add outlier absorption to the model, which appears to be critical for inference of subclonal populations from real data (i.e., ACNV output), which may have spurious segments, oversegmentation, etc. Simple clonal models appear to work reasonably well without this, though.; - [x] Evaluate algorithm on simulated data.; - Implemented simple Queue pipeline for running CLI on simulated ACNV segment files. Takes <2 minutes for ~1000 iterations for each sample, can run 100s of samples in parallel on the gsa clusters.; - Need to write up some scripts to automatically calculate and plot metrics.; - [x] Evaluate algorithm on real data; - Some initial runs on HCC1143 purity series show reasonable results for the clonal model",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2909:585,down,down,585,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2909,1,['down'],['down']
Availability,"@sooheelee commented on [Fri Feb 17 2017](https://github.com/broadinstitute/gatk-protected/issues/911). A fix was implemented for HaplotypeCaller but not ported to GenotypeGVCFs nor CombineGVCFs nor CombineVariants. Although user is using v3.7-0-gcfedb67, my understanding is that these types of fixes will only be worked on in GATK4. - Previous discussion of HaplotypeCaller fix; https://github.com/broadinstitute/gsa-unstable/issues/855#issuecomment-278478318. ---; ### Test data submitted by user can be found at; /humgen/gsa-scr1/pub/incoming/bugrep_jgeibel_1.tar.gz. This includes chicken reference files. . ---; ### The command the user uses to generate the error is very long because we have many vcfs:; ```; Program Args: -T GenotypeGVCFs -R /usr/users/geibel/chicken/chickenrefgen/galGal5_Dec2015/galGal5.fa --variant /usr/users/geibel/chicken/pool_sequence_nov2016/data/gVCF/i_WL_72631_chr26.raw.g.vcf --variant /usr/users/geibel/chicken/pool_sequence_nov2016/data/gVCF/i_WL_72632_chr26.raw.g.vcf --variant /usr/users/geibel/chicken/pool_sequence_nov2016/data/gVCF/i_WL_72633_chr26.raw.g.vcf --variant /usr/users/geibel/chicken/pool_sequence_nov2016/data/gVCF/i_WL_72634_chr26.raw.g.vcf --variant /usr/users/geibel/chicken/pool_sequence_nov2016/data/gVCF/i_WL_72635_chr26.raw.g.vcf --variant /usr/users/geibel/chicken/pool_sequence_nov2016/data/gVCF/i_WL_72636_chr26.raw.g.vcf --variant /usr/users/geibel/chicken/pool_sequence_nov2016/data/gVCF/i_WL_72637_chr26.raw.g.vcf --variant /usr/users/geibel/chicken/pool_sequence_nov2016/data/gVCF/i_WL_72638_chr26.raw.g.vcf --variant /usr/users/geibel/chicken/pool_sequence_nov2016/data/gVCF/i_WL_72639_chr26.raw.g.vcf --variant /usr/users/geibel/chicken/pool_sequence_nov2016/data/gVCF/i_WL_72640_chr26.raw.g.vcf --variant /usr/users/geibel/chicken/pool_sequence_nov2016/data/gVCF/i_WL_72641_chr26.raw.g.vcf --variant /usr/users/geibel/chicken/pool_sequence_nov2016/data/gVCF/i_WL_72642_chr26.raw.g.vcf --variant /usr/users/geibel/chicken/pool_seq",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2946:664,error,error,664,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2946,1,['error'],['error']
Availability,"@sooheelee commented on [Wed May 17 2017](https://github.com/broadinstitute/gatk-protected/issues/1048). Hey @cmnbroad. Instead of slacking you this stacktrace, I thought I'd put it here. Let me know if you want the more detailed debug report, etc. ---; ```; WMCF9-CB5:hellbender shlee$ git branch; * master; shl_mark_documented_splitncigarreads; WMCF9-CB5:hellbender shlee$ git pull origin master; From github.com:broadinstitute/gatk; * branch master -> FETCH_HEAD; Already up-to-date.; WMCF9-CB5:hellbender shlee$ cd ../hellbender-protected/; WMCF9-CB5:hellbender-protected shlee$ ./gradlew -PgatkSourceDir=../hellbender gatkDoc; :compileJava UP-TO-DATE; :processResources UP-TO-DATE; :classes UP-TO-DATE; :cleanGatkDoc; :gatkDoc; Note: The GATK source folder must contain the same version of GATK that is used to build gatk-protected; javadoc: error - In doclet class org.broadinstitute.hellbender.utils.help.GATKHelpDoclet, method start has thrown an exception java.lang.reflect.InvocationTargetException; java.lang.RuntimeException: Could not find the field corresponding to java.lang.Throwable.backtrace, presumably because the field is inaccessible; at org.broadinstitute.barclay.help.DefaultDocWorkUnitHandler.getFieldDoc(DefaultDocWorkUnitHandler.java:604); at org.broadinstitute.barclay.help.DefaultDocWorkUnitHandler.getFieldDoc(DefaultDocWorkUnitHandler.java:622); at org.broadinstitute.barclay.help.DefaultDocWorkUnitHandler.getFieldDoc(DefaultDocWorkUnitHandler.java:622); at org.broadinstitute.barclay.help.DefaultDocWorkUnitHandler.getFieldDoc(DefaultDocWorkUnitHandler.java:622); at org.broadinstitute.barclay.help.DefaultDocWorkUnitHandler.getFieldDoc(DefaultDocWorkUnitHandler.java:591); at org.broadinstitute.barclay.help.DefaultDocWorkUnitHandler.getFieldDocForCommandLineArgument(DefaultDocWorkUnitHandler.java:403); at org.broadinstitute.barclay.help.DefaultDocWorkUnitHandler.processNamedArgument(DefaultDocWorkUnitHandler.java:357); at org.broadinstitute.barclay.help.DefaultD",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2988:847,error,error,847,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2988,1,['error'],['error']
Availability,@takutosato Here it is. The failure has nothing to do with this branch -- every branch is failing in the same way currently. I have tested and debugged this thoroughly and I am deliberately not writing unit tests for now because we're too busy with MC3 and the M2 paper. I intend to come back to these later.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4998:28,failure,failure,28,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4998,1,['failure'],['failure']
Availability,@takutosato Silly error on my part. Made the argument parser crash whenever the argument was set to a non-default value. @Closes #5978.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5982:18,error,error,18,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5982,1,['error'],['error']
Availability,@takutosato This change doesn't hurt sensitivity in our validations and made M2 25% faster. We were getting a lot of active regions based on single substitution errors in overlapping reads.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5078:161,error,errors,161,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5078,1,['error'],['errors']
Availability,"@takutosato This corrects the math error you pointed out in your code review of the docs. While we're at it, it also outputs the error bars according to the formula given in the docs. I have tested it on an in silico contamination series and it improves results slightly.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3385:35,error,error,35,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3385,2,['error'],['error']
Availability,"@takutosato This error should be thrown once detected. Currently it leads to a divide-by-zero downstream, which only throws an error even further downstream when the NaN shows up.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6445:17,error,error,17,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6445,4,"['down', 'error']","['downstream', 'error']"
Availability,"@takutosato This fixes two sources of the bug:. * Threshold was equal to the error probability of the worst unfiltered variant, but filtering was based on `errorProbability > threshold - EPSILON`, which ends up filtering this variant.; * Threshold was adjusted *and* filtering parameters were changed on the last pass, which means that error probabilities could shift slightly relative to those used to set the threshold.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6101:77,error,error,77,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6101,3,['error'],"['error', 'errorProbability']"
Availability,"@takutosato This is really important for overcoming transient errors in Firecloud, especially as long as we don't have call-caching for NIO.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5049:62,error,errors,62,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5049,1,['error'],['errors']
Availability,@takutosato We have seen samples with a handful of cases and I would rather not force users to run with `--independent-mates` just to avoid an error at a few sites.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6240:143,error,error,143,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6240,1,['error'],['error']
Availability,"@takutosato commented on [Mon Mar 27 2017](https://github.com/broadinstitute/gatk-protected/issues/959). Mutect2.wdl is a monolithic beast that does way more than what it's designed to do i.e. run Mutect2. It's good style to split standalone tasks (Mutect2, Oncotator, OxoG filter) into modules. On the other hand, in the cloud it's cheaper to have all tasks in one wdl. We should find a good balance between these opposing forces. ---. @davidbenjamin commented on [Sun Apr 09 2017](https://github.com/broadinstitute/gatk-protected/issues/959#issuecomment-292795106). @takutosato I recently made a few modest (and orthogonal) steps to clean the wdl (PR #974). Let me know if the rebase gets messy, since it will be my fault for causing the mess.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2962:718,fault,fault,718,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2962,1,['fault'],['fault']
Availability,"@tedsharpe please review. - SVKmerizer takes in an integer specifying the spacing between between kmers. This is is an effective way to reduce the kmer set size without affecting sensitivity much.; - SVKmerShort - added masking function that returns a copy of the current kmer after deleting bases at the specified positions; - Reworded some error messages about kmer length; - Moved and added some hashing functions to SVUtils, which will be used in another PR for the long-typed set classes and de-duplication filter.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2662:220,mask,masking,220,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2662,2,"['error', 'mask']","['error', 'masking']"
Availability,@thebkaufman1995 encountered the following warning when trying to use TSV count files in the gCNV pipeline:. ```; HDF5-DIAG: Error detected in HDF5 (1.8.14) thread 0:; #000: /mnt/scr1/abyrne/HDFJava-platypus-2.11/native/HDF5-prefix/src/HDF5/src/H5F.c line 604 in H5Fopen(): unable to open file; major: File accessibilty; minor: Unable to open file; #001: /mnt/scr1/abyrne/HDFJava-platypus-2.11/native/HDF5-prefix/src/HDF5/src/H5Fint.c line 1085 in H5F_open(): unable to read superblock; major: File accessibilty; minor: Read failed; #002: /mnt/scr1/abyrne/HDFJava-platypus-2.11/native/HDF5-prefix/src/HDF5/src/H5Fsuper.c line 277 in H5F_super_read(): file signature not found; major: File accessibilty; minor: Not an HDF5 file; ```. My guess is this is because we first try to open counts files as HDF5 and then fall back to TSV (catching the relevant exception). Perhaps slightly different versions of the HDF5 library result in these warnings being emitted.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4482:125,Error,Error,125,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4482,1,['Error'],['Error']
Availability,"@tomwhite can you review? We have CHD 5.7 running now and 1.6 is available on the cloud so no reason to not upgrade AFAIK. For some reason, the lists returned from `.collect` are no longer mutable so i have to make copies in 1 test",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1834:65,avail,available,65,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1834,1,['avail'],['available']
Availability,"@vdauwera commented on [Mon Nov 14 2016](https://github.com/broadinstitute/gatk-protected/issues/772). @vruano commented on [Tue Jul 21 2015](https://github.com/broadinstitute/gsa-unstable/issues/1064). The PCR error model applied pre-pairHMM does not seem to always do the right thing. . This is explained in class TandemRepeatFinder JavaDoc (soon to be merged in). Moreover the code responsible to detect STR repeats seems rather inefficient doing multiple passes on the read bases for each position on the read when it seems that it must be possible to accomplish the same just doing at most one pass per possible STR length. This task is to fix the PCR artifact modeling issues evaluating whether there is at least no a drop in calling accuracy all. Also try to make the code more efficient. ---. @ldgauthier commented on [Tue Jul 21 2015](https://github.com/broadinstitute/gsa-unstable/issues/1064#issuecomment-123431158). @yfarjoun and I just added a Palantir issue for this this morning -- should the analysis wait until you're done updating the code?. ---. @vruano commented on [Tue Jul 21 2015](https://github.com/broadinstitute/gsa-unstable/issues/1064#issuecomment-123431971). Just waiting for test to pass...; So you knew about this issue already?. ---. @ldgauthier commented on [Tue Jul 21 2015](https://github.com/broadinstitute/gsa-unstable/issues/1064#issuecomment-123432816). We were talking about it because the PCR-free option doesn't get used in production (on PCR-free data) and we didn't know how much difference it actually makes. ---. @vruano commented on [Tue Jul 21 2015](https://github.com/broadinstitute/gsa-unstable/issues/1064#issuecomment-123481297). Merged. ; I think that you can go ahead with the analysis and I would borrow your set up to see if the eventual code update improves things for PCR-plus. . ---. @vruano commented on [Tue Jul 21 2015](https://github.com/broadinstitute/gsa-unstable/issues/1064#issuecomment-123481614). Sorry for the confusion, that merge",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2915:211,error,error,211,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2915,1,['error'],['error']
Availability,"@vdauwera reported this here #950 :. > Can't seem to do git clone https://github.com/broadinstitute/hellbender/. ```; wmd16-c9e:codespace vdauwera$ git clone http://github.com/broadinstitute/hellbender/; Cloning into 'hellbender'...; remote: Counting objects: 22221, done.; remote: Compressing objects: 100% (142/142), done.; remote: Total 22221 (delta 47), reused 4 (delta 4), pack-reused 22046; Receiving objects: 100% (22221/22221), 36.63 MiB | 3.58 MiB/s, done.; Resolving deltas: 100% (9903/9903), done.; Checking connectivity... done.; Downloading src/test/resources/large/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.bam (76.16 MB); Username for 'http://github.com': vdauwera; Password for 'http://vdauwera@github.com': ; Error accessing media: src/test/resources/large/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.bam (6b1304800e60c0ac0358df137bdad48b7857a36465b04fef3fbbb09380f04746). Errors logged to /Users/vdauwera/codespace/hellbender/.git/lfs/objects/logs/20151005T220016.510795175.log.; Use `git lfs logs last` to view the log.; Downloading src/test/resources/large/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.bam.bai (11.25 KB); Username for 'http://github.com': ; ```. > Looks like I'm failing to download large test files. Do I need to be on VPN for this to work? Or is it expected and I should ignore it?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/952:542,Down,Downloading,542,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/952,5,"['Down', 'Error', 'down']","['Downloading', 'Error', 'Errors', 'download']"
Availability,"@vdauwera reports getting this error when running `GenomicsDBImport` with a large interval list as the `-L` input:. ```; java.util.concurrent.CompletionException: org.broadinstitute.hellbender.exceptions.GATKException: Cannot call query with different interval, expected:1:29867-31003 queried with: 1:68590-70510; ```. Looking at the code that produces this error, this seems like a ""should never happen"" type of error that would likely only be produced by a race condition of some kind. Full stderr log follows:. ```; Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/cromwell_root/tmp.876625c8; 04:37:28.801 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/gatk/gatk-package-4.0.9.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; 04:37:29.319 INFO GenomicsDBImport - ------------------------------------------------------------; 04:37:29.319 INFO GenomicsDBImport - The Genome Analysis Toolkit (GATK) v4.0.9.0; 04:37:29.320 INFO GenomicsDBImport - For support and documentation go to https://software.broadinstitute.org/gatk/; 04:37:29.320 INFO GenomicsDBImport - Executing as root@7a7880aef99b on Linux v4.9.0-0.bpo.6-amd64 amd64; 04:37:29.321 INFO GenomicsDBImport - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_171-8u171-b11-0ubuntu0.16.04.1-b11; 04:37:29.321 INFO GenomicsDBImport - Start Date/Time: October 8, 2018 4:37:28 AM UTC; 04:37:29.321 INFO GenomicsDBImport - ------------------------------------------------------------; 04:37:29.322 INFO GenomicsDBImport - ------------------------------------------------------------; 04:37:29.322 INFO GenomicsDBImport - HTSJDK Version: 2.16.1; 04:37:29.323 INFO GenomicsDBImport - Picard Version: 2.18.13; 04:37:29.323 INFO GenomicsDBImport - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 04:37:29.323 INFO GenomicsDBImport - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 04:37:29.324 INFO GenomicsDBImport - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 04:37:29.324 INFO GenomicsDBImport - HTSJDK Defaults.US",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5300:31,error,error,31,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5300,3,['error'],['error']
Availability,"@vdauwera reports that the following `ApplyBQSRSpark` command fails with an NIO-related error on dataproc:. ```; time ./gatk-launch ApplyBQSRSpark \; -I gs://hellbender/test/resources/benchmark/CEUTrio.HiSeq.WEx.b37.NA12892.bam \; -R gs://gatk-legacy-bundles/b37/human_g1k_v37.2bit \; -O gs://gatk-demo/TEST/gatk4-spark/recalibrated.bam \; -bqsr gs://gatk-demo/TEST/gatk4-spark/recalibration.table \; -apiKey $APIKEY_ORTMP \; -- \; --sparkRunner GCS \; --cluster gvda-test-bqsr \; --num-executors 40 \; --executor-cores 4 \; --executor-memory 20g; ```. ```; java.nio.file.FileSystemNotFoundException: Provider ""gs"" not installed; at java.nio.file.Paths.get(Paths.java:147); at org.seqdoop.hadoop_bam.util.NIOFileUtil.asPath(NIOFileUtil.java:30); at org.seqdoop.hadoop_bam.util.SAMFileMerger.mergeParts(SAMFileMerger.java:51); at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSink.writeReadsSingle(ReadsSparkSink.java:231); at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSink.writeReads(ReadsSparkSink.java:153); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.writeReads(GATKSparkTool.java:247); at org.broadinstitute.hellbender.tools.spark.ApplyBQSRSpark.runTool(ApplyBQSRSpark.java:49); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:348); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:38); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:109); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:167); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:186); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:76); at org.broadinstitute.hellbender.Main.main(Main.java:92); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2287:88,error,error,88,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2287,1,['error'],['error']
Availability,@vruano commented on [Tue Oct 11 2016](https://github.com/broadinstitute/gatk-protected/issues/741). Recently there was mishap where the same class (but different code version) was present in gatk (public) and gatk-protected. #738. For some reason that did not caused a Travis failure but it was detected when trying to use the affected tool in an actual analysis. . Since there is a flow of code from gatk-protected to gatk (public) I guess it would be advisable to add step in Travis to verify there is no class name clashes between gatk-protected code base and the imported gatk.4 dependency. ---. @lbergelson commented on [Tue Oct 25 2016](https://github.com/broadinstitute/gatk-protected/issues/741#issuecomment-256082980). We've had this issue a few times. One thing that would help would be to move all the code in gatk-protected into a `protected` sub package so we would have a separate namespace that could never accidentally conflict with gatk-public.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2902:277,failure,failure,277,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2902,1,['failure'],['failure']
Availability,"@yfarjoun and I recently discovered the following artifact in 30 FFPE samples:. The artifact occurs in DNA transposons with sequence 5'[S1][ITR][transposase][ITR'][S2]3', where S1 and S2 are arbitrary flanking sequence, ITR and ITR' are the inverted tandem repeat and its reverse complement (on the *same* strand). The artifact occurs when FFPE damage in the ITR sequence disrupts base pairing, causing ITR to pair with ITR', thereby creating a single-strand loop. Then end-repair (that is, filling in the 3' underhang) copies sequence from S1 into S2, yielding an insertion artifact. We verified a few signatures of this artifact:; * The insertion is always on read 2; * the fragment size for any given artifact is constant + 2 * # of soft-clipped bases; * When the artifact occurs upstream (downstream) of the insertion it is on a forward (reverse) strand read.; * the fragments 3' and 5' sequences are reverse complements of each other. The most natural way to filter would be with the read and its mate, but that's tricky in the GATK engine so we can also implement a filter that knows the reference context. This could also work as a hard-clipping read transformer.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4892:474,repair,repair,474,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4892,2,"['down', 'repair']","['downstream', 'repair']"
Availability,"A GATK user is getting a java.lang.NullPointerException when running Concordance. It seems that their eval VCF has contigs that do not match the truth dataset. It would be helpful to add a better error message for this case. This request was created from a contribution made by Priyadarshini Thirunavukkarasu on November 11, 2021 10:19 UTC. Link: [https://gatk.broadinstitute.org/hc/en-us/community/posts/4410110105755-GATK-concordance](https://gatk.broadinstitute.org/hc/en-us/community/posts/4410110105755-GATK-concordance). \--. Hello. I am running GATK/4.2.2.0-foss-2018b-Java-1.8 in the cluster. After running the given below code, I am not able to find the output file (summary file). This is the link, where the code is given \[[https://gatk.broadinstitute.org/hc/en-us/articles/4405451404699-Concordance#--summary\](/hc/en-us/articles/4405451404699-Concordance#--summary)](https://gatk.broadinstitute.org/hc/en-us/articles/4405451404699-Concordance#--summary](/hc/en-us/articles/4405451404699-Concordance#--summary)). Please also find the log file below. Is the summary file required as input file to run the below script? Please advice.  gatk Concordance \\ ; ;    -R /scicore/home/cichon/GROUP/memory\_optimization/data/reference/gch38.fa \\ ; ;    -eval /scicore/home/cichon/GROUP/memory\_optimization/variants/filtered/sample1\_affect.filtered.vcf \\ ; ;    --truth /scicore/home/cichon/GROUP/memory\_optimization/variants/filtered/NA12878.vcf.gz \\ ; ;    --summary /scicore/home/cichon/GROUP/memory\_optimization/variants/filtered/summary.tsv   ; 11:26:21.545 INFO NativeLibraryLoader - Loading libgkl\_compression.so from jar:file:/scicore/soft/apps/GATK/4.2.2.0-foss-2018b-Java-1.8/gatk-package-4.2.2.0-local.jar!/com/intel/gkl/native/libgkl\_compression.so ; ; Nov 11, 2021 11:26:21 AM shaded.cloud\_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine ; ; INFO: Failed to detect whether we are running on Google Compute Engine. ; ; 11:26:21.681 INFO Concordance",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7562:196,error,error,196,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7562,1,['error'],['error']
Availability,A collection of changes to enhance reliability and ease-of-use. Users no longer have to make a table containing the sample names to extract in GvsPrepareCallset (which was painful) and they don't have to re-supply that same table when rendering the VCF in GvsExtractCallset (which was error prone). GvsPrepareCallet now takes a file of sample names as a parameter as well as an export table _prefix_. The main `sample_info` table is then subset to the sample names in the supplied file and stored in the table `{export_prefix}__SAMPLES`. The export table is created and now named `{export_prefix}__DATA`. GvsExtractCallset now only needs to take this export prefix and is able to get the sample list and data it needs from these tables. @ericsong -- does this fit the AoU use case well?,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7272:35,reliab,reliability,35,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7272,2,"['error', 'reliab']","['error', 'reliability']"
Availability,A couple of places in the GATK doc rely on an external web service (http://latex.codecogs.com) to generate equation images. It would be more reliable to generate these statically and embed them in the doc bundle rather than dynamicaly generating them (see https://github.com/broadinstitute/gatk/issues/6599). Whatever process used would need to work for both javadoc and gatkdoc.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6645:141,reliab,reliable,141,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6645,1,['reliab'],['reliable']
Availability,"A couple of users have reported errors with --disable-tool-default-read-filters. Is this expected? This user says the tool runs without that flag. ----; User Report; ----. I just encountered this error in Mutect2: . Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx4g -jar /Users/loeblabm11/bioinformatics/programs/GATK/gatk-4.0.3.0/gatk-package-4.0.3.0-local.jar Mutect2 -R /Users/loeblabm11/bioinformatics/reference/human/hg19/hg19.fa -I 20171027_BN31_python.dcs.filt.no_overlap.bam -tumor BN31 -O 20171027_BN31_python.dcs.MuTect2.vcf -bamout 20171027_BN31_python.dcs.MuTect2.bam --max-reads-per-alignment-start 0 --max-population-af 1 --disable-tool-default-read-filters; 12:18:10.900 INFO NativeLibraryLoader - Loading libgkl_compression.dylib from jar:file:/Users/loeblabm11/bioinformatics/programs/GATK/gatk-4.0.3.0/gatk-package-4.0.3.0-local.jar!/com/intel/gkl/native/libgkl_compression.dylib; 12:18:11.387 INFO Mutect2 - ------------------------------------------------------------; 12:18:11.388 INFO Mutect2 - The Genome Analysis Toolkit (GATK) v4.0.3.0; 12:18:11.388 INFO Mutect2 - For support and documentation go to https://software.broadinstitute.org/gatk/; 12:18:11.388 INFO Mutect2 - Executing as loeblabm11@LoeblabM11s-iMac.local on Mac OS X v10.12.6 x86_64; 12:18:11.388 INFO Mutect2 - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_151-b12; 12:18:11.388 INFO Mutect2 - Start Date/Time: April 11, 2018 12:18:10 PM PDT; 12:18:11.388 INFO Mutect2 - ------------------------------------------------------------; 12:18:11.388 INFO Mutect2 - ------------------------------------------------------------; 12:18:11.388 INFO Mutect2 - HTSJDK Version: 2.14.3; 12:18:11.388 INFO Mutect2 - Picard Version: 2.17.2; 12:18:11.388 INFO Mutect2 - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 12:18:11.388 INFO Mutect2 - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : fals",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4665:32,error,errors,32,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4665,2,['error'],"['error', 'errors']"
Availability,"A few things worth mentioning. 1) This skeleton is mostly a direct port of the existing Dataflow pipeline.; 2) I had to modify some test data because there is a (masked) bug in the Dataflow code, see #795.; 3) Serialization was a slight pain and I had to bump the kryo version to the latest 2.x, as well as add two custom Serializers. If there's a cleaner way to handle any of that I'm all ears.; 4) I'm using Hadoop-bam for reading and writing reads and variants.; 5) There are unit tests for all code except for the skeleton itself. I've run it on a cluster on my machine successfully, but haven't written the tests (which will take a little while to design and get right).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/850:162,mask,masked,162,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/850,1,['mask'],['masked']
Availability,"A forum user reported an [issue](https://gatkforums.broadinstitute.org/gatk/discussion/comment/62040) with HaplotypeCallerSpark when run in --spark-mode on a non-dataproc cluster. ```; /gatk HaplotypeCallerSpark \; --input /data2/gatkBaseRecall/sorted.deduped.bqsr.bam \; -R /data2/gatk/gatk-4.1.4.1/Homo_sapiens_assembly19.fasta \; --emit-ref-confidence GVCF \; --output /data2/gatkBaseRecall/part/genome.vcf \; -- \; --spark-runner SPARK \; --spark-master spark://<myhost>:7077 \; --total-executor-cores 80 \; --executor-memory 10g; ```; He encounters the following error:. ```; Exception in thread ""main"" java.lang.NoSuchMethodError: htsjdk.samtools.util.IOUtil.isBlockCompressed(Ljava/nio/file/Path;Z)Z. Caused by: com.esotericsoftware.kryo.KryoException: Unable to find class: htsjdk.samtools.reference.AbstractFastaSequenceFile$$Lambda$85/2028177366; Serialization trace:; initializer (htsjdk.samtools.util.Lazy); dictionary (htsjdk.samtools.reference.IndexedFastaSequenceFile); sequenceFile (org.broadinstitute.hellbender.utils.fasta.CachingIndexedFastaSequenceFile); val$taskReferenceSequenceFile (org.broadinstitute.hellbender.tools.HaplotypeCallerSpark$1); at com.esotericsoftware.kryo.util.DefaultClassResolver.readName(DefaultClassResolver.java:156); at com.esotericsoftware.kryo.util.DefaultClassResolver.readClass(DefaultClassResolver.java:133); at com.esotericsoftware.kryo.Kryo.readClass(Kryo.java:670); at com.esotericsoftware.kryo.serializers.ObjectField.read(ObjectField.java:118); at com.esotericsoftware.kryo.serializers.FieldSerializer.read(FieldSerializer.java:551); at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:708); at com.esotericsoftware.kryo.serializers.ObjectField.read(ObjectField.java:125); at com.esotericsoftware.kryo.serializers.FieldSerializer.read(FieldSerializer.java:551); at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:708); at com.esotericsoftware.kryo.serializers.ObjectField.read(ObjectField.java:125); at com.esotericsoftware.kryo.serialize",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6341:568,error,error,568,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6341,1,['error'],['error']
Availability,A non-minimally represented allele in dbsnp was causing GenotypeGVCFs to throw an error. This PR fixes this and removes a TODO.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8567:82,error,error,82,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8567,1,['error'],['error']
Availability,A potential avenue of improvement to the Junciton Tree code would be to include mate information when generating junction trees. We likely would want to implement this feature in one form or another if we choose to expand the active region size for HaplotypeCaller. This would have the advantage of significantly improving our junction tree haplotype recovery range be ~ associated with insert size. Unfortunately this requires thought in order to figure out how to handle resolving the missing insert sequences. A solution to the insert problem will likely be closely linked to the solution to #5924.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6035:351,recover,recovery,351,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6035,1,['recover'],['recovery']
Availability,A quick and dirty implementation. The on thing that needs extra scrutiny is going to be the various conditions/failure states in the validate method. I think i caught most of the cases but there might be a gap somewhere.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8724:111,failure,failure,111,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8724,1,['failure'],['failure']
Availability,"A user building GATK on a POWER system tried to set `GATK_SKIP_NATIVE_BUILD=true`, but it didn't prevent the build from failing. ```; FAILURE: Build failed with an exception. * What went wrong:; A problem occurred configuring root project 'gatk'.; > Exception thrown while executing model rule: NativeComponentModelPlugin.Rules#createBinaries; > Invalid NativePlatform: linux_ppc64. BUILD FAILED; ```. the temporary workaround was the following change:. ```; $ diff build.gradle.org build.gradle; 406c406,408; < VectorLoglessPairHMM(NativeLibrarySpec) {. ---; > if(System.properties[""os.arch""] != ""ppc64""); > {; > VectorLoglessPairHMM(NativeLibrarySpec) {; 458a461; > }; ```. This is a bug and is likely to cause failures on other systems as well.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1711:134,FAILURE,FAILURE,134,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1711,2,"['FAILURE', 'failure']","['FAILURE', 'failures']"
Availability,"A user gets an issue with the HDF5 library when running DenoiseReadCounts on an arm64 processor. We would like to create a fallback solution for this tool, since in this case the tool is not working with HDF5 files. This request was created from a contribution made by dbpiero on June 01, 2021 10:22 UTC. Link: [https://gatk.broadinstitute.org/hc/en-us/community/posts/360078197412-Error-running-DenoiseReadCounts-on-arm64-processor](https://gatk.broadinstitute.org/hc/en-us/community/posts/360078197412-Error-running-DenoiseReadCounts-on-arm64-processor). \--. If you are seeing an error, please provide(REQUIRED) : ; ; a) GATK version used: 4.2.0.0. b) Exact command used: gatk DenoiseReadCounts -I sample.counts.tsv --annotated-intervals annotated\_intervals.tsv --standardized-copy-ratios sample.standardizedCR.tsv --denoised-copy-ratios sample.denoisedCR.tsv. c) Entire error log: A USER ERROR has occurred: Cannot load the required HDF5 library. HDF5 is currently supported on x86-64 architecture and Linux or OSX systems. Dear Administrators,. I try to run DenoiseReadCounts on new apple silicon chip (M1) with arm64 architecture, but I got this error: A USER ERROR has occurred: Cannot load the required HDF5 library. HDF5 is currently supported on x86-64 architecture and Linux or OSX systems. I created a docker with ubuntu 20.04 to launch gatk and I have already installed libhdf5-103:arm64 library and hdf5-tools inside but launching DenoiseReadCounts i get the same error. Is there a way to solve this issue?. Thanks<br><br><i>(created from <a href='https://broadinstitute.zendesk.com/agent/tickets/161375'>Zendesk ticket #161375</a>)<br>gz#161375</i>",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7297:382,Error,Error-running-DenoiseReadCounts-on-,382,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7297,8,"['ERROR', 'Error', 'error']","['ERROR', 'Error-running-DenoiseReadCounts-on-', 'error']"
Availability,"A user has encountered the following error when running GenotypeGVCFs on an input: ; ```Using GATK jar /nics/d/home/hchen3/bin/gatk-4.1.2.0/gatk-package-4.1.2.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /nics/d/home/hchen3/bin/gatk-4.1.2.0/gatk-package-4.1.2.0-local.jar GenotypeGVCFs -R /lustre/haven/proj/UTHSC0013/Tristan_GATK/reference/genome.fa -V gendb:///lustre/haven/proj/UTHSC0013/Tristan_GATK//DB/chr7 -G StandardAnnotation --use-new-qual-calculator -O /lustre/haven/proj/UTHSC0013/Tristan_GATK//gvcf//merged//joint_called_gvcfs_chr7.vcf; 23:15:47.053 WARN GATKAnnotationPluginDescriptor - Redundant enabled annotation group (StandardAnnotation) is enabled for this tool by default; 23:15:47.249 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/nics/d/home/hchen3/bin/gatk-4.1.2.0/gatk-package-4.1.2.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Jan 07, 2020 11:15:49 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 23:15:49.543 INFO GenotypeGVCFs - ------------------------------------------------------------; 23:15:49.545 INFO GenotypeGVCFs - The Genome Analysis Toolkit (GATK) v4.1.2.0; 23:15:49.546 INFO GenotypeGVCFs - For support and documentation go to https://software.broadinstitute.org/gatk/; 23:15:49.547 INFO GenotypeGVCFs - Executing as hchen3@acf-knl002 on Linux v3.10.0-514.26.1.el7.x86_64 amd64; 23:15:49.548 INFO GenotypeGVCFs - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_131-b12; 23:15:49.548 INFO GenotypeGVCFs - Start Date/Time: January 7, 2020 11:15:47 PM EST; 23:15:49.549 INFO GenotypeGVCFs - ------------------------------------------------------------; 23:15:49.549 INFO GenotypeGVCFs - ------------------------------------------------------------; 23:15:49.551 INFO ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6357:37,error,error,37,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6357,2,"['Redundant', 'error']","['Redundant', 'error']"
Availability,"A user has identified an issue with variants near regions of the reference with `N` bases:. https://gatk.broadinstitute.org/hc/en-us/community/posts/360072168572-Funcotator-errors-?page=1#community_comment_360012539271. If Funcotator gets to a codon sequence with `N` bases in it, right now it throws an exception because it cannot decode the `N` bases into a valid amino acid. Funcotator needs to be updated to provide a symbolic protein prediction stating that it was ambiguous because of reference IUPAC bases. The variant in question is from **HG19**:; ```; 4	9274640	.	A	ATCACTG,ATCCTG	.	.	BETA=0.989,0.141;FRACTION=0.022; ```. The reference around this variant is:. ![image](https://user-images.githubusercontent.com/11667487/91493420-4a1e1000-e885-11ea-97f5-820a44a054bc.png). ### Stack Trace:; ```; ***********************************************************************. A USER ERROR has occurred: Unknown file is malformed: File contains a bad codon sequence that has no amino acid equivalent: CNN. ***********************************************************************; org.broadinstitute.hellbender.exceptions.UserException$MalformedFile: Unknown file is malformed: File contains a bad codon sequence that has no amino acid equivalent: CNN; 	at org.broadinstitute.hellbender.tools.funcotator.FuncotatorUtils.createAminoAcidSequenceHelper(FuncotatorUtils.java:1195); 	at org.broadinstitute.hellbender.tools.funcotator.FuncotatorUtils.createAminoAcidSequence(FuncotatorUtils.java:1158); 	at org.broadinstitute.hellbender.tools.funcotator.ProteinChangeInfo.createProteinSequences(ProteinChangeInfo.java:125); 	at org.broadinstitute.hellbender.tools.funcotator.ProteinChangeInfo.<init>(ProteinChangeInfo.java:52); 	at org.broadinstitute.hellbender.tools.funcotator.ProteinChangeInfo.create(ProteinChangeInfo.java:371); 	at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createSequenceComparison(GencodeFuncotationFactory.java:2045); 	at org.broad",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6774:173,error,errors,173,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6774,2,"['ERROR', 'error']","['ERROR', 'errors']"
Availability,"A user has reported an error in the following code, on inspection it seems the only way we could be seeing this ArrayIndexOutOfBounds exception is if the byte in the recovered base array is -2, which should absolutely not be the case. I am asking for more context in the hopes of figuring out what is going on but this seems to be related with Cache misses due to the traversal pattern for CombineGVCFs. The issue can be found here: https://gatkforums.broadinstitute.org/gatk/discussion/24705/gatk-combinegvcfs-java-lang-arrayindexoutofboundsexception-index-2-out-of-bounds-for-length-256#latest. ```; java.lang.ArrayIndexOutOfBoundsException: Index -2 out of bounds for length 256; at org.broadinstitute.hellbender.utils.BaseUtils.convertIUPACtoN(BaseUtils.java:120); at org.broadinstitute.hellbender.utils.fasta.CachingIndexedFastaSequenceFile.getSubsequenceAt(CachingIndexedFastaSequenceFile.java:326); at org.broadinstitute.hellbender.engine.ReferenceFileSource.queryAndPrefetch(ReferenceFileSource.java:78); at org.broadinstitute.hellbender.engine.ReferenceDataSource.queryAndPrefetch(ReferenceDataSource.java:64); ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6338:23,error,error,23,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6338,2,"['error', 'recover']","['error', 'recovered']"
Availability,"A user on the GATK Forum submitted a request to make the INFO field easier to manipulate through creating a table. At the GATK Office Hours meeting 11/8, we discussed the two ideas and favored the first idea to make a new tool, similar to VariantsToTable, that would unpack the INFO field. This request was created from a contribution made by Shahryar Alavi on October 30, 2020 19:54 UTC. Link: [https://gatk.broadinstitute.org/hc/en-us/community/posts/360073983291-VariantsToTable-not-extracting-INFO-sub-fields-#community\_comment\_360013343072](https://gatk.broadinstitute.org/hc/en-us/community/posts/360073983291-VariantsToTable-not-extracting-INFO-sub-fields-#community_comment_360013343072). \--. But MAF output is somewhat different from VCF; and I think the VCF output format is better for germline variant annotation. With Funcotator we get an integrated (and minuter) ""variant calling - annotation"" workflow. But the problem is ""vertical bar"" separated INFOs are not easy for downstream text processing. I have two suggestions for the GATK Team:. You may want to develop a new tool (like VariantsToTable) to separate each ""sub-info"" in the FUNCOTATION INFO, and put them into separate columns with corresponding headers when creating the tab-delimited table. Or add a feature to Funcotator to create multiple INFOs with FUNCOTATION prefix in their IDs; e.g. #INFO=<ID=FUNCOTATION\\\_Gencode\\\_34\\\_hugoSymbol,...> ; ; #INFO=<ID=FUNCOTATION\\\_Gencode\\\_34\\\_ncbiBuild,...>. instead of. #INFO=<ID=FUNCOTATION,...,Description=""Funcotation fields are: Gencode\\\_34\\\_hugoSymbol|Gencode\\\_34\\\_ncbiBuild|..."">. Thanks<br><br><i>(created from <a href='https://broadinstitute.zendesk.com/agent/tickets/45403'>Zendesk ticket #45403</a>)<br>gz#45403</i>",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7556:987,down,downstream,987,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7556,1,['down'],['downstream']
Availability,"A user reported seeing this error with SplitNCigarReads v4.8.1.0 -- ""contig must be non-null and not equal to *, and start must be >= 1"".; There was a similar issue ticket for the same exception a couple years back: https://github.com/broadinstitute/gatk/issues/3466. User bug report below:. This request was created from a contribution made by Giulia Corsi on August 19, 2020 15:26 UTC. Link: [https://gatk.broadinstitute.org/hc/en-us/community/posts/360072548271-Error-in-SplitNCigarReads](https://gatk.broadinstitute.org/hc/en-us/community/posts/360072548271-Error-in-SplitNCigarReads). \--. I get the following error with GATK 4.1.8.1 when running SplitNCigarReads after MarkDuplicates on RNA-seq data:. java.lang.IllegalArgumentException: contig must be non-null and not equal to \*, and start must be >= 1. The command I used was the following (I did not include the full path to the files):. gatk SplitNCigarReads -R /home/data/hg38\_GRCh38.97\_nobackup/hg38\_primary\_refseq.fa -I /home/results/SOD1/results/5\_GATK\_dedupSplit/SOD1P\_A272C\_rep2/SOD1P\_A272C\_rep2.Dedup.bam -O /home/results/SOD1/results/5\_GATK\_dedupSplit/SOD1P\_A272C\_rep2/SOD1P\_A272C\_rep2.Split.bam. Here the log:. 11:08:24.240 INFO NativeLibraryLoader - Loading libgkl\_compression.so from jar:file:/home/results/SOD1/.snakemake/conda/93139e1d/share/gatk4-4.1.8.1-0/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl\_compression.so ; ; Aug 19, 2020 11:08:25 AM shaded.cloud\_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine ; ; INFO: Failed to detect whether we are running on Google Compute Engine. ; ; 11:08:25.663 INFO SplitNCigarReads - ------------------------------------------------------------ ; ; 11:08:25.663 INFO SplitNCigarReads - The Genome Analysis Toolkit (GATK) v4.1.8.1 ; ; 11:08:25.663 INFO SplitNCigarReads - For support and documentation go to [https://software.broadinstitute.org/gatk/](https://software.broadinstitute.org/gatk/) ; ; 11:08:25.664 INFO SplitNCi",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6776:28,error,error,28,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6776,4,"['Error', 'error']","['Error-in-SplitNCigarReads', 'error']"
Availability,"A user reported that when running GetPileupSummaries on gnomad vcf, the tool runs out of java heap memory. Xmx value was set to `-Xmx30G` and the machine has >200G RAM. **User Report**: I'm trying to run the cross sample contamination check on my samples, but GetPileupSummaries (4.1.1.0) keeps running out of memory, even when running a single sample on a VM that has >200GB of RAM available. <pre>; 14:35:16.874 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/gatk/gatk-package-4.1.1.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; 14:35:17.116 INFO GetPileupSummaries - ------------------------------------------------------------; 14:35:17.117 INFO GetPileupSummaries - The Genome Analysis Toolkit (GATK) v4.1.1.0; 14:35:17.117 INFO GetPileupSummaries - For support and documentation go to https://software.broadinstitute.org/gatk/; 14:35:17.118 INFO GetPileupSummaries - Executing as root@c64bec8aea6f on Linux v4.15.0-47-generic amd64; 14:35:17.118 INFO GetPileupSummaries - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_191-8u191-b12-0ubuntu0.16.04.1-b12; 14:35:17.118 INFO GetPileupSummaries - Start Date/Time: April 24, 2019 2:35:16 PM UTC; 14:35:17.118 INFO GetPileupSummaries - ------------------------------------------------------------; 14:35:17.119 INFO GetPileupSummaries - ------------------------------------------------------------; 14:35:17.119 INFO GetPileupSummaries - HTSJDK Version: 2.19.0; 14:35:17.119 INFO GetPileupSummaries - Picard Version: 2.19.0; 14:35:17.120 INFO GetPileupSummaries - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 14:35:17.120 INFO GetPileupSummaries - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 14:35:17.120 INFO GetPileupSummaries - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 14:35:17.120 INFO GetPileupSummaries - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 14:35:17.120 INFO GetPileupSummaries - Deflater: IntelDeflater; 14:35:17.120 INFO GetPileupSummaries - Inflater: IntelInflater;",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5918:383,avail,available,383,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5918,1,['avail'],['available']
Availability,"A while back I added a .dockstore.yml file to the gatk repo so that gatk workflows in the /script/ folder would be automatically synced in Dockstore after every push or release. This also allowed the workflows in every branch/release to be readily available in Terra. However, GATK’s 700+ branches has been causing problems for Dockstore syncs and in some instances associated released tags to be missing ([forum discussion](https://discuss.dockstore.org/t/dockstore-could-not-find-a-workflow-in-git-using-yml-though-it-worked-previously/4255/5)). . This PR adds filters to the dockstore.yml so that only the master branch and the releases gets synced to dockstore, also any future branches aren’t automatically synced. If anyone wants to sync their branch they’ll have to add their branch name to the dockstore.yml file in their branch.; More info on dockstore yml and filters can be found [here](https://docs.dockstore.org/en/develop/getting-started/github-apps/github-apps.html)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7217:248,avail,available,248,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7217,1,['avail'],['available']
Availability,A wrapper WDL that cuts down on excess params for our Beta users,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7894:24,down,down,24,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7894,1,['down'],['down']
Availability,"A.bam -L /share/Onc_Soft_DB/database/capsmart/bed/gene102.snpindel.capsmart.bed -U -o /share/Onc_RD_Pipeline/OncDir/yanhs/test/GATK/Z19W06700-F1WA.HaplotypeCaller.raw.vcf -stand_call_conf 50 -A RMSMappingQuality -A BaseCounts; INFO 14:49:42,892 HelpFormatter - Executing as yanhs3941@compute-0-76 on Linux 2.6.32-696.el6.x86_64 amd64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_11-b12.; INFO 14:49:42,892 HelpFormatter - Date/Time: 2021/10/09 14:49:42; INFO 14:49:42,892 HelpFormatter - ------------------------------------------------------------------------------------; INFO 14:49:42,892 HelpFormatter - ------------------------------------------------------------------------------------; INFO 14:49:42,922 NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/share/Onc_Soft_DB/software/GATK3.8/GenomeAnalysisTK.jar!/com/intel/gkl/native/libgkl_compression.so; INFO 14:49:42,957 GenomeAnalysisEngine - Deflater: IntelDeflater; INFO 14:49:42,958 GenomeAnalysisEngine - Inflater: IntelInflater; INFO 14:49:42,958 GenomeAnalysisEngine - Strictness is SILENT; INFO 14:49:43,125 GenomeAnalysisEngine - Downsampling Se. the error is :; maxAltAlleles (6), the following will be dropped: TAAC.; WARN 14:59:10,944 HaplotypeCallerGenotypingEngine - location chr12:21623284-21623286: too many alternative alleles found (8) larger than the maximum requested with -maxAltAlleles (6), the following will be dropped: C, CA.; INFO 14:59:13,453 ProgressMeter - chr12:21624342 1.0358131E7 9.5 m 55.0 s 49.5% 19.2 m 9.7 m; WARN 14:59:37,613 HaplotypeCallerGenotypingEngine - location chr12:133237753-133237756: too many alternative alleles found (9) larger than the maximum requested with -maxAltAlleles (6), the following will be dropped: G, TAAA, GAAAAAAA.; INFO 14:59:43,454 ProgressMeter - chr13:32892450 1.0955099E7 10.0 m 54.0 s 54.0% 18.5 m 8.5 m; INFO 15:00:13,456 ProgressMeter - chr13:32912251 1.0976428E7 10.5 m 57.0 s 55.2% 19.0 m 8.5 m; ##### ERROR --; ##### ERROR stack trace; java.lang.Ill",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7499:2065,Down,Downsampling,2065,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7499,1,['Down'],['Downsampling']
Availability,AFCalculator.getLog10PNonRef() was throwing a confusing error due to a typo.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2153:56,error,error,56,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2153,1,['error'],['error']
Availability,"AFPriorProviderUnitTest.java:37 compared doubles by strict equality which is not the right way. It should use the `TOLERANCE` (equal to `0.0001`) eg change . ```; Assert.assertEquals(priors[j], Math.log10(het) - Math.log10(j)); ```. to. ```; Assert.assertEquals(priors[j], Math.log10(het) - Math.log10(j), TOLERANCE); ```. @frank-y-liu can you make this change and see it if fixed your problem? If yes, can you contribute a fix?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1536:115,TOLER,TOLERANCE,115,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1536,2,['TOLER'],['TOLERANCE']
Availability,ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 16:46:04.321 INFO VariantsToTable - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 16:46:04.321 INFO VariantsToTable - Deflater: IntelDeflater; 16:46:04.322 INFO VariantsToTable - Inflater: IntelInflater; 16:46:04.322 INFO VariantsToTable - GCS max retries/reopens: 20; 16:46:04.322 INFO VariantsToTable - Requester pays: disabled; 16:46:04.322 INFO VariantsToTable - Initializing engine; 16:46:04.805 INFO FeatureManager - Using codec VCFCodec to read file file:///home/india/Downloads/Galaxy57-%5BMerged_file.vcf%5D.vcf; 16:46:04.896 INFO VariantsToTable - Done initializing engine; 16:46:04.917 WARN VariantsToTable - Allele-specific fields will only be split if splitting multi-allelic variants is specified (`--split-multi-allelic` or `-SMA`; 16:46:04.918 INFO ProgressMeter - Starting traversal; 16:46:04.918 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 16:46:05.217 INFO VariantsToTable - Shutting down engine; [16 October 2020 at 4:46:05 PM IST] org.broadinstitute.hellbender.tools.walkers.variantutils.VariantsToTable done. Elapsed time: 0.04 minutes.; Runtime.totalMemory()=132120576; htsjdk.tribble.TribbleException: partial missing values for GL field; 	at htsjdk.variant.variantcontext.GenotypeLikelihoods.parseDeprecatedGLString(GenotypeLikelihoods.java:269); 	at htsjdk.variant.variantcontext.GenotypeLikelihoods.fromGLField(GenotypeLikelihoods.java:78); 	at htsjdk.variant.vcf.AbstractVCFCodec.createGenotypeMap(AbstractVCFCodec.java:817); 	at htsjdk.variant.vcf.AbstractVCFCodec$LazyVCFGenotypesParser.parse(AbstractVCFCodec.java:121); 	at htsjdk.variant.variantcontext.LazyGenotypesContext.decode(LazyGenotypesContext.java:158); 	at htsjdk.variant.variantcontext.LazyGenotypesContext.ensureSampleNameMap(LazyGenotypesContext.java:180); 	at htsjdk.variant.variantcontext.GenotypesContext.containsSample(GenotypesContext.java:659); 	at htsjdk.variant.variantcontext.VariantContext.hasGenotype(Varia,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6897:3486,down,down,3486,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6897,1,['down'],['down']
Availability,"ATK version used: 4.1.8.1 ; ; b) Exact command used:. java -Xmx8000m -Djava.io.tmpdir=/broad/hptmp/cbao \\ ; ; \-jar ${path2gatk}/gatk-package-4.1.8.1-local.jar \\ ; ; ASEReadCounter \\ ; ; \-L scattered.interval\_list \\ ; ; \-R Homo\_sapiens\_assembly19.fasta \\ ; ; \-V 1000G\_phase1.snps.high\_confidence.b37.vcf.gz \\ ; ; \-I downsample\_10k.bam \\ ; ; \-O output.txt --verbosity INFO. c) Entire error log:. 19:13:25.991 INFO NativeLibraryLoader - Loading libgkl\_compression.so from jar:file:/broad/software/free/Linux/redhat\_7\_x86\_64/pkgs/gatk\_4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl\_compression.so. Jun 14, 2021 7:13:26 PM shaded.cloud\_nio.com.google.auth.oauth2.DefaultCredentialsProvider warnAboutProblematicCredentials. WARNING: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a ""quota exceeded"" or ""API not enabled"" error. For more information about service accounts, see [https://cloud.google.com/docs/authentication/](https://cloud.google.com/docs/authentication/). 19:13:26.217 INFO ASEReadCounter - ------------------------------------------------------------. 19:13:26.218 INFO ASEReadCounter - The Genome Analysis Toolkit (GATK) v4.1.8.1. 19:13:26.218 INFO ASEReadCounter - For support and documentation go to [https://software.broadinstitute.org/gatk/](https://software.broadinstitute.org/gatk/). 19:13:26.219 INFO ASEReadCounter - Executing as [cbao@uger-c009.broadinstitute.org](mailto:cbao@uger-c009.broadinstitute.org) on Linux v3.10.0-1160.15.2.el7.x86\_64 amd64. 19:13:26.219 INFO ASEReadCounter - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0\_181-b13. 19:13:26.219 INFO ASEReadCounter - Start Date/Time: June 14, 2021 7:13:25 PM UTC. 19:13:26.219 INFO ASEReadCounter - ------------------------------------------------------------",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7327:2027,error,error,2027,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7327,1,['error'],['error']
Availability,"About 3% of our GATK 4.0.0.0 GenotypeGVCFs runs (with a GenomicsDB as input) are failing with a `__pthread_tpp_change_priority` error and exiting with status -6. The stderr of such a run ends like this:; ```; 2018-03-10T07:14:27.165578644Z GENOMICSDB_TIMER,GenomicsDB iterator next() timer,Wall-clock time(s),74.01474455399772,Cpu time(s),62.96424693700022; 2018-03-10T07:14:27.168329699Z java: tpp.c:84: __pthread_tpp_change_priority: Assertion `new_prio == -1 || (new_prio >= fifo_min_prio && new_prio <= fifo_max_prio)' failed.; ```. Stdout from the same run:; ```; 2018-03-09T13:13:41.095913747Z 13:13:41.095 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/gatk/gatk.jar!/com/intel/gkl/native/libgkl_compression.so; 2018-03-09T13:13:41.329888610Z 13:13:41.327 INFO GenotypeGVCFs - ------------------------------------------------------------; 2018-03-09T13:13:41.329934964Z 13:13:41.327 INFO GenotypeGVCFs - The Genome Analysis Toolkit (GATK) v4.0.0.0; 2018-03-09T13:13:41.329942970Z 13:13:41.327 INFO GenotypeGVCFs - For support and documentation go to https://software.broadinstitute.org/gatk/; 2018-03-09T13:13:41.329952404Z 13:13:41.328 INFO GenotypeGVCFs - Executing as root@localhost on Linux v4.4.0-112-generic amd64; 2018-03-09T13:13:41.329960555Z 13:13:41.328 INFO GenotypeGVCFs - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_151-8u151-b12-1~deb9u1-b12; 2018-03-09T13:13:41.329988865Z 13:13:41.328 INFO GenotypeGVCFs - Start Date/Time: March 9, 2018 1:13:41 PM UTC; 2018-03-09T13:13:41.329995417Z 13:13:41.328 INFO GenotypeGVCFs - ------------------------------------------------------------; 2018-03-09T13:13:41.330000910Z 13:13:41.328 INFO GenotypeGVCFs - ------------------------------------------------------------; 2018-03-09T13:13:41.330011002Z 13:13:41.328 INFO GenotypeGVCFs - HTSJDK Version: 2.13.2; 2018-03-09T13:13:41.330022980Z 13:13:41.328 INFO GenotypeGVCFs - Picard Version: 2.17.2; 2018-03-09T13:13:41.330030226Z 13:13:41.329 INFO GenotypeGVCFs - ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4518:128,error,error,128,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4518,1,['error'],['error']
Availability,"Accompanying this branch is and will be an official new release of the Funcotator Datasource bundles: ; gs://broad-public-datasets/funcotator/funcotator_dataSources.v1.8.hg19.20230908g.tar.gz; gs://broad-public-datasets/funcotator/funcotator_dataSources.v1.8.hg19.20230908s.tar.gz; gs://broad-public-datasets/funcotator/funcotator_dataSources.v1.8.hg38.20230908g.tar.gz; gs://broad-public-datasets/funcotator/funcotator_dataSources.v1.8.hg38.20230908s.tar.gz; ; Note that the format of the datasources bundles has changed somewhat, importantly they are now split into separate hg19 and hg38 bundles to cut down on size. In this branch are:; - The necessary changes to the FuncotatorDownloaderScript to accomidate the new bundles; - Changes to the various Funcotator datasource downloader scripts to point to newer releases of bundled sources used in this release; - A fix for the MAF output renderer to handle Gencodev43 datasources. Fixes #8296",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8512:606,down,down,606,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8512,2,['down'],"['down', 'downloader']"
Availability,"According to [https://docs.travis-ci.com/user/customizing-the-build#git-clone-depth](url), Travis CI provide a way to shallow clone a repository. This has the obvious benefit of speed, since you only need to download a small number of commits.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7415:208,down,download,208,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7415,1,['down'],['download']
Availability,Add DocOnlyArgumentCollection for better downstream toolkit extensibility,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4474:41,down,downstream,41,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4474,1,['down'],['downstream']
Availability,"Add `rebalanceChunks` which allows the ExampleNioCountReads to work with inputs that contain many large contigs. I was able to run it on a 300GB full genome input without crashes or hangs. This PR also fixes a bug where ExampleNioCountReads would return different values depending on how much workers were assigned. The bug's now fixed for small inputs, but a related one still happens for large inputs (though the magnitude of the error's less). I'm still submitting since this work is more of a proof-of-concept at this point, but it's good to keep in mind.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3526:432,error,error,432,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3526,1,['error'],['error']
Availability,Add a few additional failures to our notes doc,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8980:21,failure,failures,21,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8980,1,['failure'],['failures']
Availability,"Add a test that validates than an ambiguous interval query can be disambiguated by the user by providing the interval in a bed file; changes the error message to recommend this alternative; fixes an issue where the error message was displaying the entire interval query multiple times, rather than the specific contigs which make the query ambiguous.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4183:145,error,error,145,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4183,2,['error'],['error']
Availability,Add a tolerance to the range check for the probability in ActivityProfileState,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1759:6,toler,tolerance,6,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1759,1,['toler'],['tolerance']
Availability,"Add ability for the Funcotator datasource downloader tool to download datasources for JUST a single reference (eg., hg38 or b37)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6711:42,down,downloader,42,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6711,2,['down'],"['download', 'downloader']"
Availability,Add ability to downsample reads in Spark at the Hadoop-BAM level.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1644:15,down,downsample,15,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1644,1,['down'],['downsample']
Availability,"Add additional validation around duplicated rows in the VAT; <img width=""1418"" alt=""duplicate_AN_or_AC_values"" src=""https://user-images.githubusercontent.com/6863459/220667710-a416ab64-4f9b-475b-9268-ef7b86bfa81e.png"">. This has a successful run (except for one failure that is because it's being run on way less data); https://job-manager.dsde-prod.broadinstitute.org/jobs/07ddde58-ac0d-4229-9f96-d093f5c11682; The failed test is:; SpotCheckForAAChangeAndExonNumberConsistency. Perhaps we want to update this to not run this test if there are less than 10k samples?; Yes we do:; Here's the ticket for that:; https://broadworkbench.atlassian.net/browse/VS-878",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8175:262,failure,failure,262,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8175,1,['failure'],['failure']
Availability,Add better error message when Java is not installed to the launch script,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5992:11,error,error,11,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5992,1,['error'],['error']
Availability,Add better error message when submitting an empty bam to spark,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4869:11,error,error,11,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4869,1,['error'],['error']
Availability,"Add hint to Cloud IO errors (""check README"")",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5477:21,error,errors,21,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5477,1,['error'],['errors']
Availability,Add masking and spacing for SVKmers,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2662:4,mask,masking,4,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2662,1,['mask'],['masking']
Availability,Add methods to SparkCommandLineProgram that let you query the amount of memory available per executor / per core,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1456:79,avail,available,79,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1456,1,['avail'],['available']
Availability,"Add more information to ""annotation will not be calculated"" error messages",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6892:60,error,error,60,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6892,1,['error'],['error']
Availability,"Add more test cases for the errors seen in issue #6289 . Specifically we should add both more unit tests and integration tests. One variant that should be added in integration tests is the following:; ```; ##fileformat=VCFv4.1; ##contig=<ID=chr9,length=138394717>; ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">; #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	Sample; chr9	67726241	.	TCA	TCACACA,TCACACACA	182	PASS	.	GT	./.; ```. The issue with adding more tests is that we don't have the full Funcotator datasources in our `git-lfs` repo because of size concerns. To add tests we'll need to add more intervals to our datasources to support the variants' loci, or create variants in the regions we already cover.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7523:28,error,errors,28,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7523,1,['error'],['errors']
Availability,Add nck with message to StreamingProcessController for passing fatal error messages.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5170:69,error,error,69,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5170,1,['error'],['error']
Availability,"Add registry of unported GATK3 tools, output nice error message when user tries to run one",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4351:50,error,error,50,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4351,1,['error'],['error']
Availability,Add retries on auth failure,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3739:20,failure,failure,20,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3739,1,['failure'],['failure']
Availability,Add script executor error message for SIGKILL exit code 137.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6414:20,error,error,20,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6414,1,['error'],['error']
Availability,Add test for DataProvider failures,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3619:26,failure,failures,26,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3619,1,['failure'],['failures']
Availability,Add the ability for downstream projects to customize which packages to search for Annotation classes,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3610:20,down,downstream,20,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3610,1,['down'],['downstream']
Availability,Add unit tests for DownsampleSam,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/203:19,Down,DownsampleSam,19,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/203,1,['Down'],['DownsampleSam']
Availability,Add utilites to update Echo filters and reference genotypes,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8867:23,Echo,Echo,23,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8867,1,['Echo'],['Echo']
Availability,Add validation to SparkSharder to get better information about sequence dictionary errors,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2615:83,error,errors,83,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2615,1,['error'],['errors']
Availability,AddOrReplaceReadGroups error,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6796:23,error,error,23,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6796,2,['error'],['error']
Availability,"Added .dockstore.yml file to the root directory of the gatk repo to allow automatic syncing to occur with workflows in [Dockstore](https://dockstore.org/organizations/BroadInstitute/collections/GATKWorkflows). ; **Problem:** ; The GATK workflows are currently organized in [Dockstore](https://dockstore.org/organizations/BroadInstitute/collections/GATKWorkflows), maintenance of the workflows requires manually refreshing the workflow profile in Dockstore in order to view the latest releases of the workflows. Also some workflows like germline_cnv fails to sync because Dockstore has trouble handling the number of branches/tags in the gatk repo.; **Solution:** ; Adding the dockstore yml file allows this syncing to happen automatically whenever there is a push to the gatk repo. This may also help focus which branches to sync and prevent Dockstore from failing during sync. . See [doc](https://docs.dockstore.org/en/develop/getting-started/github-apps/github-apps.html) for description.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6770:364,mainten,maintenance,364,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6770,1,['mainten'],['maintenance']
Availability,"Added XGBoostEvidenceFilter, an alternative BreakpointEvidence filter; based on XGBoost classifier.; - Default is still BreakpointDensityFilter. Switch by passing; ""--sv-evidence-filter-type XGBOOST"" instead of ""DENSITY"".; - Decisions based on evidence overlap or coherence are now scaled based; on coverage depth (in both filter types).; - Multiple avenues for supplying saved classifier binary file,; including built-in resource, local file, and google cloud storage.; - BreakpointEvidence updated to carry information necessary for; classifier. Unit tests were correspondingly updated.; - Data from genome tracts used for some classifier features. From the; hg38 genome: gaps, centromeres, and umap s100. Additional changes to convenience scripts; - Updated sanity_checks.sh to return error signal when exiting; - Bugfixes to manage_sv_pipeline.sh for linux compatibility; - Update run_whole_pipeline.sh to detect preemptible workers and; thus set NUM_EXECUTORS correctly",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4769:788,error,error,788,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4769,1,['error'],['error']
Availability,Added a more informative error message to pileup when the user provides invalid output file,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1917:25,error,error,25,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1917,1,['error'],['error']
Availability,"Added a new catch block in `PathLineIterator` for character encoding; errors, along with a new error message to be given to the user for such; cases. Added unit test for malformed xsv locatable files. Fixes #4006",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5124:70,error,errors,70,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5124,2,['error'],"['error', 'errors']"
Availability,"Added a new catch block in `PathLineIterator` for character encoding; errors, along with a new error message to be given to the user for such; cases. Fixes #4006",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5119:70,error,errors,70,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5119,2,['error'],"['error', 'errors']"
Availability,Added a slightly better debugging/error message to MarkDuplciatesSpark for duplicate readname issues.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4879:34,error,error,34,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4879,1,['error'],['error']
Availability,Added a slightly more helpful error message to the reads filter,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7947:30,error,error,30,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7947,1,['error'],['error']
Availability,Added better error messages around missing ReadGroups in MarkDuplicatesSpark,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5177:13,error,error,13,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5177,1,['error'],['error']
Availability,Added in a script to pull down the latest Gencode data source.; Fixed an issue in 5' UTR processing that would cause variant alleles with length > 1 to throw an exception (issue 4712).; Added three test cases to prevent regression of issue 4712.; Updated Gencode codec to be compatible with latest Gencode release (v28).; Fixed a bug in the version detection for Funcotator data sources that would prevent newer data source versions from being detected as compatible (date comparison error).,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4770:26,down,down,26,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4770,2,"['down', 'error']","['down', 'error']"
Availability,Added in code to pull config elements from the Owner configuration.; Hooked the configuration into the classes where it is necessary.; Added in a config file with defaults.; Added in utilities and consolidated hooks for configuration code.; Added in help text for configuration file options in gatk-launch. Basic configuration options have been implemented and hooked; into files where appropriate. Configuration values in properties files cannot currently have; trailing spaces - this results in a parsing error. There is a; workaround that has not yet been implemented. Fixes #3126,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3447:507,error,error,507,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3447,1,['error'],['error']
Availability,"Added in test condition for AD field with only 1 value in MAF mode. This isn't really a bug, but an error mode that needed more explicit; feedback.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5860:100,error,error,100,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5860,1,['error'],['error']
Availability,Added new catch block for character encoding error cases.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5119:45,error,error,45,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5119,2,['error'],['error']
Availability,Added the ability for Indels to be recovered from dangling heads,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6113:35,recover,recovered,35,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6113,1,['recover'],['recovered']
Availability,Added the option to supply multiple mask files to VariantFiltration,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8237:36,mask,mask,36,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8237,1,['mask'],['mask']
Availability,Adding `FuncotateSegments` as an option to the Somatic CNV WDL.; - Added automated WDL test to find obvious failures.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5967:108,failure,failures,108,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5967,1,['failure'],['failures']
Availability,"Adding in the option for using a compressed representation of our reference data. The flag use_compressed_references needs to be passed into ingest and also export, and doing so causes us to use a different internal schema for the ref_ranges table that can save ~40% on space. On the VCF path, the packed data is expanded while we populate the prepare tables before extract. On the VDS path, the packed data is expanded while we extract from the tables to create the Avro files. I updated integration tests to take use_compressed_refs as an option, and saw what I needed. Integrations tests for the VCF and VDS paths go to completion and fail, but in the expected way. AssertIdenticalOutputs, the important part, passes. AssertTableSizesAreExpected fails because the ref_ranges table is so much smaller (255884464 vs 431805033 expected) and AssertCostIsTrackedAndExpected fails because the PrepareRangesCallsetTask.GvsPrepareRanges.BigQuery Query Scanned is similarly smaller (340787200 vs 515899392). Given the nature of the change and the fact that it is an optional flag that defaults to zero, updating the integration tests to cover this path did not seem sound at this time. But using them to verify that the _content_ of the final vcfs wasn't affected by the change makes more sense. VCF integration run: https://job-manager.dsde-prod.broadinstitute.org/jobs/e9896786-9d3f-48b9-ab6f-9a76d9fafafe; Hail integration run: https://job-manager.dsde-prod.broadinstitute.org/jobs/dbdd0934-50c3-4477-a191-3282341eacd3. another post-merge integration run with same results: identical outputs, failure due to lower table sizes and query scan costs; https://job-manager.dsde-prod.broadinstitute.org/jobs/edabdac3-1856-4e2a-aadc-3bcd4c353956",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8543:1590,failure,failure,1590,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8543,1,['failure'],['failure']
Availability,Adding links to download java 8 to the ReadMe.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6025:16,down,download,16,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6025,1,['down'],['download']
Availability,"Adding the errorOnOutOfDateIndex option, which will cause a; UserException to be thrown when an index file is opened that is out of; date with respect to its data file. This option defaults to false to; preserve baseline behavior. Split tests apart and added a method to change the last modified time of a file. Fixes #1683",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3063:11,error,errorOnOutOfDateIndex,11,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3063,1,['error'],['errorOnOutOfDateIndex']
Availability,"Additional cleanup on the VAT--specifically focused on the failing shards and optimizing the workflow with them in mind. As a next step, this workflow will be split up into 3 sub-workflows to keep the failures from knocking over the remaining likely-successful shards",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7531:201,failure,failures,201,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7531,1,['failure'],['failures']
Availability,"Addresses #6242. Current behavior: when all the reads in a read group are filtered in the base recalibration step, the read group is not logged in the recal table. Then ApplyBQSR encounters these reads, can't find the read group in the recal table, and throws an error. New behavior: if `--allow-read-group` flag is set to true, then ApplyBQSR outputs the original quantities (after quantizing). . I avoided the alternative approach of collapsing (marginalizing) across the read groups, mostly because it would require a complete overhaul of the code. I also think that using recal data from other read groups might not be a good idea. In any case, using OQ should be good enough; I assume that these ""missing"" read groups are low enough quality to be filtered out and are likely to be thrown out by downstream tools. I also refactored the BQSR code, mostly to update the variable and class names to be more accurate and descriptive. For instance:. ReadCovariates.java -> PerReadCovariateMatrix.java; EstimatedQReported -> ReportedQuality",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/9020:263,error,error,263,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/9020,2,"['down', 'error']","['downstream', 'error']"
Availability,"Addresses https://github.com/broadinstitute/dsp-spec-ops/issues/307. - Increase headroom on VM above Java; - Increase disk space (incidental, not related to OOM); - parameterized Gnarly usage, default to false; - --emit-pls set to false no longer pulls down PLs. Compared results against baseline and saw no changes in GIAB results using ACMG cohort",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7245:253,down,down,253,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7245,1,['down'],['down']
Availability,"Addresses two user requests to more flexibly and accurately match dbSNP variants. https://gatk.broadinstitute.org/hc/en-us/community/posts/360066006472-gatk-4-1-4-1-HaplotypeCaller-D-parameter-for-MIXED-type. https://gatk.broadinstitute.org/hc/en-us/community/posts/360062537671-GATK-4-1-7-0-does-not-annotate-ID-using-dbSNP-build-153-VCF. The first change is to add all dbsnp id's which match a particular variant to the variant's id, instead of just the first one found in the dbsnp vcf. The second change is to be less brittle to variant normalization issues, and match differing variant representations of the same underlying variant. This is implemented by splitting and trimming multiallelics before checking for a match, which I suspect are the predominant cause of these types of matching failures.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6626:797,failure,failures,797,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6626,1,['failure'],['failures']
Availability,"Addressing OOM in CohortExtract (#7245); - make outputs optional, change case in output (#7252); - Support for FORMAT/FT VQSLod Filtering and cohort-wide LowQual filter (#7248); - removed arrays code, renamed packages (#7260); - 279 labels (#7233); - add conda commands to GIAB readme (#7268); - remove gvs branch (#7263); - remove gvs branch (#7263); - upgrade bq libraries (#7264); - #299 - Sample list ease of use for cohort extracts (#7272); - check for duplicate ids (#7273); - Rc 274 passing sites only (#7275); - added default value to drop_state; broadinstitute/dsp-spec-ops#310 (#7278); - version bump for reliability (#7284); - add timestamp check to ExtractTask call https://github.com/broadinstitute/dsp-spec-ops/issues/320; - serial inserts for scaling prepare, factored out sample name (#7288); - Remove training sites only param from ExtractFeatures broadinstitute/dsp-spec-ops#261; - add param for mem for indels (#7282); - Ah prepare localize option (#7299); - Export sites only vcf STEP 1-- 317 add AC, AN, AF to the final VCF (#7279); - AoU GVS Cohort Extract wdl (#7242); - reliability (#7310); - bump to include FT tag filtering (#7316); - First pass at a Terra QuickStart (#7267); - Ah fix timestamp query (#7319); - 313 Cleanup Extract Cohort params (#7293); - bump bq storage version. See GVS-332 (#7330); - Variant Store extraction - Add VCF size to output (#7329); - add WARP-style scattering to SNPsVariantRecalibrator in GvsCreateFilterSet (#7320); - added ref ranges support (#7337); - 318 Sites only filtered vcf then annotate wdl (#7305); - Replace service_account_json (file) with service_account_json_path (string) to allow call-caching (#7347); - Parallelize create filterset by breaking out the 3 filter set file creation/loads into separate tasks (#7342); - Create WDL to validate VAT and add first test (#7352); - Add task for VAT validation #3 (#7360); - Add task for VAT validation #4 (#7363); - Instructions on how to download BQ Metadata and visualize results ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8248:15255,reliab,reliability,15255,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8248,2,['reliab'],['reliability']
Availability,"Adds PathSeqPipelineSpark master tool, which required some minor changes:; -Refactored PSScoreUtils class to a PSScorer, which now includes the main Score tool code; -Moved code for paring down the pathogen header into a new function removeUnmappedHeaderSequences(). Spark-related optimizations:; -Removed cache() calls when possible, and replaced with persist(), spilling to disk with serialization, if necessary; -Removed try-with-resources in Filter and Bwa tools, which seemed to be causing the BWA/kmer references to be unloaded prematurely. Other changes:; -Changed ambiguous base filter from using a fraction of bases to number of bases; -Added function for closing all kmer filter instances; -Optimized PSBwaAligner SA tag construction; -Renamed repartitionPairedReads() to repartitionReadsByName(); -Resolved some conflicting tool argument names; -Created PathSeq tool program group; -Filled out tool summary strings",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3271:189,down,down,189,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3271,1,['down'],['down']
Availability,"Adds a WDL that replaces the ""serial"" SnpThenIndel joint filtering workflow added in #7932. This simplified replacement only runs one iteration of the extract-train-score toolchain, rather than running one iteration for SNPs followed by another for INDELs. The original SnpThenIndel workflow (used for Ultima) will be updated and moved to the WARP repo. (EDIT: I was originally confused here, the WDL that was replaced in this PR simply ran SNPs and indels separately, rather than serially. Curious that things still tied out, but I’m not sure it’s worth looking into at this point.). Test files have also been subset to chr21-22 and slimmed down. A test for the positive-negative was also added, as well as tests of an empty shard. The first commit contains the original workflow (JointVcfFilteringOriginal.wdl), as well as a reimplementation (JointVcfFilteringSnpThenIndel.wdl) that calls the simplified workflow (JointVcfFiltering.wdl). I've verified that both the original and reimplemented SnpThenIndel workflows tie out on the original test data. The second commit then removes the original and the reimplementation, leaving only the simplified workflow. It may thus be easier to review the first commit, second commit, or the overall changes, depending on what you are looking at. @meganshand can you take a look and let me know if there's any missing functionality, or if this otherwise won't work for Ultima and/or importing in WARP? Apologies for the delay!",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8074:642,down,down,642,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8074,1,['down'],['down']
Availability,Adds additional filtering steps to the PathSeq filter to 1) trim adapter sequences and 2) mimic a simple filter used in RepeatMasker that masks windows with excessive A/T or G/C content.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3354:138,mask,masks,138,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3354,1,['mask'],['masks']
Availability,"Adds updated tools for creating the host reference kmer set (PathSeqBuildKmers) and filtering reads that are low-quality, low-complexity, or come from the host (PathSeqFilterSpark). Sorry for the especially large size on this PR. **PathSeqBuildKmers tool**. Note this has been renamed from PathSeqKmerSpark. Input:; 1) Host reference FASTA; 2) False positive probability (0 create a hash set, >0 to create a Bloom filter); 3) Kmer length (1-31); 4) Kmer base indices to mask (optional). Output:; 1) Serialized kmer Hopscotch set (.hss) or Bloom filter (.bfi) file. For each reference record, the tool generates a list of long's containing the canonicalized/masked kmers. The result is a Collection<long[]> variable, which is then converted to either a PSKmerSet (Hopscotch set) or PSKmerBloomFilter, depending on the desired false positive probability. . The PSKmerSet/BloomFilter classes are basically wrappers for LargeLongHopscotchSet and LongBloomFilter, respectively. They both inherit PSKmerCollection, which provides a contains() function for querying new kmers for set membership and makes loading the kmers for filtering more convenient. These classes also store the kmer size, mask, and false positive probability. They also handle canonicalization/masking on queried kmers. **PathSeqFilterSpark tool**. Input:; 1) Input BAM; 2) Host kmer set file (optional); 3) Host reference bwa image (optional). Output:; 1) BAM containing paired reads that still have mates; 2) BAM containing unpaired reads / reads whose mates were filtered out; 3) Metrics file containing read counts and elapsed wall time at each step (optional). Filtering steps performed on each read:; - If the user sets the --isHostAligned, the read will first be filtered if it is aligned sufficiently well ; - Alignment info is stripped; - A series of quality filters (same as in the previous version of this tool); - Kmerized and filtered out if at least a threshold number of kmers are in the host set (default 1); - Aligned t",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3115:470,mask,mask,470,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3115,2,['mask'],"['mask', 'masked']"
Availability,"After #5416 one of the lingering potential sources of difference between HaplotypeCallerSpark and HaplotypeCaller are in the downsampling, which could cost Spark both correctness and performance at pathological sites. This likely requires #5437 or some equivalent change to be implemented so we can save ourselves from materializing and shuffling all the reads in their AssemblyRegions.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5476:125,down,downsampling,125,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5476,1,['down'],['downsampling']
Availability,"After banging my head on GetPileupSummaries for a bit, I think I've figured out a problem with the tool: it assumes that the AF INFO annotation is always present in an input VCF. There are several ways that it could proceed with a record/VCF that doesn't have AF, but the way it currently does (silently skip all of those records) is not a good one. I had zero indication as to why the output was empty.; FWIW, I would suggest doing the following:; 1. Warn the user the first time it encounters a record with no AF that such a record will be ignored.; 2. If no records contain AF then throw a User error at the end of the traversal.; 3. Provide an option to the tool that tells it to assume that the AF is less than 0.2 if not present. We should probably fix this before the release.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3955:598,error,error,598,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3955,1,['error'],['error']
Availability,"After doing somatic variant calling, the AD shows that the alternate allele is supported by three to five reads out of typically about eighty reads for almost all of the variants and the patient has about 10 times less SNVs reported in their VCF than all of the other patients with the same disease. Could MuTect2 have a QC failure status output if almost all of the variants reported are close to the limit of detection, which appears to be about three reads for MuTect2, looking at the second AD values in the cancer sample?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6674:324,failure,failure,324,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6674,1,['failure'],['failure']
Availability,Allow users to turn off Mutect2 error model fix from 4.1.9.0,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8447:32,error,error,32,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8447,1,['error'],['error']
Availability,"Also changed LegacySegmentCollection and CalledLegacySegmentCollection writers to overwrite instead of append. (This was fixed for AbstractRecordCollection writers in an earlier PR but was missed in these collections that override the default writer.). See https://gatkforums.broadinstitute.org/gatk/discussion/24048/a-few-things-need-help-about-output-of-command-modelsegments#latest for some context. In principle, IGV should be able to handle linear scaling, but it scales automatically for seg files and I'm not sure if you can get around it without some additional steps. Seems easier to just output log2 copy ratios. (Perhaps we initially output linear copy ratios to maintain backwards compatibility with previous versions of GATK CNV? If so, the *LegacySegmentCollections seem to be pulling double duty, since we use them to provide IGV compatibility. In any case, we are currently inconsistent between ModelSegments and CallCopyRatioSegments, as I noted in the forum post.) . @LeeTL1220 any objections? If downstream scripts are consuming the IGV output of ModelSegments, they should be adjusted if necessary.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5976:1015,down,downstream,1015,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5976,1,['down'],['downstream']
Availability,"Also extracted some argument collections and genotyping code (see https://github.com/broadinstitute/gatk/issues/3915), fixed up some documentation, and did some refactoring to the Segmenter classes. This is just a first implementation for evaluation and feedback. There is some redundant (but cheap) computation performed in the genotyping step and both the genotyping and segmentation steps are not optimized for memory use. However, since requirements are not onerous (probably around ~10GB memory and <10 minutes for ~10 typical WGS samples), it might not be worth fixing up at the expense of extra code. Likewise, this implementation requires all inputs be available. We could relax this to allow optional dimensions of input (i.e., copy ratios or allele counts) and/or case-only mode (as in ModelSegments), at the expense of extra control-flow code. One could also perform segmentation with an external tool and pass it to ModelSegments, as long as it is properly formatted. Closes #2924.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6499:278,redundant,redundant,278,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6499,2,"['avail', 'redundant']","['available', 'redundant']"
Availability,"Also fixed some minor style issues in argument variable names and the WDL. This should help recover some deletions and might possibly clear up some issues with MAF estimation when the number of hets is small. @LeeTL1220 can you run on some test cases to check the effect? (Note that the changes to fix estimation of the posterior widths, which will in turn affect similar-segment smoothing, are in another branch; we should test those changes as well.). Note that the default threshold of zero for the tumor in matched-normal mode should ensure that the sites genotyped as het should always match in the tumor and the normal. (This will ultimately make multisample segmentation, as enabled by #5524, more straightforward.) There was previously a check for this condition in the integration test; however, it wasn't actually activated by the test data. I could modify the test data to add a proper regression test, but since these test files are generated by running another tool on a test BAM in the repo, this could be misleading. I'm OK with punting in this case. @jonn-smith do you mind reviewing, since this resulted from your turn as liaison? Should be super quick. Thanks again for raising the issue!",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5556:92,recover,recover,92,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5556,1,['recover'],['recover']
Availability,"Also, update code to use Hellbender's IOUtils instead of htsjdk's IOUtil; for these checks. We have both, presumably there's a reason Hellbender has their own and we should use them (for example, we can only add the hinting in our own). Sample error now:. A USER ERROR has occurred: Couldn't read file gs://foo/sam/m54113_160913_184949.scraps.beginning.sam. Error was: Error 403: jp-testing@redacted.iam.gserviceaccount.com does not have storage.objects.get access to foo/sam/m54113_160913_184949.scraps.beginning.sam. Potential cause: incorrect Google Cloud configuration; see instructions in the README. Fixes: #5468",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5477:244,error,error,244,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5477,4,"['ERROR', 'Error', 'error']","['ERROR', 'Error', 'error']"
Availability,An argument of GetPileupSummaries maybe redundant in Mutect2.wdl ?,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7731:40,redundant,redundant,40,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7731,1,['redundant'],['redundant']
Availability,An error in Gamma.java in commons-math3-3.5.sources.jar,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6133:3,error,error,3,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6133,1,['error'],['error']
Availability,"An issue has come up on the GATK forum with a user running FilterFuncotations. They have two transcripts for the same gene and are getting a duplicate key error. Ted Brookings identified how to solve this issue:; -The exact problem is in AlleleFrequencyUtils.java, line 30.; -The solution is to skip collecting as a map, have getMaxMinorAlleleFreq take a stream and return an optional float, then return false if the float is missing, otherwise value <= maxMaf. Don't ever call allFrequenciesFiltered. This request was created from a contribution made by Azza Ahmed on October 14, 2021 10:53 UTC. Link: [https://gatk.broadinstitute.org/hc/en-us/community/posts/4408348163227-FilterFuncotations-Duplicate-key-error](https://gatk.broadinstitute.org/hc/en-us/community/posts/4408348163227-FilterFuncotations-Duplicate-key-error). \--. Hello,. I'm using the `FilterFuncotations` to process the output from the `Functotator` as per this WARP \[pipeline\]( [warp/AnnotationFiltration.wdl at cec97750e3819fd88ba382534aaede8e05ec52df · broadinstitute/warp (github.com)](https://github.com/broadinstitute/warp/blob/cec97750e3819fd88ba382534aaede8e05ec52df/pipelines/broad/annotation_filtration/AnnotationFiltration.wdl)). . ; ; ; ; /home/azzaea/software/gatk/gatk-4.2.2.0/gatk --java-options ""-Xmx3072m"" \ ; FilterFuncotations \ ; --variant /scratch/FPTVM/src/warp/pipelines/broad/annotation\_filtration/cromwell-executions/AnnotationFiltration/4e3bd06b-3018-4c94-ac98-feb78b924d1f/call-FilterFuncotations/shard-0/inputs/1333115969/104566-001-001.filtered.vcf.funcotated.vcf.gz \ ; --output 104566-001-001.filtered.vcf.filtered.vcf.gz \ ; --ref-version hg38 \ ; --allele-frequency-data-source gnomad --lenient true; ; ; ; ; . However, the command fails with the error message below:. ; ; ; ; [October 14, 2021 at 12:20:24 PM CEST] org.broadinstitute.hellbender.tools.funcotator.FilterFuncotations done. Elapsed time: 16.57 minutes. ; Runtime.totalMemory()=1134559232 ; java.lang.IllegalStateException: Duplicat",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7504:155,error,error,155,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7504,3,['error'],['error']
Availability,"AnalysisEngine - Inflater: IntelInflater; INFO 14:49:42,958 GenomeAnalysisEngine - Strictness is SILENT; INFO 14:49:43,125 GenomeAnalysisEngine - Downsampling Se. the error is :; maxAltAlleles (6), the following will be dropped: TAAC.; WARN 14:59:10,944 HaplotypeCallerGenotypingEngine - location chr12:21623284-21623286: too many alternative alleles found (8) larger than the maximum requested with -maxAltAlleles (6), the following will be dropped: C, CA.; INFO 14:59:13,453 ProgressMeter - chr12:21624342 1.0358131E7 9.5 m 55.0 s 49.5% 19.2 m 9.7 m; WARN 14:59:37,613 HaplotypeCallerGenotypingEngine - location chr12:133237753-133237756: too many alternative alleles found (9) larger than the maximum requested with -maxAltAlleles (6), the following will be dropped: G, TAAA, GAAAAAAA.; INFO 14:59:43,454 ProgressMeter - chr13:32892450 1.0955099E7 10.0 m 54.0 s 54.0% 18.5 m 8.5 m; INFO 15:00:13,456 ProgressMeter - chr13:32912251 1.0976428E7 10.5 m 57.0 s 55.2% 19.0 m 8.5 m; ##### ERROR --; ##### ERROR stack trace; java.lang.IllegalStateException: Never found start -1 or stop -1 given cigar 17I; at org.broadinstitute.gatk.utils.sam.AlignmentUtils.getBasesCoveringRefInterval(AlignmentUtils.java:204); at org.broadinstitute.gatk.utils.sam.AlignmentUtils.countBasesAtPileupPosition(AlignmentUtils.java:1418); at org.broadinstitute.gatk.tools.walkers.annotator.BaseCounts.getBaseCounts(BaseCounts.java:93); at org.broadinstitute.gatk.tools.walkers.annotator.BaseCounts.annotate(BaseCounts.java:78); at org.broadinstitute.gatk.tools.walkers.annotator.VariantAnnotatorEngine.annotateContextForActiveRegion(VariantAnnotatorEngine.java:315); at org.broadinstitute.gatk.tools.walkers.annotator.VariantAnnotatorEngine.annotateContextForActiveRegion(VariantAnnotatorEngine.java:260); at org.broadinstitute.gatk.tools.walkers.haplotypecaller.HaplotypeCallerGenotypingEngine.annotateCall(HaplotypeCallerGenotypingEngine.java:328); at org.broadinstitute.gatk.tools.walkers.haplotypecaller.HaplotypeCallerGe",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7499:2905,ERROR,ERROR,2905,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7499,2,['ERROR'],['ERROR']
Availability,"AnalyzeCovariates Error ""gplots""",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7006:18,Error,Error,18,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7006,1,['Error'],['Error']
Availability,AnalyzeCovariates Rscript error,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6650:26,error,error,26,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6650,1,['error'],['error']
Availability,"And `SparkCommandLineProgram` should not set a default master. This should be left to `spark-submit`. Otherwise, the settings actually mask my requested spark master that I set with `spark-submit --master ...`.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1070:135,mask,mask,135,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1070,1,['mask'],['mask']
Availability,"And split out a common superclass for ReadThreadingGraph and ExperimentalReadThreadingGraph. Perhaps these should have better names? This is merely a checkpoint of progress intended to aid the review process for this work. . I will probably shortly add to this branch the first attempt at dangling tail merging, it was causing me some problems... Fixes #5923",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5980:150,checkpoint,checkpoint,150,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5980,1,['checkpoint'],['checkpoint']
Availability,Annotate downsampled VCs in HC active regions with `DS` flag,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7753:9,down,downsampled,9,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7753,1,['down'],['downsampled']
Availability,"Any objections to exposing SW parameters to the command line? This looks like something we will want to explore for malaria. I'm also not convinced that our current parameters have been justified and/or optimized in any documented way. A few questions:. 1) There are 3 sets of parameters used in various ways, a) haplotype-to-reference alignment, b) read-to-haplotype alignment, and c) dangling ends. Any chance we can evaluate the effect of consolidating at least c), if not all sets? @emeryj I was told that you might be the one to ask about c) in particular; @davidbenjamin speculated that these might effectively yield STR-specific parameters. In general, if there are any quick and readily available evaluations (which ideally include variant normalization), I'd appreciate pointers to them. 2) Any suggestions on what the resulting command line should look like? I don't want to add 12 parameters, in the worst case. I also think that using integer arrays might be clunky. Perhaps I can suggest the use of args files in the doc string---although I don't think that those are expanded in the `##GATKCommandLine`, right?. 3) Should I touch `SWOverhangStrategy` at all? See e.g. https://github.com/broadinstitute/gatk/issues/6576. It looks like we thread both this and the `SWParameters` through many methods and classes, so the code could stand quite a bit of refactoring, but for now I will stick to the minimal changes required to expose. @droazen @ldgauthier any thoughts?. In some simple experiments of changing the a) parameters (from the somewhat questionable `NEW_SW_PARAMETERS = new SWParameters(200, -150, -260, -11)` back to `STANDARD_NGS = new SWParameters(25, -50, -110, -6)`), I've seen that there are non-negligible differences in the calls (beyond representation) at the few percent level, as well as changes in annotations.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6863:695,avail,available,695,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6863,1,['avail'],['available']
Availability,AoU Echo Precision and Sensitivity Updates [VS-1093],MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8578:4,Echo,Echo,4,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8578,1,['Echo'],['Echo']
Availability,Apply latest test changes to echo callset,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8807:29,echo,echo,29,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8807,1,['echo'],['echo']
Availability,Arg clarification for requester pays to avoid confusion and failures,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6594:60,failure,failures,60,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6594,1,['failure'],['failures']
Availability,"Arguments may now define `sensitive`. Sensitive arguments will be printed as ***\* instead of as their value.; Removed output of raw command line from IntegrationTestSpec. The censored command line is output by the command line program itself. These changes are far from bulletproof. Sensitive arguments may be leaked stack traces or errors, but it should fix the worst offenders.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/852:334,error,errors,334,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/852,1,['error'],['errors']
Availability,ArrayIndexOutOfBoundsException error in BaseRecalibratorSpark,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2732:31,error,error,31,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2732,1,['error'],['error']
Availability,"As @droazen and I have been investigating, providing the `--gcs-project-for-requester-pays` argument when accessing buckets where the user does not have storage.bucket.get permission will cause failures. This clarifies the argument usage.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6594:194,failure,failures,194,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6594,1,['failure'],['failures']
Availability,"As John loads data into the Echo callset, he will certainly run into issues in the documentation, that should be addressed",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8649:28,Echo,Echo,28,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8649,1,['Echo'],['Echo']
Availability,"As a step toward productionizing gCNV, I explore the idea of aggressive filtering of reads (or targets, or bins) based on known annotations, such as genome mappability, complexity, SINEs, LINEs, repeats, etc. This post is about mappability filtering, and in particular, for WGS samples. Let us consider coverage data collected by `CollectFragmentCounts` (default tool args: well-formed paired, FR orientation, MQ > 30) for a several WGS samples (hg38, BWA-MEM). Here's how the coverage distribution looks like for a random sample:; ![image](https://user-images.githubusercontent.com/15305869/37785053-8c9ca298-2dcf-11e8-9eb4-20192af80647.png). Notice the main peak at ~ 90 fragments/bin, the diffuse counts below 90, and the peak at 0. To proceed, I calculated the average mappability score of each bin using the recently published [multi-read Umap track](https://bismap.hoffmanlab.org/). It is not an ideal mappability scoring scheme (since it does not consider Illumina-like errors and paired-end reads), but it is the best I could find for hg38. I filtered out all bins that had a mappability score short of 100% (very aggressive). Here's how the filtered coverage distribution looks like:; ![image](https://user-images.githubusercontent.com/15305869/37785397-6c8052ba-2dd0-11e8-9fed-f8f1aa4406cf.png). Evidently, the diffusive low coverage part of the distribution has completely disappeared, along with the peak at 0. Here's a plot of the number of _retained bins_ after filtering with various mean mappability cutoffs:; ![image](https://user-images.githubusercontent.com/15305869/37785471-9d155920-2dd0-11e8-87bf-b8fb579250ff.png). Except for chrY, the most aggressive filtering only gets rid of 20% of the genome. Let us fit different distributions to the filtered coverage data:; ![image](https://user-images.githubusercontent.com/15305869/37785506-b80a4790-2dd0-11e8-97e4-9bff775a93ce.png). As we expect, negative binomial is almost a _perfect_ fit! this is very reassuring, because gCNV mode",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4558:977,error,errors,977,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4558,1,['error'],['errors']
Availability,"As described in #1464, I ported a `LocusWalker` class as the GATK3 one using `LocusIteratorByState` (LIBS). The default implementation uses no downsampling (probably it should be change once #64 is addressed), includes reads with deletions and does not track the previous reads in the LIBS. One important think is that the `intervalsForTraversal` is not used at all, so it is up to the author discard regions out of this ones. I was thinking to check every position for overlap in any of the interval in the list, but I'm not sure if the `intervalsForTraversal` is sorted or not; and an exhaustive checking could reduce performance. I don't know if it could be possible to implement some query in LIBS, to return only the positions that overlaps some intervals, but that will be easier.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1526:143,down,downsampling,143,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1526,1,['down'],['downsampling']
Availability,"As described in #2034, samtools mpileup and the internal pileup generated by `LocusIteratorByState` (LIBS) is not providing the same result because overlapping read-pairs are not taken into account. In this PR I addressed this issue using the same approach as samtools to combine qualities, including new functionality to LIBS and `LocusWalker`:; - Refactoring constructors for LIBS, solving #1879.; - Including an option for ignore overlapping read-pairs in LIBS; - Including command line option in `LocusWalker`to ignore overlapping read-pairs and to downsample with a maximum coverage by sample.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2041:553,down,downsample,553,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2041,1,['down'],['downsample']
Availability,"As discussed at the GATK Office Hours meeting, the --genotype-germline-sites should no longer be labeled as experimental. Link: [https://gatk.broadinstitute.org/hc/en-us/community/posts/360077847071-Mutect-genotype-germline-sites-status](https://gatk.broadinstitute.org/hc/en-us/community/posts/360077847071-Mutect-genotype-germline-sites-status). \--. If not an error, choose a category for your question(REQUIRED): ; ; e) Will Mutect2's \[--genotype-germline-sites\](/hc/en-us/articles/360037593851-Mutect2#--genotype-germline-sites) be in future releases?. I notice that this flag is still set to `EXPERIMENTAL` in the Mutect2 docs.  Is there a way I can track the status of this feature?  It is important for the functionality of the pipeline I have built (i.e. we want to be able to see all of the germline variants that Mutect wants to call -- doesn't have to perfect per sé, but those calls are important), so we want to ensure it stays in the picture because it seems to be working for our needs (even after a lot of pressure testing).<br><br><i>(created from <a href='https://broadinstitute.zendesk.com/agent/tickets/149087'>Zendesk ticket #149087</a>)<br>gz#149087</i>",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7318:363,error,error,363,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7318,1,['error'],['error']
Availability,"As discussed briefly on Slack, this would encourage stability of these dependencies and would cut down on Travis build time. (However, we might still want to test the build regularly.). One possible approach would be to use a base yml containing the non-GATK python packages to establish the conda enviroment in the base Docker, and then separately add the lines to pip install the GATK python package for users that might want to use the resulting yml outside of Docker. Note that we may want to clean up dependencies for e.g. VCF processing and perhaps consolidate on a common ML framework at some point in the near future.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6535:98,down,down,98,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6535,1,['down'],['down']
Availability,"As discussed here is the information regarding the OutOfBoundsException. Please find below the user report:. I am running the Mutect2 pipeline on canine tumor samples in Terra, using WDL version 2.5 and GATK version 4.1.2.0. I was able to run the pipeline successfully without entering a germline resource file or VCF of common variants for contamination, however, when I did add these files in, I got the following error:. ```; java.lang.IndexOutOfBoundsException: Index: 5, Size: 5; 	at java.util.ArrayList.rangeCheck(ArrayList.java:657); 	at java.util.ArrayList.get(ArrayList.java:433); 	at org.broadinstitute.hellbender.tools.walkers.mutect.SomaticGenotypingEngine.lambda$getGermlineAltAlleleFrequencies$31(SomaticGenotypingEngine.java:350); 	at java.util.stream.ReferencePipeline$6$1.accept(ReferencePipeline.java:244); 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:545); 	at java.util.stream.AbstractPipeline.evaluateToArrayNode(AbstractPipeline.java:260); 	at java.util.stream.DoublePipeline.toArray(DoublePipeline.java:506); 	at org.broadinstitute.hellbender.tools.walkers.mutect.SomaticGenotypingEngine.getGermlineAltAlleleFrequencies(SomaticGenotypingEngine.java:352); 	at org.broadinstitute.hellbender.tools.walkers.mutect.SomaticGenotypingEngine.getNegativeLogPopulationAFAnnotation(SomaticGenotypingEngine.java:335); 	at org.broadinstitute.hellbender.tools.walkers.mutect.SomaticGenotypingEngine.callMutations(SomaticGenotypingEngine.java:141); 	at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2Engine.callRegion(Mutect2Engine.java:250); 	at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2.apply(Mutect2.java:324); 	at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.processReadShard(Assembl",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6098:416,error,error,416,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6098,1,['error'],['error']
Availability,"As discussed in #5608 with @nalinigans. . ## Software version. GATK v4.1.0.0-32-g213f99c-SNAPSHOT. ## OS/Platform. ```; $ uname -a; Linux hnpv-fargenCompute01 4.4.0-101-generic #124-Ubuntu SMP Fri Nov 10 18:29:59 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux. $ lsb_release -a; No LSB modules are available.; Distributor ID: Ubuntu; Description: Ubuntu 16.04.3 LTS; Release: 16.04; Codename: xenial; ```. ## Command . ```; TILEDB_DISABLE_FILE_LOCKING=1. gatk --java-options ""-Xmx4g -Xms4g"" GenomicsDBImport \; -V [GVCF file] \; -V [GVCF file] \; --genomicsdb-workspace-path data/genomicsdb/run1 \; --tmp-dir=tmp \; -L [target BED file]; ```. ## CIFS configuration. /etc/fstab:; ```; /[servername]/[mountame] /mnt/[mountname] cifs credentials=/root/.smbcredentials,iocharset=utf8,uid=1004,gid=1005,file_mode=0770,dir_mode=0770,noperm,mfsymlinks 0 0; ```. ## Log. Using GATK wrapper script /mnt/fargen/experiments/joint_call/gatk_27-02-2019_213f99c/gatk/build/install/gatk/bin/gatk; Running:; /mnt/fargen/experiments/joint_call/gatk_27-02-2019_213f99c/gatk/build/install/gatk/bin/gatk GenomicsDBImport -V data/gvcf/FN000009.g.vcf.gz -V old_data/FN000010.g.vcf.gz --genomicsdb-workspace-path data/genomicsdb/run1 --tmp-dir=tmp -L /mnt/fargen/resources/sureselect_human_all_exon_v6_utr_grch38/S07604624_Padded.bed; 12:52:35.654 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/mnt/fargen/experiments/joint_call/gatk_27-02-2019_213f99c/gatk/build/install/gatk/lib/gkl-0.8.6.jar!/com/intel/gkl/native/libgkl_compression.so; 12:52:37.520 INFO GenomicsDBImport - ------------------------------------------------------------; 12:52:37.521 INFO GenomicsDBImport - The Genome Analysis Toolkit (GATK) v4.1.0.0-32-g213f99c-SNAPSHOT; 12:52:37.521 INFO GenomicsDBImport - For support and documentation go to https://software.broadinstitute.org/gatk/; 12:52:37.521 INFO GenomicsDBImport - Executing as olavur@hnpv-fargenCompute01.heilsunet.fo on Linux v4.4.0-101-generic amd64; 12:52:37.521 INFO Geno",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5740:291,avail,available,291,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5740,1,['avail'],['available']
Availability,"As discussed in GATK office hours, this issue was reported by a user with HaplotypeCaller Spark. The entire stack trace is included below. This request was created from a contribution made by stanedav on August 03, 2020 10:07 UTC. Link: [https://gatk.broadinstitute.org/hc/en-us/community/posts/360072104512-HaplotypeCallerSpark-error](https://gatk.broadinstitute.org/hc/en-us/community/posts/360072104512-HaplotypeCallerSpark-error). \--. Hello, I am testing HaplotypeCallerSpark algorithm on my local machine for speeding up the variant calling. I tried to apply algorithm on my BQSR bam but I am getting this error (full log below):. ERROR Executor: Exception in task 15.0 in stage 5.0 (TID 1324) ; ; java.util.ConcurrentModificationException ... (more in log). Version of GATK: 4.1.7.0. Command I used:. $gatk --java-options ""-Xmx48g -Xms32g"" HaplotypeCallerSpark \\ ; ; \-R hg19.fasta \\ ; ; \-I remdup\_recal.bam \\ ; ; \-O output.g.vcf \\ ; ; \-L wes.bed \\ ; ; \-ERC GVCF \\ ; ; \--dont-use-soft-clipped-bases. Full log:. [https://www.dropbox.com/s/iez0zixclsh86zp/hc.log?dl=0](https://www.dropbox.com/s/iez0zixclsh86zp/hc.log?dl=0)<br><br><i>(created from <a href='https://broadinstitute.zendesk.com/agent/tickets/6546'>Zendesk ticket #6546</a>)<br>gz#6546</i>",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6738:329,error,error,329,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6738,4,"['ERROR', 'error']","['ERROR', 'error']"
Availability,"As of https://github.com/broadinstitute/gatk/pull/1424, `VariantWalker` prefers the sequence dictionary from the driving variants in `getBestAvailableSequenceDictionary()` over other sequence dictionaries, as it should. However, if the driving variants input does not have a declared sequence dictionary, but does have an index file, we end up creating an incomplete sequence dictionary from the index with no contig lengths and using it as the ""best available"" dictionary, even if better dictionaries from the reference or reads are available. This is discussed in https://github.com/broadinstitute/gatk/pull/1424#discussion_r70674157, and is replicated in the test `ExampleVariantWalkerIntegrationTest.testExampleVariantWalker_UndefinedContigLengthsInDictionary`",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1999:451,avail,available,451,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1999,2,['avail'],['available']
Availability,"As per our discussion with @davidbenjamin, we think the code in the `SmithWatermanAligner` classes that is used to avoid having to actually call out to SmithWaterman can be improved. For instance we suspect the current heuristic of searching for an exact substring match in the reference from the read could be improved (for instance we could look for mismatches of exactly 1 base etc...). We want to both develop the tools to quantify the amount of time we currently spend in smith waterman code and come up with ways of cutting down on SmithWaterman calls in all parts of the HaplotypeCaller/Mutect Engine.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6014:530,down,down,530,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6014,1,['down'],['down']
Availability,"As pointed out by Julian, I incorrectly propagated errors in one part of the model translation. Not sure if this has any effect on ABSOLUTE results, but we can fix it up. Probably should re-examine some of the other expressions as well---would be great to finally get feedback on whether these are at all sensible.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5804:51,error,errors,51,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5804,1,['error'],['errors']
Availability,"As reported by @jkobject testing our latest gatk-nightly image, certain non-requester-pays accesses fail with the latest google-cloud-nio version (0.123.23) when `--gcs-project-for-requester-pays` is specified. . The specific issue appears to be checks for the existence of non-existent files in non-requester-pays buckets when `--gcs-project-for-requester-pays` is set, resulting in a ""User project specified in the request is invalid"" error:. ```; code: 400; message: User project specified in the request is invalid.; reason: invalid; location: null; retryable: false; com.google.cloud.storage.StorageException: User project specified in the request is invalid.; 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.translate(HttpStorageRpc.java:233); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.list(HttpStorageRpc.java:376); 	at com.google.cloud.storage.StorageImpl.lambda$listBlobs$11(StorageImpl.java:391); 	at com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:105); 	at com.google.cloud.RetryHelper.run(RetryHelper.java:76); 	at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:50); 	at com.google.cloud.storage.Retrying.run(Retrying.java:51); 	at com.google.cloud.storage.StorageImpl.listBlobs(StorageImpl.java:388); 	at com.google.cloud.storage.StorageImpl.list(StorageImpl.java:359); 	at com.google.cloud.storage.contrib.nio.CloudStoragePath.seemsLikeADirectoryAndUsePseudoDirectories(CloudStoragePath.java:118); 	at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.checkAccess(CloudStorageFileSystemProvider.java:743); 	at java.nio.file.Files.exists(Files.java:2385); 	at htsjdk.tribble.util.ParsingUtils.resourceExists(ParsingUtils.java:418); 	at htsjdk.tribble.TribbleIndexedFeatureReader.loadIndex(TribbleIndexedFeatureReader.java:162); 	at htsjdk.tribble.TribbleIndexedFeatureReader.hasIndex(TribbleIndexedFeatureReader.java:228); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSourc",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7716:437,error,error,437,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7716,1,['error'],['error']
Availability,"As reported in this forum thread: https://gatk.broadinstitute.org/hc/en-us/community/posts/360060174372-Haplotype-Caller-4-1-6-0-java-lang-IllegalStateException-Smith-Waterman-alignment-failure- as well as in the closed ticket https://github.com/broadinstitute/gatk/issues/6490#issuecomment-605486643, there appears to be a regression in GATK 4.1.6.0 causing HaplotypeCaller/Mutect2 to fail with an error like the following:. ```; java.lang.IllegalStateException: Smith-Waterman alignment failure. Cigar = 275M with reference length 275 but expecting referenc; e length of 303 ref = GGACTGGTCATCAGCTACCCCGAGACCAGGACTGGTCATCAGCTACCCCGAGACCAGGACTGGTCATCAGCTACCCCGAGACCAGGACTGGTCATCAGCTACCCCG; AGACCAGGACTGGTCATCAGCTACCCCGAGAACAGGACTGGTCATCAGCTACCCCGAGACCAGGACTGGTCATCAGCTACCCCGAGACCAGGACTGGTCATCAGCTACCCCGAGACCAGGACTGGTCA; TCAGCTACTCCGAGACCAGCATGGAGAGGTTTGCTGATGGTTGGCTGACTGCTAGTGTGAGCACTTGTC path GGACTGGTCATCAGCTACCCCGAGACCAGGACTGGTCATCAGCTACCCCGAGA; CCAGGACTGGTCATCAGCTACCCCGAGACCAGGACTGGTCATCAGCTACCCCGAGAACAGGACTGGTCATCAGCTACCCCGAGAACAGGACTGGTCATCAGCTACCCCGAGACCAGGACTGGTCATCA; GCTACCCCGAGACCAGGACTGGTCATCAGCTACTCCGAGACCAGCATGGAGAGGTTTGCTGATGGTTGGCTGACTGCTAGTGTGAGCACTTGTC; at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.readthreading.ReadThreadingAssembler.findBestPaths(ReadTh; readingAssembler.java:354); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.readthreading.ReadThreadingAssembler.assembleKmerGraphsAn; dHaplotypeCall(ReadThreadingAssembler.java:196); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.readthreading.ReadThreadingAssembler.runLocalAssembly(Rea; dThreadingAssembler.java:146); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.AssemblyBasedCallerUtils.assembleReads(AssemblyBasedCalle; rUtils.java:269); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerEngine.callRegion(HaplotypeCallerEngine.ja; va:541); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCaller.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6533:186,failure,failure,186,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6533,3,"['error', 'failure']","['error', 'failure']"
Availability,"As reported recently by Eric Jones:. ""Many newer Linux distributions will mount /tmp with the noexec mount option. If /tmp is noexec, then any JNA code (Java code that extracts native binary components into shareable libraries and then executes that code) will fail. There are a number of GATK methods that do this. A typical error looks like:. java.lang.UnsatisfiedLinkError: /tmp/libbwa.2929202181066681888.jnilib: /tmp/libbwa.2929202181066681888.jnilib: failed to map segment from shared object. There's an easy fix for it: you can use --tmpdir or one of the typical java methods that reset java.io.tmpdir to name a directory that isn't noexec. But it's amazingly hard to find clues about that being necessary. I found no references to noexec on the forum nor in the help section of the gatk site"". We should address this by explicitly checking on GATK startup whether the selected temp dir is marked noexec, and warn the user in that case.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8453:326,error,error,326,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8453,1,['error'],['error']
Availability,"At least -I and -O, to be consistent with ModelSegments pipeline. I think our general rule for the CNV tools is that we do not introduce any CNV-specific short names, but we can use the standard ones already available.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4403:208,avail,available,208,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4403,1,['avail'],['available']
Availability,"At the moment, all tests share a global Spark context. Once the test context is created, subsequent calls to `getTestSparkContext(Map<String, String> overridingProperties)` or `getSparkContext(...)` return the existing context and `overridingProperties` is ignored. This results in failure of integration tests of tools that need to override certain Spark configs (e.g. to register custom serializers). To make life a bit easier for gatk-protected devs, it is (at least) desirable to take a global set of overriding Spark config key-value pairs from within the gradle build script, and considering them when instantiating the global test Spark context. In particular, I would like to add a few comma-separated extra registrators to `spark.kryo.registrator`. Perhaps this feature is already present?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2337:282,failure,failure,282,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2337,1,['failure'],['failure']
Availability,"Attempting to get wgs coverage with 10000 bp bin size on; /seq/picard_aggregation/D4491/HCC1143/v1/HCC1143.bam; produces the following stacktrace (see first line for command line). ```; ERROR 14:06:46,283 FunctionEdge - Error: java -Xmx16g -jar /dsde/working/slee/acnv-eval/resources/gatk-protected-536b94e-create-apon.jar SparkGenomeReadCounts -o /dsde/working/aaronc/testing/case/HCC1143/cov/HCC1143-coverage.tsv -I /seq/picard_aggregation/D4491/HCC1143/v1/HCC1143.bam -bins 10000 -R /seq/references/Homo_sapiens_assembly19/v1/Homo_sapiens_assembly19.fasta --sparkMaster local[1] ; ERROR 14:06:46,288 FunctionEdge - Contents of /dsde/working/aaronc/testing/case/HCC1143/cov/HCC1143-coverage.tsv.out:; 16/08/24 14:06:09 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.2 KB, free 284.6 KB); 16/08/24 14:06:09 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:56998 (size: 23.2 KB, free: 10.4 GB); 16/08/24 14:06:09 INFO SparkContext: Created broadcast 0 from newAPIHadoopFile at ReadsSparkSource.java:105; 16/08/24 14:06:10 INFO FileInputFormat: Total input paths to process : 1; 16/08/24 14:06:21 INFO SparkUI: Stopped Spark web UI at http://10.200.98.30:4040; 16/08/24 14:06:21 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 16/08/24 14:06:21 INFO MemoryStore: MemoryStore cleared; 16/08/24 14:06:21 INFO BlockManager: BlockManager stopped; 16/08/24 14:06:21 INFO BlockManagerMaster: BlockManagerMaster stopped; 16/08/24 14:06:21 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 16/08/24 14:06:21 INFO SparkContext: Successfully stopped SparkContext; 14:06:21.109 INFO SparkGenomeReadCounts - Shutting down engine; [August 24, 2016 2:06:21 PM EDT] org.broadinstitute.hellbender.tools.genome.SparkGenomeReadCounts done. Elapsed time: 0.36 minutes.; Runtime.totalMemory()=3192389632; java.lang.IndexOutOfBoundsException; at java.nio.ByteBuffer.wrap(ByteBuffer.ja",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2113:186,ERROR,ERROR,186,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2113,3,"['ERROR', 'Error']","['ERROR', 'Error']"
Availability,Avoids an out-of-bounds error when there are large numbers of alt alleles.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6086:24,error,error,24,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6086,1,['error'],['error']
Availability,"BQSR: avoid throwing an error when read group is missing in the recal table, and some refactoring.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/9020:24,error,error,24,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/9020,1,['error'],['error']
Availability,BaseRecalibratorSparkOptimizedIntegrationTest.testBQSRLocal fails once we started doing stringent checks of results. It needs to be fixed. It may have something to do with masking of variants,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1119:172,mask,masking,172,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1119,1,['mask'],['masking']
Availability,"BaseRecalibrator：A USER ERROR has occurred: Number of read groups must be >= 1, but is 0",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7031:24,ERROR,ERROR,24,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7031,1,['ERROR'],['ERROR']
Availability,"Based on GATK office hrs discussion, this issue requires adjusting the buffer size, but that option is not available in GATK. Please find below the user error report:. Hello, I've been trying to get the HaplotypeCaller-in-gVCF-mode to work for a combination of exome samples, some of which are diploid individuals, and others of which are bulks with ploidies ~20. For about 20% of my chromosomes, The GenomicsDBImport step fails, with the following error message:. ```; 09:58:45.656 INFO ProgressMeter - Current Locus Elapsed Minutes Batches Processed Batches/Minute; 09:58:46.530 INFO GenomicsDBImport - Importing batch 1 with 6 samples; terminate called after throwing an instance of 'File2TileDBBinaryException'; what(): File2TileDBBinaryException : read_one_line_fully && ""Buffer did not have space to hold a line fully - increase buffer size""; ```. I'm not sure what this means, and a google search brings up next to nothing. . I am working with mosquito exome data, 150bp PE illumina reads, GATK 4.1.3.0, java 1.8.0_181. I've been following the Broad best practices pretty closely, although I haven't managed to figure out how to bootstrap base recalibration yet. Example GenomicsDBImport command:; ```; gatk --java-options '-Xmx5G' GenomicsDBImport \; --genomicsdb-workspace-path ../vcfs/combined_gvcfs/NW_021837046.1 \; --intervals NW_021837046.1 \; -V ../vcfs/gvcfs/BH2.gvcf \; -V ../vcfs/gvcfs/BH3.gvcf \; -V ../vcfs/gvcfs/K01.gvcf \; -V ../vcfs/gvcfs/K02.gvcf \; -V ../vcfs/gvcfs/M01.gvcf \; -V ../vcfs/gvcfs/M02.gvcf ; ``` . I played around with increasing ""--genomicsdb-segment-size"" and ""--genomicsdb-vcf-buffer-size"", as well as the amount of memory available to java. Increasing any or all of them by a factor of about 10 had no effect, always producing the same error. This Issue was generated from your [forums] ; [forums]: https://gatkforums.broadinstitute.org/gatk/discussion/24420/genomicsdbimport-error-file2tiledbbinaryexception/p1",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6150:107,avail,available,107,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6150,6,"['avail', 'error']","['available', 'error', 'error-']"
Availability,"Based on my HaplotypeCaller GVCF performance evaluation, we are spending a significant amount of time in `ReferenceConfidenceModel.calcNIndelInformativeReads()', including upwards of 40% of the overall runtime on a bam under some conditions. To this end we have already done some performance work optimizing its constituent methods (#5469, #5470). Even with those changes it appears that the method can take upwards of 25% of the total runtime, which appears to be a consequence of the nature of the algorithm. It appears that the core of the problem appears to be associated with the calls we make to `isReadInformativeAboutIndelsOfSize()` which has a complexity overall of approximately `O(pileupsPerRegion * readsPerPileup * basesPerRead * maxIndelSize)` which ends up being a large number. One approach to fixing this problem be to rethink the repetitive operations we do for every pileup and instead do it on a per-read basis, and furthermore we could exploit the nature of the existing algorithm to avoid checking mismatches at the front of the read when we know that down the line we will fail out because of mismatches at the end of the read. Furthermore there is the broader philisophical question of whether there are changes that could be made to the algorithm that might carry a bigger risk of changing the results, like applying some heuristic based on the complexity of the reference sequence at a given site to reduce the amount of work we have to do.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5488:1074,down,down,1074,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5488,1,['down'],['down']
Availability,"Based on this forum [post](https://gatk.broadinstitute.org/hc/en-us/community/posts/12230735621403-Missing-RawGtCount-annoation-from-GenotypeGVCF-output), when the argument `--tree-score-threshold-to-no-call` is used in `ReblockGVCFs` with input that doesn't contain the `TREE_SCORE` annotation, the tool gets very slow, since it tries to no-call every variant. An error message should be thrown before starting traversal of the VCF if the input is missing this annotation when that argument is set.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8203:365,error,error,365,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8203,1,['error'],['error']
Availability,"Based on timing results (see below), we should do two things:; 	1) Switch to the HTSJDK `ParsingUtils::split` method for all; 	 cases where we split a string using a single character.; 	2) Switch to the `Utils::split` method for all cases where; 	 we split a string by another string of length > 1. A quick stopgap that will reduce splitting time by ~1/2 is to just; replace all calls to Java's `String::split` with `Utils::split` (since; they both take two Strings as arguments, it should be very easy). Also, I have disabled the test so that it doesn't slow down testing cycles. Fixes #3759. | Method | Benchmark | Total Time (ns) | Total Time (ms) | Time Per Split Operation (ns) | Time Per Split Operation (ms) | ; | --- | --- | --- | --- | --- | --- |; | Java String::split | Split on Words | 131867865203 | 131867.865203 | 6048.98464233945 | 0.00604898464233945 |; | Java String::split | Split on Chars | 12917243085 | 12917.243085 | 3004.010019767442 | 0.003004010019767442 |; | HTSJDK ParsingUtils::split | Split on Words | N/A | N/A | N/A | N/A | ; | HTSJDK ParsingUtils::split | Split on Chars | 5882790859 | 5882.790859 | 1368.0908974418605 | 0.0013680908974418606 | ; | GATK Utils::split | Split on Words | 38734463275 | 38734.463275 | 1776.8102419724771 | 0.0017768102419724772 |; | GATK Utils::split | Split on Chars | 7120052467 | 7120.052467 | 1655.826155116279 | 0.0016558261551162792 |",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3776:560,down,down,560,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3776,1,['down'],['down']
Availability,"Because in `Main`the call to `Utils.forceJVMLocaleToUSEnglish()` is done in an static block, this is not applied to downstream projects. I wonder if this call can be moved to `Main.mainEntry`, to assess extending classes apply the same locale.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3483:116,down,downstream,116,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3483,1,['down'],['downstream']
Availability,"Because of the initial use cases for Funcotator everything is reported on the + strand (eg. upstream / downstream bases, sequences, etc.). We should add a flag that would change the output to be native to the strand on which the gene is located. For + strand genes the output would not change, but any bases reported for genes on the - strand would be reverse-complemented.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7057:103,down,downstream,103,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7057,1,['down'],['downstream']
Availability,"Because the filename doesn't occur at the beginning of a word when you use a logical name:. --arg aname:~/dir1/... the ~ doesn't get expanded by the shell, so the command fails, and the resulting error message is confusing because we call file.getAbsolutePath() on the file object to create the exception, which prepends the current directory onto the (unexpanded, nonexistent) filename (see https://github.com/broadinstitute/gatk/issues/2199). If we can't fix the underlying problem we should try to improve the error message.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2200:196,error,error,196,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2200,2,['error'],['error']
Availability,"Before our cromwell/WDL tests even start to build the docker image, we could run womtool to validate the WDL. This will catch some obvious errors in much less time.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4802:139,error,errors,139,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4802,1,['error'],['errors']
Availability,Better error bars for samples with small contamination in CalculateContamination,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7003:7,error,error,7,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7003,1,['error'],['error']
Availability,Better error message for AlignAssembledContigsSpark if run with wrong BWA index version,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2123:7,error,error,7,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2123,1,['error'],['error']
Availability,Better error message for GetPileupSummaries from wrong file type in -I argument,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7479:7,error,error,7,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7479,1,['error'],['error']
Availability,Better error message when GCS credentials are required,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5468:7,error,error,7,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5468,1,['error'],['error']
Availability,Better error messages for missing contigs in reference,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6469:7,error,error,7,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6469,1,['error'],['error']
Availability,"Bug Report. Affected tool(s) or class(es); mutect2 and Funcotator. Affected version(s); gatk-4.1.8.1. ### Description ; I tried to use Funcotator to annotate a vcf file. The vcf file had 436 records. I had download database funcotator_dataSources.v1.7.20200521s to my linux machine, and use --data-sources-path to appoint it; 1. when Funcotator with contidion ""gnomAD_genome.tar.gz "",no results got. ; The error is ; message: All 20 retries failed. Waited a total of 1918000 ms between attempts; Caused by: com.google.cloud.storage.StorageException: Connection reset; Caused by: java.net.SocketException: Connection reset; 2. when Funcotator with contidion ""gnomAD_genome "", results got but has nothing, this is a file with title annotation message but no records. ; The error is ; java.lang.IllegalArgumentException: Unexpected value: MANE_Select. ###Steps to reproduce; vcf file from mutect2-FilterMutectCalls,both snv and indel record. code1; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /root/software/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar Funcotator -R /data/Homo_sapiens/Homo_sapiens_38/Homo_sapiens_assembly38.fasta -V /data/project/naangda_panel_20230228/output/mutect/probe/normal_mutect/sssss4.filtered.mutect2.vcf -O /data/project/naangda_panel_20230228/output/mutect/Funcotator/sssss4.funcocator.maf --output-file-format MAF --data-sources-path /data/Homo_sapiens/Homo_sapiens_38/funcotator/funcotator_dataSources.v1.7.20200521s/ --ref-version hg38. code2; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /root/software/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar Funcotator -R /data/Homo_sapiens/Homo_sapiens_38/Homo_sapiens_assembly38.fasta -V /data/project/naan",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8275:206,down,download,206,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8275,3,"['down', 'error']","['download', 'error']"
Availability,Bug fix release that fixes #5919 and https://github.com/disq-bio/disq/pull/101 (the latter caused BAM count errors).,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5981:108,error,errors,108,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5981,1,['error'],['errors']
Availability,Bug on 4.0.0.0 reported on forum -- please advise how to proceed @droazen @lbergelson. ---. Ok now things are getting more interesting. Disabling intelflaters seems to solve the problem. But why?. Same flaters work with standalone picard as well and they don't have any issues. Compression level does not change anything. Is this a memory allocation error? I don't think so because it does not segfault. The error message says filename not found. . I am wondering if this has anything to do with meltdown patches. Both of my systems (Ubuntu and macOS) are patched against meltdown bug. And Intel flaters are causing this issue. But this won't explain why standalone picard is still working fine with them. The only explanation that I have is the difference between HTSJDK and GKL versions between standalone picard 2.17.2 and embedded picard 2.17.2 in gatk. The latest HTSJDK update for standalone picard mentions 2.13.1 version but the one in gatk 4.0 is 2.13.2 I believe. I don't have the info about GKL version used in them. . This Issue was generated from your [forums] ; [forums]: https://gatkforums.broadinstitute.org/gatk/discussion/comment/44985#Comment_44985,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4133:350,error,error,350,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4133,2,['error'],['error']
Availability,Bug report recieved via email: . I am testing GATK4 walker version. I tried the following command. ./gatk-launch BaseRecalibrator -R human_g1k_v37_decoy.fasta -I NA12878.md.bam -O NA12878.br.table --knownSites 1000G_phase1.indels.b37.vcf **-L Broad.human.exome.b37.interval_list -jdk_inflater=true**. It will fail with the following error message `htsjdk.samtools.SAMFormatException: Invalid GZIP header`. If I run ; ./gatk-launch BaseRecalibrator -R human_g1k_v37_decoy.fasta -I NA12878.md.bam -O NA12878.br.table --knownSites 1000G_phase1.indels.b37.vcf **-L Broad.human.exome.b37.interval_list**. or . ./gatk-launch BaseRecalibrator -R human_g1k_v37_decoy.fasta -I NA12878.md.bam -O NA12878.br.table --knownSites 1000G_phase1.indels.b37.vcf **-jdk_inflater=true**. or . ./gatk-launch BaseRecalibrator -R human_g1k_v37_decoy.fasta -I NA12878.md.bam -O NA12878.br.table --knownSites 1000G_phase1.indels.b37.vcf. all three will run with no problem. However when combined **-L and -jdk_inflater=true** it will fail with error. This problem is on both Intel system and Power system. It feels like an easy fix. Would you please look into that? Thanks!,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2722:333,error,error,333,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2722,2,['error'],['error']
Availability,Bug report:HaplotypeCaller haploid GVCF format error?,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4657:47,error,error,47,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4657,1,['error'],['error']
Availability,BuildActionRunner.run(ChainingBuildActionRunner.java:35); 22:05:55.978 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.exec.InProcessBuildActionExecuter.execute(InProcessBuildActionExecuter.java:41); 22:05:55.978 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.exec.InProcessBuildActionExecuter.execute(InProcessBuildActionExecuter.java:26); 22:05:55.978 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.tooling.internal.provider.ContinuousBuildActionExecuter.execute(ContinuousBuildActionExecuter.java:79); 22:05:55.978 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.tooling.internal.provider.ContinuousBuildActionExecuter.execute(ContinuousBuildActionExecuter.java:51); 22:05:55.978 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.ExecuteBuild.doBuild(ExecuteBuild.java:59); 22:05:55.979 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.BuildCommandOnly.execute(BuildCommandOnly.java:36); 22:05:55.979 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); 22:05:55.979 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.WatchForDisconnection.execute(WatchForDisconnection.java:47); 22:05:55.979 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); 22:05:55.979 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.ResetDeprecationLogger.execute(ResetDeprecationLogger.java:26); 22:05:55.979 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemo,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4687:7704,ERROR,ERROR,7704,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4687,1,['ERROR'],['ERROR']
Availability,"Building with Intellij 2017.2 generates an /out directory instead of using the build/ folder from gradle, that is show as untracked but can be committed by error. This folder cannot be changed, even if the compiler output is changed (see CrazyCoder comment in https://stackoverflow.com/questions/45174989/building-with-intellij-2017-2-out-directory-duplicates-files-in-build-director).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3495:156,error,error,156,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3495,1,['error'],['error']
Availability,ByteChannelPrefetcher.java:309); 	at htsjdk.samtools.seekablestream.SeekablePathStream.read(SeekablePathStream.java:86); 	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:286); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at htsjdk.samtools.seekablestream.SeekableBufferedStream.read(SeekableBufferedStream.java:100); 	at htsjdk.samtools.util.BlockCompressedInputStream.readBytes(BlockCompressedInputStream.java:550); 	at htsjdk.samtools.util.BlockCompressedInputStream.readBytes(BlockCompressedInputStream.java:539); 	at htsjdk.samtools.util.BlockCompressedInputStream.processNextBlock(BlockCompressedInputStream.java:493); 	at htsjdk.samtools.util.BlockCompressedInputStream.nextBlock(BlockCompressedInputStream.java:451); 	at htsjdk.samtools.util.BlockCompressedInputStream.readBlock(BlockCompressedInputStream.java:441); 	at htsjdk.samtools.util.BlockCompressedInputStream.available(BlockCompressedInputStream.java:194); 	at htsjdk.samtools.util.BlockCompressedInputStream.read(BlockCompressedInputStream.java:322); 	at htsjdk.tribble.readers.TabixReader.readIndex(TabixReader.java:215); 	at htsjdk.tribble.readers.TabixReader.readIndex(TabixReader.java:269); 	at htsjdk.tribble.readers.TabixReader.<init>(TabixReader.java:161); 	at htsjdk.tribble.readers.TabixReader.<init>(TabixReader.java:125); 	at htsjdk.tribble.TabixFeatureReader.<init>(TabixFeatureReader.java:84); 	at htsjdk.tribble.AbstractFeatureReader.getFeatureReader(AbstractFeatureReader.java:106); 	at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImport.getReaderFromVCFUri(GenomicsDBImport.java:437); 	at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImport.getFeatureReaders(GenomicsDBImport.java:419); 	at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImport.traverse(GenomicsDBImport.java:344); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:740); 	at org.broadinst,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2685:2700,avail,available,2700,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2685,1,['avail'],['available']
Availability,"CAACATGTTGAAACCCCGTCTCTATTAAAAATACAAAA""; echo ""+""; echo ""6#A/AEEEEEEEAEEEEEEEEEEEAEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEAEEEEEEEEEEEEEEEEEE<EEEEEEEEAEEEEEEEEEEEEEAEEEAEEEAEEEEEE/EEEEEEEEE/E/E<AEEEEE/6A/<<<EE/AEE/E""; echo ""@NB500989:333:HKYJNAFX2:1:11101:10000:1915""; echo ""AGACACATGGCGTTTATCCAGAATTAGCAAATTTATCTTCAGATATGGGATTTTCCTTCTTTTTTTAAATCTTGAGTCTGGCAGCAATTTGTAAAGGCTCATAAAAATCTGAAGCTTACATTTTTTGTCAAGTTACCGATGCTTGTGTCT""; echo ""+""; echo ""AAAAAEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEAEEEEEEEEEEEEEEEEEAEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEAEEEEEAEEEEEEEEEAEEEEEEEEEAEEEEEEEEEEEAAAEAAAEEE/A<AEEEEEEEEEEAA"") | \; gzip > R1.fastq.gz. (echo ""@NB500989:333:HKYJNAFX2:1:11101:24447:1024""; echo ""NNNNTTGTATTTTTAATAGAGACGGGGTTTCAACATGTTGGCCAGGCTGGTCTTGAACTCCTGACCTCAGATGATCCACCCGCCTTGGCCTCCCAAAGTGCTAAGATTACAGGTGTGAGCTACTGCACCTGGCCCCCTCTAGTTTCTTTC""; echo ""+""; echo ""####AEEEEEEEEEEEEEEEE/EEEEEEEEEE6EEEEEEEEEEEEA<EEEEEEEEE/<EEEEEEE/EEEEEEEEEEE/EEEEEAEEEEEAEAEEEE/EEEEE/EEEEEEEEEEEEEAEEEEEEEEAE/<AAAA/<A<EE<<EA<A/AAE<""; echo ""@NB500989:333:HKYJNAFX2:1:11101:10000:1915""; echo ""TTACAGGATCTGAAGAGAGGGAAAAATAAACATGCACGATTATTTAATTCTTTTGGAAAAACTGCATGTAAGTGAAGTTCTCTTTCACAAGACACAAGCATCGGTAACTTGACAAAAAATGTAAGCTTCAGATTTTTATGAGCCTTTACA""; echo ""+""; echo ""AAAAAEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE/EEEEEEEEEE6EEEEEEEEEEEEAEEEEEE/EEEAEEEEEEEEEEEEEAEEAE/EEEEEEEEEAEEEEEEA<EEEEEE<AAEEEEEEEEEEAEEEEEAEAAEAE/AAEAEAA<E"") | \; gzip > R2.fastq.gz; ```. Install bwa and GATK resources:; ```; sudo apt install java11-runtime bwa samtools; wget https://github.com/broadinstitute/gatk/releases/download/4.2.1.0/gatk-4.2.1.0.zip; unzip gatk-4.2.1.0.zip; echo dict fasta fasta.fai fasta.64.alt fasta.64.sa fasta.64.amb fasta.64.bwt fasta.64.ann fasta.64.pac | \; tr ' ' '\n' | xargs -i echo gs://gcp-public-data--broad-references/hg38/v0/Homo_sapiens_assembly38.{} | \; gsutil -m cp -I .; ```. Run FastqToSam with the `-SORT_ORDER ""unsorted""` option:; ```; gatk-4.2.1.0/gatk \; FastqToSam \; -FASTQ R1.fastq.gz \; -FASTQ2 R2.fastq.gz \; -OUTPUT unmapped.bam",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7398:821,echo,echo,821,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7398,8,['echo'],['echo']
Availability,"CFs step using a GenomicsDB database. ---; Hi,. I am trying to process locally 260 WES gvcf through joint discovery wdl pipeline. I encountered an error at GenotypeGVCFs below which I am not sure how to proceed. I have used all the default reference libraries and only modified the merge_count in the script to be 8144 so that my server resources won't be maxout fully in the ImportGVCFs step. . [https://github.com/gatk-workflows/gatk4-germline-snps-indels/blob/master/joint-discovery-gatk4-local.wdl](https://github.com/gatk-workflows/gatk4-germline-snps-indels/blob/master/joint-discovery-gatk4-local.wdl ""https://github.com/gatk-workflows/gatk4-germline-snps-indels/blob/master/joint-discovery-gatk4-local.wdl""). ```; 23:17:43.992 WARN InbreedingCoeff - Annotation will not be calculated, must provide at least 10 samples; 23:17:44.064 WARN InbreedingCoeff - Annotation will not be calculated, must provide at least 10 samples; 23:17:46.334 INFO GenotypeGVCFs - Shutting down engine; GENOMICSDB_TIMER,GenomicsDB iterator next() timer,Wall-clock time(s),30.197597194999727,Cpu time(s),28.791204838999864; [June 25, 2018 11:17:46 PM UTC] org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs done. Elapsed time: 4.01 minutes.; Runtime.totalMemory()=5354029056; java.lang.IllegalArgumentException: log10LikelihoodsOfAC are bad 2.559797571100845E-21,NaN; 	at org.broadinstitute.hellbender.tools.walkers.genotyper.afcalc.AFCalculationResult.<init>(AFCalculationResult.java:72); 	at org.broadinstitute.hellbender.tools.walkers.genotyper.afcalc.AlleleFrequencyCalculator.getLog10PNonRef(AlleleFrequencyCalculator.java:143); 	at org.broadinstitute.hellbender.tools.walkers.genotyper.GenotypingEngine.calculateGenotypes(GenotypingEngine.java:255); 	at org.broadinstitute.hellbender.tools.walkers.genotyper.GenotypingEngine.calculateGenotypes(GenotypingEngine.java:210); 	at org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs.calculateGenotypes(GenotypeGVCFs.java:266); 	at org.broadinstitute.hel",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4975:1259,down,down,1259,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4975,1,['down'],['down']
Availability,CGACCCTATAAATGATGACCTCCGTTATCGGAAGGGCACAGAACCGTCAGCCGCAACACCAGCAGCTGTAGGCCCTGCTGGGCGCGCTGGG	8;72442435768::8443224764768:84:7534457962;99:787;628:7557;::7:72878:7;:7;:8754;9:::87:8799:7:7:87::	YA:Z:chr20:3145675:600M138N208I599M	MC:Z:100M	PG:Z:MarkDuplicates	RG:Z:1	NH:i:1	HI:i:1	YM:i:0	nM:i:100	YO:Z:chr20:3146278:+:56S44M	MQ:i:60	AS:i:140	YX:i:49	mc:i:3146406	ms:i:2300; ```. #### Steps to reproduce; Command line:; ```; gatk \; --java-options '-DGATK_STACKTRACE_ON_USER_EXCEPTION=true' \; SplitNCigarReads \; --reference $REF \; --input 100I_rna.bam \; --output gatk.split.bam \; > split.log 2>&1; ```. A tiny BAM file illustrating the problem is attached (it is gzipped to allow Github upload).; [100I_rna.bam.gz](https://github.com/broadinstitute/gatk/files/2456955/100I_rna.bam.gz). #### Actual behavior; Here is the stacktrace:; ```; ***********************************************************************. A USER ERROR has occurred: Badly formed genome unclippedLoc: Parameters to GenomeLocParser are incorrect:The stop position 3146412 is less than start 3146413 in contig chr20. ***********************************************************************; org.broadinstitute.hellbender.exceptions.UserException$MalformedGenomeLoc: Badly formed genome unclippedLoc: Parameters to GenomeLocParser are incorrect:The stop position 3146412 is less than start 3146413 in contig chr20; at org.broadinstitute.hellbender.utils.GenomeLocParser.vglHelper(GenomeLocParser.java:280); at org.broadinstitute.hellbender.utils.GenomeLocParser.validateGenomeLoc(GenomeLocParser.java:226); at org.broadinstitute.hellbender.utils.GenomeLocParser.createGenomeLoc(GenomeLocParser.java:185); at org.broadinstitute.hellbender.utils.GenomeLocParser.createGenomeLoc(GenomeLocParser.java:169); at org.broadinstitute.hellbender.utils.GenomeLocParser.createGenomeLoc(GenomeLocParser.java:150); at org.broadinstitute.hellbender.tools.walkers.rnaseq.OverhangFixingManager$SplitRead.setRead(OverhangFixingManager.java:402); at ,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5293:1654,ERROR,ERROR,1654,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5293,1,['ERROR'],['ERROR']
Availability,"CGCCTTGGCCTCCCAAAGTGCTAAGATTACAGGTGTGAGCTACTGCACCTGGCCCCCTCTAGTTTCTTTC""; echo ""+""; echo ""####AEEEEEEEEEEEEEEEE/EEEEEEEEEE6EEEEEEEEEEEEA<EEEEEEEEE/<EEEEEEE/EEEEEEEEEEE/EEEEEAEEEEEAEAEEEE/EEEEE/EEEEEEEEEEEEEAEEEEEEEEAE/<AAAA/<A<EE<<EA<A/AAE<""; echo ""@NB500989:333:HKYJNAFX2:1:11101:10000:1915""; echo ""TTACAGGATCTGAAGAGAGGGAAAAATAAACATGCACGATTATTTAATTCTTTTGGAAAAACTGCATGTAAGTGAAGTTCTCTTTCACAAGACACAAGCATCGGTAACTTGACAAAAAATGTAAGCTTCAGATTTTTATGAGCCTTTACA""; echo ""+""; echo ""AAAAAEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE/EEEEEEEEEE6EEEEEEEEEEEEAEEEEEE/EEEAEEEEEEEEEEEEEAEEAE/EEEEEEEEEAEEEEEEA<EEEEEE<AAEEEEEEEEEEAEEEEEAEAAEAE/AAEAEAA<E"") | \; gzip > R2.fastq.gz; ```. Install bwa and GATK resources:; ```; sudo apt install java11-runtime bwa samtools; wget https://github.com/broadinstitute/gatk/releases/download/4.2.1.0/gatk-4.2.1.0.zip; unzip gatk-4.2.1.0.zip; echo dict fasta fasta.fai fasta.64.alt fasta.64.sa fasta.64.amb fasta.64.bwt fasta.64.ann fasta.64.pac | \; tr ' ' '\n' | xargs -i echo gs://gcp-public-data--broad-references/hg38/v0/Homo_sapiens_assembly38.{} | \; gsutil -m cp -I .; ```. Run FastqToSam with the `-SORT_ORDER ""unsorted""` option:; ```; gatk-4.2.1.0/gatk \; FastqToSam \; -FASTQ R1.fastq.gz \; -FASTQ2 R2.fastq.gz \; -OUTPUT unmapped.bam \; -SAMPLE_NAME SM \; -SORT_ORDER ""unsorted""; ```; Notice the option `-SORT_ORDER ""unsorted""` which prevents the tool from resorting the reads which can add both computational and storage requirements. Aligned the data with bwa:; ```; gatk-4.2.1.0/gatk \; SamToFastq \; -INPUT unmapped.bam \; -FASTQ /dev/stdout \; -INTERLEAVE true | \; bwa mem -K 100000000 -p -v 3 -t 16 -Y Homo_sapiens_assembly38.fasta /dev/stdin | \; samtools view -1 - > aligned.unmerged.bam; ```. Merge unmapped and aligned BAMs:; ```; gatk-4.2.1.0/gatk \; MergeBamAlignment \; -ALIGNED_BAM aligned.unmerged.bam \; -UNMAPPED_BAM unmapped.bam \; -OUTPUT aligned.unsorted.bam \; -SORT_ORDER ""unsorted"" \; -REFERENCE_SEQUENCE \; Homo_sapiens_assembly38.fasta; ```. This produces th",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7398:1936,echo,echo,1936,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7398,1,['echo'],['echo']
Availability,CI failures because of conda environment problems,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7800:3,failure,failures,3,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7800,1,['failure'],['failures']
Availability,CNN error python module,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4591:4,error,error,4,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4591,1,['error'],['error']
Availability,"CNNScoreVariant relies on a computationally demanding operation - a deep neural network. Using an Intel-optimized version of TensorFlow gives a 10X improvement in performance (e.g. 50 hours to 5 hours for a typical input). However, these improvements mean that we now have a minimum hardware requirement - the availability of AVX.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5291:310,avail,availability,310,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5291,1,['avail'],['availability']
Availability,CNV Pipeline outputs NaN and errors at segmentation with heavily downsampled input,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2944:29,error,errors,29,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2944,2,"['down', 'error']","['downsampled', 'errors']"
Availability,"CNV workflows are unable to handle GRCh38 alternate and decoy contig names. This acts as an unintended safeguard against users including these contigs in a CNV analysis, which _they should not do for somatic analyses_. . However, in principle, this inability to process data for a contig, albeit an alternate contig, is a bug that should be fixed. This may be relevant to someone's research as I explain to the forum user who brought this bug to our attention. My reply is shown below. ---; Hey @ameynert,. Use three ticks on an independent line to surround your code block. I see from:; ```; /exports/igmm/eddie/bioinfsvice/ameynert/software/gatk-4.beta.2/gatk-launch SparkGenomeReadCounts \; -I ../../bcbio/final/WW00247b/WW00247b-ready.bam \; -o WW00247b.prop_cov \; --reference /exports/igmm/eddie/bioinfsvice/ameynert/bcbio/data/genomes/Hsapiens/hg38/seq/hg38.fa ; ```; that you are using GRCh38. So I think the `A*01` from the error message refers to any of the eleven HLA-A contigs:; ```; WMCF9-CB5:~ shlee$ cat ~/Documents/ref/hg38/Homo_sapiens_assembly38.dict | grep 'A\*01'; @SQ	SN:HLA-A*01:01:01:01	LN:3503	M5:01cd0df602495b044b2c214d69a60aa2	AS:38	UR:/seq/references/Homo_sapiens_assembly38/v0/Homo_sapiens_assembly38.fasta	SP:Homo sapiens; @SQ	SN:HLA-A*01:01:01:02N	LN:3291	M5:743d9f66c77fc21b964a681e0c6de2ad	AS:38	UR:/seq/references/Homo_sapiens_assembly38/v0/Homo_sapiens_assembly38.fasta	SP:Homo sapiens; @SQ	SN:HLA-A*01:01:38L	LN:3374	M5:dd27b7fe617e92bb77eea00fede6fd15	AS:38	UR:/seq/references/Homo_sapiens_assembly38/v0/Homo_sapiens_assembly38.fasta	SP:Homo sapiens; @SQ	SN:HLA-A*01:02	LN:3374	M5:3ba47a11a8a5b47ccb855308e26a2f4a	AS:38	UR:/seq/references/Homo_sapiens_assembly38/v0/Homo_sapiens_assembly38.fasta	SP:Homo sapiens; @SQ	SN:HLA-A*01:03	LN:3503	M5:554d43de8f2a97cae068169fe3d8462e	AS:38	UR:/seq/references/Homo_sapiens_assembly38/v0/Homo_sapiens_assembly38.fasta	SP:Homo sapiens; @SQ	SN:HLA-A*01:04N	LN:3136	M5:072ea3e53c79f3d00e1f1a7b492b0a8f	AS:38	UR:/seq/references/",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3357:933,error,error,933,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3357,1,['error'],['error']
Availability,"COMPRESSION_LEVEL : 2; 20:11:35.530 INFO CombineGVCFs - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 20:11:35.531 INFO CombineGVCFs - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 20:11:35.531 INFO CombineGVCFs - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 20:11:35.531 INFO CombineGVCFs - Deflater: IntelDeflater; 20:11:35.531 INFO CombineGVCFs - Inflater: IntelInflater; 20:11:35.531 INFO CombineGVCFs - GCS max retries/reopens: 20; 20:11:35.531 INFO CombineGVCFs - Requester pays: disabled; 20:11:35.531 INFO CombineGVCFs - Initializing engine; 20:11:35.957 INFO FeatureManager - Using codec VCFCodec to read file file:///fs/scratch/PHS0338/appz/elprep-v5.0.2/PA113.vcf.gz; 20:11:35.969 INFO CombineGVCFs - Shutting down engine; [June 13, 2021 8:11:35 PM GMT] org.broadinstitute.hellbender.tools.walkers.CombineGVCFs done. Elapsed time: 0.03 minutes.; Runtime.totalMemory()=1772093440; ***********************************************************************; A USER ERROR has occurred: An index is required but was not found for file /fs/scratch/PHS0338/appz/elprep-v5.0.2/PA113.vcf.gz. Support for unindexed block-compressed files has been temporarily disabled. Try running IndexFeatureFile on the input. ***********************************************************************. Set the system property GATK_STACKTRACE_ON_USER_EXCEPTION (--java-options '-DGATK_STACKTRACE_ON_USER_EXCEPTION=true') to print the stack trace.; Using GATK jar /gatk/gatk-package-4.2.0.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /gatk/gatk-package-4.2.0.0-local.jar CombineGVCFs -R /users/PHS0338/jpac1984/data/Autosome.fasta --variant PA113.vcf.gz --variant PA113corr.vcf.gz --variant PA112.vcf.gz --variant PA112corr.vcf.gz --variant IN33.vcf.gz --variant IN33corr.vcf.gz --variant AL82.vcf.gz -O test.vcf.gz. ------; The CombineGVCFs websi",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7311:3837,ERROR,ERROR,3837,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7311,1,['ERROR'],['ERROR']
Availability,"CPU usage was high. ```; %CPU WallTime Time Lim RSS mem memlim cpus; hugemem-ex; 105958574 R ds6924 hm82 getpileu 99 07:23:01 16:00:00 1120GB 1120GB 1400GB 37; ```. However, it never proceeds past the first interval. ```; 08:21:42.921 INFO GetPileupSummaries - The Genome Analysis Toolkit (GATK) v4.4.0.0; 08:21:42.921 INFO GetPileupSummaries - Start Date/Time: January 12, 2024 at 8:21:42 AM GMT+10:00; 08:21:42.927 INFO GetPileupSummaries - Initializing engine; 08:55:35.361 INFO IntervalArgumentCollection - Processing 326649654 bp from intervals; 08:57:45.036 INFO GetPileupSummaries - Done initializing engine; 08:57:45.101 INFO ProgressMeter - Starting traversal; 08:57:45.106 INFO ProgressMeter - Current Locus Elapsed Minutes Loci Processed Loci/Minute; (END); ```. There is a memory error in some log files but only after many hours and no intervals processed. ```; 08:34:26.243 INFO ProgressMeter - Starting traversal; 08:34:26.244 INFO ProgressMeter - Current Locus Elapsed Minutes Loci Processed Loci/Minute; 15:35:01.977 INFO GetPileupSummaries - Shutting down engine; [January 12, 2024 at 3:35:02 PM GMT+10:00] org.broadinstitute.hellbender.tools.walkers.contamination.GetPileupSummaries done. Elapsed time: 433.32 minutes.; Runtime.totalMemory()=31136546816; Exception in thread ""main"" java.lang.OutOfMemoryError: Java heap space; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8654:792,error,error,792,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8654,2,"['down', 'error']","['down', 'error']"
Availability,"Caller - ------------------------------------------------------------; 09:54:54.731 INFO HaplotypeCaller - ------------------------------------------------------------; 09:54:54.732 INFO HaplotypeCaller - HTSJDK Version: 2.21.2; 09:54:54.732 INFO HaplotypeCaller - Picard Version: 2.21.9; 09:54:54.732 INFO HaplotypeCaller - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 09:54:54.732 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 09:54:54.732 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 09:54:54.732 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 09:54:54.732 INFO HaplotypeCaller - Deflater: IntelDeflater; 09:54:54.732 INFO HaplotypeCaller - Inflater: IntelInflater; 09:54:54.732 INFO HaplotypeCaller - GCS max retries/reopens: 20; 09:54:54.732 INFO HaplotypeCaller - Requester pays: disabled; 09:54:54.732 INFO HaplotypeCaller - Initializing engine; 09:55:05.747 INFO HaplotypeCaller - Shutting down engine; [September 11, 2020 9:55:05 AM CEST] org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCaller done. Elapsed time: 0.19 minutes.; Runtime.totalMemory()=5152178176; ***********************************************************************. A USER ERROR has occurred: Fasta dict file file:///home/averdier/test/dna-seq-pipeline/Triticum_aestivum_Claire_EIv1.1.dict for reference file:///home/averdier/test/dna-seq-pipeline/Triticum_aestivum_Claire_EIv1.1.fa.gz does not exist.; Please see http://gatkforums.broadinstitute.org/discussion/1601/how-can-i-prepare-a-fasta-file-to-use-as-reference for help creating it. ***********************************************************************; Set the system property GATK_STACKTRACE_ON_USER_EXCEPTION (--java-options '-DGATK_STACKTRACE_ON_USER_EXCEPTION=true') to print the stack trace. Command 'java -Xmx100G -jar /opt/gatk/gatk-package-4.1.7.0-local.jar HaplotypeCaller -R Triticum_aestivum_Claire_EIv1.1.fa.gz --sequence-dictionary Tr",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6808:2387,down,down,2387,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6808,1,['down'],['down']
Availability,"Caused by: com.google.api.client.googleapis.json.GoogleJsonResponseException: 400 Bad Request; GET https://storage.googleapis.com/storage/v1/b/fc-secure-bd7b8bc9-f665-4269-997e-5a402088a369/o?maxResults=1&prefix=5c2db926-3b1c-479c-9ed3-a99ce518de91/omics_mutect2/60955825-7723-4bc9-8202-bdd9975bb5c0/call-mutect2/Mutect2/7d737efc-c8be-4a6d-8803-4f786129521a/call-SplitIntervals/glob-0fc990c5ca95eebc97c4c204e3e303e1/0000-scattered.interval_list.idx/&projection=full&userProject; {; ""code"" : 400,; ""errors"" : [ {; ""domain"" : ""global"",; ""message"" : ""User project specified in the request is invalid."",; ""reason"" : ""invalid""; } ],; ""message"" : ""User project specified in the request is invalid.""; }; 	at com.google.api.client.googleapis.json.GoogleJsonResponseException.from(GoogleJsonResponseException.java:146); 	at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:118); 	at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:37); 	at com.google.api.client.googleapis.services.AbstractGoogleClientRequest$1.interceptResponse(AbstractGoogleClientRequest.java:428); 	at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1111); 	at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:514); 	at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:455); 	at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.execute(AbstractGoogleClientRequest.java:565); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.list(HttpStorageRpc.java:366); 	... 33 more; ```. This can be triggered by providing an `interval_list` file in a non-RP bucket to the `-L` argument, since GATK will check for the existence of an index on the `interval_list` file and fail with the above error.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7716:5912,error,error,5912,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7716,1,['error'],['error']
Availability,"Census_Table_1_full_2012-03-15.txt -> file:///home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s/cancer_gene_census/hg19/CancerGeneCensus_Table_1_full_2012-03-15.txt; 15:41:51.073 INFO DataSourceUtils - Resolved data source file path: file:///home/shiyang/softwares/gatk-4.1.8.1/Cosmic.db -> file:///home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s/cosmic/hg19/Cosmic.db; 15:41:51.190 INFO DataSourceUtils - Resolved data source file path: file:///home/shiyang/softwares/gatk-4.1.8.1/gencode.v34lift37.annotation.REORDERED.gtf -> file:///home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s/gencode/hg19/gencode.v34lift37.annotation.REORDERED.gtf; 15:41:51.190 INFO DataSourceUtils - Setting lookahead cache for data source: Gencode : 100000; 15:41:51.191 WARN GencodeGtfCodec - GENCODE GTF Header line 1 has a version number that is above maximum tested version (v 28) (given: 34): ##description: evidence-based annotation of the human genome (GRCh38), version 34 (Ensembl 100), mapped to GRCh37 with gencode-backmap Continuing, but errors may occur.; 15:41:51.192 WARN GencodeGtfCodec - GENCODE GTF Header line 1 has a version number that is above maximum tested version (v 28) (given: 34): ##description: evidence-based annotation of the human genome (GRCh38), version 34 (Ensembl 100), mapped to GRCh37 with gencode-backmap Continuing, but errors may occur.; 15:41:51.192 INFO FeatureManager - Using codec GencodeGtfCodec to read file file:///home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s/gencode/hg19/gencode.v34lift37.annotation.REORDERED.gtf; 15:41:51.193 WARN GencodeGtfCodec - GENCODE GTF Header line 1 has a version number that is above maximum tested version (v 28) (given: 34): ##description: evidence-based annotation of the human genome (GRCh38), version 34 (Ensembl 100), mapped to GRCh37 with gencode-backmap Continuing, but errors may occur.; 15:4",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6758:18040,error,errors,18040,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6758,1,['error'],['errors']
Availability,"CentOS Linux release 7.8.2003 (Core); JAVA: openjdk/14.0.1; GATK: 4.1.8.1. ---. I was running this following command:. intervals=$(echo ""$(seq 1 22) X Y"" | tr "" "" ""\n"" | sed 's/^/-L /' | xargs); ref_fasta=""/data1/GenomicDatabases/Human/GATK/b37/human_g1k_v37_decoy.fasta""; gvcfs=$(find hapcall -maxdepth 1 -name ""*_hapcall.g.vcf.gz"" -type f | xargs ls | sed 's/^/-V /' | xargs); /data1/software/gatk/4.1.8.1/gatk --java-options ""-XX:ParallelGCThreads=30 -Xms100g -Xmx100g -Djava.io.tmpdir=tmp"" CombineGVCFs -R ${ref_fasta} -O combine/human_combine.g.vcf.gz ${gvcfs} ${intervals} -G StandardAnnotation -G AS_StandardAnnotation --create-output-variant-index true > combine/human_combine.log 2>&1. ---. Here the log:; [human_combine.log](https://github.com/broadinstitute/gatk/files/5165640/human_combine.log). 09:10:26.647 INFO IntervalArgumentCollection - Processing 3095677412 bp from intervals; 09:10:26.694 INFO CombineGVCFs - Done initializing engine; 09:10:26.713 INFO ProgressMeter - Starting traversal; 09:10:26.714 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 09:10:30.685 WARN ReferenceConfidenceVariantContextMerger - Detected invalid annotations: When trying to merge variant contexts at location 1:13021 the annotation MLEAC=[1, 0] was not a numerical value and was ignored; 09:10:39.543 INFO ProgressMeter - 1:232994 0.2 1000 4676.9; 09:10:51.253 INFO ProgressMeter - 1:688469 0.4 2000 4890.4; 09:11:01.889 INFO ProgressMeter - 1:809005 0.6 3000 5117.3; 09:11:13.838 INFO ProgressMeter - 1:818424 0.8 5000 6366.2; 09:11:16.811 INFO CombineGVCFs - Shutting down engine; [September 3, 2020 at 9:11:16 AM CST] org.broadinstitute.hellbender.tools.walkers.CombineGVCFs done. Elapsed time: 1.20 minutes.; Runtime.totalMemory()=107374182400; java.lang.NullPointerException; 	at org.broadinstitute.hellbender.tools.walkers.annotator.allelespecific.StrandBiasUtils.encode(StrandBiasUtils.java:52); 	at java.base/java.util.stream.ReferencePipeline$3$1.accep",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6790:131,echo,echo,131,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6790,1,['echo'],['echo']
Availability,Change IOUtils.createTempFile() to be more robust to all side outputs.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7017:43,robust,robust,43,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7017,1,['robust'],['robust']
Availability,Change backticks to single quotes in several error messages,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7995:45,error,error,45,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7995,1,['error'],['error']
Availability,Change backticks to single quotes in several error messages - causing shell to attempt to execute. ```; /cromwell_root/script: line 26: load_data_batch_size: command not found; Importing 25000 samples but not explicitly specified; limit for auto batch-sizing is 20000 samples.; ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7995:45,error,error,45,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7995,1,['error'],['error']
Availability,Change the json to enable running of funcotator and fix any errors that occur.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4807:60,error,errors,60,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4807,1,['error'],['errors']
Availability,Changed so that PopulateFilterSetInfo now explicitly prints to STDERR any error it encounters. . Example run [here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Quickstart%20v3%20ggrant/job_history/2f86bfa0-bf1b-451a-8217-a0ab4cba5834).; stderr has this error now:. > Error loading combined TSV into gvs-internal.gg_VS_1056.filter_set_info:; > BigQuery error in load operation: Provided Schema does not match Table gvs-; > internal:gg_VS_1056.filter_set_info. Cannot add fields (field: score2),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8530:74,error,error,74,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8530,4,"['Error', 'error']","['Error', 'error']"
Availability,"Changes to enable multi-threaded native AVX PairHMM using OpenMP. Also includes a performance improvement in the native C++ `Context` class. `VectorLoglessPairHMM.java` is hardcoded to set the maximum number of PairHMM threads (`maxNumberOfThreads`) to 100. This is the maximum number of threads **allowed** by GATK, not the number of threads **requested**. C code in the native library will query OpenMP for the number of threads available on the platform, and use min(OpenMP threads available, `maxNumberOfThreads`) threads. **Measured Speedup**; Command. ```; ./gatk-launch HaplotypeCaller -R src/test/resources/large/human_g1k_v37.20.21.fasta -I src/test/resources/large/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.bam -O out.g.vcf -ERC GVCF; ```. 1 thread; INFO PairHMM - Total compute time in PairHMM computeLogLikelihoods() : 36.882098080000006; 2 threads; INFO PairHMM - Total compute time in PairHMM computeLogLikelihoods() : 18.160468659000003; 3 threads; INFO PairHMM - Total compute time in PairHMM computeLogLikelihoods() : 12.541517043; 4 threads; INFO PairHMM - Total compute time in PairHMM computeLogLikelihoods() : 9.727374342000001. **Potential issues**; - The target platform running GATK must have OpenMP installed; - The code has not been tested on Mac. **Todo**; - New Java code to allow the user to specify `maxNumberOfThreads` variable in `VectorLoglessPairHMM.java`.; - Move `maxNumberOfThreads` to the native `initialize` function, once we migrate to the new native library.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1813:431,avail,available,431,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1813,2,['avail'],['available']
Availability,Checkpoint of necessary changes for DRAGEN v3.7.8 concordance,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8083:0,Checkpoint,Checkpoint,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8083,1,['Checkpoint'],['Checkpoint']
Availability,Closes #3291 . - Detects the issue earlier and fails with a better error message that is local (in code) to the problem.; - Removes the spew of warnings that are not useful except in debug.; - Fixes an issue where filter values were being replaced instead of appended.; - Implemented a wrapper to always guarantee sorting never collides.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3305:67,error,error,67,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3305,1,['error'],['error']
Availability,"Closes #4782 ; Closes #5959. We should discuss a few issues, and modify/cleanup if necessary, before this goes in (if it does at all). In particular, I'd like to understand the original intent behind using the /root directory (e.g., in all of our WDLs) and make sure we don't break typical downstream uses by instead using /gatk; we could even consider ""deprecating"" this over a few releases. I think it's also worth discussing whether we want to continue to release a rootful image, but perhaps parameterize the Docker build script to easily allow the building of an image with a non-root user. I must admit that I don't have good visibility on the various use cases of our Dockers (outside of our typical use with Terra/Cromwell), so if any users would like to chime in, that would certainly be appreciated. In particular, users may still have to do some work on their end to remap user namespaces. In any case, this is at least a proof-of-principle that mounting resources is possible within our test framework with the option for a non-root user. So unless we have other good reasons for requiring a root user, it seems worthwhile to at least allow this option, even if we don't make that the new default. (EDIT: Just to clarify, at some point I was told by another developer that the need to mount testing resources within Travis was at least one reason why we needed a root user---turns out this isn't the case.)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6525:290,down,downstream,290,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6525,1,['down'],['downstream']
Availability,"Closes #4829. Also cleans up many other implausible deletions in the bamout, a few tens of thousands per genome. @ldgauthier I would especially like your thoughts on the ungainly use of `useReferenceIfUninformative`. I wanted to be conservative about switching things like contamination downsampling to the new version, but it's inelegant.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4858:287,down,downsampling,287,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4858,1,['down'],['downsampling']
Availability,"Closes #4868. @takutosato This reduces false positives and improves speed at no cost to sensitivity. I'm not quite ready to turn it on by default but I want it in the code to begin experiments, such as combining with linked de Bruijn graphs and FFPE error correction.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6470:250,error,error,250,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6470,1,['error'],['error']
Availability,"Closes #5088. @takutosato Not a high priority, just cutting down the list of open issues.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5555:60,down,down,60,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5555,1,['down'],['down']
Availability,"Closes #5391. @takutosato this will make several users happy: https://gatkforums.broadinstitute.org/gatk/discussion/13467/mutect2-pipeline-fails-for-some-inputs#latest, https://gatkforums.broadinstitute.org/gatk/discussion/12618/run-mutect2-in-gatk-4-0-4-0-with-an-error-java-lang-numberformatexception-for-input-string. Looping in @bhanugandham",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5442:265,error,error-java-lang-numberformatexception-for-input-string,265,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5442,1,['error'],['error-java-lang-numberformatexception-for-input-string']
Availability,"Closes #6336. @fleharty could you verify that this branch fixes the error and review? This uses code similar to other annotations that find an offset into a read's bases and are not buggy, as far as we know.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6355:68,error,error,68,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6355,1,['error'],['error']
Availability,"Closes #6586. @droazen . `AlleleLikelihoods` caches the evidence-to-index `Map`. The previous implementation tried to update this map on the fly whenever evidence was removed. The new approach is to simply invalidate the cache and allow the existing code to generate it to run later. I don't expect this to cause performance problems for a few reasons:. 1. It only applies when we're doing contamination downsampling.; 2. It may save time whenever evidence is removed and we don't need the evidence-to-index map later.; 3. Regenerating the cache is O(N), but so is updating on-the-fly even when only one read is removed.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6593:404,down,downsampling,404,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6593,1,['down'],['downsampling']
Availability,"Closes #6686. @fleharty This option did nothing because a copy of the original reads was modified. By deleting the unnecessary mapping quality filtering (this is totally redundant with the M2 read filter), we finalize (and thereby discard soft clips if requested) an assembly region made from the original reads, not a copy.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6823:170,redundant,redundant,170,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6823,1,['redundant'],['redundant']
Availability,"Closes https://broadworkbench.atlassian.net/browse/VS-159. - move execute_with_retry to utils so that only defined in one place; - add more specific error handling. **NOTE for reviewers**: you probably want to check ""Hide whitespace changes"" under settings because IntelliJ did some ""helpful"" cleanup when I made some code changes to files.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7480:149,error,error,149,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7480,1,['error'],['error']
Availability,"Cloud tests are failing due to ""Error while looking up reference set EOSsjdnTicvzwAE"".",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4163:32,Error,Error,32,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4163,1,['Error'],['Error']
Availability,Code coverage down by 20%,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5001:14,down,down,14,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5001,1,['down'],['down']
Availability,CollectSequencingArtifactMetrics (GATK) has errors and requires workaround in downstream tools,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3030:44,error,errors,44,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3030,2,"['down', 'error']","['downstream', 'errors']"
Availability,CombineGVCFs error,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7311:13,error,error,13,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7311,1,['error'],['error']
Availability,CombineGVCFs meet error,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8869:18,error,error,18,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8869,1,['error'],['error']
Availability,CombineGVCFs: ERROR input alleles must contain <NON_REF>,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7737:14,ERROR,ERROR,14,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7737,1,['ERROR'],['ERROR']
Availability,"Coming from https://gatkforums.broadinstitute.org/gatk/discussion/9358/gatk-runtime-error-read-max-length-must-be-0-but-got-0-with-1000g-bam#latest. There seems to be a bug somewhere in the implementation of pair hmm, which multiple users have run into. The most recent user reported running Mutect2 on two different machines with the same inputs, and same versions of GATK. One run was successful, while the other failed with ; ``` ; java.lang.IllegalArgumentException: readMaxLength must be > 0 but got 0; 	at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:730); 	at org.broadinstitute.hellbender.utils.pairhmm.PairHMM.initialize(PairHMM.java:152); 	at org.broadinstitute.hellbender.utils.pairhmm.N2MemoryPairHMM.initialize(N2MemoryPairHMM.java:28); 	at org.broadinstitute.hellbender.utils.pairhmm.LoglessPairHMM.initialize(LoglessPairHMM.java:7); 	at org.broadinstitute.hellbender.utils.pairhmm.PairHMM.initialize(PairHMM.java:177); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.PairHMMLikelihoodCalculationEngine.initializePairHMM(PairHMMLikelihoodCalculationEngine.java:242); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.PairHMMLikelihoodCalculationEngine.computeReadLikelihoods(PairHMMLikelihoodCalculationEngine.java:177); 	at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2Engine.callRegion(Mutect2Engine.java:207); 	at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2.apply(Mutect2.java:212); 	at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.processReadShard(AssemblyRegionWalker.java:291); 	at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.traverse(AssemblyRegionWalker.java:267); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:979); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:137); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:182); 	at org.broadins",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5543:84,error,error-read-max-length-must-be-,84,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5543,1,['error'],['error-read-max-length-must-be-']
Availability,"Command:; ```; bash build_docker_bash.sh; ```; Error:; ```; ...; Step 12/13 : RUN Rscript install_R_packages.R; ---> Running in 96b5753b6c04; Installing packages into '/usr/local/lib/R/site-library'; (as 'lib' is unspecified); Error: (converted from warning) dependency 'caTools' is not available; Execution halted; The command '/bin/sh -c Rscript install_R_packages.R' returned a non-zero code: 1; ```; I came up with this temporary workaround in `install_R_packages.R`:; ```; repos <- c(""http://cran.mtu.edu""); install.packages(c(""bitops""), repos = repos, clean = TRUE); InstallPackageFromArchive(""caTools"", ""https://cran.r-project.org/src/contrib/Archive/caTools/caTools_1.17.tar.gz""); dependencies = c(""gplots"",; ""digest"", ""gtable"", ""MASS"", ""plyr"", ""reshape2"", ""scales"", ""tibble"", ""lazyeval"", # for ggplot2; ""tidyselect"", ""BH"", ""plogr"") # for dplyr; install.packages(dependencies, repos = repos, clean = TRUE); ```; which at least builds successfully.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6489:47,Error,Error,47,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6489,3,"['Error', 'avail']","['Error', 'available']"
Availability,"Command:; `java -Djava.io.tmpdir=/work/TMP \ ; -Xmx40g -jar ~/bin/gatk-4.0.8.1/gatk-package-4.0.8.1-local.jar \ ; GenomicsDBImport \ ; -V /work/Analysis/III_3P_RG_DupMark.raw.snps.indels.g.vcf \ ; -V /work/Analysis/IV_11N_RG_DupMark.raw.snps.indels.g.vcf \; -V /work/Analysis/IV_8N_RG_DupMark.raw.snps.indels.g.vcf \; -V /work/Analysis/IV_10P_RG_DupMark.raw.snps.indels.g.vcf \; -V /work/Analysis/IV_20P_RG_DupMark.raw.snps.indels.g.vcf \; --genomicsdb-workspace-path /work/Analysis/wang_chr19_re \; --intervals chr19`. **Error Log**. 15:00:35.770 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/wang/bin/gatk-4.0.8.1/gatk-package-4.0.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; 15:00:35.944 INFO GenomicsDBImport - ------------------------------------------------------------; 15:00:35.944 INFO GenomicsDBImport - The Genome Analysis Toolkit (GATK) v4.0.8.1; 15:00:35.945 INFO GenomicsDBImport - For support and documentation go to https://software.broadinstitute.org/gatk/; 15:00:35.945 INFO GenomicsDBImport - Executing as wang@Ubuntu1604 on Linux v3.16.0-43-generic amd64; 15:00:35.945 INFO GenomicsDBImport - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_171-8u171-b11-2~14.04-b11; 15:00:35.945 INFO GenomicsDBImport - Start Date/Time: October 2, 2018 3:00:35 PM JST; 15:00:35.945 INFO GenomicsDBImport - ------------------------------------------------------------; 15:00:35.945 INFO GenomicsDBImport - ------------------------------------------------------------; 15:00:35.946 INFO GenomicsDBImport - HTSJDK Version: 2.16.0; 15:00:35.946 INFO GenomicsDBImport - Picard Version: 2.18.7; 15:00:35.946 INFO GenomicsDBImport - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 15:00:35.946 INFO GenomicsDBImport - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 15:00:35.946 INFO GenomicsDBImport - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 15:00:35.946 INFO GenomicsDBImport - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 15:00:35.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5342:522,Error,Error,522,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5342,1,['Error'],['Error']
Availability,CommandLineProgram.java:195); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:131); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:152); 	at org.broadinstitute.hellbender.Main.main(Main.java:233); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:736); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.io.IOException: Error code 404 trying to get security access token from Compute Engine metadata for the default service account. This may be because the virtual machine instance does not have permission scopes specified.; 	at shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials.refreshAccessToken(ComputeEngineCredentials.java:137); 	at shaded.cloud_nio.com.google.auth.oauth2.OAuth2Credentials.refresh(OAuth2Credentials.java:160); 	at shaded.cloud_nio.com.google.auth.oauth2.OAuth2Credentials.getRequestMetadata(OAuth2Credentials.java:146); 	at shaded.cloud_nio.com.google.auth.http.HttpCredentialsAdapter.initialize(HttpCredentialsAdapter.java:96); 	at com.google.cloud.http.HttpTransportOptions$1.initialize(HttpTransportOptions.java:157); 	at shaded.cloud_nio.com.google.api.client.http.HttpRequestFactory.buildRequest(HttpRequestFactory.java:93); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.buildHttpRequest(AbstractGoogleClientRequest.java:300); 	at shaded.cloud_nio.com.google.api.client.googleapis.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3591:3620,Error,Error,3620,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3591,1,['Error'],['Error']
Availability,"CompareSAMs ignores validation stringency. Running this. ```; build/install/hellbender/bin/hellbender CompareSAMs src/test/resources/org/broadinstitute/hellbender/tools/BQSR/NA12878.chr17_69k_70k.dictFix.bam src/test/resources/org/broadinstitute/hellbender/tools/BQSR/NA12878.chr17_69k_70k.dictFix.bam --VALIDATION_STRINGENCY SILENT; ```. results in this. ```; htsjdk.samtools.SAMFormatException: SAM validation error: ERROR: Record 130, Read name 809R9ABXX101220:5:6:17918:145992, Mate Alignment start should be 0 because reference name = *.; at htsjdk.samtools.SAMUtils.processValidationErrors(SAMUtils.java:439); at htsjdk.samtools.BAMFileReader$BAMFileIterator.advance(BAMFileReader.java:643); at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:628); at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:598); at htsjdk.samtools.SamReader$AssertingIterator.next(SamReader.java:544); at htsjdk.samtools.SamReader$AssertingIterator.next(SamReader.java:518); at htsjdk.samtools.util.PeekIterator.peek(PeekIterator.java:67); at htsjdk.samtools.SecondaryOrSupplementarySkippingIterator.skipAnyNotprimary(SecondaryOrSupplementarySkippingIterator.java:36); at htsjdk.samtools.SecondaryOrSupplementarySkippingIterator.advance(SecondaryOrSupplementarySkippingIterator.java:31); at org.broadinstitute.hellbender.utils.read.SamComparison.compareCoordinateSortedAlignments(SamComparison.java:111); at org.broadinstitute.hellbender.utils.read.SamComparison.compareAlignments(SamComparison.java:68); at org.broadinstitute.hellbender.utils.read.SamComparison.<init>(SamComparison.java:44); at org.broadinstitute.hellbender.tools.picard.sam.CompareSAMs.doWork(CompareSAMs.java:34); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:94); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:144); at org.broadinstitute.hellbender.cmdline.PicardCommandLineProgram.instanceMain(PicardComm",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/419:412,error,error,412,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/419,2,"['ERROR', 'error']","['ERROR', 'error']"
Availability,"Completed tests with three options including MINIMUM_MAPPING_QUALITY=39, TAIL_LIMIT=25000, and CHIMERA_KB_MIN=200000. However, throws an error when using ""null"". Needless to say, so does Picard.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/884:137,error,error,137,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/884,1,['error'],['error']
Availability,Concordance testing against GATK3 annotations for HaplotypeCaller (with a configurable tolerance before failure),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1732:87,toler,tolerance,87,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1732,2,"['failure', 'toler']","['failure', 'tolerance']"
Availability,Concordance tool should detect the case where no sequence dictionaries are available and throw a UserException,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7023:75,avail,available,75,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7023,1,['avail'],['available']
Availability,ConcurrentModificationException causes HaplotypeCallerSparkIntegrationTest.testVCFModeIsConcordantWithGATK3_8Results failure.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6513:117,failure,failure,117,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6513,1,['failure'],['failure']
Availability,Confusing error from GenomicsDBImport:. ```; $ ./gatk-launch GenomicsDBImport --genomicsDBWorkspace /tmp/gendb --intervals chr20:1-64444167 --batchSize 300 --genomicsDBSegmentSize 1048576 --overwriteExistingGenomicsDBWorkspace true --cloudPrefetchBuffer 2 --cloudIndexPrefetchBuffer 2 --variant gs://hellbender/test/resources/large/gvcfs/NA19625.g.vcf.gz; (...); [TileDB::Fragment] Error: Cannot rename fragment directory; Directory not empty.; ```. /tmp/gendb is empty before my call to GenomicsDBImport.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2743:10,error,error,10,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2743,2,"['Error', 'error']","['Error', 'error']"
Availability,Confusing error message when hdfs file isn't found,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1257:10,error,error,10,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1257,1,['error'],['error']
Availability,"Consider if your ""issue"" is better addressed on the GATK forum: http://gatkforums.broadinstitute.org/gatk Post there if you have questions about expected tool behavior, output format, unexpected results, or generally any question that does not fit into the categories above; - Use a **concise** yet **descriptive** title; - Choose the corresponding template block below and fill it in, replacing or deleting text in italics (surrounded by `_`) as appropriate; - Delete the other template blocks and this header. ----. ## Bug Report. ### Affected tool(s) or class(es); Funcotator; gatk Funcotator --variant test.somatic.vcf --reference ucsc.hg19.fasta --ref-version hg19 --data-sources-path funcotator_dataSources.v1.7.20200521s --output test.maf --output-file-format MAF; ### Affected version(s); gatk4.1.8.1 (installed using conda). ### Description ; I want to use Funcotator to annotate the VCF file given by Illumina TruSight Oncology 500 pipeline. But when I run the command above, it throws out an error, seems something related with malformat. I check my VCF file and think it should be OK. So I wonder if you can kindly tell me how to fix this bug?; The ERROR is:; `Using GATK jar /home/shiyang/softwares/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /home/shiyang/softwares/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar Funcotator --variant /home/shiyang/Project/BGB900_101/TSO_result/TSO_somatic_vcf/112-0005-0031-B1_L1.UP12.tmb.tsv.tso.somatic.vcf --reference /storage01/ref_genome/hg19/bwa/ucsc.hg19.fasta --ref-version hg19 --data-sources-path /home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s --output /home/shiyang/Project/BGB900_101/TSO_result/test.maf --output-file-format MAF; 15:41:48.793 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/shiyang/s",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6758:1653,error,error,1653,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6758,1,['error'],['error']
Availability,"ContainerLaunch.call(ContainerLaunch.java:302); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Container exited with a non-zero exit code 50. Driver stacktrace:; 17/10/11 14:19:38 INFO spark.ExecutorAllocationManager: Existing executor 2 has been removed (new total is 0); 17/10/11 14:19:38 INFO scheduler.DAGScheduler: Job 0 failed: saveAsNewAPIHadoopFile at ReadsSparkSink.java:203, took 19.909238 s; 17/10/11 14:19:38 INFO ui.SparkUI: Stopped Spark web UI at http://10.131.101.159:4040; 17/10/11 14:19:38 INFO cluster.YarnClientSchedulerBackend: Interrupting monitor thread; 17/10/11 14:19:38 INFO cluster.YarnClientSchedulerBackend: Shutting down all executors; 17/10/11 14:19:38 INFO cluster.YarnClientSchedulerBackend: Asking each executor to shut down; 17/10/11 14:19:38 INFO cluster.YarnClientSchedulerBackend: Stopped; 17/10/11 14:19:38 INFO spark.MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 17/10/11 14:19:38 INFO storage.MemoryStore: MemoryStore cleared; 17/10/11 14:19:38 INFO storage.BlockManager: BlockManager stopped; 17/10/11 14:19:38 INFO storage.BlockManagerMaster: BlockManagerMaster stopped; 17/10/11 14:19:38 INFO scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 17/10/11 14:19:38 INFO spark.SparkContext: Successfully stopped SparkContext; 14:19:38.600 INFO PrintReadsSpark - Shutting down engine; [October 11, 2017 2:19:38 PM CST] org.broadinstitute.hellbender.tools.spark.pipelines.PrintReadsSpark done. Elapsed time: 0.48 minutes.; Runtime.totalMemory()=986185728; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686:30997,down,down,30997,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686,1,['down'],['down']
Availability,"Context.scala:1899); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1899); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); at org.apache.spark.scheduler.Task.run(Task.scala:86); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748). 00:11:09.634 ERROR TaskSetManager:70 - Task 15 in stage 1.0 failed 1 times; aborting job; 00:11:09.810 WARN TaskSetManager:66 - Lost task 33.0 in stage 1.0 (TID 528, localhost): TaskKilled (killed intentionally); 00:11:24.786 INFO HaplotypeCallerSpark - Shutting down engine; [May 26, 2017 12:11:24 AM UTC] org.broadinstitute.hellbender.tools.HaplotypeCallerSpark done. Elapsed time: 10.58 minutes.; Runtime.totalMemory()=16622026752; org.apache.spark.SparkException: Job aborted due to stage failure: Task 15 in stage 1.0 failed 1 times, most recent failure: Lost task 15.0 in stage 1.0 (TID 519; , localhost): java.lang.IllegalStateException: Duplicate key [B@4e233a3c; at java.util.stream.Collectors.lambda$throwingMerger$0(Collectors.java:133); at java.util.HashMap.merge(HashMap.java:1253); at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1320); at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.PairHMMLikelihoodCal",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3018:9674,failure,failure,9674,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3018,1,['failure'],['failure']
Availability,Convergence Error running GATK GermlineCNVCaller cohort mode,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8952:12,Error,Error,12,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8952,1,['Error'],['Error']
Availability,Cost WDL should throw on FISS API errors [VS-518],MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7942:34,error,errors,34,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7942,1,['error'],['errors']
Availability,Could it be possible to move the locale setup and picard-parser config to the first method in `mainEntry` (or another place that can be overrided and/or picked by the tests/downstream toolkits)?. https://github.com/broadinstitute/gatk/blob/51273676b20d25cacf238d1c0429ebc79b321a85/src/main/java/org/broadinstitute/hellbender/Main.java#L38-L50,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5014:173,down,downstream,173,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5014,1,['down'],['downstream']
Availability,"Could it be possible to set all these properties and configurations in a method annotated with `@BeforeSuite`?. https://github.com/broadinstitute/gatk/blob/3c960c9d7174785a82d272fe9cd33076ae7ed271/src/main/java/org/broadinstitute/hellbender/utils/test/BaseTest.java#L35-L42. Downstream toolkits using the testing framework provided by GATK (and thus, extending `BaseTest`) might benefit for that change - currently they are kept unset if not explicitly defined by the implementation. If it is not possible because it is not correctly handled by TestNG, feel free to close the issue.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5013:275,Down,Downstream,275,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5013,1,['Down'],['Downstream']
Availability,"CountVariants and SelectVariants both read the same file successfully. gatk-launch SortVcf --input /humgen/test.filtered.maf_annotated.vcf --output sortvcf.vcf. htsjdk.tribble.TribbleException$MalformedFeatureFile: Unable to parse header with error: Your input file has a malformed header: This codec is strictly for VCFv4; please use the VCF3 codec for VCFv3.3, for input source: /humgen/test.filtered.maf_annotated.vcf; at htsjdk.tribble.TribbleIndexedFeatureReader.readHeader(TribbleIndexedFeatureReader.java:226); at htsjdk.tribble.TribbleIndexedFeatureReader.<init>(TribbleIndexedFeatureReader.java:92); at htsjdk.tribble.TribbleIndexedFeatureReader.<init>(TribbleIndexedFeatureReader.java:103); at htsjdk.tribble.AbstractFeatureReader.getFeatureReader(AbstractFeatureReader.java:89); at htsjdk.tribble.AbstractFeatureReader.getFeatureReader(AbstractFeatureReader.java:66); at htsjdk.variant.vcf.VCFFileReader.<init>(VCFFileReader.java:58); at org.broadinstitute.hellbender.tools.picard.vcf.SortVcf.collectFileReadersAndHeaders(SortVcf.java:92); at org.broadinstitute.hellbender.tools.picard.vcf.SortVcf.doWork(SortVcf.java:76); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:98); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:146); at org.broadinstitute.hellbender.cmdline.PicardCommandLineProgram.instanceMain(PicardCommandLineProgram.java:61); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:66); at org.broadinstitute.hellbender.Main.main(Main.java:81); Caused by: htsjdk.tribble.TribbleException$InvalidHeader: Your input file has a malformed header: This codec is strictly for VCFv4; please use the VCF3 codec for VCFv3.3; at htsjdk.variant.vcf.VCFCodec.readActualHeader(VCFCodec.java:100); at htsjdk.tribble.AsciiFeatureCodec.readHeader(AsciiFeatureCodec.java:88); at htsjdk.tribble.AsciiFeatureCodec.readHeader(AsciiFeatureCodec.java:41); at htsjdk.tribble.TribbleIn",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1304:243,error,error,243,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1304,1,['error'],['error']
Availability,CountVariants bogus error message when file missing and -L is used,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1896:20,error,error,20,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1896,1,['error'],['error']
Availability,Create framework for intelligent comparison of annotation values (with tolerance) in the test suite,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3275:71,toler,tolerance,71,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3275,1,['toler'],['tolerance']
Availability,CreateSomaticPanelOfNormals germlineAF error,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7215:39,error,error,39,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7215,1,['error'],['error']
Availability,CreateVariantIngestFiles robust to partially / fully loaded samples [VS-262],MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7843:25,robust,robust,25,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7843,1,['robust'],['robust']
Availability,Created NioFileCopier that copies files using nio paths (includes; optional progress indicator and integrity validation).; Updated an error message in funcotator to make it more descriptive. Fixes #4549,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5150:134,error,error,134,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5150,1,['error'],['error']
Availability,Created VAT here: https://app.terra.bio/#workspaces/gvs-dev/RSA%20-%20GVS%20Quickstart%20V2%20/job_history/b5c03ce6-cc74-462a-b81d-8ea102be314e; Validated VAT here: https://app.terra.bio/#workspaces/gvs-dev/RSA%20-%20GVS%20Quickstart%20V2%20/job_history/e6511960-8340-4e74-8f06-6c1a69d848bd (confirming with Rori that the failures are not surprising given it's only 10 samples),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8665:322,failure,failures,322,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8665,1,['failure'],['failures']
Availability,Created a FuncotatorDataSourceRetriever to download data sources.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5150:43,down,download,43,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5150,1,['down'],['download']
Availability,Creating Conda gatk env error,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4822:24,error,error,24,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4822,1,['error'],['error']
Availability,"Creating test files by hand is tedious, error-prone, and bloats the repo. When writing new tests, we should try to generate test data in-memory where possible. Picard has SamFileTester, which is a wrapper around HTSJDK's SAMRecordSetBuilder. GATK has ArtificialSAMUtils. SamFileTester/SAMRecordSetBuilder is only used in a few places (e.g. MarkDuplicates), whereas ArtificialSAMUtils is heavily used, so I would say stick with the latter.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/211:40,error,error-prone,40,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/211,1,['error'],['error-prone']
Availability,"Cromwell still struggles with call caching and metadata bloat in our gCNV workflows. Specific improvements to reduce overhead will modify scattered tasks:. 1. `GermlineCNVCallerCohort(Case)Mode` - Replace input `Array[File] read_count_files` with a list of files, i.e. `File read_count_file_paths`. This should be generated using `WritePathList`, rather than using `write_lines()` which does not function in WDL workflow blocks on some Cromwell servers. Replace output `Array[File] gcnv_call_tars` with a single tarball `File gcnv_call_tar` containing all of the calls. It appears there are a number of redundant outputs - kernel version, denoising configs, output file lists, etc. that were added with the [joint calling pipeline](https://github.com/broadinstitute/gatk/commit/31df35bb9204b5551cc1a3ee7468e2b0e577215d). We should rework that to extract/generate those in joint calling workflow when needed and eliminate these outputs.; 2. Add a transpose task following `GermlineCNVCallerCohort(Case)Mode` that consumes the interval-sharded `Array[File] gcnv_call_tar` output, and generates a sample-sharded `Array[File] gcnv_calls_by_sample` output of tarballs.; 2. Add a model bundling task following `GermlineCNVCallerCohort(Case)Mode` that consumes the interval-sharded `Array[File] gcnv_model_tar` output, extracts the files, and tarballs all of them together to produce a single tarball output. Make this the output of the cohort workflow and input to the case mode workflows, rather than an array of model tars (retain the current `Array[File]` input as an optional type `Array[File]?` that will be used as the default if provided to case mode in order to support users still working with the old paradigm).; 3. `PostprocessGermlineCNVCalls` - replace input `Array[File] gcnv_calls_tars` with `File gcnv_sample_calls`, the sample-sharded output from the aforementioned transpose task. Delete inputs `calling_configs`, `denoising_configs`, `gcnvkernel_version`, `sharded_interval_lists`, as the",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7721:603,redundant,redundant,603,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7721,1,['redundant'],['redundant']
Availability,"Currently GATK4 walker mode won't recognize altivec-based libVectorLoglessPairHMM.so only AVX based library. On POWER it will Falling back to the MUCH slower LOGLESS_CACHING implementation. To avoid performance degradation on POWER for Haplotyecaller, please include support for Altivec based pairhmm library libVectorLoglessPairHMM.so; Two possible ways to do it:; 1. integrate support by using ""grep -i altivec /proc/cpuinfo"" to identify availability of Altivec support and then integrate the library; 2. We can setup Java path or other options that will look for any libVectorLoglessPairHMM.so available and test compatibility. We would do all necessary works to get this done, but would appreciate your direction on which way to peruse. Thanks!",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3180:440,avail,availability,440,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3180,2,['avail'],"['availability', 'available']"
Availability,"Currently `Funcotator` annotates IGR ""other transcripts"" entries as ""IGR_ANNOTATION"". This must be fixed to be correct. The correct format is:. <UPSTREAM GENE NAME>(<# bases away> upstream) : <DOWNSTREAM GENE NAME>(<# bases away> downstream)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3849:193,DOWN,DOWNSTREAM,193,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3849,2,"['DOWN', 'down']","['DOWNSTREAM', 'downstream']"
Availability,"Currently `ReferenceConfidenceVariantContextMerger.merge()` does not pass in the remapped alleles to `GATKVariantContextUtils.makeGenotypeCall()` for the `originalGT` argument, which seems problematic and could cause the code to incorrectly fall back on reference calls in some cases. The GVS team has found it necessary to use the remapped alleles when genotyping in order to get correct genotypes out of the merge -- we should make this behavior the default. . Currently, making it the default causes failures in the tests for the `--include-non-variant-sites` argument in `GenotypeGVCFs` (see https://github.com/broadinstitute/gatk/pull/8288#issuecomment-1509295869). This appears related to the current implementation incorrectly calculating the reference allele when we are at some non-zero offset from the start of a GVCF reference block.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8317:503,failure,failures,503,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8317,1,['failure'],['failures']
Availability,"Currently `SamAssertionUtils.assertSamsEqual` fails with `""SAM file output differs from expected output""`. It uses `SamComparison`, which prints a lot of helpful information about how the files differ to stdout. This output is often hidden when running it in a test suite though. It's also a bit strange to print error messages to stdout. `SamComparison` should capture this information and provide an accessor to retrieve it instead of dumping it to stdout.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/375:313,error,error,313,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/375,1,['error'],['error']
Availability,"Currently `VariantFiltration` does not have the ability to mask a VCF file with multiple bed files. The files must be run individually in sequence to aggregate all the annotations in the `FILTER` column. . To fix this, the `--mask` and `--mask-name` options should be changed to `List` inputs with a 1:1 mapping implied between them.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8161:59,mask,mask,59,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8161,3,['mask'],"['mask', 'mask-name']"
Availability,"Currently based off Kevin's branch, I plan to merge this to ah_var_store after Kevin's branch merges. We should then merge / pick this back to the EchoCallset branch and add an entry for EchoCallset in .dockstore.yml",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8739:147,Echo,EchoCallset,147,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8739,2,['Echo'],['EchoCallset']
Availability,"Currently if a site has too many alleles GenomicsDB doesn't output PLs for diploid samples at that site. At sites where all samples are diploid this site is successfully skipped. If the site has a mix of haploid and diploid calls (for example chrX with the latest versions of dragen on WGS data), then the site wasn't being skipped correctly and an error would be thrown by GenotypeGVCFs at the annotation step. Now the site will be skipped if any of the called sites don't have PLs excluding no calls and hom ref genotypes. If the site is all no-calls or hom-ref then it retains the current behavior by only skipping sites where all the genotypes are missing PLs. I'm not sure if this happens frequently in the wild, but it is a common edge case in our tests.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8862:349,error,error,349,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8862,1,['error'],['error']
Availability,Currently if the number of headers do not match the number of rows it manifests as:`AssertionError: Some contigs do not have ploidy priors`. It would be good if the error message could more explicitly state how the ploidy prior file is malformed. In the event where it's actually the case it might also be worth explicitly stating which contig was found not to have a ploidy prior.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4486:165,error,error,165,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4486,1,['error'],['error']
Availability,Currently if you submit a bam with no reads to a spark tool AND it's header indicates that it is queryname sorted it will throw an unhelpful error message in the repartitioning code. This should be fixed somehow.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4869:141,error,error,141,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4869,1,['error'],['error']
Availability,"Currently it defaults to 1 core. It seems like it scales well to 4 cores and correctly throttles back if there are fewer cores, so we should make it use the available resources if possible.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2717:157,avail,available,157,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2717,1,['avail'],['available']
Availability,"Currently it just tells you that an R script exited with value 1. This is totally worthless, it should tell you what errors it actually failed with.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/223:117,error,errors,117,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/223,1,['error'],['errors']
Availability,Currently the `SimpleKeyXsvFuncotationFactory` needs to be improved to throw better error messages when the encoding of a file is inconsistent. This is really an issue involving how `Files.lines()` deals with the encodings. When using the `PathLineIterator` the encoding issue is not found until calling `it.next()` and getting a line with inconsistent encodings. This issue is then manifested as a `java.nio.charset.MalformedInputException`. This page has some information on a fix:. https://stackoverflow.com/questions/26064689/files-lines-to-skip-broken-lines-in-java8,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4006:84,error,error,84,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4006,1,['error'],['error']
Availability,Currently the behavior is not guaranteed in the situation where the user doesn't specify either spark.executor.cores or spark.executor.memory and is running with autoscaling enabled. Additionally the program will return a different value (the maximum memory available for caching) if the user is running in local mode.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1947:258,avail,available,258,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1947,1,['avail'],['available']
Availability,Currently the error messages are very vague. They should be as specific as possible.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/169:14,error,error,14,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/169,1,['error'],['error']
Availability,Currently the html doc we build looks pretty ugly in the browser. We don't have the appropriate style sheets available locally. We should check those into the repo so that it can build a nice looking copy of the documentation.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2769:109,avail,available,109,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2769,1,['avail'],['available']
Availability,"Currently the script fails when configured to run tests, since it doesn't have access to the large files in the docker image. These need to be downloaded and mounted for the tests to pass, as we do in the docker tests on travis.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3191:143,down,downloaded,143,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3191,1,['down'],['downloaded']
Availability,"Currently we check only that sequence dictionaries have a common subset of equal contigs. When comparing against the reference sequence dictionary, however, we need to check that the ref dictionary contains all contigs from the reads/variants dictionaries. If this is not the case, we can see null pointer exceptions with cram files and other nasty errors.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/802:349,error,errors,349,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/802,1,['error'],['errors']
Availability,"Currently we dump all htsjdk properties in `Defaults` to the logger, even though only a few are applicable to GATK:. ```; 16:30:25.790 INFO GenomicsDBImport - Defaults.BUFFER_SIZE : 131072; 16:30:25.790 INFO GenomicsDBImport - Defaults.COMPRESSION_LEVEL : 1; 16:30:25.790 INFO GenomicsDBImport - Defaults.CREATE_INDEX : false; 16:30:25.791 INFO GenomicsDBImport - Defaults.CREATE_MD5 : false; 16:30:25.791 INFO GenomicsDBImport - Defaults.CUSTOM_READER_FACTORY : ; 16:30:25.791 INFO GenomicsDBImport - Defaults.EBI_REFERENCE_SERVICE_URL_MASK : http://www.ebi.ac.uk/ena/cram/md5/%s; 16:30:25.791 INFO GenomicsDBImport - Defaults.NON_ZERO_BUFFER_SIZE : 131072; 16:30:25.791 INFO GenomicsDBImport - Defaults.REFERENCE_FASTA : null; 16:30:25.791 INFO GenomicsDBImport - Defaults.SAM_FLAG_FIELD_FORMAT : DECIMAL; 16:30:25.791 INFO GenomicsDBImport - Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 16:30:25.792 INFO GenomicsDBImport - Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : false; 16:30:25.792 INFO GenomicsDBImport - Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 16:30:25.792 INFO GenomicsDBImport - Defaults.USE_CRAM_REF_DOWNLOAD : false; ```. We should subset these down to only the relevant ones.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2691:1172,down,down,1172,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2691,1,['down'],['down']
Availability,"Currently we have Spark performance tests on gatk-jenkins which fail intermittently due to normal variance in runtimes. As a result, we don't always closely look into failures. We need Spark correctness tests in jenkins that are separate from the performance tests and that fail only when there's an actual regression -- and when these fail, it should always trigger a timely investigation by an engineer into what's gone wrong.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2288:167,failure,failures,167,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2288,1,['failure'],['failures']
Availability,"Currently, FilterByOrientation requires replacing a required input's contents with a sed command: . ```; sed -r ""s/picard\.analysis\.artifacts\.SequencingArtifactMetrics\\\$PreAdapterDetailMetrics/org\.broadinstitute\.; hellbender\.tools\.picard\.analysis\.artifacts\.SequencingArtifactMetrics\$PreAdapterDetailMetrics/g"" \; ""metrics.pre_adapter_detail_metrics"" > ""gatk.pre_adapter_detail_metrics""; ```. The required input is the detailed pre-adapter summary metrics from Picard's CollectSequencingArtifactMetrics. The sed command replaces; ```; ## METRICS CLASS	picard.analysis.artifacts.SequencingArtifactMetrics$PreAdapterDetailMetrics; ```; with ; ```; ## METRICS CLASS	org.broadinstitute.hellbender.tools.picard.analysis.artifacts.SequencingArtifactMetrics$PreAdapterDetailMetrics; ```. If this class is not replaced, then the tool errors with: ; ```; htsjdk.samtools.SAMException: Could not locate class with name gatk.analysis.artifacts.SequencingArtifactMetrics$PreAdapterDetailMetrics; 	at htsjdk.samtools.metrics.MetricsFile.read(MetricsFile.java:356); 	at org.broadinstitute.hellbender.tools.exome.FilterByOrientationBias.onTraversalStart(FilterByOrientationBias.java:102); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:777); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:115); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:170); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:189); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:122); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:143); 	at org.broadinstitute.hellbender.Main.main(Main.java:221); Caused by: java.lang.ClassNotFoundException: gatk.analysis.artifacts.SequencingArtifactMetrics$PreAdapterDetailMetrics; 	at java.net.URLClassLoader.findClass(URLClassLoader.java:381); 	at java.lang.ClassLoader.loadCla",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3030:837,error,errors,837,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3030,1,['error'],['errors']
Availability,"Currently, `IntervalArgumentCollection` still uses `GenomeLocs` internally during parsing, despite the rest of the engine using `SimpleIntervals`. This forces us to provide a sequence dictionary when interval arguments are present even if the only input is an interval list (eg., an `IntervalWalker` that purely processes/transforms intervals). We should provide a mode in `IntervalArgumentCollection` in which intervals can be parsed into `SimpleIntervals` without a sequence dictionary. This will require us to fill in a special value such as `Integer.MAX_VALUE` for the stop position of intervals that don't contain a stop position (eg., ""chr1"" or ""chr1:1+""), since we won't know the true contig lengths, but our future query interfaces should all be robust to requests for locations outside of contig boundaries (and not blow up given such requests). This will also require adding some way of determining whether or not an interval has been validated against a sequence dictionary -- perhaps `ValidatedInterval` could be a subclass of `SimpleInterval`.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/298:754,robust,robust,754,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/298,1,['robust'],['robust']
Availability,"Currently, if the GATK doesn't have permission to check whether a GCS bucket is Requester Pays (which is a separate permission from access to the bucket itself!), we get a cryptic error message along the lines of:. ```; User does not have storage.buckets.get access to bucket_name; ```. This is the same error the gsutil client gives in the same situation:. ```; $ gsutil requesterpays get gs://gatk-best-practices; AccessDeniedException: 403 droazen@broadinstitute.org does not have storage.buckets.get access to gatk-best-practices.; ```. Ideally we should detect this situation upfront in the GATK and emit a more informative error message.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6349:180,error,error,180,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6349,3,['error'],['error']
Availability,"Currently, only a public interval list is allowed--this changes that and copies down the SA before the interval list is used. used here:; https://app.terra.bio/#workspaces/allofus-drc-wgs-dev/AoU_DRC_WGS_12-6-21_beta_ingest/job_history/f5ca0b70-1ae2-4e86-b4fc-3d7d19674347 . with interval list: 	gs://prod-drc-broad/beta-release-99k-v3/0000000000-scattered.interval_list",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7743:80,down,down,80,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7743,1,['down'],['down']
Availability,"Currently, the engine-level shutdown routine `onShutdown()` is always invoked, even when an exception occurs during traversal, but the tool-level shutdown routine `onTraversalDone()` is not wrapped within a `finally` block and so not invoked when an exception occurs. Do we want it to always be invoked? Some tools might be designed on the assumption that `onTraversalDone()` will only be reached if the traversal completed start to finish without error (and so it's appropriate to generate certain final output, etc.), while other tools might prefer it to always be invoked so that resources can be closed. Thoughts?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/358:448,error,error,448,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/358,1,['error'],['error']
Availability,"Currently, we recommend the use of gatk-launch, but we're inconsistent about how we display the app name in output, including in command lines embedded in output files. We alternatively use 'gatk', gatk-launch', or '':. > Using GATK wrapper script /Users/cnorman/projects/gatk/build/install/gatk/bin/gatk; > Running:; > /Users/cnorman/projects/gatk/build/install/gatk/bin/gatk CalculateTargetCoverage -I ...; > [July 19, 2017 3:31:55 PM EDT] CalculateTargetCoverage --input ... Note there is no app name listed in the last line above, due to [this](https://github.com/broadinstitute/gatk/blob/33d316f0e8e35572bb60c83a144297c8557bb37d/src/main/java/org/broadinstitute/hellbender/Main.java#L103). This also affects embedded command line output. Also, downstream projects need some way to customize this.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3312:749,down,downstream,749,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3312,1,['down'],['downstream']
Availability,"D; [INFO] GATK Aggregator Protected .......................... SKIPPED; [INFO] GATK Tools Private ................................. SKIPPED; [INFO] GATK Package Internal .............................. SKIPPED; [INFO] NA12878 KB Utilities ............................... SKIPPED; [INFO] GATK Queue Private ................................. SKIPPED; [INFO] GATK Queue Extensions Internal ..................... SKIPPED; [INFO] GATK Queue Package Internal ........................ SKIPPED; [INFO] GATK Aggregator Private ............................ SKIPPED; [INFO] ------------------------------------------------------------------------; [INFO] BUILD FAILURE; [INFO] ------------------------------------------------------------------------; [INFO] Total time: 01:23 min; [INFO] Finished at: 2018-04-20T20:52:19+02:00; [INFO] Final Memory: 67M/922M; [INFO] ------------------------------------------------------------------------; [ERROR] Failed to execute goal on project external-example: Could not resolve dependencies for project org.mycompany.app:external-example:jar:1.0-SNAPSHOT: The following artifacts could not be resolved: org.broadinstitute.gatk:gatk-tools-public:jar:3.8-SNAPSHOT, org.broadinstitute.gatk:gatk-utils:jar:tests:3.8-SNAPSHOT, org.broadinstitute.gatk:gatk-engine:jar:tests:3.8-SNAPSHOT: Could not find artifact org.broadinstitute.gatk:gatk-tools-public:jar:3.8-SNAPSHOT in gatk.public.repo.local (file:../../public/repo) -> [Help 1]; [ERROR] ; [ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.; [ERROR] Re-run Maven using the -X switch to enable full debug logging.; [ERROR] ; [ERROR] For more information about the errors and possible solutions, please read the following articles:; [ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/DependencyResolutionException; [ERROR] ; [ERROR] After correcting the problems, you can resume the build with the command; [ERROR] mvn <goals> -rf :external-example; ```. it could be the cause.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4686:3077,ERROR,ERROR,3077,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4686,11,"['ERROR', 'error']","['ERROR', 'errors']"
Availability,DBImport - Vid Map JSON file will be written to /lustre/scratch118/malaria/team112/personal/vr6/pf8-update/work/8e/c9ed494e9cd5d45835890fff4fa34c/Pf3D7_08_v3_33.bed.gdb/vidmap.json; 01:25:02.077 INFO GenomicsDBImport - Callset Map JSON file will be written to /lustre/scratch118/malaria/team112/personal/vr6/pf8-update/work/8e/c9ed494e9cd5d45835890fff4fa34c/Pf3D7_08_v3_33.bed.gdb/callset.json; 01:25:02.077 INFO GenomicsDBImport - Complete VCF Header will be written to /lustre/scratch118/malaria/team112/personal/vr6/pf8-update/work/8e/c9ed494e9cd5d45835890fff4fa34c/Pf3D7_08_v3_33.bed.gdb/vcfheader.vcf; 01:25:02.077 INFO GenomicsDBImport - Importing to workspace - /lustre/scratch118/malaria/team112/personal/vr6/pf8-update/work/8e/c9ed494e9cd5d45835890fff4fa34c/Pf3D7_08_v3_33.bed.gdb; 01:25:02.078 INFO ProgressMeter - Starting traversal; 01:25:02.078 INFO ProgressMeter - Current Locus Elapsed Minutes Batches Processed Batches/Minute; [TileDB::FileSystem] Error: (write_to_file) Cannot write to file; File writing error; path=/lustre/scratch118/malaria/team112/personal/vr6/pf8-update/work/8e/c9ed494e9cd5d45835890fff4fa34c/Pf3D7_08_v3_33.bed.gdb/vidmap.json; errno=5(Input/output error); [TileDB::FileSystem] Error: (write_to_file) Cannot write to file; File writing error; path=/lustre/scratch118/malaria/team112/personal/vr6/pf8-update/work/8e/c9ed494e9cd5d45835890fff4fa34c/Pf3D7_08_v3_33.bed.gdb/vidmap.json; errno=5(Input/output error); 01:25:43.661 INFO GenomicsDBImport - Starting batch input file preload; 01:26:19.244 INFO GenomicsDBImport - Finished batch preload; 01:26:19.244 INFO GenomicsDBImport - Importing batch 1 with 2 samples; 01:30:20.226 INFO ProgressMeter - unmapped 5.3 1 0.2; 01:30:20.226 INFO GenomicsDBImport - Done importing batch 1/1; 01:30:20.227 INFO ProgressMeter - unmapped 5.3 1 0.2; 01:30:20.227 INFO ProgressMeter - Traversal complete. Processed 1 total batches in 5.3 minutes.; 01:30:20.227 INFO GenomicsDBImport - Import of all batches to GenomicsDB compl,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7598:4102,Error,Error,4102,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7598,2,"['Error', 'error']","['Error', 'error']"
Availability,"DBImporter.<init>(GenomicsDBImporter.java:222); at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImport.traverse(GenomicsDBImport.java:743); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1048); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:163); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:206); at org.broadinstitute.hellbender.Main.main(Main.java:292); ```. ### Second Example; This user is running multiple chromosomes at a time in parallel; Please see this link for more info: https://gatk.broadinstitute.org/hc/en-us/community/posts/360072732791-Import-GVCFs-using-GenomicsDBImport-one-chromosome-at-a-time-and-parallel-the-jobs-encounter-a-Duplicate-Sample-Name-Error?page=1#community_comment_360012681711. `time ${gatk} --java-options ""-Xmx8g -Xms2g"" GenomicsDBImport --tmp-dir /paedwy/disk1/yangyxt/test_tmp --genomicsdb-update-workspace-path ${probe_dir}/genomicdbimport_chr${1} -R ${ref_gen}/ucsc.hg19.fasta --batch-size 0 --sample-name-map ${gvcf}/batch_cohort.sample_map --reader-threads 5 --intervals chr${1}`. ```; 01:07:01.704 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/yangyxt/software/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Aug 29, 2020 1:07:01 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 01:07:02.001 INFO GenomicsDBImport - ------------------------------------------------------------; 01:07:02.002 INFO GenomicsDBImport - The Genome Analysis Toolkit (GATK) v4.1.8.1; 01:07:02.002 INFO G",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6793:9888,Error,Error,9888,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6793,1,['Error'],['Error']
Availability,"DD$$anonfun$count$1.apply(RDD.scala:1157); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1944); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1944); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:99); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). 18/12/21 13:14:09 ERROR scheduler.TaskSetManager: Task 16 in stage 0.0 failed 4 times; aborting job; 13:14:09.675 INFO CountReadsSpark - Shutting down engine; [December 21, 2018 1:14:09 PM EST] org.broadinstitute.hellbender.tools.spark.pipelines.CountReadsSpark done. Elapsed time: 0.97 minutes.; Runtime.totalMemory()=937426944; org.apache.spark.SparkException: Job aborted due to stage failure: Task 16 in stage 0.0 failed 4 times, most recent failure: Lost task 16.3 in stage 0.0 (TID 11, scc-q16.scc.bu.edu, executor 2): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 1, start 146479558, span 42247, expected MD5 8e364a33b9a9350f9ebfac1db38af647; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1760); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1157); at org.apache.spark.rdd.RDD$$anon",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547:12736,failure,failure,12736,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547,1,['failure'],['failure']
Availability,"DF5/src/H5FDint.c line 204 in H5FD_read(): ; driver read request failed; major: Virtual File Layer; minor: Read failed; #011: /mnt/scr1/abyrne/HDFJava-platypus-2.11/native/HDF5-prefix/src/HDF5/src/H5FDsec2.c line 725 in H5FD_sec2_re; ad(): file read failed: time = Wed Apr 14 11:52:33 2021; , filename = '/SCRATCH-BIRD/users/lindenbaum-p/work/NEXTFLOW/20210411.GRCh37.gatkcnv.brs/work/92/579e5a48aa9e52cd0; e1df603266809/B00HOTD.counts.hdf5', file descriptor = 250, errno = 121, error message = 'Remote I/O error', buf = ; 0x2b6ebddf38e8, total read size = 384, bytes this sub-read = 384, bytes actually read = 18446744073709551615, offs; et = 712120; major: Low-level I/O; minor: Read failed; HDF5-DIAG: Error detected in HDF5 (1.8.14) thread 0:; #000: /mnt/scr1/abyrne/HDFJava-platypus-2.11/native/HDF5-prefix/src/HDF5/src/H5D.c line 826 in H5Dvlen_reclaim(); : invalid dataspace; major: Invalid arguments to routine; minor: Inappropriate type; 11:52:33.796 INFO GermlineCNVCaller - Shutting down engine; [April 14, 2021 11:52:33 AM CEST] org.broadinstitute.hellbender.tools.copynumber.GermlineCNVCaller done. Elapsed t; ime: 0.90 minutes.; Runtime.totalMemory()=2374500352; Exception in thread ""main"" java.lang.InternalError: H5DreadVL_str: failed to read variable length strings; 	at ncsa.hdf.hdf5lib.H5.H5DreadVL(Native Method); 	at org.broadinstitute.hdf5.HDF5File.lambda$readStringArray$0(HDF5File.java:161); 	at org.broadinstitute.hdf5.HDF5File.readDataset(HDF5File.java:349); 	at org.broadinstitute.hdf5.HDF5File.readStringArray(HDF5File.java:150); 	at org.broadinstitute.hellbender.tools.copynumber.utils.HDF5Utils.readIntervals(HDF5Utils.java:62); 	at org.broadinstitute.hellbender.tools.copynumber.formats.collections.HDF5SimpleCountCollection.lambda$new; $2(HDF5SimpleCountCollection.java:76); 	at htsjdk.samtools.util.Lazy.get(Lazy.java:25); 	at org.broadinstitute.hellbender.tools.copynumber.formats.collections.HDF5SimpleCountCollection.getInterva; ls(HDF5SimpleCountCollection.java:85",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7202:3540,down,down,3540,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7202,1,['down'],['down']
Availability,"DP=1399;ECNT=1;MBQ=36,36;MFRL=209,211;MMQ=60,60;MPOS=34;POPAF=7.3;TLOD=42.57	GT:AD:AF:DP:F1R2:F2R1:SAAF:SAPP	0/1:1327,27:0.019:1354:672,12:655,15:0.02,0.02,0.02:0.0007239,0.005058,0.994; 11	108175462	.	G	A	.	.	DP=972;ECNT=1;MBQ=36,36;MFRL=209,206;MMQ=60,60;MPOS=37;POPAF=7.3;TLOD=15.55	GT:AD:AF:DP:F1R2:F2R1:SAAF:SAPP	0/1:898,12:0.013:910:446,6:452,6:0.01,0.01,0.013:0.002966,0.0009292,0.996; 12	12037318	.	C	G	.	.	DP=975;ECNT=1;MBQ=36,36;MFRL=205,218;MMQ=60,60;MPOS=48;POPAF=7.3;TLOD=15.41	GT:AD:AF:DP:F1R2:F2R1:SAAF:SAPP	0/1:893,12:0.013:905:438,4:455,8:0.01,0.01,0.013:0.004146,0.0007942,0.995; 15	66679819	.	G	C	.	.	DP=870;ECNT=1;MBQ=36,36;MFRL=215,211;MMQ=60,60;MPOS=52;POPAF=7.3;TLOD=25.62	GT:AD:AF:DP:F1R2:F2R1:SAAF:SAPP	0/1:797,17:0.022:814:384,11:413,6:0.02,0.02,0.021:0.004622,0.001165,0.994; 18	42532923	.	T	C	.	.	DP=1402;ECNT=1;MBQ=36,36;MFRL=197,222;MMQ=60,60;MPOS=51;POPAF=7.3;TLOD=41.21	GT:AD:AF:DP:F1R2:F2R1:SAAF:SAPP	0/1:1312,25:0.019:1337:681,13:631,12:0.02,0.01,0.019:0.0009167,0.002842,0.996; 20	31019360	.	AT	A	.	.	DP=1530;ECNT=1;MBQ=36,36;MFRL=198,199;MMQ=60,60;MPOS=44;POPAF=7.3;RPA=7,6;RU=T;STR;TLOD=30.65	GT:AD:AF:DP:F1R2:F2R1:SAAF:SAPP	0/1:1424,34:0.022:1458:673,20:751,14:0.02,0.02,0.023:0.003063,0.0009654,0.996; ```. #### Steps to reproduce; ```; # Call without --alleles option does not produce the variants.; gatk Mutect2 --reference GRCh37.fa --read-validation-stringency LENIENT -I subset_properheader.bam -L enrichment.bed --interval-set-rule INTERSECTION -O unfiltered_noalleles.vcf.gz; # Call with --alleles option produces the variants with presumably high quality scores; gatk Mutect2 --reference GRCh37.fa --read-validation-stringency LENIENT -I subset_properheader.bam -L enrichment.bed --interval-set-rule INTERSECTION -O unfiltered_alleles.vcf.gz --alleles truth_small_variants_NA12878-NA24385-mix_sorted.vcf.gz; ```; The BAM, BED and output VCF files are available for download [here](https://gatk-validation.s3-eu-west-1.amazonaws.com/mutect2-4.1.9.0.zip).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7015:6353,avail,available,6353,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7015,2,"['avail', 'down']","['available', 'download']"
Availability,Data is sensitive and bug is recapitulated in https://github.com/broadinstitute/dsde-docs/issues/3026. CombineGVCFs gives the following error message:; ```; java.lang.IllegalArgumentException: Invalid interval. Contig:HLA-DRB1*15:03:01:02 start:11569 end:11005; 	at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:687); 	at org.broadinstitute.hellbender.utils.SimpleInterval.validatePositions(SimpleInterval.java:61); 	at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:37); 	at org.broadinstitute.hellbender.tools.walkers.CombineGVCFs.onTraversalSuccess(CombineGVCFs.java:415); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:895); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:135); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:180); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:199); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:159); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:202); 	at org.broadinstitute.hellbender.Main.main(Main.java:288); ```; Here are the dictionary lines for two consecutive HLA-DRB1 contigs:; ```; @SQ SN:HLA-DRB1*15:03:01:02 LN:11569 M5:4e0d459b9bd15bff8645de84334e3d25 AS:38 UR:/seq/references/Homo_sapiens_assembly38/v0/Homo_sapiens_assembly38.fasta SP:Homo sapiens; @SQ SN:HLA-DRB1*16:02:01 LN:11005 M5:4a972df76bd3ee2857b87bd5be5ea00a AS:38 UR:/seq/references/Homo_sapiens_assembly38/v0/Homo_sapiens_assembly38.fasta SP:Homo sapiens; ```; Notice the `LN` lengths match up. It appears that our tool is mistaking contig information.; Note that `HLA-DRB1*16:02:01` is the very last contig in GRCh38.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4572:136,error,error,136,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4572,1,['error'],['error']
Availability,"DataSourceUtils - Resolved data source file path: file:///data/nws/WES/LMM_Path_LP_VUS5-variants-6-12-18.sorted_liftover_b38.corrected.vcf -> file:///data/nws/WES/reference/funcotator_dataSources.v1.7.20200521g/lmm_known/hg38/LMM_Path_LP_VUS5-variants-6-12-18.sorted_liftover_b38.corrected.vcf; 06:42:41.652 INFO FeatureManager - Using codec VCFCodec to read file file:///data/nws/WES/reference/funcotator_dataSources.v1.7.20200521g/lmm_known/hg38/LMM_Path_LP_VUS5-variants-6-12-18.sorted_liftover_b38.corrected.vcf; 06:42:41.663 INFO DataSourceUtils - Resolved data source file path: file:///data/nws/WES/gencode.v34.annotation.REORDERED.gtf -> file:///data/nws/WES/reference/funcotator_dataSources.v1.7.20200521g/gencode/hg38/gencode.v34.annotation.REORDERED.gtf; 06:42:41.663 INFO DataSourceUtils - Setting lookahead cache for data source: Gencode : 100000; 06:42:41.665 WARN GencodeGtfCodec - GENCODE GTF Header line 1 has a version number that is above maximum tested version (v 28) (given: 34): ##description: evidence-based annotation of the human genome (GRCh38), version 34 (Ensembl 100) Continuing, but errors may occur.; 06:42:41.665 INFO FeatureManager - Using codec GencodeGtfCodec to read file file:///data/nws/WES/reference/funcotator_dataSources.v1.7.20200521g/gencode/hg38/gencode.v34.annotation.REORDERED.gtf; 06:42:41.666 WARN GencodeGtfCodec - GENCODE GTF Header line 1 has a version number that is above maximum tested version (v 28) (given: 34): ##description: evidence-based annotation of the human genome (GRCh38), version 34 (Ensembl 100) Continuing, but errors may occur.; 06:42:41.691 INFO DataSourceUtils - Resolved data source file path: file:///data/nws/WES/gencode.v34.pc_transcripts.fa -> file:///data/nws/WES/reference/funcotator_dataSources.v1.7.20200521g/gencode/hg38/gencode.v34.pc_transcripts.fa; 06:42:46.805 INFO DataSourceUtils - Resolved data source file path: file:///data/nws/WES/clinvar_20180429_hg38.vcf -> file:///data/nws/WES/reference/funcotator_dataSo",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7090:6683,error,errors,6683,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7090,1,['error'],['errors']
Availability,"Dataflow and spark both wrap thrown exceptions in their own exceptions before transmitting them back to the client. Spark doesn't maintain the cause field for the new exception, which makes it difficult to unwrap and retrieve the original exception type. . The ability to do this is important because we want to present error's differently to the user depending on if they have a known `UserException` or some other type of exception. It also makes our testing much more robust if we can test for specific failure conditions rather than the error prone `RuntimeException`",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/575:320,error,error,320,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/575,4,"['error', 'failure', 'robust']","['error', 'failure', 'robust']"
Availability,"DataflowUtils#getReadsFromLocalBams will return unmapped reads if they have a start position that overlaps an interval, but the Hadoop version will filter them out. This change fixes this inconsistency, and makes the MarkDuplicates dataflow tests use the Spark Dataflow runner if it's specified on the command line (it used to ignore the setting). The change to the MarkDuplicates test also uncovered another problem where some tests failed with ""Mate unmapped flag should not be set for unpaired read"". I fixed this by moving from `com.google.cloud.genomics.utils.ReadUtils.makeRead` and `GoogleGenomicsReadToGATKReadAdapter` (which are lossy, and presumably caused the failures) to `SAMRecordToGATKReadAdapter`.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/880:671,failure,failures,671,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/880,1,['failure'],['failures']
Availability,"Dealing with case when two alignment blocks contain each other in their ref span, indicating duplication.; Instead of outputting CIGARs for the duplicated units like we did for duplication records now in master pipeline, we output alt haplotype sequence from the evidence contigs we assembled, since we did an experiment work with inverted duplications. Some performance evaluation based on the logs. ```; master.vcf. 10:28:46.262 INFO DiscoverVariantsFromContigAlignmentsSAMSpark - Discovered 6324 variants.; 10:28:46.277 INFO DiscoverVariantsFromContigAlignmentsSAMSpark - INV: 237; 10:28:46.277 INFO DiscoverVariantsFromContigAlignmentsSAMSpark - DEL: 3680; 10:28:46.277 INFO DiscoverVariantsFromContigAlignmentsSAMSpark - DUP: 1141; 10:28:46.277 INFO DiscoverVariantsFromContigAlignmentsSAMSpark - INS: 1266; 10:28:46.483 INFO DiscoverVariantsFromContigAlignmentsSAMSpark - Shutting down engine; [October 4, 2017 10:28:46 AM EDT] org.broadinstitute.hellbender.tools.spark.sv.discovery.DiscoverVariantsFromContigAlignmentsSAMSpark done. Elapsed time: 0.53 minutes.; Runtime.totalMemory()=3954180096. ==============. feature.vcf. 13:51:48.490 INFO DiscoverVariantsFromContigAlignmentsSAMSpark - Discovered 6543 variants.; 13:51:48.502 INFO DiscoverVariantsFromContigAlignmentsSAMSpark - INV: 229; 13:51:48.502 INFO DiscoverVariantsFromContigAlignmentsSAMSpark - DEL: 3679; 13:51:48.502 INFO DiscoverVariantsFromContigAlignmentsSAMSpark - DUP: 1365; 13:51:48.502 INFO DiscoverVariantsFromContigAlignmentsSAMSpark - INS: 1270; 13:51:48.770 INFO DiscoverVariantsFromContigAlignmentsSAMSpark - Shutting down engine; [October 5, 2017 1:51:48 PM EDT] org.broadinstitute.hellbender.tools.spark.sv.discovery.DiscoverVariantsFromContigAlignmentsSAMSpark done. Elapsed time: 0.49 minutes.; Runtime.totalMemory()=4026531840; ```. No variants that were dropped are simple variants, and they are expected to be brought back with the correct interpretation once complex sv PR series are fully coded. __Two known i",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3668:887,down,down,887,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3668,1,['down'],['down']
Availability,"Dear *,; I just tested the Docker Container 4.4.0.0 (upgrade from 4.3.0.0) and my pipeline tried to execute BaseRecalibrator and ApplyBQSR. It crashed with a message:; `/usr/bin/env: 'python': No such file or directory`. A simple test with a python script, using ""/usr/bin/python"" in shebang revealed that is truly not available in this path.; A test with the 4.3.0.0 Container worked. I solved the issue by typing ; `ln -s /usr/bin/python3 /usr/bin/python`. Kind regards,; Daniel",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8402:319,avail,available,319,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8402,1,['avail'],['available']
Availability,"Dear GATK developers,. Thank you very much for the tool! I recently encountered an issue while running GATK gCNV, specifically with the step GermlineCNVCaller in cohort mode. I ran the workflow using WDL and the GATK v4.3.0.0 docker image. I am not sure how the error should be interpreted and thus would like to seek your advice on debugging. Since the entire cohort contains 75 samples, I omitted some verbose debug messages in the error log below. ```; Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/paedyl01/disk1/louisshe/work/NGS/wdl/test_workflow_cnv/germline/cromwell-executions/CNVGermlineCohortWorkflow/d53c0a12-6b07-4f74-acb; 21:05:38.275 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/gatk/gatk-package-4.3.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; 21:05:38.297 DEBUG NativeLibraryLoader - Extracting libgkl_compression.so to /paedyl01/disk1/louisshe/tmp/gatk/libgkl_compression8230524266824482022.so; 21:05:38.388 INFO GermlineCNVCaller - ------------------------------------------------------------; 21:05:38.388 INFO GermlineCNVCaller - The Genome Analysis Toolkit (GATK) v4.3.0.0; 21:05:38.388 INFO GermlineCNVCaller - For support and documentation go to https://software.broadinstitute.org/gatk/; 21:05:38.388 INFO GermlineCNVCaller - Executing as louisshe@paedyl02 on Linux v3.10.0-1160.11.1.el7.x86_64 amd64; 21:05:38.389 INFO GermlineCNVCaller - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_242-8u242-b08-0ubuntu3~18.04-b08; 21:05:38.389 INFO GermlineCNVCaller - Start Date/Time: August 13, 2024 9:05:38 PM GMT; 21:05:38.389 INFO GermlineCNVCaller - ------------------------------------------------------------; 21:05:38.389 INFO GermlineCNVCaller - ------------------------------------------------------------; 21:05:38.390 INFO GermlineCNVCaller - HTSJDK Version: 3.0.1; 21:05:38.390 INFO GermlineCNVCaller - Picard Version: 2.27.5; 21:05:38.390 INFO GermlineCNVCaller - Built for Spark Version: 2.4.5; 21:05:38.391 INFO GermlineCNVCaller -",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8952:262,error,error,262,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8952,2,['error'],['error']
Availability,"Dear GATK team,. I am getting errors with haplotyper of GATK 4.1.6.0 when i run gatk-variant pipeline from bcbio on one WGS sample. I am getting same error when i run using same version of GATK installed on my machine. ### Error log. [April 15, 2020 8:14:35 AM GMT] org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCaller done. Elapsed time: 0.80 minutes.; Runtime.totalMemory()=4151902208; java.lang.ArrayIndexOutOfBoundsException: 6; at org.broadinstitute.hellbender.utils.GenotypeUtils.computeDiploidGenotypeCounts(GenotypeUtils.java:70); at org.broadinstitute.hellbender.tools.walkers.annotator.ExcessHet.calculateEH(ExcessHet.java:86); at org.broadinstitute.hellbender.tools.walkers.annotator.ExcessHet.annotate(ExcessHet.java:74); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorEngine.annotateContext(VariantAnnotatorEngine.java:293); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerGenotypingEngine.makeAnnotatedCall(HaplotypeCallerGenotypingEngine.java:365); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerGenotypingEngine.assignGenotypeLikelihoods(HaplotypeCallerGenotypingEngine.java:189); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerEngine.callRegion(HaplotypeCallerEngine.java:608); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCaller.apply(HaplotypeCaller.java:212); at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.processReadShard(AssemblyRegionWalker.java:200); at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.traverse(AssemblyRegionWalker.java:173); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1048); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); at org.broadinstitute.hellbender.cmdline.CommandLi",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6552:30,error,errors,30,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6552,3,"['Error', 'error']","['Error', 'error', 'errors']"
Availability,"Dear Sir or Madame, . I am testing the germline CNV tools (GATK version 4.0.3.0). I know it is still in beta but maybe you can tell me what this error is about. . ```; 13:16:06.332 INFO gcnvkernel.tasks.inference_task_base - (sampling epoch 1): 0%| | 0/100 [00:00<?, ?it/s]; 13:16:08.494 INFO gcnvkernel.tasks.inference_task_base - (sampling epoch 1) relative error: 1.0000 +/- 0.0000: 1%|1 | 1/100 [00:02<03:33, 2.16s/it]; 13:16:10.652 INFO gcnvkernel.tasks.inference_task_base -; Stderr: Traceback (most recent call last):; File ""/tmp/die9s/cohort_determine_ploidy_and_depth.861556744637254264.py"", line 106, in <module>; gcnvkernel.io_ploidy.PloidyModelWriter(ploidy_config, ploidy_workspace,; AttributeError: module 'gcnvkernel.io.io_ploidy' has no attribute 'PloidyModelWriter'. at org.broadinstitute.hellbender.utils.python.PythonExecutorBase.getScriptException(PythonExecutorBase.java:75); at org.broadinstitute.hellbender.utils.runtime.ScriptExecutor.executeCuratedArgs(ScriptExecutor.java:126); at org.broadinstitute.hellbender.utils.python.PythonScriptExecutor.executeArgs(PythonScriptExecutor.java:170); at org.broadinstitute.hellbender.utils.python.PythonScriptExecutor.executeScript(PythonScriptExecutor.java:151); at org.broadinstitute.hellbender.utils.python.PythonScriptExecutor.executeScript(PythonScriptExecutor.java:121); at org.broadinstitute.hellbender.tools.copynumber.DetermineGermlineContigPloidy.executeDeterminePloidyAndDepthPythonScript(DetermineGermlineContigPloidy.java:365); at org.broadinstitute.hellbender.tools.copynumber.DetermineGermlineContigPloidy.doWork(DetermineGermlineContigPloidy.java:263); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:134); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:179); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:198); at org.broadinstitute.hellbender.Main.runCommandLin",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4679:145,error,error,145,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4679,2,['error'],['error']
Availability,"Dear all,. I installed the latest version of gatk as follows;. download the latest version of gatk (https://github.com/broadinstitute/gatk/releases). followed this (https://gatk.broadinstitute.org/hc/en-us/articles/360035889851--How-to-Install-and-use-Conda-for-GATK4) (conda env create -n gatk4 -f gatkcondaenv.yml). installation was completed as below;. Pip subprocess output:; Processing ./gatkPythonPackageArchive.zip; Building wheels for collected packages: gatkpythonpackages; Building wheel for gatkpythonpackages (setup.py): started; Building wheel for gatkpythonpackages (setup.py): finished with status 'done'; Created wheel for gatkpythonpackages: filename=gatkpythonpackages-0.1-py3-none-any.whl size=117482 sha256=5e0f0b2eb6027268eb5814acd8c8b57d265b7aeb371702c736dd4723aa1beee4; Stored in directory: /tmp/pip-ephem-wheel-cache-gyc4oo9g/wheels/86/46/5d/d5d2d327a9cdc718f906fa1d0cd6e18392bd4eea267f327437; Successfully built gatkpythonpackages; Installing collected packages: gatkpythonpackages; Successfully installed gatkpythonpackages-0.1. done. when I started to run this command;. gatk CNNScoreVariants -V 21002.HaplotypeCaller.output.g.vcf.gz -R hg19.fa -O annotated.vcf; it gives an error as below;. java.lang.RuntimeException: A required Python package (""gatktool"") could not be imported into the Python environment. This tool requires that the GATK Python environment is properly established and activated. Please refer to GATK README.md file for instructions on setting up the GATK Python environment.; at org.broadinstitute.hellbender.utils.python.PythonScriptExecutor.checkPythonEnvironmentForPackage(PythonScriptExecutor.java:205); at org.broadinstitute.hellbender.utils.python.StreamingPythonScriptExecutor.start(StreamingPythonScriptExecutor.java:121); at org.broadinstitute.hellbender.tools.walkers.vqsr.CNNScoreVariants.onTraversalStart(CNNScoreVariants.java:302); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1046); at org.broadinstitute.hellbend",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7397:63,down,download,63,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7397,1,['down'],['download']
Availability,"Dear all,. I'm trying to run GenotypeGVCFs using the my_folder database created with GenomicsDBImport which should contain 222 samples. The database was created by adding progressively 10 samples at a time using the command --genomicsdb-update-workspace-path and the relative .sample_map file containing the path to my g.vcf.gz and g.vcf.gz.tbi files. I tried running the GenomicsDBImport followed by GenotypeGVCFs using only four sampled and it worked appropriately by generating a .vcf.gz file along with the index .vcf.gz.tbi file. However, when I run GenotypeGVCFs with 222 samples I get the error: A USER ERROR has occurred: Couldn't create GenomicsDBFeatureReader. The GATK version used is gatk-4.4.0.0 and the command used is the following:. python2.7 /home/administrator/tool/gatk-4.4.0.0/gatk --java-options ""-Xmx4g"" GenotypeGVCFs -R /mnt/nas/Stefano/Cashmere/Reference_Genome/GCF_001704415.1_ARS1_genomic.fna -V gendb://my_database -O /mnt/nas2/Stefano/Cashmere/joint_variant_calling/222_goats.vcf.gz. attaches below also the complete program log. and the content of my callset.json file. Any idea about that?. Thank you very much. Stefano. REQUIRED for all errors and issues:; a) GATK version used: gatk-4.4.0.0; b) Exact command used: python2.7 /home/administrator/tool/gatk-4.4.0.0/gatk --java-options ""-Xmx4g"" GenotypeGVCFs -R /mnt/nas/Stefano/Cashmere/Reference_Genome/GCF_001704415.1_ARS1_genomic.fna -V gendb://my_database -O /mnt/nas2/Stefano/Cashmere/joint_variant_calling/222_goats_fatte_con_GenomicsDBImport.vcf.gz. c) Entire program log:. (base) administrator@srv2-napolioni:/mnt/nas2/Stefano/Cashmere/joint_variant_calling$ python2.7 /home/administrator/tool/gatk-4.4.0.0/gatk --java-options ""-Xmx4g"" GenotypeGVCFs -R /mnt/nas/Stefano/Cashmere/Reference_Genome/GCF_001704415.1_ARS1_genomic.fna -V gendb://my_database -O /mnt/nas2/Stefano/Cashmere/joint_variant_calling/222_goats.vcf.gz; Using GATK jar /home/administrator/tool/gatk-4.4.0.0/gatk-package-4.4.0.0-local.jar; Runnin",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8709:596,error,error,596,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8709,2,"['ERROR', 'error']","['ERROR', 'error']"
Availability,"Dear all:; I have a error flow:; INFO 14:49:42,880 HelpFormatter - ------------------------------------------------------------------------------------; INFO 14:49:42,883 HelpFormatter - The Genome Analysis Toolkit (GATK) v3.8-1-0-gf15c1c3ef, Compiled 2018/02/19 05:43:50; INFO 14:49:42,884 HelpFormatter - Copyright (c) 2010-2016 The Broad Institute; INFO 14:49:42,884 HelpFormatter - For support and documentation go to https://software.broadinstitute.org/gatk; INFO 14:49:42,884 HelpFormatter - [Sat Oct 09 14:49:42 CST 2021] Executing on Linux 2.6.32-696.el6.x86_64 amd64; INFO 14:49:42,884 HelpFormatter - Java HotSpot(TM) 64-Bit Server VM 1.8.0_11-b12; INFO 14:49:42,889 HelpFormatter - Program Args: -T HaplotypeCaller -R /share/Onc_Soft_DB/database/capsmart/hg19/hg19_20210805/hg19.rm_CRLF2_P2RY8.fix_PRSS1_MUC16.fasta -I /share/Onc_RD_Pipeline/OncDir/zhuangll/210927-commercial-tissue-zhangaiyuan/germline/Z19W06700-F1WA/2.Realign/Z19W06700-F1WA.bam -L /share/Onc_Soft_DB/database/capsmart/bed/gene102.snpindel.capsmart.bed -U -o /share/Onc_RD_Pipeline/OncDir/yanhs/test/GATK/Z19W06700-F1WA.HaplotypeCaller.raw.vcf -stand_call_conf 50 -A RMSMappingQuality -A BaseCounts; INFO 14:49:42,892 HelpFormatter - Executing as yanhs3941@compute-0-76 on Linux 2.6.32-696.el6.x86_64 amd64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_11-b12.; INFO 14:49:42,892 HelpFormatter - Date/Time: 2021/10/09 14:49:42; INFO 14:49:42,892 HelpFormatter - ------------------------------------------------------------------------------------; INFO 14:49:42,892 HelpFormatter - ------------------------------------------------------------------------------------; INFO 14:49:42,922 NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/share/Onc_Soft_DB/software/GATK3.8/GenomeAnalysisTK.jar!/com/intel/gkl/native/libgkl_compression.so; INFO 14:49:42,957 GenomeAnalysisEngine - Deflater: IntelDeflater; INFO 14:49:42,958 GenomeAnalysisEngine - Inflater: IntelInflater; INFO 14:49:42,958 GenomeAnalysisEngine -",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7499:20,error,error,20,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7499,1,['error'],['error']
Availability,"Dear developers,; At present, I am using GATK's CombineGVCFs module in AWS platform to merge gvcf of 30 samples respectively according to different chromosomes. This species has 10 chromosomes, so a total of 10 CombineGVCFs tasks are carried out in parallel (10 EC2 virtual machines are opened respectively). The input gvcf file is stored in S3 and mounted to the EC2 VM. In this process, java.io.IOException occurs after some samples are analyzed: The Transport endpoint is not connected, but the merged gvcf file and its index are still produced. I did not find any feedback about GATK relation on the Internet, so I would like to know the reason for the error and why some staining machines reported errors. Some will not report errors, in addition, will the gvcf file generated after the ""Transport endpoint is not connected"" prompt be used? At present, I have tried gatk4.5, 4.4, 4.2 and other versions, and this has happened. Paste the run log as follows:. 06:26:14.775 INFO  NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/gatk/gatk-package-4.5.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; 06:26:14.867 INFO  CombineGVCFs - ------------------------------------------------------------; 06:26:14.869 INFO  CombineGVCFs - The Genome Analysis Toolkit (GATK) v4.5.0.0; 06:26:14.869 INFO  CombineGVCFs - For support and documentation go to https://software.broadinstitute.org/gatk/; 06:26:14.869 INFO  CombineGVCFs - Executing as root@ip-10-1-156-254.cn-northwest-1.compute.internal on Linux v4.14.334-252.552.amzn2.x86_64 amd64; 06:26:14.869 INFO  CombineGVCFs - Java runtime: OpenJDK 64-Bit Server VM v17.0.9+9-Ubuntu-122.04; 06:26:14.869 INFO  CombineGVCFs - Start Date/Time: March 13, 2024 at 6:26:14 AM GMT; 06:26:14.869 INFO  CombineGVCFs - ------------------------------------------------------------; 06:26:14.869 INFO  CombineGVCFs - ------------------------------------------------------------; 06:26:14.870 INFO  CombineGVCFs - HTSJDK Version: 4.1.0; 06:2",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8735:657,error,error,657,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8735,3,['error'],"['error', 'errors']"
Availability,"Dec012014.tsv -> file:///home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s/simple_uniprot/hg19/simple_uniprot_Dec012014.tsv; 15:41:54.747 INFO DataSourceUtils - Resolved data source file path: file:///home/shiyang/softwares/gatk-4.1.8.1/gencode_xrefseq_v75_37.tsv -> file:///home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s/gencode_xrefseq/hg19/gencode_xrefseq_v75_37.tsv; 15:41:54.798 INFO Funcotator - Initializing Funcotator Engine...; 15:41:54.811 INFO Funcotator - Creating a MAF file for output: file:/home/shiyang/Project/BGB900_101/TSO_result/test.maf; 15:41:54.826 INFO ProgressMeter - Starting traversal; 15:41:54.827 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 15:41:54.853 INFO VcfFuncotationFactory - ClinVar_VCF 20180401 cache hits/total: 0/0; 15:41:54.854 INFO VcfFuncotationFactory - dbSNP 9606_b151 cache hits/total: 0/0; 15:41:54.860 INFO Funcotator - Shutting down engine; [August 19, 2020 3:41:54 PM CST] org.broadinstitute.hellbender.tools.funcotator.Funcotator done. Elapsed time: 0.10 minutes.; Runtime.totalMemory()=2588409856; htsjdk.tribble.TribbleException$MalformedFeatureFile: Error parsing LineIteratorImpl(SynchronousLineReader) at the first queried after chr1:2489658, for input source: file:///home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s/gencode/hg19/gencode.v34lift37.annotation.REORDERED.gtf; at htsjdk.tribble.TribbleIndexedFeatureReader$QueryIterator.readNextRecord(TribbleIndexedFeatureReader.java:532); at htsjdk.tribble.TribbleIndexedFeatureReader$QueryIterator.<init>(TribbleIndexedFeatureReader.java:441); at htsjdk.tribble.TribbleIndexedFeatureReader.query(TribbleIndexedFeatureReader.java:297); at org.broadinstitute.hellbender.engine.FeatureDataSource.refillQueryCache(FeatureDataSource.java:567); at org.broadinstitute.hellbender.engine.FeatureDataSource.queryAndPrefetch(FeatureDataSource.java:536); at",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6758:20315,down,down,20315,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6758,1,['down'],['down']
Availability,Default Java version mismatch error message,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/489:30,error,error,30,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/489,1,['error'],['error']
Availability,"Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 12:55:36.414 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 12:55:36.415 INFO HaplotypeCaller - Deflater: IntelDeflater; 12:55:36.415 INFO HaplotypeCaller - Inflater: IntelInflater; 12:55:36.415 INFO HaplotypeCaller - GCS max retries/reopens: 20; 12:55:36.415 INFO HaplotypeCaller - Requester pays: disabled; 12:55:36.415 INFO HaplotypeCaller - Initializing engine; 12:55:36.508 INFO IntervalArgumentCollection - Processing 1 bp from intervals; 12:55:36.511 INFO HaplotypeCaller - Done initializing engine; 12:55:36.515 INFO HaplotypeCallerEngine - Disabling physical phasing, which is supported only for reference-model confidence output; 12:55:36.523 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/home/linux/Downloads/SNP/gatk-4.2.0.0/gatk-package-4.2.0.0-local.jar!/com/intel/gkl/native/libgkl_utils.so; 12:55:36.524 INFO NativeLibraryLoader - Loading libgkl_pairhmm_omp.so from jar:file:/home/linux/Downloads/SNP/gatk-4.2.0.0/gatk-package-4.2.0.0-local.jar!/com/intel/gkl/native/libgkl_pairhmm_omp.so; 12:55:36.552 INFO IntelPairHmm - Flush-to-zero (FTZ) is enabled when running PairHMM; 12:55:36.553 INFO IntelPairHmm - Available threads: 12; 12:55:36.553 INFO IntelPairHmm - Requested threads: 4; 12:55:36.553 INFO PairHMM - Using the OpenMP multi-threaded AVX-accelerated native PairHMM implementation; 12:55:36.569 INFO ProgressMeter - Starting traversal; 12:55:36.569 INFO ProgressMeter - Current Locus Elapsed Minutes Regions Processed Regions/Minute; 12:55:36.587 INFO HaplotypeCaller - 0 read(s) filtered by: MappingQualityReadFilter ; 0 read(s) filtered by: MappingQualityAvailableReadFilter ; 0 read(s) filtered by: MappedReadFilter ; 0 read(s) filtered by: NotSecondaryAlignmentReadFilter ; 0 read(s) filtered by: NotDuplicateReadFilter ; 0 read(s) filtered by: PassesVendorQualityCheckReadFilter ; 0 read(s) filtered by: NonZeroReferenceLengthAlignmentReadFilter ; 0 read(s) filtered",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7229:2355,Down,Downloads,2355,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7229,1,['Down'],['Downloads']
Availability,Delete redundant methods in SVCigarUtils; rewrite and move the rest to CigarUtils,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6481:7,redundant,redundant,7,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6481,1,['redundant'],['redundant']
Availability,"Depends on #2222, which should be done first. The error message should point users to the tool that allows them to add a sequence dictionary to their VCF.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2223:50,error,error,50,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2223,1,['error'],['error']
Availability,Deprecate --allowMissingData and add --errorIfMissingData in VariantsToTable,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3188:39,error,errorIfMissingData,39,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3188,1,['error'],['errorIfMissingData']
Availability,"Deprecate --allowMissingData, add --errorIfMissingData and print NA for null object in VariantsToTable",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3190:36,error,errorIfMissingData,36,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3190,1,['error'],['errorIfMissingData']
Availability,"DepthOfCoverage ; DiagnoseTargets . From @vdauwera ; It would probably make sense to write one really good tool for coverage analysis to replace these two. DoC is great at providing per-locus coverage counts, and the main output table is straightforward and easy for downstream scripts to consume. The summary results table is also ok. But the functionality for aggregating results over intervals and refseq gene lists is super confusing; intervals and genelists interact in an counterintuitive way, and the refseq format requirements are a little vague. In contrast, DT is great at providing per-interval results that give you a go/no-go for callability (+ a culprit metric e.g. MAPQ0, DP etc. in case of a no-go call), but the output is terrible (a pseudo-VCF, which users dont like) and it does not give any per-site counts. There are related tools that users find somewhat useful like CallableLoci, CompareCallableLoci, QualifyMissingIntervals, FindCoveredIntervals, CoveredByNSamplesSites etc. which have overlapping functionality with the coverage tools, and whose functionalities could perhaps be folded into a pan-coverage tool.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/19:267,down,downstream,267,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/19,1,['down'],['downstream']
Availability,"Description:. The proportion of samples that have missing data (and hence no genotype) for a given site. Influenced by:. Common structural variation, repetitive region, extreme GC content (hard to sequence), capture bias or general sample preparation failures. Remark:. This QC highlights issues with the region if many samples have missing data there. It is important to flag these sites. The GVCFs contain this information in the genotype fields. A sample with a no call (./.) or a sample with very low GQ is a sample whose data is missing. All other samples will have a genotype. Alternatively we could use a per-site PGEN metric defined as ( 1 - PMISS ). Typical threshold: The site is filtered out if PMISS is higher than (50\%).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/539:251,failure,failures,251,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/539,1,['failure'],['failures']
Availability,"Despite much development work in the past year to iron the bugs out of htsjdk's cram implementation, there is still a need for much better, more robust tests, as we keep running into new issues. In particular, we need roundtrip bam -> cram -> bam tests on non-trivially-sized inputs.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1661:145,robust,robust,145,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1661,1,['robust'],['robust']
Availability,Detect and handle Python OOM errors,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5820:29,error,errors,29,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5820,1,['error'],['errors']
Availability,Determine whether spark.local.dir is automatically set to use the SSD on Google dataproc when one is available,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2426:101,avail,available,101,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2426,1,['avail'],['available']
Availability,Disable CNNVariantPipelineTest.testTrainingReadModel until failures are resolved.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6331:59,failure,failures,59,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6331,1,['failure'],['failures']
Availability,"Discovered in v4.0.1.1, recapitulates in v4.0.3.0. ModelSegments `--number-of-smoothing-iterations-per-fit` option default is 0 and accepts any integer I give it. ![screenshot 2018-04-19 09 54 13](https://user-images.githubusercontent.com/11543866/38995751-9c85f3d2-43b7-11e8-84be-4793da9c123f.png). However, the number of smoothing iterations changes only when the parameter is set to one. It does not change for 2, 5, 25, etc and if given these non-one numbers, behaves as if it is set to zero, without any exception nor error. Seems this option should be a boolian type, where there is either smoothing per fit (1) or not (0), in which case it should be renamed to represent its type. Let me know if this is just a matter of clarifying in the documentation that the parameter takes only 0 or 1 argument.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4683:523,error,error,523,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4683,1,['error'],['error']
Availability,"Discussed in office hours. Seems to be a bug with --force-output-intervals in GenotypeGVCFs when using GenomicsDB. ----------. This request was created from a contribution made by Zane Swaydan on June 30, 2022 11:13 UTC. Link: [https://gatk.broadinstitute.org/hc/en-us/community/posts/6972994559643-java-lang-IllegalStateException-in-GenotypeGVCFs-after-GenomicsDBImport-GATK-4-2-6-1](https://gatk.broadinstitute.org/hc/en-us/community/posts/6972994559643-java-lang-IllegalStateException-in-GenotypeGVCFs-after-GenomicsDBImport-GATK-4-2-6-1). \--. I'm using the GenotypeGVCFs function based on GenomicsDBImport database. I've divided the reference into 50 intervals. Some intervals seems ok, but some reports error as following. I used a VCF file in ""--force-output-intervals"" for down stream analysis. I've never seen this error without ""--force-output-intervals"". I've searched for the error message and changed my GATK version to 4.2.6.1 since similar error has been solved as a bug in recent update, but it still not works on my dataset... REQUIRED for all errors and issues: ; ; a) GATK version used:. GenomicsDBImport: GATK 4.2.4.0. GenotypeGVCFs: GATK 4.2.6.1. b) Exact command used:. java -Dsamjdk.use\_async\_io\_read\_samtools=false -Dsamjdk.use\_async\_io\_write\_samtools=true -Dsamjdk.use\_async\_io\_write\_tribble=false -Dsamjdk.compression\_level=2 -Xms4G -Xmx16G -XX:+UseParallelGC -XX:ParallelGCThreads=2 -jar MySoftwares/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar GenotypeGVCFs -R PigeonBatch5/000\_DataLinks/000\_RefSeq/Cliv2.1\_genomic.fasta --intervals 006\_IntervalsSplit\_DBImport\_VCFref/interval\_9.list --force-output-intervals PigeonBatch4/008\_RawVcfGz/MergeVcf/pigeonBatch1234\_filtered.vcf.gz -V gendb://007\_Database\_DBImport\_VCFref/database\_interval\_9 -O 008\_RawVcfGz\_DBImport\_VCFref/001\_DividedIntervals/interval\_9.vcf.gz --tmp-dir TMPDIR --allow-old-rms-mapping-quality-annotation-data --only-output-calls-starting-in-intervals --verbosity ERROR.   ; ; c) ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7966:709,error,error,709,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7966,5,"['down', 'error']","['down', 'error']"
Availability,Does this need to be merged into the EchoCallset branch eventually instead?. [Full integration run with the VDS Creation WDL instead of creating a VDS locally in a VM (yes yes also in a WDL but not scaleable)](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/be8cbcbf-1a92-4ec9-97cf-6530fe44ea2c). [VDS Creation run with VQSR Classic](https://job-manager.dsde-prod.broadinstitute.org/jobs/ec917eaf-b1c4-49d5-a51b-b82ddecf47ae). [VDS Creation run with VETS / vqsr LITE](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Quickstart%20v3%20cremer/job_history/112d710d-650e-4ac8-9b54-dc05e194c681),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8554:37,Echo,EchoCallset,37,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8554,1,['Echo'],['EchoCallset']
Availability,Don't redundantly delete temporary directories in RSCriptExecutor.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5894:6,redundant,redundantly,6,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5894,1,['redundant'],['redundantly']
Availability,DoubleFunctionCache - cache miss 0 > -1 expanding to 10; 11:35:45.413 DEBUG Mutect2Engine - Active Region chrM:1154-1397; 11:35:45.413 DEBUG Mutect2Engine - Extended Act Region chrM:1054-1497; 11:35:45.413 DEBUG Mutect2Engine - Ref haplotype coords chrM:1054-1497; 11:35:45.413 DEBUG Mutect2Engine - Haplotype count 1; 11:35:45.413 DEBUG Mutect2Engine - Kmer sizes count 0; 11:35:45.414 DEBUG Mutect2Engine - Kmer sizes values []; 11:35:45.737 DEBUG Mutect2 - Processing assembly region at chrM:1398-1697 isActive: false numReads: 2722; 11:35:45.837 DEBUG Mutect2 - Processing assembly region at chrM:1698-1997 isActive: false numReads: 0; 11:35:45.999 DEBUG Mutect2 - Processing assembly region at chrM:1998-2297 isActive: false numReads: 0; 11:35:46.219 DEBUG Mutect2 - Processing assembly region at chrM:2298-2543 isActive: false numReads: 2555; 11:35:46.674 DEBUG Mutect2 - Processing assembly region at chrM:2544-2841 isActive: true numReads: 5108; 11:35:48.094 DEBUG ReadThreadingGraph - Recovered 17 of 20 dangling tails; 11:35:48.198 DEBUG ReadThreadingGraph - Recovered 16 of 50 dangling heads; 11:35:48.511 DEBUG IntToDoubleFunctionCache - cache miss 2389 > 10 expanding to 2399; 11:35:48.874 DEBUG Mutect2Engine - Active Region chrM:2544-2841; 11:35:48.874 DEBUG Mutect2Engine - Extended Act Region chrM:2444-2941; 11:35:48.875 DEBUG Mutect2Engine - Ref haplotype coords chrM:2444-2941; 11:35:48.875 DEBUG Mutect2Engine - Haplotype count 128; 11:35:48.875 DEBUG Mutect2Engine - Kmer sizes count 0; 11:35:48.875 DEBUG Mutect2Engine - Kmer sizes values []; 11:36:08.907 INFO ProgressMeter - chrM:2544 0.4 10 22.3; 11:36:08.954 DEBUG Mutect2 - Processing assembly region at chrM:2842-2920 isActive: false numReads: 4726; 11:36:09.094 DEBUG Mutect2 - Processing assembly region at chrM:2921-3202 isActive: true numReads: 4600; 11:36:09.663 DEBUG ReadThreadingGraph - Recovered 1 of 2 dangling tails; 11:36:09.671 DEBUG ReadThreadingGraph - Recovered 4 of 7 dangling heads; 11:36:09.750 DEBUG Mu,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7281:9192,Recover,Recovered,9192,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7281,1,['Recover'],['Recovered']
Availability,Downsample a bam by duplicate sets instead of reads,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6512:0,Down,Downsample,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6512,1,['Down'],['Downsample']
Availability,Downsample reads with ReservoirDownsampler in CNNScoreVariants.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5622:0,Down,Downsample,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5622,1,['Down'],['Downsample']
Availability,Downsample ref reads in Mutect,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3021:0,Down,Downsample,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3021,1,['Down'],['Downsample']
Availability,DownsampleSam discards NM tag,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8558:0,Down,DownsampleSam,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8558,1,['Down'],['DownsampleSam']
Availability,Downsampling Issue: Large duplication missed (reads softclips involved),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6088:0,Down,Downsampling,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6088,1,['Down'],['Downsampling']
Availability,Downstream analysis of ASEReadCounter output,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3267:0,Down,Downstream,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3267,1,['Down'],['Downstream']
Availability,Duplicate field error in GenomicsDBImport 4.1.2.0,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6158:16,error,error,16,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6158,1,['error'],['error']
Availability,"EEEEEEEEEAEEEEEEEEEAEEEEEEEEEEEAAAEAAAEEE/A<AEEEEEEEEEEAA"") | \; gzip > R1.fastq.gz. (echo ""@NB500989:333:HKYJNAFX2:1:11101:24447:1024""; echo ""NNNNTTGTATTTTTAATAGAGACGGGGTTTCAACATGTTGGCCAGGCTGGTCTTGAACTCCTGACCTCAGATGATCCACCCGCCTTGGCCTCCCAAAGTGCTAAGATTACAGGTGTGAGCTACTGCACCTGGCCCCCTCTAGTTTCTTTC""; echo ""+""; echo ""####AEEEEEEEEEEEEEEEE/EEEEEEEEEE6EEEEEEEEEEEEA<EEEEEEEEE/<EEEEEEE/EEEEEEEEEEE/EEEEEAEEEEEAEAEEEE/EEEEE/EEEEEEEEEEEEEAEEEEEEEEAE/<AAAA/<A<EE<<EA<A/AAE<""; echo ""@NB500989:333:HKYJNAFX2:1:11101:10000:1915""; echo ""TTACAGGATCTGAAGAGAGGGAAAAATAAACATGCACGATTATTTAATTCTTTTGGAAAAACTGCATGTAAGTGAAGTTCTCTTTCACAAGACACAAGCATCGGTAACTTGACAAAAAATGTAAGCTTCAGATTTTTATGAGCCTTTACA""; echo ""+""; echo ""AAAAAEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE/EEEEEEEEEE6EEEEEEEEEEEEAEEEEEE/EEEAEEEEEEEEEEEEEAEEAE/EEEEEEEEEAEEEEEEA<EEEEEE<AAEEEEEEEEEEAEEEEEAEAAEAE/AAEAEAA<E"") | \; gzip > R2.fastq.gz; ```. Install bwa and GATK resources:; ```; sudo apt install java11-runtime bwa samtools; wget https://github.com/broadinstitute/gatk/releases/download/4.2.1.0/gatk-4.2.1.0.zip; unzip gatk-4.2.1.0.zip; echo dict fasta fasta.fai fasta.64.alt fasta.64.sa fasta.64.amb fasta.64.bwt fasta.64.ann fasta.64.pac | \; tr ' ' '\n' | xargs -i echo gs://gcp-public-data--broad-references/hg38/v0/Homo_sapiens_assembly38.{} | \; gsutil -m cp -I .; ```. Run FastqToSam with the `-SORT_ORDER ""unsorted""` option:; ```; gatk-4.2.1.0/gatk \; FastqToSam \; -FASTQ R1.fastq.gz \; -FASTQ2 R2.fastq.gz \; -OUTPUT unmapped.bam \; -SAMPLE_NAME SM \; -SORT_ORDER ""unsorted""; ```; Notice the option `-SORT_ORDER ""unsorted""` which prevents the tool from resorting the reads which can add both computational and storage requirements. Aligned the data with bwa:; ```; gatk-4.2.1.0/gatk \; SamToFastq \; -INPUT unmapped.bam \; -FASTQ /dev/stdout \; -INTERLEAVE true | \; bwa mem -K 100000000 -p -v 3 -t 16 -Y Homo_sapiens_assembly38.fasta /dev/stdin | \; samtools view -1 - > aligned.unmerged.bam; ```. Merge unmapped and aligned BAMs:; ```; gatk-4.2.1.0/gatk \",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7398:1746,down,download,1746,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7398,1,['down'],['download']
Availability,"EMR - 5.13.0; Spark - 2.3.0. Running on m5.2xlarge 1 Master and 2 Worker nodes.; While running Haplotype Caller Spark on EMR, running into the stack overflow error. ; `[hadoop@ip-xx.xx.xx.xx gatk]$ ./gatk HaplotypeCallerSpark -I hdfs:///user/hadoop/testdata/TestData.cram -R hdfs:///user/hadoop/reference/hg38.fasta -O hdfs:///user/hadoop/output/testgatkvcf.vcf \; > -- \; > --spark-runner SPARK --spark-master yarn; Using GATK jar /home/hadoop/gatk/build/libs/gatk-spark.jar; Running:; /usr/lib/spark/bin/spark-submit --master yarn --conf spark.driver.userClassPathFirst=false --conf spark.io.compression.codec=lzf --conf spark.driver.maxResultSize=0 --conf spark.executor.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 --conf spark.driver.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 --conf spark.kryoserializer.buffer.max=512m --conf spark.yarn.executor.memoryOverhead=600 /home/hadoop/gatk/build/libs/gatk-spark.jar HaplotypeCallerSpark -I hdfs:///user/hadoop/testdata/TestData -R hdfs:///user/hadoop/reference/hg38.fasta -O hdfs:///user/hadoop/output/testgatkvcf.vcf --spark-master yarn; 19/04/08 19:01:40 WARN SparkConf: The configuration key 'spark.yarn.executor.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.executor.memoryOverhead' instead.; 19:01:43.413 WARN SparkContextFactory - Environment variables HELLBENDER_TEST_PROJECT and HELLBENDER_JSON_SERVICE_ACCOUNT_KEY must be set or the GCS hadoop connector will not be configured properly; 19:01:43.565 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/hadoop/gatk/build/libs/gatk-spark.jar!/com/intel/gkl/na",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5869:158,error,error,158,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5869,1,['error'],['error']
Availability,"ENV: Centos7 JAVA1.8 GTAK4.1.0.0 ; Preparation:; 1. download datasource funcotator_dataSources.v1.6.20190124g; 2. untar the gnomAD. ```shell; fa=/share/share/data/NGS/ref_index/GATK_bundle/hg38/Homo_sapiens_assembly38.fasta; func=/share/share/data/NGS/ref_index/GATK_bundle/funcotator_dataSources.v1.6.20190124g; gatk Funcotator \; 	--variant ../relapse.filtered.snps.indels.vcf \; 	--reference $fa \; 	--ref-version hg38 \; 	--data-sources-path $func \; 	--output relapse.funcotated.maf \; 	--output-file-format MAF; ```; after running the script above, it stucked and show nothing anymore, is there something I ignored ?. ```; Using GATK jar /share/share/soft/gatk-4.1.0.0/gatk-package-4.1.0.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /share/share/soft/gatk-4.1.0.0/gatk-package-4.1.0.0-local.jar Funcotator --variant ../relapse.filtered.snps.indels.vcf --reference /share/share/data/NGS/ref_index/GATK_bundle/hg38/Homo_sapiens_assembly38.fasta --ref-version hg38 --data-sources-path /share/share/data/NGS/ref_index/GATK_bundle/funcotator_dataSources.v1.6.20190124g --output relapse.funcotated.maf --output-file-format MAF; 10:24:47.787 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/share/share/soft/gatk-4.1.0.0/gatk-package-4.1.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; 10:24:50.558 INFO Funcotator - ------------------------------------------------------------; 10:24:50.559 INFO Funcotator - The Genome Analysis Toolkit (GATK) v4.1.0.0; 10:24:50.559 INFO Funcotator - For support and documentation go to https://software.broadinstitute.org/gatk/; 10:24:50.560 INFO Funcotator - Executing as javis@node4 on Linux v3.10.0-514.el7.x86_64 amd64; 10:24:50.560 INFO Funcotator - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_161-b12; 10:24:50.560 INFO Funcotator - Start Date/Time: April 24, 2019 10:24:4",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5903:52,down,download,52,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5903,1,['down'],['download']
Availability,"ERROR has occurred (version 3.8-0-ge9d806836): ; ##### ERROR; ##### ERROR This means that one or more arguments or inputs in your command are incorrect.; ##### ERROR The error message below tells you what is the problem.; ##### ERROR; ##### ERROR If the problem is an invalid argument, please check the online documentation guide; ##### ERROR (or rerun your command with --help) to view allowable command-line arguments for this tool.; ##### ERROR; ##### ERROR Visit our website and forum for extensive documentation and answers to ; ##### ERROR commonly asked questions https://software.broadinstitute.org/gatk; ##### ERROR; ##### ERROR Please do NOT post this error to the GATK forum unless you have really tried to fix it yourself.; ##### ERROR; ##### ERROR MESSAGE: Input files reads and reference have incompatible contigs. Please see https://software.broadinstitute.org/gatk/documentation/article?id=63for more information. Error details: No overlapping contigs found.; ##### ERROR reads contigs = [LmjF04_01_20050601_V5.2, LmjF05_01_20050601_V5.2, LmjF24_01_20050601_V5.2, LmjF01_01_20050601_V5.2, LmjF03_01_20050601_V5.2, LmjF13_01_20050601_V5.2, LmjF14_01_20050601_V5.2, LmjF19_01_20050601_V5.2, LmjF21_01_20050601_V5.2, LmjF23_01_20050601_V5.2, LmjF10_01_20050601_V5.2, LmjF11_01_20050601_V5.2, LmjF15_01_20050601_V5.2, LmjF18_01_20050601_V5.2, LmjF02_01_20050601_V5.2, LmjF25_01_20050601_V5.2, LmjF27_01_20050601_V5.2, LmjF28_01_20050601_V5.2, LmjF29_01_20050601_V5.2, LmjF30_01_20050601_V5.2, LmjF31_01_20050601_V5.2, LmjF32_01_20050601_V5.3, LmjF33_01_20050601_V5.2, LmjF34_01_20050601_V5.2, LmjF35_01_20050601_V5.2, LmjF36_01_20050601_V5.2, LmjF07_01_20050601_V5.2, LmjF08_01_20050601_V5.2, LmjF09_01_20050601_V5.2, LmjF06_01_20050601_V5.2, LmjF12_01_20050601_V5.2, LmjF16_01_20050601_V5.2, LmjF17_01_20050601_V5.2, LmjF20_01_20050601_V5.2, LmjF22_01_20050601_V5.2, LmjF26_01_20050601_V5.2]; ##### ERROR reference contigs = [LmjLV39_01, LmjLV39_02, LmjLV39_03, LmjLV39_04, LmjLV39_05, Lm",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6798:3729,ERROR,ERROR,3729,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6798,1,['ERROR'],['ERROR']
Availability,ERROR: Couldn't create GenomicsDBFeatureReader,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6616:0,ERROR,ERROR,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6616,1,['ERROR'],['ERROR']
Availability,"ER_NAME=""svdev-caller""; MASTER_NODE=""hdfs://svdev-caller-m:8020""; PROJECT_DIR=""user/shuang/NA12878_PCR-_30X"". ./gatk-launch FindBreakpointEvidenceSpark \; -R ""$MASTER_NODE""/reference/Homo_sapiens_assembly38.fasta \; -I ""$MASTER_NODE""/data/smallCram.cram \; -O ""$MASTER_NODE""/""$PROJECT_DIR""/fastq \; --exclusionIntervals gs://sv-data-dsde-dev/reference/GRCh38.kill.intervals \; --kmersToIgnore gs://sv-data-dsde-dev/reference/Homo_sapiens_assembly38.dups \; --kmerIntervals ""$MASTER_NODE""/""$PROJECT_DIR""/kmerIntervals \; --breakpointEvidenceDir ""$MASTER_NODE""/""$PROJECT_DIR""/evidence \; --breakpointIntervals ""$MASTER_NODE""/""$PROJECT_DIR""/intervals \; --qnameIntervalsMapped ""$MASTER_NODE""/""$PROJECT_DIR""/qnameIntervalsMapped \; --qnameIntervalsForAssembly ""$MASTER_NODE""/""$PROJECT_DIR""/qnameIntervalsForAssembly \; --maxFASTQSize 10000000 \; -- \; --sparkRunner GCS \; --cluster svdev-caller; ```. ========================. On the other hand, we see a similar error if the input is changed to the same file but stored in a google bucket (although the cited cause is different):. ```; ***********************************************************************. A USER ERROR has occurred: Failed to read bam header from gs://sv-data-dsde-dev/test_data/smallCram.cram; Caused by:null. ***********************************************************************; org.broadinstitute.hellbender.exceptions.UserException: A USER ERROR has occurred: Failed to read bam header from gs://sv-data-dsde-dev/test_data/smallCram.cram; Caused by:null; 	at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSource.getHeader(ReadsSparkSource.java:182); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.initializeReads(GATKSparkTool.java:381); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.initializeToolInputs(GATKSparkTool.java:361); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:351); 	at org.broadinstitute.hellbender.engine.spark.Spa",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2382:5268,error,error,5268,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2382,1,['error'],['error']
Availability,EST; 09:48:14.872 INFO GenotypeGVCFs - ------------------------------------------------------------; 09:48:14.872 INFO GenotypeGVCFs - ------------------------------------------------------------; 09:48:14.873 INFO GenotypeGVCFs - HTSJDK Version: 2.21.2; 09:48:14.873 INFO GenotypeGVCFs - Picard Version: 2.21.9; 09:48:14.873 INFO GenotypeGVCFs - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 09:48:14.874 INFO GenotypeGVCFs - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 09:48:14.874 INFO GenotypeGVCFs - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 09:48:14.874 INFO GenotypeGVCFs - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 09:48:14.874 INFO GenotypeGVCFs - Deflater: IntelDeflater; 09:48:14.874 INFO GenotypeGVCFs - Inflater: IntelInflater; 09:48:14.874 INFO GenotypeGVCFs - GCS max retries/reopens: 20; 09:48:14.874 INFO GenotypeGVCFs - Requester pays: disabled; 09:48:14.874 INFO GenotypeGVCFs - Initializing engine; 09:48:16.015 INFO GenotypeGVCFs - Shutting down engine; [27 May 2020 09:48:16 CEST] oAB.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs done. Elapsed time: 0.03 minutes.; Runtime.totalMemory()=2301100032; ***********************************************************************. A USER ERROR has occurred: Couldn't create GenomicsDBFeatureReader. ***********************************************************************; oAB.broadinstitute.hellbender.exceptions.UserException: Couldn't create GenomicsDBFeatureReader; 	at oAB.broadinstitute.hellbender.engine.FeatureDataSource.getGenomicsDBFeatureReader(FeatureDataSource.java:410); 	at oAB.broadinstitute.hellbender.engine.FeatureDataSource.getFeatureReader(FeatureDataSource.java:326); 	at oAB.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:282); 	at oAB.broadinstitute.hellbender.engine.VariantLocusWalker.initializeDrivingVariants(VariantLocusWalker.java:76); 	at oAB.broadinstitute.hellbender.engine.VariantWalkerBase.initializeFeatures(VariantWalkerBase.j,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6616:10221,down,down,10221,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6616,1,['down'],['down']
Availability,EVALUATING Merge all from ah_var_store into EchoCallset,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8701:44,Echo,EchoCallset,44,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8701,1,['Echo'],['EchoCallset']
Availability,"EVEL : 5; 11:43:32.131 INFO SortSam - Defaults.CREATE_INDEX : false; 11:43:32.131 INFO SortSam - Defaults.CREATE_MD5 : false; 11:43:32.131 INFO SortSam - Defaults.CUSTOM_READER_FACTORY : ; 11:43:32.131 INFO SortSam - Defaults.EBI_REFERENCE_SERVICE_URL_MASK : http://www.ebi.ac.uk/ena/cram/md5/%s; 11:43:32.131 INFO SortSam - Defaults.NON_ZERO_BUFFER_SIZE : 131072; 11:43:32.131 INFO SortSam - Defaults.REFERENCE_FASTA : null; 11:43:32.131 INFO SortSam - Defaults.SAM_FLAG_FIELD_FORMAT : DECIMAL; 11:43:32.131 INFO SortSam - Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 11:43:32.131 INFO SortSam - Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : false; 11:43:32.131 INFO SortSam - Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 11:43:32.131 INFO SortSam - Defaults.USE_CRAM_REF_DOWNLOAD : false; 11:43:32.131 INFO SortSam - Deflater IntelDeflater; 11:43:32.131 INFO SortSam - Initializing engine; 11:43:32.131 INFO SortSam - Done initializing engine; 11:43:42.134 INFO SortSam - Shutting down engine; [December 7, 2016 11:43:42 AM AST] org.broadinstitute.hellbender.tools.picard.sam.SortSam done. Elapsed time: 0.17 minutes.; Runtime.totalMemory()=1890058240; Exception in thread ""main"" java.lang.NoClassDefFoundError: org/xerial/snappy/LoadSnappy; 	at htsjdk.samtools.util.SnappyLoader.<init>(SnappyLoader.java:86); 	at htsjdk.samtools.util.SnappyLoader.<init>(SnappyLoader.java:52); 	at htsjdk.samtools.util.TempStreamFactory.getSnappyLoader(TempStreamFactory.java:42); 	at htsjdk.samtools.util.TempStreamFactory.wrapTempOutputStream(TempStreamFactory.java:74); 	at htsjdk.samtools.util.SortingCollection.spillToDisk(SortingCollection.java:223); 	at htsjdk.samtools.util.SortingCollection.add(SortingCollection.java:166); 	at htsjdk.samtools.SAMFileWriterImpl.addAlignment(SAMFileWriterImpl.java:192); 	at org.broadinstitute.hellbender.tools.picard.sam.SortSam.doWork(SortSam.java:52); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:112); 	at org.broad",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2299:1291,down,down,1291,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2299,2,['down'],['down']
Availability,"EX_UMI=false FLOW_MODE=false FLOW_DUP_STRATEGY=FLOW_QUALITY_SUM_STRATEGY USE_END_IN_UNPAIRED_READS=false USE_UNPAIRED_CLIPPED_END=false UNPAIRED_END_UNCERTAINTY=0 UNPAIRED_START_UNCERTAINTY=0 FLOW_SKIP_FIRST_N_FLOWS=0 FLOW_Q_IS_KNOWN_END=false FLOW_EFFECTIVE_QUALITY_THRESHOLD=15 ADD_PG_TAG_TO_READS=true REMOVE_DUPLICATES=false ASSUME_SORTED=false DUPLICATE_SCORING_STRATEGY=SUM_OF_BASE_QUALITIES PROGRAM_RECORD_ID=MarkDuplicates PROGRAM_GROUP_NAME=MarkDuplicates READ_NAME_REGEX=<optimized capture of last three ':' separated fields as numeric values> OPTICAL_DUPLICATE_PIXEL_DISTANCE=100 MAX_OPTICAL_DUPLICATE_SET_SIZE=300000 VERBOSITY=INFO QUIET=false VALIDATION_STRINGENCY=STRICT COMPRESSION_LEVEL=2 MAX_RECORDS_IN_RAM=500000 CREATE_INDEX=false CREATE_MD5_FILE=false USE_JDK_DEFLATER=false USE_JDK_INFLATER=false; [Wed Jul 03 15:26:21 CEST 2024] Executing as qnick@Barbus on Linux 6.5.0-41-generic amd64; OpenJDK 64-Bit Server VM 17.0.11+9-Ubuntu-122.04.1; Deflater: Intel; Inflater: Intel; Provider GCS is available; Picard version: 4.6.0.0; INFO 2024-07-03 15:26:21 MarkDuplicates Start of doWork freeMemory: 189357416; totalMemory: 234881024; maxMemory: 32178700288; INFO 2024-07-03 15:26:21 MarkDuplicates Reading input file and constructing read end information.; INFO 2024-07-03 15:26:21 MarkDuplicates Will retain up to 116589493 data points before spilling to disk.; [Wed Jul 03 15:26:25 CEST 2024] picard.sam.markduplicates.MarkDuplicates done. Elapsed time: 0.07 minutes.; Runtime.totalMemory()=3774873600; To get help, see http://broadinstitute.github.io/picard/index.html#GettingHelp; java.lang.NullPointerException: Cannot invoke ""htsjdk.samtools.SAMReadGroupRecord.getReadGroupId()"" because the return value of ""htsjdk.samtools.SAMRecord.getReadGroup()"" is null; at picard.sam.markduplicates.MarkDuplicates.buildSortedReadEndLists(MarkDuplicates.java:558); at picard.sam.markduplicates.MarkDuplicates.doWork(MarkDuplicates.java:270); at picard.cmdline.CommandLineProgram.instanceMa",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8904:7640,avail,available,7640,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8904,1,['avail'],['available']
Availability,"EX_UMI=false FLOW_MODE=false FLOW_DUP_STRATEGY=FLOW_QUALITY_SUM_STRATEGY USE_END_IN_UNPAIRED_READS=false USE_UNPAIRED_CLIPPED_END=false UNPAIRED_END_UNCERTAINTY=0 UNPAIRED_START_UNCERTAINTY=0 FLOW_SKIP_FIRST_N_FLOWS=0 FLOW_Q_IS_KNOWN_END=false FLOW_EFFECTIVE_QUALITY_THRESHOLD=15 ADD_PG_TAG_TO_READS=true REMOVE_DUPLICATES=false ASSUME_SORTED=false DUPLICATE_SCORING_STRATEGY=SUM_OF_BASE_QUALITIES PROGRAM_RECORD_ID=MarkDuplicates PROGRAM_GROUP_NAME=MarkDuplicates READ_NAME_REGEX=<optimized capture of last three ':' separated fields as numeric values> OPTICAL_DUPLICATE_PIXEL_DISTANCE=100 MAX_OPTICAL_DUPLICATE_SET_SIZE=300000 VERBOSITY=INFO QUIET=false VALIDATION_STRINGENCY=STRICT COMPRESSION_LEVEL=5 MAX_RECORDS_IN_RAM=500000 CREATE_INDEX=false CREATE_MD5_FILE=false USE_JDK_DEFLATER=false USE_JDK_INFLATER=false; [Wed Jul 03 15:25:31 CEST 2024] Executing as qnick@Barbus on Linux 6.5.0-41-generic amd64; OpenJDK 64-Bit Server VM 17.0.11+9-Ubuntu-122.04.1; Deflater: Intel; Inflater: Intel; Provider GCS is available; Picard version: 3.2.0-1-gd8d87c971-SNAPSHOT; INFO 2024-07-03 15:25:31 MarkDuplicates Start of doWork freeMemory: 377343072; totalMemory: 402653184; maxMemory: 32178700288; INFO 2024-07-03 15:25:31 MarkDuplicates Reading input file and constructing read end information.; INFO 2024-07-03 15:25:31 MarkDuplicates Will retain up to 116589493 data points before spilling to disk.; [Wed Jul 03 15:25:35 CEST 2024] picard.sam.markduplicates.MarkDuplicates done. Elapsed time: 0.07 minutes.; Runtime.totalMemory()=6861881344; To get help, see http://broadinstitute.github.io/picard/index.html#GettingHelp; Exception in thread ""main"" java.lang.NullPointerException: Cannot invoke ""htsjdk.samtools.SAMReadGroupRecord.getReadGroupId()"" because the return value of ""htsjdk.samtools.SAMRecord.getReadGroup()"" is null; at picard.sam.markduplicates.MarkDuplicates.buildSortedReadEndLists(MarkDuplicates.java:558); at picard.sam.markduplicates.MarkDuplicates.doWork(MarkDuplicates.java:270); ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8904:3879,avail,available,3879,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8904,1,['avail'],['available']
Availability,"E_ASYNC_IO_READ_FOR_SAMTOOLS : false; 14:40:45.791 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 14:40:45.792 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 14:40:45.792 INFO HaplotypeCaller - Deflater: IntelDeflater; 14:40:45.792 INFO HaplotypeCaller - Inflater: IntelInflater; 14:40:45.792 INFO HaplotypeCaller - GCS max retries/reopens: 20; 14:40:45.792 INFO HaplotypeCaller - Requester pays: disabled; 14:40:45.792 INFO HaplotypeCaller - Initializing engine; 14:40:47.694 INFO IntervalArgumentCollection - Processing 50818468 bp from intervals; 14:40:47.714 INFO HaplotypeCaller - Done initializing engine; 14:40:47.826 INFO HaplotypeCallerEngine - Disabling physical phasing, which is supported only for reference-model confidence output; 14:40:47.864 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/share/pkg.7/gatk/4.1.7.0/install/bin/gatk-package-4.1.7.0-local.jar!/com/intel/gkl/native/libgkl_utils.so; 14:40:47.868 INFO NativeLibraryLoader - Loading libgkl_pairhmm_omp.so from jar:file:/share/pkg.7/gatk/4.1.7.0/install/bin/gatk-package-4.1.7.0-local.jar!/com/intel/gkl/native/libgkl_pairhmm_omp.so; 14:40:47.921 INFO IntelPairHmm - Flush-to-zero (FTZ) is enabled when running PairHMM; 14:40:47.922 INFO IntelPairHmm - Available threads: 1; 14:40:47.922 INFO IntelPairHmm - Requested threads: 4; 14:40:47.922 WARN IntelPairHmm - Using 1 available threads, but 4 were requested; 14:40:47.922 INFO PairHMM - Using the OpenMP multi-threaded AVX-accelerated native PairHMM implementation; 14:40:48.005 INFO ProgressMeter - Starting traversal; 14:40:48.006 INFO ProgressMeter - Current Locus Elapsed Minutes Regions Processed Regions/Minute; 14:40:51.792 WARN InbreedingCoeff - InbreedingCoeff will not be calculated; at least 10 samples must have called genotypes; 14:40:58.312 INFO ProgressMeter - chr22:10659064 0.2 35790 208384.3; 14:41:09.992 INFO ProgressMeter - chr22:10687910 0.4 35990 98217.0. ```. ----",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7076:8663,Avail,Available,8663,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7076,2,"['Avail', 'avail']","['Available', 'available']"
Availability,Echo Scale Test VDS Updates [VS-1095] [VS-1112],MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8602:0,Echo,Echo,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8602,1,['Echo'],['Echo']
Availability,Echo callset,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8972:0,Echo,Echo,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8972,1,['Echo'],['Echo']
Availability,Echo log file after failed travis run.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7020:0,Echo,Echo,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7020,1,['Echo'],['Echo']
Availability,Eliminate error message in travis logs by creating the srcdir before copying to it.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5878:10,error,error,10,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5878,1,['error'],['error']
Availability,Eliminate redundant AnnotatedInterval class.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3884:10,redundant,redundant,10,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3884,1,['redundant'],['redundant']
Availability,Emit error bars in CalculateContamination,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3384:5,error,error,5,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3384,1,['error'],['error']
Availability,"Empirical testing has shown that this tool performs best at scale with cloud buffering; disabled. With cloud buffering on and thousands of concurrent GenomicsDBImport tasks,; we do too many simultaneous GCS accesses (since the prefetcher spawns a new thread for each; reader upon a query) and start seeing intermittent failures, even with aggressive retries.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3110:319,failure,failures,319,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3110,1,['failure'],['failures']
Availability,Ensure VQSR QC plotting is robust to dbsnp version,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/385:27,robust,robust,27,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/385,1,['robust'],['robust']
Availability,Ensure that multi-threaded AVX PairHMM falls back to single-threaded mode when OpenMP is not available or is the wrong version,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1819:93,avail,available,93,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1819,1,['avail'],['available']
Availability,"Environment:. * GATK 4.0.3.0; * Python 2.7.14; * Red Hat Enterprise Linux Server release 7.4 (Maipo). I'm using GATK CNNScoreVariants 1D model(CPU mode) for hundreds of VCF files, but the following error occurred in some of them. 00:13:26.470 INFO ProgressMeter - Traversal complete. Processed 4924627 total variants in 79.6 minutes.; 00:14:14.422 INFO CNNScoreVariants - Shutting down engine; [2018/05/02 13:10:44 JST] org.broadinstitute.hellbender.tools.walkers.vqsr.CNNScoreVariants done. Elapsed time: 79.75 minutes.; Runtime.totalMemory()=1126694912; org.broadinstitute.hellbender.utils.python.PythonScriptExecutorException: Traceback detected: Traceback (most recent call last):; File ""<stdin>"", line1, in <module>; File "".../lib/python2.7/site-packages/vqsr_cnn/inference.py"", line 51, in score_and_write_batch; reference_batch.append(reference_string_to_tensor(fifo_data[4])); File "".../lib/python2.7/site-packages/vqsr_cnn/inference.py"", line 107, in reference_string_to_tensor; raise ValueError('Error! Unknown code:', b); ValueError('Error! Unknown code:', '\x00'); >>>; at org.broadinstitute.hellbender.utils.python.StreamingPythonScriptExecutor.getAccumulatedOutput(StreamingPythonScriptExecutor.java:214); at org.broadinstitute.hellbender.tools.walkers.vqsr.CNNScoreVariants.onTraversalSuccess(CNNScoreVariants.java:385); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:894); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:134); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:179); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:198); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289); ; I tried again, but same message are shown.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4727:198,error,error,198,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4727,4,"['Error', 'down', 'error']","['Error', 'down', 'error']"
Availability,"Error Message from VariantAnnotator is a NullPointerException. The user found the issue, but the error message could be improved. The issue involves the sample names from the VCF not existing in the BAM file. . This request was created from a contribution made by Wout Megchelenbrink on October 21, 2020 12:29 UTC. Link: [https://gatk.broadinstitute.org/hc/en-us/community/posts/360073989631-VariantAnnotator-returns-NullPointerException](https://gatk.broadinstitute.org/hc/en-us/community/posts/360073989631-VariantAnnotator-returns-NullPointerException). \--. If you are seeing an error, please provide(REQUIRED) : ; ; **a) GATK version used:**. 4.1.8.1. **b) Exact command used:**. gatk VariantAnnotator -V WES.vcf.gz -I WES.bam --output WES\_VA.vcf -A Coverage. **c) Entire error log:**. java.lang.NullPointerException ; ; at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.AssemblyBasedCallerUtils.splitReadsBySample(AssemblyBasedCallerUtils.java:162) ; ; at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotator.makeLikelihoods(VariantAnnotator.java:244) ; ; at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotator.apply(VariantAnnotator.java:234) ; ; at org.broadinstitute.hellbender.engine.VariantWalker.lambda$traverse$0(VariantWalker.java:104) ; ; at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183) ; ; at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195) ; ; at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:177) ; ; at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195) ; ; at java.base/java.util.Iterator.forEachRemaining(Iterator.java:133) ; ; at java.base/java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801) ; ; at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484) ; ; at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPip",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6915:0,Error,Error,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6915,4,"['Error', 'error']","['Error', 'error']"
Availability,"Error exit condition is also met when contamination = 0, because in this case, stdError is also equal to 0, and thus is always less than the minimum value for (contamination * MIN_RELATIVE_ERROR [0.2] + MIN_ABSOLUTE_ERROR [0.001]), which cannot be less than 0.001. . final double stdError = homs.isEmpty() ? 1 : Math.sqrt(homs.stream().mapToDouble(ps -> {; final double d = ps.getTotalCount();; final double f = 1 - oppositeAlleleFrequency.applyAsDouble(ps);; return (1 - f) * d * contamination * ((1 - contamination) + f * d * contamination);; }).sum()) / totalDepthWeightedByOppositeFrequency;. ** return (1 - f) * d * contamination * ((1 - contamination) + f * d * contamination);**. Root cause:; At the first MAF iteration where errorDepth is greater than oppositeDepth, contamination is set to “0” (according to the code logic shown below), the function exits the iteration process, and no further MAF thresholds are tested. **contaminationOppositeDepth = Math.max(oppositeDepth - errorDepth, 0);**; **contamination = contaminationOppositeDepth / totalDepthWeightedByOppositeFrequency**. Solution proposed:; Currently, when errorDepth is greater than oppositeDepth, the output contamination is reported as **’0’ contamination**; it seems to us that this should instead be interpreted as **“unable to calculate contamination”** because of the high error rate in these pileups. Improvements for current version:; In addition, we suggest calculating all contamination values over all strategies/iterations and outputting the highest contamination value (by MAF and/or strategy, as appropriate), rather than exiting after the first MAF iteration where stdError exit condition is met. ### Description what needs to be added or modified; Please see the code change attached, compare it to 4.2.0.0. The code outputs all pileups used in each iteration and shows the non zero contamination value if exist.; [Contamination.zip](https://github.com/broadinstitute/gatk/files/6232262/Contamination.zip). ----",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7177:2064,error,errorDepth,2064,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7177,3,['error'],"['error', 'errorDepth']"
Availability,Error getting access token for service account,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2514:0,Error,Error,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2514,1,['Error'],['Error']
Availability,Error handling for non-existent reference files.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1614:0,Error,Error,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1614,1,['Error'],['Error']
Availability,Error in BaseRecalibrator while using NIO,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3316:0,Error,Error,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316,1,['Error'],['Error']
Availability,Error in CombineGVCFs v4.1.8.1,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6790:0,Error,Error,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6790,1,['Error'],['Error']
Availability,Error in CombineGvcfs,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6368:0,Error,Error,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6368,1,['Error'],['Error']
Availability,Error in Mutect2,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4665:0,Error,Error,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4665,1,['Error'],['Error']
Availability,Error in PalindromeArtifactClipReadTransformer,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5036:0,Error,Error,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5036,1,['Error'],['Error']
Availability,Error in SplitNCigarReads v4.8.1.0,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6776:0,Error,Error,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6776,1,['Error'],['Error']
Availability,Error in StructuralVariationDiscoveryPipelineSpark: UnhandledCaseSeen in CpxVariantInterpreter,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4649:0,Error,Error,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4649,1,['Error'],['Error']
Availability,Error in StructuralVariationDiscoveryPipelineSpark: invalid interval in CpxVariantInterpreter,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4648:0,Error,Error,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4648,1,['Error'],['Error']
Availability,Error in VariantFiltration: SnpCluster,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8500:0,Error,Error,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8500,1,['Error'],['Error']
Availability,Error in creating read tensors,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6002:0,Error,Error,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6002,1,['Error'],['Error']
Availability,Error in executing the BwaAndMarkDuplicatesPipelineSpark,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4112:0,Error,Error,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4112,1,['Error'],['Error']
Availability,Error in gcnv kernel of DetermineGermlineContigPloidy,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4679:0,Error,Error,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4679,1,['Error'],['Error']
Availability,Error in line 84 cohort_determine_ploidy_and_depth.py,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4125:0,Error,Error,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4125,1,['Error'],['Error']
Availability,Error in smith waterman native library,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5690:0,Error,Error,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5690,1,['Error'],['Error']
Availability,Error in the cleanHardClippedCigar function ClippingOp class,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6130:0,Error,Error,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6130,1,['Error'],['Error']
Availability,Error message for no callable sites in M2,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6445:0,Error,Error,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6445,1,['Error'],['Error']
Availability,Error running HaplotypeCallerSpark in GVCF mode,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4393:0,Error,Error,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4393,1,['Error'],['Error']
Availability,Error running gatk seq-format-validation workflow,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6710:0,Error,Error,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710,1,['Error'],['Error']
Availability,"Error type 1: . gatk --java-options ""-Xmx32G -XX:ParallelGCThreads=8 -Djava.io.tmpdir=/tmp"" SplitNCigarReads --spark-runner LOCAL -I 10_mkdup/SAMD00025146_mkdup.bam -R Gallus_gallus.GRCg6a.dna.toplevel.fa -L chicken_chr.list -O 11_cigar/SAMD00025146_cigar.bam --create-output-bam-index true --max-reads-in-memory 5000. 00:01:27.347 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/dguan/anaconda3/envs/Chicken_GTEx/share/gatk4-4.1.9.0-0/gatk-package-4.1.9.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Feb 21, 2021 12:01:27 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 00:01:27.611 INFO SplitNCigarReads - ------------------------------------------------------------; 00:01:27.612 INFO SplitNCigarReads - The Genome Analysis Toolkit (GATK) v4.1.9.0; 00:01:27.612 INFO SplitNCigarReads - For support and documentation go to https://software.broadinstitute.org/gatk/; 00:01:27.612 INFO SplitNCigarReads - Executing as dguan@bigmem8 on Linux v4.15.0-118-generic amd64; 00:01:27.613 INFO SplitNCigarReads - Java runtime: OpenJDK 64-Bit Server VM v10.0.2+13; 00:01:27.613 INFO SplitNCigarReads - Start Date/Time: February 21, 2021 at 12:01:27 AM PST; 00:01:27.613 INFO SplitNCigarReads - ------------------------------------------------------------; 00:01:27.613 INFO SplitNCigarReads - ------------------------------------------------------------; 00:01:27.614 INFO SplitNCigarReads - HTSJDK Version: 2.23.0; 00:01:27.614 INFO SplitNCigarReads - Picard Version: 2.23.3; 00:01:27.615 INFO SplitNCigarReads - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 00:01:27.615 INFO SplitNCigarReads - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 00:01:27.615 INFO SplitNCigarReads - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 00:01:27.615 INFO SplitNCigarReads - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 00:01:27.615 INFO Spl",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7091:0,Error,Error,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7091,1,['Error'],['Error']
Availability,Error when running VariantRecalibrator,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2199:0,Error,Error,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2199,1,['Error'],['Error']
Availability,Error when using IntervalListTools in gatk4,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4619:0,Error,Error,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4619,1,['Error'],['Error']
Availability,Error while using somatic CNV in wdl,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6189:0,Error,Error,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6189,1,['Error'],['Error']
Availability,Error with java -jar gatk-protected-package-version-unknown-SNAPSHOT-spark.jar,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2676:0,Error,Error,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2676,1,['Error'],['Error']
Availability,"Error: A JNI error has occurred, please check your installation and try again; Exception in thread ""main"" java.lang.SecurityException: Invalid signature file digest for Manifest main attributes; 	at sun.security.util.SignatureFileVerifier.processImpl(SignatureFileVerifier.java:314); 	at sun.security.util.SignatureFileVerifier.process(SignatureFileVerifier.java:268); 	at java.util.jar.JarVerifier.processEntry(JarVerifier.java:316); 	at java.util.jar.JarVerifier.update(JarVerifier.java:228); 	at java.util.jar.JarFile.initializeVerifier(JarFile.java:383); 	at java.util.jar.JarFile.getInputStream(JarFile.java:450); 	at sun.misc.JarIndex.getJarIndex(JarIndex.java:137); 	at sun.misc.URLClassPath$JarLoader$1.run(URLClassPath.java:839); 	at sun.misc.URLClassPath$JarLoader$1.run(URLClassPath.java:831); 	at java.security.AccessController.doPrivileged(Native Method); 	at sun.misc.URLClassPath$JarLoader.ensureOpen(URLClassPath.java:830); 	at sun.misc.URLClassPath$JarLoader.<init>(URLClassPath.java:803); 	at sun.misc.URLClassPath$3.run(URLClassPath.java:530); 	at sun.misc.URLClassPath$3.run(URLClassPath.java:520). This error seems to be resulting from signed jars and there are recommendations on the web such as exclude 'META-INF/*.RSA', 'META-INF/*.SF','META-INF/*.DSA'; I will greatly appreciate if someone could tell me where to add the aforementioned line in 'build.gradle' file.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2676:0,Error,Error,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2676,3,"['Error', 'error']","['Error', 'error']"
Availability,Error: Cannot read from buffer; Error: cannot load book-keeping,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7012:0,Error,Error,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7012,2,['Error'],['Error']
Availability,Error: Cannot rename fragment directory; Directory not empty.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2743:0,Error,Error,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2743,1,['Error'],['Error']
Availability,Errors direct to non-existent forum posts,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8201:0,Error,Errors,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8201,1,['Error'],['Errors']
Availability,Errors in SplitNCigarReads,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7091:0,Error,Errors,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7091,1,['Error'],['Errors']
Availability,Errors in VariantFiltration - possibly due to (or exposed by) async tribble reading,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1638:0,Error,Errors,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1638,1,['Error'],['Errors']
Availability,Errors in spark tests when connected to Broad VPN,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1534:0,Error,Errors,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1534,1,['Error'],['Errors']
Availability,"Every overlapping read pair in HaplotypeCaller and Mutect2 ; goes through `FragmentUtils.adjustQualsOfOverlappingPairedFragments`, which has the following *hard-coded* logic:. ```; if ( firstReadBase == secondReadBase ) {; firstReadQuals[firstReadIndex] = Math.min(firstReadQuals[firstReadIndex], HALF_OF_DEFAULT_PCR_ERROR_QUAL);; secondReadQuals[i] = Math.min(secondReadQuals[i], HALF_OF_DEFAULT_PCR_ERROR_QUAL);; } else {; firstReadQuals[firstReadIndex] = 0;; secondReadQuals[i] = 0;; }; ```. This makes sense -- we modify the quals to reflect that sequencing errors are independent but PCR errors are not. However, `HALF_OF_DEFAULT_PCR_ERROR_QUAL` is 20, so if we start out with high-quality UMI reads we basically kill the quality and with it our SNV sensitivity. Note that in the very important application of cfDNA basically every base is an overlap. What's worse is that Mutect2 later throws out one of the reads, so that we could start out with two BQ = 60 reads and end up with one BQ = 20 read!. @fleharty @yfarjoun This is a problem. I could just make the PCR error quality an adjustable parameter, but can you think of anything else?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4958:562,error,errors,562,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4958,3,['error'],"['error', 'errors']"
Availability,Exception in onShutdown mask the actual cause of problems in onStartup.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/528:24,mask,mask,24,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/528,1,['mask'],['mask']
Availability,ExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.RequestStopIfSingleUsedDaemon.execute(RequestStopIfSingleUsedDaemon.java:34); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.ForwardClientInput$2.call(ForwardClientInput.java:74); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.ForwardClientInput$2.call(ForwardClientInput.java:72); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.util.Swapper.swap(Swapper.java:38); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.ForwardClientInput.execute(ForwardClientInput.java:72); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.LogAndCheckHealth.execute(LogAndCheckHealth.java:55); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.LogToClient.doBuild(LogToClient.java:60); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.BuildCommandOnly.execute(BuildCommandOnly.java:36); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.api.DaemonCommandExec,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2802:11100,ERROR,ERROR,11100,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2802,1,['ERROR'],['ERROR']
Availability,ExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.RequestStopIfSingleUsedDaemon.execute(RequestStopIfSingleUsedDaemon.java:34); 22:05:55.980 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); 22:05:55.980 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.ForwardClientInput$2.call(ForwardClientInput.java:74); 22:05:55.980 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.ForwardClientInput$2.call(ForwardClientInput.java:72); 22:05:55.980 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.util.Swapper.swap(Swapper.java:38); 22:05:55.980 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.ForwardClientInput.execute(ForwardClientInput.java:72); 22:05:55.981 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); 22:05:55.982 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.LogAndCheckHealth.execute(LogAndCheckHealth.java:55); 22:05:55.982 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); 22:05:55.982 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.LogToClient.doBuild(LogToClient.java:60); 22:05:55.982 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.BuildCommandOnly.execute(BuildCommandOnly.java:36); 22:05:55.982 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.api.DaemonCommandExec,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4687:9842,ERROR,ERROR,9842,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4687,1,['ERROR'],['ERROR']
Availability,"Exclude the field AS_YNG from VCFs extracted from GVS.; This is the merge into EchoCallset; Integration tests (run on the branch into ah_var_store) [here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/ffed3910-761e-487f-98b3-c0582acc13e8); Note that I had to update the truth data (since the contents of the VCFs had changed, and that there is one failure, but it's due to a slight cost difference - which is presumably in the noise.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8734:79,Echo,EchoCallset,79,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8734,2,"['Echo', 'failure']","['EchoCallset', 'failure']"
Availability,"Exclude the field AS_YNG from VCFs extracted from GVS.; This is the merge into ah_var_store to match the one into EchoCallset; Integration tests [here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/5b513630-203f-4e4c-a14c-7423f300645e) - one failure for unrelated reasons.; Note that I had to update the truth data (since the contents of the VCFs had changed, and that there is one failure, but it's due to a slight cost difference - which is presumably in the noise.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8738:114,Echo,EchoCallset,114,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8738,3,"['Echo', 'failure']","['EchoCallset', 'failure']"
Availability,ExecuteAtMostOnceTaskExecuter.java:43); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.CatchExceptionTaskExecuter.execute(CatchExceptionTaskExecuter.java:34); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.taskgraph.DefaultTaskGraphExecuter$EventFiringTaskWorker$1.execute(DefaultTaskGraphExecuter.java:236); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.taskgraph.DefaultTaskGraphExecuter$EventFiringTaskWorker$1.execute(DefaultTaskGraphExecuter.java:228); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.Transformers$4.transform(Transformers.java:169); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:106); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:61); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.taskgraph.DefaultTaskGraphExecuter$EventFiringTaskWorker.execute(DefaultTaskGraphExecuter.java:228); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.taskgraph.DefaultTaskGraphExecuter$EventFiringTaskWorker.execute(DefaultTaskGraphExecuter.java:215); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.taskgraph.AbstractTaskPlanExecutor$TaskExecutorWorker.processTask(AbstractTaskPlanExecutor.java:77); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.taskgraph.AbstractTaskPlanExecutor$TaskExecutorWorker.run(AbstractTaskPlanExecutor.java:58); 11:54:40.434 [ERROR] [org,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2802:3176,ERROR,ERROR,3176,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2802,1,['ERROR'],['ERROR']
Availability,Execution failed for task ':gatkDoc'.; > Javadoc generation failed. ### Affected tool(s) or class(es); GATK. ### Affected version(s); 4.1.4.1; ### Description ; when trying to compile with .gradlew bundle get the error above. * What went wrong:; Execution failed for task ':gatkDoc'.; > Javadoc generation failed. Generated Javadoc options file (useful for troubleshooting): '/usr/bin/gatk/build/tmp/gatkDoc/javadoc.options'. * Try:; Run with --info or --debug option to get more log output. Run with --scan to get full insights. * Exception is:; org.gradle.api.tasks.TaskExecutionException: Execution failed for task ':gatkDoc'.; at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter$3.accept(ExecuteActionsTaskExecuter.java:166); at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter$3.accept(ExecuteActionsTaskExecuter.java:163); at org.gradle.internal.Try$Failure.ifSuccessfulOrElse(Try.java:191); at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.execute(ExecuteActionsTaskExecuter.java:156); at org.gradle.api.internal.tasks.execution.ValidatingTaskExecuter.execute(ValidatingTaskExecuter.java:62); at org.gradle.api.internal.tasks.execution.SkipEmptySourceFilesTaskExecuter.execute(SkipEmptySourceFilesTaskExecuter.java:108); at org.gradle.api.internal.tasks.execution.ResolveBeforeExecutionOutputsTaskExecuter.execute(ResolveBeforeExecutionOutputsTaskExecuter.java:67); at org.gradle.api.internal.tasks.execution.ResolveAfterPreviousExecutionStateTaskExecuter.execute(ResolveAfterPreviousExecutionStateTaskExecuter.java:46); at org.gradle.api.internal.tasks.execution.CleanupStaleOutputsExecuter.execute(CleanupStaleOutputsExecuter.java:94); at org.gradle.api.internal.tasks.execution.FinalizePropertiesTaskExecuter.execute(FinalizePropertiesTaskExecuter.java:46); at org.gradle.api.internal.tasks.execution.ResolveTaskExecutionModeExecuter.execute(ResolveTaskExecutionModeExecuter.java:95); at org.gradle.api.internal.tasks.execution.SkipTa,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6466:213,error,error,213,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6466,2,"['Failure', 'error']","['Failure', 'error']"
Availability,"Executor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745). 16/11/16 23:25:11 ERROR TaskSetManager: Task 0 in stage 1.0 failed 1 times; aborting job; 16/11/16 23:25:11 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool ; 16/11/16 23:25:11 INFO TaskSchedulerImpl: Cancelling stage 1; 16/11/16 23:25:11 INFO DAGScheduler: ResultStage 1 (saveAsNewAPIHadoopFile at ReadsSparkSink.java:202) failed in 0.276 s; 16/11/16 23:25:11 INFO DAGScheduler: Job 0 failed: saveAsNewAPIHadoopFile at ReadsSparkSink.java:202, took 1.029776 s; 16/11/16 23:25:11 INFO SparkContext: SparkContext already stopped.; [November 16, 2016 11:25:11 PM AST] org.broadinstitute.hellbender.tools.spark.pipelines.PrintReadsSpark done. Elapsed time: 0.07 minutes.; Runtime.totalMemory()=2058354688; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 1.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1.0 (TID 1, localhost): java.lang.AbstractMethodError: org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSink$$Lambda$78/237665701.call(Ljava/lang/Object;)Ljava/lang/Iterable;; 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:159); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:159); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$20.apply(RDD.scala:710); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$20.apply(RDD.scala:710); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270); 	at or",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2268:17049,failure,failure,17049,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2268,1,['failure'],['failure']
Availability,Experimental tool that allows downloading reads and variants files from an htsget server. . @lbergelson,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6611:30,down,downloading,30,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6611,1,['down'],['downloading']
Availability,"External bams sometimes use faulty adapter trimming algorithms that leave a few identical, repeated reads in a bam (i.e. not PCR duplicates but exactly the same read name etc). While these bams are faulty there is no reason not to be able to handle them, as we could as of GATK 3.6. This patch prevents an error without changing how we process good bams.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3122:28,fault,faulty,28,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3122,3,"['error', 'fault']","['error', 'faulty']"
Availability,"F file consists of 12 chromosomes but the output shows only one chromosome. Could you please help me out.; OS:-Ubuntu 20.04; GATK version:-4.1.9.0; Java:-open jdk version 11.0.8; Command:-gatk VariantsToTable -R '/home/india/Downloads/Reference.fasta' -V '/home/india/Downloads/Galaxy57-[Merged_file.vcf].vcf' -F CHROM -F POS -F REF -F ALT -GF AD -GF DP -GF GQ -GF PL -O bothbulks_new.table. Using GATK jar /home/india/Downloads/gatk-4.1.9.0/gatk-package-4.1.9.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /home/india/Downloads/gatk-4.1.9.0/gatk-package-4.1.9.0-local.jar VariantsToTable -R /home/india/Downloads/Reference.fasta -V /home/india/Downloads/Galaxy57-[Merged_file.vcf].vcf -F CHROM -F POS -F REF -F ALT -GF AD -GF DP -GF GQ -GF PL -O bothbulks_new.table; 16:46:03.294 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/india/Downloads/gatk-4.1.9.0/gatk-package-4.1.9.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Oct 16, 2020 4:46:04 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 16:46:04.315 INFO VariantsToTable - ------------------------------------------------------------; 16:46:04.316 INFO VariantsToTable - The Genome Analysis Toolkit (GATK) v4.1.9.0; 16:46:04.316 INFO VariantsToTable - For support and documentation go to https://software.broadinstitute.org/gatk/; 16:46:04.317 INFO VariantsToTable - Executing as india@india-HP-ProBook-445-G1 on Linux v5.4.0-26-generic amd64; 16:46:04.317 INFO VariantsToTable - Java runtime: OpenJDK 64-Bit Server VM v11.0.8+10-post-Ubuntu-0ubuntu120.04; 16:46:04.317 INFO VariantsToTable - Start Date/Time: 16 October 2020 at 4:46:02 PM IST; 16:46:04.318 INFO VariantsToTable - ------------------------------------------------------------; 16:",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6897:1062,Down,Downloads,1062,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6897,1,['Down'],['Downloads']
Availability,"FO IntelPairHmm - Available threads: 8; 08:33:37.707 INFO IntelPairHmm - Requested threads: 4; 08:33:37.707 INFO PairHMM - Using the OpenMP multi-threaded AVX-accelerated native PairHMM implementation; 08:33:37.708 INFO ProgressMeter - Starting traversal; 08:33:37.708 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x00007ff7b7dfe32d, pid=849, tid=0x00007ff82e11d700; #; # JRE version: OpenJDK Runtime Environment (8.0_242-b08) (build 1.8.0_242-8u242-b08-0ubuntu3~18.04-b08); # Java VM: OpenJDK 64-Bit Server VM (25.242-b08 mixed mode linux-amd64 compressed oops); # Problematic frame:; # C [libgkl_smithwaterman5951765478004985534.so+0x132d] smithWatermanBackTrack(dnaSeqPair*, int, int, int, int, int*, int)+0x1bd; #; # Failed to write core dump. Core dumps have been disabled. To enable core dumping, try ""ulimit -c unlimited"" before starting Java again; #; # An error report file with more information is saved as:; # /home/gatk/hs_err_pid849.log; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; # The crash happened outside the Java Virtual Machine in native code.; # See problematic frame for where to report the bug.; #; ```. **RELEVANT FILES**; [hs_err_pid100.log](https://github.com/broadinstitute/gatk/files/6203288/hs_err_pid100.log); [hs_err_pid164.log](https://github.com/broadinstitute/gatk/files/6203289/hs_err_pid164.log); [hs_err_pid274.log](https://github.com/broadinstitute/gatk/files/6203290/hs_err_pid274.log); [hs_err_pid400.log](https://github.com/broadinstitute/gatk/files/6203291/hs_err_pid400.log); [hs_err_pid482.log](https://github.com/broadinstitute/gatk/files/6203292/hs_err_pid482.log); [hs_err_pid711.log](https://github.com/broadinstitute/gatk/files/6203293/hs_err_pid711.log); [hs_err_pid735.log](https://github.com/broadinstitute/gatk/files/6203294/hs_err_pid735.lo",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7162:6117,error,error,6117,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7162,1,['error'],['error']
Availability,"FO SparkUI: Stopped Spark web UI at http://xx.xx.xx.16:4040; 18/04/24 17:56:39 INFO StandaloneSchedulerBackend: Shutting down all executors; 18/04/24 17:56:39 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down; 18/04/24 17:56:39 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 18/04/24 17:56:39 INFO MemoryStore: MemoryStore cleared; 18/04/24 17:56:39 INFO BlockManager: BlockManager stopped; 18/04/24 17:56:39 INFO BlockManagerMaster: BlockManagerMaster stopped; 18/04/24 17:56:39 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 18/04/24 17:56:39 INFO SparkContext: Successfully stopped SparkContext; 17:56:39.758 INFO PathSeqPipelineSpark - Shutting down engine; [April 24, 2018 5:56:39 PM CEST] org.broadinstitute.hellbender.tools.spark.pathseq.PathSeqPipelineSpark done. Elapsed time: 1.75 minutes.; Runtime.totalMemory()=821559296; org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 2.0 failed 4 times, most recent failure: Lost task 1.3 in stage 2.0 (TID 10, xx.xx.xx.16, executor 3): org.broadinstitute.hellbender.exceptions.UserException$CouldNotReadInputFile: Couldn't read file. Error was: hg19mini.hss with exception: hg19mini.hss (No such file or directory); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:112); at org.broadinstitute.hellbender.tools.spark.pathseq.PSKmerUtils.readKmerFilter(PSKmerUtils.java:131); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilter.<init>(ContainsKmerReadFilter.java:27); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:35); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:15); at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78); at org.apache.spark.api.java.JavaRDD$$anonfun$filte",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4699:38327,failure,failure,38327,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4699,1,['failure'],['failure']
Availability,"FO SparkUI: Stopped Spark web UI at http://xx.xx.xx.xx:4040; 18/04/23 20:42:02 INFO StandaloneSchedulerBackend: Shutting down all executors; 18/04/23 20:42:02 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down; 18/04/23 20:42:03 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 18/04/23 20:42:03 INFO MemoryStore: MemoryStore cleared; 18/04/23 20:42:03 INFO BlockManager: BlockManager stopped; 18/04/23 20:42:03 INFO BlockManagerMaster: BlockManagerMaster stopped; 18/04/23 20:42:03 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 18/04/23 20:42:03 INFO SparkContext: Successfully stopped SparkContext; 20:42:03.045 INFO PathSeqPipelineSpark - Shutting down engine; [April 23, 2018 8:42:03 PM CEST] org.broadinstitute.hellbender.tools.spark.pathseq.PathSeqPipelineSpark done. Elapsed time: 0.43 minutes.; Runtime.totalMemory()=793247744; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 0.0 failed 4 times, most recent failure: Lost task 0.3 in stage 0.0 (TID 3, xx.xx.xx.xx, executor 0): java.lang.IllegalStateException: unread block data; at java.io.ObjectInputStream$BlockDataInputStream.setBlockDataMode(ObjectInputStream.java:2740); at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1567); at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245); at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169); at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027); at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535); at java.io.ObjectInputStream.readObject(ObjectInputStream.java:422); at org.apache.spark.serializer.JavaDeserializationStream.readObject(JavaSerializer.scala:75); at org.apache.spark.serializer.JavaSerializerInstance.deserialize(JavaSerializer.scala:114); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:309); at java.util.con",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694:17595,failure,failure,17595,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694,1,['failure'],['failure']
Availability,"FOR_SAMTOOLS : false; 04:59:43.046 INFO ApplyBQSR - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 04:59:43.046 INFO ApplyBQSR - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 04:59:43.046 INFO ApplyBQSR - Deflater: IntelDeflater; 04:59:43.046 INFO ApplyBQSR - Inflater: IntelInflater; 04:59:43.046 INFO ApplyBQSR - GCS max retries/reopens: 20; 04:59:43.046 INFO ApplyBQSR - Requester pays: disabled; 04:59:43.047 INFO ApplyBQSR - Initializing engine; WARNING: BAM index file /scratch/ddo/markedsam/C18-436P.sort.rmdup.bam.bai is older than BAM /scratch/ddo/markedsam/C18-436P.sort.rmdup.bam; 04:59:43.556 INFO ApplyBQSR - Done initializing engine; 04:59:43.592 WARN ApplyBQSR - This tool has only been well tested on ILLUMINA-based sequencing data. For other data use at your own risk.; 04:59:43.592 INFO ProgressMeter - Starting traversal; 04:59:43.592 INFO ProgressMeter - Current Locus Elapsed Minutes Reads Processed Reads/Minute; 04:59:45.014 INFO ApplyBQSR - Shutting down engine; [November 8, 2021 at 4:59:45 a.m. PST] org.broadinstitute.hellbender.tools.walkers.bqsr.ApplyBQSR done. Elapsed time: 0.05 minutes.; Runtime.totalMemory()=557842432; java.lang.IllegalStateException: **The covariates table is missing ReadGroup V300019285_L2_ in RecalTable0**; 	at org.broadinstitute.hellbender.utils.Utils.validate(Utils.java:750); 	at org.broadinstitute.hellbender.utils.recalibration.covariates.ReadGroupCovariate.keyForReadGroup(ReadGroupCovariate.java:81); 	at org.broadinstitute.hellbender.utils.recalibration.covariates.ReadGroupCovariate.recordValues(ReadGroupCovariate.java:53); 	at org.broadinstitute.hellbender.utils.recalibration.covariates.StandardCovariateList.recordAllValuesInStorage(StandardCovariateList.java:133); 	at org.broadinstitute.hellbender.utils.recalibration.RecalUtils.computeCovariates(RecalUtils.java:546); 	at org.broadinstitute.hellbender.utils.recalibration.RecalUtils.computeCovariates(RecalUtils.java:527); 	at org.broadinstitute.hellbender.tr",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7549:3184,down,down,3184,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7549,1,['down'],['down']
Availability,Failure Serializing Reference in HaplotypeCallerSpark,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6341:0,Failure,Failure,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6341,1,['Failure'],['Failure']
Availability,Failure on SparkGenomeReadCounts (addProbabilisticSplits),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2113:0,Failure,Failure,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2113,1,['Failure'],['Failure']
Availability,Failure returns exist status 0 (i.e. success),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/342:0,Failure,Failure,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/342,1,['Failure'],['Failure']
Availability,"Failure using samtools-generated .idx/.dict when reference has ambiguity code "".""",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3306:0,Failure,Failure,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3306,1,['Failure'],['Failure']
Availability,Failure with missing host and port in --knownSites for HDFS on GCP,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3468:0,Failure,Failure,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3468,1,['Failure'],['Failure']
Availability,"Failures now include the url:. `org.broadinstitute.hellbender.exceptions.UserException: Invalid request https://htsget.ga4gh.org/reads/A1-B000168-3_57_F-1-1_R2.mus.Aligned.out.sorted.bam?referenceName=chr1&start=23999999&end=25000000, received error code: 404, error type: NotFound, message: The requested resource could not be associated with a registered data source; `",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6799:0,Failure,Failures,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6799,3,"['Failure', 'error']","['Failures', 'error']"
Availability,Feature support: stripped-down replacement for the old GATK ROD system,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/224:26,down,down,26,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/224,1,['down'],['down']
Availability,"FeatureManager dynamically discovers all `FeatureInput` arguments in a tool by accepting a (pre-populated) CommandLineProgram object, which it then passes to static methods in Barclay. Those methods perform the same `@Argument`/`@ArgumentCollection` discovery already implemented by the parser, but using separate, out-of-date code paths that currently don't discover `@PositionalArguments` or plugin descriptor arguments. Rather than fixing the redundant code paths and static methods in Barclay, they can be eliminated and replaced with an instance method on the parser. Since FeatureManager already requires that the parser have been run on the tool, the parser already has the state necessary to just collect the results. However, this means that FeatureManager would require a CommandLineParser object instead of the tool itself. (Alternatively, we could extract the results from the parser and pass them in directly to FeatureManager instead of the parser). @droazen do you have any opinion on this before I refactor this part of the parser ?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4480:446,redundant,redundant,446,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4480,1,['redundant'],['redundant']
Availability,FilterAlignmentArtifacts Invalid Intervals and Segmentation Faults,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6344:60,Fault,Faults,60,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6344,1,['Fault'],['Faults']
Availability,FilterAlignmentArtifacts error,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7247:25,error,error,25,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7247,1,['error'],['error']
Availability,FilterByOrientationBias gives random failures,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3291:37,failure,failures,37,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3291,1,['failure'],['failures']
Availability,FilterFuncotations Duplicate key error,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7504:33,error,error,33,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7504,1,['error'],['error']
Availability,"FilterFuncotations Error, ShouldNeverReachHereException, FuncotationMap",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7865:19,Error,Error,19,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7865,1,['Error'],['Error']
Availability,"FilterMutectCalls ""Duplicate key"" error",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6996:34,error,error,34,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6996,1,['error'],['error']
Availability,FilterMutectCalls : errorRate must be good probability but got NaN,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6058:20,error,errorRate,20,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6058,1,['error'],['errorRate']
Availability,"FilterMutectCalls failed with ; ```; java.lang.IllegalArgumentException: beta must be greater than 0 but got -87566.7500301585; ```; ""this error only comes after the first pass of filtermutectCalls completed."". ValidateVarinats shows no errors when run on VCF.; ""The stats file was created by mutect2 for each shard and then joined with MergeMutectStats. Similar the read orientation model was built with the f1r2 files from all shards."". @davidbenjamin. --------------; Hi there,. I have a simulated dataset of related samples and currently running Mutect2 on it (10 tumor samples WGS with 130x); I managed to run everything through and now FilterMutectCalls crashes after the first pass through the variants with. ```; [October 1, 2019 12:16:16 PM UTC] org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls done. Elapsed time: 370.68 minutes.; Runtime.totalMemory()=20597702656; java.lang.IllegalArgumentException: beta must be greater than 0 but got -87566.7500301585; at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:724); at org.broadinstitute.hellbender.tools.walkers.readorientation.BetaDistributionShape.<init>(BetaDistributionShape.java:14); at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.BinomialCluster.getFuzzyBinomial(BinomialCluster.java:42); at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.BinomialCluster.learn(BinomialCluster.java:33); at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.lambda$learnAndClearAccumulatedData$7(SomaticClusteringModel.java:131); at org.broadinstitute.hellbender.utils.IndexRange.forEach(IndexRange.java:116); at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.learnAndClearAccumulatedData(SomaticClusteringModel.java:131); at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.learnParameters(Mutect2FilteringEngine.java:156); at org.broadinstitute.hellbender.tools.wa",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6202:139,error,error,139,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6202,2,['error'],"['error', 'errors']"
Availability,FilterMutectCalls in 4.2.0.0 has an error with AS_UNIQ_ALT_READ_COUNT annotation format,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7298:36,error,error,36,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7298,1,['error'],['error']
Availability,FilterMutectCalls: Error initializing feature reader,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7114:19,Error,Error,19,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7114,1,['Error'],['Error']
Availability,FilterMutectCalls: errorRate must be good probability but got NaN,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5821:19,error,errorRate,19,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5821,1,['error'],['errorRate']
Availability,FilterVariantTranches error with version 4.1.8.0,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6701:22,error,error,22,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6701,1,['error'],['error']
Availability,"Find out if there's a way to disable this awful behavior via `SamReaderFactory` -- if not, let's patch htsjdk itself to turn off reference auto-downloading by default.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/677:144,down,downloading,144,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/677,1,['down'],['downloading']
Availability,"First commit:; -Added CreateReadCountPanelOfNormals tool. This is an update of CreatePanelOfNormals. Related code is written from scratch.; -Added DenoiseReadCounts tool. This is an update of NormalizeSomaticReadCounts. Related code is written from scratch.; -Added AnnotateIntervals tool. This is an update of AnnotateTargets. Related code (e.g., GCBiasCorrector) is mostly ported and does not have to be closely re-reviewed. I naively introduced RecordCollection and LocatableCollection classes that are analogous to SampleRecordCollection and SampleLocatableCollection, respectively, for collections that are not tied to a sample (e.g., GC-content annotations); we can go back and refactor these classes later.; -SVDDenoisingUtils contains many package-private helper methods for filtering and denoising without unit tests. This is intentional. I have verified that this code exactly reproduces the old PoN results down to the 1E-16 level (with the discrepancy coming from the removal of redundant pseudoinverse operations). Rather than writing or porting unit tests for this code, I think it is best if we simply do not reuse this code or make non-trivial changes to it going forward. We can add unit tests later if we have extra time on our hands...; -SparkGenomeReadCounts now outputs TSV and HDF5.; -Added some tests for SimpleCountCollection, HDF5SimpleCountCollection, and some disabled tests for HDF5Utils.; -Miscellaneous cleanup and boy scout activities. Second commit:; -Updated coverage collection in germline and legacy somatic CNV WDLs to use only integer read counts and account for changes to SparkGenomeReadCounts.; -Added tasks for PreprocessIntevals, AnnotateIntervals, and CollectFragmentCounts.; -Renamed and moved some files. Closes #3570.; Closes #3356.; Closes #3349.; Closes #3246.; Closes #3153.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3820:918,down,down,918,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3820,2,"['down', 'redundant']","['down', 'redundant']"
Availability,First it does not complain that the file does not exists but when you request the getReadsHeader() it results in a deep down NPE exception. The fact that the walker requires reads does not help either.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2541:120,down,down,120,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2541,1,['down'],['down']
Availability,"First of all, thank you so much for your hard work! I am excited to explore GATK 4.0.0.0.; I would like to report minor issues in setting up optional dependencies for GATK4. First, `gatkcondaenv.yml` defines `gatkPythonPackageArchive.zip` location as; `build/gatkPythonPackageArchive.zip`; The path doesn't seem to work seamlessly with the release archive, though the path makes sense in the root directory of source repo. Unzipping the package file locates both files in the same directory and, to me, it is natural to create the conda environment in the directory. Second, it would be more convenient to include `install_R_packages.R` in the release like gatkcondaenv.yml for python dependencies. Also, I had an issue running `install_R_packages.R` for fresh compiled R-3.2.5. The way `install_R_packages.R` install `optparse` prevents its dependency (the getopt package) from being automatically installed, because (I guess) repos argument is set to NULL. I think the helper script needs to install the getopt package as well.; ```; optparseUrl=""http://cran.r-project.org/src/contrib/Archive/optparse/optparse_1.3.2.tar.gz""; if (!(""optparse"" %in% rownames(installed.packages()))) {; install.packages(optparseUrl, repos=NULL, type=""source""); }; ```. Finally, it would be convenient to depend on a R version available in conda, so that R dependency can be a part of the gatk conda environment. I wasn't able to get the recommended R-3.2.5 from conda.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4209:1309,avail,available,1309,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4209,1,['avail'],['available']
Availability,Fix GenomeLocParser error reporting.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2191:20,error,error,20,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2191,1,['error'],['error']
Availability,Fix compile error in test.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6483:12,error,error,12,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6483,1,['error'],['error']
Availability,Fix copy/paste errors with Docker image variable names,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8474:15,error,errors,15,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8474,1,['error'],['errors']
Availability,Fix dataproc failures in broad-gatk-test,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1611:13,failure,failures,13,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1611,1,['failure'],['failures']
Availability,Fix deprecation-related errors.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2354:24,error,errors,24,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2354,1,['error'],['errors']
Availability,Fix error in genotype given alleles mode when input alleles have genotypes,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5341:4,error,error,4,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5341,1,['error'],['error']
Availability,Fix error(s) in InfiniteRandomMatingPopulationModel,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1856:4,error,error,4,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1856,1,['error'],['error']
Availability,"Fix for https://github.com/broadinstitute/gatk/issues/5511, intermittent LeftAlignAndTrimVariants unit tests failures.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5519:109,failure,failures,109,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5519,1,['failure'],['failures']
Availability,Fix intermittent failure in StreamingProcessControllerUnitTest code.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4015:17,failure,failure,17,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4015,1,['failure'],['failure']
Availability,Fix intermittent gradle out-of-memory errors in travis,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1113:38,error,errors,38,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1113,1,['error'],['errors']
Availability,Fix minor typos and a format error in README.md,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3111:29,error,error,29,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3111,1,['error'],['error']
Availability,Fix naming errors in script and added the ability to specify the temp directory for Hail.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8487:11,error,errors,11,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8487,1,['error'],['errors']
Availability,Fix stack trace error message.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3307:16,error,error,16,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3307,1,['error'],['error']
Availability,Fix test errors in PathSeqScoreIntegrationTest,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3910:9,error,errors,9,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3910,1,['error'],['errors']
Availability,Fix two bugs in multiple alignment assembly contig classification:; 1. arguments passed in wrong order leading to wrong contigs being filtered out and wrong contigs being sent to call variants; 2. copy-paste error in detecting reference order switch between head/tail alignments (predicate essentially always return true). Added tests.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3871:208,error,error,208,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3871,1,['error'],['error']
Availability,FixCallSetSampleOrdering: support repairing callsets in which the sample in the file headers did not match the samples given to GenomicsDBImport,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3868:34,repair,repairing,34,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3868,1,['repair'],['repairing']
Availability,Fixed Mutect failure for germline resource without AF,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4607:13,failure,failure,13,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4607,1,['failure'],['failure']
Availability,Fixed RAM usage parameter error in unsupported combine_tracks.wdl.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5358:26,error,error,26,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5358,1,['error'],['error']
Availability,Fixed SplitNCigarReads ArrayIndexOutOfBounds error for short reads with deletions,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5285:45,error,error,45,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5285,1,['error'],['error']
Availability,Fixed an error message in SVD utils,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6608:9,error,error,9,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6608,1,['error'],['error']
Availability,Fixed bug #355.; The problem was that reads and reference file had incompatible sequence dictionaries. ; @jean-philippe-martin please review and confirm that the NPE is fixed. @lbergelson please review for merging. . The result now is something like this:; `A USER ERROR has occurred: Contig chr1 not present in the sequence dictionary [17]`,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/357:265,ERROR,ERROR,265,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/357,1,['ERROR'],['ERROR']
Availability,Fixed bug in download metrics script.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8418:13,down,download,13,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8418,1,['down'],['download']
Availability,Fixed error in FilterIntervals logic when filtering on annotations with -XL.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7046:6,error,error,6,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7046,1,['error'],['error']
Availability,Fixed errors in the GVCF extension for IndexFeatureFile,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2163:6,error,errors,6,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2163,1,['error'],['errors']
Availability,"Fixes #4274 and #4303. Relies on https://github.com/HadoopGenomics/Hadoop-BAM/pull/194, so this won't pass (and shouldn't be merged) until a new release of Hadoop-BAM is available.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4463:170,avail,available,170,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4463,1,['avail'],['available']
Availability,"Fixes #4739; Refactored UTR VariantClassification handling.; Added warning statement when a transcript in the UTR has no sequence info (now is the same behavior as in protein coding regions).; Added tests to prevent regression on data source date comparison bug.; Now can run on large data.; Fixed DNA Repair Genes getter script.; Fixed an issue in COSMIC to make it robust to bad COSMIC data.; Gencode no longer crashes when given an indel that starts just before an exon.; Fixed the SimpleKeyXsvFuncotationFactory to allow any characters to work as delimiters (including characters used in regular expressions, such as pipes).; Modified several methods to allow for negative start positions in; preparation for allowing indels that start outside exons.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4817:302,Repair,Repair,302,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4817,2,"['Repair', 'robust']","['Repair', 'robust']"
Availability,"Fixes #7068 . - When adding AC, AF, AN, DP header lines, SelectVariants now checks if these lines are in the original header already and if so, overwrites these lines with the respective standard lines; - Without this check, an issue in htsjdk causes duplicate header lines with the same ID if the description differs. This should be fixed there but this fix provides a downstream workaround; - Modified the integration test validation files, which have been invalid VCF files with duplicate header lines; - Removed addition of AC, AF, AN if `--set-filtered-gt-to-nocall` is set, because these lines will be added later anyway",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7069:370,down,downstream,370,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7069,1,['down'],['downstream']
Availability,Fixes a ArrayIndexOutOfBound exception into a more informative error message …,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4847:63,error,error,63,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4847,1,['error'],['error']
Availability,"Fixes a bug that I inadvertently introduced long ago in #5408. A method there originally assumed that the intervals to be filtered coincide with the annotated intervals when filtering on annotations, but this assumption can be violated when e.g. using `-XL` to further exclude intervals. This breaks the annotation-based filtering and will result in incorrectly retained/dropped intervals. Unfortunately, the integration test cases were not quite complete enough to catch this. Fortunately, for typical data and parameters, the number of affected intervals is typically a very small percentage, especially in human (e.g., the default GC filters of [0.1, 0.9] affect <0.1% of 250bp bins); I only caught this when running on malaria data, since GC filtering has more impact there. I would also expect count-based filters to mitigate some of the effects (e.g., a bin with extreme GC that was erroneously retained when filtering on annotations might later be filtered because it has poor coverage). Downstream results are also all correct---they're just given for a slightly different set of intervals than would be expected. This bug would affect users that made use of the `blacklist_intervals_for_filter_intervals` option in the gCNV WDLs, but my feeling is this functionality is not used that frequently. @droazen I think this is a relatively minor bug, but it might be good to mention it in the release notes.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7046:995,Down,Downstream,995,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7046,1,['Down'],['Downstream']
Availability,"Fixes a bug that was exposed in https://gatk.broadinstitute.org/hc/en-us/community/posts/360075631171-BQSR-no-output-table-found. The issue is that bytes are signed in java, and yet we were treating them as unsigned and directly indexing an array with them.....this works as long as you don't have weird characters in your bam/reference...but if you do you get an access error that is non-informative.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7010:371,error,error,371,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7010,1,['error'],['error']
Availability,"Fixes broken docker image pull that throws an error:; ```; docker pull broadinstitute/genomes-in-the-cloud:2.1.1; 2.1.1: Pulling from broadinstitute/genomes-in-the-cloud; [DEPRECATION NOTICE] Docker Image Format v1 and Docker Image manifest version 2, schema 1 support is disabled by default and will be removed in an upcoming release. Suggest the author of docker.io/broadinstitute/genomes-in-the-cloud:2.1.1 to upgrade the image to the OCI Format or Docker Image manifest v2, schema 2. More information at https://docs.docker.com/go/deprecated-image-specs/. ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8891:46,error,error,46,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8891,1,['error'],['error']
Availability,"Fixes failures caused by 1) sample names containing `@`, which pandas interprets as a midline comment character, and 2) cohorts where all samples have numerical names, in which case leading zeros may be stripped when pandas infers the column dtype to be int. Added some commits to address a few more issues. Closes #5778. Closes #5809.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5811:6,failure,failures,6,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5811,1,['failure'],['failures']
Availability,Fixes for IndexFeatureFile error reporting.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6367:27,error,error,27,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6367,1,['error'],['error']
Availability,"Fixes https://github.com/broadinstitute/gatk/issues/4014. This test uses python to test the controller, and was not properly synchronizing on all commands before asserting the results, leading to intermittent timing-dependent failures.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4015:226,failure,failures,226,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4015,1,['failure'],['failures']
Availability,"Fixes https://github.com/broadinstitute/gatk/issues/4024. The timeout for this test was relatively short, and we hit it once in travis, so lengthen it a lot to ensure we don't get random failures. Also removed a couple of unreferenced lines of code.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4028:187,failure,failures,187,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4028,1,['failure'],['failures']
Availability,"Fixes https://github.com/broadinstitute/gatk/issues/4768. The ReservoirDownsampler currently declares reads to be finalized immediately after they're submitted, but in order to guaranty that every read has equal probability of being discarded, it should consume the entire stream of input items before declaring any item to be finalized. When used with a ReadsDownsamplingIterator, no reads are ever downsampled because the iterator populates it's internal cache by eagerly consuming finalized reads as soon as they become available. Also, PositionalDownsampler doesn't reset it's internal ReservoirDownsampler's state correctly.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5594:400,down,downsampled,400,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5594,2,"['avail', 'down']","['available', 'downsampled']"
Availability,"Fixes https://github.com/broadinstitute/gatk/issues/5065. This test verifies that we receive output written to Python's stderr, but it fails occasionally due to an inherent race condition in the assert (occasionally the assert executes before the data is received and the test fails). I added a Python statement that explicitly flushes stderr first, and ran the test 1000 times and it still failed once for the same reason. Since I don't see any way to have a reliable test condition (that doesn't involve polling inside a loop and a long timeout), I'm just removing the test.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5097:460,reliab,reliable,460,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5097,1,['reliab'],['reliable']
Availability,"Fixes https://github.com/broadinstitute/gatk/issues/5336. `HaplotypeCallerGenotypingEngine.replaceWithSpanDelVC` replaces the given alleles `VariantContext` objects with new VCs in which the alleles have been replaced with star alleles to represent spanning deletions. However, if the input variant records had genotypes, the original (non-star) deletion alleles were still being retained, causing a downstream error. This fixes that issue.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5341:400,down,downstream,400,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5341,2,"['down', 'error']","['downstream', 'error']"
Availability,Fixes memory leaks due to failure to free C side resources when an index is closed.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3723:26,failure,failure,26,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3723,1,['failure'],['failure']
Availability,Fixes rounding errors in FS using the same solution as R,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2629:15,error,errors,15,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2629,1,['error'],['errors']
Availability,Fixing LoadData error discovered in delcho run,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8556:16,error,error,16,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8556,1,['error'],['error']
Availability,Fixing README.md to reflect current Git LFS download size as approximately 5 GB. Fixes #6932,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6933:44,down,download,44,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6933,1,['down'],['download']
Availability,Fixing error when spanning deletions overlap coding regions,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4881:7,error,error,7,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4881,1,['error'],['error']
Availability,Fixing the path reported by the gatkbot when there are test failures,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8069:60,failure,failures,60,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8069,1,['failure'],['failures']
Availability,"Following the instructions to build from the main readme, `./gradlew bundle` and `./gradlew clean` ends with these error messages:; ```; ...; Download https://repo1.maven.org/maven2/commons-codec/commons-codec/1.6/commons-codec-1.6.jar; Executing: git lfs pull --include src/main/resources/large. FAILURE: Build failed with an exception. * Where:; Build file '/gatk/build.gradle' line: 105. * What went wrong:; A problem occurred evaluating root project 'gatk'.; > Execution of ""git lfs pull --include src/main/resources/large"" failed with exit code: 1. git-lfs is required to build GATK but may not be installed. See https://github.com/broadinstitute/gatk#building for information on how to build GATK. * Try:; Run with --stacktrace option to get the stack trace. Run with --info or --debug option to get more log output.; ```. The build is being attempted in a docker container in a 64-bit ubuntu VM on a Win10 host. What am I doing wrong?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6019:115,error,error,115,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6019,3,"['Down', 'FAILURE', 'error']","['Download', 'FAILURE', 'error']"
Availability,"Following up on a [forum thread](https://gatk.broadinstitute.org/hc/en-us/community/posts/4493905884699/comments/4682115320731) reporting a runtime compile error for gCNV:; ```; Exception: ('Compilation failed (return status=1): collect2: error: ld returned 1 exit status. ', '[Elemwise{second,no_inplace}(v, <TensorType(float64, (True,))>)]'); 19:40:38.193 INFO GermlineCNVCaller - Shutting down engine; ```; which could be fixed by explicitly setting the home and tmp directories. This is a pervasive issue in WDLs, as these directories are set by the OS. It is known that when running in Cromwell on GCP, tmp is by default on the boot disk and should be overridden for any tasks that use temporary storage.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7722:156,error,error,156,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7722,3,"['down', 'error']","['down', 'error']"
Availability,"For @davidbenjamin. I am using the beta.3 stable jar. The data was generated in the Cloud using the WDL script commands from the repo and tool defaults. @vdauwera can share the workspace with you so you can see the actual workflow and download the callsets. Here are the five calls with untrimmed REF allele representations from my WES callset:; ```; WMCF9-CB5:8640dac1_waf_wpon shlee$ gzcat other_waf_wpon.vcf.gz | grep -v '#' | less; chr2 38856503 . CT TT . germline_risk;panel_of_normals DP=78;ECNT=1;IN_PON;NLOD=2.87;N_ART_LOD=-2.323e-01;POP_AF=1.000e-03;P_GERMLINE=-1.812e-01;TLOD=6.41 GT:AD:AF:MBQ:MCL:MFRL:MMQ:MPOS:OBAM:OBAMRC:SA_MAP_AF:SA_POST_PROB 0/0:24,4:0.213:13,19:0,0:215,172:60,60:8,8:false:false 0/1:30,8:0.249:0,23:0,0:0,183:0,47:0,12:false:false:0.495,0.00,0.500:0.025,0.028,0.947; chr2 99390427 . GT TT . panel_of_normals;t_lod DP=120;ECNT=2;IN_PON;NLOD=6.15;N_ART_LOD=-3.396e-01;POP_AF=2.719e-04;P_GERMLINE=-4.564e+00;TLOD=4.89 GT:AD:AF:MBQ:MCL:MFRL:MMQ:MPOS:OBAM:OBAMRC:SA_MAP_AF:SA_POST_PROB 0/0:58,5:0.136:25,31:0,0:211,240:60,60:22,20:false:false 0/1:39,6:0.186:26,31:0,0:235,216:60,60:22,26:false:false:0.202,0.00,0.200:0.011,0.053,0.936; chr7 65961067 . CAAA AAAA . base_quality;panel_of_normals;t_lod DP=178;ECNT=1;IN_PON;NLOD=15.64;N_ART_LOD=-8.858e-01;POP_AF=1.000e-03;P_GERMLINE=-1.452e+01;TLOD=3.82 GT:AD:AF:MBQ:MCL:MFRL:MMQ:MPOS:OBAM:OBAMRC:SA_MAP_AF:SA_POST_PROB 0/0:75,9:0.211:20,2:0,0:169,181:60,60:22,12:false:false 0/1:42,12:0.281:26,5:0,0:155,168:60,60:21,21:false:false:0.253,0.00,0.250:0.011,0.068,0.921; chr10 26536222 . GAAA AAAA . artifact_in_normal;base_quality;panel_of_normals DP=385;ECNT=1;IN_PON;NLOD=7.23;N_ART_LOD=2.38;POP_AF=1.000e-03;P_GERMLINE=-3.938e+00;TLOD=7.64 GT:AD:AF:MBQ:MCL:MFRL:MMQ:MPOS:OBAM:OBAMRC:SA_MAP_AF:SA_POST_PROB 0/0:75,18:0.241:14,6:0,0:169,221:60,60:21,18:false:false 0/1:187,45:0.241:19,8:0,0:134,190:60,60:24,17:false:false:0.111,0.00,0.108:9.821e-04,0.663,0.336; chr20 34445260 . GT TT . germline_risk;panel_of_normals DP=55;",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3506:235,down,download,235,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3506,1,['down'],['download']
Availability,For GATK4 docs. Should add in ApplyVQSR webpage when available.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2781:53,avail,available,53,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2781,1,['avail'],['available']
Availability,"For compatibility with long reads, if we will become interested in supporting their features down the road. Otherwise, please take this ticket as informational. New aligner by Heng Li, Minimap2, has option to emit `CG` tag containing full CIGAR string for long reads that would have >65535 CIGAR operations. This is for BAM compatibility. My understanding is that in such cases, the CIGAR field would then contain only clipping information. Minimap2 will also have the option to emit a `CS` tag, encoding bases at mismatches and INDELs. This mapper is originally intended for long read mapping, e.g. at the scale of PacBio and Oxford Nanopore (ONT), where it is ~ten times faster than BWA-MEM and other conventional mappers for ~10kb noisy reads. **The mapper is also currently compatible with >100 base reads, either genomic (DNA) or spliced nucleotide (RNA) and for these, is three times faster than BWA-MEM and Bowtie2.** . See <https://github.com/lh3/minimap2> for details and <https://arxiv.org/pdf/1708.01492.pdf> for the preprint.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3799:93,down,down,93,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3799,1,['down'],['down']
Availability,"For discussion with @LeeTL1220 @samuelklee @mbabadi @vruano. ---; ### CreatePanelOfNormals gives unexpected error; Running CNV's CreatePanelOfNormals on forty 1000 Genomes Project WES samples using conservatively derived and padded target intervals (189,493 targets). Tool gives the following error. ```; Using GATK jar /usr/shlee/gatk-4.alpha.2-1134-ga9d9d91-SNAPSHOT/gatk-package-4.alpha.2-1134-ga9d9d91-SNAPSHOT-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -Dsnappy.disable=true -Xmx16g -jar /usr/shlee/gatk-4.alpha.2-1134-ga9d9d91-SNAPSHOT/gatk-package-4.alpha.2-1134-ga9d9d91-SNAPSHOT-local.jar CreatePanelOfNormals -I shlee-dev/CNV/1kgmix_gccorrect_pon/CreateCNVPon/95bf88a5-c5aa-45eb-9178-efc7d5c75946/call-CombineReadCounts/String_combinedcoverage.tsv -O String.pon --disableSpark; Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/cromwell_root/tmp; [June 23, 2017 6:54:00 PM UTC] CreatePanelOfNormals --input shlee-dev/CNV/1kgmix_gccorrect_pon/CreateCNVPon/95bf88a5-c5aa-45eb-9178-efc7d5c75946/call-CombineReadCounts/String_combinedcoverage.tsv --output String.pon --disableSpark true --minimumTargetFactorPercentileThreshold 25.0 --maximumColumnZerosPercentage 2.0 --maximumTargetZerosPercentage 5.0 --extremeColumnMedianCountPercentileThreshold 2.5 --truncatePercentileThreshold 0.1 --numberOfEigensamples auto --noQC false --dryRun false --sparkMaster local[*] --help false --version false --showHidden false --verbosity INFO --QUIET false --use_jdk_deflater false --use_jdk_inflater false; [June 23, 2017 6:54:00 PM UTC] Executing as root@b4f42b5ba157 on Linux 4.9.0-0.bpo.3-amd64 amd64; OpenJDK 64-Bit Server VM 1.8.0_91-8u91-b14-1~bpo8+1-b14; Version: 4.alpha.2-1134-ga9d9d91-SNAPSHOT; log4j:WARN No appenders could be found for logger (org.broadinstitute.hdf5.HDF5Library).; log4j:WARN Please initialize the log4j system properly.; log4j:WARN See http://l",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3163:108,error,error,108,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3163,2,['error'],['error']
Availability,"For discussion with @davidbenjamin. Conversation will benefit Mutect2 workflow documentation. The Mutect2 WDL pipeline at <https://github.com/broadinstitute/gatk/blob/master/scripts/mutect2_wdl/mutect2.wdl> uses the following:. 1. SplitIntervals in default mode (clarified in #3032 that default INTERVAL_SUBDIVISION mode can cut into an interval in the intervals list); ```; java -jar $GATK_JAR SplitIntervals -R ${ref_fasta} ${""-L "" + intervals} -scatter ${scatter_count} -O interval-files; cp interval-files/*.intervals .; ```; 2. Scatter Mutect2 over files of intervals; ```; scatter (subintervals in SplitIntervals.interval_files ) {; call M2 {; ```; 3. MergeVCFs to collate the resulting VCF callsets; ```; java -Xmx2g -jar $GATK_JAR MergeVcfs -I ${sep=' -I ' input_vcfs} -O ${output_vcf_name}.vcf; ```. Assuming Mutect2 handles active regions in the same manner as HaplotypeCaller, which will expand/pad active regions, then a consequence of the current workflow is potential _duplicate calls_ (that can also differ slightly from each other e.g. due to rounding) for the same genomic locus that result from expansion of the active region into the edges of the intervals being split. MergeVCFs as well as GatherVCFs, allows duplicate calls in the final VCF without checks. GatherVCFs does not allow for out-of-genomic-order-inputs and will give an error. However, I'm noticing something interesting (see below). I would recommend creating intervals without splitting, i.e. with the BALANCING_WITHOUT_INTERVAL_SUBDIVISION option and setting the default of the tool to such to ward against accidental misuse.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3061:1353,error,error,1353,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3061,1,['error'],['error']
Availability,"For downstream projects, there is a way to bundle single class files into the toolkit by adding them to the `Main.getClassList`; nevertheless, this only allows to include classes extending the `org.broadinstitute.hellbender.cmdline.CommandLineProgram`. For including a tool from picard, the only way is to add a whole package where `picard.cmdline.CommandLineProgram` extensions are located. Either a new method for include single classes from Picard should be added, or https://github.com/broadinstitute/barclay/issues/127 implemented (a proposal has been done in https://github.com/broadinstitute/barclay/pull/96) and move Picard/GATK to use the common interface.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4660:4,down,downstream,4,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4660,1,['down'],['downstream']
Availability,"For some reason, this user is getting an error in 4.0.5.1 when this was supposed to have been fixed in GATK3. ----; User Report; ----; I'm trying to get a set of robust variants to use to recalibrate quality scores. I called variants using gatk4, and then tried to perform VariantFiltration:. gatk-4.0.5.1/gatk VariantFiltration -R data/genome.fasta -V variants/6753_12-15-2015_first_pass_filtered.vcf -filter 'QD > 2 && FS > 60 && SOR < 3 && MQ > 40 && MQRankSum > -3 && ReadPosRankSum > -4' -output variants/6753_12-15-2015_second_pass_filtered.vcf -filter-name ""default"" . However, it complains with a java.lang.NumberFormatException:. Using GATK jar gatk-4.0.5.1/gatk-package-4.0.5.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar gatk-4.0.5.1/gatk-package-4.0.5.1-local.jar VariantFiltration -R data/genome.fasta -V variants/6753_12-15-2015_first_pass_filtered.vcf -filter QD > 2 && FS > 60 && SOR < 3 && MQ > 40 && MQRankSum > -3 && ReadPosRankSum > -4 -output variants/6753_12-15-2015_second_pass_filtered.vcf -filter-name default; 15:42:33.964 INFO NativeLibraryLoader - Loading libgkl_compression.dylib from jar:file:gatk-4.0.5.1/gatk-package-4.0.5.1-local.jar!/com/intel/gkl/native/libgkl_compression.dylib; 15:42:34.114 INFO VariantFiltration - ------------------------------------------------------------; 15:42:34.115 INFO VariantFiltration - The Genome Analysis Toolkit (GATK) v4.0.5.1; 15:42:34.115 INFO VariantFiltration - For support and documentation go to https://software.broadinstitute.org/gatk/; 15:42:34.115 INFO VariantFiltration - Executing as sherlock@DN52ehae.SUNet on Mac OS X v10.13.5 x86_64; 15:42:34.116 INFO VariantFiltration - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_91-b14; 15:42:34.116 INFO VariantFiltration - Start Date/Time: June 15, 2018 3:42:33 PM PDT; 15:42:34.116 INFO VariantFiltration - ----------------",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4921:41,error,error,41,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4921,2,"['error', 'robust']","['error', 'robust']"
Availability,"For the various GATK docker images, the larger `4.x.y.z` tags are available in GCR but the smaller `gatkbase-a.b.c` tags are only available in [docker hub](https://hub.docker.com/r/broadinstitute/gatk/tags/). ```shell; $ gcloud container images list-tags us.gcr.io/broad-gatk/gatk; DIGEST TAGS TIMESTAMP; 1c870d8bea16 4.0.3.0,latest 2018-03-28T05:12:42; fd8e7a9e65e6 4.0.2.1 2018-03-03T03:52:42; 899b5d55c45b 4.0.2.0 2018-02-27T11:57:49; 14b4dd387cf6 4.0.1.2 2018-02-10T03:48:55; 98b2f223dce4 4.0.1.1 2018-02-02T05:45:05; 634e2aaa5565 4.0.1.0 2018-02-01T00:13:47; 277658fad225 4.0.0.0 2018-01-10T03:16:45; 460c6b71b019 4.beta.6 2017-10-17T05:14:55; 98ed56704964 4.beta.5 2017-09-07T02:47:16; 12b65b9fe0bf 4.beta.4 2017-08-26T11:03:39; fa4d2b05e376 4.beta.3 2017-07-26T23:55:37; $ ; ```. The smaller ""base"" images are 1/5th of the size of the larger images while still containing a number of useful utilities for GATK based workflows.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4610:66,avail,available,66,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4610,2,['avail'],['available']
Availability,"Frequently we find our pipeline detecting STR expansions whose size >50, i.e. in the SV domain, but we cannot fully assemble the expanded allele, as judged by PacBio calls.; We need a strategy on how to reliably report ; * what is found and; * how likely it is that we have assembled the full allele, or only part of the expansion (lower bound estimate).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4388:203,reliab,reliably,203,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4388,1,['reliab'],['reliably']
Availability,"From @cmnbroad:. The write side for non-coordinate sorted CRAMs works now, but there is still a problem with reading queryname sorted input crams with unmapped reads. There is an existing test in GATK for this case that is already enabled and has been passing, but only because there is another bug in the test code that is masking the failure because it uses the value ""outputExtension"", which results in a BAM file being created. When I went to fix that as part of re-enabling the disabled CRAM tests, the verification of the queryname test output now fails. The test itself runs, but the samsEqualStringent verification fails reading the output. So the write-side issues with the presorted flag are fixed with samtools/htsjdk#368, but there is still a limitation in htsjdk for reading crams with unmapped reads that are not coordinate sorted that we need to fix/understand. See also:; https://github.com/broadinstitute/gatk/issues/777; https://github.com/samtools/htsjdk/issues/404",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1259:324,mask,masking,324,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1259,2,"['failure', 'mask']","['failure', 'masking']"
Availability,"From ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/funcotator/ the file `gencode/hg38/gencode.config` makes reference to `gencode.v27.pc_transcripts.fasta` . ```; # Required field for GENCODE files.; # Path to the FASTA file from which to load the sequences for GENCODE transcripts:; gencode_fasta_path = gencode.v27.pc_transcripts.fasta; ```. which is not present in the directory. . ```; $ ls; gencode.config; gencode.v27.chr_patch_hapl_scaff.annotation.REORDERED.gtf; gencode.v27.chr_patch_hapl_scaff.annotation.REORDERED.gtf.idx; gencode.v27.transcripts.dict; gencode.v27.transcripts.fasta; gencode.v27.transcripts.fasta.fai; ```. Downloading the pc_transcript.fasta from gencode does not fix the errors thrown when trying to use the reference. The error message is a fairly uninformative null pointer exception. . ```; 00:27:35.745 INFO Funcotator - Done initializing engine; 00:27:35.758 INFO Funcotator - Shutting down engine; [March 12, 2018 12:27:35 AM UTC] org.broadinstitute.hellbender.tools.funcotator.Funcotator done. Elapsed time: 0.01 minutes.; Runtime.totalMemory()=2258108416; java.lang.NullPointerException; 	at org.broadinstitute.hellbender.tools.funcotator.Funcotator.closeTool(Funcotator.java:330); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:897); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:135); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:180); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:199); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:159); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:202); 	at org.broadinstitute.hellbender.Main.main(Main.java:288); ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4521:645,Down,Downloading,645,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4521,4,"['Down', 'down', 'error']","['Downloading', 'down', 'error', 'errors']"
Availability,"From https://github.com/broadinstitute/dsde-docs/issues/1517.; For `ApplyBQSR`, if the input covariates table file for base quality score recalibration has a read group in the quality score (RecalTable1) or covariates (RecalTable2) report that is not in read group report (RecalTable0), give an informative error.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2430:307,error,error,307,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2430,1,['error'],['error']
Availability,FuncotateSegments errors out on short segments,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6575:18,error,errors,18,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6575,1,['error'],['errors']
Availability,Funcotator - Add redundant codons to DNA -> Protein table for IUPAC bases,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6777:17,redundant,redundant,17,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6777,1,['redundant'],['redundant']
Availability,Funcotator - SimpleXsv parser needs improved error handling for different encodings,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4006:45,error,error,45,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4006,1,['error'],['error']
Availability,Funcotator - logic error for large deletions overlapping 5'UTR,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6345:19,error,error,19,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6345,1,['error'],['error']
Availability,Funcotator Error parsing LineIteratorImpl(SynchronousLineReader),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6758:11,Error,Error,11,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6758,1,['Error'],['Error']
Availability,Funcotator has small errors with non-left-aligned insertions,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7176:21,error,errors,21,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7176,1,['error'],['errors']
Availability,Funcotator keep running without error but no results,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7135:32,error,error,32,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7135,1,['error'],['error']
Availability,"Funcotator needs to be able to handle variants in the upstream and downstream flanks of a gene. Right now because we walk over variants that match genes in Gencode, there will be no gene matches for upstream and downstream variants. . To do this we will need to update our features to match +/- the maximum of the padding for each en(5' or 3' padding). This will also affect IGR processing. We will need to update the caching scheme in `FeatureCache` to cache around a locus rather than just in front of it (in a configurable manner). 5' should default to 5000 and 3' should default to zero.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4771:67,down,downstream,67,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4771,2,['down'],['downstream']
Availability,"Funcotator produces MAF files in accordance with `TCGA MAF Spec v2.4.1` ([TCGA_MAF_SPEC_2_4_1.tar.gz](https://github.com/broadinstitute/gatk/files/7008573/TCGA_MAF_SPEC_2_4_1.tar.gz)). The current public MAF format is [`GDC MAF v1.0.0`](https://docs.gdc.cancer.gov/Data/File_Formats/MAF_Format/). . All our documentation must be updated to reflect this. Worse, the TCGA MAF 2.4.1 Spec is now locked behind a login screen and may not be available at all. When I sent an email about this, I was told it would change soon. That was over 2 years ago.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7424:436,avail,available,436,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7424,1,['avail'],['available']
Availability,Funcotator should error and stop when annotating a VCF that already contains funcotations.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5679:18,error,error,18,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5679,1,['error'],['error']
Availability,Funcotator should produce an `error` transcript if a particular transcript was not able to be annotated due to an error,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4861:30,error,error,30,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4861,2,['error'],['error']
Availability,Funcotator shuts down,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6182:17,down,down,17,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6182,1,['down'],['down']
Availability,Funcotator throwing error more than one config file,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8647:20,error,error,20,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8647,1,['error'],['error']
Availability,Funcotator user-defined data source Error,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6223:36,Error,Error,36,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6223,1,['Error'],['Error']
Availability,"Funcotator will only write alt/ref counts to a MAF inferred from the AD field if the genotype (GT) field is also present in the somatic VCF:. https://github.com/broadinstitute/gatk/blob/febd7cbbd1fc2a631fa9d7dcde52383e3134e88c/src/main/java/org/broadinstitute/hellbender/tools/funcotator/mafOutput/CustomMafFuncotationCreator.java#L74-L76. However, requiring that the GT field be present is unnecessary, since the comma-delimited values of the AD field have no bearing on the contents of the GT field. Indeed, the majority of somatic callers either output `0/1` for every single GT field (e.g. MuTect) or nothing at all (e.g. Strelka), since somatic zygosity (usually called ""multiplicity"") is generally not calculated by a short variant caller, but rather by a downstream tool that computes overall tumor purity/absolute copy number. I came across this bug when trying to convert a Strelka VCF to MAF and noticed that alt/ref counts are not output by Funcotator to the MAF, since Strelka does not write a GT field to its VCFs. Luckily, this is an extremely easy fix. I'm happy to contribute a tiny PR changing the three offending lines above.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7011:762,down,downstream,762,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7011,1,['down'],['downstream']
Availability,"GAKT 4.1.8.1 - PostprocessGermlineCNVCalls - Error ""Records were not strictly sorted in dictionary order""",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6924:45,Error,Error,45,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6924,1,['Error'],['Error']
Availability,GATK 4.2.2.0 bug GenotypeGVCFs error IndexOutOfBoundsException,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7465:31,error,error,31,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7465,1,['error'],['error']
Availability,GATK Concordance: java.lang.NullPointerException instead of nice error message,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7562:65,error,error,65,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7562,1,['error'],['error']
Availability,GATK Docker sets $HOME to /root which can result in failures on write,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4782:52,failure,failures,52,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4782,1,['failure'],['failures']
Availability,GATK Funcotator [SQLITE_IOERR_LOCK] I/O error in the advisory file locking logic (disk I/O error),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7474:40,error,error,40,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7474,2,['error'],['error']
Availability,"GATK Version: 4.0.9.0. The issue: ; The previously available ""beta"" tool MarkDuplicatesGATK introduced reliable support for CRAM formatted files into the GATK tool chain. . Since that was removed again, I noticed that the default/picard-derived MarkDuplicates does not work reliably on CRAM formatted files. I am getting:. java.lang.IllegalStateException: A valid CRAM reference was not supplied and one cannot be acquired via the property settings reference_fasta or use_cram_ref_download. using this call:; gatk MarkDuplicates -I Sample_AS-230151.clean.cram -O test.cram -M metrics -R /ifs/data/nfs_share/ikmb_repository/references/gatk/bundle/2.8/b37/human_g1k_v37.clean.fasta. Files in folder: Sample_AS-230151.clean.cram Sample_AS-230151.clean.cram.bai Sample_AS-230151.clean.cram.crai. Since CRAM provides a *significant* storage saving over BAM, we would very much like use CRAM exclusively. But this still seems to be an issue, despite reports over at the Picard-side of things dating back to 2016 and beyond. . Any chance of this ever getting fixed?. Cheers,; Marc",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5218:51,avail,available,51,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5218,3,"['avail', 'reliab']","['available', 'reliable', 'reliably']"
Availability,"GATK doesn't seem to be working on Windows any longer, at least HaploTypeCaller crashes with the following. Tested with GATK 4.0.9.0, 4.0.11.0 and 4.1.0.0. ```; java.exe -jar gatk-package-4.1.0.0-local.jar HaplotypeCaller -R refa.fa -I refa.bam -O bam_chramma.vcf; java.nio.file.InvalidPathException: Illegal char <:> at index 2: /C:/Users/Teemu/AppData/Local/Temp/; at sun.nio.fs.WindowsPathParser.normalize(Unknown Source); at sun.nio.fs.WindowsPathParser.parse(Unknown Source); at sun.nio.fs.WindowsPathParser.parse(Unknown Source); at sun.nio.fs.WindowsPath.parse(Unknown Source); at sun.nio.fs.WindowsFileSystem.getPath(Unknown Source); at java.nio.file.Paths.get(Unknown Source); at org.broadinstitute.hellbender.utils.io.IOUtils.getPath(IOUtils.java:759); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:161); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289). ```. The last version I have tested where this still works is 4.0.8.1. It is caused most likely because of the forward slash before C:. There are several examples of the error that can be googled. Here's one:. https://bugs.eclipse.org/bugs/show_bug.cgi?id=518079",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5805:1351,error,error,1351,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5805,1,['error'],['error']
Availability,GATK error,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6604:5,error,error,5,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6604,1,['error'],['error']
Availability,GATK error ：OSError: [Errno 8] Exec format error: 'java',MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7484:5,error,error,5,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7484,2,['error'],['error']
Availability,GATK launch has a fairly complex set of error conditions it can handle. Since it's in python it's very easy to break it without realizing. We need tests for it.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1694:40,error,error,40,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1694,1,['error'],['error']
Availability,"GATK seems to not handle gzipped reference genomes and throws quite cryptic errors instead. This is problem given that the readily available reference genome is gzipped (see [here](ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/000/001/405/GCA_000001405.15_GRCh38/seqs_for_alignment_pipelines.ucsc_ids/) and its not obvious that gzipped files cannot be handled by GATK (samtools and picard seem to handle them just fine). This just happened to me with the `gatk SplitNCigarsReads`. This can be easily made more user-friendly by checking if the file has "".gz"" or "".gzip"" filetype and checking the first two bytes are ""1f 8b"" (see [here](https://stackoverflow.com/a/3703300) )",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6590:76,error,errors,76,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6590,2,"['avail', 'error']","['available', 'errors']"
Availability,GATK should give a better error message when the wrong extension is used for an interval file,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7095:26,error,error,26,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7095,1,['error'],['error']
Availability,GATK v4.0.8.1 GenomicsDBImport Error (VariantStorageManagerException exception); File syncing error,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5342:31,Error,Error,31,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5342,2,"['Error', 'error']","['Error', 'error']"
Availability,"GATK version: 4.4.0.0. Crashing in FilterAlignmentArtifacts. Not clear why. Command; ```; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx30g -jar /gpfs/data/lab/bin/gatk/gatk-package-4.4.0.0-local.jar FilterAlignmentArtifacts -R /gpfs/data/lab/reference-files/hg38-gatk/Homo_sapiens_assembly38.fasta -V 60603-bulk.filtered.vcf.gz -I /gpfs/data/lab/projects/Mini/analysis/STR/60603-bulk_results/60603-bulk.cram --bwa-mem-index-image /gpfs/data/lab/reference-files/hg38-gatk/Homo_sapiens_assembly38.fasta.img -O 60603-bulk.filtered.FAA.vcf.gz; ```. Error:; ```; 11:02:16.087 INFO ProgressMeter - chrX:144247387 619.0 145000 234.3; 11:05:08.297 WARN IntelInflater - Zero Bytes Written : 0; 12:29:39.297 INFO FilterAlignmentArtifacts - Shutting down engine; [August 15, 2023 at 12:29:39 PM EDT] org.broadinstitute.hellbender.tools.walkers.realignmentfilter.FilterAlignmentArtifacts done. Elapsed time: 710.24 minutes.; Runtime.totalMemory()=4345298944; java.lang.IllegalStateException: Padded span must contain active span.; at org.broadinstitute.hellbender.utils.Utils.validate(Utils.java:814); at org.broadinstitute.hellbender.engine.AssemblyRegion.<init>(AssemblyRegion.java:109); at org.broadinstitute.hellbender.engine.AssemblyRegion.<init>(AssemblyRegion.java:85); at org.broadinstitute.hellbender.engine.AssemblyRegion.<init>(AssemblyRegion.java:120); at org.broadinstitute.hellbender.tools.walkers.realignmentfilter.FilterAlignmentArtifacts.makeAssemblyRegionFromVariantReads(FilterAlignmentArtifacts.java:280); at org.broadinstitute.hellbender.tools.walkers.realignmentfilter.FilterAlignmentArtifacts.apply(FilterAlignmentArtifacts.java:212); at org.broadinstitute.hellbender.engine.MultiVariantWalkerGroupedOnStart.apply(MultiVariantWalkerGroupedOnStart.java:133); at org.broadinstitute.hellbender.engine.MultiVariantWalkerGroupedOnStart.afterTraverse(MultiVariantWalkerGroupedO",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8476:664,Error,Error,664,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8476,2,"['Error', 'down']","['Error', 'down']"
Availability,"GATK version: GATK 4.1.3.0; docker container used: quay.io/biocontainers/gatk4:4.1.3.0--0. Please find below the error report from a GATK user:. 20:06:25.036 INFO GenomicsDBImport - GCS max retries/reopens: 20; 20:06:25.036 INFO GenomicsDBImport - Requester pays: disabled; 20:06:25.037 INFO GenomicsDBImport - Initializing engine; 20:07:32.463 INFO FeatureManager - Using codec IntervalListCodec to read file file:///gscmnt/gc2560/core/model_data/2887491634/build21f22873ebe0486c8e6f69c15435aa96/GRCh38_autosomal.interval_list; 20:07:32.555 INFO IntervalArgumentCollection - Processing 2875001522 bp from intervals; 20:07:32.792 INFO GenomicsDBImport - Done initializing engine; 20:07:33.106 INFO GenomicsDBImport - Shutting down engine; [August 22, 2019 8:07:33 PM GMT] org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImport done. Elapsed time: 1.17 minutes.; Runtime.totalMemory()=253493248; Exception in thread ""main"" java.lang.ExceptionInInitializerError; 	at org.genomicsdb.GenomicsDBUtils.createTileDBWorkspace(GenomicsDBUtils.java:37); 	at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImport.overwriteCreateOrCheckWorkspace(GenomicsDBImport.java:883); 	at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImport.onTraversalStart(GenomicsDBImport.java:605); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1046); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:162); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:205); 	at org.broadinstitute.hellbender.Main.main(Main.java:291); Caused by: org.genomicsdb.exception.GenomicsDBException: Could not load genomicsdb native library; 	at org.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6122:113,error,error,113,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6122,2,"['down', 'error']","['down', 'error']"
Availability,GATK versioning scheme for downstream projects,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4603:27,down,downstream,27,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4603,1,['down'],['downstream']
Availability,GATK4 & Spark local memory error,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3465:27,error,error,27,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3465,1,['error'],['error']
Availability,"GATK4 BaseRecalibratorSpark , Executor heartbeat timed out after X ms",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4515:39,heartbeat,heartbeat,39,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4515,1,['heartbeat'],['heartbeat']
Availability,GATK4 GenomicsDB error with GenomicsDB versions 0.9.0 and 0.9.2,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4514:17,error,error,17,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4514,1,['error'],['error']
Availability,"GATK4 Mutect2 error ：af-only-gnomad.raw.sites.hg19.vcf.gz has invalid uncompressedLength: -795051631,",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6248:14,error,error,14,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6248,1,['error'],['error']
Availability,GATK4 ReadsPipelineSpark A USER ERROR: The input .bam file contains reads with no platform information,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1949:32,ERROR,ERROR,32,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1949,1,['ERROR'],['ERROR']
Availability,"GATK4 has a number of options that presumably alter performance in different ways under different conditions, including and probably not limited to: Intel Deflater/Inflater, snappy, and HTSJDK's various USE_ASYNC_XXXXX_READ params. I can appreciate there is probably not a one-size fits all answer, but would it be possible to provide some type of general guidance on what's available, and when one or the other might be worth evaluating? Thanks.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3648:375,avail,available,375,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3648,1,['avail'],['available']
Availability,"GATKVariantContextUtils.createVCFWriter attempts to determine the output vcf type based on the file extension provided by the user, and defaults to vcf if the extension isn't a recognized type. There is code in VariantContextWriterBuilder (determineOutputTypeFromFile) in htsjdk that attempts to do the same mapping, but isn't public. We should expose that in htsjdk and use it in GATKVariantConextUtils so we can get rid of the redundant code.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2128:429,redundant,redundant,429,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2128,1,['redundant'],['redundant']
Availability,GKL 0.5.5 fixes a critical bug in the FPGA PairHMM implementation. The bug produces a segmentation fault when FPGA PairHMM is invoked in 'private' mode. GKL 0.5.5 is otherwise identical to 0.5.3.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3401:99,fault,fault,99,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3401,1,['fault'],['fault']
Availability,GKL failures in MacOS,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3532:4,failure,failures,4,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3532,1,['failure'],['failures']
Availability,GQBands 19 --GVCFGQBands 20 --GVCFGQBands 21 --GVCFGQBands 22 --GVCFGQBands 23 --GVCFGQBands 24 --GVCFGQBands 25 --GVCFGQBands 26 --GVCFGQBands 27 --GVCFGQBands 28 --GVCFGQBands 29 --GVCFGQBands 30 --GVCFGQBands 31 --GVCFGQBands 32 --GVCFGQBands 33 --GVCFGQBands 34 --GVCFGQBands 35 --GVCFGQBands 36 --GVCFGQBands 37 --GVCFGQBands 38 --GVCFGQBands 39 --GVCFGQBands 40 --GVCFGQBands 41 --GVCFGQBands 42 --GVCFGQBands 43 --GVCFGQBands 44 --GVCFGQBands 45 --GVCFGQBands 46 --GVCFGQBands 47 --GVCFGQBands 48 --GVCFGQBands 49 --GVCFGQBands 50 --GVCFGQBands 51 --GVCFGQBands 52 --GVCFGQBands 53 --GVCFGQBands 54 --GVCFGQBands 55 --GVCFGQBands 56 --GVCFGQBands 57 --GVCFGQBands 58 --GVCFGQBands 59 --GVCFGQBands 60 --GVCFGQBands 70 --GVCFGQBands 80 --GVCFGQBands 90 --GVCFGQBands 99 --indelSizeToEliminateInRefModel 10 --useAllelesTrigger false --dontTrimActiveRegions false --maxDiscARExtension 25 --maxGGAARExtension 300 --paddingAroundIndels 150 --paddingAroundSNPs 20 --kmerSize 10 --kmerSize 25 --dontIncreaseKmerSizesForCycles false --allowNonUniqueKmersInRef false --numPruningSamples 1 --recoverDanglingHeads false --doNotRecoverDanglingBranches false --minDanglingBranchLength 4 --consensus false --maxNumHaplotypesInPopulation 128 --errorCorrectKmers false --minPruning 2 --debugGraphTransformations false --kmerLengthForReadErrorCorrection 25 --minObservationsForKmerToBeSolid 20 --likelihoodCalculationEngine PairHMM --base_quality_score_threshold 18 --gcpHMM 10 --pair_hmm_implementation FASTEST_AVAILABLE --pcr_indel_model CONSERVATIVE --phredScaledGlobalReadMismappingRate 45 --useDoublePrecision false --debug false --useFilteredReadsForAnnotations false --bamWriterType CALLED_HAPLOTYPES --disableOptimizations false --justDetermineActiveRegions false --dontGenotype false --dontUseSoftClippedBases false --captureAssemblyFailureBAM false --errorCorrectReads false --doNotRunPhysicalPhasing false --min_base_quality_score 10 --useNewAFCalculator false --annotateNDA false --heterozygosity 0.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3631:5217,recover,recoverDanglingHeads,5217,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3631,3,"['error', 'recover']","['errorCorrectKmers', 'errorCorrectReads', 'recoverDanglingHeads']"
Availability,"GRCh38_no_alt_analysis_set.fna.gz --MINIMUM_QUALITY_SCORE 20 --MINIMUM_MAPPING_QUALITY 30 --MINIMUM_INSERT_SIZE 60 --MAXIMUM_INSERT_SIZE 600 --INCLUDE_UNPAIRED false --INCLUDE_DUPLICATES false --INCLUDE_NON_PF_READS false --TANDEM_READS false --USE_OQ true --CONTEXT_SIZE 1 --ASSUME_SORTED true --STOP_AFTER 0 --VERBOSITY INFO --QUIET false --VALIDATION_STRINGENCY STRICT --COMPRESSION_LEVEL 2 --MAX_RECORDS_IN_RAM 500000 --CREATE_INDEX false --CREATE_MD5_FILE false --GA4GH_CLIENT_SECRETS client_secrets.json --help false --version false --showHidden false --USE_JDK_DEFLATER false --USE_JDK_INFLATER false; Aug 10, 2023 12:49:43 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; [Thu Aug 10 12:49:43 UTC 2023] Executing as root@34684eaa046e on Linux 4.15.0-208-generic amd64; OpenJDK 64-Bit Server VM 1.8.0_191-8u191-b12-0ubuntu0.16.04.1-b12; Deflater: Intel; Inflater: Intel; Provider GCS is available; Picard version: Version:4.1.3.0; [Thu Aug 10 12:49:43 UTC 2023] picard.analysis.artifacts.CollectSequencingArtifactMetrics done. Elapsed time: 0.03 minutes.; Runtime.totalMemory()=2076049408; To get help, see http://broadinstitute.github.io/picard/index.html#GettingHelp; htsjdk.samtools.SAMException: Cannot read non-existent file: file:///gatk/data/Continuum/WES/vcf/NG-27280_CLTSS_LTS_001A_lib506241_7636_2_MarkedDup.bam; at htsjdk.samtools.util.IOUtil.assertFileIsReadable(IOUtil.java:483); at htsjdk.samtools.util.IOUtil.assertFileIsReadable(IOUtil.java:470); at picard.analysis.SinglePassSamProgram.makeItSo(SinglePassSamProgram.java:95); at picard.analysis.SinglePassSamProgram.doWork(SinglePassSamProgram.java:84); at picard.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:305); at org.broadinstitute.hellbender.cmdline.PicardCommandLineProgramExecutor.instanceMain(PicardCommandLineProgramExecutor.java:25); at org.broadinstitute.hellbender.Main.runComma",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8462:1862,avail,available,1862,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8462,1,['avail'],['available']
Availability,GarbageCollector error in GenotypeGVCFs after GenomicsDBImport after HaplotypeCaller,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4467:17,error,error,17,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4467,1,['error'],['error']
Availability,Gatk validate variants doesn't report an error on non-spec-compliant headers,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6762:41,error,error,41,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6762,1,['error'],['error']
Availability,Gatk3 allowed inputs like `-L some_intervals.vcf`. This functionality should be integrated into the `IntervalArgumentCollection` so that it is available to all tools.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/605:143,avail,available,143,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/605,1,['avail'],['available']
Availability,Gauss-Legendre integration error,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3317:27,error,error,27,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3317,1,['error'],['error']
Availability,"Gbp genome that is roughly 30M entries. Easily a text interval_list in its simplest form would need around 30ch for each interval that bump it up to 900MB . However one could express the same list just like:. `* *:100`. where the first asterisk stands for ""any contig"", the second stands for ""whole contig"" and the 100 means into 100bp adjacent intervals. from 7ch to 900M??? A few more example as to how such a language could look like:. ```; chr1 # the entire chr1; chr1 * # same; chr1,chr2 # both chr1 and chr2, in full.; * # all contigs in full.; * * # same.; chr1 100-200 # sigle interval from 100-200 on chr1.; chr1 { 100-200 } # same; chr1 { # same; 100-200; }; * 100-200 # 100-200 at every contig.; chr1,chr2 100-200 # only on chr1 and chr2; chr1 *200 # from 1-200 i.e. start to 200.; chr1 4000* # from 4000 to the end of chr1.; chr1 4000 # only position 4000; chr1 4M # only position 4 million. M=10^6, k/K=10^3 ; chr1 10000-99 # from 10000 to 10099... ; # perhaps is best not to accept this as it might silence user input errors.; # but what about instead?; chr1 100[00-99]; chr1 10000+100 # 100 bps starting at 10000 so 10000-10099; chr1 4k # only poistion 4000.; chr20 1M+32K # from position 1 million extending to the following 32Kbps.; chr20 1M1+32K # from position 1 million and 1 instead. (avoiding all those 0s). chr1 *:200 # consecutive 200bp intervals for the entire chromosome; chr1 *:200(100) # 200bp intervals with 100 gaps; chr1 *:200/20 # 200bp intervals with an overlap of 20bp.; chr1 *:20/200 # 200bp starting every 20 positions (so 180bp overlap); chr1 *:200~20 # 200bp intervals truncating down to 20bp if necessary. ; chr1 { # we can combine interval specs in blocks if they apply to the same contig(s).; 1M-2M:150(20) # from 1 to 2Mbp 150 intervals with 20bp gap; 20M-25M # a big interval from 20 to 25M.; 40012451-40023451 # another standalone interval ; } . ```; ## Interval exclusion; We could specify the exclused interval in the same file:; ```; chr20 *:200 exclude",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5702:1419,error,errors,1419,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5702,1,['error'],['errors']
Availability,"Generally, it is easier on users (and people doing deployment) to have multiple files that list the bam and index files in corresponding order. . So two files, rather than one:; ```; sample1.bam; sample2.bam; ....; ```; and; ```; sample1.bai; sample2.bai; ....; ```. For example, changing the input parameters to:. ```; workflow CNVSomaticPanelWorkflow {; # Workflow input files; ....snip....; # The next two parameters are files that list (in corresponding order) the bam files and bam index files, respectively.; File normal_bams; File normal_bam_idxs; ; # Create (bam, bai) pairs for iterating over scatter loop.; Array[Pair[File,File]] normal_pairs = zip(read_lines(normal_bams), read_lines(normal_bam_idxs)); ....snip....; ```. and further down in that file:. ```; ....snip....; scatter (normal_pair in normal_pairs) {; call CollectCoverage {; input:; padded_targets = select_first([PadTargets.padded_targets, """"]),; bam = normal_pair.left,; bam_idx = normal_pair.right,; ref_fasta = ref_fasta,; ref_fasta_fai = ref_fasta_fai,; ref_fasta_dict = ref_fasta_dict,; gatk_jar = gatk_jar,; gatk_docker = gatk_docker; }; }; ....snip....; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3460:745,down,down,745,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3460,1,['down'],['down']
Availability,"Generate a toy fastq dataset:; ```; (echo ""@NB500989:333:HKYJNAFX2:1:11101:24447:1024""; echo ""CNGAAAGAAACTAGAGGGGGCCAGGTGCAGTAGCTCACACCTGTAATCTTAGCACTTTGGGAGGCCAAGGCGGGTGGATCATCTGAGGTCAGGAGTTCAAGACCAGCCTGGCCAACATGTTGAAACCCCGTCTCTATTAAAAATACAAAA""; echo ""+""; echo ""6#A/AEEEEEEEAEEEEEEEEEEEAEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEAEEEEEEEEEEEEEEEEEE<EEEEEEEEAEEEEEEEEEEEEEAEEEAEEEAEEEEEE/EEEEEEEEE/E/E<AEEEEE/6A/<<<EE/AEE/E""; echo ""@NB500989:333:HKYJNAFX2:1:11101:10000:1915""; echo ""AGACACATGGCGTTTATCCAGAATTAGCAAATTTATCTTCAGATATGGGATTTTCCTTCTTTTTTTAAATCTTGAGTCTGGCAGCAATTTGTAAAGGCTCATAAAAATCTGAAGCTTACATTTTTTGTCAAGTTACCGATGCTTGTGTCT""; echo ""+""; echo ""AAAAAEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEAEEEEEEEEEEEEEEEEEAEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEAEEEEEAEEEEEEEEEAEEEEEEEEEAEEEEEEEEEEEAAAEAAAEEE/A<AEEEEEEEEEEAA"") | \; gzip > R1.fastq.gz. (echo ""@NB500989:333:HKYJNAFX2:1:11101:24447:1024""; echo ""NNNNTTGTATTTTTAATAGAGACGGGGTTTCAACATGTTGGCCAGGCTGGTCTTGAACTCCTGACCTCAGATGATCCACCCGCCTTGGCCTCCCAAAGTGCTAAGATTACAGGTGTGAGCTACTGCACCTGGCCCCCTCTAGTTTCTTTC""; echo ""+""; echo ""####AEEEEEEEEEEEEEEEE/EEEEEEEEEE6EEEEEEEEEEEEA<EEEEEEEEE/<EEEEEEE/EEEEEEEEEEE/EEEEEAEEEEEAEAEEEE/EEEEE/EEEEEEEEEEEEEAEEEEEEEEAE/<AAAA/<A<EE<<EA<A/AAE<""; echo ""@NB500989:333:HKYJNAFX2:1:11101:10000:1915""; echo ""TTACAGGATCTGAAGAGAGGGAAAAATAAACATGCACGATTATTTAATTCTTTTGGAAAAACTGCATGTAAGTGAAGTTCTCTTTCACAAGACACAAGCATCGGTAACTTGACAAAAAATGTAAGCTTCAGATTTTTATGAGCCTTTACA""; echo ""+""; echo ""AAAAAEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE/EEEEEEEEEE6EEEEEEEEEEEEAEEEEEE/EEEAEEEEEEEEEEEEEAEEAE/EEEEEEEEEAEEEEEEA<EEEEEE<AAEEEEEEEEEEAEEEEEAEAAEAE/AAEAEAA<E"") | \; gzip > R2.fastq.gz; ```. Install bwa and GATK resources:; ```; sudo apt install java11-runtime bwa samtools; wget https://github.com/broadinstitute/gatk/releases/download/4.2.1.0/gatk-4.2.1.0.zip; unzip gatk-4.2.1.0.zip; echo dict fasta fasta.fai fasta.64.alt fasta.64.sa fasta.64.amb fasta.64.bwt fasta.64.ann fasta.64.pac | \; tr ' ' '\n' | xargs -i echo gs://gcp-public-data--broad-references/hg38/v0/Homo_sapiens_",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7398:37,echo,echo,37,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7398,8,['echo'],['echo']
Availability,GenomeDBImport output errors resulting in incomplete DB do not result in error return (exit code == 0).,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7598:22,error,errors,22,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7598,2,['error'],"['error', 'errors']"
Availability,GenomicsDB Duplicate Sample Name Error,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6793:33,Error,Error,33,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6793,1,['Error'],['Error']
Availability,GenomicsDB errors discovered in the wild,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4753:11,error,errors,11,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4753,1,['error'],['errors']
Availability,GenomicsDB malloc unaligned tcache chunk error,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8683:41,error,error,41,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8683,1,['error'],['error']
Availability,GenomicsDBImport crash without error reported in log file,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7218:31,error,error,31,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7218,1,['error'],['error']
Availability,GenomicsDBImport datastore format folder permissions | cause for ERROR: Couldn't create GenomicsDBFeatureReader,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8233:65,ERROR,ERROR,65,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8233,1,['ERROR'],['ERROR']
Availability,GenomicsDBImport disk quota exceeded error,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6950:37,error,error,37,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6950,1,['error'],['error']
Availability,GenomicsDBImport error (VariantStorageManagerException exception : Error while syncing array to disk),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5740:17,error,error,17,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5740,2,"['Error', 'error']","['Error', 'error']"
Availability,GenomicsDBImport error: File2TileDBBinaryException,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6150:17,error,error,17,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6150,1,['error'],['error']
Availability,GenomicsDBImport needs better error messages for parallel import,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4592:30,error,error,30,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4592,1,['error'],['error']
Availability,GenomicsDBImport: A fatal error has been detected by the Java Runtime Environment,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5045:26,error,error,26,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5045,1,['error'],['error']
Availability,GenomicsDBImport: [TileDB::FileSystem] Error: (write_to_file) GCS: Only the last of the uploadable parts can be less than 5MB,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7653:39,Error,Error,39,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7653,1,['Error'],['Error']
Availability,"GenomicsDBImport; Latest public release version [4.2.0.0]. I am running GenomicsDBImport on 5X WGS of ~1000 human samples, which is parallelized for each chromosome with batch size = 400. The code I use is as following:. <pre>gatk --java-options ""-Xmx80G -Xms80G"" GenomicsDBImport \; --genomicsdb-workspace-path ""${outpath}/chr${region}"" \; -L $region \; --sample-name-map $sample_map \; -R /scratch/PI/boip/Reference/Human_genome/GRCh37/hs37d5.fa \; --batch-size 400 \; --reader-threads 5; </pre>. It seems that GenomicsDBImport crash after finishing 1 batch for large chromosomes. For example, here I simultaneously run for chr1-12 (not finished yet). For chr5-12, file size of 1 batch is less than 40GB and they successfully finished import batch 1 and running for batch 2 or 3. Thus, the file size for chr5-12 are 59GB now. However, for chr1-4, they just crash in batch 1 for very long time without any error. I have check the memory usage and there is still >35GB free memory for the compute node of each chromosome. Please see the followings for detail:. File size for all chromosomes, the GenomicsDB for chr1-4 is smaller:; <pre>[hcaoad@login-0 GenomicsDB]> du -h --max-depth=1; 59G ./chr10; 59G ./chr6; 50G ./chr2; 59G ./chr12; 59G ./chr9; 59G ./chr5; 59G ./chr7; 48G ./chr1; 59G ./chr11; 59G ./chr8; 40G ./chr4; 41G ./chr3; 647G .; </pre>. Files in GenomicsDB of chr1 batch 1. As you can see, no update for the database since Apr 20 13:34, while current time is Apr 21.; <pre>[hcaoad@login-0 .__6f46d0f3-86b3-4e38-92be-9a912291df0c139544093255424_1618555702611]> pwd; /home/hcaoad/scratch/Han/WGS/HK_WGS_5X/GenomicsDB/chr1/1$1$249250621/.__6f46d0f3-86b3-4e38-92be-9a912291df0c139544093255424_1618555702611; [hcaoad@login-0 .__6f46d0f3-86b3-4e38-92be-9a912291df0c139544093255424_1618555702611]> date; Wed Apr 21 11:09:46 HKT 2021; [hcaoad@login-0 .__6f46d0f3-86b3-4e38-92be-9a912291df0c139544093255424_1618555702611]> ll -h; total 48G; -rwx------ 1 hcaoad boip 260M Apr 20 13:34 AD.tdb; -rwx--",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7218:907,error,error,907,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7218,1,['error'],['error']
Availability,GenomicsDBImporter constructor calls generateSortedCallSetMap() to download headers to get sample names it already has,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2714:67,down,download,67,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2714,1,['down'],['download']
Availability,GenotypeGVCFs - A USER ERROR has occurred: Couldn't create GenomicsDBFeatureReader,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8709:23,ERROR,ERROR,23,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8709,1,['ERROR'],['ERROR']
Availability,"GenotypeGVCFs - Deflater: IntelDeflater; 12:31:14.785 INFO GenotypeGVCFs - Inflater: IntelInflater; 12:31:14.785 INFO GenotypeGVCFs - GCS max retries/reopens: 20; 12:31:14.785 INFO GenotypeGVCFs - Requester pays: disabled; 12:31:14.785 INFO GenotypeGVCFs - Initializing engine; 12:31:15.766 INFO GenomicsDBLibLoader - GenomicsDB native library version : 1.4.3-6069e4a; 12:31:17.675 info NativeGenomicsDB - pid=3151 tid=3153 No valid combination operation found for INFO field InbreedingCoeff - the field will NOT be part of INFO fields in the generated VCF records; 12:31:17.675 info NativeGenomicsDB - pid=3151 tid=3153 No valid combination operation found for INFO field MLEAC - the field will NOT be part of INFO fields in the generated VCF records; 12:31:17.675 info NativeGenomicsDB - pid=3151 tid=3153 No valid combination operation found for INFO field MLEAF - the field will NOT be part of INFO fields in the generated VCF records; 12:31:19.634 INFO IntervalArgumentCollection - Processing 3714165 bp from intervals; 12:31:19.665 INFO GenotypeGVCFs - Done initializing engine; 12:31:19.700 INFO FeatureManager - Using codec BEDCodec to read file file:///home/groups/pgpdata/ColonyData/207/@files/sequenceOutputs/mmul10.WGS-WXS.whitelist.v2.3.sort.merge.bed; 12:34:40.705 INFO ProgressMeter - Starting traversal; 12:34:40.705 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute. and then at: 15 Feb 2022 12:37:38,923:; [TileDB::StorageBuffer] Error: (gzip_read_buffer) Cannot read to buffer; Mem allocation error errno=12(Cannot allocate memory); [TileDB::StorageBuffer] Error: (read_buffer) Cannot decompress and/or read bytes path=/home/exacloud/gscratch/prime-seq/cachedData/16b9ede7-6db8-103a-9262-f8f3fc86a851/WGS_Feb22_1852.gdb/1$1$223616942/__9b9a9e96-139c-4105-81ec-ab1455d1f01d140490873108224_1597099702436/__book_keeping.tdb.gz errno=12(Cannot allocate memory); [TileDB::BookKeeping] Error: Cannot load book-keeping; Reading domain size failed.; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7674:4566,Error,Error,4566,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7674,4,"['Error', 'error']","['Error', 'error']"
Availability,GenotypeGVCFs ArrayIndexOutOfBoundsException Error,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7348:45,Error,Error,45,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7348,1,['Error'],['Error']
Availability,GenotypeGVCFs bcf codec error 'nps && nps*line->n_sample==n' failed,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6742:24,error,error,24,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6742,1,['error'],['error']
Availability,GenotypeGVCFs error in 4.2.4.1 java.lang.IllegalStateException,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7639:14,error,error,14,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7639,1,['error'],['error']
Availability,GenotypeGVCFs error in GATK 4.6.0.0: java.lang.RuntimeException: Invalid deflate block found.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8969:14,error,error,14,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8969,1,['error'],['error']
Availability,GenotypeGVCFs error log10LikelihoodsOfAC are bad,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5009:14,error,error,14,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5009,1,['error'],['error']
Availability,GenotypeGVCFs is reporting Buffer overflow errors,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7976:43,error,errors,43,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7976,1,['error'],['errors']
Availability,GenotypeGVCFs returns a fatal error.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7008:30,error,error,30,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7008,1,['error'],['error']
Availability,"GenotypeGVCFs with the Error ""Did not inflate expected amount"" and ""java.util.zip.DataFormatException: invalid code lengths set""",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7614:23,Error,Error,23,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7614,1,['Error'],['Error']
Availability,GenotypeGVCFs/GenomicsDB and Cannot allocate memory error,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7674:52,error,error,52,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7674,1,['error'],['error']
Availability,GenotypeGVCFs: Memory map error,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8302:26,error,error,26,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8302,1,['error'],['error']
Availability,"GermlineCNVCaller Error with Python Exit code 137, Failing at Denoising model (warm-up)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6183:18,Error,Error,18,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6183,1,['Error'],['Error']
Availability,"GermlineCNVCaller `-XL` gives error ""Intervals for read-count file do not contain all specified intervals""",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5388:30,error,error,30,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5388,1,['error'],['error']
Availability,GermlineCNVCaller error when testing for nf-core modules,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8097:18,error,error,18,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8097,1,['error'],['error']
Availability,GetPileupSummaries runs out of memory even with >200 available RAM,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5918:53,avail,available,53,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5918,1,['avail'],['available']
Availability,"Go the following:. ```; Current git hash does not match GATK git hash. Run anyway?yes; error: malformed object name 1; usage: git branch [<options>] [-r | -a] [--merged | --no-merged]; or: git branch [<options>] [-l] [-f] <branch-name> [<start-point>]; or: git branch [<options>] [-r] (-d | -D) <branch-name>...; or: git branch [<options>] (-m | -M) [<old-branch>] <new-branch>; or: git branch [<options>] [-r | -a] [--points-at]; ...; ```; Not sure the first error message about the ""hashes"" means perhaps that is the cause though. Assigned to @TedBrookings because I think this is you beast.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3593:87,error,error,87,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3593,2,['error'],['error']
Availability,"Goal was to get WGS coverage collection at 100bp at ~15 cents per sample. Since this is I/O bound (takes ~2 hours to stream or localize a BAM, or about the same to decompress a CRAM), cost reduction can be most easily achieved by reducing the memory requirements and moving down to a cheaper VM. . Memory requirements at 100bp are dominated by manipulations of the list of ~30M intervals. There were a few easy fixes to reduce requirements that did not require changing the collection method (which can be easily modified for future investigations, see #4551):. -removed WellformedReadFilter. See #5233. EDIT: We decided after PR review to retain this filter by default and disable it at the WDL level when Best Practices is released. Leaving the issue open.; -initialized HashMultiSet capacity; -removed unnecessary call to OverlapDetector.getAll; -avoided a redundant defensive copy in SimpleCountCollection; -used per-contig OverlapDetectors, rather than a global one. This brought the cost down to ~9 cents per sample using n1-standard-2's with 7.5GB of memory when collecting on BAMs with NIO. Note that I didn't optimize disk size, which accounts for ~50% of the total cost and is unused when running with NIO, so we are closer to ~5 cents per sample. It is possible that using CRAMs with or without NIO and with or without SSDs might be cheaper. Note that OverlapDetectors may be overkill for our case, since bins are guaranteed to be sorted and non-overlapping and queries are also sorted. We could probably roll something that is O(1) in memory. However, since we are I/O bound, as long as we are satisfied with the current cost, I am willing to sacrifice memory for implementation and maintenance costs, as well as the option to change strategies easily. In any case, @lbergelson found some easy wins in OverlapDetector that may further bring the memory usage down, and will issue a fix in htsjdk soon.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5715:274,down,down,274,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5715,5,"['down', 'mainten', 'redundant']","['down', 'maintenance', 'redundant']"
Availability,"Google is deprecating and removing their implementation of the old style GA4GH read and reference API's. . > ; > Reads API functionality is now replaced by the htsget protocol ; > ; > This year, the GA4GH team introduced the htsget protocol to allow users to download read data for subsections of the genome in which they are interested. This is a richer and more flexible approach to working with reads data. It allows you to keep your genomics data in a common BAM file format on Google Cloud Storage and work with it efficiently from your computation pipelines, using standard bioinformatics tools. We have already launched our own open source implementation of this protocol, which you can use to access your reads data. Many popular tools such as samtools and htslib have been updated by the community to support htsget. Documentation is provided here. The Reads API is now deprecated, and will be decommissioned after one year, or after there has been no API activity for one month by those receiving this notice, whichever comes first. ; > ; > Variants API is now replaced by htsget and Variant Transforms ; > ; > The GA4GH team also plans to extend the htsget protocol to cover variant data, and we will extend our implementation of htsget to cover this use case. ; > ; > After analyzing usage of the Variants API, we found that users primarily used it to import variant data and then export it to BigQuery. To save time and effort, we created Variant Transforms, an open source tool for directly importing VCF data into BigQuery. Variant Transforms and its documentation are published here. Variant Transforms is more scalable than the legacy Variants API, and it has a robust roadmap with a dedicated team. We also welcome collaborators on this project as it advances. ; > ; > The Variants API is now deprecated, and will be decommissioned after one year, or after there has been no API activity for one month, whichever comes first. ; > ; > We are excited to move in step with the global ge",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4166:259,down,download,259,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4166,1,['down'],['download']
Availability,"Google made an incompatible change to the dataproc api which is causing all builds to fail. We're seeing errors like this:; ```; ERROR: (gcloud.beta.dataproc.clusters.create) The required property [region] is not currently set.; It can be set on a per-command basis by re-running your command with the [--region] flag. You may set it for your current workspace by running:. $ gcloud config set dataproc/region VALUE. or it can be set temporarily by the environment variable [CLOUDSDK_DATAPROC_REGION]; ```. It's mentioned in gcloud release notes here:; ```; 260.0.0 (2019-08-27); Breaking Changes; (Cloud Dataproc) Modified --region flag to be mandatory.; To use Cloud Dataproc commands, pass the --region flag on every invocation, or set the dataproc/region configuration variable via gcloud config set dataproc/region.; For gcloud beta dataproc commands, this flag/config value is required.; For gcloud dataproc commands, the default will remain global until January 2020.; ```. I'm going to set the environment variable in our travis config right now, and then open a separate PR to specify region in all the commands.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6129:105,error,errors,105,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6129,2,"['ERROR', 'error']","['ERROR', 'errors']"
Availability,Graph - Recovered 4 of 7 dangling heads; 11:36:09.750 DEBUG Mutect2Engine - Active Region chrM:2921-3202; 11:36:09.750 DEBUG Mutect2Engine - Extended Act Region chrM:2821-3302; 11:36:09.750 DEBUG Mutect2Engine - Ref haplotype coords chrM:2821-3302; 11:36:09.751 DEBUG Mutect2Engine - Haplotype count 32; 11:36:09.751 DEBUG Mutect2Engine - Kmer sizes count 0; 11:36:09.751 DEBUG Mutect2Engine - Kmer sizes values []; 11:36:14.909 DEBUG Mutect2 - Processing assembly region at chrM:3203-3502 isActive: false numReads: 2398; 11:36:15.137 DEBUG Mutect2 - Processing assembly region at chrM:3503-3702 isActive: false numReads: 2587; 11:36:15.184 DEBUG Mutect2 - Processing assembly region at chrM:3703-3943 isActive: true numReads: 5164; 11:36:15.511 DEBUG ReadThreadingGraph - Recovered 3 of 5 dangling tails; 11:36:15.517 DEBUG ReadThreadingGraph - Recovered 1 of 5 dangling heads; 11:36:15.911 DEBUG ReadThreadingGraph - Recovered 34 of 41 dangling tails; 11:36:15.932 DEBUG ReadThreadingGraph - Recovered 13 of 31 dangling heads; 11:36:15.995 DEBUG IntToDoubleFunctionCache - cache miss 2401 > 2399 expanding to 4800; 11:36:16.347 DEBUG Mutect2Engine - Active Region chrM:3703-3943; 11:36:16.348 DEBUG Mutect2Engine - Extended Act Region chrM:3603-4043; 11:36:16.348 DEBUG Mutect2Engine - Ref haplotype coords chrM:3603-4043; 11:36:16.348 DEBUG Mutect2Engine - Haplotype count 254; 11:36:16.348 DEBUG Mutect2Engine - Kmer sizes count 0; 11:36:16.348 DEBUG Mutect2Engine - Kmer sizes values []; 11:36:40.673 DEBUG Mutect2 - Processing assembly region at chrM:3944-4243 isActive: false numReads: 2581; 11:36:40.736 DEBUG Mutect2 - Processing assembly region at chrM:4244-4543 isActive: false numReads: 0; 11:36:40.749 DEBUG Mutect2 - Processing assembly region at chrM:4544-4843 isActive: false numReads: 0; 11:36:40.760 DEBUG Mutect2 - Processing assembly region at chrM:4844-5143 isActive: false numReads: 0; 11:36:40.765 DEBUG Mutect2 - Processing assembly region at chrM:5144-5443 isActive: false num,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7281:11131,Recover,Recovered,11131,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7281,1,['Recover'],['Recovered']
Availability,H5F5 Library Error running DenoiseReadCounts on arm64 processor,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7297:13,Error,Error,13,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7297,1,['Error'],['Error']
Availability,"Hadoop bam `AnySAMInputFormat.createRecordReader` throws `IllegalArgumentException` if it can't determine the format of a sam/bam file. If this is caused by a nonexistant file it hides the `FileNotFoundException` which would be a more useful error message. . This cropped up in a case where a file local to one machine was being specified as an input a spark cluster with multiple nodes. The file existed for the master node, but the workers failed because it was unavailable to them. . It would be helpful if the error message mentioned this possibility. . see #1417 for the original issue",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1452:242,error,error,242,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1452,2,['error'],['error']
Availability,Handle read errors in junction trees,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5924:12,error,errors,12,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5924,1,['error'],['errors']
Availability,"Handler: Started o.s.j.s.ServletContextHandler@10618775{/environment/json,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@20a3e10c{/executors,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5e2a6991{/executors/json,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6f96dd64{/executors/threadDump,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@409732fb{/executors/threadDump/json,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5e99e2cb{/static,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@478967eb{/,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@7f2b39a{/api,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@18c880ea{/jobs/job/kill,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6afbe6a1{/stages/stage/kill,null,AVAILABLE,@Spark}; 18/01/09 18:30:56 INFO ui.SparkUI: Bound SparkUI to 0.0.0.0, and started at http://192.168.1.4:4040; 18/01/09 18:30:56 INFO spark.SparkContext: Added JAR file:/opt/NfsDir/BioDir/GATK4/gatk/build/libs/gatk-package-4.beta.5-50-g8d666b6-SNAPSHOT-spark.jar at spark://192.168.1.4:38793/jars/gatk-package-4.beta.5-50-g8d666b6-SNAPSHOT-spark.jar with timestamp 1515493856032; 18/01/09 18:30:56 INFO gcs.GoogleHadoopFileSystemBase: GHFS version: 1.6.1-hadoop2; 18/01/09 18:30:57 INFO client.RMProxy: Connecting to ResourceManager at tele-1/192.168.1.4:8032; 18/01/09 18:30:57 INFO yarn.Client: Requesting a new application from cluster with 4 NodeManagers; 18/01/09 18:30:58 INFO yarn.Client: Verifying our application has ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4112:10058,AVAIL,AVAILABLE,10058,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4112,1,['AVAIL'],['AVAILABLE']
Availability,"Handler: Started o.s.j.s.ServletContextHandler@3db6dd52{/stages/pool,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6ef4cbe1{/stages/pool/json,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2baac4a7{/storage,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6bce4140{/storage/json,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5882b202{/storage/rdd,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@b506ed0{/storage/rdd/json,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@65f3e805{/environment,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@10618775{/environment/json,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@20a3e10c{/executors,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5e2a6991{/executors/json,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6f96dd64{/executors/threadDump,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@409732fb{/executors/threadDump/json,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5e99e2cb{/static,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@478967eb{/,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@7f2b39a{/api,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4112:9142,AVAIL,AVAILABLE,9142,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4112,1,['AVAIL'],['AVAILABLE']
Availability,"Handler: Started o.s.j.s.ServletContextHandler@69d103f0{/stages/json,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@74fb5b59{/stages/stage,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@26fadd98{/stages/stage/json,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@3db6dd52{/stages/pool,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6ef4cbe1{/stages/pool/json,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2baac4a7{/storage,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6bce4140{/storage/json,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5882b202{/storage/rdd,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@b506ed0{/storage/rdd/json,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@65f3e805{/environment,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@10618775{/environment/json,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@20a3e10c{/executors,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5e2a6991{/executors/json,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6f96dd64{/executors/threadDump,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@409732fb{/executors/threadDump/json,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.C",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4112:8740,AVAIL,AVAILABLE,8740,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4112,1,['AVAIL'],['AVAILABLE']
Availability,Handling gzipped reference genome and associated cryptic errors -- possible UI improvement?,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6590:57,error,errors,57,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6590,1,['error'],['errors']
Availability,"HaplotypeCaller / Mutect2 should detect amplicon data, and warn about downsampling settings",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7567:70,down,downsampling,70,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7567,1,['down'],['downsampling']
Availability,HaplotypeCaller Error Message,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5372:16,Error,Error,16,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5372,1,['Error'],['Error']
Availability,"HaplotypeCaller checks for `samplesList.numberOfSamples() != 1`. The idea was probably about detecting cases with `> 1`, but when no `@RG` present in the BAM file (i.e. `== 0`), it throws the same error. Obviously, such files are not multi-sample, so ideally HaplotypeCaller should just treat them normally without any error. If it's not possible, at least make more informative error message indicating that the problem is having no read groups at all, not ""multi-sample BAM file"". https://github.com/broadinstitute/gatk/blob/1353e3201bb11e29039efd89359b0a4cfc11e5c0/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/HaplotypeCallerEngine.java#L279",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6501:197,error,error,197,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6501,3,['error'],['error']
Availability,"HaplotypeCaller discard reads in active regions that do not pass a small set QC criteria. These reads are then not used for assembly nor to calculate the likelihoods that we use for GT and QUAL and other call quality annotations. However these reads are incorporated back into the data that is passed down to vcf record annotators. . This might be ok under some circumstances but arguably most user would like to see consistency between ; PL and AD or DP,. . Moreover there is an argument that seem that should be included in order to add those filtered reads:; ```---use-filtered-reads-for-annotations```; However its doc line indicates that it means those reads excluded to correct for contamination. The question here is whether should we revise this behavior and make it default to NOT include them instead.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7144:301,down,down,301,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7144,1,['down'],['down']
Availability,HaplotypeCaller doesn't downsample contamination reads for ref blocks,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6152:24,down,downsample,24,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6152,1,['down'],['downsample']
Availability,HaplotypeCaller giving zero byte vcf output file with errorMessage: WARN IntelPairHmm - Flush-to-zero (FTZ) is enabled when running PairHMM,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4788:54,error,errorMessage,54,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4788,1,['error'],['errorMessage']
Availability,HaplotypeCaller improved error message: at AssemblyRegion.getReference,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6783:25,error,error,25,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6783,1,['error'],['error']
Availability,"HaplotypeCaller is ignorant of read pairs, which is sad, because we're throwing away valuable information. Here's what needs to happen to fully utilize pairs:; - [ ] Make sure downsampling removes both reads in a pair; - [ ] Expand active region size to our ""typical"" insert size; - [ ] Pull both reads of a pair into active region, within reason; - [ ] Pull in supplemental alignments?; - [ ] Calculate genotype likelihoods based on fragments rather than individual reads. Recent work #5831 offers a solution to fragment likelihoods. Anything else you can think of @davidbenjamin ? I figure as long as we're not doing a full de novo assembly insert size probably is going to add much.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6151:176,down,downsampling,176,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6151,1,['down'],['downsampling']
Availability,HaplotypeCaller native SmithWaterman: core dumps and JVM errors,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6733:57,error,errors,57,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6733,1,['error'],['errors']
Availability,HaplotypeCaller or htsjdk improved error message for long contigs,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6992:35,error,error,35,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6992,1,['error'],['error']
Availability,HaplotypeCaller: hook up downsampling,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1642:25,down,downsampling,25,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1642,1,['down'],['downsampling']
Availability,"HaplotypeCallerSpark ""Duplicate key"" error",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3018:37,error,error,37,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3018,1,['error'],['error']
Availability,"HaplotypeCallerSpark - ""Caused by: java.lang.IllegalArgumentException: Sequence ... filters= added out of order currentReferenceIndex: 9, referenceIndex:11"" Error",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8490:157,Error,Error,157,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8490,1,['Error'],['Error']
Availability,HaplotypeCallerSpark Enable downsampling in the AssemblyRegionWalker,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5476:28,down,downsampling,28,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5476,1,['down'],['downsampling']
Availability,HaplotypeCallerSpark ReadThreadingAssembler error,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6738:44,error,error,44,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6738,1,['error'],['error']
Availability,HaplotypeCallerSpark empty collection error on regions with no reads,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4234:38,error,error,38,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4234,1,['error'],['error']
Availability,Haplotypecaller error,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8984:16,error,error,16,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8984,1,['error'],['error']
Availability,Hardcode Echo branch factor [VS-901],MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8711:9,Echo,Echo,9,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8711,1,['Echo'],['Echo']
Availability,"Have been having the following issue running StructuralVariationDiscoveryPipeline on previous and the newest release of GATK(4.1.0.0). Currently attempting to use on a computing cluster without spark enabled. . Command line used:; gatk/gatk-4.1.0.0/gatk StructuralVariationDiscoveryPipelineSpark \; -I $CRAM \; -R $Hg38 \; --aligner-index-image reference.fasta.Hg38.img \; --kmers-to-ignore kmers_to_ignore_hg38.txt \; --contig-sam-file aligned_contigs.sam \; -O ${base}_GATK_SV_output.vcf . **Error Log**:; 19/02/01 21:28:27 INFO TaskSetManager: Starting task 700.0 in stage 5.0 (TID 4405, localhost, executor driver, partition 700, PROCESS_LOCAL, 4940 bytes); 19/02/01 21:28:27 INFO Executor: Running task 700.0 in stage 5.0 (TID 4405); 19/02/01 21:28:27 INFO TaskSetManager: Finished task 668.0 in stage 5.0 (TID 4373) in 37331 ms on localhost (executor driver) (669/741); 19/02/01 21:28:27 INFO BlockManagerInfo: Removed taskresult_4373 on 10.120.16.54:34926 in memory (size: 1645.1 KB, free: 15.8 GB); 19/02/01 21:28:27 INFO NewHadoopRDD: Input split: file: /cram8/1-00004__CG0000-1789.GMKF2.cram:23488102400+33554432; 19/02/01 21:28:28 ERROR Executor: Exception in task 698.0 in stage 5.0 (TID 4403); **java.lang.IllegalArgumentException: provided start is negative: -24**; at org.broadinstitute.hellbender.tools.spark.sv.utils.SVInterval$SVIntervalConstructorArgsValidator.lambda$static$3(SVInterval.java:76); at org.broadinstitute.hellbender.tools.spark.sv.utils.SVInterval$SVIntervalConstructorArgsValidator.lambda$andThen$0(SVInterval.java:61); at org.broadinstitute.hellbender.tools.spark.sv.utils.SVInterval.<init>(SVInterval.java:86); at org.broadinstitute.hellbender.tools.spark.sv.utils.SVInterval.<init>(SVInterval.java:51); at org.broadinstitute.hellbender.tools.spark.sv.evidence.QNameFinder.apply(QNameFinder.java:48); at org.broadinstitute.hellbender.tools.spark.sv.evidence.QNameFinder.apply(QNameFinder.java:16); at org.broadinstitute.hellbender.tools.spark.utils.FlatMapGluer.ha",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5647:494,Error,Error,494,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5647,1,['Error'],['Error']
Availability,Heap Space error in PopulateFilterSetInfo. Passing Integration Test [here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/50d867c5-3f6f-405b-8e7b-a714ab7e806f).,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8575:11,error,error,11,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8575,1,['error'],['error']
Availability,"Hello - I was running the exact command with GATK-Mutect2 4.0.0.0 and then switched to 4.0.1.2; an error message was returned:. ```**BETA FEATURE - WORK IN PROGRESS**; USAGE: Mutect2 [arguments]; Call somatic SNVs and indels via local assembly of haplotypes; Version:4.0.1.2; ...; ***********************************************************************; A USER ERROR has occurred: dbsnp is not a recognized option; ***********************************************************************; ```. The exact command works with 4.0.0.0:; ```12:56:44.435 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/group/bioinformatics/software/GATK/4.0.0.0/gatk-package-4.0.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; 12:56:44.750 INFO Mutect2 - ------------------------------------------------------------; 12:56:44.750 INFO Mutect2 - The Genome Analysis Toolkit (GATK) v4.0.0.0; 12:56:44.750 INFO Mutect2 - For support and documentation go to https://software.broadinstitute.org/gatk/; 12:56:44.751 INFO Mutect2 - Executing as rbao@cri16in002 on Linux v2.6.32-573.12.1.el6.x86_64 amd64; 12:56:44.751 INFO Mutect2 - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_92-b14; 12:56:44.751 INFO Mutect2 - Start Date/Time: February 11, 2018 12:56:44 PM CST; 12:56:44.751 INFO Mutect2 - ------------------------------------------------------------; 12:56:44.751 INFO Mutect2 - ------------------------------------------------------------; 12:56:44.751 INFO Mutect2 - HTSJDK Version: 2.13.2; 12:56:44.751 INFO Mutect2 - Picard Version: 2.17.2; 12:56:44.752 INFO Mutect2 - HTSJDK Defaults.COMPRESSION_LEVEL : 1; 12:56:44.752 INFO Mutect2 - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 12:56:44.752 INFO Mutect2 - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 12:56:44.752 INFO Mutect2 - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 12:56:44.752 INFO Mutect2 - Deflater: IntelDeflater; 12:56:44.752 INFO Mutect2 - Inflater: IntelInflater; ```. I was ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4390:99,error,error,99,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4390,2,"['ERROR', 'error']","['ERROR', 'error']"
Availability,"Hello - we're trying to run Funcotator with a custom data source, where that source is a locatableXsv (i.e. simple tab-delimited file with columns for contig, start, and end). I believe I understand how to make this TSV and the config file. The issue is that I dont see a way to create the index (i.e. tsv.idx), and GATK fails when I try to run against a data source without the index. Not that surprisingly, IndexFeatureFile errors when trying to index a TSV saying ""no suitable codecs found"". Is there another tool that's able to make indexes on simple TSVs?. FWIW, the only example LocatableXsv source I could find in the default data sources is Oreganno. The majority of TSV-based sources are simpleXSV and just map using Gene symbol (so apparently no index is required). When I try to index the existing oreganno.tsv file, I get the same problem. I dont know how that original index was created. Thanks for any help or ideas.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7986:426,error,errors,426,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7986,1,['error'],['errors']
Availability,"Hello All,; Is there a detailed manual or documentation available explaining all the flags/filters applied by Mutect2?; For example: bad_haplotype, germline_risk, str_contraction, and many more.; It would be good to understand the principle or rationale behind assigning flags to variants which would help us eventually customize and filter the variants required as per the analysis.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6308:56,avail,available,56,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6308,1,['avail'],['available']
Availability,"Hello GATK team!. ## Bug Report. ### Affected tool(s) or class(es). mutect2. ### Affected version(s); - Latest public release version: 4.2.6.1. ### Description . getting fail for all scatter task with the argument ""--emit-ref-confidence GVCF"", no fails without it. error:; ```; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx3000m -jar /root/gatk.jar GetSampleName -R gs://genomics-public-data/resources/broad/hg38/v0/Homo_sapiens_assembly38.fasta -I gs://cclebams/hg38_wes/CDS-ce3y1s.hg38.bam -O tumor_name.txt -encode --gcs-project-for-requester-pays broad-firecloud-ccle; Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/cromwell_root/tmp.b3fd1830; 14:13:40.205 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/gatk/gatk-package-4.2.6.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; 14:13:40.275 INFO Mutect2 - ------------------------------------------------------------; 14:13:40.276 INFO Mutect2 - The Genome Analysis Toolkit (GATK) v4.2.6.1; 14:13:40.277 INFO Mutect2 - For support and documentation go to https://software.broadinstitute.org/gatk/; 14:13:40.277 INFO Mutect2 - Executing as root@0b46ce3a6ba5 on Linux v5.10.107+ amd64; 14:13:40.277 INFO Mutect2 - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_242-8u242-b08-0ubuntu3~18.04-b08; 14:13:40.278 INFO Mutect2 - Start Date/Time: May 13, 2022 2:13:40 PM GMT; 14:13:40.278 INFO Mutect2 - ------------------------------------------------------------; 14:13:40.278 INFO Mutect2 - ------------------------------------------------------------; 14:13:40.279 INFO Mutect2 - HTSJDK Version: 2.24.1; 14:13:40.280 INFO Mutect2 - Picard Version: 2.27.1; 14:13:40.284 INFO Mutect2 - Built for Spark Version: 2.4.5; 14:13:40.284 INFO Mutect2 - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 14:13:40.284 INFO Mutect2 - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 14:13:40.285 INFO Mutect2 - H",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7849:265,error,error,265,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7849,1,['error'],['error']
Availability,"Hello GATK team, I'm running the following command but getting the following error. Do you know how to solve it? Thank you very much!. ```; java -Xmx80g -Djava.io.tmpdir=/lustre/home/xyliu/02_tmp -jar /lustre/home/ksun/software/GATK-4.2.3.0/gatk-package-4.2.3.0-local.jar PathSeqBuildKmers --reference pathseq_host.fa --output pathseq_host.hss --bloom-false-positive-probability 0.001 --kmer-mask 16 --kmer-size 31 &; ```. ```; $ 10:49:50.605 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/lustre/home/ksun/software/GATK-4.2.3.0/gatk-package-4.2.3.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Feb 15, 2023 10:49:50 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 10:49:50.812 INFO PathSeqBuildKmers - ------------------------------------------------------------; 10:49:50.813 INFO PathSeqBuildKmers - The Genome Analysis Toolkit (GATK) v4.2.3.0; 10:49:50.813 INFO PathSeqBuildKmers - For support and documentation go to https://software.broadinstitute.org/gatk/; 10:49:50.813 INFO PathSeqBuildKmers - Executing as xyliu@fat16 on Linux v3.10.0-862.el7.x86_64 amd64; 10:49:50.813 INFO PathSeqBuildKmers - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_161-b14; 10:49:50.813 INFO PathSeqBuildKmers - Start Date/Time: February 15, 2023 10:49:50 AM CST; 10:49:50.813 INFO PathSeqBuildKmers - ------------------------------------------------------------; 10:49:50.814 INFO PathSeqBuildKmers - ------------------------------------------------------------; 10:49:50.814 INFO PathSeqBuildKmers - HTSJDK Version: 2.24.1; 10:49:50.814 INFO PathSeqBuildKmers - Picard Version: 2.25.4; 10:49:50.814 INFO PathSeqBuildKmers - Built for Spark Version: 2.4.5; 10:49:50.814 INFO PathSeqBuildKmers - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 10:49:50.814 INFO PathSeqBuildKmers - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 10:49:50.814 INFO PathSeqBuildKmer",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8204:77,error,error,77,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8204,2,"['error', 'mask']","['error', 'mask']"
Availability,"Hello again, I have not been able to solve the problem with the launch ReadsPipelineSparkMulticore.wdl. :(; ![qoKs8pEt_-0](https://user-images.githubusercontent.com/55628707/161521914-49b7b10f-3264-43d5-8f5c-739d924656a1.jpg); I use this command:; `java -jar ../cromwell-77.jar run ReadsPipelineSparkMulticore.wdl -i exome/ReadsPiplineSpark_exome.json`; This is my json file:; ![qo2S-PSVs_xNXb5ZysWT8g](https://user-images.githubusercontent.com/55628707/164080985-ae983a19-104a-4742-9401-82ea938ef69e.jpeg); Here is my configuration (CPU and RAM):; ![PEP_IbcPaXyZtql0oefE_A](https://user-images.githubusercontent.com/55628707/164081131-58958f86-5aaf-450f-b985-d7885d4a8de4.jpeg); ![FDmF-6wr4RelT11qqByfGA](https://user-images.githubusercontent.com/55628707/164081137-2d07fe83-845e-463e-ab17-7a5cecb415e0.jpeg). Found this error in my stderr file:; 22/04/06 15:36:17 ERROR Executor: Exception in task 10.0 in stage 11.0 (TID 1596); java.lang.OutOfMemoryError: GC overhead limit exceeded; 	at org.broadinstitute.hellbender.utils.recalibration.BaseRecalibrationEngine.calculateFractionalErrorArray(BaseRecalibrationEngine.java:440); 	at org.broadinstitute.hellbender.utils.recalibration.BaseRecalibrationEngine.processRead(BaseRecalibrationEngine.java:141); 	at org.broadinstitute.hellbender.tools.spark.transforms.BaseRecalibratorSparkFn.lambda$null$0(BaseRecalibratorSparkFn.java:33); 	at org.broadinstitute.hellbender.tools.spark.transforms.BaseRecalibratorSparkFn$$Lambda$705/136574652.accept(Unknown Source); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at org.broadinstitute.hellbender.utils.iterators.CloseAtEndIterator.forEachRemaining(CloseAtEndIterator.java:47); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:647); 	at org.broadinstitute.hellbender.tools.spark.transforms.BaseRecalibratorSparkFn.lambda$apply$6ed74b3e$1(BaseRecalibratorSparkFn.java:33); 	at or",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7796:822,error,error,822,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7796,2,"['ERROR', 'error']","['ERROR', 'error']"
Availability,"Hello everyone, I'm using GATK and hg38 data, and i obtained this problem. 12:22:44.594 ERROR GencodeFuncotationFactory - Problem creating a GencodeFuncotation on transcript ENST00000377837.5 for variant: chr1:6412417-6412418(AT* -> A): Variant overlaps transcript but is not completely contained within it. Funcotator cannot currently handle this case. Transcript: ENST00000377837.5 Variant: [VC Unknown @ chr1:6412417-6412418 Q. of type=INDEL alleles=[AT*, A] attr={AS_FilterStatus=SITE, AS_SB_TABLE=[0, 0|0, 0], DP=1, ECNT=5, GERMQ=1, MBQ=[0, 30], MFRL=[0, 225], MMQ=[60, 60], MPOS=39, POPAF=1.28, RPA=[22, 21], RU=T, STR=true, STRQ=1, TLOD=4.20} GT=GT:AD:AF:DP:F1R2:F2R1:FAD:SB 0/1:0,1:0.667:1:0,0:0,1:0,1:0,0,1,0 filters=clustered_events,germline,slippage; 12:22:44.600 WARN GencodeFuncotationFactory - Creating default GencodeFuncotation on transcript ENST00000377837.5 for problem variant: chr1:6412417-6412418(AT* -> A); 12:22:46.360 INFO ProgressMeter - chr1:7546157 0.2 3000 14771.0; 12:22:56.769 INFO ProgressMeter - chr1:15441040 0.4 6000 15932.0; 12:23:08.615 INFO ProgressMeter - chr1:24268222 0.6 10000 17420.6; 12:23:18.806 INFO ProgressMeter - chr1:32245507 0.7 13000 17475.9; 12:23:29.190 INFO ProgressMeter - chr1:40884137 0.9 16000 17449.2; 12:23:40.060 INFO ProgressMeter - chr1:49383659 1.1 19000 17302.6; 12:23:52.381 INFO ProgressMeter - chr1:59695584 1.3 23000 17645.3; 12:24:03.424 INFO ProgressMeter - chr1:68377682 1.5 27000 18151.3; 12:24:13.590 INFO ProgressMeter - chr1:76887474 1.7 31000 18709.1; 12:24:25.294 INFO ProgressMeter - chr1:85925943 1.9 36000 19438.3; 12:24:35.871 INFO ProgressMeter - chr1:94465524 2.0 40000 19721.1; 12:24:46.052 INFO ProgressMeter - chr1:102403847 2.2 44000 20018.4; 12:24:57.807 INFO ProgressMeter - chr1:111078655 2.4 49000 20468.7; 12:25:09.216 INFO ProgressMeter - chr1:120476481 2.6 53000 20510.4; 12:25:20.032 INFO ProgressMeter - chr1:148975263 2.8 57000 20620.0; 12:25:23.276 ERROR GencodeFuncotationFactory - Problem creating a ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8844:88,ERROR,ERROR,88,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8844,1,['ERROR'],['ERROR']
Availability,"Hello everyone,; When I use the PathSeqPipelineSpark to analyze my datasets, I meet the next issue:; ERROR DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /tmp/blockmgr-a212bfd7-e23c-4634-977e-979a86afe37f/34/temp_shuffle_f93ccbcf-1ccf-4ba9-a9e9-9b09345b533f; My command line just like this:; gatk PathSeqPipelineSpark \; --input simulate_200_change.sam \; --kmer-file pathseq_host.bfi \; --filter-bwa-image pathseq_host.fa.img \; --microbe-bwa-image pathseq_microbe.fa.img \; --microbe-fasta pathseq_microbe.fa \; --taxonomy-file pathseq_taxonomy.db \; --min-clipped-read-length 60 \; --min-score-identity 0.90 \; --identity-margin 0.02 \; --scores-output scores.txt \; --output output_reads.bam \; --filter-metrics filter_metrics.txt \; --score-metrics score_metrics.txt; I have 5 datasets to run pathseq, 3 of them can Normal operation, but the Two large data sets cannot function normally, and such errors are always prompted. (I have checked the sam files format of 5 datasets. They don't have any errors be found. ); The size of the first three files are: 544MB, 183MB, 914MB. The size of the last two files are 2.14GB, 7.15GB.; I am confused of my problem, can you help me.; Best and Thank you,. Meng",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6293:101,ERROR,ERROR,101,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6293,3,"['ERROR', 'error']","['ERROR', 'errors']"
Availability,"Hello!. When I try running gatk 4.0.7.0 on spark 2.2 Microsoft Azure hdinsight cluster (using data from here https://gatkforums.broadinstitute.org/gatk/discussion/6484/how-to-generate-an-unmapped-bam-from-fastq-or-aligned-bam#optionA) I get ""java.lang.NoClassDefFoundError: org/apache/logging/log4j/core/appender/AbstractAppender"" error like the one below. The thing that gatk-package-4.0.7.0-spark.jar has that class as can be verified by ; $jar tvf gatk-package-4.0.7.0-spark.jar; but nonetheless it seems like it does not load it correctly somehow. $java -version; openjdk version ""1.8.0_171""; OpenJDK Runtime Environment (build 1.8.0_171-8u171-b11-0ubuntu0.16.04.1-b11); OpenJDK 64-Bit Server VM (build 25.171-b11, mixed mode). What would be the possible fix for it?. $./gatk PrintReadsSpark -I ../6484_snippet.bam -O ../output.bam -- --spark-runner SPARK --spark-master spark://10.0.0.21:7077; Using GATK jar /root/gatk-4.0.7.0/gatk-package-4.0.7.0-spark.jar; Running:; /usr/hdp/current/spark2-client/bin/spark-submit --master spark://10.0.0.21:7077 --conf spark.driver.userClassPathFirst=false --conf spark.io.compression.codec=lzf --conf spark.driver.maxResultSize=0 --conf spark.executor.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 --conf spark.driver.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 --conf spark.kryoserializer.buffer.max=512m --conf spark.yarn.executor.memoryOverhead=600 /root/gatk-4.0.7.0/gatk-package-4.0.7.0-spark.jar PrintReadsSpark -I ../6484_snippet.bam -O ../output.bam --spark-master spark://10.0.0.21:7077; SLF4J: Class path contains multiple SLF4J bindings.; SLF4J: Found binding in [jar:file:/usr/hdp/2.6.3.40-13/spark2/jars/sl",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5126:331,error,error,331,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5126,1,['error'],['error']
Availability,"Hello, . I made two changes in output files of cnv_somatic_pair_workflow.wdl to fix bugs:; 1. Change ""File"" into ""String"" for all ""entity_id"" outputs. The ""File"" type will make error when Output Copying was used in cromwell, as there is no such file in output;; 2. Change ""File select_first([CNVOncotatorWorkflow.oncotated_called_file, ""null""])"" into ""File? oncotated_called_file_tumor"" for oncotate and funcotate outputs. If oncotate or funcotate was not performed, the original will output ""null"" and make error when Output Copying was used in cromwell, as there is ""null"" file in output;",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6735:177,error,error,177,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6735,2,['error'],['error']
Availability,"Hello, ; I have been using he GenotypeGVCFs function to call variants on roughly 300 whole genome sequenced individuals. I have not run into any issue when calling variants for these same individuals using the majority of chromosomes, however when I use the same script for chromosomes 1, 2 and 3 of the species I get the error ""Couldn't create GenomicsDBFeatureReader"" as in issue #6616 although I believe our issues may differ because I also have the errors ""Cannot read from buffer"" and ""cannot load book-keeping; Reading-tiles offset"". . Below is the computer output: . Using GATK jar /data1/_software/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Xmx16g -jar /data1/_software/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar GenotypeGVCFs --reference /data1/EquCab/_ECA30/Equus_caballus.EquCab3.0.dna_sm.toplevel.fa/ -V gendb://ECA3_GenomicsDB_260/1 -O ECA3_GenomicsDB_260.1.g.vcf.gz; 13:56:51.939 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/data1/_software/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Dec 21, 2020 1:56:52 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 13:56:52.185 INFO GenotypeGVCFs - ------------------------------------------------------------; 13:56:52.186 INFO GenotypeGVCFs - The Genome Analysis Toolkit (GATK) v4.1.8.1; 13:56:52.186 INFO GenotypeGVCFs - For support and documentation go to https://software.broadinstitute.org/gatk/; 13:56:52.186 INFO GenotypeGVCFs - Executing as ccastane9@andersserver-01.cvm.tamu.edu on Linux v3.10.0-1127.19.1.el7.x86_64 amd64; 13:56:52.186 INFO GenotypeGVCFs - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_275-b01; 13:56:52.186 INFO Gen",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7012:322,error,error,322,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7012,2,['error'],"['error', 'errors']"
Availability,"Hello, ; I want to merge multi HaplotypeCaller GVCF files into a single GVCF with **CombineGVCFs**, but I got a error warnings, **Key END found in VariantContext field INFO at Gbar_A01:24359 but this key isn't defined in the VCFHeader. We require all VCFs to have complete VCF headers by default.**; I ran the gatk with 4.1.6 version, here is my command.; `java -Xmx200g -jar /public/home/qymeng/biosoft/gatk-4.1.6.0/gatk-package-4.1.6.0-local.jar CombineGVCFs -O Gb.gatk.vcf -R /data/cotton/QingyingMeng/Gbarbadese_5Sample/3-79/Ref/Gbarbadense_3-79_HAU_v2.fasta -V Y2003/Y2003.gatk.vcf -V Y2010/Y2010.gatk.vcf -V Y2013/Y2013.gatk.vcf `,. I recheck my gvcf files and find the variant in the Y2010.gatk.vcf, which is a delete variant ; **Gbar_A01 24359 . GA G 847.03 . AC=2;AF=1.00;AN=2;DP=25;ExcessHet=3.0103;FS=0.000;MLEAC=2;MLEAF=1.00;MQ=46.41;QD=27.24;SOR=0.963 GT:AD:DP:GQ:PL 1/1:0,23:23:69:861,69,0** . I have no ideal to solve it, did anyone eocounter the same error warnings,. Best wishes,; Qingying. And here is my log . 21:09:58.763 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/public/home/qymeng/biosoft/gatk-4.1.6.0/gatk-package-4.1.6.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Mar 06, 2022 9:09:59 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 21:09:59.072 INFO CombineGVCFs - ------------------------------------------------------------; 21:09:59.073 INFO CombineGVCFs - The Genome Analysis Toolkit (GATK) v4.1.6.0; 21:09:59.073 INFO CombineGVCFs - For support and documentation go to https://software.broadinstitute.org/gatk/; 21:09:59.073 INFO CombineGVCFs - Executing as qymeng@s004 on Linux v3.10.0-862.el7.x86_64 amd64; 21:09:59.073 INFO CombineGVCFs - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_92-b15; 21:09:59.073 INFO CombineGVCFs - Start Date/Time: March 6, 2022 9:09:58 PM CST; 21:09:59.073 INFO CombineGVCFs - ---",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7708:112,error,error,112,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7708,2,['error'],['error']
Availability,"Hello, ; I was trying to create a candidates SNP list for **GATK4 BaseRecalibrator** to recalibrate the alignment for SNP calling. And I met a problem with the indexing of the my vcf file of candidates SNPs. ; The indexing step and recalibrating step ran without any error, but only very small amount of SNPs (~2900) were detected from a genome **~15Gbp** size, which is definitely not correct as compared with other methods when **~million SNPs** were detected. ; I tracked down the problem is at the indexing step for the candidates vcf file (**925751 SNPs, through HaplotypeCaller**). The problem looks like only the **last chromosome** was indexed.; This is my log file in which the Google engine related part was omitted as I did not use it: ; ```; $ cat ${LOGDIR}/index_candidates.log. (09:28:38.902 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/storage/ppl/yifang/download-software/anaconda3/envs/exome/share/gatk4-4.1.0.0-0/gatk-package-4.1.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; May 06, 2019 9:28:39 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; WARNING: Failed to detect whether we are running on Google Compute Engine.; java.net.ConnectException: Connection refused; 	at java.net.PlainSocketImpl.socketConnect(Native Method). ...... May 06, 2019 9:28:39 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; WARNING: Failed to detect whether we are running on Google Compute Engine.; java.net.ConnectException: Connection refused; 	at java.net.PlainSocketImpl.socketConnect(Native Method); 	; May 06, 2019 9:28:39 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; WARNING: Failed to detect whether we are running on Google Compute Engine.; java.net.ConnectException: Connection refused. ...... 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:205); 	at org.broadinstitute.hellbender.Main.main(Main.java:291).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5917:267,error,error,267,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5917,3,"['down', 'error']","['down', 'download-software', 'error']"
Availability,"Hello, GATK team. When I genotyped 309 samples using the GenotypeGVCFs module, there was a memory overflow error (either using -Xmx20G/100G/800G with 1TB of physical memory). The same memory error can occur in CombineGVCFs, so I select GenomicsDBImport for genome-merging. This is the code when using GenomicsDBImport, completed successfully.; ```; gatk GenomicsDBImport \; -R $path1/ref/genome.fa --java-options ""-Xmx100g -Xms80g"" \; $(for i in $(ls $path1/sortbam/2/*.g.vcf.gz); do echo ""--variant $i""; done) \; $(for i in $(ls $path1/sortbam/4/*.g.vcf.gz); do echo ""--variant $i""; done) \; $(for i in $(ls $path1/sortbam/6/*.g.vcf.gz); do echo ""--variant $i""; done) \; --genomicsdb-workspace-path $path1/DBI \; --tmp-dir $path1/NOHUP/tmp --intervals $path1/chr.list; ```; But when I run the following **GenotypeGVCFs code**: ; ```; gatk --java-options '-Xmx800G -DGATK_STACKTRACE_ON_USER_EXCEPTION=true' GenotypeGVCFs \; -R $path1/ref/genome.fa -V gendb://$path1/DBI \; -O $path1/sortbam/combDBI.vcf.gz --tmp-dir $path1/NOHUP/tmp. ```; **It warns**: [TileDB::ReadState] Error: Cannot read tile from file; Memory map error. ```; 21:02:06.717 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/wtc/software/gatk-4.2.0.0/gatk-package-4.2.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Apr 29, 2023 9:02:06 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 21:02:06.864 INFO GenotypeGVCFs - ------------------------------------------------------------; 21:02:06.864 INFO GenotypeGVCFs - The Genome Analysis Toolkit (GATK) v4.2.0.0; 21:02:06.864 INFO GenotypeGVCFs - For support and documentation go to https://software.broadinstitute.org/gatk/; 21:02:06.864 INFO GenotypeGVCFs - Executing as wtc@PC10-7742 on Linux v4.4.0-19041-Microsoft amd64; 21:02:06.864 INFO GenotypeGVCFs - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_121-b15; 21:02:06.865 IN",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8302:107,error,error,107,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8302,5,"['echo', 'error']","['echo', 'error']"
Availability,"Hello, I am getting this error when running **gatk MarkDuplicatesSpark -I file.bam -O spark.bam** :. A USER ERROR has occurred: Failed to load reads from file.bam; Caused by:Unsupported class file major version 55. Any solutions?. Thank you.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6350:25,error,error,25,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6350,2,"['ERROR', 'error']","['ERROR', 'error']"
Availability,"Hello, I made a PoN with my samples and created an hdf5 PoN. This was made using . ##Preprocess; ``; gatk PreprocessIntervals -R ref/hs37d5.fa --bin-length 10000 --padding 0 -O preprocessed_intervals.interval_list; ``. ##annotate; ``; gatk AnnotateIntervals -R ref/hs37d5.fa -L preprocessed_intervals.interval_list --interval-merging-rule OVERLAPPING_ONLY -O annotated_intervals.tsv; ``. ##PoN; ``; gatk --java-options ""-Xmx6500m"" CreateReadCountPanelOfNormals -I MD0078B1.counts.hdf5 -I MD1341B1.counts.hdf5 --minimum-interval-median-percentile 5.0 -O sandbox/cnvponC.pon.hdf5; ``. When I use DenoiseReadCounts on the .counts.hdf5 for the tumour samples, I get an error.; This is the command I used: ; ``; gatk DenoiseReadCounts -I BT1813.counts.hdf5 --count-panel-of-normals cnvponC2.pon.hdf5 --standardized-copy-ratios BT1813.standardizedCR.tsv --denoised-copy-ratios BT1813.denoisedCR.tsv; ``. I know that some of these errors are expected but I don't see any other errors and I'm not sure why it stopped running. Any help would be appreciated thank you!. ##Affected Version: gatk/4.0.1.2. ##Bug Report. Using GATK jar /hpf/tools/centos6/gatk/4.0.1.2/gatk-package-4.0.1.2-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -jar /hpf/tools/centos6/gatk/4.0.1.2/gatk-package-4.0.1.2-local.jar DenoiseReadCounts -I BT1813.counts.hdf5 --count-panel-of-normals cnvponC2.pon.hdf5 --standardized-copy-ratios BT1813.standardizedCR.tsv --denoised-copy-ratios BT1813.denoisedCR.tsv; 20:08:44.839 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/hpf/tools/centos6/gatk/4.0.1.2/gatk-package-4.0.1.2-local.jar!/com/intel/gkl/native/libgkl_compression.so; 20:08:45.222 INFO DenoiseReadCounts - ------------------------------------------------------------; 20:08:45.222 INFO DenoiseReadCounts - The Genome Analysis Toolkit (GATK) v4.0.1.2; 20:08:45.222 INFO D",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7258:665,error,error,665,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7258,3,['error'],"['error', 'errors']"
Availability,"Hello, I use GATK tools quite often in my daily work life. I use quite a lot of sample data every time I use it. The fact that GATK tools use a single core causes analysis processes to take quite a long time. Although I command --java-options ""-Xmx32G -XX:ParallelGCThreads=8"" to GATK tools, GATK tools slow down the process by using only one thread instead of using 8 threads. How can I get GATK tools to use 8 threads? Thank you.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6941:308,down,down,308,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6941,1,['down'],['down']
Availability,"Hello, I use gatk-4.1.1.0. The `ModelSegments` command always throw `OutOfMemoryError`. Error message is long, I paste a few line of it.; ```bash; [May 20, 2019 4:43:37 AM CST] org.broadinstitute.hellbender.tools.copynumber.ModelSegments done. Elapsed time: 357.17 minutes.; Runtime.totalMemory()=28631367680; Exception in thread ""main"" java.lang.OutOfMemoryError: GC overhead limit exceeded; at java.lang.AbstractStringBuilder.<init>(AbstractStringBuilder.java:68); at java.lang.StringBuilder.<init>(StringBuilder.java:101); ```; I don't think this is caused by memory size. I set max memory to 500G, my `denoised_copy_ratios` input file size is `5.7M` and `AllelicCounts` inpute file size is `3.2G`. ; After some search, [this website](https://www.oracle.com/technetwork/java/javase/gc-tuning-6-140523.html#par_gc.oom) gives an explanation. ; > The parallel collector will throw an OutOfMemoryError if too much time is being spent in garbage collection: if more than 98% of the total time is spent in garbage collection and less than 2% of the heap is recovered, an OutOfMemoryError will be thrown. This feature is designed to prevent applications from running for an extended period of time while making little or no progress because the heap is too small. If necessary, this feature can be disabled by adding the option -XX:-UseGCOverheadLimit to the command line.; > ; This means some code bug?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5948:88,Error,Error,88,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5948,2,"['Error', 'recover']","['Error', 'recovered']"
Availability,"Hello, I was using GATK4 LiftoverVcf to adjust the coordinates of variants in my vcf4.2 file (created by plink1.9) to hg38 reference build. However, I got this error:; The provided VCF file is malformed at approximately line number 218: Insertions/Deletions are not supported when reading 3.x VCF's. Please convert your file to VCF4 using VCFTools, available at http://vcftools.sourceforge.net/index.html. And I tried to use vcf-convert in vcftools to convert my vcf4.2 file to vcf4.0 form, but the problem was not solved.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7460:160,error,error,160,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7460,2,"['avail', 'error']","['available', 'error']"
Availability,"Hello, When I implement ""HaplotypeCaller"" commands, the reference genome is about 15G , every chromosome is more then 600M, I get some errors, could you give me some advice?; the commands; ```; # the step is after marked duplication ; samtools index -c markdup.bam.gz; gatk --java-options ""-Xmx100G -Djava.io.tmpdir=./"" HaplotypeCaller -R Triticum_aestivum.IWGSC.dna.toplevel.fa -I rmarkdup.bam.gz -O SRR9851087.gvcf.gz -ERC GVCF -OVI >3gvcf.log 2>&1; ```; the bug:; ```; Using GATK jar /home/ywt/anaconda3/share/gatk4-4.3.0.0-0/gatk-package-4.3.0.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx100G -Djava.io.tmpdir=./ -jar /home/ywt/anaconda3/share/gatk4-4.3.0.0-0/gatk-package-4.3.0.0-local.jar HaplotypeCaller -R Triticum_aestivum.IWGSC.dna.; toplevel.fa -I rmarkdup.bam.gz -O SRR9851087.gvcf.gz -ERC GVCF -OVI; 09:01:25.845 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/ywt/anaconda3/share/gatk4-4.3.0.0-0/gatk-package-4.3.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; 09:01:25.950 INFO HaplotypeCaller - ------------------------------------------------------------; 09:01:25.950 INFO HaplotypeCaller - The Genome Analysis Toolkit (GATK) v4.3.0.0; 09:01:25.950 INFO HaplotypeCaller - For support and documentation go to https://software.broadinstitute.org/gatk/; 09:01:25.950 INFO HaplotypeCaller - Executing as ywt@ywt-Precision-5820-Tower on Linux v5.15.0-41-generic amd64; 09:01:25.950 INFO HaplotypeCaller - Java runtime: OpenJDK 64-Bit Server VM v17.0.5+8-Ubuntu-2ubuntu122.04; 09:01:25.950 INFO HaplotypeCaller - Start Date/Time: February 8, 2023 at 9:01:25 AM CST; 09:01:25.950 INFO HaplotypeCaller - ------------------------------------------------------------; 09:01:25.950 INFO HaplotypeCaller - ------------------------------------------------------------; 09:01:25.951 INFO HaplotypeCaller - HTSJDK V",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8192:135,error,errors,135,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8192,1,['error'],['errors']
Availability,"Hello, i'm trying to run GATK4 BaseRecalibratorSpark in local in a nextflow pipeline, but I got every time the same error with this command :. **gatk-launch BaseRecalibratorSpark --spark-runner LOCAL --spark-master local[23] -R $indexbit -I ${input_bam} --known-sites ${params.dbsnpAll} -L ${params.targetBed} -O ${output_name}-recalibration_report.grp**. Here is the full error output, basically, the failure seems to be linked to an absence of activity of the BaseRecalibratorSpark during 12s which kill the spark heartbeat and then the processus :. ```; 18/03/09 09:22:08 WARN Executor: Issue communicating with driver in heartbeater; java.lang.NullPointerException; at org.apache.spark.storage.memory.MemoryStore.getSize(MemoryStore.scala:127); at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$getCurrentBlockStatus(BlockManager.scala:387); at org.apache.spark.storage.BlockManager$$anonfun$reportAllBlocks$3.apply(BlockManager.scala:218); at org.apache.spark.storage.BlockManager$$anonfun$reportAllBlocks$3.apply(BlockManager.scala:217); at scala.collection.Iterator$class.foreach(Iterator.scala:893); at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); at org.apache.spark.storage.BlockManager.reportAllBlocks(BlockManager.scala:217); at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:236); at org.apache.spark.executor.Executor.org$apache$spark$executor$Executor$$reportHeartBeat(Executor.scala:522); at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply$mcV$sp(Executor.scala:547); at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply(Executor.scala:547); at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply(Executor.scala:547); at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1953); at org.apache.spark.executor.Executor$$anon$1.run(Executor.scala:547); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4515:116,error,error,116,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4515,5,"['error', 'failure', 'heartbeat']","['error', 'failure', 'heartbeat', 'heartbeater']"
Availability,"Hello, more information on the parameters and runtime can be found here: #7492 . the stacktrace is now:; ```; ...; 22:14:59.985 INFO ProgressMeter - chrUn_JTFH01001653v1_decoy:301 116.6 2161460 18530.7; 22:15:11.142 INFO ProgressMeter - chrUn_JTFH01001673v1_decoy:301 116.8 2161540 18501.9; Using GATK jar /root/gatk.jar defined in environment variable GATK_LOCAL_JAR; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx15500m -jar /root/gatk.jar Mutect2 -R gs://genomics-public-data/resources/broad/hg38/v0/Homo_sapiens_assembly38.fasta -I gs://cclebams/hg38_wes/CDS-02waxZ.hg38.bam -tumor TUHR14TKB --germline-resource gs://depmapomicsdata/gnomad.genomes.r3.0.sites.vcf.bgz -pon gs://depmapomicsdata/1000g_pon.hg38.vcf.gz -L gs://fc-secure-d2a2d895-a7af-4117-bdc7-652d7d268324/cec2a1a6-ffc3-4f1b-ba94-27ae918c56e9/Mutect2/b389d86b-8b0b-4d77-8224-a5a3e3a0b4e5/call-SplitIntervals/cacheCopy/glob-0fc990c5ca95eebc97c4c204e3e303e1/0004-scattered.interval_list -O output.vcf.gz --f1r2-tar-gz f1r2.tar.gz --gcs-project-for-requester-pays broad-firecloud-ccle; ln: failed to access '/cromwell_root/*normal-pileups.table': No such file or directory; ln: failed to access '/cromwell_root/*tumor-pileups.table': No such file or directory; 2021/10/05 22:15:24 Starting delocalization.; ...; ```. I run mutect2 in tumor only mode. ; Interestingly, this error always only happen at the last shard only (every other shard runs to completion). Thanks!",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7494:1466,error,error,1466,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7494,1,['error'],['error']
Availability,"Hello,. Could you help me with this? I ran this code:; ```; prg=/home/user1/Programs/gatk-4.5.0.0; log_dir=/home/user1/Programs/logs; java -Xmx64g -XX:ParallelGCThreads=2 -DGATK_STACKTRACE_ON_USER_EXCEPTION=true \; -jar ${prg}/gatk-package-4.5.0.0-local.jar IndexFeatureFile -I ${dir}/snp_allsamples.vcf.gz \; --output snp_allsamples.vcf.tbi \; 2>${log_dir}/snp_allsamples_gvcf_index.err. ```; and I received the following error message. ```; 09:36:35.254 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/user1/Programs/gatk-4.5.0.0/gatk-package-4.5.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; 09:36:35.386 INFO IndexFeatureFile - ------------------------------------------------------------; 09:36:35.389 INFO IndexFeatureFile - The Genome Analysis Toolkit (GATK) v4.5.0.0; 09:36:35.389 INFO IndexFeatureFile - For support and documentation go to https://software.broadinstitute.org/gatk/; 09:36:35.389 INFO IndexFeatureFile - Executing as user1@xxx.xx on Linux v5.4.0-150-generic amd64; 09:36:35.389 INFO IndexFeatureFile - Java runtime: OpenJDK 64-Bit Server VM v17.0.3-internal+0-adhoc..src; 09:36:35.389 INFO IndexFeatureFile - Start Date/Time: March 21, 2024 at 9:36:35 a.m. CST; 09:36:35.390 INFO IndexFeatureFile - ------------------------------------------------------------; 09:36:35.390 INFO IndexFeatureFile - ------------------------------------------------------------; 09:36:35.390 INFO IndexFeatureFile - HTSJDK Version: 4.1.0; 09:36:35.391 INFO IndexFeatureFile - Picard Version: 3.1.1; 09:36:35.391 INFO IndexFeatureFile - Built for Spark Version: 3.5.0; 09:36:35.391 INFO IndexFeatureFile - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 09:36:35.391 INFO IndexFeatureFile - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 09:36:35.392 INFO IndexFeatureFile - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 09:36:35.392 INFO IndexFeatureFile - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 09:36:35.392 INFO IndexFeature",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8747:423,error,error,423,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8747,1,['error'],['error']
Availability,"Hello,. I am running GATK GenotypeGVCFs v4.2.5.0 using a command similar to the one below. I downloaded the gatk ZIP from github, unzipped, and we run the local JAR (renamed to GenomeAnalysisTK4.jar). I am consistently getting a strange NoClassDefFoundError error (below). I noticed com/google/common/base is relocated in the shadowJar step, and that is the class it's complaining about here. Have you seen an error like this before?. ```; /home/exacloud/gscratch/prime-seq/java/java8/bin/java \; 	-Djava.io.tmpdir=<path> \; 	-Xmx178g -Xms178g \; 	-Xss2m \; 	-jar GenomeAnalysisTK4.jar \; 	GenotypeGVCFs \; 	-R 128_Mmul_10.fasta \; 	--variant gendb:///home/exacloud/gscratch/prime-seq/cachedData/16b9ede7-6db8-103a-9262-f8f3fc86a851/WGS_Feb22_1852.gdb \; 	-O /home/exacloud/gscratch/prime-seq/workDir/1bb5295c-6ec5-103a-8692-f8f3fc86cd3f/Job1.work/WGS_pre-mGAPv2.3_1852.vcf.gz \; 	--annotate-with-num-discovered-alleles \; 	-stand-call-conf 30 \; 	--max-alternate-alleles 6 \; 	--force-output-intervals mmul10.WGS-WXS.whitelist.v2.3.sort.merge.bed \; 	-L 1:1-3714165 \; 	--only-output-calls-starting-in-intervals \; 	--genomicsdb-shared-posixfs-optimizations; ```. and the exception:. ```; Exception in thread ""main"" java.lang.NoClassDefFoundError: org/broadinstitute/hellbender/relocated/com/google/common/base/Function; 	at org.broadinstitute.hellbender.Main.<clinit>(Main.java:45); Caused by: java.lang.ClassNotFoundException: org.broadinstitute.hellbender.relocated.com.google.common.base.Function; 	at java.net.URLClassLoader$1.run(URLClassLoader.java:370); 	at java.net.URLClassLoader$1.run(URLClassLoader.java:362); 	at java.security.AccessController.doPrivileged(Native Method); 	at java.net.URLClassLoader.findClass(URLClassLoader.java:361); 	at java.lang.ClassLoader.loadClass(ClassLoader.java:424); 	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331); 	at java.lang.ClassLoader.loadClass(ClassLoader.java:357); 	... 1 more; Caused by: java.util.zip.ZipException: invalid LOC h",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7675:93,down,downloaded,93,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7675,3,"['down', 'error']","['downloaded', 'error']"
Availability,"Hello,. I am running GenotypeGVCFs using a GenomicsDB workspace with ~1200 WGS samples as input. We're running these jobs scattered on a slurm/lustre cluster, with each job given intervals. ~197/200 jobs finished, but several gave an odd error. I'm probably not giving you enough information to debug, but maybe this is enough to ask questions. the command is below:. ```. java8 -Xmx48g -Xms48g -Xss2m \; -jar GenomeAnalysisTK4.jar GenotypeGVCFs \; -R REF.fasta \; --variant gendb://<genomicsdb_path> \; -O OUTPUT.vcf.gz \; --annotate-with-num-discovered-alleles \; -stand-call-conf 30 --max-alternate-alleles 12 \; -L <Repeated ~40 times for small contigs>. ```; ; The error is the following:. ```. 21:58:51.873 WARN  MinimalGenotypingEngine - Attempting to genotype more than 50 alleles. Site will be skipped at location QNVO02001146.1:1343; --; 21:59:01.308 INFO  ProgressMeter -  QNVO02001146.1:1679            425.0               1264000           2974.3; GENOMICSDB_TIMER,GenomicsDB iterator next() timer,Wall-clock time(s),6.825391631999999,Cpu time(s),6.825079531999995; #; # A fatal error has been detected by the Java Runtime Environment:; #; #  SIGSEGV (0xb) at pc=0x00007fcca9a2ea19, pid=36873, tid=140574431450880; #; # JRE version: Java(TM) SE Runtime Environment (8.0_60-b27) (build 1.8.0_60-b27); # Java VM: Java HotSpot(TM) 64-Bit Server VM (25.60-b23 mixed mode linux-amd64 ); # Problematic frame:; # C  [libtiledbgenomicsdb3086049122144672414.so+0x3e3a19]  ArraySchema::tile_num(void const*) const+0x79; #; # Core dump written. Default location: /home/groups/MgapGenomicsDb/@files/sequenceOutputPipeline/SequenceOutput_2020-10-06_16-46-33/Job734/core or core.36873; #; # An error report file with more information is saved as:; # /home/groups/MgapGenomicsDb/@files/sequenceOutputPipeline/SequenceOutput_2020-10-06_16-46-33/Job734/hs_err_pid36873.log; #; # If you would like to submit a bug report, please visit:; #   http://bugreport.java.com/bugreport/crash.jsp; # The crash happen",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6910:238,error,error,238,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6910,2,['error'],['error']
Availability,"Hello,. I am trying to set up a python environment to use gatk DetermineGermlineContigPloidy module. I cannot use conda. I have tried to install in a virtual python environment the dependencies found in these two files:. gatk/scripts/gatkcondaenv.yml.template ; gatk/src/main/python/org/broadinstitute/hellbender/setup_gcnvkernel.py. I have installed gcnvkernel in my virtual environment. . ----. This is the error message I get when I try to import gcnvkernel: python -c ""import gcnvkernel"". Traceback (most recent call last):; File ""/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.6.10/lib/python3.6/configparser.py"", line 1138, in _unify_values; sectiondict = self._sections[section]; KeyError: 'blas'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/lustre04/scratch/helene/Ticket/0196857/ENV_python_3.6.10/lib/python3.6/site-packages/theano/configparser.py"", line 168, in fetch_val_for_key; return theano_cfg.get(section, option); File ""/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.6.10/lib/python3.6/configparser.py"", line 781, in get; d = self._unify_values(section, vars); File ""/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.6.10/lib/python3.6/configparser.py"", line 1141, in _unify_values; raise NoSectionError(section); configparser.NoSectionError: No section: 'blas'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/lustre04/scratch/helene/Ticket/0196857/ENV_python_3.6.10/lib/python3.6/site-packages/theano/configparser.py"", line 328, in __get__; delete_key=delete_key); File ""/lustre04/scratch/helene/Ticket/0196857/ENV_python_3.6.10/lib/python3.6/site-packages/theano/configparser.py"", line 172, in fetch_val_for_key; raise KeyError(key); KeyError: 'blas.ldflags'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File """,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8387:409,error,error,409,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8387,1,['error'],['error']
Availability,"Hello,. I am using the latest gatk4 from bioconda (4.0.2.0-0). I have genotyped 40 bacterial samples with HaplotypeCaller and -ERC BP_RESOLUTION. I have then merged the gvcfs files in a genomic db using GenomicsDBImport. However, when I try genotyping this genomics db, the genotyper starts but hangs rather rapidly like so : . ```; 07:18:31.127 INFO ProgressMeter - NC_016854.1:20000 0.2 20000 86132.6; 07:18:42.173 INFO ProgressMeter - NC_016854.1:58000 0.4 58000 139322.6; 07:21:16.150 INFO ProgressMeter - NC_016854.1:82000 3.0 82000 27493.1; 07:21:27.087 INFO ProgressMeter - NC_016854.1:99000 3.2 99000 31280.9; 07:24:06.157 INFO ProgressMeter - NC_016854.1:102000 5.8 102000 17537.7; 07:24:16.220 INFO ProgressMeter - NC_016854.1:138000 6.0 138000 23062.5; 07:24:29.116 INFO ProgressMeter - NC_016854.1:175000 6.2 175000 28231.8; 07:43:58.742 INFO GenotypeGVCFs - Shutting down engine; GENOMICSDB_TIMER,GenomicsDB iterator next() timer,Wall-clock time(s),29.644886145999088,Cpu time(s),29.480321756000397; Using GATK jar /opt/conda/envs/789546e2/share/gatk4-4.0.1.1-0/gatk-package-4.0.1.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -jar /opt/conda/envs/789546e2/share/gatk4-4.0.1.1-0/gatk-package-4.0.1.1-local.jar GenotypeGVCFs -ploidy 1 -R references/359488/genome_fasta.fasta --annotate-with-num-discovered-alleles true --annotations-to-exclude InbreedingCoeff -V gendb://typing/gatk_gvcfs/full_genome/359488/bwa/genomics_db -O typing/gatk_gvcfs/full_genome/359488/bwa/all_samples.vcf; ```; In between the last ProgressMeter and the Shutting down of the engine, I see the java process still running with top. Do you know what could be causing the problem ? Could it be related to -ERC BP_RESOLUTION ? I used to use -ERC GVCF before but I would rather keep the information of the coverage for post filtering, and I am not sure how to use --GVCFGQBands to",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4467:880,down,down,880,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4467,1,['down'],['down']
Availability,"Hello,. I use GATK(4.2.0.0) HaplotypeCaller call SNPs and CombineGVCFs combining the .g.vcf files. everything goes well.; However, when I use GenotypeGVCFs, I encounter an error [htsjdk.samtools.SAMFormatException: Did not inflate expected amount]. And I see the same Error in [#7582](https://github.com/broadinstitute/gatk/issues/7582), I try to add two parameters --use-jdk-deflater & --use-jdk-inflater, but I get the new Error [java.util.zip.DataFormatException: invalid code lengths set]. ----. ### Version and Tools; GATK 4.2.0.0 GenotypeGVCFs. ### The commend ; java -Xmx10g -jar /home/software/gatk-4.2.0.0/gatk-package-4.2.0.0-local.jar GenotypeGVCFs --use-jdk-inflater true --use-jdk-deflater true -R ref.rename.fa -V test.vcf.gz -O test_geno.vcf.gz. ### Error log 1. 21:12:43.028 INFO GenotypeGVCFs - Shutting down engine; [2021年12月20日 下午09时12分43秒] org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs done. Elapsed time: 6.12 minutes.; Runtime.totalMemory()=4856479744; htsjdk.samtools.SAMFormatException: Did not inflate expected amount; 	at htsjdk.samtools.util.BlockGunzipper.unzipBlock(BlockGunzipper.java:147); 	at htsjdk.samtools.util.BlockGunzipper.unzipBlock(BlockGunzipper.java:96); 	at htsjdk.samtools.util.BlockCompressedInputStream.inflateBlock(BlockCompressedInputStream.java:550); 	at htsjdk.samtools.util.BlockCompressedInputStream.processNextBlock(BlockCompressedInputStream.java:532); 	at htsjdk.samtools.util.BlockCompressedInputStream.nextBlock(BlockCompressedInputStream.java:468); 	at htsjdk.samtools.util.BlockCompressedInputStream.readBlock(BlockCompressedInputStream.java:458); 	at htsjdk.samtools.util.BlockCompressedInputStream.available(BlockCompressedInputStream.java:196); 	at htsjdk.samtools.util.BlockCompressedInputStream.read(BlockCompressedInputStream.java:331); 	at htsjdk.samtools.util.BlockCompressedInputStream.read(BlockCompressedInputStream.java:257); 	at htsjdk.tribble.readers.PositionalBufferedStream.fill(PositionalBufferedStream.java:132);",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7614:172,error,error,172,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7614,5,"['Error', 'down', 'error']","['Error', 'down', 'error']"
Availability,"Hello,. I'd like to report a FilterMutectCalls error. It was run using mutect2.wdl with gatk 4.0.12.0.; FilterMutectCalls of gatk 4.0.10.1 succeeded using same input.; Please let me know if there is something else I can provide. Thank you. ```; java.lang.IllegalArgumentException: errorRateLog10 must be good probability but got NaN; at org.broadinstitute.hellbender.utils.QualityUtils.phredScaleLog10ErrorRate(QualityUtils.java:321); at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2FilteringEngine.lambda$applyGermlineVariantFilter$10(Mutect2FilteringEngine.java:207); at java.util.stream.DoublePipeline$3$1.accept(DoublePipeline.java:231); at java.util.Spliterators$DoubleArraySpliterator.forEachRemaining(Spliterators.java:1198); at java.util.Spliterator$OfDouble.forEachRemaining(Spliterator.java:822); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:545); at java.util.stream.AbstractPipeline.evaluateToArrayNode(AbstractPipeline.java:260); at java.util.stream.IntPipeline.toArray(IntPipeline.java:502); at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2FilteringEngine.applyGermlineVariantFilter(Mutect2FilteringEngine.java:207); at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2FilteringEngine.calculateFilters(Mutect2FilteringEngine.java:436); at org.broadinstitute.hellbender.tools.walkers.mutect.FilterMutectCalls.firstPassApply(FilterMutectCalls.java:120); at org.broadinstitute.hellbender.engine.TwoPassVariantWalker.lambda$traverseVariants$0(TwoPassVariantWalker.java:76); at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); at java.util.Iterator.forEachRemaining(Iterator.java:116); at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); at ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5553:47,error,error,47,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5553,1,['error'],['error']
Availability,"Hello,. I'm testing gatk4.3 against 3 WES samples. For less time comsuption, I scattered the bed file into 45 small interval list. But an error prompted out in the GermlineCNVCaller step with the err below:. ```; 23:43:52.386 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/gpfs/hpc/home/lijc/xiangxud/software/miniconda3/envs/gatk4/share/gatk4-4.3.0.0-0/gatk-package-4.3.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; 23:43:52.401 DEBUG NativeLibraryLoader - Extracting libgkl_compression.so to /tmp/libgkl_compression16416313594950485777.so; 23:43:52.469 INFO GermlineCNVCaller - ------------------------------------------------------------; 23:43:52.469 INFO GermlineCNVCaller - The Genome Analysis Toolkit (GATK) v4.3.0.0; 23:43:52.469 INFO GermlineCNVCaller - For support and documentation go to https://software.broadinstitute.org/gatk/; 23:43:52.470 INFO GermlineCNVCaller - Executing as xiangxud@cu22 on Linux v3.10.0-1160.el7.x86_64 amd64; 23:43:52.470 INFO GermlineCNVCaller - Java runtime: OpenJDK 64-Bit Server VM v11.0.8-internal+0-adhoc..src; 23:43:52.470 INFO GermlineCNVCaller - Start Date/Time: August 3, 2024 at 11:43:52 PM CST; 23:43:52.470 INFO GermlineCNVCaller - ------------------------------------------------------------; 23:43:52.470 INFO GermlineCNVCaller - ------------------------------------------------------------; 23:43:52.470 INFO GermlineCNVCaller - HTSJDK Version: 3.0.1; 23:43:52.470 INFO GermlineCNVCaller - Picard Version: 2.27.5; 23:43:52.470 INFO GermlineCNVCaller - Built for Spark Version: 2.4.5; 23:43:52.471 INFO GermlineCNVCaller - HTSJDK Defaults.BUFFER_SIZE : 131072; 23:43:52.471 INFO GermlineCNVCaller - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 23:43:52.471 INFO GermlineCNVCaller - HTSJDK Defaults.CREATE_INDEX : false; 23:43:52.471 INFO GermlineCNVCaller - HTSJDK Defaults.CREATE_MD5 : false; 23:43:52.471 INFO GermlineCNVCaller - HTSJDK Defaults.CUSTOM_READER_FACTORY : ; 23:43:52.471 INFO GermlineCNVCaller - HTSJ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8938:138,error,error,138,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8938,1,['error'],['error']
Availability,"Hello,. I'm trying to use the CNVGermline Pipeline with Nextflow and a GATK Singularity image pulled from your Docker image. . As you can see, I'm trying to run the DetermineGermlineContigPloidy with 57 samples, and I got a permission error within my Singularity container. This error is directly related to Singularity permissions to create a directory ('/root/.theano/compiledir_Linux-4.10--generic-x86_64-with-debian-stretch-sid-x86_64-3.6.2-64'), because it's running fine with Singularity when I'm root and Docker (without root). So it's not really a GATK4 problem but more a singularity-GATK4 related problem. Maybe your GATK4 Germline CNV calling pipeline is not designed to work as a Singularity container (which is quite understandable), because for tools like HaplotypeCaller, MarkDuplicates ... It's working fine. I didn't know where to post this error, singularity or GATK github, so why not both ! . Do you have any idea make it run properly ? Change a bit the design of your CNV pipeline to make it compatible with Singularity ?. ## Version of softwares:. Singularity : 2.5.1, GATK : 4.0.4.0. ### Command. Singularity : ; singularity build gatk-4.0.4.0.img docker://broadinstitute/gatk:4.0.4.0. GATK4 : ; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /gatk/build/libs/gatk-package-4.0.4.0-local.jar DetermineGermlineContigPloidy --input 2044098202-8046_S5_sample.counts.hdf5 --input 2045946179-9076_S2_sample.counts.hdf5 --input 2045946166-9075_S1_sample.counts.hdf5 --input 2048220927-11022_S4_sample.counts.hdf5 --input 2045599261-9046ci_S1_sample.counts.hdf5 --input 2046745668-1007_S5_sample.counts.hdf5 --input 2044098101-8043_S2_sample.counts.hdf5 --input 2044098168-8044_S3_sample.counts.hdf5 --input 2046746598-1012_S4_sample.counts.hdf5 --input 2044395763-8064ci_S4_sample.counts.hdf5 --input 2044395647-8061ci_S1_sample.counts.hdf5 --input 70-20-CI_S3_sample",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4782:235,error,error,235,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4782,3,['error'],['error']
Availability,"Hello,. I'm using the GATK4 docker image to evaluate the efficiency of my targeted experiment. After googling around, I realize that CollectHsMetrics is the tool to use from now on (correct me if i'm wrong). The old DepthOfCoverage, CalculateTargetCoverage, CalculateHsMetrics are not available anymore, so I'm trying to implement this utility in our pipeline. Given the fact I'm providing the same file as the BAITS_INTERVALS and TARGETS_INTERVALS, I'd expect the PCT_OFF_BAIT and PCT_EXC_OFF_TARGET to be the same, but then I [read here](https://gatkforums.broadinstitute.org/gatk/discussion/7442/collecthsmetrics) that the ON_BAIT_BASES and ON_TARGET_BASES may actually differ due to the fact one relies on the NEAR_DISTANCE argument (that only applies on the ON_BAIT_BASES) and other depends on some read filters (MINIMUM_BASE_QUALITY and MINIMUM_MAPPING_QUALITY that may apply to ON_TARGET_BASES, didn't find any documention on that). Indeed, I observed the described differences in the ON_BAIT_BASES/ON_TARGET_BASES metrics:. > ON_BAIT_BASES 1733719583; ON_TARGET_BASES 1274990601. which was reflected in the PCT_SELECTED_BASES (Fraction of bases from reads passing the filters located on or near a baited region):; > PCT_SELECTED_BASES 0.690911. Then, for the PCT_EXC_OFF_TARGET (Fraction of aligned bases that were filtered out because they did not align over a target base.) I got:; >PCT_EXC_OFF_TARGET 0.731878. which doesn't make sense to be so high. Shouldn't this value be close to the result of (`1-PCT_SELECTED_BASES`) , given that the BAITS and TARGETS intervals file is the same ?. Sending this example attached.; [H2106.1_HS_metrics.txt](https://github.com/broadinstitute/gatk/files/1643326/H2106.1_HS_metrics.txt). Best,; Pedro Barbosa",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4200:285,avail,available,285,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4200,1,['avail'],['available']
Availability,"Hello,. We're trying to run GenotypeGVCFs on a large genomicsDB workspace. The command is below, with the output. We run these jobs scatter/gather, with each job getting a define, small interval set. Despite being given a huge amount of RAM (testing >250GB), virtually all of the jobs die without any messages right after the ""Starting traversal' message. A few gave error messages like the one below. . In this example, you'll see it's running with Xmx178g. We added 60G to the cluster memory request to leave buffer for the C layer. We're on v4.2.5.0. Does this error look familiar, and/or do you have any troubleshooting suggestions? Thanks in advance. ```; /home/exacloud/gscratch/prime-seq/java/java8/bin/java \; 	-Djava.io.tmpdir=<path> \; 	-Xmx178g -Xms178g \; 	-Xss2m \; 	-jar GenomeAnalysisTK4.jar \; 	GenotypeGVCFs \; 	-R 128_Mmul_10.fasta \; 	--variant gendb:///home/exacloud/gscratch/prime-seq/cachedData/16b9ede7-6db8-103a-9262-f8f3fc86a851/WGS_Feb22_1852.gdb \; 	-O /home/exacloud/gscratch/prime-seq/workDir/1bb5295c-6ec5-103a-8692-f8f3fc86cd3f/Job1.work/WGS_pre-mGAPv2.3_1852.vcf.gz \; 	--annotate-with-num-discovered-alleles \; 	-stand-call-conf 30 \; 	--max-alternate-alleles 6 \; 	--force-output-intervals mmul10.WGS-WXS.whitelist.v2.3.sort.merge.bed \; 	-L 1:1-3714165 \; 	--only-output-calls-starting-in-intervals \; 	--genomicsdb-shared-posixfs-optimizations. 12:31:14.647 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/exacloud/gscratch/prime-seq/bin/GenomeAnalysisTK4.jar!/com/intel/gkl/native/libgkl_compression.so; Feb 15, 2022 12:31:14 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 12:31:14.783 INFO GenotypeGVCFs - ------------------------------------------------------------; 12:31:14.783 INFO GenotypeGVCFs - The Genome Analysis Toolkit (GATK) v4.2.5.0; 12:31:14.783 INFO GenotypeGVCFs - For support and documentation go to",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7674:367,error,error,367,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7674,2,['error'],['error']
Availability,"Hello,. when running the cnn I have this error : ; File ""<stdin>"", line 1, in <module>; AttributeError: 'module' object has no attribute 'get_metric_dict'. As I know you are working on another version, I am not totally sure if it is appropriate to report this issue for the current version. You can ignore it I can wait for the other version release. . Thanks a lot",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4591:41,error,error,41,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4591,1,['error'],['error']
Availability,"Hello,; I'm trying to run SparkPileup from the most recent GATK 4.1.7 on a WES sample like this:. gatk PileupSpark --spark-runner SPARK --spark-master local[{threads}] --conf ""spark.driver.memory=22g"" -I $DATA/NA12878.proper.wes.md.bam -R $DATA/Homo_sapiens_assembly18.fasta -O /tmp/gatk4s_{threads}.pileup'. mwiewior@Mareks-MacBook-Pro ~ % spark-submit --version; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /___/ .__/\_,_/_/ /_/\_\ version 2.4.5; /_/; ; Using Scala version 2.11.12, OpenJDK 64-Bit Server VM, 1.8.0_252; Branch HEAD. No matter how high I set the max file descriptors (even to 1M); mwiewior@Mareks-MacBook-Pro ~ % ulimit -a; -t: cpu time (seconds) unlimited; -f: file size (blocks) unlimited; -d: data seg size (kbytes) unlimited; -s: stack size (kbytes) 8192; -c: core file size (blocks) 0; -v: address space (kbytes) unlimited; -l: locked-in-memory size (kbytes) unlimited; -u: processes 2048; -n: file descriptors 1000000. I'm keep on getting the following error:. 20/06/06 14:56:35 ERROR Utils: Aborting task; org.broadinstitute.hellbender.exceptions.UserException$CouldNotReadInputFile: Couldn't read file file:///private/var/folders/5s/v5t08tmd42z_2m2c30vqf6kc0000gn/T/spark-556aa7a2-4d88-4bae-ad16-36d5af920fa9/userFiles-aeb68992-3215-4897-8f8a-040396296185/Homo_sapiens_assembly18.fasta. Error was: Fasta index file could not be opened: /private/var/folders/5s/v5t08tmd42z_2m2c30vqf6kc0000gn/T/spark-556aa7a2-4d88-4bae-ad16-36d5af920fa9/userFiles-aeb68992-3215-4897-8f8a-040396296185/Homo_sapiens_assembly18.fasta.fai; at org.broadinstitute.hellbender.utils.fasta.CachingIndexedFastaSequenceFile.<init>(CachingIndexedFastaSequenceFile.java:159); at org.broadinstitute.hellbender.utils.fasta.CachingIndexedFastaSequenceFile.<init>(CachingIndexedFastaSequenceFile.java:125); at org.broadinstitute.hellbender.utils.fasta.CachingIndexedFastaSequenceFile.<init>(CachingIndexedFastaSequenceFile.java:110); at org.broadinstitute.hellbender.engine.ReferenceF",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6642:1003,error,error,1003,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6642,1,['error'],['error']
Availability,"Hello,; I'm using gatk 4.2.2.0 with PathSeqPipelineSpark but I'm having some problems.; For some samples I have the generation of the outuput.bam file while for others no. gatk --java-options ""-Xmx750G"" PathSeqPipelineSpark \; --input output.bam \; --filter-bwa-image ${imagehuman} \; --kmer-file ${pathseqdb}/host.hss \; --min-clipped-read-length 60 \; --microbe-dict ${bactdict} \; --microbe-bwa-image ${pathseqdb}/bacteria_only.fa.img \; --taxonomy-file $taxdb \; --output ${outpath}pathseq.complete0.8.bam \; --scores-output ${outpath}/pathseq.complete0.8.csv \; --is-host-aligned false \; --filter-duplicates false \; --min-score-identity .8. The path to the related file are correct so I was wondering if someone can help me. This is the error; A USER ERROR has occurred: Couldn't write file pathseq.complete0.8.bam because writing failed with exception No FileSystem for scheme ""null"". Best,; Martina",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8909:744,error,error,744,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8909,2,"['ERROR', 'error']","['ERROR', 'error']"
Availability,"Hello,; There's a question about haplotypecaller that's been bothering me for a long time.; GT is 0/1 in haplotypecaller's out vcf, but 1/1 in IGV. Can you help me explain?; This is cmd:; `gatk-4.2.6.1/gatk HaplotypeCaller -R hg19.fasta -I bam -A QualByDepth -A FisherStrand -A ReadPosRankSumTest -A StrandOddsRatio -A MappingQualityRankSumTest -A RMSMappingQuality --max-reads-per-alignment-start 0 --linked-de-bruijn-graph --recover-all-dangling-branches --max-mnp-distance 2 -O vcf`; IGV picture as below:; ![image](https://github.com/broadinstitute/gatk/assets/35715828/de85a9ed-6d80-43fb-9ce6-a6fec79fca67)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8356:427,recover,recover-all-dangling-branches,427,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8356,1,['recover'],['recover-all-dangling-branches']
Availability,"Hello,; When I use GenomicsDBImport and GenotypeGVCFs , I get the following error: Couldn't create GenomicsDBFeatureReader, I have no problem with running CombineGVCFs with CombineGVCFs. I reference #6616 , but I think we have different errors, And I checked my environment variable, the parameter is displayed as ' declare -x TILEDB_DISABLE_FILE_LOCKING=""1"" '. Hope you can give me some help, thanks in advance. Exact GATK commands used : gatk GenotypeGVCFs -R path/hg38ncbi.fa -V gendb://mydatabase -O rawvariants.vcf. > java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /home//miniconda3/share/gatk4-4.1.7.0-0/gatk-package-4.1.7.0-local.jar GenotypeGVCFs -R /home//workdir/data_single_cell/sperm/hg38ncbi.fa -V gendb://mydatabase -O rawvariants.vcf; > 21:14:29.330 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/miniconda3/share/gatk4-4.1.7.0-0/gatk-package-4.1.7.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; > May 25, 2020 9:14:29 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; > INFO: Failed to detect whether we are running on Google Compute Engine.; > 21:14:29.494 INFO GenotypeGVCFs - ------------------------------------------------------------; > 21:14:29.495 INFO GenotypeGVCFs - The Genome Analysis Toolkit (GATK) v4.1.7.0; > 21:14:29.495 INFO GenotypeGVCFs - For support and documentation go to https://software.broadinstitute.org/gatk/; > 21:14:29.495 INFO GenotypeGVCFs - Executing as lbjiang@mu01 on Linux v3.10.0-327.el7.x86_64 amd64; > 21:14:29.495 INFO GenotypeGVCFs - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_192-b01; > 21:14:29.495 INFO GenotypeGVCFs - Start Date/Time: May 25, 2020 9:14:29 PM CST; > 21:14:29.495 INFO GenotypeGVCFs - ------------------------------------------------------------; > 21:14:29.495 INFO GenotypeGVCFs - ----------------------------------------",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6627:76,error,error,76,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6627,2,['error'],"['error', 'errors']"
Availability,"Hello. I am Adam Yongxin Ye, a PhD candidate in Peking University, supervised by Prof Liping Wei. We have developed MosaicHunter, a bioinformatic tool that can identify postzygotic single-nucleotide mosaicisms (with allele fraction deviated from homozygous 0, 1 and heterozygous 0.5) in bulk sequencing data of a single sample without matched control. After I had the recent lectures on GATK4 tutorial in Beijing, I thought it might be great to merge MosaicHunter into GATK framework, especially for the local assembly function in HaplotypeCaller and Mutect2, to increase the sensitivity & specificity and even extend for mosaic indels, as well as to make MosaicHunter easy for more users to use. MosaicHunter utilized GATK preprocessing, distinguished mosaicisms from germline homozygous and heterozygous sites by a Bayesian genotyper, and applied several stringent hard filters. MosaicHunter has been published (https://academic.oup.com/nar/article/45/10/e76/2962179 and http://www.nature.com/articles/cr2014131) and is publicly available (http://mosaichunter.cbi.pku.edu.cn/ and https://github.com/zzhang526/MosaicHunter (with source code in java)). So I wonder if GATK team is interested in this suggestion. Could someone or may we contribute it into GATK?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4632:1031,avail,available,1031,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4632,1,['avail'],['available']
Availability,"Hello.; I am not sure if this is a bug or simply a tool version problem but when running the tests with `./gradlew test` I get 18 failures with the `org.broadinstitute.hellbender.tools.walkers.variantutils.LeftAlignAndTrimVariantsUnitTest` class. I wanted to make sure GATK was working right when compiled it from source to have a working base a I intend to try out some experimental modifications to the code. ## Bug Report. ### Affected tool(s) or class(es); `org.broadinstitute.hellbender.tools.walkers.variantutils.LeftAlignAndTrimVariantsUnitTest`. ### Affected version(s); - [ ] Latest public release version [version?]; - [x] Latest master branch as of [11.12.18]. ### Description; The following commands were used to build and test GATK; ```; git pull; ./gradlew clean; ./gradlew bundle; ./gradlew test; ```; The tests resulted in 18 failed as can be seen in the attached file. ; [Test results - Class org.broadinstitute.hellbender.tools.walkers.variantutils.LeftAlignAndTrimVariantsUnitTest.html.zip](https://github.com/broadinstitute/gatk/files/2667609/Test.results.-.Class.org.broadinstitute.hellbender.tools.walkers.variantutils.LeftAlignAndTrimVariantsUnitTest.html.zip). If this is normal (expected) when building from the last commit on master you can close this issue. For experimental development should I use the most recent release or can I work from the most recent commit on master ?. #### Steps to reproduce; see commands above description. The problem could be from a library or java version maybe. I run a Ubuntu 16.04 LTS desktop.; ```; uname -a; Linux A13PC04 4.4.0-140-generic #166-Ubuntu SMP Wed Nov 14 20:09:47 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux. javac -version; javac 1.8.0_102. java -version; java version ""1.8.0_102""; Java(TM) SE Runtime Environment (build 1.8.0_102-b14); Java HotSpot(TM) 64-Bit Server VM (build 25.102-b14, mixed mode); ```. #### Expected behavior; I was expecting the tests to pass. #### Actual behavior; 18 tests failed.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5511:130,failure,failures,130,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5511,1,['failure'],['failures']
Availability,"Hello.; I believe there is an error in the description of the algorithm in the pairHMM alignment stage. It states that it does **local** alignment, however the code implements a **global** alignment.; Therefore I fixed the comments and added the correct reference to Durbin's book. (The figure referenced is not the Finite State Machine implemented). This was discussed on the GATK forum before I made the pull request.; See discussion here : [Discussion Thread](https://gatkforums.broadinstitute.org/gatk/discussion/23197/question-about-the-alignment-performed-in-the-haplotypecaller-pairhmm#latest). I believe this is important, because the difference between the two FSMs is as important as the difference between running the Needleman–Wunsch and Smith-Waterman algorithm (global vs local). Regards.; Rick",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5528:30,error,error,30,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5528,1,['error'],['error']
Availability,"Heng's paper _""A statistical framework for SNP calling. . .""_ presents two methods for calculating a variant QUAL score. The first and simpler approach finds a maximum likelihood allele fraction. The second, which is implemented in the GATK, enumerates the likelihoods of all possible partitions of allele counts among the total ploidy of all samples. The latter approach becomes nightmarish (in terms of speed and code complexity) for non-diploid organisms _or_ multiple alt alleles and scales poorly (quadratically, I believe) with the number of samples. Known bugs in the calculation -- and the difficulty of repairing them -- can be attributed to its complexity. And its treatment of multiple alt alleles involves a major hack. The task is to generalize the allele fraction (as opposed to allele count) equations to non-diploid samples with multiple alt alleles, figure out appropriate priors, and implement it as a new QUAL score calculator.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1697:612,repair,repairing,612,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1697,1,['repair'],['repairing']
Availability,Here is an user trying to enable flow based annotations for non-flow data. . https://gatk.broadinstitute.org/hc/en-us/community/posts/24596063911963-Error-while-running-Mutect2-java-lang-IllegalArgumentException-the-index-points-past-the-last-element-of-the-collection-or-array-334-333. What could be done to prevent this? ; Possible ideas; - Check data and disable nonmatching annotations with a warning in the log; - Prevent running the command at all with error messages in the log; - Change the way annotations are named such as FB_myannotation...,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8788:149,Error,Error-while-running-,149,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8788,2,"['Error', 'error']","['Error-while-running-', 'error']"
Availability,"Here is my command:; spark-submit --driver-memory 8G --master local[1] --conf spark.kryoserializer.buffer.max=512m --conf spark.driver.maxResultSize=0 --conf spark.driver.userClassPathFirst=true --conf spark.executor.userClassPathFirst=true --conf spark.io.compression.codec=lzf --conf spark.yarn.executor.memoryOverhead=600 gatk-4.alpha/build/libs/gatk-all-version-unknown-SNAPSHOT-spark.jar BaseRecalibratorSpark -knownSites test.vcf -R hg19_rCRSchrm.2bit -I test.bam -O test.txt. The error msg is:; java.lang.ClassCastException: org.broadinstitute.hellbender.utils.variant.MinimalVariant cannot be cast to htsjdk.samtools.util.Locatable; at org.broadinstitute.hellbender.utils.collections.IntervalsSkipList.<init>(IntervalsSkipList.java:35); at org.broadinstitute.hellbender.engine.spark.BroadcastJoinReadsWithVariants.join(BroadcastJoinReadsWithVariants.java:22); at org.broadinstitute.hellbender.engine.spark.AddContextDataToReadSpark.add(AddContextDataToReadSpark.java:35); at org.broadinstitute.hellbender.tools.spark.BaseRecalibratorSpark.runTool(BaseRecalibratorSpark.java:91); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:257). It seems like BroadCast strategy in BaseRecalibratorSpark has some bugs when trying to join variants with reads. . i can see that Variant is implements from htsjdk.samtools.util.Locatable, but why it still have some problem there?. Is it because that somehow in some java environment, this clause will cause problem?; final IntervalsSkipList<Variant> variantSkipList = new IntervalsSkipList<>(variants.collect());. And it should be this assertion:; final IntervalsSkipList<Variant> variantSkipList = new IntervalsSkipList<Variant>(variants.collect());. I use java 1.8.0_66",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1386:487,error,error,487,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1386,1,['error'],['error']
Availability,"Here it is. An overview of what's been added:; - metrics package; - a few general metrics classes (e.g. MultiLevelMetrics); - may want to push these down into HTSJDK later; - added some utils; - utils.gene: gene annotation; - utils.illumina: general Illumina-related utils (adapters, etc); - utils.text.parsers: text parsing; - utils.variant: added dbSNP stuff; - MathUtils: added a few basic things (mean, stddev, etc) with unit tests; - tools; - three major packages:; - analysis: metrics + analyses (including necessary Rscripts); - illumina: Illumina parsing + validation; - vcf: VCF manipulation + GenotypeConcordance; - also two smaller packages, fastq and intervals, containing a few tools each; - tests; - all existing tests were ported; still, overall test coverage goes down by ~6%; - all CLP integration tests have been ported to the new argument system; - test data has also been carried over, and is neatly organized; - there are no huge files, and very few above 100KB (just a few VCFs I think); - however, the Illumina test data is pretty big - ~6MB spread over ~1700 files",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/347:149,down,down,149,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/347,2,['down'],['down']
Availability,"Here's what this PR does:. * Adds an argument to skip a locus rather than downsample if depth is too high. This handles horrible regions so rife with mapping errors that we wouldn't believe any calls from them. Basically, it blacklists on the fly intervals that should have been blacklisted ahead of time.; * Adds a stride argument for positional downsampling so that we downsample within a range of alignment start positions. This regularizes statistical fluctuations in coverage and, more importantly, makes positional downsampling much more useful for data where many reads share the same start position while most start positions have no reads. I believe @fleharty deals with this kind of stuff.; * ~~Deletes a few methods in the `ReadsDownsampler` API that were only used in their own unit tests.~~; * Adds an option to bias downsampling in favor of reads with high mapping quality.; * Beefs up the unit tests for `PositionalDownsampler`. The new functionality is a superset of the old, and the old stuff is unchanged. HaplotypeCaller is not affected, unless of course someone wants to run it with the new options. The new options allow Mutect2 to run much faster.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3238:74,down,downsample,74,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3238,6,"['down', 'error']","['downsample', 'downsampling', 'errors']"
Availability,"Hey @mbabadi, I've answered this user question but I think my answer needs your review. Also, DR mentioned perhaps this option could be set automatically for users? Thanks. ---; Thanks @shlee for the update,; I used the latest jar from the gatk4 repo as recommended. And managed to derive the read count input file and sex genotype table. I just wanted to confirm whether Nd4j also needed to be installed if not using Spark. #script run; ./gatk-launch GermlineCNVCaller --contigAnnotationsTable ../gatk4_Hellbender/grch37_contig_annotations.tsv --copyNumberTransitionPriorTable ../gatk4_Hellbender/grch37_germline_CN_priors.tsv --jobType LEARN_AND_CALL --outputPath ./TS1 --input ../gatk4_Hellbender/target_cov.tsv --targets ../gatk4_Hellbender/targets.txt --disableSpark true --sexGenotypeTable ../gatk4_Hellbender/TS1_genotype --rddCheckpointing false --biasCovariateSolverType LOCAL. #I am getting the following error which seems to be linked with Nd4j:. Using GATK jar ~/localwork/playground/programs/gatk-protected/build/libs/gatk-protected-package-b4390fb-SNAPSHOT-local.jar; 102-b14; Version: 4.alpha.2-1136-gc18e780-SNAPSHOT; 16:55:21.931 INFO GermlineCNVCaller - HTSJDK Defaults.COMPRESSION_LEVEL : 1; 16:55:21.932 INFO GermlineCNVCaller - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 16:55:21.932 INFO GermlineCNVCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 16:55:21.932 INFO GermlineCNVCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 16:55:21.932 INFO GermlineCNVCaller - Deflater: IntelDeflater; 16:55:21.932 INFO GermlineCNVCaller - Inflater: IntelInflater; 16:55:21.932 INFO GermlineCNVCaller - Initializing engine; 16:55:21.932 INFO GermlineCNVCaller - Done initializing engine; 16:55:21.933 INFO GermlineCNVCaller - Spark disabled. sparkMaster option (local[*]) ignored.; 16:55:23.448 INFO GermlineCNVCaller - Parsing the read counts table...; 16:55:24.876 INFO GermlineCNVCaller - Parsing the sample sex genotypes table...; 16:55:24.896",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3098:915,error,error,915,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3098,1,['error'],['error']
Availability,"Hey folks,. I have a test dataset that interestingly core-dumps or JVM errors with `--smith-waterman FASTEST_AVAILABLE` but not with `--smith-waterman JAVA`. The only thing I can think of is somehow Intel's HMM has a length limitation, as I am using `--assembly-region-padding 1000` to GATK to call 100-1000bp indels (and it works!). I cannot share the test BAM unfortunately. What can I do to help debug further?. I'm using `gatk4-4.1.8.1-0` from `conda create -n debug-gatk4 -c defaults -c conda-forge -c bioconda gatk4`. ```; $gatk ... -version; The Genome Analysis Toolkit (GATK) v4.1.8.1; HTSJDK Version: 2.23.0; Picard Version: 2.22.8; $ java -version; openjdk version ""1.8.0_152-release""; OpenJDK Runtime Environment (build 1.8.0_152-release-1056-b12); OpenJDK 64-Bit Server VM (build 25.152-b12, mixed mode); ```. First error motif:; ```; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x000000010efa9dc2, pid=23946, tid=0x000000000000a503; #; # JRE version: OpenJDK Runtime Environment (8.0_152-b12) (build 1.8.0_152-release-1056-b12); # Java VM: OpenJDK 64-Bit Server VM (25.152-b12 mixed mode bsd-amd64 compressed oops); # Problematic frame:; # V [libjvm.dylib+0x3a9dc2] PhaseIdealLoop::set_ctrl(Node*, Node*)+0x10; #; # Failed to write core dump. Core dumps have been disabled. To enable core dumping, try ""ulimit -c unlimited"" before starting Java again; #; # An error report file with more information is saved as:; #; # Compiler replay data is saved as:; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; ```. Second error motif:; ```; java(24057,0x7000035bd000) malloc: Incorrect checksum for freed object 0x7fd8a8193600: probably modified after being freed.; Corrupt value: 0x2e4630002e47e; java(24057,0x7000035bd000) malloc: *** set a breakpoint in malloc_error_break to debug; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6733:71,error,errors,71,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6733,5,['error'],"['error', 'errors']"
Availability,"Hey there!. I am currently working on a project involving mutagenesis analysis using the AnalyzeSaturationMutagenesis tool. Our rationale is that a single nucleotide exchange due to a sequencing error is more likely than two or three consecutive nucleotide changes in one mutated codon, making it important for us to adjust the quality standards based on the type of variant (single/double/triple exchanges). I would like to ask if there is any existing functionality within the AnalyzeSaturationMutagenesis tool to incorporate base-specific nucleotide quality into the analysis, especially in a way that allows for different quality thresholds based on the number of consecutively mutated bases in one codon. If such a feature is not available, I would appreciate any suggestions you may have for a potential workaround that would enable us to set a stricter quality threshold for single nucleotide variations in the current tool. Thank you in advance!. Best,; Benni. @MaximilianStammnitz; @tedsharpe",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8995:195,error,error,195,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8995,2,"['avail', 'error']","['available', 'error']"
Availability,"Hey there~ I have run the following command:. gatk HaplotypeCaller \; -R bbv18h27rm.fa \; -ERC GVCF \; --alleles db_raw_call_bbe_6largest.vcf \; -I bbe_off_xL3_68.concordant_withRG.bam \; -O test_call_off_xL3_68_allele_46samples.vcf.gz. and had some error:; ```; Using GATK jar /home/cc/gatk/gatk_dir/gatk/build/libs/gatk-package-4.1.3.0-25-g8d88f6e-SNAPSHOT-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /home/cc/gatk/gatk_dir/gatk/build/libs/gatk-package-4.1.3.0-25-g8d88f6e-SNAPSHOT-local.jar HaplotypeCaller -R /db_students1/genetic_map/snp_calling/bbv18h27rm.fa -ERC GVCF --alleles /db_students1/gatk_out/db_raw_call_bbe_6largest.vcf -I /db_students1/genetic_map/reseqData_mapping_bam/bam/bbe_off_xL3_68.concordant_withRG.bam -O /db_students1/gatk_out/test_call_off_xL3_68_allele_46samples.vcf.gz; 17:04:13.440 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/cc/gatk/gatk_dir/gatk/build/libs/gatk-package-4.1.3.0-25-g8d88f6e-SNAPSHOT-local.jar!/com/intel/gkl/native/libgkl_compression.so; Nov 12, 2019 5:04:15 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 17:04:15.137 INFO HaplotypeCaller - ------------------------------------------------------------; 17:04:15.138 INFO HaplotypeCaller - The Genome Analysis Toolkit (GATK) v4.1.3.0-25-g8d88f6e-SNAPSHOT; 17:04:15.138 INFO HaplotypeCaller - For support and documentation go to https://software.broadinstitute.org/gatk/; 17:04:15.138 INFO HaplotypeCaller - Executing as cc@hr18b on Linux v3.10.0-957.el7.x86_64 amd64; 17:04:15.138 INFO HaplotypeCaller - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_212-b04; 17:04:15.138 INFO HaplotypeCaller - Start Date/Time: November 12, 2019 5:04:13 PM CST; 17:04:15.139 INFO HaplotypeCaller - --------------------------",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6260:250,error,error,250,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6260,1,['error'],['error']
Availability,"Hi . I used CollectAllelicCounts with a bed file for the `-I` parameter and got the following error message:. `A USER ERROR has occurred: Badly formed genome unclippedLoc: Parameters to GenomeLocParser are incorrect:The stop position 29430911 is less than start 29430912 in contig chr2`. The only entry in my bed file dealing with this position is the following:. `chr2	 29430911	29430911	ENSE00001695104	3	ENST00000431873	ENSG00000171094	ALK`. There seems to be a problem, that CollectAllelicCounts add 1 base to the start of each interval. I tried it with a padding of 10 (`-ip 10`) but did not get it to work. Am I on the wrong way? Isn't it a problem with the bed file?`; Thanks in advance; Stefan",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4504:94,error,error,94,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4504,2,"['ERROR', 'error']","['ERROR', 'error']"
Availability,"Hi ; This is an issue derived from the GATK forum. . https://gatk.broadinstitute.org/hc/en-us/community/posts/17996976455067-HaplotypecallerSpark-error?page=1#community_comment_18161302676123. User is having an issue with HaplotypeCallerSpark possibly a traversal issue. This problem was also present in the past in another github issue. https://github.com/broadinstitute/gatk/issues/7199. User tried with the latest version as well and even providing a bed file as in the former issue did not help solve the problem. HaplotypeCaller works fine with or without the bed file but Spark version does not. . Here is the error message. ```; **Caused by: java.lang.IllegalArgumentException: Sequence [VC HC_call @ NW_020555792.1:138 Q78.32 of type=SNP alleles=[T*, G] attr={AC=2, AF=1.0, AN=2, DP=2, ExcessHet=0.0000, FS=0.000, MLEAC=[1], MLEAF=[0.5], MQ=47.00, QD=29.09, SOR=0.693} GT=[[AR0111 G/G GQ 6 DP 2 AD 0,2 PL 90,6,0]] filters= added out of order currentReferenceIndex: 9, referenceIndex:11; at htsjdk.tribble.index.tabix.AllRefsTabixIndexCreator.addFeature(AllRefsTabixIndexCreator.java:79); at htsjdk.variant.variantcontext.writer.IndexingVariantContextWriter.add(IndexingVariantContextWriter.java:203); at htsjdk.variant.variantcontext.writer.VCFWriter.add(VCFWriter.java:242); at org.disq_bio.disq.impl.formats.vcf.HeaderlessVcfOutputFormat$VcfRecordWriter.write(HeaderlessVcfOutputFormat.java:93); at org.disq_bio.disq.impl.formats.vcf.HeaderlessVcfOutputFormat$VcfRecordWriter.write(HeaderlessVcfOutputFormat.java:56); at org.apache.spark.internal.io.HadoopMapReduceWriteConfigUtil.write(SparkHadoopWriter.scala:368); at org.apache.spark.internal.io.SparkHadoopWriter$.$anonfun$executeTask$1(SparkHadoopWriter.scala:138); at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1538); at org.apache.spark.internal.io.SparkHadoopWriter$.executeTask(SparkHadoopWriter.scala:135); ... 9 more; 01:50:24.007 INFO ShutdownHookManager - Shutdown hook called**; ```; User wa",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8490:146,error,error,146,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8490,2,['error'],['error']
Availability,"Hi Adam,. This is based on your feedback from Friday afternoon. ; Lots of issues are still to be addressed (multilevel collection, more test coverage, performance, etc).; If you are too busy to review, let me know and I'll bug @cwhelan or @tedsharpe or someone else. Branch travis log available [here](https://travis-ci.org/broadinstitute/gatk/builds/110702136). Thank you.; Steve",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1514:285,avail,available,285,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1514,1,['avail'],['available']
Availability,"Hi GATK Team. I got the following error when using MarkDupliactesSpark tool:. `A USER ERROR has occurred: Couldn't write file /media/Berechnungen/190218_NB501654_0110_AHT7VFBGX9/0046-19_Exom (Intelligenzminderung)/0046-19.dedup.bam because writing failed with exception File file:/media/Berechnungen/190218_NB501654_0110_AHT7VFBGX9/0046-19_Exom%20(Intelligenzminderung)/0046-19.dedup.bam.parts/header does not exist`. I looked at the specified path and the `header` file is in the right directory. ; Is it possible, that MDSpark replaces a space in the filepath to %20 and at the end does not replace it back to space, so it does not finde the `header` file?. Thanks in advance; Stefan . This Issue was generated from your [forums] ; [forums]: https://gatkforums.broadinstitute.org/gatk/discussion/23509/markduplicatespark-does-not-find-file-though-it-is-there/p1",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5729:34,error,error,34,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5729,2,"['ERROR', 'error']","['ERROR', 'error']"
Availability,"Hi GATK developers:. Have 4 pacbio WGS bam files do to Haplotype calling. Each bam file was divided by chromosomes, but 3 parallele jobs failed due to java core dump:; - Syntax I ran was pretty basic, I also tried latest gatk version4.2.2.0, same result. Java version is ``` OpenJDK Runtime Environment (build 1.8.0_252-b09) ```; ```; /gatk-4.0.11.0/gatk --java-options ""-Xmx4G"" HaplotypeCaller \; -R GRCh38.p2.fa \; -I RT4_STD.bam \; -ERC GVCF \; -L chr16 \; -O RT4_STD.g.vcf \; -new-qual; ```; - Error message is also different; - First one is :; ```; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x00002aaad9f1e54a, pid=7818, tid=0x00002aaaabdce700; #; # JRE version: Java(TM) SE Runtime Environment (8.0_111-b14) (build 1.8.0_111-b14); # Java VM: Java HotSpot(TM) 64-Bit Server VM (25.111-b14 mixed mode linux-amd64 compressed oops); # Problematic frame:; # C [libgkl_pairhmm_omp1890484777463615571.so+0x6954a] double compute_full_prob_avxd<double>(testcase*)+0x34a; #; # Core dump written. Default location: core or core.7818; #; # An error report file with more information is saved as:; # hs_err_pid7818.log; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; # The crash happened outside the Java Virtual Machine in native code.; # See problematic frame for where to report the bug.; ```. -Second one is ; ```; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x00000035dfe84364, pid=160107, tid=0x00002aaaabdce700; #; # JRE version: Java(TM) SE Runtime Environment (8.0_111-b14) (build 1.8.0_111-b14); # Java VM: Java HotSpot(TM) 64-Bit Server VM (25.111-b14 mixed mode linux-amd64 ); # Problematic frame:; # C [libc.so.6+0x84364]; #; # Core dump written. Default location: core or core.160107; #; # An error report file with more information is saved as:; # hs_err_pid160107.log; #; # If you would like to submit a bug report, please visit",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7515:498,Error,Error,498,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7515,2,"['Error', 'error']","['Error', 'error']"
Availability,"Hi GATK team,. I had error message as following with GATK4.1.0.0 on our local cluster: ; `; Using GATK jar /dsg_cent/packages/GATK/gatk-4.1.0.0/gatk-package-4.1.0.0-local.jar; Running:; java1.8 -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx5; g -jar /dsg_cent/packages/GATK/gatk-4.1.0.0/gatk-package-4.1.0.0-local.jar SelectVariants -R /dsgmnt/llfs2/masterdata/geno/hg38/resources_broad_hg38_v0_Homo_sapiens_assembl; y38.fasta -L chr1 -V /dsgmnt/seq5_llfs/work/xhong/v4100/ApplyVQSR//ExcessHet_joint525_c1_22.SNP.VQSR.g.vcf.gz -O /dsgmnt/seq5_llfs/work/xhong/v4100/ApplyVQSR//ExcessHet_joi; nt525_c1.SNP.VQSR.g.vcf.gz; 09:15:49.372 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/dsg_cent/packages/GATK/gatk-4.1.0.0/gatk-package-4.1.0.0-local.jar!/com/intel/gkl/nati; ve/libgkl_compression.so; 09:15:51.131 INFO SelectVariants - ------------------------------------------------------------; 09:15:51.132 INFO SelectVariants - The Genome Analysis Toolkit (GATK) v4.1.0.0; 09:15:51.132 INFO SelectVariants - For support and documentation go to https://software.broadinstitute.org/gatk/; 09:15:51.132 INFO SelectVariants - Executing as xhong@blade5-4-11.dsg.wustl.edu on Linux v2.6.32-573.12.1.el6.x86_64 amd64; 09:15:51.133 INFO SelectVariants - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_31-b13; 09:15:51.133 INFO SelectVariants - Start Date/Time: June 27, 2019 9:15:49 AM CDT; 09:15:51.133 INFO SelectVariants - ------------------------------------------------------------; 09:15:51.133 INFO SelectVariants - ------------------------------------------------------------; 09:15:51.134 INFO SelectVariants - HTSJDK Version: 2.18.2; 09:15:51.134 INFO SelectVariants - Picard Version: 2.18.25; 09:15:51.134 INFO SelectVariants - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 09:15:51.135 INFO SelectVariants - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : fals",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6021:21,error,error,21,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6021,1,['error'],['error']
Availability,"Hi GATK team,. I tried running your PathSeq pipeline (broadinstitute/gatk:4.1.8.0) on my cohort and almost half of the samples failed the scoring step with this error message:; `20/07/17 09:38:35 INFO NewHadoopRDD: Input split: file:/cromwell_root/fc-6e61d4b2-bdc8-4abd-bb94-18d8fa11d9b6/7c1b0faa-e956-4289-9e2d-4fb8b9eff6ff/PathSeqPipeline/0ca5578f-70d3-498e-b7cc-23590f0ab31f/call-PathSeqAlign/MMRF_2072_2_BM.microbe_aligned.paired.bam:33554432+33554432 20/07/17 09:38:46 ERROR Executor: Exception in task 0.0 in stage 2.0 (TID 5) java.util.NoSuchElementException: next on empty iterator at scala.collection.Iterator$$anon$2.next(Iterator.scala:39) at scala.collection.Iterator$$anon$2.next(Iterator.scala:37) at scala.collection.Iterator$$anon$13.next(Iterator.scala:469) at scala.collection.convert.Wrappers$IteratorWrapper.next(Wrappers.scala:31) at org.broadinstitute.hellbender.relocated.com.google.common.collect.Iterators$PeekingImpl.next(Iterators.java:1155) at org.broadinstitute.hellbender.utils.spark.SparkUtils.lambda$putReadsWithTheSameNameInTheSamePartition$7bd206b0$1(SparkUtils.java:190) at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:153) at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:153) at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:823) at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:823) at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52) at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346) at org.apache.spark.rdd.RDD.iterator(RDD.scala:310) at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90) at org.apache.spark.scheduler.Task.run(Task.scala:123) at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408) at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360) at org.apache.spark.executor.Executor$TaskRunner.run(Executor.s",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6709:161,error,error,161,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6709,2,"['ERROR', 'error']","['ERROR', 'error']"
Availability,"Hi all, . I am using CNV detection with GATK v4.3.0.0 for quite a while very successfully. Now we changed the enrichment kit and I had to do a new model. Everything worked well for the model phase. . As I now run one sample against this model I got the following error at the CNV detection step:. ```gatk GermlineCNVCaller --run-mode CASE -contig-ploidy-calls /media/Ergebnisse/0115-24_Masterpanel_NB501654_0623/0115-24_DGCP_noProbe-calls/ --model /media/Data/MasterV3/GCNV_noProbe-model/ --input /media/Ergebnisse/0115-24_Masterpanel_NB501654_0623/0115-24_noProbe.hdf5 --output /media/Ergebnisse/0115-24_Masterpanel_NB501654_0623/ --output-prefix 0115-24_GCNV_noProbe --tmp-dir /media/Data/tmp/; Using GATK jar /usr/BioinfSoftware/GATK/4.3.0.0/gatk-package-4.3.0.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /usr/BioinfSoftware/GATK/4.3.0.0/gatk-package-4.3.0.0-local.jar GermlineCNVCaller --run-mode CASE -contig-ploidy-calls /media/Ergebnisse/0115-24_Masterpanel_NB501654_0623/0115-24_DGCP_noProbe-calls/ --model /media/Data/MasterV3/GCNV_noProbe-model/ --input /media/Ergebnisse/0115-24_Masterpanel_NB501654_0623/0115-24_noProbe.hdf5 --output /media/Ergebnisse/0115-24_Masterpanel_NB501654_0623/ --output-prefix 0115-24_GCNV_noProbe --tmp-dir /media/Data/tmp/; 10:20:01.611 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/usr/BioinfSoftware/GATK/4.3.0.0/gatk-package-4.3.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; 10:20:01.717 INFO GermlineCNVCaller - ------------------------------------------------------------; 10:20:01.718 INFO GermlineCNVCaller - The Genome Analysis Toolkit (GATK) v4.3.0.0; 10:20:01.718 INFO GermlineCNVCaller - For support and documentation go to https://software.broadinstitute.org/gatk/; 10:20:01.718 INFO GermlineCNVCaller - Executing as die9s@k-hg-srv3 on Linux v5.3.18-24.37-default am",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8740:263,error,error,263,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8740,1,['error'],['error']
Availability,"Hi all,. Below error occurs trying to access Funcotator data source directory installed on lustre file system. We have a non-lustre mounted fs for cases like this, but I thought it was worth bringing up. ```; org.broadinstitute.hellbender.exceptions.GATKException: Unable to query the database for geneName: null; 	at org.broadinstitute.hellbender.tools.funcotator.dataSources.cosmic.CosmicFuncotationFactory.createFuncotations(CosmicFuncotationFactory.java:244); 	at org.broadinstitute.hellbender.tools.funcotator.Funcotator.enqueueAndHandleVariant(Funcotator.java:404); 	at org.broadinstitute.hellbender.tools.funcotator.Funcotator.apply(Funcotator.java:316); 	at org.broadinstitute.hellbender.engine.VariantWalkerBase.lambda$traverse$0(VariantWalkerBase.java:110); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); 	at org.broadinstitute.hellbender.engine.VariantWalkerBase.traverse(VariantWalkerBase.java:108); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:893); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:136); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:179); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgr",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4413:15,error,error,15,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4413,1,['error'],['error']
Availability,"Hi all.; This looks like an issue presented by a forum post . [Haplotypecaller FORMAT:DP is affected by the interval in WGS](https://gatk.broadinstitute.org/hc/en-us/community/posts/27992393649051-Haplotypecaller-FORMAT-DP-is-affected-by-the-interval-in-WGS). User uploaded a toy data for us to test and I was able to recreate this issue under GATK 4.6.0.0. I have not tested it with any other versions. When whole contig is given as interval all variant sites in the multisample VCF is reported with DP value much less than what it is supposed to be in samples where no variation occur. Samples with variants are shown as expected DP. Setting ploidy 2 for this analysis restores the expected DP value for samples with HOMREF sites no matter what interval is used. Numbers can be seen in the figure as well as those variant contexts. . This is what user and I got with the whole contig given as interval. ```; #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	DA10_DA10	TDY1754_TDY1754; CP022325.1	69348	.	T	A	2920.63	.	AC=1;AF=0.500;AN=2;DP=85;FS=0.000;MLEAC=1;MLEAF=0.500;MQ=60.00;QD=29.56;SOR=0.824	GT:AD:DP:GQ:PL	0:4,0:4:99:0,119	1:0,79:79:99:2931,0; ```; This is what comes when -L is set to `CP022325.1:69347-69349`. This is the same DP reported when ploidy is set to 2 no matter what interval is used. This is also the expected DP value. . ```; #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	DA10_DA10	TDY1754_TDY1754; CP022325.1	69348	.	T	A	2920.63	.	AC=1;AF=0.500;AN=2;DP=98;FS=0.000;MLEAC=1;MLEAF=0.500;MQ=60.00;QD=25.36;SOR=0.824	GT:AD:DP:GQ:PL	0:17,0:17:99:0,685	1:0,79:79:99:2931,0; ```. ![image](https://github.com/user-attachments/assets/269169f8-7de2-415c-ba60-8356937da561). User data is in the incoming folder with name `cmateusiak_20240805.tar.gz`. The reference genome is a fungal one from the below link. [Fungi reference C.NeoformansKN99](https://fungidb.org/common/downloads/release-68/CneoformansKN99/fasta/data/FungiDB-68_CneoformansKN99_Genome.fasta)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8943:1883,down,downloads,1883,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8943,1,['down'],['downloads']
Availability,"Hi all;; When validation runs on the GATK 4.0.0 release (congrats!) we're running into segfault issues on some `GenomicsDBImport` runs which look to be due to the length of the database path:; ```; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x00007f99a7642c5b, pid=7446, tid=0x00007f99fbfa0700; #; # JRE version: OpenJDK Runtime Environment (8.0_121-b15) (build 1.8.0_121-b15); # Java VM: OpenJDK 64-Bit Server VM (25.121-b15 mixed mode linux-amd64 compressed oops); # Problematic frame:; # C [libtiledbgenomicsdb8843204539247232071.so+0x4fdc5b] std::string::compare(char const*) const+0x1b; ```; Here is a self-contained test case that reproduces the issue:. https://s3.amazonaws.com/chapmanb/testcases/gatk/gatk4_genomicsdb_length.tar.gz. A standard small name and longer name of 105 characters work fine:; ```; gatk-launch --java-options '-Xms1g -Xmx2g' GenomicsDBImport --reader-threads 1 --genomicsdb-workspace-path short_genomicsdb -L chr22:15069-15500 --variant Test1.vcf.gz --variant Test2.vcf.gz; gatk-launch --java-options '-Xms1g -Xmx2g' GenomicsDBImport --reader-threads 1 --genomicsdb-workspace-path long_aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa_genomicsdb/works_aaaaaaaaaaaaaaaaaaaaaaaaaa -L chr22:15069-15500 --variant Test1.vcf.gz --variant Test2.vcf.gz; ```; But when you add an additional character, you trigger the segfault:; ```; gatk-launch --java-options '-Xms1g -Xmx2g' GenomicsDBImport --reader-threads 1 --genomicsdb-workspace-path long_aaaaaa; aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa_genomicsdb/fails_aaaaaaaaaaaaaaaaaaaaaaaaaaa -L chr22:15069-15500 -; -variant Test1.vcf.gz --variant Test2.vcf.gz; ```; Thank you for looking at this and please let me know if I can provide any other information to help debug.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4160:208,error,error,208,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4160,1,['error'],['error']
Availability,"Hi folks. @chandrans and I have laid out some plans towards updating GATK4 docs for the January 9 release. Our approach is to prioritize documentation around stable Best Practice Workflows. On the docket currently is the single stable workflow--germline SNP and indel calling from DNA data. We will of course update tool docs (excluding Spark and BWA tools) and supporting tutorials. Even for tools we are unfamiliar with, we aim to have at the least a basic description and an example command. Thanks for the documentation you have already done and the help you give us in updating these. If you are certain your workflow will be ready for the release, then please let us know immediately so we can plan accordingly. If your workflow will be ready later, then can you still give us an estimate for your release so we can plan ahead? Thanks. - @davidbenjamin, did I hear you correctly that you think somatic SNV and indel calling will be ready for the Jan 9 release?; - @samuelklee, I know major changes are currently afoot for somatic CNV. Will you make the Jan 9 release for the targeted exomes use-case? What about WGS?; - @mbabadi, is March, 2018 still the plan?; - @jonn-smith, what is the status on the Tool-That-Must-Not-Be-Named?; - @cwhelan @tedsharpe @SHuang-Broad, is SV on for next year or thereafter?. It would be most helpful to users if we also have validation of our workflows as applied to real data. Are there plans to make benchmarking stats available for each of your workflows?. Sheila and I have 30-man days we can give between us towards updating documentation by December 14. Besides Geraldine, we will rely on some of you to review further refinements to documentation from now to December 14. Thanks again.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3769:1461,avail,available,1461,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3769,1,['avail'],['available']
Availability,"Hi gatk team,. I just run a cfDNA sample and there is no variant being called, thus there is no "".stats"" file being generated so that when it comes to `filterMutectCalls`, it gives error. I wonder if it is wiser that we output an empty stats file, e.g.; ```; statistic	value; callable	0; ```. or simply reports . ```; ERROR: No callable variants detected!; ```. instead of reporting missing stats file? This would be more informative. Thanks!!",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6170:181,error,error,181,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6170,2,"['ERROR', 'error']","['ERROR', 'error']"
Availability,"Hi gatk team,. I'm working with generating CNV for somatic with wdl, using this command:. `java -Xmx75G -Dconfig.file=gatk.conf -jar cromwell-46.1.jar run cnv_somatic_panel_workflow.wdl -i parameters.json `. But I got this error in which I don't know the exact reason for it:. ```; [2019-10-01 02:52:52,49] [info] Running with database db.url = jdbc:hsqldb:mem:e98d186c-96db-46ae-92e5-c326e7aa05d9;shutdown=false;hsqldb.tx=mvcc; [2019-10-01 02:53:01,19] [info] Running migration RenameWorkflowOptionsInMetadata with a read batch size of 100000 and a write batch size of 100000; [2019-10-01 02:53:01,20] [info] [RenameWorkflowOptionsInMetadata] 100%; [2019-10-01 02:53:01,31] [info] Running with database db.url = jdbc:hsqldb:mem:c4b3296a-4b73-4053-b6bf-d4eeb71c8956;shutdown=false;hsqldb.tx=mvcc; [2019-10-01 02:53:01,85] [info] Slf4jLogger started; [2019-10-01 02:53:02,22] [info] Workflow heartbeat configuration:; {; ""cromwellId"" : ""cromid-876ccf5"",; ""heartbeatInterval"" : ""2 minutes"",; ""ttl"" : ""10 minutes"",; ""failureShutdownDuration"" : ""5 minutes"",; ""writeBatchSize"" : 10000,; ""writeThreshold"" : 10000; }; [2019-10-01 02:53:02,28] [info] Metadata summary refreshing every 1 second.; [2019-10-01 02:53:02,31] [info] KvWriteActor configured to flush with batch size 200 and process rate 5 seconds.; [2019-10-01 02:53:02,31] [info] WriteMetadataActor configured to flush with batch size 200 and process rate 5 seconds.; [2019-10-01 02:53:02,32] [info] CallCacheWriteActor configured to flush with batch size 100 and process rate 3 seconds.; [2019-10-01 02:53:02,32] [warn] 'docker.hash-lookup.gcr-api-queries-per-100-seconds' is being deprecated, use 'docker.hash-lookup.gcr.throttle' instead (see reference.conf); [2019-10-01 02:53:02,40] [info] JobExecutionTokenDispenser - Distribution rate: 50 per 1 seconds.; [2019-10-01 02:53:02,43] [info] SingleWorkflowRunnerActor: Version 46.1; [2019-10-01 02:53:02,44] [info] SingleWorkflowRunnerActor: Submitting workflow; [2019-10-01 02:53:02,49] [info] ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6189:223,error,error,223,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6189,4,"['error', 'failure', 'heartbeat']","['error', 'failureShutdownDuration', 'heartbeat', 'heartbeatInterval']"
Availability,"Hi team,. GATK have a GRCh38 version that available in Resource bundle. It is not clear if this version have a masked duplicates.; Could you provide a GRCH38 version, ready to use, with masked duplicates? that can deal with this issue that affect on variants recall in these regions, such as CBS gene. B.W",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8043:42,avail,available,42,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8043,3,"['avail', 'mask']","['available', 'masked']"
Availability,"Hi team,. I'm trying to run `DetermineGermlineContigPloidy` on one sample that I have, but in `CASE` mode it requires `--model a_valid_ploidy_model_dir` in which here (https://gatkforums.broadinstitute.org/gatk/discussion/23471/the-parameter-model-of-determinegermlinecontigploidy-when-use-case-mode#latest). They said that it came from running `COHORT` mode first to have it, but in my case; I want to run `CASE` mode because I only have one sample, so to get --model from `COHORT` mode; I will not be able to have it since it couldn't run on one sample. `A USER ERROR has occurred: Bad input: Invalid combination of inputs: Running in cohort mode, but only a single sample was provided.`. So, how I could produce `-- model` for `CASE` mode to be used for one sample?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6162:564,ERROR,ERROR,564,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6162,1,['ERROR'],['ERROR']
Availability,Hi team. ; This is an old topic from the forum . [LeftAlignIndels Alignments added out of order... Offending records are at [chr7:55268881] and [chr7:55268881]](https://gatk.broadinstitute.org/hc/en-us/community/posts/20834436731547-LeftAlignIndels-Alignments-added-out-of-order-Offending-records-are-at-chr7-55268881-and-chr7-55268881). ```; java.lang.IllegalArgumentException: Alignments added out of order in SAMFileWriterImpl.addAlignment for file:///Users/jcovino/Desktop/PLAA_2390/broken.bam. Sort order is coordinate. Offending records are at [chr7:55268881] and [chr7:55268881]; at htsjdk.samtools.SAMFileWriterImpl.assertPresorted(SAMFileWriterImpl.java:212); at htsjdk.samtools.SAMFileWriterImpl.addAlignment(SAMFileWriterImpl.java:199); at htsjdk.samtools.AsyncSAMFileWriter.synchronouslyWrite(AsyncSAMFileWriter.java:36); at htsjdk.samtools.AsyncSAMFileWriter.synchronouslyWrite(AsyncSAMFileWriter.java:16); at htsjdk.samtools.util.AbstractAsyncWriter$WriterRunnable.run(AbstractAsyncWriter.java:123); at java.base/java.lang.Thread.run(Thread.java:840); ```. The only current solution to this problem is feeding reads in queryname sorted way. When reads are coordinate sorted this error occurs. . There is a request from users that this tool should be able to work with coordinate sorted reads.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8975:1193,error,error,1193,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8975,1,['error'],['error']
Availability,"Hi! I have used HaplotypeCaller to get gvcfs of a sample called xl4_70. They are gvcfs of scf1-128, scf1280-18, scf180-25 ... (use parameter ""-L"" to help with the division). Then i used CombineGvcfs to combine these 7 gvcfs with a sample into a gvcfs, but i got an error:. ```; Using GATK jar /home/cc/gatk/gatk_dir/gatk/build/libs/gatk-package-4.1.3.0-25-g8d88f6e-SNAPSHOT-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /home/cc/gatk/gatk_dir/gatk/build/libs/gatk-package-4.1.3.0-25-g8d88f6e-SNAPSHOT-local.jar CombineGVCFs -R /db_students1/cc/genetic_map/snp_calling/bbv18h27rm.fa --variant /db_students1/cc/gatk_out/tmp_vcf/raw_new52_off_xL4_70_1to128.g.vcf.gz --variant /db_students1/cc/gatk_out/tmp_vcf/raw_new52_off_xL4_70_1280to18.g.vcf.gz --variant /db_students1/cc/gatk_out/tmp_vcf/raw_new52_off_xL4_70_180to25.g.vcf.gz --variant /db_students1/cc/gatk_out/tmp_vcf/raw_new52_off_xL4_70_250to35.g.vcf.gz --variant /db_students1/cc/gatk_out/tmp_vcf/raw_new52_off_xL4_70_350to5.g.vcf.gz --variant /db_students1/cc/gatk_out/tmp_vcf/raw_new52_off_xL4_70_50to69.g.vcf.gz --variant /db_students1/cc/gatk_out/tmp_vcf/raw_new52_off_xL4_70_690to999.g.vcf.gz -O /db_students1/cc/gatk_out/raw_new52_off_xL4_70.g.vcf.gz; 17:52:22.080 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/cc/gatk/gatk_dir/gatk/build/libs/gatk-package-4.1.3.0-25-g8d88f6e-SNAPSHOT-local.jar!/com/intel/gkl/native/libgkl_compression.so; Jan 11, 2020 5:52:23 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 17:52:23.841 INFO CombineGVCFs - ------------------------------------------------------------; 17:52:23.841 INFO CombineGVCFs - The Genome Analysis Toolkit (GATK) v4.1.3.0-25-g8d88f6e-SNAPSHOT; 17:52:23.841 INFO CombineGVCFs - For support a",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6368:265,error,error,265,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6368,1,['error'],['error']
Availability,"Hi!. I am using the gatk tool AnalyzeSaturationMutagenesis to analyze some data produced with the MITE-seq technology. It works perfectly for my purpose, so I decided to include it as a step in my pipeline written in Nextflow. ; Strangely enough, when I try to run the SAME EXACT command line inside a Nextflow module, it gives a generic error for most of the samples (sometimes all of them, sometimes some of them). ; It looks like a random issue, because if I run the same code outside of Nextflow, it works perfectly on every sample. . I would really appreciate if someone may give me some hints on why this is occurring and, eventually, how to fix it. ## Bug Report. ### Affected tool(s) or class(es); AnalyzeSaturationMutagenesis . ### Affected version(s); gatk4-4.3.0.0. ### Description ; Here it follows the output from Nextflow that appears on screen:. ```; Error executing process > 'gatk_count (gatk)'. Caused by:; Process `gatk_count (gatk)` terminated with an error exit status (247). Command executed:. gatk AnalyzeSaturationMutagenesis -I MITE6_P1_out.sam -R /home/tigem/f.panariello/Scratch/Cacchiarelli/MITE/QC_1804//i ndex/genome.fa --orf 1-5610 -O ./MITE6_P1. Command exit status:; 247. Command output:; (empty). Command error:; WARNING: Not mounting requested bind point (already mounted in container): /home/tigem/f.panariello; Using GATK jar /usr/local/share/gatk4-4.3.0.0-0/gatk-package-4.3.0.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=f alse -Dsamjdk.compression_level=2 -jar /usr/local/share/gatk4-4.3.0.0-0/gatk-package-4.3.0.0-local.jar AnalyzeSaturationMutagenesis -I MITE6_P1_out.sam -R /home/tigem/f.panariello/Scratch/Cacchiarelli/MITE/QC_1804//index/genome.fa --orf 1-5610 -O ./MIT E6_P1; 09:36:03.173 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/usr/local/share/gatk4-4.3.0.0-0/gatk-package -4.3.0.0-local.jar!/com/intel/gkl/native/libgk",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8357:338,error,error,338,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8357,3,"['Error', 'error']","['Error', 'error']"
Availability,"Hi, . I am testing the GATK beta 4.6 at the moment. It's a great improvement in time used to analyse data. Similarly I am interested in calling germline CNV events. I tried out the workflow with only two samples, just to find the right tools and see how it behaves. ; First I used `gatk-launch CalculateTargetCoverage` and `gatk-launch TargetCoverageSexGenotyper` and used the resulting files as input for `gatk-launch GermlineCNVCaller`. Unfortunatelly I got the following error when calling GermlineCNVCaller:. `A USER ERROR has occurred: Couldn't read file /media/Berechnungen/GATKTest/CN_transition_matrix_autosomal.tsvx. Error was: Could not read NDArray tsv file`. I found out that this error has something to do with Numpy. I have installed Numpy 1.13.1. ; Have you seen some error like this before?. Thanks in advance; Stefan",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3996:474,error,error,474,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3996,5,"['ERROR', 'Error', 'error']","['ERROR', 'Error', 'error']"
Availability,"Hi, . I am using `GATK ASEReadCounter` from GATK 4.2.0.0 and encounter the error . `A USER ERROR has occurred: More then one variant context at position: chrX:2774793`. As I googled, that means that there are 2 different entries with the same genomic coordinate in my VCF file. ; But by doing a `grep -P 'chrX\t2774793' 16-98_WGS.vcf | cut -f1-5` for my vcf file I only get one line:. `chrX 2774793 . G *,C`. The whole command I am using is as following . ```; gatk ASEReadCounter ; -R /media/Data/Referenzgenome/HG19/HG19.karyo.fasta ; -I /media/Data/Marco/16-98/16-98_iPSC_A.recal.rh.bam ; -I /media/Data/Marco/16-98/16-98_iPSC_B.recal.rh.bam ; -V /media/Data/Marco/16-98/16-98_WGS.vcf ; -O /media/Data/Marco/16-98/16-98_Out_iPSC_A_B.table ; -L chrX; ```. Do you have any idea how to solve this?; Thanks in advance ; Stefan",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7249:75,error,error,75,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7249,2,"['ERROR', 'error']","['ERROR', 'error']"
Availability,"Hi, . I have the same issue reported here https://github.com/broadinstitute/gatk/issues/6766 that relates to CombineGVCFs. It was supposed to be fixed with the new version 4.1.9.0, however. I still get the same error when I tried it with the current version. . Here is the error report . > Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/orange/reed/nhouse/Raw_seqs/SEQ9_samples/tmp; 11:30:50.248 WARN GATKAnnotationPluginDescriptor - Redundant enabled annotation group (StandardAnnotation) is enabled for this tool by default; 11:30:50.478 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/apps/gatk/4.1.9.0/gatk-package-4.1.9.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Oct 26, 2020 11:30:50 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 11:30:50.791 INFO CombineGVCFs - ------------------------------------------------------------; 11:30:50.791 INFO CombineGVCFs - The Genome Analysis Toolkit (GATK) v4.1.9.0; 11:30:50.792 INFO CombineGVCFs - For support and documentation go to https://software.broadinstitute.org/gatk/; 11:30:50.792 INFO CombineGVCFs - Executing as nwijewardena@c3a-s8.ufhpc on Linux v3.10.0-1062.18.1.el7.x86_64 amd64; 11:30:50.792 INFO CombineGVCFs - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_31-b13; 11:30:50.792 INFO CombineGVCFs - Start Date/Time: October 26, 2020 11:30:50 AM EDT; 11:30:50.793 INFO CombineGVCFs - ------------------------------------------------------------; 11:30:50.793 INFO CombineGVCFs - ------------------------------------------------------------; 11:30:50.794 INFO CombineGVCFs - HTSJDK Version: 2.23.0; 11:30:50.794 INFO CombineGVCFs - Picard Version: 2.23.3; 11:30:50.794 INFO CombineGVCFs - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 11:30:50.794 INFO CombineGVCFs - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 11:30:50.794 INFO CombineGVCFs - HTSJDK Defaults.USE_ASYNC_IO_WRI",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6913:211,error,error,211,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6913,3,"['Redundant', 'error']","['Redundant', 'error']"
Availability,"Hi, . I was wondering if it's possible to use funcotator to annotate a VCF with structural variants. I'm trying to use funcotator (GATK 4.1.9.0) to annotate a VCF from manta but it fails with the first variant (SVTYPE=DEL):. ```; [...]; 17:07:32.003 ERROR GencodeFuncotationFactory - Problem creating a GencodeFuncotation on transcript ENST00000378191.5 for variant: chr1:4709859-185537688(G* -> <DEL>): Variant overlaps transcript but is not completely contained ; within it. Funcotator cannot currently handle this case. Transcript: ENST00000378191.5 Variant: [VC Unknown @ chr1:4709859-185537688 Q. of type=SYMBOLIC alleles=[G*, <DEL>] attr={CIEND=[0, 4], CIPOS=[0, 4], END=185537688, HOML; EN=4, HOMSEQ=TCCT, SOMATIC=true, SOMATICSCORE=141, SVLEN=-180827829, SVTYPE=DEL} GT=PR:SR 68,0:94,0 38,23:94,24 filters=; 17:07:32.003 WARN GencodeFuncotationFactory - Creating default GencodeFuncotation on transcript ENST00000378191.5 for problem variant: chr1:4709859-185537688(G* -> <DEL>); 17:07:32.009 INFO VcfFuncotationFactory - ClinVar_VCF 20180429_hg38 cache hits/total: 0/0; 17:07:32.010 INFO VcfFuncotationFactory - dbSNP 9606_b151 cache hits/total: 0/0; 17:07:32.010 INFO VcfFuncotationFactory - gnomAD_exome 2.1 cache hits/total: 0/0; 17:07:32.010 INFO VcfFuncotationFactory - gnomAD_genome 2.1 cache hits/total: 0/0; 17:07:32.136 INFO Funcotator - Shutting down engine; [14 January 2021 17:07:32 GMT] org.broadinstitute.hellbender.tools.funcotator.Funcotator done. Elapsed time: 0.77 minutes.; Runtime.totalMemory()=1426182144; java.lang.ArrayIndexOutOfBoundsException: 0; at org.broadinstitute.hellbender.tools.funcotator.FuncotatorUtils.getNonOverlappingAltAlleleBaseString(FuncotatorUtils.java:294); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.getGenomeChangeString(GencodeFuncotationFactory.java:2346); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createGencodeFuncotationBuilderWithTri",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7040:250,ERROR,ERROR,250,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7040,1,['ERROR'],['ERROR']
Availability,"Hi, . I'm trying to run ""cnv_germline_cohort_workflow"" from this workspace (https://app.terra.bio/#workspaces/help-gatk/Germline-CNVs-GATK4), and the workflow is keep failing at the ""CollectCounts"" step with the following error; in multiple shards. --------------------------------------------------------------------------------------------------------------------; A USER ERROR has occurred: Traversal by intervals was requested but some input files are not indexed.; Please index all input files:. samtools index /cromwell_root/dg.4DFC_3615e55e-6aa3-43e7-8d7b-6f2824071971/C345.TCGA-A3-3373-11A-01D-1421-08.5.bam; --------------------------------------------------------------------------------------------------------------------. This was weird since I set a correct index file as an input, but after some investigation, I realized that ; the error seemed to be occurring when the bucket path where BAM index was located was different from that of BAM file ; For example, if you look at this log below, . `Attempting to download gs://gdc-tcga-phs000178-controlled/KIRC/DNA/WXS/BI/ILLUMINA/C345.TCGA-A3-3373-11A-01D-1421-08.5.bam to /cromwell_root/dg.4DFC_3615e55e-6aa3-43e7-8d7b-6f2824071971/C345.TCGA-A3-3373-11A-01D-1421-08.5.bam; Successfully activated service account; Will continue with download. Activated service account credentials for: [kd5mqbpsed8lzz0kyz9tvkht-3274@dcf-prod.iam.gserviceaccount.com]; Download complete!; 2021/09/29 15:46:14 Localizing input drs://dg.4DFC:ab4d57fa-bfff-4a48-bd96-f2866ecfe0e1 -> /cromwell_root/dg.4DFC_ab4d57fa-bfff-4a48-bd96-f2866ecfe0e1/C345.TCGA-A3-3373-11A-01D-1421-08.5.bam.bai; Requester Pays project ID is Some(vanallen-firecloud-nih); Attempting to download gs://gdc-tcga-phs000178-controlled/KIRC/DNA/WXS/BI/ILLUMINA/C345.TCGA-A3-3373-11A-01D-1421-08.5.bam.bai to /cromwell_root/dg.4DFC_ab4d57fa-bfff-4a48-bd96-f2866ecfe0e1/C345.TCGA-A3-3373-11A-01D-1421-08.5.bam.bai; Successfully activated service account; Will continue with download. Activa",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7487:222,error,error,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7487,3,"['ERROR', 'error']","['ERROR', 'error']"
Availability,"Hi, . In the Mutect2.wdl file, the section of task definition for M2, I found the following argument maybe redundant, but I am not quite sure. -L ~{variants_for_contamination} . Best regards!",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7731:107,redundant,redundant,107,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7731,1,['redundant'],['redundant']
Availability,"Hi, ; I am experimenting with submitting a PrintReadsSpark job to a yarn spark cluster in AWS. I run the job with the following command. ```; spark-submit --deploy-mode cluster --class org.broadinstitute.hellbender.Main --deploy-mode cluster --master yarn gatk-package-4.alpha.2-248-gcd449bf-SNAPSHOT-spark.jar PrintReadsSpark -I hdfs://chr1.bam -O hdfs://output.bam; ```. I can see from the output files that the job finished successfully, however the cluster tells me that it failed. It shows the following error message:. ```; 17/05/05 06:03:53 INFO ApplicationMaster: Final app status: FAILED, exitCode: 16, (reason: Shutdown hook called before final status was reported.); ```. I believe this may be due to the `System.exit(0)` statement at line 144 in hellbender.Main, though I am not sure. . Here is a more complete snippet from the stderr log. . ```; 17/05/05 06:03:50 INFO FileOutputCommitter: File Output Committer Algorithm version is 1; 17/05/05 06:03:52 WARN DFSClient: Caught exception ; java.lang.InterruptedException; 	at java.lang.Object.wait(Native Method); 	at java.lang.Thread.join(Thread.java:1249); 	at java.lang.Thread.join(Thread.java:1323); 	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.closeResponder(DFSOutputStream.java:609); 	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.endBlock(DFSOutputStream.java:370); 	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:546); 17/05/05 06:03:52 INFO FileOutputCommitter: Saved output of task 'attempt_20170505060336_0011_r_000001_0' to hdfs://ip-172-30-0-86.ec2.internal:8020/output.bam.parts/_temporary/0/task_20170505060336_0011_r_000001; 17/05/05 06:03:52 INFO Executor: Finished task 1.0 in stage 2.0 (TID 3). 1921 bytes result sent to driver; 17/05/05 06:03:52 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 3) in 10260 ms on localhost (executor driver) (1/4); 17/05/05 06:03:53 INFO FileOutputCommitter: Saved output of task 'attempt_20170505060336_0011_r_000000_0' to ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2666:509,error,error,509,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2666,1,['error'],['error']
Availability,"Hi, ; I need to run BaseRecalibrator as a part of the preprocessing of my RNAseq bam files before variant calling. But I experience difficulties with memory! Here is the error I get:. ```; 22:30:25.477 INFO BaseRecalibrator - Start Date/Time: March 8, 2024 at 10:30:25 PM GMT; 22:30:25.477 INFO BaseRecalibrator - ------------------------------------------------------------; 22:30:25.477 INFO BaseRecalibrator - ------------------------------------------------------------; 22:30:25.477 INFO BaseRecalibrator - HTSJDK Version: 4.1.0; 22:30:25.478 INFO BaseRecalibrator - Picard Version: 3.1.1; 22:30:25.478 INFO BaseRecalibrator - Built for Spark Version: 3.5.0; 22:30:25.478 INFO BaseRecalibrator - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 22:30:25.478 INFO BaseRecalibrator - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 22:30:25.478 INFO BaseRecalibrator - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 22:30:25.478 INFO BaseRecalibrator - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 22:30:25.478 INFO BaseRecalibrator - Deflater: IntelDeflater; 22:30:25.478 INFO BaseRecalibrator - Inflater: IntelInflater; 22:30:25.478 INFO BaseRecalibrator - GCS max retries/reopens: 20; 22:30:25.479 INFO BaseRecalibrator - Requester pays: disabled; 22:30:25.479 INFO BaseRecalibrator - Initializing engine; WARNING 2024-03-08 22:30:25 SamFiles The index file /mnt/storage/users/dockworker/mpedersen/work/RNAseq_variant_call/work/d6/362957b6215ad2e8193c27c895d42d/VR0024SA.withoutERCCs.withRG.markedDup.splitNcigar.bai was found by resolving the canonical path of a symlink: VR0024SA.withoutERCCs.withRG.markedDup.splitNcigar.bam -> /mnt/storage/users/dockworker/mpedersen/work/RNAseq_variant_call/work/d6/362957b6215ad2e8193c27c895d42d/VR0024SA.withoutERCCs.withRG.markedDup.splitNcigar.bam; 22:30:25.631 INFO FeatureManager - Using codec VCFCodec to read file file://1000G_phase1.snps.high_confidence.hg38.vcf.gz; 22:30:25.754 INFO FeatureManager - Using codec VCFCodec to read",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8726:170,error,error,170,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8726,1,['error'],['error']
Availability,"Hi, ; This is what i got when i run the command gatk --help ; (base) ameni@ameni-Aspire-A315-55G:~/Documents/pharmacogenomics$ gatk --help. Usage template for all tools (uses --spark-runner LOCAL when used with a Spark tool); gatk AnyTool toolArgs. Usage template for Spark tools (will NOT work on non-Spark tools); gatk SparkTool toolArgs [ -- --spark-runner <LOCAL | SPARK | GCS> sparkArgs ]. Getting help; gatk --list Print the list of available tools. gatk Tool --help Print help on a particular tool. Configuration File Specification; --gatk-config-file PATH/TO/GATK/PROPERTIES/FILE. gatk forwards commands to GATK and adds some sugar for submitting spark jobs. --spark-runner <target> controls how spark tools are run; valid targets are:; LOCAL: run using the in-memory spark runner; SPARK: run using spark-submit on an existing cluster ; --spark-master must be specified; --spark-submit-command may be specified to control the Spark submit command; arguments to spark-submit may optionally be specified after -- ; GCS: run using Google cloud dataproc; commands after the -- will be passed to dataproc; --cluster <your-cluster> must be specified after the --; spark properties and some common spark-submit parameters will be translated ; to dataproc equivalents. --dry-run may be specified to output the generated command line without running it; --java-options 'OPTION1[ OPTION2=Y ... ]' optional - pass the given string of options to the ; java JVM at runtime. ; Java options MUST be passed inside a single string with space-separated values. --debug-port <number> sets up a Java VM debug agent to listen to debugger connections on a; particular port number. This in turn will add the necessary java VM arguments; so that you don't need to explicitly indicate these using --java-options.; --debug-suspend sets the Java VM debug agent up so that the run get immediatelly suspended; waiting for a debugger to connect. By default the port number is 5005 but; can be customized using --debug-port.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8280:439,avail,available,439,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8280,1,['avail'],['available']
Availability,"Hi, ; When I used the `enable-all-annotations` option to run Mutect2, it failed.; ```; ~/software/gatktools/gatk-4.1.3.0/gatk Mutect2 \; -R ~/database/hg19/gatk_bundle/ucsc.hg19.fasta \; -I sample.recalibrated.bam -tumor sample -L tmp.bed \; --germline-resource ~/af-only-gnomad.raw.sites.hg19.vcf.gz \; -O gatk4p1p3p0.enable-all-annotations.vcf --enable-all-annotations true; ```; Error logs:; ```; ...; 15:52:06.727 INFO Mutect2 - Shutting down engine; [December 12, 2019 3:52:06 PM CST] org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2 done. Elapsed time: 0.17 minutes.; Runtime.totalMemory()=2494038016; org.broadinstitute.hellbender.exceptions.GATKException: Reference coordinate corresponds to a non-existent base in the read. This should never happen -- check read with alignment start: 6257722 and cigar: 5H134M; at org.broadinstitute.hellbender.utils.read.ReadUtils.getReadCoordinateForReferenceCoordinate(ReadUtils.java:830); at org.broadinstitute.hellbender.utils.read.ReadUtils.getReadCoordinateForReferenceCoordinate(ReadUtils.java:761); at org.broadinstitute.hellbender.utils.read.ReadUtils.getReadCoordinateForReferenceCoordinateUpToEndOfRead(ReadUtils.java:679); at org.broadinstitute.hellbender.tools.walkers.annotator.BaseQualityRankSumTest.getReadBaseQuality(BaseQualityRankSumTest.java:43); at org.broadinstitute.hellbender.tools.walkers.annotator.allelespecific.AS_BaseQualityRankSumTest.getElementForRead(AS_BaseQualityRankSumTest.java:57); at org.broadinstitute.hellbender.tools.walkers.annotator.RankSumTest.getElementForRead(RankSumTest.java:108); at org.broadinstitute.hellbender.tools.walkers.annotator.RankSumTest.fillQualsFromLikelihood(RankSumTest.java:86); at org.broadinstitute.hellbender.tools.walkers.annotator.allelespecific.AS_RankSumTest.annotate(AS_RankSumTest.java:47); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorEngine.annotateContext(VariantAnnotatorEngine.java:278); at org.broadinstitute.hellbender.tools.walkers.mutec",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6314:382,Error,Error,382,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6314,2,"['Error', 'down']","['Error', 'down']"
Availability,"Hi, GATK contributors. Thank you for the great software!. I had looked for the answer several days. . Question:; Several samples are new sequenced and `g.vcf` was called using `GATK` with `-ERC GVCF` models.; I want to add this new sample variants into the existing VCF file (no g.vcf avaliable) that downloaded from other researchers.; I have tested some commands like `CombineGVCFs`, `MergeVcfs` but all failed.; Could you give some advices?; Any respone would be helpful. Thanks ~",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7292:301,down,downloaded,301,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7292,1,['down'],['downloaded']
Availability,"Hi, GATK team! I'm working on GATK WGS somatic CNV calling pipeline. . When I tried gatk --java-options ""-Xmx2800g"" ModelSegments --denoised-copy-ratios ${tumor}.denoisedCR.tsv --allelic-counts ${tumor}.allelicCounts.tsv --normal-allelic-counts ${normal}.allelicCounts.tsv --output-prefix ${tumor} -O ${outdir}, I got this type of error:. 10:00:18.408 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/lustre/home/acct-medliuyb/medliuyb-user1/gatk-4.2.0.0/gatk-package-4.2.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Jan 10, 2022 10:00:18 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 10:00:18.544 INFO ModelSegments - ------------------------------------------------------------; 10:00:18.544 INFO ModelSegments - The Genome Analysis Toolkit (GATK) v4.2.0.0; 10:00:18.544 INFO ModelSegments - For support and documentation go to https://software.broadinstitute.org/gatk/; 10:00:18.544 INFO ModelSegments - Executing as medliuyb-user1@huge2.pi.sjtu.edu.cn on Linux v3.10.0-1062.el7.x86_64 amd64; 10:00:18.545 INFO ModelSegments - Java runtime: OpenJDK 64-Bit Server VM v10.0.2+13; 10:00:18.545 INFO ModelSegments - Start Date/Time: January 10, 2022 at 10:00:18 AM CST; 10:00:18.545 INFO ModelSegments - ------------------------------------------------------------; 10:00:18.545 INFO ModelSegments - ------------------------------------------------------------; 10:00:18.545 INFO ModelSegments - HTSJDK Version: 2.24.0; 10:00:18.545 INFO ModelSegments - Picard Version: 2.25.0; 10:00:18.545 INFO ModelSegments - Built for Spark Version: 2.4.5; 10:00:18.545 INFO ModelSegments - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 10:00:18.546 INFO ModelSegments - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 10:00:18.546 INFO ModelSegments - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 10:00:18.546 INFO ModelSegments - HTSJDK Defaults",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7633:331,error,error,331,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7633,1,['error'],['error']
Availability,"Hi, I am working with WES data with 130 samples. I've been following GATK4 best practices and also using the GRCh38 reference from the GATK bundle. I've been able to pre-process all the samples and to use Haplotypecaller for the 130 samples, then I proceed to merge all into a single gVCF file to then perform a join-call of SNPs and INdels. However, I got the following error message when using ""GenotypeGVCF"" ; Thank you; Cristian. ### Affected tool(s) or class(es); GenotypeGVCFs. ### Affected version(s); GATK v4.0.5.2; ### Description ; 12:37:00.202 WARN GATKAnnotationPluginDescriptor - Redundant enabled annotation group (StandardAnnotation) is enabled for this tool by default; 12:37:00.306 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home-1/cvalenc1@jhu.edu/apps/GATK4/gatk-4.0.5.2/gatk-package-4.0.5.2-local.jar!/com/intel/gkl/native/libg; kl_compression.so; 12:37:00.524 INFO GenotypeGVCFs - ------------------------------------------------------------; 12:37:00.524 INFO GenotypeGVCFs - The Genome Analysis Toolkit (GATK) v4.0.5.2; 12:37:00.524 INFO GenotypeGVCFs - For support and documentation go to https://software.broadinstitute.org/gatk/; 12:37:00.529 INFO GenotypeGVCFs - Executing as cvalenc1@jhu.edu@compute0207 on Linux v2.6.32-696.28.1.el6.x86_64 amd64; 12:37:00.530 INFO GenotypeGVCFs - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_45-b14; 12:37:00.530 INFO GenotypeGVCFs - Start Date/Time: July 12, 2018 12:37:00 PM EDT; 12:37:00.530 INFO GenotypeGVCFs - ------------------------------------------------------------; 12:37:00.530 INFO GenotypeGVCFs - ------------------------------------------------------------; 12:37:00.530 INFO GenotypeGVCFs - HTSJDK Version: 2.16.0; 12:37:00.530 INFO GenotypeGVCFs - Picard Version: 2.18.7; 12:37:00.530 INFO GenotypeGVCFs - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 12:37:00.531 INFO GenotypeGVCFs - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 12:37:00.531 INFO GenotypeGVCFs - HTSJDK Defau",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5009:371,error,error,371,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5009,2,"['Redundant', 'error']","['Redundant', 'error']"
Availability,"Hi, I downloaded the newest version of GATK [""https://github.com/broadinstitute/gatk.git""] and I combined g.vcf files into vcf with the command; <pre>; gatk GenomicsDBImport --sample-name-map /work7_P1/GATK_RegionCall/Variant_call/cohort.sample_map --reader-threads 5 --batch-size 50 --genomicsdb-workspace-path /work7_P1/GATK_RegionCall/DBimport/chr01_directory --intervals chr01; </pre> . From the perspective of site 1660261, we have a missing C from 1660261 to 1660272. However, from site 1660263, we have a long deletion of ""CTCTCTCTC"", which is a conflict with information from 1660261. As I was trying to construct a personalized genome, tools I know can only deal with the first variant while ignoring overlapping variant. A good way to deal this might be isolating specific sample and trim the same tailing bases, for example, converting GTAAC->GAAC to GT->G. <pre>; chr01 <b>1660261</b> . TCTCTCTCTCTC TTCTCTCTCTC,T,* 93054.98 . AC=382,4,2;AF=0.070,7.294e-04,3.647e-04;AN=5484;BaseQRankSum=0.947;DP=21527;ExcessHet=-0.0000;FS=0.000;InbreedingCoeff=0.6279;MLEAC=463,3,1;MLEAF=0.084,5.470e-04,1.823e-04;MQ=58.57;MQRankSum=0.00;QD=27.98;ReadPosRankSum=0.00;SOR=0.533 GT:AD:DP:GQ:PGT:PID:PL:PS 0|1:4,14,0,0:18:99:<b>0|1:1660261_TC_T</b>:507,0,114,519,156,675,519,156,675,675:1660261; chr01 1660262 . C *,T 6047.70 . AC=388,26;AF=0.070,4.712e-03;AN=5518;BaseQRankSum=1.38;DP=21571;ExcessHet=-0.0000;FS=0.000;InbreedingCoeff=0.5827;MLEAC=466,19;MLEAF=0.084,3.443e-03;MQ=59.84;MQRankSum=0.00;QD=2.47;ReadPosRankSum=0.431;SOR=0.510 GT:AD:DP:GQ:PGT:PID:PL:PS 0|1:4,14,0:18:99:<b>0|1:1660261_TC_T</b>:507,0,114,519,156,675:1660261; chr01 <b>1660263</b> . TCTCTCTCTC TTCTCTCTC,T,* 120442.78 . AC=102,382,6;AF=0.018,0.069,1.085e-03;AN=5530;BaseQRankSum=0.916;DP=21553;ExcessHet=-0.0000;FS=0.000;InbreedingCoeff=0.6783;MLEAC=119,455,4;MLEAF=0.022,0.082,7.233e-04;MQ=58.72;MQRankSum=0.00;QD=32.35;ReadPosRankSum=0.00;SOR=0.482 GT:AD:DP:GQ:PGT:PID:PL:PS <b>0|2</b>:4,0,14,0:18:99:<b>0|1:1660261_TC_T</b>:50",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5944:6,down,downloaded,6,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5944,1,['down'],['downloaded']
Availability,"Hi, I encountered the following error while running GATK.; It is hard for me to say what exactly is wrong, and extensive searching has not been helpul. Thanks in advance!. ```; gatk ValidateVariants -V ../../data/geno/phased/chr1-22.phased.rename.reheader.vcf.gz -R ../../../../index/hg19.fa.gz; Using GATK jar ~/tools/gatk-4.1.8.0/gatk-package-4.1.8.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /home/zepengmu/tools/gatk-4.1.8.0/gatk-package-4.1.8.0-local.jar ValidateVariants -V ../../data/geno/phased/chr1-22.phased.rename.reheader.vcf.gz -R ../../../../index/hg19.fa.gz; 19:53:34.379 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/zepengmu/tools/gatk-4.1.8.0/gatk-package-4.1.8.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Oct 25, 2020 7:53:34 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 19:53:34.606 INFO ValidateVariants - ------------------------------------------------------------; 19:53:34.606 INFO ValidateVariants - The Genome Analysis Toolkit (GATK) v4.1.8.0; 19:53:34.606 INFO ValidateVariants - For support and documentation go to https://software.broadinstitute.org/gatk/; 19:53:34.607 INFO ValidateVariants - Executing as zepengmu@midway2-login1.rcc.local on Linux v3.10.0-1127.8.2.el7.x86_64 amd64; 19:53:34.607 INFO ValidateVariants - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_45-b14; 19:53:34.607 INFO ValidateVariants - Start Date/Time: October 25, 2020 7:53:34 PM CDT; 19:53:34.607 INFO ValidateVariants - ------------------------------------------------------------; 19:53:34.607 INFO ValidateVariants - ------------------------------------------------------------; 19:53:34.607 INFO ValidateVariants - HTSJDK Version: 2.22.0; 19:53:34.607 INFO ValidateVarian",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6911:32,error,error,32,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6911,1,['error'],['error']
Availability,"Hi, I want to use HaplotypeCaller and GenotypeGVCFs to call SNPs and meet a problem and my GATK version is v3.3-0-g37228af . Here is my script and I have 427 sample：. $JAVA -Xmx8g -jar $GATK -T HaplotypeCaller -R Chr06.fa -I $NOW/${RIL}.final.bam -ERC GVCF -o $NOW/${RIL}.raw.g.vcf --genotyping_mode DISCOVERY -variant_index_type LINEAR -variant_index_parameter 128000 -nct 24; $JAVA -Xmx4g -jar $GATK -T GenotypeGVCFs -nt 24 -R $REF/Chr06.fa \; --variant $NOW/w-1.raw.g.vcf \; --variant $NOW/w-10.raw.g.vcf \; --variant $NOW/w-100.raw.g.vcf \; -o KF427.raw.vcf. I got a error like this:. ##### ERROR MESSAGE: Invalid command line: No tribble type was provided on the command line and the type of the file could not be determined dynamically. Please add an explicit type tag :NAME listing the correct type from among the supported types:; ##### ERROR Name FeatureType Documentation; ##### ERROR BCF2 VariantContext (this is an external codec and is not documented within GATK); ##### ERROR VCF VariantContext (this is an external codec and is not documented within GATK); ##### ERROR VCF3 VariantContext (this is an external codec and is not documented within GATK); ##### ERROR ------------------------------------------------------------------------------------------. then I added a name like this:. --variant:VCF $NOW/w-91.raw.g.vcf \; --variant:VCF $NOW/w-92.raw.g.vcf \; --variant:VCF $NOW/w-93.raw.g.vcf \. also met a error like this:. ##### ERROR; ##### ERROR MESSAGE: Your input file has a malformed header: We never saw the required CHROM header line (starting with one #) for the input VCF file; ##### ERROR ------------------------------------------------------------------------------------------. and I change the name like this:. --variant:VCF3 $NOW/w-91.raw.g.vcf \; --variant:VCF3 $NOW/w-92.raw.g.vcf \; --variant:VCF3 $NOW/w-93.raw.g.vcf \. also error:. ##### ERROR MESSAGE: Unable to parse header with error: Your input file has a malformed header: This codec is strictly for VCFv3 ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7315:571,error,error,571,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7315,2,"['ERROR', 'error']","['ERROR', 'error']"
Availability,"Hi, I'm interested in your keras model for variant calling. Is there anyway I can download it to study it?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4511:82,down,download,82,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4511,1,['down'],['download']
Availability,"Hi, i can't install gatk via conda/mamba. couldyou pls help; pls see steps that i took. ```; $conda config --add channels conda-forge; $conda config --add channels bioconda; $conda config --add channels defaults; $conda config --set channel_priority strict; ```. install command; ```; bash:iscxf001:/data1/greenbab/users/ahunos/apps/gatk-4.5.0.0 1023 $ conda env create -n gatk -f gatkcondaenv.yml; ```. ```; Channels:; - conda-forge; - defaults; - bioconda; Platform: linux-64; Collecting package metadata (repodata.json): done; Solving environment: failed. PackagesNotFoundError: The following packages are not available from current channels:. - conda-forge::typing_extensions==4.1.1; - conda-forge::theano==1.0.4; - pkgs/main::tensorflow==1.15.0; - conda-forge::scipy==1.0.0; - conda-forge::scikit-learn==0.23.1; - conda-forge::python==3.6.10; - bioconda::pysam==0.15.3; - conda-forge::pymc3==3.1; - conda-forge::pip==21.3.1; - conda-forge::pandas==1.0.3; - conda-forge::numpy==1.17.5; - conda-forge::mkl-service==2.3.0; - conda-forge::mkl==2019.5; - conda-forge::matplotlib==3.2.1; - conda-forge::keras==2.2.4; - conda-forge::joblib==1.1.1; - pkgs/main::intel-openmp==2019.4; - conda-forge::h5py==2.10.0; - conda-forge::dill==0.3.4. Current channels:. - https://conda.anaconda.org/conda-forge/linux-64; - https://repo.anaconda.com/pkgs/main/linux-64; - https://repo.anaconda.com/pkgs/r/linux-64; - https://conda.anaconda.org/bioconda/linux-64; - https://conda.anaconda.org/bioconda; - https://conda.anaconda.org/conda-forge; - https://conda.anaconda.org/conda-forge; - https://conda.anaconda.org/conda-forge; - https://conda.anaconda.org/conda-forge; - https://conda.anaconda.org/conda-forge; - https://conda.anaconda.org/conda-forge; - https://conda.anaconda.org/conda-forge; - https://conda.anaconda.org/conda-forge; - https://conda.anaconda.org/conda-forge; - https://conda.anaconda.org/conda-forge; - https://conda.anaconda.org/conda-forge; - https://conda.anaconda.org/conda-forge; - https:/",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8838:613,avail,available,613,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8838,1,['avail'],['available']
Availability,"Hi, recently I was trying expand the annotation data source when using funcotator, however, the document didn't give much information or example. Now I was trying to add CADD to the data source folder. After running the funcotator, I got the error:. ```; org.broadinstitute.hellbender.exceptions.GATKException: Error initializing feature reader for path file: funcotator_dataSources.v1.6.20190124s/cadd/hg19/cadd.config; at org.broadinstitute.hellbender.engine.FeatureDataSource.getTribbleFeatureReader(FeatureDataSource.java:353); at org.broadinstitute.hellbender.engine.FeatureDataSource.getFeatureReader(FeatureDataSource.java:305); at org.broadinstitute.hellbender.engine.FeatureDataSource.&lt;init&gt;(FeatureDataSource.java:256); at org.broadinstitute.hellbender.engine.FeatureManager.addToFeatureSources(FeatureManager.java:234); at org.broadinstitute.hellbender.engine.GATKTool.addFeatureInputsAfterInitialization(GATKTool.java:957); at org.broadinstitute.hellbender.tools.funcotator.dataSources.DataSourceUtils.createAndRegisterFeatureInputs(DataSourceUtils.java:328); at org.broadinstitute.hellbender.tools.funcotator.dataSources.DataSourceUtils.createDataSourceFuncotationFactoriesForDataSources(DataSourceUtils.java:277); at org.broadinstitute.hellbender.tools.funcotator.Funcotator.onTraversalStart(Funcotator.java:774); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1037); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:162); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:205); at org.broadinstitute.hellbender.Main.main(Main.java:291); Caused by: htsjdk.tribble.TribbleException$MalformedFeatureFile: Unable to",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6223:242,error,error,242,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6223,2,"['Error', 'error']","['Error', 'error']"
Availability,"Hi, when I executed the BwaAndMarkDuplicatesPipelineSpark command, there are some issues, I am not sure the issue related to the Spark environment or to the files I used. The ""ucsc.hg19.fasta.img"" is generated by the ""gatk-launch BwaMemIndexImageCreator ucsc.hg19.fasta"" command. The ""1982.unmapped.bam"" is generated by the picard command FastqToSam.jar :1234: . ```; ""java -jar /opt/NfsDir/BioDir/picard-tools-1.119/FastqToSam.jar F1=/opt/NfsDir/UserDir/lvxy/pipeline_test/BRCA/1982.R1.clean.fastq.gz F2=/opt/NfsDir/UserDir/lvxy/pipeline_test/BRCA/1982.R2.clean.fastq.gz V=Standard O=/opt/NfsDir/UserDir/wujh/1982.unmapped.bam SM=R1""; ```. Are there some examples I can follow?; ------------------------; ```; [sun@tele-1 download]/opt/NfsDir/BioDir/GATK4/gatk/gatk-launch BwaAndMarkDuplicatesPipelineSpark --bwamemIndexImage hdfs:///user/sun/ucsc.hg19.fasta.img -I hdfs:///user/sun/1982.unmapped.bam -R hdfs:///user/sun/ucsc.hg19.fasta -O hdfs:///user/sun/17F02897_17F02897M_WES_img.bwa.bam -- --sparkRunner SPARK --sparkMaster yarn --sparkSubmitCommand spark2-submit --driver-memory 4G --num-executors 4 --executor-cores 6 --executor-memory 16G --conf spark.dynamicAllocation.enabled=false; Using GATK jar /opt/NfsDir/BioDir/GATK4/gatk/build/libs/gatk-package-4.beta.5-50-g8d666b6-SNAPSHOT-spark.jar; Running:; spark2-submit --master yarn --conf spark.driver.userClassPathFirst=true --conf spark.io.compression.codec=lzf --conf spark.driver.maxResultSize=0 --conf spark.executor.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -Dsnappy.disable=true --conf spark.driver.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -Dsnappy.disable=true --conf spark.kryoserializer",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4112:723,down,download,723,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4112,1,['down'],['download']
Availability,"Hi, when I run gatk Funcotator, A USER ERROR has occurred; ```; Using GATK jar /export/.conda/envs/wes/share/gatk4-4.0.5.1-0/gatk-package-4.0.5.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /export/bioinfo-team/home/liuhw/.conda/envs/wes/share/gatk4-4.0.5.1-0/gatk-package-4.0.5.1-local.jar Funcotator --data-sources-path /export2/liuhw/software/gatk_Funcotator/funcotator_dataSources.v1.8.hg38.20230908s/ -V /export2/liuhw/wes_test//Mutect2_filter/K001137N_somatic_filtered.vcf.gz -R /Shared_Software/ref_genome/GATK_GRCh38/Homo_sapiens_assembly38.fasta --ref-version hg38 -O /export2/liuhw/wes_test//annotate/K001137N.funcotator.maf --output-file-format MAF; 02:55:31.904 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/export/bioinfo-team/home/liuhw/.conda/envs/wes/share/gatk4-4.0.5.1-0/gatk-package-4.0.5.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; 02:55:32.062 INFO Funcotator - ------------------------------------------------------------; 02:55:32.062 INFO Funcotator - The Genome Analysis Toolkit (GATK) v4.0.5.1-0.0.3; 02:55:32.062 INFO Funcotator - For support and documentation go to https://software.broadinstitute.org/gatk/; 02:55:32.062 INFO Funcotator - Executing as liuhw@RichardLi-Lab01 on Linux v5.4.0-74-generic amd64; 02:55:32.062 INFO Funcotator - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_412-b08; 02:55:32.063 INFO Funcotator - Start Date/Time: July 12, 2024 2:55:31 AM EDT; 02:55:32.063 INFO Funcotator - ------------------------------------------------------------; 02:55:32.063 INFO Funcotator - ------------------------------------------------------------; 02:55:32.063 INFO Funcotator - HTSJDK Version: 2.15.1; 02:55:32.063 INFO Funcotator - Picard Version: 2.18.2; 02:55:32.063 INFO Funcotator - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 02:55:32.063 INFO Funcotator - HTSJDK Defaults.USE_AS",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8913:39,ERROR,ERROR,39,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8913,1,['ERROR'],['ERROR']
Availability,"Hi,. First I filter snp.raw.vcf with `VariantFiltration` command below: ; `gatk-4.1.2.0/gatk --java-options ""-Djava.io.tmpdir=/tmp/"" VariantFiltration -R genome.fa -V snp_rmnan.raw.vcf --filter-expression ""QUAL < 30.0 || QD < 2.0 || FS > 60.0 || MQ < 40.0 || SOR > 4.0 || ReadPosRankSum < -8.0"" --filter-name ""my_snp_filter"" --missing-values-evaluate-as-failing true -O snp_rmnan.raw.vcf.tmp.vcf `. This command runs successfully. But when I'm using `SelectVariants` command to extact the filtered site:; `gatk-4.1.2.0/gatk --java-options ""-Djava.io.tmpdir=/tmp/"" SelectVariants -R genome.fa -V snp_rmnan.raw.vcf.tmp.vcf --exclude-filtered -O snp_rmnan.raw.vcf.filter.vcf `. I get this java ERROR below, even without the wrong line number and do not know how to deal with it......... o(╥﹏╥)o，Thank you very much!. ~~~; 11:15:52.195 INFO ProgressMeter - Chr01:15144308 19.9 541000 27161.2; 11:16:04.187 INFO ProgressMeter - Chr01:15388212 20.1 547000 27189.6; 11:16:12.515 INFO SelectVariants - Shutting down engine; [May 9, 2019 11:16:12 AM CST] org.broadinstitute.hellbender.tools.walkers.variantutils.SelectVariants done. Elapsed time: 20.37 minutes.; Runtime.totalMemory()=2814377984; java.lang.NumberFormatException: For input string: ""1,0""; at java.lang.NumberFormatException.forInputString(NumberFormatException.java:65); at java.lang.Integer.parseInt(Integer.java:580); at java.lang.Integer.parseInt(Integer.java:615); at htsjdk.variant.vcf.AbstractVCFCodec.createGenotypeMap(AbstractVCFCodec.java:734); at htsjdk.variant.vcf.AbstractVCFCodec$LazyVCFGenotypesParser.parse(AbstractVCFCodec.java:132); at htsjdk.variant.variantcontext.LazyGenotypesContext.decode(LazyGenotypesContext.java:158); at htsjdk.variant.variantcontext.LazyGenotypesContext.getGenotypes(LazyGenotypesContext.java:148); at htsjdk.variant.variantcontext.GenotypesContext.iterator(GenotypesContext.java:465); at org.broadinstitute.hellbender.tools.walkers.variantutils.SelectVariants.initalizeAlleleAnyploidIndicesCache(Sele",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5929:691,ERROR,ERROR,691,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5929,1,['ERROR'],['ERROR']
Availability,"Hi,. I am having the error below when I try to run PrintReadsSpark using an external spark cluster. ```; ./gatk-launch PrintReadsSpark -I ~/storage/NA12878_V2.5_Robot_1.dedup.realigned.recalibrated.bam -O ~/storage/output.bam -- --sparkRunner SPARK --sparkMaster spark://192.168.1.110:7077; Using GATK jar /home/centos/gatk-4.beta.5/gatk-package-4.beta.5-spark.jar; Running:; spark-submit --master spark://192.168.1.110:7077 --conf spark.driver.userClassPathFirst=true --conf spark.io.compression.codec=lzf --conf spark.driver.maxResultSize=0 --conf spark.executor.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -Dsnappy.disable=true --conf spark.driver.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -Dsnappy.disable=true --conf spark.kryoserializer.buffer.max=512m --conf spark.yarn.executor.memoryOverhead=600 /home/centos/gatk-4.beta.5/gatk-package-4.beta.5-spark.jar PrintReadsSpark -I /home/centos/storage/NA12878_V2.5_Robot_1.dedup.realigned.recalibrated.bam -O /home/centos/storage/output.bam --sparkMaster spark://192.168.1.110:7077; 05:27:50.924 WARN SparkContextFactory - Environment variables HELLBENDER_TEST_PROJECT and HELLBENDER_JSON_SERVICE_ACCOUNT_KEY must be set or the GCS hadoop connector will not be configured properly; 05:27:51.034 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/centos/gatk-4.beta.5/gatk-package-4.beta.5-spark.jar!/com/intel/gkl/native/libgkl_compression.so; [October 3, 2017 5:27:51 AM UTC] PrintReadsSpark --output /home/centos/storage/output.bam --input /home/centos/storage/NA12878_V2.5_Robot_1.dedup.realigned.recalibrated.bam --sparkMaster spark://192.168.1.110:7077 --readValidationStringe",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3651:21,error,error,21,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3651,1,['error'],['error']
Availability,"Hi,. I am on GATK v4.3.0.0 (CentOS) and would like to implement GermlineCNVCaller in my work. In an attempt to set up the conda environment (gcnvkernel) from zip using the command `conda env create -f gatkcondaenv.yml`, I got an error like this: `Found conflicts! Looking for incompatible packages.` . I also tried installing with tar, but I couldn't find gatkPythonPackageArchive.zip as required in the yml. Any help on this issue is much appreciated!. Java version: 1.8.0_201",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8091:229,error,error,229,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8091,1,['error'],['error']
Availability,"Hi,. I am trying to call germline CNVs for a set of samples. After running DetermineGermlineContigPloidy and GermlineCNVCaller, I am using PostprocessGermlineCNVCalls to generate the VCF files with CNV calls. The ""interval"" VCF files are generated successfully. But I got the following error message when segmenting contigs:. org.broadinstitute.hellbender.utils.python.PythonScriptExecutorException:; python exited with 1; Command Line: python /tmp/shulik7/segment_gcnv_calls.2338024416841754264.py --ploidy_calls_path /scratch/users/shulik7/test_GATK_CNV/Postprocess/../DetermineGermlineContigPloidy/model/test_run-calls/ --model_shards /scratch/shulik7/test_GATK_CNV/Postprocess/../GermlineCNVCaller/cnvs/test_run-model --calls_shards /scratch/shulik7/test_GATK_CNV/Postprocess/../GermlineCNVCaller/cnvs/test_run-calls --output_path /tmp/shulik7/gcnv-segmented-calls28280883609685538 --sample_index 0; Stdout: 11:32:16.728 INFO segment_gcnv_calls - Loading ploidy calls...; 11:32:16.729 INFO gcnvkernel.io.io_metadata - Loading germline contig ploidy and global read depth metadata...; 11:32:16.730 INFO segment_gcnv_calls - Instantiating the Viterbi segmentation engine...; 11:32:18.585 INFO gcnvkernel.postprocess.viterbi_segmentation - Assembling interval list and copy-number class posterior from model shards...; 11:32:25.158 INFO gcnvkernel.structs.metadata - Generating intervals metadata...; 11:32:27.543 INFO gcnvkernel.postprocess.viterbi_segmentation - Compiling theano forward-backward function...; 11:32:34.406 INFO gcnvkernel.postprocess.viterbi_segmentation - Compiling theano Viterbi function...; 11:32:40.598 INFO gcnvkernel.postprocess.viterbi_segmentation - Compiling theano variational HHMM...; 11:32:42.862 INFO gcnvkernel.postprocess.viterbi_segmentation - Processing sample index: 0, sample name: test_sample_0...; 11:32:43.631 INFO gcnvkernel.postprocess.viterbi_segmentation - Segmenting contig (1/24) (contig name: 1)... Stderr: Traceback (most recent call last):; File ""/t",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4724:286,error,error,286,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4724,1,['error'],['error']
Availability,"Hi,. I am trying to test the pathseq tutorial following the tutorial on [this]( https://gatkforums.broadinstitute.org/gatk/discussion/10913/how-to-run-the-pathseq-pipeline ""this"") link. I ran the following commands. bioinfo@bioinfo$ conda activate gatk; (gatk) bioinfo@bioinfo$ gatk PathSeqPipelineSpark \; > --input test_sample.bam \; > --filter-bwa-image hg19mini.fasta.img \; > --kmer-file hg19mini.hss \; > --min-clipped-read-length 70 \; > --microbe-fasta e_coli_k12.fasta \; > --microbe-bwa-image e_coli_k12.fasta.img \; > --taxonomy-file e_coli_k12.db \; > --output output.pathseq.bam \; > --scores-output output.pathseq.txt. And encountered below error:. Using GATK jar /home/bioinfo/Installers/gatk4/gatk-4.1.0.0/gatk-package-4.1.0.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /home/bioinfo/Installers/gatk4/gatk-4.1.0.0/gatk-package-4.1.0.0-local.jar PathSeqPipelineSpark --input test_sample.bam --filter-bwa-image hg19mini.fasta.img --kmer-file hg19mini.hss --min-clipped-read-length 70 --microbe-fasta e_coli_k12.fasta --microbe-bwa-image e_coli_k12.fasta.img --taxonomy-file e_coli_k12.db --output output.pathseq.bam --scores-output output.pathseq.txt; 18:57:39.629 WARN SparkContextFactory - Environment variables HELLBENDER_TEST_PROJECT and HELLBENDER_JSON_SERVICE_ACCOUNT_KEY must be set or the GCS hadoop connector will not be configured properly; 18:57:39.729 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/bioinfo/Installers/gatk4/gatk-4.1.0.0/gatk-package-4.1.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; 18:57:41.594 INFO PathSeqPipelineSpark - ------------------------------------------------------------; 18:57:41.594 INFO PathSeqPipelineSpark - The Genome Analysis Toolkit (GATK) v4.1.0.0; 18:57:41.594 INFO PathSeqPipelineSpark - For support and documentation go to https://software.broadi",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5802:655,error,error,655,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5802,1,['error'],['error']
Availability,"Hi,. I am using GATK `version gatk4-4.0.6.0-0` as part of the bcbio-nextgen pipeline for RNA-seq variant calling. There is one step in the pipeline i.e. `gatk GenomicsDBImport` that's been failing consistently no matter how less or many resources in terms of memory and cores I provide. I have tried to run the command as part of the pipeline and in stand-alone mode (like below) and both produce the same error:. ```; [rathik@reslnrefo01 log]$ gatk --java-options '-Xms454m -Xmx3181m -XX:+UseSerialGC' GenomicsDBImport --reader-threads 1 --genomicsdb-workspace-path CDL-164-04P-1_0_249250621_genomicsdb -L 1:1-249250621 --variant /mnt/isilon/cbmi/variome/rathik/mendelian_rnaseq/gatk_output/CDL-164-04P/variation/rnaseq/gatk-haplotype/Sample_1__CDL-164-04P-gatk-haplotype-annotated-rnaedit-annotated-gemini.vcf.gz; Using GATK jar /mnt/isilon/cbmi/variome/bin/bcbio-nextgen/bcbio/anaconda/share/gatk4-4.0.6.0-0/gatk-package-4.0.6.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xms454m -Xmx3181m -XX:+UseSerialGC -jar /mnt/isilon/cbmi/variome/bin/bcbio-nextgen/bcbio/anaconda/share/gatk4-4.0.6.0-0/gatk-package-4.0.6.0-local.jar GenomicsDBImport --reader-threads 1 --genomicsdb-workspace-path CDL-164-04P-1_0_249250621_genomicsdb -L 1:1-249250621 --variant /mnt/isilon/cbmi/variome/rathik/mendelian_rnaseq/gatk_output/CDL-164-04P/variation/rnaseq/gatk-haplotype/Sample_1__CDL-164-04P-gatk-haplotype-annotated-rnaedit-annotated-gemini.vcf.gz; Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/mnt/isilon/cbmi/variome/tmp/rathik; 11:49:24.784 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/mnt/isilon/cbmi/variome/bin/bcbio-nextgen/bcbio/anaconda/share/gatk4-4.0.6.0-0/gatk-package-4.0.6.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; 11:49:25.130 INFO GenomicsDBImport - ------------------------------------------------------------; 11:49",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5045:406,error,error,406,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5045,1,['error'],['error']
Availability,"Hi,. I am using GATK version 4.0.3.0 using a shell script. I am working with a haploid organism. I created a single sample BAM file by first aligning PE reads using HISAT2; samtools sort .SAM to .BAM files; then marked duplicate reads using picard. . I keep getting the error message:. A USER ERROR has occurred: Argument --emitRefConfidence has a bad value: Can only be used in single sample mode currently. Use the sample_name argument to run on a single sample out of a multi-sample BAM file. ```; time gatk --java-options ""-Xmx4g"" HaplotypeCaller \ ; -R reference.fa \ ; -I sample1.md.bam \ ; -O sample1.raw.g.vcf \; -ERC GVCF. ```. What am I doing wrong? . ```; Using GATK jar /usr/local/apps/eb/GATK/4.0.3.0-Java-1.8.0_144/gatk-package-4.0.3.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx4g -jar /usr/local/apps/eb/GATK/4.0.3.0-Java-1.8.0_144/gatk-package-4.0.3.0-local.jar HaplotypeCaller -R Af293.41.fa -I eAF01_md.bam -O eAF01.raw.g.vcf.gz -ERC GVCF; 22:25:20.396 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/usr/local/apps/eb/GATK/4.0.3.0-Java-1.8.0_144/gatk-package-4.0.3.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; 22:25:20.633 INFO HaplotypeCaller - ------------------------------------------------------------; 22:25:20.634 INFO HaplotypeCaller - The Genome Analysis Toolkit (GATK) v4.0.3.0; 22:25:20.634 INFO HaplotypeCaller - For support and documentation go to https://software.broadinstitute.org/gatk/; 22:25:20.635 INFO HaplotypeCaller - Executing as sek53827@n583.ecompute on Linux v3.10.0-229.20.1.el7.x86_64 amd64; 22:25:20.635 INFO HaplotypeCaller - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_144-b01; 22:25:20.635 INFO HaplotypeCaller - Start Date/Time: October 29, 2018 10:25:20 PM EDT; 22:25:20.635 INFO HaplotypeCaller - ------------------------------------------------------------",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5372:270,error,error,270,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5372,2,"['ERROR', 'error']","['ERROR', 'error']"
Availability,"Hi,. I don't know if it's a bug, but whenever I try to do a GenomicsDBImport I get an error, no matter which file I use. The command I run is (using GATK 4.0):. gatk GenomicsDBImport -V AD0616.10.g.vcf.gz --genomicsdb-workspace-path gdbworkspace-gatk -L 10. And the error I get is:. Using GATK jar /apps/GATK/4.0/gatk-package-4.0.0.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -jar /apps/GATK/4.0/gatk-package-4.0.0.0-local.jar GenomicsDBImport -V /scratch/production/cluengo/genomicsdb/AD0616.10.g.vcf.gz --genomicsdb-workspace-path gdbworkspace-gatk -L 10; 17:00:53.658 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/apps/GATK/4.0/gatk-package-4.0.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; 17:00:53.770 INFO GenomicsDBImport - ------------------------------------------------------------; 17:00:53.771 INFO GenomicsDBImport - The Genome Analysis Toolkit (GATK) v4.0.0.0; 17:00:53.771 INFO GenomicsDBImport - For support and documentation go to https://software.broadinstitute.org/gatk/; 17:00:53.771 INFO GenomicsDBImport - Executing as cluengo@login1 on Linux v2.6.32-696.13.2.el6.Bull.128.x86_64 amd64; 17:00:53.771 INFO GenomicsDBImport - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_102-b14; 17:00:53.771 INFO GenomicsDBImport - Start Date/Time: March 8, 2018 5:00:53 PM CET; 17:00:53.771 INFO GenomicsDBImport - ------------------------------------------------------------; 17:00:53.771 INFO GenomicsDBImport - ------------------------------------------------------------; 17:00:53.772 INFO GenomicsDBImport - HTSJDK Version: 2.13.2; 17:00:53.772 INFO GenomicsDBImport - Picard Version: 2.17.2; 17:00:53.772 INFO GenomicsDBImport - HTSJDK Defaults.COMPRESSION_LEVEL : 1; 17:00:53.772 INFO GenomicsDBImport - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 17:00:53.772 INFO GenomicsDBImport - HTS",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4514:86,error,error,86,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4514,2,['error'],['error']
Availability,"Hi,. I got a java.lang.IllegalStateException: Smith-Waterman alignment failure in Mutect2 (gatk 4.1.6.0).; When running the same input with the same options using gatk 4.1.4.1 the files get processed without error. Here the exception output:; java.lang.IllegalStateException: Smith-Waterman alignment failure. Cigar = 348M with reference length 348 but expecting reference length of 378 ref = CATACGCGTATACACACAATATAGGC; ATTGCATACGCGTATACACACAATATAGGCATTGCATACGCGTATACACACAATATAGGCATTGCATACGCGTATACACACAATATAGGCATTGCATACGCGTATACACACAATATAGGCATTGCATACGCGTATACACACAATATAGGCATTGCATACGCGTATACACACAATATAG; GCATTGCATACGCGTATACACACAAAATAGGCATTGTATACGCGTATACACACAAAATAGGCATTGTATACGCGTATACACACAAAATAGGCATTGTATACGCGTATACACACAAAATAGGCATTGTATACGCGTATACAATATAGGCATTGTATACGCGTATACAATATAGGC pat; h CATACGCGTATACACACAATATAGGCATTGCATACGCGTATACACACAATATAGGCATTGCATACGCGTATACACACAATATAGGCATTGCATACGCGTATACACACAATATAGGCATTGCATACGCGTATACACACAATATAGGCATTGCATACGCGTATACACACAATATAGGC; ATTGCATACGCGTATACACACAAAATAGGCATTGCATACGCGTATACACACAAAATAGGCATTGTATACGCGTATACACACAAAATAGGCATTGTATACGCGTATACACACAAAATAGGCATTGTATACGCGTATACAATATATGCATTGTATACGCGTATACAATATATGC; at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.readthreading.ReadThreadingAssembler.findBestPaths(ReadThreadingAssembler.java:354); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.readthreading.ReadThreadingAssembler.assembleKmerGraphsAndHaplotypeCall(ReadThreadingAssembler.java:196); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.readthreading.ReadThreadingAssembler.runLocalAssembly(ReadThreadingAssembler.java:146); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.AssemblyBasedCallerUtils.assembleReads(AssemblyBasedCallerUtils.java:269); at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2Engine.callRegion(Mutect2Engine.java:226); at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2.apply(Mutect2.java:299); at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.processR",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6529:71,failure,failure,71,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6529,3,"['error', 'failure']","['error', 'failure']"
Availability,"Hi,. I have the allele counts from ASEReadCounter and I would like to do some statistical test on the output. You suggest MAMBA in your manual but in their manual they say the input file should have the required field: `EXON_INFO - variant annotation label`. . Can you recommend any other downstream tools to analyze ASEReadCounter output?. Thanks,; Komal",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3267:289,down,downstream,289,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3267,1,['down'],['downstream']
Availability,"Hi,. I made an alignment with my pair-end reads with this command line i have found on the internet:. ```; #!/bin/bash. header=$(zcat $1 | head -n 1); id=$(echo $header | head -n 1 | cut -f 1-4 -d"":"" | sed 's/@//' | sed 's/:/_/g'); sm=$(echo $header | head -n 1 | grep -Eo ""[ATGCN]+$""); echo ""Read Group @RG\tID:$id\tSM:$id""_""$sm\tLB:$id""_""$sm\tPL:ILLUMINA"". bwa mem \; -M \; -t 8 \; -v 3 \; -R $(echo ""@RG\tID:$id\tSM:$id""_""$sm\tLB:$id""_""$sm\tPL:ILLUMINA"") \; ""$path_genome_dir"" \; $1 $2 | samblaster -M | samtools fixmate - - | samtools sort -O bam -o ""mapped-bwa.bam""; ```; Then, I created "".fai"" and "".dict"" extension of my genome by using,. `java -jar picard.jar CreateSequenceDictionary R= genome.fa O= genome.fa.dict`. `samtools faidx genome.fa`. Then I used this command to use HaplotypeCaller feature of gatk (4.1.3.0): `""./gatk --java-options ""-Xmx8G"" HaplotypeCaller -R genome.fa -I mapped-bwa.bam -O mapped-bwa.vcf""`. Then, this gave me an error: `java.lang.IllegalArgumentException: VCFHeaderLine: ID cannot contain an equals sign; 	at htsjdk.variant.vcf.VCFSimpleHeaderLine.initialize(VCFSimpleHeaderLine.java:108); 	at htsjdk.variant.vcf.VCFSimpleHeaderLine.<init>(VCFSimpleHeaderLine.java:91); 	at htsjdk.variant.vcf.VCFContigHeaderLine.<init>(VCFContigHeaderLine.java:66); 	at htsjdk.variant.vcf.VCFHeader.setSequenceDictionary(VCFHeader.java:294); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerEngine.makeVCFHeader(HaplotypeCallerEngine.java:423); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerEngine.writeHeader(HaplotypeCallerEngine.java:435); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCaller.onTraversalStart(HaplotypeCaller.java:229); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1046); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceM",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6127:156,echo,echo,156,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6127,5,"['echo', 'error']","['echo', 'error']"
Availability,"Hi,. I ran into this issue when running VariantRecalibrator in GATK4. I used the same command as recommended in the GATK3 best practice, but seems the command can't recognize the track information of the resources:. **java -jar ~/Softwares/gatk/build/libs/gatk-package-4.alpha.2-49-g491f7f2-SNAPSHOT-local.jar VariantRecalibrator \; -R ~/Resources/genome_b38/genome.fa \; -V ${op}/DUKE_6954540_200400624.vcf.gz \; -resource hapmap,known=false,training=true,truth=true,prior=15.0 ~/Resources/genome_b38/hapmap_3.3.b38.vcf.gz \; -resource omni,known=false,training=true,truth=true,prior=12.0 \; ~/Resources/genome_b38/1000G_omni2.5.b38.vcf.gz \; -resource 1000G,known=false,training=true,truth=false,prior=10.0 \; ~/Resources/genome_b38/tmp/1000G_phase3.snps.high_confidence.b38.rh.vcf.gz \; -resource dbsnp,known=true,training=false,truth=false,prior=2.0 \; ~/Resources/genome_b38/dbsnp_142.b38.vcf.gz \; -an DP \; -an QD \; -an FS \; -an MQRankSum \; -an ReadPosRankSum \; -mode SNP \; -tranche 100.0 -tranche 99.9 -tranche 99.0 -tranche 90.0 \; -O DUKE_6954540_200400624.snp.output.recal \; -tranchesFile DUKE_6954540_200400624.snp.output.tranches** . The error I got is:. **""A USER ERROR has occurred: Invalid command line: Invalid argument '~/Resources/genome_b38/hapmap_3.3.b38.vcf.gz'"".** . It seems the command treat **hapmap,known=false,training=true,truth=true,prior=15.0** and **~/Resources/genome_b38/hapmap_3.3.b38.vcf.gz** as different arguments. And if I only provided ""**~/Resources/genome_b38/hapmap_3.3.b38.vcf.gz**"" to '**-resource**', the job shut down immediately. Is this a bug? Thanks.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2199:1157,error,error,1157,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2199,3,"['ERROR', 'down', 'error']","['ERROR', 'down', 'error']"
Availability,"Hi,. I tried to build a gCNV model and got the error `python exited with 139` but can#t figure out what is the cause of this error. Can you please help me with that error message? I attended the whole command and output here. ```; (gatk4.2.0.0) k-hg-srv3:/media/Data/AnnotationDBs/CNV/Genom/hdf5 # gatk GermlineCNVCaller --run-mode COHORT -L ../Genom.filtered.interval_list -I 0028-21.hdf5 -I 0045-21.hdf5 -I 0098-18.hdf5 -I 0156-21.hdf5 -I 0429-20.hdf5 -I 0779-18.hdf5 -I 1030-20.hdf5 -I 1098-13.hdf5 -I 1450-20.hdf5 -I 1495-17.hdf5 -I 1575-20.hdf5 -I 1586-18.hdf5 -I 1658-14.hdf5 -I 1974-20.hdf5 -I 2008-20.hdf5 -I 0030-21.hdf5 -I 0058-21.hdf5 -I 0129-20.hdf5 -I 0249-04.hdf5 -I 0614-20.hdf5 -I 0834-19.hdf5 -I 1080-20.hdf5 -I 1331-18.hdf5 -I 1460-18.hdf5 -I 1498-18.hdf5 -I 1576-20.hdf5 -I 1592-20.hdf5 -I 1716-15.hdf5 -I 1985-20.hdf5 -I 2167-20.hdf5 -I 0038-21.hdf5 -I 0094-21.hdf5 -I 0139-18.hdf5 -I 0345-20.hdf5 -I 0641-18.hdf5 -I 0949-20.hdf5 -I 1081-20.hdf5 -I 1416-20.hdf5 -I 1491-20.hdf5 -I 1553-18.hdf5 -I 1577-20.hdf5 -I 1600-20.hdf5 -I 1720-20.hdf5 -I 1995-20.hdf5 --contig-ploidy-calls ../ploidy-calls/ --annotated-intervals ../Genom.annotated.tsv --interval-merging-rule OVERLAPPING_ONLY --output /media/Data/AnnotationDBs/CNV/Genom --output-prefix CNV --tmp-dir /media/Data/tmp/; Using GATK jar /usr/BioinfSoftware/GATK/4.2.0.0/gatk-package-4.2.0.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /usr/BioinfSoftware/GATK/4.2.0.0/gatk-package-4.2.0.0-local.jar GermlineCNVCaller --run-mode COHORT -L ../Genom.filtered.interval_list -I 0028-21.hdf5 -I 0045-21.hdf5 -I 0098-18.hdf5 -I 0156-21.hdf5 -I 0429-20.hdf5 -I 0779-18.hdf5 -I 1030-20.hdf5 -I 1098-13.hdf5 -I 1450-20.hdf5 -I 1495-17.hdf5 -I 1575-20.hdf5 -I 1586-18.hdf5 -I 1658-14.hdf5 -I 1974-20.hdf5 -I 2008-20.hdf5 -I 0030-21.hdf5 -I 0058-21.hdf5 -I 0129-20.hdf5 -I 0249-04.hdf5 -I 0614-20.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7234:47,error,error,47,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7234,3,['error'],['error']
Availability,"Hi,. I tried to use your new released GATK4 package to do CNV analysis. I know it's a beta tool... I followed the tools documentation and did ""CollectFragmentCounts"" first to get hdf5 files. After that I tried to run ""DetermineGermlineContigPloidy"" in cohort mode with these files. I created a ploidy_priors.tsv file like described in the documentation and used 8 hdf5-files. A few seconds after starting the tool I get the following error:. ```; [11. Januar 2018 16:42:24 MEZ]; org.broadinstitute.hellbender.tools.copynumber.DetermineGermlineContigPloidy done. Elapsed time: 0.05 minutes.; Runtime.totalMemory()=2294808576; org.broadinstitute.hellbender.utils.python.PythonScriptExecutorException:; python exited with 1; Command Line: python /tmp/die9s/cohort_determine_ploidy_and_depth.9149389425697869853.py --sample_coverage_metadata=/tmp/die9s/samples-by-coverage-per-contig814612566493224652.tsv --output_calls_path=/media/Berechnungen/CNV_analysis/GATK4/normal_cohort-calls --mapping_error_rate=1.000000e-02 --psi_s_scale=1.000000e-04 --mean_bias_sd=1.000000e-02 --psi_j_scale=1.000000e-03 --learning_rate=5.000000e-02 --adamax_beta1=9.000000e-01 --adamax_beta2=9.990000e-01 --log_emission_samples_per_round=2000 --log_emission_sampling_rounds=100 --log_emission_sampling_median_rel_error=5.000000e-04 --max_advi_iter_first_epoch=1000 --max_advi_iter_subsequent_epochs=1000 --min_training_epochs=20 --max_training_epochs=100 --initial_temperature=2.000000e+00 --num_thermal_epochs=20 --convergence_snr_averaging_window=5000 --convergence_snr_trigger_threshold=1.000000e-01 --convergence_snr_countdown_window=10 --max_calling_iters=1 --caller_update_convergence_threshold=1.000000e-03 --caller_admixing_rate=7.500000e-01 --disable_caller=false --disable_sampler=false --disable_annealing=false --interval_list=/tmp/die9s/intervals671187352630642175.tsv --contig_ploidy_prior_table=/media/Berechnungen/CNV_analysis/GATK4/ploidy_priors.tsv --output_model_path=/media/Berechnungen/CNV_analysis/GATK",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4125:434,error,error,434,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4125,1,['error'],['error']
Availability,"Hi,. I'm trying to run BaseRecalibratorSpark (gatk-4.1.7.0) but I'm hitting a problem where the process carshe with a ""too many open files"" error. Here is my command:. ulimit -n 4096; /usr/local/bioinf/gatk/gatk-4.1.7.0/gatk BaseRecalibratorSpark \; --java-options '-Xmx64G' \; --tmp-dir /local/scratch/rieder \; -I Normal_fixed.bam \; -R GRCh38.d1.vd1.fa \; -L S07604514_Regions_merged_padded.interval_list \; -O P45507_normal_bqsr.table \; --known-sites Homo_sapiens_assembly38.dbsnp138.vcf \; --known-sites Homo_sapiens_assembly38.known_indels.vcf \; --known-sites Mills_and_1000G_gold_standard.indels.hg38.vcf \; --spark-master local[8] \; --conf 'spark.executor.cores=8' \; --conf 'spark.local.dir=/local/scratch/rieder'. Here is the (hopefully) relevant log extract:. 20/04/29 01:51:51 INFO TaskSetManager: Finished task 578.0 in stage 0.0 (TID 578) in 2720 ms on localhost (executor driver) (576/1585); 20/04/29 01:51:51 INFO NewHadoopRDD: Input split: file:/data/projects/2019/NeoAG/VCF-phasing/work/b8/d8dc550b7ba5f57d935d04e27b756a/Normal_fixed.bam:19562233856+33554432; 01:51:51.374 INFO FeatureManager - Using codec VCFCodec to read file file:///local/scratch/rieder/spark-bb59423b-0368-4de5-85e0-e6641fb25380/userFiles-a91d5958-33f5-4685-bf9d-c8fc0924f7c6/Homo_sapiens_assembly38.dbsnp138.vcf; 01:51:51.431 INFO FeatureManager - Using codec VCFCodec to read file file:///local/scratch/rieder/spark-bb59423b-0368-4de5-85e0-e6641fb25380/userFiles-a91d5958-33f5-4685-bf9d-c8fc0924f7c6/Homo_sapiens_assembly38.known_indels.vcf; 01:51:51.451 INFO FeatureManager - Using codec VCFCodec to read file file:///local/scratch/rieder/spark-bb59423b-0368-4de5-85e0-e6641fb25380/userFiles-a91d5958-33f5-4685-bf9d-c8fc0924f7c6/Mills_and_1000G_gold_standard.indels.hg38.vcf; 01:51:51.457 INFO FeatureManager - Using codec VCFCodec to read file file:///local/scratch/rieder/spark-bb59423b-0368-4de5-85e0-e6641fb25380/userFiles-a91d5958-33f5-4685-bf9d-c8fc0924f7c6/Homo_sapiens_assembly38.dbsnp138.vcf; 01:",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6578:140,error,error,140,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6578,1,['error'],['error']
Availability,"Hi,. Using GATK mutect2's wdl file on Terra (version 21 on agora) I keep getting the same error:; ""pet-102022583875839491351@broad-firecloud-ccle.iam.gserviceaccount.com does not have storage.buckets.get access to the Google Cloud Storage bucket"" . Here is part of the stacktrace : ; ```; 20:59:48.744 INFO Mutect2 - Inflater: IntelInflater; 20:59:48.744 INFO Mutect2 - GCS max retries/reopens: 20; 20:59:48.744 INFO Mutect2 - Requester pays: enabled. Billed to: broad-firecloud-ccle; 20:59:48.744 INFO Mutect2 - Initializing engine; 20:59:54.630 INFO FeatureManager - Using codec VCFCodec to read file gs://depmapomicsdata/1000g_pon.hg38.vcf.gz; 20:59:55.629 INFO Mutect2 - Shutting down engine; [October 4, 2021 8:59:55 PM GMT] org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2 done. Elapsed time: 0.12 minutes.; Runtime.totalMemory()=876609536; code: 403; message: pet-102022583875839491351@broad-firecloud-ccle.iam.gserviceaccount.com does not have storage.buckets.get access to the Google Cloud Storage bucket.; reason: forbidden; location: null; retryable: false; com.google.cloud.storage.StorageException: pet-102022583875839491351@broad-firecloud-ccle.iam.gserviceaccount.com does not have storage.buckets.get access to the Google Cloud Storage bucket.; at com.google.cloud.storage.spi.v1.HttpStorageRpc.translate(HttpStorageRpc.java:229); at com.google.cloud.storage.spi.v1.HttpStorageRpc.get(HttpStorageRpc.java:406); at com.google.cloud.storage.StorageImpl$4.call(StorageImpl.java:217); ...; ```. This happens while it runs the command:. ```; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx15500m\ ; -jar /root/gatk.jar Mutect2 -R gs://genomics-public-data/resources/broad/hg38/v0/Homo_sapiens_assembly38.fasta\ ; -I gs://cclebams/hg38_wes/CDS-00rz9N.hg38.bam -tumor BC1_HAEMATOPOIETIC_AND_LYMPHOID_TISSUE --germline-resource gs://gcp-public-data--gnomad/release/3",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7492:90,error,error,90,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7492,2,"['down', 'error']","['down', 'error']"
Availability,"Hi,. When I try to run Funcotator, using the below command:. gatk Funcotator \; --variant /rsrch5/home/tdccct/ppshah/shared/CAS_MOSAIC/mutect/mrn_2507919/WES/KShaw-ROPR0004-DNA-229761-WX01-T_HMCKJDSX2-4-ATTGGCTC/KShaw-ROPR0004-DNA-229761-WX01-T_HMCKJDSX2-4-ATTGGCTC_filtered.vcf.gz \; --reference /rsrch5/home/tdccct/ppshah/shared/gencode/Homo_sapiens/GATK/GRCh38/Sequence/WholeGenomeFasta/Homo_sapiens_assembly38.fasta \; --ref-version hg38 \; --data-sources-path /rsrch5/home/tdccct/ppshah/shared/pipelines/mutect/funcotator_dataSources.v1.7.20200521s \; --output /rsrch5/home/tdccct/ppshah/shared/CAS_MOSAIC/mutect/mrn_2507919/WES/KShaw-ROPR0004-DNA-229761-WX01-T_HMCKJDSX2-4-ATTGGCTC/KShaw-ROPR0004-DNA-229761-WX01-T_HMCKJDSX2-4-ATTGGCTC_funcotated.vcf \; --output-file-format VCF; ; I get the following error:; ; Using GATK jar /gatk/gatk-package-4.4.0.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /gatk/gatk-package-4.4.0.0-local.jar Funcotator --variant /home/ppshah/shared/CAS_MOSAIC/mutect/mrn_2507919/WES/KShaw-ROPR0004-DNA-229761-WX01-T_HMCKJDSX2-4-ATTGGCTC/KShaw-ROPR0004-DNA-229761-WX01-T_HMCKJDSX2-4-ATTGGCTC_filtered.vcf.gz --reference /home/ppshah/shared/gencode/Homo_sapiens/GATK/GRCh38/Sequence/WholeGenomeFasta/Homo_sapiens_assembly38.fasta --ref-version hg38 --data-sources-path /home/ppshah/shared/pipelines/mutect/funcotator_dataSources.v1.7.20200521s --output /home/ppshah/shared/CAS_MOSAIC/mutect/mrn_2507919/WES/KShaw-ROPR0004-DNA-229761-WX01-T_HMCKJDSX2-4-ATTGGCTC/KShaw-ROPR0004-DNA-229761-WX01-T_HMCKJDSX2-4-ATTGGCTC_funcotated.vcf --output-file-format VCF; 16:36:22.352 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/gatk/gatk-package-4.4.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; 16:36:22.392 INFO Funcotator - ------------------------------------------------------------; 16:36:22.396 ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8647:808,error,error,808,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8647,1,['error'],['error']
Availability,"Hi,; I am trying to build from gatk-4 master sources. I received this error code `2` admitedly when I had no git-lfs installed. Now it is installed and in my PATH, but the error still occurs. Can't you capture the real error message?. ```; 22:05:55.883 [QUIET] [system.out] Executing: git lfs pull --include src/main/resources/large; 22:05:55.943 [DEBUG] [org.gradle.configuration.project.BuildScriptProcessor] Timing: Running the build script took 12.879 secs; 22:05:55.952 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] ; 22:05:55.954 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] FAILURE: Build failed with an exception.; 22:05:55.955 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] ; 22:05:55.956 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] * Where:; 22:05:55.956 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] Build file '/scratch/var/tmp/portage/sci-biology/gatk-9999/work/gatk-9999/build.gradle' line: 102; 22:05:55.964 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] ; 22:05:55.964 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] * What went wrong:; 22:05:55.966 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] A problem occurred evaluating root project 'gatk'.; 22:05:55.966 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] > Execution of ""git lfs pull --include src/main/resources/large"" failed with exit code: 2. git-lfs is required to build GATK but may not be installed. See https://github.com/broadinstitute/gatk#building for information on how to build GATK.; 22:05:55.967 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] ; 22:05:55.968 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] * Exception is:; 22:05:55.969 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] org.gradle.api.GradleScriptException: A problem occurred evaluating root project 'gatk'.; 22:05:55.969 [ERROR] [o",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4687:70,error,error,70,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4687,9,"['ERROR', 'FAILURE', 'error']","['ERROR', 'FAILURE', 'error']"
Availability,"Hi,; I am working on GATK VariantsToTable tool and my VCF file consists of 12 chromosomes but the output shows only one chromosome. Could you please help me out.; OS:-Ubuntu 20.04; GATK version:-4.1.9.0; Java:-open jdk version 11.0.8; Command:-gatk VariantsToTable -R '/home/india/Downloads/Reference.fasta' -V '/home/india/Downloads/Galaxy57-[Merged_file.vcf].vcf' -F CHROM -F POS -F REF -F ALT -GF AD -GF DP -GF GQ -GF PL -O bothbulks_new.table. Using GATK jar /home/india/Downloads/gatk-4.1.9.0/gatk-package-4.1.9.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /home/india/Downloads/gatk-4.1.9.0/gatk-package-4.1.9.0-local.jar VariantsToTable -R /home/india/Downloads/Reference.fasta -V /home/india/Downloads/Galaxy57-[Merged_file.vcf].vcf -F CHROM -F POS -F REF -F ALT -GF AD -GF DP -GF GQ -GF PL -O bothbulks_new.table; 16:46:03.294 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/india/Downloads/gatk-4.1.9.0/gatk-package-4.1.9.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Oct 16, 2020 4:46:04 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 16:46:04.315 INFO VariantsToTable - ------------------------------------------------------------; 16:46:04.316 INFO VariantsToTable - The Genome Analysis Toolkit (GATK) v4.1.9.0; 16:46:04.316 INFO VariantsToTable - For support and documentation go to https://software.broadinstitute.org/gatk/; 16:46:04.317 INFO VariantsToTable - Executing as india@india-HP-ProBook-445-G1 on Linux v5.4.0-26-generic amd64; 16:46:04.317 INFO VariantsToTable - Java runtime: OpenJDK 64-Bit Server VM v11.0.8+10-post-Ubuntu-0ubuntu120.04; 16:46:04.317 INFO VariantsToTable - Start Date/Time: 16 October 2020 at 4:46:02 PM IST; 16:46:04.318 INFO VariantsToTable - ----------",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6897:281,Down,Downloads,281,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6897,6,['Down'],['Downloads']
Availability,"Hi,; I need to include the SnpCluster filter in VariantFiltration but the filtration is not working for me. I have included the other filters but I'm not sure about the usage of this particular filter. The command that I have used:; --genotype-filter-name ""SnpCluster"" \; --genotype-filter-expression ""clusterSize=3"" \. The error that I'm facing:; 12:52:33.595 WARN JexlEngine - ![0,15]: 'clusterSize = 3;' context is readonly. ![image](https://github.com/broadinstitute/gatk/assets/125788800/9cd32db5-0010-489f-be8c-091b53e02c99)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8500:324,error,error,324,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8500,1,['error'],['error']
Availability,"Hi,; I ran into the following error when combining gVCF files generated by the HaplotypeCaller:. > htsjdk.tribble.TribbleException$InvalidHeader: Your input file has a malformed header: Discordant field size detected for field AS_RAW_ReadPosRankSum at chr1:13417. Field had 2 values but the header says this should have 1 values based on header record INFO=<ID=AS_RAW_ReadPosRankSum,Number=1,Type=String,Description=""allele specific raw data for rank sum test of read position bias"". Similar number info was found for several allele-specific annotations:; ```; ##INFO=<ID=AS_InbreedingCoeff,Number=A,Type=Float,Description=""allele specific heterozygosity as estimated from the genotype likelihoods per-sample when compared against the Hardy-Weinberg expectation; relate to inbreeding coefficient"">; ##INFO=<ID=AS_QD,Number=A,Type=Float,Description=""Allele-specific Variant Confidence/Quality by Depth"">; ##INFO=<ID=AS_RAW_BaseQRankSum,Number=1,Type=String,Description=""raw data for allele specific rank sum test of base qualities"">; ##INFO=<ID=AS_RAW_MQ,Number=1,Type=String,Description=""Allele-specfic raw data for RMS Mapping Quality"">; ##INFO=<ID=AS_RAW_MQRankSum,Number=1,Type=String,Description=""Allele-specfic raw data for Mapping Quality Rank Sum"">; ##INFO=<ID=AS_RAW_ReadPosRankSum,Number=1,Type=String,Description=""allele specific raw data for rank sum test of read position bias"">; ##INFO=<ID=AS_SB_TABLE,Number=1,Type=String,Description=""Allele-specific forward/reverse read counts for strand bias tests"">; ```; I assume, the correct annotation should be ""Number=A"". The gVCF files were generated with HaplotypeCaller using; ```; --emit-ref-confidence GVCF \; --annotation-group StandardAnnotation \; --annotation-group AS_StandardAnnotation \; --annotation-group StandardHCAnnotation \; ```. GATK version 4.0.0.0 (downloaded from GATK website)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4162:30,error,error,30,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4162,2,"['down', 'error']","['downloaded', 'error']"
Availability,"Hi,; I recently started getting error messages when running a Nextflow pipeline for WGS analysis. I am using GATK 4.0.1.2 and was wondering whether:. /bin/env python - too many levels of symbolic links. may have to do with a broken conda environment (which GATK seems to use)? This happens for tools such as GenomicsDBImport. If I run the job in question outside of Nextflow, it seems to start just fine. But as far as I know Nextflow does not use python, so doesn't look like the obvious culprit.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4459:32,error,error,32,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4459,1,['error'],['error']
Availability,"Hi,; I recently used GATK4 Spark local version for somatic variant call. The machine has 40 cores and 160g mem. I tried 20 and 10 cores for each tumor/normal pair in the BQSR step (BaseRecalibratorSpark) and the two samples are processed at the same time. However, the pipeline frequently failes (errors like outofmemory, cannot allocate a page) unless I use 4 cores for each sample. I think the problem should be solved by tuning Spark and JAVA parameters. I considered options like `--conf spark.driver.memory=10g`, `-XX:ParallelGCThreads=10` but had no luck. Can someone suggest the parameter options that I should look at? . Thanks,. -Han",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3465:297,error,errors,297,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3465,1,['error'],['errors']
Availability,"Hi,; I run the PathSeqPipelineSpark on a SPARK HPC with a master and several workers. I downloaded SPARK 2.2.0 with hadoop 2.7.3; Java is 1.8.0_131; I set the java classpath (I think correctly). The command runs well without the --spark-master option, so the files are at the right place, but when I run the following command line:; `gatk PathSeqPipelineSpark --spark-master spark://XX.XX.XX.XX:7077 --input test_sample.bam --filter-bwa-image hg19mini.fasta.img --kmer-file hg19mini.hss --min-clipped-read-length 70 --microbe-fasta e_coli_k12.fasta --microbe-bwa-image e_coli_k12.fasta.img --taxonomy-file e_coli_k12.db --output output.pathseq.bam --verbosity DEBUG --scores-output output.pathseq.txt -- --spark-runner SPARK`. I get the following error:; ```; 18/04/24 17:55:54 WARN TaskSetManager: Lost task 1.0 in stage 2.0 (TID 4, xx.xx.xx.16, executor 3): **org.broadinstitute.hellbender.exceptions.UserException$CouldNotReadInputFile: Couldn't read file. Error was: hg19mini.hss with exception: hg19mini.hss (No such file or directory); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:112)**; at org.broadinstitute.hellbender.tools.spark.pathseq.PSKmerUtils.readKmerFilter(PSKmerUtils.java:131); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilter.<init>(ContainsKmerReadFilter.java:27); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:35); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:15); at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78); at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:463); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:125); a",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4699:88,down,downloaded,88,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4699,3,"['Error', 'down', 'error']","['Error', 'downloaded', 'error']"
Availability,"Hi,; I run the code below to to skip optical duplicate detection during marking duplicate.; `java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=trueDsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /gatk-4.1.8.0/gatk-package-4.1.8.0-local.jar MarkDuplicatesSpark --spark-master local[28] --conf spark.local.dir=/datatmp/ -I ./A.sort.bam -O ./A.sort.bam.Mdup.bam -M ./A.sort.bam.Md.metrics.txt --tmp-dir /datatmp/ --conf spark.network.timeout=200h --conf spark.executor.heartbeatInterval=100h --read-name-regex null`; It reports the error below.; `20/12/15 11:43:00 ERROR Executor: Exception in task 15.0 in stage 7.0 (TID 12538); java.lang.NullPointerException; at org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSparkUtils.lambda$handleFragments$12(MarkDuplicatesSparkUtils.java:395); at java.util.stream.ReferencePipeline$11$1.accept(ReferencePipeline.java:372); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.reduce(ReferencePipeline.java:479); at java.util.stream.ReferencePipeline.max(ReferencePipeline.java:515); at org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSparkUtils.handleFragments(MarkDuplicatesSparkUtils.java:396); at org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSparkUtils.lambda$markDuplicateRecords$fa45b352$1(MarkDuplicatesSparkUtils.java:304); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143); at org.apache.spark.api.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7001:527,heartbeat,heartbeatInterval,527,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7001,3,"['ERROR', 'error', 'heartbeat']","['ERROR', 'error', 'heartbeatInterval']"
Availability,"Hi,; I tried to use Funcotator to annotate a vcf file. The vcf file had just 10 records. The program kept running without errors but no results got. . **The command I used:**. /technology/software_tools/gatk-4.2.0.0/gatk Funcotator \; --variant P01.mutect2.somatic.filterMutectCalls.indels.vcf.gz \; --reference /technology/dependent_resource/genome/hsa/ensembl/GRCh37.p13_GATK/genome.fa \; --ref-version hg19 \; --data-sources-path /technology/dependent_resource/variation/hg19/funcotator_dataSources.v1.7.20200521s \; --output P01.mutect2.somatic.filterMutectCalls.indels.funcotator.vcf \; --output-file-format VCF. **Screen output:**. Using GATK jar /technology/software_tools/gatk-4.2.0.0/gatk-package-4.2.0.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /technology/software_tools/gatk-4.2.0.0/gatk-package-4.2.0.0-local.jar Funcotator --variant P01.mutect2.somatic.filterMutectCalls.indels.vcf.gz --reference /technology/dependent_resource/genome/hsa/ensembl/GRCh37.p13_GATK/genome.fa --ref-version hg19 --data-sources-path /technology/dependent_resource/variation/hg19/funcotator_dataSources.v1.7.20200521s --output P01.mutect2.somatic.filterMutectCalls.indels.funcotator.vcf --output-file-format VCF; 10:25:49.484 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/technology/software_tools/gatk-4.2.0.0/gatk-package-4.2.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Mar 09, 2021 10:25:49 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 10:25:49.665 INFO Funcotator - ------------------------------------------------------------; 10:25:49.665 INFO Funcotator - The Genome Analysis Toolkit (GATK) v4.2.0.0; 10:25:49.665 INFO Funcotator - For support and documentation go to https://software.broadinstit",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7135:122,error,errors,122,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7135,1,['error'],['errors']
Availability,"Hi,; I use the gatk4.0.2.1 to detect variant and the command line:; time gatk-4.0.2.1/gatk --java-options ""-XX:ParallelGCThreads=5 -Xmx30G"" HaplotypeCaller --input rice.RGAP7.R01.dedup.bam --output rice.RGAP7.1.0.g.vcf --reference ref.genome.fa --native-pair-hmm-threads --emit-ref-confidence GVCF --indel-size-to-eliminate-in-ref-model 50 --sample-ploidy 2 --intervals rice.RGAP7.chr_allocation.1.list --TMP_DIR tmp --verbosity ERROR. **real	32m47.986s**; user	32m56.767s; sys	0m22.567s. I ues the gatk3.8 to detect variant and the command line:; time java -XX:ParallelGCThreads=5 -Djava.io.tmpdir=tmp -Xmx30G GenomeAnalysisTK/3.8/GenomeAnalysisTK.jar -T HaplotypeCaller -R ref.genome.fa --indelSizeToEliminateInRefModel 50 --emitRefConfidence GVCF --sample_ploidy 2 -nct 4 -o rice.RGAP7.1.0.g.vcf -L rice.RGAP7.chr_allocation.1.list -I rice.RGAP7.R01.dedup.realn.bam . **real	8m49.673s**; user	35m42.770s; sys	0m21.607s. Theoretically，the gatk4 runtime is faster than gatk3.x .; Why do I get the opposite result?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5090:429,ERROR,ERROR,429,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5090,1,['ERROR'],['ERROR']
Availability,"Hi,; I use your software with docker swarm where is deploy spark and hadoop the configuration for docker image is this:; ```; FROM bde2020/spark-master:2.2.0-hadoop2.8-hive-java8. MAINTAINER Jhonattan Loza <toro.ryan.jcl@gmail.com>. COPY picard.jar /; COPY GenomeAnalysisTK_v3.8-0-ge9d806836.jar /. RUN curl -s https://packagecloud.io/install/repositories/github/git-lfs/script.deb.sh | bash; RUN apt-get install -y git-lfs; RUN git lfs install; RUN apt-get install unzip; RUN apt-get install wget; RUN apt-get install git. RUN mkdir /gatk; RUN apt-get update && apt-get install -y python git mlocate htop && export JAVA_TOOL_OPTIONS=-Dfile.encoding=UTF8 && \; wget https://github.com/broadinstitute/gatk/releases/download/4.0.4.0/gatk-4.0.4.0.zip && unzip gatk-4.0.4.0.zip -d tmp && mv tmp/gatk-4.0.4.0/* /gatk && cp /spark/conf/spark-defaults.conf.template /spark/conf/spark-defaults.conf && \; echo ""spark.eventLog.enabled true"" >> /spark/conf/spark-defaults.conf && \; echo ""spark.eventLog.dir file:///spark/logs/"" >> /spark/conf/spark-defaults.conf. ENV PATH=""$PATH:/spark/bin""; ```; I have this configurations for docker-compose:; - Spark. ```; version: '3'; services:; spark-master:; image: atahualpa/spark-master:GATK4.0.4; networks:; - workbench; deploy:; replicas: 1; mode: replicated; restart_policy:; condition: on-failure; labels:; traefik.docker.network: workbench; traefik.port: 8080; env_file:; - ./hadoop.env; ports:; - 8333:8080; - 4040:4040; - 6066:6066; - 7077:7077; volumes:; - /data0/reference/hg19-ucsc/:/reference/hg19-ucsc/; - /data0/fastq/:/fastq/; - /data0/NGS-SparkGATK/NGS-SparkGATK/:/NGS-SparkGATK/; - /data/ngs/:/ngs/; - /data0/output/:/output/; spark-worker:; image: bde2020/spark-worker:2.2.0-hadoop2.8-hive-java8; networks:; - workbench; environment:; - SPARK_MASTER=spark://spark-master:7077; deploy:; mode: global; restart_policy:; condition: on-failure; labels:; traefik.docker.network: workbench; traefik.port: 8081. env_file:; - ./hadoop.env; volumes:; - referen",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4820:714,down,download,714,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4820,3,"['down', 'echo']","['download', 'echo']"
Availability,"Hi,; I'm running a command:; ```; java -jar gatk-4.0.3.0/gatk-package-4.0.3.0-local.jar SelectVariants \; -R ref/human_g1k_b37_20.fasta \; -V dupa.raw.indels.snps.vcf \; -selectType INDEL \; -O dupa_raw.INDEL.vcf. ```; and I get error:; ```; ***********************************************************************. A USER ERROR has occurred: s is not a recognized option. ***********************************************************************; ```; Tested on various input files. ```; java -version; openjdk version ""1.8.0_152""; OpenJDK Runtime Environment (Zulu 8.25.0.1-linux64) (build 1.8.0_152-b16); OpenJDK 64-Bit Server VM (Zulu 8.25.0.1-linux64) (build 25.152-b16, mixed mode); ```. Looks like it's a bug?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4705:229,error,error,229,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4705,2,"['ERROR', 'error']","['ERROR', 'error']"
Availability,"Hi,; I've got some error messages about ""tranches"" when I'm running VariantRecalibrator. Here is my command lines:; ```; gatk=/public/home/fan_lab/shali/gatk/gatk-4.1.8.1/gatk; reference=/public/home/fan_lab/shali/gatk/gatk_bundle/Homo_sapiens_assembly38.fasta; GATK_bundle=/public/home/fan_lab/shali/gatk/gatk_bundle. indir=/public/home/fan_lab/shali/NGS_new; outdir=/public/home/fan_lab/shali/NGS_new. gatk VariantRecalibrator \; -R $reference \; --variant $outdir/population/24samples.HC.vcf.gz \; --resource:hapmap,known=false,training=true,truth=true,prior=15.0 $GATK_bundle/hapmap_3.3.hg38.vcf.gz \; --resource:omni,known=false,training=true,truth=false,prior=12.0 $GATK_bundle/1000G_omni2.5.hg38.vcf.gz \; --resource:1000G,known=false,training=true,truth=false,prior=10.0 $GATK_bundle/1000G_phase1.snps.high_confidence.hg38.vcf.gz \; --resource:dbsnp,known=true,training=false,truth=false,prior=6.0 $GATK_bundle/dbsnp_146.hg38.vcf.gz \; -an DP -an QD -an FS -an SOR -an ReadPosRankSum -an MQRankSum \; --mode SNP \; --tranche 100.0 -tranche 99.9 -tranche 99.0 -tranche 95.0 -tranche 90.0 \; --rscript-file $outdir/population/24samples.HC.snps.plots.R \; --tranches-file $outdir/poplation/24samples.HC.snps.tranches \; -O $outdir/poplation/24samples.HC.snps.recal; ```; The mission ended quickly.When I look at the log file, I find the following error message:; ```; A USER ERROR has occurred: /public/home/fan_lab/shali/NGS_new/poplation/24samples.HC.snps.tranches; ```; Any suggestions for me? Look forward to your reply. Thanks ever so much.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7225:19,error,error,19,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7225,3,"['ERROR', 'error']","['ERROR', 'error']"
Availability,"Hi,; Our spark installation use a mapr filesystem ( hdfs compatible ).; GATK spark tools does not seems to recognize it.; When running the following command:; > /home/axverdier/Tools/GATK4/gatk-4.beta.6/gatk-launch CountReadsSpark --programName gatk4-testing --input maprfs://spark-ics/user/axverdier/data/710-PE-G1.bam --output maprfs://spark-ics/user/axverdier/testOutGATK_CountReadsSpark --sparkRunner SPARK --sparkMaster yarn --javaOptions -Dmapr.library.flatclass; I got the following error!. > Driver stacktrace:; > 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1436); > 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1424); > 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1423); > 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); > 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); > 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1423); > 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); > 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); > 	at scala.Option.foreach(Option.scala:257); > 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:802); > 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1651); > 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1606); > 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1595); > 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); > 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:628); > 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1918); > 	at org.apache.spark.SparkCo",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3936:490,error,error,490,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3936,1,['error'],['error']
Availability,"Hi,; This is a part of my script and I get the mistakes after I run it:; for sample in $samples ; do ; sample_gvcfs=${sample_gvcfs}"" --variant /data/users/zhanglei/species/Medicago/result/${sample}.HC.g.vcf.gz ""; done; time gatk CombineGVCFs \; -R /data/users/zhanglei/species/Medicago/Medicago.fa \; ${sample_gvcfs} \; -O $outdir/population/${outname}.HC.g.vcf.gz && echo ""** ${outname}.HC.g.vcf.gz done **"" &&. 18:08:13.704 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/software/gatk-4.0.3.0/gatk-package-4.0.3.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; 18:08:13.872 INFO CombineGVCFs - ------------------------------------------------------------; 18:08:13.873 INFO CombineGVCFs - The Genome Analysis Toolkit (GATK) v4.0.3.0; 18:08:13.873 INFO CombineGVCFs - For support and documentation go to https://software.broadinstitute.org/gatk/; 18:08:13.873 INFO CombineGVCFs - Executing as zhanglei@GenEngine on Linux v3.10.0-327.el7.x86_64 amd64; 18:08:13.873 INFO CombineGVCFs - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_201-b09; 18:08:13.874 INFO CombineGVCFs - Start Date/Time: May 18, 2019 6:08:13 PM CST; 18:08:13.874 INFO CombineGVCFs - ------------------------------------------------------------; 18:08:13.874 INFO CombineGVCFs - ------------------------------------------------------------; 18:08:13.874 INFO CombineGVCFs - HTSJDK Version: 2.14.3; 18:08:13.874 INFO CombineGVCFs - Picard Version: 2.17.2; 18:08:13.874 INFO CombineGVCFs - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 18:08:13.875 INFO CombineGVCFs - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 18:08:13.875 INFO CombineGVCFs - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 18:08:13.875 INFO CombineGVCFs - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 18:08:13.875 INFO CombineGVCFs - Deflater: IntelDeflater; 18:08:13.875 INFO CombineGVCFs - Inflater: IntelInflater; 18:08:13.875 INFO CombineGVCFs - GCS max retries/reopens: 20; 18:08:13.875 I",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5947:368,echo,echo,368,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5947,1,['echo'],['echo']
Availability,"Hi,; Where Can I download the GATK3 ,I want to use Realigner and IndelRealigner tools in GATK.However the GATK4 is not available.; Anyone who can tell me where to download the GATK3 version?; --; Thank you!--",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6373:17,down,download,17,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6373,3,"['avail', 'down']","['available', 'download']"
Availability,"Hi,; While I test a new data set from fastq using bwamem, samtools and gatk4, I use the following scripts:. % step1: bwa mem. > bwa mem -t 12 -Ma -R '@RG ID:HCC1954 LB:HCC1954 SM:HCC1954' human_g1k_v37.fasta HCC1954_1.fq HCC1954_2.fq > HCC1954.sam. % step2: sort by queryname. > samtools sort -n HCC1954.sam -@ 24 > HCC1954.readnamesort.bam . % step3: gatk4 ReadsPipelineSpark. > /gatk-launch \; > ReadsPipelineSpark \; > -I HCC1954.readnamesort.bam \; > -R /benchmark/human_g1k_v37.2bit \; > -O HCC1954.bam \; > --knownSites /benchmark/dbsnp_138.b37.excluding_sites_after_129.vcf \; > --shardedOutput false \; > --emit_original_quals \; > --duplicates_scoring_strategy SUM_OF_BASE_QUALITIES \; > --sparkRunner SPARK \; > --driver-memory 8G \; > --executor-memory 60g \; > --num-executors 1 \; > --executor-cores 4 \; > --sparkMaster local[4]. I encounter problem like this:. org.broadinstitute.hellbender.exceptions.UserException$MalformedRead: A USER ERROR has occurred: Read C097FACXX111207:2:2301:17281:179267 1:1139151-1139251 is malformed: The input .bam file contains reads with no platform information. First observed at read with name = C097FACXX111207:2:2301:17281:179267; at org.broadinstitute.hellbender.utils.recalibration.RecalUtils.parsePlatformForRead(RecalUtils.java:510); at org.broadinstitute.hellbender.utils.recalibration.BaseRecalibrationEngine.processRead(BaseRecalibrationEngine.java:122); at org.broadinstitute.hellbender.tools.spark.transforms.BaseRecalibratorSparkFn.lambda$apply$26a6df3e$1(BaseRecalibratorSparkFn.java:33); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:159); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:159); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$20.apply(RDD.scala:710); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$20.apply(RDD.scala:710); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apach",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1949:953,ERROR,ERROR,953,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1949,1,['ERROR'],['ERROR']
Availability,"Hi,; during compilation of 3.8 sources I get. ```; [INFO] --- exec-maven-plugin:1.2.1:exec (delete-mavens-links) @ gatk-aggregator ---; rm: missing operand; Try 'rm --help' for more information.; rm: missing operand; Try 'rm --help' for more information.; [INFO] ; [INFO] --- maven-failsafe-plugin:2.16:integration-test (integration-tests) @ gatk-aggregator ---; ```. I have no idea whether it breaks something downstream but provided building fails for me later with. ```; [INFO] Reactor Summary:; [INFO] ; [INFO] GATK Root .......................................... SUCCESS [ 16.744 s]; [INFO] GATK Aggregator .................................... SUCCESS [ 4.647 s]; [INFO] GATK GSALib ........................................ SUCCESS [ 6.040 s]; [INFO] GATK Utils ......................................... SUCCESS [ 39.733 s]; [INFO] GATK Engine ........................................ SUCCESS [ 7.557 s]; [INFO] GATK Tools Public .................................. SUCCESS [ 7.689 s]; [INFO] External Example ................................... FAILURE [ 0.051 s]; [INFO] GATK Queue ......................................... SKIPPED; [INFO] GATK Queue Extensions Generator .................... SKIPPED; [INFO] GATK Queue Extensions Public ....................... SKIPPED; [INFO] GATK Aggregator Public ............................. SKIPPED; [INFO] GATK Tools Protected ............................... SKIPPED; [INFO] GATK Package Distribution .......................... SKIPPED; [INFO] GATK Queue Extensions Distribution ................. SKIPPED; [INFO] GATK Queue Package Distribution .................... SKIPPED; [INFO] GATK Aggregator Protected .......................... SKIPPED; [INFO] GATK Tools Private ................................. SKIPPED; [INFO] GATK Package Internal .............................. SKIPPED; [INFO] NA12878 KB Utilities ............................... SKIPPED; [INFO] GATK Queue Private ................................. SKIPPED; [INFO] GATK Queue Extensions Inter",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4686:411,down,downstream,411,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4686,1,['down'],['downstream']
Availability,"Hi,; first of all, I find it very awkward that after 3.8 release there is 3.8-1. Why the dash instead of a dot, as usual? It only complicates automated package downloads which in general work with numbers separated by dots. You just mix together two schemes. Is that really necessary?. Anyway, the pom.xml is broken:. ```; >>> Preparing source in /scratch/var/tmp/portage/sci-biology/gatk-3.8.1/work/gatk-3.8-1 ...; Equivalent maven command; mvn -Dmaven.repo.local=/scratch/var/tmp/portage/sci-biology/gatk-3.8.1/work/.m2/repository verify '-Ddisable.shadepackage'; [INFO] Scanning for projects...; [ERROR] [ERROR] Some problems were encountered while processing the POMs:; [FATAL] Non-parseable POM /scratch/var/tmp/portage/sci-biology/gatk-3.8.1/work/gatk-3.8-1/public/gatk-root/pom.xml: unexpected character in markup < (position: END_TAG seen ...</artifactId>\n<<... @15:3) @ /scratch/var/tmp/portage/sci-biology/gatk-3.8.1/work/gatk-3.8-1/public/gatk-root/pom.xml, line 15, column 3; @ ; [ERROR] The build could not read 1 project -> [Help 1]; [ERROR] ; [ERROR] The project org.broadinstitute.gatk:gatk-aggregator:[unknown-version] (/scratch/var/tmp/portage/sci-biology/gatk-3.8.1/work/gatk-3.8-1/pom.xml) has 1 error; [ERROR] Non-parseable POM /scratch/var/tmp/portage/sci-biology/gatk-3.8.1/work/gatk-3.8-1/public/gatk-root/pom.xml: unexpected character in markup < (position: END_TAG seen ...</artifactId>\n<<... @15:3) @ /scratch/var/tmp/portage/sci-biology/gatk-3.8.1/work/gatk-3.8-1/public/gatk-root/pom.xml, line 15, column 3 -> [Help 2]; [ERROR] ; [ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.; [ERROR] Re-run Maven using the -X switch to enable full debug logging.; [ERROR] ; [ERROR] For more information about the errors and possible solutions, please read the following articles:; [ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/ProjectBuildingException; [ERROR] [Help 2] http://cwiki.apache.org/confluence/display/MAVEN/ModelPar",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4685:160,down,downloads,160,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4685,3,"['ERROR', 'down']","['ERROR', 'downloads']"
Availability,"Hi- I'm using `FilterMutectCalls` on a vcf produced by mutect2 (same gatk version). I get the following exception from `FilterMutectCalls`:. ```; INFO annotation 'MFRL' contains a non-int value '7.97254e+06'; ```. This is odd since the MFRL is a FORMAT tag, not INFO and anyway is of type float:. ```; zcat gatk/TT001T03.snv.vcf.gz | grep '##' | grep MFRL; ##FORMAT=<ID=MFRL,Number=R,Type=Float,Description=""median fragment length"">; ```. The faulty record:. ```; zcat gatk/TT001T03.snv.vcf.gz | grep '7.97254e+06'; chr6	32197424	.	G	A	.	.	DP=626;ECNT=1;NLOD=88.13;N_ART_LOD=1.78;POP_AF=0.001;P_GERMLINE=-86.27;TLOD=4.57;	GT:AD:AF:F1R2:F2R1:MBQ:MFRL:MMQ:MPOS:SA_MAP_AF:SA_POST_PROB	0/0:323,3:0.035:172,3:151,0:41:141,254:60:27:.:.	0/1:264,3:0.038:127,1:137,2:41:124,7.97254e+06:60:27:0.01,0,0.011:0.001247,0.011,0.987; ```. **EDIT**: It appears that the int 7972545 is converted to 7.97254e+06 after I passed the vcf file through a custom filter, so not really a fault of gatk (apologies). Still '7.97254e+06' should be a valid float. Full stack trace:. ```; gatk FilterMutectCalls --variant gatk/TT001T03.snv.vcf.gz --output test.vcf.gz. Using GATK jar /home/db291g/applications/gatk/gatk-4.0.1.0/gatk-package-4.0.1.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -jar /home/db291g/applications/gatk/gatk-4.0.1.0/gatk-package-4.0.1.0-local.jar FilterMutectCalls --variant gatk/TT001T03.snv.vcf.gz --output test.vcf.gz; 10:10:10.424 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/db291g/applications/gatk/gatk-4.0.1.0/gatk-package-4.0.1.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; 10:10:10.528 INFO FilterMutectCalls - ------------------------------------------------------------; 10:10:10.528 INFO FilterMutectCalls - The Genome Analysis Toolkit (GATK) v4.0.1.0; 10:10:10.528 INFO FilterMutectCalls - For support and docum",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4363:443,fault,faulty,443,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4363,2,['fault'],"['fault', 'faulty']"
Availability,"Hi. After creating a GenomicsDB with 36 gvcf withGenomicsDBimport, I used GEnotypeGVCF on the GenomicsDB folder but get the following error: ""ERROR: Couldn't create GenomicsDBFeatureReader"". See below for the complete output. FYI, I don't get this error when importing only six samples in GenomicsDB and then running GenotypeGVCF. . FYI, also added ""TILEDB_DISABLE_FILE_LOCKING=1"" to environment (export TILEDB_DISABLE_FILE_LOCKING=1) before executing GenomicsDBimport command but that dit not help either. Any suggestion would be highly appreciated. ##GenotypeVCF not working on 36 samples; (base) xxxxxx@galaxy:~$ gatk --java-options ""-Xmx30g"" GenomicsDBImport \; > -V output/B7_2.g.vcf.gz \; > -V output/B7_6.g.vcf.gz \; > -V output/B8_7.g.vcf.gz \; > -V output/B8_5.g.vcf.gz \; > -V output/B8_17.g.vcf.gz \; > -V output/B8_9.g.vcf.gz \; > -V output/B7_9.g.vcf.gz \; > -V output/B7_10.g.vcf.gz \; > -V output/B8_13.g.vcf.gz \; > -V output/B7_15.g.vcf.gz \; > -V output/B8_8.g.vcf.gz \; > -V output/B8_10.g.vcf.gz \; > -V output/B8_11.g.vcf.gz \; > -V output/F_A.g.vcf.gz \; > -V output/B7_3.g.vcf.gz \; > -V output/B8_19.g.vcf.gz \; > -V output/A8.g.vcf.gz \; > -V output/B7_4.g.vcf.gz \; > -V output/B8_4.g.vcf.gz \; > -V output/B8_4g.g.vcf.gz \; > -V output/B8_16.g.vcf.gz \; > -V output/A9_1.g.vcf.gz \; > -V output/X2.g.vcf.gz \; > -V output/X1.g.vcf.gz \; > -V output/7_5_2.g.vcf.gz \; > -V output/C3.g.vcf.gz \; > -V output/C1.g.vcf.gz \; > -V output/C2.g.vcf.gz \; > -V output/C3.g.vcf.gz \; > -V output/A9-10.g.vcf.gz \; > -V output/P3.g.vcf.gz \; > -V output/P4.g.vcf.gz \; > -V output/X4.g.vcf.gz \; > -V output/X5.g.vcf.gz \; > -V output/X6.g.vcf.gz \; > -V output/X7.g.vcf.gz \; > --genomicsdb-workspace-path ABchroneALL \; > --intervals pseudochromosome_1 \; > --intervals pseudochromosome_2 \; > --intervals pseudochromosome_3 \; > --batch-size 6; Using GATK jar /data/xxxxxx/miniconda3/share/gatk4-4.1.6.0-0/gatk-package-4.1.6.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_s",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6616:134,error,error,134,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6616,3,"['ERROR', 'error']","['ERROR', 'error']"
Availability,"Hi. I failed to build GATK4. . I am a very beginner of bioinformatics and data science. ; I am using google VM ubuntu. ; I downloaded gatk-4.4.0.0. Step by step, I tried to build GATK4. (https://github.com/broadinstitute/gatk/blob/master/README.md#building). I made a gitclone using ; wget https://github.com/broadinstitute/gatk. and entered gatk folder. ; there was a gradlew.; and I entered ; ./gradlew bundle ; or; ./gradlew. but it failed to build GATK4 with following errors. . ====================================; OpenJDK 64-Bit Server VM warning: Insufficient space for shared memory file:; 30934; Try using the -Djava.io.tmpdir= option to select an alternate temp location. FAILURE: Build failed with an exception. * What went wrong:; Gradle could not start your build.; > Cannot create service of type DependencyLockingHandler using method DefaultDependencyManagementServices$DependencyResolutionScopeServices.createDependencyLockingHandler() as there is a problem with parameter #2 of type ConfigurationContainerInternal.; > Cannot create service of type ConfigurationContainerInternal using method DefaultDependencyManagementServices$DependencyResolutionScopeServices.createConfigurationContainer() as there is a problem with parameter #13 of type DefaultConfigurationFactory.; > Cannot create service of type DefaultConfigurationFactory using DefaultConfigurationFactory constructor as there is a problem with parameter #2 of type ConfigurationResolver.; > Cannot create service of type ConfigurationResolver using method DefaultDependencyManagementServices$DependencyResolutionScopeServices.createDependencyResolver() as there is a problem with parameter #1 of type ArtifactDependencyResolver.; > Cannot create service of type ArtifactDependencyResolver using method DependencyManagementBuildScopeServices.createArtifactDependencyResolver() as there is a problem with parameter #4 of type List<ResolverProviderFactory>.; > Could not create service of type VersionControlRepositoryConnect",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8346:123,down,downloaded,123,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8346,3,"['FAILURE', 'down', 'error']","['FAILURE', 'downloaded', 'errors']"
Availability,"Hi. I had a question on Java version to use for GATK/PIcard. . https://gatk.broadinstitute.org/hc/en-us/articles/360035889531-What-are-the-requirements-for-running-GATK- ; states that `the Java runtime version should be at 1.8 exactly`. As you might be aware, Java 1.8 has reached its end of life - https://endoflife.date/java . Given this , I tried running MarkDuplicates and some other tools using Amazon Corretto 17 and they seem to work fine. More importantly, I did not encounter the `Unsupported major.minor version` error as mentioned here: https://gatk.broadinstitute.org/hc/en-us/articles/360035532332. Also happened to see this - https://github.com/broadinstitute/gatk/issues/7436. Question: Am I OK using Amazon Corretto for GATK/Picard or do I need to absolutely stick on to Java 1.8 for GATK/Picard. ```; java -version; openjdk version ""17.0.2"" 2022-01-18 LTS; OpenJDK Runtime Environment Corretto-17.0.2.8.1 (build 17.0.2+8-LTS); OpenJDK 64-Bit Server VM Corretto-17.0.2.8.1 (build 17.0.2+8-LTS, mixed mode, sharing); ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7842:523,error,error,523,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7842,1,['error'],['error']
Availability,"Hi. The VCF output file of HaplotypeCaller is not same when different interval split. It seems that smaller region will product more var into vcf file.; split1:chr unit; 5,089,533 var in vcf; split2: gatk4.SplitIntervals.sh(500 unit); 5,142,322 var in vcf. fastq files; HiSeqX-PCR-free-v2.5-NA12878 70x from BaseSpace. gatk version:4.0.3.0. By the way, there are some many diff site just in QD value. ; such as QD=28.13 vs QD=25.36, and other attr are same. Reason:; download sample without a fixed seed for every site?; or https://github.com/broadinstitute/gatk/issues/4614?; or others?. Best Regards",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4617:467,down,download,467,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4617,1,['down'],['download']
Availability,"Hi; I tried to run the recalibration using the gatk-generated vcf file as a known vcf file. I got an error which has been previously described ""The covariates table is missing ReadGroup V300019285_L2_ in RecalTable0"" but without the solution. ; I am wondering if the solution has been found. Anyone has the experience to fix this issue.; Thank ; **This is the batch file** ; java -Xmx16g -jar /scratch/ddo/gatk-4.1.9.0/gatk-package-4.1.9.0-local.jar ApplyBQSR \; -R /scratch/ddo/refgenomenew/New_IDs.fasta \; -I /scratch/ddo/markedsam/C18-436P.sort.rmdup.bam \; --bqsr-recal-file /scratch/ddo/reclibration/gatkmf01_C18-436P.recal_data.table \; -O /scratch/ddo/reclibration/C18-436P.bqsr.maf01.bam . **This is the log file**; -----------------------------------------------------------------------------------------------------; Picked up JAVA_TOOL_OPTIONS: -Xmx2g; 04:59:42.641 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/scratch/ddo/gatk-4.1.9.0/gatk-package-4.1.9.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Nov 08, 2021 4:59:43 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 04:59:43.044 INFO ApplyBQSR - ------------------------------------------------------------; 04:59:43.045 INFO ApplyBQSR - The Genome Analysis Toolkit (GATK) v4.1.9.0; 04:59:43.045 INFO ApplyBQSR - For support and documentation go to https://software.broadinstitute.org/gatk/; 04:59:43.045 INFO ApplyBQSR - Executing as on Linux v3.10.0-1160.36.2.el7.x86_64 amd64; 04:59:43.045 INFO ApplyBQSR - Java runtime: OpenJDK 64-Bit Server VM v13.0.2+8; 04:59:43.045 INFO ApplyBQSR - Start Date/Time: November 8, 2021 at 4:59:42 a.m. PST; 04:59:43.045 INFO ApplyBQSR - ------------------------------------------------------------; 04:59:43.045 INFO ApplyBQSR - ------------------------------------------------------------; 04:59:43.046 INFO ApplyBQSR - HTSJDK Version: 2.23.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7549:101,error,error,101,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7549,1,['error'],['error']
Availability,"Hi; I'm using HaplotypeCaller to do mutation calling in a large single-cell RNA-seq dataset. Im wondering if there is a way to get HaplotypeCaller to spit out _amino acid_ coordinates instead of _genome_? Can we maybe include a column such as 'Mutation.AA' that would contain entries like this? ; <img width=""151"" alt=""screen shot 2018-11-16 at 5 51 52 pm"" src=""https://user-images.githubusercontent.com/33501625/48655137-54309080-e9c8-11e8-9431-6e83b5afd9d7.png"">; It would be very useful for downstream applications like searching for clinically relevant SNPs/indels. ; Thanks; Lincoln",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5431:494,down,downstream,494,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5431,1,['down'],['downstream']
Availability,"Hiya,. I downloaded some VCF files for SNP detection in GATK. However when I tried to use them at the recalibration step it said I needed an index, when I try an run the index feature function it gives me the error: Input file is not in valid block compressed format. The files are .VCF.gz. Is there a way of reformatting please?. Best wishes,; B",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7500:9,down,downloaded,9,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7500,2,"['down', 'error']","['downloaded', 'error']"
Availability,How do we do this? What happens if a job runs locally but fails in the cloud? How do we log and understand errors?,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/276:107,error,errors,107,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/276,1,['error'],['errors']
Availability,I WAS running this commande : java -jar /Users/mac/Downloads/gatk-4.1.8.0/gatk-package-4.1.8.0-local.jar RealignerTargetCreator \ -R /Users/mac/Desktop/LmjFwholegenome_20070731_V5.2.fasta -I /Users/mac/Desktop/NGS/marked-duplicates42.bam -O SRR6369642_realtarget.list ; I get : ; A USER ERROR has occurred: RealignerTargetCreator is no longer included in GATK as of version 4.0.0.0. Please use GATK3 to run this tool. ***********************************************************************; Set the system property GATK_STACKTRACE_ON_USER_EXCEPTION (--java-options '-DGATK_STACKTRACE_ON_USER_EXCEPTION=true') to print the stack trace.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6703:51,Down,Downloads,51,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6703,2,"['Down', 'ERROR']","['Downloads', 'ERROR']"
Availability,"I _believe_ that the user error text didn't get updated when the `--sequence-dictionary` argument got added. It would be great to mention that argument in GATKTool::initializeIntervals(), which currently says `""We require a sequence dictionary from a reference, a source of reads, or a source of variants to process intervals. "" +; ""Since reference and reads files generally contain sequence dictionaries, this error most commonly occurs "" +; ""for VariantWalkers that do not require a reference or reads. You can fix the problem by passing a reference file with a sequence dictionary "" +; ""via the -R argument or you can run the tool UpdateVCFSequenceDictionary on your vcf.""`. I would change the last sentence to:; `You can fix the problem by passing a reference file with a sequence dictionary via the -R argument, a *.dict dictionary file via the --sequence-dictionary argument, or you can run the tool UpdateVCFSequenceDictionary on your vcf.""`",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4507:26,error,error,26,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4507,2,['error'],['error']
Availability,"I added -m to `gsutil cp` in a previous PR but missed the `gsutil mv` step post-`bq load` - so here that is. tested it from the command line, works well. also confirmed that it will throw an error if one (or more) files has an error:. ```; $ cat test_files_bucket.txt | gsutil -m mv -I gs://dsp-fieldeng-dev/test_mv/. If you experience problems with multiprocessing on MacOS, they might be related to https://bugs.python.org/issue33725. You can disable multiprocessing by editing your .boto config or by adding the following flag to your command: `-o ""GSUtil:parallel_process_count=1""`. Note that multithreading is still available even if you disable multiprocessing. Copying gs://dsp-fieldeng-dev/test_cp/test1.txt [Content-Type=text/plain]...; Copying gs://dsp-fieldeng-dev/test_cp/test2.txt [Content-Type=text/plain]...; CommandException: No URLs matched: gs://dsp-fieldeng-dev/test_cp/test4.txt; Copying gs://dsp-fieldeng-dev/test_cp/test3.txt [Content-Type=text/plain]...; Copying gs://dsp-fieldeng-dev/test_cp/test5.txt [Content-Type=text/plain]...; Copying gs://dsp-fieldeng-dev/test_cp/test6.txt [Content-Type=text/plain]...; Removing gs://dsp-fieldeng-dev/test_cp/test1.txt...; Removing gs://dsp-fieldeng-dev/test_cp/test2.txt...; Removing gs://dsp-fieldeng-dev/test_cp/test3.txt...; Removing gs://dsp-fieldeng-dev/test_cp/test5.txt...; Removing gs://dsp-fieldeng-dev/test_cp/test6.txt...; - [5/5 files][ 37.0 B/ 37.0 B] 100% Done; Operation completed over 5 objects/37.0 B.; CommandException: 1 file/object could not be transferred.; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7129:191,error,error,191,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7129,3,"['avail', 'error']","['available', 'error']"
Availability,"I added a test according to #4642 , but can't reproduce the error. The user also noted that the error message was badly formed, which is true because it ended with a colon. Now it looks like:; ""Input src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleBad.vcf fails strict validation of type CHR_COUNTS: the Allele Count (AC) tag is incorrect for the record at position 1:985447, 1 vs. 2""",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6076:60,error,error,60,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6076,2,['error'],['error']
Availability,"I also removed the obsolete errorProbability variable line of code in the SomaticGenotypingEngine.java and noted this argument is deprecated in the M2ArgumentCollection. Somewhat relatedly, see request in #3123.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3124:28,error,errorProbability,28,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3124,1,['error'],['errorProbability']
Availability,"I am attempting to create fasta files from specific regions in approximately 270 VCF files. For every other region/gene I've looked at, I have not had this issue. For one particular region (mrr1), I am getting the error seen below. I checked the coverage of the bam file and viewed the vcf in IGV viewer, but notice no problems. Can you please advise? Thank you. Similar to this issue, but am still not sure how to approach it?; https://github.com/broadinstitute/gatk/issues/6260#issue-521418442. Bash script:; ```; #!/bin/bash --login; #SBATCH --time=1:00:00 # limit of wall clock time - how long the job will run; #SBATCH --ntasks=1 # number of tasks - how many tasks (nodes) that you requir; #SBATCH --cpus-per-task=1 # number of CPUs (or cores) per task (same as -c); #SBATCH --mem=50G # memory required per node - amount of memory (in bytes); #SBATCH --job-name=VCF_FastaNEP_CCR; #SBATCH --mail-user=lukaskon@msu.edu; #SBATCH --mail-type=ALL; #SBATCH -o SpeciesID_CCR7_slurm. cd /mnt/research/Hausbeck_group/Lukasko/BotrytisDNASeq/. module load Java/JDK12. for sample in AI7 W18 B5 BU9 I9 R23 Y1; do; base=$(basename ${sample}). gatk-4.2.5.0/gatk SelectVariants -R /mnt/research/Hausbeck_group/Lukasko/BotrytisDNASeq/0_DNAscripts/ReferenceGenome/Botrytis_cinerea.ASM83294v1.dna.toplevel.fa -V /mn; t/research/Hausbeck_group/Lukasko/BotrytisDNASeq/10_FilteredVCF/Plates123/BcinereaP123.SNVonly.filteredPASS_renamed.vcf -sn ${sample} --remove-unused-alternates --exclu; de-sample-name /mnt/research/Hausbeck_group/Lukasko/BotrytisDNASeq/CCR7/ConservedGenes/ExcludeList.args -O /mnt/research/Hausbeck_group/Lukasko/BotrytisDNASeq/CCR7/Cons; ervedGenes/VCFs/${base}.vcf. gatk-4.2.5.0/gatk FastaAlternateReferenceMaker -R /mnt/research/Hausbeck_group/Lukasko/BotrytisDNASeq/0_DNAscripts/ReferenceGenome/Botrytis_cinerea.ASM83294v1.dna.tople; vel.fa -O /mnt/research/Hausbeck_group/Lukasko/BotrytisDNASeq/CCR7/ConservedGenes/mrr1/${base}_mrr1.fasta -L 5:680219-684662 -V /mnt/research/Hausbeck_group/Lu",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8427:214,error,error,214,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8427,1,['error'],['error']
Availability,"I am available to help in this process @jonn-smith. Just to give you an idea of the evolution of tutorials, here are some example tutorials that focus on somatic CNV calling. - Alpha tutorial that Lee wrote:; <https://gatkforums.broadinstitute.org/gatk/discussion/7387/description-and-examples-of-the-steps-in-the-acnv-case-workflow>; - A demo-like tutorial that Sam Lee planned and developed (also Mehrtash was involved so don't be shy about asking around for help) and I encased in writing:; <https://gatkforums.broadinstitute.org/gatk/discussion/9143/how-to-call-somatic-copy-number-variants-using-gatk4-cnv/p1>; - A tutorial to highlight the factors in PoN creation currently used in workshops that I planned, developed and wrote: [GATK4_SomaticCNV_worksheet.pdf](https://github.com/broadinstitute/gatk/files/1435691/GATK4_SomaticCNV_worksheet.pdf). Depending on how much responsibility you want to take (I think it nice for you to post a tutorial on the forum under your name for posterity), you can choose to get my review only or have me help in brainstorming, organizing and/or formatting the content. I have a template available for copy-pasting with formatting elements at <https://gatkforums.broadinstitute.org/dsde/discussion/9140/how-to-tutorial-template-a-la-soo-hee-for-copy-pasting#latest>. Notice this document is only visible to DSDE members and similarly, you can draft a tutorial in private first then move it to a public forum. Here are some steps I go through in developing a tutorial. You may choose to skip certain elements, e.g. example data. I have to say that having example data really helps the users.; - Find small test data to illustrate important features of the tool; ensure data is publically sharable; - Write out commands that include recommended parameters; - Explain the important parameters and the impact of changing them; - Illustrate with results and screenshots; - Get reviewed early by others and incorporate changes; - A section of links to related or help",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3774:5,avail,available,5,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3774,1,['avail'],['available']
Availability,I am getting the following error when creating the gatk environment with conda env create -n gatk -f scripts/gatkcondaenv.yml. NoPackagesFoundError: Package missing in current linux-64 channels:; - intel-openmp 2018.0.0*. Below is the complete listing. Any suggestions?. .```; /gradlew createPythonPackageArchive; :createPythonPackageArchive UP-TO-DATE. BUILD SUCCESSFUL. Total time: 13.183 secs. conda env create -n gatk -f scripts/gatkcondaenv.yml; Using Anaconda API: https://api.anaconda.org; Fetching package metadata ............. NoPackagesFoundError: Package missing in current linux-64 channels:; - intel-openmp 2018.0.0*; ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4822:27,error,error,27,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4822,1,['error'],['error']
Availability,"I am looking at using GATK and first checked at the docker image using **_docker pull broadinstitute/gatk_**. this container image has 1460 vulnerabilities and a lot of them are critical. ; <img width=""1737"" alt=""Screenshot 2023-02-21 212830"" src=""https://user-images.githubusercontent.com/4427764/220508376-aeead13b-999b-4cfd-a7d6-295241df532a.png"">. Then I decided not to use this image and instead create my own image and just deploy the released version 4.2.6.1 from here (https://github.com/broadinstitute/gatk/releases/download/4.2.6.1/gatk-4.2.6.1.zip). Even this has many vulnerabilities include things stemming from log4j 1.2.17. These have been fixed by log4j team years back in version 2.17.1 onwards. I am really stunned that a popular library like gatk is not keeping up with basic security fixes. <img width=""854"" alt=""Screenshot 2023-02-21 212751"" src=""https://user-images.githubusercontent.com/4427764/220508300-7bfe331d-8286-4950-a6dc-e1f5f97c65d0.png"">. the latest version of docker desktop has integrated image scanning and can very easily highlight the issues listed above. Can we start addressing these issues sooner than later.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8215:525,down,download,525,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8215,1,['down'],['download']
Availability,"I am running GATK GenotypeGVCFs, v4.2.6.1. I am trying to call Genotypes on a GenomicsDB workspace with about 500 WGS samples. Note, this is the macaque MMul10 genome, so it has 2,939 contigs (including unplaced). We've run commands like this quite a lot before, though we periodically do have issues like this. We can consolidate on this workspace prior to running this (using a standalone tool @nalinigans provided on #7674). As you can see we ran java with relatively low RAM, but left ~150G for the C++ layer. I'm surprised this isnt good enough. . I'm going to try to interactively inspect this, but the error is from slurm killing my job, not a java memory error, which I believe means the -Xmx 92G isnt getting exceeded. I could be mistaken though. You'll also see: 1) I'm using --force-output-intervals, 2) I'm giving it -XL to excluded repetitive regions (and therefore also skipping some of the more gnarly and memory-intensive sites), and 3) I'm giving it a fairly small -L interval list (this is split into 750 jobs/genome). . ```; java8 \; -Djava.io.tmpdir=<folder> \; -Xmx92g -Xms92g -Xss2m \; -jar GenomeAnalysisTK4.jar \; GenotypeGVCFs \; -R 128_Mmul_10.fasta \; --variant gendb:///<path>/WGS_v2_db03_500.gdb \; -O WGS_v2_db03_500.temp.vcf.gz \; --annotate-with-num-discovered-alleles \; -stand-call-conf 30 \; -XL NCBI_Mmul_10.softmask.bed \; --max-alternate-alleles 6 \; --genomicsdb-max-alternate-alleles 9 \; --force-output-intervals mmul10.WGS-WXS.whitelist.v2.3.sort.merge.bed \; -L 14:37234750-41196525 \; --only-output-calls-starting-in-intervals \; --genomicsdb-shared-posixfs-optimizations; ```. Each job gets about 250K to 800K variants into the data, and then they pretty consistently start to exceed memory and get killed. . Does anyone have suggestions on debugging or troubleshooting steps? Thanks in advance for any help.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7968:609,error,error,609,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7968,2,['error'],['error']
Availability,"I am running Gatk SelectVariant with -L and -ip options to filter out variants that are not inside my bed defined region +- interval padding. I am running gatk version 4.1.0.0 and for some of my task fails and returns ``` rc 1 (exit code 1) ``` but there is no clear error message on any logs. . ``` Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Dsamjdk.compression_level=5 -Xms100g -Xmx100g -jar /root/gatk.jar SelectVariants -L /cromwell_root/mybucket/ref/bed_files/mybedfile.bed -R /cromwell_root/mybucket2/NGS/ref/hg38/v0/Homo_sapiens_assembly38.fasta -V /cromwell_root/mybucket/cromwell-execution/mypipeline/2baacdb4-d3c5-4d98-afb2-6578c3ddcda9/call-MT2/calling.Mutect2/a4839059-9209-42da-b106-a91393c47546/call-Filter/input.vcf -ip 20 -O output.vcf --verbosity DEBUG ; ```. Task seems to end prematurely but I can not find out why. Also output file is generated but it only has variants from chr 1 even though my sample is whole exome, which also supports the premature end of task theory. Stdout is empty and stderr seems to end prematurely. [failing_SelectVariants-stderr.log](https://github.com/broadinstitute/gatk/files/5652756/failing_SelectVariants-stderr.log)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6990:267,error,error,267,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6990,1,['error'],['error']
Availability,"I am running into an issue with MarkDuplicatesSpark where it runs successfully in local mode, but if I run it in standalone mode with files on the file system or hdfs I get unexpected results. It could be that I'm doing something very basic wrong here, so I'm pasting a bunch of contextual information in case it helps. Thanks in advance!. ```; # Output BAM is correct in local mode:; $GATK_DIR/gatk-launch MarkDuplicatesSpark -I NA12878.chrom20.100kb.ILLUMINA.bwa.CEU.exome.20121211.bam -O test.local.bam. # Outputs empty BAM (i.e. header but no alignments) in standalone mode:; $GATK_DIR/gatk-launch MarkDuplicatesSpark -I NA12878.chrom20.100kb.ILLUMINA.bwa.CEU.exome.20121211.bam -O test.standalone.bam -- --sparkRunner SPARK --sparkMaster spark://localhost:7077. # Errors out with a wrong FS type (stacktrace below):; $GATK_DIR/gatk-launch MarkDuplicatesSpark -I hdfs://bam/NA12878.chrom20.100kb.ILLUMINA.bwa.CEU.exome.20121211.bam -O hdfs://bam/test.hdfs.bam -- --sparkRunner SPARK --sparkMaster spark://localhost:7077; ```. And the stacktrace for the HDFS case (I'm running HDFS in Pseudo-Distributed mode on the same host as I a running Spark standalone mode on): . ```; org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSpark done. Elapsed time: 0.07 minutes.; Runtime.totalMemory()=1029177344; java.lang.IllegalArgumentException: Wrong FS: hdfs://bam/NA12878.chrom20.100kb.ILLUMINA.bwa.CEU.exome.20121211.bam, expected: file:///; at org.apache.hadoop.fs.FileSystem.checkPath(FileSystem.java:645); at org.apache.hadoop.fs.FileSystem.makeQualified(FileSystem.java:465); at org.apache.hadoop.fs.FilterFileSystem.makeQualified(FilterFileSystem.java:119); at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSource.getHeader(ReadsSparkSource.java:181); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.initializeReads(GATKSparkTool.java:284); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.initializeToolInputs(GATKSparkTool.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1444:769,Error,Errors,769,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1444,1,['Error'],['Errors']
Availability,"I am running sortsam and getting error Exception in thread ""main"" java.lang.NoClassDefFoundError: org/xerial/snappy/LoadSnappy",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2299:33,error,error,33,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2299,2,['error'],['error']
Availability,"I am starting a Maven Project in which I would like to import your library; so I added this [dependency](http://search.maven.org/#artifactdetails%7Corg.broadinstitute%7Cgatk%7C4.beta.2%7C) to my pom.xml; ```; <dependency>;     <groupId>org.broadinstitute</groupId>;     <artifactId>gatk</artifactId>;     <version>4.beta.2</version>; </dependency>; ```; When I execute `mvn clear install` in my folder project, I receive this error: ; ```; [ERROR] Failed to execute goal on project GATKpipe: ; Could not resolve dependencies for project uk.ac.ncl:GATKpipe:jar:0.0.1-SNAPSHOT: ; Could not find artifact com.github.fommil.netlib:all:jar:1.1.2 in ; all (https://mvnrepository.com/artifact/com.github.fommil.netlib/all) -> [Help 1]; ```; and it seems that the problem is the dependency by com.github.fommil.netlib/all, indeed according to the output of `mvn clear install`, it attempt to download all-1.1.2.jar:; `Downloading: https://repo.maven.apache.org/maven2/com/github/fommil/netlib/all/1.1.2/all-1.1.2.jar`; but this jar is not available in the repository. I noticed that even in other [projects](https://github.com/amplab/ml-matrix/issues/11) have the same issue. How is possible to resolve this issue? . Thanks for your time,; Nicholas",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3724:426,error,error,426,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3724,5,"['Down', 'ERROR', 'avail', 'down', 'error']","['Downloading', 'ERROR', 'available', 'download', 'error']"
Availability,"I am trying to do SNPs call using GATK but I am getting below error. Any idea how can I solve this error? . (base) glier_ubuntu@glierubuntu-Precision-7920-Tower:/media/glier_ubuntu/4TB/Javad_Final/7gatk/ScriptforSNP$ call_snps_gatk_firstpass.sh 6 '/media/glier_ubuntu/4TB/Javad_Final/5-trinity/Fastajavad_Trinity/Trinity.fasta' '/media/glier_ubuntu/4TB/Javad_Final/6bwa/2/filtered_merged.bam' ; Using GATK jar /home/glier_ubuntu/gatk-4.1.1.0/gatk-package-4.1.1.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx8G -jar /home/glier_ubuntu/gatk-4.1.1.0/gatk-package-4.1.1.0-local.jar CreateSequenceDictionary -R /media/glier_ubuntu/4TB/Javad_Final/5-trinity/Fastajavad_Trinity/Trinity.fasta -O /media/glier_ubuntu/4TB/Javad_Final/5-trinity/Fastajavad_Trinity/Trinity.dict; 15:46:56.167 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/glier_ubuntu/gatk-4.1.1.0/gatk-package-4.1.1.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; [Wed May 13 15:46:56 EDT 2020] CreateSequenceDictionary --OUTPUT /media/glier_ubuntu/4TB/Javad_Final/5-trinity/Fastajavad_Trinity/Trinity.dict --REFERENCE /media/glier_ubuntu/4TB/Javad_Final/5-trinity/Fastajavad_Trinity/Trinity.fasta --TRUNCATE_NAMES_AT_WHITESPACE true --NUM_SEQUENCES 2147483647 --VERBOSITY INFO --QUIET false --VALIDATION_STRINGENCY STRICT --COMPRESSION_LEVEL 2 --MAX_RECORDS_IN_RAM 500000 --CREATE_INDEX false --CREATE_MD5_FILE false --GA4GH_CLIENT_SECRETS client_secrets.json --help false --version false --showHidden false --USE_JDK_DEFLATER false --USE_JDK_INFLATER false; May 13, 2020 3:46:57 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; [Wed May 13 15:46:57 EDT 2020] Executing as glier_ubuntu@glierubuntu-Precision-7920-Tower on Linux 4.15.0-99-generic am",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6604:62,error,error,62,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6604,2,['error'],['error']
Availability,"I am trying to run GATK (v4.1.8.0) BaseRecalibrator for my whole exome sequencing data. I generated the interval_list file using picard such that:. ```; dict=/data/anderslab/Annotation/GATK/Homo_sapiens_assembly38.dict; picard_jar=/nfs/software/helmod/apps/Core/picard-tools/2.4.1-gcb01/picard.jar; java -jar ${picard_jar} BedToIntervalList \; I=Padded.bed \; O=Padded.interval_list \; SD=${dict}; ```; But when I feed the file into the GATK I got an error:. ```; [August 18, 2020 10:31:17 AM EDT] org.broadinstitute.hellbender.tools.walkers.bqsr.BaseRecalibrator done. Elapsed time: 0.04 minutes.; Runtime.totalMemory()=2224553984; ***********************************************************************. A USER ERROR has occurred: Badly formed genome unclippedLoc: Query interval ; ""/data/refs/GATK/S31285117_hs_hg38/interval_list/Padded.interval_list"" is not valid for this input. ***********************************************************************; Set the system property GATK_STACKTRACE_ON_USER_EXCEPTION (--java-options '-DGATK_STACKTRACE_ON_USER_EXCEPTION=true') to print the stack trace.; ```; Some suggestions?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6755:451,error,error,451,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6755,2,"['ERROR', 'error']","['ERROR', 'error']"
Availability,"I am trying to use FilterVariantTranches in GATK 4.0.3.0 after running CNNScoreVariants. ```; ./gatk FilterVariantTranches \; -V test.cnnscore.vcf \; --snp-truth-vcf hapmap_3.3.hg19.sites.vcf \; --indel-truth-vcf Mills_and_1000G_gold_standard.indels.hg19.sites.vcf \; --info-key CNN_1D \; --tranche 99.9 --tranche 99.0 --tranche 95 \; --max-sites 8000 \; -O test.cnnscore.filtered.vcf; ```. There are also index files in the directory. ```; test.cnnscore.vcf.idx (generated by CNNScoreVariants); hapmap_3.3.hg19.sites.vcf.idx; Mills_and_1000G_gold_standard.indels.hg19.sites.vcf.idx; ```. and I got the error. ```; Traceback (most recent call last):; File ""/tmp/zzxzxzzxz/tranches.5887233932112211461.py"", line 124, in <module>; run(); File ""/tmp/zzxzxzzxz/tranches.5887233932112211461.py"", line 10, in run; write_tranches(args); File ""/tmp/zzxzxzzxz/tranches.5887233932112211461.py"", line 34, in write_tranches; v_scored = allele_in_vcf(allele, variant, vcf_reader); File ""/tmp/zzxzxzzxz/tranches.5887233932112211461.py"", line 84, in allele_in_vcf; variants = vcf_ram.fetch(variant.contig, variant.pos-1, variant.pos); File ""pysam/libcbcf.pyx"", line 4321, in pysam.libcbcf.VariantFile.fetch; ValueError: fetch requires an index. at org.broadinstitute.hellbender.utils.python.PythonExecutorBase.getScriptException(PythonExecutorBase.java:75); at org.broadinstitute.hellbender.utils.runtime.ScriptExecutor.executeCuratedArgs(ScriptExecutor.java:126); at org.broadinstitute.hellbender.utils.python.PythonScriptExecutor.executeArgs(PythonScriptExecutor.java:170); at org.broadinstitute.hellbender.utils.python.PythonScriptExecutor.executeScript(PythonScriptExecutor.java:151); at org.broadinstitute.hellbender.utils.python.PythonScriptExecutor.executeScript(PythonScriptExecutor.java:121); at org.broadinstitute.hellbender.tools.walkers.vqsr.FilterVariantTranches.doWork(FilterVariantTranches.java:134); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:134); at",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4794:603,error,error,603,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4794,1,['error'],['error']
Availability,"I am trying version 4.2.3.0. I set `--java-options ""-Xmx128g""` and it gradually increased to consume all of the RAM. ```; PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND; 3286969 dario 20 0 136.7g 133.2g 27012 S 1478 26.4 725:33.44 java; ```. The input is a modest whole genome sequencing BAM file. ```; $ ls -lh CSCC_0163-B1.final*; -r-------- 1 dario stgrad 9.2M Dec 15 10:22 CSCC_0163-B1.final.bai; -r-------- 1 dario stgrad 86G Dec 15 10:21 CSCC_0163-B1.final.bam; ```. After about one hour without any progress messages, the process shuts down due to running out of heap space. ```; 12:03:07.666 INFO ProgressMeter - Starting traversal; 12:03:07.666 INFO ProgressMeter - Current Locus Elapsed Minutes Loci Processed Loci/Minute; 13:08:22.336 INFO GetPileupSummaries - Shutting down engine; [December 15, 2021 at 1:08:22 PM AEDT] org.broadinstitute.hellbender.tools.walkers.contamination.GetPileupSummaries done. Elapsed time: 84.45 minutes.; Runtime.totalMemory()=30333206528; Exception in thread ""main"" java.lang.OutOfMemoryError: Java heap space; ```. The two other key parameters were `-L af-only-gnomad.hg38.vcf.gz -V af-only-gnomad.hg38.vcf.gz`. I think this module is far too inefficient to be in production, if this is how it typically works.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7606:550,down,down,550,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7606,2,['down'],['down']
Availability,"I am using ASEReadCounter to call allelic read counts on 1000 genome reference. But, I found ASEReadCounter generatd only header in output file. Here I enclosed my command and stderr log. Please help me to check it. Thank you!. If you are seeing an error, please provide(REQUIRED) :; a) GATK version used: 4.1.8.1; b) Exact command used:. java -Xmx8000m -Djava.io.tmpdir=/broad/hptmp/cbao \; -jar ${path2gatk}/gatk-package-4.1.8.1-local.jar \; ASEReadCounter \; -L scattered.interval_list \; -R Homo_sapiens_assembly19.fasta \; -V 1000G_phase1.snps.high_confidence.b37.vcf.gz \; -I downsample_10k.bam \; -O output.txt --verbosity INFO . c) Entire error log:; 19:13:25.991 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/broad/software/free/Linux/redhat_7_x86_64/pkgs/gatk_4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Jun 14, 2021 7:13:26 PM shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider warnAboutProblematicCredentials; WARNING: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a ""quota exceeded"" or ""API not enabled"" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/.; 19:13:26.217 INFO ASEReadCounter - ------------------------------------------------------------; 19:13:26.218 INFO ASEReadCounter - The Genome Analysis Toolkit (GATK) v4.1.8.1; 19:13:26.218 INFO ASEReadCounter - For support and documentation go to https://software.broadinstitute.org/gatk/; 19:13:26.219 INFO ASEReadCounter - Executing as cbao@uger-c009.broadinstitute.org on Linux v3.10.0-1160.15.2.el7.x86_64 amd64; 19:13:26.219 INFO ASEReadCounter - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_181-b13; 19:13:26.219 INFO ASEReadCounter - Start Date/Time: June 14, 2021 7:13:25 PM ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7314:249,error,error,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7314,2,['error'],['error']
Availability,"I am using GATK 4.4.0.0 via the official docker release to reheader output from SVABA with an appropriate sequence dictionary. I am using `UpdateVCFSequenceDictionary` for this purpose with the following command: . ```; singularity exec -B ""$PWD"" broadinstitute-gatk-4.4.0.0.img gatk UpdateVCFSequenceDictionary --source-dictionary Mus_musculus.GRCm39.dna.primary_assembly.dict -V svaba.somatic.indel.vcf --replace true -O svaba.somatic.indel.vcf.reheaded.vcf; ```. I have encountered a curious behavior, where by the tool is not simply adjusting the sequence dictionary, but is also modifying a FORMAT field. . Original VCF header: . ```; ##FORMAT=<ID=GQ,Number=1,Type=String,Description=""Genotype quality (currently not supported. Always 0)"">; ```. Updated VCF header: . ```; ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Genotype Quality"">; ```. From what I can see, the updated text is used frequently in your GATK VCF files, but I can't dig out the specific code where it is being set via `UpdateVCFSequenceDictionary`. I am wondering if there is a collision where `UpdateVCFSequenceDictionary` detects GQ and prints a stock header field to match expectation, rather than leaving it alone. I would expect the tool to simply replace the dictionary portion of the VCF without modifying the FORMAT/INFO fields. This is causing issues with downstream analysis because SVABA QC values are float/string not integer.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8629:1346,down,downstream,1346,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8629,1,['down'],['downstream']
Availability,"I am using GATK DepthOfCoverage tool for some of my samples.; I need to use genome reference GRCh37.; Everything is working fine but an error will occur whenever I run it (attached photos).; I have used all different type of references, including Ensembl, UCSC, NCBI, and GATK source itself but the same error is still there.; Also I know that I need to use a unique database and use that to create all fai, dict, bed file so that for sure the namings are the same in my all types of files. But I don't know how to create .bed file out of a reference genome (i.e. Homo_sapiens.GRCh37.dna.primary_assembly.fa); Would you please guide me what can I do about that?. . ![Screenshot from 2021-09-02 00-11-51](https://user-images.githubusercontent.com/87016284/131868327-660a9a9c-cc93-4c6e-a08c-0a67eddf2f47.png); ![Screenshot from 2021-09-02 00-12-00](https://user-images.githubusercontent.com/87016284/131868369-0a80d306-8a05-4a87-a566-02c3713561c4.png)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7453:136,error,error,136,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7453,2,['error'],['error']
Availability,"I am using the GATK GenotypeGVCFs command to generate vcf through gvcf, but two samples in the same batch of individuals have the following error:; ```; Using GATK jar /share/org/YZWL/yzwl_hanxt/software/gatk-4.6.0.0/gatk-package-4.6.0.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx60g -jar /share/org/YZWL/yzwl_hanxt/software/gatk-4.6.0.0/gatk-package-4.6.0.0-local.jar GenotypeGVCFs -R /share/org/YZWL/yzwl_hanxt/leizhou/ref/ARS1.2_chr30_2.fasta -V H-4.g.vcf.gz -O /share/org/YZWL/yzwl_hanxt/leizhou/variant/temp/H-4.vcf.gz; 09:55:48.764 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/share/org/YZWL/yzwl_hanxt/software/gatk-4.6.0.0/gatk-package-4.6.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; 09:55:48.863 INFO GenotypeGVCFs - ------------------------------------------------------------; 09:55:48.865 INFO GenotypeGVCFs - The Genome Analysis Toolkit (GATK) v4.6.0.0; 09:55:48.865 INFO GenotypeGVCFs - For support and documentation go to https://software.broadinstitute.org/gatk/; 09:55:48.865 INFO GenotypeGVCFs - Executing as yzwl_hanxt@c01n0583 on Linux v4.18.0-513.5.1.el8_9.x86_64 amd64; 09:55:48.865 INFO GenotypeGVCFs - Java runtime: Java HotSpot(TM) 64-Bit Server VM v17.0.12+8-LTS-286; 09:55:48.866 INFO GenotypeGVCFs - Start Date/Time: September 3, 2024 at 9:55:48 AM CST; 09:55:48.866 INFO GenotypeGVCFs - ------------------------------------------------------------; 09:55:48.866 INFO GenotypeGVCFs - ------------------------------------------------------------; 09:55:48.866 INFO GenotypeGVCFs - HTSJDK Version: 4.1.1; 09:55:48.866 INFO GenotypeGVCFs - Picard Version: 3.2.0; 09:55:48.866 INFO GenotypeGVCFs - Built for Spark Version: 3.5.0; 09:55:48.866 INFO GenotypeGVCFs - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 09:55:48.867 INFO GenotypeGVCFs - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false;",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8969:140,error,error,140,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8969,1,['error'],['error']
Availability,"I am using zipped FASTQ files stored on GCP as inputs for ""Paired FASTQ to unmapped BAM"" tool in ""Sequence-Format-Conversion"" workspace and getting an error since I have to provide unzipped FASTQ files. ; Is it possible to modify this tool to allow inputting both zipped and unzipped FASTQ files.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6509:151,error,error,151,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6509,1,['error'],['error']
Availability,"I believe `sites` and `variants` should be equivalent. I see that there is a warning emitted by GATK4 at sites that are not het, but it shouldn't be an error. If you're getting an error can you please post the full message in this thread?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7747:152,error,error,152,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7747,2,['error'],['error']
Availability,"I believe `sites` and `variants` should be equivalent. I see that there is a warning emitted by GATK4 at sites that are not het, but it shouldn't be an error. If you're getting an error can you please post the full message in this thread? . ASEReadCounter will only process het sites in both GATK3 and GATK4, but it's possible that GATK3 silently skipped non-het sites rather than emitting a warning. _Originally posted by @meganshand in https://github.com/broadinstitute/gatk/issues/7712#issuecomment-1084552468_",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7747:152,error,error,152,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7747,2,['error'],['error']
Availability,"I bumped into an error in a PR of mine due to a recent update in master. While I should make the code of the PR more robust I think that the approach take to compose approximate likehoods in ```VariantAnnotator.makeLikelihoods``` can and should be improved. Currently uses -Infility as ""unlikely"" lk (I would say rather ""impossible"" lk) and 0 as ""likely"" based on whether the read pileup does not match the allele or it does match the allele. . IMO the ""unlikely"" lk should never be less than the mapping quality of the read. And it can be further reduced by the base quality in case of an snp or the indel error probrability; by default is 45 Phred yet as part of the integration with Illumina/DRAGEN Dragstr, at least in germline, we can come out with indel penalties that are tailred to the reference, read context.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7312:17,error,error,17,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7312,3,"['error', 'robust']","['error', 'robust']"
Availability,"I calculated ASECount of genome resequence data by GATK-3.8 , but I want do the same test by GATK-4.0 , It's so strange when I use GATK-4.0 argument ""--variants"" to substitute ""sites"" of GATK-3.8 , the ERROR remaind me that the ""SNP site is not hetero"" , so l want to ask ; What is the mean of ASECountReader ""sites"" argument of GATK-3.8 ? and what is the corresponding argument in GATK-4.0 ? the answer is undocumented in instruction of ""GATK-3.8 --help"", so l want get exact answer, thank you !",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7712:202,ERROR,ERROR,202,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7712,1,['ERROR'],['ERROR']
Availability,"I came across some notes I made 20170901, while developing the Helsinki Mutect2 tutorial, to report a particular bug, that I am just now getting around to. Here is the command I ended up using to solve the problem:; ```; gatk-launch PrintReads -I hcc1143_N_clean.bam -O hcc1143_N_chr17.bam -L chr17 -L chr11:915890-1133890 -L chr6:29941013-29946495 -L chr11_KI270927v1_alt -L HLA-A*24:03:01:1+; ```. Notice the protection tag `:1+` that I add to the last interval. If I do not add this, I get the following error:; ```; ***********************************************************************. A USER ERROR has occurred: Badly formed genome unclippedLoc: Contig 'HLA-A*24:03' does not match any contig in the GATK sequence dictionary derived from the reference; are you sure you are using the correct reference fasta file?. ***********************************************************************; ```; This error persists even if I provide a dictionary/ref to the command. . The solution comes from the pipelines team, in their [PESS workflow that I documented](https://gatkforums.broadinstitute.org/gatk/discussion/7899/reference-implementation-pairedendsinglesamplewf-pipeline), so credit goes to them. Perhaps our code can do this internally for HLA contigs. Sorry for the late notice. I've been extremely busy. I will assign @droazen since we touched upon this briefly last week.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3807:507,error,error,507,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3807,3,"['ERROR', 'error']","['ERROR', 'error']"
Availability,I can see the reassurance of knowing that the input Locatable is constant and with a non-null contig... yet as a result we are often creating redundant simpleIntervals instances when our objects of interest are some other type of Locatable.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3541:142,redundant,redundant,142,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3541,1,['redundant'],['redundant']
Availability,"I changed the `--mask` and `-mask-name` arguments to be lists so it's possible to supply multiple mask files. There are still some questions to discuss that may warrant changes:. 1. Should `-filter-not-in-mask` also be a list, so the user specifies whether to do a mask or reverse mask for each file?; a. My inclination is no, since that would make things kind of complicated and probably you just want to filter variants that appear in none of the mask files; 2. What should `maskName` default to now?; a. Previously, it defaulted to ""Mask"".; b. I changed it to default to ""Mask"" for the first mask, and then ""Mask2"", ""Mask3"", etc. Not sure if this is ideal?; 3. Should the variable names be changed?; a. i.e. `mask` -> `masks` and `maskName` -> `maskNames`; b. Obviously the arguments would keep the same names; 4. When using `-filter-not-in-mask`, what should we list for filters?; a. All the mask names? (this is what I'm doing now, but it could obviously get very long and maybe be misleading?); b. Should we just allow one `-maskName` if `-filter-not-in-mask` is specified?; 5. Is my implementation likely to cause a prohibitive performance reduction?. Closes #8119",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8237:17,mask,mask,17,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8237,19,"['Mask', 'mask']","['Mask', 'mask', 'mask-name', 'maskName', 'maskNames', 'masks']"
Availability,"I cloned GATK4 into /humgen/gsa-scr1/gauthier/workspaces/gatk/ (from gsa5), then tried `./gatk-launch --list`, which didn't work because I hadn't built yet. gatk-launch told me to run `/humgen/gsa-scr1/gauthier/workspaces/gatk/gradlew installDist`, which I did and it threw the following error (sorry for the huge stacktrace, but I didn't want to leave out anything important):. [...]; Download https://repo1.maven.org/maven2/xpp3/xpp3_min/1.1.4c/xpp3_min-1.1.4c.jar; Download https://repo1.maven.org/maven2/commons-beanutils/commons-beanutils/1.8.0/commons-beanutils-1.8.0.jar. FAILURE: Build failed with an exception.; - What went wrong:; A problem occurred configuring root project 'gatk'.; ; > Could not resolve all dependencies for configuration ':classpath'.; > Could not download commons-beanutils.jar (commons-beanutils:commons-beanutils:1.8.0); > Could not get resource 'https://repo1.maven.org/maven2/commons-beanutils/commons-beanutils/1.8.0/commons-beanutils-1.8.0.jar'.; > > Failed to move file '/tmp/gradle_download3865353896539966562bin' into filestore at '/home/unix/gauthier/.gradle/caches/modules-2/files-2.1/commons-beanutils/commons-beanutils/1.8.0/c651d5103c649c12b20d53731643e5fffceb536/commons-beanutils-1.8.0.jar'; - Try:; Run with --stacktrace option to get the stack trace. Run with --info or --debug option to get more log output. BUILD FAILED. Total time: 22.394 secs; Could not stop org.gradle.cache.internal.DefaultMultiProcessSafePersistentIndexedCache@1fc775a3.; org.gradle.api.UncheckedIOException: org.gradle.api.UncheckedIOException: java.io.IOException: Disk quota exceeded; at org.gradle.cache.internal.btree.BTreePersistentIndexedCache.close(BTreePersistentIndexedCache.java:197); at org.gradle.cache.internal.DefaultMultiProcessSafePersistentIndexedCache$4.run(DefaultMultiProcessSafePersistentIndexedCache.java:78); at org.gradle.cache.internal.DefaultFileLockManager$DefaultFileLock.doWriteAction(DefaultFileLockManager.java:173); at org.gradle.cache.internal.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1364:288,error,error,288,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1364,5,"['Down', 'FAILURE', 'down', 'error']","['Download', 'FAILURE', 'download', 'error']"
Availability,"I did not use the official download of the Funcotator datasources (1.2), but I did find some extraneous files that should be removed. Complete list is below:. ```; drwxrwx--- 1 root vboxsf 0 Apr 30 15:44 achilles/; drwxrwx--- 1 root vboxsf 0 Apr 30 15:44 cancer_gene_census/; drwxrwx--- 1 root vboxsf 0 Apr 30 15:44 clinvar/; drwxrwx--- 1 root vboxsf 0 Apr 30 15:44 cosmic/; drwxrwx--- 1 root vboxsf 0 Apr 30 15:44 cosmic_fusion/; drwxrwx--- 1 root vboxsf 0 Apr 30 15:44 cosmic_tissue/; drwxrwx--- 1 root vboxsf 0 Apr 30 15:39 dbsnp/; drwxrwx--- 1 root vboxsf 0 Apr 30 15:39 dna_repair_genes/; -rwxrwx--- 1 root vboxsf 6148 Apr 30 15:38 .DS_Store*; drwxrwx--- 1 root vboxsf 0 Apr 30 15:39 familial/; drwxrwx--- 1 root vboxsf 0 Apr 30 15:39 gencode/; drwxrwx--- 1 root vboxsf 0 Apr 30 15:39 gencode_xhgnc/; drwxrwx--- 1 root vboxsf 0 Apr 30 15:39 gencode_xrefseq/; drwxrwx--- 1 root vboxsf 0 Apr 30 15:39 hgnc/; drwxrwx--- 1 root vboxsf 0 Apr 30 15:44 .idea/; drwxrwx--- 1 root vboxsf 0 Apr 30 15:38 oreganno/; -rwxrwx--- 1 root vboxsf 5274 Apr 30 15:38 README.txt*; drwxrwx--- 1 root vboxsf 0 Apr 30 15:38 simple_uniprot/; -rwxrwx--- 1 root vboxsf 1557 Apr 30 15:38 template.config*. ```; `.DS_Store` and `.idea` should not be in the official download.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4722:27,down,download,27,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4722,2,['down'],['download']
Availability,I download 4.1.8.1 release tar.gz file but can't unzip.; ```; 63800K .......... .......... .......... .......... .......... 49.2K; 63850K 533G=21m48s. 2020-07-22 09:06:30 (48.8 KB/s) - ‘4.1.8.1.tar.gz’ saved [65382686]; ```; Here is Error:; ```; $tar -zxf 4.1.8.1.tar.gz . gzip: stdin: unexpected end of file; tar: Unexpected EOF in archive; tar: Unexpected EOF in archive; tar: Error is not recoverable: exiting now; ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6719:2,down,download,2,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6719,4,"['Error', 'down', 'recover']","['Error', 'download', 'recoverable']"
Availability,"I get a consistent failure with BaseRecalibrator on a handful of samples. It occurs in both GATK 4 and GATK 3 (I checked the most current git repository of both). I also submitted this bug to the gatk forum before seeing that it affects GATK 4 and submitted this bug report.; [Forum link](https://gatkforums.broadinstitute.org/gatk/discussion/comment/44650). I've trimmed the command line down to the minimum necessary to generate the error, and I've trimmed the input files to the minimum section needed to generate the failure (a specific single read). You can find the failure below, but I also dug out the location of the failure with a proposed fix. ./gatk/src/main/java/org/broadinstitute/hellbender/utils/recalibration/covariates/ContextCovariate.java line 191 -->. ```; while (bases[currentNPenalty] != 'N') {; final int baseIndex = BaseUtils.simpleBaseToBaseIndex(bases[currentNPenalty]);; currentKey |= (baseIndex << offset);; offset -= 2;; currentNPenalty--;; }; ```. The current while loop allows the array index to become negative and walk right off the edge of the read. So a proposed fix is as follows (assuming it does not break the covariate logic) -->. ```; while (currentNPenalty > 0 && bases[currentNPenalty] != 'N') {; final int baseIndex = BaseUtils.simpleBaseToBaseIndex(bases[currentNPenalty]);; currentKey |= (baseIndex << offset);; offset -= 2;; currentNPenalty--;; }; ```. Minimal Command (test.bam attached - added txt extension just so site would let me attach it) -->. ```; gatk-launch BaseRecalibrator -I test.bam -O test.table -R GATK_Bundle_Build38/Homo_sapiens_assembly38.fasta --knownSites GATK_Bundle_Build38/dbsnp_146.hg38.vcf.gz; ```. Error message --> . ```; java.lang.ArrayIndexOutOfBoundsException: -1; 	at org.broadinstitute.hellbender.utils.recalibration.covariates.ContextCovariate.contextWith(ContextCovariate.java:191); 	at org.broadinstitute.hellbender.utils.recalibration.covariates.ContextCovariate.recordValues(ContextCovariate.java:68); 	at org.broad",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4005:19,failure,failure,19,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4005,6,"['down', 'error', 'failure']","['down', 'error', 'failure']"
Availability,"I got 348 samples to analyse their variants. I have read several turorials about how to use gatk to get a population vcf. At the beginning , I tried to use CombineGVCFs to get the Gvcf and use SelectVariants to pick the snps out. . CombineGVCFs truns to a error ""Exception in thread ""main"" java.lang.OutOfMemoryError"" .; then I chose to use GenomicsDBImport to do this job. It still doesn't work. First error is ""read_one_line_fully && ""Buffer did not have space to hold a line fully - increase buffer size""; I add ""--genomicsdb-vcf-buffer-size 16384000"" , it causes different error ""Exception in thread ""main"" java.lang.OutOfMemoryError: Java heap space"". This is my command and work log.; My java version is ; openjdk version ""1.8.0_152-release""; OpenJDK Runtime Environment (build 1.8.0_152-release-1056-b12). GATK is very helpful in my research, and I really need some help to get it work. gatk --java-options ""-Xmx48g -Xms48G"" GenomicsDBImport -V C1_sentieon_gvcf.gz .......... -V SCAU-106.gvcf.gz -V SCAU-107.gvcf.gz -V SCAU-108.gvcf.gz -V SCAU-128.gvcf.gz --genomicsdb-workspace-path my_database.chr01 -R IRGSP-1.0_genome.fasta --genomicsdb-vcf-buffer-size 16384000 --intervals chr01. 11:48:08.245 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/ayu/anaconda3/share/gatk4-4.0.5.1-0/gatk-package-4.0.5.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; 11:48:09.327 INFO GenomicsDBImport - ------------------------------------------------------------; 11:48:09.327 INFO GenomicsDBImport - The Genome Analysis Toolkit (GATK) v4.0.5.1; 11:48:09.327 INFO GenomicsDBImport - For support and documentation go to https://software.broadinstitute.org/gatk/; 11:48:09.327 INFO GenomicsDBImport - Executing as ayu@ayu on Linux v5.15.90.1-microsoft-standard-WSL2 amd64; 11:48:09.327 INFO GenomicsDBImport - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_152-release-1056-b12; 11:48:09.327 INFO GenomicsDBImport - Start Date/Time: November 26, 2023 11:48:08 AM CST; 11:48:0",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8593:256,error,error,256,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8593,3,['error'],['error']
Availability,"I got the following error and log file from BaseRecalibrator: . ```; Using GATK jar /usr/gitc/gatk4/gatk-package-4.beta.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -Dsnappy.disable=true -XX:GCTimeLimit=50 -XX:GCHeapFreeLimit=10 -XX:+PrintFlagsFinal -XX:+PrintGCTimeStamps -XX:+PrintGCDateStamps -XX:+PrintGCDetails -Xloggc:gc_log.log -Xms4000m -jar /usr/gitc/gatk4/gatk-package-4.beta.1-local.jar BaseRecalibrator -R /cromwell_root/broad-references/hg38/v0/Homo_sapiens_assembly38.fasta -I gs://broad-gotc-dev-cromwell-execution/PairedEndSingleSampleWorkflow/66442def-ad3f-4c6c-960e-17578f6b382c/call-SortAndFixSampleBam/CHMI_CHMI3_WGS2.aligned.duplicate_marked.sorted.bam --useOriginalQualities -O CHMI_CHMI3_WGS2.recal_data.csv -knownSites gs://broad-references/hg38/v0/Homo_sapiens_assembly38.dbsnp138.vcf -knownSites /cromwell_root/broad-references/hg38/v0/Mills_and_1000G_gold_standard.indels.hg38.vcf.gz -knownSites /cromwell_root/broad-references/hg38/v0/Homo_sapiens_assembly38.known_indels.vcf.gz -L chr11:1+; Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/cromwell_root/tmp.WXYB31; [July 20, 2017 2:18:26 PM UTC] BaseRecalibrator --useOriginalQualities true --knownSites gs://broad-references/hg38/v0/Homo_sapiens_assembly38.dbsnp138.vcf --knownSites /cromwell_root/broad-references/hg38/v0/Mills_and_1000G_gold_standard.indels.hg38.vcf.gz --knownSites /cromwell_root/broad-references/hg38/v0/Homo_sapiens_assembly38.known_indels.vcf.gz --output CHMI_CHMI3_WGS2.recal_data.csv --intervals chr11:1+ --input gs://broad-gotc-dev-cromwell-execution/PairedEndSingleSampleWorkflow/66442def-ad3f-4c6c-960e-17578f6b382c/call-SortAndFixSampleBam/CHMI_CHMI3_WGS2.aligned.duplicate_marked.sorted.bam --reference /cromwell_root/broad-references/hg38/v0/Homo_sapiens_assembly38.fasta --mismatches_context_size 2 --indels_context_size 3 --maximum_cycle_value 500 --misma",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3316:20,error,error,20,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316,1,['error'],['error']
Availability,"I got the following error when running on a cluster (Centos 6.6). The file _/lib64/libz.so.1_ is symlinked to version 1.2.3, which is too low (<1.2.3.3). When I rebuilt jbwa locally it worked fine. ```; java.lang.UnsatisfiedLinkError: /data/11/yarn/nm/usercache/tom/appcache/application_1460561740089_0118/container_1460561740089_0118_01_000002/tmp/libbwajni.5713518835392178075.so: /lib64/libz.so.1: version `ZLIB_1.2.3.3' not found (required by /data/11/yarn/nm/usercache/tom/appcache/application_1460561740089_0118/container_1460561740089_0118_01_000002/tmp/libbwajni.5713518835392178075.so); at java.lang.ClassLoader$NativeLibrary.load(Native Method); at java.lang.ClassLoader.loadLibrary0(ClassLoader.java:1937); at java.lang.ClassLoader.loadLibrary(ClassLoader.java:1822); at java.lang.Runtime.load0(Runtime.java:809); at java.lang.System.load(System.java:1086); at org.broadinstitute.hellbender.utils.NativeUtils.loadLibraryFromClasspath(NativeUtils.java:63) ; at org.broadinstitute.hellbender.utils.bwa.BWANativeLibrary.load(BWANativeLibrary.java:14); ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1916:20,error,error,20,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1916,1,['error'],['error']
Availability,I got this error running tests once. It's unclear what the problem was. It's nice that it bubbles up as a java exception but it's hard to know what the underlying issue was. ```; java.io.IOException: GenomicsDB JNI Error: std::exception; 	at org.genomicsdb.reader.GenomicsDBQueryStream.jniGenomicsDBInit(Native Method); 	at org.genomicsdb.reader.GenomicsDBQueryStream.<init>(GenomicsDBQueryStream.java:209); 	at org.genomicsdb.reader.GenomicsDBQueryStream.<init>(GenomicsDBQueryStream.java:182); 	at org.genomicsdb.reader.GenomicsDBQueryStream.<init>(GenomicsDBQueryStream.java:91); 	at org.genomicsdb.reader.GenomicsDBFeatureReader.generateHeadersForQuery(GenomicsDBFeatureReader.java:200); 	at org.genomicsdb.reader.GenomicsDBFeatureReader.<init>(GenomicsDBFeatureReader.java:85); 	at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImportIntegrationTest.getGenomicsDBFeatureReader(GenomicsDBImportIntegrationTest.java:927); 	at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImportIntegrationTest.checkGenomicsDBAgainstExpected(GenomicsDBImportIntegrationTest.java:551); 	at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImportIntegrationTest.checkGenomicsDBAgainstExpected(GenomicsDBImportIntegrationTest.java:521); 	at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImportIntegrationTest.testWriteToAndQueryFromGCS(GenomicsDBImportIntegrationTest.java:1104); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.base/java.lang.reflect.Method.invoke(Method.java:566); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:133); 	at org.testng.internal.TestInvoker.invokeMethod(TestInvoker.java:584); 	at org.testng.internal.TestInvoker.invokeTestMethod(TestInvoker.java:1,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6745:11,error,error,11,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6745,2,"['Error', 'error']","['Error', 'error']"
Availability,"I had a dumb permissions issue that had me spinning my wheels for a while because of some very terse logging. With the 5 reader threads we use in production I get:; `A USER ERROR has occurred: Couldn't read file. Error was: Failure while waiting for FeatureReader to initialize with exception: com.google.cloud.storage.StorageException: All 20 retries failed. Waited a total of 1918000 ms between attempts` ; (The error message has a placeholder for a path, but for some reason it's empty for me.). Finally I went to one thread, which called the serial FeatureReader creation method and gave me an error that could actually help solve my problem:; ```; com.google.cloud.storage.StorageException: All 20 retries failed. Waited a total of 1918000 ms between attempts; 	at com.google.cloud.storage.contrib.nio.CloudStorageRetryHandler.handleRetryForStorageException(CloudStorageRetryHandler.java:108); 	at com.google.cloud.storage.contrib.nio.CloudStorageRetryHandler.handleStorageException(CloudStorageRetryHandler.java:89); 	at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.checkAccess(CloudStorageFileSystemProvider.java:621); 	at java.nio.file.Files.exists(Files.java:2385); 	at htsjdk.tribble.util.ParsingUtils.resourceExists(ParsingUtils.java:419); 	at htsjdk.tribble.AbstractFeatureReader.isTabix(AbstractFeatureReader.java:243); 	at htsjdk.tribble.AbstractFeatureReader$ComponentMethods.isTabix(AbstractFeatureReader.java:249); 	at htsjdk.tribble.AbstractFeatureReader.getFeatureReader(AbstractFeatureReader.java:103); 	at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImport.getReaderFromPath(GenomicsDBImport.java:619); 	at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImport.getFeatureReadersSerially(GenomicsDBImport.java:602); 	at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImport.traverse(GenomicsDBImport.java:490); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:893); 	at org.broadinstitute.hellbender.cmd",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4592:173,ERROR,ERROR,173,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4592,5,"['ERROR', 'Error', 'Failure', 'error']","['ERROR', 'Error', 'Failure', 'error']"
Availability,"I have Java 8 installed, but it's not my _default_ Java version, so `gradle check` gives me this error message:. ```; :compileJava FAILED. FAILURE: Build failed with an exception. * What went wrong:; Execution failed for task ':compileJava'.; > invalid source release: 1.8; ```. `JAVA_HOME=$JAVA8_HOME gradle check` succeeded. . I would prefer an error message like ""Hellbender requires JAVA_HOME to point to a valid Java 8 installation"" to make it immediately obvious what needs to be done.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/489:97,error,error,97,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/489,3,"['FAILURE', 'error']","['FAILURE', 'error']"
Availability,"I have a question on why would a trio call is not considered De novo?. I visually inspected the variant (and other variants that follow the same pattern) and from the bam file the variants are well supported (see below the vcf output) with a good number of reads supporting each genotype. The vast majority of the reads were very high qual and high mapping scores (almost all near 60). . Based on the vcf output the reason for failure is LowGQ, but how would this fail that parameter when so many passed with similar outcomes (bellow is another variant that was called de novo). I found this issue in a large number of variants in our cohort (several thousands of variants some of which are variants of interest in our samples.) . . Outputs - LowGQ (failed to call De novo). ```; chrZ yy yy A G 532.25 PASS AC=1;AF=0.167;AN=6;BaseQRankSum=0.362;ClippingRankSum=-1.980e-01;DB;DP=101;ExcessHet=3.0103;FS=0.000;MLEAC=1;MLEAF=0.167;MQ=59.54;MQRankSum=0.329;PG=0,0,0;QD=14.78;RAW_MQ=127600.00;ReadPosRankSum=-2.960e-01;SOR=0.542;VQSLOD=3.50 GT:AD:DP:FT:GQ:JL:JP:PL:PP 0/0:24,0:24:lowGQ:0:59:3:0,60,734:0,0,674 0/0:41,0:41:PASS:34:59:3:0,91,1289:0,34,1232 0/1:13,23:36:PASS:99:59:3:541,0,274:484,0,334. chrZ yy yy A G 342.25 PASS AC=1;AF=0.167;AN=6;BaseQRankSum=1.47;ClippingRankSum=0.825;DP=99;ExcessHet=3.0103;FS=5.073;MLEAC=1;MLEAF=0.167;MQ=60.00;MQRankSum=-8.590e-01;PG=0,0,0;QD=9.78;RAW_MQ=129600.00;ReadPosRankSum=1.26;SOR=1.623;VQSLOD=14.90;culprit=MQ . GT:AD:DP:FT:GQ:JL:JP:PL:PP . 0/0:42,0:42:PASS:51:59:3:0,108,1620:0,51,1563 0/0:21,0:21:lowGQ:0:59:3:0,60,690:0,0,630 0/1:21,14:35:PASS:99:59:3:351,0,575:294,0,635. ```. . Output - call trio (passed to call De novo). ```; chrZ yy1 yy1 C CA 46.57 PASS 90.07 PASS C=1;AF=0.167;AN=6;BaseQRankSum=-6.930e-01;ClippingRankSum=-3.900e-01;DP=120;ExcessHet=3.0103;FS=0.000;MLEAC=1;MLEAF=0.167;MQ=60.00;MQRankSum=-8.800e-02;PG=0,0,0;QD=9.89;RAW_MQ=154800.00;ReadPosRankSum=-7.180e-01;SOR=0.709;VQSLOD=14.67;culprit=MQ;hiConfDeNovo=BS_RMKCB0F4 GT:AD:DP:GQ:JL",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6424:427,failure,failure,427,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6424,1,['failure'],['failure']
Availability,"I have already get "".g.vcf "" through ""gatk Haplotype Caller"" but when I used the code ""./gatk GenotypeGVCFs -R /Users/lubo/sorgum/GCF_000003195.3_Sorghum_bicolor_NCBIv3_genomic.fna. ; -V /Users/lubo/sorgum/propinquum_variation.g.vcf; -O /Users/lubo/sorgum/propinquum.vcf"" to generate the output file ""propinquum.vcf"" ,A USER ERROR has occurred: The list of input alleles must contain <NON_REF> as an allele but that is not the case at position 11733; please use the Haplotype Caller with gVCF output to generate appropriate records。 ; I don't know what's wrong with my code ,is that mean my input file have something wrong?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7147:325,ERROR,ERROR,325,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7147,1,['ERROR'],['ERROR']
Availability,I have been trying to run the tutorial ( https://gatkforums.broadinstitute.org/gatk/discussion/10913/how-to-run-the-pathseq-pipeline ). When running without the --spark-master the turoail runs smoothly. Bu twhen I try my spark master I get an error. I downloaded SPARK 2.2.0 with hadoop 2.7.3; Java is 1.8.0_131; I set the java classpath (I think correctly); I am aware of this thread: https://github.com/broadinstitute/gatk/issues/3050. But noentheless I cannot get the error to solve. I tried to copy the jar files:; hbase-client-1.4.3.jar; hbase-common-1.4.3.jar; hbase-hadoop2-compat-1.4.3.jar; hbase-protocol-1.4.3.jar; hbase-server-1.4.3.jar; To my spark jar folder. Shall I do smething else? I am also a SPARK newbie. Thank you very much!. ***************** Here is the error log:. ../../../gatk PathSeqPipelineSpark --spark-master spark://xx.xx.xx.xx:7077 --input test_sample.bam --filter-bwa-image hg19mini.fasta.img --kmer-file hg19mini.hss --min-clipped-read-length 70 --microbe-fasta e_coli_k12.fasta --microbe-bwa-image e_coli_k12.fasta.img --conf [jars=~/bin/spark-2.2.0-bin-hadoop2.7/jars/hbase-client-1.4.3.jar] --taxonomy-file e_coli_k12.db --output output.pathseq.bam --verbosity DEBUG --scores-output output.pathseq.txt; Using GATK jar /scratch/home/int/eva/zorzan/bin/gatk-4.0.3.0/gatk-package-4.0.3.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /scratch/home/int/eva/zorzan/bin/gatk-4.0.3.0/gatk-package-4.0.3.0-local.jar PathSeqPipelineSpark --spark-master spark://xx.xx.xx.xx:7077 --input test_sample.bam --filter-bwa-image hg19mini.fasta.img --kmer-file hg19mini.hss --min-clipped-read-length 70 --microbe-fasta e_coli_k12.fasta --microbe-bwa-image e_coli_k12.fasta.img --conf [jars=~/bin/spark-2.2.0-bin-hadoop2.7/jars/hbase-client-1.4.3.jar] --taxonomy-file e_coli_k12.db --output output.pathseq.bam --verbosity DEBUG --scores-output,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694:243,error,error,243,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694,4,"['down', 'error']","['downloaded', 'error']"
Availability,"I have found an error in the _ClippingOp_ class used by the _ReadClipper_. The offending function is _cleanHardClippedCigar_. In this function a logic error results in the returned _CigarShift_ object always having zero values for the _shiftFromStart_ and _shiftFromEnd_ members. The offending loop is shown below:; `. for (int i = 1; i <= 2; i++) {; final int shift = 0;; int totalHardClip = 0;; boolean readHasStarted = false;; boolean addedHardClips = false;. while (!cigarStack.empty()) {; final CigarElement cigarElement = cigarStack.pop();. if (!readHasStarted &&; cigarElement.getOperator() != CigarOperator.DELETION &&; cigarElement.getOperator() != CigarOperator.SKIPPED_REGION &&; cigarElement.getOperator() != CigarOperator.HARD_CLIP) {; readHasStarted = true;; } else if (!readHasStarted && cigarElement.getOperator() == CigarOperator.HARD_CLIP) {; totalHardClip += cigarElement.getLength();; } else if (!readHasStarted && cigarElement.getOperator() == CigarOperator.DELETION) {; totalHardClip += cigarElement.getLength();; } else if (!readHasStarted && cigarElement.getOperator() == CigarOperator.SKIPPED_REGION) {; totalHardClip += cigarElement.getLength();; }. if (readHasStarted) {; if (i == 1) {; if (!addedHardClips) {; if (totalHardClip > 0) {; inverseCigarStack.push(new CigarElement(totalHardClip, CigarOperator.HARD_CLIP));; }; addedHardClips = true;; }; inverseCigarStack.push(cigarElement);; } else {; if (!addedHardClips) {; if (totalHardClip > 0) {; cleanCigar.add(new CigarElement(totalHardClip, CigarOperator.HARD_CLIP));; }; addedHardClips = true;; }; cleanCigar.add(cigarElement);; }; }; }; // first pass (i=1) is from end to start of the cigar elements; if (i == 1) {; shiftFromEnd = shift;; cigarStack = inverseCigarStack;; }; // second pass (i=2) is from start to end with the end already cleaned; else {; shiftFromStart = shift;; }; }; }; `. Notice that the variable _shift_ is initialized, but never assigned to again for the duration of the loop. Thus _shiftFromSta",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6130:16,error,error,16,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6130,2,['error'],['error']
Availability,"I have found an error when using GATK4 Mutect2 ,error as follow,thanks and waitting your reply; Using GATK jar /home/vip/biosoft/gatk/gatk-4.0.5.1/gatk-package-4.0.5.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx10g -jar /home/vip/biosoft/gatk/gatk-4.0.5.1/gatk-package-4.0.5.1-local.jar Mutect2 -R /data/bigbiosoft/GATK/resources/bundle/hg19/ucsc.hg19.fasta -I 02_bamdst/zhaoxuelan.sorted.algn.bam --tumor zhaoxuelan --germline-resource /home/vip/data/Mutect2/af-only-gnomad.raw.sites.hg19.vcf.gz --max-reads-per-alignment-start 0 -L /home/vip/lxdata/bed/lung9_gene_format.bed -O 03_somatic/zhaoxuelan.sorted.algn.bam.raw.vcf --af-of-alleles-not-in-resource 0.00003125 --min-base-quality-score 20 --read-filter MateOnSameContigOrNoMappedMateReadFilter --create-output-variant-md5; 16:46:49.608 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/vip/biosoft/gatk/gatk-4.0.5.1/gatk-package-4.0.5.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; 16:46:49.698 INFO Mutect2 - ------------------------------------------------------------; 16:46:49.698 INFO Mutect2 - The Genome Analysis Toolkit (GATK) v4.0.5.1; 16:46:49.698 INFO Mutect2 - For support and documentation go to https://software.broadinstitute.org/gatk/; 16:46:49.698 INFO Mutect2 - Executing as vip@zjm-System-Product-Name on Linux v4.18.0-25-generic amd64; 16:46:49.698 INFO Mutect2 - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_222-8u222-b10-1ubuntu1~18.04.1-b10; 16:46:49.699 INFO Mutect2 - Start Date/Time: November 6, 2019 4:46:49 PM CST; 16:46:49.699 INFO Mutect2 - ------------------------------------------------------------; 16:46:49.699 INFO Mutect2 - ------------------------------------------------------------; 16:46:49.699 INFO Mutect2 - HTSJDK Version: 2.15.1; 16:46:49.699 INFO Mutect2 - Picard Version: 2.18.2; 16:46:49.699 INFO Mutect2 - HTSJDK D",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6248:16,error,error,16,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6248,2,['error'],['error']
Availability,"I have managed to generate a minimal bam file that reproduces the issue. First of all, you have to download the mini input.bam file from this dropbox link: https://www.dropbox.com/sh/xae79hanumpireu/AABKo1l4Y-z5G5YLBqSpylRva?dl=0. Then the following code will reproduce the issue:; ```; wget https://github.com/broadinstitute/picard/releases/download/2.19.0/picard.jar. wget https://github.com/broadinstitute/gatk/releases/download/4.1.2.0/gatk-4.1.2.0.zip; unzip gatk-4.1.2.0.zip. wget -O- ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/000/001/405/GCA_000001405.15_GRCh38/seqs_for_alignment_pipelines.ucsc_ids/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz | \; gzip -d > GCA_000001405.15_GRCh38_no_alt_analysis_set.fna. samtools faidx GCA_000001405.15_GRCh38_no_alt_analysis_set.fna. java -jar picard.jar \; CreateSequenceDictionary \; R=GCA_000001405.15_GRCh38_no_alt_analysis_set.fna \; O=GCA_000001405.15_GRCh38_no_alt_analysis_set.dict. (echo ""##fileformat=VCFv4.2""; \; echo ""##contig=<ID=chrX,length=156040895>""; \; echo -e ""#CHROM\tPOS\tID\tREF\tALT\tQUAL\tFILTER\tINFO""; \; echo -e ""chr1\t97329945\t.\tT\tA\t.\t.\t.""; \; echo -e ""chr1\t97329967\t.\tC\tT\t.\t.\t."") | bgzip > input.vcf.gz && \; tabix -f input.vcf.gz. for score in 11 12; do; gatk-4.1.2.0/gatk HaplotypeCaller \; -R GCA_000001405.15_GRCh38_no_alt_analysis_set.fna \; -I input.bam \; -O output.$score.vcf.gz \; --genotyping-mode GENOTYPE_GIVEN_ALLELES \; --alleles input.vcf.gz \; -L chr1:97329945-97329967 \; --min-base-quality-score $score && \; bcftools query \; -f ""[%CHROM\t%POS\t%REF\t%ALT\t%GT\t%AD\n]"" \; output.$score.vcf.gz \; -r chr1:97329945-97329967; done; ```. When the parameter `--min-base-quality-score 11` is used, the GT/AD output is this:; ```; chr1	97329945	T	A	1/1	0,35; chr1	97329967	C	T	1/1	0,33; ```; When the parameter `--min-base-quality-score 12` is used, the GT/AD output is this:; ```; chr1	97329945	T	A	0/1	9,10; chr1	97329967	C	T	0/1	6,11; ```; The first output is the output that makes sense. W",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6045:99,down,download,99,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6045,4,"['down', 'echo']","['download', 'echo']"
Availability,"I have noticed that when running spark tools (e.g. CountReadsSpark or MarkDuplicatesSpark) that running with an input in the form ""CountReadsSpark -I gs://my-bucket-dir/my-file.bam."" The tool crashes with the following unhelpful stacktraces:. ```; java.io.IOException: Error getting access token from metadata server at: http://metadata/computeMetadata/v1/instance/service-accounts/default/token; 	at com.google.cloud.hadoop.util.CredentialFactory.getCredentialFromMetadataServiceAccount(CredentialFactory.java:208); 	at com.google.cloud.hadoop.util.CredentialConfiguration.getCredential(CredentialConfiguration.java:70); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.configure(GoogleHadoopFileSystemBase.java:1825); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.initialize(GoogleHadoopFileSystemBase.java:1012); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.initialize(GoogleHadoopFileSystemBase.java:975); 	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2653); 	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:92); 	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2687); 	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2669); 	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:371); 	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:295); 	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.setInputPaths(FileInputFormat.java:500); 	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.setInputPaths(FileInputFormat.java:469); 	at org.apache.spark.SparkContext$$anonfun$newAPIHadoopFile$2.apply(SparkContext.scala:1084); 	at org.apache.spark.SparkContext$$anonfun$newAPIHadoopFile$2.apply(SparkContext.scala:1072); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); 	at org.apache.spark.SparkContext.withScope(SparkContext.scala:679); 	at org.ap",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4369:269,Error,Error,269,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4369,1,['Error'],['Error']
Availability,"I have problems running gatk Mutect2. . ### gatk version; - 4.1.8.0. #### command-line. `gatk Mutect2 -R /home/proj/stage/cancer/reference/GRCh37/genome/human_g1k_v37_decoy.fasta -L /home/proj/stage/cancer/reference/target_capture_bed/production/balsamic/gicfdna_3.1_hg1`. ### Error; ```; Using GATK jar /home/proj/bin/conda/envs/D_UMI_APJ/share/gatk4-4.1.8.0-0/gatk-package-4.1.8.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /home/proj/bin/conda/envs/D_UMI_APJ/share/gatk4-4.1.8.0-0/gatk-package-4.1.8.0-local.jar Mutect2 -R /home/proj/stage/cancer/reference/GRCh37/genome/human_g1k_v37_decoy.fasta -L /home/proj/stage/cancer/reference/target_capture_bed/production/balsamic/gicfdna_3.1_hg19_design.bed -I consensus/concatenated_ACC5611A1_XXXXXX_consensusalign_ss_r2.bam -O mutect2/concatenated_ACC5611A1_XXXXXX_mutect2_unfiltered_ss_r2.vcf.gz; 09:39:55.358 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/proj/bin/conda/envs/D_UMI_APJ/share/gatk4-4.1.8.0-0/gatk-package-4.1.8.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Jul 03, 2020 9:39:55 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 09:39:55.559 INFO Mutect2 - ------------------------------------------------------------; 09:39:55.559 INFO Mutect2 - The Genome Analysis Toolkit (GATK) v4.1.8.0; 09:39:55.559 INFO Mutect2 - For support and documentation go to https://software.broadinstitute.org/gatk/; 09:39:55.559 INFO Mutect2 - Executing as ashwini.jeggari@hasta.scilifelab.se on Linux v3.10.0-1062.4.1.el7.x86_64 amd64; 09:39:55.560 INFO Mutect2 - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_152-release-1056-b12; 09:39:55.560 INFO Mutect2 - Start Date/Time: July 3, 2020 9:39:55 AM CEST; 09:39:55.560 INFO Mutect2 - ------------------",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6695:277,Error,Error,277,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6695,1,['Error'],['Error']
Availability,"I have run :; gatk MarkDuplicates -MAX_FILE_HANDLES 1000 -I ERR036185_sort.bam -O ERR036185_mark.bam -M ERR036185_mark_metrics.txt. but raise an error:OSError: [Errno 8] Exec format error: 'java'; i don‘t know why this error raise, as I can successfully run the command ""gatk"" without error,but if ""gatk MarkDuplicates"", the error raised again",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7484:145,error,error,145,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7484,5,['error'],['error']
Availability,"I have tested several program functions by GATK4, some of them work pretty well. GATK4 does a great job to organize all steps by different tools like BWA, samtools, picard. Besides, it seems that there is also some optimization inside. Like ""cleanSam"" step, GATK4 cuts the time half compared to the one using Picard. (From 8 mins to 4 mins on same data) . However, the problem about GATK4 is that some programs fail due to java related problem (Maybe some reasons else). So far, the functions I failed are ""FastqToSam"" and ""ReadsPipelineSpark "". . Note that, I am using spark locally not scale-out cluster. So the command I am running ReadsPipelineSpark is as below(with oracle java8). Then it gives me java error. . ./bin/gatk/gatk­launch \; ReadsPipelineSpark \; -O hdfs:<PATH>CEUTrio.HiSeq.WEx.b37.NA12892.readnamesort.bam.md.bqsr \; -I hdfs:<PATH>/CEUTrio.HiSeq.WEx.b37.NA12892.readnamesort.bam \; -R hdfs:<PATH>human_g1k_v37.2bit \; --knownSites hdfs:<PATH>dbsnp_138.b37.excluding_sites_after_129.vcf \; --shardedOutput true \; --emit_original_quals \; --duplicates_scoring_strategy SUM_OF_BASE_QUALITIES. All the failure seems to do with the java.lang.IllegalArgumentException with different error causes:; 1. readpipeline: java.lang.IllegalArgumentException: Null object is not allowed here; 2. fastqtosam: java.lang.IllegalArgumentException: Self-suppression not permitted",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1876:708,error,error,708,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1876,3,"['error', 'failure']","['error', 'failure']"
Availability,"I have the following instruction in a handson tutorial:. > If you haven't already done so, create a symlink to the gatk-launch script. Navigate back to /gatk and test the symlink by listing the tools available.; ```; cd /usr/local/bin; ln -s /gatk/gatk-launch gatk-launch; cd /gatk; gatk-launch –-list; ```. @vdauwera says:; > wouldn't it be simpler to export to path?. My reply:; > Environmental variables persist ephemerally. I haven't tested persistence when containers are stopped and restarted. @vdauwera requests:; > hmm, could also add to path in the bash profile... we should ask the devs if it's possible to set that up in the docker itself, for next time. Could we have both an environmental variable and a symlink that invokes the launch script in the Docker from any location? Thanks.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3899:200,avail,available,200,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3899,1,['avail'],['available']
Availability,"I have three main reasons to propose to move the arguments in CLP to an argument collection that is configurable by downstream tools/projects:. 1. Support hiding some arguments for downstream projects. For example, I do not want to support a config file by the user, but rather decide the settings for the framework and expose only some configuration.; 1. Set custom defaults for some downstream tools (including GATK). For example, a concrete tool might want to force the temp directory to be specified to avoid failures due to no space (and specify that in the documentation).; 1. Support old-style arguments (not kebab-case) for downstream projects that rely on the current argument definitions. I am specially affected by this one, because updating GATK to the 4.0.0 release of January will be a breaking change that will cause some nightmares for my users - and I don't want to do a major version bump yet (I have to re-work a bit my own framework before it). Thus, the first commit of this PR holds the proposal for the new argument collection. As I know that the team is also trying to normalize arguments and documentation, I included two more commits to help with the task (they can be removed if you think that it is better after the argument collection):; * Use `java.nio.Path` for temp directories (to support temp directories in HDFS, for example); * Change arguments moved to the collection to kebab-case (to help with #3853)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3998:116,down,downstream,116,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3998,5,"['down', 'failure']","['downstream', 'failures']"
Availability,"I have to deal with this component recently and I found the design rather awkward.... In general between GATK and htsjdk we don't seem to have a proper support for managing and querying Supplementary alignment information from read alignment records:. 1. Querying: implemented in htsjdk consists in forging artificial SAMRecords that contain only the alignment info in the SA tag element... It seems to me that it makes more sense to create class to hold this information alone (e.g. ReadAlignmentInfo or ReadAlignment); SATagBuilder already has defined a private inner class with that in mind ""SARead"" so why not flesh it out and make it public. 2. Writing: currently SATagBuilder gets attached to a read, parsing its current SA attribute content into SARead instances. It provides the possibility adding additional SAM record one by one or clearing the list. ... then it actually updates the SA attribute on the original read when a method (setTag) is explicitly called.; I don't see the need to attach the SATag Builder to a read... it could perfectly be free standing; the same builder could be re-apply to several reads for that matter and I don't see any gain in hiding the read SA tag setting process,... even if typically this builder output would go to the ""SA"" tag, perhaps at some point we would like to also write SA coordinate list somewhere else, some other tag name or perhaps an error message... why impose this single purpose limitation?; I suggest to drop the notion of a builder for a more general custom ReadAlignmentInfo (or whatever name) list. Such list could be making reference to a dictionary to validate its elements, prevent duplicates, keep the primary SA in the first position... etc.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3324:1395,error,error,1395,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3324,1,['error'],['error']
Availability,"I hit this same segmentation violation issue on 4 separate branches on travis today (I believe in each case only the Java 11 unit test job failed - the rest of the matrix succeeded). It seems to be intermittent since, so far rerunning the job seems to make it go away. . ```; Finished 210000 tests; Finished 220000 tests; Finished 230000 tests; Finished 240000 tests; Finished 250000 tests; Finished 260000 tests; Finished 270000 tests; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x00007f2bcaefd0f2, pid=10075, tid=10100; #; # JRE version: OpenJDK Runtime Environment (11.0.2+9) (build 11.0.2+9); # Java VM: OpenJDK 64-Bit Server VM (11.0.2+9, mixed mode, tiered, compressed oops, g1 gc, linux-amd64); # Problematic frame:; # V [libjvm.so+0x8fd0f2] jni_GetByteArrayElements+0x72; #; # Core dump will be written. Default location: Core dumps may be processed with ""/usr/share/apport/apport %p %s %c %d %P %E"" (or dumping to /home/travis/build/broadinstitute/gatk/core.10075); #; # An error report file with more information is saved as:; # /home/travis/build/broadinstitute/gatk/hs_err_pid10075.log; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; #. Gradle suite > Gradle test > org.broadinstitute.hellbender.utils.pairhmm.VectorPairHMMUnitTest > testLikelihoodsFromHaplotypesForAvailableImplementations SKIPPED; Results: SUCCESS (276386 tests, 276385 successes, 0 failures, 1 skipped). > Task :test FAILED; ```. Entire log is attached. ; [java11segv.txt](https://github.com/broadinstitute/gatk/files/4747769/java11segv.txt)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6649:450,error,error,450,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6649,3,"['error', 'failure']","['error', 'failures']"
Availability,"I just pulled to the latest version and was surprised to see `gradlew clean` not work!; ```; $ ./gradlew clean; (...); Could not find org.broadinstitute:barclay:1.0.0-24-g87c3fa2-SNAPSHOT; ```. Reverting to 1.0.0-17-g30db73c-SNAPSHOT didn't work (same error).; Reverting to 1.0.0 made it fail somewhere else, with:; Could not resolve org.broadinstitute:gatk-bwamem-jni:1.0.0-rc1-SNAPSHOT. What's going on? Is there something wrong with my configuration?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2579:252,error,error,252,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2579,1,['error'],['error']
Availability,"I just tried Mutect2 from GATK 4.1.1.0 and got an error:; ```; A USER ERROR has occurred: standard-min-confidence-threshold-for-calling is not a recognized option; ```. From the [online documentation](https://software.broadinstitute.org/gatk/documentation/tooldocs/4.1.0.0/org_broadinstitute_hellbender_tools_walkers_mutect_Mutect2.php):. > Note that the default was changed from 10.0 to 30.0 in version 4.1.0.0 to accompany the switch to use the the new quality score by default. Thus, it was still maintained in 4.1.0.0. Based on that, I am surprised that it was removed. There are actually a few other parameters that got dropped. For example, `normal-artifact-lod` from `FilterMutectCalls`. Are these changes explained somewhere?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5845:50,error,error,50,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5845,2,"['ERROR', 'error']","['ERROR', 'error']"
Availability,"I just try to run PrintReadsSpark on cloudera cluster and meet this error. Command:; ```; $ ./gatk-launch PrintReadsSpark -I NA12878.chr17_69k_70k.dictFix.bam -O /user/yaron/output.bam -- --sparkRunner SPARK --sparkMaster yarn --num-executors 5 --executor-cores 2 --executor-memory 1g; ```; Results:; ```; Using GATK jar /home/yaron/gatk/build/libs/gatk-spark.jar; Running:; spark-submit --master yarn --conf spark.kryoserializer.buffer.max=512m --conf spark.driver.maxResultSize=0 --conf spark.driver.userClassPathFirst=true --conf spark.io.compression.codec=lzf --conf spark.yarn.executor.memoryOverhead=600 --conf spark.driver.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -Dsnappy.disable=true --conf spark.executor.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -Dsnappy.disable=true --num-executors 5 --executor-cores 2 --executor-memory 1g /home/yaron/gatk/build/libs/gatk-spark.jar PrintReadsSpark -I NA12878.chr17_69k_70k.dictFix.bam -O /user/yaron/output.bam --sparkMaster yarn; 09:14:13.551 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/yaron/gatk/build/libs/gatk-spark.jar!/com/intel/gkl/native/libgkl_compression.so; [June 8, 2017 9:14:13 AM CST] org.broadinstitute.hellbender.tools.spark.pipelines.PrintReadsSpark --output /user/yaron/output.bam --input NA12878.chr17_69k_70k.dictFix.bam --sparkMaster yarn --readValidationStringency SILENT --interval_set_rule UNION --interval_padding 0 --interval_exclusion_padding 0 --bamPartitionSize 0 --disableSequenceDictionaryValidation false --shardedOutput false --numReducers 0 --help false --version false --showHidden false --verbosity INFO --QUIET false --use_jdk_deflater f",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3066:68,error,error,68,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3066,1,['error'],['error']
Availability,"I met this exception when I was trying to run spark commands on a standalone Spark server. I searched for possible causes, and I found two results. One is the spark lacks some jar files to handle the file system. The other says the version of spark on the server is not the same as the one codes are compiled with. ; So for the first one, I tried downloading jars from Zookeeper, Hive and Hbase, and implemented them as said in ""https://stackoverflow.com/questions/34901331/spark-hbase-error-java-lang-illegalstateexception-unread-block-data"", but it doesn't really change anything. ; And for the other one, I tried spark-2.0.0-hadoop-2.6, spark-2.0.0-hadoop-2.7, spark-2.1.1-hadoop-2.7 and spark-1.6.1-hadoop-2.6. But none of them changed the error message. **So I want to ask what version of Spark should I use actually?**. And I will put the error message here:; Using GATK jar /curr/tianj/gatk/build/libs/gatk-spark.jar; Running:; ```; spark-submit --master spark://ip-xxx-xx-xx-xxx:xxxx --conf spark.kryoserializer.buffer.max=512m --conf spark.driver.maxResultSize=0 --conf spark.driver.userClassPathFirst=true --conf spark.io.compression.codec=lzf --conf spark.yarn.executor.memoryOverhead=600 --conf spark.driver.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -Dsnappy.disable=true --conf spark.executor.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -Dsnappy.disable=true /curr/tianj/gatk/build/libs/gatk-spark.jar MarkDuplicatesSpark -I /curr/tianj/data/sortedbam/xx_sort.bam -M xx.m -O xx_markduplicatespark.bam --TMP_DIR tmp --sparkMaster spark://ip-xxx-xx-xx-xxx:xxxx; 00:48:13.577 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/c",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3050:347,down,downloading,347,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3050,4,"['down', 'error']","['downloading', 'error', 'error-java-lang-illegalstateexception-unread-block-data']"
Availability,"I noticed, while looking at https://github.com/broadinstitute/gatk/issues/2713, that the main `GenomicsDBImporter` constructor calls `GenomicsDBImporter.generateSortedCallSetMap()` to download all VCF headers to get the sample names, but it already has the sample names passed in to it (as `variants.keySet()`). This sort of defeats the purpose of the `--sampleNameMap` argument in the `GenomicsDBImport` tool...",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2714:184,down,download,184,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2714,1,['down'],['download']
Availability,"I obtain this reproducible issue with gatk 4.1.2.0:. Using the following code:; ```; wget https://github.com/broadinstitute/picard/releases/download/2.19.0/picard.jar. wget https://github.com/broadinstitute/gatk/releases/download/4.1.2.0/gatk-4.1.2.0.zip; unzip gatk-4.1.2.0.zip. wget -O- ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/000/001/405/GCA_000001405.15_GRCh38/seqs_for_alignment_pipelines.ucsc_ids/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz | \; gzip -d > GCA_000001405.15_GRCh38_no_alt_analysis_set.fna. samtools faidx GCA_000001405.15_GRCh38_no_alt_analysis_set.fna. java -jar picard.jar \; CreateSequenceDictionary \; R=GCA_000001405.15_GRCh38_no_alt_analysis_set.fna \; O=GCA_000001405.15_GRCh38_no_alt_analysis_set.dict. (echo ""##fileformat=VCFv4.2""; \; echo ""##contig=<ID=chrX,length=156040895>""; \; echo -e ""#CHROM\tPOS\tID\tREF\tALT\tQUAL\tFILTER\tINFO""; \; echo -e ""chrX\t1052617\t.\tC\tCAAAGGCTGCAATGTGAATGAATTTTTGGAAATAGCCCTAATGCTCATCTATGAAGGAGTGATAAACACAGCATCCTTTATCCATGCAATGGAATATTATGCAGTCTAGAAAAGGAATAAGGCTCTGACAAAAGACTGCAATATGTATGAATTTTGGAAACAGCCCTACTGCCCATCTATAAAGGAATGGATAAACACAGCATAGTTCATCTATACAATGCAATATTATAATGGAATATTATGCAGCCTGGAACAGGAACAAGGCTCTGAG\t.\t.\t."") | \; bgzip > input.vcf.gz; \; tabix -f input.vcf.gz. (echo -e ""@HD\tVN:1.6\tGO:none\tSO:coordinate""; \; echo -e ""@SQ\tSN:chrX\tLN:156040895""; \; echo -e ""@RG\tID:ID\tPL:ILLUMINA\tPU:ID\tLB:LIBRARY\tSM:SAMPLE"") | \; samtools view -Sb -o input.bam; \; samtools index input.bam. gatk-4.1.2.0/gatk HaplotypeCaller \; -R GCA_000001405.15_GRCh38_no_alt_analysis_set.fna \; -I input.bam \; -O output.vcf.gz \; --genotyping-mode GENOTYPE_GIVEN_ALLELES \; --alleles input.vcf.gz; ```. I get the following error:. ```; java.lang.IllegalArgumentException: Cigar cannot be null; 	at org.broadinstitute.hellbender.utils.read.AlignmentUtils.consolidateCigar(AlignmentUtils.java:716); 	at org.broadinstitute.hellbender.utils.haplotype.Haplotype.setCigar(Haplotype.java:193); 	at org.broadinstitute.hellbender.tools.walker",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6037:140,down,download,140,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6037,6,"['down', 'echo']","['download', 'echo']"
Availability,"I obtain this reproducible issue with gatk 4.1.3.0:. First of all, you have to download the mini input.bam file from this dropbox link: https://www.dropbox.com/sh/78rz5wrhu9zkfzh/AACW9ZPhl4WnD-wmAkKcdHT3a?dl=0. Then setup a GATK working environment:; ```; wget https://github.com/broadinstitute/picard/releases/download/2.19.0/picard.jar. wget https://github.com/broadinstitute/gatk/releases/download/4.1.3.0/gatk-4.1.3.0.zip; unzip gatk-4.1.3.0.zip. wget -O- ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/000/001/405/GCA_000001405.15_GRCh38/seqs_for_alignment_pipelines.ucsc_ids/GCA_000001405\; .15_GRCh38_no_alt_analysis_set.fna.gz | \; gzip -d > GCA_000001405.15_GRCh38_no_alt_analysis_set.fna. samtools faidx GCA_000001405.15_GRCh38_no_alt_analysis_set.fna. java -jar picard.jar \; CreateSequenceDictionary \; R=GCA_000001405.15_GRCh38_no_alt_analysis_set.fna \; O=GCA_000001405.15_GRCh38_no_alt_analysis_set.dict; ```. Now if I run Mutect2:; ```; gatk-4.1.3.0/gatk \; Mutect2 \; -R GCA_000001405.15_GRCh38_no_alt_analysis_set.fna \; -I input.bam \; -O output.vcf.gz \; -L chr1:233443225-233443225; ```. This will generate a VCF file with one variant:; ```; GT:AD:AF:DP:F1R2:F2R1:SB; 0/1:6,21:0.778:27:4,8:0,11:2,4,12,9; ```; With an allelic depth of six supporting the reference. However, there are only four fragments supporting the reference. If I remove those for fragments from the BAM file:; ```; samtools view -h input.bam | \; grep -v "":6112\|:10233\|:18618\|:20229"" | \; samtools view -Sb -o input2.bam && \; samtools index input2.bam; ```. And I run Mutect2 again:; ```; gatk-4.1.3.0/gatk \; Mutect2 \; -R GCA_000001405.15_GRCh38_no_alt_analysis_set.fna \; -I input2.bam \; -O output.vcf.gz \; -L chr1:233443225-233443225; ```. It will generate a VCF with the same variant:; ```; GT:AD:AF:DP:F1R2:F2R1:SB; 0/1:0,20:0.954:20:0,7:0,11:0,0,11,9; ```; With an allelic depth of zero supporting the reference. The same problem exists with the HaplotypeCaller. I believe this was not the intended ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6096:79,down,download,79,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6096,3,['down'],['download']
Availability,"I prepared a clean Bam file following GATK Best Practice and used GATK4 HaplotypeCaller to create a gvcf with ploidy1 option:. '''; gatk-4.0.2.1/gatk HaplotypeCaller --native-pair-hmm-threads 24 -I KU_filtered_sorted_mdup.bam -O HC.KU.raw.snps.indels.g.vcf -R ref.fasta -ploidy 1 --emit-ref-confidence GVCF; '''. When I validated the gvcf, ValidateVariants threw errors at the end:. '''; <br />11:27:55.681 INFO ProgressMeter - Traversal complete. Processed 124689522 total variants in 3.8 minutes.; 11:27:55.681 INFO ValidateVariants - Shutting down engine; [April 10, 2018 11:27:55 AM JST] org.broadinstitute.hellbender.tools.walkers.variantutils.ValidateVariants done. Elapsed time: 3.82 minutes.; Runtime.totalMemory()=4682940416; java.lang.IllegalArgumentException: Illegal character in path at index 15:HC.KU.raw.snps.indels.g.vcf; at java.net.URI.create(URI.java:852); at org.broadinstitute.hellbender.engine.FeatureInput.makeIntoAbsolutePath(FeatureInput.java:242); at org.broadinstitute.hellbender.engine.FeatureInput.toString(FeatureInput.java:314); at java.util.Formatter$FormatSpecifier.printString(Formatter.java:2886); at java.util.Formatter$FormatSpecifier.print(Formatter.java:2763); at java.util.Formatter.format(Formatter.java:2520); at java.util.Formatter.format(Formatter.java:2455); at java.lang.String.format(String.java:2940); at org.broadinstitute.hellbender.engine.FeatureDataSource.close(FeatureDataSource.java:589); at org.broadinstitute.hellbender.engine.FeatureManager.lambda$close$9(FeatureManager.java:505); at java.util.LinkedHashMap$LinkedValues.forEach(LinkedHashMap.java:608); at org.broadinstitute.hellbender.engine.FeatureManager.close(FeatureManager.java:505); at org.broadinstitute.hellbender.engine.GATKTool.onShutdown(GATKTool.java:857); at org.broadinstitute.hellbender.engine.VariantWalker.onShutdown(VariantWalker.java:95); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:138); at org.broadinstitute.hellbender.cm",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4657:363,error,errors,363,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4657,2,"['down', 'error']","['down', 'errors']"
Availability,"I ran 408 invocations of an nio using command for BQSR using gatk4 and got 2 failures that looked pretty similar. Is there something I might be doing wrong? The two failures were also on different shards. . I cant remember exactly when I built this jar but it was after this commit - https://github.com/broadinstitute/gatk/commit/4df1d16518cbd3a05a45a070d682446878ec4eaa less than a week ago. If you need any more info let me know, thanks. ```; Using GATK jar /usr/gitc/gatk4/gatk-package-4.beta.3-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -Dsnappy.disable=true -XX:+PrintFlagsFinal -XX:+PrintGCTimeStamps -XX:+PrintGCDateStamps -XX:+PrintGCDetails -Xloggc:gc_log.log -XX:GCTimeLimit=50 -XX:GCHeapFreeLimit=10 -Xms3000m -jar /usr/gitc/gatk4/gatk-package-4.beta.3-local.jar ApplyBQSR --createOutputBamMD5 --addOutputSAMProgramRecord -R /cromwell_root/broad-references/hg38/v0/Homo_sapiens_assembly38.fasta -I gs://broad-gotc-dev-cromwell-execution/PairedEndSingleSampleWorkflow/4a87f12f-014e-438a-9a10-260c70bf3584/call-SortSampleBam/attempt-4/NA12878.aligned.duplicate_marked.sorted.bam --useOriginalQualities -O NA12878.aligned.duplicates_marked.recalibrated.bam -bqsr /cromwell_root/broad-gotc-dev-cromwell-execution/PairedEndSingleSampleWorkflow/4a87f12f-014e-438a-9a10-260c70bf3584/call-GatherBqsrReports/NA12878.recal_data.csv -SQQ 10 -SQQ 20 -SQQ 30 -L chr5:1+; Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/cromwell_root/tmp.Ni4zSL; [August 22, 2017 2:52:59 PM UTC] ApplyBQSR --output NA12878.aligned.duplicates_marked.recalibrated.bam --bqsr_recal_file /cromwell_root/broad-gotc-dev-cromwell-execution/PairedEndSingleSampleWorkflow/4a87f12f-014e-438a-9a10-260c70bf3584/call-GatherBqsrReports/NA12878.recal_data.csv --useOriginalQualities true --static_quantized_quals 10 --static_quantized_quals 20 --static_quantized_quals 30 --intervals chr5:1+ --input gs",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3481:77,failure,failures,77,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3481,2,['failure'],['failures']
Availability,"I ran CalibrateDragstrModel on one of the NYGC 1000G crams (which should be Functionally Equivalent with ours) and got the error: `A reference must be supplied that includes the reference sequence for chr12` I did pass a reference to the tool, but couldn't get it to run until I set the samjdk.reference_fasta black magic (at @droazen 's suggestion) in the java invocation. Huge stack trace:; java.lang.IllegalArgumentException: java.lang.IllegalArgumentException: java.lang.IllegalArgumentException: A reference must be supplied that includes the reference sequence for chr12).; 	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method); 	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62); 	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45); 	at java.lang.reflect.Constructor.newInstance(Constructor.java:423); 	at java.util.concurrent.ForkJoinTask.getThrowableException(ForkJoinTask.java:593); 	at java.util.concurrent.ForkJoinTask.get(ForkJoinTask.java:1005); 	at org.broadinstitute.hellbender.utils.Utils.runInParallel(Utils.java:1479); 	at org.broadinstitute.hellbender.tools.dragstr.CalibrateDragstrModel.collectCaseStatsParallel(CalibrateDragstrModel.java:473); 	at org.broadinstitute.hellbender.tools.dragstr.CalibrateDragstrModel.traverse(CalibrateDragstrModel.java:152); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1057); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); 	at org.broadinstitute.hellbender.Main.main(Main.java:289); Caus",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7060:123,error,error,123,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7060,1,['error'],['error']
Availability,"I ran GATK 4.1.0.0 Mutect2 on a small (~1Mb) targeted panel. I am using a normal control that is not the same individual (basically to exclude technical artifacts), so I do expect to see more variants than with a proper matched normal. I was getting around 100-300 variants per sample with GATK 4.0.6.0. I am still roughly in the same range for some samples GATK 4.1.0.0, but I am getting 0 for some. The problem seems to be at the FilterMutectCalls stage where I am seeing the following error:; ```; [March 19, 2019 10:43:17 PM EDT] org.broadinstitute.hellbender.tools.walkers.mutect.FilterMutectCalls done. Elapsed time: 0.04 minutes.; Runtime.totalMemory()=8851030016; java.lang.IllegalArgumentException: errorRate must be good probability but got NaN; at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:730); at org.broadinstitute.hellbender.utils.QualityUtils.errorProbToQual(QualityUtils.java:227); at org.broadinstitute.hellbender.utils.QualityUtils.errorProbToQual(QualityUtils.java:211); at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2FilteringEngine.applyContaminationFilter(Mutect2FilteringEngine.java:79); at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2FilteringEngine.calculateFilters(Mutect2FilteringEngine.java:518); at org.broadinstitute.hellbender.tools.walkers.mutect.FilterMutectCalls.firstPassApply(FilterMutectCalls.java:130); at org.broadinstitute.hellbender.engine.TwoPassVariantWalker.lambda$traverseVariants$0(TwoPassVariantWalker.java:76); at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); at java.util.Iterator.forEachRemaining(Iterator.java:116); at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ForEachOps$For",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5821:488,error,error,488,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5821,4,['error'],"['error', 'errorProbToQual', 'errorRate']"
Availability,"I ran IndexFeatureFile on a VCF with a valid header but no variant features. IndexFeatureFile crashes due to something regarding the progress meter. This might be a good place to output one of your helpful `USER ERROR` messages. . Thanks!. ```; acesnik@DESKTOP$ gatk/gatk IndexFeatureFile --feature-file bad.vcf; Using GATK jar gatk/gatk-package-4.0.0.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -jar gatk/gatk-package-4.0.0.0-local.jar IndexFeatureFile --feature-file bad.vcf; 00:17:06.701 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:gatk/gatk-package-4.0.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; 00:17:06.843 INFO IndexFeatureFile - ------------------------------------------------------------; 00:17:06.843 INFO IndexFeatureFile - The Genome Analysis Toolkit (GATK) v4.0.0.0; 00:17:06.844 INFO IndexFeatureFile - For support and documentation go to https://software.broadinstitute.org/gatk/; 00:17:06.845 INFO IndexFeatureFile - Executing as acesnik@DESKTOP-NTA5PMC on Linux v4.4.0-43-Microsoft amd64; 00:17:06.845 INFO IndexFeatureFile - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_161-b12; 00:17:06.846 INFO IndexFeatureFile - Start Date/Time: January 26, 2018 12:17:06 AM GMT; 00:17:06.846 INFO IndexFeatureFile - ------------------------------------------------------------; 00:17:06.846 INFO IndexFeatureFile - ------------------------------------------------------------; 00:17:06.847 INFO IndexFeatureFile - HTSJDK Version: 2.13.2; 00:17:06.847 INFO IndexFeatureFile - Picard Version: 2.17.2; 00:17:06.848 INFO IndexFeatureFile - HTSJDK Defaults.COMPRESSION_LEVEL : 1; 00:17:06.849 INFO IndexFeatureFile - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 00:17:06.849 INFO IndexFeatureFile - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 00:17:06.850 INFO IndexFeatureFile - HTSJ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4269:212,ERROR,ERROR,212,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4269,1,['ERROR'],['ERROR']
Availability,"I ran the full test suite using a [branch](https://github.com/broadinstitute/gatk/tree/cn_check_cache_thrash) that throws if a tool ever tries to query the FeatureCache using a query interval that is earlier than, but on the same contig as, the one currently cached. Several tests failed, including a few of the Mutect2/HC ones:. Mutect2IntegrationTest.testContaminationFilter; Mutect2IntegrationTest.testDreamTumorNormal; Mutect2IntegrationTest.testGivenAllelesMode; Mutect2IntegrationTest.testPon; Mutect2IntegrationTest.testTumorOnly ; HaplotypeCallerIntegrationTest.testGenotypeGivenAllelesMode. The FeatureCache assumes that queries are always increasing along a contig; the failures in this branch indicate that the caller is attempting to back up and re-query territory that has already been cached and then trimmed. I didn't track down all of these cases, but the general pattern appears to be that active region determination results in initial caching and trimming, and then the same/similar territory is traversed again during calling, resulting in cache misses. It happens pretty frequently when running M2 tests, at least for pon and germline resource inputs; we should investigate how much a better caching strategy would help performance. If it would, we'd need https://github.com/broadinstitute/gatk/pull/4902 at a mimimum in order to use a alternate cache strategy.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5148:680,failure,failures,680,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5148,2,"['down', 'failure']","['down', 'failures']"
Availability,"I read the [CNNScoreVariants documentation](https://software.broadinstitute.org/gatk/documentation/tooldocs/current/org_broadinstitute_hellbender_tools_walkers_vqsr_CNNScoreVariants.php#--info-annotation-keys) and ran the ```--help``` option, and both state the following. ```; --info-annotation-keys,-info-annotation-keys:String; 		The VCF info fields to send to python. This argument may be specified 0 or more times.; 		Default value: [MQ, DP, SOR, FS, QD, MQRankSum, ReadPosRankSum]. ; ``` . I successfully executed the CNNScoreVariants command with the default value of the ```--info-annotation-keys``` argument in the following way. ```; --info-annotation-keys '[MQ, DP, SOR, FS, QD, MQRankSum, ReadPosRankSum]' ; ```. However, when I try to change the number of fields, for example like. ```; --info-annotation-keys '[MQ, DP, SOR, FS, QD, MQRankSum]' ; ```. or anything more or less than seven fields I get an error like the following one. ```; Traceback (most recent call last):; 		File ""<stdin>"", line 1, in <module>; 		File ""/opt/miniconda/envs/gatk/lib/python3.6/site-packages/vqsr_cnn/vqsr_cnn/inference.py"", line 127, in score_and_write_batch; 		batch_size=python_batch_size); 		File ""/opt/miniconda/envs/gatk/lib/python3.6/site-packages/keras/engine/training.py"", line 1152, in predict; 		x, _, _ = self._standardize_user_data(x); 		File ""/opt/miniconda/envs/gatk/lib/python3.6/site-packages/keras/engine/training.py"", line 754, in _standardize_user_data; 		exception_prefix='input'); 		File ""/opt/miniconda/envs/gatk/lib/python3.6/site-packages/keras/engine/training_utils.py"", line 136, in standardize_input_data; 		str(data_shape)); 	ValueError: Error when checking input: expected annotations to have shape (7,) but got array with shape (6,); ```. According to the documentation, I should be able to use the argument with an arbitrary number of fields. Is this a bug, or am I using the ```--info-annotation-keys``` argument incorrectly?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5939:917,error,error,917,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5939,2,"['Error', 'error']","['Error', 'error']"
Availability,"I recently noticed a series of what were evidently memory failures when running HaplotypeCaller on some standard test WGS data when using the exact task used in the warp pipeline here: https://github.com/broadinstitute/warp/blob/develop/pipelines/broad/dna_seq/germline/variant_calling/VariantCalling.wdl. I found that running that wdl with otherwise default inputs except for `haplotype_scatter_count` being set to 10 (so each node doing approximately 5x as much work as when the default, 50, is set) I would get repeated HaplotypeCaller job failures after a few hours that had the pattern of memory failures. The errors tend to involve HaplotypeCaller abruptly ending without any sort of error message or exception at all (which could indicate the vm is dying):; ```; 03:22:15.993 INFO ProgressMeter - chr13:18173014 378.6 1419490 3749.0; 03:22:26.338 INFO ProgressMeter - chr13:18177988 378.8 1419530 3747.4; 03:22:36.801 INFO ProgressMeter - chr13:18203610 379.0 1419700 3746.1; (END); ```; Or alternatively it seems to end without the end-of-run messages being output:; ```; 23:05:30.662 INFO ProgressMeter - chr2:47207099 428.8 1372310 3200.4; 23:05:40.859 INFO ProgressMeter - chr2:47323745 429.0 1372960 3200.7; 23:05:50.896 INFO ProgressMeter - chr2:47476709 429.1 1373720 3201.2; Using GATK jar /gatk/gatk-package-4.2.2.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx6933m -Xms6933m -XX:GCTimeLimit=50 -XX:GCHeapFreeLimit=10 -jar /gatk/gatk-package-4.2.2.0-local.jar HaplotypeCaller [INPUTS]; 2022/02/10 23:06:52 Starting delocalization.; 2022/02/10 23:06:53 Delocalization script execution started...; ```. These failures appear to be reproducible and happen at about the same point in every run. The fact that increasing the memory or decreasing the interval per shard seems to remove the issue it makes me suspect there might be an issue where Hapl",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7693:58,failure,failures,58,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7693,5,"['error', 'failure']","['error', 'errors', 'failures']"
Availability,"I run HaplotypeCaller twice , the former one was stopped because of unexpected power outages. I check the LOG and found the chromosome where HaplotypeCaller stopped. So i star another HaplotypeCaller(later one) with the ""-L *.intervals"", it begin from the chromosome where former HaplotypeCaller stopped.The ref genome and the parameters were all the same. However, HaplotypeCaller give different results. Note: the ref genome has 26 chromosomes :A01-A13;D01-D13. **_The former LOG:_**. nohup: ignoring input and appending output to ‘nohup.out’; 09:04:49.857 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/share/home/chenwei/biosoft/gatk-4.0.10.1/gatk-package-4.0.10.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; 09:05:02.971 INFO HaplotypeCaller - ------------------------------------------------------------; 09:05:02.971 INFO HaplotypeCaller - The Genome Analysis Toolkit (GATK) v4.0.10.1; 09:05:02.971 INFO HaplotypeCaller - For support and documentation go to https://software.broadinstitute.org/gatk/; 09:05:02.972 INFO HaplotypeCaller - Executing as chenwei@localhost.localdomain on Linux v3.10.0-1160.31.1.el7.x86_64 amd64; 09:05:02.972 INFO HaplotypeCaller - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_292-b10; 09:05:02.973 INFO HaplotypeCaller - Start Date/Time: August 22, 2021 9:04:49 AM CST; 09:05:02.973 INFO HaplotypeCaller - ------------------------------------------------------------; 09:05:02.973 INFO HaplotypeCaller - ------------------------------------------------------------; 09:05:02.974 INFO HaplotypeCaller - HTSJDK Version: 2.16.1; 09:05:02.974 INFO HaplotypeCaller - Picard Version: 2.18.13; 09:05:02.975 INFO HaplotypeCaller - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 09:05:02.975 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 09:05:02.975 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 09:05:02.975 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBL",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7454:85,outage,outages,85,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7454,1,['outage'],['outages']
Availability,I run `build/install/hellbender/bin/hellbender BaseRecalibrator`; and I get this scary message (notice the three colons (`:`) on that line and lots of UPPERCASE). ```; ***********************************************************************. A USER ERROR has occurred: Invalid command line: Argument RECAL_TABLE_FILE was missing: Argument 'RECAL_TABLE_FILE' is required. ***********************************************************************; ```. I think it should say something like this:. ```; ***********************************************************************. Invalid command line for BaseRecalibrator: Required argument RECAL_TABLE_FILE was missing. Run BaseRecalibrator -h to see all arguments. ***********************************************************************; ```. @vdauwera please weigh in on what's most useful,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/418:248,ERROR,ERROR,248,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/418,1,['ERROR'],['ERROR']
Availability,"I run the BaseRecalibrator,and at fisrt it can good running,after a time,I got this error：; htsjdk.samtools.SAMFormatException: Invalid GZIP header; This is the log:; Using GATK jar /data/home/wuly/soft/GATK4/gatk-4.1.2.0/gatk-package-4.1.2.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx20G -Djava.io.tmpdir=./; -jar /data/home/wuly/soft/GATK4/gatk-4.1.2.0/gatk-package-4.1.2.0-local.jar BaseRecalibrator -R /data/home/wuly/source/Homo_sapiens_assembly38.fasta -I M1.bam --known-sites /data/home/wuly/source/dbsnp_146.hg38.vcf.gz --known-sites /data/home/wuly/source/Mills_and_1000G_gold_standard.indels.hg38.vcf.gz --known-sites /data/home/wuly/source/1000G_phase1.snps.high_confidence.hg38.vcf.gz --known-sites /data/home/wuly/source/hapmap_3.3.hg38.vcf.gz -O M1_recal.table17:55:54.326 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/data/home/wuly/soft/GATK4/gatk-4.1.2.0/gatk-package-4.1.2.0-local.jar!/com/intel/gkl/native/libgkl_compre; ssion.soMay 24, 2019 5:55:56 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 17:55:56.095 INFO BaseRecalibrator - ------------------------------------------------------------; 17:55:56.096 INFO BaseRecalibrator - The Genome Analysis Toolkit (GATK) v4.1.2.0; 17:55:56.096 INFO BaseRecalibrator - For support and documentation go to https://software.broadinstitute.org/gatk/; 17:55:56.096 INFO BaseRecalibrator - Executing as wuly@localhost.localdomain on Linux v3.10.0-957.10.1.el7.x86_64 amd64; 17:55:56.096 INFO BaseRecalibrator - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_192-b01; 17:55:56.096 INFO BaseRecalibrator - Start Date/Time: May 24, 2019 5:55:54 PM EDT; 17:55:56.096 INFO BaseRecalibrator - ------------------------------------------------------------; 17:55:",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5968:84,error,error,84,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5968,1,['error'],['error']
Availability,"I run the GATK MarkDuplicates in Spark mode and it throws an; **NoClassDefFoundError: scala/Product$class**. The GATK version is **4.1.7** and; **4.0.0**,the environment is: **spark-3.0.0**, **scala-2.12.11**. **GATK commands:**. ```; gatk MarkDuplicatesSpark \; -I hdfs://master2:9000/Drosophila/output/Drosophila.sorted.bam \; -O hdfs://master2:9000/Drosophila/output/Drosophila.sorted.markdup.bam \; -M; hdfs://master2:9000/Drosophila/output/Drosophila.sorted.markdup_metrics.txt; \; -- \; --spark-runner SPARK --spark-master spark://master2:7077; ```; **error logs:**. ```; Exception in thread ""main"" java.lang.NoClassDefFoundError:; scala/Product$class; at; org.bdgenomics.adam.serialization.InputStreamWithDecoder.<init>(ADAMKryoRegistrator.scala:35); at; org.bdgenomics.adam.serialization.AvroSerializer.<init>(ADAMKryoRegistrator.scala:45); at; org.bdgenomics.adam.models.VariantContextSerializer.<init>(VariantContext.scala:94); at; org.bdgenomics.adam.serialization.ADAMKryoRegistrator.registerClasses(ADAMKryoRegistrator.scala:179); at; org.broadinstitute.hellbender.engine.spark.GATKRegistrator.registerClasses(GATKRegistrator.java:78); at; org.apache.spark.serializer.KryoSerializer.$anonfun$newKryo$8(KryoSerializer.scala:170); at; org.apache.spark.serializer.KryoSerializer.$anonfun$newKryo$8$adapted(KryoSerializer.scala:170); at scala.Option.foreach(Option.scala:407); at; org.apache.spark.serializer.KryoSerializer.$anonfun$newKryo$5(KryoSerializer.scala:170); at; scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23); at; org.apache.spark.util.Utils$.withContextClassLoader(Utils.scala:221); at; org.apache.spark.serializer.KryoSerializer.newKryo(KryoSerializer.scala:161); at; org.apache.spark.serializer.KryoSerializer$$anon$1.create(KryoSerializer.scala:102); at; com.esotericsoftware.kryo.pool.KryoPoolQueueImpl.borrow(KryoPoolQueueImpl.java:48); at; org.apache.spark.serializer.KryoSerializer$PoolWrapper.borrow(KryoSerializer.scala:109); at; org.apache.spark",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6644:558,error,error,558,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6644,1,['error'],['error']
Availability,"I suspect this may be a somewhat controversial change. One of the issues we face for downsampling in spark is that we need to be able to reproduce the same downsampling behavior at a given site across different partitions/environments. To this end I have implemented the ability to reset the random generator used in the ReservoirDownsampler based on the start position of the next reservoir of reads and the gatk default random seed. I'm interested to know what peoples thoughts are on this change, as theoretically it will make the gatk downsampling the same for each start position in the genome. . Fixes #5437",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5448:85,down,downsampling,85,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5448,3,['down'],['downsampling']
Availability,"I tested this using the following sketchy procedure: I temporarily reverted https://github.com/broadinstitute/gatk/pull/5936 on this branch, thereby re-introducing non-ASCII characters into the source. That builds without error, as it should. Then I temporarily changed the newly added encoding declarations included this PR in build.gradle from ""UTF-8"" to ""US-ASCII"", after which I was able to reproduce exactly the same errors as reported in https://github.com/broadinstitute/gatk/issues/5934, for both compile and gatkDoc tasks. So I think these changes achieve the desired result (accept UTF-8 in source).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5946:222,error,error,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5946,2,['error'],"['error', 'errors']"
Availability,"I think CollectSequencingArtifactMetrics requires a reference, but the documentation lists it as optional. Without reference, I get an instant crash. I also get NullPointer exceptions when proving --DB_SNP. . ```; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -Dsnappy.disable=true -jar /home/riestma1/gatk-4.beta.3/gatk-package-4.beta.3-local.jar CollectSequencingArtifactMetrics --input sample1.bam --output sample1_pre_adapter_detail_metrics; ...; 18:06:26.220 INFO CollectSequencingArtifactMetrics - Shutting down engine; [July 26, 2017 6:06:26 PM EDT] org.broadinstitute.hellbender.tools.picard.analysis.artifacts.CollectSequencingArtifactMetrics done. Elapsed time: 0.02 minutes.; Runtime.totalMemory()=1517289472; java.lang.NullPointerException; 	at org.broadinstitute.hellbender.tools.picard.analysis.artifacts.CollectSequencingArtifactMetrics.acceptRead(CollectSequencingArtifactMetrics.java:214); 	at org.broadinstitute.hellbender.tools.picard.analysis.SinglePassSamProgram.makeItSo(SinglePassSamProgram.java:114); 	at org.broadinstitute.hellbender.tools.picard.analysis.SinglePassSamProgram.doWork(SinglePassSamProgram.java:53); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:116); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:173); 	at org.broadinstitute.hellbender.cmdline.PicardCommandLineProgram.instanceMain(PicardCommandLineProgram.java:62); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:131); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:152); 	at org.broadinstitute.hellbender.Main.main(Main.java:233); ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3362:637,down,down,637,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3362,1,['down'],['down']
Availability,"I think this user report sums it up nicely. ----; User Report; ----. In my BASH scripts I often use ""$?"" to monitor the exit status of a process and normally stop if there is an error. However, I am using the latest version of GATK (4.0.0.0) and some tools return 0 exit status even if they fail. Instead, they display the following message to STDOUT:; ; Tool returned:; 1. Though inconvenient for error handling in BASH scripts, this might be an intended behaviour, but not all tools exhibit it. To mention a few, MarkDuplicates, CollectMultipleMetrics, CollectGcBiasMetrics always have a 0 exit status, whereas VariantsToTable or CountVariants do return 1 if they encounter an error. . A similar issue had been reported in the past for previous versions of GATK (https://gatkforums.broadinstitute.org/gatk/discussion/8618/error-handling-end-exit-codes-in-gatk). Best regards,. Roger. This Issue was generated from your [forums] ; [forums]: https://gatkforums.broadinstitute.org/gatk/discussion/11414/exit-codes-in-gatk-4-0/p1",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4433:178,error,error,178,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4433,4,['error'],"['error', 'error-handling-end-exit-codes-in-gatk']"
Availability,"I think this user sums it up nicely:. ""Unless I am missing something, the current set up in GATK 4.0 is not ideal for routine sequencing. First, I need to combine all animals every time a new batch of data is added (rather than adding a batch to existing database). Second, if I decide to use combineGVCFs in GATK 4.0, I have to run it twice, first to combine the new cohort, then to combine the new cohort with older animals so that I have 1 file to feed to genotypegVCF. . As such I am now reverting back to GATK 3.6. It would be very nice if genomicDBimport allowed addition of new data to existing database, and/or genotypegVCF allowed multiple gVCFs."". ----; User Report; ----. This is the error message I am getting but it doesn't make much sense, given that I got it also on smaller datasets with large amounts of memory (larger than some of the specifications listed on this forum for genomicDBimport). Our IT people, after observing the job, seem to think this is a java-related bug as the process itself doesn't use anywhere near the memory specified. We have installed a new version of java and I will be re-running the analysis to see if this solved the issues. . I'm not sure if I should be creating a new thread for this, but I do have a general comment about genomicDBimport. The project I am involved with is in partnership with an industrial partner, who sequences a number of animals every few weeks. In the pipeline using GATK 3.6, the newly sequenced animals were combined using combinegVCF and multiple gVCFs were then fed into genotypeGVCFs. . Unless I am missing something, the current set up in GATK 4.0 is not ideal for routine sequencing. First, I need to combine all animals every time a new batch of data is added (rather than adding a batch to existing database). Second, if I decide to use combineGVCFs in GATK 4.0, I have to run it twice, first to combine the new cohort, then to combine the new cohort with older animals so that I have 1 file to feed to genotypegVCF. .",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4667:695,error,error,695,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4667,1,['error'],['error']
Availability,I took my bam files that were giving this error and removed the secondary alignments (samtools view -F 256) and ran them again through Mutect2 4.1.4. I didn't get this error now. Does that mean that Mutect2 uses secondary alignments in its calling algorithm normally? BWA generates secondary alignments by default and doesn't have an option to turn them off. This Issue was generated from your [forums] ; [forums]: https://gatkforums.broadinstitute.org/gatk/discussion/comment/61300#Comment_61300,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6230:42,error,error,42,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6230,2,['error'],['error']
Availability,"I tried running MarkDuplicatesSpark with multiple inputs like it is run in production and got this user error. ```; A USER ERROR has occurred: Sorry, we only support a single reads input for spark tools for now.; ```. For this to go into production it would need to have the ability to take in multiple inputs (I'm currently trying to make a ""fast"" version of the production germline pipeline and it would be great to have this tool included in that pipeline). @jamesemery",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5398:104,error,error,104,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5398,2,"['ERROR', 'error']","['ERROR', 'error']"
Availability,"I tried to run VariantRecalibrator using the args echoed from an integration test and found that the resource files weren't listed properly. The command in the test was ` "" --resource known,known=true,prior=10.0:"" + getLargeVQSRTestDataDir() + ""dbsnp_132_b37.leftAligned.20.1M-10M.vcf""` and what came out of the engine was `--resource known:/Users/gauthier/workspaces/gatk/src/test/resources/large/VQSR/dbsnp_132_b37.leftAligned.20.1M-10M.vcf`, so it lost the known=true and the prior which makes the command line unrunnable. Probably affects #2269 too. This behavior can be replicated by running any of the VariantRecalibration integration tests and checking the console output.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3247:50,echo,echoed,50,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3247,1,['echo'],['echoed']
Availability,I use these steps to produce variant calls for haploid data:; HaplotypeCaller in GVCF mode -> CombineGVCFs -> GenotypeGVCFs; and I then create a snpmask file by adding to it any sites I don't want and keep all called SNPs and INDELs inside per sample vcf files. I then try to create a consensus sequence by running in GATK v 4.2.1.0:. ```; gatk FastaAlternateReferenceMaker \; -R myref.fasta \; -V persamplevariants.vcf \; -O new.fasta \; --line-width 80 \; --snp-mask mask.vcf \; --snp-mask-priority ; ```. But I get this error:. ```; java.lang.IllegalArgumentException: Illegal base [ ] seen in the allele; 	at htsjdk.variant.variantcontext.Allele.create(Allele.java:251); 	at htsjdk.variant.variantcontext.Allele.create(Allele.java:402); 	at org.broadinstitute.hellbender.tools.walkers.fasta.FastaAlternateReferenceMaker.lambda$handlePosition$0(FastaAlternateReferenceMaker.java:176); 	at java.util.Optional.orElseGet(Optional.java:267); 	at org.broadinstitute.hellbender.tools.walkers.fasta.FastaAlternateReferenceMaker.handlePosition(FastaAlternateReferenceMaker.java:176); 	at org.broadinstitute.hellbender.tools.walkers.fasta.FastaAlternateReferenceMaker.apply(FastaAlternateReferenceMaker.java:141); 	at org.broadinstitute.hellbender.engine.ReferenceWalker.traverse(ReferenceWalker.java:55); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1085); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); 	at org.broadinstitute.hellbender.Main.main(Main.java:289); ```. By narrowing down on where this happens I find it happens here:. ```; chrom	16798	.	TAGC	*	41.94,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7433:464,mask,mask,464,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7433,4,"['error', 'mask']","['error', 'mask', 'mask-priority']"
Availability,"I used HaplotypeCaller (-ERC GVCF) to generate a few hundred GVCF files (see a section below, Fig. 1; ![Fig1](https://user-images.githubusercontent.com/15146751/85318178-27d2d500-b485-11ea-8efb-a92bdad2cc1d.png); ). Then I was trying to use GenomicsDBImport to generate the datastore to be further processed by GenotypeGVCFs:; `gatk --java-options ""-Xmx10g -Xms10g"" GenomicsDBImport \; --genomicsdb-workspace-path /home/zhen.fu/fu_scratch/Helico/genotye/chr1 \; --batch-size 30 \; -L HaChr01 \; --sample-name-map sample_map_file \; --tmp-dir=/home/zhen.fu/fu_scratch/Helico/genotye/tmp \; --reader-threads 2; `. However, I realized that GenomicsDBImport seemed to only recognize ""GT:DP:GQ:MIN_DP:PL"", where ALT field is <NON_REF> for these sites. Conversely, GenomicsDBImport did not recognize the features in the true variant sites, where a true variant and <NON_REF> coexist, such as ""GT:AD:DP:GQ:PL:SB"". As GVCF records all sites, including the variant and non-variant sites. . The error I got was:; ![Fig2](https://user-images.githubusercontent.com/15146751/85318248-3f11c280-b485-11ea-9c5e-71f01b8db1d9.png). The GenomicsDBImport would only process the first batch (30 samples) and not going further. ; The version I am using is GATK 4.15",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6670:985,error,error,985,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6670,1,['error'],['error']
Availability,"I used newly GATK4.1 version, and my scripts are:. java -Xmx300g -jar $GATK Mutect2 \; --dont-use-soft-clipped-bases true \; --tmp-dir $cw/$i/tmp \; --input $DNAbam/ADAR16-DNA-2_NKD180600323/ADAR16-DNA-2_NKD180600323.best.uniq.pair.sort.markdup.bam \; --input $RNAbam/$i/$i.merge.markdup.reheader.bam \; --reference $genome\; --output $cw/$i/$i.dna.rna.vcf \; --normal-sample ADAR16-DNA-2_NKD180600323 \; --tumor-sample $i \; -bamout $cw/$i/$i.support.bam. and tail of error log are:. 12:05:06.287 INFO ProgressMeter - scaffold23905:111448 948.1 636040 670.9; 12:05:30.519 INFO ProgressMeter - scaffold23905:133852 948.5 636120 670.7; 12:05:57.277 INFO ProgressMeter - scaffold23905:147186 949.0 636170 670.4; 12:24:34.669 INFO PairHMM - Total compute time in PairHMM computeLogLikelihoods() : 31261.455155273; 12:24:34.670 INFO SmithWatermanAligner - Total compute time in java Smith-Waterman : 14618.28 sec; INFO	2019-04-13 12:45:11	SortingCollection	Creating merging iterator from 2 files; 13:30:49.708 INFO Mutect2 - Shutting down engine; [April 13, 2019 1:30:49 PM CST] org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2 done. Elapsed time: 1,035.35 minutes.; Runtime.totalMemory()=238653800448; Exception in thread ""main"" java.lang.OutOfMemoryError: Java heap space; 	at java.util.Arrays.copyOf(Arrays.java:3332); 	at java.lang.AbstractStringBuilder.expandCapacity(AbstractStringBuilder.java:137); 	at java.lang.AbstractStringBuilder.ensureCapacityInternal(AbstractStringBuilder.java:121); 	at java.lang.AbstractStringBuilder.append(AbstractStringBuilder.java:421); 	at java.lang.StringBuilder.append(StringBuilder.java:136); 	at htsjdk.samtools.SAMTextHeaderCodec.advanceLine(SAMTextHeaderCodec.java:142); 	at htsjdk.samtools.SAMTextHeaderCodec.decode(SAMTextHeaderCodec.java:97); 	at htsjdk.samtools.reference.ReferenceSequenceFileFactory.loadDictionary(ReferenceSequenceFileFactory.java:235); 	at htsjdk.samtools.reference.AbstractFastaSequenceFile.(AbstractFastaSequenceFile.java:68)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5900:469,error,error,469,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5900,1,['error'],['error']
Availability,"I want to filter SNP, but encountered this error. Can anyone help me resolve this error. thanks .; zhang. `##### ERROR ------------------------------------------------------------------------------------------; ##### ERROR A USER ERROR has occurred (version 3.8-1-0-gf15c1c3ef): ; ##### ERROR; ##### ERROR This means that one or more arguments or inputs in your command are incorrect.; ##### ERROR The error message below tells you what is the problem.; ##### ERROR; ##### ERROR If the problem is an invalid argument, please check the online documentation guide; ##### ERROR (or rerun your command with --help) to view allowable command-line arguments for this tool.; ##### ERROR; ##### ERROR Visit our website and forum for extensive documentation and answers to ; ##### ERROR commonly asked questions https://software.broadinstitute.org/gatk; ##### ERROR; ##### ERROR Please do NOT post this error to the GATK forum unless you have really tried to fix it yourself.; ##### ERROR; ##### ERROR **MESSAGE: Bad input: The clustered SNPs filter does not work in the presence of non-variant records; see the** documentation for more details; ##### ERROR ------------------------------------------------------------------------------------------; `",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7042:43,error,error,43,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7042,21,"['ERROR', 'error']","['ERROR', 'error']"
Availability,"I wanted to detect variants with HaplotypeCaller（GATK version 4.1.1.0）, i run the program twice with two reference.fa, and i got so different results. The content of this two reference.fa is same and they are in the same version of soybean (Gmax_275_v2.0.fa). The differences of this two reference.fa are as below:; 1.This two reference.fa were downloaded from different databases;; 2.the order of scaffold is different, one is in the number order (just like scaffold_1, scaffold_2, scaffold_ 3, scaffold_4...),and the other one is in the dictionary order(just like scaffold_1002, scaffold_1005, scaffold_101, scaffold_1010...);; 3.the coding method is different, one was coded with upper and lower letters (like ATGGccatgataGGTCaatgca), and the other one was coded only with upper words (like ATGGCCATGATAGGTCAATGCA). . I compared the coding bases of this two reference.fa, totally same, but when i run HaplotypeCaller with this two reference.fa, i got a very different result, so i am wondering, if results of HaplotypeCaller can be affected by the the scaffold order and the lower or upper letters in the reference.fa file?. ### Instructions. The github issue tracker is for bug reports, feature requests, and API documentation requests. General questions about how to use the GATK, how to interpret the output, etc. should be asked on the [official support forum](http://gatkforums.broadinstitute.org/gatk).; - Search the existing github issues to see if your issue (or something similar) has already been reported. If the issue already exists, you may comment there to inquire about the progress.; - Determine whether your issue is a **bug report**, a **feature request**, or a **documentation request** (for tool/class javadoc only -- for forum docs please post there); - Consider if your ""issue"" is better addressed on the GATK forum: http://gatkforums.broadinstitute.org/gatk Post there if you have questions about expected tool behavior, output format, unexpected results, or generally any qu",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6825:345,down,downloaded,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6825,1,['down'],['downloaded']
Availability,"I was able to replicate the users error with GATK4.1.1.0 and the latest build on Nov21. The users data is on the FTP as livinlrg_Problem_Interval. . Running SelectVariants on the same data generates the same error as GenomicsDBImport. ```; /home/tools/gatk/gatk SelectVariants --java-options ""-Xmx20g"" -R /home/test/livinlrg_Problem_Interval/Reference/sacCer3_2micron.fasta -V gendb:///home/test/livinlrg_Problem_Interval/GenomicsDB_ProblemInterval_Test -O /home/test/livinlrg_Problem_Interval/work_dir/selectvariantsout.vcf. WARNING: No valid combination operation found for INFO field MLEAF - the field will NOT be part of INFO fields in the generated VCF records; 14:28:46.814 INFO ProgressMeter - chrI:2000 0.2 2000 10258.2; 14:29:00.359 INFO ProgressMeter - chrI:6003 0.4 6000 14261.4; 14:29:28.258 INFO SelectVariants - Shutting down engine; GENOMICSDB_TIMER,GenomicsDB iterator next() timer,Wall-clock time(s),37.44650732699998,Cpu time(s),37.414083634000015; [November 21, 2019 2:29:29 PM UTC] org.broadinstitute.hellbender.tools.walkers.variantutils.SelectVariants done. Elapsed time: 0.92 minutes.; Runtime.totalMemory()=1783103488; htsjdk.tribble.TribbleException: Invalid block size -1539959833; at htsjdk.variant.bcf2.BCF2Decoder.readNextBlock(BCF2Decoder.java:66); at htsjdk.variant.bcf2.BCF2Codec.decode(BCF2Codec.java:134); at htsjdk.variant.bcf2.BCF2Codec.decode(BCF2Codec.java:58); at org.genomicsdb.reader.GenomicsDBFeatureIterator.next(GenomicsDBFeatureIterator.java:181); at org.genomicsdb.reader.GenomicsDBFeatureIterator.next(GenomicsDBFeatureIterator.java:49); at java.util.Iterator.forEachRemaining(Iterator.java:116); at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150); at java.util.stream.ForEachOps$F",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6275:34,error,error,34,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6275,3,"['down', 'error']","['down', 'error']"
Availability,"I was developing a `LocusWalker` (#1707) when I found that if several BAM files are provided, the `LocusIteratorByState` (LIBS) returns only a `AlignmentContext` with associated `ReadPileup` with only one sample. I realized that in the LIBS there is a commented exception thrown about that multi-sample is not supported. Because it is commented, the LIBS is providing an `AlignmentContext` for the next sample if the first of them does not have coverage. This is misleading for an API user (it took me some time to understand where the error comes from). I was thinking to do a pull request (or include this in #1707) to solve the issue. There are two ways of doing this:; - As in GATK3, implement an internal `PerSampleReadPileup` that extends the `ReadPileup` and provides an efficient way of separate sample-specific pileups.; - If there is no plan to support multi-sample pileups (I'm worried about this, because I will need it), construct the `AlignmentContext` in the LIBS from all samples. Then, the method `makeFilteredPileup` could be used to extract (in a complicated way) a per-sample pileup by the user side. Because the current implementation was done by @akiezun, could you please give me some feedback? I will need it for my stuff, and I will be very grateful if I can solve this as soon as possible...",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1752:536,error,error,536,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1752,1,['error'],['error']
Availability,I was getting a SQL syntax error before making this change.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7050:27,error,error,27,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7050,1,['error'],['error']
Availability,I was running : java -jar /Users/mac/Downloads/picard-2.jar AddOrReplaceReadGroups I=/Users/mac/Desktop/NGS-/SRR6369642-pe.bam O=/Users/mac/Desktop/NGS-/SRR6369642-pe-RG.bam RGID=C7BDWACXX.5 RGLB=Lmj_A445_EP+3.2_run1 RGPL=Illumina RGPU=C7BDWACXX.5 RGSM=NO8162944 . I get :00:13:06.733 INFO NativeLibraryLoader - Loading libgkl_compression.dylib from jar:file:/Users/mac/Downloads/picard-2.jar!/com/intel/gkl/native/libgkl_compression.dylib; [Tue Sep 08 00:13:07 WEST 2020] AddOrReplaceReadGroups INPUT=/Users/mac/Desktop/NGS-/SRR6369642-pe.bam OUTPUT=/Users/mac/Desktop/NGS-/SRR6369642-pe-RG.bam RGID=C7BDWACXX.5 RGLB=Lmj_A445_EP+3.2_run1 RGPL=Illumina RGPU=C7BDWACXX.5 RGSM=NO8162944 VERBOSITY=INFO QUIET=false VALIDATION_STRINGENCY=STRICT COMPRESSION_LEVEL=5 MAX_RECORDS_IN_RAM=500000 CREATE_INDEX=false CREATE_MD5_FILE=false GA4GH_CLIENT_SECRETS=client_secrets.json USE_JDK_DEFLATER=false USE_JDK_INFLATER=false; [Tue Sep 08 00:13:07 WEST 2020] Executing as mac@MacBook-Air-de-mac.local on Mac OS X 10.15.6 x86_64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_65-b17; Deflater: Intel; Inflater: Intel; Provider GCS is not available; Picard version: 2.23.0; INFO	2020-09-08 00:13:08	AddOrReplaceReadGroups	Created read-group ID=C7BDWACXX.5 PL=Illumina LB=Lmj_A445_EP+3.2_run1 SM=NO8162944. INFO	2020-09-08 00:13:08	AddOrReplaceReadGroups	Seen many non-increasing record positions. Printing Read-names as well.; fatal error . the first time is was sorting ana indexing when I do it again I get this error how should I fix it !!,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6797:37,Down,Downloads,37,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6797,5,"['Down', 'avail', 'error']","['Downloads', 'available', 'error']"
Availability,"I was running BaseRecalibrator with an --interval of GL00207.1:1+ and received this error:. A USER ERROR has occurred: The file GL000207.1:1+ does not exist. It seems like if the contig name has a '.' in it, it thinks it should be looking for a file. This worked for all other contigs that did not have a '.' in the name and it didn't complain about the Y or MT contigs that come before GL00207.1 in the full command:. org.broadinstitute.hellbender.tools.walkers.bqsr.BaseRecalibrator --useOriginalQualities true --knownSites /cromwell_root/broad-gitc-reference/hg19/Homo_sapiens_assembly19.dbsnp138.vcf --knownSites /cromwell_root/broad-gitc-reference/hg19/Mills_and_1000G_gold_standard.indels.b37.sites.vcf --knownSites /cromwell_root/broad-gitc-reference/hg19/Homo_sapiens_assembly19.known_indels_20120518.vcf --output NA12878.recal_data.csv --intervals Y:1+ --intervals MT:1+ --intervals GL000207.1:1+ --intervals GL000226.1:1+ --intervals GL000229.1:1+ --intervals GL000231.1:1+ --intervals GL000210.1:1+ --intervals GL000239.1:1+ --intervals GL000235.1:1+ --intervals GL000201.1:1+ --intervals GL000247.1:1+ --intervals GL000245.1:1+ --intervals GL000197.1:1+ --intervals GL000203.1:1+ --intervals GL000246.1:1+ --intervals GL000249.1:1+ --intervals GL000196.1:1+ --intervals GL000248.1:1+ --intervals GL000244.1:1+ --intervals GL000238.1:1+ --intervals GL000202.1:1+ --intervals GL000234.1:1+ --intervals GL000232.1:1+ --intervals GL000206.1:1+ --intervals GL000240.1:1+ --intervals GL000236.1:1+ --intervals GL000241.1:1+ --intervals GL000243.1:1+ --intervals GL000242.1:1+ --intervals GL000230.1:1+ --intervals GL000237.1:1+ --intervals GL000233.1:1+ --intervals GL000204.1:1+ --intervals GL000198.1:1+ --intervals GL000208.1:1+ --intervals GL000191.1:1+ --intervals GL000227.1:1+ --intervals GL000228.1:1+ --intervals GL000214.1:1+ --intervals GL000221.1:1+ --intervals GL000209.1:1+ --intervals GL000218.1:1+ --intervals GL000220.1:1+ --intervals GL000213.1:1+ --intervals GL000211.1:1+ --i",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1626:84,error,error,84,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1626,2,"['ERROR', 'error']","['ERROR', 'error']"
Availability,"I was running this cmd : ; I get : java -jar /Users/mac/Downloads/picard-2.jar AddOrReplaceReadGroups I=/Users/mac/Desktop/NGS-/SRR6369642-pe.bam O=/Users/mac/Desktop/NGS-/SRR6369642-pe-RG.bam RGID=C7BDWACXX.5 RGLB=Lmj_A445_EP+3.2run1 RGPL=Illumina RGPU=C7BDWACXX.5 RGSM=NO8162944. record positions. Printing Read-names as well.; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x000000010d32bea7, pid=1681, tid=6403; #; # JRE version: Java(TM) SE Runtime Environment (8.0_65-b17) (build 1.8.0_65-b17); # Java VM: Java HotSpot(TM) 64-Bit Server VM (25.65-b01 mixed mode bsd-amd64 compressed oops); # Problematic frame:; # C [libgkl_compression7875913179822684367.dylib+0x6ea7] deflate_medium+0x867; #; # Failed to write core dump. Core dumps have been disabled. To enable core dumping, try ""ulimit -c unlimited"" before starting Java again; #; # An error report file with more information is saved as:; # /Users/mac/Desktop/NGS-/hs_err_pid1681.log; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; # The crash happened outside the Java Virtual Machine in native code.; # See problematic frame for where to report the bug.; #; Abort trap: 6. how can I fix it",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6796:56,Down,Downloads,56,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6796,3,"['Down', 'error']","['Downloads', 'error']"
Availability,"I was running this following CML :; java -Xmx8G -jar /Users/mac/Downloads/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar VariantFiltration \ -R /Users/mac/Desktop/LmjFwholegenome_20070731_V5.2.fasta \ -V /Users/mac/Desktop/NGS-/57variants.vcf \ -o /Users/mac/Desktop/NGS-/59varians_filt.vcf \ --filter-expression ""QD < 2.0 || MQ > 50"" \ --filter-name ""hard_filtering_snp and I get : A USER ERROR has occurred: Illegal argument value: Positional arguments were provided ', -R{/Users/mac/Desktop/LmjFwholegenome_20070731_V5.2.fasta{ -V{/Users/mac/Desktop/NGS-/57variants.vcf{ -o{/Users/mac/Desktop/NGS-/59varians_filt.vcf{ --filter-expression{QD < 2.0 || MQ > 50{ }' but no positional argument is defined for this tool; how should I fix it and get a filter files ?!",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6789:64,Down,Downloads,64,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6789,2,"['Down', 'ERROR']","['Downloads', 'ERROR']"
Availability,"I was trying to use SVAnnotate to generate annotation for my own `vcf` file:; ```; $java17 -jar $gatkjar SVAnnotate -V 31354420/250000.vcf --protein-coding-gtf $newgtf_path -O 31354420/annotated_250000.vcf; ```; However, I got the following error message:; ```bash; java.lang.NullPointerException: Cannot invoke ""org.broadinstitute.hellbender.utils.codecs.gtf.GencodeGtfGeneFeature.addTranscript(org.banscriptFeature)"" because ""gene"" is null; at org.broadinstitute.hellbender.utils.codecs.gtf.AbstractGtfCodec.aggregateRecordsIntoGeneFeature(AbstractGtfCodec.java:339); at org.broadinstitute.hellbender.utils.codecs.gtf.AbstractGtfCodec.decode(AbstractGtfCodec.java:170); at org.broadinstitute.hellbender.utils.codecs.gtf.AbstractGtfCodec.decode(AbstractGtfCodec.java:23); at htsjdk.tribble.TribbleIndexedFeatureReader$WFIterator.readNextRecord(TribbleIndexedFeatureReader.java:376); at htsjdk.tribble.TribbleIndexedFeatureReader$WFIterator.<init>(TribbleIndexedFeatureReader.java:343); at htsjdk.tribble.TribbleIndexedFeatureReader.iterator(TribbleIndexedFeatureReader.java:310); at org.broadinstitute.hellbender.engine.FeatureDataSource.iterator(FeatureDataSource.java:531); at org.broadinstitute.hellbender.tools.walkers.sv.SVAnnotate.buildIntervalTreesFromGTF(SVAnnotate.java:297); at org.broadinstitute.hellbender.tools.walkers.sv.SVAnnotate.onTraversalStart(SVAnnotate.java:227); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1096); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:149); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:198); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:217); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289); ```. Seems like these ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8394:241,error,error,241,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8394,1,['error'],['error']
Availability,I was wondering what version of Picard is bundled with GATK. I assume it's the latest available (2.18.4 at this time) but apparently there's no way to tell:; `$ gatk MergeSamFiles -version` output `Version:4.0.4.0`,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4733:86,avail,available,86,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4733,1,['avail'],['available']
Availability,"I would be useful to be able to explicitly indicate the Codec class for a FeatureInputs perhaps using an annotation. . Currently the feature manager tries every possible codec hoping to find one and only one that answers yes to the canDecode(FileName) method call. If none does execution fails saying that there is no code available to deal with the input file; if more than one codec returns true then is supposed to throw another error indicating the ambiguity. The former is likely an user cased error whereas the later is rather a bug as Codec developers seems to be responsible to make sure that such a collision never happens... This has a few draw backs:; - Seems to quasi-force to establish a 1-to-1 assignation of Codecs and file extension names; canDecode documentation encourages use the file name as the way to determine whether the codec can decode or not the file. What if the file is a simple tab separated value file (with some column count and format constrains) and general extensions such as .tab or .tsv seem acceptable names in practice?; - The error message when there is no supporting code does not tell what the problem is; whether the extension of the file (due to the the 1-to-1 name to type quasi-restriction above) or a more complex formatting issue in the file (e.g. required header missing, version not supported ... blah blah). ; - All codecs are tried out even when most won't ever apply. Even if the performance impact should in practice be minimal still may cause several file IO open operations as several Codec do actually peek into the file (e.g. BCF and VCF codecs). ; - Codec developers have to make sure their new codec does not collides with others; it would be better if codec development can be totally independent.; - General file extensions such as .tab , .tsv cannot be used by codecs due to possible collisions constraining users to name their files the way GATK needs them to; ""I don't like people telling what file names a have to use... I'm already pl",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1184:323,avail,available,323,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1184,3,"['avail', 'error']","['available', 'error']"
Availability,"I would like to have a look to #3447 and review it because it is quite important for downstream projects. But GitHub just show a fancy unicorn saying that ""This page is taking way too long to load"". . I wonder if this is a problem only for me, and if something can be done to be able to review before accepting it. Do you have any idea of why this is happening? @droazen or @jonn-smith, could you help me here? I would like to review before it gets in, for have minimal effects in downstream projects like mine...",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3945:85,down,downstream,85,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3945,2,['down'],['downstream']
Availability,"I'll be adding documented feature tags to the 57 annotation modules. Before I get to these, I need a new ANNOTATORS category to exist in HelpConstants.java. . I've taken the liberty to name the category ANNOTATORS. Here is the relevant info I added to HelpConstants.java:. - group name variable and descriptor: DOC_CAT_ANNOTATORS = ""Annotation Modules""; - group summary variable and descriptor: DOC_CAT_ANNOTATORS_SUMMARY = ""Annotations available to HaplotypeCaller, Mutect2 and VariantAnnotator""; - super category: Utilities (same group as read filters)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3835:437,avail,available,437,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3835,1,['avail'],['available']
Availability,"I'm almost certain this used to work. ```; ./bin/gatk/gatk-launch FlagStatSpark -I file:///local/dev/akiezun/bin/gatk/src/test/resources/org/broadinstitute/hellbender/tools/valid.bam -- --sparkRunner SPARK --sparkMaster yarn-client; ```. the error is . ```; java.lang.IllegalArgumentException: Wrong FS: file:/local/dev/akiezun/bin/gatk/src/test/resources/org/broadinstitute/hellbender/tools/valid.bam, expected: hdfs://dataflow01.broadinstitute.org:8020; at org.apache.hadoop.fs.FileSystem.checkPath(FileSystem.java:654); at org.apache.hadoop.fs.FileSystem.makeQualified(FileSystem.java:474); at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSource.getHeader(ReadsSparkSource.java:181); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.initializeReads(GATKSparkTool.java:284); ```. It's fine when running a LOCAL runner, or when the file is on HDFS. . When resolving the ticket, make sure to devise a way (or at least enter a ticket) to prevent this from happening again - ie some way to discover this kind of problem.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1417:242,error,error,242,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1417,1,['error'],['error']
Availability,I'm getting a type error here because L278 expects a string for `POSSIBLE_GERMLINE` but `pandas.read_csv` returns a `float64` for this column.; https://github.com/broadinstitute/gatk/blob/d4db277dfa1a9c13188644fd28616249061f8704/scripts/unsupported/combine_tracks_postprocessing_cnv/combine_tracks.wdl#L277-L278,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5360:19,error,error,19,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5360,1,['error'],['error']
Availability,"I'm missing the possibility of tuning the logging to produce TRACE level log messages. As it is stands the users only can choose down to DEBUG. . It seems that this is due to the integration of several logging systems from old GATK, htjsdk and picard where DEBUG the lowest common level. . It would be great to have the ability to produce TRACE level log messages allowing the user to have control on whether these are output or not. . In this case DEBUG log messages that are going to be produced in big numbers should be TRACE whereas unfrequent (one very 5 second or more) would stay as DEBUG.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6378:129,down,down,129,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6378,1,['down'],['down']
Availability,"I'm pretty sure this is a hadoop-bam issue, but I'm finding that any BAM produced by bwa (VN 0.7.16a-r1181) will not load in Spark. The BAM loads successfully in ValidateSamFile (although it throws errors because there are no RGs). Running it through AddOrReplaceReadGroups makes the error go away. Attempting to load from local disk gives the following error:. `htsjdk.samtools.SAMFormatException: Does not seem like a BAM file; 	at org.seqdoop.hadoop_bam.BAMSplitGuesser.<init>(BAMSplitGuesser.java:88); 	at org.seqdoop.hadoop_bam.BAMInputFormat.addProbabilisticSplits(BAMInputFormat.java:228); 	at org.seqdoop.hadoop_bam.BAMInputFormat.getSplits(BAMInputFormat.java:155); 	at org.seqdoop.hadoop_bam.AnySAMInputFormat.getSplits(AnySAMInputFormat.java:252); 	at org.apache.spark.rdd.NewHadoopRDD.getPartitions(NewHadoopRDD.scala:121); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:248); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:246); 	at scala.Option.getOrElse(Option.scala:121); 	at org.apache.spark.rdd.RDD.partitions(RDD.scala:246); 	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:248); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:246); 	at scala.Option.getOrElse(Option.scala:121); 	at org.apache.spark.rdd.RDD.partitions(RDD.scala:246); 	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:248); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:246); 	at scala.Option.getOrElse(Option.scala:121); 	at org.apache.spark.rdd.RDD.partitions(RDD.scala:246); 	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:248); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:246); 	at scala.Option.getOrE",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3488:198,error,errors,198,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3488,3,['error'],"['error', 'errors']"
Availability,"I'm receiving the following error on Mac OS X El Capitan when trying to run gcnv:; ```; 13:32:10.054 DEBUG ScriptExecutor - Executing:; 13:32:10.054 DEBUG ScriptExecutor - python; 13:32:10.054 DEBUG ScriptExecutor - -c; 13:32:10.054 DEBUG ScriptExecutor - import gcnvkernel. Traceback (most recent call last):; File ""<string>"", line 1, in <module>; File ""/Users/markw/anaconda/envs/gatk/lib/python3.6/site-packages/gcnvkernel/__init__.py"", line 1, in <module>; from pymc3 import __version__ as pymc3_version; File ""/Users/markw/anaconda/envs/gatk/lib/python3.6/site-packages/pymc3/__init__.py"", line 12, in <module>; from .sampling import *; File ""/Users/markw/anaconda/envs/gatk/lib/python3.6/site-packages/pymc3/sampling.py"", line 14, in <module>; from .plots.traceplot import traceplot; File ""/Users/markw/anaconda/envs/gatk/lib/python3.6/site-packages/pymc3/plots/__init__.py"", line 1, in <module>; from .autocorrplot import autocorrplot; File ""/Users/markw/anaconda/envs/gatk/lib/python3.6/site-packages/pymc3/plots/autocorrplot.py"", line 2, in <module>; import matplotlib.pyplot as plt; File ""/Users/markw/anaconda/envs/gatk/lib/python3.6/site-packages/matplotlib/pyplot.py"", line 113, in <module>; _backend_mod, new_figure_manager, draw_if_interactive, _show = pylab_setup(); File ""/Users/markw/anaconda/envs/gatk/lib/python3.6/site-packages/matplotlib/backends/__init__.py"", line 60, in pylab_setup; [backend_name], 0); File ""/Users/markw/anaconda/envs/gatk/lib/python3.6/site-packages/matplotlib/backends/backend_macosx.py"", line 19, in <module>; from matplotlib.backends import _macosx; RuntimeError: Python is not installed as a framework. The Mac OS X backend will not be able to function correctly if Python is not installed as a framework. See the Python documentation for more information on installing Python as a framework on Mac OS X. Please either reinstall Python as a framework, or try one of the other backends. If you are using (Ana)Conda please install python.app and replace t",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4743:28,error,error,28,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4743,1,['error'],['error']
Availability,I'm running in intermittent issues when running HaplotypeCallerSpark with GATK 4.0.3.0 and was hoping to generate ideas to debug further. The underlying error is an index error when calculating likelihoods:; ```; java.lang.ArrayIndexOutOfBoundsException: 4; 	at org.broadinstitute.hellbender.tools.walkers.genotyper.GenotypeLikelihoodCalculators.calculateGenotypeCountUsingTables(GenotypeLikelihoodCalculators.java:388); ```; I've been unable to generate a reproducible test case. Re-running on the same machine (Amazon m4.4xlarge instances with 16 cores and 64Gb of memory) works. I've seen the error on two different datasets but it happens infrequently as I've also run hundreds using the same setup without any exceptions. The only other thing I spot when looking through the traceback is block issues about the RDDs but I'm not sure if these are a symptom of the failure or a cause:; ```; 18/04/15 03:55:19 WARN BlockManager: Putting block rdd_18_12 failed due to an exception; 18/04/15 03:55:19 WARN BlockManager: Block rdd_18_12 could not be removed as it was not found on disk or in memory; ```; Here's the full traceback of the failure:; ```; [2018-04-15T03:55Z] ip-10-0-0-57: 18/04/15 03:55:19 WARN BlockManager: Putting block rdd_18_12 failed due to an exception; [2018-04-15T03:55Z] ip-10-0-0-57: 18/04/15 03:55:19 WARN BlockManager: Block rdd_18_12 could not be removed as it was not found on disk or in memory; [2018-04-15T03:55Z] ip-10-0-0-57: 18/04/15 03:55:19 ERROR Executor: Exception in task 12.0 in stage 7.0 (TID 828); [2018-04-15T03:55Z] ip-10-0-0-57: java.lang.ArrayIndexOutOfBoundsException: 4; [2018-04-15T03:55Z] ip-10-0-0-57: 	at org.broadinstitute.hellbender.tools.walkers.genotyper.GenotypeLikelihoodCalculators.calculateGenotypeCountUsingTables(GenotypeLikelihoodCalculators.java:388); [2018-04-15T03:55Z] ip-10-0-0-57: 	at org.broadinstitute.hellbender.tools.walkers.genotyper.GenotypeLikelihoodCalculators.getInstance(GenotypeLikelihoodCalculators.java:263); [2018-04-1,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4661:153,error,error,153,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4661,3,['error'],['error']
Availability,I'm sick of scrolling to the bottom to find the test report uri.; This saves the pain of having to scroll all the way down.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3892:118,down,down,118,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3892,1,['down'],['down']
Availability,"I'm trying to get the container/image from spacecade7/tutorial_11682_11683/ to use the copy number alteration tutorial.; The following error comes up on both my macbook, and on a linux system. . $ docker pull spacecade7/tutorial_11682_11683; Using default tag: latest; Error response from daemon: manifest for spacecade7/tutorial_11682_11683:latest not found: manifest unknown: manifest unknown",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6836:135,error,error,135,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6836,2,"['Error', 'error']","['Error', 'error']"
Availability,"I'm trying to run Mutect2 in tumor-only mode, for a small panel, and I get this errors at the FilterMutectCalls step. ```bash; [July 26, 2019 9:34:50 AM UTC] org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls done. Elapsed time: 0.06 minutes.; Runtime.totalMemory()=2129657856; java.lang.IllegalArgumentException: errorRate must be good probability but got NaN; at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:730); at org.broadinstitute.hellbender.utils.QualityUtils.errorProbToQual(QualityUtils.java:225); at org.broadinstitute.hellbender.utils.QualityUtils.errorProbToQual(QualityUtils.java:209); at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.lambda$applyFiltersAndAccumulateOutputStats$13(Mutect2FilteringEngine.java:176); at java.util.Optional.ifPresent(Optional.java:159); at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.applyFiltersAndAccumulateOutputStats(Mutect2FilteringEngine.java:174); at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls.nthPassApply(FilterMutectCalls.java:142); at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverse$0(MultiplePassVariantWalker.java:40); at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverseVariants$1(MultiplePassVariantWalker.java:77); at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); at java.util.Iterator.forEachRemaining(Iterator.java:116); at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6058:80,error,errors,80,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6058,4,['error'],"['errorProbToQual', 'errorRate', 'errors']"
Availability,"I'm using GATK 4.2.1.0-0 tool `Mutect2` to call mutations in a mitochondrion genome, and later processing the VCFs with `FilterMutectCalls` enabling as well the mitochondria mode (`--mitochondria-mode true`). For some reason, this results in **some** of the VCFs to return the following error:. > java.lang.IllegalArgumentException: log10p: Log10-probability must be 0 or less; > 	at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:798); > 	at org.broadinstitute.hellbender.utils.MathUtils.log10BinomialProbability(MathUtils.java:646); > 	at org.broadinstitute.hellbender.utils.MathUtils.binomialProbability(MathUtils.java:639); > 	at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.lambda$calculateQuantileBackgroundResponsibilities$10(SomaticClusteringModel.java:271); > 	at org.broadinstitute.hellbender.utils.MathUtils.applyToArray(MathUtils.java:1035); > 	at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.calculateQuantileBackgroundResponsibilities(SomaticClusteringModel.java:271); > 	at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.initializeClusters(SomaticClusteringModel.java:165); > 	at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.learnAndClearAccumulatedData(SomaticClusteringModel.java:325); > 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.learnParameters(Mutect2FilteringEngine.java:153); > 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls.afterNthPass(FilterMutectCalls.java:165); > 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.traverse(MultiplePassVariantWalker.java:44); > 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1085); > 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); > 	at org.broadinstitute.hellbender.cmdline.CommandLineProgr",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8455:287,error,error,287,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8455,1,['error'],['error']
Availability,"I'm using GATK4 as a framework to implement my own tools, and it will be nice to have a way of perform integration tests using `IntegrationTestSpec`. Nevertheless, it requires the extension of the `CommandLineProgramTest` to run the command, and thus it is extending `BaseTest`. The issues that this infrastructure generates when trying to use this test classes are the following:; - `BaseTest` loading of `GenomeLocParser` is annotated with `@BeforeClass`, which throws an error because the reference genome (hg19MiniReference) is not present in the repository.; - `CommandLineProgramTest` is using `org.broadinstitute.hellbender.Main` for running the commands, but for custom tools the instanceMain with a different list of packages. Although this could be solved by extending the class by another abstract class. I propose (and I can implemented if you agree) the following:; - `CommandLineProgramTest` not implementing `BaseTest`.; - `CommandLineProgramTest` as a real abstract class without implementations of `getTestDataDir()` or `runCommandLine()`; - Abstract `GATKCommandLineProgramTest` extending both `CommandLineProgramTest` and `BaseTest`, sited in `org.broadinstitute.hellbender.utils.test` and used in all integrations tests in this repository and the protected repository.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2033:474,error,error,474,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2033,1,['error'],['error']
Availability,"I'm using HaplotypeCaller (`gatk-package-4.beta.5`) to analyse the control medulloblastoma sample from the ICGC benchmark https://www.nature.com/articles/ncomms10001. Reads are aligned to `GRCh37` (from the Broad bundle, without decoy sequences) using `bwa mem`. Analysis is performed within the [bcbio-nextgen](https://github.com/chapmanb/bcbio-nextgen), which splits input into chunks by chromosome for parallelisation. For some reason, the chunk corresponding to the chromosome `GL000216.1` makes HaplotypeCaller crash with the error `IllegalArgumentException: contig must be non-null and not equal to *, and start must be >= 1`. I isolated the `gatk-launch` command, and narrowed down the reproducible example to these 2 reads:; ```; H239:179:C1K3VACXX:8:2116:11771:72429 161 GL000216.1 19 23 70S31M 4 49141708 0 ATTCCCTTACATTCGGATTGATACTATTAAAATCACTTACTCTTCCTTACATTCCATTCCATCCGGGCTGTTCCATTTCATTCTATTACACTCCACTCAAT ?1:=D>?B?CC:?A,<C;:AEGC<+AC+++2+:3*1:*11999*:099?<?0?99BBG*9?D*?##################################### NM:i:2 MD:Z:25T2C2 AS:i:25 XS:i:20 RG:Z:MB_normal_50x MQ:i:0 ms:i:1911 mc:i:49141802 MC:Z:11S30M5D60M; HWI-7001436:66:C3FYFACXX:5:1216:4411:82080 65 GL000216.1 27 57 101M 9 72653232 0 CATTCTATTACACTCCATTCCATTTCTATCCATTCCATTCCATTCTATTCCATTCCACTTGGGTCGATTCAATTCCATTCCATTCTATCCCTTCCATTCCA CCCFFFFFHHHHHJJJJJIJJJJJJIJJJJHIJJJJJJJJJJJJJJJJJJJJJJJJJIJIJIJGGIJIJJJJJJJJJJJJJJJJJJGJHHHHHHFFFFFFD NM:i:7 MD:Z:24C2T14A16C1T21C4T12 AS:i:66 XS:i:36 RG:Z:MB_normal_50x MQ:i:0 ms:i:3858 mc:i:72653218 MC:Z:14S45M1D33M9; ```; And one nucleotide target region:; ```; GL000216.1 87 88; ```. These BAM and BED files are attached here: [GL000216.1_87_gatk_debug.zip](https://github.com/broadinstitute/gatk/files/1477532/GL000216.1_87_gatk_debug.zip). Running command below:; ```; gatk-launch HaplotypeCaller \; -R /data/projects/punim0010/local/share/bcbio/genomes/Hsapiens/GRCh37/seq/GRCh37.fa \ ; -I GL000216.1_start_49__read_84_88.bam \; -L GL000216.1_87-88.bed \; --output out.vcf.gz; ```. Gives",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3845:531,error,error,531,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3845,2,"['down', 'error']","['down', 'error']"
Availability,"I'm wondering if you have a recommended way of detecting misencoded base quality reads. If I run FixMisencodedBaseQualityReads, I do get a USER ERROR message that I could possibly detect by checking the logs, but I would rather use another tool to check for the error in a script, or store an emitted value from the tool to check for the error. As far as I can tell, I don't see such a tool or value. I have tried the following in a bash commandline interface:; ```; acesnik@DESKTOP$ var=$(gatk FixMisencodedBaseQualityReads -I input.bam -O output.bam); acesnik@DESKTOP$ echo $var # this echos nothing, indicating there's no emitted value; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4242:144,ERROR,ERROR,144,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4242,5,"['ERROR', 'echo', 'error']","['ERROR', 'echo', 'echos', 'error']"
Availability,I'm working on some Plasmodium falciparum callsets in GATK and I have come across a curious error:. ```; Using GATK wrapper script /juffowup/gatk/build/install/gatk/bin/gatk; Running:; /juffowup/gatk/build/install/gatk/bin/gatk HaplotypeCaller -R /juffowup2/malaria/references/PlasmoDB-61_Pfalciparum3D7_Genome.fasta -I /juffowup2/malaria/haplotypecaller_arg_testing/fixed_bam/PG0004-CW.aligned.merged.markDuplicates.sorted.BQSR.bam -O /juffowup2/malaria/haplotypecaller_arg_testing/PG0004-CW.haplotype_caller.fixed_bam_file.with_pileup.g.vcf.gz --bam-output /juffowup2/malaria/haplotypecaller_arg_testing/PG0004-CW.haplotype_caller.fixed_bam_file.with_pileup.bamout.bam -contamination 0 --sample-ploidy 2 --linked-de-bruijn-graph --pileup-detection true --pileup-detection-enable-indel-pileup-calling true --max-reads-per-alignment-start 20 --annotate-with-num-discovered-alleles -GQB 10 -GQB 20 -GQB 30 -GQB 40 -GQB 50 -GQB 60 -GQB 70 -GQB 80 -GQB 90 -G StandardAnnotation -G StandardHCAnnotation -ERC GVCF --verbosity INFO; 14:14:15.323 WARN GATKAnnotationPluginDescriptor - Redundant enabled annotation group (StandardAnnotation) is enabled for this tool by default; 14:14:15.328 WARN GATKAnnotationPluginDescriptor - Redundant enabled annotation group (StandardHCAnnotation) is enabled for this tool by default; 14:14:15.388 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/juffowup/gatk/build/install/gatk/lib/gkl-0.8.11.jar!/com/intel/gkl/native/libgkl_compression.so; 14:14:15.435 INFO HaplotypeCaller - ------------------------------------------------------------; 14:14:15.439 INFO HaplotypeCaller - The Genome Analysis Toolkit (GATK) v4.4.0.0-44-g1529aa1-SNAPSHOT; 14:14:15.439 INFO HaplotypeCaller - For support and documentation go to https://software.broadinstitute.org/gatk/; 14:14:15.439 INFO HaplotypeCaller - Executing as jonn@dsde-methods-jonn-juffowup on Linux v5.4.0-1104-gcp amd64; 14:14:15.439 INFO HaplotypeCaller - Java runtime: OpenJDK 64-Bit Server VM,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8440:92,error,error,92,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8440,1,['error'],['error']
Availability,I've added back in `ReadTransformer` and `ReadFilter`; I moved the all the default ReadFilters into `ReadFilter` instead of the now redundant `ReadFilters`; The `ReadFilter`s now come pre-negated.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/179:132,redundant,redundant,132,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/179,1,['redundant'],['redundant']
Availability,"I've been trying repeatedly to run SplitNCigarReads on a mapped RNA-seq bam file (from STAR), but receive the following error:. [March 2, 2023 at 8:40:36 AM EST] org.broadinstitute.hellbender.tools.walkers.rnaseq.SplitNCigarReads done. Elapsed time: 1.23 minutes.; Runtime.totalMemory()=5184159744; htsjdk.samtools.util.RuntimeIOException: Attempt to add record to closed writer.; 	at htsjdk.samtools.util.AbstractAsyncWriter.write(AbstractAsyncWriter.java:57); 	at htsjdk.samtools.AsyncSAMFileWriter.addAlignment(AsyncSAMFileWriter.java:58); 	at org.broadinstitute.hellbender.utils.read.SAMFileGATKReadWriter.addRead(SAMFileGATKReadWriter.java:21); 	at org.broadinstitute.hellbender.tools.walkers.rnaseq.OverhangFixingManager.writeReads(OverhangFixingManager.java:358); 	at org.broadinstitute.hellbender.tools.walkers.rnaseq.OverhangFixingManager.flush(OverhangFixingManager.java:338); 	at org.broadinstitute.hellbender.tools.walkers.rnaseq.SplitNCigarReads.closeTool(SplitNCigarReads.java:192); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1101); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); 	at org.broadinstitute.hellbender.Main.main(Main.java:289). I've run the following command:. /cold/gatk-4.3.0.0/./gatk	 --java-options ""-Xmx25g"" SplitNCigarReads \; 	 -R /cold/base/Homo_sapiens.GRCh38.dna.primary_assembly.fa -I subset_TINY_rehead.bam \; 	 --tmp-dir /thing -O thing.bam. I've tried setting --tmp-dir, as well as the system varliable TEMP_DIR, but all to no avail. Any suggestions/work-arounds?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8232:120,error,error,120,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8232,2,"['avail', 'error']","['avail', 'error']"
Availability,"I've got this error. java.lang.IllegalArgumentException: Invalid interval. Contig:ENST00000342066.7|ENSG00000187634.11|OTTHUMG00000040719.10|OTTHUMT00000276866.2|SAMD11-202|SAMD11|2551|protein_coding| start:0 end:0. I'm working on hg38. The VCF input file was produced from Mutect2. First, I've the error ""java.lang.NullPointerException"". So I put only ""gencode"" folder in the data-source folder. Then, I've got the error message above.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4712:14,error,error,14,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4712,3,['error'],['error']
Availability,"I've had several Travis test failures (on my picard removal branch) that appear to be failures during kryo serialization of a mocked ReferenceMultiSource object (based on the failing class name, (org.broadinstitute.hellbender.engine.datasources.ReferenceMultiSource$$EnhancerByMockitoWithCGLIB$$b0dc631f, which looks like the CGLIB names mentioned [here](https://github.com/mockito/mockito/issues/319)). We're on an ancient version of mockito anyway, and newer versions no longer use cglib, so it seemed like a good time to upgrade. To do so I also had to replace usage of the method getArgumentAt, which has been [deprecated](https://github.com/mockito/mockito/pull/373) in favor of getArgument.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3581:29,failure,failures,29,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3581,2,['failure'],['failures']
Availability,"I've run into an error using a certain BAM file I created for testing. Possibly relevant: I also tried running it through PrintReads - all reads were filtered out by the WellFormedReadFilter because they do not have read groups or base qualities. [test_pathseq_unmapped.bam.zip](https://github.com/broadinstitute/gatk/files/537153/test_pathseq_unmapped.bam.zip). > > ./gatk-launch PrintReadsSpark -I ~/Work/gatk/tests/test_pathseq_unmapped.bam -O ~/Work/gatk/tests/test_pathseq_unmapped.output.bam; > > Using GATK wrapper script /Users/markw/IdeaProjects/gatk/build/install/gatk/bin/gatk; > > Running:; > > /Users/markw/IdeaProjects/gatk/build/install/gatk/bin/gatk PrintReadsSpark -I /Users/markw/Work/gatk/tests/test_pathseq_unmapped.bam -O /Users/markw/Work/gatk/tests/test_pathseq_unmapped.output.bam; > > 15:10:22.765 INFO IntelGKLUtils - Trying to load Intel GKL library from:; > > jar:file:/Users/markw/IdeaProjects/gatk/build/install/gatk/lib/gkl-0.1.2.jar!/com/intel/gkl/native/libIntelGKL.dylib; > > 15:10:22.790 INFO IntelGKLUtils - Intel GKL library loaded from classpath.; > > [October 18, 2016 3:10:22 PM EDT] org.broadinstitute.hellbender.tools.spark.pipelines.PrintReadsSpark --output /Users/markw/Work/gatk/tests/test_pathseq_unmapped.output.bam --input /Users/markw/Work/gatk/tests/test_pathseq_unmapped.bam --readValidationStringency SILENT --interval_set_rule UNION --interval_padding 0 --interval_exclusion_padding 0 --bamPartitionSize 0 --disableSequenceDictionaryValidation false --shardedOutput false --numReducers 0 --sparkMaster local[*] --help false --version false --verbosity INFO --QUIET false --use_jdk_deflater false --disableAllReadFilters false; > > [October 18, 2016 3:10:22 PM EDT] Executing as markw@WMC9F-819 on Mac OS X 10.11.6 x86_64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_91-b14; Version: Version:4.alpha.1-318-gcdc484c-SNAPSHOT; > > 15:10:22.793 INFO PrintReadsSpark - Defaults.BUFFER_SIZE : 131072; > > 15:10:22.793 INFO PrintReadsSpark - Defaults.COMPRESS",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2219:17,error,error,17,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2219,1,['error'],['error']
Availability,"I've run into this error in the past as well. As far as I can tell, the SparkGenomeReadCounts code is not trying to do anything too funky, so I wonder if this could be a more general htsjdk/engine issue. But I could be wrong. @droazen could you assign someone to help me look into it? Thanks!. org.apache.spark.SparkException: Job aborted due to stage failure: Task 137 in stage 0.0 failed 1 times, most recent failure: Lost task 137.0 in stage 0.0 (TID 137, localhost): java.lang.IllegalArgumentException: Reference name for '858929714' not found in sequence dictionary.; at htsjdk.samtools.SAMRecord.resolveNameFromIndex(SAMRecord.java:569); at htsjdk.samtools.SAMRecord.setReferenceIndex(SAMRecord.java:422); at htsjdk.samtools.BAMRecord.<init>(BAMRecord.java:87); at htsjdk.samtools.DefaultSAMRecordFactory.createBAMRecord(DefaultSAMRecordFactory.java:42); at htsjdk.samtools.BAMRecordCodec.decode(BAMRecordCodec.java:210); at htsjdk.samtools.BAMFileReader$BAMFileIterator.getNextRecord(BAMFileReader.java:829); at htsjdk.samtools.BAMFileReader$BAMFileIndexIterator.getNextRecord(BAMFileReader.java:981); at htsjdk.samtools.BAMFileReader$BAMFileIterator.advance(BAMFileReader.java:803); at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:797); at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:765); at htsjdk.samtools.BAMFileReader$BAMQueryFilteringIterator.advance(BAMFileReader.java:1034); at htsjdk.samtools.BAMFileReader$BAMQueryFilteringIterator.<init>(BAMFileReader.java:1003); at htsjdk.samtools.BAMFileReader.createIndexIterator(BAMFileReader.java:944); at org.seqdoop.hadoop_bam.BAMRecordReader.initialize(BAMRecordReader.java:174); at org.seqdoop.hadoop_bam.BAMInputFormat.createRecordReader(BAMInputFormat.java:226); at org.seqdoop.hadoop_bam.AnySAMInputFormat.createRecordReader(AnySAMInputFormat.java:190); at org.apache.spark.rdd.NewHadoopRDD$$anon$1.<init>(NewHadoopRDD.scala:170); at org.apache.spark.rdd.NewHadoopRDD.compute(NewHadoop",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3679:19,error,error,19,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3679,3,"['error', 'failure']","['error', 'failure']"
Availability,"I've seen this a few times on two different Mac laptops (both with 16G), primarily while running the IntelInflaterDeflaterIntegrationTest from within IntelliJ, but a couple of times I've seen it while running the full test suite from gradle. I saw these while trying to narrow down https://github.com/broadinstitute/gatk/issues/2490 - its probably related. This one happened while several times when running just the IntelInflaterDeflaterIntegrationTest from (on one of the PrintReads tests) from within IntelliJ:. [TestNG] Running:; /Users/cnorman/Library/Caches/IntelliJIdea2016.3/temp-testng-customsuite.xml; java(79316,0x700000d3b000) malloc: *** error for object 0x7f9543bf1000: pointer being freed was not allocated; *** set a breakpoint in malloc_error_break to debug; Process finished with exit code 134 (interrupted by signal 6: SIGABRT). This one happened while running the full gatk test suite from gradle (note that this one appears to occur during VariantsSparkSinkUnitTest, but in this case the IntelInflaterDeflaterIntegrationTest was the test that had been run immediately previously):. Gradle suite > Gradle test > org.broadinstitute.hellbender.engine.spark.datasources.VariantsSparkSinkUnitTest.testWritingToFileURL[0](/Users/cmn/projects/hellbender/src/test/resources/Homo_sapiens_assembly19.dbsnp135.chr1_1M.exome_intervals.vcf, .vcf) STANDARD_OUT; 23:02 DEBUG: [kryo] Write: SerializableConfiguration; java(51936,0x119471000) malloc: *** error for object 0x7fd0b7a1d600: pointer being freed was not allocated; *** set a breakpoint in malloc_error_break to debug; Results: SUCCESS (0 tests, 0 successes, 0 failures, 0 skipped)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2535:277,down,down,277,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2535,4,"['down', 'error', 'failure']","['down', 'error', 'failures']"
Availability,"ID 1976). 667 bytes result sent to driver; 23/05/23 13:20:19 INFO TaskSetManager: Finished task 66.0 in stage 31.0 (TID 2040) in 160 ms on localhost (executor driver) (1/128); 23/05/23 13:20:19 INFO TaskSetManager: Finished task 2.0 in stage 31.0 (TID 1976) in 330 ms on localhost (executor driver) (2/128); 23/05/23 13:20:19 INFO Executor: Finished task 3.0 in stage 31.0 (TID 1977). 667 bytes result sent to driver; ...; 23/05/23 13:20:19 INFO TaskSetManager: Finished task 97.0 in stage 31.0 (TID 2071) in 123 ms on localhost (executor driver) (127/128); 23/05/23 13:20:19 INFO TaskSetManager: Finished task 112.0 in stage 31.0 (TID 2086) in 88 ms on localhost (executor driver) (128/128); 23/05/23 13:20:19 INFO TaskSchedulerImpl: Removed TaskSet 31.0, whose tasks have all completed, from pool ; 23/05/23 13:20:19 INFO DAGScheduler: ResultStage 31 (foreach at BwaMemIndexCache.java:84) finished in 0.389 s; 23/05/23 13:20:19 INFO DAGScheduler: Job 7 finished: foreach at BwaMemIndexCache.java:84, took 0.392269 s; 23/05/23 13:20:19 INFO SparkUI: Stopped Spark web UI at http://d01.capitalbiotech.local:4040; 23/05/23 13:20:19 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 23/05/23 13:20:26 INFO MemoryStore: MemoryStore cleared; 23/05/23 13:20:26 INFO BlockManager: BlockManager stopped; 23/05/23 13:20:26 INFO BlockManagerMaster: BlockManagerMaster stopped; 23/05/23 13:20:26 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 23/05/23 13:20:26 INFO SparkContext: Successfully stopped SparkContext; 13:20:26.099 INFO PathSeqPipelineSpark - Shutting down engine; [May 23, 2023 1:20:26 PM CST] org.broadinstitute.hellbender.tools.spark.pathseq.PathSeqPipelineSpark done. Elapsed time: 1.04 minutes.; Runtime.totalMemory()=156475326464; 23/05/23 13:20:26 INFO ShutdownHookManager: Shutdown hook called; 23/05/23 13:20:26 INFO ShutdownHookManager: Deleting directory pathseq/tmp/spark-2042a18b-a4af-4a86-a236-c4914f0407a1",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8339:58018,down,down,58018,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8339,1,['down'],['down']
Availability,"ID 6, xx.xx.xx.16, executor 3, partition 0, PROCESS_LOCAL, 6010 bytes); 18/04/24 17:55:55 INFO TaskSetManager: Lost task 0.1 in stage 2.0 (TID 6) on xx.xx.xx.16, executor 3: org.broadinstitute.hellbender.exceptions.UserException$CouldNotReadInputFile (Couldn't read file. Error was: hg19mini.hss with exception: hg19mini.hss (No such file or directory)) [duplicate 2]; 01:00 DEBUG: [kryo] Write: WrappedArray([NC_000913.3_127443_127875_0:0:0_0:0:0_a507 UNMAPPED, NC_000913.3_127443_127875_0:0:0_0:0:0_a507 UNMAPPED]); 18/04/24 17:55:55 INFO TaskSetManager: Starting task 0.2 in stage 2.0 (TID 7, xx.xx.xx.23, executor 5, partition 0, PROCESS_LOCAL, 6010 bytes); 18/04/24 17:55:55 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on xx.xx.xx.23:42535 (size: 6.4 KB, free: 366.3 MB); 18/04/24 17:55:55 INFO TaskSetManager: Lost task 0.2 in stage 2.0 (TID 7) on xx.xx.xx.23, executor 5: org.broadinstitute.hellbender.exceptions.UserException$CouldNotReadInputFile (Couldn't read file. Error was: hg19mini.hss with exception: hg19mini.hss (No such file or directory)) [duplicate 3]; 01:00 DEBUG: [kryo] Write: WrappedArray([NC_000913.3_127443_127875_0:0:0_0:0:0_a507 UNMAPPED, NC_000913.3_127443_127875_0:0:0_0:0:0_a507 UNMAPPED]); 18/04/24 17:55:55 INFO TaskSetManager: Starting task 0.3 in stage 2.0 (TID 8, xx.xx.xx.24, executor 4, partition 0, PROCESS_LOCAL, 6010 bytes); 18/04/24 17:56:00 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on xx.xx.xx.24:49966 (size: 6.4 KB, free: 366.3 MB); 18/04/24 17:56:04 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on xx.xx.xx.24:49966 (size: 23.1 KB, free: 366.3 MB); 18/04/24 17:56:07 WARN TaskSetManager: Lost task 1.1 in stage 2.0 (TID 5, xx.xx.xx.24, executor 1): org.broadinstitute.hellbender.exceptions.UserException$CouldNotReadInputFile: Couldn't read file. Error was: hg19mini.hss with exception: hg19mini.hss (No such file or directory); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4699:28628,Error,Error,28628,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4699,1,['Error'],['Error']
Availability,"INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on xx.xx.xx.24:35903 (size: 6.4 KB, free: 366.3 MB); 18/04/24 17:56:39 INFO TaskSetManager: Lost task 1.3 in stage 2.0 (TID 10) on xx.xx.xx.16, executor 3: org.broadinstitute.hellbender.exceptions.UserException$CouldNotReadInputFile (Couldn't read file. Error was: hg19mini.hss with exception: hg19mini.hss (No such file or directory)) [duplicate 1]; 18/04/24 17:56:39 ERROR TaskSetManager: Task 1 in stage 2.0 failed 4 times; aborting job; 18/04/24 17:56:39 INFO TaskSchedulerImpl: Cancelling stage 2; 18/04/24 17:56:39 INFO TaskSchedulerImpl: Stage 2 was cancelled; 18/04/24 17:56:39 INFO DAGScheduler: ShuffleMapStage 2 (mapToPair at PSFilter.java:125) failed in 45.219 s due to Job aborted due to stage failure: Task 1 in stage 2.0 failed 4 times, most recent failure: Lost task 1.3 in stage 2.0 (TID 10, xx.xx.xx.16, executor 3): org.broadinstitute.hellbender.exceptions.UserException$CouldNotReadInputFile: Couldn't read file. Error was: hg19mini.hss with exception: hg19mini.hss (No such file or directory); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:112); at org.broadinstitute.hellbender.tools.spark.pathseq.PSKmerUtils.readKmerFilter(PSKmerUtils.java:131); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilter.<init>(ContainsKmerReadFilter.java:27); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:35); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:15); at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78); at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:463); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeS",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4699:35222,Error,Error,35222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4699,1,['Error'],['Error']
Availability,"INFO BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up; 10:33:06.831 INFO SparkEnv - Registering BlockManagerMasterHeartbeat; 10:33:06.846 INFO DiskBlockManager - Created local directory at /raid/tmp/d6/c66ba827e22dbc38625af1cbc85adc/tmp/blockmgr-8dc41ac8-6cf4-4424-9b15-7e2cbfc9e538; 10:33:06.872 INFO MemoryStore - MemoryStore started with capacity 1076.2 GiB; 10:33:06.886 INFO SparkEnv - Registering OutputCommitCoordinator; 10:33:06.916 INFO log - Logging initialized @3948ms to org.sparkproject.jetty.util.log.Slf4jLog; 10:33:06.992 INFO Server - jetty-9.4.46.v20220331; built: 2022-03-31T16:38:08.030Z; git: bc17a0369a11ecf40bb92c839b9ef0a8ac50ea18; jvm 17.0.9+8-LTS; 10:33:07.009 INFO Server - Started @4042ms; 10:33:07.080 INFO AbstractConnector - Started ServerConnector@2f829853{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}; 10:33:07.081 INFO Utils - Successfully started service 'SparkUI' on port 4040.; 10:33:07.116 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@7074da1d{/,null,AVAILABLE,@Spark}; 10:33:07.182 INFO Executor - Starting executor ID driver on host 172.20.19.130; 10:33:07.189 INFO Executor - Starting executor with user classpath (userClassPathFirst = false): ''; 10:33:07.208 INFO Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43279.; 10:33:07.208 INFO NettyBlockTransferService - Server created on 172.20.19.130:43279; 10:33:07.210 INFO BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy; 10:33:07.214 INFO BlockManagerMaster - Registering BlockManager BlockManagerId(driver, 172.20.19.130, 43279, None); 10:33:07.221 INFO BlockManagerMasterEndpoint - Registering block manager 172.20.19.130:43279 with 1076.2 GiB RAM, BlockManagerId(driver, 172.20.19.130, 43279, None); 10:33:07.225 INFO BlockManagerMaster - Registered BlockManager BlockManagerId(driver, 172.20.19.130, 43279, None); 10:33:07.226 INFO BlockManager - Initialized BlockManager: B",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8949:43641,AVAIL,AVAILABLE,43641,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8949,1,['AVAIL'],['AVAILABLE']
Availability,INFO CombineGVCFs - Shutting down engine,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5947:29,down,down,29,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5947,1,['down'],['down']
Availability,"INFO GenotypeGVCFs - ------------------------------------------------------------; > 21:14:29.496 INFO GenotypeGVCFs - HTSJDK Version: 2.21.2; > 21:14:29.496 INFO GenotypeGVCFs - Picard Version: 2.21.9; > 21:14:29.496 INFO GenotypeGVCFs - HTSJDK Defaults.COMPRESSION_LEVEL : 2; > 21:14:29.496 INFO GenotypeGVCFs - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; > 21:14:29.496 INFO GenotypeGVCFs - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; > 21:14:29.496 INFO GenotypeGVCFs - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; > 21:14:29.496 INFO GenotypeGVCFs - Deflater: IntelDeflater; > 21:14:29.496 INFO GenotypeGVCFs - Inflater: IntelInflater; > 21:14:29.496 INFO GenotypeGVCFs - GCS max retries/reopens: 20; > 21:14:29.496 INFO GenotypeGVCFs - Requester pays: disabled; > 21:14:29.496 INFO GenotypeGVCFs - Initializing engine; > **[TileDB::StorageManager] Error: Cannot lock consolidation filelock; Cannot lock.**; > 21:14:30.336 INFO GenotypeGVCFs - Shutting down engine; > [May 25, 2020 9:14:30 PM CST] org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs done. Elapsed time: 0.02 minutes.; > Runtime.totalMemory()=1199570944; > ***********************************************************************; > ; > A USER ERROR has occurred: Couldn't create GenomicsDBFeatureReader; > ; > ***********************************************************************; > Set the system property GATK_STACKTRACE_ON_USER_EXCEPTION (--java-options '-DGATK_STACKTRACE_ON_USER_EXCEPTION=true') to print the stack trace. and last GATK commands used:. ```; gatk GenomicsDBImport \; -V SRR630496.erc.g.vcf \; -V SRR630877.erc.g.vcf \; --genomicsdb-workspace-path mydatabase \; --intervals chr22; ```. > java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /home/miniconda3/share/gatk4-4.1.7.0-0/gatk-package-4.1.7.0-local.jar GenomicsDBImport -V SRR630496.erc.g.vcf -V SR",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6627:2933,down,down,2933,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6627,1,['down'],['down']
Availability,"INFO field FS - the field will NOT be part of INFO fields in the generated VCF records; 20:09:23.524 info NativeGenomicsDB - pid=1332903 tid=1332904 No valid combination operation found for INFO field InbreedingCoeff - the field will NOT be part of INFO fields in the generated VCF records; 20:09:23.524 info NativeGenomicsDB - pid=1332903 tid=1332904 No valid combination operation found for INFO field QD - the field will NOT be part of INFO fields in the generated VCF records; 20:09:23.524 info NativeGenomicsDB - pid=1332903 tid=1332904 No valid combination operation found for INFO field SOR - the field will NOT be part of INFO fields in the generated VCF records; 20:09:23.528 INFO GenotypeGVCFs - Shutting down engine; [September 23, 2023 at 8:09:23 PM CST] org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs done. Elapsed time: 0.04 minutes.; Runtime.totalMemory()=2801795072; ***********************************************************************. A USER ERROR has occurred: Couldn't create GenomicsDBFeatureReader. ***********************************************************************; org.broadinstitute.hellbender.exceptions.UserException: Couldn't create GenomicsDBFeatureReader; at org.broadinstitute.hellbender.engine.FeatureDataSource.getGenomicsDBFeatureReader(FeatureDataSource.java:463); at org.broadinstitute.hellbender.engine.FeatureDataSource.getFeatureReader(FeatureDataSource.java:365); at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:319); at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:291); at org.broadinstitute.hellbender.engine.VariantLocusWalker.initialize at org.broadinstitute.hellbender.engine.VariantWalkerBase.initializeFava:726); at org.broadinstitute.hellbender.engine.VariantLocusWalker.onStartup(VariantLocusWalker.java:63); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:138); at org.broadinstitute.hellbender.cmdline.Com",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8527:5989,ERROR,ERROR,5989,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8527,1,['ERROR'],['ERROR']
Availability,"INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@418f0534{/jobs,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@134a8ead{/jobs/json,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@54247647{/jobs/job,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5463f035{/jobs/job/json,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@44fd7ba4{/stages,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@69d103f0{/stages/json,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@74fb5b59{/stages/stage,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@26fadd98{/stages/stage/json,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@3db6dd52{/stages/pool,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6ef4cbe1{/stages/pool/json,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2baac4a7{/storage,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6bce4140{/storage/json,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5882b202{/storage/rdd,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@b506ed0{/storage/rdd/json,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@65f3e805{/environment,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4112:8083,AVAIL,AVAILABLE,8083,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4112,1,['AVAIL'],['AVAILABLE']
Availability,"IO_READ_FOR_SAMTOOLS : false; > 21:14:29.496 INFO GenotypeGVCFs - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; > 21:14:29.496 INFO GenotypeGVCFs - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; > 21:14:29.496 INFO GenotypeGVCFs - Deflater: IntelDeflater; > 21:14:29.496 INFO GenotypeGVCFs - Inflater: IntelInflater; > 21:14:29.496 INFO GenotypeGVCFs - GCS max retries/reopens: 20; > 21:14:29.496 INFO GenotypeGVCFs - Requester pays: disabled; > 21:14:29.496 INFO GenotypeGVCFs - Initializing engine; > **[TileDB::StorageManager] Error: Cannot lock consolidation filelock; Cannot lock.**; > 21:14:30.336 INFO GenotypeGVCFs - Shutting down engine; > [May 25, 2020 9:14:30 PM CST] org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs done. Elapsed time: 0.02 minutes.; > Runtime.totalMemory()=1199570944; > ***********************************************************************; > ; > A USER ERROR has occurred: Couldn't create GenomicsDBFeatureReader; > ; > ***********************************************************************; > Set the system property GATK_STACKTRACE_ON_USER_EXCEPTION (--java-options '-DGATK_STACKTRACE_ON_USER_EXCEPTION=true') to print the stack trace. and last GATK commands used:. ```; gatk GenomicsDBImport \; -V SRR630496.erc.g.vcf \; -V SRR630877.erc.g.vcf \; --genomicsdb-workspace-path mydatabase \; --intervals chr22; ```. > java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /home/miniconda3/share/gatk4-4.1.7.0-0/gatk-package-4.1.7.0-local.jar GenomicsDBImport -V SRR630496.erc.g.vcf -V SRR630877.erc.g.vcf --genomicsdb-workspace-path mydatabase -L chr22; > 21:21:17.641 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/miniconda3/share/gatk4-4.1.7.0-0/gatk-package-4.1.7.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; > May 25, 2020 9:21:17 PM shaded.cloud_nio.com.google.auth.oauth2.Comput",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6627:3195,ERROR,ERROR,3195,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6627,1,['ERROR'],['ERROR']
Availability,"If I clone GATK with the ssh URL (`git@github.com:broadinstitute/gatk.git`), and then run a `docker build` command from the root of that clone, I get ssh authentication errors at the `git lfs pull` step:. ```; Step 9/36 : RUN git lfs pull; ---> Running in 1f415556efd2; Git LFS: (0 of 104 files) 0 B / 1.28 GB ; batch request: Host key verification failed.: exit status 255; batch request: Host key verification failed.: exit status 255; error: failed to fetch some objects from 'https://github.com/broadinstitute/gatk.git/info/lfs'; The command '/bin/sh -c git lfs pull' returned a non-zero code: 2; ```. If I do the same thing from a GATK clone created using the https URL (`https://github.com/broadinstitute/gatk.git`), I get no lfs error. This also raises the larger question of whether we are authenticating with github before doing `git lfs pull` during the docker build, as I believe that the quotas for unauthenticated `git lfs` operations are much smaller than for authenticated operations.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7077:169,error,errors,169,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7077,3,['error'],"['error', 'errors']"
Availability,"If I make a tool fail, e.g. a bad argument. the process exit status is 0 making difficult to track failure in including scripts, SGE and (perhaps?) Queue?. Failure should result in a non-zero exit status.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/342:99,failure,failure,99,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/342,2,"['Failure', 'failure']","['Failure', 'failure']"
Availability,"If I run BaseRecalibrator on a reference with contigs [20,21] and knownSites only has only sites from 17, then GATK3 blows up:. ```; ##### ERROR MESSAGE: Input files knownSites and reference have incompatible contigs: No overlapping contigs found.; ##### ERROR knownSites contigs = [17]; ##### ERROR reference contigs = [20, 21]; ```. but gatk4 does not (and it should). This is the cause of the bogus tests in #1017 (they should have never been allowed to exist). The commandline for GATK3 is; (the VCF has no sequence dictionary). ```; -T BaseRecalibrator -R src/test/resources/large/human_g1k_v37.20.21.fasta -I src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.bam --out gatk3.3.recal.txt --knownSites src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_132.b37.excluding_sites_after_129.chr17_69k_70k.vcf; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1029:139,ERROR,ERROR,139,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1029,3,['ERROR'],['ERROR']
Availability,If I try to navigate to https://gatk-jenkins.broadinstitute.org/ I get:. ```; Proxy Error. The proxy server received an invalid response from an upstream server.; The proxy server could not handle the request GET /. Reason: Error reading from remote server. Apache Server at gatk-jenkins.broadinstitute.org Port 443; ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3862:84,Error,Error,84,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3862,2,['Error'],['Error']
Availability,"If a `VariantWalker` driving variant is indexed with tribble but does not have an sequence dictionary in the header, the dictionary is loaded from the index. Nevertheless, this is a truncated dictionary because the end coordinate for each chromosome is the last variant in that contig. Thus, even if a proper interval for the genome is provided (regarding the reference sequence), the program throw an user error exception. This could be reproduced with the following test in `ExampleVariantWalkerIntegrationTest`:. ``` java; @Test; public void testExampleVariantWalkerInvalidDictionary() throws IOException {; final IntegrationTestSpec testSpec = new IntegrationTestSpec(; "" -L 1:200-1125"" +; "" -R "" + hg19MiniReference +; "" -I "" + TEST_DATA_DIRECTORY + ""reads_data_source_test1.bam"" +; "" -V "" + TEST_DATA_DIRECTORY + ""example_variants.vcf"" +; "" -auxiliaryVariants "" + TEST_DATA_DIRECTORY + ""feature_data_source_test.vcf"" +; "" -O %s"", Arrays.asList(TEST_OUTPUT_DIRECTORY + ""expected_ExampleVariantWalkerIntegrationTest_output.txt""));; testSpec.executeTest(""testExampleVariantWalker_UndefinedContigLengthsInDictionary"", this);; }; ```. The thrown exceptions is the following:. ``` java; java.lang.RuntimeException: org.broadinstitute.hellbender.exceptions.UserException$MalformedGenomeLoc: A USER ERROR has occurred: Badly formed genome loc: Failed to parse Genome Location string: 1:200-1125; ```. This comes from the overrided method `VariantWalker.getBestAvailableSequenceDictionary()`, which prefers the one from the driving variant (in this case, the one which comes from the index), not using the one from the reference/reads if available.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2081:407,error,error,407,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2081,3,"['ERROR', 'avail', 'error']","['ERROR', 'available', 'error']"
Availability,"If a core dump is produced while running tests on travis, this will echo the log file to the travis log (ie., it was triggered [here](https://api.travis-ci.com/v3/job/468677651/log.txt) by the pair hmm seg fault) so the java and native thread stacks can be inspected.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7020:68,echo,echo,68,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7020,2,"['echo', 'fault']","['echo', 'fault']"
Availability,"If an invalid path is given to `Pileup`, the exception is not informative for the final user: `A USER ERROR has occurred: Invalid command line: Argument output has a bad value: /some/invalid/path. Problem constructing PrintStream from the string '/some/invalid/path'.`. Although #121 should correct this issue, in the meanwhile it could be better to use `File` in the argument and generate the stream in `onTraversalStart` to throw a more informative `CouldNotCreateOutputFile`. Thanks to @lbergelson for pointing it out when reviewing #1862.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1909:102,ERROR,ERROR,102,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1909,1,['ERROR'],['ERROR']
Availability,"If gatk-launch is run so that it invokes a local jar directly without the generated launch script, it fails to properly pass system properties. This will cause confusing bugs and performance issues. It was discovered in due to #2300. This effects all users using our packaged jars available on the website since they don't include the gradle generated wrapper script.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2316:281,avail,available,281,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2316,1,['avail'],['available']
Availability,"If one of the block compressed VCFs in the list is empty (i.e. it does have proper header lines but there are no variant records, which is perfectly valid) then the tool fails with an IllegalStateException:. java.lang.IllegalStateException: Could not read available bytes from BlockCompressedInputStream.; at org.broadinstitute.hellbender.utils.Utils.validate(Utils.java:697); at org.broadinstitute.hellbender.tools.GatherVcfs.gatherWithBlockCopying(GatherVcfs.java:354)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3218:256,avail,available,256,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3218,1,['avail'],['available']
Availability,"If the version of the data sources is not up to date, Funcotator should give an error to that effect and halt.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5660:80,error,error,80,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5660,1,['error'],['error']
Availability,"If you click the link for --read-index on this tooldocs page, it redirects to the tools index instead of jumping down to the explanation of the flag https://gatk.broadinstitute.org/hc/en-us/articles/360041416652-AnnotateIntervals",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6600:113,down,down,113,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6600,1,['down'],['down']
Availability,"If you have a barclay `@Argument` field of type `List`, barclay will fail to set the field value properly when the argument is specified if the `List` is initialized using an immutable Collection, such as that returned by `Collections.emptyList()`. Example error:. ```; java.lang.UnsupportedOperationException; 	at java.util.AbstractList.add(AbstractList.java:148); 	at java.util.AbstractList.add(AbstractList.java:108); 	at org.broadinstitute.barclay.argparser.CommandLineArgumentParser.setArgument(CommandLineArgumentParser.java:706); 	at org.broadinstitute.barclay.argparser.CommandLineArgumentParser.parseArguments(CommandLineArgumentParser.java:427); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.parseArgs(CommandLineProgram.java:220); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:194); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); 	at org.broadinstitute.hellbender.Main.main(Main.java:289); ```. Ideally, barclay should detect immutable collections and replace them with mutable ones when necessary.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4702:257,error,error,257,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4702,1,['error'],['error']
Availability,"If you look at the approximation going from equation 34 to 35 in https://github.com/broadinstitute/gatk/blob/master/docs/mutect/mutect.pdf you will find that we replace f(1 - e) + (1 - f)e by just f(1 - e), where f is the allele fraction and e is the error rate. When f is much bigger than e this is okay but when they are comparable (consider mitochondrial or cfDNA calling with f = 1% and base qualities of 25) the approximation breaks down and we significantly underestimate the log odds, thereby failing to consider a region active. This must be fixed!. @meganshand",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4816:251,error,error,251,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4816,2,"['down', 'error']","['down', 'error']"
Availability,"If you run AlignAssembledContigsSpark with an incorrect BWA index version (ie. one that was generated with BWA index 0.7.12 or previous), you get executor logs that trace back to an ""IOException: File system is closed"" error, which is very misleading. I believe that this happens because Spark retries the tasks multiple times after they have failed, and in the subsequent tries the filesystem is in a bad state. It would be nice if we could either catch this error earlier, or check to make sure that the reference is compatible before trying to load it somehow.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2123:219,error,error,219,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2123,2,['error'],['error']
Availability,"Implement a `SeqGraph` version of the junction trees described in Kiran's paper. For now we can do something naive about reads with errors corresponding to pruned edges, such as skipping the remainder of the read. In addition to involving a minimal change to the current code, using `SeqGraph`s will make handling read errors a bit simpler and is a much more natural way to handle dangling ends.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5923:132,error,errors,132,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5923,2,['error'],['errors']
Availability,Implement a convolutional network for the reference context merged with a dense network for annotations. The training data for the classifier consists of low-AF false positives from a normal and true hets with alt alleles downsampled to look like somatic variants. (This is in the db_m2_pon_mode branch).,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3239:222,down,downsampled,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3239,1,['down'],['downsampled']
Availability,Implement a test that catches failures to register new annotations in GATKVCFHeaderLines,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1713:30,failure,failures,30,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1713,1,['failure'],['failures']
Availability,"Implement https://github.com/broadinstitute/gatk/issues/2147. ```; Change ReadPosRankSumTest.isUsableRead to take deletions into account. Previously, reads were skipped because the variant location was considered downstream from the read. ; ```; The same fix was done to `AS_ReadPosRankSumTest`.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2318:213,down,downstream,213,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2318,1,['down'],['downstream']
Availability,"Implements two new tools and updates some methods for a revamp of the `CombineBatches` cross-batch integration module in [gatk-sv](https://github.com/broadinstitute/gatk-sv). - `SVStratify` - tool for splitting out a VCF by variant class. Users pass in a configuration table (see tool documentation for an example) specifying one or more stratification groups classified by SVTYPE, SVLEN range, and reference context(s). The latter are specified as a set of interval lists using `--context-name` and `--context-intervals` arguments. All variants are matched with their respective group which is annotated in the `STRAT` INFO field. Optionally, the output can be split into multiple VCFs by group, which is a very useful functionality that currently can't be done efficiently with common commands/toolkits.; - `GroupedSVCluster` - a hybrid tool combining functionality from `SVStratify` with `SVCluster` to perform intra-stratum clustering. This tool is critical for fine-tuned clustering of specific variants types within certain reference contexts. For example, small variants in simple repeats tend to have lower breakpoint accuracy and are typically ""reclustered"" during call set refinement with looser clustering criteria.; - `SVStratificationEngine` - new class for performing stratification.; - Updates to breakpoint refinement in `CanonicalSVCollapser` that should improve breakpoint accuracy, particularly in larger call sets. Raw evidence support and variant quality are now considered when choosing a representative breakpoint for a group of clustered SVs.; - Added `FlagFieldLogic` type for customizing how `BOTHSIDE_PASS` and `HIGH_SR_BACKGROUND` INFO flags are collapsed during clustering.; - `RD_CN` is now used as a backup if `CN` is not available when determining carrier status for sample overlap.; - Removed no-sort option in favor of spooled sorting.; - Bug fix: support for empty EVIDENCE info fields; - Bug fix: in one of the JointGermlineCnvDefragmenter tests",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8990:1753,avail,available,1753,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8990,1,['avail'],['available']
Availability,Improve Hadoop-bam error message in createRecordReader,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1452:19,error,error,19,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1452,1,['error'],['error']
Availability,Improve error message for no-access and disabled-account cases,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2417:8,error,error,8,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2417,1,['error'],['error']
Availability,Improve error message in GATKRead.setMatePosition,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6779:8,error,error,8,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6779,1,['error'],['error']
Availability,Improve error message in GenomicsDBImport,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7375:8,error,error,8,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7375,1,['error'],['error']
Availability,Improve error message in spark tools when trying to access a local file from other nodes,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1417:8,error,error,8,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1417,1,['error'],['error']
Availability,Improve error message when Genotype PL and PP do not have 3 items when calculatePosteriorGLs,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3320:8,error,error,8,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3320,1,['error'],['error']
Availability,Improve failure message in VariantContextTestUtils,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8725:8,failure,failure,8,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8725,1,['failure'],['failure']
Availability,Improve import error message [VS-437],MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7855:15,error,error,15,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7855,1,['error'],['error']
Availability,Improve indel calls on repeats (review the current PCR error model).,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2519:55,error,error,55,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2519,1,['error'],['error']
Availability,"In FindBreakpointEvidenceSpark, KmerCleaner is ugly and seems redundant",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1889:62,redundant,redundant,62,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1889,1,['redundant'],['redundant']
Availability,"In GATK Office hours we found a change that contributed to this error message. The issue may be a bug or an issue with the data that is showing up with the more strict filters in the latest version. This request was created from a contribution made by Igor Islanov on July 06, 2020 12:11 UTC. Link: [https://gatk.broadinstitute.org/hc/en-us/community/posts/360071204731-FilterVariantTranches-brakes-on-new-version-of-Gatk](https://gatk.broadinstitute.org/hc/en-us/community/posts/360071204731-FilterVariantTranches-brakes-on-new-version-of-Gatk). \--. Good day,. While updating gatk from 4.1.4.0 to 4.1.8.0 and after running pipeline it brakes on FilterVariantTranches step with error:. htsjdk.tribble.TribbleException: The provided reference alleles do not appear to represent the same position, C\* vs. T\*. The command line  is  ; ; gatk FilterVariantTranches -I ${R1%%\_\*}-recal.bam -V ${R1%%\_\*}-annotated.vcf -R /mnt/d/GenLab/WES/reference/hg19.fasta --create-output-variant-index true --resource /mnt/d/GenLab/WES/db/00-All.vcf.gz --resource /mnt/d/GenLab/WES/db/00-common\_all.vcf.gz --resource /mnt/d/GenLab/WES/reference/1000G\_phase1.indels.hg19.sites.vcf --resource /mnt/d/GenLab/WES/reference/Mills\_and\_1000G\_gold\_standard.indels.hg19.sites.vcf --snp-tranche 99.9 --snp-tranche 99.95 --indel-tranche 99.0 --indel-tranche 99.4 -O ${R1%%\_\*}-filtered.vcf --tmp-dir /mnt/d/GenLab/WES/output/tmp --java-options ""-Xmx24G"". On 4.1.4.0 no problems whatsoever, on 4.1.8.0 not working at all. Double-confirmed by 2 seperate conda envs. The reference file is unchanged during whole running processes, obviously. Full error log: ; ; Running: ; ; java -Dsamjdk.use\_async\_io\_read\_samtools=false -Dsamjdk.use\_async\_io\_write\_samtools=true -Dsamjdk.use\_async\_io\_write\_tribble=false -Dsamjdk.compression\_level=2 -Xmx24G -jar /mnt/d/GenLab/WES/software/gatk-4.1.8.0/gatk-package-4.1.8.0-local.jar FilterVariantTranches -I D1394-recal.bam -V D1394-annotated.vcf -R /mnt/d/GenLab/WES/refe",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6701:64,error,error,64,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6701,2,['error'],['error']
Availability,"In GATK3, the VQSR tools have specific expectations for novel Ti/Tv that are based on what was known at the time before the 1000 Genomes project results were added to dbsnp. If you use the corresponding ""old"" dbsnp version, the expectations are fulfilled and your QC plots come out looking shiny. If you use a more recent version, key assumptions break down and it screws up the VQSR's QC routines (which produce the plots). Would be good to be able to handle whatever version of dbsnp users use. . This Issue was generated from your [forums](http://gatkforums.broadinstitute.org/discussion/comment/20493#Comment_20493)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/385:353,down,down,353,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/385,1,['down'],['down']
Availability,"In GATK4 (specifically 4.0.1.2), you can no longer give SelectVariants a file of variant IDs to keep. There isn't any error message, but the output VCF is empty. (It works in GATK3)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4460:118,error,error,118,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4460,1,['error'],['error']
Availability,"In IntervalUtils, when Picard intervals are parsed and checked for validity, (line 359 `glParser.isValidGenomeLoc(interval.getContig(), interval.getStart(), interval.getEnd(), true)`), if the contig doesn't match the supplied reference (via -R) then the error produced is `has an invalid interval`. The interval is perfectly valid, especially since the Picard interval_list has a corresponding sequence dictionary. I'm not sure if the preferred behavior here is to validate against the interval_list seqdict and then note that the -R reference doesn't match or to error because the -R ref doesn't match. Maybe if the tool requiresReference() and the -R doesn't match throw an error?. I encountered this in the context of a tool similar to SplitIntervals, which requires a reference even if a Picard interval_list is provided. I see that this is a TODO in GATKTool::getBestAvailableSequenceDictionary.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5410:254,error,error,254,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5410,3,['error'],['error']
Availability,"In a joint calling run with 11,000 samples, and broken up into over 10,000 scatters, a single one failed with a NPE. I was able to get around it for now by just ignoring that scatter for the output, but that's really not an ideal thing to do for joint calling (and we cannot do that for the CCDG callset). I can't give you the inputs because it was running on so many samples (and via GenomicsDB), but hopefully the stacktrace will help here:. java.lang.NullPointerException; at org.broadinstitute.hellbender.tools.walkers.genotyper.AlleleSubsettingUtils.calculateLikelihoodSums(AlleleSubsettingUtils.java:234); at org.broadinstitute.hellbender.tools.walkers.genotyper.AlleleSubsettingUtils.calculateMostLikelyAlleles(AlleleSubsettingUtils.java:199); at org.broadinstitute.hellbender.tools.walkers.genotyper.GenotypingEngine.calculateGenotypes(GenotypingEngine.java:241); at org.broadinstitute.hellbender.tools.walkers.genotyper.GenotypingEngine.calculateGenotypes(GenotypingEngine.java:205); at org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs.calculateGenotypes(GenotypeGVCFs.java:276); at org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs.regenotypeVC(GenotypeGVCFs.java:234); at org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs.apply(GenotypeGVCFs.java:213). I'm not sure who now owns this code, so will ping @davidbenjamin, @ldgauthier, @droazen.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3210:1334,ping,ping,1334,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3210,1,['ping'],['ping']
Availability,In case of shut down while updating gvcf file to GenomicDB,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7324:16,down,down,16,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7324,1,['down'],['down']
Availability,"In doing some performance evaluation work for some other HaplotypeCaller work I have noticed that there is apparently a performance regression on the order of perhaps 10-20% of runtime. Running locally I find that running over the same section of a WGS chromosome 15 on the current master 78a9ecd3123fdb77acf3dd7a73b0c12bf4602a1c vs the release 4.1.5.0 i get the following results: . Master: ; real	12m19.765s; user	13m49.276s; sys	0m8.571s; 4.1.5.0: ; real	9m50.558s; user	11m11.924s; sys	0m10.193s. Doing some very cursory digging it would appear that the culprit is in the HMM adjacent code being slowed down. (Note the relative runtime of HMM vs SW) ; Master: ; <img width=""822"" alt=""Screen Shot 2020-04-23 at 1 28 52 PM"" src=""https://user-images.githubusercontent.com/16102845/80130392-80115780-8566-11ea-8f2b-a6978ac71d39.png"">. 4.1.5.0: ; <img width=""850"" alt=""Screen Shot 2020-04-23 at 1 28 33 PM"" src=""https://user-images.githubusercontent.com/16102845/80130396-80115780-8566-11ea-9a1e-1e923bef47a5.png"">",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6567:607,down,down,607,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6567,1,['down'],['down']
Availability,In doing some trials with the ReadErrorCorrector I have noticed that it apparently seems to have no impact on my results. Upon closer inspection I have found the offending lines. In `ReadErrorCorrector.correctRead(final GATKRead inputRead)` we compute the `correctedQuals` and `correctedBases` arrays and then neglect to add them to the copied read later. This needs to be fixed. ; Other issues with the class:; - It apparently slows the HaplotypeCaller down 10x; - There is no tiebreaking for hamming distance comparisons; - ^those comparisons are done non-deterministically,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6365:454,down,down,454,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6365,1,['down'],['down']
Availability,"In helping @bhanugandham figure out why a particular site was failing it became apparent that merging dangling head code was failing to recover deletions in the dangling head. Furthermore there is some code in the dangling end recovery code that asserts a certain high standard of matching (usually 1 but sometimes dangling branch length/kmersize) `getMaxMismatches(final int lengthOfDanglingBranch)`. Both of these facts seem likely to cause dangling heads to be dropped despite their being still potentially informative, particularly the indel code. . I have added the ability for the index recovery code to account for the cigar string when merging dangling ends. Addtionally rather than counting mismatches to reject the branch it simply requires a minimum matching end (which can be changed, I suspect this is where the lionshare of the differences come from). Unfortunately changing the tests is non-trivial (as this happened to change the integration test results for HaplotypeCaller at a few sites) so I wanted to get this branch up to solicit advice a to whether it is worth pursuing this fix. @davidbenjamin @ldgauthier @droazen",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6113:136,recover,recover,136,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6113,3,['recover'],"['recover', 'recovery']"
Availability,"In high-depth calling (eg @meganshand's work with mitochondria) it is necessary to tweak the `min-pruning` argument. If it is too low, base errors render the assembly graph nearly dense, causing a loss of sensitivity when the assembly engine essentially chooses random haplotypes. If it is too high, we also lose sensitivity because true variants are pruned. Setting the command line argument differently for each sample is not only cumbersome. It also doesn't solve the problem because depth varies within the same bam. Thus, pruning must adapt to each assembly region.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4867:140,error,errors,140,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4867,1,['error'],['errors']
Availability,"In keeping concordance with gatk3, when computing the RankSumAnnotation for pileups when the likelihoods map is not available we attempt to match the bases of the reads to the allele in the variant context. This is problematic if the variant is not a snp. For most other annotations we explicitly only compute the annotation for SNPs in this case, but in order to mimic gatk3 behavior it will still attempt to compute the rank sum over indels. This should be evaluated and changed. . Related to #4450, #3803",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4452:116,avail,available,116,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4452,1,['avail'],['available']
Availability,"In light of the discovery of the (relatively minor) numerical differences caused by changes to non-CNV code outlined in #7649, and because we are still awaiting coverage from pipeline-level/CARROT testing, I decided to go ahead and add these exact-match tests. This essentially freezes current ModelSegments behavior, which has been exactly stable since https://github.com/broadinstitute/gatk/pull/5814; that is, from sometime between 4.1.0.0/4.1.1.0 almost 3 years ago up to 4.2.4.1 today. Note that the original test files were generated from the test BAMs (e.g., src/test/resources/large/cnv_somatic_workflows_test_files/HCC1143-t1-chr20-downsampled.deduplicated.bam), since these BAMs have been used in the past to consistently generate test files for other tools in the ModelSegments and GermlineCNVCaller pipelines. However, these original test files contained insufficient data to activate the changes found in #7649, even had exact-match tests been present. I thus took some old HCC1143T 100% WES data that I had and snippeted it to chr20. I've confirmed that the added tests with these files would've picked up the regression of log10factorial seen in #7649 for all relevant modes (i.e., all those that take in the allele counts as input, since that regression only affected allele-fraction MCMC sampling). Tests take maybe an additional minute to run and there was about ~12MB of additional large resources checked in, but I didn't try too hard to bring either down. I also added some early-fail parameter validation to check that the minimum total allele count in the case sample is zero in matched-normal mode. There are actually some open questions in my mind as to what the best behavior should be here, but given some of the discussion in #6499 and possible plans for using joint segmentation to do filtering of germline events, I think it's best to enforce that all het sites coming out of the genotyping step are the same across all samples. Recall that we added this parameter in #55",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7652:641,down,downsampled,641,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7652,1,['down'],['downsampled']
Availability,"In looking at Mutect2 for clinical applications, one thing that always seems to come up has to do with the big difference between the ref/alt coverage denoted in the VCF file and what is seen in IGV. For clinical reporting, many labs will provide mutant allele depths, along with the VAF estimate. I understand the purpose of downsampling at stages of the m2 workflow, and I also understand this negatively affects amplicon-based studies. How viable is it to provide more exact (include reads that are high quality but not used during variant determination) estimates of coverage at variant loci, while not substantially increasing runtime? It would be great to get some of our analysts away from always feeling as if they need to visualize calls in IGV... Thanks,; John",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3808:326,down,downsampling,326,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3808,1,['down'],['downsampling']
Availability,"In our Mutect2 workflow, we run a pair of Normal/Tumor through `CalculateContamination` step, the output of which is used in `FilterMutectCalls`. Since upgrading to `4.1.0.0`, `CalculateContamination` is breaking in cases where there're mismatched of N/T samples. . For e.g., `4.0.11.0` generates the following output:; ```; level contamination error; whole_bam 0.5013841326835697 0.0055644124674135865; ```; And `4.1.0.0` gives the following:; ```; sample contamination error; Run06_Pair07_Tumor 1.0 0.03452380752462225; ```. As a result of the above output files, the next step in our pipeline `FilterMutectCall` is failing (issue related to https://github.com/broadinstitute/gatk/issues/5821)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5880:345,error,error,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5880,2,['error'],['error']
Availability,"In running and re-running GvsPrepareCallset.wdl, one past run did not use compressed references, so that is always used with call caching is turned on (which it is by default), even though the dataset has reingested compressed references since then. This is the exact scenario that GetBQTableLastModifiedDatetime was created for — database-based tasks that we want to be able to call cache accurately. Integration run here: https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/ea2ecb01-f35f-441a-ba08-1e7938da2ebe (single failure is for ExtractFilterTask.GvsCreateFilterSet.BigQuery Query Scanned ""The relative difference between these is 0.0507051, which is greater than the allowed tolerance (0.05)"")",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8667:541,failure,failure,541,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8667,2,"['failure', 'toler']","['failure', 'tolerance']"
Availability,"In scripts/gatkcondaenv.yml.template, the following line produces an error upon the initial attempt to create the conda environment:. `anaconda::tensorflow=1.12.0=mkl_py36h69b6ba0_0`. It seems that the up to date dependency should be:. `anaconda::tensorflow=1.12.0=mkl_py36h2b2bbaf_0`. To replicate, perform a clean clone, with no conda environment created yet, and then:. `$ ./gradlew localDevCondaEnv`. This will fail with:. `ResolvePackageNotFound: - anaconda::tensorflow==1.12.0=mkl_py36h69b6ba0_0 `",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6369:69,error,error,69,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6369,1,['error'],['error']
Availability,"In some preliminary testing I've done it looks like using native Hadoop libraries can speed up tools running in Spark local mode. In private Spark tools under development (which travers a WGS BAM and then performing several shuffles) I have seen speedups of up to 40% (~ 46 minutes -> 26 minutes). An initial test of `MarkDuplicatesSpark` using a 30GB bam file gave me a 9% speedup (logs are below). It might be good to investigate making this easier for users (I downloaded Hadoop and built it from source, and then set gatk's java opts to load the native library). Two options might be: 1) distribute native libraries for supported architectures with gatk or 2) make sure gatk docker images include the native libraries and are set to use them. Logs for `MarkDuplicatesSpark` without and with native libraries, running on a Broad login server:. Without:. ```; $ ${GATK_DIR}/gatk MarkDuplicatesSpark -I CEUTrio.HiSeq.WEx.b37.NA12892.readnamesort.bam -O CEUTrio.HiSeq.WEx37; .NA12892.readnamesort.dupmarked.bam -- --spark-runner LOCAL --spark-master local[8]; Using GATK wrapper script ${GATK_DIR}/gatk/build/install/gatk/bin/gatk; Running:; ${GATK_DIR}/gatk/build/install/gatk/bin/gatk MarkDuplicatesSpark -I CEUTrio.HiSeq.WEx.b37.NA12892.readnamesort.bam -O CEUTrio.HiSeq.WEx.b37.NA12892.readnamesort.dupmarked.bam --spark; -master local[8]; 14:40:21.800 WARN SparkContextFactory - Environment variables HELLBENDER_TEST_PROJECT and HELLBENDER_JSON_SERVICE_ACCOUNT_KEY must be set or the GCS hadoop connector will not be configured properly; 14:40:21.889 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:${GATK_DIR}/gatk/build/install/gatk/lib/gkl-0.8.5.jar!/com/intel/gkl/native/libgkl_compression.so; 14:40:21.989 INFO MarkDuplicatesSpark - ------------------------------------------------------------; 14:40:21.990 INFO MarkDuplicatesSpark - The Genome Analysis Toolkit (GATK) v4.0.4.0-7-g46a8661-SNAPSHOT; 14:40:21.990 INFO MarkDuplicatesSpark - For support and documentatio",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4746:464,down,downloaded,464,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4746,1,['down'],['downloaded']
Availability,"In the README, the full download size when downloading large files using Git LFS is reported to be 2 GB in one section and several hundred MB in another section, when it is actually ~4.81 GB in size. ![git_lfs](https://user-images.githubusercontent.com/52426291/97712898-5d38a080-1abf-11eb-8070-d71d63d5add1.png)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6932:24,down,download,24,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6932,2,['down'],"['download', 'downloading']"
Availability,"In the VAT validation, give clearer error msg about which clinvar classification values are missing",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7939:36,error,error,36,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7939,1,['error'],['error']
Availability,"In the branch `dr_intel_deflater_bug_repro`, running `./gradlew clean test -Dtest.single=GatherVcfsIntegrationTest` will trigger the following test failure:. ```; Gradle suite > Gradle test > org.broadinstitute.hellbender.tools.GatherVcfsIntegrationTest.testBlockGather[14](/Users/droazen/src/hellbender/src/test/resources/large/gvcfs/combined.gatk3.7_30_ga4f720357.expected.vcf, 8536) FAILED; java.lang.AssertionError: different sizes 16940 vs 17070; at org.broadinstitute.hellbender.utils.test.VariantContextTestUtils.assertEqualVariants(VariantContextTestUtils.java:173); at org.broadinstitute.hellbender.tools.GatherVcfsIntegrationTest.testBlockGather(GatherVcfsIntegrationTest.java:103); Results: FAILURE (15 tests, 14 successes, 1 failures, 0 skipped); ```. The tool writes a vcf that, when read back in by GATK, appears to have fewer records than it should. The same test does NOT fail if you do ANY of the following:. * Edit `GatherVcfsIntegrationTest.testBlockGather()` to turn on the JDK deflater by changing `.addBooleanArgument(""use_jdk_deflater"", false);` to `.addBooleanArgument(""use_jdk_deflater"", true);`. * Keep the Intel deflater on, but edit `build.gradle` to change `samjdk.compression_level` to 1 or 2. (You'll also need to change the `Assert.assertEquals(System.getProperty(""samjdk.compression_level""), ""5"");` line in `GatherVcfsIntegrationTest.testBlockGather()` accordingly). * Edit the `getVcfsToShard` `DataProvider` in `GatherVcfsIntegrationTest` to change the failing `{LARGE_VCF, 8536}` test case to `{LARGE_VCF, 8535}`. This cuts the number of files that the vcf gets split into in half, and the test passes. * Comment out all but the last test case in the `getVcfsToShard` `DataProvider` in `GatherVcfsIntegrationTest`. This indicates that there is something stateful going on, since the test case does not fail if run in isolation. One additional bit of information: the test fails with the Intel deflater and compression levels 5 and 9, but with compression level 9 GA",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3117:148,failure,failure,148,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3117,3,"['FAILURE', 'failure']","['FAILURE', 'failure', 'failures']"
Availability,"In the course of tinkering with the GATK tutorial, I discovered that FilterVariantTranches errors out if it doesn't find any indels. The new logic isn't bulletproof (e.g. it will still run if it has SNP input and indel training), but it solves the SNP-only (and indel-only) case.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6411:91,error,errors,91,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6411,1,['error'],['errors']
Availability,In the error handling for `catch ( final FuncotatorUtils.TranscriptCodingSequenceException ex )` in `GencodeFuncotationFactory` we should add an `otherTranscript` to the output annotations with the transcript ID and an ERROR statement if an error occurred during processing. This will make the user more likely to see it if there was a problem creating funcotations for a particular transcript.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4861:7,error,error,7,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4861,3,"['ERROR', 'error']","['ERROR', 'error']"
Availability,"In the latest master, running for example `java -jar build/libs/gatk.jar FixVcfHead` returns:. ```; USAGE: <program name> [-h]. Available Programs:; --------------------------------------------------------------------------------------; Base Calling: Tools that process sequencing machine data, e.g. Illumina base calls, and detect sequencing level attributes, e.g. adapters; CheckIlluminaDirectory (Picard) Asserts the validity for specified Illumina basecalling data.; CollectIlluminaBasecallingMetrics (Picard) Collects Illumina Basecalling metrics for a sequencing run. ...skipped for brevity... VcfFormatConverter (Picard) Converts VCF to BCF or BCF to VCF.; VcfToIntervalList (Picard) Converts a VCF or BCF file to a Picard Interval List. --------------------------------------------------------------------------------------. Exception in thread ""main"" org.broadinstitute.hellbender.exceptions.UserException: 'FixVcfHead' is not a valid command.; Did you mean this?; FixVcfHeader; 	at org.broadinstitute.hellbender.Main.extractCommandLineProgram(Main.java:341); 	at org.broadinstitute.hellbender.Main.setupConfigAndExtractProgram(Main.java:172); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:192); 	at org.broadinstitute.hellbender.Main.main(Main.java:275); ```. I expect something without the stack trace and the scary ""Exception"" message. For example:. ```; USAGE: <program name> [-h]. Available Programs:; --------------------------------------------------------------------------------------; Base Calling: Tools that process sequencing machine data, e.g. Illumina base calls, and detect sequencing level attributes, e.g. adapters; CheckIlluminaDirectory (Picard) Asserts the validity for specified Illumina basecalling data.; CollectIlluminaBasecallingMetrics (Picard) Collects Illumina Basecalling metrics for a sequencing run. ...skipped for brevity... VcfFormatConverter (Picard) Converts VCF to BCF or BCF to VCF.; VcfToIntervalList (Picard) Converts a VCF or BCF file to ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4256:128,Avail,Available,128,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4256,1,['Avail'],['Available']
Availability,"In this branch are a number of improvements and changes that form the baseline for the current ongoing evaluation of the DRAGEN/GATK pipeline. This represents the joint work of both msyelf and @vruano. The major improvements in this branch are as follows:; - `EstimateDragstrModelParameters` tool for estimating the per-sample/per-STRType errors for use in the HMM gap open/gap close penalties as well as the necessary changes to the PairHMM loading code in order to adjust the model appropriately.; - Support for using the DragstrParams and flat SNP priors to compute genotype posteriors and the support for using them in the selection of genotypes as well as for computing the QUAL score. ; - Base Quality Dropout (BQD) model which penalizes variants with low average base quality scores among genotyped reads and reads that were otherwise excluded from the genotyper. A number of additional arguments to expose internal behaviors in the readThreadingAssembler and HaplotypeCaller have been made in order to support threading more lowBQ reads through to the genotyper. ; - Foreign Read Detection (FRD) model which uses an adjusted mapping quality score as well as read strandedness information to penalize reads that are likely to have originated from somewhere else on the genome. A number of additional arguments and behaviors have been exposed in order to preserve lower mapping quality reads in the HaplotypeCaller in service.; - Dynamic Read Disqualification, allows for longer/lower base quality reads to be less likely to be rejected by eliminating the hard cap on quality scores and further adjusting the limit based on the average base quality for bases in the read. . Design decisions that I would direct the reviewers attention to as they correspond to potentially dangerous/controversial changes:; - Because FRD/BQD require low quality ends to be included in the models for genotyping, I have added the option to softclipLowQualityEnds (as opposed to their current treatment which involv",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6634:339,error,errors,339,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6634,1,['error'],['errors']
Availability,"Included a test case generated using the buggy version of GenomicsDBImport in which the sample names declared in the file headers did not always match the samples provided to GenomicsDBImport via the sample name map file, and showed that the tool could repair the callset successfully.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3868:253,repair,repair,253,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3868,1,['repair'],['repair']
Availability,"Includes latest Gencode and an implicit fix for #6564. Had to make some code changes for latest liftover Gencode data(v34 -> hg19). . The associated DS test release correctly annotates data on hg19 and hg38. Left to do:. - [x] Update data sources downloader.; - [x] Update data source version validation code. Code updates:; - Now both hg19 and hg38 have the contig names translated to `chr__`; - Added 'lncRNA' to GeneTranscriptType.; - Added ""TAGENE"" gene tag.; - Added the MANE_SELECT tag to FeatureTag.; - Added the STOP_CODON_READTHROUGH tag to FeatureTag.; - Updated the GTF versions that are parseable.; - Fixed a parsing error with new versions of gencode and the remap; positions (for liftover files).; - Added test for indexing new lifted over gencode GTF.; - Added Gencode_34 entries to MAF output map.; - Minor changes to FuncotatorIntegrationTest.java for code syntax.; - Pointed data source downloader at new data sources URL.; - Minor updates to workflows to point at new data sources. Script updates:; - Updated retrieval scripts for dbSNP and Gencode.; - Added required field to gencode config file generation.; - Now gencode retrieval script enforces double hash comments at; top of gencode GTF files. Bug Fixes:; Removing erroneous trailing tab in MAF file output. - Fixes #6693",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6660:247,down,downloader,247,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6660,3,"['down', 'error']","['downloader', 'error']"
Availability,"Inconsistencies applies to GATK 4.beta.6 (observed by forum user) and 3.7 (recapitulated by @sooheelee). The inconsistency is namely in the form of BQ-clipping, e.g. from `AAFFFKKKKKKKKKKKKKKKKKKK` to `AAF55!!5!!!5!!!55!!5!!!!` for read and a supplementary read of the mate that is highlighted in red:. <img width=""1281"" alt=""screenshot 2017-11-14 14 00 00"" src=""https://user-images.githubusercontent.com/11543866/32800037-56ea32ba-c947-11e7-9d4d-b33a3ac5030a.png"">. This particular read pair does not contribute to variant calling. However, I assume there could be scenarios in which such BQ-clipped reads end up counting towards variant calling. - original forum user report for v4.beta.6: https://gatkforums.broadinstitute.org/gatk/discussion/comment/43851#Comment_43851; - original user data bundle: /humgen/gsa-scr1/pub/incoming/BasequalityBug.tar.gz; - Comms recapitulation and observations including for v3.7: https://github.com/broadinstitute/dsde-docs/issues/2661. I also request that GATK4 HaplotypeCaller port the `--emitDroppedReads` option that is available in v3 but not so far in v4. This option allows users to understand why a read may be dropped from HaplotypeCaller consideration.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3834:1061,avail,available,1061,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3834,1,['avail'],['available']
Availability,Incorrect error message when trying to read corrupt bam file,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2551:10,error,error,10,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2551,1,['error'],['error']
Availability,IndelRealignement error,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6798:18,error,error,18,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6798,1,['error'],['error']
Availability,IndexFeatureFile Error to Run Funcotator with Mouse Ensembl GTF,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7054:17,Error,Error,17,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7054,1,['Error'],['Error']
Availability,IndexFeatureFile: more informative error message when trying to index a malformed file,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4187:35,error,error,35,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4187,1,['error'],['error']
Availability,Ingest Error Handling Fixes [VS-261],MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7787:7,Error,Error,7,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7787,2,['Error'],['Error']
Availability,Initial check-in to find test failures. . Adresses #8328,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8689:30,failure,failures,30,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8689,1,['failure'],['failures']
Availability,"InputStream.readNonProxyDesc(ObjectInputStream.java:1826); 	at java.io.ObjectInputStream.readClassDesc(ObjectInputStream.java:1713); 	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2000); 	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535); 	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:422); 	at com.esotericsoftware.kryo.serializers.JavaSerializer.read(JavaSerializer.java:63); 	... 20 more; 17/11/15 19:43:35 INFO org.spark_project.jetty.server.AbstractConnector: Stopped Spark@5917b44d{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 17/11/15 19:43:35 WARN org.apache.spark.ExecutorAllocationManager: No stages are running, but numRunningTasks != 0; 19:43:35.858 INFO PrintVariantsSpark - Shutting down engine; [November 15, 2017 7:43:35 PM UTC] org.broadinstitute.hellbender.tools.spark.pipelines.PrintVariantsSpark done. Elapsed time: 0.43 minutes.; Runtime.totalMemory()=823132160; org.apache.spark.SparkException: Job aborted due to stage failure: Exception while getting task result: com.esotericsoftware.kryo.KryoException: Error during Java deserialization.; Serialization trace:; genotypes (org.seqdoop.hadoop_bam.VariantContextWithHeader); interval (org.broadinstitute.hellbender.engine.spark.SparkSharder$PartitionLocatable); 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAG",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3840:8207,failure,failure,8207,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3840,1,['failure'],['failure']
Availability,Instructions on how to download BQ Metadata and visualize results,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7359:23,down,download,23,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7359,1,['down'],['download']
Availability,Integer overflow error,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6302:17,error,error,17,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6302,1,['error'],['error']
Availability,Integration run [here](https://job-manager.dsde-prod.broadinstitute.org/jobs/76c46310-3c0d-43a8-9fce-072ef7750651). As written the task requires `apt-get`. Converting this to Alpine would be non-trivial and not really worthwhile as it might even take longer to build all the extra things into the `alpine` image that we simply download with the `slim` image.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8065:327,down,download,327,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8065,1,['down'],['download']
Availability,"Integration run here: https://app.terra.bio/#workspaces/gvs-dev/mlc%20GVS%20Quickstart%203%20samples/job_history/acb5b878-af45-443d-8139-0f0044cbcb38. The basic problem: https://news.ycombinator.com/item?id=9255830. Repro:. ```; % # make a file shaped like what was failing in ingest; % for i in $(seq 50000); do ; echo foo,${i} >> file.csv; done; % # repro the pipeline that was failing; % set -o pipefail; % cat file.csv | cut -d, -f2 | sort -r -n | head -1; 50000; % echo $?; 141; % # repeat with temp file construct; % head -1 <(cat file.csv | cut -d, -f2 | sort -r -n) ; 50000; % echo $?; 0; %; ```; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8441:315,echo,echo,315,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8441,3,['echo'],['echo']
Availability,IntegrationTestSpec is hardwired to text files and bam files but compares them byte-by-byte. We need more digested way of comparing files to remove the brittleness of md5 while retaining the ability to notice failures.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/190:209,failure,failures,209,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/190,1,['failure'],['failures']
Availability,Interesting to see whether it recovers real vairants.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7321:30,recover,recovers,30,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7321,1,['recover'],['recovers']
Availability,Intermittent errors when running on distributed Spark cluster,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1491:13,error,errors,13,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1491,1,['error'],['errors']
Availability,"Intermittent failure at https://travis-ci.com/github/broadinstitute/gatk/jobs/297047618. ```; [TileDB::FileSystem] Error: hdfs: Cannot list contents of dir gs://hellbender-test-logs/staging/703469fc-52fe-441d-b6e0-8092a114fe2c//chr20$17960187$17981445/genomicsdb_meta_dir; hdfsBuilderConnect(forceNewInstance=0, nn=gs://hellbender-test-logs, port=0, kerbTicketCachePath=(NULL), userName=(NULL)) error:; java.io.IOException: Must supply a value for configuration setting: fs.gs.project.id; 	at com.google.cloud.hadoop.util.ConfigurationUtil.getMandatoryConfig(ConfigurationUtil.java:39); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.createOptionsBuilderFromConfig(GoogleHadoopFileSystemBase.java:2185); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.configure(GoogleHadoopFileSystemBase.java:1832); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.initialize(GoogleHadoopFileSystemBase.java:1013); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.initialize(GoogleHadoopFileSystemBase.java:976); 	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2812); 	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:100); 	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2849); 	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2831); 	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:389); 	at org.apache.hadoop.fs.FileSystem$1.run(FileSystem.java:171); 	at org.apache.hadoop.fs.FileSystem$1.run(FileSystem.java:168); 	at java.base/java.security.AccessController.doPrivileged(Native Method); 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423); 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1836); 	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:168); 	at org.genomicsdb.reader.GenomicsDBQueryStream.jniGenomicsDBInit(Native Method); 	at org.genomicsdb.reader.GenomicsDBQueryStream.<init>(GenomicsDBQueryStream.java:209); 	at o",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6522:13,failure,failure,13,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6522,3,"['Error', 'error', 'failure']","['Error', 'error', 'failure']"
Availability,Intermittent failure of AsynchronousStreamWriterServiceUnitTest.testAsyncWriteInBatches on Travis.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4024:13,failure,failure,13,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4024,1,['failure'],['failure']
Availability,Intermittent failure of GenomicsDBImportIntegrationTest.testWriteToAndQueryFromGCS,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6522:13,failure,failure,13,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6522,1,['failure'],['failure']
Availability,"IntervalArgumentCollection - Processing 83257441 bp from intervals; 14:52:21.917 INFO PrintReads - Done initializing engine; 14:52:22.027 INFO ProgressMeter - Starting traversal; 14:52:22.027 INFO ProgressMeter - Current Locus Elapsed Minutes Reads Processed Reads/Minute; 14:52:32.033 INFO ProgressMeter - chr17:6779805 0.2 494000 2962814.9; 14:52:42.035 INFO ProgressMeter - chr17:18100301 0.3 1275000 3823661.7; 14:52:52.089 INFO ProgressMeter - chr17:32183301 0.5 2017000 4025814.2; 14:53:02.141 INFO ProgressMeter - chr17:38342966 0.7 2500000 3739436.1; 14:53:12.267 INFO ProgressMeter - chr17:46549838 0.8 3360000 4012818.7; 14:53:22.273 INFO ProgressMeter - chr17:63099258 1.0 4210000 4192879.1; 14:53:30.687 INFO PrintReads - No reads filtered by: WellformedReadFilter; 14:53:30.687 INFO ProgressMeter - chr17:83185333 1.1 5250614 4588427.4; 14:53:30.687 INFO ProgressMeter - Traversal complete. Processed 5250614 total reads in 1.1 minutes.; 14:53:33.576 INFO PrintReads - Shutting down engine; [October 5, 2017 2:53:33 PM EDT] org.broadinstitute.hellbender.tools.PrintReads done. Elapsed time: 1.38 minutes.; Runtime.totalMemory()=8385462272; ```. ## Cloud CRAM; Running just PrintReads without `-L` intervals succeeds.; ```; /humgen/gsa-hpprojects/GATK/gatk4/gatk-4.beta.5/gatk-launch PrintReads \; -I gs://shlee-dev/1kg/exome_GRCh38DH/cram/HG00190.alt_bwamem_GRCh38DH.20150826.FIN.exome.cram \; -R /humgen/gsa-hpprojects/dev/shlee/ref/GRCh38_1kg/GRCh38_full_analysis_set_plus_decoy_hla.fa \; -O HG00190_cram.bam; ```; ```; -bash-4.1$ /humgen/gsa-hpprojects/GATK/gatk4/gatk-4.beta.5/gatk-launch PrintReads \; > -I gs://shlee-dev/1kg/exome_GRCh38DH/cram/HG00190.alt_bwamem_GRCh38DH.20150826.FIN.exome.cram \; > -R /humgen/gsa-hpprojects/dev/shlee/ref/GRCh38_1kg/GRCh38_full_analysis_set_plus_decoy_hla.fa \; > -O HG00190_cram.bam; Using GATK jar /humgen/gsa-hpprojects/GATK/gatk4/gatk-4.beta.5/gatk-package-4.beta.5-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjd",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3669:4502,down,down,4502,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3669,1,['down'],['down']
Availability,IntervalUtils::loadIntervals gives bad error on missing .interval_list file,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6956:39,error,error,39,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6956,1,['error'],['error']
Availability,Investigate GATK error message with docker --network none,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7983:17,error,error,17,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7983,1,['error'],['error']
Availability,Investigate NIO retry failures observed in CNV walkers.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5631:22,failure,failures,22,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5631,1,['failure'],['failures']
Availability,Investigate Potential Base Recovery Error In Reference Caching Code,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6338:27,Recover,Recovery,27,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6338,2,"['Error', 'Recover']","['Error', 'Recovery']"
Availability,Investigate dataflow debugging/error logging,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/276:31,error,error,31,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/276,1,['error'],['error']
Availability,Investigate errors seen in the DRAGEN-GATK GVCF outputs,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7108:12,error,errors,12,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7108,1,['error'],['errors']
Availability,Investigate out of memory error in CalibrateDragstrModel,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7189:26,error,error,26,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7189,1,['error'],['error']
Availability,Is the Downsampled annotation still a real thing?,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5678:7,Down,Downsampled,7,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5678,1,['Down'],['Downsampled']
Availability,"Is there a script that can be tuned to stop putting the legend of VQSR plots on top of the plot?; It is masking important information as shown below.; When this is using ggplot2, the legend could be captured and plotted as a separate grid object next to the plot (for instance). ![example](https://i.imgur.com/53rbF0c.png)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6585:104,mask,masking,104,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6585,1,['mask'],['masking']
Availability,"Is there a way to specify the number of threads or cores to use ? Specifically for HaplotypeCaller ?; In GATK3, we had -nt and -nct (more of less reliable for what I read) but it doesn't seems to be here anymore.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4448:146,reliab,reliable,146,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4448,1,['reliab'],['reliable']
Availability,"Issue from the forum regarding GenotypeGVCFs. User is getting an error with the bcf codec. They are running 4.1.7.0, so I recommended updating to 4.1.8.1 for now to see if it is fixed. This request was created from a contribution made by Brynjar Sigurðsson on August 04, 2020 09:49 UTC. Link: [https://gatk.broadinstitute.org/hc/en-us/community/posts/360072049511-Assertion-nps-nps-line-n-sample-n-failed](https://gatk.broadinstitute.org/hc/en-us/community/posts/360072049511-Assertion-nps-nps-line-n-sample-n-failed). \--. Hello,. I am running a variant calling using GenotypeGVCFs. The process first creates a GenomicsDB on 50Kbase regions from 150K GVCFs and then runs GenotypeGVCFs wrapped in GNU parallel (after splitting the region into as many threads as are available). Most regions complete without a problem, but some fail on GenotypeGVCFs with the assertion error. java: /home/vagrant/GenomicsDB/dependencies/htslib/vcf.c:4225: bcf\_update\_format: Assertion \`nps && nps\*line->n\_sample==n' failed. Some of the failing regions I have run with up to 1.5 TB memory (18 threads) but they still fail. **a) GATK version used**. **version 4.1.7.0**. **b) Exact GATK commands used**. java -Dsamjdk.use\_async\_io\_read\_samtools=false -Dsamjdk.use\_async\_io\_write\_samtools=true -Dsamjdk.use\_async\_io\_write\_tribble=false -Dsamjdk.compression\_level=2 -Xmx1290240M -Xms1290240M -DGATK\_STACKTRACE\_ON\_USER\_EXCEPTION=true -jar /nfs/fs1/bioinfo/apps-x86\_64/GATK/gatk-4.1.7.0/gatk-package-4.1.7.0-local.jar GenomicsDBImport --genomicsdb-workspace-path /tmp/tmp.ceRdvv/GDB --intervals chr1:5149001-5201000 --tmp-dir /tmp/tmp.ceRdvv/GDB\_tmp --sample-name-map /tmp/tmp.ceRdvv/snmap --batch-size 100 --reader-threads 17. java -Dsamjdk.use\_async\_io\_read\_samtools=false -Dsamjdk.use\_async\_io\_write\_samtools=true -Dsamjdk.use\_async\_io\_write\_tribble=false -Dsamjdk.compression\_level=2 -Djava.io.tmpdir=/tmp/tmp.ceRdvv -Xmx71680M -Xms71680M -jar /nfs/fs1/bioinfo/apps-x86\_64/GATK/gatk",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6742:65,error,error,65,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6742,3,"['avail', 'error']","['available', 'error']"
Availability,"Issue while Building GATK4. sudo ./gradlew bundle; Starting a Gradle Daemon, 1 incompatible and 1 stopped Daemons could not be reused, use --status for details. FAILURE: Build failed with an exception. * Where:; Build file '/home/rafay/gatk-4.0.2.0/build.gradle' line: 289. * What went wrong:; A problem occurred evaluating root project 'gatk'.; > Cannot find '.git' directory. * Try:; Run with --stacktrace option to get the stack trace. Run with --info or --debug option to get more log output. BUILD FAILED. Total time: 24.349 secs",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4475:161,FAILURE,FAILURE,161,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4475,1,['FAILURE'],['FAILURE']
Availability,"Issue: Integer overflow error caused Mutect2 v4.1.4.0 to generate a stats file with a negative number. Solution is to change the int data type to long. User report:. Hello, I've just adapted my pipeline to the new filtering strategies, while looking at the files I noticed that for a WGS run I obtained a stats file with a negative number:; [egrassi@occam biodiversa]>cat mutect/CRC1307LMO.vcf.gz.stats; statistic value; callable -1.538687311E9. Looking around about the meaning of the number I found https://gatkforums.broadinstitute.org/gatk/discussion/24496/regenerating-mutect2-stats-file, so I'm wondering if I should be worried by having a negative number of callable sites :/; What's more puzzling is that FilterMutectCalls after ran without any error. Before running mutect I used the usual best practices pipeline, then:; ; gatk Mutect2 -tumor CRC1307LMO -R /archive/home/egrassi/bit/task/annotations/dataset/gnomad/GRCh38.d1.vd1.fa -I align/realigned_CRC1307LMO.bam -O mutect/CRC1307LMO.vcf.gz --germline-resource /archive/home/egrassi/bit/task/annotations/dataset/gnomad/af-only-gnomad.hg38.vcf.gz --f1r2-tar-gz mutect/CRC1307LMO_f1r2.tar.gz --independent-mates 2> mutect/CRC1307LMO.vcf.gz.log; ; gatk CalculateContamination -I mutect/CRC1307LMO.pileup.table -O mutect/CRC1307LMO.contamination.table --tumor-segmentation mutect/CRC1307LMO.tum.seg 2> mutect/CRC1307LMO.contamination.table.log; ; gatk LearnReadOrientationModel -I mutect/CRC1307LMO_f1r2.tar.gz -O mutect/CRC1307LMO_read-orientation-model.tar.gz 2> mutect/CRC1307LMO_read-orientation-model.tar.gz.log; ; gatk FilterMutectCalls -V mutect/CRC1307LMO.vcf.gz -O mutect/CRC1307LMO.filtered.vcf.gz -R /archive/home/egrassi/bit/task/annotations/dataset/gnomad/GRCh38.d1.vd1.fa --stats mutect/CRC1307LMO.vcf.gz.stats --contamination-table mutect/CRC1307LMO.contamination.table --tumor-segmentation=mutect/CRC1307LMO.tum.seg --filtering-stats mutect/CRC1307LMO_filtering_stats.tsv --ob-priors mutect/CRC1307LMO_read-orientation-model.t",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6302:24,error,error,24,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6302,2,['error'],['error']
Availability,"It appears for at least the last 6 days that our travis tests for the the CNV and M2 WDLs have been failing generating the following error messages:. `[2017-09-07 10:05:53,75] [warn] BackendPreparationActor_for_0b561ba3:CNVSomaticPanelWorkflow.PadTargets:-1:1 [0b561ba3]: Docker lookup failed:; java.lang.Exception: Docker image broadinstitute/gatk:80d8662d760f451045957080813d3963a1b68cc5 not found; 	at cromwell.engine.workflow.WorkflowDockerLookupActor.cromwell$engine$workflow$WorkflowDockerLookupActor$$handleLookupFailure(WorkflowDockerLookupActor.scala:193); 	at cromwell.engine.workflow.WorkflowDockerLookupActor$$anonfun$3.applyOrElse(WorkflowDockerLookupActor.scala:91); 	at cromwell.engine.workflow.WorkflowDockerLookupActor$$anonfun$3.applyOrElse(WorkflowDockerLookupActor.scala:75); 	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36); 	at akka.actor.FSM$class.processEvent(FSM.scala:663); 	at cromwell.engine.workflow.WorkflowDockerLookupActor.akka$actor$LoggingFSM$$super$processEvent(WorkflowDockerLookupActor.scala:39); 	at akka.actor.LoggingFSM$class.processEvent(FSM.scala:799); 	at cromwell.engine.workflow.WorkflowDockerLookupActor.processEvent(WorkflowDockerLookupActor.scala:39); 	at akka.actor.FSM$class.akka$actor$FSM$$processMsg(FSM.scala:657); 	at akka.actor.FSM$$anonfun$receive$1.applyOrElse(FSM.scala:651); 	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36); 	at cromwell.docker.DockerClientHelper$$anonfun$dockerResponseReceive$1.applyOrElse(DockerClientHelper.scala:16); 	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:170); 	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171); 	at akka.actor.Actor$class.aroundReceive(Actor.scala:496); 	at cromwell.engine.workflow.WorkflowDockerLookupActor.aroundReceive(WorkflowDockerLookupActor.scala:39); 	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:526); 	at akka.actor.ActorCell.invoke(ActorCell.scala:495); 	at akka.d",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3558:133,error,error,133,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3558,1,['error'],['error']
Availability,"It is not clear to me from the docs whether parent/child pairs are intended to be supported by `CalculateGenotypePosteriors`, but a quick glance at the [mention](https://github.com/broadinstitute/gatk/blob/67f0f0f2e59185b721398b17c24eba487a2ac76c/src/main/java/org/broadinstitute/hellbender/tools/walkers/variantutils/FamilyLikelihoods.java#L210)[s](https://github.com/broadinstitute/gatk/blob/67f0f0f2e59185b721398b17c24eba487a2ac76c/src/main/java/org/broadinstitute/hellbender/tools/walkers/variantutils/FamilyLikelihoods.java#L231) in comments in `FamilyLikelihoods.java` makes me suspect that they are intended to be supported. (In any case, from my perspective, it would be a very nice feature as I have yet to find a tool that will robustly handle this use case.). Here are the main issues that I'm encountering when trying to use `CalculateGenotypePosteriors` for a parent-child pair:; 1) If I supply a ped file with two individuals like the following, [this check](https://github.com/broadinstitute/gatk/blob/1e98c6d02cefefbaa1a15db0aea64ea7518025fa/src/main/java/org/broadinstitute/hellbender/tools/walkers/variantutils/CalculateGenotypePosteriors.java#L260) gets triggered, resulting in printing of the warning and skipping family priors.; ```; FAM	MOM	0	0	2	0; FAM	CHILD	0	MOM	2	0; ```; 2) If I add a father to the ped file to form a trio, like below, `CalculateGenotypePosteriors` proceeds without the warning that occurs in first approach, but the output doesn't appear to make any adjustments to genotypes, posteriors, etc. Note that there is no entry for ""DAD"" in the input VCF.; ```; FAM	MOM	0	0	2	0; FAM	DAD	0	0	1	0; FAM	CHILD	DAD	MOM	2	0; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5409:738,robust,robustly,738,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5409,1,['robust'],['robustly']
Availability,"It looks like all of our builds are failing since we cleared the cache because of R dependency issues. ```; ... Setting up r-base-core (3.1.3-1trusty) ...; Installing new version of config file /etc/bash_completion.d/R ...; Installing new version of config file /etc/R/Renviron.site ...; Installing new version of config file /etc/R/Makeconf ...; Installing new version of config file /etc/R/repositories ...; Installing new version of config file /etc/R/Rprofile.site ...; Installing new version of config file /etc/R/ldpaths ...; Replacing config file /etc/R/Renviron with new version; W: --force-yes is deprecated, use one of the options starting with --allow instead.; Installing packages into ‘/home/travis/site-library’; (as ‘lib’ is unspecified); Error: (converted from warning) dependencies ‘rlang’, ‘vctrs’ are not available; Execution halted; ```. Both libraries now require R >= 3.2.; We could either try again to nail down the R versions exactly, which is almost certainly possible but not something we've ever figured out a good way to do, or we could just upgrade R and hope for the best, kicking the can down the road again.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6072:754,Error,Error,754,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6072,4,"['Error', 'avail', 'down']","['Error', 'available', 'down']"
Availability,"It looks like this is a bug with 4.2.0.0 because the same Mutect2 output has no issues with FilterMutectCalls 4.1.6.0. . This request was created from a contribution made by Qihan Long on June 04, 2021 03:21 UTC. Link: [https://gatk.broadinstitute.org/hc/en-us/community/posts/360078236332-The-output-of-Mutect2-cannot-be-accepted-by-FilterMutectCalls-in-GATK-4-2-0-0](https://gatk.broadinstitute.org/hc/en-us/community/posts/360078236332-The-output-of-Mutect2-cannot-be-accepted-by-FilterMutectCalls-in-GATK-4-2-0-0). \--. If you are seeing an error, please provide(REQUIRED) : ; ; a) GATK version used: 4.2.0.0 ; ; b) Exact command used: . gatk FilterMutectCalls \\ ; ; \-R /public1/data/resources/ref\_genome/GRCh38/GRCh38.d1.vd1.fa \\ ; ; \-V somatic\_mutation/Mutect2/test.vcf.gz \\ ; ; \-O somatic\_mutation/FilterMutectCalls/test.vcf.gz. c) Entire error log:. I used the ""--enable-all-annotations"" option within Mutect2 to get a vcf file with abundant information. However, the following FilterMutectCalls step seemed to be intolerant of some information within previous step's vcf file record. The intolerated record within vcf listed below: . chr1 6197724 . C CT,CTT,CTTT . . AC=1,1,1;AF=0.167,0.167,0.167;AN=6;AS\_BaseQRankSum=-6.431;AS\_MQ=60.00,60.00,60.00;AS\_MQRankSum=0.000;AS\_ReadPosRankSum=5.751;AS\_SB\_TABLE=42,880|3,164|3,32|0,14;**AS\_UNIQ\_ALT\_READ\_COUNT=167|35|14**;BQHIST=5,1,0,0,1,11,2,0,0,0,14,2,0,0,1,15,1,0,0,0,16,1,0,0,0,17,0,2,0,0,18,2,0,0,1,19,6,0,1,0,20,25,0,2,2,21,13,0,1,2,22,20,0,3,3,23,2,1,2,1,24,6,0,2,0,25,21,1,4,7,26,33,0,5,6,27,18,0,0,7,28,29,0,0,4,29,26,2,4,8,30,161,4,5,51,31,263,2,3,51,32,129,2,3,22,33,41,0,0,0,34,15,0,0,0,35,20,0,0,0,36,19,0,0,0,37,12,0,0,0,38,1,0,0,0,39,9,0,0,0,41,18,0,0,0,44,26,0,0,0;BaseQRankSum=-6.431;ClippingRankSum=-7.714;DP=1323;ECNT=1;FS=0.000;LikelihoodRankSum=-7.886;MBQ=31,30,26,30;MFRL=6590,6585,4819,6586;MMQ=60,60,60,60;MPOS=16,15,7;MQ=59.98;MQ0=0;MQRankSum=0.000;NALOD=0.569,1.49,1.49;NCC=0;NCount=0;NLOD=27.80,30.51,30",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7298:545,error,error,545,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7298,2,['error'],['error']
Availability,"It looks like we've found a bug in GenomicsDB. We had a project with 26 replicates (same sample in there twice) among another ~1000 samples. Therefore we uniquified the names in the sample map that’s input to TileDB for those 26 samples (i.e. converted them to project.sample instead of just sample) -- but obviously the names in the gvcfs remained unaltered. When we look at the output VCF from GenomicsDB, there's definitely a problem. These 52 samples are the first ones in the list and here's what we see:. The first 26 samples (the first occurrence of the replicates) are fine.; Then the next 24 samples (the second occurrence of the replicates) are all “.:0,0” (i.e. empty) for all columns in the VCF.; Then the next 2 samples (also second occurrences of replicates) are fine. Given that our batch size was 50 when importing into GenomicsDB, this looks suspiciously like an error with the batching. So within a batch it looks like it’s not respecting the renaming somehow?. @kgururaj",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3814:880,error,error,880,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3814,1,['error'],['error']
Availability,"It looks like when this was added, a mistake was made between a filter returning test() == true (passing the filter) and test() == false (failing the filter, read removed). Furthermore the invert filter argument in here is now redundant as of #8724 and I will go ahead and remove it from this filter. I have also tweaked the filter arguments slightly to clarify what they do now mean more intuitively. . Fixes #8887",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8888:227,redundant,redundant,227,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8888,1,['redundant'],['redundant']
Availability,"It seems a lot of users use bcftools on their VCFs, and it sometimes converts floats to integers. For example MQ=31.0 to MQ=31. This change causes GATK tools to error. Is it possible to relax this validation?. ----; User Report; ----. Hi,. Every time I had this message, this was due to bcftools which can change some float values to an integer representation : (e.g : before bcftools : MQ=31.0; after bcftools : MQ=31). . The fact that GATK is very strict on that subject (40.0 is considered as a float while 40 is not) have some advantages and some drawbacks. I hope this problem will be resolved in GATK4 because bcftools is really useful and widely used when dealing with vcf files. This Issue was generated from your [forums] ; [forums]: https://gatkforums.broadinstitute.org/gatk/discussion/comment/43270#Comment_43270",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3734:161,error,error,161,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3734,1,['error'],['error']
Availability,"It seems like the argument `--force-call-filtered-alleles` is redundant with `--alleles`. Unless I misunderstand it, it looks like force-call-filtered-alleles is just used to decide if we should look at the `--alleles` argument or not, which is only used in conjunction with force calling. It seems redundant. Couldn't we merge them into a single argument that takes an allele list?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6572:62,redundant,redundant,62,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6572,2,['redundant'],['redundant']
Availability,"It seems that a [few users](https://gatk.broadinstitute.org/hc/en-us/community/posts/11440622639387-Unable-to-trim-uncertain-bases-without-flow-order-information?page=1#community_comment_12925222020763) have complained when they try to use LongReads that their minimap2 bams are failing with the message: ; `org.broadinstitute.hellbender.exceptions.GATKException: Unable to trim uncertain bases without flow order information`. It looks like in `AssemblyBasedCallerUtils.java:147` we are calling `FlowBasedReadUtils.isFlow(originalRead)` on every read and the presence of the `tp` read tag in reads is considered sufficient to flag reads as being flow based which finally causes them to fail. This check was probably misguided, we should really be checking flow-based identity (at this stage anyway) from the readgroup in the header to prevent any spurious read tags from god knows what aligners don't cause problems like this again. Alternatively we should thread the ""isFlowBased"" check down into this part of the code so its opt-in to treat flow based reads specially when clipping here.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8335:989,down,down,989,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8335,1,['down'],['down']
Availability,"It seems that insQual and delQual score may produce by BQSR or modified by the Indel error model may sum more than 1. Eg. IQ = 1, DQ = 1 so 0.9 prob of an insertion and 0.9 prob of a deletion. This would result Prob > 1 in PairHMM (a different bug from the previously reported to this regard). . The question is how to fix this… must be controlled by BQSR/ index error model… should result in a warning and the qual adjusted to a maximum error probability.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/268:85,error,error,85,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/268,3,['error'],['error']
Availability,"It seems that the code in SparkSharder responsible of grouping Locatables into sharded reference intervals cannot handle large locatables that would overlap more than a couple of shards... . ```; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 2.0 failed 1 times, most recent failure: Lost task 0.0 in stage 2.0 (TID 2, localhost): org.broadinstitute.hellbender.exceptions.UserException: Max size of locatable exceeded. Max size is 10000, but locatable size is 1157593. Try increasing shard size and/or padding. Locatable: [VC Unknown @ 1:29721370-30878962 Q. of type=SYMBOLIC alleles=[C*, <INV>] attr={ALIGN_LENGTHS=144, ASSEMBLY_IDS=276, CONTIG_IDS=contig-5, END=30878962, HQ_MAPPINGS=1, INSERTED_SEQUENCE=AAACCAGGCCCCAGGGCCCCAGAAAGCAGGTAGTAGGGCCAAGCGAGGGCCGGGGCAGGCTAGCTCCAAGCCCACTGCAGGCCTCAGCTCTGCT, INV55=true, MAPPING_QUALITIES=60, MAX_ALIGN_LENGTH=144, SVLEN=1157592, SVTYPE=INV, TOTAL_MAPPINGS=1} GT=[]; 	at org.broadinstitute.hellbender.engine.spark.SparkSharder$4.computeNext(SparkSharder.java:232); 	at org.broadinstitute.hellbender.engine.spark.SparkSharder$4.computeNext(SparkSharder.java:212); 	at org.broadinstitute.hellbender.relocated.com.google.common.collect.AbstractIterator.tryToComputeNext(AbstractIterator.java:143); 	at org.broadinstitute.hellbender.relocated.com.google.common.collect.AbstractIterator.hasNext(AbstractIterator.java:138); 	at org.broadinstitute.hellbender.relocated.com.google.common.collect.Iterators$7.computeNext(Iterators.java:650); 	at org.broadinstitute.hellbender.relocated.com.google.common.collect.AbstractIterator.tryToComputeNext(AbstractIterator.java:143); 	at org.broadinstitute.hellbender.relocated.com.google.common.collect.AbstractIterator.hasNext(AbstractIterator.java:138); 	at org.broadinstitute.hellbender.relocated.com.google.common.collect.TransformedIterator.hasNext(TransformedIterator.java:43); 	at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42). ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2554:254,failure,failure,254,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2554,2,['failure'],['failure']
Availability,It should detect that java is missing and exit with a clear error message instead.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5993:60,error,error,60,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5993,1,['error'],['error']
Availability,"It should instead notice that `sampleToVCMap.get()` has returned null, and throw a descriptive error message (including, crucially, the sample name in question) instead of allowing a `NullPointerException` to occur.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2715:95,error,error,95,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2715,1,['error'],['error']
Availability,It was noticed while doing #8351 that the `GencodeFunctotation.equals()` method has the following line in it; ``` ; if (geneTranscriptType != that.geneTranscriptType) return false; ; ```. Unfortunately the geneTranscriptType is stored as a Sting and thus this should NOT be expected to succeed in almost any case. As it stands fixing this innocuous oversight seems to break several of the combinatorial funcotator tests and an integration test. Somebody should fix this behavior (easy) and validate that the test changes are within tolerable levels (hard).,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8385:532,toler,tolerable,532,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8385,1,['toler'],['tolerable']
Availability,"It's a little confusing that we use downsampled tumor BAMs for the gCNV WDL tests, for example. Can wait until after release.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4007:36,down,downsampled,36,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4007,1,['down'],['downsampled']
Availability,"Its possible to specify CNN inference size argument values that cause the Python process run out of memory, and the failure mode appears to be the java process hangs. Its not clear whether its always possible to recover from this using the global exception handler we currently install on the Python side - we need to explore a bit to see if the handler is being invoked on OOM; whether catching the OOM exception explicitly would help, or if we need an alternative reporting strategy for low-memory conditions. Attached is a log provided by @bhanugandham from a run in a Terra notebook that failed and that exhibited a hang that we assume was due to OOM, and that was resolved by reducing the inference batch size. [gatkStreamingProcessJournal-772629669.txt](https://github.com/broadinstitute/gatk/files/2988819/gatkStreamingProcessJournal-772629669.txt)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5820:116,failure,failure,116,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5820,2,"['failure', 'recover']","['failure', 'recover']"
Availability,JAVA doc error,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6466:9,error,error,9,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6466,1,['error'],['error']
Availability,"JDK Defaults.COMPRESSION_LEVEL : 2; 23:15:30.439 INFO AnalyzeCovariates - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 23:15:30.440 INFO AnalyzeCovariates - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 23:15:30.440 INFO AnalyzeCovariates - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 23:15:30.440 INFO AnalyzeCovariates - Deflater: IntelDeflater; 23:15:30.440 INFO AnalyzeCovariates - Inflater: IntelInflater; 23:15:30.440 INFO AnalyzeCovariates - GCS max retries/reopens: 20; 23:15:30.440 INFO AnalyzeCovariates - Requester pays: disabled; 23:15:30.440 INFO AnalyzeCovariates - Initializing engine; 23:15:30.440 INFO AnalyzeCovariates - Done initializing engine; 23:15:30.790 INFO AnalyzeCovariates - Generating csv file '/tmp/AnalyzeCovariates6611620304443967041.csv'; 23:15:30.854 INFO AnalyzeCovariates - Generating plots file '/researchers/sebastian.hollizeck/lowcWGS/IN-PM01004/Bam/AnalyzeCovariates.pdf'; 23:15:31.932 INFO AnalyzeCovariates - Shutting down engine; [January 19, 2020 11:15:31 PM UTC] org.broadinstitute.hellbender.tools.walkers.bqsr.AnalyzeCovariates done. Elapsed time: 0.04 minutes.; Runtime.totalMemory()=2161115136; org.broadinstitute.hellbender.utils.R.RScriptExecutorException: ; Rscript exited with 1; Command Line: Rscript -e tempLibDir = '/tmp/Rlib.2074992987327687075';source('/tmp/BQSR.6874121927957307421.R'); /tmp/AnalyzeCovariates6611620304443967041.csv /researchers/sebastian.hollizeck/lowcWGS/IN-PM01004/Bam/IN-PM01004_rmd.recal.bam.recalTable /researchers/sebastian.hollizeck/lowcWGS/IN-PM01004/Bam/AnalyzeCovariates.pdf; Stdout: WARNING: ignoring environment value of R_HOME. Stderr: During startup - Warning messages:; 1: Setting LC_CTYPE failed, using ""C"" ; 2: Setting LC_COLLATE failed, using ""C"" ; 3: Setting LC_TIME failed, using ""C"" ; 4: Setting LC_MESSAGES failed, using ""C"" ; 5: Setting LC_MONETARY failed, using ""C"" ; 6: Setting LC_PAPER failed, using ""C"" ; 7: Setting LC_MEASUREMENT failed, using ""C"" ; Error in rea",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6393:3050,down,down,3050,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6393,1,['down'],['down']
Availability,Java heap space error (java.lang.OutOfMemoryError) in mutect2,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5900:16,error,error,16,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5900,1,['error'],['error']
Availability,Java related error encountered while running gatk PathSeqPipelineSpark,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5802:13,error,error,13,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5802,1,['error'],['error']
Availability,Javadoc update: minor error in the documentation regarding --genotyping-mode,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5657:22,error,error,22,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5657,1,['error'],['error']
Availability,JointDiscovery Workflow Errors due to Java Heap Space?,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6165:24,Error,Errors,24,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6165,1,['Error'],['Errors']
Availability,"Just a minor annoyance:. ```/home/slee/.pyenv/versions/anaconda3-5.3.1/envs/gatk/lib/python3.6/site-packages/gcnvkernel/io/io_commons.py:394: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.; mu_slice = mu_all[_get_singleton_slice_along_axis(mu_all, var_sample_axis, sample_index)]; /home/slee/.pyenv/versions/anaconda3-5.3.1/envs/gatk/lib/python3.6/site-packages/gcnvkernel/io/io_commons.py:395: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.; std_slice = std_all[_get_singleton_slice_along_axis(mu_all, var_sample_axis, sample_index)]```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6226:385,error,error,385,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6226,2,['error'],['error']
Availability,"Just a minor fix, but could conceivably change results by keeping/dropping samples/intervals on the edge of the filter. See discussion in https://gatk.broadinstitute.org/hc/en-us/community/posts/360057785591-Error-while-running-CreateReadCountPanelOfNormals",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6624:208,Error,Error-while-running-CreateReadCountPanelOfNormals,208,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6624,1,['Error'],['Error-while-running-CreateReadCountPanelOfNormals']
Availability,"Just splitting off a chunk of @vruano's ideas in #264 here:. We start threading at the first unique kmer of each read (sequence). There are at least two problems with this. First, since we track unique kmers as we go the resulting graph may depend on the order in which reads were threaded. Second, we are throwing away information at the beginning of the read before the first unique (and existing) k-mer in each sequence is found. This is only partly fixed when we recover dangling heads.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4942:467,recover,recover,467,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4942,1,['recover'],['recover']
Availability,"Justin Rhoades of the blood biopsy team noticed a bug in the Mutect2 pipeline: if the number of scatters was sufficiently high, the last chunk of intervals did not contain any autosomal contigs, and therefore `GetPileupSummaries` was run on an empty interval for that scatter, throwing an error. For the pipeline there is no reason not to allow this empty interval and consequent empty output because it gets merged with other output later in the pipeline. It also seems that this is a generic feature of scattered jobs -- empty intersection of intervals need not imply a user error. Therefore, I added an argument to `IntervalArgumentCollection` to allow empty intervals. Since the change to the Mutect2 pipeline is tiny the primary need in code review is to judge whether the changes to `IntervalArgumentCollection` are acceptable. @lbergelson could you look at this PR?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6209:289,error,error,289,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6209,2,['error'],['error']
Availability,"K/NGS-SparkGATK/:/NGS-SparkGATK/; - /data/ngs/:/ngs/; - /data0/output/:/output/; spark-worker:; image: bde2020/spark-worker:2.2.0-hadoop2.8-hive-java8; networks:; - workbench; environment:; - SPARK_MASTER=spark://spark-master:7077; deploy:; mode: global; restart_policy:; condition: on-failure; labels:; traefik.docker.network: workbench; traefik.port: 8081. env_file:; - ./hadoop.env; volumes:; - reference-image:/reference_image. reference:; image: vzzarr/reference:hg19_img; networks:; - workbench; deploy:; mode: global; restart_policy:; condition: on-failure; tty: true #keeps the container alive; volumes:; - reference-image:/reference_image. volumes:; reference-image:. networks:; workbench:; external: true; ```; - Hadoop:; ```; version: '3'; services:; namenode:; image: bde2020/hadoop-namenode:2.0.0-hadoop2.7.4-java8; networks:; - workbench; volumes:; - namenode:/hadoop/dfs/name; environment:; - CLUSTER_NAME=test; env_file:; - ./hadoop.env; deploy:; mode: replicated; replicas: 1; restart_policy:; condition: on-failure; labels:; traefik.docker.network: workbench; traefik.port: 50070; ports:; - 8334:50070; volumes:; - /data0/reference/hg19-ucsc/:/reference/hg19-ucsc/; - /data0/output/:/output/; - /data/ngs/:/ngs/; datanode:; image: bde2020/hadoop-datanode:2.0.0-hadoop2.7.4-java8; networks:; - workbench; volumes:; - datanode:/hadoop/dfs/data; environment:; SERVICE_PRECONDITION: ""namenode:50070""; # depends_on:; # - namenode; env_file:; - ./hadoop.env; deploy:; mode: global; restart_policy:; condition: on-failure; labels:; traefik.docker.network: workbench; traefik.port: 50075. volumes:; datanode:; namenode:. networks:; workbench:; external: true; ```; the datanodes and namenode and spark master and workers are all working.; My hardware resources are:; 16 core and 1Tb memory ssd and 56Gb ram for 3 machines. I have this problem when I launch the version(GATK) v4.0.4.0 but not with this version v4.0.2.0-4-gb59d863-SNAPSHOT:. >java.lang.IllegalStateException: Duplicate key -",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4820:2621,failure,failure,2621,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4820,1,['failure'],['failure']
Availability,"KI270448v1, chrUn_KI270521v1, chrUn_GL000195v1, chrUn_GL000219v1, chrUn_GL000220v1, chrUn_GL000224v1, chrUn_KI270741v1, chrUn_GL000226v1, chrUn_GL000213v1, chrUn_KI270743v1, chrUn_KI270744v1, chrUn_KI270745v1, chrUn_KI270746v1, chrUn_KI270747v1, chrUn_KI270748v1, chrUn_KI270749v1, chrUn_KI270750v1, chrUn_KI270751v1, chrUn_KI270752v1, chrUn_KI270753v1, chrUn_KI270754v1, chrUn_KI270755v1, chrUn_KI270756v1, chrUn_KI270757v1, chrUn_GL000214v1, chrUn_KI270742v1, chrUn_GL000216v2, chrUn_GL000218v1, chrEBV]; features contigs = [X, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22]"". The VCF that I have uses just numbers for chromosomes, whereas the reference genome uses chr1, chr2, etc. Both naming conventions are valid. This is a 4.3 VCF. I have read https://gatk.broadinstitute.org/hc/en-us/articles/360035891131-Errors-about-input-files-having-missing-or-incompatible-contigs and this seems to be the same issue, but I believe there should be a translation that happens, e.g. 1 -> chr1 or the reverse as well. #### Steps to reproduce; Ran the following command using a VCF and reference file that I have:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /gatk/gatk-package-4.2.2.0-local.jar LeftAlignAndTrimVariants --max-indel-length 500 --max-leading-bases 2000 --dont-trim-alleles false --verbosity DEBUG --variant <input vcf file> --output /data/<vcf_output> --reference /data/<reference file> --split-multi-allelics true. #### Expected behavior; I would expect GATK to be able to translate 1 -> chr1, 2 -> chr2, etc. since both naming conventions are valid according to the VCF spec http://samtools.github.io/hts-specs/VCFv4.3.pdf. When running the same exact command on a VCF file that uses chr1, chr2, etc. as the naming convention the command runs successfully. #### Actual behavior; GATK exits and gives error message mentioned in description.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7538:5320,error,error,5320,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7538,1,['error'],['error']
Availability,"KTRACE\_ON\_USER\_EXCEPTION=true -jar /nfs/fs1/bioinfo/apps-x86\_64/GATK/gatk-4.1.7.0/gatk-package-4.1.7.0-local.jar GenomicsDBImport --genomicsdb-workspace-path /tmp/tmp.ceRdvv/GDB --intervals chr1:5149001-5201000 --tmp-dir /tmp/tmp.ceRdvv/GDB\_tmp --sample-name-map /tmp/tmp.ceRdvv/snmap --batch-size 100 --reader-threads 17. java -Dsamjdk.use\_async\_io\_read\_samtools=false -Dsamjdk.use\_async\_io\_write\_samtools=true -Dsamjdk.use\_async\_io\_write\_tribble=false -Dsamjdk.compression\_level=2 -Djava.io.tmpdir=/tmp/tmp.ceRdvv -Xmx71680M -Xms71680M -jar /nfs/fs1/bioinfo/apps-x86\_64/GATK/gatk-4.1.7.0/gatk-package-4.1.7.0-local.jar GenotypeGVCFs --genomicsdb-use-vcf-codec -R /odinn/data/extdata/1000genomes/2019-06-21\_GRCh38/GRCh38\_full\_analysis\_set\_plus\_decoy\_hla.fa -V gendb:///tmp/tmp.ceRdvv/GDB --tmp-dir=/tmp/tmp.ceRdvv --interval-padding 1000 --only-output-calls-starting-in-intervals -L chr1:5161113-5163890 -O /tmp/tmp.ceRdvv/splitdir/reg\_5.padded.vcf.gz. **c) The entire error log if applicable.**. Running: ; ; java -Dsamjdk.use\_async\_io\_read\_samtools=false -Dsamjdk.use\_async\_io\_write\_samtools=true -Dsamjdk.use\_async\_io\_write\_tribble=false -Dsamjdk.compression\_level=2 -Xmx1290240M -Xms1290240M -DGATK\_STACKTRACE\_ON\_USER\_EXCEPTION=true -jar /nfs/fs1/bioinfo/apps-x86\_64/GATK/gatk-4.1.7.0/gatk-package-4.1.7.0-local.jar GenomicsDBImport --genomicsdb-workspace-path /tmp/tmp.ceRdvv/GDB --intervals chr1:5149001-5201000 --tmp-dir /tmp/tmp.ceRdvv/GDB\_tmp --sample-name-map /tmp/tmp.ceRdvv/snmap --batch-size 100 --reader-threads 17 ; ; 20:05:36.112 INFO NativeLibraryLoader - Loading libgkl\_compression.so from jar:file:/nfs/fs1/bioinfo/apps-x86\_64/GATK/gatk-4.1.7.0/gatk-package-4.1.7.0-local.jar!/com/intel/gkl/native/libgkl\_compression.so ; ; Jul 27, 2020 8:05:40 PM shaded.cloud\_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine ; ; INFO: Failed to detect whether we are running on Google Compute Engine. ; ; 20:05:40.627 IN",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6742:2398,error,error,2398,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6742,1,['error'],['error']
Availability,"KTool.doWork(GATKTool.java:966); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:138); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:162); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:205); 	at org.broadinstitute.hellbender.Main.main(Main.java:291); Using GATK jar /gatk/gatk-package-4.1.0.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /gatk/gatk-package-4.1.0.0-local.jar BaseRecalibrator --input sorted.bam --output sorted.baserecalibrator_report.txt --reference GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.bowtie_index.fasta --use-original-qualities true --known-sites snp151common_tablebrowser.bed.bgz --known-sites snp151flagged_tablebrowser.bed.bgz; ```. I downsampled the fastq files and got similar results.; However, when giving only the reduced known-sites file (`--known-sites snp151flagged_tablebrowser.bed.bgz`) and specifying two intervals (`--intervals chr22 --intervals chrY`), it worked. I attached the downsampled bam file and the reduced known-sites file [here](https://gatkforums.broadinstitute.org/gatk/discussion/comment/57049/#Comment_57049), and the reference file can be found [here](ftp://ftp.ncbi.nlm.nih.gov/genomes/archive/old_genbank/Eukaryotes/vertebrates_mammals/Homo_sapiens/GRCh38/seqs_for_alignment_pipelines/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna). I hope you can help me understanding what is going on and how to fix it. Thank you in advance. Best regards,. Miguel. This Issue was generated from your [forums] ; [forums]: https://gatkforums.broadinstitute.org/gatk/discussion/comment/57049#Comment_57049",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5807:8860,down,downsampled,8860,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5807,2,['down'],['downsampled']
Availability,"K}/lib/python3.6/site-packages/theano/__init__.py"", line 110, in <module>; from theano.compile import (; File ""${INSTALLDIRGATK}/lib/python3.6/site-packages/theano/compile/__init__.py"", line 12, in <module>; from theano.compile.mode import *; File ""${INSTALLDIRGATK}/lib/python3.6/site-packages/theano/compile/mode.py"", line 11, in <module>; import theano.gof.vm; File ""${INSTALLDIRGATK}/lib/python3.6/site-packages/theano/gof/vm.py"", line 674, in <module>; from . import lazylinker_c; File ""${INSTALLDIRGATK}/lib/python3.6/site-packages/theano/gof/lazylinker_c.py"", line 140, in <module>; preargs=args); File ${INSTALLDIRGATK}/lib/python3.6/site-packages/theano/gof/cmodule.py"", line 2396, in compile_str; (status, compile_stderr.replace('\n', '. '))); Exception: Compilation failed (return status=1): /usr/bin/ld.gold: error: ${INSTALLDIRGCC}/bin/../lib/gcc/x86_64-pc-linux-gnu/7.3.0/crtbeginS.o: unsupported reloc 42 against global symbol _ITM_deregisterTMCloneTable. /usr/bin/ld.gold: error: ${INSTALLDIRGCC}/bin/../lib/gcc/x86_64-pc-linux-gnu/7.3.0/crtbeginS.o: unsupported reloc 42 against global symbol _ITM_registerTMCloneTable. ${INSTALLDIRGCC}/bin/../lib/gcc/x86_64-pc-linux-gnu/7.3.0/crtbeginS.o(.text+0x1a): error: unsupported reloc 42. ${INSTALLDIRGCC}/bin/../lib/gcc/x86_64-pc-linux-gnu/7.3.0/crtbeginS.o(.text+0x6b): error: unsupported reloc 42. collect2: error: ld returned 1 exit status. ```. Then I have installed theano with python 3.6.6 which is compiled with gcc 5.4.0, and it was giving me no errors. ```sh. $ theano-nose . ----------------------------------------------------------------------; Ran 0 tests in 0.012s. OK; ```. The Theano toolchain issue might be caused by theano not being actively developed anymore. Probably they never tested it with newer toolchains.; See this message that is also on the Theano github page.; https://groups.google.com/d/msg/theano-users/7Poq8BZutbY/rNCIfvAEAwAJ. #### Steps to reproduce; see description. #### Expected behavior; see descrip",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5766:3110,error,error,3110,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5766,1,['error'],['error']
Availability,"LE : false; 10:20:01.719 INFO GermlineCNVCaller - Deflater: IntelDeflater; 10:20:01.719 INFO GermlineCNVCaller - Inflater: IntelInflater; 10:20:01.719 INFO GermlineCNVCaller - GCS max retries/reopens: 20; 10:20:01.719 INFO GermlineCNVCaller - Requester pays: disabled; 10:20:01.720 INFO GermlineCNVCaller - Initializing engine; 10:20:07.111 INFO GermlineCNVCaller - Done initializing engine; 10:20:07.207 INFO GermlineCNVCaller - Running the tool in CASE mode...; 10:20:07.207 INFO GermlineCNVCaller - Validating and aggregating data from input read-count files...; 10:20:07.231 INFO GermlineCNVCaller - Aggregating read-count file /media/Ergebnisse/0115-24_Masterpanel_NB501654_0623/0115-24_noProbe.hdf5 (1 / 1); log4j:WARN No appenders could be found for logger (org.broadinstitute.hdf5.HDF5Library).; log4j:WARN Please initialize the log4j system properly.; log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.; 10:20:25.874 INFO GermlineCNVCaller - Shutting down engine; [March 14, 2024 at 10:20:25 AM CET] org.broadinstitute.hellbender.tools.copynumber.GermlineCNVCaller done. Elapsed time: 0.40 minutes.; Runtime.totalMemory()=2147483648; org.broadinstitute.hellbender.utils.python.PythonScriptExecutorException:; python exited with 1; Command Line: python /media/Data/tmp/case_denoising_calling.3564509013495540802.py --ploidy_calls_path=/media/Ergebnisse/0115-24_Masterpanel_NB501654_0623/0115-24_DGCP_noProbe-calls --output_calls_path=/media/Ergebnisse/0115-24_Masterpanel_NB501654_0623/0115-24_GCNV_noProbe-calls --output_tracking_path=/media/Ergebnisse/0115-24_Masterpanel_NB501654_0623/0115-24_GCNV_noProbe-tracking --input_model_path=/media/Data/MasterV3/GCNV_noProbe-model --random_seed=1984 --read_count_tsv_files /media/Data/tmp/0115-24.rc16220482177493702615.tsv --psi_s_scale=1.000000e-04 --mapping_error_rate=1.000000e-02 --depth_correction_tau=1.000000e+04 --q_c_expectation_mode=hybrid --num_samples_copy_ratio_approx=200 --p_alt=1.000000e-06 --cnv_",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8740:3936,down,down,3936,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8740,1,['down'],['down']
Availability,"Largely taken from Lee's sample code, see JIRA ticket for details. Spins up a Hail cluster and runs a script to extract from a VDS to VCF files on a per-chromosome basis. Includes some refactoring to move some of the workspace-sniffing that was part of bulk ingest into more generic utility code. In terms of cluster tracking:. - Cluster name is calculated in shell script and visible in the logs; - Cluster name is written to a file which is delocalized even if the workload script fails. . Unintended but useful example [here](https://job-manager.dsde-prod.broadinstitute.org/jobs/a96667a7-e08c-43f4-abad-b55fbe7f0c06) where not only is the cluster name logged and written to an output file which is delocalized, but the cluster gets shut down anyway by cleanup code.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8525:741,down,down,741,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8525,1,['down'],['down']
Availability,"Last week, spark 2.0.0 is formally released. However, when I tested gatk4 on spark2.0.0, I found they were incompatible. It seems that the interface isn't match. The error log looks like below. Exception in thread ""main"" java.lang.NoSuchMethodError: scala.collection.Seq.aggregate(Ljava/lang/Object;Lscala/Function2;Lscala/Function2;)Ljava/lang/Object;; at org.bdgenomics.adam.models.NonoverlappingRegions.mergeRegions(NonoverlappingRegions.scala:75); at org.bdgenomics.adam.models.NonoverlappingRegions.<init>(NonoverlappingRegions.scala:55); at org.bdgenomics.adam.models.NonoverlappingRegions$.apply(NonoverlappingRegions.scala:169); at org.bdgenomics.adam.util.TwoBitRecord$.apply(TwoBitFile.scala:193); at org.bdgenomics.adam.util.TwoBitFile$$anonfun$6.apply(TwoBitFile.scala:70); at org.bdgenomics.adam.util.TwoBitFile$$anonfun$6.apply(TwoBitFile.scala:70); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.immutable.HashMap$HashMap1.foreach(HashMap.scala:221); at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428); at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428); at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); at scala.collection.AbstractTraversable.map(Traversable.scala:104); at org.bdgenomics.adam.util.TwoBitFile.<init>(TwoBitFile.scala:70); at org.broadinstitute.hellbender.engine.spark.datasources.ReferenceTwoBitSource.<init>(ReferenceTwoBitSource.java:43); at org.broadinstitute.hellbender.engine.datasources.ReferenceMultiSource.<init>(ReferenceMultiSource.java:41); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.initializeReference(GATKSparkTool.java:353); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.initializeToolInputs(GATKSparkTool.java:320); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2073:166,error,error,166,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2073,1,['error'],['error']
Availability,Lessons learned in VDS creation during Echo Scale Testing. Successful integration run [here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/9e6aa362-e25b-49d0-83cd-d64e926c6386).,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8602:39,Echo,Echo,39,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8602,1,['Echo'],['Echo']
Availability,Let's use Exceptions instead to indicate error conditions. The main program can return a error status but not internal classes. Return values are too valuable to use them for error codes.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/71:41,error,error,41,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/71,3,['error'],['error']
Availability,Let's use a different downsampling strategy than GATK3 for the `HaplotypeCaller` -- perhaps a `ReservoirDownsampler` whose size is proportional to the size of each region. Need to make sure that whatever strategy we use allows us to deal with high-coverage regions without introducing calling artifacts / missed calls.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1642:22,down,downsampling,22,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1642,1,['down'],['downsampling']
Availability,"List(),; started=false); 18/01/09 18:31:26 INFO cluster.YarnClientSchedulerBackend: Stopped; 18/01/09 18:31:26 INFO spark.MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 18/01/09 18:31:26 INFO memory.MemoryStore: MemoryStore cleared; 18/01/09 18:31:26 INFO storage.BlockManager: BlockManager stopped; 18/01/09 18:31:26 INFO storage.BlockManagerMaster: BlockManagerMaster stopped; 18/01/09 18:31:26 INFO scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 18/01/09 18:31:26 INFO spark.SparkContext: Successfully stopped SparkContext; 18:31:26.896 INFO BwaAndMarkDuplicatesPipelineSpark - Shutting down engine; [January 9, 2018 6:31:26 PM CST] org.broadinstitute.hellbender.tools.spark.pipelines.BwaAndMarkDuplicatesPipelineSpark done. Elapsed time: 0.89 minutes.; Runtime.totalMemory()=881328128; ***********************************************************************. A USER ERROR has occurred: Input files reference and reads have incompatible contigs: No overlapping contigs found.; reference contigs = [chrM, chr1, chr2, chr3, chr4, chr5, chr6, chr7, chr8, chr9, chr10, chr11, chr12, chr13, chr14, chr15, chr16, chr17, chr18, chr19, chr20, chr21, chr22, chrX, chrY, chr1_gl000191_random, chr1_gl000192_random, chr4_ctg9_hap1, chr4_gl000193_random, chr4_gl000194_random, chr6_apd_hap1, chr6_cox_hap2, chr6_dbb_hap3, chr6_mann_hap4, chr6_mcf_hap5, chr6_qbl_hap6, chr6_ssto_hap7, chr7_gl000195_random, chr8_gl000196_random, chr8_gl000197_random, chr9_gl000198_random, chr9_gl000199_random, chr9_gl000200_random, chr9_gl000201_random, chr11_gl000202_random, chr17_ctg5_hap1, chr17_gl000203_random, chr17_gl000204_random, chr17_gl000205_random, chr17_gl000206_random, chr18_gl000207_random, chr19_gl000208_random, chr19_gl000209_random, chr21_gl000210_random, chrUn_gl000211, chrUn_gl000212, chrUn_gl000213, chrUn_gl000214, chrUn_gl000215, chrUn_gl000216, chrUn_gl000217, chrUn_gl000218, chrUn_gl000219, chrUn_gl000220, chrUn_g",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4112:31357,ERROR,ERROR,31357,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4112,1,['ERROR'],['ERROR']
Availability,Locally testing does ok but when run in Travis you get an error consistently. The stack trace reads:. <pre>; org.broadinstitute.hellbender.tools.exome.allelefraction.AlleleFractionInitializerUnitTest.testInitialize FAILED; java.lang.AssertionError: expected [0.0] but found [-0.023368743794425884]; at org.testng.Assert.fail(Assert.java:94); at org.testng.Assert.failNotEquals(Assert.java:496); at org.testng.Assert.assertEquals(Assert.java:209); at org.testng.Assert.assertEquals(Assert.java:222); at org.broadinstitute.hellbender.tools.exome.allelefraction.AlleleFractionInitializerUnitTest.testInitialize(AlleleFractionInitializerUnitTest.java:41); </pre>,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1320:58,error,error,58,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1320,1,['error'],['error']
Availability,"Looks like this java.lang.NullPointerException is from an environment set up issue. . This request was created from a contribution made by Jordi Maggi on April 25, 2022 09:25 UTC. Link: [https://gatk.broadinstitute.org/hc/en-us/community/posts/5574426055963-CNNScoreVariants-crashes-with-java-lang-NullPointerException](https://gatk.broadinstitute.org/hc/en-us/community/posts/5574426055963-CNNScoreVariants-crashes-with-java-lang-NullPointerException). \--. Hi,. I created a conda environment and installed gatk4 through `conda install -c bioconda gatk4`. I have been using this environment to run all steps of the single sample germline variant calling best practices workflow (both gatk and picard). However, I have never been able to run CNNScoreVariants with this setup, as it always results in a java.lang.NullPointerException error. The only way I am able to run this step is by running it through the docker image you provide. That, however, is not ideal for our setup. Any idea as to what I may try to be able to run it directly?. GATK version:. Using GATK jar /home/analyst/anaconda3/envs/snakemake\_env/share/gatk4-4.2.5.0-0/gatk-package-4.2.5.0-local.jar ; ; Running: ; ;     java -Dsamjdk.use\_async\_io\_read\_samtools=false -Dsamjdk.use\_async\_io\_write\_samtools=true -Dsamjdk.use\_async\_io\_write\_tribble=false -Dsamjdk.compression\_level=2 -jar /home/analyst/anaconda3/envs/snakemake\_env/share/gatk4-4.2.5.0-0/gatk-package-4.2.5.0-local.jar --version ; ; The Genome Analysis Toolkit (GATK) v4.2.5.0 ; ; HTSJDK Version: 2.24.1 ; ; Picard Version: 2.25.4. Exact command:. gatk CNNScoreVariants -I 73318\_WES\_hg19\_recalibrated.sorted.bam -V 73318\_80\_IDTv1.vcf.gz -R /media/analyst/Data/Reference\_data/hg19.fa -O /media/analyst/Data/73318\_CNNScore\_test.vcf.gz -tensor-type read\_tensor > /media/analyst/Data/CNNScoreVariants.log. Entire console output:. Running: ; ;     java -Dsamjdk.use\_async\_io\_read\_samtools=false -Dsamjdk.use\_async\_io\_write\_samtools=true -Dsamjdk",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7811:833,error,error,833,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7811,1,['error'],['error']
Availability,Lower error rate in SGA overlap and better error handling,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1997:6,error,error,6,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1997,2,['error'],['error']
Availability,"M error are related. The only difference in invocation was that with the OOM failure, I was running with the default for `--max-reads-per-alignment-start` (`50`). This also works just fine with that setting at 15. The failure seems to occur around the same place in the data each time (the end of `chr13`). At that point in the data, there is a very large pileup which is probably instigating this. Additionally, if I remove the `--linked-de-bruijn-graph` argument, this runs just fine with the default setting of `--max-reads-per-alignment-start`. I have a minimally reproductive dataset that I can share which reproduces the OOM error for sure (I'm 99% sure it reproduces this one as well). For the OOM failures, the final logs from HaplotypeCaller look like this:. ```; ./gatk HaplotypeCaller ...; ...; 15:56:23.205 INFO ProgressMeter - Pf3D7_13_v3:2603234 100.5 114070 1134.5; 15:56:33.443 INFO ProgressMeter - Pf3D7_13_v3:2661462 100.7 114420 1136.1; Dangling End recovery killed because of a loop (getReferencePathForwardFromKmer); 15:56:43.998 INFO ProgressMeter - Pf3D7_13_v3:2730055 100.9 114840 1138.3; 15:56:59.911 INFO ProgressMeter - Pf3D7_13_v3:2798281 101.2 115210 1139.0; 15:59:27.062 INFO ProgressMeter - Pf3D7_13_v3:2861780 103.6 115460 1114.4; Dangling End recovery killed because of a loop (getReferencePathForwardFromKmer); Dangling End recovery killed because of a loop (getReferencePathForwardFromKmer); 15:59:37.457 INFO ProgressMeter - Pf3D7_13_v3:2869697 103.8 115500 1112.9. real 671m24.770s; user 777m30.923s; sys 6m13.682s. $ echo $?; 247; ```. Here is my command-line invocation:; ```; ./gatk --java-options ""-Xmx100000m -Xms25000m"" \; HaplotypeCaller \; -R /juffowup2/malaria/references/PlasmoDB-61_Pfalciparum3D7_Genome.fasta \; -I ${WORKING_DIR}/fixed_bam/PG0004-CW.aligned.merged.markDuplicates.sorted.BQSR.bam \; -O ${WORKING_DIR}/PG0004-CW.haplotype_caller.fixed_bam_file.with_pileup.g.vcf.gz \; --bam-output ${WORKING_DIR}/PG0004-CW.haplotype_caller.fixed_bam_fil",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8440:5294,recover,recovery,5294,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8440,1,['recover'],['recovery']
Availability,M2 error with canine germline resource and variants_for_contamination files,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6098:3,error,error,3,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6098,1,['error'],['error']
Availability,"M2 wdl doesn't emit unfiltered vcf, which is redundant",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5076:45,redundant,redundant,45,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5076,1,['redundant'],['redundant']
Availability,MARK DUPLICATE PROCESS ERROR,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8596:23,ERROR,ERROR,23,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8596,1,['ERROR'],['ERROR']
Availability,"MIGRATED FROM GATK3. @ldgauthier commented on [Thu Mar 12 2015](https://github.com/broadinstitute/gsa-unstable/issues/868). From Grace Tiao:. We found a large number of PASS frameshift indels that looked suspicious in our pan-cancer germline callset (~37k samples) that are driving the top genes in some of our case-control associations. These indels all have the following properties:; 1. They are flagged as PASS by VQSR and are PASS in ExAC; but examination in IGV shows that these variants are all present at extremely low allelic fractions. (These are all normal samples.); 2. These variants occur in the specific context of 7-base (and in one case, 8-base) homopolymer runs. The variant we looked at in the meeting had a very low QD score, and Eric Banks's suggestion for the short-term is to filter our callset for low QD indels (i.e., remove all indels with QD<1). The hard filter will take care of most of these faulty variants, but at least two of the suspicious indels have QD scores > 1 (see VCF columns below). In the long run, it might be beneficial to catch these cases in the VQSR indel modeling. 1 33745932 . G GC 2175.55 PASS AC=131;AF=1.743e-03;AN=75168;BaseQRankSum=-1.540e-01;CCC=75168;ClippingRankSum=0.306;DP=886479;FS=0.000;GQ_MEAN=58.06;GQ_STDDEV=13.70;HWP=1.0000;InbreedingCoeff=-0.0041;MLEAC=86;MLEAF=1.144e-03;MQ=59.62;MQ0=0;MQRankSum=0.457;NCC=23;QD=0.55;ReadPosRankSum=-2.130e-01;VQSLOD=2.00;culprit=QD; 1 40028015 . T TG 3661.09 PASS AC=143;AF=1.902e-03;AN=75202;BaseQRankSum=0.169;CCC=75202;ClippingRankSum=0.331;DP=1059106;FS=0.000;GQ_MEAN=61.43;GQ_STDDEV=19.66;HWP=1.0000;InbreedingCoeff=-0.0032;MLEAC=93;MLEAF=1.237e-03;MQ=59.79;MQ0=0;MQRankSum=0.331;NCC=6;QD=0.53;ReadPosRankSum=-1.760e-01;VQSLOD=2.03;culprit=QD; 2 220504281 . T TG 2883 PASS AC=98;AF=1.303e-03;AN=75214;BaseQRankSum=0.095;CCC=75214;ClippingRankSum=0.040;DP=1139600;FS=0.000;GQ_MEAN=68.44;GQ_STDDEV=17.59;HWP=1.0000;InbreedingCoeff=-0.0022;MLEAC=57;MLEAF=7.578e-04;MQ=59.42;MQ0=0;MQRankSum=0.401;NC",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2508:921,fault,faulty,921,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2508,1,['fault'],['faulty']
Availability,"MPRESSION_LEVEL : 2; 12:57:16.776 INFO AnalyzeCovariates - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 12:57:16.776 INFO AnalyzeCovariates - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 12:57:16.776 INFO AnalyzeCovariates - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 12:57:16.776 INFO AnalyzeCovariates - Deflater: IntelDeflater; 12:57:16.776 INFO AnalyzeCovariates - Inflater: IntelInflater; 12:57:16.776 INFO AnalyzeCovariates - GCS max retries/reopens: 20; 12:57:16.776 INFO AnalyzeCovariates - Requester pays: disabled; 12:57:16.776 INFO AnalyzeCovariates - Initializing engine; 12:57:16.776 INFO AnalyzeCovariates - Done initializing engine; 12:57:17.333 INFO AnalyzeCovariates - Generating csv file '/tmp/AnalyzeCovariates17353441228865531235.csv'; 12:57:17.414 INFO AnalyzeCovariates - Generating plots file '/home/detagen/Desktop/pipeline/playground/NECESSARY/FMF-248/AnalyzeCovariates.FMF-248.pdf'; 12:57:17.829 INFO AnalyzeCovariates - Shutting down engine; [December 17, 2020 at 12:57:17 PM TRT] org.broadinstitute.hellbender.tools.walkers.bqsr.AnalyzeCovariates done. Elapsed time: 0.02 minutes.; Runtime.totalMemory()=633339904; org.broadinstitute.hellbender.utils.R.RScriptExecutorException: ; Rscript exited with 1; Command Line: Rscript -e tempLibDir = '/tmp/Rlib.10272183847736955081';source('/tmp/BQSR.16251220439562120273.R'); /tmp/AnalyzeCovariates17353441228865531235.csv /home/detagen/Desktop/pipeline/playground/BACKUP/FMF-248_Backup/before.recal.FMF-248.table /home/detagen/Desktop/pipeline/playground/NECESSARY/FMF-248/AnalyzeCovariates.FMF-248.pdf; Stdout: ; Stderr: Error in library(gplots) : there is no package called ‘gplots’; Calls: source -> withVisible -> eval -> eval -> library; Execution halted. 	at org.broadinstitute.hellbender.utils.R.RScriptExecutor.getScriptException(RScriptExecutor.java:80); 	at org.broadinstitute.hellbender.utils.R.RScriptExecutor.getScriptException(RScriptExecutor.java:19); 	at org.broadinstitute.hel",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7006:3474,down,down,3474,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7006,1,['down'],['down']
Availability,"MRecordToReadIterator.java:13); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); 	at org.broadinstitute.hellbender.engine.ReadWalker.traverse(ReadWalker.java:94); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1048); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:163); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:206); 	at org.broadinstitute.hellbender.Main.main(Main.java:292); Caused by: java.nio.channels.ClosedChannelException; 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher.position(SeekableByteChannelPrefetcher.java:416); 	at htsjdk.samtools.seekablestream.SeekablePathStream.seek(SeekablePathStream.java:63); 	at htsjdk.samtools.CRAMFileReader.queryUnmapped(CRAMFileReader.java:402); 	... 23 more; ```. #### Steps to reproduce; It looks to me like running with the two -L args (`-L loci.interval_list -L UNMAPPED`) causes this. ; Removing either one of them prevents the error, so my current work-around is to run ; PrintReads separately - once with `-L loci.interval_list` and once with `-L UNMAPPED`",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6475:3373,error,error,3373,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6475,1,['error'],['error']
Availability,"MT; 22:19:48.307 INFO FixMisencodedBaseQualityReads - ------------------------------------------------------------; 22:19:48.307 INFO FixMisencodedBaseQualityReads - ------------------------------------------------------------; 22:19:48.309 INFO FixMisencodedBaseQualityReads - HTSJDK Version: 2.13.2; 22:19:48.309 INFO FixMisencodedBaseQualityReads - Picard Version: 2.17.2; 22:19:48.310 INFO FixMisencodedBaseQualityReads - HTSJDK Defaults.COMPRESSION_LEVEL : 1; 22:19:48.314 INFO FixMisencodedBaseQualityReads - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 22:19:48.318 INFO FixMisencodedBaseQualityReads - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 22:19:48.319 INFO FixMisencodedBaseQualityReads - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 22:19:48.325 INFO FixMisencodedBaseQualityReads - Deflater: IntelDeflater; 22:19:48.326 INFO FixMisencodedBaseQualityReads - Inflater: IntelInflater; 22:19:48.330 INFO FixMisencodedBaseQualityReads - GCS max retries/reopens: 20; 22:19:48.330 INFO FixMisencodedBaseQualityReads - Using google-cloud-java patch 6d11bef1c81f885c26b2b56c8616b7a705171e4f from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 22:19:48.331 INFO FixMisencodedBaseQualityReads - Initializing engine; 22:19:48.861 INFO FixMisencodedBaseQualityReads - Done initializing engine; 22:19:48.917 INFO ProgressMeter - Starting traversal; 22:19:48.917 INFO ProgressMeter - Current Locus Elapsed Minutes Reads Processed Reads/Minute; 22:19:49.026 INFO FixMisencodedBaseQualityReads - 196 read(s) filtered by: WellformedReadFilter. 22:19:49.029 INFO ProgressMeter - unmapped 0.0 918 505321.1; 22:19:49.030 INFO ProgressMeter - Traversal complete. Processed 918 total reads in 0.0 minutes.; 22:19:49.079 INFO FixMisencodedBaseQualityReads - Shutting down engine; [January 23, 2018 10:19:49 PM GMT] org.broadinstitute.hellbender.tools.FixMisencodedBaseQualityReads done. Elapsed time: 0.02 minutes.; Runtime.totalMemory()=580386816; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4241:2992,down,down,2992,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4241,1,['down'],['down']
Availability,"MTOOLS : false; 14:59:15.873 INFO PrintReads - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 14:59:15.873 INFO PrintReads - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 14:59:15.873 INFO PrintReads - Deflater: IntelDeflater; 14:59:15.873 INFO PrintReads - Inflater: IntelInflater; 14:59:15.873 INFO PrintReads - GCS max retries/reopens: 20; 14:59:15.873 INFO PrintReads - Using google-cloud-java patch c035098b5e62cb4fe9155eff07ce88449a361f5d from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 14:59:15.873 INFO PrintReads - Initializing engine; 14:59:21.404 INFO IntervalArgumentCollection - Processing 83257441 bp from intervals; 14:59:21.421 INFO PrintReads - Shutting down engine; [October 5, 2017 2:59:22 PM EDT] org.broadinstitute.hellbender.tools.PrintReads done. Elapsed time: 0.11 minutes.; Runtime.totalMemory()=2129133568; ***********************************************************************. A USER ERROR has occurred: Traversal by intervals was requested but some input files are not indexed.; Please index all input files:. samtools index /1kg/exome_GRCh38DH/cram/HG00190.alt_bwamem_GRCh38DH.20150826.FIN.exome.cram. ***********************************************************************; Set the system property GATK_STACKTRACE_ON_USER_EXCEPTION (--javaOptions '-DGATK_STACKTRACE_ON_USER_EXCEPTION=true') to print the stack trace.; ```. Still fails with `-readIndex` specified (.cram.crai OR .crai):; ```; -bash-4.1$ /humgen/gsa-hpprojects/GATK/gatk4/gatk-4.beta.5/gatk-launch PrintReads \; > -I gs://shlee-dev/1kg/exome_GRCh38DH/cram/HG00190.alt_bwamem_GRCh38DH.20150826.FIN.exome.cram \; > -R /humgen/gsa-hpprojects/dev/shlee/ref/GRCh38_1kg/GRCh38_full_analysis_set_plus_decoy_hla.fa \; > -readIndex gs://shlee-dev/1kg/exome_GRCh38DH/cram/HG00190.alt_bwamem_GRCh38DH.20150826.FIN.exome.cram.crai \; > -O HG00190_cram.bam \; > ; Using GATK jar /humgen/gsa-hpprojects/GATK/gatk4/gatk-4.beta.5/gatk-package-4.beta.5-local.jar; Running:; ja",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3669:12185,ERROR,ERROR,12185,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3669,1,['ERROR'],['ERROR']
Availability,"MTOOLS : false; 15:00:08.250 INFO PrintReads - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 15:00:08.250 INFO PrintReads - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 15:00:08.250 INFO PrintReads - Deflater: IntelDeflater; 15:00:08.250 INFO PrintReads - Inflater: IntelInflater; 15:00:08.250 INFO PrintReads - GCS max retries/reopens: 20; 15:00:08.250 INFO PrintReads - Using google-cloud-java patch c035098b5e62cb4fe9155eff07ce88449a361f5d from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 15:00:08.250 INFO PrintReads - Initializing engine; 15:00:13.258 INFO IntervalArgumentCollection - Processing 83257441 bp from intervals; 15:00:13.275 INFO PrintReads - Shutting down engine; [October 5, 2017 3:00:14 PM EDT] org.broadinstitute.hellbender.tools.PrintReads done. Elapsed time: 0.10 minutes.; Runtime.totalMemory()=2233466880; ***********************************************************************. A USER ERROR has occurred: Traversal by intervals was requested but some input files are not indexed.; Please index all input files:. samtools index /1kg/exome_GRCh38DH/cram/HG00190.alt_bwamem_GRCh38DH.20150826.FIN.exome.cram. ***********************************************************************; Set the system property GATK_STACKTRACE_ON_USER_EXCEPTION (--javaOptions '-DGATK_STACKTRACE_ON_USER_EXCEPTION=true') to print the stack trace.; ```; ```; -bash-4.1$ /humgen/gsa-hpprojects/GATK/gatk4/gatk-4.beta.5/gatk-launch PrintReads \; > -I gs://shlee-dev/1kg/exome_GRCh38DH/cram/HG00190.alt_bwamem_GRCh38DH.20150826.FIN.exome.cram \; > -R /humgen/gsa-hpprojects/dev/shlee/ref/GRCh38_1kg/GRCh38_full_analysis_set_plus_decoy_hla.fa \; > -readIndex gs://shlee-dev/1kg/exome_GRCh38DH/cram/HG00190.alt_bwamem_GRCh38DH.20150826.FIN.exome.crai \; > -O HG00190_cram.bam \; > -L chr17; Using GATK jar /humgen/gsa-hpprojects/GATK/gatk4/gatk-4.beta.5/gatk-package-4.beta.5-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_asy",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3669:19749,ERROR,ERROR,19749,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3669,1,['ERROR'],['ERROR']
Availability,"Main.mainEntry(Main.java:206); at org.broadinstitute.hellbender.Main.main(Main.java:292); Caused by: java.io.FileNotFoundException: /tmp/test%20a/data/calling/a.vcf.gz (No such file or directory); at java.io.RandomAccessFile.open0(Native Method); at java.io.RandomAccessFile.open(RandomAccessFile.java:316); at java.io.RandomAccessFile.<init>(RandomAccessFile.java:243); at htsjdk.samtools.seekablestream.SeekableFileStream.<init>(SeekableFileStream.java:47); at htsjdk.samtools.seekablestream.SeekableStreamFactory$DefaultSeekableStreamFactory.getStreamFor(SeekableStreamFactory.java:99); at htsjdk.tribble.readers.TabixReader.<init>(TabixReader.java:129); at htsjdk.tribble.TabixFeatureReader.<init>(TabixFeatureReader.java:80); at htsjdk.tribble.AbstractFeatureReader.getFeatureReader(AbstractFeatureReader.java:117); ... 9 more; ```. #### Steps to reproduce; Below few steps to reproduce the bug and the specificities mentioned above. ```bash; # Create test directory without whitespace; cd /tmp; mkdir -p test-a/data/calling/; cd test-a. # Upload appropriate VCFs in data/calling. # Run MergeVcfs; gatk MergeVcfs -I data/calling/a.vcf.gz -I data/calling/b.vcf.gz -O c.vcf.gz ## It runs as expected. # Introduce a whitespace in the directory name and move into the directory again; cd ..; mv test-a ""test a""; cd ""test a"". # Run MergeVcfs; gatk MergeVcfs -I data/calling/a.vcf.gz -I data/calling/b.vcf.gz -O c.vcf.gz ## It throws an error. # Introduce withespace in the VCFs; mv data/calling/a.vcf.gz -I data/calling/a\ 1.vcf.gz; mv data/calling/b.vcf.gz -I data/calling/b\ 1.vcf.gz. # Run MergeVcfs; gatk MergeVcfs -I data/calling/a\ 1.vcf.gz -I data/calling/b\ 1.vcf.gz -O c.vcf.gz ## It runs as expected. # If VCFs without whitespace in their names are moved into data or in the current working directory (""test a""), merging works as expected.; ```. #### Expected behavior; MergeVcfs should be able to handle whitespace when present anywhere in the file path. #### Actual behavior; It does not.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6664:4888,error,error,4888,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6664,1,['error'],['error']
Availability,Make Google NIO provider for GCS public and available via maven,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1547:44,avail,available,44,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1547,1,['avail'],['available']
Availability,Make ReadsSparkSource.putPairsInSamePartition() more robust,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2442:53,robust,robust,53,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2442,1,['robust'],['robust']
Availability,Make RobustBrentSolver more flexible,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2971:5,Robust,RobustBrentSolver,5,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2971,1,['Robust'],['RobustBrentSolver']
Availability,Make error informative for non-diploid family likelihoods,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3329:5,error,error,5,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3329,1,['error'],['error']
Availability,"Make the logging frequency used by the ProgressLogger available as an input. If not used, sets the default value. Variants team is using a branch of gatk and have made this change there, so pulling this change into master to simplify future merges / branch updates.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8662:54,avail,available,54,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8662,1,['avail'],['available']
Availability,Make warnings into errors,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/368:19,error,errors,19,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/368,1,['error'],['errors']
Availability,"Makes CreateVariantIngestFiles robust to partially or fully loaded samples. Commit 21828af8f5a925cc331dce6093c0d510042d7b64 is what I actually propose to merge, while commit de673204183a4c45059dc9ea4e05868e2ea6ae59 randomly injects failures covering all the known failure modes. I tested these changes using both commits and was able to verify that partially loaded samples were handled correctly on subsequent attempts to load the sample (unfortunately we can't actually prevent these partial loadings from happening in the first place because preemptions, among other possible reasons).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7843:31,robust,robust,31,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7843,3,"['failure', 'robust']","['failure', 'failures', 'robust']"
Availability,"Makes `CreateVariantIngestFiles` robust to partially or fully loaded samples. Commit a8dc5ea89653a7f94588aa040b49d0264d17f72d is what I actually propose to merge, while commit 118a44604343e8f77d53bcc6545b2360fefbe1cc randomly injects failures covering all the known failure modes. I tested these changes using both commits and was able to verify that partially loaded samples were handled correctly on subsequent attempts to load the sample (unfortunately we can't actually prevent these partial loadings from happening in the first place because preemptions, among other possible reasons).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7831:33,robust,robust,33,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7831,3,"['failure', 'robust']","['failure', 'failures', 'robust']"
Availability,Many of the Picard tools we'd like to port have no existing unit tests. We should write them and then backport them to Picard. Let's keep track of them here:. picard.sam:; AddOrReplaceReadGroups; BamIndexStats; BuildBamIndex; CalculateReadGroupChecksum; CheckTerminatorBlock; DownsampleSam; EstimateLibraryComplexity?; FilterReads; FixMateInformation; ReorderSam; ReplaceSamHeader; RevertOriginalBaseQualitiesAndAddMateCigar; SortSam. TODO other packages,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/144:276,Down,DownsampleSam,276,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/144,1,['Down'],['DownsampleSam']
Availability,MarkDuplicates Spark output needs to tested against the version of picard they use in production to ensure that it produces identical output and is reasonably robust to pathological files. This requires that the following issues have been resolved:; #3705 ; #3706,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4675:159,robust,robust,159,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4675,1,['robust'],['robust']
Availability,MarkDuplicatesSpark error when FASTQ headers contain another @ in string,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8134:20,error,error,20,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8134,1,['error'],['error']
Availability,MarkDuplicatesSpark improvements checkpoint,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4656:33,checkpoint,checkpoint,33,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4656,1,['checkpoint'],['checkpoint']
Availability,MarkDuplicatesSpark throw an error,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7035:29,error,error,29,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7035,1,['error'],['error']
Availability,Mask duplicates,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8043:0,Mask,Mask,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8043,1,['Mask'],['Mask']
Availability,Master is broken. [E.g.](https://travis-ci.com/broadinstitute/gatk/jobs/227807624). ```; Fetched 217 kB in 1s (163 kB/s); Reading package lists...; W: http://ppa.launchpad.net/couchdb/stable/ubuntu/dists/trusty/Release.gpg: Signature by key 15866BAFD9BCC4F3C1E0DFC7D69548E1C17EAB57 uses weak digest algorithm (SHA1); W: GPG error: https://packagecloud.io/github/git-lfs/ubuntu trusty InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 6B05F25D762E3157; W: The repository 'https://packagecloud.io/github/git-lfs/ubuntu trusty InRelease' is not signed.; W: There is no public key available for the following key IDs:; 6B05F25D762E3157 . ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6116:324,error,error,324,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6116,3,"['avail', 'error']","['available', 'error']"
Availability,Mention acceptable compressed VCF file extension in GenomicsDBImport error message,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7692:69,error,error,69,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7692,1,['error'],['error']
Availability,Merge changes from the EchoCallset branch back into our main branch ('ah_var_store'). Most of these changes are VDS creation related. Passing Integration test [here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/f5cb7a2d-b224-4b8e-8daf-2d22939a1d96),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8993:23,Echo,EchoCallset,23,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8993,1,['Echo'],['EchoCallset']
Availability,Merging VS-1379 code into Echo Callset branch now. Need some thumbs,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8879:26,Echo,Echo,26,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8879,1,['Echo'],['Echo']
Availability,Migrate read arguments and downstream code to GATKPathSpecifier,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6561:27,down,downstream,27,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6561,1,['down'],['downstream']
Availability,Migrate reference arguments and downstream code to GATKPathSpecifier.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6524:32,down,downstream,32,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6524,1,['down'],['downstream']
Availability,Misleading error message about multi-sample when no read groups are present,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6501:11,error,error,11,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6501,1,['error'],['error']
Availability,ModelSegments command memory error,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5948:29,error,error,29,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5948,1,['error'],['error']
Availability,ModelSegments integration test failures on newer Java 11 releases,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8107:31,failure,failures,31,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8107,1,['failure'],['failures']
Availability,Modern versions of womtool don't tolerate task inputs with the same name as task outputs and produce baffling error messages like [this](https://broadinstitute.slack.com/archives/C4GSMFXS9/p1654807836682679).,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8265:33,toler,tolerate,33,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8265,2,"['error', 'toler']","['error', 'tolerate']"
Availability,More robust parsing of the flow based read - determines the maximal possible quality automatically,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8642:5,robust,robust,5,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8642,1,['robust'],['robust']
Availability,Move NativeUtils class to gatk-native-bindings once it's available via maven,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1848:57,avail,available,57,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1848,1,['avail'],['available']
Availability,"Move to google-cloud-java snapshot with more robust retries, and set number of retries/reopens globally",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3295:45,robust,robust,45,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3295,1,['robust'],['robust']
Availability,Moving classes that tests depend on from the test folders into the src folders in the utils.test package. This way they will be available to projects that depend on hellbender. Fixes #525 . Updating to the newest testng release.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/527:128,avail,available,128,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/527,1,['avail'],['available']
Availability,MuTect2 Should Error if Almost All Somatic Variants Supported by Few Reads,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6674:15,Error,Error,15,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6674,1,['Error'],['Error']
Availability,Multithreading is not worth the errors and must be removed from hellbender code. GATK4 is a single-thread toolkit.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/402:32,error,errors,32,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/402,1,['error'],['errors']
Availability,Mutect downsampler that recognizes and skips bad mapping regions,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3988:7,down,downsampler,7,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3988,1,['down'],['downsampler']
Availability,Mutect isActive loses sensitivity when allele fraction is comparable to base error rate,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4816:77,error,error,77,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4816,1,['error'],['error']
Availability,Mutect2 (GATK 4.1.0.0) fails occasionally in smith waterman native library as below. stderr is attached. I can also provide core dump if necessary. [stderr.tar.gz](https://github.com/broadinstitute/gatk/files/2880800/stderr.tar.gz). ```; 07:30:59.335 INFO ProgressMeter - 17:78451657 627.7 1223980 1950.0; *** Error in `java': munmap_chunk(): invalid pointer: 0x00002ba8e50b7740 ***; ======= Backtrace: =========; /lib64/libc.so.6(+0x7ab54)[0x2ba8df926b54]; /gpfs/data/software/cromwell/log/cromwell-executions/Mutect2/2cebc7be-fe23-4787-9095-9b91227c6526/call-M2/shard-13/attempt-2/tmp.945f1f83/libgkl_smithwaterman5575294852416409537.so(_Z19runSWOnePairBT_avx2iiiiPhS_iiaPcPs+0x338)[0x2ba9aee21fa8]; /gpfs/data/software/cromwell/log/cromwell-executions/Mutect2/2cebc7be-fe23-4787-9095-9b91227c6526/call-M2/shard-13/attempt-2/tmp.945f1f83/libgkl_smithwaterman5575294852416409537.so(Java_com_intel_gkl_smithwaterman_IntelSmithWaterman_alignNative+0xd8)[0x2ba9aee21bf8]; [0x2ba8e8f6675a]; ======= Memory map: ========; 00400000-00401000 r-xp 00000000 08:03 5769910 /usr/lib/jvm/java-1.8.0-openjdk-1.8.0.111-1.b15.el7_2.x86_64/jre/bin/java; 00600000-00601000 r--p 00000000 08:03 5769910 /usr/lib/jvm/java-1.8.0-openjdk-1.8.0.111-1.b15.el7_2.x86_64/jre/bin/java; ...; ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5690:310,Error,Error,310,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5690,1,['Error'],['Error']
Availability,Mutect2 error ComparableSamRecordIterator,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7872:8,error,error,8,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7872,1,['error'],['error']
Availability,Mutect2 error getNumTandemRepeatUnits String index out of range,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6516:8,error,error,8,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6516,1,['error'],['error']
Availability,Mutect2 error when running inside a pipeline in parallel with intervals,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7059:8,error,error,8,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7059,1,['error'],['error']
Availability,Mutect2 error when trying to create fragment with no read support,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6310:8,error,error,8,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6310,1,['error'],['error']
Availability,Mutect2 gatk 4.1.6.0: java.lang.IllegalStateException: Smith-Waterman alignment failure,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6529:80,failure,failure,80,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6529,1,['failure'],['failure']
Availability,"Mutect2 matches called variants against known variants retrieved from the germline resource VCF (if available) for the POPAF annotation. While comparing the called allele to the germline resource variants, Mutect2 only takes into account the sequence of the alternate allele(s) while ignoring the reference allele sequence. This can cause incorrect annotations at sites with multiple alternate alleles (e.g. CT -> C/CTT in the germline resource while M2 calls C -> CT). This PR is a proposed fix along with some unit tests that demonstrate the issue.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6999:100,avail,available,100,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6999,1,['avail'],['available']
Availability,"Mutect3 dataset enhancements: optional truth VCF for labels, seq error likelihood annotation",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7975:65,error,error,65,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7975,1,['error'],['error']
Availability,"My struggles with indexes in GATK4 continue. I forgot to pull down the corresponding *.tbi index for my .vcf.gz, but SelectVariants just toodled along until chr14:; ```; htsjdk.tribble.TribbleException: Line 3889836: there aren't enough columns for line chr14 24737838 rs1101636 C T . PASS AC=2;AF=1.00;AN=2;DB;DP=38;ExcessHet=0.7420;FS=0.000;InbreedingCoeff=0.0357;MQ=59.98;MQRankSum=0.026;MQ_DP=24332;POSITIVE_TRAIN_SITE;QD=22.41;QUALapprox=537 (we expected 9 tokens, and saw 8 ), for input source: file:///humgen/gsa-hpprojects/dev/gauthier/reblockGVCF/gnomADaccuracyTest.noMQinSNPVQSR.SynDip.vcf.gz; at htsjdk.variant.vcf.AbstractVCFCodec.decodeLine(AbstractVCFCodec.java:281); at htsjdk.variant.vcf.AbstractVCFCodec.decode(AbstractVCFCodec.java:262); at htsjdk.variant.vcf.AbstractVCFCodec.decode(AbstractVCFCodec.java:64); at htsjdk.tribble.AsciiFeatureCodec.decode(AsciiFeatureCodec.java:70); at htsjdk.tribble.AsciiFeatureCodec.decode(AsciiFeatureCodec.java:37); at htsjdk.tribble.TribbleIndexedFeatureReader$WFIterator.readNextRecord(TribbleIndexedFeatureReader.java:365); at htsjdk.tribble.TribbleIndexedFeatureReader$WFIterator.next(TribbleIndexedFeatureReader.java:346); at htsjdk.tribble.TribbleIndexedFeatureReader$WFIterator.next(TribbleIndexedFeatureReader.java:307); at java.util.Iterator.forEachRemaining(Iterator.java:116); at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); at org.broadinstitute.hellbender.engine.VariantWalkerBase.traverse(VariantWalkerBase.java:108); ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4224:62,down,down,62,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4224,1,['down'],['down']
Availability,N StrandBiasBySample - Annotation will not be calculated at position chr6:67407399 and possibly subsequent; genotype for sample 8939{JXM}-3 is not called ; ; 23:44:10.556 WARN DepthPerSampleHC - Annotation will not be calculated at position chr6:67407415 and possibly subsequent; genotype for sample 8939{JXM}-3 is not called ; ; 23:44:10.556 WARN StrandBiasBySample - Annotation will not be calculated at position chr6:67407415 and possibly subsequent; genotype for sample 8939{JXM}-3 is not called ; ; 23:44:14.224 INFO ProgressMeter - chr6:67607778 569.6 5544800 9734.3 ; ; 23:44:24.280 INFO ProgressMeter - chr6:68147283 569.8 5547230 9735.7 ; ; 23:44:30.026 INFO VectorLoglessPairHMM - Time spent in setup for JNI call : 27.307544954 ; ; 23:44:30.027 INFO PairHMM - Total compute time in PairHMM computeLogLikelihoods() : 4768.198119518001 ; ; 23:44:30.027 INFO SmithWatermanAligner - Total compute time in java Smith-Waterman : 4695.36 sec ; ; 23:44:30.027 INFO HaplotypeCaller - Shutting down engine ; ; \[2021年11月1日 下午11时44分30秒\] org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCaller done. Elapsed time: 569.97 minutes. ; ; Runtime.totalMemory()=742916096 ; ; htsjdk.samtools.SAMFormatException: Did not inflate expected amount ; ; at htsjdk.samtools.util.BlockGunzipper.unzipBlock(BlockGunzipper.java:147) ; ; at htsjdk.samtools.util.BlockGunzipper.unzipBlock(BlockGunzipper.java:96) ; ; at htsjdk.samtools.util.BlockCompressedInputStream.inflateBlock(BlockCompressedInputStream.java:550) ; ; at htsjdk.samtools.util.BlockCompressedInputStream.processNextBlock(BlockCompressedInputStream.java:532) ; ; at htsjdk.samtools.util.BlockCompressedInputStream.nextBlock(BlockCompressedInputStream.java:468) ; ; at htsjdk.samtools.util.BlockCompressedInputStream.readBlock(BlockCompressedInputStream.java:458) ; ; at htsjdk.samtools.util.BlockCompressedInputStream.available(BlockCompressedInputStream.java:196) ; ; at htsjdk.samtools.util.BlockCompressedInputStream.read(BlockC,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7582:7953,down,down,7953,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7582,1,['down'],['down']
Availability,"N; Y 59252232 59252800 target_189882_VAMP7 NaN; Y 59272120 59272713 target_189883_VAMP7 NaN; Y 59274302 59274871 target_189884_VAMP7 NaN; Y 59330180 59330708 target_189885_IL9R NaN; Y 59333828 59334429 target_189886_IL9R NaN; Y 59335302 59335904 target_189887_IL9R NaN; Y 59335905 59336289 target_189888_IL9R NaN; Y 59336290 59336776 target_189889_IL9R NaN; Y 59336840 59337486 target_189890_IL9R NaN; Y 59337698 59338400 target_189891_IL9R NaN; Y 59338503 59339109 target_189892_IL9R NaN; Y 59339943 59340528 target_189893_IL9R NaN; Y 59342236 59343330 target_189894_IL9R NaN. ---. @mbabadi commented on [Fri Aug 26 2016](https://github.com/broadinstitute/gatk-protected/issues/651#issuecomment-242767764). @davidbenjamin could you please take a look? it sounds like it could be a problem with the reference missing these regions. ---. @mbabadi commented on [Fri Aug 26 2016](https://github.com/broadinstitute/gatk-protected/issues/651#issuecomment-242774747). OK it turns out that the reference is hard masked and has ""N"" in that region. Nevertheless, we shouldn't get NaNs. In my opinion, the correct behavior is to drop targets on which GC percentage can not be defined + emit informative error messages. ---. @davidbenjamin commented on [Sun Sep 11 2016](https://github.com/broadinstitute/gatk-protected/issues/651#issuecomment-246177779). I will address this. ---. @mbabadi commented on [Tue Sep 27 2016](https://github.com/broadinstitute/gatk-protected/issues/651#issuecomment-250018497). @davidbenjamin also, CorrectGCBias produces NaNs when a sample has very low coverage. I think the correct behavior is this:. (1) when annotating targets, it is OK to produce NaNs on targets whose GC bias can not be determined. When correcting for GC bias, those targets must be removed altogether. (2) if the bias curve can not be determined (let's say because of low coverage), the tool should remove that sample from the collection and emit appropriate warning messages. If all samples are removed, the",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2882:3808,mask,masked,3808,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2882,1,['mask'],['masked']
Availability,"NCODE GTF Header line 1 has a version number that is above maximum tested version (v 34) (given: 37): ##description: evidence-based annotation of the human genome (GRCh38), version 37 (Ensembl 103), mapped to GRCh37 with gencode-backmap Continuing, but errors may occur.; 18:53:59.419 WARN GencodeGtfCodec - GENCODE GTF Header line 1 has a version number that is above maximum tested version (v 34) (given: 37): ##description: evidence-based annotation of the human genome (GRCh38), version 37 (Ensembl 103), mapped to GRCh37 with gencode-backmap Continuing, but errors may occur.; 18:53:59.422 INFO FeatureManager - Using codec EnsemblGtfCodec to read file file:///home/robby/Tools/NGS/gatk-master4_2_src/scripts/funcotator/data_sources/gencode/hg19/gencode.v37lift37.annotation.REORDERED.gtf; 18:53:59.433 INFO ProgressMeter - Starting traversal; 18:53:59.433 INFO ProgressMeter - Current Locus Elapsed Minutes Records Processed Records/Minute; 18:54:01.952 INFO IndexFeatureFile - Shutting down engine; [March 8, 2021 at 6:54:01 PM CET] org.broadinstitute.hellbender.tools.IndexFeatureFile done. Elapsed time: 0.05 minutes.; Runtime.totalMemory()=473956352; java.lang.IllegalArgumentException: Unexpected value: MANE_Plus_Clinical; at org.broadinstitute.hellbender.utils.codecs.gtf.GencodeGtfFeature$FeatureTag.getEnum(GencodeGtfFeature.java:1388); at org.broadinstitute.hellbender.utils.codecs.gtf.GencodeGtfFeature.<init>(GencodeGtfFeature.java:197); at org.broadinstitute.hellbender.utils.codecs.gtf.GencodeGtfTranscriptFeature.<init>(GencodeGtfTranscriptFeature.java:19); at org.broadinstitute.hellbender.utils.codecs.gtf.GencodeGtfTranscriptFeature.create(GencodeGtfTranscriptFeature.java:23); at org.broadinstitute.hellbender.utils.codecs.gtf.GencodeGtfFeature$FeatureType$2.create(GencodeGtfFeature.java:768); at org.broadinstitute.hellbender.utils.codecs.gtf.GencodeGtfFeature.create(GencodeGtfFeature.java:327); at org.broadinstitute.hellbender.utils.codecs.gtf.AbstractGtfCodec.decode(Ab",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7134:2738,down,down,2738,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7134,1,['down'],['down']
Availability,"NC\_IO\_READ\_FOR\_SAMTOOLS : false ; ; 04:33:13.196 INFO IndexFeatureFile - HTSJDK Defaults.USE\_ASYNC\_IO\_WRITE\_FOR\_SAMTOOLS : true ; ; 04:33:13.196 INFO IndexFeatureFile - HTSJDK Defaults.USE\_ASYNC\_IO\_WRITE\_FOR\_TRIBBLE : false ; ; 04:33:13.196 INFO IndexFeatureFile - Deflater: IntelDeflater ; ; 04:33:13.196 INFO IndexFeatureFile - Inflater: IntelInflater ; ; 04:33:13.196 INFO IndexFeatureFile - GCS max retries/reopens: 20 ; ; 04:33:13.196 INFO IndexFeatureFile - Requester pays: disabled ; ; 04:33:13.196 INFO IndexFeatureFile - Initializing engine ; ; 04:33:13.196 INFO IndexFeatureFile - Done initializing engine ; ; 04:33:13.396 INFO FeatureManager - Using codec EnsemblGtfCodec to read file file:///gatk/funcotator-scripts/gencode/mm10/gencode.vM25.annotation.gtf ; ; 04:33:13.400 INFO ProgressMeter - Starting traversal ; ; 04:33:13.400 INFO ProgressMeter - Current Locus Elapsed Minutes Records Processed Records/Minute ; ; 04:33:21.040 INFO IndexFeatureFile - Shutting down engine ; ; \[January 25, 2021 4:33:21 AM GMT\] org.broadinstitute.hellbender.tools.IndexFeatureFile done. Elapsed time: 0.13 minutes. ; ; Runtime.totalMemory()=1835532288 ; ; java.lang.IllegalArgumentException: Unexpected value: IG\_D\_pseudogene ; ; at org.broadinstitute.hellbender.utils.codecs.gtf.GencodeGtfFeature$GeneTranscriptType.getEnum(GencodeGtfFeature.java:1060) ; ; at org.broadinstitute.hellbender.utils.codecs.gtf.GencodeGtfFeature.<init>(GencodeGtfFeature.java:158) ; ; at org.broadinstitute.hellbender.utils.codecs.gtf.GencodeGtfGeneFeature.<init>(GencodeGtfGeneFeature.java:19) ; ; at org.broadinstitute.hellbender.utils.codecs.gtf.GencodeGtfGeneFeature.create(GencodeGtfGeneFeature.java:23) ; ; at org.broadinstitute.hellbender.utils.codecs.gtf.GencodeGtfFeature$FeatureType$1.create(GencodeGtfFeature.java:760) ; ; at org.broadinstitute.hellbender.utils.codecs.gtf.GencodeGtfFeature.create(GencodeGtfFeature.java:327) ; ; at org.broadinstitute.hellbender.utils.codecs.gtf.AbstractGtfCo",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7054:3604,down,down,3604,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7054,1,['down'],['down']
Availability,NDArray error from GermlineCNVCaller,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3996:8,error,error,8,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3996,1,['error'],['error']
Availability,"NFO DataSourceUtils - Resolved data source file path: file:///home/pkus/mutect_test/gencode_xrefseq_v90_38.tsv -> file:///home/pkus/resources/gatk/funcotator2/funcotator_dataSources.v1.7.20200521s/gencode_xrefseq/hg38/gencode_xrefseq_v90_38.tsv; > 15:16:43.878 INFO DataSourceUtils - Resolved data source file path: file:///home/pkus/mutect_test/cosmic_tissue.tsv -> file:///home/pkus/resources/gatk/funcotator2/funcotator_dataSources.v1.7.20200521s/cosmic_tissue/hg38/cosmic_tissue.tsv; > 15:16:43.926 INFO DataSourceUtils - Resolved data source file path: file:///home/pkus/mutect_test/gencode.v34.annotation.REORDERED.gtf -> file:///home/pkus/resources/gatk/funcotator2/funcotator_dataSources.v1.7.20200521s/gencode/hg38/gencode.v34.annotation.REORDERED.gtf; > 15:16:43.926 INFO DataSourceUtils - Setting lookahead cache for data source: Gencode : 100000; > 15:16:43.937 WARN GencodeGtfCodec - GENCODE GTF Header line 1 has a version number that is above maximum tested version (v 28) (given: 34): ##description: evidence-based annotation of the human genome (GRCh38), version 34 (Ensembl 100) Continuing, but errors may occur.; > 15:16:43.938 WARN GencodeGtfCodec - GENCODE GTF Header line 1 has a version number that is above maximum tested version (v 28) (given: 34): ##description: evidence-based annotation of the human genome (GRCh38), version 34 (Ensembl 100) Continuing, but errors may occur.; > 15:16:43.939 INFO FeatureManager - Using codec GencodeGtfCodec to read file file:///home/pkus/resources/gatk/funcotator2/funcotator_dataSources.v1.7.20200521s/gencode/hg38/gencode.v34.annotation.REORDERED.gtf; > 15:16:43.946 WARN GencodeGtfCodec - GENCODE GTF Header line 1 has a version number that is above maximum tested version (v 28) (given: 34): ##description: evidence-based annotation of the human genome (GRCh38), version 34 (Ensembl 100) Continuing, but errors may occur.; > 15:16:44.093 INFO DataSourceUtils - Resolved data source file path: file:///home/pkus/mutect_test/gencode.v3",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6708:13791,error,errors,13791,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6708,1,['error'],['errors']
Availability,"NFO DetermineGermlineContigPloidy - GCS max retries/reopens: 20; 08:48:45.928 INFO DetermineGermlineContigPloidy - Requester pays: disabled; 08:48:45.928 INFO DetermineGermlineContigPloidy - Initializing engine; 08:48:45.931 DEBUG ScriptExecutor - Executing:; 08:48:45.931 DEBUG ScriptExecutor - python; 08:48:45.932 DEBUG ScriptExecutor - -c; 08:48:45.932 DEBUG ScriptExecutor - import gcnvkernel. WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.; /home/ec2-user/miniconda3/envs/gatk/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.; from ._conv import register_converters as _register_converters; 08:48:50.351 DEBUG ScriptExecutor - Result: 0; 08:48:50.351 INFO DetermineGermlineContigPloidy - Done initializing engine; 08:48:50.352 INFO DetermineGermlineContigPloidy - Shutting down engine; [October 17, 2019 8:48:50 AM UTC] org.broadinstitute.hellbender.tools.copynumber.DetermineGermlineContigPloidy done. Elapsed time: 0.08 minutes.; Runtime.totalMemory()=597164032; java.lang.IllegalArgumentException: List of input read-count files cannot contain duplicates.; at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:725); at org.broadinstitute.hellbender.tools.copynumber.DetermineGermlineContigPloidy.validateArguments(DetermineGermlineContigPloidy.java:304); at org.broadinstitute.hellbender.tools.copynumber.DetermineGermlineContigPloidy.doWork(DetermineGermlineContigPloidy.java:277); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); at org.broadinstitute.hellbender.Main.runCommandLineProg",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6217:6756,down,down,6756,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6217,1,['down'],['down']
Availability,"NFO GenomicsDBImport - Requester pays: disabled; 12:52:37.524 INFO GenomicsDBImport - Initializing engine; 12:52:38.096 INFO FeatureManager - Using codec BEDCodec to read file file:///mnt/fargen/resources/sureselect_human_all_exon_v6_utr_grch38/S07604624_Padded.bed; 12:52:43.641 INFO IntervalArgumentCollection - Processing 134492644 bp from intervals; 12:52:43.720 WARN GenomicsDBImport - A large number of intervals were specified. Using more than 100 intervals in a single import is not recommended and can cause performance to suffer. If GVCF data only exists within those intervals, performance can be improved by aggregating intervals with the merge-input-intervals argument.; 12:52:43.722 INFO GenomicsDBImport - Done initializing engine; 12:52:44.113 INFO GenomicsDBImport - Vid Map JSON file will be written to /mnt/fargen/experiments/joint_call/data/genomicsdb/run1/vidmap.json; 12:52:44.113 INFO GenomicsDBImport - Callset Map JSON file will be written to /mnt/fargen/experiments/joint_call/data/genomicsdb/run1/callset.json; 12:52:44.114 INFO GenomicsDBImport - Complete VCF Header will be written to /mnt/fargen/experiments/joint_call/data/genomicsdb/run1/vcfheader.vcf; 12:52:44.114 INFO GenomicsDBImport - Importing to array - /mnt/fargen/experiments/joint_call/data/genomicsdb/run1/genomicsdb_array; 12:52:44.114 INFO ProgressMeter - Starting traversal; 12:52:44.115 INFO ProgressMeter - Current Locus Elapsed Minutes Batches Processed Batches/Minute; 13:03:44.100 INFO GenomicsDBImport - Importing batch 1 with 2 samples; [TileDB::FileSystem] Error: (sync_path) Cannot sync file; File syncing error; path=/mnt/fargen/experiments/joint_call/data/genomicsdb/run1/chr1$11981$12351/.__cd28ac27-6a06-422f-a674-2acfbdb072d1140406632785664_1551359040166; errno=22(Invalid argument); terminate called after throwing an instance of 'VariantStorageManagerException'; what(): VariantStorageManagerException exception : Error while syncing array chr1$11981$12351 to disk; TileDB error message :",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5740:4624,Error,Error,4624,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5740,4,"['Error', 'error']","['Error', 'error']"
Availability,NFO GenotypeGVCFs - Picard Version: 2.21.9; 09:48:14.873 INFO GenotypeGVCFs - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 09:48:14.874 INFO GenotypeGVCFs - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 09:48:14.874 INFO GenotypeGVCFs - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 09:48:14.874 INFO GenotypeGVCFs - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 09:48:14.874 INFO GenotypeGVCFs - Deflater: IntelDeflater; 09:48:14.874 INFO GenotypeGVCFs - Inflater: IntelInflater; 09:48:14.874 INFO GenotypeGVCFs - GCS max retries/reopens: 20; 09:48:14.874 INFO GenotypeGVCFs - Requester pays: disabled; 09:48:14.874 INFO GenotypeGVCFs - Initializing engine; 09:48:16.015 INFO GenotypeGVCFs - Shutting down engine; [27 May 2020 09:48:16 CEST] oAB.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs done. Elapsed time: 0.03 minutes.; Runtime.totalMemory()=2301100032; ***********************************************************************. A USER ERROR has occurred: Couldn't create GenomicsDBFeatureReader. ***********************************************************************; oAB.broadinstitute.hellbender.exceptions.UserException: Couldn't create GenomicsDBFeatureReader; 	at oAB.broadinstitute.hellbender.engine.FeatureDataSource.getGenomicsDBFeatureReader(FeatureDataSource.java:410); 	at oAB.broadinstitute.hellbender.engine.FeatureDataSource.getFeatureReader(FeatureDataSource.java:326); 	at oAB.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:282); 	at oAB.broadinstitute.hellbender.engine.VariantLocusWalker.initializeDrivingVariants(VariantLocusWalker.java:76); 	at oAB.broadinstitute.hellbender.engine.VariantWalkerBase.initializeFeatures(VariantWalkerBase.java:67); 	at oAB.broadinstitute.hellbender.engine.GATKTool.onStartup(GATKTool.java:706); 	at oAB.broadinstitute.hellbender.engine.VariantLocusWalker.onStartup(VariantLocusWalker.java:63); 	at oAB.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLine,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6616:10469,ERROR,ERROR,10469,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6616,1,['ERROR'],['ERROR']
Availability,"NFO ProgressMeter - chr6:7646289 1.0 171000 166913.4; 23:23:03.973 INFO ProgressMeter - chr6:9029926 1.2 200000 167553.3; 23:23:14.220 INFO ProgressMeter - chr6:10374988 1.4 229000 167835.2; 23:23:24.322 INFO ProgressMeter - chr6:11782077 1.5 259000 168971.8; 23:23:34.465 INFO ProgressMeter - chr6:13360174 1.7 290000 170404.5; 23:23:44.556 INFO ProgressMeter - chr6:14757971 1.9 319000 170585.2; 23:23:54.657 INFO ProgressMeter - chr6:16217652 2.0 350000 171704.7; 23:24:04.905 INFO ProgressMeter - chr6:17737681 2.2 381000 172461.9; 23:24:15.102 INFO ProgressMeter - chr6:19070725 2.4 409000 171911.3; 23:24:25.321 INFO ProgressMeter - chr6:20580950 2.5 441000 172978.5; 23:24:36.315 INFO ProgressMeter - chr6:22100346 2.7 472000 172724.0; 23:24:46.346 INFO ProgressMeter - chr6:23531348 2.9 502000 173112.4; 23:24:56.432 INFO ProgressMeter - chr6:24734131 3.1 531000 173078.8; 23:25:06.662 INFO ProgressMeter - chr6:26183595 3.2 559000 172612.6; 23:25:11.087 INFO ApplyVQSR - Shutting down engine; [October 12, 2022 11:25:11 PM EDT] org.broadinstitute.hellbender.tools.walkers.vqsr.ApplyVQSR done. Elapsed time: 3.33 minutes.; Runtime.totalMemory()=8242331648; org.broadinstitute.hellbender.exceptions.GATKException: Exception thrown at chr6:26914009 [VC chr6.raw.excessHet.vcf.gz @ chr6:26914009 Q276902.75 of type=INDEL alleles=[G*, GTGTA, GTGTATA, GTGTGTA] attr={AC=[4269, 29, 5], AF=[0.620, 4.209e-03, 7.257e-04], AN=6890, AS_BaseQRankSum=[0.500, 0.500, 0.500], AS_FS=[0.544, 0.000, 0.000], AS_InbreedingCoeff=[0.0312, 0.0151, 0.0858], AS_MQ=[59.29, 57.89, 58.81], AS_MQRankSum=[0.000, -3.800, -3.800], AS_QD=[3.94, 0.05, 0.01], AS_ReadPosRankSum=[0.200, 0.300, 0.300], AS_SOR=[0.747, 0.705, 0.739], BaseQRankSum=0.515, DP=121924, ExcessHet=0.1315, FS=0.552, InbreedingCoeff=0.0304, MLEAC=[4273, 28, 5], MLEAF=[0.620, 4.064e-03, 7.257e-04], MQ=57.54, MQRankSum=-1.059e+00, QD=3.98, ReadPosRankSum=0.244, SOR=0.780} GT=GT:AD:DP:GQ:PGT:PID:PL:PS31/1:0,15,0,0:18:45:.:.:106,45,0,569,45,106,569,4",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8054:3634,down,down,3634,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8054,1,['down'],['down']
Availability,"NFO VariantAnnotator - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 14:02:45.348 INFO VariantAnnotator - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 14:02:45.349 INFO VariantAnnotator - Deflater: JdkDeflater; 14:02:45.349 INFO VariantAnnotator - Inflater: JdkInflater; 14:02:45.349 INFO VariantAnnotator - GCS max retries/reopens: 20; 14:02:45.349 INFO VariantAnnotator - Requester pays: disabled; 14:02:45.349 INFO VariantAnnotator - Initializing engine; 14:02:45.425 INFO FeatureManager - Using codec VCFCodec to read file file:///directory_masked/test.vcf; 14:02:45.436 INFO VariantAnnotator - Done initializing engine; 14:02:45.459 INFO ProgressMeter - Starting traversal; 14:02:45.459 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 14:02:45.498 WARN VariantAnnotatorEngine - Jumbo genotype annotations requested but fragment likelihoods or haplotype likelihoods were not given.; 14:02:45.505 INFO VariantAnnotator - Shutting down engine; [April 30, 2024 at 2:02:45 PM HKT] org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotator done. Elapsed time: 0.00 minutes.; Runtime.totalMemory()=285212672; java.lang.IndexOutOfBoundsException: Index 1 out of bounds for length 1; at java.base/jdk.internal.util.Preconditions.outOfBounds(Preconditions.java:64); at java.base/jdk.internal.util.Preconditions.outOfBoundsCheckIndex(Preconditions.java:70); at java.base/jdk.internal.util.Preconditions.checkIndex(Preconditions.java:266); at java.base/java.util.Objects.checkIndex(Objects.java:361); at java.base/java.util.ArrayList.get(ArrayList.java:427); at java.base/java.util.Collections$UnmodifiableList.get(Collections.java:1347); at org.broadinstitute.hellbender.tools.walkers.annotator.AllelePseudoDepth$1.visit(AllelePseudoDepth.java:119); at org.apache.commons.math3.linear.Array2DRowRealMatrix.walkInRowOrder(Array2DRowRealMatrix.java:400); at org.apache.commons.math3.linear.AbstractRealMatrix.walkInOptimizedOrder(Abstra",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8800:2896,down,down,2896,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8800,1,['down'],['down']
Availability,"NIENT \ ; --nativePairHmmThreads 32 \; --createOutputVariantIndex true \; --output NA12892.raw.snps.indels.g.vcf_. **This execution time for GATK 4 Beta2 is: 51 Hours, 32 min**. Alternatively, I was running the same sample (NA12892) using GATK 3.7 using the following command: . _time -p java -XX:+UseParallelGC -XX:ParallelGCThreads=32 -Xmx128g \; -jar /gpfs/software/genomics/GATK/3.7/base/GenomeAnalysisTK.jar -T HaplotypeCaller \; -nct 8 -pairHMM VECTOR_LOGLESS_CACHING \ ; -R /gpfs/data_jrnas1/ref_data/Hsapiens/hs37d5/hs37d5.fa \; -I NA12892.realigned.recal.bam -\ ; -emitRefConfidence GVCF \; --variant_index_type LINEAR \; --variant_index_parameter 128000 \; --dbsnp /gpfs/data_jrnas1/ref_data/Hsapiens/GRCh37/variation/dbsnp_138.vcf.gz \; -o NA12892.raw.snps.indels.g.vcf _. **This execution time for GATK 3.7 is: 18 Hours, 12 min**. I don't know, how to use multithreads (e.g. -nct) for GATK 4 version to reduce the execution time on the single node. Because, we have 32 cores per node with 512GB memory available for benchmarking. To parallelize the GATK 4 workload, I used the Spark version also. . I used **GATK 4 Beta2 Spark job on the cluster of 32 nodes** (32 nodes x 32 cores, totaling 1024 cores). The execution time is almost same as GATK 4 Beta2 ( 50 Hours, 21 min). Please help me, how to reduce the execution time for GATK 4 Beta2 HaplotypeCaller? . Please see this below Spark logs:. + /gpfs/software/spark/spark-2.1.0-bin-hadoop2.7//bin/spark-submit --master spark://nsnode11:6311 --driver-java-options -Dsamjdk.use_async_io_read_samtools=false,-Dsamjdk.use_async_io_write_samtools=true,-Dsamjdk.use_async_io_write_tribble=false,-Dsamjdk.compression_level=1 --conf spark.io.compression.codec=snappy --conf spark.yarn.executor.memoryOverhead=6000 --conf spark.kryoserializer.buffer.max=512m --conf spark.driver.userClassPathFirst=true --conf spark.driver.maxResultSize=0 --conf spark.executor.cores=1024 --conf spark.reducer.maxSizeInFlight=100m --conf spark.shuffle.file.buffer",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3631:1574,avail,available,1574,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3631,1,['avail'],['available']
Availability,"NIO error: ""position should be non-negative""",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2516:4,error,error,4,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2516,1,['error'],['error']
Availability,"NVAR, or Number of genotyped VARiants. Description:. [minor/major allele] A minor (respectively major) allele is an allele present in less than (respectively, in at least) half the alleles from all the genotyped samples. Description:. [NMIN] NMIN is the number of variants of the given sample with a genotype that is not major/major. Influenced by:. Ethnicity (the distribution of NMIN is usually bimodal with Africans in one mode in the higher values). Remark:. Since this metric focuses of minor alleles, the proportion of rare variants considered (where more errors are expected) is higher. This makes NMIN more sensitive to errors than NALT, which is a desirable feature. Calculated by:. pseq i-stats (NMIN)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/536:562,error,errors,562,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/536,2,['error'],['errors']
Availability,"NVCaller --run-mode COHORT -L /outputs/gatk_intervals.interval_list --interval-merging-rule OVERLAPPING_ONLY --annotated-intervals /outputs/gatk_intervals.interval_list.annotated.tsv --contig-ploidy-calls /outputs/COHORT_runDir/COHORT-calls --input /outputs/E07002_normal_alignment.bam.counts.hdf5 --input /outputs/E07002_tumor_alignment.bam.counts.hdf5 --output /outputs/COHORT_runDir --output-prefix COHORT; ```. We used data from `PRJNA399748` project to test. #### Expected behavior. - `test_gatkgermlinecnvcaller_genotyped-intervals-cohort_0.woTimestamp.vcf` (`##contig` cut from header and only first 5 `chr22` CNVs present). ```; ##fileformat=VCFv4.2; ##FORMAT=<ID=CN,Number=1,Type=Integer,Description=""Copy number maximum a posteriori value"">; ##FORMAT=<ID=CNLP,Number=.,Type=Integer,Description=""Copy number log posterior (in Phred-scale) rounded down"">; ##FORMAT=<ID=CNQ,Number=1,Type=Integer,Description=""Genotype call quality as the difference between the best and second best phred-scaled log posterior scores"">; ##FORMAT=<ID=GT,Number=1,Type=Integer,Description=""Genotype"">; ##INFO=<ID=END,Number=1,Type=Integer,Description=""End coordinate of the variant"">; ##contig=<ID=chr1,length=248956422,assembly=GRCh38.d1.vd1>; ...; ##contig=<ID=HPV-mSD2,length=7300,assembly=GRCh38.d1.vd1>; ##source=PostprocessGermlineCNVCalls; #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	E07002_normal; chr1	10000	CNV_chr1_10000_10999	N	<DEL>,<DUP>	.	.	END=10999	GT:CN:CNLP:CNQ	1:0:0,80,90,100,108,116:80; chr1	11000	CNV_chr1_11000_11999	N	<DEL>,<DUP>	.	.	END=11999	GT:CN:CNLP:CNQ	1:0:0,81,86,89,92,95:81; chr1	12000	CNV_chr1_12000_12999	N	<DEL>,<DUP>	.	.	END=12999	GT:CN:CNLP:CNQ	1:0:0,93,107,119,129,137:93; chr1	13000	CNV_chr1_13000_13999	N	<DEL>,<DUP>	.	.	END=13999	GT:CN:CNLP:CNQ	1:0:0,89,95,99,102,104:89; chr1	14000	CNV_chr1_14000_14999	N	<DEL>,<DUP>	.	.	END=14999	GT:CN:CNLP:CNQ	1:0:0,86,91,93,96,97:86; chr1	15000	CNV_chr1_15000_15999	N	<DEL>,<DUP>	.	.	END=15999	GT:CN:CNLP:CNQ	1:0:0,82,88,92,97,101:",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8619:2714,down,down,2714,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8619,1,['down'],['down']
Availability,"Naive subsampling of the data in the ModelSegments MCMC (i.e., limiting per-segment and global quantities to 1000 points randomly sampled each MCMC iteration and rescaling likelihoods accordingly) was implemented in #3913 to bring WGS runtime down to reasonable levels. However, this sort of naive subsampling does not accurately preserve the posterior, which leads to some artifacts in posterior estimation. @MartonKN suspected that this negatively affected downstream performance in his caller, since weights of larger segments were underestimated. . For example, the copy-ratio posterior widths should scale with the inverse square root of the number of copy-ratio bins in each segment. However, subsampling yields an artificial break at 1000 bins and screws up the scaling:. ![cr-ss](https://user-images.githubusercontent.com/11076296/51122629-417be180-17e8-11e9-9a8f-e17a5d0563f5.png). To fix this, I implemented minibatch slice sampling as described in http://proceedings.mlr.press/v33/dubois14.pdf. This uses early stopping of sampling as determined by a simple statistical test to perform approximate sampling of the posterior in a way that is more well behaved:. ![cr-mb](https://user-images.githubusercontent.com/11076296/51122680-61aba080-17e8-11e9-992a-f756a267d0ce.png). Note that the scaling levels off for larger segments, but the approximation can be made exact by taking the appropriate parameter to zero (here, this parameter is set to 0.1). However, since subsampling parameters were not exposed in the old code, I have not exposed the parameters for the approximation here. We can do this in a future PR if desired. Changing these parameters can affect runtime and results, but I've set them to reasonable values for now. The implementation involved 1) creating an abstract class to extract some common functionality shared with the old batch SliceSampler (which is now no longer used in production code), 2) implementing the MinibatchSliceSampler as described in the above referen",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5575:243,down,down,243,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5575,2,['down'],"['down', 'downstream']"
Availability,Native libraries should be downloadable as dependencies via gradle,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1654:27,down,downloadable,27,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1654,1,['down'],['downloadable']
Availability,Need better CreatePanelOfNormals error catching and messages.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2901:33,error,error,33,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2901,1,['error'],['error']
Availability,"Needs better error message: Using --all-sites in GATK4.1.1.0 GenotypeGVCFs throws the IllegalStateException ""There are no sources based on those query parameters""",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5865:13,error,error,13,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5865,1,['error'],['error']
Availability,"New functionality to limit the amount of memory needed to read in all the data, intended for use with large WGS callsets. (VQSR downsamples training data if there are more than 2.5M variants anyway.). Also contains port of broadinstitute/gsa-unstable#1608 and broadinstitute/gsa-unstable#1575. Addresses #3230",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3255:128,down,downsamples,128,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3255,1,['down'],['downsamples']
Availability,"New implementation of `SlidingWindowWalker` with some ideas from the discussion in #1528. The thinks that are requested in #1198 still holds, but now it is more general: padding option is added and construction of windows are done by interval. The code contain a lot of TODO because it relies on changes implemented in #1567, and because it is suppose to be a walker over `ReadWindow` instead of `SimpleInterval`+`ReadsContext` if reads are available. I think that with these changes it could be general to be extended by `ReadWindowWalker` and by users that needs a different way of ""slide"" over intervals.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1708:441,avail,available,441,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1708,1,['avail'],['available']
Availability,New qual parameter errors GenotypeGVCFs in v4.0.5.0.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4975:19,error,errors,19,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4975,1,['error'],['errors']
Availability,"New tool aiming to call all types of precise variants detectable by long read alignments (not fully functioning yet in the sense that not all types of variants are detected yet&mdash;to be handled by later PRs in this series).; This new tool splits the input long reads by scanning their alignment characteristics (number of alignments, if strand switch is involved, if mapped to the same chromosome, if have equally good alignment configurations based on the scoring tool, etc), and send them down different code path/logic units for variant type inference and VCF output.; This PR would only deal with simple INSDEL, for long reads having exactly 2 alignments (no other equally good alignment configuration) mapped to the same chromosome without strand switch or order switch (translocation or large tandem duplications), because we already have this type of variant covered in master. __UPDATE__; See updated roadmap in #2703. NEEDS TO WAIT UNTIL PART 1 IS IN.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3456:494,down,down,494,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3456,1,['down'],['down']
Availability,"NioByteUnsafe.read(AbstractNioByteChannel.java:131); at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:511); at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:468); at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:382); at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:354); at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:111); at java.lang.Thread.run(Thread.java:744); ```. And then warnings about lost tasks:. ```; 16/02/16 11:45:59 WARN TaskSetManager: Lost task 42.1 in stage 0.0 (TID 364, dataflow03.broadinstitute.org): java.io.IOException: Connection from /69.173.65.227:56014 closed; ```. Then errors like this:. ```; 16/02/16 11:47:37 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@69.173.65.227:47043] -> [akka.tcp://sparkExecutor@dataflow05.broadinstitute.org:36695]: Error [Association failed with [akka.tcp://sparkExecutor@dataflow05.broadinstitute.org:36695]] [; ```. akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkExecutor@dataflow05.broadinstitute.org:36695]; Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: dataflow05.broadinstitute.org/69.173.65.230:36695; ]; akka.event.Logging$Error$NoCause$. ```; 16/02/16 11:47:39 ERROR YarnScheduler: Lost executor 37 on dataflow02.broadinstitute.org: remote Rpc client disassociated; ```. This seems to be causing tasks to be re-queued and executed, which hurts performance. The command line I'm using is:. ```; gatk-launch FindBadGenomicKmersSpark --reference hdfs:///user/cwhelan/reference/Homo_sapiens_assembly19.2bit --output bad_kmers_v5_cluster.txt -- --sparkRunner SPARK --sparkMaster yarn-client --executor-memory 8g --driver-memory 8g --conf spark.broadcast.blockSize=1g; ```. Running against commit f2b3bae of branch https://github.com/broadinstitute/gatk/tree/cw_clusterize_sv_spark_tools",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1491:6062,Error,Error,6062,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1491,2,"['ERROR', 'Error']","['ERROR', 'Error']"
Availability,No space left on device M2 WDL Travis failure.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3572:38,failure,failure,38,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3572,1,['failure'],['failure']
Availability,Non-informative error message when the reference dictionary (.dict) file is missing,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3492:16,error,error,16,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3492,1,['error'],['error']
Availability,Not sure if there is a better way to do this. UserException seems wrong since its displays USER Error.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3057:96,Error,Error,96,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3057,1,['Error'],['Error']
Availability,"Not sure if this is the right change. We are seeing `Unrecognized name: CALL_PS at [4:136]` error in AoU genomic workflow. So make this optional, when column is missing, return null",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/9025:92,error,error,92,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/9025,1,['error'],['error']
Availability,"Notes:. - Classes in hellbender/tools/picard/analysis/artifacts are removed and replaced with Picard versions (except Transition, which is not public in Picard).; - GATK version of GatherVcfs is retained, and the Picard version is masked out - is this what we want ?; - The non-Spark GATK metrics tools have been removed and replaced with the Picard versions. The test data is retained (but moved) since its used by the Spark metrics tool tests. Additional changes we'll want to make separately to minimize the complexity of this PR:; - Eliminate the download of picard.jar from the GATK WDL tests and update the WDL to run Picard tools through GATK.; - Unify and merge the Picard and GATK program groups. These are similar, but not identical, and the combined result has artificial/duplicate groups.; - Normalize the confusing mix of Alpha/Beta/Experimental tags and comments.; - Add unified doc and tab-completion tasks that include Picard.; - Remove and replace SamComparison and Transition classes with the Picard versions.; - Fix GATK CompareBaseQualities (its a PicardCommandLineProgram).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3620:231,mask,masked,231,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3620,2,"['down', 'mask']","['download', 'masked']"
Availability,"Noticed some compile warnings in the Travis logs, looks like a funky apostrophe is to blame?. :compileJava/gatk/src/main/java/org/broadinstitute/hellbender/tools/walkers/ReferenceConfidenceVariantContextMerger.java:511: error: unmappable character for encoding ASCII; // if there???s more than 1 DEL allele then we need to use the best one; ^",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3748:220,error,error,220,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3748,1,['error'],['error']
Availability,Now can create annotations for symbollic alleles and masked alleles.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5406:53,mask,masked,53,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5406,1,['mask'],['masked']
Availability,"Now that UserException has been ported, we should eventually make an effort to wrap exceptions in htsjdk that are the result of user error in UserExceptions.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/86:133,error,error,133,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/86,1,['error'],['error']
Availability,"Now that we've added the complete B37 and HG38 references to our test data (https://github.com/broadinstitute/gatk/pull/5309), we should remove redundant snippets of these references to save space, and replace usages of the snippets with usages of the full-sized references.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5313:144,redundant,redundant,144,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5313,1,['redundant'],['redundant']
Availability,Now throws a user error for an AD field with only 1 value in MAF mode.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5860:18,error,error,18,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5860,1,['error'],['error']
Availability,NullPointerException error while running Mutect2,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6142:21,error,error,21,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6142,1,['error'],['error']
Availability,NullPointerException error while running VariantEval,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6212:21,error,error,21,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6212,1,['error'],['error']
Availability,"O FilterMutectCalls - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 11:30:15.674 INFO FilterMutectCalls - Deflater: IntelDeflater; 11:30:15.674 INFO FilterMutectCalls - Inflater: IntelInflater; 11:30:15.674 INFO FilterMutectCalls - GCS max retries/reopens: 20; 11:30:15.675 INFO FilterMutectCalls - Requester pays: disabled; 11:30:15.675 INFO FilterMutectCalls - Initializing engine; 11:30:15.870 INFO FeatureManager - Using codec VCFCodec to read file file:///tmp/tmp.8lRGFREUhm/mu.2.vcf; 11:30:15.883 INFO FilterMutectCalls - Done initializing engine; 11:30:15.929 INFO ProgressMeter - Starting traversal; 11:30:15.929 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 11:30:15.930 INFO FilterMutectCalls - Starting pass 0 through the variants; 11:30:15.958 INFO FilterMutectCalls - Finished pass 0 through the variants; 11:30:15.970 INFO FilterMutectCalls - Starting pass 1 through the variants; 11:30:15.974 INFO FilterMutectCalls - Shutting down engine; [November 7, 2019 11:30:15 AM CET] org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls done. Elapsed time: 0.01 minutes.; Runtime.totalMemory()=2252865536; java.lang.IllegalArgumentException: log10 p: Values must be non-infinite and non-NAN; 	at org.broadinstitute.hellbender.utils.NaturalLogUtils.logSumExp(NaturalLogUtils.java:84); 	at org.broadinstitute.hellbender.utils.NaturalLogUtils.normalizeLog(NaturalLogUtils.java:51); 	at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.clusterProbabilities(SomaticClusteringModel.java:203); 	at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.probabilityOfSequencingError(SomaticClusteringModel.java:96); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.TumorEvidenceFilter.calculateErrorProbability(TumorEvidenceFilter.java:27); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2VariantFilter.errorProbability",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6255:9463,down,down,9463,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6255,1,['down'],['down']
