quality_attribute,sentence,source,author,repo,version,id,keyword,matched_word,match_idx,wiki,url,total_similar,target_keywords,target_matched_words
Availability,"Make the same resiliency changes I made to site recent to the other stateless services. Schedule them on 3 nodes, tolerate pre-emptibles, and autoscale 3-10 replicas. Preemptibles might be too aggressive, we should watch uptime. We probably want at least once instance running on non-preemptibles. We can do that explicitly by duplicating the pod spec, but I don't see a way to do it with tolerations and/or (anti-)affinities. We can also do this with notebook2 since it is stateless, but I'll leave that for another PR. I changed the Makefile structure, basically, don't support local docker build anymore and always pull from the repo and use --cache-from. I will modify the rest of the projects analogously in a separate PR. Switch infrastructure modules (gateway, router-resolver) to new jinja2 templating, instead of old @foo@ sed-based templating.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6201:14,resilien,resiliency,14,https://hail.is,https://github.com/hail-is/hail/pull/6201,3,"['resilien', 'toler']","['resiliency', 'tolerate', 'tolerations']"
Availability,Make the version length coming from error messages consistent,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3593:36,error,error,36,https://hail.is,https://github.com/hail-is/hail/pull/3593,1,['error'],['error']
Availability,"MakeNDArray should return a missing NDArray if shape or data are missing, but should raise an error if any elements of the shape or data are missing.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6957:94,error,error,94,https://hail.is,https://github.com/hail-is/hail/issues/6957,1,['error'],['error']
Availability,Makes it possible to proceed past the duplicate-multiallelic-loci error.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7071:66,error,error,66,https://hail.is,https://github.com/hail-is/hail/pull/7071,1,['error'],['error']
Availability,"Makes some further progress on simplifying the `PruneDeadFields` pass, with the primary goal of decoupling it from the details of the binding structure. The primary change is to `memoizeValueIR`. Before, it passed in only the requested type of the node, and returned and environment containing all free variables and their requested types. Any bound variables would then need to be removed, and the environments of all children then merged. This low-level manipulation of environments made it closely tied to the binding structure, essentially redundantly encoding everything in `Binds.scala`. Now we pass an environment down into the children, which maps variables to a mutable state tracking the requested type. Each `Ref` node unions the requested type at the reference with the state in the environment. This lets us use the general environment infrastructure. I didn't do an assertion directly comparing the old and new implementations, as I've done with some other pass rewrites. But `PruneDeadFields` has pretty good test coverage.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14509:544,redundant,redundantly,544,https://hail.is,https://github.com/hail-is/hail/pull/14509,2,"['down', 'redundant']","['down', 'redundantly']"
Availability,"Many of our tests look like:. ```scala; // ExprSuite.scala; assert(eval[Int](""a[0]"").contains(1)); assert(eval[Int](""a[1]"").contains(2)); assert(eval[Int](""a[2]"").isEmpty); assert(eval[Int](""a[3]"").contains(6)); assert(eval[Int](""a[-1]"").contains(8)); assert(eval[Int](""a[-2]"").contains(-1)); ```. Test failures from these expressions simply state that the result was not as expected. If these tests were instead written as below,. ```scala; assert(eval[Int](""a[0]"") == Some(1)); assert(eval[Int](""a[1]"") == Some(2)); assert(eval[Int](""a[2]"") == None); assert(eval[Int](""a[3]"") == Some(6)); assert(eval[Int](""a[-1]"") == Some(8)); assert(eval[Int](""a[-2]"") == Some(-1)); ```; then test failures would print both the expected value and the actual value:; ```; org.scalatest.exceptions.TestFailedException: Some(7) did not equal Some(1); ```. Furthermore, there are a tools in the [scalatest library](http://www.scalatest.org/at_a_glance/FlatSpec) which enable richer specifications. Suppose that Hail included a `randInt : (Int, Int) => Int` function, we might like to verify that this is true:. ```scala; eval[Int](""randInt(0, 10) * 2 + 1"") should (be > 0 and be (even)); ```. When this expression fails, the messages look like:. ```; org.scalatest.exceptions.TestFailedException: 7 was greater than 0, but 7 was odd; ```. These natural language matchers are a bit finicky. I'm not sure if I like them, but I do like having nice error messages.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1286:303,failure,failures,303,https://hail.is,https://github.com/hail-is/hail/issues/1286,3,"['error', 'failure']","['error', 'failures']"
Availability,Map values serialization error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1179:25,error,error,25,https://hail.is,https://github.com/hail-is/hail/issues/1179,1,['error'],['error']
Availability,MapPartitionsRDD.compute(MapPartitionsRDD.scala:52) at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346) at org.apache.spark.rdd.RDD.iterator(RDD.scala:310) at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52) at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346) at org.apache.spark.rdd.RDD.iterator(RDD.scala:310) at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90) at org.apache.spark.scheduler.Task.run(Task.scala:123) at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408) at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360) at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748). 	Java stack trace:; 	java.lang.RuntimeException: error while applying lowering 'InterpretNonCompilable'; 			at is.hail.expr.ir.lowering.LoweringPipeline$$anonfun$apply$1.apply(LoweringPipeline.scala:26); 			at is.hail.expr.ir.lowering.LoweringPipeline$$anonfun$apply$1.apply(LoweringPipeline.scala:18); 			at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); 			at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35); 			at is.hail.expr.ir.lowering.LoweringPipeline.apply(LoweringPipeline.scala:18); 			at is.hail.expr.ir.CompileAndEvaluate$._apply(CompileAndEvaluate.scala:28); 			at is.hail.backend.spark.SparkBackend.is$hail$backend$spark$SparkBackend$$_execute(SparkBackend.scala:317); 			at is.hail.backend.spark.SparkBackend$$anonfun$execute$1.apply(SparkBackend.scala:304); 			at is.hail.backend.spark.SparkBackend$$anonfun$execute$1.apply(SparkBackend.scala:303); 			at is.hail.expr.ir.ExecuteContext$$anonfun$scoped$1.apply(ExecuteContext.scala:20); 			at is.hail.expr.ir.ExecuteContext$$anonfun$scoped$1.apply(Exec,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8944:6179,error,error,6179,https://hail.is,https://github.com/hail-is/hail/issues/8944,1,['error'],['error']
Availability,"Masahiro got this error message: . ```; File ""/tmp/59d4e99c253d424a9211eec0bdb4cd37/write_hardcall_mt.py"", line 20, in <module>; hl.export_bgen(mt, f'gs://ukbb-hail/ukb31063.dosage.hard_call.gwas_samples.chr{chrom}', gp=mt.GP, varid=mt.rsid); File ""</opt/conda/default/lib/python3.6/site-packages/decorator.py:decorator-gen-1226>"", line 2, in export_bgen; File ""/opt/conda/default/lib/python3.6/site-packages/hail/typecheck/check.py"", line 585, in wrapper; return __original_func(*args_, **kwargs_); File ""/opt/conda/default/lib/python3.6/site-packages/hail/methods/impex.py"", line 235, in export_bgen; Env.hail().utils.ExportType.getExportType(parallel)))); File ""/opt/conda/default/lib/python3.6/site-packages/hail/backend/backend.py"", line 109, in execute; result = json.loads(Env.hc()._jhc.backend().executeJSON(self._to_java_ir(ir))); File ""/usr/lib/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py"", line 1257, in __call__; File ""/opt/conda/default/lib/python3.6/site-packages/hail/utils/java.py"", line 225, in deco; 'Error summary: %s' % (deepest, full, hail.__version__, deepest)) from None; hail.utils.java.FatalError: AssertionError: assertion failed. Java stack trace:; java.lang.RuntimeException: error while applying lowering 'InterpretNonCompilable'; at is.hail.expr.ir.lowering.LoweringPipeline$$anonfun$apply$1.apply(LoweringPipeline.scala:26); at is.hail.expr.ir.lowering.LoweringPipeline$$anonfun$apply$1.apply(LoweringPipeline.scala:18); at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35); at is.hail.expr.ir.lowering.LoweringPipeline.apply(LoweringPipeline.scala:18); at is.hail.expr.ir.CompileAndEvaluate$$anonfun$apply$1.apply(CompileAndEvaluate.scala:16); at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:69); at is.hail.expr.ir.CompileAndEvaluate$.apply(CompileAndEvaluate.scala:14); at is.hail.backend.Backend$$anonfun$execute$1.apply(Backend.scala:56)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8161:18,error,error,18,https://hail.is,https://github.com/hail-is/hail/issues/8161,1,['error'],['error']
Availability,MatrixEntriesTable didn't define `uid_field_name` in `_handle_randomness`. Downstream operations failed to fetch the field and inserted a NA into `RNGSplit`. Assert that TableIRs define `uid_field_name` when provided to `handle_randomness`. Fixes: #14303,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14371:75,Down,Downstream,75,https://hail.is,https://github.com/hail-is/hail/pull/14371,1,['Down'],['Downstream']
Availability,MatrixReader errors are wrapped in Serialization MappingExceptions,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5030:13,error,errors,13,https://hail.is,https://github.com/hail-is/hail/issues/5030,1,['error'],['errors']
Availability,MatrixTable.show errors if it tries to show more columns than in the MT,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5832:17,error,errors,17,https://hail.is,https://github.com/hail-is/hail/issues/5832,1,['error'],['errors']
Availability,"May not be implemented in aiohttp. Flag prevents cookie from being carried with cross-origin request. Lax allows cookie to be carried with GET requests. Only available in relatively recent browsers. With CSRF protection in place not strictly necessary, but an added layer of protection, for low cost",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7132:158,avail,available,158,https://hail.is,https://github.com/hail-is/hail/issues/7132,1,['avail'],['available']
Availability,Mendel error code fix,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3303:7,error,error,7,https://hail.is,https://github.com/hail-is/hail/pull/3303,1,['error'],['error']
Availability,Mendel error computation need to be adapted to multi-allelic sites,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/45:7,error,error,7,https://hail.is,https://github.com/hail-is/hail/issues/45,1,['error'],['error']
Availability,Mendel errors shouldn't report variants on the MT chromosome,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2005:7,error,errors,7,https://hail.is,https://github.com/hail-is/hail/issues/2005,1,['error'],['errors']
Availability,Mention 'unify' in the union error message,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5888:29,error,error,29,https://hail.is,https://github.com/hail-is/hail/pull/5888,1,['error'],['error']
Availability,"Merge of https://github.com/hail-is/hail/pull/12868 and https://github.com/hail-is/hail/pull/12867 because I expect each is likely to fail due to the other's error. ---. [qob] retry `storage.writer` and `storage.reader`; ; I do not think we frequently get errors in `storage.reader`, but I think `storage.writer` was; always flaky and we were protected by the `retryTransientErrors` on `createNoCompression`. My; change to fix requester pays delayed the error until either the first `write` or the `close`; which do not have a `retryTransientErrors` (and it is not obvious to me that it is safe to retry; a `flush`). ---. [qob] retry transient errors reading the results file. ---",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12869:158,error,error,158,https://hail.is,https://github.com/hail-is/hail/pull/12869,4,['error'],"['error', 'errors']"
Availability,"Minrep (in split multi) throwing:; ```; hail.utils.java.FatalError: HailException: invalid allele ""GN"". Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 9 in stage 10.0 failed 20 times, most recent failure: Lost task 9.19 in stage 10.0 (TID 1997, exomes-w-1.c.broad-mpg-gnomad.internal, executor 15): is.hail.utils.HailException: invalid allele ""GN""; 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:6); 	at is.hail.utils.package$.fatal(package.scala:26); 	at is.hail.variant.AltAlleleMethods$.validate(AltAlleleMethods.scala:24); 	at is.hail.variant.AltAlleleMethods$.altAlleleType(AltAlleleMethods.scala:28); 	at is.hail.variant.AltAlleleMethods$.isStar(AltAlleleMethods.scala:73); 	at is.hail.variant.VariantMethods$$anonfun$minRep$1.apply(VariantMethods.scala:43); 	at is.hail.variant.VariantMethods$$anonfun$minRep$1.apply(VariantMethods.scala:43); 	at scala.collection.IndexedSeqOptimized$class.prefixLengthImpl(IndexedSeqOptimized.scala:38); 	at scala.collection.IndexedSeqOptimized$class.forall(IndexedSeqOptimized.scala:43); 	at scala.collection.mutable.WrappedArray.forall(WrappedArray.scala:35); 	at is.hail.variant.VariantMethods$.minRep(VariantMethods.scala:43); 	at is.hail.methods.SplitMultiPartitionContext$$anonfun$2.apply(SplitMulti.scala:196); 	at is.hail.methods.SplitMultiPartitionContext$$anonfun$2.apply(SplitMulti.scala:192); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at scala.collection.Iterator$class.foreach(Iterator.scala:893); 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); 	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59); 	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104); 	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48); 	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310); 	at scala.collection.AbstractIterator.to(Iterator.scala:1336); 	at scala.collection.Tra",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3480:181,failure,failure,181,https://hail.is,https://github.com/hail-is/hail/issues/3480,4,"['Error', 'failure']","['ErrorHandling', 'failure']"
Availability,Missing key error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4799:12,error,error,12,https://hail.is,https://github.com/hail-is/hail/issues/4799,1,['error'],['error']
Availability,Modify compiler arguments to emit warnings required for scalafix.; Fix failures that arise from the new build configuration.; Run scalafix.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14103:71,failure,failures,71,https://hail.is,https://github.com/hail-is/hail/pull/14103,1,['failure'],['failures']
Availability,More info here: https://discuss.hail.is/t/export-elasticsearch-error/1755/4,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9686:63,error,error,63,https://hail.is,https://github.com/hail-is/hail/pull/9686,1,['error'],['error']
Availability,More specific error message when trying to read non-existent vds,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/327:14,error,error,14,https://hail.is,https://github.com/hail-is/hail/issues/327,1,['error'],['error']
Availability,More tolerance,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6776:5,toler,tolerance,5,https://hail.is,https://github.com/hail-is/hail/pull/6776,1,['toler'],['tolerance']
Availability,"Most of the functionality was already available in EmitFunctionBuilder, but Compile() didn't make it available. This PR creates a `PrintWriter` during assertEvalsTo if you set the `jvm_bytecode_dump` flag to a file path you want the bytecode to be written to. Example:; ```scala; HailContext.setFlag(""jvm_bytecode_dump"", ""arr_filter_bytecode.java""); assertEvalsTo(ArrayFilter(a, ""x"",; ApplyComparisonOp(LT(TInt32()), Ref(""x"", TInt32()), I32(6))), FastIndexedSeq(3)); HailContext.setFlag(""jvm_bytecode_dump"", null); ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7199:38,avail,available,38,https://hail.is,https://github.com/hail-is/hail/pull/7199,2,['avail'],['available']
Availability,"Mostly small, straightforward stuff. /auth must only return 2xx, 401 or 403, or nginx returns 500. Redirect auth failures connecting to instance to /error, too. Changed ""Create/Open Notebook"" to ""Launch/Open Jupyter"" and associated language throughout. I'll run through the whole test playbook again after these go in. Note to self, some improvements to consider:; - Validate image, memory, cpu values in workshop-admin. Right now, if you enter invalid values, you get a 500 on launch Jupyter with invalid pod spec.; - Could change notebook.hail.is/notebook URL to notebook.hail.is/jupyter now.; - A background loop to kill any notebook workers associated to inactive workshops. Then if you just inactivate the workshop at the end, everything gets cleaned up.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7162:113,failure,failures,113,https://hail.is,https://github.com/hail-is/hail/pull/7162,2,"['error', 'failure']","['error', 'failures']"
Availability,Move Mendel errors to Python,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3240:12,error,errors,12,https://hail.is,https://github.com/hail-is/hail/pull/3240,1,['error'],['errors']
Availability,"Move installed location of hail-all-spark.jar to from hail/ to; hail/backend/. We were not finding the jar properly with pkg_resources, and so were not; setting the paths appropriately for pip installs, causing 'JavaPackage; not callable' errors.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8405:239,error,errors,239,https://hail.is,https://github.com/hail-is/hail/pull/8405,1,['error'],['errors']
Availability,"Moves multi-pod deployments over to using Headless Services, which enables client-side load-balancing to the underlying pods. See #12095 for more context. The reason I put this in its own PR is that Kubernetes won't let me apply the `clusterIP: None` changes to existing `Services`, and I must delete the `Service` resources first. I can manually delete and apply new headless services in a way that is compatible with what is currently on main and with just a few seconds of downtime, but I should do this manually just before this PR merges.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12094:476,downtime,downtime,476,https://hail.is,https://github.com/hail-is/hail/pull/12094,1,['downtime'],['downtime']
Availability,Movie lens hosting is down. We can re-enable when it is back up.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5632:22,down,down,22,https://hail.is,https://github.com/hail-is/hail/pull/5632,1,['down'],['down']
Availability,Much OOM. Related to #2108?. ```; Java stack trace:; java.lang.OutOfMemoryError: Java heap space; 	at java.util.HashMap.resize(HashMap.java:703); 	at java.util.HashMap.putVal(HashMap.java:662); 	at java.util.HashMap.put(HashMap.java:611); 	at htsjdk.variant.vcf.VCFHeader.buildVCFReaderMaps(VCFHeader.java:164); 	at htsjdk.variant.vcf.VCFHeader.<init>(VCFHeader.java:146); 	at htsjdk.variant.vcf.VCFStandardHeaderLines.repairStandardHeaderLines(VCFStandardHeaderLines.java:75); 	at htsjdk.variant.vcf.AbstractVCFCodec.parseHeaderFromLines(AbstractVCFCodec.java:223); 	at htsjdk.variant.vcf.VCFCodec.readActualHeader(VCFCodec.java:111); 	at htsjdk.tribble.AsciiFeatureCodec.readHeader(AsciiFeatureCodec.java:83); 	at is.hail.io.vcf.LoadVCF$.parseHeader(LoadVCF.scala:162); 	at is.hail.io.vcf.LoadVCF$$anonfun$4.apply(LoadVCF.scala:205); 	at is.hail.io.vcf.LoadVCF$$anonfun$4.apply(LoadVCF.scala:205); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); 	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186); 	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); 	at scala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:186); 	at is.hail.io.vcf.LoadVCF$.apply(LoadVCF.scala:205); 	at is.hail.HailContext.importVCFsGeneric(HailContext.scala:528); 	at is.hail.HailContext.importVCFs(HailContext.scala:484); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2136:419,repair,repairStandardHeaderLines,419,https://hail.is,https://github.com/hail-is/hail/issues/2136,1,['repair'],['repairStandardHeaderLines']
Availability,"My change https://github.com/hail-is/hail/pull/8581 introduced a bug, count of native reads with pushed down intervals could give the wrong answer.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8631:104,down,down,104,https://hail.is,https://github.com/hail-is/hail/pull/8631,1,['down'],['down']
Availability,"My first approach was to populate an error.html template and return that. I could get the title to be ""Error"", but none of the content was showing up. I couldn't figure out why, so I switched to raising HTTPErrorFound with the traceback message. This works fine, but it won't work if we need the decorator above the authentication decorators. This decorator has to be the furthest down the call stack.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10503:37,error,error,37,https://hail.is,https://github.com/hail-is/hail/pull/10503,3,"['Error', 'down', 'error']","['Error', 'down', 'error']"
Availability,NDArrayRef Better Error Message,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9444:18,Error,Error,18,https://hail.is,https://github.com/hail-is/hail/pull/9444,1,['Error'],['Error']
Availability,"NFO: Finished task 0.0 in stage 5.0 (TID 5). 1119 bytes result sent to driver; ```; </details>. <details>; <summary>Broken hail.log</summary>. ```; 2018-10-09 14:46:38 Hail: INFO: SparkUI: http://10.32.119.167:4040; 2018-10-09 14:46:38 Hail: INFO: Running Hail version devel-e7552fd55a9d; 2018-10-09 14:46:38 SharedState: INFO: loading hive config file: file:/Users/michafla/spark/spark-2.2.0-bin-hadoop2.7/conf/hive-site.xml; 2018-10-09 14:46:38 SharedState: INFO: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/michafla/projects/R/pkg/hailr/inst/unitTests/spark-warehouse/').; 2018-10-09 14:46:38 SharedState: INFO: Warehouse path is 'file:/Users/michafla/projects/R/pkg/hailr/inst/unitTests/spark-warehouse/'.; 2018-10-09 14:46:38 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@28f0ac7{/SQL,null,AVAILABLE,@Spark}; 2018-10-09 14:46:38 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@49a30f89{/SQL/json,null,AVAILABLE,@Spark}; 2018-10-09 14:46:38 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@4495af6e{/SQL/execution,null,AVAILABLE,@Spark}; 2018-10-09 14:46:38 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@6baf9f3b{/SQL/execution/json,null,AVAILABLE,@Spark}; 2018-10-09 14:46:38 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@562ad221{/static/sql,null,AVAILABLE,@Spark}; 2018-10-09 14:46:39 StateStoreCoordinatorRef: INFO: Registered StateStoreCoordinator endpoint; 2018-10-09 14:46:39 SparkSession$Builder: WARN: Using an existing SparkSession; some configuration may not take effect.; 2018-10-09 14:46:39 SparkSqlParser: INFO: Parsing command: SHOW TABLES; 2018-10-09 14:46:40 SparkContext: INFO: Starting job: collect at utils.scala:44; 2018-10-09 14:46:40 DAGScheduler: INFO: Got job 0 (collect at utils.scala:44) with 1 output partitions; 2018-10-09 14:46:40 DAGScheduler: INFO: Final stage: ResultStage 0 (collect at utils.scala:44); 2018-10-09 14:46:40 DAGScheduler: INFO:",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4513:31772,AVAIL,AVAILABLE,31772,https://hail.is,https://github.com/hail-is/hail/issues/4513,1,['AVAIL'],['AVAILABLE']
Availability,"NOTEBOOK-2441824](https://snyk.io/vuln/SNYK-PYTHON-NOTEBOOK-2441824) | `notebook:` <br> `5.7.16 -> 6.4.12` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **449/1000** <br/> **Why?** Has a fix available, CVSS 4.7 | Access Restriction Bypass <br/>[SNYK-PYTHON-NOTEBOOK-2928995](https://snyk.io/vuln/SNYK-PYTHON-NOTEBOOK-2928995) | `notebook:` <br> `5.7.16 -> 6.4.12` <br> | No | No Known Exploit ; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **399/1000** <br/> **Why?** Has a fix available, CVSS 3.7 | Race Condition <br/>[SNYK-PYTHON-PROMPTTOOLKIT-6141120](https://snyk.io/vuln/SNYK-PYTHON-PROMPTTOOLKIT-6141120) | `prompt-toolkit:` <br> `1.0.18 -> 3.0.13` <br> | No | No Known Exploit ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | **696/1000** <br/> **Why?** Proof of Concept exploit, Has a fix available, CVSS 7.5 | Regular Expression Denial of Service (ReDoS) <br/>[SNYK-PYTHON-PYGMENTS-1086606](https://snyk.io/vuln/SNYK-PYTHON-PYGMENTS-1086606) | `pygments:` <br> `2.5.2 -> 2.15.0` <br> | No | Proof of Concept ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | **589/1000** <br/> **Why?** Has a fix available, CVSS 7.5 | Denial of Service (DoS) <br/>[SNYK-PYTHON-PYGMENTS-1088505](https://snyk.io/vuln/SNYK-PYTHON-PYGMENTS-1088505) | `pygments:` <br> `2.5.2 -> 2.15.0` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **479/1000** <br/> **Why?** Has a fix available, CVSS 5.3 | Regular Expression Denial of Service (ReDoS) <br/>[SNYK-PYTHON-PYGMENTS-5750273](https://snyk.io/vuln/SNYK-PYTHON-PYGMENTS-5750273) | `pygments:` <br> `2.5.2 -> 2.15.0` <br> | No | No Known Exploit ; ![medium seve",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14205:5816,avail,available,5816,https://hail.is,https://github.com/hail-is/hail/pull/14205,1,['avail'],['available']
Availability,"NYK-PYTHON-CRYPTOGRAPHY-6092044) | `cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **616/1000** <br/> **Why?** Proof of Concept exploit, Has a fix available, CVSS 5.9 | Information Exposure <br/>[SNYK-PYTHON-CRYPTOGRAPHY-6126975](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-6126975) | `cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **489/1000** <br/> **Why?** Has a fix available, CVSS 5.5 | NULL Pointer Dereference <br/>[SNYK-PYTHON-CRYPTOGRAPHY-6210214](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-6210214) | `cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **519/1000** <br/> **Why?** Has a fix available, CVSS 6.1 | Information Exposure <br/>[SNYK-PYTHON-REQUESTS-5595532](https://snyk.io/vuln/SNYK-PYTHON-REQUESTS-5595532) | `requests:` <br> `2.27.1 -> 2.31.0` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiIxM2UyYzQ2MC1mZTA2LTQwOTktYWRhYi1lMWY4ZmE5MzFkZTAiLCJldmVudCI6IlBSIH",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14329:9783,avail,available,9783,https://hail.is,https://github.com/hail-is/hail/pull/14329,1,['avail'],['available']
Availability,"Naturally, every possible Spark version uses a different elasticsearch library. . This also uses curl instead of gsutil to download the jar, so we don't require people to have gsutil to make.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10255:123,down,download,123,https://hail.is,https://github.com/hail-is/hail/pull/10255,1,['down'],['download']
Availability,Needed to guard against errors in the k8s pod stream.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6511:24,error,errors,24,https://hail.is,https://github.com/hail-is/hail/pull/6511,1,['error'],['errors']
Availability,Nested array element aggregations weren't working. This fixes it and adds a test for nested ArrayAggs. Caught by test failures from #6698.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6743:118,failure,failures,118,https://hail.is,https://github.com/hail-is/hail/pull/6743,1,['failure'],['failures']
Availability,New entry filtering semantics was removing children with no errors; leading to incorrect counts. fixes #5786,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5855:60,error,errors,60,https://hail.is,https://github.com/hail-is/hail/pull/5855,1,['error'],['errors']
Availability,Nicer error for case/switch statements,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3830:6,error,error,6,https://hail.is,https://github.com/hail-is/hail/pull/3830,1,['error'],['error']
Availability,No error checking on LoadVCF if user-provided header file,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2437:3,error,error,3,https://hail.is,https://github.com/hail-is/hail/pull/2437,1,['error'],['error']
Availability,"No one has complained about this yet, but I suspect there's a lurking issue in `linreg`. On line 75 of LinearRegression.scala, we create a writable region value using a context managed region. This region will be kept alive (in the garbage collection sense) by the context until the end of the Task (which I believe is the end of processing one partition). As such, `linreg` will generate a bunch of garbage. We close the child as soon as we know it is no longer used, thus saving memory use, at the cost of copying the results. In a future where we can reference-count regions then we could avoid the copy and simply return the writable region value. This future is not here yet.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3590:218,alive,alive,218,https://hail.is,https://github.com/hail-is/hail/pull/3590,1,['alive'],['alive']
Availability,"Non-daemon threads [keep a JVM alive](https://docs.oracle.com/javase/8/docs/api/java/lang/Thread.html):. > When a Java Virtual Machine starts up, there is usually a single non-daemon thread (which typically calls the method named main of some designated class). The Java Virtual Machine continues to execute threads until either of the following occurs:; >; > The exit method of class Runtime has been called and the security manager has permitted the exit operation to take place.; >; > All threads that are not daemon threads have died, either by returning from the call to the run method or by throwing an exception that propagates beyond the run method. Spark appears to wait for the JVM to terminate before it considers a job complete.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13916:31,alive,alive,31,https://hail.is,https://github.com/hail-is/hail/pull/13916,1,['alive'],['alive']
Availability,Non-specific OOB error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3041:17,error,error,17,https://hail.is,https://github.com/hail-is/hail/issues/3041,1,['error'],['error']
Availability,Not a correctness bug because we raise an assertion error in the partition function.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13550:52,error,error,52,https://hail.is,https://github.com/hail-is/hail/pull/13550,1,['error'],['error']
Availability,"Not all of the Hail Tables and MatrixTables that are publicly available on the gnomAD [downloads](https://gnomad.broadinstitute.org/downloads) page are currently available in the Datasets API/Annotation DB. . This PR makes the following changes to the datasets available via the Hail Datasets API/Annotation DB:. - Add `gnomad_genome_sites` Table, versions: 3.1.1, 3.1.2; - Add `gnomad_hgdp_1kg_subset_dense` MatrixTable, version: 3.1.2; - Rename `gnomad_hgdp_1kg_callset` MatrixTable to `gnomad_hgdp_1kg_subset_dense`, version: 3.1; - Add `gnomad_hgdp_1kg_subset_sparse` MatrixTable, version: 3.1.2; - Add `gnomad_hgdp_1kg_subset_sample_metadata` Table, version: 3.1.2; - Add `gnomad_hgdp_1kg_subset_variant_annotations` Table, version: 3.1.2; - Add `gnomad_variant_co-occurrence` Table, version: 2.1.1; - Add `gnomad_pca_variant_loadings` Table, versions: 2.1, 3.1. Other general changes:. - Add/update the schema `.rst` files, for the datasets listed above, for the [docs](https://hail.is/docs/0.2/datasets/schemas.html); - Set the example dataset loaded in `hl.experimental.load_dataset` to be the most recent `gnomad_hgdp_1kg_subset_dense` MatrixTable (version 3.1.2)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11608:62,avail,available,62,https://hail.is,https://github.com/hail-is/hail/pull/11608,5,"['avail', 'down']","['available', 'downloads']"
Availability,Not great that CI hasn't been erroring because of this.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13671:30,error,erroring,30,https://hail.is,https://github.com/hail-is/hail/pull/13671,1,['error'],['erroring']
Availability,"Not helpful for debugging, we still get logs on errors",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11977:48,error,errors,48,https://hail.is,https://github.com/hail-is/hail/pull/11977,1,['error'],['errors']
Availability,Not including a test since Patrick has an open PR that obviates this kind of error completely.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11181:77,error,error,77,https://hail.is,https://github.com/hail-is/hail/pull/11181,1,['error'],['error']
Availability,Not sure if this is unidiomatic but I always write little scripts that don't close the service backend and end with errors about unclosed sessions. This auto-closes a `ServiceBackend`.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10776:116,error,errors,116,https://hail.is,https://github.com/hail-is/hail/pull/10776,1,['error'],['errors']
Availability,Not sure if this will help make GKE move the pod if the node needs to be repaired rather than waiting for the node to repair.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9653:73,repair,repaired,73,https://hail.is,https://github.com/hail-is/hail/pull/9653,2,['repair'],"['repair', 'repaired']"
Availability,"Not sure who to assign this to since it spans everything. I targeted the slowest test jobs. Currently CI's PR page timings are wrong. If you scroll down to ""Build History"" and click on a batch, that page has the right timings. (The CI PR page timings will be fixed by #6746",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6863:148,down,down,148,https://hail.is,https://github.com/hail-is/hail/pull/6863,1,['down'],['down']
Availability,"Not sure why the extra line is required here... riddles of Sphinx. https://hail.is/docs/0.2/hail.Table.html#hail.Table.checkpoint; https://hail.is/docs/0.2/hail.MatrixTable.html#hail.MatrixTable.checkpoint. Before; <img width=""1029"" alt=""Screen Shot 2020-06-08 at 9 30 12 PM"" src=""https://user-images.githubusercontent.com/1156625/84096487-0cb98d00-a9d0-11ea-8623-12288df6eace.png"">. After; <img width=""1042"" alt=""Screen Shot 2020-06-08 at 9 35 06 PM"" src=""https://user-images.githubusercontent.com/1156625/84096490-10e5aa80-a9d0-11ea-9be9-c3dfd8b049a9.png"">",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8938:119,checkpoint,checkpoint,119,https://hail.is,https://github.com/hail-is/hail/pull/8938,2,['checkpoint'],['checkpoint']
Availability,"Note that `mt.cols()[mt.col_key]` is obviously wrong but instead we get a big error message that is ultimately really quite confusing. A good error message would be ""cannot index matrix table with itself"". (randomly assigning someone). ```; ExpressionException Traceback (most recent call last); <ipython-input-47-76acaa85d728> in <module>; 9 #combined.show(); 10; ---> 11 combined = combined.annotate_rows (N_Aa1 = mt.cols()[mt.col_key].N_Aa); 12; 13 combined.cols().show(). <decorator-gen-1171> in annotate_rows(self, **named_exprs). ~/opt/miniconda3/lib/python3.7/site-packages/hail/typecheck/check.py in wrapper(__original_func, *args, **kwargs); 612 def wrapper(__original_func, *args, **kwargs):; 613 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 614 return __original_func(*args_, **kwargs_); 615; 616 return wrapper. ~/opt/miniconda3/lib/python3.7/site-packages/hail/matrixtable.py in annotate_rows(self, **named_exprs); 955 caller = ""MatrixTable.annotate_rows""; 956 check_annotate_exprs(caller, named_exprs, self._row_indices); --> 957 return self._select_rows(caller, self._rvrow.annotate(**named_exprs)); 958; 959 @typecheck_method(named_exprs=expr_any). <decorator-gen-651> in annotate(self, **named_exprs). ~/opt/miniconda3/lib/python3.7/site-packages/hail/typecheck/check.py in wrapper(__original_func, *args, **kwargs); 612 def wrapper(__original_func, *args, **kwargs):; 613 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 614 return __original_func(*args_, **kwargs_); 615; 616 return wrapper. ~/opt/miniconda3/lib/python3.7/site-packages/hail/expr/expressions/typed_expressions.py in annotate(self, **named_exprs); 1624; 1625 result_type = tstruct(**new_types); -> 1626 indices, aggregations = unify_all(self, *[x for (f, x) in named_exprs.items()]); 1627; 1628 return construct_expr(ir.InsertFields.construct_with_deduplication(. ~/opt/miniconda3/lib/python3.7/site-packages/hail/expr/exp",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/9121:78,error,error,78,https://hail.is,https://github.com/hail-is/hail/issues/9121,2,['error'],['error']
Availability,"Note this PR replaces the previous [Feature/sas token merge](https://github.com/hail-is/hail/pull/12877) because the original PR branch got jacked up beyond repair. All the comments on the earlier PR are responded to there and addressed in the code for this one. This PR is to enable `hail-az/https` Azure file references to contain SAS tokens to enable bearer-auth style file access to Azure storage. Basic summary of the changes:; - Update `AzureAsyncFS` url parsing function to look for and separate out a SAS-token-like query string. Note: made fairly specific to SAS tokens - generic detection of query string syntax interferes with glob support and '?' characters in file names; - Added `generate_sas_token` convenience function to `AzureAsyncFS`. Adds new azure-mgmt-storage package requirement.; - Updated `AzureAsyncFS` to use `(account, container, credential)` tuple as internal `BlobServiceClient` cache key; - Updated `AzureAsyncFSURL` and `AzureFileListEntry` to track the token separately from the name, and extend the base classes to allow returning url with or without a token; - Update `RouterFS.ls` function and associated listfiles function to allow for trailing query strings during path traversal; - Update `AsyncFS.open_from` function to handle query-string urls in zero-length case; - Change to existing behavior: `LocalAsyncFSURL.__str__` no longer returns 'file:' prefix. Done to make `str()` output be appropriate for input to `fs` functions across all subclasses; - Updated `InputResource` to not include the SAS token as part of the destination file name; - Updated `inter_cloud/test_fs.py` to generically use query-string-friendly file path building functions to respect the new model, where it is no longer safe to extend URLs by just appending new segments with `+ ""/""` because there may be a query string, and added `'sas/azure-https'` test case to the fixture. Running tests for the SAS case requires some new test variables to allow the test code to generate SAS toke",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13140:157,repair,repair,157,https://hail.is,https://github.com/hail-is/hail/pull/13140,1,['repair'],['repair']
Availability,Noticed that ArrayExpression.head was not documented as deprecated when it was deprecated in #9482. This also fixes a rendering error with one of its examples. https://hail.is/docs/0.2/hail.expr.ArrayExpression.html#hail.expr.ArrayExpression.head,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10032:128,error,error,128,https://hail.is,https://github.com/hail-is/hail/pull/10032,1,['error'],['error']
Availability,Now available in Dataproc 1.1: https://cloud.google.com/dataproc/docs/concepts/dataproc-versions,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/695:4,avail,available,4,https://hail.is,https://github.com/hail-is/hail/issues/695,1,['avail'],['available']
Availability,"Now image fetcher asks the running notebook image what worker image its using and pulls that. Also, add a five second sleep after the service's endpoints are configured. Hopefully that prevents these intermittent gateway errors.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4690:221,error,errors,221,https://hail.is,https://github.com/hail-is/hail/pull/4690,1,['error'],['errors']
Availability,"Now it seems you should use string.isMissing, while this returns an error.; I suggest isMissing(a), which makes clear the proper use of the syntax.; In Brief: update help here: https://github.com/broadinstitute/hail/blob/master/docs/HailExpressionLanguage.md",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/374:68,error,error,68,https://hail.is,https://github.com/hail-is/hail/issues/374,1,['error'],['error']
Availability,Now raises an error instead of asserting. resolves #4770 by clarifying problem with old syntax introduced by [breaking change](https://discuss.hail.is/t/breaking-change-redesign-of-aggregator-interface/701),MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5110:14,error,error,14,https://hail.is,https://github.com/hail-is/hail/pull/5110,1,['error'],['error']
Availability,"Now that we are running with very small nodes, image-fetcher doesn't seem to provide all that much benefit. The intention is that caching through the memory service will ultimately prove better without having to run a daemonset. This also was running a whole daemon set for every PR namespace which meant a lot of our pods were redundant image-fetchers.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10272:328,redundant,redundant,328,https://hail.is,https://github.com/hail-is/hail/pull/10272,1,['redundant'],['redundant']
Availability,"Now the command:; ```; pca_vds.logreg('wald', 'sa.isCase', ['sa.scores.PC1, sa.scores.PC2']).count(); ```; gives the right error; ```; FatalError Traceback (most recent call last); <ipython-input-28-2fb5c41b2314> in <module>(); ----> 1 pca_vds.logreg('wald', 'sa.isCase', ['sa.scores.PC1, sa.scores.PC2']).count(). <decorator-gen-218> in logreg(self, test, y, covariates, root). /Users/jbloom/hail/python/hail/java.pyc in handle_py4j(func, *args, **kwargs); 105 except Py4JJavaError as e:; 106 msg = env.jutils.getMinimalMessage(e.java_exception); --> 107 raise FatalError(msg); 108 except Py4JError as e:; 109 env.jutils.log().error('hail: caught python exception: ' + str(e)). FatalError: `|' expected but `,' found; <input>:1:sa.scores.PC1, sa.scores.PC2; ^; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1502:123,error,error,123,https://hail.is,https://github.com/hail-is/hail/pull/1502,2,['error'],['error']
Availability,"OGRAPHY-6036192) | `cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **479/1000** <br/> **Why?** Has a fix available, CVSS 5.3 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-6050294](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-6050294) | `cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **616/1000** <br/> **Why?** Proof of Concept exploit, Has a fix available, CVSS 5.9 | NULL Pointer Dereference <br/>[SNYK-PYTHON-CRYPTOGRAPHY-6092044](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-6092044) | `cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **616/1000** <br/> **Why?** Proof of Concept exploit, Has a fix available, CVSS 5.9 | Information Exposure <br/>[SNYK-PYTHON-CRYPTOGRAPHY-6126975](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-6126975) | `cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **489/1000** <br/> **Why?** Has a fix available, CVSS 5.5 | NULL Pointer Dereference <br/>[SNYK-PYTHON-CRYPTOGRAPHY-6210214](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-6210214) | `cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **519/1000** <br/> **Why?** Has a fix available, CVSS 6.1 | Information Exposure <br/>[SNYK-PYTHON-REQUESTS-5595532](https://snyk.io/vuln/SNYK-PYTHON-REQUESTS-5595532) | `requests:` <br> `2.27.1 -> 2.31.0` <br> | No | No Known Exploit . (*) Note that the real score m",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14329:9047,avail,available,9047,https://hail.is,https://github.com/hail-is/hail/pull/14329,1,['avail'],['available']
Availability,"OGRAPHY-6036192) | `cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **479/1000** <br/> **Why?** Has a fix available, CVSS 5.3 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-6050294](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-6050294) | `cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **616/1000** <br/> **Why?** Proof of Concept exploit, Has a fix available, CVSS 5.9 | NULL Pointer Dereference <br/>[SNYK-PYTHON-CRYPTOGRAPHY-6092044](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-6092044) | `cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **616/1000** <br/> **Why?** Proof of Concept exploit, Has a fix available, CVSS 5.9 | Information Exposure <br/>[SNYK-PYTHON-CRYPTOGRAPHY-6126975](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-6126975) | `cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **561/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 5.5 | NULL Pointer Dereference <br/>[SNYK-PYTHON-CRYPTOGRAPHY-6210214](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-6210214) | `cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **519/1000** <br/> **Why?** Has a fix available, CVSS 6.1 | Information Exposure <br/>[SNYK-PYTHON-REQUESTS-5595532](https://snyk.io/vuln/SNYK-PYTHON-REQUESTS-5595532) | `requests:` <br> `2.27.1 -> 2.31.0` <br> | No | No Known Exploit . (*) Note t",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14327:9039,avail,available,9039,https://hail.is,https://github.com/hail-is/hail/pull/14327,1,['avail'],['available']
Availability,"OK, I gave you maximum spicy. I don't think it's so bad, but let me know if you want me to cut it up. Some remarks:; - This PR successfully tests (and it passes!) and then cleans up this branch: https://github.com/hail-is/hail/pull/5842. See `build.yaml`. It's a thing of beauty (I think).; - That branch has everything but Scala tests and dataproc/cloudtools tests. The latter are easy, the former are a little messy since I want to test against a test jar, and I've decided to switch to maven for that.; - No support for publish or deploy yet.; - There are synchronous calls it `git` in various places which can make the UI sluggish. I'll fix those in another PR.; - Work remains to validate build.yaml and the deploy step yaml.; - I currently run jinja2 if the file (Dockerfile or deployment yaml) ends in `.in`, but I think I'm going to make it unconditional. `.in` just seem error prone.; - In CreateDatabaseStep, I put secret credentials in the pod configuration. That's not ideal, but I don't think it is a serious problem, because nobody who isn't privileged can read the pods, and I can fix it in a later PR (the create database step should generate the passwords, not ci2).; - I disabled the fixme pylint message (on # FIXME comments), since are fixmes are longer lived than a single change sometimes.; - I'm slightly confused about runImage (which generates a batch job) and deploy of a pod spec (which runs kubectl apply as a batch job). Right now, runImage always runs in batch-pods, and a deploy job runs in whatever namespace you specify. Fixes https://github.com/hail-is/hail/issues/5903",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5891:880,error,error,880,https://hail.is,https://github.com/hail-is/hail/pull/5891,1,['error'],['error']
Availability,"OK, so. This continues to be a mammoth PR despite a day's worth of pruning. I think it would be good to start getting some eyes on it. Over all, I feel a bit weird about it. The intention is for this to be a functional but not scalable or reliable shuffler. It will allow Hail Query to exist, albeit in a limited way (keys cannot exceed shuffler memory). However, in parallel to getting this PR merged, I'm designing the real shuffler: a horizontally scalable sorting system. So. We have to live with this code for a few months, so let's make sure we feel good about it, but also know that this is all going away in a few months.  . # High Level Overview; - implement the shuffler as a single machine, multi-threaded service which buffers keys until the write phase of a shuffle is done, then sorts the keys, then serves them to clients.; - implement non-spark shuffling as: write records to `dbuf` and write pairs of (data key, dbuf key) to shuffler, then read back re-partitioned keys and fetch records from dbuf.; - I use SBT because the Akka examples use it, it's not obvious how to do this SBT assembly merging thing in Gradle; - I'm really not using Akka properly. There's all this DataSource stuff that I don't understand. I'll probably have to get this right to get good performance, but it doesn't seem critical now and the Akka docs are incredibly hard to understand.; - I turn the optimizer off in the tests because it often optimizes away shuffles into local sorts. There are some FIXMEs throughout the code that I would appreciate thoughts on.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8205:239,reliab,reliable,239,https://hail.is,https://github.com/hail-is/hail/pull/8205,1,['reliab'],['reliable']
Availability,"ON-JUPYTERSERVER-5862881](https://snyk.io/vuln/SNYK-PYTHON-JUPYTERSERVER-5862881) | `jupyter-server:` <br> `1.24.0 -> 2.7.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **/1000** <br/> **Why?** | Open Redirect <br/>[SNYK-PYTHON-JUPYTERSERVER-5862882](https://snyk.io/vuln/SNYK-PYTHON-JUPYTERSERVER-5862882) | `jupyter-server:` <br> `1.24.0 -> 2.7.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **509/1000** <br/> **Why?** Has a fix available, CVSS 5.9 | Regular Expression Denial of Service (ReDoS) <br/>[SNYK-PYTHON-SETUPTOOLS-3180412](https://snyk.io/vuln/SNYK-PYTHON-SETUPTOOLS-3180412) | `setuptools:` <br> `39.0.1 -> 65.5.1` <br> | No | No Known Exploit ; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **384/1000** <br/> **Why?** Has a fix available, CVSS 3.4 | Open Redirect <br/>[SNYK-PYTHON-TORNADO-5537286](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-5537286) | `tornado:` <br> `6.2 -> 6.3.3` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **494/1000** <br/> **Why?** Has a fix available, CVSS 5.6 | HTTP Request Smuggling <br/>[SNYK-PYTHON-TORNADO-5840803](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-5840803) | `tornado:` <br> `6.2 -> 6.3.3` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13718:2471,avail,available,2471,https://hail.is,https://github.com/hail-is/hail/pull/13718,3,['avail'],['available']
Availability,"ON-JUPYTERSERVER-5862881](https://snyk.io/vuln/SNYK-PYTHON-JUPYTERSERVER-5862881) | `jupyter-server:` <br> `1.24.0 -> 2.7.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **/1000** <br/> **Why?** | Open Redirect <br/>[SNYK-PYTHON-JUPYTERSERVER-5862882](https://snyk.io/vuln/SNYK-PYTHON-JUPYTERSERVER-5862882) | `jupyter-server:` <br> `1.24.0 -> 2.7.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **509/1000** <br/> **Why?** Has a fix available, CVSS 5.9 | Regular Expression Denial of Service (ReDoS) <br/>[SNYK-PYTHON-SETUPTOOLS-3180412](https://snyk.io/vuln/SNYK-PYTHON-SETUPTOOLS-3180412) | `setuptools:` <br> `39.0.1 -> 65.5.1` <br> | No | No Known Exploit ; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **384/1000** <br/> **Why?** Has a fix available, CVSS 3.4 | Open Redirect <br/>[SNYK-PYTHON-TORNADO-5537286](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-5537286) | `tornado:` <br> `6.2 -> 6.3.3` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **494/1000** <br/> **Why?** Has a fix available, CVSS 5.6 | HTTP Request Smuggling <br/>[SNYK-PYTHON-TORNADO-5840803](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-5840803) | `tornado:` <br> `6.2 -> 6.3.3` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **496/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 4.2 | Information Exposure Through Sent Data <br/>[SNYK-PYTHON-URLLIB3-6002459](https://snyk.io/vuln/SNYK-PYTHON-URLLIB3-6002459) | `urllib3:` <br> `1.26.17 -> 1.26.18` <br> | No | No Known Exploit . (*) Note that the real score may have changed since ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13873:2539,avail,available,2539,https://hail.is,https://github.com/hail-is/hail/pull/13873,1,['avail'],['available']
Availability,"ON-JUPYTERSERVER-5862881](https://snyk.io/vuln/SNYK-PYTHON-JUPYTERSERVER-5862881) | `jupyter-server:` <br> `1.24.0 -> 2.7.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **/1000** <br/> **Why?** | Open Redirect <br/>[SNYK-PYTHON-JUPYTERSERVER-5862882](https://snyk.io/vuln/SNYK-PYTHON-JUPYTERSERVER-5862882) | `jupyter-server:` <br> `1.24.0 -> 2.7.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **509/1000** <br/> **Why?** Has a fix available, CVSS 5.9 | Regular Expression Denial of Service (ReDoS) <br/>[SNYK-PYTHON-SETUPTOOLS-3180412](https://snyk.io/vuln/SNYK-PYTHON-SETUPTOOLS-3180412) | `setuptools:` <br> `39.0.1 -> 65.5.1` <br> | No | No Known Exploit ; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **384/1000** <br/> **Why?** Has a fix available, CVSS 3.4 | Open Redirect <br/>[SNYK-PYTHON-TORNADO-5537286](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-5537286) | `tornado:` <br> `6.2 -> 6.3.3` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **494/1000** <br/> **Why?** Has a fix available, CVSS 5.6 | HTTP Request Smuggling <br/>[SNYK-PYTHON-TORNADO-5840803](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-5840803) | `tornado:` <br> `6.2 -> 6.3.3` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **539/1000** <br/> **Why?** Has a fix available, CVSS 6.5 | HTTP Request Smuggling <br/>[SNYK-PYTHON-TORNADO-6041512](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-6041512) | `tornado:` <br> `6.2 -> 6.3.3` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities co",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14026:2580,avail,available,2580,https://hail.is,https://github.com/hail-is/hail/pull/14026,1,['avail'],['available']
Availability,"ON-MISTUNE-2940625](https://snyk.io/vuln/SNYK-PYTHON-MISTUNE-2940625) | `mistune:` <br> `0.8.4 -> 2.0.3` <br> | No | No Known Exploit ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | **726/1000** <br/> **Why?** Proof of Concept exploit, Has a fix available, CVSS 8.1 | Cross-site Scripting (XSS) <br/>[SNYK-PYTHON-NBCONVERT-2979829](https://snyk.io/vuln/SNYK-PYTHON-NBCONVERT-2979829) | `nbconvert:` <br> `5.6.1 -> 6.3.0b0` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **434/1000** <br/> **Why?** Has a fix available, CVSS 4.4 | Open Redirect <br/>[SNYK-PYTHON-NOTEBOOK-1041707](https://snyk.io/vuln/SNYK-PYTHON-NOTEBOOK-1041707) | `notebook:` <br> `5.7.16 -> 6.4.12` <br> | No | No Known Exploit ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | **589/1000** <br/> **Why?** Has a fix available, CVSS 7.5 | Information Exposure <br/>[SNYK-PYTHON-NOTEBOOK-2441824](https://snyk.io/vuln/SNYK-PYTHON-NOTEBOOK-2441824) | `notebook:` <br> `5.7.16 -> 6.4.12` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **449/1000** <br/> **Why?** Has a fix available, CVSS 4.7 | Access Restriction Bypass <br/>[SNYK-PYTHON-NOTEBOOK-2928995](https://snyk.io/vuln/SNYK-PYTHON-NOTEBOOK-2928995) | `notebook:` <br> `5.7.16 -> 6.4.12` <br> | No | No Known Exploit ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | **696/1000** <br/> **Why?** Proof of Concept exploit, Has a fix available, CVSS 7.5 | Regular Expression Denial of Service (ReDoS) <br/>[SNYK-PYTHON-PYGMENTS-1086606](https://snyk.io/vuln/SNYK-PYTHON-PYGMENTS-1086606) | `pygments:` <br> `2.5.2 -> 2.15.0` <br> | No | Proof of Concept ; ![high severity](htt",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13717:4028,avail,available,4028,https://hail.is,https://github.com/hail-is/hail/pull/13717,2,['avail'],['available']
Availability,"ON-MISTUNE-2940625](https://snyk.io/vuln/SNYK-PYTHON-MISTUNE-2940625) | `mistune:` <br> `0.8.4 -> 2.0.3` <br> | No | No Known Exploit ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | **726/1000** <br/> **Why?** Proof of Concept exploit, Has a fix available, CVSS 8.1 | Cross-site Scripting (XSS) <br/>[SNYK-PYTHON-NBCONVERT-2979829](https://snyk.io/vuln/SNYK-PYTHON-NBCONVERT-2979829) | `nbconvert:` <br> `5.6.1 -> 6.3.0b0` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **434/1000** <br/> **Why?** Has a fix available, CVSS 4.4 | Open Redirect <br/>[SNYK-PYTHON-NOTEBOOK-1041707](https://snyk.io/vuln/SNYK-PYTHON-NOTEBOOK-1041707) | `notebook:` <br> `5.7.16 -> 6.4.12` <br> | No | No Known Exploit ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | **589/1000** <br/> **Why?** Has a fix available, CVSS 7.5 | Information Exposure <br/>[SNYK-PYTHON-NOTEBOOK-2441824](https://snyk.io/vuln/SNYK-PYTHON-NOTEBOOK-2441824) | `notebook:` <br> `5.7.16 -> 6.4.12` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **449/1000** <br/> **Why?** Has a fix available, CVSS 4.7 | Access Restriction Bypass <br/>[SNYK-PYTHON-NOTEBOOK-2928995](https://snyk.io/vuln/SNYK-PYTHON-NOTEBOOK-2928995) | `notebook:` <br> `5.7.16 -> 6.4.12` <br> | No | No Known Exploit ; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **399/1000** <br/> **Why?** Has a fix available, CVSS 3.7 | Race Condition <br/>[SNYK-PYTHON-PROMPTTOOLKIT-6141120](https://snyk.io/vuln/SNYK-PYTHON-PROMPTTOOLKIT-6141120) | `prompt-toolkit:` <br> `1.0.18 -> 3.0.13` <br> | No | No Known Exploit ; ![high severity](https://res.cloudinary.com/snyk/image/upload",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14205:4720,avail,available,4720,https://hail.is,https://github.com/hail-is/hail/pull/14205,1,['avail'],['available']
Availability,"ON-SPHINX-5811865](https://snyk.io/vuln/SNYK-PYTHON-SPHINX-5811865) | `sphinx:` <br> `1.8.6 -> 3.3.0` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **586/1000** <br/> **Why?** Proof of Concept exploit, Has a fix available, CVSS 5.3 | Regular Expression Denial of Service (ReDoS) <br/>[SNYK-PYTHON-SPHINX-5812109](https://snyk.io/vuln/SNYK-PYTHON-SPHINX-5812109) | `sphinx:` <br> `1.8.6 -> 3.3.0` <br> | No | Proof of Concept ; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **384/1000** <br/> **Why?** Has a fix available, CVSS 3.4 | Open Redirect <br/>[SNYK-PYTHON-TORNADO-5537286](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-5537286) | `tornado:` <br> `5.1.1 -> 6.3.3` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **494/1000** <br/> **Why?** Has a fix available, CVSS 5.6 | HTTP Request Smuggling <br/>[SNYK-PYTHON-TORNADO-5840803](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-5840803) | `tornado:` <br> `5.1.1 -> 6.3.3` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiIyMjlkNGUyNC0xMDE4LTQ5ZDItYTQ3NC04MmViZDVhNzZlMDEiLCJldmVudCI6IlBSIHZpZ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13717:8459,avail,available,8459,https://hail.is,https://github.com/hail-is/hail/pull/13717,1,['avail'],['available']
Availability,"ON-SPHINX-5811865](https://snyk.io/vuln/SNYK-PYTHON-SPHINX-5811865) | `sphinx:` <br> `1.8.6 -> 3.3.0` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **586/1000** <br/> **Why?** Proof of Concept exploit, Has a fix available, CVSS 5.3 | Regular Expression Denial of Service (ReDoS) <br/>[SNYK-PYTHON-SPHINX-5812109](https://snyk.io/vuln/SNYK-PYTHON-SPHINX-5812109) | `sphinx:` <br> `1.8.6 -> 3.3.0` <br> | No | Proof of Concept ; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **384/1000** <br/> **Why?** Has a fix available, CVSS 3.4 | Open Redirect <br/>[SNYK-PYTHON-TORNADO-5537286](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-5537286) | `tornado:` <br> `5.1.1 -> 6.3.3` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **494/1000** <br/> **Why?** Has a fix available, CVSS 5.6 | HTTP Request Smuggling <br/>[SNYK-PYTHON-TORNADO-5840803](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-5840803) | `tornado:` <br> `5.1.1 -> 6.3.3` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **539/1000** <br/> **Why?** Has a fix available, CVSS 6.5 | HTTP Request Smuggling <br/>[SNYK-PYTHON-TORNADO-6041512](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-6041512) | `tornado:` <br> `5.1.1 -> 6.3.3` <br> | No | No Known Exploit ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | **589/1000** <br/> **Why?** Has a fix available, CVSS 7.5 | Regular Expression Denial of Service (ReDoS) <br/>[SNYK-PYTHON-WHEEL-3180413](https://snyk.io/vuln/SNYK-PYTHON-WHEEL-3180413) | `wheel:` <br> `0.30.0 -> 0.38.0` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was r",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14108:8494,avail,available,8494,https://hail.is,https://github.com/hail-is/hail/pull/14108,2,['avail'],['available']
Availability,"Old State Diagram:; Created -> Ready -> Complete; Cancelled. New State Diagram:; Pending -> Ready -> (Error, Running -> (Failed, Success)); Cancelled",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6268:102,Error,Error,102,https://hail.is,https://github.com/hail-is/hail/pull/6268,1,['Error'],['Error']
Availability,Old versions of pip could only download some packages in source form which; requires compiling them. New version of pip can download these packages in; binary form which requires no compilation. This *substantially* improves docker; build times when you have to run `pip` in any layer.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9127:31,down,download,31,https://hail.is,https://github.com/hail-is/hail/pull/9127,2,['down'],['download']
Availability,"On a test of 1-2 partitions with 5000 samples, this takes the second stage of a densify from 2 minutes down to 1.4 minutes (only loading GT).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6967:103,down,down,103,https://hail.is,https://github.com/hail-is/hail/pull/6967,1,['down'],['down']
Availability,On the web site:; https://hail.is/docs/stable/getting_started.html. The links to the current distributions are broken:; Current distribution for Spark 2.0.2; Current distribution for Spark 2.1.0. The error is:; NoSuchKeyThe specified key does not exist.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2217:200,error,error,200,https://hail.is,https://github.com/hail-is/hail/issues/2217,1,['error'],['error']
Availability,"One more if/when you want to take a look. Changes:; - Keep track of failed requests to workers, failed_request_count. Reset on a successful communication in Instance.mark_healthy.; - Don't retry the /job/create request. The scheduler loop will just retry.; - Don't schedule on nodes with failed count > 1. This basically ignores 1-off hiccups.; - The /jobs/delete (unscheduled) call is an interested situation. I decided to retry with back off and stop if the instance gets deactivated. Retry abstractions seem hard, I'm not quite sure how to share this code with request_retry_transient_error, for example, given different exit conditions. Sometime to think about as we see more examples.; - Ignore errors for each schedule attempt, so if there is a failure, count the request as failed and keep scheduling the current block of jobs before getting another block.; - Don't kill unhealthy instances. You might object to this, but I'm worried about when a job has been running for 3hrs (or 5 weeks, once we support scheduling on non-premptibles) and we delete an instance after a 5m network disconnect. I appreciate the need to clean up resources, I have more thoughts about that that I'll write elsewhere.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7441:700,error,errors,700,https://hail.is,https://github.com/hail-is/hail/pull/7441,2,"['error', 'failure']","['errors', 'failure']"
Availability,One more step of stripping down router. ukbb lives in its own namespace and we never run dev versions of it so it's pretty much a drop-in.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10179:27,down,down,27,https://hail.is,https://github.com/hail-is/hail/pull/10179,1,['down'],['down']
Availability,"One more time, with feeling! (was: #10072). - [x] (@tpoterba) a1f3b2a5c9 add fails_service_backend; - [ ] (@tpoterba, @cseed) dc0bee7ce1 [hail] introduce and use mktemp and mktempd; - [ ] (@tpoterba) 4b663be367 [hail] make is.hail.expr.ir.functions threadsafe; - [ ] (@tpoterba) d3c1f0987c [hail] fix use of row requiredness in lowerDistributedSort; - [ ] (@catoverdrive) aab6ba98be [query-service] handle void-typed IRs in query-service; - [ ] (@catoverdrive) a1619cff36 [query-service] make user cache thread-safe; - [ ] (@tpoterba) c315fcb0b1 [query-service] bugfix: preserve globals through a shuffle; - [ ] (@catoverdrive) 912c21f709 [shuffler] log ShuffleCodecSpec anytime it is created; - [x] (@daniel-goldstein) c2495837e7 [scala-lsm] bugfix: least key may equal greatest key; - [x] (@daniel-goldstein) 5fb3db703e [services] discovered new transient error; - [x] (@daniel-goldstein) 9cd0999938 [shuffler] more assertions in ShuffleClient; - [x] (@daniel-goldstein) a71a3c9b8c [shuffler] bugfix: shuffler needs a HailContext to decode loci; - [x] (@daniel-goldstein) 41b06aeaa8 [query-service] move hail.jar earlier in Dockerfile; - [x] (@daniel-goldstein) 8df4029698 [query-service] permit pod scaling and remove cpu limit; - [ ] (@catoverdrive) 0354e1f557 [query-service] simplify socket handling; - [x] (@jigold) 6690a4decc [batch] teach JVMJob where to find the hail configuration files; - [x] (@daniel-goldstein) ae2e3d2996 [query-service] switch to services team approved logging; - [ ] (@tpoterba) b18f86e647 [query-service] query workers need a hail context; - [ ] (@daniel-goldstein, @catoverdrive) 6d5d0b68af [query-service] use a UNIX Domain Socket for Py-Scala communication; - [ ] (@daniel-goldstein, @catoverdrive) 0d42df8b08 [query-service] run tests against query service; - [x] (@jigold) f9d361e686 [query-service] aiohttp.ClientSession must be created in async code; - [ ] (@cseed) c35f2e10e3 [query-service][hail][build.yaml] address miscellaneous comments from cotton; - [x]",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10100:858,error,error,858,https://hail.is,https://github.com/hail-is/hail/pull/10100,1,['error'],['error']
Availability,Only one coro waits on receive now. We still error if a message is sent before; we make our first response.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10159:45,error,error,45,https://hail.is,https://github.com/hail-is/hail/pull/10159,1,['error'],['error']
Availability,"Open question: we're using ~20GiB on /prometheus for 15d. We request 150GiB (and get closer to 146GiB). Should we increase the storage to give ourselves more slack? Assuming linear scaling, 90d would use 120GiB (26GiB of slack). https://hail.zulipchat.com/#narrow/stream/300487-Hail-Batch-Dev/topic/Grafana.20retention.20period; ```; /prometheus $ df -h; Filesystem Size Used Available Use% Mounted on; overlay 94.3G 28.9G 65.3G 31% /; tmpfs 64.0M 0 64.0M 0% /dev; tmpfs 3.6G 0 3.6G 0% /sys/fs/cgroup; /dev/sdf 146.6G 18.9G 127.6G 13% /prometheus; /dev/sda1 94.3G 28.9G 65.3G 31% /etc/prometheus; /dev/sda1 94.3G 28.9G 65.3G 31% /etc/hosts; /dev/sda1 94.3G 28.9G 65.3G 31% /dev/termination-log; /dev/sda1 94.3G 28.9G 65.3G 31% /etc/hostname; /dev/sda1 94.3G 28.9G 65.3G 31% /etc/resolv.conf; shm 64.0M 4.0K 64.0M 0% /dev/shm; tmpfs 5.5G 12.0K 5.5G 0% /var/run/secrets/kubernetes.io/serviceaccount; tmpfs 3.6G 0 3.6G 0% /proc/acpi; tmpfs 64.0M 0 64.0M 0% /proc/kcore; tmpfs 64.0M 0 64.0M 0% /proc/keys; tmpfs 64.0M 0 64.0M 0% /proc/timer_list; tmpfs 3.6G 0 3.6G 0% /proc/scsi; tmpfs 3.6G 0 3.6G 0% /sys/firmware; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14194:376,Avail,Available,376,https://hail.is,https://github.com/hail-is/hail/pull/14194,1,['Avail'],['Available']
Availability,"Operations for all interaction with blobs. This change ensures that QoB only uses Class A Operations when necessary. Inspired by @jigold 's file system improvement campaign, I pursued the avoidance of ""list"" operations. I anticipate this reduces flakiness in Azure (which is tracked in #13351) and cost in Azure. I enforced aiotools.fs terminology on hail.fs and Scala:. 1. `FileStatus`. Metadata about a blob or file. It does not know if a directory exists at this path. 2. `FileListEntry`. Metadata from a list operation. It knows if a directory exists at this path. Variable names were updated to reflect this distinction:. 1. `fileStatus` / `fileStatuses`. 2. `fle`/ `fles` / `fileListEntry` / `fileListEntries`, respectively. `listStatus` renamed to `listDirectory` for clarity. In both Azure and Google, `fileStatus` does not use a list operation. `fileListEntry` can be used when we must know if a directory exists. I just rewrote this from first principles because:; 1. In neither Google nor Azure did it check if the path was a directory and a file.; 2. In Google, if the directory entry wasn't in the first page, it would fail (NB: there are fifteen non-control characters in ASCII before `/`, if the page size is 15 or fewer, we'd miss the first entry with a `/` at the end).; 3. In Azure, we issued both a get and a list. There are now unit tests for this method. ---. 1. `copyMerge` and `concatenateFiles` previously used `O(N_FILES)` list operations, they now use `O(N_FILES)` get operations.; 2. Writers that used `exists` to check for a _SUCCESS file now use a get operation.; 3. Index readers, import BGEN, and import plink all now check file size with a get operation. That said, overall, the bulk of our Class A Operations are probably writes. fix test failures. passes tests. fixes. fix tests to not use fileStatus for folders. only file vs directory status matters. fix azure. azure dislikes %. finally get azure right. nix empty line. fix merge cruft. azure bug. lots of changes",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13883:1827,failure,failures,1827,https://hail.is,https://github.com/hail-is/hail/pull/13883,1,['failure'],['failures']
Availability,Optimized sampleqc for (fixed) VSM structure. Added; downsamplevariants. Make sure all file IO goes through hadoop IO; interface.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/93:53,down,downsamplevariants,53,https://hail.is,https://github.com/hail-is/hail/pull/93,1,['down'],['downsamplevariants']
Availability,OrderedJoinDistinctRDD2 fails if the right side has no partitions (assertion failure in BinarySearch),MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2876:77,failure,failure,77,https://hail.is,https://github.com/hail-is/hail/issues/2876,1,['failure'],['failure']
Availability,OrderedRVD assertion error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3998:21,error,error,21,https://hail.is,https://github.com/hail-is/hail/issues/3998,1,['error'],['error']
Availability,OrderedRVD error!,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4096:11,error,error,11,https://hail.is,https://github.com/hail-is/hail/issues/4096,1,['error'],['error']
Availability,Otherwise you get an error from the compiler on IR construction/typechecking,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12080:21,error,error,21,https://hail.is,https://github.com/hail-is/hail/pull/12080,1,['error'],['error']
Availability,"Our GKE nodes come with 2 CPU and 7.5 GB each, but not all of that is allocatable to our pods. In reality, somewhere between 5.7-5.9GB ([GCP Docs](https://cloud.google.com/kubernetes-engine/docs/concepts/cluster-architecture) say 5.7, GKE console says 5.9) of memory and 1.9CPU are available for us to use. Some of our Big services request 1 CPU and 3.75GB, but then we can never fit two big pods on one node. This is an attempt to standardize our requests so their easier to reason about while hopefully getting better packing. . | resource | Big | Medium | Small |; | --- | --- | --- | --- |; | CPU | 600m | 100m | 20m |; | Memory | 2G | 200M | 20M |. The intentions here are:; - always be able to comfortably get 2 Big pods on a node; - medium pods shouldn't have to force new nodes to spin up just because there's a Big pod there already; - small pods take up minimal resources; - there's ample room for small pods (which are mostly on HPA) to scale up considering most nodes shouldn't be at their medium pod capacity. The ratios don't match exactly, because I didn't want to assign CPU lower than 20m to prevent HPA thrashing we saw with auth and see a bit now with router. Setting it to 20m should hopefully convince k8s that idle small apps don't need to be scaled up under normal fluctuation. ## Big; - query; - batch-driver; - shuffler; - memory. ## Medium; - grafana; - ukbb-browser; - ukbb-static; - blog; - ci; - internal-gateway. ## Small; - amundsen; - router; - gateway; - site; - batch; - address; - atgu; - router-resolver; - ci/test statefulset & deployment; - auth-driver; - echo; - benchmark; - image-fetcher. ### Fun surprises I found along the way; - CI test statefulsets and deployment are getting .5GB and .5 CPU each; - We run a lot of image fetchers because a daemon set gets added per PR namespace. EDIT: It seems that discrepancy between GCP docs and GKE console is the console counts kube-system pods in ""Allocatable Memory"", and it really does take 2GB to run the Kuberne",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10117:282,avail,available,282,https://hail.is,https://github.com/hail-is/hail/pull/10117,1,['avail'],['available']
Availability,"Our current HTML display of tables flattens the table and concatenates the field; names to produce table headers. This leads to long, unreadable headers. This change reproduces the nesting structure of the types with several table; header layers. The essential activity is to convert:. ```; bing; foo:; bar:; baz; quux; fizzle:; fazz:; fazz1; fazz2; fezz; quork; bang; ```. into. ```; foo; -------------------------------; fizzle; ----------------; bar fazz; -------- -----------; bing baz quux fazz1 fazz2 fezz quork bang; ```. The bottom layer are the names of the leaves of this tree. Working from the; bottom, a name appears when the row corresponds to that name's tree height. For; this reason `bar` appears lower than `fizzle`. This frustrates finding peer; fields. However, I prefer it. I think I have some sense of visual gravity that; wants bar to fall down. Anyway, I implement this with some html grunginess in `Table._Show` and a new; class named `PlacementTree`. We construct a `PlacementTree` from a type. It is a; tree whose internal and leaf nodes contain a name, width, and height. It has a; method `to_grid` which converts it to an HTML-table-like structure with ""spacer""; elements. Our above example looks like:. ```python3; [[(None, 1), ('foo', 6), (None, 1)],; [(None, 1), (None, 2), ('fizzle', 3), (None, 1), (None, 1)],; [(None, 1), ('bar', 2), ('fazz', 2), (None, 1) (None, 1), (None, 1)],; [('bing', 1), ('baz', 1), ('quux', 1), ('fazz1', 1), ('fazz2', 1), ('fezz', 1) ('quork', 1), ('bang', 1)]]; ```. The code in `Table._Show` converts this to HTML table rows that looks like:; ```html; <tr><td></td><td colspan=""6"">foo</td><td></td></tr>; <tr><td></td><td colspan=""2""></td><td colspan=3>fizzle</td><td></td><td></td></tr>; <tr><td></td><td colspan=""2"">bar</td><td colspan=2>fazz</td><td></td><td></td><td></td></tr>; <tr><td>bing</td><td>baz</td><td>quux</td><td>fazz1</td><td>fazz2</td><td>fezz</td><td>quork</td><td>bang</td></tr>; ```. Which looks like:. <table>; <tr><t",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8811:862,down,down,862,https://hail.is,https://github.com/hail-is/hail/pull/8811,1,['down'],['down']
Availability,"Our team is currently trying to run kinship analysis with [king()](https://hail.is/docs/0.2/methods/relatedness.html#hail.methods.king) on just under 110k samples. We have run this successfully in the past on 10k samples using a google cloud cluster with the following configuration. ```; hailctl dataproc start cluster --vep GRCh38 \; 	--requester-pays-allow-annotation-db \; 	--packages gnomad --requester-pays-allow-buckets gnomad-public-requester-pays \; 	--master-machine-type=n1-highmem-8 --worker-machine-type=n1-highmem-8 \; 	--num-workers=300	--num-secondary-workers=0 \; 	--worker-boot-disk-size=1000 \; 	--properties=dataproc:dataproc.logging.stackdriver.enable=true,dataproc:dataproc.monitoring.stackdriver.enable=true; ```; We are currently receiving a spark error when using this cluster for our larger dataset. ```; [Stage 10:=====> (69 + 656) / 729]; raise err; File ""/opt/conda/default/lib/python3.8/site-packages/hail/backend/py4j_backend.py"", line 98, in execute; result_tuple = self._jbackend.executeEncode(jir, stream_codec, timed); File ""/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py"", line 1304, in __call__; File ""/opt/conda/default/lib/python3.8/site-packages/hail/backend/py4j_backend.py"", line 31, in deco; raise fatal_error_from_java_error_triplet(deepest, full, error_id) from None; hail.utils.java.FatalError: SparkException: Job aborted due to stage failure: Task 582 in stage 10.0 failed 20 times, most recent failure: Lost task 582.19 in stage 10.0 (TID 461381) (cluster-w-144.c.project-.internal executor 3568): ExecutorLostFailure (executor 3568 exited caused by one of the running tasks) Reason: Executor heartbeat timed out after 128936 ms; Driver stacktrace:. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 582 in stage 10.0 failed 20 times, most recent failure: Lost task 582.19 in stage 10.0 (TID 461381) (cluster-w-144.c.gbsc-project.internal executor 3568): ExecutorLostFailure (executor 3568 e",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12290:772,error,error,772,https://hail.is,https://github.com/hail-is/hail/issues/12290,1,['error'],['error']
Availability,"Output for a requirement failed exception now looks like:. ```; Traceback (most recent call last):; File ""hail_extract_cohorts.py"", line 37, in <module>; vds = vds.annotate_global('global.samples_to_exclude', set(samples_to_exclude_list), hail.TSet(hail.TString())); File ""<decorator-gen-390>"", line 2, in annotate_global; File ""/home/cotton/hail/python/hail/java.py"", line 167, in handle_py4j; 'Error summary: %s' % (e.desc, e.stackTrace, Env.hc().version, e.desc)); hail.java.FatalError: requirement failed. Java stack trace:; scala.Predef$.require(Predef.scala:212); 	 at is.hail.variant.VariantSampleMatrix.annotateGlobal(VariantSampleMatrix.scala:564); 	 at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	 at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	 at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	 at java.lang.reflect.Method.invoke(Method.java:498); 	 at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237); 	 at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	 at py4j.Gateway.invoke(Gateway.java:280); 	 at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	 at py4j.commands.CallCommand.execute(CallCommand.java:79); 	 at py4j.GatewayConnection.run(GatewayConnection.java:214); 	 at java.lang.Thread.run(Thread.java:748); Hail version: devel-75de081; Error summary: requirement failed; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2554:396,Error,Error,396,https://hail.is,https://github.com/hail-is/hail/pull/2554,2,['Error'],['Error']
Availability,"P; valueFrom:; fieldRef:; apiVersion: v1; fieldPath: status.podIP; - name: POD_NAME; valueFrom:; fieldRef:; apiVersion: v1; fieldPath: metadata.name; image: konradjk/saige:0.35.8.2.2; imagePullPolicy: IfNotPresent; name: main; resources:; requests:; cpu: ""1""; memory: 500M; terminationMessagePath: /dev/termination-log; terminationMessagePolicy: File; volumeMounts:; - mountPath: /gsa-key; name: gsa-key; - mountPath: /io; name: batch-2554-job-4-8vvgl; - mountPath: /var/run/secrets/kubernetes.io/serviceaccount; name: default-token-8h99c; readOnly: true; dnsPolicy: ClusterFirst; enableServiceLinks: true; nodeName: gke-vdc-preemptible-pool-9c7148b2-4gq2; priority: 500000; priorityClassName: user; restartPolicy: Never; schedulerName: default-scheduler; securityContext: {}; serviceAccount: default; serviceAccountName: default; terminationGracePeriodSeconds: 30; tolerations:; - key: preemptible; value: ""true""; - effect: NoExecute; key: node.kubernetes.io/not-ready; operator: Exists; tolerationSeconds: 300; - effect: NoExecute; key: node.kubernetes.io/unreachable; operator: Exists; tolerationSeconds: 300; volumes:; - name: gsa-key; secret:; defaultMode: 420; secretName: konradk-gsa-key; - name: batch-2554-job-4-8vvgl; persistentVolumeClaim:; claimName: batch-2554-job-4-8vvgl; - name: default-token-8h99c; secret:; defaultMode: 420; secretName: default-token-8h99c; status:; conditions:; - lastProbeTime: null; lastTransitionTime: ""2019-06-25T03:09:04Z""; status: ""True""; type: Initialized; - lastProbeTime: null; lastTransitionTime: ""2019-06-25T03:09:04Z""; message: 'containers with unready status: [main]'; reason: ContainersNotReady; status: ""False""; type: Ready; - lastProbeTime: null; lastTransitionTime: ""2019-06-25T03:09:04Z""; message: 'containers with unready status: [main]'; reason: ContainersNotReady; status: ""False""; type: ContainersReady; - lastProbeTime: null; lastTransitionTime: ""2019-06-25T03:09:04Z""; status: ""True""; type: PodScheduled; containerStatuses:; - image: konradj",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6466:6490,toler,tolerationSeconds,6490,https://hail.is,https://github.com/hail-is/hail/issues/6466,1,['toler'],['tolerationSeconds']
Availability,PCA throws error using Breeze 0.12 and natives (BLAS),MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/209:11,error,error,11,https://hail.is,https://github.com/hail-is/hail/issues/209,1,['error'],['error']
Availability,"PHY-6092044) | `cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **616/1000** <br/> **Why?** Proof of Concept exploit, Has a fix available, CVSS 5.9 | Information Exposure <br/>[SNYK-PYTHON-CRYPTOGRAPHY-6126975](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-6126975) | `cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **561/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 5.5 | NULL Pointer Dereference <br/>[SNYK-PYTHON-CRYPTOGRAPHY-6210214](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-6210214) | `cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **519/1000** <br/> **Why?** Has a fix available, CVSS 6.1 | Information Exposure <br/>[SNYK-PYTHON-REQUESTS-5595532](https://snyk.io/vuln/SNYK-PYTHON-REQUESTS-5595532) | `requests:` <br> `2.27.1 -> 2.31.0` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI5ZjJhMGZlMy1kYmVkLTQ2YzAtYmQyMC0yMjM3NzFiYzE0OTciLCJldmVudCI6IlBSIH",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14327:9795,avail,available,9795,https://hail.is,https://github.com/hail-is/hail/pull/14327,1,['avail'],['available']
Availability,"PTOOLS-3180412](https://snyk.io/vuln/SNYK-PYTHON-SETUPTOOLS-3180412) | `setuptools:` <br> `39.0.1 -> 65.5.1` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **711/1000** <br/> **Why?** Mature exploit, Has a fix available, CVSS 6.5 | Cross-site Scripting (XSS) <br/>[SNYK-PYTHON-SPHINX-570772](https://snyk.io/vuln/SNYK-PYTHON-SPHINX-570772) | `sphinx:` <br> `1.8.6 -> 3.3.0` <br> | No | Mature ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **701/1000** <br/> **Why?** Mature exploit, Has a fix available, CVSS 6.3 | Cross-site Scripting (XSS) <br/>[SNYK-PYTHON-SPHINX-570773](https://snyk.io/vuln/SNYK-PYTHON-SPHINX-570773) | `sphinx:` <br> `1.8.6 -> 3.3.0` <br> | No | Mature ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **586/1000** <br/> **Why?** Proof of Concept exploit, Has a fix available, CVSS 5.3 | Regular Expression Denial of Service (ReDoS) <br/>[SNYK-PYTHON-SPHINX-5811865](https://snyk.io/vuln/SNYK-PYTHON-SPHINX-5811865) | `sphinx:` <br> `1.8.6 -> 3.3.0` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **586/1000** <br/> **Why?** Proof of Concept exploit, Has a fix available, CVSS 5.3 | Regular Expression Denial of Service (ReDoS) <br/>[SNYK-PYTHON-SPHINX-5812109](https://snyk.io/vuln/SNYK-PYTHON-SPHINX-5812109) | `sphinx:` <br> `1.8.6 -> 3.3.0` <br> | No | Proof of Concept ; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **384/1000** <br/> **Why?** Has a fix available, CVSS 3.4 | Open Redirect <br/>[SNYK-PYTHON-TORNADO-5537286](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-5537286) | `tornado:` <br> `5.1.1 -> 6.3.3` <br> | No | No Known Exploit ; ![medium severit",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13717:7354,avail,available,7354,https://hail.is,https://github.com/hail-is/hail/pull/13717,3,['avail'],['available']
Availability,"PYTHON-SPHINX-570773) | `sphinx:` <br> `1.8.6 -> 3.3.0` <br> | No | Mature ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **586/1000** <br/> **Why?** Proof of Concept exploit, Has a fix available, CVSS 5.3 | Regular Expression Denial of Service (ReDoS) <br/>[SNYK-PYTHON-SPHINX-5811865](https://snyk.io/vuln/SNYK-PYTHON-SPHINX-5811865) | `sphinx:` <br> `1.8.6 -> 3.3.0` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **586/1000** <br/> **Why?** Proof of Concept exploit, Has a fix available, CVSS 5.3 | Regular Expression Denial of Service (ReDoS) <br/>[SNYK-PYTHON-SPHINX-5812109](https://snyk.io/vuln/SNYK-PYTHON-SPHINX-5812109) | `sphinx:` <br> `1.8.6 -> 3.3.0` <br> | No | Proof of Concept ; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **384/1000** <br/> **Why?** Has a fix available, CVSS 3.4 | Open Redirect <br/>[SNYK-PYTHON-TORNADO-5537286](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-5537286) | `tornado:` <br> `5.1.1 -> 6.3.3` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **494/1000** <br/> **Why?** Has a fix available, CVSS 5.6 | HTTP Request Smuggling <br/>[SNYK-PYTHON-TORNADO-5840803](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-5840803) | `tornado:` <br> `5.1.1 -> 6.3.3` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13717:8116,avail,available,8116,https://hail.is,https://github.com/hail-is/hail/pull/13717,1,['avail'],['available']
Availability,"PYTHON-SPHINX-570773) | `sphinx:` <br> `1.8.6 -> 3.3.0` <br> | No | Mature ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **586/1000** <br/> **Why?** Proof of Concept exploit, Has a fix available, CVSS 5.3 | Regular Expression Denial of Service (ReDoS) <br/>[SNYK-PYTHON-SPHINX-5811865](https://snyk.io/vuln/SNYK-PYTHON-SPHINX-5811865) | `sphinx:` <br> `1.8.6 -> 3.3.0` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **586/1000** <br/> **Why?** Proof of Concept exploit, Has a fix available, CVSS 5.3 | Regular Expression Denial of Service (ReDoS) <br/>[SNYK-PYTHON-SPHINX-5812109](https://snyk.io/vuln/SNYK-PYTHON-SPHINX-5812109) | `sphinx:` <br> `1.8.6 -> 3.3.0` <br> | No | Proof of Concept ; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **384/1000** <br/> **Why?** Has a fix available, CVSS 3.4 | Open Redirect <br/>[SNYK-PYTHON-TORNADO-5537286](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-5537286) | `tornado:` <br> `5.1.1 -> 6.3.3` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **494/1000** <br/> **Why?** Has a fix available, CVSS 5.6 | HTTP Request Smuggling <br/>[SNYK-PYTHON-TORNADO-5840803](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-5840803) | `tornado:` <br> `5.1.1 -> 6.3.3` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **539/1000** <br/> **Why?** Has a fix available, CVSS 6.5 | HTTP Request Smuggling <br/>[SNYK-PYTHON-TORNADO-6041512](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-6041512) | `tornado:` <br> `5.1.1 -> 6.3.3` <br> | No | No Known Exploit ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14108:8151,avail,available,8151,https://hail.is,https://github.com/hail-is/hail/pull/14108,2,['avail'],['available']
Availability,Pending confirmation from Ben W. that this is indeed a user error...,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10645:60,error,error,60,https://hail.is,https://github.com/hail-is/hail/pull/10645,1,['error'],['error']
Availability,Place mendel error output in state / annotations,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/597:13,error,error,13,https://hail.is,https://github.com/hail-is/hail/issues/597,1,['error'],['error']
Availability,"Plus better error checking!. - Some bioinformatic tools expect a secondary implied file to be present. For example, sample.vcf and it's index file sample.vcf.tbi. This PR adds file localization such that if any file in a resource group is used, the entire resource group will be copied and not just the mentioned file. - Added a mentioned set that tracks whether a resource was defined in the command or declare resource group functions. Otherwise, you could do something like this which would throw an error upon execution:. ```python; p = Pipeline(); t = p.new_task(); p.write_output(t.undefined_variable, 'gs://foo/foo'); p.run(); ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5455:12,error,error,12,https://hail.is,https://github.com/hail-is/hail/pull/5455,2,['error'],['error']
Availability,"Plus:; - Boolean ldc (load constant) instructions need an int, not a boolean. JVM seems OK with it, but the asm bytecode verifier rejects it.; - In Apply codegen, the zip in function lookup was potentially truncating the arguments, selecting an incorrect function. Fix, and simplify the definition of `methods`.; - Fix/simplify asm error reporting from asm in lir Emit. The old code was crashing inside asm. I used the new code to debug some bytecode issues, it works well.; - compute max locals/stack, needed by the asm verifier (CheckClass). @konradjk This fixes your class not found issue.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8537:332,error,error,332,https://hail.is,https://github.com/hail-is/hail/pull/8537,1,['error'],['error']
Availability,"Pool$.scoped(RegionPool.scala:17); 	at is.hail.backend.ExecuteContext$.scoped(ExecuteContext.scala:59); 	at is.hail.backend.spark.SparkBackend.withExecuteContext(SparkBackend.scala:339); 	at is.hail.backend.spark.SparkBackend.$anonfun$executeEncode$1(SparkBackend.scala:483); 	at is.hail.utils.ExecutionTimer$.time(ExecutionTimer.scala:52); 	at is.hail.backend.spark.SparkBackend.executeEncode(SparkBackend.scala:482); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:282); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:238); 	at java.lang.Thread.run(Thread.java:750). Hail version: 0.2.107-2387bb00ceee; Error summary: SparkException: Job aborted due to stage failure: Task 0 in stage 1.0 failed 4 times, most recent failure: Lost task 0.4 in stage 1.0 (TID 10) (all-of-us-1774-w-0.c.terra-vpc-sc-23dfb1a3.internal executor 7): ExecutorLostFailure (executor 7 exited caused by one of the running tasks) Reason: Container from a bad node: container_e01_1690206305672_0001_01_000007 on host: all-of-us-1774-w-0.c.terra-vpc-sc-23dfb1a3.internal. Exit status: 137. Diagnostics: [2023-07-24 13:52:49.515]Container killed on request. Exit code is 137; [2023-07-24 13:52:49.517]Container exited with a non-zero exit code 137. ; [2023-07-24 13:52:49.518]Killed by external signal; .; Driver stacktrace:; ```; [hail-20230724-1347-0.2.107-2387bb00ceee.log](https://github.com/hail-is/hail/files/12146671/hail-20230724-1347-0.2.107-2387bb00ceee.log)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13287:12193,Error,Error,12193,https://hail.is,https://github.com/hail-is/hail/issues/13287,3,"['Error', 'failure']","['Error', 'failure']"
Availability,"Posting with recommendation from @konradjk ; ### Hail version:; devel-2c596b7. ### What you did:; Creating a ClinVar matrixtable from a tsv and vep'ing. ```; import hail as hl; import hail.expr.aggregators as agg; from gnomad_hail import *; hl.init(). clinvar_ht= hl.import_table(""gs://gnomad-resources/clinvar/source/clinvar_alleles.single.b37.tsv.gz"", impute=True, missing='NA'); clinvar_ht = clinvar_ht.annotate(locus = hl.locus(clinvar_ht.chrom, clinvar_ht.pos),; alleles = hl.array({clinvar_ht.ref, clinvar_ht.alt})). clinvar_ht = clinvar_ht.key_by(clinvar_ht.locus, clinvar_ht.alleles); clinvar_mt = hl.MatrixTable.from_rows_table(clinvar_ht); clinvar_mt = split_multi_dynamic(clinvar_mt, left_aligned = False); clinvar_mt = clinvar_mt.repartition(100); clinvar_mt = clinvar_mt.key_rows_by(clinvar_mt.locus, clinvar_mt.alleles); clinvar_vep = hl.vep(clinvar_mt, vep_config); ```. ### What went wrong (all error messages here, including the full java stack trace):; ```; In [6]: clinvar_vep = hl.vep(clinvar_mt, vep_config); 2018-03-08 02:46:03 Hail: WARN: property `hail.vep.assembly' not specified. Setting to GRCh37; [Stage 22:======================================================>(99 + 1) / 100]2018-03-08 02:54:37 Hail: INFO: vep: annotated 243477 variants; ---------------------------------------------------------------------------; FatalError Traceback (most recent call last); <ipython-input-6-a229f1f9de81> in <module>(); ----> 1 clinvar_vep = hl.vep(clinvar_mt, vep_config). <decorator-gen-843> in vep(dataset, config, block_size, name, csq). /hadoop_gcs_connector_metadata_cache/hail/hail-devel-0c961806173f.zip/hail/typecheck/check.py in _typecheck(__orig_func__, *args, **kwargs); 491 def _typecheck(__orig_func__, *args, **kwargs):; 492 args_, kwargs_ = check_all(__orig_func__, args, kwargs, checkers, is_method=False); --> 493 return __orig_func__(*args_, **kwargs_); 494; 495 return decorator(_typecheck). /hadoop_gcs_connector_metadata_cache/hail/hail-devel-0c961806173f.zip/h",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3099:911,error,error,911,https://hail.is,https://github.com/hail-is/hail/issues/3099,1,['error'],['error']
Availability,"Previously we get a stack trace without the http response body. I tested this; locally on a branch that does not exist:. # hailctl dev deploy --branch danking/hail:shuffler-deploymefdsafdsa --steps test_shuffler; HTTP Response code was 400; error finding {""repo"": {""owner"": ""danking"", ""name"": ""hail""}, ""name"": ""shuffler-deploymefdsafdsa""} at GitHub",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8846:241,error,error,241,https://hail.is,https://github.com/hail-is/hail/pull/8846,1,['error'],['error']
Availability,"Previously, accidentally passing an empty string to the list of missing values throws an inscrutable assertion error. This checks in python.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11078:111,error,error,111,https://hail.is,https://github.com/hail-is/hail/pull/11078,1,['error'],['error']
Availability,"Previously, if you did:. ```; x = hl.bool(True); if x:; ....; ```. You'd get a message like: ""Expressions do not have a static length"", because in Python, truthiness is resolved by first checking if `__bool__` is defined, then checking if `__len__` is nonzero. This PR gives a better message suggesting that the user has in some way tried to coerce an `Expression` into a bool, and only shows the other error if someone does something that specifically needs the length.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10741:403,error,error,403,https://hail.is,https://github.com/hail-is/hail/pull/10741,1,['error'],['error']
Availability,"Previously, when we did `hl.agg.group_by(group_expr, aggregation_expr)`, we were only tracking the indices picked up from the `aggregation_expr`. This led to us throwing bad error messages.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9570:174,error,error,174,https://hail.is,https://github.com/hail-is/hail/pull/9570,1,['error'],['error']
Availability,Print VEP stderr in error message if VEP fails,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4767:20,error,error,20,https://hail.is,https://github.com/hail-is/hail/issues/4767,1,['error'],['error']
Availability,Print a whole traceback on build error page,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6778:33,error,error,33,https://hail.is,https://github.com/hail-is/hail/pull/6778,1,['error'],['error']
Availability,Print lhs on out of bounds error on [] in expr language. Also throwing a FatalException will distinguish bugs on our end vs bugs in user expressions.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2921:27,error,error,27,https://hail.is,https://github.com/hail-is/hail/issues/2921,1,['error'],['error']
Availability,"Prior to Kubernetes 1.24, when a `ServiceAccount` called `sa-foo` is created, a corresponding `Secret` containing a token for the service account is created call `sa-foo-token-xxxx`. The `ServiceAccount` resource contains the name of the corresponding secret, and to use the service account in Batch the batch-driver discovers the secret name from the service account resource. In [Kubernetes >=1.24](https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG/CHANGELOG-1.24.md#urgent-upgrade-notes), creating a `ServiceAccount` no longer automatically creates a corresponding token secret. Our cluster auto-upgraded and PRs are failing because batch cannot find the secret field in the service account resource for SAs in test namespaces. From here on out, we need to make those token secrets ourselves. I explicitly added a token secret for the service accounts that need it and changed the batch-driver to handle both old and new service accounts. I tested this in my own project since I already had an instance of Hail Batch / CI up and running. It was running on 1.23 so did not encounter this issue, but I:; 1. Upgraded the cluster to 1.24; 2. Dev deployed and received the same error that we're now seeing in [PRs](https://ci.hail.is/batches/7103889/jobs/14); 3. Manually redeployed batch and CI (from this branch); 4. Dev deployed successfully",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12745:1189,error,error,1189,https://hail.is,https://github.com/hail-is/hail/pull/12745,1,['error'],['error']
Availability,"Produces better error messages, and allows for deeply nested; conversion if we want to do that.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3158:16,error,error,16,https://hail.is,https://github.com/hail-is/hail/pull/3158,1,['error'],['error']
Availability,Properly print full stacktrace on error.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/612:34,error,error,34,https://hail.is,https://github.com/hail-is/hail/pull/612,1,['error'],['error']
Availability,"Proposed fix for https://github.com/hail-is/hail/issues/9833. Summary: fix run time error when a matrix table row has an empty struct. Example: `info` field below is an empty struct; ```; ----------------------------------------; Global fields:; None; ----------------------------------------; Row fields:; 'locus': locus<GRCh38> ; 'alleles': array<str> ; 'rsid': str ; 'qual': float64 ; 'filters': set<str> ; 'info': struct {} ; ----------------------------------------; Key: ['locus', 'alleles']; ----------------------------------------; ```. The function `max` will throw this error; ```; ValueError: max() arg is an empty sequence; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9834:84,error,error,84,https://hail.is,https://github.com/hail-is/hail/pull/9834,2,['error'],['error']
Availability,"Provider Plugin and Credential Provider Config API's updated from v1alpha1 to v1beta1 with no API changes. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/108847"">kubernetes/kubernetes#108847</a>, <a href=""https://github.com/adisky""><code>@adisky</code></a>)</li>; <li>Make STS available replicas optional again. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/109241"">kubernetes/kubernetes#109241</a>, <a href=""https://github.com/ravisantoshgudimetla""><code>@ravisantoshgudimetla</code></a>)</li>; <li>MaxUnavailable for StatefulSets, allows faster RollingUpdate by taking down more than 1 pod at a time. The number of pods you want to take down during a RollingUpdate is configurable using maxUnavailable parameter. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/82162"">kubernetes/kubernetes#82162</a>, <a href=""https://github.com/krmayankk""><code>@krmayankk</code></a>)</li>; <li>Non-graceful node shutdown handling is enabled for stateful workload failovers (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/108486"">kubernetes/kubernetes#108486</a>, <a href=""https://github.com/sonasingh46""><code>@sonasingh46</code></a>)</li>; <li>Omit enum declarations from the static openapi file captured at <a href=""https://git.k8s.io/kubernetes/api/openapi-spec"">https://git.k8s.io/kubernetes/api/openapi-spec</a>. This file is used to generate API clients, and use of enums in those generated clients (rather than strings) can break forward compatibility with additional future values in those fields. See <a href=""https://issue.k8s.io/109177"">https://issue.k8s.io/109177</a> for details. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/109178"">kubernetes/kubernetes#109178</a>, <a href=""https://github.com/liggitt""><code>@liggitt</code></a>)</li>; <li>OpenAPI V3 is turned on by default (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pu",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12196:10212,failover,failovers,10212,https://hail.is,https://github.com/hail-is/hail/pull/12196,1,['failover'],['failovers']
Availability,Providing users with more helpful errors,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10655:34,error,errors,34,https://hail.is,https://github.com/hail-is/hail/pull/10655,1,['error'],['errors']
Availability,Push down `filtervariants interval --keep` queries into DAG construction,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1041:5,down,down,5,https://hail.is,https://github.com/hail-is/hail/pull/1041,1,['down'],['down']
Availability,Put an example of downloading logs from google cloud in `Hail on the Cloud`,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8005:18,down,downloading,18,https://hail.is,https://github.com/hail-is/hail/issues/8005,1,['down'],['downloading']
Availability,"Python API doesn't support lists like it claims. Should be on VariantDatasetFunctions, not VSM[T] (will cause class cast errors)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1511:121,error,errors,121,https://hail.is,https://github.com/hail-is/hail/issues/1511,1,['error'],['errors']
Availability,"Qin He reported that listing a folder containing around 50k files took 1h15. This new code takes ~16 seconds which is about how long it takes `gcloud storage ls`. There are two improvements:. 1. Use `bounded_gather2`. The use of a semaphore in `bounded_gather2`, which is missing from `bounded_gather`, allows it to be used recursively. In particular, suppose we had a semaphore of; 50. The outer `bounded_gather2` might need 20 slots to run its 20 paths in parallel. That leaves 30 slots of parallelism left over for its children. By passing the semaphore down, we let our children optimistically use some of that excess parallelism. 2. If we happen to have the `StatResult` for a particular object, we should never again look it up. In particular, getting the `StatResult` for every file in a directory can be done in O(1) requests. Getting the `StatResult` for each of those files individually (using their full paths) is necessarily O(N). If there was at least one glob and also there are no `suffix_components`, then we can use the `StatResult`s that we learned when checking the glog pattern. The latter point is perhaps a bit more clear with examples:. 1. `gs://foo/bar/baz`. Since there are no globs, we can make exactly one API request to list `gs://foo/bar/baz`. 2. `gs://foo/b*r/baz`. In this case, we must make one API request to list `gs://foo/`. This gives us a list of paths under that prefix. We check each path for conformance to the glob pattern `gs://foo/b*r`. For any path that matches, we must then list `<the matching path>/baz` which may itself be a directory containing files. Overall we make O(1) API requests to do the glob and then O(K) API requests to get the final `StatResult`s, where K is the number of paths matching the glob pattern. 3. `gs://foo/bar/b*z`. In this case, we must make one API request to list `gs://foo/bar/`. In `main`, we then throw away the `StatResult`s we got from that API request! Now we have to make O(K) requests to recover those `StatResult`s ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13253:557,down,down,557,https://hail.is,https://github.com/hail-is/hail/pull/13253,1,['down'],['down']
Availability,"R. - Changes to the following files to upgrade the vulnerable dependencies to a fixed version:; - web_common/pinned-requirements.txt. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **663/1000** <br/> **Why?** Proof of Concept exploit, Recently disclosed, Has a fix available, CVSS 5.4 | Improper Input Validation <br/>[SNYK-PYTHON-AIOHTTP-6091621](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-6091621) | `aiohttp:` <br> `3.8.6 -> 3.9.0` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **663/1000** <br/> **Why?** Proof of Concept exploit, Recently disclosed, Has a fix available, CVSS 5.4 | Improper Input Validation <br/>[SNYK-PYTHON-AIOHTTP-6091622](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-6091622) | `aiohttp:` <br> `3.8.6 -> 3.9.0` <br> | No | Proof of Concept . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI3ZTZiMDk2ZC0xYzc5LTQ2ZjctYjY5Ni0yNjFlM2QzYzU",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14036:1286,avail,available,1286,https://hail.is,https://github.com/hail-is/hail/pull/14036,1,['avail'],['available']
Availability,"RANSACTION:; TRANSACTION 1215034156, ACTIVE 0 sec inserting; mysql tables in use 6, locked 6; 22 lock struct(s), heap size 1136, 13 row lock(s), undo log entries 7; MySQL thread id 962349, OS thread handle 139741180090112, query id 6809294284 10.32.5.50 jigold update; INSERT INTO batch_inst_coll_cancellable_resources (batch_id, inst_coll, token, n_running_cancellable_jobs, running_cancellable_cores_mcpu); VALUES (OLD.batch_id, OLD.inst_coll, rand_token, -1, -OLD.cores_mcpu); ON DUPLICATE KEY UPDATE; n_running_cancellable_jobs = n_running_cancellable_jobs - 1,; running_cancellable_cores_mcpu = running_cancellable_cores_mcpu - OLD.cores_mcpu; *** (2) HOLDS THE LOCK(S):; RECORD LOCKS space id 1578686 page no 3 n bits 72 index PRIMARY of table `jigold`.`instances_free_cores_mcpu` trx id 1215034156 lock_mode X locks rec but not gap; Record lock, heap no 3 PHYSICAL RECORD: n_fields 4; compact format; info bits 0; 0: len 30; hex 62617463682d776f726b65722d6a69676f6c642d7374616e646172642d62; asc batch-worker-jigold-standard-b; (total 34 bytes);; 1: len 6; hex 0000486bf32c; asc Hk ,;;; 2: len 7; hex 600001287513cb; asc ` (u ;;; 3: len 4; hex 80002de6; asc - ;;. *** (2) WAITING FOR THIS LOCK TO BE GRANTED:; RECORD LOCKS space id 1578672 page no 3 n bits 272 index PRIMARY of table `jigold`.`batch_inst_coll_cancellable_resources` trx id 1215034156 lock_mode X locks rec but not gap waiting; Record lock, heap no 162 PHYSICAL RECORD: n_fields 10; compact format; info bits 0; 0: len 8; hex 8000000000000001; asc ;;; 1: len 8; hex 7374616e64617264; asc standard;;; 2: len 4; hex 80000020; asc ;;; 3: len 6; hex 0000486bf329; asc Hk );;; 4: len 7; hex 5d0000e7531a42; asc ] S B;;; 5: len 4; hex 7ffffff6; asc ;;; 6: len 8; hex 7ffffffffffff63c; asc <;;; 7: len 4; hex 7fffffff; asc ;;; 8: len 8; hex 7fffffffffffff06; asc ;;; 9: len 4; hex 80000000; asc ;;. *** WE ROLL BACK TRANSACTION (1); ```. We cannot separate these two changes out as the number of deadlock errors will actually increase.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11959:3810,error,errors,3810,https://hail.is,https://github.com/hail-is/hail/pull/11959,1,['error'],['errors']
Availability,"RCh38/Homo_sapiens.GRCh38.dna.toplevel.fa.gz --plugin LoF,loftee_path:/opt/vep/Plugins/,gerp_bigwig:/opt/vep/.vep/gerp_conservation_scores.homo_sapiens.GRCh38.bw,human_ancestor_fa:/opt/vep/.vep/human_ancestor.fa.gz,conservation_file:/opt/vep/.vep/loftee.sql --dir_plugins /opt/vep/Plugins/ -o STDOUT' failed with non-zero exit status 2; VEP Error output:; Smartmatch is experimental at /opt/vep/Plugins/de_novo_donor.pl line 175.; Smartmatch is experimental at /opt/vep/Plugins/de_novo_donor.pl line 214.; Smartmatch is experimental at /opt/vep/Plugins/splice_site_scan.pl line 191.; Smartmatch is experimental at /opt/vep/Plugins/splice_site_scan.pl line 194.; Smartmatch is experimental at /opt/vep/Plugins/splice_site_scan.pl line 238.; Smartmatch is experimental at /opt/vep/Plugins/splice_site_scan.pl line 241.; DBI connect('dbname=/opt/vep/.vep/loftee.sql','',...) failed: unable to open database file at /opt/vep/Plugins/LoF.pm line 126. -------------------- EXCEPTION --------------------; MSG: ERROR: No cache found for homo_sapiens, version 95. STACK Bio::EnsEMBL::VEP::CacheDir::dir /opt/vep/src/ensembl-vep/modules/Bio/EnsEMBL/VEP/CacheDir.pm:328; STACK Bio::EnsEMBL::VEP::CacheDir::init /opt/vep/src/ensembl-vep/modules/Bio/EnsEMBL/VEP/CacheDir.pm:227; STACK Bio::EnsEMBL::VEP::CacheDir::new /opt/vep/src/ensembl-vep/modules/Bio/EnsEMBL/VEP/CacheDir.pm:111; STACK Bio::EnsEMBL::VEP::AnnotationSourceAdaptor::get_all_from_cache /opt/vep/src/ensembl-vep/modules/Bio/EnsEMBL/VEP/AnnotationSourceAdaptor.pm:115; STACK Bio::EnsEMBL::VEP::AnnotationSourceAdaptor::get_all /opt/vep/src/ensembl-vep/modules/Bio/EnsEMBL/VEP/AnnotationSourceAdaptor.pm:91; STACK Bio::EnsEMBL::VEP::BaseRunner::get_all_AnnotationSources /opt/vep/src/ensembl-vep/modules/Bio/EnsEMBL/VEP/BaseRunner.pm:175; STACK Bio::EnsEMBL::VEP::Runner::init /opt/vep/src/ensembl-vep/modules/Bio/EnsEMBL/VEP/Runner.pm:123; STACK Bio::EnsEMBL::VEP::Runner::run /opt/vep/src/ensembl-vep/modules/Bio/EnsEMBL/VEP/Runner.pm:194; STACK ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14513:2190,ERROR,ERROR,2190,https://hail.is,https://github.com/hail-is/hail/issues/14513,4,['ERROR'],['ERROR']
Availability,"RDD.scala:346) at org.apache.spark.rdd.RDD.iterator(RDD.scala:310) at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90) at org.apache.spark.scheduler.Task.run(Task.scala:123) at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408) at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360) at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748). Spark Worker Logs (truncated to crash):. 2020-06-10 10:09:36 INFO ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 16 ms; 2020-06-10 10:09:36 INFO ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 17 ms; 2020-06-10 10:09:36 INFO ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 17 ms; 2020-06-10 10:09:36 INFO ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 17 ms; [thread 46926922934016 also had an error][thread 46922053207808 also had an error][thread 46926901880576 also had an error][thread 46926888195840 also had an error][thread 46926887143168 also had an error][thread 46924854015744 also had an error]; [thread 46924847699712 also had an error]. 	#. 	# A fatal error has been detected by the Java Runtime Environment:. 	[thread 46926905038592 also had an error]#; 	# ; 	[thread 46926895564544 also had an error][thread 46926900827904 also had an error]. 	SIGSEGV (0xb) at pc=0x00002aaab5115c88, pid=34051, tid=0x00002aae05d1a700; 	#; 	# JRE version: OpenJDK Runtime Environment (8.0_242-b08) (build 1.8.0_242-b08); 	# Java VM: OpenJDK 64-Bit Server VM (25.242-b08 mixed mode linux-amd64 compressed oops); 	# Problematic frame:; 	[thread 46926929250048 also had an error]# ; 	[thread 46926881888000 also had an error]; 	J 5583 C2 __C111CompiledWithAggs.__m131wrapped(Lis/hail/annotations/Region;J)V (280 bytes) @ 0x",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8944:18498,error,error,18498,https://hail.is,https://github.com/hail-is/hail/issues/8944,7,['error'],['error']
Availability,RDDOperationScope$.withScope(RDDOperationScope.scala:112); E at org.apache.spark.rdd.RDD.withScope(RDD.scala:362); E at org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:971); E at org.apache.spark.rdd.RDD$$anonfun$saveAsTextFile$2.apply$mcV$sp(RDD.scala:1507); E at org.apache.spark.rdd.RDD$$anonfun$saveAsTextFile$2.apply(RDD.scala:1495); E at org.apache.spark.rdd.RDD$$anonfun$saveAsTextFile$2.apply(RDD.scala:1495); E at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); E at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); E at org.apache.spark.rdd.RDD.withScope(RDD.scala:362); E at org.apache.spark.rdd.RDD.saveAsTextFile(RDD.scala:1495); E at is.hail.utils.richUtils.RichRDD$.writeTable$extension1(RichRDD.scala:77); E at is.hail.utils.richUtils.RichRDD$.writeTable$extension0(RichRDD.scala:38); E at is.hail.io.vcf.ExportVCF$.apply(ExportVCF.scala:453); E at is.hail.variant.VariantDatasetFunctions$.exportVCF$extension(VariantDataset.scala:425); E at is.hail.variant.VariantDatasetFunctions.exportVCF(VariantDataset.scala:425); E at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); E at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); E at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); E at java.lang.reflect.Method.invoke(Method.java:498); E at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); E at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); E at py4j.Gateway.invoke(Gateway.java:280); E at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); E at py4j.commands.CallCommand.execute(CallCommand.java:79); E at py4j.GatewayConnection.run(GatewayConnection.java:214); E at java.lang.Thread.run(Thread.java:748); E; E; E; E Hail version: 0.1-74bf1eb; E Error summary: ClassNotFoundException: Class org.apache.hadoop.mapred.DirectFileOutputCommitter not found; ```,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3946:15416,Error,Error,15416,https://hail.is,https://github.com/hail-is/hail/issues/3946,1,['Error'],['Error']
Availability,"ROAD.MIT.EDU/cvittal/src/hail-alt/hail/python/hail/matrixtable.py"", line 2569, in show; actual_n_cols = self.count_cols(); File ""</home/BROAD.MIT.EDU/cvittal/.cache/hail-env/lib/python3.6/site-packages/decorator.py:decorator-gen-994>"", line 2, in count_cols; File ""/home/BROAD.MIT.EDU/cvittal/src/hail-alt/hail/python/hail/typecheck/check.py"", line 585, in wrapper; return __original_func(*args_, **kwargs_); File ""/home/BROAD.MIT.EDU/cvittal/src/hail-alt/hail/python/hail/matrixtable.py"", line 2404, in count_cols; return Env.backend().execute(ir); File ""/home/BROAD.MIT.EDU/cvittal/src/hail-alt/hail/python/hail/backend/backend.py"", line 108, in execute; result = json.loads(Env.hc()._jhc.backend().executeJSON(self._to_java_ir(ir))); File ""/home/BROAD.MIT.EDU/cvittal/.local/opt/spark/spark-2.4.0-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py"", line 1257, in __call__; File ""/home/BROAD.MIT.EDU/cvittal/src/hail-alt/hail/python/hail/utils/java.py"", line 221, in deco; 'Error summary: %s' % (deepest, full, hail.__version__, deepest)) from None; hail.utils.java.FatalError: MatchError: locus<GRCh37> (of class is.hail.expr.types.virtual.TLocus). Java stack trace:; scala.MatchError: locus<GRCh37> (of class is.hail.expr.types.virtual.TLocus); 	at is.hail.expr.ir.ExtractIntervalFilters$.minimumValueByType(ExtractIntervalFilters.scala:42); 	at is.hail.expr.ir.ExtractIntervalFilters$.openInterval(ExtractIntervalFilters.scala:94); 	at is.hail.expr.ir.ExtractIntervalFilters$$anonfun$extractAndRewrite$6.apply(ExtractIntervalFilters.scala:205); 	at is.hail.expr.ir.ExtractIntervalFilters$$anonfun$extractAndRewrite$6.apply(ExtractIntervalFilters.scala:201); 	at scala.Option.flatMap(Option.scala:171); 	at is.hail.expr.ir.ExtractIntervalFilters$.extractAndRewrite(ExtractIntervalFilters.scala:201); 	at is.hail.expr.ir.ExtractIntervalFilters$.extractAndRewrite(ExtractIntervalFilters.scala:151); 	at is.hail.expr.ir.ExtractIntervalFilters$.extractPartitionFilters(ExtractIntervalF",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6458:2389,Error,Error,2389,https://hail.is,https://github.com/hail-is/hail/issues/6458,1,['Error'],['Error']
Availability,RR: https://github.com/hail-is/hail/issues/13045; RR: https://github.com/hail-is/hail/issues/13046 ; Support symmetric comparison of structs and struct expressions.; Provide better error messages when attempting to construct literals from expressions with free variables.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13226:181,error,error,181,https://hail.is,https://github.com/hail-is/hail/pull/13226,1,['error'],['error']
Availability,RR: https://github.com/hail-is/hail/issues/13261. Grouping asserts of distributed `BlockMatrix` queries via `BatchAssert` lead to repeated timeout failures during tests that used the batch-service backend.; This change removes all `BatchAssert`s from `test_linalg.py`. It uses `pytest.mark.parameterize` to gain parallelism in test execution from the test driver.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13348:147,failure,failures,147,https://hail.is,https://github.com/hail-is/hail/pull/13348,1,['failure'],['failures']
Availability,"RROR] [system.err] /tmp/testExportKT.tsv; 14:17:27.810 [ERROR] [system.err] merge time: 7.677ms; 14:17:28.591 [ERROR] [system.err] hail: info: Coerced sorted dataset; 14:17:30.368 [ERROR] [system.err] .hail: info: Coerced sorted dataset; 14:17:31.306 [ERROR] [system.err] ...; 14:17:31.904 [ERROR] [system.err] ==================================================================; 14:17:31.905 [ERROR] [system.err] ERROR: test_dataset (hail.tests.ContextTests); 14:17:31.905 [ERROR] [system.err] ----------------------------------------------------------------------; 14:17:31.905 [ERROR] [system.err] Traceback (most recent call last):; 14:17:31.905 [ERROR] [system.err] File ""/scratch/PI/dpwall/computeEnvironments/hail/python/hail/tests.py"", line 181, in test_dataset; 14:17:31.906 [ERROR] [system.err] sample2.grm('gcta-grm-bin', '/tmp/sample2.grm'); 14:17:31.906 [ERROR] [system.err] File ""/scratch/PI/dpwall/computeEnvironments/hail/python/hail/dataset.py"", line 1988, in grm; 14:17:31.906 [ERROR] [system.err] self.hc._run_command(self, pargs); 14:17:31.906 [ERROR] [system.err] File ""/scratch/PI/dpwall/computeEnvironments/hail/python/hail/context.py"", line 90, in _run_command; 14:17:31.907 [ERROR] [system.err] raise_py4j_exception(e); 14:17:31.907 [ERROR] [system.err] File ""/scratch/PI/dpwall/computeEnvironments/hail/python/hail/java.py"", line 87, in raise_py4j_exception; 14:17:31.907 [ERROR] [system.err] raise FatalError(msg, e.java_exception); 14:17:31.908 [ERROR] [system.err] FatalError: NoSuchMethodError: breeze.linalg.DenseVector$.canSetD()Lbreeze/generic/UFunc$InPlaceImpl2;; 14:17:31.908 [ERROR] [system.err]; 14:17:31.908 [ERROR] [system.err] ----------------------------------------------------------------------; 14:17:31.908 [ERROR] [system.err] Ran 7 tests in 83.523s. I noticed that a previous issue #209 from early last year had the exact same issue in a different context where the function `breeze.linalg.DenseVector$.canSetD()Lbreeze/generic/UFunc$InPlaceImpl2;` didn'",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1419:1332,ERROR,ERROR,1332,https://hail.is,https://github.com/hail-is/hail/issues/1419,1,['ERROR'],['ERROR']
Availability,"RSERVER-5862882](https://snyk.io/vuln/SNYK-PYTHON-JUPYTERSERVER-5862882) | `jupyter-server:` <br> `1.24.0 -> 2.7.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **509/1000** <br/> **Why?** Has a fix available, CVSS 5.9 | Regular Expression Denial of Service (ReDoS) <br/>[SNYK-PYTHON-SETUPTOOLS-3180412](https://snyk.io/vuln/SNYK-PYTHON-SETUPTOOLS-3180412) | `setuptools:` <br> `39.0.1 -> 65.5.1` <br> | No | No Known Exploit ; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **384/1000** <br/> **Why?** Has a fix available, CVSS 3.4 | Open Redirect <br/>[SNYK-PYTHON-TORNADO-5537286](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-5537286) | `tornado:` <br> `6.2 -> 6.3.3` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **494/1000** <br/> **Why?** Has a fix available, CVSS 5.6 | HTTP Request Smuggling <br/>[SNYK-PYTHON-TORNADO-5840803](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-5840803) | `tornado:` <br> `6.2 -> 6.3.3` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI2ZTAyYTQ3Zi02MzNlLTQ2MDUtYjM1OS1mN2RjOGIyMDk1YTYiLCJldmVudCI6IlBSIHZpZXd",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13933:2880,avail,available,2880,https://hail.is,https://github.com/hail-is/hail/pull/13933,1,['avail'],['available']
Availability,"RSERVER-5862882](https://snyk.io/vuln/SNYK-PYTHON-JUPYTERSERVER-5862882) | `jupyter-server:` <br> `1.24.0 -> 2.7.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **509/1000** <br/> **Why?** Has a fix available, CVSS 5.9 | Regular Expression Denial of Service (ReDoS) <br/>[SNYK-PYTHON-SETUPTOOLS-3180412](https://snyk.io/vuln/SNYK-PYTHON-SETUPTOOLS-3180412) | `setuptools:` <br> `39.0.1 -> 65.5.1` <br> | No | No Known Exploit ; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **384/1000** <br/> **Why?** Has a fix available, CVSS 3.4 | Open Redirect <br/>[SNYK-PYTHON-TORNADO-5537286](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-5537286) | `tornado:` <br> `6.2 -> 6.3.3` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **494/1000** <br/> **Why?** Has a fix available, CVSS 5.6 | HTTP Request Smuggling <br/>[SNYK-PYTHON-TORNADO-5840803](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-5840803) | `tornado:` <br> `6.2 -> 6.3.3` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI3NTkyMDJiMS1hZTUwLTQxMjUtYjNhNS1iZjFmOTM3NTU1YWMiLCJldmVudCI6IlBSIHZpZXd",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13836:2880,avail,available,2880,https://hail.is,https://github.com/hail-is/hail/pull/13836,1,['avail'],['available']
Availability,"RSERVER-5862882](https://snyk.io/vuln/SNYK-PYTHON-JUPYTERSERVER-5862882) | `jupyter-server:` <br> `1.24.0 -> 2.7.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **509/1000** <br/> **Why?** Has a fix available, CVSS 5.9 | Regular Expression Denial of Service (ReDoS) <br/>[SNYK-PYTHON-SETUPTOOLS-3180412](https://snyk.io/vuln/SNYK-PYTHON-SETUPTOOLS-3180412) | `setuptools:` <br> `39.0.1 -> 65.5.1` <br> | No | No Known Exploit ; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **384/1000** <br/> **Why?** Has a fix available, CVSS 3.4 | Open Redirect <br/>[SNYK-PYTHON-TORNADO-5537286](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-5537286) | `tornado:` <br> `6.2 -> 6.3.3` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **494/1000** <br/> **Why?** Has a fix available, CVSS 5.6 | HTTP Request Smuggling <br/>[SNYK-PYTHON-TORNADO-5840803](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-5840803) | `tornado:` <br> `6.2 -> 6.3.3` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJkMzg0ZDAwZS1iMThiLTQxYmMtODcxZi00Y2YyYTU3YWQ5MzgiLCJldmVudCI6IlBSIHZpZXd",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13718:2812,avail,available,2812,https://hail.is,https://github.com/hail-is/hail/pull/13718,1,['avail'],['available']
Availability,"RSERVER-5862882](https://snyk.io/vuln/SNYK-PYTHON-JUPYTERSERVER-5862882) | `jupyter-server:` <br> `1.24.0 -> 2.7.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **509/1000** <br/> **Why?** Has a fix available, CVSS 5.9 | Regular Expression Denial of Service (ReDoS) <br/>[SNYK-PYTHON-SETUPTOOLS-3180412](https://snyk.io/vuln/SNYK-PYTHON-SETUPTOOLS-3180412) | `setuptools:` <br> `39.0.1 -> 65.5.1` <br> | No | No Known Exploit ; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **384/1000** <br/> **Why?** Has a fix available, CVSS 3.4 | Open Redirect <br/>[SNYK-PYTHON-TORNADO-5537286](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-5537286) | `tornado:` <br> `6.2 -> 6.3.3` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **494/1000** <br/> **Why?** Has a fix available, CVSS 5.6 | HTTP Request Smuggling <br/>[SNYK-PYTHON-TORNADO-5840803](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-5840803) | `tornado:` <br> `6.2 -> 6.3.3` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **496/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 4.2 | Information Exposure Through Sent Data <br/>[SNYK-PYTHON-URLLIB3-6002459](https://snyk.io/vuln/SNYK-PYTHON-URLLIB3-6002459) | `urllib3:` <br> `1.26.17 -> 1.26.18` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13873:2880,avail,available,2880,https://hail.is,https://github.com/hail-is/hail/pull/13873,1,['avail'],['available']
Availability,"RSERVER-5862882](https://snyk.io/vuln/SNYK-PYTHON-JUPYTERSERVER-5862882) | `jupyter-server:` <br> `1.24.0 -> 2.7.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **509/1000** <br/> **Why?** Has a fix available, CVSS 5.9 | Regular Expression Denial of Service (ReDoS) <br/>[SNYK-PYTHON-SETUPTOOLS-3180412](https://snyk.io/vuln/SNYK-PYTHON-SETUPTOOLS-3180412) | `setuptools:` <br> `39.0.1 -> 65.5.1` <br> | No | No Known Exploit ; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **384/1000** <br/> **Why?** Has a fix available, CVSS 3.4 | Open Redirect <br/>[SNYK-PYTHON-TORNADO-5537286](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-5537286) | `tornado:` <br> `6.2 -> 6.3.3` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **494/1000** <br/> **Why?** Has a fix available, CVSS 5.6 | HTTP Request Smuggling <br/>[SNYK-PYTHON-TORNADO-5840803](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-5840803) | `tornado:` <br> `6.2 -> 6.3.3` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **539/1000** <br/> **Why?** Has a fix available, CVSS 6.5 | HTTP Request Smuggling <br/>[SNYK-PYTHON-TORNADO-6041512](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-6041512) | `tornado:` <br> `6.2 -> 6.3.3` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:**",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14026:2921,avail,available,2921,https://hail.is,https://github.com/hail-is/hail/pull/14026,1,['avail'],['available']
Availability,RVD physical key bug: assertion error if physical key field is not part of requested type,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4874:32,error,error,32,https://hail.is,https://github.com/hail-is/hail/issues/4874,1,['error'],['error']
Availability,RVD$$anonfun$orderedJoin$1.apply(KeyedOrderedRVD.scala:56); 	at is.hail.sparkextras.ContextRDD$$anonfun$czipPartitions$1$$anonfun$apply$26.apply(ContextRDD.scala:357); 	at is.hail.sparkextras.ContextRDD$$anonfun$czipPartitions$1$$anonfun$apply$26.apply(ContextRDD.scala:357); 	at is.hail.sparkextras.ContextRDD$$anonfun$cmapPartitionsWithIndex$1$$anonfun$apply$22$$anonfun$apply$23.apply(ContextRDD.scala:310); 	at is.hail.sparkextras.ContextRDD$$anonfun$cmapPartitionsWithIndex$1$$anonfun$apply$22$$anonfun$apply$23.apply(ContextRDD.scala:310); 	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$21$$anon$3.hasNext(OrderedRVD.scala:1015); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); 	at is.hail.utils.package$.getIteratorSizeWithMaxN(package.scala:357); 	at is.hail.sparkextras.ContextRDD$$anonfun$12.apply(ContextRDD.scala:444); 	at is.hail.sparkextras.ContextRDD$$anonfun$12.apply(ContextRDD.scala:444); 	at is.hail.sparkextras.ContextRDD$$anonfun$runJob$1.apply(ContextRDD.scala:471); 	at is.hail.sparkextras.ContextRDD$$anonfun$runJob$1.apply(ContextRDD.scala:469); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2062); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2062); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Hail version: devel-eb5d13fe97fc; Error summary: HailException: OrderedRVD error! Unexpected PK in partition 1; Range bounds for partition 1: ([bar]-[foo]]; Invalid PK: [quam]; Full key: [quam],MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4055:13131,Error,Error,13131,https://hail.is,https://github.com/hail-is/hail/issues/4055,2,"['Error', 'error']","['Error', 'error']"
Availability,RVD.scala:736); at is.hail.rvd.OrderedRVD$$anonfun$apply$6$$anon$5.next(OrderedRVD.scala:730); at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); at is.hail.rvd.OrderedRVD$$anonfun$apply$6$$anon$5.next(OrderedRVD.scala:736); at is.hail.rvd.OrderedRVD$$anonfun$apply$6$$anon$5.next(OrderedRVD.scala:730); at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); at scala.collection.Iterator$class.foreach(Iterator.scala:893); at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); at scala.collection.TraversableOnce$class.foldLeft(TraversableOnce.scala:157); at scala.collection.AbstractIterator.foldLeft(Iterator.scala:1336); at scala.collection.TraversableOnce$class.aggregate(TraversableOnce.scala:214); at scala.collection.AbstractIterator.aggregate(Iterator.scala:1336); at org.apache.spark.rdd.RDD$$anonfun$aggregate$1$$anonfun$22.apply(RDD.scala:1113); at org.apache.spark.rdd.RDD$$anonfun$aggregate$1$$anonfun$22.apply(RDD.scala:1113); at org.apache.spark.SparkContext$$anonfun$33.apply(SparkContext.scala:2118); at org.apache.spark.SparkContext$$anonfun$33.apply(SparkContext.scala:2118); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:108); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748). Hail version: devel-6bb4670; Error summary: AssertionError: assertion failed; ERROR: (gcloud.dataproc.jobs.submit.pyspark) Job [b09ec92a-49f4-4d16-ad6d-efc5a5805e92] entered state [ERROR] while waiting for [DONE].; Submitting to cluster 'robert1'...; gcloud command:; gcloud dataproc jobs submit pyspark hail2/05_variant_qc.py \; --cluster=robert1 \; --files= \; --properties= \; -- \; onep; ```,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3063:21953,Error,Error,21953,https://hail.is,https://github.com/hail-is/hail/issues/3063,3,"['ERROR', 'Error']","['ERROR', 'Error']"
Availability,"Rahul reported this failing on the following gnomad pipeline:. ```; import hail as hl; from gnomad.utils.vep import process_consequences; from gnomad.resources.grch37 import gnomad. gnomad_v2_exomes = gnomad.public_release(""exomes""); ht_exomes = gnomad_v2_exomes.ht(); ht_exomes_proc = process_consequences(ht_exomes); ht_exomes_proc._force_count(); ```. No test case included, but this kind of error will be impossible soon; (when requiredness exists on EmitType, not SType/PType).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10286:395,error,error,395,https://hail.is,https://github.com/hail-is/hail/pull/10286,1,['error'],['error']
Availability,Raise expression error for misuse of filter/explode without aggregation,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5110:17,error,error,17,https://hail.is,https://github.com/hail-is/hail/pull/5110,1,['error'],['error']
Availability,"Ran hit this with a typo in --num-workers. We just exited, instead of calling google or returning an error.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7717:101,error,error,101,https://hail.is,https://github.com/hail-is/hail/pull/7717,1,['error'],['error']
Availability,"Rather than letting Breeze throw a SingularMatrixException, we should check for dependence and give an informative error message. The most common mistakes leading to dependence are accidentally including the same covariate twice (identical columns) or encoding a categorical variable with n categories using n rather than n - 1 covariates (since the model has an intercept term, this creates linear relation. We might also consider automating this encoding).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1156:115,error,error,115,https://hail.is,https://github.com/hail-is/hail/issues/1156,1,['error'],['error']
Availability,Readable error messages for command-line filtering,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/84:9,error,error,9,https://hail.is,https://github.com/hail-is/hail/issues/84,1,['error'],['error']
Availability,Reading Matrix table error: Parsed JSON values do not match with class constructor,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5744:21,error,error,21,https://hail.is,https://github.com/hail-is/hail/issues/5744,1,['error'],['error']
Availability,Reading a table as a matrixtable produces a bad error:,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3089:48,error,error,48,https://hail.is,https://github.com/hail-is/hail/issues/3089,1,['error'],['error']
Availability,Reading datasets with custom reference genomes throws an error if reference wasn't already predefined in python,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6907:57,error,error,57,https://hail.is,https://github.com/hail-is/hail/issues/6907,1,['error'],['error']
Availability,"Reading function/contexts from GCS on query workers can contribute a significant portion of the runtime for small jobs. For a simple query like `hl.utils.range_table(10).collect()`, the jobs in the batch can range in time from 5-9 seconds depending on GCS latency. This builds on #9484 to add write-through capability to `memory` and a `ServiceCacheableFS` in Scala. The cacheable FS reads/writes through `memory` and falls back to GCS, so in the good path the ServiceBackend writes the compiled function and contexts to `memory`, workers read inputs and write outputs exclusively from/to memory, from which the ServiceBackend reads the results. From small benchmarks in dev, this cuts down read times on the workers by ~30-40% compared to the worst case GCS latencies and roughly matches the current implementation in the best case. Writing the outputs is comparable to writing through an already warmed up GCS connection.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10315:686,down,down,686,https://hail.is,https://github.com/hail-is/hail/pull/10315,1,['down'],['down']
Availability,"Realized that the notebook python app should in fact speak https because it is exposed on the pod even though it does not have a service in front of it. For example, prometheus scrapes all visible ports on a pod and it anticipates https. This was triggering the deluge of errors from notebook and deploying this into default seems to have stopped them.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10250:272,error,errors,272,https://hail.is,https://github.com/hail-is/hail/pull/10250,1,['error'],['errors']
Availability,"Recent log demonstrating the failure: https://cloudlogging.app.goo.gl/ayiTFRnkLdrSzY2j7. In retrospect this seems kind of obvious. Consider `JVMEntryway`. The first `log` statement occurs on line 98 (the line after we set the filename). I think, in my head, the Appender would be created when we initialized the Logger on line 17. That's apparently incorrect. The Appender is lazily created when some internal buffer fills and the logger flushes that buffer. That internal buffer is most likely to fill on the `log.error` lines because they dump a (large) stack trace to the log. That's why we always see the error there. The fix is simple: we track the currently desired output filename and, if we happen to create an appender *after* someone has called `changeFileInAllAppenders`, we initialize that new appender with the filename. This change ensures that, except for a short period during start up, there is always a valid filename. That short period is just the time between the JVM starting, allocating a `JVMEntryway`, calling `main` and getting to line 97. During that time, we carefully use `System.err.println` (not a logger) if something goes wrong.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13664:29,failure,failure,29,https://hail.is,https://github.com/hail-is/hail/pull/13664,3,"['error', 'failure']","['error', 'failure']"
Availability,"Ref:; apiVersion: v1; fieldPath: status.podIP; - name: POD_NAME; valueFrom:; fieldRef:; apiVersion: v1; fieldPath: metadata.name; image: gcr.io/hail-vdc/ci-intermediate:oyyg6y2um4kx; imagePullPolicy: IfNotPresent; name: main; resources:; requests:; cpu: 100m; memory: 500M; terminationMessagePath: /dev/termination-log; terminationMessagePolicy: File; volumeMounts:; - mountPath: /test-gsa-key; name: test-gsa-key; - mountPath: /gsa-key; name: gsa-key; - mountPath: /var/run/secrets/kubernetes.io/serviceaccount; name: default-token-8h99c; readOnly: true; dnsPolicy: ClusterFirst; enableServiceLinks: true; nodeName: gke-vdc-preemptible-pool-9c7148b2-1f89; priority: 500000; priorityClassName: user; restartPolicy: Never; schedulerName: default-scheduler; securityContext: {}; serviceAccount: default; serviceAccountName: default; terminationGracePeriodSeconds: 30; tolerations:; - key: preemptible; value: ""true""; - effect: NoExecute; key: node.kubernetes.io/not-ready; operator: Exists; tolerationSeconds: 300; - effect: NoExecute; key: node.kubernetes.io/unreachable; operator: Exists; tolerationSeconds: 300; volumes:; - name: test-gsa-key; secret:; defaultMode: 420; optional: false; secretName: test-gsa-key; - name: gsa-key; secret:; defaultMode: 420; secretName: ci-gsa-key; - name: default-token-8h99c; secret:; defaultMode: 420; secretName: default-token-8h99c; status:; conditions:; - lastProbeTime: null; lastTransitionTime: ""2019-07-12T17:17:15Z""; status: ""True""; type: Initialized; - lastProbeTime: null; lastTransitionTime: ""2019-07-12T17:17:15Z""; message: 'containers with unready status: [main]'; reason: ContainersNotReady; status: ""False""; type: Ready; - lastProbeTime: null; lastTransitionTime: ""2019-07-12T17:17:15Z""; message: 'containers with unready status: [main]'; reason: ContainersNotReady; status: ""False""; type: ContainersReady; - lastProbeTime: null; lastTransitionTime: ""2019-07-12T17:17:15Z""; status: ""True""; type: PodScheduled; containerStatuses:; - image: gcr.io/hail",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6625:4441,toler,tolerationSeconds,4441,https://hail.is,https://github.com/hail-is/hail/issues/6625,1,['toler'],['tolerationSeconds']
Availability,Refactor annotateVariantsTable. Annotate global table. Added extra key table method. checkpoint. Checkpoint. checkpoint before tests. Some of the docs. Passing tests. Fixed tutorial. Fix tutorial styling. Finish rebase. Fix rebase errors. Fix tests,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1687:85,checkpoint,checkpoint,85,https://hail.is,https://github.com/hail-is/hail/pull/1687,8,"['Checkpoint', 'checkpoint', 'error']","['Checkpoint', 'checkpoint', 'errors']"
Availability,"Refactors `Bindings` to return an object encoding the change to the environment (any new bindings, whether the agg/scan env is promoted, etc). This allows the deletion of `SegregatedBindingEnv`. Follow up work will use this to replace the other specializations of `GenericBindingEnv`, and to greatly simplify compiler passes, such as `NormalizeNames` and `PruneDeadFields`, which currently need to redundantly encode the binding structure of every node.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14496:398,redundant,redundantly,398,https://hail.is,https://github.com/hail-is/hail/pull/14496,1,['redundant'],['redundantly']
Availability,Regenie defaults to requesting 1 core. I also fixed some syntax errors in test_batch.py,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9470:64,error,errors,64,https://hail.is,https://github.com/hail-is/hail/pull/9470,1,['error'],['errors']
Availability,"Remarkably, this is just a warning, not an error.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1342:43,error,error,43,https://hail.is,https://github.com/hail-is/hail/pull/1342,1,['error'],['error']
Availability,Remove extra checkpoint from blanczos_pca,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9434:13,checkpoint,checkpoint,13,https://hail.is,https://github.com/hail-is/hail/pull/9434,1,['checkpoint'],['checkpoint']
Availability,"Remove the `Begin` node, as its behavior can now be represented by the `Let` node. Besides removing redundant nodes, this will also make the new ssa-style text representation simpler. The `Begin` node emmitter performed method splitting, emitting groups of 16 children in seperate methods. This preserves that behavior by doing a similar optimization in the `Let` emitter. This is a significant change in how we split generated code into methods, so we should watch out for how this affects things.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14068:100,redundant,redundant,100,https://hail.is,https://github.com/hail-is/hail/pull/14068,1,['redundant'],['redundant']
Availability,"Removes any occurences of async / sync / async nesting in the code, i.e. a coroutine should not involve somewhere deep down a synchronous call that blocks on the completion of an async task.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13677:119,down,down,119,https://hail.is,https://github.com/hail-is/hail/pull/13677,1,['down'],['down']
Availability,"Removes this error from the logs:. ```; Traceback (most recent call last):; --; File ""/usr/local/lib/python3.7/dist-packages/batch/resource_usage.py"", line 220, in periodically_measure; await self.measure(); File ""/usr/local/lib/python3.7/dist-packages/batch/resource_usage.py"", line 187, in measure; memory_usage_bytes = self.memory_usage_bytes(); File ""/usr/local/lib/python3.7/dist-packages/batch/resource_usage.py"", line 126, in memory_usage_bytes; return int(f.read().rstrip()); OSError: [Errno 19] No such device; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12752:13,error,error,13,https://hail.is,https://github.com/hail-is/hail/pull/12752,1,['error'],['error']
Availability,"Replicable bug:. ```; hail -b 0 importvcf src/test/resources/multipleChromosomes.vcf -n 10 exportvcf -o /tmp/out.vcf.bgz importvcf /tmp/out.vcf.bgz -n 10 count --genotypes. hail: count: caught exception: Job aborted due to stage failure: Task 4 in stage 0.0 failed 1 times, most recent failure: Lost task 4.0 in stage 0.0 (TID 4, localhost): htsjdk.samtools.SAMFormatException: Invalid GZIP header; at htsjdk.samtools.util.BlockGunzipper.unzipBlock(BlockGunzipper.java:72); at htsjdk.samtools.util.BlockCompressedInputStream.inflateBlock(BlockCompressedInputStream.java:410); at htsjdk.samtools.util.BlockCompressedInputStream.readBlock(BlockCompressedInputStream.java:392); at htsjdk.samtools.util.BlockCompressedInputStream.available(BlockCompressedInputStream.java:127); at org.seqdoop.hadoop_bam.util.BGZFSplitCompressionInputStream.readWithinBlock(BGZFSplitCompressionInputStream.java:81); at org.seqdoop.hadoop_bam.util.BGZFSplitCompressionInputStream.read(BGZFSplitCompressionInputStream.java:48); at java.io.InputStream.read(InputStream.java:101); at org.apache.hadoop.mapreduce.lib.input.CompressedSplitLineReader.fillBuffer(CompressedSplitLineReader.java:130); at org.apache.hadoop.util.LineReader.readDefaultLine(LineReader.java:216); at org.apache.hadoop.util.LineReader.readLine(LineReader.java:174); at org.apache.hadoop.mapreduce.lib.input.CompressedSplitLineReader.readLine(CompressedSplitLineReader.java:159); at org.apache.hadoop.mapred.LineRecordReader.<init>(LineRecordReader.java:134); at org.apache.hadoop.mapred.TextInputFormat.getRecordReader(TextInputFormat.java:67); at org.apache.spark.rdd.HadoopRDD$$anon$1.<init>(HadoopRDD.scala:239); at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:216); at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:101); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:297); at org.apache.spark.rdd.RDD.iterator(RDD.scala:264); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apac",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/566:229,failure,failure,229,https://hail.is,https://github.com/hail-is/hail/issues/566,3,"['avail', 'failure']","['available', 'failure']"
Availability,"Replicable with the following:. ```; ds = hc.read('gs://future-variant-calling/future-pipeline/future.vds'); ds.filter_rows(ds.v.num_alleles() == 2).count_rows(); ```. ```; Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 66 in stage 2.0 failed 20 times, most recent failure: Lost task 66.19 in stage 2.0 (TID 2061, tim-debug-sw-h2hs.c.broad-ctsa.internal): java.lang.AssertionError: assertion failed; 	at scala.Predef$.assert(Predef.scala:156); 	at is.hail.annotations.Region.loadInt(Region.scala:36); 	at is.hail.expr.types.TBinary$.loadLength(TBinary.scala:62); 	at is.hail.annotations.UnsafeRow$.readBinary(UnsafeRow.scala:128); 	at is.hail.annotations.UnsafeRow$.readString(UnsafeRow.scala:139); 	at is.hail.annotations.UnsafeRow$.readAltAllele(UnsafeRow.scala:152); 	at is.hail.annotations.UnsafeRow$.readArrayAltAllele(UnsafeRow.scala:164); 	at is.hail.annotations.UnsafeRow$.read(UnsafeRow.scala:210); 	at is.hail.annotations.UnsafeRow.get(UnsafeRow.scala:257); 	at is.hail.expr.FilterVariants$$anonfun$10.apply(Relational.scala:428); 	at is.hail.expr.FilterVariants$$anonfun$10.apply(Relational.scala:425); 	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:463); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$9$$anon$5.hasNext(OrderedRVD.scala:694); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$9$$anon$5.hasNext(OrderedRVD.scala:694); 	at scala.collection.Iterator$class.foreach(Iterator.scala:893); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$9$$anon$5.foreach(OrderedRVD.scala:691); 	at is.hail.methods.SampleQC$$anonfun$results$1.apply(SampleQC.scala:170); 	at is.hail.methods.SampleQC$$anonfun$results$1.apply(SampleQC.scala:166); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:785); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:785); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPa",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2803:250,failure,failure,250,https://hail.is,https://github.com/hail-is/hail/issues/2803,2,['failure'],['failure']
Availability,Reported by Theodore Wang [on Zulip](https://hail.zulipchat.com/#narrow/stream/123010-Hail-0.2E2.20support/subject/failure.20running.20recent.20builds.20of.20Hail.200.2E2).,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4105:115,failure,failure,115,https://hail.is,https://github.com/hail-is/hail/pull/4105,1,['failure'],['failure']
Availability,Requiredness mismatch throws error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4127:29,error,error,29,https://hail.is,https://github.com/hail-is/hail/issues/4127,1,['error'],['error']
Availability,"Requiredness stuff was assuming that tuples were well-ordered and contiguously indexed, which is wrong because the pruner can prune tuple elements. See https://discuss.hail.is/t/arrayindexoutofboundsexception-error-in-hail-0-2-40/1413/5",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8786:209,error,error-in-hail-,209,https://hail.is,https://github.com/hail-is/hail/pull/8786,1,['error'],['error-in-hail-']
Availability,Requirements.txt has spaces that causes errors,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12002:40,error,errors,40,https://hail.is,https://github.com/hail-is/hail/pull/12002,1,['error'],['errors']
Availability,Requires network requests -- I had to comment this out to build during a power outage :). Totally open to better ways to do this than converting it to a shell script -- this is not my expertise.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12616:79,outage,outage,79,https://hail.is,https://github.com/hail-is/hail/pull/12616,1,['outage'],['outage']
Availability,"Resolves #10747. I sshed into a VM and tried to do a clean install based on the issue raised above. As noted there, lz4 was missing from our cluster install docs. I also noticed `pip` returns a nonzero exit code if it tries to install something but doesn't find it, so I added some `|| true` to prevent a confusing error message. I also updated our examples to use Spark 3 by default.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10756:315,error,error,315,https://hail.is,https://github.com/hail-is/hail/pull/10756,1,['error'],['error']
Availability,Resolves #10843 . Now you'll see:. ```; Hail version: 0.2.74-467a12fcbef9; Error summary: HailException: No file or directory found at gs://hail-datasets-us/annotations/THIS_PATH_DOES_NOT_EXIST; ```. instead of the error about it not being a directory.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10847:75,Error,Error,75,https://hail.is,https://github.com/hail-is/hail/pull/10847,2,"['Error', 'error']","['Error', 'error']"
Availability,"Resolves error where exportVariants exported an Interval as `Interval(14:968765858,22:1565768082)` and import parser expects `14:968765858-22:1565768082`",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1538:9,error,error,9,https://hail.is,https://github.com/hail-is/hail/pull/1538,1,['error'],['error']
Availability,"Resource groups are permitted to use dashes, underscores, uppercase letters,; and probably other characters not permitted in storage account names. This; PR cahanges `bootstrap.sh` to:. 1. Ignore invalid characters in the resouce group. 2. Ensure (via randomness) that the generated name is unique. 3. Do not try to create a new storage account if `backend-config.tfvars` exists. I lightly tested this. Here is an example of how it sanitizes a resource group name:. ```; RESOURCE_GROUP=bu__ild-batch-worker-i32mage; possibly_invalid_storage_account_name=""$(cat /dev/urandom | LC_ALL=C tr -dc 0-9 | head -c 4)${RESOURCE_GROUP}""; STORAGE_ACCOUNT_NAME=$(LC_ALL=C tr -dc a-z0-9 <<< ""${possibly_invalid_storage_account_name}"" | head -c 24); echo $STORAGE_ACCOUNT_NAME; 7241buildbatchworkeri32m; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11313:736,echo,echo,736,https://hail.is,https://github.com/hail-is/hail/pull/11313,1,['echo'],['echo']
Availability,"Retry ALL requests with temporary failures. We might want to add more exceptions/status codes, but these seem like a good first cut. Also, don't cancel a batch that failed to submit. It shouldn't be cancellable unless it was closed (in case the submit block in question would have succeeded). At some point we should have something that cleans up unclosed batches after a while (e.g. 24hrs).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7215:34,failure,failures,34,https://hail.is,https://github.com/hail-is/hail/pull/7215,1,['failure'],['failures']
Availability,"Revert ""[batch] ensure batches are cancelled on error (#10762)""",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10976:48,error,error,48,https://hail.is,https://github.com/hail-is/hail/pull/10976,1,['error'],['error']
Availability,Reverts hail-is/hail#10693 while we inspect errors pulling large numbers of images at once.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10884:44,error,errors,44,https://hail.is,https://github.com/hail-is/hail/pull/10884,1,['error'],['errors']
Availability,Reverts hail-is/hail#11750. The code is still causing out of disk errors.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11968:66,error,errors,66,https://hail.is,https://github.com/hail-is/hail/pull/11968,1,['error'],['errors']
Availability,"Rewrite invocations of `hl.cond()` to `hl.if_else()`, `hl.null()` to `hl.missing()`, and `hl.zip_with_index()` to `hl.enumerate()`. Very minor, but a few of these appear in our test logs (and probably yours as well), which makes for noise when you're tracking down other problems in the logs:. ```; hail/methods/misc.py:437: DeprecationWarning: Call to deprecated function (or staticmethod) cond. (Replaced by hl.if_else) -- Deprecated since version 0.2.59.; hail/vds/methods.py:79: DeprecationWarning: Call to deprecated function (or staticmethod) zip_with_index. (Replaced by hl.enumerate) -- Deprecated since version 0.2.56.; hail/vds/methods.py:75: DeprecationWarning: Call to deprecated function (or staticmethod) null. (Replaced by hl.missing) -- Deprecated since version 0.2.62.; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13349:260,down,down,260,https://hail.is,https://github.com/hail-is/hail/pull/13349,1,['down'],['down']
Availability,Right now dependencies to include the in shadowJar are managed by hand and it is incredibly error prone. There has to be a better way to do this.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/577:92,error,error,92,https://hail.is,https://github.com/hail-is/hail/issues/577,1,['error'],['error']
Availability,"Right now, IR function registration fails in the following case.; - Multiple Python HailContexts are running on the same cluster; - User on HailContext A calls a function (eg. create histogram) that triggers `hl.experimental.define_function`; * An anonymous function is used to create a new `Set` in `IRFunctionRegistry.irRegistry`; - User on HailContext B calls the same function; * The anonymous function is added to create a `Set` of size `2` in `IRFunctionRegistry.irRegistry`, as anonymous functions are never considered equivalent; * This triggers a fatal error `Multiple functions found that satisfy ...`. By changing the definition of `IRFunctionRegistry.irRegistry` from a `MultiMap(functionName -> Set[argumentTypes, returnType, alwaysInline, anonymousFunction])` to a `Map(functionName -> Map((argumentTypes, returnType, alwaysInline) -> anonymousFunction))` , we ensure function registration is idempotent as we do not compare on the `anonymousFunction`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8123:562,error,error,562,https://hail.is,https://github.com/hail-is/hail/pull/8123,1,['error'],['error']
Availability,"Rori encountered some confusing output. _same is private, but this is good both for GVS/AoU and also for us. Things are indented properly, it uses as much terminal width as is available, the names are slightly less confusing, and we see both globals & row failures if both fail. ```python3; Table._same: rows differ:; Row mismatch at key=Struct(locus=Locus(contig=1, position=1, reference_genome=GRCh37), alleles=['A', 'C']):; Left:; [Struct(ancestral_af=0.381520365258488,; af=[0.6482459117152142],; __uid_entries_85=[Struct(GT=Call(alleles=[1, 1], phased=False)), Struct(GT=Call(alleles=[1, 1], phased=False))])]; Right:; [Struct(ancestral_af=0.381520365258488,; af=[0.2510276144176496],; __uid_entries_85=[Struct(GT=Call(alleles=[0, 0], phased=False)), Struct(GT=Call(alleles=[0, 1], phased=False))])]; Row mismatch at key=Struct(locus=Locus(contig=1, position=2, reference_genome=GRCh37), alleles=['A', 'C']):; Left:; [Struct(ancestral_af=0.7058845354840656,; af=[0.5224710728099119],; __uid_entries_85=[Struct(GT=Call(alleles=[0, 0], phased=False)), Struct(GT=Call(alleles=[0, 0], phased=False))])]; Right:; [Struct(ancestral_af=0.7058845354840656,; af=[0.5042641171983404],; __uid_entries_85=[Struct(GT=Call(alleles=[1, 1], phased=False)), Struct(GT=Call(alleles=[1, 1], phased=False))])]; ```. versus. ```python3; Table._same: rows differ:; Row mismatch at key=Struct(_key=Struct(locus=Locus(contig=1, position=1, reference_genome=GRCh37), alleles=['A', 'C'])):; Left:; [Struct(ancestral_af=0.381520365258488,; af=[0.08835032612615329],; __uid_39=[Struct(GT=Call(alleles=[0, 0], phased=False)),; Struct(GT=Call(alleles=[0, 0], phased=False))])]; Right:; [Struct(ancestral_af=0.381520365258488,; af=[0.6631710694002383],; __uid_39=[Struct(GT=Call(alleles=[0, 1], phased=False)),; Struct(GT=Call(alleles=[1, 1], phased=False))])]; Row mismatch at key=Struct(_key=Struct(locus=Locus(contig=1, position=2, reference_genome=GRCh37), alleles=['A', 'C'])):; Left:; [Struct(ancestral_af=0.7058845354840",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13825:176,avail,available,176,https://hail.is,https://github.com/hail-is/hail/pull/13825,2,"['avail', 'failure']","['available', 'failures']"
Availability,"Ruff linting the tests is not too hard, so I did it. I also looked at pyright/pylint, but the Hail package has way too many errors to make that feasible on a Friday night.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14159:124,error,errors,124,https://hail.is,https://github.com/hail-is/hail/pull/14159,1,['error'],['errors']
Availability,"Running a function like:; ```; def annotate_tx_expression_data(ht, tx_ht, location):; key = ht.key if isinstance(ht, hl.Table) else ht.row_key; return hl.find(lambda csq: (csq.ensg == location.gene_id) &; (csq.csq == location.most_severe_consequence),; tx_ht[key].tx_annotation); mt = mt.annotate_rows(expressed=annotate_tx_expression_data(mt, tx_ht, mt.lof_csqs).mean_expression > 0.1); mt.describe(); mt.group_rows_by(*list(annotation_expr.keys())).aggregate_rows(; classic_caf=hl.agg.sum(mt.freq[0].AF),; max_af=hl.agg.max(mt.freq[0].AF),; classic_caf_array=hl.agg.array_sum(mt.freq.map(lambda x: x.AF)); ).aggregate_entries(; num_homs=hl.agg.count_where(mt.GT.is_hom_var()),; num_hets=hl.agg.count_where(mt.GT.is_het()),; defined_sites=hl.agg.count_where(hl.is_defined(mt.GT)); ).result(); ```; errors out with `Error summary: AssertionError: assertion failed: ensg not in struct{mean_expression: float64}`. the describe shows that it's doing the right thing (`expressed` is a `bool`), but i'm guessing that since ensg is not strictly referred to except in a lambda, that it's getting pruned out?. Full log posted on zulip",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4754:799,error,errors,799,https://hail.is,https://github.com/hail-is/hail/issues/4754,2,"['Error', 'error']","['Error', 'errors']"
Availability,"Running on Apache Spark version 2.3.0; Hail version 0.2.12-9409c0635781. The follow error occurs when reading a matrix table. This code worked with Hail v2.8. ```; Traceback (most recent call last):; File ""/restricted/projectnb/ukbiobank/ad/analysis/ad.v1/ad_parent_linreg_all_races_one_over_60.py"", line 70, in <module>; mt=hl.read_matrix_table(mt_fn); File ""<decorator-gen-1219>"", line 2, in read_matrix_table; File ""/share/pkg.7/hail/0.2.12/install/hail/hail/build/distributions/hail-python.zip/hail/typecheck/check.py"", line 561, in wrapper; File ""/share/pkg.7/hail/0.2.12/install/hail/hail/build/distributions/hail-python.zip/hail/methods/impex.py"", line 1704, in read_matrix_table; File ""/share/pkg.7/hail/0.2.12/install/hail/hail/build/distributions/hail-python.zip/hail/matrixtable.py"", line 558, in __init__; File ""/share/pkg.7/hail/0.2.12/install/hail/hail/build/distributions/hail-python.zip/hail/ir/base_ir.py"", line 158, in typ; File ""/share/pkg.7/hail/0.2.12/install/hail/hail/build/distributions/hail-python.zip/hail/ir/matrix_ir.py"", line 40, in _compute_type; File ""/share/pkg.7/hail/0.2.12/install/hail/hail/build/distributions/hail-python.zip/hail/backend/backend.py"", line 104, in matrix_type; File ""/share/pkg.7/hail/0.2.12/install/hail/hail/build/distributions/hail-python.zip/hail/backend/backend.py"", line 87, in _to_java_ir; File ""/share/pkg.7/hail/0.2.12/install/hail/hail/build/distributions/hail-python.zip/hail/ir/base_ir.py"", line 163, in parse; File ""/share/pkg/spark/2.3.0/install/python/lib/py4j-0.10.6-src.zip/py4j/java_gateway.py"", line 1160, in __call__; File ""/share/pkg.7/hail/0.2.12/install/hail/hail/build/distributions/hail-python.zip/hail/utils/java.py"", line 227, in deco; hail.utils.java.FatalError: MappingException: Parsed JSON values do not match with class constructor; args=; arg types=; constructor=public is.hail.variant.AbstractMatrixTableSpec(). Java stack trace:; org.json4s.package$MappingException: Parsed JSON values do not match with class con",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5744:84,error,error,84,https://hail.is,https://github.com/hail-is/hail/issues/5744,1,['error'],['error']
Availability,"Running:; ```; def generate_downsamplings_cumulative(mt: hl.MatrixTable) -> Tuple[hl.MatrixTable, List[int]]:; pop_data = [x[0] for x in get_sample_data(mt, [mt.meta.pop])]; pops = Counter(pop_data); downsamplings = DOWNSAMPLINGS + list(pops.values()); downsamplings = sorted([x for x in downsamplings if x <= sum(pops.values())]); kt = mt.cols(); kt = kt.annotate(r=hl.rand_unif(0, 1)); kt = kt.order_by(kt.r).add_index('global_idx'). for i, pop in enumerate(pops):; pop_kt = kt.filter(kt.meta.pop == pop).add_index('pop_idx'); if not i:; global_kt = pop_kt; else:; global_kt = global_kt.union(pop_kt). return mt.annotate_cols(downsampling=global_kt[mt.s]), downsamplings. ```; Getting this. Guessing it's something with the ordering?; ```; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-8-0255aa65130d> in <module>(); 48 ; 49 if calculate_downsampling:; ---> 50 mt, downsamplings = generate_downsamplings_cumulative(mt); 51 print(f'Got {len(downsamplings)} downsamplings: {downsamplings}'); 52 cut_dict = {'pop': hl.agg.counter(hl.agg.filter(hl.is_defined(mt.meta.pop), mt.meta.pop)),. <ipython-input-8-0255aa65130d> in generate_downsamplings_cumulative(mt); 18 global_kt = pop_kt; 19 else:; ---> 20 global_kt = global_kt.union(pop_kt); 21 ; 22 return mt.annotate_cols(downsampling=global_kt[mt.s]), downsamplings. /home/hail/hail.zip/hail/typecheck/check.py in wrapper(*args, **kwargs); 545 def wrapper(*args, **kwargs):; 546 args_, kwargs_ = check_all(f, args, kwargs, checkers, is_method=is_method); --> 547 return f(*args_, **kwargs_); 548 ; 549 update_wrapper(wrapper, f). /home/hail/hail.zip/hail/table.py in union(self, *tables); 1718 f"" Expected: {self.row.dtype}\n""; 1719 f"" Table {i}: {ht.row.dtype}""); -> 1720 elif list(ht.key) != list(self.key):; 1721 raise TypeError(f""'union': table {i} has a different key.""; 1722 f"" Expected: {list(self.key)}\n"". TypeError: 'NoneType' object is not iterable; ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4080:200,down,downsamplings,200,https://hail.is,https://github.com/hail-is/hail/issues/4080,10,"['DOWN', 'down']","['DOWNSAMPLINGS', 'downsampling', 'downsamplings']"
Availability,"SB is a reserved INFO field in VCFs, and so downstream tools may; overwrite the header. SB_TABLE is more what we want and the header will; be correct for the datatype (array of 4 ints)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5400:44,down,downstream,44,https://hail.is,https://github.com/hail-is/hail/pull/5400,1,['down'],['downstream']
Availability,"SE (<a href=""https://github-redirect.dependabot.com/python/mypy/issues/12330"">#12330</a>)</li>; <li><a href=""https://github.com/python/mypy/commit/8650f5c2eedc26f11b6f5c35cf0c0d752aaf51fb""><code>8650f5c</code></a> stubgen: fix non default keyword-only argument positioning (<a href=""https://github-redirect.dependabot.com/python/mypy/issues/12303"">#12303</a>)</li>; <li><a href=""https://github.com/python/mypy/commit/226661f62f365102f5fd913b39b32ed3f12e208b""><code>226661f</code></a> Exhaustiveness checking for match statements (<a href=""https://github-redirect.dependabot.com/python/mypy/issues/12267"">#12267</a>)</li>; <li><a href=""https://github.com/python/mypy/commit/fce1b548be74f7c65f8e3645f2a2b46aeff0c5a8""><code>fce1b54</code></a> CI: Do not run mypy_primer on stubtest/stubgen PRs (<a href=""https://github-redirect.dependabot.com/python/mypy/issues/12295"">#12295</a>)</li>; <li><a href=""https://github.com/python/mypy/commit/c7a81620bef7585cca6905861bb7ef34ec12da2f""><code>c7a8162</code></a> stubtest: ignore more dunder positional-only errors (<a href=""https://github-redirect.dependabot.com/python/mypy/issues/12294"">#12294</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/python/mypy/compare/v0.780...v0.941"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=mypy&package-manager=pip&previous-version=0.780&new-version=0.941)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@depe",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11573:2194,error,errors,2194,https://hail.is,https://github.com/hail-is/hail/pull/11573,3,['error'],['errors']
Availability,"SERVER-6099119](https://snyk.io/vuln/SNYK-PYTHON-JUPYTERSERVER-6099119) | `jupyter-server:` <br> `1.24.0 -> 2.11.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **509/1000** <br/> **Why?** Has a fix available, CVSS 5.9 | Regular Expression Denial of Service (ReDoS) <br/>[SNYK-PYTHON-SETUPTOOLS-3180412](https://snyk.io/vuln/SNYK-PYTHON-SETUPTOOLS-3180412) | `setuptools:` <br> `39.0.1 -> 65.5.1` <br> | No | No Known Exploit ; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **384/1000** <br/> **Why?** Has a fix available, CVSS 3.4 | Open Redirect <br/>[SNYK-PYTHON-TORNADO-5537286](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-5537286) | `tornado:` <br> `6.2 -> 6.3.3` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **494/1000** <br/> **Why?** Has a fix available, CVSS 5.6 | HTTP Request Smuggling <br/>[SNYK-PYTHON-TORNADO-5840803](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-5840803) | `tornado:` <br> `6.2 -> 6.3.3` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **539/1000** <br/> **Why?** Has a fix available, CVSS 6.5 | HTTP Request Smuggling <br/>[SNYK-PYTHON-TORNADO-6041512](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-6041512) | `tornado:` <br> `6.2 -> 6.3.3` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:**",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14109:4246,avail,available,4246,https://hail.is,https://github.com/hail-is/hail/pull/14109,2,['avail'],['available']
Availability,"SERVER-6099119](https://snyk.io/vuln/SNYK-PYTHON-JUPYTERSERVER-6099119) | `jupyter-server:` <br> `1.24.0 -> 2.11.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **509/1000** <br/> **Why?** Has a fix available, CVSS 5.9 | Regular Expression Denial of Service (ReDoS) <br/>[SNYK-PYTHON-SETUPTOOLS-3180412](https://snyk.io/vuln/SNYK-PYTHON-SETUPTOOLS-3180412) | `setuptools:` <br> `40.5.0 -> 65.5.1` <br> | No | No Known Exploit ; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **384/1000** <br/> **Why?** Has a fix available, CVSS 3.4 | Open Redirect <br/>[SNYK-PYTHON-TORNADO-5537286](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-5537286) | `tornado:` <br> `6.2 -> 6.3.3` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **494/1000** <br/> **Why?** Has a fix available, CVSS 5.6 | HTTP Request Smuggling <br/>[SNYK-PYTHON-TORNADO-5840803](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-5840803) | `tornado:` <br> `6.2 -> 6.3.3` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **539/1000** <br/> **Why?** Has a fix available, CVSS 6.5 | HTTP Request Smuggling <br/>[SNYK-PYTHON-TORNADO-6041512](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-6041512) | `tornado:` <br> `6.2 -> 6.3.3` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:**",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14365:3580,avail,available,3580,https://hail.is,https://github.com/hail-is/hail/pull/14365,1,['avail'],['available']
Availability,"SNYK-PYTHON-CERTIFI-3164749) | `certifi:` <br> `2021.10.8 -> 2023.7.22` <br> | No | No Known Exploit ; ![critical severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/c.png ""critical severity"") | **704/1000** <br/> **Why?** Has a fix available, CVSS 9.8 | Improper Following of a Certificate&#x27;s Chain of Trust <br/>[SNYK-PYTHON-CERTIFI-5805047](https://snyk.io/vuln/SNYK-PYTHON-CERTIFI-5805047) | `certifi:` <br> `2021.10.8 -> 2023.7.22` <br> | No | No Known Exploit ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | **624/1000** <br/> **Why?** Has a fix available, CVSS 8.2 | Arbitrary Code Execution <br/>[SNYK-PYTHON-IPYTHON-2348630](https://snyk.io/vuln/SNYK-PYTHON-IPYTHON-2348630) | `ipython:` <br> `5.10.0 -> 8.10.0` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **531/1000** <br/> **Why?** Proof of Concept exploit, Has a fix available, CVSS 4.2 | Remote Code Execution (RCE) <br/>[SNYK-PYTHON-IPYTHON-3318382](https://snyk.io/vuln/SNYK-PYTHON-IPYTHON-3318382) | `ipython:` <br> `5.10.0 -> 8.10.0` <br> | No | Proof of Concept ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | **604/1000** <br/> **Why?** Has a fix available, CVSS 7.8 | Improper Privilege Management <br/>[SNYK-PYTHON-JUPYTERCORE-3063766](https://snyk.io/vuln/SNYK-PYTHON-JUPYTERCORE-3063766) | `jupyter-core:` <br> `4.6.3 -> 4.11.2` <br> | No | No Known Exploit ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | **589/1000** <br/> **Why?** Has a fix available, CVSS 7.5 | Regular Expression Denial of Service (ReDoS) <br/>[SNYK-PYTHON-MISTUNE-2940625](https://snyk.io/vuln/SNYK-PYTHON-MISTUNE-2940625) | `mistune:` <br> `0.8.4 -> 2.0.3` <br> | No | No Known Exploit ; ![high severity](https:",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13717:2200,avail,available,2200,https://hail.is,https://github.com/hail-is/hail/pull/13717,2,['avail'],['available']
Availability,"SNYK-PYTHON-CERTIFI-3164749) | `certifi:` <br> `2021.10.8 -> 2023.7.22` <br> | No | No Known Exploit ; ![critical severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/c.png ""critical severity"") | **704/1000** <br/> **Why?** Has a fix available, CVSS 9.8 | Improper Following of a Certificate&#x27;s Chain of Trust <br/>[SNYK-PYTHON-CERTIFI-5805047](https://snyk.io/vuln/SNYK-PYTHON-CERTIFI-5805047) | `certifi:` <br> `2021.10.8 -> 2023.7.22` <br> | No | No Known Exploit ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | **624/1000** <br/> **Why?** Has a fix available, CVSS 8.2 | Arbitrary Code Execution <br/>[SNYK-PYTHON-IPYTHON-2348630](https://snyk.io/vuln/SNYK-PYTHON-IPYTHON-2348630) | `ipython:` <br> `5.10.0 -> 8.10.0` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **531/1000** <br/> **Why?** Proof of Concept exploit, Has a fix available, CVSS 4.2 | Remote Code Execution (RCE) <br/>[SNYK-PYTHON-IPYTHON-3318382](https://snyk.io/vuln/SNYK-PYTHON-IPYTHON-3318382) | `ipython:` <br> `5.10.0 -> 8.10.0` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **556/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 5.4 | Cross-site Scripting (XSS) <br/>[SNYK-PYTHON-JINJA2-6150717](https://snyk.io/vuln/SNYK-PYTHON-JINJA2-6150717) | `jinja2:` <br> `2.11.3 -> 3.1.3` <br> | No | No Known Exploit ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | **604/1000** <br/> **Why?** Has a fix available, CVSS 7.8 | Improper Privilege Management <br/>[SNYK-PYTHON-JUPYTERCORE-3063766](https://snyk.io/vuln/SNYK-PYTHON-JUPYTERCORE-3063766) | `jupyter-core:` <br> `4.6.3 -> 4.11.2` <br> | No | No Known Exploit ; ![high severity](ht",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14205:2518,avail,available,2518,https://hail.is,https://github.com/hail-is/hail/pull/14205,1,['avail'],['available']
Availability,"SQL migrations are not permitted to be modified. Unfortunately, our tests; previously did not verify this at all. Indeed, a PR merged which modified a SQL; file. This PR caused main to fail a deploy. This change verifies that no SQL migration is mutated in the source SHA relative; to the target SHA. One can also use it locally by running `make; check-services` from the root. Unfortunately, it does not work properly when run; on the main branch because there is no obvious point of comparison. I considered comparing against the previous commit, but that might cause; failures if we have to manually fix something in batch. As such, I prefer a; non-deploy only test.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9544:571,failure,failures,571,https://hail.is,https://github.com/hail-is/hail/pull/9544,1,['failure'],['failures']
Availability,"SS	AC=2,4,6,1;AF=1.23e-03,5.550e-05,4.44e-05,2.00e-04;AN=265;AS_AltDP=10,0,3,10;AS_BaseQRankSum=0.000,.,0.100,0.500;AS_FS=7.777,.,2.144,8.001;AS_MQ=55.75,.,38.98,40.20;AS_MQRankSum=0.200,.,-1.050,-0.500;AS_QD=0.50,0.00,0.25,0.52;AS_ReadPosRankSum=-0.200,.,0.500,-0.220;AS_SOR=2.300,.,1.600,3.000;BaseQRankSum=0.200;DP=600000;ExcessHet=0.0477;FS=0.900;MQ=55.02;MQRankSum=-0.553;QD=1.00;ReadPosRankSum=-0.162;SOR=0.792;VarDP=650	GT:AD:DP:GQ:PGT:PID:PL:PS:SB	0/0:.:21:30	0/0:.:300:20	0/0:.:30:72	0/0:.:31:98	0|1:29,3,0,0,0:33:78:0|1:113_GG_G:78,0,1100,140,1400,1200,172,1600,1200,1000,175,1100,1100,1300,1000:113:19,19,2,1	0/0:.:20:19	0/0:.:19:20	0/0:.:25:50		0|1:90,2,0,0,0:30:40:0|1:113_GG_G:40,0,600,70,650,600,90,640,900,300,60,800,400,900,900:113:2,14,2,0	0/0:.:20:10	0/0:.:9:20	0/0:.:30:40	0/0:.:37:38		0/4:5,0,0,0,1:5:33:.:.:30,40,400,50,220,220,38,270,270,270,0,200,200,200,202:.:5,0,0,1	. 	at is.hail.utils.ErrorHandling.fatal(ErrorHandling.scala:22); 	at is.hail.utils.ErrorHandling.fatal$(ErrorHandling.scala:22); 	at is.hail.utils.package$.fatal(package.scala:81); 	at is.hail.io.vcf.MatrixVCFReader.$anonfun$executeGeneric$7(LoadVCF.scala:1921); 	at is.hail.io.vcf.MatrixVCFReader.$anonfun$executeGeneric$7$adapted(LoadVCF.scala:1909); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:515); 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460); 	at __C678stream_Let.apply(Emit.scala); 	at is.hail.expr.ir.CompileIterator$$anon$2.step(Compile.scala:302); 	at is.hail.expr.ir.CompileIterator$LongIteratorWrapper.hasNext(Compile.scala:155); 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:490); 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:490); 	at is.hail.rvd.RVD$.$anonfun$getKeyInfo$2(RVD.scala:1030); 	at is.hail.rvd.RVD$.$anonfun$getKeyInfo$2$adapted(RVD.scala:1029); 	at is.hail.sparkextras.Co",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14102:7348,Error,ErrorHandling,7348,https://hail.is,https://github.com/hail-is/hail/issues/14102,2,['Error'],['ErrorHandling']
Availability,SVD tests should be robust to sign ambiguity,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9727:20,robust,robust,20,https://hail.is,https://github.com/hail-is/hail/pull/9727,1,['robust'],['robust']
Availability,Saw this in https://ci.azure.hail.is/batches/38760/jobs/99. I think the log of a container is actually never None any more. It can; be empty if bash has started but the echo command has not yet run.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11552:169,echo,echo,169,https://hail.is,https://github.com/hail-is/hail/pull/11552,1,['echo'],['echo']
Availability,"Screenshots should give the main overview of the changes; Questions for reviewers. Technical:; - [X] Are there any CSS conventions within Hail? I assume I need to migrate the ad-hoc ""style"" tags into CSS?; - [X] There still seems to be a bunch of unused space after truncated batch names. I'm not sure why. UX:; - [x] I've moved the status indicator to the front of the line. Is that ok?; - to help with layout within the batch-name box; - to put it in a reliable place (ie not moving around based on how long the name is); - [x] I'm not really sure I like the change to Pending. Curious for others' thoughts. #### Example: Batches page; (layout and columns). ##### Before:; <img width=""1735"" alt=""image"" src=""https://github.com/user-attachments/assets/c2966f9a-1802-479f-8fb4-3882a4552fad"">. ##### After:; <img width=""1748"" alt=""image"" src=""https://github.com/user-attachments/assets/4a6a5c5a-23a5-42a4-bc8e-6624f83880fa"">. #### Example: Batch Details page; (Renaming confusing 'Pending' field). ##### Before:; <img width=""1044"" alt=""image"" src=""https://github.com/user-attachments/assets/ebb3eb52-69d7-44ba-a2c5-f0f219a0b5bb"">. ##### After:; <img width=""1059"" alt=""image"" src=""https://github.com/user-attachments/assets/6fa01eae-567d-49e5-a59e-768bf936a1b1"">. Fixes #14628. Adds and shuffles content on the new Batches table",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14640:455,reliab,reliable,455,https://hail.is,https://github.com/hail-is/hail/pull/14640,1,['reliab'],['reliable']
Availability,"Script:; ```python3; #!/usr/bin/env python3; import hail as hl; hl.init(log='/dev/null'); mt = hl.import_vcf('src/test/resources/sample.vcf'); mt.filter_rows(mt.locus < hl.Locus('1', 1)).show(); ```. Output:; ```; 2019-06-24 19:12:05 WARN Utils:66 - Your hostname, wp086-661 resolves to a loopback address: 127.0.1.1; using 10.1.8.50 instead (on interface wlp2s0); 2019-06-24 19:12:05 WARN Utils:66 - Set SPARK_LOCAL_IP if you need to bind to another address; 2019-06-24 19:12:06 WARN NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).; Running on Apache Spark version 2.4.0; SparkUI available at http://wp086-661.broadinstitute.org:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.2.16-e95038bbed35; LOGGING: writing to /dev/null; Traceback (most recent call last):; File ""/tmp/x"", line 4, in <module>; mt.filter_rows(mt.locus < hl.Locus('1', 1)).show(); File ""</home/BROAD.MIT.EDU/cvittal/.cache/hail-env/lib/python3.6/site-packages/decorator.py:decorator-gen-1000>"", line 2, in show; File ""/home/BROAD.MIT.EDU/cvittal/src/hail-alt/hail/python/hail/typecheck/check.py"", line 585, in wrapper; return __original_func(*args_, **kwargs_); File ""/home/BROAD.MIT.EDU/cvittal/src/hail-alt/hail/python/hail/matrixtable.py"", line 2569, in show; actual_n_cols = self.count_cols(); File ""</home/BROAD.MIT.EDU/cvittal/.cache/hail-env/lib/python3.6/site-packages/decorator.py:decorator-gen-994>"", line 2, in count_cols; File ""/home/BROAD.MIT.EDU/cvittal/src/hail-alt/hail/python/hail/typecheck/check.py"", line 585, in wrapper; return __original_func(*args_, **kwargs_); File ""/home/BROAD.MIT.EDU/cvittal/src/hail-alt/hail/python/hail/matrixtable.py"", line 2404, in count_cols; return Env.backend().execute(ir); File ""/home/BROAD.MIT.EDU/cvittal/src/hail-alt/hail/py",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6458:789,avail,available,789,https://hail.is,https://github.com/hail-is/hail/issues/6458,1,['avail'],['available']
Availability,See attached log. Error not clear:. `[Stage 0:==========> (596 + 168) / 2836]hail: write: caught exception: Job aborted.`. [hail.log.txt](https://github.com/broadinstitute/hail/files/269500/hail.log.txt),MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/391:18,Error,Error,18,https://hail.is,https://github.com/hail-is/hail/issues/391,1,['Error'],['Error']
Availability,See discuss post: https://discuss.hail.is/t/redirect-or-find-vep-or-other-error-output-from-a-hail-pipeline/1308/9?u=danking. It looks like Hail isnt capturing all the VEP output. Can someone look into this? Probably the way were executing external commands needs to also capture stderr and print it. Assigning Tim for delegation.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8146:74,error,error-output-from-a-hail-pipeline,74,https://hail.is,https://github.com/hail-is/hail/issues/8146,1,['error'],['error-output-from-a-hail-pipeline']
Availability,"See discussion on Zulip https://hail.zulipchat.com/#narrow/stream/127527-team/topic/batch. Our worst case monthly cost moves from 40 USD to 4000 USD. However, PVCs seem to be rather reliably cleaned up now, so I am not overly concerned about this. We also have monitoring on PVC storage capacity.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6366:182,reliab,reliably,182,https://hail.is,https://github.com/hail-is/hail/pull/6366,1,['reliab'],['reliably']
Availability,"See each message below. ---. [[query/vds] Fix local_to_global with missing fill](https://github.com/hail-is/hail/pull/13325/commits/7d84189ca1a1b9460f4e0c96821cd43b8b0068fa) ; ; There was a logic error in constructFromIndicesUnsafe, if a missing; value was pushed, pushing a present value with the same index would not; clear the missing bit. ---. [[batch/test] Wait for job to be running in list_jobs_v2 test](https://github.com/hail-is/hail/pull/13325/commits/724da249255c06ea4ed1816704e4de51bd8f9b89). ---. [[qob] halve the number of active tests](https://github.com/hail-is/hail/pull/13325/commits/c2638702325526b29bebd416fceeedea52d42245). ---. [[batch] Turn off oms_agent in test and dev](https://github.com/hail-is/hail/pull/13325/commits/bbd65e4f66d41ef69c130091b0506087975c4851). ---",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13325:196,error,error,196,https://hail.is,https://github.com/hail-is/hail/pull/13325,1,['error'],['error']
Availability,"See here:; https://hail.zulipchat.com/#narrow/stream/123010-Hail-0.2E2.20support/topic/Error.20when.20writing.20HailTable.2E. ```; logger.info('Read MatrixTable.'); mt = hl.read_matrix_table('path'). logger.info('Calculate median x in each group2.'); mt = mt.group_cols_by('group1', 'group2').aggregate(x = hl.median(hl.agg.collect(mt.x))). logger.info('Calculate mean x in group1.'); mt = mt.group_cols_by('group1').aggregate(x_stats = hl.agg.stats(mt.x)). logger.info('Calculate relative x.'); mt = mt.annotate_entries(x = mt.x_stats.mean); mt = mt.annotate_rows(row_sum = hl.agg.sum(mt.x)); mt = mt.select_entries(rx = mt.x/mt.row_sum). #----; logger.info('Export as HailTable.'); ht = mt.entries(); ht = ht.drop('row_sum', 'gene_id'). ht.export('path'); ```. Can write the MatrixTable before entries, but not the HailTable after",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6295:87,Error,Error,87,https://hail.is,https://github.com/hail-is/hail/issues/6295,1,['Error'],['Error']
Availability,See https://ci.hail.is/batches/532603/jobs/112. We encounter a `is.hail.relocated.com.google.cloud.storage.StorageException` which is caused by a; `com.google.api.client.http.HttpResponseException`. The latter exception is not currently; considered a transient error. This PR changes isTransientError to recognize `HttpResponseException`; as a transient error.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11402:261,error,error,261,https://hail.is,https://github.com/hail-is/hail/pull/11402,2,['error'],['error']
Availability,"See https://github.com/broadinstitute/gnomad-browser/issues/914. In [the line in question](https://github.com/broadinstitute/gnomad-browser/blob/b497106d97773affd81b48eadfa5586259e011e5/data-pipeline/src/data_pipeline/data_types/gtex_tissue_expression.py#L14), we attempt to export a `Table` with ~13,000 columns, and get the following error: `is.hail.relocated.org.objectweb.asm.MethodTooLargeException: Method too large: __C19580collect_distributed_array.__m19633split_InsertFields ()V` (see above-referenced issue for full stacktrace). Hail version was 0.2.96-39909e0a396f",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/11972:336,error,error,336,https://hail.is,https://github.com/hail-is/hail/issues/11972,1,['error'],['error']
Availability,"See https://github.com/erdewit/nest_asyncio/issues/11. Original error was this:. ```; _________________ ServiceTests.test_single_task_resource_group _________________. self = <test.hailtop.batch.test_batch.ServiceTests testMethod=test_single_task_resource_group>. def test_single_task_resource_group(self):; b = self.batch(); j = b.new_job(); j.declare_resource_group(output={'foo': '{root}.foo'}); j.command(f'echo ""hello"" > {j.output.foo}'); > res = b.run(). ../test/hailtop/batch/test_batch.py:484: ; _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ; batch/batch.py:565: in run; run_result = self._backend._run(self, dry_run, verbose, delete_scratch_on_exit, **backend_kwargs) # pylint: disable=assignment-from-no-return; batch/backend.py:475: in _run; self._async_run(batch, dry_run, verbose, delete_scratch_on_exit, wait, open, disable_progress_bar, callback, token, **backend_kwargs)); utils/utils.py:127: in async_to_blocking; return asyncio.get_event_loop().run_until_complete(coro); /usr/local/lib/python3.7/dist-packages/nest_asyncio.py:63: in run_until_complete; return self._run_until_complete_orig(future); /usr/lib/python3.7/asyncio/base_events.py:574: in run_until_complete; self.run_forever(); /usr/lib/python3.7/asyncio/base_events.py:541: in run_forever; self._run_once(); _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . self = <_UnixSelectorEventLoop running=False closed=False debug=False>. def _run_once(self):; """"""Run one full iteration of the event loop.; ; This calls all currently ready callbacks, polls for I/O,; schedules the resulting callbacks, and finally schedules; 'call_later' callbacks.; """"""; ; sched_count = len(self._scheduled); if (sched_count > _MIN_SCHEDULED_TIMER_HANDLES and; self._timer_cancelled_count / sched_count >; _MIN_CANCELLED_TIMER_HANDLES_FRACTION):; # Remove delayed calls that were cancelled if their number; # is too high; new_scheduled = []; for handle in self._scheduled:; if ha",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10705:64,error,error,64,https://hail.is,https://github.com/hail-is/hail/pull/10705,2,"['echo', 'error']","['echo', 'error']"
Availability,See https://hail.zulipchat.com/#narrow/stream/127527-team/topic/ci.20down/near/297868370 for details. I'll file a ticket with Azure to see if this is a breaking change that they're fine making and if so if there is a more robust way for us to filter to disk costs.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12169:222,robust,robust,222,https://hail.is,https://github.com/hail-is/hail/pull/12169,1,['robust'],['robust']
Availability,"See the discuss post here: https://discuss.hail.is/t/error-indexing-bgen-files/833. @catoverdrive At check-in, we discussed this error that occurs in `PackCodecSpec.buildEncoder` and thought you'd be the best person to fix this bug since you added this feature. If not, I'll try and come up with a fix.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5144:53,error,error-indexing-bgen-files,53,https://hail.is,https://github.com/hail-is/hail/issues/5144,2,['error'],"['error', 'error-indexing-bgen-files']"
Availability,"Seems to have been introduced sometime between `0.2-29fbaeaf265e` (works) and `0.2-60a06028e9db` (see error below). The code is pretty involved, so whoever gets assigned, if you need it, let me know and I can send.; ```; hail.utils.java.FatalError: AssertionError: assertion failed. Java stack trace:; java.lang.AssertionError: assertion failed; 	at scala.Predef$.assert(Predef.scala:156); 	at is.hail.expr.ir.MatrixNativeReader.apply(MatrixIR.scala:242); 	at is.hail.expr.ir.MatrixRead.execute(MatrixIR.scala:426); 	at is.hail.expr.ir.CastMatrixToTable.execute(TableIR.scala:1167); 	at is.hail.expr.ir.TableMapGlobals.execute(TableIR.scala:656); 	at is.hail.expr.ir.TableMapRows.execute(TableIR.scala:514); 	at is.hail.expr.ir.TableMapGlobals.execute(TableIR.scala:656); 	at is.hail.expr.ir.TableMapGlobals.execute(TableIR.scala:656); 	at is.hail.expr.ir.TableMapRows.execute(TableIR.scala:514); 	at is.hail.expr.ir.TableMapGlobals.execute(TableIR.scala:656); 	at is.hail.expr.ir.TableMapRows.execute(TableIR.scala:514); 	at is.hail.expr.ir.CastTableToMatrix.execute(MatrixIR.scala:2283); 	at is.hail.expr.ir.MatrixAnnotateColsTable.execute(MatrixIR.scala:1725); 	at is.hail.expr.ir.CastMatrixToTable.execute(TableIR.scala:1167); 	at is.hail.expr.ir.TableMapGlobals.execute(TableIR.scala:656); 	at is.hail.expr.ir.TableMapRows.execute(TableIR.scala:514); 	at is.hail.expr.ir.CastTableToMatrix.execute(MatrixIR.scala:2283); 	at is.hail.expr.ir.MatrixMapCols.execute(MatrixIR.scala:1413); 	at is.hail.expr.ir.CastMatrixToTable.execute(TableIR.scala:1167); 	at is.hail.expr.ir.TableMapGlobals.execute(TableIR.scala:656); 	at is.hail.expr.ir.TableMapGlobals.execute(TableIR.scala:656); 	at is.hail.expr.ir.TableMapRows.execute(TableIR.scala:514); ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4746:102,error,error,102,https://hail.is,https://github.com/hail-is/hail/issues/4746,1,['error'],['error']
Availability,"Self-explanatory :). -------------------------------------------------------------------------------------------. ### Hail version:. ### What you did:. ### What went wrong (all error messages here, including the full java stack trace):",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3047:177,error,error,177,https://hail.is,https://github.com/hail-is/hail/issues/3047,1,['error'],['error']
Availability,Set `contains` - segmentation fault,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4522:30,fault,fault,30,https://hail.is,https://github.com/hail-is/hail/issues/4522,1,['fault'],['fault']
Availability,"Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/michafla/projects/R/pkg/hailr/inst/unitTests/spark-warehouse/').; 2018-10-09 14:46:38 SharedState: INFO: Warehouse path is 'file:/Users/michafla/projects/R/pkg/hailr/inst/unitTests/spark-warehouse/'.; 2018-10-09 14:46:38 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@28f0ac7{/SQL,null,AVAILABLE,@Spark}; 2018-10-09 14:46:38 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@49a30f89{/SQL/json,null,AVAILABLE,@Spark}; 2018-10-09 14:46:38 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@4495af6e{/SQL/execution,null,AVAILABLE,@Spark}; 2018-10-09 14:46:38 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@6baf9f3b{/SQL/execution/json,null,AVAILABLE,@Spark}; 2018-10-09 14:46:38 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@562ad221{/static/sql,null,AVAILABLE,@Spark}; 2018-10-09 14:46:39 StateStoreCoordinatorRef: INFO: Registered StateStoreCoordinator endpoint; 2018-10-09 14:46:39 SparkSession$Builder: WARN: Using an existing SparkSession; some configuration may not take effect.; 2018-10-09 14:46:39 SparkSqlParser: INFO: Parsing command: SHOW TABLES; 2018-10-09 14:46:40 SparkContext: INFO: Starting job: collect at utils.scala:44; 2018-10-09 14:46:40 DAGScheduler: INFO: Got job 0 (collect at utils.scala:44) with 1 output partitions; 2018-10-09 14:46:40 DAGScheduler: INFO: Final stage: ResultStage 0 (collect at utils.scala:44); 2018-10-09 14:46:40 DAGScheduler: INFO: Parents of final stage: List(); 2018-10-09 14:46:40 DAGScheduler: INFO: Missing parents: List(); 2018-10-09 14:46:40 DAGScheduler: INFO: Submitting ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:41), which has no missing parents; 2018-10-09 14:46:40 MemoryStore: INFO: Block broadcast_0 stored as values in memory (estimated size 6.0 KB, free 366.3 MB); 2018-10-09 14:46:41 MemoryStore: INFO: Block broadcast_0_piece0 stored as bytes in memory (estimated ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4513:32158,AVAIL,AVAILABLE,32158,https://hail.is,https://github.com/hail-is/hail/issues/4513,1,['AVAIL'],['AVAILABLE']
Availability,"Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/michafla/projects/R/pkg/hailr/inst/unitTests/spark-warehouse/').; 2018-10-09 15:04:33 SharedState: INFO: Warehouse path is 'file:/Users/michafla/projects/R/pkg/hailr/inst/unitTests/spark-warehouse/'.; 2018-10-09 15:04:33 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@16ba3696{/SQL,null,AVAILABLE,@Spark}; 2018-10-09 15:04:33 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@2780d0b8{/SQL/json,null,AVAILABLE,@Spark}; 2018-10-09 15:04:33 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@7cea1161{/SQL/execution,null,AVAILABLE,@Spark}; 2018-10-09 15:04:33 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@696b1f0{/SQL/execution/json,null,AVAILABLE,@Spark}; 2018-10-09 15:04:33 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@14d32b0c{/static/sql,null,AVAILABLE,@Spark}; 2018-10-09 15:04:34 StateStoreCoordinatorRef: INFO: Registered StateStoreCoordinator endpoint; 2018-10-09 15:04:34 SparkSession$Builder: WARN: Using an existing SparkSession; some configuration may not take effect.; 2018-10-09 15:04:34 SparkSqlParser: INFO: Parsing command: SHOW TABLES; 2018-10-09 15:04:36 SparkContext: INFO: Starting job: collect at utils.scala:44; 2018-10-09 15:04:36 DAGScheduler: INFO: Got job 0 (collect at utils.scala:44) with 1 output partitions; 2018-10-09 15:04:36 DAGScheduler: INFO: Final stage: ResultStage 0 (collect at utils.scala:44); 2018-10-09 15:04:36 DAGScheduler: INFO: Parents of final stage: List(); 2018-10-09 15:04:36 DAGScheduler: INFO: Missing parents: List(); 2018-10-09 15:04:36 DAGScheduler: INFO: Submitting ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:41), which has no missing parents; 2018-10-09 15:04:36 MemoryStore: INFO: Block broadcast_0 stored as values in memory (estimated size 6.0 KB, free 366.3 MB); 2018-10-09 15:04:36 MemoryStore: INFO: Block broadcast_0_piece0 stored as bytes in memory (estimated ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4513:14643,AVAIL,AVAILABLE,14643,https://hail.is,https://github.com/hail-is/hail/issues/4513,1,['AVAIL'],['AVAILABLE']
Availability,"Setup failure is distinguished from creation failure because we at least have a pod status. Jobs now have three ways to finish:. - creation failure; never scheduled due to PVC failure or image pull back off; - setup failure; setup container failed, we probably won't get the logs; - normal termination; keep alive container survived, we'll get the logs.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6961:6,failure,failure,6,https://hail.is,https://github.com/hail-is/hail/pull/6961,6,"['alive', 'failure']","['alive', 'failure']"
Availability,"Shortly after this merged, we encountered issues where some workers shut down soon after starting up, but while they were running jobs. I think the `startup_tasks` idled out even though we activated, which caused us to return without shutting down the site. That meant we shut down while we were processing jobs and those workers spewed a bunch of errors before they finally killed themselves off. I think it's wrong here to tie in the timing out trying to activate with other startup tasks that could potentially take a longer amount of time but will certainly finish and we should let them finish. We also don't need all of the network namespaces created in order to start accepting jobs. For context, I think it takes just about MAX_IDLE_TIMEOUT_SECONDS to create all the network namespaces.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11728:73,down,down,73,https://hail.is,https://github.com/hail-is/hail/pull/11728,4,"['down', 'error']","['down', 'errors']"
Availability,Should fix this error:. ```; azure.core.exceptions.HttpResponseError: The specified block list is invalid.; ```,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11110:16,error,error,16,https://hail.is,https://github.com/hail-is/hail/pull/11110,1,['error'],['error']
Availability,Should throw an error on gt>2,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2634:16,error,error,16,https://hail.is,https://github.com/hail-is/hail/issues/2634,1,['error'],['error']
Availability,"Should unify the two schemas, setting fields to missing as needed. If a similarly-named field in the two tables can be coerced (int32 / int64), do that. Throw an error if coercion is not posible.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5854:162,error,error,162,https://hail.is,https://github.com/hail-is/hail/issues/5854,1,['error'],['error']
Availability,Significantly improve error messages for expr,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2659:22,error,error,22,https://hail.is,https://github.com/hail-is/hail/pull/2659,1,['error'],['error']
Availability,"Since Amanda is out, fixed test failure, replacing: https://github.com/hail-is/hail/pull/3817. @catoverdrive wrote it and I already reviewed it. Last commit is my fix, mostly unrelated to this change.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3832:32,failure,failure,32,https://hail.is,https://github.com/hail-is/hail/pull/3832,1,['failure'],['failure']
Availability,"Since `ServiceBackend` only uses cloud storage, the user should receive an error when trying to pass in a local (`file://` or unprefixed) path, which is implemented in this change.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12186:75,error,error,75,https://hail.is,https://github.com/hail-is/hail/pull/12186,1,['error'],['error']
Availability,Slightly improves error message for Expression.__iter__,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4088:18,error,error,18,https://hail.is,https://github.com/hail-is/hail/pull/4088,1,['error'],['error']
Availability,"Snyk has created this PR to fix one or more vulnerable packages in the `pip` dependencies of this project.</h3>. #### Changes included in this PR. - Changes to the following files to upgrade the vulnerable dependencies to a fixed version:; - hail/python/hailtop/pinned-requirements.txt. <details>; <summary> <b>Warning</b></summary>. ```; msal-extensions 1.0.0 requires portalocker, which is not installed.; aiosignal 1.3.1 requires frozenlist, which is not installed.; aiohttp 3.8.5 requires frozenlist, which is not installed. ```; </details>. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **496/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 4.2 | Information Exposure Through Sent Data <br/>[SNYK-PYTHON-URLLIB3-6002459](https://snyk.io/vuln/SNYK-PYTHON-URLLIB3-6002459) | `urllib3:` <br> `1.26.17 -> 1.26.18` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI0MmRjMDIwMC02MDI1LTQ1M2QtYWUxNC00NDRlZjM",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13854:1129,avail,available,1129,https://hail.is,https://github.com/hail-is/hail/pull/13854,1,['avail'],['available']
Availability,"Snyk has created this PR to fix one or more vulnerable packages in the `pip` dependencies of this project.</h3>. #### Changes included in this PR. - Changes to the following files to upgrade the vulnerable dependencies to a fixed version:; - hail/python/hailtop/pinned-requirements.txt. <details>; <summary> <b>Warning</b></summary>. ```; msal-extensions 1.0.0 requires portalocker, which is not installed.; aiosignal 1.3.1 requires frozenlist, which is not installed.; aiohttp 3.8.5 requires frozenlist, which is not installed. ```; </details>. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **581/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 5.9 | Information Exposure Through Sent Data <br/>[SNYK-PYTHON-URLLIB3-5926907](https://snyk.io/vuln/SNYK-PYTHON-URLLIB3-5926907) | `urllib3:` <br> `1.26.16 -> 1.26.17` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiIxOGU4YzI4Yi1kYWQ0LTQ5ZDUtOTExNi04NjFkYTd",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13773:1129,avail,available,1129,https://hail.is,https://github.com/hail-is/hail/pull/13773,1,['avail'],['available']
Availability,"So I just had the following situation: saved an Excel doc from a collaborator as CSV to the import it into hail. Running `hl.import_table` didn't return any error... but somehow the header was both correctly assigned as column names but also added as the first line. After some poking around, it turns out that the file encoding was UTF8 with BOM and that it somehow tripped `hl.import_table`. Same file works after re-encoding it as plain UTF8. . Please include the full Hail version and as much detail as possible.; version 0.2.34-914bd8a10ca2; -----------------------------------------------------------------------------",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8395:157,error,error,157,https://hail.is,https://github.com/hail-is/hail/issues/8395,1,['error'],['error']
Availability,"So I'm of two minds here, and I don't quite know which to choose. Imagine we make an internal (service to service) request. It fails with a transient error like a timeout. What do we do?. Option 1. Retry. Option 2. Return a transient error 503 service unavailable to our client, and let them to decide what to do. I've implemented both options here: request_{retry, raise}_transient_errors. Which should I use in, for example, the auth decorators which hit the auth/userinfo endpoint?. I've chosen option 1 after bouncing back and forth a few times. I feel like retrying will give a better experience in the common case (a real transient error) and both will recover eventually in the case of a real outage. It appears that browsers don't retry 503 even with Retry-After header set. I'd want it to retry immediately or after a very short delay (1s). In the end, this is what convinced me we should retry. Currently CI uses option 1 when calling batch because it is hardcoded into the batch client. The signature of these functions match aiohttp.ClientSession.request. @danking I'm compelled by your concern that we have a potentially infinite loop of failures nobody will be notified about. I will follow up with another PR to add some logging to the request_retry function. Finally, I'm not quite sure why we're getting so many transient errors. I suspect some of it is gaps in k8s service handoffs, but I'm not sure.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7284:150,error,error,150,https://hail.is,https://github.com/hail-is/hail/pull/7284,7,"['error', 'failure', 'outage', 'recover']","['error', 'errors', 'failures', 'outage', 'recover']"
Availability,"So this evening I noticed that one of my vds files (written four days ago) makes Hail crash when I try to read it. When I do:; hail read -i /user/satterst/DBS_v3/DBS_v3_split_vep.vds. I get the following error message: ; hail: read: caught exception: java.lang.IllegalArgumentException: requirement failed; and then a big stack trace, captured here:. /mnt/lustre/satterst/hail.crash.log. I'd be interested to know what's up. One line in the log says:; 2016-08-27 20:16:41 WARN AbstractLifeCycle:204 - FAILED SelectChannelConnector@0.0.0.0:54054: java.net.BindException: Address already in use; but I don't know what this means or if it's relevant.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/700:204,error,error,204,https://hail.is,https://github.com/hail-is/hail/issues/700,1,['error'],['error']
Availability,"So this works (`cuts` is an array of 50 entries, so this is 2500 `counters`):; ```; joint_sfs = ht.aggregate(hl.struct(; joint_freq_bin_counters=[[hl.agg.counter((ht.freq_bins[i], ht.freq_bins[j], ht.consequence)); for i, _ in enumerate(cuts)] for j, _ in enumerate(cuts)])); ```; but this:; ```; counters = ht.aggregate(hl.struct(; enrichment_counters=[hl.agg.array_agg(lambda x: hl.agg.counter(x), ht.enrichments[i]); for i, _ in enumerate(cuts)],; enrichment_pseudo_counters=[hl.agg.array_agg(lambda x: hl.agg.counter(x), ht.enrichments_pseudo[i]); for i, _ in enumerate(cuts)])); ```; immediately results in OOMs. Each of `enrichments[i]` is also 50 elements, so this should be the same amount of work (well double since I have 2). But a few tasks finish but they generally struggle and eventually die with:; ```; [Stage 3:> (4 + 13) / 9997]OpenJDK 64-Bit Server VM warning: INFO: os::commit_memory(0x00007f94d8700000, 5428477952, 0) failed; error='Cannot allocate memory' (errno=12); #; # There is insufficient memory for the Java Runtime Environment to continue.; # Native memory allocation (mmap) failed to map 5428477952 bytes for committing reserved memory.; # An error report file with more information is saved as:; # /tmp/04eb6abfd9594f99ad2fac1a8e4cd0d1/hs_err_pid25110.log; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6074:946,error,error,946,https://hail.is,https://github.com/hail-is/hail/issues/6074,2,['error'],['error']
Availability,"Some delimited text processors use quotes to escape quotes so that the string `a""b` is rendered as `a""""b`. Moreover an individual entry of the delimited text is itself wrapped in double quotes, so, for example, a delimited text file representing one row containing the strings: `hello`, `a""b`, `goodbye` would contain the following bytes:; ```; ""hello"",""a""""b"",""goodbye""; ```. ---. Attempting to import and show the attached TSV file with `hl.import_table(""test.txt"", quote='""').show()` throws an exception:; ```; is.hail.utils.HailException: terminating quote character '""' not at end of field; 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:9); 	at is.hail.utils.package$.fatal(package.scala:28); 	at is.hail.expr.ir.TextTableReader$.splitLine(TextTableReader.scala:107); 	at is.hail.expr.ir.TextTableReader$$anonfun$28$$anonfun$apply$7$$anonfun$apply$8.apply(TextTableReader.scala:379); 	at is.hail.expr.ir.TextTableReader$$anonfun$28$$anonfun$apply$7$$anonfun$apply$8.apply(TextTableReader.scala:378); 	at is.hail.utils.WithContext.map(Context.scala:33); 	at is.hail.expr.ir.TextTableReader$$anonfun$28$$anonfun$apply$7.apply(TextTableReader.scala:378); 	at is.hail.expr.ir.TextTableReader$$anonfun$28$$anonfun$apply$7.apply(TextTableReader.scala:408); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at is.hail.utils.package$.getIteratorSizeWithMaxN(package.scala:385); 	at is.hail.sparkextras.ContextRDD$$anonfun$14.apply(ContextRDD.scala:559); 	at is.hail.sparkextras.ContextRDD$$anonfun$14.apply(ContextRDD.scala:559); 	at is.hail.sparkextras.ContextRDD$$anonfun$runJob$1.apply(ContextRDD.scala:589); 	at is.hail.sparkextras.ContextRDD$$anonfun$runJob$1.apply(ContextRDD.scala:587); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.scheduler.ResultTask.r",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5796:613,Error,ErrorHandling,613,https://hail.is,https://github.com/hail-is/hail/issues/5796,2,['Error'],['ErrorHandling']
Availability,Some fixes to my recent resiliency changes. These weren't caught because gateway and router-resolver are part of infrastructure that isn't automated by ci yet. I needed to make these changes to deploy them by hand (which I did successfully).,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6211:24,resilien,resiliency,24,https://hail.is,https://github.com/hail-is/hail/pull/6211,1,['resilien'],['resiliency']
Availability,"Some of the examples create errors in the new version (ex: need to use ""importannotations table"", and the -r flag doesn't exist anymore). (also -- would be great to add a link to this page from the main page!)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/519:28,error,errors,28,https://hail.is,https://github.com/hail-is/hail/issues/519,1,['error'],['errors']
Availability,"Somehow, this didn't trigger an error in master but did in 0.1. Nonetheless, removing unnecessary data seems good.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2349:32,error,error,32,https://hail.is,https://github.com/hail-is/hail/pull/2349,1,['error'],['error']
Availability,"Spaces in sample names are a nightmare for downstream analysis tools, so when I get my callsets from Picard, I immediately remove spaces in sample names and re-write my VCF. It usually takes a day or two to re-write the entire VCF, depending on the size of the callset. I would be an extremely happy camper if I could immediately import my VCF from Picard and either fix sample names on the fly during the import, or fix sample names in the .vds after the import (as a separate step). Either way, this should save a substantial chunk of time right off the top in the QC process.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/157:43,down,downstream,43,https://hail.is,https://github.com/hail-is/hail/issues/157,1,['down'],['downstream']
Availability,"Spaces were screwing things up because the `location` directive matches the decoded string (e.g. ""%20"" is converted back to "" ""). We don't need to reconstruct the URL explicitly with the regex pieces and the `$args` (which refers to HTTP query parameters), `$request_uri` is all that, but still encoded. The notebook was receiving requests without encoded spaces which appear as a bunch of weird hex characters. Obviously the notebook errors when it sees such demonic lettering.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4978:435,error,errors,435,https://hail.is,https://github.com/hail-is/hail/pull/4978,1,['error'],['errors']
Availability,"Spark 3.1 still relies on Breeze 1.0, which is very broken: https://github.com/scalanlp/breeze/issues/772. We can never allow use of Breeze 1.0. . To fix, I have hard coded the insistence that we use Breeze 1.1, relocated it into our hail jar. In the process, I also made it so that we don't support building with Scala 2.11 anymore, but that doesn't preclude us from still building with Spark 2.4.8 for now. . Our old ""fix"" in the build.gradle that said to change Spark 1.0 to 1.1 was actually making things more confusing. It was making it so that when we pulled down Spark and Breeze from Maven ourselves we'd switch out Breeze 1.0 for Breeze 1.1. However, it had no effect on what happened in dataproc, when breeze and Spark are provided on the classpath and we just use what's available. . I also added a dataproc test to catch this behavior.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11555:565,down,down,565,https://hail.is,https://github.com/hail-is/hail/pull/11555,2,"['avail', 'down']","['available', 'down']"
Availability,"Spark 3.3.0 uses log4j2. Note the ""2"". If you use the log4j1 programmatic reconfiguration system, you will break log4j2 for you and everyone else. The only way to recover from such a breakage is to use the log4j2 programmatic reconfiguration system. Changes in this PR:. 1. Include JVM output in error logs when the JVM crashes. This should help debugging of JVM crashing in production until the JVM logs are shown on a per-worker page. 2. JVMEntryway is now a real gradle project. I need to compile against log4j, and I didn't want to do that by hand with `javac`. Ignore gradlew, gradlew.bat, and gradle/wrapper, they're programmatically generated by gradle. 3. Add logging to JVMEntryway. JVMEntryway now logs its arguments into the QoB job log. I also log exceptions from the main thread or the cancel thread into the job log. We also flush the logs after the main thread completes, the cancel thread completes, and when the try-catch exits. This should ensure that regardless of what goes wrong (even if both threads fail to start) we at least see the arguments that the JVMEntryway received. 4. Use log4j2 programmatic reconfiguration after every job. This restores log4j2 to well enough working order that, *if you do not try to reconfigure it using log4j1 programmatic configuration*, logs will work. All old versions of Hail use log4j1 programmatic configuration. As a result, **all old versions of Hail will still have no logs**. However, new versions of Hail will log correctly even if an old version of Hail used the JVM before it. 5. `QoBAppender`. This is how we always should have done logging. A custom appender which we can flush and then redirect to a new file at our whim. I followed the log4j2 best practices for creating a new appender. All these annotations, factory methods, and managers are The Right Way, for better or worse. If we ever ban old versions of Hail from the cluster, then we can also eliminate the log4j2 reconfiguration. New versions of Hail work fine without an",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12941:163,recover,recover,163,https://hail.is,https://github.com/hail-is/hail/pull/12941,2,"['error', 'recover']","['error', 'recover']"
Availability,"Spark breaks down when a job has too many partitions. We should modify the implementation of CollectDistributedArray on the Spark backend to automatically break up jobs that are above some threshold of number of partitions into a few sequential smaller jobs. This would have a large impact on groups like AoU who are using Hail on the biggest datasets, who currently have to hack around this issue with trial and error.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14584:13,down,down,13,https://hail.is,https://github.com/hail-is/hail/issues/14584,2,"['down', 'error']","['down', 'error']"
Availability,"Spark depends on a very old verison of SLF4J. We cannot upgrade. This removes this message:; ```; SLF4J: No SLF4J providers were found.; SLF4J: Defaulting to no-operation (NOP) logger implementation; SLF4J: See https://www.slf4j.org/codes.html#noProviders for further details.; SLF4J: Class path contains SLF4J bindings targeting slf4j-api versions 1.7.x or earlier.; SLF4J: Ignoring binding found at [jar:file:/usr/lib/spark/jars/log4j-slf4j-impl-2.17.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]; SLF4J: See https://www.slf4j.org/codes.html#ignoredBindings for an explanation.; ```. Which, IMO, really should be a stop-the-world error.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14054:634,error,error,634,https://hail.is,https://github.com/hail-is/hail/pull/14054,1,['error'],['error']
Availability,"Spark depends on a very old verison of SLF4J. We cannot upgrade. We added this dependency ages ago to fix some undocumented issue with logging and SLF4J. It seems reasonable to me that we should just accept whatever version of SLF4J that Spark provides. This removes this message:; ```; SLF4J: No SLF4J providers were found.; SLF4J: Defaulting to no-operation (NOP) logger implementation; SLF4J: See https://www.slf4j.org/codes.html#noProviders for further details.; SLF4J: Class path contains SLF4J bindings targeting slf4j-api versions 1.7.x or earlier.; SLF4J: Ignoring binding found at [jar:file:/usr/lib/spark/jars/log4j-slf4j-impl-2.17.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]; SLF4J: See https://www.slf4j.org/codes.html#ignoredBindings for an explanation.; ```. Which, IMO, really should be a stop-the-world error.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14055:823,error,error,823,https://hail.is,https://github.com/hail-is/hail/pull/14055,1,['error'],['error']
Availability,Spark executor heartbeat timeout during hl.king(),MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12290:15,heartbeat,heartbeat,15,https://hail.is,https://github.com/hail-is/hail/issues/12290,1,['heartbeat'],['heartbeat']
Availability,"SparkBackend.scala:75); 	at is.hail.backend.spark.SparkBackend$.executeJSON(SparkBackend.scala:18); 	at is.hail.backend.spark.SparkBackend.executeJSON(SparkBackend.scala); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:483); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:282); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:238); 	at java.lang.Thread.run(Thread.java:745). Hail version: 0.2.14-8dcb6722c72a; Error summary: ScalaSigParserError: Unexpected failure; ```; If that does execute, which it does sometimes (unclear why, I don't make any code changes), I get an error from mt = hl.read_matrix_table('data/1kg.mt'):. ```; [Stage 1:> (0 + 2) / 2]2019-06-10 14:40:22 Hail: INFO: Coerced sorted dataset; [Stage 2:> (0 + 2) / 2]2019-06-10 14:40:25 Hail: INFO: wrote matrix table with 10961 rows and 284 columns in 2 partitions to data/1kg.mt; Traceback (most recent call last):; File ""gwas_tutorial.py"", line 13, in <module>; mt = hl.read_matrix_table('data/1kg.mt'); File ""</Users/username/miniconda3/envs/hail1/lib/python3.7/site-packages/decorator.py:decorator-gen-1136>"", line 2, in read_matrix_table; File ""/Users/username/miniconda3/envs/hail1/lib/python3.7/site-packages/hail/typecheck/check.py"", line 561, in wrapper; return __original_func(*args_, **kwargs_); File ""/Users/username/miniconda3/envs/hail1/lib/python3.7/site-packages/hail/methods/impex.py"", line 1708, in read_matrix_table; return MatrixTable(MatrixRead(MatrixNativeReader(path), _drop_cols, _drop_rows)); File ""/",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6299:6556,Error,Error,6556,https://hail.is,https://github.com/hail-is/hail/issues/6299,3,"['Error', 'error', 'failure']","['Error', 'error', 'failure']"
Availability,"Spinning up a VM takes around two minutes. Downloading fresh container images; takes additional time, maybe a whole minute. The cost of timing out is high: an otherwise passing PR test run may fail; demanding a bump and delaying merging of said PR by fifteen to twenty minutes. The cost of waiting two more minutes is that a resource deadlock may last; two extra minutes. We address deadlocks by scaling up and limiting concurrent; PR tests to four.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6878:43,Down,Downloading,43,https://hail.is,https://github.com/hail-is/hail/pull/6878,1,['Down'],['Downloading']
Availability,Split from https://github.com/hail-is/hail/pull/14103; Co-Authored by @patrick-schultz . This change includes some edits to prevent build failures caused by using the scala formatter,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14126:138,failure,failures,138,https://hail.is,https://github.com/hail-is/hail/pull/14126,1,['failure'],['failures']
Availability,Split multi error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3469:12,error,error,12,https://hail.is,https://github.com/hail-is/hail/issues/3469,1,['error'],['error']
Availability,"Spyder IPython Import Error | TypeError: An asyncio.Future, a coroutine or an awaitable is required",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/11758:22,Error,Error,22,https://hail.is,https://github.com/hail-is/hail/issues/11758,1,['Error'],['Error']
Availability,Stack trace from @lfrancioli ([full trace](https://nealelab.slack.com/files/laurent/F3P268282/error.txt)). ```; Caused by: java.lang.AssertionError: assertion failed; at scala.Predef$.assert(Predef.scala:156); at org.broadinstitute.hail.utils.richUtils.RichIterable$$anon$4$$anon$10.next(RichIterable.scala:71); at org.broadinstitute.hail.methods.Aggregators$$anonfun$buildVariantAggregations$1.apply(Aggregators.scala:54); at org.broadinstitute.hail.methods.Aggregators$$anonfun$buildVariantAggregations$1.apply(Aggregators.scala:45); at org.broadinstitute.hail.driver.AnnotateVariantsExpr$$anonfun$4$$anonfun$apply$1.apply(AnnotateVariantsExpr.scala:51); ; ```. The iterator returned by the genotype stream has an additional constraint (over the `Iterator[T]` interface) that `hasNext` must be called before every call to `next`. The failing assertion verifies that.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1227:94,error,error,94,https://hail.is,https://github.com/hail-is/hail/issues/1227,1,['error'],['error']
Availability,StackOverflow Kryo error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1528:19,error,error,19,https://hail.is,https://github.com/hail-is/hail/issues/1528,1,['error'],['error']
Availability,"Stacked on #11905 . Before this change, we had one long running test which verified all; the old files still parsed properly. In the service backend in particular,; one test split job was substantially longer than the rest. This is bad; for PR merge time. This change has one significant downside, ""collecting"" the tests in pytest; requires evaluating two glob patterns which takes several seconds against; GCS. It is relatively fast against the local filesystem.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11906:288,down,downside,288,https://hail.is,https://github.com/hail-is/hail/pull/11906,1,['down'],['downside']
Availability,"Stacked on #12757. - This PR gets the ranges of existing rows from the attempt_resources, aggregated_*_resources_v2 tables in bunches of 100 and then migrates each bunch by triggering an after update trigger for those rows that haven't been migrated. The triggers were added in #12757. ; - There's an audit at the end to make sure the new v3 tables give the same answer as the old v2 tables with duplicate resources.; - We use the same trick with a burn-in period to avoid the birthday problem with deadlocks.; - I added a function that generates the where statements programmatically based on looking at the where statement from previous migrations where we wrote out the where statement by hand. I think this way is less error-prone than writing out the where statement for each table, but it might be harder to reason about. Let me know if this way is too confusing.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12761:723,error,error-prone,723,https://hail.is,https://github.com/hail-is/hail/pull/12761,1,['error'],['error-prone']
Availability,"Stacked on #7260 . Also set wire and memory spec to LZ4Fast. It was a bit annoying to make serialization work with a shared super class, so if anything looks funny down there that's probably why.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7261:164,down,down,164,https://hail.is,https://github.com/hail-is/hail/pull/7261,1,['down'],['down']
Availability,"Stacked on #9346 . Changes:; - infrastructure needed for kill switch; - UI page; - Default value for the limit is None. Testing:; - In the database migration, there's two updates that populate the initial state of the aggregated_billing_resources_table. I tested this by hand using a database that hadn't been migrated previously, but this might be good to double check.; - I ran the `check_resource_aggregation` loop while running `test_batch` and made sure there were no errors.; - I tested the UI page editing the limits with negative values and gibberish by hand to make sure those failed. I also refreshed the page to make sure the values were in the database and the update worked. So here's a PR where I convinced myself it was correct a couple of days ago, but the longer this sits, the less confident I'm going to be that there's not a mistake somewhere, especially if there are a lot of changes that need to be made to the code.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9354:473,error,errors,473,https://hail.is,https://github.com/hail-is/hail/pull/9354,1,['error'],['errors']
Availability,"Stacked on: https://github.com/hail-is/hail/pull/5507. Drops one broadcast from my test dataset from 1.4MB => 300KB (5x). I think that corresponds to the parallelize for writeSplitSpecs, which is now constant (won't scale according to the number of inputs). The RDD actually doing the writing, the OriginUnionRDD, still scales linearly. I think that's inevitable unless we do the LightweightContextRVDDistributedArray thing I mentioned on Zulip since we necessarily allocate at least one RDD per input. It might still be possible to push the constants down. The point of this change is to avoid capturing the OriginUnionRDD partitions inside the map step. I did this essentially by turning OriginUnionRDD into a union with ""mapPartitionsWithOriginIndex"". I think it might be wroth trying to re-run it after this goes in. Between this one and the last one, there are some pretty big memory/broadcast savings here.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5509:552,down,down,552,https://hail.is,https://github.com/hail-is/hail/pull/5509,1,['down'],['down']
Availability,Stacked on: https://github.com/hail-is/hail/pull/5891. I found getting .in (or not) consistent between the configuration and the files was just error prone. I think this is just simpler.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5907:144,error,error,144,https://hail.is,https://github.com/hail-is/hail/pull/5907,1,['error'],['error']
Availability,"Stacked on: https://github.com/hail-is/hail/pull/7031. Changes:; - primary change was to add `Tokens.namespace_token_or_error` which prints a friendly error of the user doesn't have the necessary authentication; - added `hailctl auth list`, and made `hailctl dev config` with no options print out the current configuration; - implemented @danking's suggestion: change some natural entrypoints (BatchClient, get_userinfo, etc.) to take optional `deploy_config` argument and load the default config if not given",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7035:151,error,error,151,https://hail.is,https://github.com/hail-is/hail/pull/7035,1,['error'],['error']
Availability,"Stacked on: https://github.com/hail-is/hail/pull/7440. Changes:; - start the instance with a 1-time use activation token in the metadata; - on activation, clear the activation token, send the worker the normal token and batch-gsa-key; - upgrade the worker image to -6 which has the latest cloud-sdk (v269). As far as I can tell, the metadata server is still available from within the worker container after the upgrade, so I'm not 100% sure why this change was necessary. However, it will make things easier to lock down later. I think the picture we want is:; - store the worker and batch logs in different buckets,; - the worker instance service account only has instance.delete* and object.insert on the worker log bucket,; - the service account used by the worker only has object.insert on the batch logs bucket,; - we block access to the metdata srever from within the docker containers.Leaving this for reference:. https://stackoverflow.com/questions/32512597/block-docker-access-to-specific-ip. This isn't 100% trivial because the metadata server is also the DNS server. We could try blocking everything except udp/53. I think ideally, we'd put the docker containers on a different network that could only route to the outside and use a public DNS server like 8.8.8.8. *An instance doesn't need extra permissions to shut itself down, so we could just do `shutdown -h now` on the worker and have the batch driver actually delete the instance. I think once this goes in we can try scale up tests again.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7447:358,avail,available,358,https://hail.is,https://github.com/hail-is/hail/pull/7447,3,"['avail', 'down']","['available', 'down']"
Availability,"Stacks on #5874. Commit specific to this pr are: https://github.com/hail-is/hail/pull/5878/commits/e959eaf270c5dd9966e3c9c96f21d4f914097012, https://github.com/hail-is/hail/pull/5878/commits/fcbb0dc6ec6c678a54655afda996ee6b1148f2a1. Minor oddity: the 'updated' property isn't always available for folders. I can get around this if needed. I return the bucket for the ""owner"" property because the google sa isn't returned in the response. Will change this to the sa email (read at GoogleStorageFS instantiation)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5878:283,avail,available,283,https://hail.is,https://github.com/hail-is/hail/pull/5878,1,['avail'],['available']
Availability,Stage failure error when aggregating,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12083:6,failure,failure,6,https://hail.is,https://github.com/hail-is/hail/issues/12083,2,"['error', 'failure']","['error', 'failure']"
Availability,Starving auth of the cycles to complete authentication requests causes cascading failures in the system.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12658:81,failure,failures,81,https://hail.is,https://github.com/hail-is/hail/pull/12658,1,['failure'],['failures']
Availability,"Store: INFO: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.2 KiB, free 434.4 MiB); 2022-05-14 12:09:09 BlockManagerInfo: INFO: Added broadcast_0_piece0 in memory on 10.40.3.21:33951 (size: 3.2 KiB, free: 434.4 MiB); 2022-05-14 12:09:09 SparkContext: INFO: Created broadcast 0 from broadcast at SparkBackend.scala:311; 2022-05-14 12:09:11 root: INFO: RegionPool: FREE: 64.0K allocated (64.0K blocks / 0 chunks), regions.size = 1, 0 current java objects, thread 30: Thread-4; 2022-05-14 12:09:11 root: ERROR: HailException: Invalid locus '11:135009883' found. Position '135009883' is not within the range [1-135006516] for reference genome 'GRCh37'.; From is.hail.utils.HailException: /data/public/prs/ex_antonk.bim:1013423: Invalid locus '11:135009883' found. Position '135009883' is not within the range [1-135006516] for reference genome 'GRCh37'.; offending line: 11	.	0	135009883	CT	C; 	at is.hail.utils.ErrorHandling.fatal(ErrorHandling.scala:30); 	at is.hail.utils.ErrorHandling.fatal$(ErrorHandling.scala:28); 	at is.hail.utils.package$.fatal(package.scala:78); 	at is.hail.utils.Context.wrapException(Context.scala:21); 	at is.hail.utils.WithContext.foreach(Context.scala:51); 	at is.hail.io.plink.LoadPlink$.$anonfun$parseBim$2(LoadPlink.scala:37); 	at is.hail.io.plink.LoadPlink$.$anonfun$parseBim$2$adapted(LoadPlink.scala:36); 	at scala.collection.Iterator.foreach(Iterator.scala:941); 	at scala.collection.Iterator.foreach$(Iterator.scala:941); 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1429); 	at is.hail.io.plink.LoadPlink$.$anonfun$parseBim$1(LoadPlink.scala:36); 	at is.hail.io.plink.LoadPlink$.$anonfun$parseBim$1$adapted(LoadPlink.scala:35); 	at is.hail.io.fs.FS.$anonfun$readLines$1(FS.scala:222); 	at is.hail.utils.package$.using(package.scala:640); 	at is.hail.io.fs.FS.readLines(FS.scala:213); 	at is.hail.io.fs.FS.readLines$(FS.scala:211); 	at is.hail.io.fs.HadoopFS.readLines(HadoopFS.scala:72); 	at is.hail.io.plink.LoadPlink$.parseB",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/11836:1618,Error,ErrorHandling,1618,https://hail.is,https://github.com/hail-is/hail/issues/11836,1,['Error'],['ErrorHandling']
Availability,Struct annotate gives wrong error for mixed type dictionaries,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3886:28,error,error,28,https://hail.is,https://github.com/hail-is/hail/issues/3886,1,['error'],['error']
Availability,"Submitting a pipeline now looks like:. ```; $ hail pipeline.py; Submitted batch 120, see https://batch2.hail.is/batches/120; Waiting for batch 120...; Batch 120 complete: failure; ```. FYI @konradjk Pipeline.run now passes through kwargs to the backend. BatchBackend supports two new args: wait (default True) to wait for the pipeline to finish, and open (default False) to open the batch URL in the browser. It no longer attempts to print the failed jobs.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7672:171,failure,failure,171,https://hail.is,https://github.com/hail-is/hail/pull/7672,1,['failure'],['failure']
Availability,"Summary of changes:; - At the end of schedule, log total time and number of jobs scheduled.; - Only log database timing if total query took >20ms.; - Make sure context_manager is cleaned up in gear.Transaction.; - Limit workers to max 250 requests/s incoming to batch driver. I used an nginx limit to do this, but it is per pod, so I turned off autoscaling and increased CPU to roughly what I saw when 100K cores was hammering against a dead driver.; - Increase the worker exponential backoff from 30s to 2m. The main thing I was trying to address was the driver getting overloaded when trying to restart with a large standing cluster. It isn't totally clear why the cluster failed in the first place. I made a few other changes to mitigate the issue before adding the nginx limit, so I'm not 100% sure which combination of changes fixed the problem:. - I put a 60s timeout on the scheduler loop. This probably isn't necessary, although the scheduler does get bogged down if many of the instances it tries to schedule on are not responding. - I put a 10s timeout on mark_job_complete. - I put a maximum of 150 active mark_job_complete requests being processed, and returned service unavailable when the max was hit. I don't think this problem is completely solved. I think we want to keep the driver in the ~80% CPU load regime where everything is being processed quickly. I think we want to back off workers if, for example, mark_job_complete is taking more than 95%ile in the not overloaded case. I'm not sure who should do this, although it could be the batch-driver if internal-gateway is doing front-line throttling. Exiting in the overload case should be very cheap. We might want to prioritize mark_job_complete over the scheduler in that case, too. @danking I'd love to get some metrics for the scheduling loop: schedules/s, jobs/s, and time once this goes in. Should I switch to logging json to make that easier?",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8149:967,down,down,967,https://hail.is,https://github.com/hail-is/hail/pull/8149,1,['down'],['down']
Availability,"Summary of changes:; - add a / index page to the workshop service with some chipper content. FYI @tpoterba, feel free to change if you don't like.; - make csrf token session-based; - add common render_template function to web_common that handles csrf and jinja2 rendering. This is necessary because the header has a logout button (potentially) so every page needs make sure the csrf is set.; - added a toplevel make check target; - fixed a forwarding bug: Host: $updated_host needs to get set when proxying to the notebook itself or you get cross-origin errors in the notebook. Things I have left to do:; - make the notebook non-clickable when it isn't ready; - write up a UI testing playbook; - link to notebook/workshop-admin somewhere",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7145:554,error,errors,554,https://hail.is,https://github.com/hail-is/hail/pull/7145,1,['error'],['errors']
Availability,"Summary;; I tried running hail with spark-submit and a .py script with a short pipeline to compare speed. Offending line:; ```; kt = vds_results.make_table('v = v', 'pval = va.pval').export(""output/test.txt""); ```; gives; ```; File ""<decorator-gen-93>"", line 2, in export; File ""/home/ludvig/Programs/hail/python/hail/java.py"", line 121, in handle_py4j; 'Error summary: %s' % (deepest, full, Env.hc().version, deepest)); hail.java.FatalError: SparkException: Job aborted due to stage failure: Task 0.0 in stage 5.0 (TID 1591) had a not serializable result: is.hail.io.bgen.BgenRecordV11$$anon$1; ```; ```; Serialization stack:; 	- object not serializable (class: is.hail.io.bgen.BgenRecordV11$$anon$1, value: BgenRecordV11(0/0:.:.:.:GP=1.0,0.0,0.0, 0/0:.:.:.:GP=1.0,0.0,0.0, 0/0:.:.:.:GP=1.0,0.0,0.0, 0/0:.:.:.:GP=1.0,0.0,0.0, 0/0:.:.:.:GP=1.0,0.0,0.0, 0/0:.:.:.:GP=1.0,0.0,0.0, 0/0:.:.:.:GP=1.0,0.0,0.0, 0/0:.:.:.:GP=1.0,0.0,0.0, 0/0:.:.:.:GP=1.0,0.0,0.0, 0/0:.:.:.:GP=1.0,0.0,0.0, 0/0:.:.:.:GP=1.0,0.0,0.0, 0/0:.:.:.:GP=1.0,0.0,0.0, 0/0:.:.:.:GP=1.0,0.0,0.0, 0/0:.:.:.:GP=1.0,0.0,0.0, 0/0:.:.:.:GP=0.99798583984375,0.00201416015625,0.0, 0/0:.:.:.:GP=1.0,0.0,0.0, 0/0:.:.:.:GP=1.0,0.0,0.0, 0/0:.:.:.:GP=1.0,0.0,0.0, 0/0:.:.:.:GP=1.0,0.0,0.0,. goes on for a while. field (class: scala.Tuple2, name: _2, type: class java.lang.Object); 	- object (class scala.Tuple2, ([rs149841286:10000179:AAAAAAAC:A,---],BgenRecordV11(0/0:.:.:.:GP=1.0,0.0,0.0, 0/0:.:.:.:GP=1.0,0.0,0.0,. keeps on going like above until remaining stack trace:. at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBu",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2527:355,Error,Error,355,https://hail.is,https://github.com/hail-is/hail/issues/2527,2,"['Error', 'failure']","['Error', 'failure']"
Availability,Support checkpoint on BlockMatrix,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6933:8,checkpoint,checkpoint,8,https://hail.is,https://github.com/hail-is/hail/pull/6933,1,['checkpoint'],['checkpoint']
Availability,"Suppose you have two branches with the same base commit. Neither branch has Scala changes. Consider `make shadowJar` when switching between these branches: it thinks there's nothing to do because the Scala code hasn't changed. This of course doesn't work because the python version *is* changing (note: make install-editable refreshes the version files) and Hail refuses to use an out of date jar. This adds a tiny make macro that lets make targets depend on variables that depend on the latent environment, like git SHAs. To create a target for such a variable add this line: `$(eval $(call ENV_VAR,VARIABLE_NAME))`. Any rule that depends on the value of `VARIABLE_NAME` should depend on the target `env/VARIABLE_NAME`. I also split `BUILD_INFO` into the scala parts and the python parts and moved the scala dependency down to the shadow jar rule, where it belongs. This bug was hidden because build.gradle still regenerates the build info every time shadowJar is called. cc: @tpoterba",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6867:820,down,down,820,https://hail.is,https://github.com/hail-is/hail/pull/6867,1,['down'],['down']
Availability,"Surfaced because sometimes k8s secrets 404 for CI pipelines and we got FK constraint failures because there is no batch 0. No danger of bad data being written, just noise and unnecessary database load. Thank you foreign key checks!",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14373:85,failure,failures,85,https://hail.is,https://github.com/hail-is/hail/pull/14373,1,['failure'],['failures']
Availability,"T = simdpp::arch_avx2::uint32<4>; unsigned int MaskCastOverride = 0]; libsimdpp-2.0-rc2/simdpp/core/cast.h:63:89: required from R simdpp::arch_avx2::bit_cast(const T&) [with R = simdpp::arch_avx2::int32<4>; T = simdpp::arch_avx2::uint32<4>]; libsimdpp-2.0-rc2/simdpp/types/int32x4.h:62:35: required from simdpp::arch_avx2::int32<4>& simdpp::arch_avx2::int32<4>::operator=(const simdpp::arch_avx2::any_vec<16, V>&) [with V = simdpp::arch_avx2::uint32<4>]; libsimdpp-2.0-rc2/simdpp/core/split.h:96:8: required from void simdpp::arch_avx2::split(const simdpp::arch_avx2::int32<N>&, simdpp::arch_avx2::int32<(N / 2)>&, simdpp::arch_avx2::int32<(N / 2)>&) [with unsigned int N = 8]; libsimdpp-2.0-rc2/simdpp/detail/insn/to_int64.h:67:20: required from here; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:40:13: error: void* memcpy(void*, const void*, size_t) copying an object of type class simdpp::arch_avx2::int32<4> with private member simdpp::arch_avx2::int32<4>::d_ from an array of const class simdpp::arch_avx2::uint32<4>; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/types.h:23,; from libsimdpp-2.0-rc2/simdpp/core/align.h:15,; from libsimdpp-2.0-rc2/simdpp/simd.h:22,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/types/int32x4.h:33:7: note: class simdpp::arch_avx2::int32<4> declared here; class int32<4, void> : public any_int32<4, int32<4,void>> {; ^~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/simd.h:132,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl: In instantiation of R simdpp::arch_avx2::detail::cast_memcpy(const T&) [with R = simdpp::arch_avx2::uint8<32>; T = simdpp::arch_avx2::int32<8>]:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::arch_a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3955:119124,error,error,119124,https://hail.is,https://github.com/hail-is/hail/issues/3955,1,['error'],['error']
Availability,"THON-CRYPTOGRAPHY-5914629) | `cryptography:` <br> `3.3.2 -> 41.0.6` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **479/1000** <br/> **Why?** Has a fix available, CVSS 5.3 | Missing Cryptographic Step <br/>[SNYK-PYTHON-CRYPTOGRAPHY-6036192](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-6036192) | `cryptography:` <br> `3.3.2 -> 41.0.6` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **616/1000** <br/> **Why?** Proof of Concept exploit, Has a fix available, CVSS 5.9 | NULL Pointer Dereference <br/>[SNYK-PYTHON-CRYPTOGRAPHY-6092044](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-6092044) | `cryptography:` <br> `3.3.2 -> 41.0.6` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **519/1000** <br/> **Why?** Has a fix available, CVSS 6.1 | Information Exposure <br/>[SNYK-PYTHON-REQUESTS-5595532](https://snyk.io/vuln/SNYK-PYTHON-REQUESTS-5595532) | `requests:` <br> `2.27.1 -> 2.31.0` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI0Yzg3NGFkNy01NjNmLTQ5Y2QtOTc3My04YjlmMTA5NWUzNmMiLCJldmVudCI6IlBSIH",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14148:8652,avail,available,8652,https://hail.is,https://github.com/hail-is/hail/pull/14148,1,['avail'],['available']
Availability,"TODO. Goal is all non-stretch items done by late tomorrow night/early Friday morning. Friday - Sunday testing, Cotton takes a closer look on Monday. - [x] No SQL; store user / svc / token labels (all things that need to be validated before redirect); - [x] Websockets; - [x] Service, pod definitions, makefile updates => notebook-v2 service name; - [x] Deploy notebook service, Deploy web service ( say web service name, mapping to web.hail.is ); - [x] Direct modification of gateway: check site service for breaks after each change to prevent user ; - [x] Test in cluster; - [x] Make sure Notebook v1 still works; - [ ] Stretch, and only in v3 so Feb 5 entropy minimized: asynchttp + uvloop; - [ ] Stretch ?: route by pod ip instead of svc name: DNS propagation latency significantly longer than pod instantiation time, which sucks for users, both because notebook instances will look broken when they're not, and because if we mask that the apparent latency to first useful operation is multiples of that needed. new: ; Cotton is right, mysql is adding too much complexity for the minimal use case, esp. with gevent conflicting with PyMySQL, necessitating per route handler connection. old:; Not ready to be merged, would like to improve SQL connection handling. 6a4599df5dfe0affdb5e367dd9cdc70cca59fd17 onward dependent on this. MySQL use is unoptimized because PyMySQL doesn't play well with gevent in the following way: initial impression from reading was that monkey.patch_all() before creation of global connection should result in connection spawned for each new request, or to at least private to a greenlet. Doesn't appear to be the case, plenty of connection errors. So establishing connection within each request, which is slow. . Python C library also out, because it does not play well with Python threading/greenlet/monkey patch implementations. MySQL Connector is an option, provides thread pools, but is also slowest option, by up to 10x, for small requests, like our are likely to be",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5215:929,mask,mask,929,https://hail.is,https://github.com/hail-is/hail/pull/5215,1,['mask'],['mask']
Availability,"TTP and HTTPS ports in <code>Host</code> header unless explicitly specified by the user</li>; </ul>; <h2>5.1.1</h2>; <p>Bug fixes:</p>; <ul>; <li>Correctly update cached sources</li>; </ul>; <p>Maintenance:</p>; <ul>; <li>Add integration tests for Gradle 7.5 and 7.5.1</li>; <li>Update dependencies</li>; </ul>; <h2>5.1.0</h2>; <p>New features:</p>; <ul>; <li>Add possibility to enable preemptive Basic authentication (through the new <code>preemptiveAuth</code> flag)</li>; <li>Warn if server does not send <code>WWW-Authenticate</code> header in 401 response</li>; <li>Log request and response headers in debug mode</li>; </ul>; <p>Maintenance:</p>; <ul>; <li>Add integration tests for Gradle 7.4.1 and 7.4.2</li>; <li>Update dependencies</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/0f43ce67de72bd511d849c07bd7728c0d6f2e6dd""><code>0f43ce6</code></a> Document path and relativePath properties</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/a8504f9d60d0264808894e4bb80d4a73b8086a3e""><code>a8504f9</code></a> Bump up version number to 5.3.0</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/708067cd11c4a013da7a8c15d91f7f946967cf94""><code>708067c</code></a> Update dependencies</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/0fdebf3c7ad43ed4739d0400c333a72b32f5d514""><code>0fdebf3</code></a> Improve verify example</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/019089b9554692674d6baee7df7d4d884f310cc9""><code>019089b</code></a> Correctly create list of output files</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/fa2739ded05333ba46d8f50bb3b2a3721cf0ca86""><code>fa2739d</code></a> Create target directories at a central place</li>; <li><a href=""https://github.com/mic",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12345:3216,down,download-task,3216,https://hail.is,https://github.com/hail-is/hail/pull/12345,1,['down'],['download-task']
Availability,Tabix just immediately creates a tiny index but does not throw any errors.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/160:67,error,errors,67,https://hail.is,https://github.com/hail-is/hail/issues/160,1,['error'],['errors']
Availability,Table field with '$' error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5120:21,error,error,21,https://hail.is,https://github.com/hail-is/hail/issues/5120,1,['error'],['error']
Availability,Table.show(-1) throws an error instead of showing everything,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6122:25,error,error,25,https://hail.is,https://github.com/hail-is/hail/issues/6122,1,['error'],['error']
Availability,Table.to_matrix_table bad error message on duplicate row keys,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4114:26,error,error,26,https://hail.is,https://github.com/hail-is/hail/issues/4114,1,['error'],['error']
Availability,"TableIRSuite extensively uses the function; ```; def collect(tir: TableIR): TableCollect = TableCollect(TableKeyBy(tir, FastIndexedSeq())); ```; to compare the result of a `TableIR` with the expected collection. But `TableCollect` makes no promises what order the results will be in, and in particular the optimizer is allowed to remove that `TableKeyBy`. This PR redefines that function to use the collect aggregator, which does promise the order rows are collected. It also fixes a small type error in the `TableJoin` lowering case that was uncovered.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9054:495,error,error,495,https://hail.is,https://github.com/hail-is/hail/pull/9054,1,['error'],['error']
Availability,"Tags and digests have no affect on whether an image is one of the hailgenetics; images that are stored in both GCR and DockerHub. This change ignores the tag and; digest when checking if we should warn about using DockerHub. In doing this, I consolidated and made more robust our Docker-image-reference parsing.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10327:269,robust,robust,269,https://hail.is,https://github.com/hail-is/hail/pull/10327,1,['robust'],['robust']
Availability,"TaskRunner.$anonfun$run$3(Executor.scala:548); 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551); 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128); 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628); 	at java.base/java.lang.Thread.run(Thread.java:829). Hail version: 0.2.130-bea04d9c79b5; Error summary: HailException: VEP command '/vep --format vcf --json --everything --allele_number --no_stats --cache --offline --minimal --assembly GRCh38 --fasta /opt/vep/.vep/homo_sapiens/95_GRCh38/Homo_sapiens.GRCh38.dna.toplevel.fa.gz --plugin LoF,loftee_path:/opt/vep/Plugins/,gerp_bigwig:/opt/vep/.vep/gerp_conservation_scores.homo_sapiens.GRCh38.bw,human_ancestor_fa:/opt/vep/.vep/human_ancestor.fa.gz,conservation_file:/opt/vep/.vep/loftee.sql --dir_plugins /opt/vep/Plugins/ -o STDOUT' failed with non-zero exit status 2; VEP Error output:; Smartmatch is experimental at /opt/vep/Plugins/de_novo_donor.pl line 175.; Smartmatch is experimental at /opt/vep/Plugins/de_novo_donor.pl line 214.; Smartmatch is experimental at /opt/vep/Plugins/splice_site_scan.pl line 191.; Smartmatch is experimental at /opt/vep/Plugins/splice_site_scan.pl line 194.; Smartmatch is experimental at /opt/vep/Plugins/splice_site_scan.pl line 238.; Smartmatch is experimental at /opt/vep/Plugins/splice_site_scan.pl line 241.; DBI connect('dbname=/opt/vep/.vep/loftee.sql','',...) failed: unable to open database file at /opt/vep/Plugins/LoF.pm line 126. -------------------- EXCEPTION --------------------; MSG: ERROR: No cache found for homo_sapiens, version 95. STACK Bio::EnsEMBL::VEP::CacheDir::dir /opt/vep/src/ensembl-vep/modules/Bio/EnsEMBL/VEP/CacheDir.pm:328; STACK Bio::EnsEMBL::VEP::CacheDir::init /opt/vep/src/ensembl-vep/modules/Bio/EnsEMBL/VEP/CacheDir.pm:227; STACK Bio::EnsEMBL::VEP::CacheDir::new /opt/vep/src/ensembl-vep/modul",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14513:20326,Error,Error,20326,https://hail.is,https://github.com/hail-is/hail/issues/14513,1,['Error'],['Error']
Availability,"Teaches `hfs.ls('gs://bucket/')` to list the files and directories at the top-level of the bucket. In `main` that command raises because this line of `_ls_no_glob` raises:. ```python3; maybe_sb_and_t, maybe_contents = await asyncio.gather(; self._size_bytes_and_time_modified_or_none(path), ls_as_dir(); ); ```. In particular, `statfile` raises a cloud-specific, esoteric error about a malformed URL or empty object names:. ```python3; async def _size_bytes_and_time_modified_or_none(self, path: str) -> Optional[Tuple[int, float]]:; try:; # Hadoop semantics: creation time is used if the object has no notion of last modification time.; file_status = await self.afs.statfile(path); return (await file_status.size(), file_status.time_modified().timestamp()); except FileNotFoundError:; return None; ```. I decided to add a sub-class of `FileNotFoundError` which is self-describing: `IsABucketError`. I changed most methods to raise that error when given a bucket URL. The two interesting cases:. 1. `isdir`. This raises an error but I could also see this returning `True`. A bucket is like a directory whose path/name is empty. 2. `isfile`. This returns False but I could also see this raising an error. This just seems convenient, we know the bucket is not a file so we should say so. ---. Apparently `hfs.ls` had no current tests because the globbing system doesn't work with Azure https:// URLs. I fixed it to use `AsyncFSURL.with_new_path_component` which is resilient to Azure https weirdness. However, I had to change `with_new_path_component` to treat an empty path in a special way. I wanted this to hold:. ```; actual = str(afs.parse_url('gs://bucket').with_new_path_component('bar')); expected = 'gs://bucket/bar'; assert actual == expected; ```. But `with_new_path_component` interacts badly with `GoogleAsyncFSURL.__str__` to return this:. ```; 'gs://bucket//bar'; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14176:372,error,error,372,https://hail.is,https://github.com/hail-is/hail/pull/14176,5,"['error', 'resilien']","['error', 'resilient']"
Availability,Test Errors from Digital China Health,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/683:5,Error,Errors,5,https://hail.is,https://github.com/hail-is/hail/issues/683,1,['Error'],['Errors']
Availability,"Test:. ```scala; @Test def testArrayLeftJoin() {; val l = Ref(genUID(), TInt32()); val r = Ref(genUID(), TInt32()); val left = ArrayRange(0, 10, 1); val right = MakeArray(Seq(2, 5, 8), TArray(TInt32())); assertEvalsTo(; ArrayLeftJoinDistinct(; left, right,; l.name, r.name,; l - r,; If(IsNA(r), l, 0)),; IndexedSeq(0, 1, 0, 3, 4, 0, 6, 7, 0, 9))(; ExecStrategy.javaOnly; ); }; ```. Fails with: `java.lang.IllegalStateException: Bytecode failed verification 1`. ```; Verify Output 2 for is/hail/codegen/generated/C1:; org.objectweb.asm.tree.analysis.AnalyzerException: Error at instruction 478: Argument 2: expected I, but found J; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6827:568,Error,Error,568,https://hail.is,https://github.com/hail-is/hail/issues/6827,1,['Error'],['Error']
Availability,"TestNG Suite from JAR File Fails to Delete Temporary Copy of Suite File (Steven Jubb); Fixed: GITHUB-2818: Add configuration key for callback discrepancy behavior (Krishnan Mahadevan); Fixed: GITHUB-2819: Ability to retry a data provider in case of failures (Krishnan Mahadevan); Fixed: GITHUB-2308: StringIndexOutOfBoundsException in findClassesInPackage - Surefire/Maven - JDK 11 fails (Krishnan Mahadevan); Fixed: GITHUB:2788: TestResult.isSuccess() is TRUE when test fails due to expectedExceptions (Krishnan Mahadevan); Fixed: GITHUB-2800: Running Test Classes with Inherited <a href=""https://github.com/Factory""><code>@Factory</code></a> and <a href=""https://github.com/DataProvider""><code>@DataProvider</code></a> Annotated Non-Static Methods Fail (Krishnan Mahadevan); New: Ability to provide custom error message for assertThrows\expectThrows methods (Anatolii Yuzhakov); Fixed: GITHUB-2780: Use SpotBugs instead of abandoned FindBugs; Fixed: GITHUB-2801: JUnitReportReporter is too slow; Fixed: GITHUB-2807: buildStackTrace should be fail-safe (Sergey Chernov); Fixed: GITHUB-2830: TestHTMLReporter parameter toString should be fail-safe (Sergey Chernov); Fixed: GITHUB-2798: Parallel executions coupled with retry analyzer results in duplicate retry analyzer instances being created (Krishnan Mahadevan)</p>; <p>7.6.1; Fixed: GITHUB-2761: Exception: ERROR java.nio.file.NoSuchFileException: /tmp/testngXmlPathInJar-15086412835569336174 (Krishnan Mahadevan); 7.6.0; Fixed: GITHUB-2741: Show fully qualified name of the test instead of just the function name for better readability of test output.(Krishnan Mahadevan); Fixed: GITHUB-2725: Honour custom attribute values in TestNG default reports (Krishnan Mahadevan); Fixed: GITHUB-2726: <a href=""https://github.com/AfterClass""><code>@AfterClass</code></a> config method is executed for EACH <a href=""https://github.com/Test""><code>@Test</code></a> method when parallel == methods (Krishnan Mahadevan); Fixed: GITHUB-2752: TestListener i",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12665:11806,error,error,11806,https://hail.is,https://github.com/hail-is/hail/pull/12665,3,"['error', 'fail-safe']","['error', 'fail-safe']"
Availability,"Tests fail, segmentation fault, issue in copyFromType added test in PBaseStruct, haven't solved yet, no remaining time today.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7958:25,fault,fault,25,https://hail.is,https://github.com/hail-is/hail/pull/7958,1,['fault'],['fault']
Availability,"Tests not passing, not sure why yet. Errors are MatchError. Stacked on #6421, will see if I can unwind; ```sh; > Task :test; Running test: Test method bitPackedVectorCorrectWhenOffsetNotZero(is.hail.methods.LocalLDPruneSuite). Gradle suite > Gradle test > is.hail.methods.LocalLDPruneSuite.bitPackedVectorCorrectWhenOffsetNotZero PASSED; Running test: Test method testBitPackUnpack(is.hail.methods.LocalLDPruneSuite). Gradle suite > Gradle test > is.hail.methods.LocalLDPruneSuite.testBitPackUnpack FAILED; scala.MatchError at LocalLDPruneSuite.scala:222; Running test: Test method testIsLocallyUncorrelated(is.hail.methods.LocalLDPruneSuite). Gradle suite > Gradle test > is.hail.methods.LocalLDPruneSuite.testIsLocallyUncorrelated FAILED; org.apache.spark.SparkException at LocalLDPruneSuite.scala:214; Caused by: scala.MatchError; Running test: Test method testR2(is.hail.methods.LocalLDPruneSuite). Gradle suite > Gradle test > is.hail.methods.LocalLDPruneSuite.testR2 FAILED; scala.MatchError at LocalLDPruneSuite.scala:244; Running test: Test method testRandom(is.hail.methods.LocalLDPruneSuite). Gradle suite > Gradle test > is.hail.methods.LocalLDPruneSuite.testRandom FAILED; java.lang.AssertionError at LocalLDPruneSuite.scala:323; Caused by: scala.MatchError at LocalLDPruneSuite.scala:323; ```. cc @tpoterba",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6425:37,Error,Errors,37,https://hail.is,https://github.com/hail-is/hail/pull/6425,1,['Error'],['Errors']
Availability,"TextContext should attach the caught exception as the cause on the resulting fatal error. I have partial code for this and will make a PR, just leaving this here as a reminder.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1556:83,error,error,83,https://hail.is,https://github.com/hail-is/hail/issues/1556,1,['error'],['error']
Availability,"The 'build' docs page implies that the only requirement for running hail is Gradle. However, I've just tried to build hail on Debian Jessie and Ubuntu 16.04, and both failed in different ways. On Jessie, I was able to figure out that the version of Gradle was too old. On Ubuntu 16.04, I get. ```; :compileJava UP-TO-DATE; :compileScala FAILED. FAILURE: Build failed with an exception. * What went wrong:; A problem was found with the configuration of task ':compileScala'.; > No value has been specified for property 'zincClasspath'. * Try:; Run with --stacktrace option to get the stack trace. Run with --info or --debug option to get more log output. BUILD FAILED; ```. A quick Google around doesn't reveal any obvious answers to this. What version of Gradle is needed? Is Scala a prerequisite? It would be very useful to provide detailed instructions on how to build hail from scratch on a fresh installation of some Linux distribution.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/594:345,FAILURE,FAILURE,345,https://hail.is,https://github.com/hail-is/hail/issues/594,1,['FAILURE'],['FAILURE']
Availability,The Azure blob storage client does not include the blob name in file not found errors. This adds that information to the `FileNotFoundError` that we raise on top of the azure error in the azure fs's `read`.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11214:79,error,errors,79,https://hail.is,https://github.com/hail-is/hail/pull/11214,2,['error'],"['error', 'errors']"
Availability,"The GENCODE GTF files associated with gnomAD annotations are occasionally useful. For example, they are needed to get the gene and transcript version numbers for VEP annotations for Ensembl transcripts. Or they can be used to get an interval for a particular gene or transcript, which can then be used to efficiently filter the variants Hail tables. However, the files hosted by GENCODE are not block gzipped. Thus, they are slow to import into Hail because the import cannot be parallelized. To make working with this data in Hail easier, it would be nice if the relevant versions of GENCODE were available in [Hail's Datasets collection](https://hail.is/docs/0.2/datasets.html). It looks like GENCODE v19 and v31 are already there. https://www.gencodegenes.org/human/releases.html; https://gnomad.broadinstitute.org/help/what-version-of-gencode-was-used-to-annotate-variants. This is effectively the same request as broadinstitute/gnomad_production#1042.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/11899:598,avail,available,598,https://hail.is,https://github.com/hail-is/hail/issues/11899,1,['avail'],['available']
Availability,"The IP address we got from `address` might be the IP of a pod that has been removed. When this happens; we get connection failed errors, which we treat as ""transient"". This change modifies the test to also; get a new IP address each time a transient error occurs. Not ideal, but more correct than previously.; There are forthcoming changes that I hope will more pervasively address this problem.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9963:129,error,errors,129,https://hail.is,https://github.com/hail-is/hail/pull/9963,2,['error'],"['error', 'errors']"
Availability,The SNP manipulation functions are huge and get inlined a million; times in sample_qc. This will help keep IR size down.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6200:115,down,down,115,https://hail.is,https://github.com/hail-is/hail/pull/6200,1,['down'],['down']
Availability,"The VDS combiner is flaky on query on batch on GCP due to issues reading VCFs with intervals. Errors observed:. - BGZ validation errors; - Unexpected end of input. Both of these point to issues in the interface between the `FSSeekableInputStream` that underpins GoogleFS and the `BGZipInputStream` that contains it at least in the presence of more than one seek. Unfortunately, the conditions that reproduce this are rare, and when our clusters are quieter (nighttime) the errors are even less frequent.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13356:94,Error,Errors,94,https://hail.is,https://github.com/hail-is/hail/issues/13356,3,"['Error', 'error']","['Errors', 'errors']"
Availability,The [API](https://docs.microsoft.com/en-us/azure/virtual-machines/states-billing) optionally postfixes an error code/modifier so it seems more robust to look at the prefixes here. This currently manifested with a `ProvisioningState/failed/AllocationFailed` state leaving an instance forever pending.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11393:106,error,error,106,https://hail.is,https://github.com/hail-is/hail/pull/11393,2,"['error', 'robust']","['error', 'robust']"
Availability,"The [documented](https://hail.is/docs/0.2/getting_started_developing.html#building-the-docs-and-website) process for building documentation is:; ```; cd hail; make docs-no-test; ```. That now fails with; ```; Warning, treated as error:; html_extra_path entry '/path/to/hail/hail/build/docs/../../../../../../../../../../../../../../../../../../../../../../../../../../../../../../../../../../../../../../../../../../../../../../../../../../www/hail-logo-cropped.png' does not exist; make[1]: *** [html] Error 2; make: *** [docs-no-test] Error 2; ```. It looks like the source of the problem is that docs/conf.py can't find the `www` directory.; https://github.com/hail-is/hail/blob/0b3823af5310a735bc9544fb73308f82426292be/hail/python/hail/docs/conf.py#L225-L232. I'm guessing this is related to changes in #8923.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8940:229,error,error,229,https://hail.is,https://github.com/hail-is/hail/issues/8940,3,"['Error', 'error']","['Error', 'error']"
Availability,"The `delete_azure_batch_instances` step is failing on various PRs with the error `jq: command not found`. This appears to be because we do not pin the version for the `mcr.microsoft.com/azure-cli` image, and while that image was previously based on the Alpine image, [now it is based on the Azure Linux image](https://learn.microsoft.com/en-us/cli/azure/run-azure-cli-docker), and does not appear to have `jq` (or `kubectl`) preinstalled on it. This change updates the commands run in the `azure-cli` container for this CI step to install `jq` and `kubectl` via `curl` before running the relevant commands. The `curl` commands were tested locally by running `docker run -it mcr.microsoft.com/azure-cli` and trying them out in the image's shell. This change also adds the installation commands in the other place where this image is used (when cleaning up from `buildImage2` jobs that are run in Azure).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14677:75,error,error,75,https://hail.is,https://github.com/hail-is/hail/pull/14677,1,['error'],['error']
Availability,The `download` function does this already.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11813:5,down,download,5,https://hail.is,https://github.com/hail-is/hail/pull/11813,1,['down'],['download']
Availability,"The `log.exception` in the wrapping try/except means we log anything that raises as an error, even things like 503's and 403's from the workers which we explicitly log as info. I think we're abusing exception handling here to catch a potentially non-exceptional failure mode which is ""we couldn't schedule, we need to add back those cores"". Didn't rework things though, just pushed the exception logging in to the only chunk of code that wasn't already in a nested try/except.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11715:87,error,error,87,https://hail.is,https://github.com/hail-is/hail/pull/11715,2,"['error', 'failure']","['error', 'failure']"
Availability,The `repr` for SparkContext displays like this: `<pyspark.context.SparkContext object at 0x7ff241c5f690>`. We don't have a history available for a SparkContext object. Not clear how to fix this other than use `sc` if a non-default arg is given for `sc` in HailContext constructor.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2180:131,avail,available,131,https://hail.is,https://github.com/hail-is/hail/issues/2180,1,['avail'],['available']
Availability,"The asyncio event loop only keeps weak references to tasks, so wherever we call `asyncio.create_task` we need to ensure that we keep a strong reference to its result. Specifically, `BackgroundTaskManager` needs to keep strong references not weak references to the tasks it creates. This is easy to do without accumulating garbage by using a done callback on the task to remove itself from the set. However, this felt iffy with the threadsafe futures, which were only used in sync.py anyway, so I pushed that functionality directly into sync.py and removed it from the `BackgroundTaskManager`. To simplify the ownership story for tasks, this changes `BackgroundTaskManager` to *not* return the task and instead hold onto strong references. If a client wants a reference to the task it creates, it should call `asyncio.create_task` directly and manage the lifecycle of the spawned task. This required only a few small changes in worker.py since most of the codebase does not assign the result of `task_manager.ensure_future`. The only change that gave me pause was the handling of `mjs_fut`, whose lifetime is a little tricky since it is potentially passed to yet another task. I think this shows a general weakness in the handling of ownership and lifetimes in between the Job and Worker classes and think a larger refactor can make this less error-prone but is out of scope for this fix. So I'd appreciate an especially scrutinizing look at that piece of the code.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12692:1342,error,error-prone,1342,https://hail.is,https://github.com/hail-is/hail/pull/12692,1,['error'],['error-prone']
Availability,"The batch UI column is named ""Failed"" but it means ""bad"" or ""Failure and Error"".",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7770:61,Failure,Failure,61,https://hail.is,https://github.com/hail-is/hail/issues/7770,2,"['Error', 'Failure']","['Error', 'Failure']"
Availability,"The children field in `table2` is the number of children with any mendel errors, not the number of children in that family. This should probably be fixed by doing an `annotate_cols` aggregation and then aggregating the result.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5786:73,error,errors,73,https://hail.is,https://github.com/hail-is/hail/issues/5786,1,['error'],['errors']
Availability,"The code I'm trying to run is below. It uses functionality from my experimental vcf_combiner branch,; available [here](https://github.com/chrisvittal/hail/blob/35456f1e4766e00958c3f0aaf464f2089bc73dfd/python/hail/experimental/vcf_combiner.py). I have attached console output of the script below as well. ```python3; #!/user/bin/env python3; import sys; from time import perf_counter. import hail as hl; from hail.experimental.vcf_combiner import combine_vcfs. def main():; hl.init(default_reference='GRCh38', min_block_size=0); start = perf_counter(); mt = hl.read_matrix_table(sys.argv[1]); mts = [mt for _ in range(0, 2)]; combine_vcfs(*mts).write(sys.argv[2]); end = perf_counter(); print(f'Time elapsed {end - start}'). if __name__ == '__main__':; main(); ```. [script.err.txt](https://github.com/hail-is/hail/files/2328852/script.err.txt)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4222:102,avail,available,102,https://hail.is,https://github.com/hail-is/hail/issues/4222,1,['avail'],['available']
Availability,"The code as written doesn't seem to allow this to happen. Did someone else bind to that port? It looks like it can happen if an unhandled exception occurs during docker stop or delete, in which case we free the port even though the container might still have the port open. ```; Traceback (most recent call last):; File ""/usr/local/lib/python3.6/site-packages/batch/worker.py"", line 354, in run; start_container, self.container); File ""/usr/local/lib/python3.6/site-packages/batch/worker.py"", line 94, in wrapper; return await asyncio.wait_for(f(*args, **kwargs), timeout); File ""/usr/local/lib/python3.6/asyncio/tasks.py"", line 358, in wait_for; return fut.result(); File ""/usr/local/lib/python3.6/site-packages/batch/worker.py"", line 142, in start_container; return await container.start(); File ""/usr/local/lib/python3.6/site-packages/aiodocker/containers.py"", line 170, in start; data=kwargs,; File ""/usr/local/lib/python3.6/site-packages/aiodocker/docker.py"", line 291, in __aenter__; resp = await self._coro; File ""/usr/local/lib/python3.6/site-packages/aiodocker/docker.py"", line 206, in _do_query; raise DockerError(response.status, json.loads(what.decode(""utf8""))); aiodocker.exceptions.DockerError: DockerError(500, 'driver failed programming external connectivity on endpoint batch-20376-job-59-main (8a971634c54c03a1e7df1b4255814137c92e10d310b3d47a1fe6cb7432222ed0): Error starting userland proxy: listen tcp 0.0.0.0:46572: bind: address already in use'); ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8411:1379,Error,Error,1379,https://hail.is,https://github.com/hail-is/hail/issues/8411,1,['Error'],['Error']
Availability,"The current `on_cleanup` code carefully attempts to close resources in the correct order (if B depends on A, we should close B before we close A). Doing so is pretty error prone though and we have messed it up in the past, leading to noisy error logs when pods are shut down. If we instead push `.close` methods onto a stack immediately after they are initialized, the exit stack cannot be executed in the wrong order.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14172:166,error,error,166,https://hail.is,https://github.com/hail-is/hail/pull/14172,3,"['down', 'error']","['down', 'error']"
Availability,"The default behavior, is, apparently, to error, not to return `None`. This change makes the missing value case return `None` which triggers the ValueError on the next line.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8651:41,error,error,41,https://hail.is,https://github.com/hail-is/hail/pull/8651,1,['error'],['error']
Availability,"The default options are all false. If left all false, the user gets an clear error saying that they must include at least one entry field. This forces users to think about what they actually need to import, as it can make a big difference on, say, UKBB until we have better tech. I've updated the docs and tests accordingly. @cseed suggested that we remove BGEN v1.1 support if nobody is reliant on it anymore. I've asked on Slack. So I didn't add more complexity to support these options for BGEN v1.1. Rather this PR requires GT and GP set to true if any file is 1.1 (as explained in docs and error message). If nobody minds, we can rip out BGEN 1.1 and update the docs simultaneously in a subsequent PR.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2930:77,error,error,77,https://hail.is,https://github.com/hail-is/hail/pull/2930,2,['error'],['error']
Availability,"The deploy job we thought was running may have been deleted for a variety of reasons. It's not an error for that to happen, especially since we're about to accept a different deploy job that was running for the same desired target sha. This can happen if an old CI starts a deploy but is then killed and this CI creates another deploy job before it hears of the old CI's deploy job (and the old one finishes first).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4979:98,error,error,98,https://hail.is,https://github.com/hail-is/hail/pull/4979,1,['error'],['error']
Availability,The docker file describes a sufficient environment to build and test hail 0.1. The Makefile wraps up Docker image production. The `hail-docs-trampoline.sh` delays the `git rev-parse` until the docs are actually built which allows `gradle downloadDependencies` to run without the `.git` folder present which allows me to cache some of the gradle dependencies once rather than per-build. `hail-ci-build-image` contains the name of a docker image in which to build and test hail 0.1. `hail-ci-build.sh` describes how to build and test hail 0.1 and populates the `artifacts` directory with the results and an index file.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4123:238,down,downloadDependencies,238,https://hail.is,https://github.com/hail-is/hail/pull/4123,1,['down'],['downloadDependencies']
Availability,"The error encountered when importing multiple VCFs with different INFO fields was not a good one. This improves the situation somewhat, by making it print the types instead of the ptypes, by calling attention to the fact that the issue is likely info fields, and by adding a test of this error message. . The situation could still be improved by pushing error ids through `TableRead`, but I have not done so yet. I will save that for a future PR.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10819:4,error,error,4,https://hail.is,https://github.com/hail-is/hail/pull/10819,3,['error'],['error']
Availability,"The error message you get is this:; ```; Error from server (BadRequest): a container name must be specified for pod blog-0, choose one of: [nginx blog]; ```. This option is described in `kubectl logs --help` as:; > --all-containers=false: Get all containers logs in the pod(s).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8494:4,error,error,4,https://hail.is,https://github.com/hail-is/hail/pull/8494,2,"['Error', 'error']","['Error', 'error']"
Availability,"The error this fixes is in the line: ; `if not step.run_if_requested or step.name in requested_step_names`. when `requested_step_names is None`, you cannot check if a value is `in` it. I chose not to make the default value of `requested_step_names = []`, since it's dangerous to do that in python (that single mutable list will be shared across invocations of the constructor)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7793:4,error,error,4,https://hail.is,https://github.com/hail-is/hail/pull/7793,1,['error'],['error']
Availability,"The errors look like this:; ```; {""levelname"": ""INFO"", ""asctime"": ""2019-07-02 13:36:45,504"", ""filename"": ""batch.py"", ""funcNameAndLine"": ""update_job_with_pod:1074"", ""message"": ""update job (278, 6858, 'main') with pod batch-278-job-6858-5879db""}; {""levelname"": ""INFO"", ""asctime"": ""2019-07-02 13:36:45,504"", ""filename"": ""batch.py"", ""funcNameAndLine"": ""update_job_with_pod:1087"", ""message"": ""job (278, 6858, 'main') mark complete""}; File ""/usr/local/lib/python3.6/dist-packages/batch/k8s.py"", line 65, in wrapped; **kwargs),; File ""/usr/local/lib/python3.6/dist-packages/batch/blocking_to_async.py"", line 6, in blocking_to_async; thread_pool, lambda: fun(*args, **kwargs)); File ""/usr/lib/python3.6/concurrent/futures/thread.py"", line 56, in run; result = self.fn(*self.args, **self.kwargs); File ""/usr/local/lib/python3.6/dist-packages/batch/blocking_to_async.py"", line 6, in <lambda>; thread_pool, lambda: fun(*args, **kwargs)); File ""/usr/local/lib/python3.6/dist-packages/kubernetes/client/apis/core_v1_api.py"", line 18538, in read_namespaced_pod_log; (data) = self.read_namespaced_pod_log_with_http_info(name, namespace, **kwargs); File ""/usr/local/lib/python3.6/dist-packages/kubernetes/client/apis/core_v1_api.py"", line 18644, in read_namespaced_pod_log_with_http_info; collection_formats=collection_formats); File ""/usr/local/lib/python3.6/dist-packages/kubernetes/client/api_client.py"", line 334, in call_api; _return_http_data_only, collection_formats, _preload_content, _request_timeout); File ""/usr/local/lib/python3.6/dist-packages/kubernetes/client/api_client.py"", line 168, in __call_api; _request_timeout=_request_timeout); File ""/usr/local/lib/python3.6/dist-packages/kubernetes/client/api_client.py"", line 355, in request; headers=headers); File ""/usr/local/lib/python3.6/dist-packages/kubernetes/client/rest.py"", line 231, in GET; query_params=query_params); File ""/usr/local/lib/python3.6/dist-packages/kubernetes/client/rest.py"", line 222, in request; raise ApiException(http_resp=r);",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6545:4,error,errors,4,https://hail.is,https://github.com/hail-is/hail/issues/6545,1,['error'],['errors']
Availability,"The first series addressing https://github.com/hail-is/hail/issues/6952. If we like this, will implement Coalesce Node in a similar manner. As part of this NA node changes, so that elements of collections are set to required (effectively a hoop when taking the boolean and of requireness on element types of non-NA nodes). Implemented and tested for every collection type, besides PNDArray, because we currently don't support arrays of NDArray. This also fixes the ToDict node inference, which requires the union of top-down and bottom-up element requiredeness inference. cc @patrick-schultz @catoverdrive",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6990:520,down,down,520,https://hail.is,https://github.com/hail-is/hail/pull/6990,1,['down'],['down']
Availability,"The fix for Notebook is on line 242. Copying from my Zulip post:. > I made a mistake when I implemented TLS.; >; > In the following code snippet we use ssl_client_session which should probably be; > called in_cluster_ssl_client_session. It's supposed to be used to communicate; > with other services in the cluster. That needs to be changed back to; > aiohttp.ClientSession which loads the normal system certificates (including the; > VeriSign root certs that signed the public certs that gateway uses, different; > from the internal certs that our services use).; >; > In particular, note that the error says ""unable to get local issuer; > certificate."" That means that the local trust store lacks a certificate that; > trusts the remote server's certificate. In Dania's case, the default python on; > OS X lacks all certificates, so every remote server is untrusted. In notebook's; > case, ssl_client_session creates an SSL/TLS session that only trusts Hail; > internal services (in particular, it does not trust the certificates that; > gateway uses for incoming public traffic). The error also says that the server; > in question is workshop.hail.is which is a public domain (note the hail.is), so; > that traffic is going through the public gateway with its public certificates.; >; > ```; > # don't have dev credentials to connect through internal.hail.is; > ready_url = deploy_config.external_url(; > service,; > f'/instance/{notebook[""notebook_token""]}/?token={notebook[""jupyter_token""]}'); > try:; > async with ssl_client_session(; > timeout=aiohttp.ClientTimeout(total=1),; > headers=headers,; > cookies=cookies) as session:; > async with session.get(ready_url) as resp:; > ```. I also changed the names and functionality of the functions in tls. Now; `in_cluster_ssl_context` will error if there is no ssl configuration found; instead of silently (and confusingly) using an SSLContext suited for public; communication (and wrong for in-cluster communication). I added `get_context_specific_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9120:599,error,error,599,https://hail.is,https://github.com/hail-is/hail/pull/9120,1,['error'],['error']
Availability,"The fix for Safari will take effect the next time the docs are deployed. In the meantime,; the docs are indeed downloaded, but Safari tells you there was a problem. If users navigate; to the Downloads directory, the file should indeed be present.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10302:111,down,downloaded,111,https://hail.is,https://github.com/hail-is/hail/pull/10302,2,"['Down', 'down']","['Downloads', 'downloaded']"
Availability,"The following error occurs when trying to liftover GRCh37 to GRCh38 for the UK Biobank GWAS for chr22. Any suggestions for this?. The code used is:. ```; chr=sys.argv[1]. bgen=""/project/ukbiobank/imp/uk.v3/bgen/ukb_imp_chr""+chr+""_v3.bgen""; sample=""/project/ukbiobank/imp/uk.v3/bgen/ukb19416_imp_chr""+chr+""_v3_s487327.sample""; # hl.index_bgen(bgen); mt=hl.import_bgen(bgen,sample_file=sample,entry_fields=['GT','GP','dosage']); print(mt.describe()); rg37 = hl.get_reference('GRCh37'); rg38 = hl.get_reference('GRCh38'); rg37.add_liftover('file:///restricted/projectnb/ukbiobank/ad/analysis/liftover/grch37_to_grch38.over.chain.gz', rg38); mt = mt.annotate_rows(new_locus=hl.liftover(mt.locus, 'GRCh38'), old_locus=mt.locus); mt = mt.filter_rows(hl.is_defined(mt.new_locus)); # mt = mt.key_rows_by(locus=mt.new_locus); print(mt.describe()); mt = mt.key_rows_by(locus=mt.new_locus,alleles=mt.alleles); print(mt.describe()); hl.export_vcf(mt,""/project/ukbiobank/imp/uk.v3.GRCh38/uk.v3.r38.chr""+chr+"".vcf.bgz""); ```. ```; Version 0.2.19-c6ec8b76eb26; LOGGING: writing to /restricted/projectnb/ukbiobank/ad/analysis/liftover/hail-20200214-1434-0.2.19-c6ec8b76eb26.log; 2020-02-14 14:35:19 Hail: INFO: Number of BGEN files parsed: 1; 2020-02-14 14:35:19 Hail: INFO: Number of samples in BGEN files: 487409; 2020-02-14 14:35:19 Hail: INFO: Number of variants across all BGEN files: 1255683. Global fields:; None; ----------------------------------------; Column fields:; 's': str; ----------------------------------------; Row fields:; 'locus': locus<GRCh38>; 'alleles': array<str>; 'rsid': str; 'varid': str; 'new_locus': locus<GRCh38>; 'old_locus': locus<GRCh37>; ----------------------------------------; Entry fields:; 'GT': call; 'GP': array<float64>; 'dosage': float64; ----------------------------------------; Column key: ['s']; Row key: ['locus', 'alleles']; ----------------------------------------; None; 2020-02-14 14:35:22 Hail: WARN: export_vcf: ignored the following fields:; 'varid' (row); 'ne",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8106:14,error,error,14,https://hail.is,https://github.com/hail-is/hail/issues/8106,1,['error'],['error']
Availability,"The goal of this PR is to have all of the JVM container logs available where all the worker logs are. I tagged the entries with ""worker.log"" so they show up with the other worker log entries. However, it's plain text with no timestamp. We can improve the formatting as a separate project. Notice the two entries with ""*"" on the left instead of the normal ""I"". The design choice I made is to have the JVM containers write to a location that is static. We cannot easily change the fluentd configuration dynamically. It requires restarting the daemon which takes 1.5 seconds. Furthermore, the configuration for fluentd is on /etc/ on the host which the batch worker container cannot access. Hence, why I took the approach of specifying it in the startup script at known locations. . Before we merge this, I'd like to confirm that (a) we want these logs and (b) they don't contain any secrets.; <img width=""1585"" alt=""Screenshot 2023-06-16 at 4 06 43 PM"" src=""https://github.com/hail-is/hail/assets/1693348/0ce9f7dc-1188-4c66-ae6f-83fcc3744f95"">",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13190:61,avail,available,61,https://hail.is,https://github.com/hail-is/hail/pull/13190,1,['avail'],['available']
Availability,"The high-level problem: . The Hail Query Service is redeployed with each commit to `main`. Each deployment has a new JAR file; whose ABI is backwards-incompatible. The high-level solution:. Hail Batch Workers can load the JAR for a given Hail version on-demand. Although not a long-term; solution, we currently start a fresh JVM for each job. As a result, we can simply start the JVM with; the correct JAR on its classpath. We cache jars on the local filesystem. I had to abandon the old approach for two reasons:. 1. Multiple JVMs race to download the JAR. In the new approach, the python worker process uses a; lock to ensure at most one coroutine is downloading a given version of a JAR at the same time. 2. The JVM includes assumes that a child ClassLoader does not redefine a class from the parent; ClassLoader. That's why ClassLoaders always prefer to load a class from the parent ClassLoader's; classes. When we decide to re-use JVMs or use a single multi-threaded JVM, we'll need to ensure the top-level; ClassLoader *does not have Hail on its classpath*. I looked briefly at this approach and found it; more work than the current approach. ---. My apologies for eliminating JVMProcess in this PR. It's an unrelated change which facilitated my; understanding of worker.py. I essentially inlined JVMProcess into JVMJob and eliminated any duplicative; code. ---. After making this change I restored the tests. Some tests had bitrotted. In the process of fixing; those tests, I found a few other bugs. Fixing these lower-level bugs unlocked a number of new; tests. One test (which was added since the service tests were removed) had to be marked as failing. Some; Hail operations rely on writing to the local file system. Implementing that properly in the Query; Worker will take some thought. Here are the bugs I fixed:. 1. Correct the error message raised when tests are run in a non-main thread (we look for this; message and start an event loop for Hail's async code because asyncio refuses t",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10314:540,down,download,540,https://hail.is,https://github.com/hail-is/hail/pull/10314,2,['down'],"['download', 'downloading']"
Availability,"The high-level problem:. The Hail Query Service is redeployed with each commit to `main`. Each deployment has a new JAR file; whose ABI is backwards-incompatible. The high-level solution:. Hail Batch Workers can load the JAR for a given Hail version on-demand. Although not a long-term; solution, we currently start a fresh JVM for each job. As a result, we can simply start the JVM with; the correct JAR on its classpath. We cache jars on the local filesystem. I had to abandon the old approach for two reasons:. 1. Multiple JVMs race to download the JAR. In the new approach, the python worker process uses a; lock to ensure at most one coroutine is downloading a given version of a JAR at the same time. 2. The JVM assumes that a child ClassLoader does not redefine a class from the parent; ClassLoader. That's why ClassLoaders always prefer to load a class from the parent ClassLoader's; classes. When we decide to re-use JVMs or use a single multi-threaded JVM, we'll need to ensure the top-level; ClassLoader *does not have Hail on its classpath*. I looked briefly at this approach and found it; more work than the current approach. ---. My apologies for eliminating JVMProcess in this PR. It's an unrelated change which facilitated my; understanding worker.py. I essentially inlined JVMProcess into JVMJob and eliminated any duplicative; code. ---. After making this change I restored the tests. Some tests had bitrotted. In the process of fixing; those tests, I found a few other bugs. Fixing these lower-level bugs unlocked a number of new; tests. A couple tests (which were added since the service tests were removed) had to be marked as; failing. Here are the bugs I fixed:. 1. Correct the error message raised when tests are run in a non-main thread (we look for this; message and start an event loop for Hail's async code because asyncio refuses to start an event; loop in a non-main thread). 2. Use a `SafeRow` to copy the globals data out of a Region and into durable, GC'ed objects. 3.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10390:539,down,download,539,https://hail.is,https://github.com/hail-is/hail/pull/10390,2,['down'],"['download', 'downloading']"
Availability,"The image below describes what I mean. The brown files are not tracked by git, because these are generated by the sphinx autosummary directives. However, they're still used as a base when we build the website. I've run into several errors today with broken references (from other git branches!) which were resolved by deleting all these untracked rsts and rebuilding. Ideally, gradle clean would delete all these, or we would copy this directory to a temporary staging area before starting the build. ![image](https://cloud.githubusercontent.com/assets/10562794/25728126/21712204-30fb-11e7-8938-964b68c940e6.png)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1766:232,error,errors,232,https://hail.is,https://github.com/hail-is/hail/issues/1766,1,['error'],['errors']
Availability,The invalid grant error below this line is wrapped in a `StorageException`. We want to open up these wrapping exceptions to see if there's a true error underneath.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11963:18,error,error,18,https://hail.is,https://github.com/hail-is/hail/pull/11963,2,['error'],['error']
Availability,"The king toolset outside of hail seems to have a feature that allows the user to generate a tree based on the results. Is there a similar feature available for [king()](https://hail.is/docs/0.2/methods/relatedness.html#hail.methods.king) in hail or an alternative to use on hail? For reference, information on the visualization can be found [here](https://www.kingrelatedness.com/KINGvisualization.shtml). Thank you.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12489:146,avail,available,146,https://hail.is,https://github.com/hail-is/hail/issues/12489,1,['avail'],['available']
Availability,"The left and right sources may provide more fields than are necessary. This is OK, but; previously this caused an error because `filterSet` expects the argument to be a subset; of the `self` argument.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10077:114,error,error,114,https://hail.is,https://github.com/hail-is/hail/pull/10077,1,['error'],['error']
Availability,"The logic trying to infer the version of various Spark dependencies; was total garbage and almost certainly except for a few specific; cases. I was feeling aggressive. I nuked it. If we want to support; building with other versions of Spark reliably (whcih we don't test)`,; we should find another way.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8676:241,reliab,reliably,241,https://hail.is,https://github.com/hail-is/hail/pull/8676,1,['reliab'],['reliably']
Availability,"The main change is to the communication protocol between the client and; the driver and between the driver and the worker. In main, both the driver and the client send messages back to the client; and driver (respectively) by writing to a file in cloud storage. In both; cases, the file (in main) has one of these two structures:. 0x00 # is_success (False); UTF-8 encoded string # the stack trace. 0x01 # is_success (True); UTF-8 encoded string # JSON message to send back to the client or driver. In this PR, the success case does not change. The failure case becomes:. 0x00 # is_sucess (False); UTF-8 encoded string # short message; UTF-8 encoded string # expanded message; 4-byte signed integer # error id. The Python client (in `service_backend.py`) and the Driver (in; `ServiceBackendSocketAPI2`) changes to read this and raise the right error if; an error id is present. I also uncovered three unrelated problems that are fixed in this PR:; 1. PlinkVariant needs to be serializable because it is broadcasted.; 2. We open an input stream in LoadPlink which ought to be closed, but there is no mechanism to do so in the ServiceBackend. I just ignore it for now. cc: @tpoterba, I'm not sure what the right answer is here.; 3. Two uses of the broadcasted file system that should use the ExecuteContext's file system.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11624:548,failure,failure,548,https://hail.is,https://github.com/hail-is/hail/pull/11624,4,"['error', 'failure']","['error', 'failure']"
Availability,"The main goal here was to flatten out the aggregator states in the tuple of aggregator states, so that we could e.g. inline the value of a prevnonnull aggregator instead of storing a pointer to the state. The big change that I made was in creating a `TupleAggregatorState` that knows its own offset so that when we initialize a state, we can initialize the value offset directly from the value of the container. (The previous StateContainer got renamed `StateTuple` and was slimmed down accordingly.) I think I eventually want `TupleAggregatorState` to implement the `AggregatorState` interface; I haven't pushed it there yet because I haven't needed to, but I think it would fit a lot better.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7110:482,down,down,482,https://hail.is,https://github.com/hail-is/hail/pull/7110,1,['down'],['down']
Availability,"The new generic lines coerce code could produce a partitioner with unsafe values. Those unsafe values ended up in the Compile cache, which become invalid when owning region was cleared. This fixes the memory errors I was seeing when running with the local backend. It is possible it will fix (some?) of the errors you were investigating, @johnc1231.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8987:208,error,errors,208,https://hail.is,https://github.com/hail-is/hail/pull/8987,2,['error'],['errors']
Availability,"The old bucket did not use uniform access control and also was multi-regional (us). I created a new bucket using the random suffix ger0g which has uniform access control. I also switched the location to us-central1 (not pictured here because that is a variable). I copied all the JARs from `gs://hail-query/jars` to `gs://hail-query-ger0g/jars` using a GCE VM. Again, global-config is not present in our terraform, so I'll have to manually edit that to reflect this new location: `gs://hail-query-ger0g`. The deployment process is:. 1. Edit global-config to reflect new bucket.; 2. Delete batch and batch-driver pods.; 3. Delete old workers. The rollback process (if necessary) is the same. Since this requires wiping the workers, I'll wait for a time when no one is on the cluster to do it. Any users using explicit JAR URLs will need to switch to `gs://hail-query-ger0g/...`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12969:646,rollback,rollback,646,https://hail.is,https://github.com/hail-is/hail/pull/12969,1,['rollback'],['rollback']
Availability,"The old code in `Transaction` to exit the transaction and release the connection back to the pool looked like this:. ```; async def _aexit(self, exc_type, exc_val, exc_tb):; try:; if self.conn is not None:; try:; if exc_type:; await self.conn.rollback(); else:; await self.conn.commit(); finally:; self.conn = None; finally:; if self.conn_context_manager is not None:; try:; await aexit(self.conn_context_manager, exc_type, exc_val, exc_tb); finally:; self.conn_context_manager = None; ```. The problem was if the current coroutine was cancelled in the call to `aexit(self.conn_context_manager, ...)`, which ultimately calls aiomysql `Pool.release`, the release never happens. This was happening when database calls in `@only_active_instances` were getting cancelled when the client timed out and terminated the request. Roughly, the solution is to shield exiting the connection, and return the connection asynchronously in a background task (using `ensure_future`). FYI @danking @jigold This is a subtle bug/pattern for managing resources that we should all be aware of.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9307:243,rollback,rollback,243,https://hail.is,https://github.com/hail-is/hail/pull/9307,1,['rollback'],['rollback']
Availability,The old error message for matmul was impossible to read. This is much clearer.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10298:8,error,error,8,https://hail.is,https://github.com/hail-is/hail/pull/10298,1,['error'],['error']
Availability,"The only remaining references are in the datasets scripts, but those are meant as references of how we created the files, and in the `hailctl dataproc` command. I chose not to change the latter because I fear some users might still have ancient versions of `gcloud`. The reviewer should verify that I got the right version of the `gcloud` command in each case. Hopefully this resolves the bizarre error we see in test-dataproc.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12781:397,error,error,397,https://hail.is,https://github.com/hail-is/hail/pull/12781,1,['error'],['error']
Availability,"The original goal of this PR was avoiding `Try` when we are not using the restartability provided by semantic hashing because I strongly suspect it is related to the loss of stacktraces in exceptions. Unrelatedly, we realized the semantic hash PR changed the semantics of Query-on-Spark even when semantic hash is disabled: previously we would abort RDD writing on the first exception. In Hail 0.2.123 through 0.2.126, the semantics were changed to only crash *after* we already ran every other partition. Two bad scenarios of which I can think:. 1. Suppose the first partition fails due to OOM. We now waste time/money on the rest of the partitions even though we cannot possibly get a valid output. 2. Suppose every partition hits a permission error. Users should get that feedback after paying for O(1) partitions run, not O(N). I created two Backend paths: the normal `parallelizeAndComputeWithIndex` with its pre-0.2.123 semantics as well as `parallelizeAndComputeWithIndexReturnAllErrors` which, as the name says, returns errors instead of raising them. While making this change, I think I found two other bugs in the ""return all errors"" path, only one of which I addressed in this PR:. 1. I'm pretty sure semantic-hash-enabled QoB batch submission is broken because it uses the logical partition ids as job indices. Suppose there are 10,000 partitions, but we only need to compute 1, 100, and 1543. 0.2.126 would try to submit a batch of size 3 but whose job indices are 1, 100, and 1543. 2. Likewise, the Query-on-Spark path returns an invalid `SparkTaskContext.partitionId` which, at best, produces confusing partition filenames. I only fixed the former because it was simple to fix. I wasn't exactly sure what to do about the latter. We should fix that separately because the changes in this PR need to urgently land in the next release to avoid unexpected cost when one partition fails.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14085:746,error,error,746,https://hail.is,https://github.com/hail-is/hail/pull/14085,3,['error'],"['error', 'errors']"
Availability,"The original problem we were seeing was this error message:. ```; Unclosed client session; client_session: <aiohttp.client.ClientSession object at 0x7fe17e8c4bd0>; Traceback (most recent call last):; File ""/usr/local/lib/python3.7/runpy.py"", line 193, in _run_module_as_main; ""__main__"", mod_spec); File ""/usr/local/lib/python3.7/runpy.py"", line 85, in _run_code; exec(code, run_globals); File ""/usr/local/lib/python3.7/site-packages/batch/copy/__main__.py"", line 34, in <module>; asyncio.run(main()); File ""/usr/local/lib/python3.7/asyncio/runners.py"", line 43, in run; return loop.run_until_complete(main); File ""/usr/local/lib/python3.7/asyncio/base_events.py"", line 587, in run_until_complete; return future.result(); concurrent.futures._base.CancelledError; sys:1: RuntimeWarning: coroutine 'retry_transient_errors' was never awaited; RuntimeWarning: Enable tracemalloc to get the object allocation traceback; ```. I'm not sure why we didn't get a better error message from the ThreadPoolExecutor, but this fix definitely solves the OOM issue. We were assuming `close` in Python means the entire write has completed, but that's not true. `close` just means the file handle in Python has been closed, but the data is still stored in the kernel's write buffer until it gets a chance to have written the data. When the pd-ssds were slow (either network bandwidth or ext3/4 is slow) and we're trying to write a lot of data, this meant we were building up lots of data in the write buffer for previously ""completed"" tasks and the semaphore was not doing its job to limit the number of ""active"" tasks to 50. There may still be another error here that we're not retrying, but I wasn't able to replicate the bug after making this fix with 5 replicas of downloading 80 Gi x 8 jobs per node.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10591:45,error,error,45,https://hail.is,https://github.com/hail-is/hail/pull/10591,4,"['down', 'error']","['downloading', 'error']"
Availability,"The picture is from asm4s:; - Value[T] is convertible to Code[T] and can be used multiple times: it is a primitive value (constant, variable ref, etc.); - Code[T] can be used once; - Settable[T] extends Value[T] and has a store operation. Changes:; - rename PValue => PCode; - add PValue which is multi-use, PSettable extends PValue; - rename EmitTriplet => EmitCode; - add EmitValue and EmitSettable; - Removed type parameter from PValue and introduced downcast operators. I'm not really happy with either option. Will revisit this again in the future. Changes that are coming:; - add EmitMethodBuilder.newEmit{Local, Field} that return EmitSettables; - Emit.E will become Env[EmitSettable]. The goal here is to rip out jointpoint and ParameterPack. EmitSettables will replace the funtionality of ParameterPack for TypedTriplets (which will go away in favor of EmitTriplet/EmitCode). Removing joinpoint will cause problems when Code[T] are reused, so the Value types must be pushed throughout the codebase. I will put out what infrastructure I can as separate PRs, but I'm having a hard time finding way to do this incrementally.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8263:454,down,downcast,454,https://hail.is,https://github.com/hail-is/hail/pull/8263,1,['down'],['downcast']
Availability,"The pods currently look like this:. ```; site-deployment-5b5697d6bb-2p5rk 1/1 Running 0 6h; site-deployment-69f686bf7f-266kg 0/1 ContainerCreating 0 2h; ```. The problem is that site mounts a volume RWO with the certs. The problem is the second pod can't launch for seamless upgrade because it can't mount the volume. There is a further discussion here: https://github.com/kubernetes/kubernetes/issues/26567. Short-term fix: we could delete the pod and recreate on upgrade, which would lead to a short window of downtime. Long-term fix: Normally the certs are only read by nginx, but need to be written by the certbot renew cron job. We could keep the certs in a volume. We could put a copy of the certs in a secret which can be mounted by multiple pods (e.g. site including when it is upgraded). Then we run certbot periodically in its own pod and update the original certs stored in the volume. After it runs, we create a new secret (or upgrade it if we can) with the new certs and then do a seamless upgrade on site.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4463:512,downtime,downtime,512,https://hail.is,https://github.com/hail-is/hail/issues/4463,1,['downtime'],['downtime']
Availability,"The previous formula, `(1/n) (sumsq - (2 * mean * sum) + (n * mean^2))` was weirdly redundant, since `mean * sum == n * mean^2`. This was added by #6728, which ported stats from Scala, but the weird formula did not come from the Scala implementation. I have no clue where this came from. The only reason for doing something like this might be for improved numerical stability, but that doesn't seem to be the case here. In fact, this current method of computing the variance (pre or post this pr) is known to be unstable when the mean is much larger than the stdev (as is easy to see: you're subtracting two nearly equal positive numbers). The Scala implementation used the spark `StatCounter`, which uses the more stable [Welford's algorithm](https://en.wikipedia.org/wiki/Algorithms_for_calculating_variance#Welford's_online_algorithm). We should probably fix any variance or stdev computation to use a stable method, which I think requires a dedicated stats aggregator that maintains count, mean, and variance in a smart way.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10132:84,redundant,redundant,84,https://hail.is,https://github.com/hail-is/hail/pull/10132,1,['redundant'],['redundant']
Availability,"The previous idiom was mapAnnotations(...).copy(vaSignature =; newVASignature), but this results (temporarily) in a VDS with an; incorrect va type that which causes problems for downstream changes; and assertions like typecheck.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2188:178,down,downstream,178,https://hail.is,https://github.com/hail-is/hail/pull/2188,1,['down'],['downstream']
Availability,"The previous implementation, while seeming to be well-abstracted at; first, actually had a rather devious property of creating agg states; for multiple classes multiple times. I'm still working on figuring out; *exactly* the place where our assumptions broke down, but this change; definitely fixes the problem, and simplifies the implementation by; directly using IR, instead of other compiled functions. This problem was a symptom of a larger issue, which is that the; ownership semantics of the current aggregator system is way too complex; to be coding against regularly. This all will go away when lowering is; complete, in favor of the *much* simpler set of IR nodes that are used; in lowering. We may need to address this problem sooner, though. CHANGELOG: Fixed memory leak affecting `Table.annotate` with scans, `hl.experimental.densify`, and `Table.group_by` / `aggregate`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9028:259,down,down,259,https://hail.is,https://github.com/hail-is/hail/pull/9028,1,['down'],['down']
Availability,"The real change here is changing the preemptible pool config from `preemptible = true` to `spot = true`, but the `spot` config was only available in the new provider which involved a major version upgrade. The only incompatibility was the addition of an explicit `project` input to `google_project_iam_member`, as opposed to picking it up from the provider configuration. Tested just now in my own project. If one wants to apply this change without incurring downtime for preemptible deployments, they should follow the instructions outlined in the [migrating node pools dev-docs](https://github.com/hail-is/hail/blob/main/dev-docs/kubernetes-operations.md#when-using-terraform).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12127:136,avail,available,136,https://hail.is,https://github.com/hail-is/hail/pull/12127,2,"['avail', 'downtime']","['available', 'downtime']"
Availability,"The real issue here is that `mt2`'s `af` field is not from the same object as `mt`, but the error message is really misleading, it moves your focus to the `mt.GT.n_alt_alleles()` which is actually fine. ```; In [13]: import hail as hl ; ...: mt = hl.balding_nichols_model(2, 5, 5) ; ...: mt2 = hl.balding_nichols_model(2, 5, 5) ; ...: mt = mt.annotate_entries(x = mt.GT.n_alt_alleles() * mt2.af) ; Initializing Hail with default parameters...; 2020-07-28 10:40:36 WARN Utils:66 - Your hostname, wm06b-953 resolves to a loopback address: 127.0.0.1; using 192.168.0.54 instead (on interface en0); 2020-07-28 10:40:36 WARN Utils:66 - Set SPARK_LOCAL_IP if you need to bind to another address; 2020-07-28 10:40:37 WARN NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).; 2020-07-28 10:40:37 WARN Hail:37 - This Hail JAR was compiled for Spark 2.4.5, running with Spark 2.4.1.; Compatibility is not guaranteed.; Running on Apache Spark version 2.4.1; SparkUI available at http://192.168.0.54:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.2.49-c6975678edc4; LOGGING: writing to /Users/dking/projects/hail/hail/hail-20200728-1040-0.2.49-c6975678edc4.log; 2020-07-28 10:40:39 Hail: INFO: balding_nichols_model: generating genotypes for 2 populations, 5 samples, and 5 variants...; 2020-07-28 10:40:39 Hail: INFO: balding_nichols_model: generating genotypes for 2 populations, 5 samples, and 5 variants...; Traceback (most recent call last):; File ""<ipython-input-13-f638f6c0399a>"", line 4, in <module>; mt = mt.annotate_entries(x = mt.GT.n_alt_alleles() * mt2.af); File ""/Users/dking/projects/hail/hail/python/hail/expr/expressions/typed_expressions.py"", line 1988, in __mul__; return self._bin_op_numeric(""*"", other); File ""/Users/dking/projects/hail/hail/py",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/9163:92,error,error,92,https://hail.is,https://github.com/hail-is/hail/issues/9163,1,['error'],['error']
Availability,The return value of these functions indicates if the containing loop; should wait or if we should immediately re-call the function. This; is intended to be used to allow functions which *know* they have more; work to eagerly invoke themselves again. The use of this variable seems to have been changed to basically always; eagerly re-run during the Azure work. This change restores the original behavior:; 1. Do not wait in job private if we saw 300 records (seems likely there were; 301 or more records in the db).; 2. Do not wait in pool scheduler if we exhaust a user's share. I do not; fully follow the pool scheduler's logic. There might be something; smarter we can do. I think we should really only re-call if we believe; the db contains more ready jobs and we have available cores.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11384:773,avail,available,773,https://hail.is,https://github.com/hail-is/hail/pull/11384,1,['avail'],['available']
Availability,"The root issue here was that sometimes exc.args[0] was a string and sometimes it was a dict. When it was a string the `in` condition worked fine. When it was a dict, it was looking at the keys of the dict and not finding the error message (which is buried under a few layers). The code was unnecessarily complex. I reworked the yaml printer to be simpler and work for any multiline string. I removed the regular expression that was used to discover the worker batch when the worker jobs were in a different batch from the driver jobs. I remove all specialized debugging information in favor of the general `debug_info` methods on `Batch` and `ServiceBackend`. I also have two clear error cases: if the driver does not write its output file, then something went horribly wrong. We dump all the debug info. If we do not receive valid JSON from the driver, again, something went horribly wrong. We dump all the debug info. The only remaining exceptional case is an error purposely serialized by the QoB driver to us (with or without an error id). In particular, note that we now completely ignore the number of failing or successful jobs. That doesn't matter. If the driver sends us an output file, we use the data found there. If the driver does not send us an output file or sends us an output file without valid JSON, we dump as much debug info as possible. cc: @tpoterba for visibility on your end; cc: @iris-garden because you're in this space (albeit, the bug you're fixing is in the QoB *driver* whereas this is the *client* [nb: *client* is the Python code which starts a batch with a *driver*. A *driver* adds zero or more *worker* jobs to its batch. You're addressing an issue with how the *driver* handles errors from the *workers*. This PR simplifies the logic for how the *client* handles errors from the *driver*.]).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12470:225,error,error,225,https://hail.is,https://github.com/hail-is/hail/pull/12470,6,['error'],"['error', 'errors']"
Availability,"The router resolver incorrectly assumed the contents of the `Authorization` header was a session; id. In fact, the structure of that header and X-Hail-Internal-Authorization is:. ```; Bearer SESSION_ID; ```. where `SESSION_ID` is a 44 base64 characters representing a 32 byte secret session id. I also took this opportunity to centralize the parsing of bearer headers as; `gear.maybe_parse_bearer_header`. ---. This caused a failure because router-resolver, when checking that a user is properly authenticated,; would send:. ```; Bearer Bearer SESSION_ID; ```. which failed the 44-byte length check in auth/front_end.py.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9919:425,failure,failure,425,https://hail.is,https://github.com/hail-is/hail/pull/9919,1,['failure'],['failure']
Availability,"The search bar for the batch docs is broken and just says `Searching` forever. Tracked it down to a bug in the `sphinx_rtd_theme` dependency that was fixed in a later release. The important files to look at are the `requirements.txt` files not the `pinned-requirements.txt` files as the latter bulk updated a bunch of patch releases when I regenerated them. . In the mess of version conflicts that updating a dependency appears to do here, I also removed `google-cloud-logging` as it appears to be an unused dependency and `pre-commit` because it is optional for developers and had a hard requirement on a `importlib-metadata` version that made it incompatible with other important libraries that we use. I also explicitly pinned `protobuf` as a major version upgrade that wasn't restricted by some google libraries we use broke those same google libraries that added that dependency.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12215:91,down,down,91,https://hail.is,https://github.com/hail-is/hail/pull/12215,1,['down'],['down']
Availability,"The semantics of setting a variable in make are kinda weird, example:. ```make; FOO := foo; BAR ?= bar; .PHONY: echo; echo:; 	echo $(FOO) $(BAR); ```. ```sh; $ FOO=baz make; echo foo bar; foo bar; $ make FOO=baz; echo baz bar; baz bar; $ BAR=baz make; echo foo baz; foo baz; ```. This will fix an issue where ci wasn't actually building with spark 3.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9556:112,echo,echo,112,https://hail.is,https://github.com/hail-is/hail/pull/9556,6,['echo'],['echo']
Availability,"The sources for agg transformations weren't being recorded correctly for transformations of hl.agg.count(). This wasn't a problem for e.g. a single-level hl.agg.group_by(key, hl.agg.count()), but was throwing errors when that was nested within other transformations.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6740:209,error,errors,209,https://hail.is,https://github.com/hail-is/hail/pull/6740,1,['error'],['errors']
Availability,"The stack trace looks like this now:. ```; Error; Traceback (most recent call last):; File ""/Users/jigold/hail/python/hail/expr/expressions/expression_typecheck.py"", line 73, in check; return self.coerce(to_expr(x)); File ""/Users/jigold/hail/python/hail/expr/expressions/base_expression.py"", line 101, in to_expr; dtype = impute_type(e); File ""/Users/jigold/hail/python/hail/expr/expressions/base_expression.py"", line 59, in impute_type; raise ExpressionException(""Cannot impute type of empty list. Use 'hl.empty_array' to create an empty array.""); hail.expr.expressions.base_expression.ExpressionException: Cannot impute type of empty list. Use 'hl.empty_array' to create an empty array. The above exception was the direct cause of the following exception:. Traceback (most recent call last):; File ""/Users/jigold/hail/python/hail/typecheck/check.py"", line 426, in check_all; arg_ = tc.check(arg, name, argname); File ""/Users/jigold/hail/python/hail/expr/expressions/expression_typecheck.py"", line 75, in check; raise TypecheckFailure from e; hail.typecheck.check.TypecheckFailure. The above exception was the direct cause of the following exception:. Traceback (most recent call last):; File ""/Users/jigold/hail/python/hail/tests/test_expr.py"", line 1085, in test_empty_collection_error_msg; self.assertRaisesRegex(hl.expr.ExpressionException, ""Cannot impute type of empty list."", hl.array([])); File ""<decorator-gen-420>"", line 2, in array; File ""/Users/jigold/hail/python/hail/typecheck/check.py"", line 494, in _typecheck; args_, kwargs_ = check_all(__orig_func__, args, kwargs, checkers, is_method=False); File ""/Users/jigold/hail/python/hail/typecheck/check.py"", line 436, in check_all; )) from e; TypeError: array: parameter 'collection': expected expression of type set<any> or array<any> or dict<('any', 'any')>, found list: []; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3497:43,Error,Error,43,https://hail.is,https://github.com/hail-is/hail/pull/3497,1,['Error'],['Error']
Availability,"The stack trace reported:. ```; [Stage 7:> (0 + 132) / 194]Traceback (most recent call last):; File ""/tmp/b54eac62-9ebc-43ff-b49c-80cc77f89aa2/genomes_sites_vcf.py"", line 42, in <module>; sites_vds.write(tmp_vds); File ""/home/teamcity/TeamCityAgent2/work/591c293e3f6bfb1d/python/pyhail/dataset.py"", line 595, in write; File ""/tmp/b54eac62-9ebc-43ff-b49c-80cc77f89aa2/utils.py"", line 211, in run_command; cmd_args); File ""/usr/lib/spark/python/lib/py4j-0.10.3-src.zip/py4j/java_gateway.py"", line 1133, in __call__; File ""/usr/lib/spark/python/lib/pyspark.zip/pyspark/sql/utils.py"", line 63, in deco; for criterion, pop in criteria_pops:; File ""/usr/lib/spark/python/lib/py4j-0.10.3-src.zip/py4j/protocol.py"", line 319, in get_return_value; py4j.protocol.Py4JJavaError: An error occurred while calling o309.run.; : org.apache.spark.SparkException: Job aborted.; 	at org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand$$anonfun$run$1.apply$mcV$sp(InsertIntoHadoopFsRelationCommand.scala:149); 	at org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand$$anonfun$run$1.apply(InsertIntoHadoopFsRelationCommand.scala:115); 	at org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand$$anonfun$run$1.apply(InsertIntoHadoopFsRelationCommand.scala:115); 	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:57); 	at org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:115); 	at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:58); 	at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:56); 	at org.apache.spark.sql.execution.command.ExecutedCommandExec.doExecute(commands.scala:74); 	at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:115); 	at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(S",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1202:771,error,error,771,https://hail.is,https://github.com/hail-is/hail/issues/1202,1,['error'],['error']
Availability,"The standard field registrations lead to TERRIBLE behavior -- . this line in a VCF:; ```; ##INFO=<ID=MQ0,Number=.,Type=Integer,Description=""Number of MAPQ == 0 reads"">; ```. ...gets returned in our code as...; ```; INFO=<ID=MQ0,Number=1,Type=Integer,Description=""Total Mapping Quality Zero Reads"">; ```. ...leading to match errors when we get to the values.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2822:324,error,errors,324,https://hail.is,https://github.com/hail-is/hail/issues/2822,1,['error'],['errors']
Availability,"The test deployment sets the default storage to 1GiB instead of the normal 10GiB. As a result, the PR tests passed. The deployment tests fail because the 10GiB default storage request forces a minimum core count of 0.5 CPU. This change explicitly requests less storage, thus preventing the rounding up of core count from 0.25 CPU to 0.5 CPU. The rounding up doubled the mcpu_msec time for the test, thus failing the test. Fixes this:. ```; -------------------------------- live log call ---------------------------------; 2020-07-28T15:42:34 INFO batch_client.aioclient aioclient.py:497:submit created batch 70818; 2020-07-28T15:42:34 INFO batch_client.aioclient aioclient.py:533:submit closed batch 70818; FAILED; _____________________________ Test.test_msec_mcpu ______________________________. self = <test.test_batch.Test testMethod=test_msec_mcpu>. def test_msec_mcpu(self):; builder = self.client.create_batch(); resources = {; 'cpu': '100m',; 'memory': '375M'; }; # two jobs so the batch msec_mcpu computation is non-trivial; builder.create_job('ubuntu:18.04', ['echo', 'foo'], resources=resources); builder.create_job('ubuntu:18.04', ['echo', 'bar'], resources=resources); b = builder.submit(); ; batch = b.wait(); assert batch['state'] == 'success', batch; ; batch_msec_mcpu2 = 0; for job in b.jobs():; # I'm dying; job = self.client.get_job(job['batch_id'], job['job_id']); job = job.status(); ; # runs at 250mcpu; job_msec_mcpu2 = 250 * max(job['status']['end_time'] - job['status']['start_time'], 0); # greater than in case there are multiple attempts; assert job['msec_mcpu'] >= job_msec_mcpu2, batch; ; batch_msec_mcpu2 += job_msec_mcpu2; ; > assert batch['msec_mcpu'] == batch_msec_mcpu2, batch; E AssertionError: {'billing_project': 'test', 'closed': True, 'complete': True, 'cost': '$0.0000', ...}; E assert 2813000 == 1406500; E -2813000; E +1406500; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9166:1070,echo,echo,1070,https://hail.is,https://github.com/hail-is/hail/pull/9166,2,['echo'],['echo']
Availability,"The test that lists batches timed out. The main problem is the limit in the aioclient used by the test_batch tests was passing a string rather than an integer. I assumed downstream the function was passing an integer. Therefore, we were doing this:. batch_id < ""137""; and not batch_id < 137. So the query was running forever and scanning all batches from the test user. I also was missing a tag annotation on the queries, but that was not causing the timeout.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13237:170,down,downstream,170,https://hail.is,https://github.com/hail-is/hail/pull/13237,1,['down'],['downstream']
Availability,The tests relying on Batch are getting slower because it takes a long time to download and build Docker images and we're putting more load on Batch. This will increase parallelism and reduce test failures due to timeouts.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9441:78,down,download,78,https://hail.is,https://github.com/hail-is/hail/pull/9441,2,"['down', 'failure']","['download', 'failures']"
Availability,"The tests use multiple threads which can race to download the references. This is a bit; of a blunt fix. In particular, this is not an asyncio-friendly lock (because I need; thread safety, which asyncio.Lock does not provide). In general, users should not try; to initialize hail multiple times in different coroutines in the same thread.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11949:49,down,download,49,https://hail.is,https://github.com/hail-is/hail/pull/11949,1,['down'],['download']
Availability,"The treatment of `ClientPayloadError` as a sometimes transient error was originally made in response to [an existing issue](https://github.com/aio-libs/aiohttp/issues/4581) in aiohttp that can cause transient errors on the client that are difficult to distinguish from a real broken server. What's in `main` matched exactly on the error message, but that error message has [since changed](https://github.com/aio-libs/aiohttp/commit/dc38630b168a169139974617d75e176530c91696) to include more information, breaking our transient error handling. This change relaxes the requirement of the error response string to fix transient error handling for our current version of `aiohttp`. I wish I had a better approach. `ClientPayloadError` can also be thrown in the case of malformed data, so I am reticent to treat it as always transient, but we could perhaps make it a `limited_retries_error` and avoid inspecting the error message.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14545:63,error,error,63,https://hail.is,https://github.com/hail-is/hail/pull/14545,8,['error'],"['error', 'errors']"
Availability,"The way that the off-heap-memory-fraction argument currently works; limits total memory usage in hail value heavy (like lowered) pipelines; immensely. The default settings both reserve AND and limit hail off heap; allocations to 60% of executor's memory. This behavior is almost never; what a user wants as it will reduce total memory that they can use. We; can retain some of the characteristics that these limits give us by; reserving off-heap-memory-fraction as overhead, and setting the; worker_off_heap_memory_per_core to be the total available memory per; core. This should still give good error messaging on attempts to; allocate too much memory for hail values while allowing us to use all; the memory we have available. A flag, --off-heap-memory-hard-limit, has been added to preserve the; previous behavior.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11531:540,avail,available,540,https://hail.is,https://github.com/hail-is/hail/pull/11531,3,"['avail', 'error']","['available', 'error']"
Availability,There are two errors in the status returned by the worker: one is caught when executing the job and the other is when executing the container (such as uploading log to google storage or timeout error). We were only handling job-level errors correctly.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8784:14,error,errors,14,https://hail.is,https://github.com/hail-is/hail/pull/8784,3,['error'],"['error', 'errors']"
Availability,"There are two problems with this:; - it is a massive de-optimization if we forward an expensive computation into a loop (e.g. arraymap); - in the above case, it is an error in if the body of the let is non-deterministic. To do this right we need to build a control flow graph.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4497:167,error,error,167,https://hail.is,https://github.com/hail-is/hail/pull/4497,1,['error'],['error']
Availability,"There could be a webserver with reference datasets, and local installs that use hail-based pipelines (eg. seqr-hail prototype) can avoid downloading large files.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/840:137,down,downloading,137,https://hail.is,https://github.com/hail-is/hail/issues/840,1,['down'],['downloading']
Availability,"There is still work to do here, but it is now complete enough that InterpretSuite can be run properly on a minimal example. Current TODOs:; - [x] Add C++ emit; - [x] Add Python api (experimental, for now); - [x] Proper type checking in python? *yes, but no type inference*; - [ ] Test ALL failure pathways; - [x] Mismatched Number of args between `Loop` and matching `Recur`; - [x] Mismatched types of args between `Loop` and matching `Recur`; - [ ] Infinite loop detection; - [ ] Not tail recursive detection",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5228:289,failure,failure,289,https://hail.is,https://github.com/hail-is/hail/pull/5228,1,['failure'],['failure']
Availability,"There must be a blank line after three dashes, otherwise you get this error:; ```; [WARNING] Could not parse YAML metadata at line 64 column 1: :8:0: Unexpected '-'. ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11960:70,error,error,70,https://hail.is,https://github.com/hail-is/hail/pull/11960,1,['error'],['error']
Availability,"There should be one definition of a service. The router should be; the authority on service definitions. The only exceptions are; self-deployed services: gateway, internal-gateway, and router-resolver. This primarily reduces possibility of error or confusion by removing; duplication. It does not impair hand deploying of any service because; every service (except the self-deployed ones) needs the router anyway.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8504:240,error,error,240,https://hail.is,https://github.com/hail-is/hail/pull/8504,1,['error'],['error']
Availability,"There was a logic error in constructFromIndicesUnsafe, if a missing value was pushed, pushing a present value with the same index would not clear the missing bit.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13263:18,error,error,18,https://hail.is,https://github.com/hail-is/hail/pull/13263,1,['error'],['error']
Availability,There were a few places where things that had `NAMESPACE` didn't use it in certain places. I also fixed that. I also standardized the error verbiage.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9695:134,error,error,134,https://hail.is,https://github.com/hail-is/hail/pull/9695,1,['error'],['error']
Availability,"There were two sources of deadlocks:. 1. The attempt resources were not inserted in the same order in the aggregated_*_resources tabes between the two triggers `attempt_resources_after_insert` and `attempts_after_update`. One had jobs -> batches -> billing projects and the other had billing_projects -> batches -> jobs. We also were inserting the resources in a different order in the two triggers. I solved the ordering issue by making sure we `INSERT MANY` the resources in alphabetical order. 2. Once I fixed (1), then the next set of errors were in `add_attempt`. We were locking the `instances_free_cores_mcpu` table only if the attempt didn't already exist. This was causing cryptic deadlock errors like this:. ```; ------------------------; LATEST DETECTED DEADLOCK; ------------------------; 2022-06-23 18:08:12 0x7f1807665700; *** (1) TRANSACTION:; TRANSACTION 1215034153, ACTIVE 0 sec starting index read; mysql tables in use 1, locked 1; LOCK WAIT 21 lock struct(s), heap size 1136, 12 row lock(s), undo log entries 5; MySQL thread id 962402, OS thread handle 139741222766336, query id 6809292838 10.32.5.50 jigold updating; UPDATE instances_free_cores_mcpu; SET free_cores_mcpu = free_cores_mcpu + cur_cores_mcpu; WHERE instances_free_cores_mcpu.name = in_instance_name; *** (1) WAITING FOR THIS LOCK TO BE GRANTED:; RECORD LOCKS space id 1578686 page no 3 n bits 72 index PRIMARY of table `jigold`.`instances_free_cores_mcpu` trx id 1215034153 lock_mode X locks rec but not gap waiting; Record lock, heap no 3 PHYSICAL RECORD: n_fields 4; compact format; info bits 0; 0: len 30; hex 62617463682d776f726b65722d6a69676f6c642d7374616e646172642d62; asc batch-worker-jigold-standard-b; (total 34 bytes);; 1: len 6; hex 0000486bf32c; asc Hk ,;;; 2: len 7; hex 600001287513cb; asc ` (u ;;; 3: len 4; hex 80002de6; asc - ;;. *** (2) TRANSACTION:; TRANSACTION 1215034156, ACTIVE 0 sec inserting; mysql tables in use 6, locked 6; 22 lock struct(s), heap size 1136, 13 row lock(s), undo log entries",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11959:539,error,errors,539,https://hail.is,https://github.com/hail-is/hail/pull/11959,2,['error'],['errors']
Availability,"There's a few things happening here:. ### Node pool updates through terraform; I extended the node pool update documentation with how to deal with terraform-managed node pools. This is what I did on Azure and worked fine. The only real change in terraform other than changing the machine type is making the node pool name configurable to adhere to the naming guidelines and allow us to do a rolling migration. ### Updated the kubernetes and azurerm providers; I updated the azurerm provider without thinking much about it and even though it's a minor version had some breaking changes that after a half-successful `apply` made it hard to downgrade. So I decided just to appease the breaking change and leave us at the new version, which is what all the `blob_properties` changes are for. They are in no way related to the node pools. ### Troubleshooting; I added a section for a bug that I've seen a couple of times (and encountered again today) but never documented how I got around it.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11636:638,down,downgrade,638,https://hail.is,https://github.com/hail-is/hail/pull/11636,1,['down'],['downgrade']
Availability,"There's a small CI feature where you can randomly assign someone from services and/or compiler team to review a PR by including a directive in the github PR body, e.g. #assign compiler. There's a slight bug where if the PR body is left blank, GitHub will report it as `None` instead of what I assumed would be """", which breaks the lines like `if ASSIGN_SERVICES in self.body` with the error that `None` is not iterable. This just inserts a guard against that.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10767:385,error,error,385,https://hail.is,https://github.com/hail-is/hail/pull/10767,1,['error'],['error']
Availability,These are the exact same error:; ```; In [4]: import asyncio; ...: import concurrent; ...: asyncio.TimeoutError == concurrent.futures.TimeoutError; Out[4]: True; ```,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10946:25,error,error,25,https://hail.is,https://github.com/hail-is/hail/pull/10946,1,['error'],['error']
Availability,"These functions have the same bytecode signature, and I'm tired of having cryptic compile errors due to changing imports. Now coerce is just for code/value/settable, and tcoerce is for types.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12333:90,error,errors,90,https://hail.is,https://github.com/hail-is/hail/pull/12333,1,['error'],['errors']
Availability,"These improvements would help for QC on trio data, and for exploring new variant quality models exploiting inheritance. .mendelI (nError per individual) should be an integer-valued sample annotation. We might also be interested in nError per trio, as sample annotation on child of trio. .mendelL (nError per locus, really variant) should be an integer-valued variant annotation. .mendel lists all errors. Each error has a unique (trio, variant). It's natural to ask for all variants where a trio has errors, and also for all trios in which a variant has an error. Perhaps the list of errors per variant should be a variant annotation from which all other annotations are derived. Note that if variants are distributed in intervals, this annotation won't be well-balanced as difficult-to-sequence regions will have far more error. .mendalF (nError per nuclear family) could be sample-keyed by the mother",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/597:397,error,errors,397,https://hail.is,https://github.com/hail-is/hail/issues/597,6,['error'],"['error', 'errors']"
Availability,"These incremental improvements set us up for a cleaner diff when the Shuffler IR lands. The bigger changes:. - add `getOrNull` to `HailContextFlags`, previously you'd always get an error if the key did not exist.; - add a few currently unused flags for the shuffler; they all default to settings appropriate for tests.; - transmit ETypes instead of codec specs; the buffer is fixed at compile-time.; - use buffers instead of raw input streams for all communication. This resolved some latent bugs that arise from mixing Hail's (In|Out)putBuffers with operations on the underlying streams. Encoders and Decoders appear to have no issue being interleaved with Buffer operations, so I now freely use the buffer of the (En|De)coder as is convenient.; - get now accepts inclusivity flags for both start and end (this was critical to use partition bounds correctly).; - implement partitionBounds.; - add a `close` to `ShuffleClient` so it can clean up ExecuteContext and the socket.; - the server and client now handshake (each sends and receives one byte) on a close so as to raise errors sooner if either one of them did not expect the conversation to end.; - KeyedCodecSpec => ShuffleCodecSpec, changed to support the all-etypes, no-codec-specs methodology.; - shrink uuid to 32 bytes, still a lot, but fits on one log line.; - implement a *whole pile* of write/read methods on `Wire.scala` that give a unified language to our mess of serializers and deserializers. I tried to make the rule: write: to buffer, read: from buffer, serialize: to string, deserialize: from string. Why are some things missing? Why are some thing unused? This is the set of things I need to ultimately make the Shuffler work. My apologies for the mammoth size of this PR. I've been trimming and trimming to get little fixes in, but now we're down to almost exclusive Shuffler changes. It seems less valuable to try and educate the team about the Shuffler via PR since it will be owned by services team.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8812:181,error,error,181,https://hail.is,https://github.com/hail-is/hail/pull/8812,3,"['down', 'error']","['down', 'error', 'errors']"
Availability,Think this should resolve this [error](https://console.cloud.google.com/logs/query;query=resource.type%3D%22k8s_container%22%0Aresource.labels.namespace_name%3D%22default%22%0Aresource.labels.container_name%3D%22auth-driver%22%0Aseverity%3DERROR;timeRange=PT3H?authuser=2&project=hail-vdc) where `auth-driver` is crashing on start,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9949:32,error,error,32,https://hail.is,https://github.com/hail-is/hail/pull/9949,1,['error'],['error']
Availability,"This CSV file is lacking any commas, it uses semicolons instead. https://github.com/jvns/pandas-cookbook/blob/master/data/bikes.csv I don't think hail should generate this error message:. ```; ---------------------------------------------------------------------------; FatalError Traceback (most recent call last); <ipython-input-5-2e52d209a59b> in <module>; ----> 1 broken_ht = hl.import_table('../data/bikes.csv'); 2 # Look at the first 3 rows; 3 broken_ht[:3]. </Users/dking/anaconda2/envs/foofoo/lib/python3.7/site-packages/decorator.py:decorator-gen-1110> in import_table(paths, key, min_partitions, impute, no_header, comment, delimiter, missing, types, quote, skip_blank_lines, force_bgz). ~/anaconda2/envs/foofoo/lib/python3.7/site-packages/hail/typecheck/check.py in wrapper(__original_func, *args, **kwargs); 558 def wrapper(__original_func, *args, **kwargs):; 559 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 560 return __original_func(*args_, **kwargs_); 561 ; 562 return wrapper. ~/anaconda2/envs/foofoo/lib/python3.7/site-packages/hail/methods/impex.py in import_table(paths, key, min_partitions, impute, no_header, comment, delimiter, missing, types, quote, skip_blank_lines, force_bgz); 1326 jt = Env.hc()._jhc.importTable(paths, key, min_partitions, jtypes, comment,; 1327 delimiter, missing, no_header, impute, quote,; -> 1328 skip_blank_lines, force_bgz); 1329 return Table._from_java(jt); 1330 . ~/anaconda2/envs/foofoo/lib/python3.7/site-packages/py4j/java_gateway.py in __call__(self, *args); 1255 answer = self.gateway_client.send_command(command); 1256 return_value = get_return_value(; -> 1257 answer, self.gateway_client, self.target_id, self.name); 1258 ; 1259 for temp_arg in temp_args:. ~/anaconda2/envs/foofoo/lib/python3.7/site-packages/hail/utils/java.py in deco(*args, **kwargs); 225 raise FatalError('%s\n\nJava stack trace:\n%s\n'; 226 'Hail version: %s\n'; --> 227 'Error summary: %s' % (deepest, full, hail.__versi",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5221:172,error,error,172,https://hail.is,https://github.com/hail-is/hail/issues/5221,1,['error'],['error']
Availability,"This PR attempts to make CI more useful as a developer feedback tool. Developers need to know the success/failure state of their PR ASAP. It is better to know that state for an old tip sha pair than to know nothing. It is better still to know that state for a more recent sha pair. It is best to know that state for the tip sha pair. We aim to test a PR's tip source sha (perhaps against an out of date target sha). ---. Our *target state* for remembering batches is:; - one is complete and the other is in-progress; the complete one is for an out-of-date tip sha pair, or ; - only one batch is in-progress or complete; it's for the tip sha pair. We forget an in-progress batch for a PR only if:; - a batch for a more recent sha pair is complete, or; - a more recent, but not tip, source sha build is also in progress. As is the case for our services, at any time we may not be in our target state. For CI, if we are not in our target state, `_refresh` and `_heal` are intended to move us towards the desired state. `_refresh` incorporates new GitHub information. `_heal` incorporates new batch state and perturbs batch as necessary. cc: services crew: @akotlar, @jigold . EDIT:. I've gone round and round with my thoughts on what the right idea here is. I would appreciate some discussion around what we should aim for.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6007:106,failure,failure,106,https://hail.is,https://github.com/hail-is/hail/pull/6007,1,['failure'],['failure']
Availability,"This PR begins the implementation of checkpointing and restoring of jobs in Batch. Currently, a container is checkpointed after 10 seconds and before running a container (using crun run) the worker container checks if it should restore a job based on a checkpoint in Google storage. Currently, the kinds of Jobs that can be checkpointed/restored are: jobs that do simple operations and only print to stdout, jobs that redirect their output to local files. Changelist:; - Add copy method to RouterAsyncFS; - Add checkpointable flag to containers (make DockerJob containers checkpointable and JVMJob containers not checkpointable); - Create checkpoint method which pauses a container, checkpoints it, copies the checkpoint directory and upper directory of the overlay into Google storage, and then resumes the container; - Add logic in _run_container to try copying checkpoint directory and upper directory from cloud storage and then running `crun restore` if the job is checkpointable",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11888:37,checkpoint,checkpointing,37,https://hail.is,https://github.com/hail-is/hail/pull/11888,12,['checkpoint'],"['checkpoint', 'checkpointable', 'checkpointed', 'checkpointing', 'checkpoints']"
Availability,"This PR breaks ""fatal"" out into two functions, ""fatal"" and ""abort"". Fatal is for unexpected error handling, and produces a python stacktrace, but 'abort' is for handled, expected errors (like invalid method inputs) and does not generate a stack trace in python.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1552:92,error,error,92,https://hail.is,https://github.com/hail-is/hail/pull/1552,2,['error'],"['error', 'errors']"
Availability,"This PR brings the `Streamify` pass back to the JVM emitter. Streamify is useful because it make explicit *in the structure of the IR*, which nodes are stream producers and which nodes are stream consumers. In particular, the following nodes **produce** streams:; ```; ReadPartition; MakeStream; StreamRange; ToStream. ArrayMap; ArrayFilter; ArrayFlatMap; ArrayScan; ArrayAggScan; ArrayLeftJoinDistinct. Let /* sometimes */; ```; And the following nodes **consume** streams (`#` indicates which arguments are streams):; ```; ToArray(#); ToDict(#); ToSet(#); GroupByKey(#) ; ArraySort(#, -, -, -); ArrayFold(#, -, -, -, -); ArrayFold2(#, -, -, -, -); ArrayFor(#, -, -); ArrayAgg(#, -, -); CollectDistributedArray(#, -, -, -, -). ArrayMap(#, -, -); ArrayFilter(#, -, -); ArrayFlatMap(#, -, #); ArrayScan(#, -, -, -, -); ArrayAggScan(#, -, -); ArrayLeftJoinDistinct(#, #, -, -, -, -). Let(-, -, #) /* sometimes */; ```. Thus, `Emit` may make better assumptions about the IR it is walking over. `emitArrayIterator` only deals with stream producers, and all stream consumers must call `emitArrayIterator` on their stream arguments. Additionally:; - `Streamify` was fixed to materialize less arrays than it used to (there were also bugs that caused errors on certain IR; see tests); - The producer `ToStream` may assume that its argument is a container.; - The IR nodes `ArrayRange` and `MakeArray` do not make their way to `Emit`.; - I'm not sure what the purpose of `{T,P}Streamable` is, I think all of its functionality is already covered by `{T,P}Iterable`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7120:1243,error,errors,1243,https://hail.is,https://github.com/hail-is/hail/pull/7120,1,['error'],['errors']
Availability,"This PR changes the `addresses` function on `DeployConfig` to retry all transient errors. In particular, if the address service is temporarily down (maybe its getting redeployed), this change allows the client to repeatedly retry until the address service comes back to life. I also added some type annotations to `retry_transient_errors`. It takes a function that returns something we can `await` and then applies that function in a loop until it does not raise an error.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9200:82,error,errors,82,https://hail.is,https://github.com/hail-is/hail/pull/9200,3,"['down', 'error']","['down', 'error', 'errors']"
Availability,"This PR implements the core IBS operations in terms of vectorized C code. In particular, we use the `libsimdpp` library to take advantage of whatever the widest available register is (many modern CPUs have AVX2 256 bit integer registers; Knights Landing will introduce AVX512 512-bit integer registers). The performance improvement is massive. We can compute the full IBD matrix on 2,535 samples and ~37 million variants in just under 17 minutes. We believe the complexity of this code is `O(nSamples^2 * nVariants)`. Assuming the scaling works out well, we should be able to compute 100,000 Variants and 40,000 samples in the same time. There were a couple issues I had to workaround, but hopefully we can re-use those workarounds:. - compiling native code from gradle; - packaging native code for `test`, `installDist`, and the JARs; - building native code specialized to certain architectures. Still left to do:. - [x] break the C tests into a separate file and call from gradle `test`; - [x] maybe use a library ([libsimdpp?](https://github.com/p12tic/libsimdpp)) to do the SIMD so we're agnostic to the underlying architecture (right now if you don't have AVX, we fall all the way back to 64-bit registers, rather than 128-bit SSE registers) ; - [x] some minor clean up of the IBSFFI class. Future Work:; - implement IBSExpectations in C as well; - expand this work to KING (or other structure correcting IBD calculations)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1092:161,avail,available,161,https://hail.is,https://github.com/hail-is/hail/pull/1092,1,['avail'],['available']
Availability,"This PR incorporates @cseed 's changes from #3477, brings everything up to date with master, and adds/fixes the following:; - added a test for linreg with no covariates against R, and deleted old `test_linear_regression_with_no_cov` since that still had intercept.; - extended Skat to work without covariates and added test that it runs, but its hard to test result against R given that the latter fails with no covariates: `Error in solve.default(t(X1) %*% X1) : 'a' is 0-diml`. The result look ""reasonable"" to me.; - added req of at least one covariate for logreg in doc and code. It's going to be painful to get logistic to take no covariates, we can always come back to it if priority goes up. Related fun breeze behavior: `a(::, *) *:* b` with `a` an `(n, 0)` matrix and `b` an `n`-vector has dimensions `(0, 0)`.; - removed default value of empty list for `covariate`, both to help signal users to consider putting in the intercept (pipelines currently using intercept only with default empty `[]` will break) and because empty is not currently valid for logreg.; - noted in docs that intercept must be included explicitly.; - added comment of R code against which linreg and logreg are testing",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4067:426,Error,Error,426,https://hail.is,https://github.com/hail-is/hail/pull/4067,1,['Error'],['Error']
Availability,"This PR introduces `SArray` and `SArrayValue`, lets us compile with arrays. I added implementations for `MakeArray` and `ArrayRef`. . To help myself out, I also registered the region allocation function on the `CompileModule` so it's always available to call. I added a `printf` function as well that takes a C++ string and a vector of `llvm::Value` to allow arbitrary debugging prints.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10128:241,avail,available,241,https://hail.is,https://github.com/hail-is/hail/pull/10128,1,['avail'],['available']
Availability,"This PR introduces `facet_wrap`, which will allow creating plots based on a specified facet. It also adds ; ` def _add_aesthetics_to_trace_args(self, trace_args, df):`; and; ` def _update_legend_trace_args(self, trace_args, legend_cache):`. two helper methods which let me clean up some of the redundant plotting work. A `legend_cache` was introduced to make sure we put traces that should have the same legend point in a `legendgroup` together. Without it, if I draw one red line in each of 4 different subplots created by a facet, then 4 entries appear in the legend.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11725:294,redundant,redundant,294,https://hail.is,https://github.com/hail-is/hail/pull/11725,1,['redundant'],['redundant']
Availability,"This PR introduces a generic pretty-printing package, which for now is only used in `ir.Pretty`. The primary motivation was to separate format specification from rendering, to simplify the formatting code, and make it easier to add multiple formatting options, including forms with line number references. Some nice properties of the new pretty-printer:; * Generic. Should be able to be used for all pretty-printing in hail scala code. This simplifies the codebase by making client pretty-printers easy to understand and modify, without getting bogged down in low-level details.; * Composable. Formatting specifications are trivially combinable, without needing to manually track context like the current indentation level, max line length, etc.; * Stack safe. Uses constant stack space.; * Uses constant heap space. Only keeps in memory text which might print in the current line, if it fits. (The pretty printer writes to a `java.io.Writer`, and I'm ignoring any heap space used by the writer.); * Lazy. If the number of lines to print is capped, doesn't scan more of the tree than is needed to print those lines.; * Produces more readable output, printing nodes on a single line where possible. As we work to increase visibility into the compiler, I think this will be very helpful. A formatted document is represented by the `Doc` type. This defines a `render` method, which takes three parameters to control the output:; * `width`: the maximum length of a line, including indentation; * `ribbonLength`: the maximum length of a line, not including indentation (too many characters on a line is hard to read, regardless of indentation); * `maxLines`: the maximum number of lines to print. There are only a few `Doc` constructors, which suffice to define all methods in the richer api contained in the `prettyPrint` package object.; * `Text(t: String)`; * `Line(ifFlat: String)`; * `Indent(i: Int, body: Doc)`; * `Concat(it: Iterable[Doc])`; * `Group(body: Doc)`. Ignoring `Group` for the moment, th",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9652:552,down,down,552,https://hail.is,https://github.com/hail-is/hail/pull/9652,1,['down'],['down']
Availability,"This PR is a step towards a general picture for generating debugging information in bytecode. The general picture is to write a sequence of files, each corresponding to a certain point in the compile pipeline, where each line in each file includes a line number pointing to the line in the previous file from which this line was derived. (We may eventually want richer source information than just a single line number, like a range or list of ranges.) The top of each file has the file name of the previous printout, which is the target of all line numbers in the file. We could in the future also print a list of transformations that were applied to get from the previous printed state to this one. The idea to implement this picture is simple. Each IR node stores a line number in a mutable variable. When we want to generate a printed checkpoint, we walk the IR, printing a representation of each node, including the stored line number, and then overwriting the node's line number with the current line count of the file being written to. Some work will be required to preserve this source information in all IR transformations. This PR implements this idea in lir only. If the `HAIL_WRITE_IR_FILES` environment variable is set, it is hardcoded to print the lir after the first `SimplifyControl` (because before that is very hard to read), and after method splitting right before emitting bytecode. It also prints out the class files themselves. Longer term we'll want to be able to control which points in the compilation get printed.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9521:839,checkpoint,checkpoint,839,https://hail.is,https://github.com/hail-is/hail/pull/9521,1,['checkpoint'],['checkpoint']
Availability,"This PR is based on discussion here: https://dev.hail.is/t/better-python-error-messages-idea/201/9 The intention is to create a system to give better error messages from python in a generic way. Tim's work in #7792 does a good job introducing behavior like this this specifically for `ArrayRef` nodes, but I want to add three things on top of that:. 1. I don't want to have to do as much custom per IR node work; 2. I don't want to send the entire python stack trace over py4j to scala for every node; 3. I don't want the user to see a Java stack trace in this scenarios. This first PR is a proof of concept that adds this behavior for the `Die` node, which will catch any errors generated by uses of `CaseBuilder.or_error`. Follow up PRs should change `ArrayRef` to work this way, as well as catch things like looking up a key in a dictionary but not finding it. In an ideal future, we'd bolt on some extra mechanism to give types to these errors, and we could throw a proper `IndexError` in the `ArrayRef` case or `KeyError` in the dictionary case. . It feels a little bit messy right now, open to suggestions. I don't love using `-1` as the ""no error"" situation, but I thought it was probably easier than dealing with optionals between python and scala. . To give an example of what it looks like, the error message for this script:. ```; import hail as hl. ht = hl.utils.range_table(10); ht = ht.annotate(foo = hl.nd.array([[1], [2], [3]])); ht = ht.annotate(bar = ht.foo[0:4, 12]); ht.collect(); ```. is. ```; Traceback (most recent call last):; File ""better_error_test.py"", line 6, in <module>; ht.collect(); File ""<decorator-gen-1103>"", line 2, in collect; File ""/Users/johnc/Code/hail/hail/python/hail/typecheck/check.py"", line 614, in wrapper; return __original_func(*args_, **kwargs_); File ""/Users/johnc/Code/hail/hail/python/hail/table.py"", line 1903, in collect; return Env.backend().execute(e._ir); File ""/Users/johnc/Code/hail/hail/python/hail/backend/spark_backend.py"", line 325, in ex",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9398:73,error,error-messages-idea,73,https://hail.is,https://github.com/hail-is/hail/pull/9398,4,['error'],"['error', 'error-messages-idea', 'errors']"
Availability,This PR is stacked on #9593. The key files to look at are in `docker/hail-ubuntu`. I introduced `hail-apt-get-install` which packages up the `apt-get update` and the removal of temporary files. I also set the number of package-download retries to 5.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9594:227,down,download,227,https://hail.is,https://github.com/hail-is/hail/pull/9594,1,['down'],['download']
Availability,"This PR is the first iteration of an AsyncFS-based copy interface. It adds RouterAsyncFS.copy. The goal of these changes is to establish the interface and behavior. I expect several follow-on PRs:. - Revise the original copy interface proposal and add to dev-docs.; - ~~Parallelizes the transfers concurrently with async and across multiple threads.~~; - ~~After parallizing, copy will involve a lot of paralellism. Throwing an exception on the first error will be very non-deterministic. Instead, copy will return a report that collects all the errors that were encountered in the course of copying, and summarizes how many files/bytes were copied.~~; - Use multi-process parallelism; - Avoid overwriting the destination if it exists and has a matching checksum (or size).; - ~~Introduce multi-part transfers~~; - add a post-pass for Google Storage to detect file-and-directory errors.; - Adds support for S3.; - Add `hailctl cp ...` (PR); - Use copy in Batch. After this goes in, these can mostly be developed in parallel. A few principles guided the implementation of copy: perform the minimal number of system calls or API requests per copy, and only do error checking when it doesn't involve additional FS operations. For example, it is too expensive to exhaustively check if we're creating a path that is a file and a directory in Google Storage. I considered doing additional and exhaustive checking for the actual copy arguments. For example, currently, `cp -T /path/to/file /path/to/dir` will not generate an error on Google Storage. In the end, I decided to go with the current behavior and I will add an option to do a postpass to check for file-and-dir paths. To achieve this, for each transfer, I simultaneously stat the destination (if needd) to determine if it is a file, directory or doesn't exist. For each source, I simultaneously try to copy it as a file and a directory. When copying each source, we don't need to know the type of the destination until after we've stat'ed the sour",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9822:451,error,error,451,https://hail.is,https://github.com/hail-is/hail/pull/9822,3,['error'],"['error', 'errors']"
Availability,This PR makes docker calls idempotent and adds a timeout for docker calls in the retry function. I got the error codes to ignore from the older docker documentation at the bottom of each API call: https://docs.docker.com/engine/api/v1.30/#operation/ContainerDelete. FYI: @cseed since you had opinions on the timeout times,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8049:107,error,error,107,https://hail.is,https://github.com/hail-is/hail/pull/8049,1,['error'],['error']
Availability,This PR mitigates the 500 error Ben was getting on the UI page when a resource usage file was corrupt. It also implements a more graceful handling of an out of space error on the worker.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12609:26,error,error,26,https://hail.is,https://github.com/hail-is/hail/pull/12609,2,['error'],['error']
Availability,"This PR rewrites the hailctl command line argument parsing code. While the interface remains largely the same, a few changes were made to how options are handled. We first introduce a bit of terminology. In a shell command invocation like `$ cmd a -o c`, `a`, `-o` and `c` are called parameters. `a` and `c` which do not start with dashes, are called arguments. `-o`, which starts with a dash, is an option. This PR makes the following changes:. - For dataproc commands taking extra gcloud parameters, all parameters after a double-dash (--) are passed to gcloud.; - The actual rule is slightly more complicated, but I think the above rule is the right take away. In detail, extra parameters are passed to gcloud. Unknown options (starting with a dash) before `--` are reported as an error. So arguments (not options) before `--` and all parameters after are passed to gcloud. ; - Short options don't need a `=` when specifying a value. It is now `-p2`, not `-p=2`.; - While I was making breaking changes, I changed `dataproc submit` `--gcloud_configuration` to `--gcloud-configuration`. I am happy to undo this one.; - Group arguments must go before the next command. Write `hailctl dataproc --beta start ...` not `hailctl dataproc start --beta ...`, which is an error since `start` has no option `--beta`. This PR rewrites argument parsing to use click instead of argparse: https://click.palletsprojects.com/en/7.x/. Things you need to know about click:; - A group is a group of commands or subgroups, like `hailctl dataproc`, `hailctl batch`, etc. Groups are defined like this:; ; ```; @hailctl.group(; help=""Manage the Hail Batch service.""); def batch():; pass; ```; - A command in a group is defined like this:. ```; @batch.command(; help=""Get a particular batch's info.""); @click.argument('batch_id', type=int); @click.option('--output-format', '-o',; type=click.Choice(['yaml', 'json']),; default='yaml', show_default=True,; help=""Specify output format"",); def get(batch_id, output_format):; ..",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9842:784,error,error,784,https://hail.is,https://github.com/hail-is/hail/pull/9842,1,['error'],['error']
Availability,"This PR teaches gear/database.py to respect four more MySQL configuration parameters: `ssl-mode`, `ssl-ca`, `ssl-cert`, `ssl-key`. In particular, we can now turn TLS on or off and rotate keys by simply changing secrets and restarting the services. Since all sql-config secrets (except those in my namespace) currently have no certs, no keys, and no ssl parameters, after this PR merges all services will still use plaintext communications to the database. After this PR merges, I will update the root secret as well as all the service secrets (e.g. sql-auth-user-config) to have a shared client cert/key and our sql database's cert. Moreover I will set `ssl-mode` to `VERIFY_CA` which means (in our world, at least) verify the server's certificate but not the hostname (we use IPs to connect to our sql server) and present your own certificate for verification. Then I will restart all the services. Then I will ban plaintext connections to the database. Then I will PR a change that raises errors if we try to start a service with plaintext connections or unverified connections. I also:; - updated `create_database.py` so that it will propagate these TLS settings, if present, to created secrets, and; - updated CI to use `gear/database.py` and standard sql-config locations. All these parameters are defined by MySQL. We only support three options for [`ssl-mode`](https://dev.mysql.com/doc/refman/5.7/en/connection-options.html#option_general_ssl-mode), the remainder are either unnecessary or not supported (e.g. we have no hostnames so `VERIFY_IDENTITY` is irrelevant).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8433:991,error,errors,991,https://hail.is,https://github.com/hail-is/hail/pull/8433,1,['error'],['errors']
Availability,"This PR teaches most of our cluster how to exclusively speak HTTPS instead of; HTTP. The exceptions are:; - from batch-driver to batch workers; - from batch workers to internal-gateway; - to ukbb-rg; - from router to notebook workers; - letsencrypt (oh the irony). ## Changes from Original PR Proposal. ### Root Certificate. I added a secret to default named `ssl-config-hail-root` containing `hail-root-key.pem`, and `hail-root-cert.pem`. Every principal trusts this root. This root trusts every principal. This PR originally prevented clients from speaking to servers with certs they didn't trust. Now everyone trusts everyone. As long as the root key is not leaked this is OK. Only `create_certs` mounts this secret. The key is used to sign every certificate and the cert is included in each principal's incoming and outgoing trust lists. The root certificate and key are never re-created, so our deploys have no downtime and we avoid addressing the rotation problem. I removed all the trust specifications. A later PR will resolve rotation and mTLS. That PR will restore the trust specifications. I didn't change the structure of the secrets (they still have an incoming and outgoing trust list which only contains the root cert) because I need this structure for mTLS anyway. The original PR text follows. ---. ## HTTPS and TLS. HTTP is implemented on TCP/IP. HTTPS is also implemented on TCP/IP and differs; very mildly. After the socket is opened, a TLS [1] connection is established; over the socket. Thereafter, every HTTP message is encrypted and transported by; the TLS machinery. The HTTP protocol is unchanged. The default port fort HTTP is; 80 and the default port for HTTPS 443, however any port may be used. There are currently four versions of TLS, the latest is TLS 1.3. All versions of; SSL are considered insecure. The OpenSSL library implements TLS. There are other implementations, such as; LibreSSL, but they implement roughly the same interface as OpenSSL. The TLS protocol def",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8561:916,downtime,downtime,916,https://hail.is,https://github.com/hail-is/hail/pull/8561,1,['downtime'],['downtime']
Availability,"This PR tries to address the error we saw last Friday on Azure where there was a stuck worker that could not pull ubuntu:20.04 from Dockerhub. The error message in the worker logs was. ```; DockerError(500, 'Head \""https://haildev.azurecr.io/v2/ubuntu/manifests/20.04\"": denied: retrieving permissions failed'); ```. I looked at the system logs and the actual error message was this:. ```; Mar 03 16:56:12 batch-worker-default-standard-nj0qy dockerd[4066]: time=""2023-03-03T16:56:12.112691249Z"" level=info msg=""Attempting next endpoint for pull after error: Head \""https://haildev.azurecr.io/v2/ubuntu/manifests/20.04\"": denied: retrieving permissions failed""; ```. Higher up in the logs was:. ```; Mar 03 16:54:50 batch-worker-default-standard-nj0qy dockerd[4066]: time=""2023-03-03T16:54:50.520878176Z"" level=debug msg=""Fetching manifest from remote"" digest=""sha256:9fa30fcef427e5e88c76bc41ad37b7cc573e1d79cecb23035e413c4be6e476ab"" error=""<nil>"" remote=""docker.io/library/ubuntu:20.04""; Mar 03 16:54:50 batch-worker-default-standard-nj0qy dockerd[4066]: time=""2023-03-03T16:54:50.762789745Z"" level=debug msg=""Fetching manifest from remote"" digest=""sha256:9fa30fcef427e5e88c76bc41ad37b7cc573e1d79cecb23035e413c4be6e476ab"" error=""ref moby/1/index-sha256:9fa30fcef427e5e88c76bc41ad37b7cc573e1d79cecb23035e413c4be6e476ab locked: unavailable"" remote=""docker.io/library/ubuntu:20.04""; ```. My working hypothesis is described in detail here that the image cache with locks got corrupted with the simultaneous pulls: https://hail.zulipchat.com/#narrow/stream/300487-Hail-Batch-Dev/topic/Azure.20CI.20appears.20hung/near/339452619. To mitigate this, when we get the error ""denied: retrieving permissions failed"", we try and delete the image and then try pulling again once more before erroring gracefully. At least for now, this errors the user's job, but that's better than the status quo where the job is stuck.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12758:29,error,error,29,https://hail.is,https://github.com/hail-is/hail/pull/12758,9,['error'],"['error', 'erroring', 'errors']"
Availability,"This PR updates a lot of NDArray code that was using the old `Code[T]` and emit triplet interface in favor of using code builders and `IEmitCode`. This is going to make it easier to update the `PNDArray` interface to not use `Code[Long]` everywhere, among other things. . Before this PR, there existed `NDArrayEmitter`, which did the old thing, and `NDArrayEmitter2`, which was a prototype of a new emitter. . After this PR, a tweaked version of `NDArrayEmitter2` has become the new `NDArrayEmitter`. `outputElement` now returns a `PCode`, and all the missingness problems are handled by carrying a `IEmitCodeGen[NDArrayEmitter]` around throughout the deforesting process, meaning the `NDArrayEmitter` no longer needs internal state about missingness. . I think the diff for `Emit.scala` is going to be pretty confusing. I'd at least opt for a side by side view instead of the intermingled one, as I've mostly implemented the same logic, just on top of our new code builder primitives. . All tests pass, but marking WIP since I'm noticing some slow down in the slice test that I want to look into. . This PR also adds a `get` function to `EmitValue` that gets the underlying `PValue` and moves two functions off of the `PNDArray` interface into `LinalgCodeUtils`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9824:1049,down,down,1049,https://hail.is,https://github.com/hail-is/hail/pull/9824,1,['down'],['down']
Availability,"This PR updates the LocalBackend to match the behavior of the SparkBackend w.r.t. error handling. . - `handle_java_exception` and `execute` are lifted into the parent file, `Py4JBackend`. ; - Tests in `test_ndarrays` that were marked as failing local tests are now passing, since the only failure was inconsistent handling of errors. . The error handling changes in question here were introduced in #9398",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9569:82,error,error,82,https://hail.is,https://github.com/hail-is/hail/pull/9569,4,"['error', 'failure']","['error', 'errors', 'failure']"
Availability,This PR:; - Replaces Fluentd with Filebeat (Filebeat config based on the recommended kubernetes filebeat config from elastic repo); - Increases elasticsearch storage. ; - Modifies Kibana's security context so that it doesn't run as root (Kibana will print an error message if it's running as root).; - Adds the `decode_json_fields` processor to filebeat so that it parse our structured log messages as json.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6659:259,error,error,259,https://hail.is,https://github.com/hail-is/hail/pull/6659,1,['error'],['error']
Availability,"This addresses a user issue whereby adding an indicator covariate that only varied in controls caused Firth to fail. Currently the standard logistic MLE is computed even for Firth regression so this beta can be used to initialize the Firth per-variant models. But if the data has a (quasi-)separated coordinate, the standard MLE may not converge, throwing an error before the Firth models are fit. With the changes in this PR, if the MLE does not converge, Firth falls back to initializing with the intercept-only estimate.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2737:359,error,error,359,https://hail.is,https://github.com/hail-is/hail/pull/2737,1,['error'],['error']
Availability,This addresses issues where the gradle download may fail. We retry a command; that is cheap (`--version`) but which requries downloading the gradle binary.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8782:39,down,download,39,https://hail.is,https://github.com/hail-is/hail/pull/8782,2,['down'],"['download', 'downloading']"
Availability,"This adds SpillingCollectIterator which avoids holding more than 1000 aggregation results in memory at one time. We could do something that listens for GC events and spills data if there's high memory pressure. That seems a bit error prone and hard. The number of results kept in memory is a flag on the HailContext. In C++ we can design a system that is aware of its memory usage and adjusts memory allocated to scans accordingly. #### Implementation Notes. I had to add two new file operations to `FS` and `HadoopFS` because I need seekable file input streams. When we add non-hadoop `FS`'s we'll need to address the interface issue. When we overflow our in-memory buffer, we spill to a disk file. We use O(n_partitions / mem_limit) files. We stream through the files to `scanLeft`, to compute the globally valid scan state per partition. The stream writes its results to another file which must be on a cluster-visible file system (we use `HailContext.getTemporaryFile`). Finally, each partition reads that file and seeks to its scan state. I somewhat better solution would be to eagerly scan as results come in. I leave that as future work. #### Timings. Master 0.2.14-4da055db5a7b; ```; In [1]: %%time ; ...: ; ...: import hail as hl ; ...: ht = hl.utils.range_table(10000, n_partitions=10000) ; ...: ht = ht.annotate(rank = hl.scan.count())._force_count() ; CPU times: user 1.45 s, sys: 333 ms, total: 1.78 s; Wall time: 24.6 s; In [3]: %%time ; ...: ; ...: import hail as hl ; ...: ht = hl.utils.range_table(1000000, n_partitions=1000) ; ...: ht = ht.annotate(rank = hl.scan.count())._force_count() ; CPU times: user 6.23 ms, sys: 1.96 ms, total: 8.19 ms; Wall time: 1.33 s; ```; This branch; ```; In [1]: %%time ; ...: ; ...: import hail as hl ; ...: ht = hl.utils.range_table(10000, n_partitions=10000) ; ...: ht = ht.annotate(rank = hl.scan.count())._force_count() ; CPU times: user 1.36 s, sys: 297 ms, total: 1.66 s; Wall time: 27.3 s. In [2]: %%time ; ...: ; ...: import hail as hl ; ...:",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6345:228,error,error,228,https://hail.is,https://github.com/hail-is/hail/pull/6345,1,['error'],['error']
Availability,"This adds `SpillingCollectIterator` which avoids holding more than 1000 aggregation results in memory at one time. We could do something that [listens for GC events](https://stackoverflow.com/questions/30041332/a-useful-metric-for-determining-when-the-jvm-is-about-to-get-into-memory-gc-trou) and spills data if there's high memory pressure. That seems a bit error prone and hard. How should I pipe the size limit down to TableMapRows? The only workable solution I can think of is a HailContext setting. Maybe I should bite the bullet and respond to memory pressure? Either way this should get Laurent cooking with gas. Spilling ten local files and then reading them in is probably in the noise of timings. . Master 0.2.14-4da055db5a7b; ```ipython; In [1]: %%time ; ...: ; ...: import hail as hl ; ...: ht = hl.utils.range_table(10000, n_partitions=10000) ; ...: ht = ht.annotate(rank = hl.scan.count())._force_count() ; CPU times: user 1.45 s, sys: 333 ms, total: 1.78 s; Wall time: 24.6 s; In [3]: %%time ; ...: ; ...: import hail as hl ; ...: ht = hl.utils.range_table(1000000, n_partitions=1000) ; ...: ht = ht.annotate(rank = hl.scan.count())._force_count() ; CPU times: user 6.23 ms, sys: 1.96 ms, total: 8.19 ms; Wall time: 1.33 s; ```; This branch:; ```ipython; In [2]: %%time ; ...: ; ...: import hail as hl ; ...: ht = hl.utils.range_table(10000, n_partitions=10000) ; ...: ht = ht.annotate(rank = hl.scan.count())._force_count() ; CPU times: user 1.41 s, sys: 313 ms, total: 1.72 s; Wall time: 25.2 s. In [3]: %%time ; ...: ; ...: import hail as hl ; ...: ht = hl.utils.range_table(1000000, n_partitions=1000) ; ...: ht = ht.annotate(rank = hl.scan.count())._force_count() ; ...: ; ...: ; CPU times: user 4.72 ms, sys: 1.82 ms, total: 6.53 ms; Wall time: 1.41 s; ```. ---. Minor implementation note: I did the rigamarole with `runJob` because I wasn't sure that using `synchronized` in a constructor was kosher and I'm also generally weary of Scala's constructor syntax.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6306:359,error,error,359,https://hail.is,https://github.com/hail-is/hail/pull/6306,2,"['down', 'error']","['down', 'error']"
Availability,"This adds `SpillingCollectIterator` which avoids holding more than 1000 aggregation results in memory at one time. We could do something that listens for GC events and spills data if there's high memory pressure. That seems a bit error prone and hard. How should I pipe the size limit down to TableMapRows? I decided to make it a HailContext `flag` which means its not very user-visible, but Laurent can set it for now. In C++ we can design a system that is aware of its memory usage and adjusts memory allocated to scans accordingly. Spilling ten local files and then reading them in is probably in the noise of timings. . ---. ### Implementation Notes. I had to add two new file operations to the `RichHadoopConfiguration` because I need seekable file input streams. I don't like the names. I'm not sure what to do here. Hadoop really screws us with the seek-ability on compressed streams. The implementation is rather simple, it just maintains an array of the per-partition results. The index of the array corresponds to the partition index. The sparsity of that array is controlled by how often we spill. For an operation with a huge number of partitions that are often spilled (e.g. large number of partitions, each with a lot of data), we may want to use a `Map` instead of an `Array`. The use of `ObjectOutputStream` without a try-catch-finally block is non-standard. I was having trouble seeking to individual classes when I used one ObjectOutputStream to output each partition's array. There were these ""bad header"" messages. This seems to work. I don't close the OOS because I'm going to re-use the underlying output stream on the next partition. We use O(n_spills) files. ---. ### Timings. Master 0.2.14-4da055db5a7b; ```; In [1]: %%time ; ...: ; ...: import hail as hl ; ...: ht = hl.utils.range_table(10000, n_partitions=10000) ; ...: ht = ht.annotate(rank = hl.scan.count())._force_count() ; CPU times: user 1.45 s, sys: 333 ms, total: 1.78 s; Wall time: 24.6 s; In [3]: %%time ; ...: ;",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6333:230,error,error,230,https://hail.is,https://github.com/hail-is/hail/pull/6333,2,"['down', 'error']","['down', 'error']"
Availability,"This adds a prometheus statefulset to track metrics like API request latency and uptime. It scrapes pods on a 15s interval and collects prometheus metrics from any container in a pod with `grafanak8sapp` label that exposes an https endpoint `/metrics`.; The batch front end was already exposing prometheus metrics, but I changed it up slightly. For any http endpoint there should be a single metric, `http_request_latency`. Prometheus adds app and namespace metrics so seeing latencies for batch in particular is just a filter applied to this single metric. You can track latency of an endpoint by adding the `@monitor_endpoint` decorator defined in `metrics.py`, which tracks latency as well as number of requests and status code per request, available in the `http_request_count` metric. I also added monitoring to all CI endpoints. This also includes an `up` metric for tracking uptime at the same 15s granularity. I'm not convinced prometheus will suit our finer-grained needs surrounding batch, but it should do well enough in the meantime for our more traditional SLIs and allows to focus on one problem at a time.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10165:744,avail,available,744,https://hail.is,https://github.com/hail-is/hail/pull/10165,1,['avail'],['available']
Availability,"This adds some useful infrastructure for Scala-generated C++. 1. Initial support for a small number of C++-to-Scala upcalls. 2. C++ info/warn/error implemented as upcall going through is.hail.utils,{info,warn,error}. 3. Scala PrettyCode auto-indenter for Scala-generated C++, so you don't have to try to; get the indentation right while generating the C++ source. 4. src/main/c/Makefile has a variable HAIL_ENABLE_DEBUG if set as "":=1"", then libs will be; built with -O1, and the initialization in src/main/NativePtr.cpp will try to start gdb in an xterm; and attach back to the hail process, allowing gdb debugging of generated C++ called from; Scala. 5. ObjectArray is a NativeObj which can hold any number of Scala Objects, holding them in C++; as JNI global-ref jobjects. This can be used for example to hold InputBuffer or InputStream; objects, and to pass them down to a constructor for a C++ object (e.g. a decoder) which will then ; make upcalls to methods of those objects. . A subsequent commit will have the RowStore/C++ decoder using all this infrastructure (passing an; InputBuffer down to the C++ decoder, which holds it and makes upcalls to pull a block of data).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4302:142,error,error,142,https://hail.is,https://github.com/hail-is/hail/pull/4302,4,"['down', 'error']","['down', 'error']"
Availability,"This adds terraform modules for CI azure resources and CI k8s resources. It also many roles to the test account that the batch account has so that we can run PR and test namespaces (internal batch instances use the test account for all the services so the test account needs tons of privilege. It looks scary, but this is the model we currently have). Thanks to #11053, which is the current version of the CI deployment in Azure, this required no change to the CI application code. ### Sidebar; It might look weird that I've added a block here for the kubernetes provider. That is because up until now I've kept all the k8s and azure terraform in separate root modules, so that they need to be `terraform apply`'d separately and therefore their provider blocks were separated as well. While keeping the code isolated is good (the k8s modules can be reused for GCP), putting them in separate apply's was purely because of [this bug](https://github.com/hashicorp/terraform-provider-kubernetes/issues/1028) in the kubernetes provider. I ran into it when experimenting tearing clusters down and putting them back up again. However, it has since proven very cumbersome to manage two different terraform states where one relies heavily on the other and I've changed my mind. The bug in question has a PR forthcoming and is really only a problem when tearing a K8s cluster down and rebuilding it while preserving other terraform state, which isn't something I see us dealing with often past initial development. Thus, I've added the k8s provider block so that I can directly invoke the CI k8s module. I'll follow up with a PR that moves the other k8s module invocations in here as well. If it would help, I can first start with a dev doc detailing our terraform structure (or where I want it to be).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11084:1082,down,down,1082,https://hail.is,https://github.com/hail-is/hail/pull/11084,2,['down'],['down']
Availability,"This adds the minimal resources to k8s to allow us to modify the gateway's configuration to include redirects for https://notebook.hail.is. Currently, that domain will timeout, but there should otherwise be no errors introduces to the k8s system. cc: @cseed",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4645:210,error,errors,210,https://hail.is,https://github.com/hail-is/hail/pull/4645,2,['error'],['errors']
Availability,"This adds the oauth2 client secret as a terraform resource instead of uploading it by hand to k8s (though you still have to download it manually from the console. It also makes use of the `bootstrap_utils.sh` script that I introduced for azure for cloud-agnostic steps, trimming down the GCP instructions by a lot.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11037:124,down,download,124,https://hail.is,https://github.com/hail-is/hail/pull/11037,2,['down'],"['down', 'download']"
Availability,"This adds two new Dockerfiles. The first has gsutil and pip-wheel-installed; Hail. The second builds on the first adding a number of bioinformatics tools; that were included in the CCG Tutorial. Deployment to dockerhub is not trivial because, unfortunately, I need to mount; the docker socket even to download and then upload an image (never starting a; container). I'll design and implement some extension to CI that lets me deploy; images to docker hub later. For now, I used dev deploy to build; these (https://ci.hail.is/batches/33294) and then manually pulled them and; uploaded them to PyPI as hailgenetics/hail:0.2.37 and; hailgenetics/genetics:0.2.37. I particularly appreciate criticism of the names.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8562:301,down,download,301,https://hail.is,https://github.com/hail-is/hail/pull/8562,1,['down'],['download']
Availability,"This astronomically cuts down on IR duplication. The following is the IR for one invocation to TableMultiWayZipJoin in the old pipeline, this would be replicated for every vcf imported:; ```; (CastMatrixToTable ""__entries"" ""__cols""; (MatrixMapEntries; (MatrixMapRows; (MatrixMapEntries; (MatrixMapRows; (MatrixMapEntries; (MatrixLiteral); (InsertFields; (SelectFields (AD DP GQ GT MIN_DP PGT PID PL SB); (Ref g)); None; (END; (GetField END; (GetField info; (Ref va)))); (BaseQRankSum; (GetField BaseQRankSum; (GetField info; (Ref va)))); (ClippingRankSum; (GetField ClippingRankSum; (GetField info; (Ref va)))); (MQ; (GetField MQ; (GetField info; (Ref va)))); (MQRankSum; (GetField MQRankSum; (GetField info; (Ref va)))); (ReadPosRankSum; (GetField ReadPosRankSum; (GetField info; (Ref va)))); (LGT; (GetField GT; (Ref g))); (LAD; (If; (ApplyComparisonOp EQ; (ApplyIR indexArray; (GetField alleles; (Ref va)); (I32 -1)); (Str ""<NON_REF>"")); (ApplyIR `[:*]`; (GetField AD; (Ref g)); (I32 -1)); (GetField AD; (Ref g)))); (LPL; (If; (ApplyComparisonOp EQ; (ApplyIR indexArray; (GetField alleles; (Ref va)); (I32 -1)); (Str ""<NON_REF>"")); (If; (ApplyComparisonOp GT; (ArrayLen; (GetField alleles; (Ref va))); (I32 2)); (ApplyIR `[:*]`; (GetField PL; (Ref g)); (ApplyUnaryPrimOp Negate; (ArrayLen; (GetField alleles; (Ref va))))); (NA Array[Int32])); (If; (ApplyComparisonOp GT; (ArrayLen; (GetField alleles; (Ref va))); (I32 1)); (GetField PL; (Ref g)); (NA Array[Int32])))); (LPGT; (GetField PGT; (Ref g))); (RGQ; (If; (ApplyComparisonOp EQ; (ApplyIR indexArray; (GetField alleles; (Ref va)); (I32 -1)); (Str ""<NON_REF>"")); (ApplyIR indexArray; (GetField PL; (Ref g)); (Apply unphasedDiploidGtIndex; (Apply Call; (I32 0); (ApplyBinaryPrimOp Subtract; (ArrayLen; (GetField alleles; (Ref va))); (I32 1)); (False)))); (NA Int32))))); (InsertFields; (SelectFields (locus alleles rsid qual filters info); (Ref va)); None; (alleles; (If; (ApplyComparisonOp EQ; (ApplyIR indexArray; (GetField alleles; (Ref va))",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5527:25,down,down,25,https://hail.is,https://github.com/hail-is/hail/pull/5527,1,['down'],['down']
Availability,"This came to mind yesterday during our pairing. This PR introduces the following properties that our image building targets do not currently have:; 1. If your intention is only to build images, you shouldn't need `kubectl`. When `DOCKER_PREFIX` is used as a docker build arg it is because we mirror some dockerhub images inside our registry (for reliability/rate limiting reasons). But for local building there's no reason you can't use the dockerhub image. Also, other people should be able to build the hail image if they want to!; 2. One should *only* need to use `kubectl` if they are intending to use an image in a kubernetes deployment. In other words, you should only need the private registry `DOCKER_PREFIX` for pushing images.; 3. One should not need to endure image pushing if the only goal is to build the image locally; 4. No intermediate tags should end up in the private registry. If we push on every image build, the private docker registry will accumulate a lot of `hail-ubuntu:dev-xxxxxx` tags that are never used again because `hail-ubuntu` is just an intermediate used to build other images. This does *not* change the number of layers that end up in the registry, but reduces a bit of the work that the registry cleanup job needs to do to untag and delete images and just seems cleaner.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13890:346,reliab,reliability,346,https://hail.is,https://github.com/hail-is/hail/pull/13890,1,['reliab'],['reliability']
Availability,"This catch was masking a `org.json4s.package$MappingException: Parsed JSON values do not match with class constructor` as a `NullPointerException` on line 148. Exceptions always include their cause in the stack trace, I see no compelling reason to maintain this try-catch.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6156:15,mask,masking,15,https://hail.is,https://github.com/hail-is/hail/pull/6156,1,['mask'],['masking']
Availability,"This caught a bug in the type inference in `GroupByKey`, which is also fixed in the PR. @konradjk I'm pretty sure that this makes #5147 work, but I haven't confirmed directly so if you could confirm that it does and then close (or re-ping) once this goes in, that would be great.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5155:234,ping,ping,234,https://hail.is,https://github.com/hail-is/hail/pull/5155,1,['ping'],['ping']
Availability,This caused assertion errors in Scala in `MakeArray.unify`.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12750:22,error,errors,22,https://hail.is,https://github.com/hail-is/hail/pull/12750,1,['error'],['errors']
Availability,"This causes issues when starting interactive sessions on clusters. Before, I get lots of output like this:; SPARKMONITOR_LISTENER: Started SparkListener for Jupyter Notebook; SPARKMONITOR_LISTENER: Port obtained from environment: ERRORNOTFOUND. SPARKMONITOR_LISTENER: Exception creating socket:java.lang.NumberFormatException: For input string: ""ERRORNOTFOUND"". SPARKMONITOR_LISTENER: Application Started: application_1569946119076_0001 ...Start Time: 1569946336092. SPARKMONITOR_LISTENER: Exception sending socket message:java.lang.NullPointerException. After:; <nothing>. I also tested to make sure the monitor still worked in a notebook.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7174:230,ERROR,ERRORNOTFOUND,230,https://hail.is,https://github.com/hail-is/hail/pull/7174,2,['ERROR'],['ERRORNOTFOUND']
Availability,"This causes the interpreter to try other possible implementations, producing weird errors. For example:. ```; if hl.dict([1], [1]):; pass; ```. raises an error about `__len__`, not `__nonzero__`",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4169:83,error,errors,83,https://hail.is,https://github.com/hail-is/hail/issues/4169,2,['error'],"['error', 'errors']"
Availability,"This change exists as part of larger refactoring work. Herein, I've exchanged; hard-coded contextual strings passed to `ExecutionTimer.time` with implict; contexts, drawing inspiration from scalatest. These contexts are now supplied after entering functions like `Compile` and; `Emit` instead of before (see `ExecuteContext.time`). By sprinking calls to ; `time` throughout the codebase after entering functions, we obtain a nice trace; of the timings with `sourcecode.Enclosing`, minus the previous verbosity. See [1] for more information about what pre-built macros are available. We can; always build our own later. See comments in [pull request id] for example output.; Note that `ExectionTimer.time` still accepts a string to support uses like; `Optimise` and `LoweringPass` where those contexts are provided already.; It is also exception-safe now. This change exposed many similarities between the implementations of query; execution across all three backends. I've stopped short of full unification; which is a greater work, I've instead simplified and moved duplicated result; encoding into the various backend api implementations. More interesting changes are to `ExecuteContext`, which now supports; - `time`, as discussed above; - `local`, a generalisation for temporarily overriding properties of an ; `ExecuteContext` (inspired by [2]). While I've long wanted this for testing,; we were doing some questionable things when reporting timings back to python,; for which locally overriding the `timer` of a `ctx` has been very useful.; We also follow this pattern for local regions. [1] https://github.com/com-lihaoyi/sourcecode; [2] https://hackage.haskell.org/package/mtl-2.3.1/docs/Control-Monad-Reader.html#v:local",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14679:572,avail,available,572,https://hail.is,https://github.com/hail-is/hail/pull/14679,1,['avail'],['available']
Availability,"This change grew out of https://github.com/hail-is/hail/pull/13674.; The idea is simple - we shouldn't be appending code after control statements as such statements are redundant. That idea opened pandora's box, but now we're not generating and dropping dead code anymore. Main changes that rose form fixing fallout from adding assert in `Block.append`:; - Implement basic control-flow structures (if, while, for, switch) in `CodeBuilderLike` and remove the older implementations from `Code`.; - main difference is these are built from sequencing `Code` operations rather than being defined from LIR; - allows for a higher-level implementation that I think is simpler to read.; - Use the type-system to prevent foot-guns like `cb.ifx(cond, label.goto)`. Other changes:; - rename `ifx`, `forLoop` and `whileLoop` to just `if_`, `for_` and `while_`, respectively.; - Implement loops in-terms of one-another to remove code duplication.; - Fix logic for when to write IRs as some default value behaviour was broken when `HAIL_WRITE_IR_FILES` was set in tests",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13752:169,redundant,redundant,169,https://hail.is,https://github.com/hail-is/hail/pull/13752,1,['redundant'],['redundant']
Availability,"This change removes previous infrastructure for building generated C++; code. The previous infrastructure would write two files, a cpp file and; a makefile, then run make to build the shared object. This change gets rid of all that in favor of a pipe-fork-exec model,; using the ability of clang++/g++ to read from stdin via `-x <LANG>` and; `-` arguments. Some notes:. * We still invoke the shell to find JAVA_HOME if it is not defined. We; do this in a similar way to what we do in the makefiles.; * Because of the odd signatures of the `exec` family of functions, we; use a `const_cast` to discard the appropriate qualifiers. This is safe; because we only do it after forking, and only to exec, and never use; that data after the call to `execvp`.; * We ignore `SIGPIPE`, as it is raised when the process tries to write; to a pipe where the other end is closed. Not doing this could crash; hail, and means that the child process died before we wrote all of the; c++ source to the pipe, other error handling will catch what actually; went wrong, rather than being unable to write to the pipe.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6927:995,error,error,995,https://hail.is,https://github.com/hail-is/hail/pull/6927,1,['error'],['error']
Availability,"This change sorts the jobs for a PR correctly in the UI, so that all jobs are placed under a header with the correct state (see screenshot). Because jobs are split into separate tables by their state, `focusOnSlash` has been removed from the relevant CI pages, since it is unknown which tables will exist on the page until it is rendered. It also fixes the error that was causing the server to return a 500 when there were no jobs yet (e.g. when a retry had just been requested), which was caused by an assumption in the original job filtering code that there would always be at least one job to display. It also passes the list of developers through to the underlying `PR` object that a `WatchedBranch` has, which was missed in https://github.com/hail-is/hail/pull/13398 but is required for CI to display the PR page correctly in dev deploys only. <img width=""714"" alt=""Screenshot 2023-08-22 at 15 08 48"" src=""https://github.com/hail-is/hail/assets/84595986/6bcab38c-a48a-4e10-8f69-770d35ea51b7"">",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13254:357,error,error,357,https://hail.is,https://github.com/hail-is/hail/pull/13254,1,['error'],['error']
Availability,This creates redundant bindings that interfere with our ability to apply certain simplification rules.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7720:13,redundant,redundant,13,https://hail.is,https://github.com/hail-is/hail/pull/7720,1,['redundant'],['redundant']
Availability,"This ended up being a great lesson in `asyncio`!. `kubernetes_asyncio` has a deeply hidden `asyncio.ClientSession` that doesn't get properly closed when we restart services with `SIGINT`. Turns out the `__del__` method on the `RESTClient` deep inside the library that holds this client session sets up a future with asyncio to close the session, but I suspect that this object is getting deleted _after_ the event loop closes. As a result we get a bunch of garbage in the logs that; - the event loop is already closed when something is trying to happen; - a `ClientSession.close` was never properly awaited. I initially tried to explicitly close the client session but still dealt with the problem that the `k8s_client` was trying to interact with the even loop after it closed. Explicitly deleting the `k8s_client` on cleanup and then awaiting any remaining futures (so the client session `close`) appears to fix the problem as I get no more errors on shutdown, but let me know if this isn't kosher. If this is alright I'll see this through to the rest of the services.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9944:943,error,errors,943,https://hail.is,https://github.com/hail-is/hail/pull/9944,1,['error'],['errors']
Availability,"This feature is not widely supported (only on MatrixTable & SparkBackend); and is not well-tested in CI (we only test that matrix writes run and return; the correct result with the _checkpoint_file parameter, not the performance; semantics). I've played around with this code on my laptop and the performance semantics; are what I expect. Logging messages provide some transparency too:. ```. In [2]: mt = hl.utils.range_matrix_table(100000, 10, 500). In [3]: mt.write('/tmp/mt_temp4.mt', _checkpoint_file='/tmp/mt_checkpoint'); 	2021-03-23 14:50:06 Hail: INFO: creating new checkpoint at /tmp/mt_checkpoint; 	^C---------------------------------------------------------------------------00]; 	KeyboardInterrupt Traceback (most recent call last); 	<snip>; 	KeyboardInterrupt:. In [4]: mt.write('/tmp/mt_temp4.mt', _checkpoint_file='/tmp/mt_checkpoint'); 	2021-03-23 14:50:14 Hail: INFO: resuming matrix write from /tmp/mt_checkpoint with 192/500 partitions written; 	^C---------------------------------------------------------------------------00]; 	KeyboardInterrupt Traceback (most recent call last); 	<snip>; 	KeyboardInterrupt:. In [5]: mt.write('/tmp/mt_temp4.mt', _checkpoint_file='/tmp/mt_checkpoint'); 	2021-03-23 14:50:22 Hail: INFO: resuming matrix write from /tmp/mt_checkpoint with 300/500 partitions written; 	^C---------------------------------------------------------------------------00]; 	KeyboardInterrupt Traceback (most recent call last); 	<snip>; 	KeyboardInterrupt:. In [6]: mt.write('/tmp/mt_temp4.mt', _checkpoint_file='/tmp/mt_checkpoint'); 	2021-03-23 14:50:29 Hail: INFO: resuming matrix write from /tmp/mt_checkpoint with 372/500 partitions written; 	2021-03-23 14:50:36 Hail: INFO: wrote matrix table with 100000 rows and 10 columns in 500 partitions to /tmp/mt_temp4.mt; 	 Total size: 391.55 KiB; 	 * Rows/entries: 391.51 KiB; 	 * Columns: 31.00 B; 	 * Globals: 11.00 B; 	 * Smallest partition: 200 rows (505.00 B); 	 * Largest partition: 200 rows (835.00 B). In [7]: mt_r",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10215:575,checkpoint,checkpoint,575,https://hail.is,https://github.com/hail-is/hail/pull/10215,1,['checkpoint'],['checkpoint']
Availability,"This fixes an issue where we cannot retrieve old batches for a PR. Addresses this error:; ```; {""levelname"": ""ERROR"", ""asctime"": ""2019-08-01 15:59:17,119"", ""filename"": ""web_protocol.py"", ""funcNameAndLine"": ""log_exception:355"", ""message"": ""Error handling request"", ""exc_info"": ""Traceback (most recent call last):\n File \""/usr/local/lib/python3.6/dist-packages/aiohttp/web_protocol.py\"", line 418, in start\n resp = await task\n File \""/usr/local/lib/python3.6/dist-packages/aiohttp/web_app.py\"", line 458, in _handle\n resp = await handler(request)\n File \""/usr/local/lib/python3.6/dist-packages/aiohttp/web_urldispatcher.py\"", line 157, in handler_wrapper\n result = await result\n File \""/usr/local/lib/python3.6/dist-packages/aiohttp_jinja2/__init__.py\"", line 91, in wrapped\n context = await coro(*args)\n File \""/ci/ci.py\"", line 170, in get_batch\n j['duration'] = humanize.naturaldelta(datetime.timedelta(seconds=sum(j['duration'])))\nTypeError: unsupported operand type(s) for +: 'int' and 'NoneType'""}; {""levelname"": ""INFO"", ""asctime"": ""2019-08-01 15:59:17,119"", ""filename"": ""web_log.py"", ""funcNameAndLine"": ""log:233"", ""message"": ""10.32.0.177 [01/Aug/2019:15:59:17 +0000] \""GET /batches/584 HTTP/1.0\"" 500 315 \""-\"" \""Mozilla/5.0 (Macintosh;; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6783:82,error,error,82,https://hail.is,https://github.com/hail-is/hail/pull/6783,3,"['ERROR', 'Error', 'error']","['ERROR', 'Error', 'error']"
Availability,"This fixes the notebook2 deployment permission issue that was resulting in CrashLoopBackoff (no permissions for the Table class to `read_namespaced_secret('get-users', 'default')`). Already tested, works (notebook2 back up). It also fixes an apparent error in the master branch RoleBinding. This diff looks slightly weird. I fixed the existing notebook Roles/RoleBindings by deleting the `create-services` `Role` and `notebook-create-services` `RoleBinding`, and then fixing the broken `notebook-create-servivces-and-pods` `RoleBiding`, by correctly updating the `roleRef` to read `create-services-and-pods`. When notebook1 totally goes away, we can probably remove the ""services"" permission. Before:; ```yaml; ---; kind: Role; apiVersion: rbac.authorization.k8s.io/v1; metadata:; namespace: default; name: create-services; rules:; - apiGroups: [""""]; resources: [""services""]; verbs: [""*""]; ---; kind: RoleBinding; apiVersion: rbac.authorization.k8s.io/v1; metadata:; namespace: default; name: notebook-create-services; subjects:; - kind: ServiceAccount; name: notebook; namespace: default; roleRef:; kind: Role; name: create-services; apiGroup: """"; ---; kind: Role; apiVersion: rbac.authorization.k8s.io/v1; metadata:; namespace: default; name: create-services-and-pods; rules:; - apiGroups: [""""]; resources: [""services""]; verbs: [""*""]; - apiGroups: [""""]; resources: [""pods""]; verbs: [""*""]; ---; kind: RoleBinding; apiVersion: rbac.authorization.k8s.io/v1; metadata:; namespace: default; name: notebook-create-services-and-pods; subjects:; - kind: ServiceAccount; name: notebook; namespace: default; roleRef:; kind: Role; name: create-services #this was causing the error, and of course the create-services role is superseded by the the create-services-and-pods role; apiGroup: """"; ---; ```. After:; ```yaml; kind: Role; apiVersion: rbac.authorization.k8s.io/v1; metadata:; namespace: default; name: create-services-and-pods; rules:; - apiGroups: [""""]; resources: [""services""]; verbs: [""*""]; - apiGrou",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5746:251,error,error,251,https://hail.is,https://github.com/hail-is/hail/pull/5746,1,['error'],['error']
Availability,"This fixes two bugs:; 1. The container logs weren't being cached. This made the logs ""disappear"" for previous tasks while the job was still running. FYI @konradjk . 2. My job got stuck in ""running"" even though the job was deleted from the worker because writing the status to GCS timed out and we didn't actually mark the job complete. I'm not sure if we should always try to retry writing the status rather than failing on non-transient errors. ```; Traceback (most recent call last):; File ""/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py"", line 384, in _make_request; six.raise_from(e, None); File ""<string>"", line 2, in raise_from; File ""/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py"", line 380, in _make_request; httplib_response = conn.getresponse(); File ""/usr/local/lib/python3.6/http/client.py"", line 1354, in getresponse; response.begin(); File ""/usr/local/lib/python3.6/http/client.py"", line 307, in begin; version, status, reason = self._read_status(); File ""/usr/local/lib/python3.6/http/client.py"", line 268, in _read_status; line = str(self.fp.readline(_MAXLINE + 1), ""iso-8859-1""); File ""/usr/local/lib/python3.6/socket.py"", line 586, in readinto; return self._sock.recv_into(b); File ""/usr/local/lib/python3.6/ssl.py"", line 1012, in recv_into; return self.read(nbytes, buffer); File ""/usr/local/lib/python3.6/ssl.py"", line 874, in read; return self._sslobj.read(len, buffer); File ""/usr/local/lib/python3.6/ssl.py"", line 631, in read; v = self._sslobj.read(len, buffer); socket.timeout: The read operation timed out. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/usr/local/lib/python3.6/site-packages/requests/adapters.py"", line 449, in send; timeout=timeout; File ""/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py"", line 638, in urlopen; _stacktrace=sys.exc_info()[2]); File ""/usr/local/lib/python3.6/site-packages/urllib3/util/retry.py"", line 368, in increment; ra",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8054:438,error,errors,438,https://hail.is,https://github.com/hail-is/hail/pull/8054,1,['error'],['errors']
Availability,This frequently fails and triggers an error log.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12472:38,error,error,38,https://hail.is,https://github.com/hail-is/hail/pull/12472,1,['error'],['error']
Availability,"This gets ld_prune on the `get_1kg` data down to around 37s. That's still ~1000 times slower than plink.; ```; mt = hl.read_matrix_table('repartitioned.mt'); pruned_tbl = hl.ld_prune(mt.GT, r2 = 0.2, bp_window_size = 1000000, memory_per_core = 1000); pruned_tbl.write(""pruned_tbl.ht"", overwrite=True); ```. Performance Wins:; - local ld prune returns an unkeyed, unsorted dataset, and `ld_prune` collects the relatively small number of variants locally instead of trying to do table joins (I'm doing the broadcast join optimization manually); - avoid `key_by` (and thus sort) of output of MIS, again we do a broadcast join; - two unnecessary writes removed (at the cost of no debugging output); - `maximal_independent_set` no longer keys by, thus avoiding a sort. Minor Changes:. - I don't set env vars anymore, so I need an easy way to pip install hail, so I added a gradle task for that and an associated file that does almost the same thing as deploy.sh. you should complain and make me consolidate these two files. ---; ## Big Data Test. I'm running a test on profile225 right now. ---. resolves #4506",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5078:41,down,down,41,https://hail.is,https://github.com/hail-is/hail/pull/5078,1,['down'],['down']
Availability,"This groups IBD and pc_relate together. I will follow up with KING. I plan to; lift some of the documentation verbiage from PC-Relate up and to unify the; mathematical presentation for PC-Relate and KING. I did not change the implementations, I just moved them into the relatedness; package. Both functions are still available at `hl.methods.XXX`. The import changes are just me using `(` and `)` instead of line continuation.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9324:317,avail,available,317,https://hail.is,https://github.com/hail-is/hail/pull/9324,1,['avail'],['available']
Availability,"This impacts all the methods that use _select_entries, e.g. within process_joins, like group_by.aggregate_rows/cols, annotate_rows/cols, transmute_rows/cols, etc. The error is expression source mismatch, which may be due to `annotate_entries` being done separately from `_annotate_all` in the joiner for `index_entries` AST:; ```; def joiner(left: MatrixTable):; localized = Table(self._jvds.localizeEntries(row_uid)); src_cols_indexed = self.cols().add_index(col_uid); src_cols_indexed = src_cols_indexed.annotate(**{col_uid: hl.int32(src_cols_indexed[col_uid])}); left = left._annotate_all(row_exprs = {row_uid: localized.index(*row_exprs)[row_uid]},; col_exprs = {col_uid: src_cols_indexed.index(*col_exprs)[col_uid]}); return left.annotate_entries(**{uid: left[row_uid][left[col_uid]]}); ```. ### Hail version:; master; b1ac051d34bcc4c26fe9dea58aeac53038f2963e. ### What you did:. ```; mt = hl.utils.range_matrix_table(4, 4); mt2 = hl.utils.range_matrix_table(4, 4); mt2 = mt2.annotate_entries(x=mt2.row_idx + mt2.col_idx); mt.select_entries(a=mt2[mt.row_idx, mt.col_idx].x,; b=mt2[mt.row_idx, mt.col_idx].x)._force_count_rows(); ```. ### What went wrong (all error messages here, including the full java stack trace):. ```; Error; Traceback (most recent call last):; File ""/Users/jbloom/anaconda/envs/py36/lib/python3.6/unittest/case.py"", line 59, in testPartExecutor; yield; File ""/Users/jbloom/anaconda/envs/py36/lib/python3.6/unittest/case.py"", line 605, in run; testMethod(); File ""/Users/jbloom/hail/python/hail/tests/test_api.py"", line 1557, in test_force_bug; b=mt2[mt.row_idx, mt.col_idx].x)._force_count_rows(); File ""/Users/jbloom/hail/python/hail/matrixtable.py"", line 1171, in select_entries; return self._select_entries(""MatrixTable.select_entries"", hl.struct(**entry)); File ""/Users/jbloom/hail/python/hail/typecheck/check.py"", line 547, in wrapper; return f(*args_, **kwargs_); File ""/Users/jbloom/hail/python/hail/matrixtable.py"", line 2844, in _select_entries; base, cleanup = se",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3763:167,error,error,167,https://hail.is,https://github.com/hail-is/hail/issues/3763,1,['error'],['error']
Availability,"This implementation lowers TableWrite with a TableNativeReader. Punting on the `stageLocally` path for now (it'll throw a lowering error) since our current implementation adds a task listener to the spark task to clean up files, and I'm not sure how we want to handle that in the general case.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8926:131,error,error,131,https://hail.is,https://github.com/hail-is/hail/pull/8926,1,['error'],['error']
Availability,"This implementation should reduce the number of list HTTP requests and a faster implementation for large directories. Basically, the key assumption here is to only request at most 2 blob listings. If there are 0 results, then the blob doesn't exist. If there's 1 result, then it either is the `Blob` for a directory or file with the desired path. And if there are at least 2 results, then the path must be a directory. It could also be a file as well as a directory here. In Python, we throw an error `FileAndDirectoryError`. But currently we, just return the first blob item we see that matches (non-deterministic). I have maintained that same behavior here. A different PR can address what to do in this case where the path is both a file and a directory.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13390:495,error,error,495,https://hail.is,https://github.com/hail-is/hail/pull/13390,1,['error'],['error']
Availability,"This introduces the necessary pieces of infrastructure to run CI in GCP and a couple of small changes such that it can run as a secondary CI. This is currently failing because one of the secrets I introduce here in the terraform does not exist in hail-vdc. If you approve of the approach I can add it in manually. . ## Terraform changes; This adds a new CI terraform module that adds a CI bucket, sets some permissions for the CI service account and adds some K8s secrets like github tokens and the zulip config. This allows the terraform deployment to optionally include resources needed for CI. This was the best way I could think to introduce this infra with the least changes, but it's not what I want in the long term. Right now we have one monolithic root module that includes all the resources necessary to run batch, with the option for tacking on CI. I would rather extract most of our root module into a `batch` module (and while we're break down the innards into modules like vdc, db, etc.) and have the root module be something that can be easily pieced together from the library of modules. This would be a decently big refactor and more importantly would require existing deployments to manually overhaul their terraform state, so it's something I want to do carefully but also sooner is better than later. Given how terraform state is indexed, I believe more modularity will be easier to manage in the long term. ## CI changes; This adds the following features to CI; - Watched branches can be marked as `mergeable`. `mergeable=true` should be the default behavior and `false` prevents CI from merging a PR on GitHub. This allows multiple CI's to run tests in different environments without stepping on each others' toes. This *does not*, however, consider statuses from multiple CIs when making the decision to merge a PR. That is currently based on the build status, and later should be changed to consider the collection of statuses on GitHub.; - Custom Deploy Steps: This is a colle",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11053:952,down,down,952,https://hail.is,https://github.com/hail-is/hail/pull/11053,1,['down'],['down']
Availability,"This is a bit of a mess so feel free to ask that I break it down or explain more in depth. In short, this:. - adds terraform for forgotten bits and pieces necessary for running PR tests like test buckets and the necessary permissions on those resources; - Adds a couple of flags that allow a CI `WatchedBranch` to be considered mergeable or not. This shouldn't change anything in default CI, but it allows you to specify that a secondary CI should run PRs, post statuses, and deploy new commits, but never actually commit anything to GitHub. Similarly there's a flag for turning off zulip notifications, but annoyingly the zulip config is still a required secret. I plan to make that nicer in the future.; - Fixes a lot of previously-unreached syntax errors in the batch tests. Following PRs will have relatively less functionality but probably a fair bit of cleanup and reorganization, e.g. getting rid of config.mk and generating it from terraform output, making scripts of the bootstrapping process etc.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10866:60,down,down,60,https://hail.is,https://github.com/hail-is/hail/pull/10866,2,"['down', 'error']","['down', 'errors']"
Availability,"This is a fix for an error Ben found. ```; Traceback (most recent call last):; File ""/usr/local/lib/python3.9/dist-packages/batch/worker/worker.py"", line 1907, in run; await self.setup_io(); File ""/usr/local/lib/python3.9/dist-packages/batch/worker/worker.py"", line 1848, in setup_io; await self.disk.create(labels=labels); File ""/usr/local/lib/python3.9/dist-packages/batch/cloud/gcp/worker/disk.py"", line 47, in create; await self._attach(); File ""/usr/local/lib/python3.9/dist-packages/batch/cloud/gcp/worker/disk.py"", line 112, in _attach; self.last_response = await self.compute_client.attach_disk(; File ""/usr/local/lib/python3.9/dist-packages/hailtop/aiocloud/aiogoogle/client/compute_client.py"", line 83, in attach_disk; return await self._request_with_zonal_operations_response(self.post, path, params, **kwargs); File ""/usr/local/lib/python3.9/dist-packages/hailtop/aiocloud/aiogoogle/client/compute_client.py"", line 126, in _request_with_zonal_operations_response; return await retry_transient_errors(request_and_wait); File ""/usr/local/lib/python3.9/dist-packages/hailtop/utils/utils.py"", line 763, in retry_transient_errors; return await retry_transient_errors_with_debug_string('', 0, f, *args, **kwargs); File ""/usr/local/lib/python3.9/dist-packages/hailtop/utils/utils.py"", line 775, in retry_transient_errors_with_debug_string; return await f(*args, **kwargs); File ""/usr/local/lib/python3.9/dist-packages/hailtop/aiocloud/aiogoogle/client/compute_client.py"", line 116, in request_and_wait; raise GCPOperationError(result['httpErrorStatusCode'],; hailtop.aiocloud.aiogoogle.client.compute_client.GCPOperationError: GCPOperationError: 400:BAD REQUEST ['RESOURCE_IN_USE_BY_ANOTHER_RESOURCE'] [""The disk resource 'projects/hail-vdc/zones/us-central1-b/disks/batch-disk-82XXXXX' is already being used by 'projects/hail-vdc/zones/us-central1-b/instances/batch-worker-default-standard-yjXXXX'""]; {'kind': 'compute#operation', 'id': 'XXXXX', 'name': 'operation-XXXXX', 'zone': 'https://www.g",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13955:21,error,error,21,https://hail.is,https://github.com/hail-is/hail/pull/13955,1,['error'],['error']
Availability,"This is a newer version of #9598. We decided to give users min(5Gi/core, 5 Gi) in `/` with mounting external storage at `/io` if they need more storage. All storage requests can be 0, 0 < storage < 10 will be rounded up to 10 Gi, or 10+Gi rounded up to the nearest integer. I added a loop to remove orphaned disks in gce.py. I changed how the resources appear in the spec. Now there's `req_cpu`, `req_storage`, `req_memory` which stores what the user specified. Then we also have `cores_mcpu`, `memory_bytes`, and `storage_gib` which are the actual resources allocated. I think this will be simpler and more understandable. Resources are computed in the front end now and the worker just uses the values from the front end (no more doing conversions on both the worker and front end). I kept backwards compatibility on the worker for now which can get deleted once there are no more jobs with batch format version < 6. I bumped the instance version to 16 so we know which workers have the new storage functionality. . I tested this by submitting 4 jobs on my 1 core test instance with 150Gi requests. I then looked at the worker logs to make sure the disks were created correctly and the value of the semaphore was correct. I also tested 0 Gi and 5 Gi by hand to make sure the resource fulfilled was 0Gi and 10Gi respectively. Lastly, I checked the billing to make sure we charged for the fraction of the SSD used as well as the cost of adding an extra persistent SSD for that job. I also looked at the disks in the GCE console to make sure they wear torn down correctly. Although there isn't a migration, we should make sure there are no non-ci jobs running so that we don't over allocate the storage available. Also, once this is merged, we should send an email to all users to let them know the cores must be a power of 2 now and about the storage now being mounted at '/io`. I put the WIP tag on so I can do this when I'm ready to.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10090:1556,down,down,1556,https://hail.is,https://github.com/hail-is/hail/pull/10090,2,"['avail', 'down']","['available', 'down']"
Availability,"This is a pretty barebones implementation of split_multi with none of the flags that the usual split_multi has. Because I think the gVCF combiner ensures that min-repping alleles doesn't move them, I'm returning the min-repped locus/alleles and erroring if the locus changes (since this would mess up the ref blocks in that row, although I suppose I could always fall back to the non-minrepped version instead). It constructs 5 table nodes (two of which are key-bys and shouldn't need to touch the actual partitioned data) and three passes---map, explode, map---which is more-or-less the same as the usual split-multi. I haven't timed this on anything yet but I'm happy to if someone points me at a dataset I can use. @chrisvittal I've assigned this to you because I figure you're in the best position to make sure I've understood the format correctly.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5394:245,error,erroring,245,https://hail.is,https://github.com/hail-is/hail/pull/5394,1,['error'],['erroring']
Availability,"This is a simplified implementation of `Process.communicate`. We feed lines into the log one-by-one; until we reach the end of both stdout and stderr. When both stdout and stderr have been closed by; the child process, we wait for the process to exit. At any point in time, the most recent log is; available to us.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10259:298,avail,available,298,https://hail.is,https://github.com/hail-is/hail/pull/10259,1,['avail'],['available']
Availability,"This is a temporary fix for the sporadic copy failures. The problem is that this code cancels a task managed by the online bounded pool, and the pool treats that cancellation as an exception that it propagates up. I need to think through the details of the bounded gather with respect to cancellation, and that's going to take a few days. We could put this back when that's done, but honestly, it doesn't seem like an important optimization (given how rarely this failure comes up), so I'll probably just leave it out.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10260:46,failure,failures,46,https://hail.is,https://github.com/hail-is/hail/pull/10260,2,['failure'],"['failure', 'failures']"
Availability,"This is a total overhaul of our docker images. Though very verbose, I tried to stick to these main tenets:. - Any docker image has exactly 1 layer in it (all the way down to ubuntu) that installs pip dependencies. This primarily aims to protect the cache for this particularly large layer and also avoids a later layer silently upgrading the version of a dependency installed in an earlier layer. This pairs nicely with the following goal; - We only ever use 1 version of a dependency across the monorepo. Liberal use of pip's [constraint files](https://pip.pypa.io/en/stable/user_guide/#constraints-files) to ensure that the dependencies for a service must be compatible with dependencies from hail. The `install-dev-dependencies` target which install all our pinned requirements files would tell you if there's any incompatible versions of transitive dependencies across the repo; - The image graph is shallow and images don't contain more than they need. In order to have a single layer with requirements and hail code on top, I moved the service images to just be based on hail-ubuntu. This shortens the critical path and therefore reduces total image building time by reducing the number of times our image data needs to be downloaded and re-uploaded to the registry. I also removed a lot of unnecessary cruft like gcloud in places it wasn't used anymore, some unused/unnecessary pip requirements, etc.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12578:166,down,down,166,https://hail.is,https://github.com/hail-is/hail/pull/12578,2,['down'],"['down', 'downloaded']"
Availability,"This is an improvement, but I think we should reconsider the batch state. Thinking out loud: The batch and CI UIs have slightly different displays. If you're running, have had a failed job, but also been cancelled, what should your state be? I think we either need columns in the batch display for open/closed, cancelled, complete and the simple state (open, running, cancelled, failure, success ... where the latter 3 mean complete), or display compound states like ""running failure cancelled"".",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7897:379,failure,failure,379,https://hail.is,https://github.com/hail-is/hail/pull/7897,2,['failure'],['failure']
Availability,This is causing CI to have 500 errors.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7542:31,error,errors,31,https://hail.is,https://github.com/hail-is/hail/pull/7542,1,['error'],['errors']
Availability,"This is going to cause problems down the line. Here's an example where inappropriate use of parentheses does something unexpected:; ```python; In [39]: x = functions.capture(5). In [40]: eval_expr((3 < x) & x > 5); Out[40]: True. In [41]: eval_expr((3 < x) & (x > 5)); Out[41]: False; ```; I'm actually not sure what the order of operations is in [40], but it's clearly wrong.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2640:32,down,down,32,https://hail.is,https://github.com/hail-is/hail/issues/2640,1,['down'],['down']
Availability,"This is in implementation of `linear_regression_rows` that does not rely on any `MatrixToTableApply` nodes. Once `TableKeyBy` is lowered, this should be executable on the service. There are lingering issues:. 1. `TableGroupWithinPartitions` is likely not the right abstraction. It forgets about keying, which forces me to rekey and scan the table even though it's already in order. 2. I don't support chained linear regression (the situation where `y` is a list of lists of phenotypes). I just throw an error there for now. . 3. It's not as fast as the current `linear_regression_rows` (addressing problem 1 should help with this). 4. I don't yet support the `pass_through` field. I want to PR this now because I would like to get the benchmark in so I can continue to measure how this performs in comparison to the current version of `linear_regression_rows`. The tests of this method also serve as useful integration tests for lots of NDArray functionality. Additionally, it'll make it easier to make a smaller PR in the future that adds the new `TableIR` that will hopefully be more suitable than `TableGroupWithinPartitions`",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8757:503,error,error,503,https://hail.is,https://github.com/hail-is/hail/pull/8757,1,['error'],['error']
Availability,"This is mostly cleanup reducing the amount of the codebase that depends on GSA key files (which are not available in terra or a future keyless hail-vdc). The core bit is instead of threading `credentials_file=""/gsa-key/key.json` through the batch and auth codebase we set `GOOGLE_APPLICATION_CREDENTIALS` in their deployments. I can't think of a scenario where `auth` or `batch` would need to use multiple identities so better to remove their ability to do so and always use the default credentials. I also did a bit of tidying up, using `$GOOGLE_APPLICATION_CREDENTIALS` instead of the hard-coded path and removing the credentials endpoints on the batch-driver which have been unused by workers for many months now.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13596:104,avail,available,104,https://hail.is,https://github.com/hail-is/hail/pull/13596,1,['avail'],['available']
Availability,"This is mostly straightforward, except in the case of PBinary and PString, where I elected to move static methods to instance methods. This was done because these methods completely depend on the PType, and having them as static methods prevents use of non-canonical versions of these methods (regardless of where they are). This includes functions like allocate, which deal with memory layout, and therefore must be configurable by ptype. Places where these static methods are used often include places where a PString or PBinary are passed around. Will finish this up after I get back most likely, or we can punt on the PStirng/PBinary issue for later (but I think it's worth doing now for the reasons outlined above). Stacked on https://github.com/hail-is/hail/pull/7903; ping @tpoterba",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7904:775,ping,ping,775,https://hail.is,https://github.com/hail-is/hail/pull/7904,1,['ping'],['ping']
Availability,"This is needed to properly implement copy/rename when you don't know if the source is a file or directory. We now only stat dest if treat_dest_as == INFER_DEST. Suppose we do `cp src dest`. There are three cases:. - Treat dest as a directory, and copy `src` to `dest/src`; - Treat dest like the target, and copy `src` to `dest` (whether src is a file or directory).; - Infer the type of dest and act accordingly. If `dest` is a directory, we're in the first case. If dest doesn't exist, or is a file, we're in the second case. I added two tests cases: test_copy_rename_dir_dest_is_target and test_overwrite_rename_dir, which test copying a directory with DEST_IS_TARGET (when the dest exists or not). I already had tests for when we were copying a file. I regenerated the copy test specs because of renames and some minor changes to error checking behavior. I spot checked the differences, and they don't seem worse (e.g. `cp file destfile/` now generates an error instead of ignoring the trailing slash.)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10127:833,error,error,833,https://hail.is,https://github.com/hail-is/hail/pull/10127,2,['error'],['error']
Availability,"This is not a real error. It is not the fault of batch that the other; end of the connection did not respond. If batch is having general; network connectivity issues, I would expect to see many other; error log statements.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11383:19,error,error,19,https://hail.is,https://github.com/hail-is/hail/pull/11383,3,"['error', 'fault']","['error', 'fault']"
Availability,"This is not this interface's final form, but it is an important; transitionary step in moving the entire code generation codebase away; from Code[T]. The CodeOrdering interface now (as before) has 12 methods, but before; the function signatures looked like:. def compare(lhs: (Code[Boolean], Code[T]), rhs: (Code[Boolean], Code[T])) -> Code[Int]. They now look like:. def compare(cb: EmitCodeBuilder, lhs: EmitCode, rhs: EmitCode) -> Code[Int]. There have been a lot of miscellaneous changes needed to get this to; work. There's some stuff that needs to be cleaned up, notably in Emit,; it's not always the case that the type of the IR/Aggregator is the same; as the type of the EmitCode that emit produces. I've tried to add; assertions where possible, but if there is an error, then a rather; cryptic 'Cannot pop value off of empty stack' exception is thrown,; generally indicating that an ordering expected an optional value, but; a required emitcode was provided.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9825:773,error,error,773,https://hail.is,https://github.com/hail-is/hail/pull/9825,1,['error'],['error']
Availability,This is part 1 in mitigating the extra rows in the billing tables with redundant resources with the same prices. I'm not sure how long it takes to drop a table of this size. Would prefer to merge in the morning in case there are any issues.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12710:71,redundant,redundant,71,https://hail.is,https://github.com/hail-is/hail/pull/12710,1,['redundant'],['redundant']
Availability,This is the cause of master test failures. More detail to follow.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6086:33,failure,failures,33,https://hail.is,https://github.com/hail-is/hail/issues/6086,1,['failure'],['failures']
Availability,"This is the compiled BGEN decoder. there's a fix to the partitioning logic as well. If there's no partitions, it previously errored. I added a `math.max` in case the maxRecordPerPartition is huge and the records is small and their floating point ratio ends up as zero. You can more easily see these changes when ignoring whitespace: https://github.com/hail-is/hail/pull/3916/files?w=1. ---. I reverted back to the `Iterator[Option[RegionValue]]` because per-row allocation isn't that bad and it just seems kind of hard an unnecessary  . cc: @patrick-schultz",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3916:124,error,errored,124,https://hail.is,https://github.com/hail-is/hail/pull/3916,1,['error'],['errored']
Availability,"This is the initial terraform setup to spinning up resources in azure, from downloading the `az` cli to getting a kubernetes cluster, database and network running. This contains instructions on initializing terraform using a remote backend in an azure container so multiple people should be able to apply terraform changes and have the same view of the system. Next step is setting up the gateway and internal gateways so that we can communicate between k8s services and VMs in the batch worker subnet.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10815:76,down,downloading,76,https://hail.is,https://github.com/hail-is/hail/pull/10815,1,['down'],['downloading']
Availability,"This is the most recently deployed version of monitoring.yaml. I'm not sure the best way to test it solves the problem that deployments faced. One thing to note is that StatefulSets don't guarantee that all of their constituent pods get deleted when the StatefulSet is deleted. To be sure the pods all get deleted, we'd have to either manually delete them or scale the StatefulSet size down to 0 before deleting it.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6343:386,down,down,386,https://hail.is,https://github.com/hail-is/hail/pull/6343,1,['down'],['down']
Availability,"This is the plan for the new Hail CI (tentatively: Hephaestus aka h8s [but Hodor is also in the running, see CI software name in Zulip for the real big questions of our time]). # Expected Repo Structure; Every repository to be tested has at least two files: `hail-ci-build-image` and `hail-ci-build.sh`. The former contains a docker image in a publicly accessible repository. The latter is a shell script that exits with 0 if this branch passes the tests, otherwise it exists with a non-zero code. The logs of this shell script will be shared publicly via the GH PR Status. This script will be executed in the image referenced by `hail-ci-build-image`. # Dockerfile.pr-builder; I carefully wrote a docker file to cache as much gradle crap as possible. # gitHash in Gradle; I pushed `gitHash`'s definition into the `doLast` blocks of the gradle steps that actually need it. `doLast` is only run when the task is actually requested. This allows me to run `downloadDependencies` without creating a dependency on the entire `.git` directory (which changes with each commit, thus invalidating the cache'd docker image).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4066:954,down,downloadDependencies,954,https://hail.is,https://github.com/hail-is/hail/pull/4066,1,['down'],['downloadDependencies']
Availability,"This is the result of some experimentation. With ten-way parallelism, the copier very rarely gets rate-limited. With 75-way parallelism (the default), we almost always experience a tens of transient errors. If we start at ten and back off as in this PR, I can get to 75 with just a handful of transient errors. cc: @jigold",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13833:199,error,errors,199,https://hail.is,https://github.com/hail-is/hail/pull/13833,2,['error'],['errors']
Availability,This is the same issue as #8487. Not actually generating the error; throwing code.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8488:61,error,error,61,https://hail.is,https://github.com/hail-is/hail/pull/8488,1,['error'],['error']
Availability,"This is unfortunately about 2x slower -- partly due to the fact; that the column + global concordance calculations are not fused,; and partly because the AggArrayPerElement stuff seems pretty; slow right now and is dragging down the per-sample concordance.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6224:224,down,down,224,https://hail.is,https://github.com/hail-is/hail/pull/6224,1,['down'],['down']
Availability,This is unused and the same as `INTERNAL_GATEWAY_IP` a few variables down,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12005:69,down,down,69,https://hail.is,https://github.com/hail-is/hail/pull/12005,1,['down'],['down']
Availability,"This is used to print the resource name in several error messages, which failed when the error occurred for an item within a ResourceGroup. Proposed fix addressing part of #13191, for your consideration. Fixes #13191",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13192:51,error,error,51,https://hail.is,https://github.com/hail-is/hail/pull/13192,2,['error'],['error']
Availability,"This is why copying is so slow:. ```; ==> NOTE: You are uploading one or more large file(s), which would run; significantly faster if you enable parallel composite uploads. This; feature can be enabled by editing the; ""parallel_composite_upload_threshold"" value in your .boto; configuration file. However, note that if you do this large files will; be uploaded as `composite objects; <https://cloud.google.com/storage/docs/composite-objects>`_,which; means that any user who downloads such objects will need to have a; compiled crcmod installed (see ""gsutil help crcmod""). This is because; without a compiled crcmod, computing checksums on composite objects is; so slow that gsutil disables downloads of composite objects. / [1/1 files][ 4.1 GiB/ 4.1 GiB] 100% Done 45.8 MiB/s ETA 00:00:00; Operation completed over 1 objects/4.1 GiB.; ```. We can also set this with -o GSUtil:parallel_composite_upload_threshold on the command line. https://cloud.google.com/storage/docs/gsutil/commands/cp. We currently use `-m` which is parallel per-file:. If you have a large number of files to transfer you might want to use the; gsutil -m option, to perform a parallel (multi-threaded/multi-processing); copy:. gsutil -m cp -r dir gs://my-bucket",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7024:475,down,downloads,475,https://hail.is,https://github.com/hail-is/hail/pull/7024,2,['down'],['downloads']
Availability,"This isn't needed any more, since setAggState() and newAggState() do the right thing when called. At least on my laptop, this brings the one test down to ; ```; Name	Mean	Median	StDev; matrix_table_many_aggs_col_wise	24.275	24.372	0.818; ```; vs with the flag disabled, which is ; ```; Name	Mean	Median	StDev; matrix_table_many_aggs_col_wise	30.147	29.706	1.868; ```; (oops)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6791:146,down,down,146,https://hail.is,https://github.com/hail-is/hail/pull/6791,1,['down'],['down']
Availability,"This isn't quite ready, but PR'ing to draw a line in the sand. There are compile errors in concordance, nirvana, vep and MT. They should all be fixed by the pending PRs with the exception of a few additional fixups in MT (fromLegacy, same, etc.) I will rebase this as those PRs go in and fix up anything else that remains.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2725:81,error,errors,81,https://hail.is,https://github.com/hail-is/hail/pull/2725,1,['error'],['errors']
Availability,"This isn't really our fault. k8s sends us a 400 when a container is in a funky state. Creating this issue so I can find it again later when I run into this. Somehow a container terminates without timing information, and the read logs request returns a 400 instead of a 404. Batch handles this fine (it treats all log read failures the same). Known issue: https://github.com/kubernetes/kubernetes/issues/59296. ```; {""levelname"": ""INFO"", ""asctime"": ""2019-07-11 14:19:39,890"", ""filename"": ""batch.py"", ""funcNameAndLine"": ""update_job_with_pod:1145"", ""message"": ""update job (9, 1, 'main') with pod batch-9-job-1-c8b9b2""}; {""levelname"": ""INFO"", ""asctime"": ""2019-07-11 14:19:39,890"", ""filename"": ""batch.py"", ""funcNameAndLine"": ""update_job_with_pod:1159"", ""message"": ""job (9, 1, 'main') mark complete""}; {""levelname"": ""WARNING"", ""asctime"": ""2019-07-11 14:19:39,899"", ""filename"": ""batch.py"", ""funcNameAndLine"": ""mark_complete:579"", ""message"": ""job (9, 1, 'main') has pod batch-9-job-1-c8b9b2 which is terminated but has no timing information. {'api_version': 'v1',\n 'kind': 'Pod',\n 'metadata': {'annotations': None,\n 'cluster_name': None,\n 'creation_timestamp': datetime.datetime(2019, 7, 11, 14, 19, 34, tzinfo=tzlocal()),\n 'deletion_grace_period_seconds': 30,\n 'deletion_timestamp': datetime.datetime(2019, 7, 11, 14, 20, 4, tzinfo=tzlocal()),\n 'finalizers': None,\n 'generate_name': None,\n 'generation': None,\n 'initializers': None,\n 'labels': {'app': 'batch-job',\n 'batch_id': '9',\n 'hail.is/batch-instance': 'ffa5abc4607849df8e5f0036e7350bcf',\n 'job_id': '1',\n 'task': 'main',\n 'user': 'test',\n 'uuid': '291b9eed73b9433c86ff1f58624cf24d'},\n 'name': 'batch-9-job-1-c8b9b2',\n 'namespace': 'pr-6604-batch-pods-cjklalqnl5u9',\n 'owner_references': None,\n 'resource_version': '86681671',\n 'self_link': '/api/v1/namespaces/pr-6604-batch-pods-cjklalqnl5u9/pods/batch-9-job-1-c8b9b2',\n 'uid': 'e878f906-a3e6-11e9-a4bb-42010a8000af'},\n 'spec': {'active_deadline_seconds': None,\n 'affinity': ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6616:22,fault,fault,22,https://hail.is,https://github.com/hail-is/hail/issues/6616,2,"['failure', 'fault']","['failures', 'fault']"
Availability,This makes hand running the release slightly less error-prone.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14325:50,error,error-prone,50,https://hail.is,https://github.com/hail-is/hail/pull/14325,1,['error'],['error-prone']
Availability,This might avoid command to long errors,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8470:33,error,errors,33,https://hail.is,https://github.com/hail-is/hail/pull/8470,1,['error'],['errors']
Availability,"This mirrors the functionality available on `TypedCodecSpec`. In some cases (the shuffler),; you might be handed a buffer that is already configured, but you still want to create a; decoder whose PType is known to be a subtype of PStruct.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8766:31,avail,available,31,https://hail.is,https://github.com/hail-is/hail/pull/8766,1,['avail'],['available']
Availability,"This moves `self.activate` into a `wait_for` with a timeout. We use a tight try-except; around the activation code to provide a precise error message if activation fails. If activation succeeds, we enter the else branch which operates as before. If activation; times out we do not deactivate. This is OK, we probably did not activate. If we did activate,; batch will eventually find out.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8816:136,error,error,136,https://hail.is,https://github.com/hail-is/hail/pull/8816,1,['error'],['error']
Availability,This must have been skipped or lost in a rebase but keeping the resources at minimum is keeping the notebook deployment at max replicas after the workshop. Giving a bit higher request (what I set as the baseline in #10117) should encourage k8s to downscale back to 3 replicas.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10230:247,down,downscale,247,https://hail.is,https://github.com/hail-is/hail/pull/10230,1,['down'],['downscale']
Availability,"This node filters an NDArray to a smaller NDArray that has only the specified rows/cols/etc. along a specific axis, in the specified order. It will be used for lowering BlockMatrixFilter. If the array of indices along a given axis is missing, then we preserve the original indexing along that axis. If an element in the array of indices is missing, we throw a runtime error. The filter/don't filter decision for a given axis could also be lifted to a compile-time decision, rather than a runtime decision (say by having the type of the filter along that axis being `ttuple[]` instead of `tarray<tint64>`). Unlike NDArraySlice, it does not give the option of reducing the number of dimensions of the NDArray, although I can change that if we have a use for it.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8122:368,error,error,368,https://hail.is,https://github.com/hail-is/hail/pull/8122,1,['error'],['error']
Availability,"This opens the possibility for compiler differences to fail builds for our users. The CI server should simply set CXX and CC to clang and rebuild hail. Moreover, we need to ensure the hail build system passes these variables all the way down to `libsimdpp`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1327:237,down,down,237,https://hail.is,https://github.com/hail-is/hail/issues/1327,1,['down'],['down']
Availability,"This pod is constantly blocking scale down. There are two of them running anyway, there is no reason not to take one down to allow scale down:; ```; (base) dking@wm28c-761 hail % k get pods -n kube-system -l k8s-app=kube-dns; NAME READY STATUS RESTARTS AGE; kube-dns-7d44cdb5d5-twvfd 4/4 Running 0 14d; kube-dns-7d44cdb5d5-xjq25 4/4 Running 0 14d; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13105:38,down,down,38,https://hail.is,https://github.com/hail-is/hail/pull/13105,3,['down'],['down']
Availability,This prevents an error in _run_command where we attempt to put an int into an array of `java.lang.String`s,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1331:17,error,error,17,https://hail.is,https://github.com/hail-is/hail/pull/1331,1,['error'],['error']
Availability,"This query is the slowest one we have right now and is making the billing projects pages to be slow. I saw substantial speed improvements using lateral joins. - For querying all open billing projects for a given user, it went from 1.8 seconds to 0.87 seconds.; - For querying all open billing projects (i.e. billing projects page), it went from 5.5 seconds to 2.6 seconds. The speed of the queries should go down further once the aggregated billing project user resources table has been deduped and further improvements after compaction.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13175:408,down,down,408,https://hail.is,https://github.com/hail-is/hail/pull/13175,1,['down'],['down']
Availability,"This reduces the size of the `repo` that's input to a lot of CI steps from ~186Mb to ~68Mb, which is substantial when you look at the build for this PR and see single-digit or low double-digit Mb download speeds ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12312:196,down,download,196,https://hail.is,https://github.com/hail-is/hail/pull/12312,1,['down'],['download']
Availability,"This removes partition key stuff, as needed, down to the IR node level. I haven't touched the signatures of any IR nodes; where needed, I have put the fill row key as the partition key. @patrick-schultz I think this should work without any additional changes.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4197:45,down,down,45,https://hail.is,https://github.com/hail-is/hail/pull/4197,1,['down'],['down']
Availability,"This retries all the basic RPC methods of GoogleStorageFS. I saw a transient; error arise from an `open` in generated code. These changes would have; retried the `open` and not failed the job (1 of 50,000 jobs :( ). However,; I am still not sure how to retry an error during actual writing (as opposed; to opening the OutputStream). I think we have to retry the whole partition.; See further discussion in Zulip.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11709:78,error,error,78,https://hail.is,https://github.com/hail-is/hail/pull/11709,2,['error'],['error']
Availability,"This should be configurable, but that was harder than I expected. This should cut down on the number of class A operations we do a bit. It is quite high right now.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11984:82,down,down,82,https://hail.is,https://github.com/hail-is/hail/pull/11984,1,['down'],['down']
Availability,"This should cut down on expensive py4j calls in import_vcfs, and the; infrastructure should also help us with complex java <=> python; interchanges, by passing the releavant information via primitive types; or strings in all cases. Brief summary:. - Add vectorIrs map to HailContext to store lists of irs that may need; be referenced later. - Switch import_vcfs to returning a json string with the id of the IR; array that is now stored in the vectorIrs map, along with the size of; that array and its type, suitable to passed to tmatrix._from_json. - Add JIRVectorReference to python, which is the deserialized version of; the returned json. - Add JavaMatrixVectorRef, which represents a single IR contained in; some stored IR array.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5613:16,down,down,16,https://hail.is,https://github.com/hail-is/hail/pull/5613,1,['down'],['down']
Availability,This should fix Julia's bug here: https://discuss.hail.is/t/arrayindexoutofboundsexception-error-in-hail-0-2-40/1413/11. I will make a follow up PR tomorrow splitting things up and making a `PCanonicalTupleCode`. I just wanted to get rid of this blatantly wrong thing.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8799:91,error,error-in-hail-,91,https://hail.is,https://github.com/hail-is/hail/pull/8799,1,['error'],['error-in-hail-']
Availability,"This should fix the test_copy failures. The problem was, we were sending a mutable byte iterator for data when inserting a new object. If that insert read some of the data, failed, and was retried, the data that was read was lost and the retry started where the failed insert left off. To retry writes, you need to keep around the data you've sent to resend in case of failure. So you don't have to keep around an unbounded amount of data, Google Storage supports resumable uploads: https://cloud.google.com/storage/docs/resumable-uploads. This allows us to send data in chunks, and release the data after Google reports back that the data has been committed. `StorageClient.insert_object`, when the upload type is resumable (the default), takes an additional argument `bufsize`. This is the amount the amount that the writer will buffer for retries, and the size of the chunks sent to GCS. I kept around the simpler media upload type since I actually want to use it in copy (copy doesn't need to buffer because it can retry by rereading the file being copied from). This code was actually kind of hard to organize. It would be better if the code immediately wrote any incoming data instead of just buffering it until we hit the chunk size, but I didn't find a manageable way to write that. Suggestions welcome, tho it would be good to get this fix in because of the test failures.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10023:30,failure,failures,30,https://hail.is,https://github.com/hail-is/hail/pull/10023,3,['failure'],"['failure', 'failures']"
Availability,"This should give a helpful python-level error message bout balding Nichols having an integer column key, but instead I get a Scala match error.; ```; In [9]: hl.export_vcf(hl.balding_nichols_model(3,10,10, n_partitions=3), '/tmp/foo.vcf') ; ```; randomly assigned",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7584:40,error,error,40,https://hail.is,https://github.com/hail-is/hail/issues/7584,2,['error'],['error']
Availability,This should help us avoid more confusing errors down the line since our workers are all running JDK 8 and cannot use JDK 11+ bytecode.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13734:41,error,errors,41,https://hail.is,https://github.com/hail-is/hail/pull/13734,2,"['down', 'error']","['down', 'errors']"
Availability,This should hopefully save on computing things like downcasts for hom-refs.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6896:52,down,downcasts,52,https://hail.is,https://github.com/hail-is/hail/pull/6896,1,['down'],['downcasts']
Availability,"This should make computing the loadings better, since it uses a checkpointed variants table instead of accidentally recomputing the incoming MatrixTable. Also made a change to avoid accidentally clobbering a field name if someone had a field named `idx`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10201:64,checkpoint,checkpointed,64,https://hail.is,https://github.com/hail-is/hail/pull/10201,1,['checkpoint'],['checkpointed']
Availability,This should suppress many spurious CI failures.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8218:38,failure,failures,38,https://hail.is,https://github.com/hail-is/hail/pull/8218,1,['failure'],['failures']
Availability,"This should take the time it takes to run IRSuite back down to ~7 minutes. Still not great, but better than 12.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5582:55,down,down,55,https://hail.is,https://github.com/hail-is/hail/pull/5582,1,['down'],['down']
Availability,"This test could run forever if batch is temporarily down between starting the job and the job completing. I'm not entirely sure what to do in this scenario, failing doesn't seem too bad because we weren't actually able to verify the test, but it seems better than potentially having the job hang.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12420:52,down,down,52,https://hail.is,https://github.com/hail-is/hail/pull/12420,1,['down'],['down']
Availability,"This test failure has occurred a few times. It's usually been resolved by simply re-running the test without any source code changes. There are at least four recent examples, all on different feature branches: . - [2017-02-21 11:10 UTC](https://ci.hail.is/viewLog.html?buildId=6489&tab=buildResultsDiv&buildTypeId=HailSourceCode_HailCi#); - [2017-02-15 21:51 UTC](https://ci.hail.is/viewLog.html?buildId=5446#2135525582_186_5446_problem); - [2017-02-15 18:45 UTC](https://ci.hail.is/viewLog.html?buildId=5333#1163765489_186_5333_problem); - [2017-02-13 22:42 UTC](https://ci.hail.is/viewLog.html?buildId=4934&tab=buildResultsDiv&buildTypeId=HailSourceCode_HailCi). ```; [11:19:14][:testHail] ======================================================================; [11:19:14][:testHail] ERROR: test_dataset (hail.tests.ContextTests); [11:19:14][:testHail] ----------------------------------------------------------------------; [11:19:14][:testHail] Traceback (most recent call last):; [11:19:14][:testHail] File ""/home/ec2-user/BuildAgent/work/c38e75e72b769a7c/python/hail/tests.py"", line 233, in test_dataset; [11:19:14][:testHail] vds_assoc = vds_assoc.lmmreg(vds_kinship, 'sa.pheno', ['sa.cov1', 'sa.cov2']); [11:19:14][:testHail] File ""<decorator-gen-89>"", line 2, in lmmreg; [11:19:14][:testHail] File ""/home/ec2-user/BuildAgent/work/c38e75e72b769a7c/python/hail/java.py"", line 93, in handle_py4j; [11:19:14][:testHail] raise FatalError(msg); [11:19:14][:testHail] FatalError: lmmreg: failed to fit delta: REML realized at delta upper search boundary e^10 = 22026.465794806718, indicating negligible genetic component of variance. Standard linear regression may be more appropriate.; ```. These are the [offending lines](https://github.com/hail-is/hail/blob/master/python/hail/tests.py#L222-L233):. ```; vds_assoc = (hc.import_vcf(test_resources + '/sample.vcf'); .split_multi(); .variant_qc(); .annotate_samples_expr(; 'sa.culprit = gs.filter(g => v == Variant(""20"", 13753124, ""A"", ""C"")).map(g =",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1416:10,failure,failure,10,https://hail.is,https://github.com/hail-is/hail/issues/1416,2,"['ERROR', 'failure']","['ERROR', 'failure']"
Availability,"This test:. ```python3; p = Pipeline(backend=BatchBackend('https://batch.hail.is')); for _ in range(30000):; p.new_task().command('/bin/true'); p.run(); ```. Revealed a number of issues:; daniel king: Problems Found:; - [x] https://github.com/hail-is/hail/issues/6543 mysql can deadlock itself, requiring you to reissue the db request; - [x] https://github.com/hail-is/hail/issues/6545 of the 20760 pods that were successfully created before #6543 happened, about 800 could not get their logs due to not existing. That's a failure rate of ~4%. The number of failures continues to grow as I type this message (now up to 1280). I'm counting failures this way:; ```; k logs -l app=batch --tail=999999 | grep 'no logs for ' | sed -E 's/^.*no logs for ([^ ]+).*$/\1/' | sort -u | wc -l; ```; - the k8s request latency spiked to 3.47s max 0.6 s mean during this test and stayed elevated for 10 minutes.; - [ ] https://github.com/hail-is/hail/issues/6546 there was a lot of volume mount failures due to, apparently, the secrets, e.g.:; ```; 9m13s Warning FailedMount Pod Unable to mount volumes for pod ""batch-278-job-10258-a49a81_batch-pods(82ea5910-9ccb-11e9-ad88-42010a800049)"": timeout expired waiting for volumes to attach or mount for pod ""batch-pods""/""batch-278-job-10258-a49a81"". list of unmounted volumes=[gsa-key default-token-8h99c]. list of unattached volumes=[gsa-key default-token-8h99c]; ```; - [ ] https://github.com/hail-is/hail/issues/6548 batch takes 4 seconds to render the batch page with 20k jobs (the web browser displays it fine though), e.g. https://batch.hail.is/batches/278; - [ ] https://github.com/hail-is/hail/issues/6548 batch UI search is DOA with 20k jobs; - [ ] https://github.com/hail-is/hail/issues/6556 delete (and likely cancel) will timeout on large batches",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6547:523,failure,failure,523,https://hail.is,https://github.com/hail-is/hail/issues/6547,4,['failure'],"['failure', 'failures']"
Availability,This was added in https://github.com/hail-is/hail/pull/12421 to help debug errors in `testSeekMoreThanMaxInt`. We have not seen that transient error in a while and I think the switch to https://github.com/hail-is/hail/pull/12590 might have fixed some underlying misuse of `AppendBlobClient` (by not using it).,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13472:75,error,errors,75,https://hail.is,https://github.com/hail-is/hail/pull/13472,2,['error'],"['error', 'errors']"
Availability,"This was causing out-of-order keys to exist and be used in #6223. This doesn't fix that issue specifically, but it will now throw the correct error (and prevent incorrect tables/matrix tables from being written out).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6267:142,error,error,142,https://hail.is,https://github.com/hail-is/hail/pull/6267,1,['error'],['error']
Availability,This was implicitly converted to a pair. SBT complained that; this was probably not what I intended. Not sure why gradle; does not report the same warning as an error.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8356:161,error,error,161,https://hail.is,https://github.com/hail-is/hail/pull/8356,1,['error'],['error']
Availability,This was the most confusing error I've seen in a while! ,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2850:28,error,error,28,https://hail.is,https://github.com/hail-is/hail/pull/2850,1,['error'],['error']
Availability,This wasn't updated when I separated out building and pushing so the `build` target wasn't pushing the image. When I fixed that the cert generation failed because `memory` is no longer available. These changes got everything working again.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14064:185,avail,available,185,https://hail.is,https://github.com/hail-is/hail/pull/14064,1,['avail'],['available']
Availability,"This way the second error will be ""caused by"" the original retry once error. I think; this is worthwhile because otherwise we will never know what the first error was.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11948:20,error,error,20,https://hail.is,https://github.com/hail-is/hail/pull/11948,3,['error'],['error']
Availability,"This will fail until #7376 lands and allows the test to create an empty matrix table. - document `sep`; - add two tests for importing empty matrix tables, one with a header and one without; - include the offending lines in error messages when files have different numbers of columns; - consistently use `String.split(separator, 0)` instead of using two different approaches which yield inconsistent results.; - simplify `parseHeader` and generalize to empty files; - improve error message when a row field found in the file does not match one of the row fields specified by `row_fields` (a dictionary from row field name to type). NB: A no-header empty file implies no columns in the MT. We print a warning to this effect when we discover an empty file. Resolves #7242",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7378:223,error,error,223,https://hail.is,https://github.com/hail-is/hail/pull/7378,2,['error'],['error']
Availability,"This will fix the upload location for 0.2 artifacts, and therefore the broken distribution download link.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4583:91,down,download,91,https://hail.is,https://github.com/hail-is/hail/pull/4583,1,['down'],['download']
Availability,This will get site updating with a short downtime while get a proper fix in place for https://github.com/hail-is/hail/issues/4463.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4476:41,downtime,downtime,41,https://hail.is,https://github.com/hail-is/hail/pull/4476,1,['downtime'],['downtime']
Availability,This would prevent people from using it naively on sample aggregations and getting errors. Can also add a mode that takes an integer nAlleles,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1610:83,error,errors,83,https://hail.is,https://github.com/hail-is/hail/issues/1610,1,['error'],['errors']
Availability,Those env variables most have been copy-pasted from another step because they're neither correct nor necessary. I tried downloading the batch-gsa-key and running `upload-query-jar` with it as the credentials and it succeeded.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11881:120,down,downloading,120,https://hail.is,https://github.com/hail-is/hail/pull/11881,1,['down'],['downloading']
Availability,"Three changes:. 1. I noticed the costs were all 0. I think this is due to `cores_mcpu INTO cores_mcpu` scoping issues in the attempt triggers, where the local variable was always zero. At least changing the local variable name immediately fixed the problem. 2. I wrote a test to verify the costs were non-zero and consistent with the reported timing for the succeeding job. It is hard to do on the cost string, so I included msec_mcpu in the batch/job status response to verify it. In trying to verify it, I noticed that timestamps in the attempts table were slightly truncated compared to start/end times in the status (JSON). This lead to rounding errors and slight disagreement. 3. Rather descend into the floating point rabbit hole of madness, I changed times everywhere to be stored as integers in milliseconds (like unix time, since the epoch). In the database, they are not BIGINT. Millisecond resolution seems fine for everything we're building. 4. (Bonus change!) Don't let timing for jobs be negative. This will require another reset.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7628:650,error,errors,650,https://hail.is,https://github.com/hail-is/hail/pull/7628,1,['error'],['errors']
Availability,"Three things:; 1. Jenkins build #116:. http://hail-ci.broadinstitute.org:8080/job/Hail%20-%20Test%20All%20Branches/116/. of master, revision 6d5fe392b32c7383370b2fc2ea259fb8cff2c1c6, failed several test cases, but I wasn't able to reproduce it on my laptop. Can we get more detailed logs, either by default or in another file, so we can debug build irreproducible build failures? Custom log4j properties for gradle might be a solution.; 1. I tried to rebuild #116 by clicking ""Rebuild"" on the left hand side menu. This resulted in build #119 . http://hail-ci.broadinstitute.org:8080/job/Hail%20-%20Test%20All%20Branches/119/. which is labeled ""rebuild of #116"", but it is a build of a different branch, origin/tp_dbnsfp_bug and a different revision. What's going on?; 1. When I noticed #116 failed, I wanted to find the last build of origin/master that succeeded. Is there a way to do that?",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/335:370,failure,failures,370,https://hail.is,https://github.com/hail-is/hail/issues/335,1,['failure'],['failures']
Availability,Throw a good error message if ASYNC_PROFILER_HOME isn't set,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9657:13,error,error,13,https://hail.is,https://github.com/hail-is/hail/pull/9657,1,['error'],['error']
Availability,Throw a useful error message when the resource does not exist instead of throwing an NPE.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4678:15,error,error,15,https://hail.is,https://github.com/hail-is/hail/pull/4678,1,['error'],['error']
Availability,Throw error if user tries to explode a key field,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3854:6,error,error,6,https://hail.is,https://github.com/hail-is/hail/pull/3854,1,['error'],['error']
Availability,"Tim, when I run the following command I get the exception below. ~/hail/build/install/hail/bin/hail import -i ~/t2d/GoT2D.first10k.vcf filtervariants --keep -c ""true"" count. I get the following exception. ""[-80"" is not in the original vcf, so Cotton thinks it may be because htsjdk parses the info, then you converts them back to Strings, and then reparses them, so you might have trouble eating your own output. I'll share the vcf with you. I have no trouble filtering based on sample and interval lists, or doing qc or linreg. ```; Exception in thread ""main"" org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 0.0 failed 1 times, most recent failure: Lost task 1.0 in stage 0.0 (TID 1, localhost): java.lang.NumberFormatException: For input string: ""[-80""; at java.lang.NumberFormatException.forInputString(NumberFormatException.java:65); at java.lang.Integer.parseInt(Integer.java:580); at java.lang.Integer.parseInt(Integer.java:615); at scala.collection.immutable.StringLike$class.toInt(StringLike.scala:272); at scala.collection.immutable.StringOps.toInt(StringOps.scala:30); at org.broadinstitute.hail.methods.AnnotationValueString$$anonfun$toArrayInt$extension$1.apply(Filter.scala:18); at org.broadinstitute.hail.methods.AnnotationValueString$$anonfun$toArrayInt$extension$1.apply(Filter.scala:18); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:245); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:245); at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186); at scala.collection.TraversableLike$class.map(TraversableLike.scala:245); at scala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:186); at org.broadinstitute.hail.methods.AnnotationValueString$.toArrayInt$extension(Filter.scala:18); at __wrapper$1$c1aef7d48806473ea6c7fc7ceb61989c.__wrapper$1$c1aef7d48806473ea6c7fc7ceb61989c$$a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/120:619,failure,failure,619,https://hail.is,https://github.com/hail-is/hail/issues/120,2,['failure'],['failure']
Availability,"To allow users on GCP to access datasets that are only available on AWS (e.g. pan-ukb LD block matrices and tables). . If trying to read dataset from `s3` path throws `FatalError: UnsupportedFileSystemException: No FileSystem for scheme ""s3""`, then will read with the `s3a` prefix instead.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10527:55,avail,available,55,https://hail.is,https://github.com/hail-is/hail/pull/10527,1,['avail'],['available']
Availability,To avoid `pymysql` packet sequence errors on long-running pods. See https://hail.zulipchat.com/#narrow/stream/300487-Hail-Batch-Dev/topic/PyMysql.20packet.20sequence.20errors/near/289668489 for context. #assign services,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12051:35,error,errors,35,https://hail.is,https://github.com/hail-is/hail/pull/12051,1,['error'],['errors']
Availability,"To avoid classname serialization overhead, we should register all of our classes that are being serialized, with the most important being those which are RDD elements, until we are able to turn on `conf.set(""spark.kryo.registrationRequired"", ""true"")` without error. This will also catch places where we are serializing far more than we thought. Background here:; https://spark.apache.org/docs/latest/tuning.html#data-serialization. Only a small number of classes are registered by default:; https://github.com/apache/spark/blob/v1.4.0/core/src/main/scala/org/apache/spark/serializer/KryoSerializer.scala#L317. More background in first answer here:; http://stackoverflow.com/questions/31394140/require-kryo-serialization-in-spark-scala",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1022:259,error,error,259,https://hail.is,https://github.com/hail-is/hail/issues/1022,1,['error'],['error']
Availability,"To be merged AFTER jb_mendel_y and jb_mendel_docs. This modifies the behavior of Pedigree to discard those samples not in the variant data set when reading in a .fam file, rather than throwing an error when indexing fails, addressing Issue #94. I'd like advice on how best to throw a warning when samples are tossed.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/153:196,error,error,196,https://hail.is,https://github.com/hail-is/hail/pull/153,1,['error'],['error']
Availability,"To be merges AFTER jb_mendel_y. Here I have:; 1) added documentation for mendel errors; 2) modified the functions leading to the individual and family files so that the SNP count is recorded in addition to the total count. Talking to analysts, the SNP count is useful for QC because indels are so much more volatile. If analysts will typically want both, it seems better to avoid forcing them to run mendel errors twice (before and after filtering to SNPs). Adding the NSNP column in .imendel and .fmendel breaks the PLINK spec but only very gently: adding one additional (final) column. Once we have a better sense of users needs, we should break it completely to best suit them. I'd feel comfortable breaking up chr:pos:ref:alt into separate columns now if you think the time has come...calling that column SNP is especially confusing given that the variant may be an indel. Next up for mendel will be Issues #94 and #148",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/149:80,error,errors,80,https://hail.is,https://github.com/hail-is/hail/pull/149,2,['error'],['errors']
Availability,"To enable easy testing, I also parameterized the methods by the branchingFactor and broke generation of the byte array away from writing the byte array to a file. The key issue is that `k * 1024 % 1024 = 0` for any integer `k`, which we were interpreting as meaning that the last block needed 1024 more elements to be full. There are no errors on write. On read, we try to calculate the number of layers present in the BGEN using `calcDepth` but this fails to correctly guess the layers when the size of the file is not a positive integral power of 1024. The only real changes (the rest are restructuring/whitespace) are using `branchingFactor` in place of `1024` and replacing; ```; - // Pad last layer so last block is 1024 elements (1024*8 bytes); - val paddingRequired = 1024 - (arr.length % 1024); ```; with; ```; + // Pad last layer so last block is branchingFactor elements (branchingFactor*8 bytes); + val danglingElements = (arr.length % branchingFactor); + val paddingRequired =; + if (danglingElements == 0) 0; + else branchingFactor - danglingElements; ```. cc: @jigold one of the PRs you asked me to break out.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3750:337,error,errors,337,https://hail.is,https://github.com/hail-is/hail/pull/3750,1,['error'],['errors']
Availability,"To make existing gnomAD datasets (already in HailTable/MatrixTable form) available via `load_dataset`:; - For v2 now includes multinucleotide variants (MNVs), proportion expressed across transcript (pext), and linkage disequilibrium (LD); - For v3 now includes mitochondrial DNA (mtDNA). The `load_dataset` function now can open a `BlockMatrix` as well, so the gnomAD v2 LD matrices are available through the datasets API in addition to the tables. Also added try/except blocks to `load_datasets`, to handle errors. For example the `gnomad_annotation_pext` dataset has a url of `gs://gcp-public-data--gnomad/papers/2019-tx-annotation/pre_computed/all.possible.snvs.tx_annotated.021520.ht`, but this is actually a `MatrixTable`. So now when trying to open a `HailTable`, it will try to open as a `MatrixTable` if an error is encountered (and vice versa).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9955:73,avail,available,73,https://hail.is,https://github.com/hail-is/hail/pull/9955,4,"['avail', 'error']","['available', 'error', 'errors']"
Availability,"To properly implement IR sets, I need to staged UnsafeOrdering's, or, at the very least, I need to be able to call them from `Code`-land. Since objects at IR-compile-time are not available at IR-run-time (without shipping them to the nodes and passing them as arguments, which I'd like to avoid), I must be able to call static methods, or have fully code-ified versions of every UnsafeOrdering used in the IR. Whenever possible, I tried to call static methods. In a few cases, I couldn't figure out how to make that work, so I had to reimplement the operation in `Code`. I also had to introduce `BindingCode[T]` which is a type alias for `(FunctionBuilder, StagedBitSet) => Code[T]`. The function builder is used to allocate new variables and the `StagedBitSet` is used to compactly store boolean values. I am also somewhat confused by the `missingGreatest` parameter which existed on the original `UnsafeOrdering`s (which I refactored while Code-ifying). cc: @cseed, I guess this parameter is only sensible on compound data? It seems like there should be a:. ```; def compare(r1: MemoryBuffer, o1: Long, m1: Boolean, r2: MemoryBuffer, o2: Long, m2: Boolean): Int; ```. which correctly applies the `missingGreatest` parameter.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2519:179,avail,available,179,https://hail.is,https://github.com/hail-is/hail/pull/2519,1,['avail'],['available']
Availability,"To replicate, replace the contents of `test_king.py::test_king_small` with:; ```; @fails_local_backend(); def test_king_small():; hl.init(idempotent=True) # Should be no error; hl.stop(); hl.init(idempotent=True) # Should be no error; hl.init(hl.spark_context(), idempotent=True) # Should be no error. plink_path = resource('balding-nichols-1024-variants-4-samples-3-populations'); mt = hl.import_plink(bed=f'{plink_path}.bed',; bim=f'{plink_path}.bim',; fam=f'{plink_path}.fam'); kinship = hl.king(mt.GT); assert_c_king_same_as_hail_king(; resource('balding-nichols-1024-variants-4-samples-3-populations.kin0'),; kinship); ```. Stack trace:; ```; E hail.utils.java.FatalError: IndexOutOfBoundsException: 0; E ; E Java stack trace:; E org.apache.spark.SparkException: Job aborted due to stage failure: Task 7 in stage 18.0 failed 1 times, most recent failure: Lost task 7.0 in stage 18.0 (TID 34, localhost, executor driver): java.lang.IndexOutOfBoundsException: 0; E 	at scala.collection.immutable.NumericRange.apply(NumericRange.scala:112); E 	at is.hail.linalg.BlockMatrixReadRowBlockedRDD$$anonfun$compute$9.apply(BlockMatrix.scala:2131); E 	at is.hail.linalg.BlockMatrixReadRowBlockedRDD$$anonfun$compute$9.apply(BlockMatrix.scala:2127); E 	at is.hail.sparkextras.ContextRDD$$anonfun$cmapPartitionsWithIndex$1$$anonfun$apply$18$$anonfun$apply$19.apply(ContextRDD.scala:259); E 	at is.hail.sparkextras.ContextRDD$$anonfun$cmapPartitionsWithIndex$1$$anonfun$apply$18$$anonfun$apply$19.apply(ContextRDD.scala:259); E 	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:435); E 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:441); E 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409); E 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:439); E 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409); E 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:439); E 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/9867:170,error,error,170,https://hail.is,https://github.com/hail-is/hail/issues/9867,5,"['error', 'failure']","['error', 'failure']"
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: ; https://discuss.hail.is/. Please include the full Hail version and as much detail as possible. -----------------------------------------------------------------------------. An error arises when executing operations/actions using field entries. For intance executing `mt.AD.show()` would give the following: . ### Error No.1: ; ```python; ---------------------------------------------------------------------------; FatalError Traceback (most recent call last); /usr/local/lib/python3.6/site-packages/IPython/core/formatters.py in __call__(self, obj); 700 type_pprinters=self.type_printers,; 701 deferred_pprinters=self.deferred_printers); --> 702 printer.pretty(obj); 703 printer.flush(); 704 return stream.getvalue(). /usr/local/lib/python3.6/site-packages/IPython/lib/pretty.py in pretty(self, obj); 400 if cls is not object \; 401 and callable(cls.__dict__.get('__repr__')):; --> 402 return _repr_pprint(obj, self, cycle); 403 ; 404 return _default_pprint(obj, self, cycle). /usr/local/lib/python3.6/site-packages/IPython/lib/pretty.py in _repr_pprint(obj, p, cycle); 695 """"""A pprint that just redirects to the normal repr function.""""""; 696 # Find newlines and replace them with p.break_(); --> 697 output = repr(obj); 698 for idx,output_line in enumerate(output.splitlines()):; 699 if idx:. /usr/local/lib/python3.6/site-packages/hail/matrixtable.py in __repr__(self); 2521 ; 2522 def __repr__(self):; -> 2523 return self.__str__(); 2524 ; 2525 def _repr_html_(self):. /usr/local/lib/python3.6/site-packages/hail/matrixtable.py in __str__(self); 2515 ; 2516 def __str__(self):; -> 2517 s = self.table_show.__str__(); 2518 if self.displayed_n_cols != self.actual_n_cols:; 2519 s += f""showing the first { self.displayed_n_cols } of { self.actual_n_cols } columns"". /usr/local/lib/python3.6/site-packages/hail/table.py in __str__(self); 1241 ; 1242 def __str__(self):; -> 1243 ret",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7044:296,error,error,296,https://hail.is,https://github.com/hail-is/hail/issues/7044,2,"['Error', 'error']","['Error', 'error']"
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: ; https://discuss.hail.is/. Please include the full Hail version and as much detail as possible. -----------------------------------------------------------------------------. Hail commit version: 5852a71e9e23. Error received:; ```; amazon-ebs: cd build/deploy; python3 setup.py -q sdist bdist_wheel; amazon-ebs: sed '/^pyspark/d' python/requirements.txt \| xargs python3 -m pip install -U; ==> amazon-ebs: ERROR: Invalid requirement: '#'; ==> amazon-ebs: make: *** [install-on-cluster] Error 123; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/10352:328,Error,Error,328,https://hail.is,https://github.com/hail-is/hail/issues/10352,3,"['ERROR', 'Error']","['ERROR', 'Error']"
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: ; https://discuss.hail.is/. Please include the full Hail version and as much detail as possible. -----------------------------------------------------------------------------. Hello. The error has occurred during bulid. I installed all the necessary libraries and matched the jdk version and Python version.; And I also installed gcc, blas, and lapack. The error is as follows. Exception in thread ""main"" java.io.IOException: Function not implemented; at sun.nio.ch.FileDispatcherImpl.lock0(Native Method); at sun.nio.ch.FileDispatcherImpl.lock(FileDispatcherImpl.java:90); at sun.nio.ch.FileChannelImpl.tryLock(FileChannelImpl.java:1114); at java.nio.channels.FileChannel.tryLock(FileChannel.java:1155); at org.gradle.wrapper.ExclusiveFileAccessManager.access(ExclusiveFileAccessManager.java:55); at org.gradle.wrapper.Install.createDist(Install.java:48); at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:107); at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); make: *** [Makefile:75: build/libs/hail-all-spark.jar] Error 1. An error occurs while compilation is in progress. There seems to be an error in the 'exec ""$JAVACMD"" ""$@"" section the gradlew file at the end. My server OS is centos7. Is there a solution?",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/9849:304,error,error,304,https://hail.is,https://github.com/hail-is/hail/issues/9849,5,"['Error', 'error']","['Error', 'error']"
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: ; https://discuss.hail.is/. Please include the full Hail version and as much detail as possible. -----------------------------------------------------------------------------. I am aggregating gVCF files using the hail function run_combiner. I am using the command below. ````; hl.experimental.run_combiner(inputs, out_file=output_file, tmp_path=temp_bucket, branch_factor=105, batch_size=100, reference_genome='GRCh38', use_genome_default_intervals=True); ````; I am finding that when the phase 1 portion of the functions creates 10 or 100 temporary mt files that the phase 2 portion is not estimating the temporary mt file names correctly. For example, when trying to aggregate 1k gVCF files, 10 temporary mt files are created in phase 1. These are labeled 0.mt -9.mt. Phase 2, however, looks for a two digit file name i.e. 00.mt. I have found the same thing occur when phase 1 creates 100 temporary mt files when aggregating 10k gVCF files. 100 mt files labeled 00.mt -99.mt are created, but phase2 looks for a three digit name 000.mt. I am assuming this is because there are 10 files and 100 files respectively. I do not see this issue when for example 11 temp mt files are created as 00.mt-10.mt. . An example of the error this throws is . ````; Hail version: 0.2.81-edeb70bc789c; Error summary: HailException: No file or directory found at gs://<path>//combiner-temporary/040b0721-5359-430d-9fe9-019f7eb263f8/_phase1_job1/00.mt; ````. is there a flag that I can add that will circumvent this?. Thank you.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/11891:1339,error,error,1339,https://hail.is,https://github.com/hail-is/hail/issues/11891,2,"['Error', 'error']","['Error', 'error']"
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: ; https://discuss.hail.is/. Please include the full Hail version and as much detail as possible. -----------------------------------------------------------------------------. I'm working through the GWAS tutorial and getting some strange errors with two different functions. On the 4th line calling hl.import_vcf('data/1kg.vcf.bgz').write('data/1kg.mt', overwrite=True) I'm getting the following error:. ```; File ""gwas_tutorial.py"", line 12, in <module>; hl.import_vcf('data/1kg.vcf.bgz').write('data/1kg.mt',overwrite=True); File ""</Users/username/miniconda3/envs/hail1/lib/python3.7/site-packages/decorator.py:decorator-gen-946>"", line 2, in write; File ""/Users/username/miniconda3/envs/hail1/lib/python3.7/site-packages/hail/typecheck/check.py"", line 561, in wrapper; return __original_func(*args_, **kwargs_); File ""/Users/username/miniconda3/envs/hail1/lib/python3.7/site-packages/hail/matrixtable.py"", line 2494, in write; Env.backend().execute(MatrixWrite(self._mir, writer)); File ""/Users/username/miniconda3/envs/hail1/lib/python3.7/site-packages/hail/backend/backend.py"", line 106, in execute; result = json.loads(Env.hail().backend.spark.SparkBackend.executeJSON(self._to_java_ir(ir))); File ""/Users/username/miniconda3/envs/hail1/lib/python3.7/site-packages/py4j/java_gateway.py"", line 1257, in __call__; answer, self.gateway_client, self.target_id, self.name); File ""/Users/username/miniconda3/envs/hail1/lib/python3.7/site-packages/hail/utils/java.py"", line 240, in deco; 'Error summary: %s' % (deepest, full, hail.__version__, deepest)) from None; hail.utils.java.FatalError: ScalaSigParserError: Unexpected failure. Java stack trace:; org.json4s.scalap.ScalaSigParserError: Unexpected failure; 	at org.json4s.scalap.Rules$$anonfun$expect$1.apply(Rules.scala:73); 	at org.json4s.scalap.scalasig.ClassFileParser$.parse(ClassFileParser.scala:95); 	at org.json4s.reflect",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6299:356,error,errors,356,https://hail.is,https://github.com/hail-is/hail/issues/6299,2,['error'],"['error', 'errors']"
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: ; https://discuss.hail.is/. Please include the full Hail version and as much detail as possible. -----------------------------------------------------------------------------. Reposting this here from the Forum. https://discuss.hail.is/t/getting-java-heap-error-tried-a-bunch-of-things-with-the-executor-and-memory-settings/2753",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12035:373,error,error-tried-a-bunch-of-things-with-the-executor-and-memory-settings,373,https://hail.is,https://github.com/hail-is/hail/issues/12035,1,['error'],['error-tried-a-bunch-of-things-with-the-executor-and-memory-settings']
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: ; https://discuss.hail.is/. Please include the full Hail version and as much detail as possible. -----------------------------------------------------------------------------. When trying to use the load_dataset() function on any dataset, I receive the following error: . ```; mt = hl.experimental.load_dataset(name='1000_Genomes_chrMT',; version='phase_3',; reference_genome='GRCh37',; region='us',; cloud='gcp'); ```. ```; ---------------------------------------------------------------------------; FatalError Traceback (most recent call last); <ipython-input-7-5fec92db8e26> in <module>; ----> 1 mt = hl.experimental.load_dataset(name='1000_Genomes_chrMT',; 2 version='phase_3',; 3 reference_genome='GRCh37',; 4 region='us',; 5 cloud='gcp'). ~/miniconda3/envs/hail-env/lib/python3.9/site-packages/hail/experimental/datasets.py in load_dataset(name, version, reference_genome, region, cloud); 109 return hl.read_table(path); 110 elif path.endswith('.mt'):; --> 111 return hl.read_matrix_table(path); 112 elif path.endswith('.bm'):; 113 return hl.linalg.BlockMatrix.read(path). ~/miniconda3/envs/hail-env/lib/python3.9/site-packages/decorator.py in fun(*args, **kw); 230 if not kwsyntax:; 231 args, kw = fix(args, kw, sig); --> 232 return caller(func, *(extras + args), **kw); 233 fun.__name__ = func.__name__; 234 fun.__doc__ = func.__doc__. ~/miniconda3/envs/hail-env/lib/python3.9/site-packages/hail/typecheck/check.py in wrapper(__original_func, *args, **kwargs); 575 def wrapper(__original_func, *args, **kwargs):; 576 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 577 return __original_func(*args_, **kwargs_); 578 ; 579 return wrapper. ~/miniconda3/envs/hail-env/lib/python3.9/site-packages/hail/methods/impex.py in read_matrix_table(path, _intervals, _filter_intervals, _drop_cols, _drop_rows, _n_partitions); 2009 :class:`.Ma",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/10530:380,error,error,380,https://hail.is,https://github.com/hail-is/hail/issues/10530,1,['error'],['error']
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: ; https://discuss.hail.is/. Please include the full Hail version and as much detail as possible. -----------------------------------------------------------------------------. hail v 0.2. I can't build from sources. Error below. $ make install-on-cluster HAIL_COMPILE_NATIVES=1 SPARK_VERSION=2.3.2; make -C src/main/c prebuilt; make[1]: Entering directory `/share/apps/luffy/hail/hail/src/main/c'; make[1]: *** No rule to make target `lz4.h', needed by `build/Decoder.o'. Stop.; make[1]: Leaving directory `/share/apps/luffy/hail/hail/src/main/c'; make: *** [native-lib-prebuilt] Error 2. How can I fix this?. thank you",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7464:333,Error,Error,333,https://hail.is,https://github.com/hail-is/hail/issues/7464,2,['Error'],['Error']
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: ; https://discuss.hail.is/. Please include the full Hail version and as much detail as possible. -----------------------------------------------------------------------------; First of all, thank you for making such a highly integrated tool. . I learned that this tool could be run in two modes, on Cloud and locally. Well, I happen to have an HPC server that I can work on, so I'd love to use the tool locally. However, many annotation tools require many annotation data that need to be prepared in advance, and no one has seen the exact format of them. Plus, the annotation data sometimes is stored on a google cloud bucket that is requester paid so I don't have a chance to take a peek at them. Therefore, even I try to fill my configuration file, the annotation data needed cannot be prepared unless I have a template of them. . Pls, consider adding a feature like, if we want to run an annotation job locally, let us download package containing all the necessary annotation data in there. So we can set up the configuration file on our own and run the job on a local HPC server. Much appreciated!",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/9059:1039,down,download,1039,https://hail.is,https://github.com/hail-is/hail/issues/9059,1,['down'],['download']
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: ; https://discuss.hail.is/. Please include the full Hail version and as much detail as possible. -----------------------------------------------------------------------------; Hello, I am having problems to read vcf file using hail. I installed using conda according to https://hail.is/docs/0.2/getting_started.html#requirements; I created the environment, activated it and installed with pip. When I try to load a vcf file, I am getting:; hl.import_vcf('/Volumes/Macintosh HD2/data/thousands_genome/hector.Q15d5.vcf.gz'); py4j.protocol.Py4JJavaError: An error occurred while calling z:is.hail.HailContext.apply. : is.hail.utils.HailException: Hail requires Java 8, found 12.0.1; Any help? Best, Zillur",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6747:672,error,error,672,https://hail.is,https://github.com/hail-is/hail/issues/6747,1,['error'],['error']
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: ; https://discuss.hail.is/. Please include the full Hail version and as much detail as possible. -----------------------------------------------------------------------------; Versions of software products:. Running on Apache Spark version 2.4.5; SparkUI available at http://vhabosgen72:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.2.61-3c86d3ba497a; LOGGING: writing to /dacs1/team/vhabhsxum/tasks/ancestryPainting/hail-20210125-1235-0.2.61-3c86d3ba497a.log. I am running the GWAS tutorial hosted at https://hail.is/docs/0.2/tutorials/01-genome-wide-association-study.html#Let's-do-a-GWAS. Everything is OK until the line to do GWAS. The error I have is as follows:. -------------- start of error ------------------; 2021-01-25 12:36:11 Hail: INFO: linear_regression_rows: running on 250 samples for 1 response variable y,; with input variable x, and 1 additional covariate...; ERROR:root:Exception while sending command.; Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 1159, in send_command; raise Py4JNetworkError(""Answer from Java side is empty""); py4j.protocol.Py4JNetworkError: Answer from Java side is empty. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 985, in send_command; response = connection.send_command(command); File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 1164, in send_command; ""Error while receiving"", e, proto.ERROR_ON_RECEIVE); py4j.protocol.Py4JNetworkError: Error while receiving; ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:44859); Traceback (most recent call last):; File ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/9939:372,avail,available,372,https://hail.is,https://github.com/hail-is/hail/issues/9939,3,"['avail', 'error']","['available', 'error']"
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: ; https://discuss.hail.is/. Please include the full Hail version and as much detail as possible. -----------------------------------------------------------------------------; version 0.2.54-8526838bf99f. When importing matrix table from VCF, the rows have the following schema. ```text; ----------------------------------------; Global fields:; None; ----------------------------------------; Row fields:; 'locus': locus<GRCh38> ; 'alleles': array<str> ; 'rsid': str ; 'qual': float64 ; 'filters': set<str> ; 'info': struct {} ; ----------------------------------------; Key: ['locus', 'alleles']; ----------------------------------------; ```. When running `mt.rows().show()` the following error is observed. ```text; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); /opt/conda/lib/python3.7/site-packages/IPython/core/formatters.py in __call__(self, obj); 343 method = get_real_method(obj, self.print_method); 344 if method is not None:; --> 345 return method(); 346 return None; 347 else:. /opt/hail/python/hail/table.py in _repr_html_(self); 1279 ; 1280 def _repr_html_(self):; -> 1281 return self._html_str(); 1282 ; 1283 def _ascii_str(self):. /opt/hail/python/hail/table.py in _html_str(self); 1381 return (f'<tr><td style=""{style}"">' + f'</td><td style=""{style}"">'.join(values) + '</td></tr>\n'); 1382 ; -> 1383 arranged_field_names = PlacementTree.from_named_type('row', self.table.row.dtype); 1384 ; 1385 s = '<table>'. /opt/hail/python/hail/utils/placement_tree.py in from_named_type(name, dtype); 16 if not isinstance(dtype, tstruct):; 17 return PlacementTree(name, 1, 0, []); ---> 18 children = [PlacementTree.from_named_type(name, dtype) for name, dtype in dtype.items()]; 19 width = sum(child.width for child in children); 20 height = max(child.height for child in children) + 1. /opt/hail/pyth",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/9833:809,error,error,809,https://hail.is,https://github.com/hail-is/hail/issues/9833,1,['error'],['error']
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: http://discuss.hail.is/. -------------------------------------------------------------------------------------------. ### Hail version: . current master. ### What you did:. Read in a giant table of phenotypes (~500k rows x ~3k columns). `; raw_phenos = hl.import_table('gs://phenotype_31063/ukb31063.raw_phenotypes.tsv.bgz',; key='eid', impute=True, types={'eid': hl.tstr}, missing='NA', min_partitions=100); raw_phenos.write('gs://armartin/disparities/ukbb_afr/ukb31063.raw_phenotypes.ht'); `; ### What went wrong (all error messages here, including the full java stack trace):. [Stage 1:> (0 + 100) / 100]Traceback (most recent call last):; File ""/tmp/0fdaf26ceb274d679f571483f658e509/run_prs_afr.py"", line 266, in <module>; main(args); File ""/tmp/0fdaf26ceb274d679f571483f658e509/run_prs_afr.py"", line 125, in main; raw_phenos.write('gs://armartin/disparities/ukbb_afr/ukb31063.raw_phenotypes.ht'); File ""<decorator-gen-652>"", line 2, in write; File ""/tmp/0fdaf26ceb274d679f571483f658e509/hail-devel-5dfbe2ec29f8.zip/hail/typecheck/check.py"", line 546, in wrapper; File ""/tmp/0fdaf26ceb274d679f571483f658e509/hail-devel-5dfbe2ec29f8.zip/hail/table.py"", line 1218, in write; File ""/usr/lib/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py"", line 1133, in __call__; File ""/tmp/0fdaf26ceb274d679f571483f658e509/hail-devel-5dfbe2ec29f8.zip/hail/utils/java.py"", line 210, in deco; hail.utils.java.FatalError: NumberFormatException: For input string: ""1001101010010110"". Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 46 in stage 1.0 failed 20 times, most recent failure: Lost task 46.19 in stage 1.0 (TID 1559, arm-sw-vq41.c.daly-ibd.internal, executor 6): is.hail.utils.HailException: ukb31063.raw_phenotypes.tsv.bgz: java.lang.NumberFormatException: could not convert ""1001101010010110"" to int32 in column ""10145-0.3""; offending li",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4268:637,error,error,637,https://hail.is,https://github.com/hail-is/hail/issues/4268,1,['error'],['error']
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: http://discuss.hail.is/. -------------------------------------------------------------------------------------------. ### Hail version: 0.1-6e815ac. ### What you did: hc.import_bgen('*.bgen) X chromosome cannot be imported, which is a major issue when working on phenotypes linked to blood coagulation, for example. ### What went wrong (all error messages here, including the full java stack trace):. [Stage 1:===============================================> (747 + 9) / 871]Traceback (most recent call last):; File ""regression1.py"", line 22, in <module>; hc.import_bgen('/mnt/volume/imputed_genotypes/*.bgen', sample_file='/mnt/volume/imputed_genotypes/MT.sample').split_multi().write('/mnt/volume/imputed_genotypes/MT_intersect_imputed.vds'); File ""<decorator-gen-285>"", line 2, in write; File ""/usr/local/hail/python/hail/java.py"", line 121, in handle_py4j; 'Error summary: %s' % (deepest, full, Env.hc().version, deepest)); hail.java.FatalError: HailException: Hail only supports diploid genotypes. Found min ploidy equals `1' and max ploidy equals `2'. Java stack trace:; org.apache.spark.SparkException: Job aborted.; at org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$write$1.apply$mcV$sp(FileFormatWriter.scala:147); at org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$write$1.apply(FileFormatWriter.scala:121); at org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$write$1.apply(FileFormatWriter.scala:121); at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:57); at org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:121); at org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:101); at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycomput",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2407:458,error,error,458,https://hail.is,https://github.com/hail-is/hail/issues/2407,2,"['Error', 'error']","['Error', 'error']"
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: http://discuss.hail.is/. -------------------------------------------------------------------------------------------. ### Hail version: 0.1. ### What you did: . kt = hc.import_table([""gnomad_coverage_chr1.tsv"", ""gnomad_coverage_chr2.tsv"", ..], min_partitions=10000). ### What went wrong (all error messages here, including the full java stack trace):. I expected the behavior with min_partitions=10000 to be the same as calling repartition(10000), but the keytable only had # of partitions = # of input .tsv files. I switched to just calling repartition(10000) after importing, and it works as expected. . May be duplicate of #508",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2420:409,error,error,409,https://hail.is,https://github.com/hail-is/hail/issues/2420,1,['error'],['error']
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: http://discuss.hail.is/. -------------------------------------------------------------------------------------------. ### Hail version: 0.1. ### What you did:. ### What went wrong (all error messages here, including the full java stack trace):. The docs under ; https://hail.is/docs/stable/hail.HailContext.html?highlight=import_vcf#hail.HailContext.import_vcf; are; ```; If generic equals False (default), Hail makes certain assumptions about the genotype fields, see Representation. On import, Hail filters (sets to no-call) any genotype that violates these assumptions. Hail interprets the format fields: GT, AD, OD, DP, GQ, PL; all others are silently dropped.; ```; but clicking the `Representation` link does lead to any additional details.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3472:302,error,error,302,https://hail.is,https://github.com/hail-is/hail/issues/3472,1,['error'],['error']
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: http://discuss.hail.is/. -------------------------------------------------------------------------------------------. ### Hail version: 0.2. ### What you did: read in a Hail Table with 96 rows and 5960 Columns; `table1.row.show(); table2.row.show()`. ### What went wrong (all error messages here, including the full java stack trace):. ```; ---------------------------------------------------------------------------; FatalError Traceback (most recent call last); <ipython-input-80-bf4d6c719c23> in <module>(); 1 table1.row.show(); ----> 2 table2.row.show(). /home/hail/hail.zip/hail/typecheck/check.py in wrapper(*args, **kwargs); 545 def wrapper(*args, **kwargs):; 546 args_, kwargs_ = check_all(f, args, kwargs, checkers, is_method=is_method); --> 547 return f(*args_, **kwargs_); 548 ; 549 update_wrapper(wrapper, f). /home/hail/hail.zip/hail/expr/expressions/base_expression.py in show(self, n, width, truncate, types); 677 Print an extra header line with the type of each field.; 678 """"""; --> 679 print(self._show(n, width, truncate, types)); 680 ; 681 def _show(self, n=10, width=90, truncate=None, types=True):. /home/hail/hail.zip/hail/expr/expressions/base_expression.py in _show(self, n, width, truncate, types); 684 if isinstance(source, hl.Table):; 685 if self is source.row:; --> 686 return source._show(n, width, truncate, types); 687 elif self is source.key:; 688 return source.select()._show(n, width, truncate, types). /home/hail/hail.zip/hail/table.py in _show(self, n, width, truncate, types); 1201 ; 1202 def _show(self, n=10, width=90, truncate=None, types=True):; -> 1203 return self._jt.showString(n, joption(truncate), types, width); 1204 ; 1205 def index(self, *exprs):. /usr/lib/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py in __call__(self, *args); 1131 answer = self.gateway_client.send_command(command); 1132 return_value = get_return_value(",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3922:393,error,error,393,https://hail.is,https://github.com/hail-is/hail/issues/3922,1,['error'],['error']
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: http://discuss.hail.is/. -------------------------------------------------------------------------------------------. ### Hail version: 0.2. ### What you did:; ```; vp_ht = vp_ht.transmute(; locus1=hl.locus(vp_ht.chrom1, vp_ht.pos1),; locus2=hl.locus(vp_ht.chrom1, vp_ht.pos2),; alleles1=[vp_ht.ref1, vp_ht.alt1],; alleles2=[vp_ht.ref2, vp_ht.alt2]; ). vp_mt = hl.MatrixTable.from_rows_table(vp_ht); vp_mt = vp_mt.key_rows_by('locus1', 'alleles1'). mt = mt.annotate_rows(v1=hl.is_defined(vp_mt[(mt.locus, mt.alleles), :])); ```. ### What went wrong (all error messages here, including the full java stack trace):; ```; In [49]: mt = mt.annotate_rows(v1=hl.is_defined(vp_mt[(mt.locus, mt.alleles),:])); ---------------------------------------------------------------------------; FatalError Traceback (most recent call last); <ipython-input-49-5ea2fe942ada> in <module>(); ----> 1 mt = mt.annotate_rows(v1=hl.is_defined(vp_mt[(mt.locus, mt.alleles),:])). /home/hail/hail.zip/hail/matrixtable.py in annotate_rows(self, **named_exprs); 894 exprs = []; 895 named_exprs = {k: to_expr(v) for k, v in named_exprs.items()}; --> 896 base, cleanup = self._process_joins(*named_exprs.values()); 897; 898 for k, v in named_exprs.items():. /home/hail/hail.zip/hail/matrixtable.py in _process_joins(self, *exprs); 2205 for j in list(e._joins)[::-1]:; 2206 if j.uid not in used_uids:; -> 2207 left = j.join_function(left); 2208 all_uids.extend(j.temp_vars); 2209 used_uids.add(j.uid). /home/hail/hail.zip/hail/matrixtable.py in <lambda>(left); 2157 prefix = 'va'; 2158 joiner = lambda left: (; -> 2159 MatrixTable(left._jvds.annotateRowsVDS(right._jvds, uid))); 2160 else:; 2161 return self.rows().index(*exprs). /usr/lib/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py in __call__(self, *args); 1131 answer = self.gateway_client.send_command(command); 1132 return_value = get_return_value",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3119:671,error,error,671,https://hail.is,https://github.com/hail-is/hail/issues/3119,1,['error'],['error']
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: http://discuss.hail.is/. -------------------------------------------------------------------------------------------. ### Hail version: 0.2.10-91149b50a53c. ### What you did:. ```; qc_ht = qc_mt.annotate_cols(; dp_stats=hl.agg.group_by(qc_mt.qc_platform, hl.agg.stats(qc_mt.DP)),; gq_stats=hl.agg.group_by(qc_mt.qc_platform, hl.agg.stats(qc_mt.GQ)),; callstats=hl.agg.group_by(qc_mt.qc_platform, hl.agg.call_stats(qc_mt.GT, qc_mt.alleles)),; call_rate=hl.agg.group_by(qc_mt.qc_platform, hl.agg.fraction(hl.is_defined(qc_mt.GQ))); ).rows(); ```. ### What went wrong (all error messages here, including the full java stack trace):. So I was distracted and used `annotate_rows` instead of `annotate_cols` and I got what seems to be an 0.1 error message:. ```; ---------------------------------------------------------------------------; AssertionError Traceback (most recent call last); <ipython-input-44-7491b514f674> in <module>; 3 gq_stats=hl.agg.group_by(qc_mt.qc_platform, hl.agg.stats(qc_mt.GQ)),; 4 callstats=hl.agg.group_by(qc_mt.qc_platform, hl.agg.call_stats(qc_mt.GT, qc_mt.alleles)),; ----> 5 call_rate=hl.agg.group_by(qc_mt.qc_platform, hl.agg.fraction(hl.is_defined(qc_mt.GQ))); 6 ).rows(); 7 # qc_ht = qc_ht.key_by('locus','alleles'). </opt/conda/lib/python3.6/site-packages/decorator.py:decorator-gen-976> in annotate_cols(self, **named_exprs). /home/hail/hail.zip/hail/typecheck/check.py in wrapper(__original_func, *args, **kwargs); 559 def wrapper(__original_func, *args, **kwargs):; 560 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 561 return __original_func(*args_, **kwargs_); 562 ; 563 return wrapper. /home/hail/hail.zip/hail/matrixtable.py in annotate_cols(self, **named_exprs); 995 caller = ""MatrixTable.annotate_cols""; 996 check_annotate_exprs(caller, named_exprs, self._col_indices); --> 997 return self._selec",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5415:687,error,error,687,https://hail.is,https://github.com/hail-is/hail/issues/5415,2,['error'],['error']
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: http://discuss.hail.is/. -------------------------------------------------------------------------------------------. ### Hail version: 0.2.11-fea176012ee0. ### What you did:. ```; hl.eval({'a':2, None: 1}); ```. ### What went wrong (all error messages here, including the full java stack trace):. ```; ---------------------------------------------------------------------------; ExpressionException Traceback (most recent call last); /home/hail/hail.zip/hail/expr/expressions/expression_typecheck.py in check(self, x, caller, param); 73 try:; ---> 74 return self.coerce(to_expr(x)); 75 except ExpressionException as e:. /home/hail/hail.zip/hail/expr/expressions/base_expression.py in to_expr(e, dtype); 99 if not dtype:; --> 100 dtype = impute_type(e); 101 x = _to_expr(e, dtype). /home/hail/hail.zip/hail/expr/expressions/base_expression.py in impute_type(x); 73 raise ExpressionException(""Cannot impute type of empty dict. Use 'hl.empty_dict' to create an empty dict.""); ---> 74 kts = {impute_type(element) for element in x.keys()}; 75 vts = {impute_type(element) for element in x.values()}. /home/hail/hail.zip/hail/expr/expressions/base_expression.py in <setcomp>(.0); 73 raise ExpressionException(""Cannot impute type of empty dict. Use 'hl.empty_dict' to create an empty dict.""); ---> 74 kts = {impute_type(element) for element in x.keys()}; 75 vts = {impute_type(element) for element in x.values()}. /home/hail/hail.zip/hail/expr/expressions/base_expression.py in impute_type(x); 85 elif x is None:; ---> 86 raise ExpressionException(""Hail cannot impute the type of 'None'""); 87 elif isinstance(x, (hl.expr.builders.CaseBuilder, hl.expr.builders.SwitchBuilder)):. ExpressionException: Hail cannot impute the type of 'None'. The above exception was the direct cause of the following exception:. TypecheckFailure Traceback (most recent call last); /home/hail/hail.zip/hail/typech",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5700:355,error,error,355,https://hail.is,https://github.com/hail-is/hail/issues/5700,1,['error'],['error']
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: http://discuss.hail.is/. -------------------------------------------------------------------------------------------. ### Hail version: 0.2.11. ### What you did: ./gradlew -Dspark.version=2.2.1 -Dspark.version=2.2.1 -Dpy4j.version=0.10.4 -Dbreeze.version=0.13.1 shadowJar. ### What went wrong (all error messages here, including the full java stack trace):; :compileJava UP-TO-DATE; :generateBuildInfo; :nativeLib; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Werror -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/usr/lib/jvm/java-8-openjdk-amd64/include -I/usr/lib/jvm/java-8-openjdk-amd64/include/linux testutils/unit-tests.cpp -MG -M -MF build/testutils/unit-tests.d -MT build/testutils/unit-tests.o; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Werror -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/usr/lib/jvm/java-8-openjdk-amd64/include -I/usr/lib/jvm/java-8-openjdk-amd64/include/linux test.cpp -MG -M -MF build/test.d -MT build/test.o; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Werror -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/usr/lib/jvm/java-8-openjdk-amd64/include -I/usr/lib/jvm/java-8-openjdk-amd64/include/linux ibs.cpp -MG -M -MF build/ibs.d -MT build/ibs.o; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Werror -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/usr/lib/jvm/java-8-openjdk-amd64/include -I/usr/lib/jvm/java-8-openjdk-amd64/include/linux davies.cpp -MG -M -MF build/davies.d -MT build/davies.o; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Werror -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/usr/lib/jvm/java-8-openjdk-amd64/include -I/usr/lib/jvm/java-8-openjdk-amd64/include/linux cache-tests.cpp -MG -M -MF build/cache-tests.d -MT build/cache-tests.o; g++ -march=s",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5659:415,error,error,415,https://hail.is,https://github.com/hail-is/hail/issues/5659,1,['error'],['error']
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: http://discuss.hail.is/. -------------------------------------------------------------------------------------------. ### Hail version: 0.2.8-844023079796. ### What you did:. ```; x = hl.utils.range_table(100); x = x.filter(False); x.show(); ```. ### What went wrong (all error messages here, including the full java stack trace):; ```; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-89-65d54ebb6a64> in <module>; 1 x = hl.utils.range_table(100); 2 x = x.filter(False); ----> 3 x.show(). /home/hail/gnomad_hail/utils/plotting.py in new_show(t, n, width, truncate, types); 25 ; 26 def new_show(t, n=10, width=140, truncate=40, types=True):; ---> 27 old_show(t, n, width, truncate, types); 28 hl.Table.show = new_show; 29 . <decorator-gen-848> in show(self, n, width, truncate, types, handler). /home/hail/hail.zip/hail/typecheck/check.py in wrapper(__original_func, *args, **kwargs); 558 def wrapper(__original_func, *args, **kwargs):; 559 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 560 return __original_func(*args_, **kwargs_); 561 ; 562 return wrapper. /home/hail/hail.zip/hail/table.py in show(self, n, width, truncate, types, handler); 1331 Handler function for data string.; 1332 """"""; -> 1333 handler(self._show(n, width, truncate, types)); 1334 ; 1335 def index(self, *exprs):. /home/hail/hail.zip/hail/table.py in _show(self, n, width, truncate, types); 1238 ; 1239 column_width = [max(len(fields[i]), len(types[i]), max([len(row[i]) for row in rows])); -> 1240 for i in range(n_fields)]; 1241 ; 1242 column_blocks = []. /home/hail/hail.zip/hail/table.py in <listcomp>(.0); 1238 ; 1239 column_width = [max(len(fields[i]), len(types[i]), max([len(row[i]) for row in rows])); -> 1240 for i in range(n_fields)]; 1241 ; 1242 column_blocks ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5173:389,error,error,389,https://hail.is,https://github.com/hail-is/hail/issues/5173,1,['error'],['error']
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: http://discuss.hail.is/. -------------------------------------------------------------------------------------------. ### Hail version: 0.2.9-c3b1183e4246. ### What you did:; ```; pops_for_subpop = pops_ht.aggregate(; hl.agg.filter(; hl.is_defined(pops_ht.pop) & (pops_ht.pop != ""oth""),; hl.agg.group_by(pops_ht.pop, hl.agg.count()); ); ); ```. ### What went wrong (all error messages here, including the full java stack trace):; ```; Traceback (most recent call last):; File ""/tmp/251cbf7beb5f4503ba74e4d69bd09ec3/sample_qc.py"", line 530, in <module>; main(args); File ""/tmp/251cbf7beb5f4503ba74e4d69bd09ec3/sample_qc.py"", line 458, in main; hl.agg.group_by(pops_ht.pop, hl.agg.count()); File ""</opt/conda/lib/python3.6/site-packages/decorator.py:decorator-gen-764>"", line 2, in aggregate; File ""/tmp/251cbf7beb5f4503ba74e4d69bd09ec3/hail-0.2-c3b1183e4246.zip/hail/typecheck/check.py"", line 560, in wrapper; File ""/tmp/251cbf7beb5f4503ba74e4d69bd09ec3/hail-0.2-c3b1183e4246.zip/hail/table.py"", line 1133, in aggregate; File ""</opt/conda/lib/python3.6/site-packages/decorator.py:decorator-gen-436>"", line 2, in analyze; File ""/tmp/251cbf7beb5f4503ba74e4d69bd09ec3/hail-0.2-c3b1183e4246.zip/hail/typecheck/check.py"", line 560, in wrapper; File ""/tmp/251cbf7beb5f4503ba74e4d69bd09ec3/hail-0.2-c3b1183e4246.zip/hail/expr/expressions/expression_utils.py"", line 94, in analyze; File ""/tmp/251cbf7beb5f4503ba74e4d69bd09ec3/hail-0.2-c3b1183e4246.zip/hail/expr/expressions/expression_utils.py"", line 237, in get_refs; File ""/tmp/251cbf7beb5f4503ba74e4d69bd09ec3/hail-0.2-c3b1183e4246.zip/hail/expr/expressions/expression_utils.py"", line 212, in _get_refs; AttributeError: 'NoneType' object has no attribute '_indices_from_ref'; ERROR: (gcloud.dataproc.jobs.submit.pyspark) Job [251cbf7beb5f4503ba74e4d69bd09ec3] entered state [ERROR] while waiting for [DONE].; Traceback (most recent call las",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5296:487,error,error,487,https://hail.is,https://github.com/hail-is/hail/issues/5296,1,['error'],['error']
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: http://discuss.hail.is/. -------------------------------------------------------------------------------------------. ### Hail version: ; version 0.2-721af83bc30a. ### What you did: ; Import UK Biobank bgen chr10. import hail as hl; import sys; hl.init(); chr=sys.argv[1]; bgen=""/project/ukbiobank/imp/uk.v3/bgen/ukb_imp_chr""+chr+""_v3.bgen""; sample=""/project/ukbiobank/imp/uk.v3/bgen/ukb19416_imp_chr""+chr+""_v3_s487327.sample""; mt=""/project/ukbiobank/imp/uk.v3/mt/ukbb_imp_chr""+chr+""_v3_s487327.mt""; hl.index_bgen(bgen); hl.import_bgen(bgen,sample_file=sample,entry_fields=['GT', 'GP','dosage']).write(mt). ### What went wrong (all error messages here, including the full java stack trace):; ```; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.2-721af83bc30a; LOGGING: writing to /restricted/projectnb/ukbiobank/ad/analysis/ad.v1/hail-20181114-1827-0.2-721af83bc30a.log; Exception in thread ""dispatcher-event-loop-8"" Exception in thread ""refresh progress"" java.lang.OutOfMemoryError: GC overhead limit exceeded; at java.util.zip.ZipCoder.getBytes(ZipCoder.java:80); at java.util.zip.ZipFile.getEntry(ZipFile.java:310); at java.util.jar.JarFile.getEntry(JarFile.java:240); at java.util.jar.JarFile.getJarEntry(JarFile.java:223); at sun.misc.URLClassPath$JarLoader.getResource(URLClassPath.java:1042); at sun.misc.URLClassPath.getResource(URLClassPath.java:239); at java.net.URLClassLoader$1.run(URLClassLoader.java:365); at java.net.URLClassLoader$1.run(URLClassLoader.java:362); at java.security.AccessController.doPrivileged(Native Method); at java.net.URLClassLoader.findClass(URLClassLoader.java:361); at java.lang.ClassLoader.loadClass(ClassLoader.java:424); at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331); at java.lang.ClassLoader.loadClass(ClassLoader.java:357); at org.apache.spark.HeartbeatReceiver$$anonfun$org$apache$s",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4780:749,error,error,749,https://hail.is,https://github.com/hail-is/hail/issues/4780,1,['error'],['error']
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: http://discuss.hail.is/. -------------------------------------------------------------------------------------------. ### Hail version: `devel-f2b0dca9f506`. ### What you did:. ```; ht.group_by('model', 'rank_id', 'bin').aggregate(titv=ht.n_ti/ht.n_tv, ; min_score=hl.agg.min(ht.min_score),; max_score=hl.agg.min(ht.max_score); ).show(); ```; ### What went wrong (all error messages here, including the full java stack trace):; ```; ---------------------------------------------------------------------------; FatalError Traceback (most recent call last); <ipython-input-26-65c5654a1482> in <module>(); 1 ht.group_by('model', 'rank_id', 'bin').aggregate(titv=ht.n_ti/ht.n_tv, ; 2 min_score=hl.agg.min(ht.min_score),; ----> 3 max_score=hl.agg.min(ht.max_score); 4 ).show(). /home/hail/gnomad_hail/utils/plotting.py in new_show(t, n, width, truncate, types); 24 ; 25 def new_show(t, n=10, width=170, truncate=40, types=True):; ---> 26 old_show(t, n, width, truncate, types); 27 hl.Table.show = new_show; 28 . /home/hail/hail.zip/hail/typecheck/check.py in wrapper(*args, **kwargs); 545 def wrapper(*args, **kwargs):; 546 args_, kwargs_ = check_all(f, args, kwargs, checkers, is_method=is_method); --> 547 return f(*args_, **kwargs_); 548 ; 549 update_wrapper(wrapper, f). /home/hail/hail.zip/hail/table.py in show(self, n, width, truncate, types); 1215 Print an extra header line with the type of each field.; 1216 """"""; -> 1217 print(self._show(n,width, truncate, types)); 1218 ; 1219 def _show(self, n=10, width=90, truncate=None, types=True):. /home/hail/hail.zip/hail/table.py in _show(self, n, width, truncate, types); 1218 ; 1219 def _show(self, n=10, width=90, truncate=None, types=True):; -> 1220 return self._jt.showString(n, joption(truncate), types, width); 1221 ; 1222 def index(self, *exprs):. /usr/lib/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py in __call__(s",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4110:485,error,error,485,https://hail.is,https://github.com/hail-is/hail/issues/4110,1,['error'],['error']
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: http://discuss.hail.is/. -------------------------------------------------------------------------------------------. ### Hail version: devel-45429b1. ### What you did:; ```; eval_expr(functions.cond(functions.capture(True), 'T', 'F') + functions.cond(functions.capture(True), 'T', 'F')); ```. ### What went wrong (all error messages here, including the full java stack trace):. ```; ---------------------------------------------------------------------------; FatalError Traceback (most recent call last); <ipython-input-20-3b0a2ce317c2> in <module>(); ----> 1 eval_expr(functions.cond(functions.capture(True), 'T', 'F') + functions.cond(functions.capture(True), 'T', 'F')). <decorator-gen-365> in eval_expr(expression). /hadoop_gcs_connector_metadata_cache/hail/hail-devel-45429b164934.zip/hail/expr/expression.py in args_to_expr(func, *args); 176 @decorator; 177 def args_to_expr(func, *args):; --> 178 return func(*(to_expr(a) for a in args)); 179; 180. /hadoop_gcs_connector_metadata_cache/hail/hail-devel-45429b164934.zip/hail/expr/expression.py in eval_expr(expression); 3576 Result of evaluating `expression`.; 3577 """"""; -> 3578 return eval_expr_typed(expression)[0]; 3579; 3580. <decorator-gen-366> in eval_expr_typed(expression). /hadoop_gcs_connector_metadata_cache/hail/hail-devel-45429b164934.zip/hail/expr/expression.py in args_to_expr(func, *args); 176 @decorator; 177 def args_to_expr(func, *args):; --> 178 return func(*(to_expr(a) for a in args)); 179; 180. /hadoop_gcs_connector_metadata_cache/hail/hail-devel-45429b164934.zip/hail/expr/expression.py in eval_expr_typed(expression); 3612 if len(expression._joins) > 0:; 3613 raise ExpressionException(""'eval_expr' methods do not support joins or broadcasts""); -> 3614 r, t = Env.hc().eval_expr_typed(expression._ast.to_hql()); 3615 return r, t; 3616. <decorator-gen-1049> in eval_expr_typed(self, expr). /hadoop_gcs",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2653:436,error,error,436,https://hail.is,https://github.com/hail-is/hail/issues/2653,1,['error'],['error']
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: http://discuss.hail.is/. -------------------------------------------------------------------------------------------. ### Hail version: devel-4f13f27cd28d. ### What you did:; ipython vcf2mt.py . import hail as hl; hl.init(default_reference='GRCh38'); chr=""22""; vcf=""/project/ukbiobank/imputation/ad.v1/vcf/ukbb.hg38.imputed.chr""+chr+"".dose.vcf.bgz""; mt=""/project/ukbiobank/imputation/ad.v1/mt/ukbb.hg38.imputed.chr""+chr; hl.import_vcf(vcf).write(mt). ### What went wrong (all error messages here, including the full java stack trace):. GC Overhead limit exceeded on Stage 2 of import_vcf.write (See below). ```; Running on Apache Spark version 2.2.0; SparkUI available at http://10.48.225.55:4041; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version devel-4f13f27cd28d; NOTE: This is a beta version. Interfaces may change; during the beta period. We recommend pulling; the latest changes weekly.; [Stage 1:======================================================>(740 + 1) / 741]2018-11-10 22:55:07 Hail: INFO: Coerced almost-sorted dataset; [Stage 2:> (0 + 24) / 741]Exception in thread ""refresh progress"" Exception in thread ""LeaseRenewer:farrell@scc"" java.lang.OutOfMemoryError: GC overhead limit exceeded; java.lang.OutOfMemoryError: GC overhead limit exceeded; ---------------------------------------------------------------------------; FatalError Traceback (most recent call last); /restricted/projectnb/ukbiobank/ad/analysis/ad.v1/vcf2mt.py in <module>(); 4 vcf=""/project/ukbiobank/imputation/ad.v1/vcf/ukbb.hg38.imputed.chr""+chr+"".dose.vcf.bgz""; 5 mt=""/project/ukbiobank/imputation/ad.v1/mt/ukbb.hg38.imputed.chr""+chr; ----> 6 hl.import_vcf(vcf).write(mt). /share/pkg/hail/2018-06-18/install/build/distributions/hail-python.zip/hail/typecheck/check.py in wrapper(*args, **kwargs); 545 def wrapper(*args, **kwargs):; 546 args_, kwargs_ = check_all",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4755:593,error,error,593,https://hail.is,https://github.com/hail-is/hail/issues/4755,2,"['avail', 'error']","['available', 'error']"
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: http://discuss.hail.is/. -------------------------------------------------------------------------------------------. ### Hail version: devel-544bf8f. ### What you did: import vcf from delly; ```; import hail as hl; hl.init(default_reference='GRCh38'); hl.import_vcf('/project/casa/vcf.5k/delly/gcad.sv.delly.5k.vcf.bgz').write('/project/casa/vdf.5k/delly'); ```. ### What went wrong (all error messages here, including the full java stack trace):. The CN field is an integer. When the integer is -1 for CN, an error is generated. ./.:0,0,0:0:LowQual:0:0:0:**-1**:0:0:0:0. The header defines CN with this:. ##FORMAT=<ID=CN,Number=1,Type=Integer,Description=""Read-depth based copy-number estimate for autosomal sites"">. ```; Hail version: devel-544bf8f; Error summary: HailException: gcad.sv.delly.5k.vcf.bgz:column 80816: invalid character '-' in integer literal; ... 2:0:0:0:6 ./.:0,0,0:0:LowQual:0:0:0:-1:0:0:0:0 ./.:0,0,0:0:LowQual:0:0:0 ...; ^; offending line: chr1 152267996 DEL00028254 AATATATATACTTTACGTAAAGT A . PASS ...; ```; Here is the full log and exception..... ```; Running on Apache Spark version 2.2.0; SparkUI available at http://10.48.225.55:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version devel-544bf8f; NOTE: This is a beta version. Interfaces may change; during the beta period. We also recommend pulling; the latest changes weekly.; [Stage 1:======================================================>(414 + 2) / 416]2018-04-15 14:38:32 Hail: INFO: Coerced almost-sorted dataset; [Stage 2:> (0 + 34) / 416]Traceback (most recent call last):; File ""/restricted/projectnb/genpro/github/hail/delly_vcf2vdf.py"", line 3, in <module>; hl.import_vcf('/project/casa/vcf.5k/delly/gcad.sv.delly.5k.vcf.bgz').write('/project/casa/vdf.5k/delly'); File ""<decorator-gen-552>"", line 2, in write; File ""/restricted/projectnb/genpro/github/ha",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3379:506,error,error,506,https://hail.is,https://github.com/hail-is/hail/issues/3379,3,"['Error', 'error']","['Error', 'error']"
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: http://discuss.hail.is/. -------------------------------------------------------------------------------------------. ### Hail version: devel-5b299ddae758. ### What you did: ; ```; hl.utils.hadoop_is_file('gs://gnomad-tmp/pbt_parents_sparse_genotype_matrix/cols_ann.ht/_SUCCESS'); ```. ### What went wrong (all error messages here, including the full java stack trace):. Got a `FileNotFoundException`. Based on the documentation, I was expecting `False`. ```; ---------------------------------------------------------------------------; FatalError Traceback (most recent call last); <ipython-input-7-5ad16e5a0601> in <module>(); 1 hl.utils.hadoop_exists('gs://gnomad-tmp/pbt_parents_sparse_genotype_matrix/cols_ann.ht/_SUCCESS'); ----> 2 hl.utils.hadoop_is_file('gs://gnomad-tmp/pbt_parents_sparse_genotype_matrix/cols_ann.ht/_SUCCESS'). /home/hail/hail.zip/hail/utils/hadoop_utils.py in hadoop_is_file(path); 164 :obj:`.bool`; 165 """"""; --> 166 return Env.jutils().isFile(path, Env.hc()._jhc); 167 ; 168 . /usr/lib/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py in __call__(self, *args); 1131 answer = self.gateway_client.send_command(command); 1132 return_value = get_return_value(; -> 1133 answer, self.gateway_client, self.target_id, self.name); 1134 ; 1135 for temp_arg in temp_args:. /home/hail/hail.zip/hail/utils/java.py in deco(*args, **kwargs); 194 raise FatalError('%s\n\nJava stack trace:\n%s\n'; 195 'Hail version: %s\n'; --> 196 'Error summary: %s' % (deepest, full, hail.__version__, deepest)) from None; 197 except pyspark.sql.utils.CapturedException as e:; 198 raise FatalError('%s\n\nJava stack trace:\n%s\n'. FatalError: FileNotFoundException: File not found : gs://gnomad-tmp/pbt_parents_sparse_genotype_matrix/cols_ann.ht/_SUCCESS; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3725:428,error,error,428,https://hail.is,https://github.com/hail-is/hail/issues/3725,2,"['Error', 'error']","['Error', 'error']"
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: http://discuss.hail.is/. -------------------------------------------------------------------------------------------. ### Hail version: devel-5b299ddae758. ### What you did:. ```; print(metrics_ht['vqsr'].globals); hl.eval_expr(metrics_ht['vqsr'].globals); ```. ### What went wrong (all error messages here, including the full java stack trace):. ```; <StructExpression of type struct{}>; ---------------------------------------------------------------------------; FatalError Traceback (most recent call last); <ipython-input-51-e812f4924948> in <module>(); 1 print(metrics_ht['vqsr'].globals); ----> 2 hl.eval_expr(metrics_ht['vqsr'].globals). /home/hail/hail.zip/hail/typecheck/check.py in wrapper(*args, **kwargs); 545 def wrapper(*args, **kwargs):; 546 args_, kwargs_ = check_all(f, args, kwargs, checkers, is_method=is_method); --> 547 return f(*args_, **kwargs_); 548 ; 549 update_wrapper(wrapper, f). /home/hail/hail.zip/hail/expr/expressions/expression_utils.py in eval_expr(expression); 135 Result of evaluating `expression`.; 136 """"""; --> 137 return eval_expr_typed(expression)[0]; 138 ; 139 . /home/hail/hail.zip/hail/typecheck/check.py in wrapper(*args, **kwargs); 545 def wrapper(*args, **kwargs):; 546 args_, kwargs_ = check_all(f, args, kwargs, checkers, is_method=is_method); --> 547 return f(*args_, **kwargs_); 548 ; 549 update_wrapper(wrapper, f). /home/hail/hail.zip/hail/expr/expressions/expression_utils.py in eval_expr_typed(expression); 169 analyze('eval_expr_typed', expression, Indices(expression._indices.source)); 170 ; --> 171 return expression.collect()[0], expression.dtype; 172 ; 173 . /home/hail/hail.zip/hail/expr/expressions/base_expression.py in collect(self); 755 """"""; 756 uid = Env.get_uid(); --> 757 t = self._to_table(uid); 758 return [r[uid] for r in t._select(""collect"", None, hl.struct(**{uid: t[uid]})).collect()]; 759 . /home/hail/hail.zi",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3728:404,error,error,404,https://hail.is,https://github.com/hail-is/hail/issues/3728,1,['error'],['error']
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: http://discuss.hail.is/. -------------------------------------------------------------------------------------------. ### Hail version: devel-6191d4c. ### What you did: vds.vep(""/vep/vep-gcloud.properties). ### What went wrong (all error messages here, including the full java stack trace):. Traceback (most recent call last):; File ""/tmp/2f781c88-64f1-4345-a2b9-433c49d5a099/script_to_submit.py"", line 8, in <module>; vdsvep = vds.vep(""/vep/vep-gcloud.properties""); File ""<decorator-gen-878>"", line 2, in vep; File ""/tmp/2f781c88-64f1-4345-a2b9-433c49d5a099/hail-devel-6191d4ce69aa.zip/hail/utils/java.py"", line 167, in handle_py4j; hail.utils.java.FatalError: Can't zip RDDs with unequal numbers of partitions: List(16979, 16992). Java stack trace:; org.apache.spark.rdd.ZippedPartitionsBaseRDD.getPartitions(ZippedPartitionsRDD.scala:57); 	 at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:248); 	 at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:246); 	 at scala.Option.getOrElse(Option.scala:121); 	 at org.apache.spark.rdd.RDD.partitions(RDD.scala:246); 	 at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35); 	 at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:248); 	 at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:246); 	 at scala.Option.getOrElse(Option.scala:121); 	 at org.apache.spark.rdd.RDD.partitions(RDD.scala:246); 	 at is.hail.sparkextras.OrderedRDD$.coerce(OrderedRDD.scala:58); 	 at is.hail.sparkextras.OrderedRDD$.apply(OrderedRDD.scala:48); 	 at is.hail.utils.richUtils.RichPairRDD$.toOrderedRDD$extension1(RichPairRDD.scala:44); 	 at is.hail.variant.MatrixTable$.fromLegacy(MatrixTable.scala:84); 	 at is.hail.variant.MatrixTable.copyLegacy(MatrixTable.scala:2019); 	 at is.hail.methods.VEP$.annotate(VEP.scala:407); 	 at is.hail.methods.VEP$.apply(VEP.scala:41",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2666:350,error,error,350,https://hail.is,https://github.com/hail-is/hail/issues/2666,1,['error'],['error']
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: http://discuss.hail.is/. -------------------------------------------------------------------------------------------. ### Hail version: devel-63d60cc. ### What you did:. Tried to run ld_prune and pc_relate on 5000 WGS samples. ```; spark-submit --verbose --master yarn --deploy-mode client \; --num-executors 14 \; --executor-cores 6 \; --jars $JAR \; --conf spark.kryo.registrator=is.hail.kryo.HailKryoRegistrator \; --conf ""spark.driver.extraClassPath=$JAR"" \; --conf ""spark.executor.extraClassPath=$JAR"" \; --executor-memory 90G\; --driver-memory 80g\; --conf spark.yarn.executor.memoryOverhead=8000 \; --conf spark.network.timeout=600 \; --conf spark.executor.heartbeatInterval=120\; hc_prune.py; ```. Where hc_prune.py is:. ```; import matplotlib.pyplot as plt; import seaborn. import numpy as np; import pandas as pd; from collections import Counter; from math import log, isnan; from pprint import pprint; # hail; import hail as hl; import hail.expr.aggregators as agg; import hail.expr.functions. hl.init(default_reference='GRCh38'); print(""Read in PASS SNVs""); passed=hl.read_matrix_table('/project/casa/hail.ds/gatk.hc/gcad.5k.snv.vqsr.pass'); print(""Filtering Common Variants""); common=passed.filter_rows(passed.variant_qc.AF > 0.01).persist(); common.write('/project/casa/hail.ds/gatk.hc/gcad.5k.snv.vqsr.pass.common'); print(""Pruning LD Variants""); pruned =hl.ld_prune(common,30,r2=0.1, memory_per_core=2048); pruned.write('/project/casa/hail.ds/gatk.hc/gcad.5k.snv.vqsr.pruned'); print(""Sample 20% of variants for running PC-Relate""); pruned_subsample = pruned.sample_rows(0.2).persist(); print(""Running PC_Relate""); rel = hl.pc_relate(pruned_subsample.GT, 0.01, k=10); rel_df = rel.to_pandas(); rel_df.describe(); pprint(rel_df); rel_df.to_csv('gcad_5k.snv.rel.csv'); ```. ### What went wrong (all error messages here, including the full java stack trace):. Got a memor",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3463:781,heartbeat,heartbeatInterval,781,https://hail.is,https://github.com/hail-is/hail/issues/3463,1,['heartbeat'],['heartbeatInterval']
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: http://discuss.hail.is/. -------------------------------------------------------------------------------------------. ### Hail version: devel-63d60cc. ### What you did:; Ran pc_relate on pruned matrix table (500K SNVs) containing 5k samples. About 800 family members are in the dataset. The data includes a number of replicates also. ### What went wrong (all error messages here, including the full java stack trace):. Replicates should have a kinship coefficient near 0.50 with themselves. Instead HAIL pc_relate calculated 0.18. King correctly calculated 0.498 on the exported plink file. ; ```; 279,A-CUHS-CU001167-BL-COL-32167BL1,A-CUHS-CU001167-BL-COL-32167BL1dea,0.18452354646323424; 280,A-CUHS-CU001167-BL-COL-32167BL1,A-CUHS-CU001167-BL-COL-32167BL1der,0.18468831264044877; 281,A-CUHS-CU001167-BL-COL-32167BL1dea,A-CUHS-CU001167-BL-COL-32167BL1der,0.18515942448861653; 282,A-CUHS-CU001167-BL-COL-32167BL1,A-CUHS-CU001167-BL-COL-32167BL1dew,0.1833498632291505; 283,A-CUHS-CU001167-BL-COL-32167BL1dea,A-CUHS-CU001167-BL-COL-32167BL1dew,0.18376901216269165; 284,A-CUHS-CU001167-BL-COL-32167BL1der,A-CUHS-CU001167-BL-COL-32167BL1dew,0.18367338097096797; 285,A-CUHS-CU001167-BL-COL-32167BL1,A-CUHS-CU001167-BL-COL-32167BL1fa,0.18470621273350465; 286,A-CUHS-CU001167-BL-COL-32167BL1dea,A-CUHS-CU001167-BL-COL-32167BL1fa,0.1852915664909736; 287,A-CUHS-CU001167-BL-COL-32167BL1der,A-CUHS-CU001167-BL-COL-32167BL1fa,0.18516143096293416; 288,A-CUHS-CU001167-BL-COL-32167BL1dew,A-CUHS-CU001167-BL-COL-32167BL1fa,0.1838098671960904; 289,A-CUHS-CU001167-BL-COL-32167BL1,A-CUHS-CU001167-BL-COL-32167BL1fr,0.1847714820370011; 290,A-CUHS-CU001167-BL-COL-32167BL1dea,A-CUHS-CU001167-BL-COL-32167BL1fr,0.18525793071221844; 291,A-CUHS-CU001167-BL-COL-32167BL1der,A-CUHS-CU001167-BL-COL-32167BL1fr,0.1852207373990892; 292,A-CUHS-CU001167-BL-COL-32167BL1dew,A-CUHS-CU001167-BL-COL-32167BL1fr,0.183",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3490:476,error,error,476,https://hail.is,https://github.com/hail-is/hail/issues/3490,1,['error'],['error']
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: http://discuss.hail.is/. -------------------------------------------------------------------------------------------. ### Hail version: devel-63d60cc. ### What you did:; Tried to run sample_qc on mt table imported from Delly vcf. ; hl.sample_qc(ds). ### What went wrong (all error messages here, including the full java stack trace):. The sample_qc had a problem when alt ref is <DEL>. ```; [Stage 3:> (0 + 140) / 415]Traceback (most recent call last):; File ""/restricted/projectnb/genpro/github/hail.qc/delly-qc.py"", line 35, in <module>; ds = hl.sample_qc(ds); File ""<decorator-gen-902>"", line 2, in sample_qc; File ""/restricted/projectnb/genpro/github/hail/python/hail/typecheck/check.py"", line 490, in _typecheck; return __orig_func__(*args_, **kwargs_); File ""/restricted/projectnb/genpro/github/hail/python/hail/methods/qc.py"", line 91, in sample_qc; return MatrixTable(Env.hail().methods.SampleQC.apply(require_biallelic(dataset, 'sample_qc')._jvds, name)); File ""/share/pkg/spark/2.2.0/install/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py"", line 1133, in __call__; File ""/restricted/projectnb/genpro/github/hail/python/hail/utils/java.py"", line 196, in deco; 'Error summary: %s' % (deepest, full, hail.__version__, deepest)) from None; hail.utils.java.FatalError: HailException: invalid allele ""<DEL>"". Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 2 in stage 3.0 failed 4 times, most recent failure: Lost task 2.3 in stage 3.0 (TID 160, scc-q01.scc.bu.edu, executor 4): is.hail.utils.HailException: invalid allele ""<DEL>""; at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:6); at is.hail.utils.package$.fatal(package.scala:26); at is.hail.variant.AltAlleleMethods$.validate(AltAlleleMethods.scala:24); at is.hail.variant.AltAlleleMethods$.altAlleleType(AltAlleleMethods.scala:29); at is.hail.methods.SampleQCCo",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3413:392,error,error,392,https://hail.is,https://github.com/hail-is/hail/issues/3413,1,['error'],['error']
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: http://discuss.hail.is/. -------------------------------------------------------------------------------------------. ### Hail version: devel-7cde2bf. ### What you did:; Tried to read in, repartition, and write 3 matrixtables. This then corrupted the previous version (as I used overwrite), so tried to recreate the matrix tables from the original vcf, and could not import. . ### What went wrong (all error messages here, including the full java stack trace):; repartition error:; ```; ---------------------------------------------------------------------------; FatalError Traceback (most recent call last); <ipython-input-8-f1eea7557457> in <module>(); ----> 1 hm3_variants_vds = hm3_variants_vds.repartition(100); <decorator-gen-688> in repartition(self, n_partitions, shuffle); /home/hail/hail.zip/hail/typecheck/check.py in _typecheck(__orig_func__, *args, **kwargs); 484 def _typecheck(__orig_func__, *args, **kwargs):; 485 args_, kwargs_ = check_all(__orig_func__, args, kwargs, checkers, is_method=True); --> 486 return __orig_func__(*args_, **kwargs_); 487 ; 488 return decorator(_typecheck); /home/hail/hail.zip/hail/matrixtable.py in repartition(self, n_partitions, shuffle); 2505 Repartitioned dataset.; 2506 """"""; -> 2507 jvds = self._jvds.coalesce(n_partitions, shuffle); 2508 return MatrixTable(jvds); 2509 ; /usr/lib/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py in __call__(self, *args); 1131 answer = self.gateway_client.send_command(command); 1132 return_value = get_return_value(; -> 1133 answer, self.gateway_client, self.target_id, self.name); 1134 ; 1135 for temp_arg in temp_args:; /home/hail/hail.zip/hail/utils/java.py in deco(*args, **kwargs); 194 raise FatalError('%s\n\nJava stack trace:\n%s\n'; 195 'Hail version: %s\n'; --> 196 'Error summary: %s' % (deepest, full, hail.__version__, deepest)) from None; 197 except pyspark.sql.utils.Capture",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3507:519,error,error,519,https://hail.is,https://github.com/hail-is/hail/issues/3507,2,['error'],['error']
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: http://discuss.hail.is/. -------------------------------------------------------------------------------------------. ### Hail version: devel-a870693. ### What you did:. ```; In [3]: x = hl.literal([1.0,2.2])\; In [4]: hl.eval_expr(hl.sum(x)); ```. ### What went wrong (all error messages here, including the full java stack trace):. ```; ---------------------------------------------------------------------------; FatalError Traceback (most recent call last); <ipython-input-11-c37a34e6bd74> in <module>(); ----> 1 hl.eval_expr(hl.sum(x)). <decorator-gen-355> in eval_expr(expression). ~/tools/hail/python/hail/typecheck/check.py in _typecheck(__orig_func__, *args, **kwargs); 488 def _typecheck(__orig_func__, *args, **kwargs):; 489 args_, kwargs_ = check_all(__orig_func__, args, kwargs, checkers, is_method=False); --> 490 return __orig_func__(*args_, **kwargs_); 491; 492 return decorator(_typecheck). ~/tools/hail/python/hail/expr/expressions/expression_utils.py in eval_expr(expression); 136 Result of evaluating `expression`.; 137 """"""; --> 138 return eval_expr_typed(expression)[0]; 139; 140. <decorator-gen-357> in eval_expr_typed(expression). ~/tools/hail/python/hail/typecheck/check.py in _typecheck(__orig_func__, *args, **kwargs); 488 def _typecheck(__orig_func__, *args, **kwargs):; 489 args_, kwargs_ = check_all(__orig_func__, args, kwargs, checkers, is_method=False); --> 490 return __orig_func__(*args_, **kwargs_); 491; 492 return decorator(_typecheck). ~/tools/hail/python/hail/expr/expressions/expression_utils.py in eval_expr_typed(expression); 172 analyze('eval_expr_typed', expression, Indices(expression._indices.source)); 173; --> 174 return expression.collect()[0], expression.dtype; 175; 176. ~/tools/hail/python/hail/expr/expressions/base_expression.py in collect(self); 770 """"""; 771 uid = Env.get_uid(); --> 772 t = self._to_table(uid); 773 return [r[ui",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3436:391,error,error,391,https://hail.is,https://github.com/hail-is/hail/issues/3436,1,['error'],['error']
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: http://discuss.hail.is/. -------------------------------------------------------------------------------------------. ### Hail version: devel-abac611 using Apache Spark version 2.2.0. ### What you did:; Tried converting joint genotyped Delly vcf file to vdf file. ```; import hail as hl; hl.init(default_reference='GRCh38'); hl.import_vcf('/project/casa/vcf.5k/delly/gcad.sv.delly.5k.vcf.bgz').write('/project/casa/vdf.5k/delly'); ```. ### What went wrong (all error messages here, including the full java stack trace):. Error reading a GL field. ; ##FORMAT=<ID=GL,Number=G,Type=Float,Description=""Log10-scaled genotype likelihoods for RR,RA,AA genotypes"">. where the entry was:; 0/1:-66.2667,0,-25.4754:10000:PASS:5639:13071:8160:2:0:0:13:27. Here are the log and error messages... ```; [Stage 1:======================================================>(415 + 1) / 416]2018-04-12 07:57:52 Hail: INFO: Coerced almost-sorted dataset; [Stage 2:> (0 + 36) / 416]Traceback (most recent call last):; File ""/restricted/projectnb/genpro/github/hail/delly_vcf2vdf.py"", line 3, in <module>; hl.import_vcf('/project/casa/vcf.5k/delly/gcad.sv.delly.5k.vcf.bgz').write('/project/casa/vdf.5k/delly'); File ""<decorator-gen-546>"", line 2, in write; File ""/restricted/projectnb/genpro/github/hail/build/distributions/hail-python.zip/hail/typecheck/check.py"", line 481, in _typecheck; File ""/restricted/projectnb/genpro/github/hail/build/distributions/hail-python.zip/hail/matrixtable.py"", line 1956, in write; File ""/share/pkg/spark/2.2.0/install/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py"", line 1133, in __call__; File ""/restricted/projectnb/genpro/github/hail/build/distributions/hail-python.zip/hail/utils/java.py"", line 196, in deco; hail.utils.java.FatalError: NumberFormatException: For input string: ""-66.2667,0,-25.4754"". Java stack trace:; org.apache.spark.SparkException: Job aborte",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3361:578,error,error,578,https://hail.is,https://github.com/hail-is/hail/issues/3361,3,"['Error', 'error']","['Error', 'error']"
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: http://discuss.hail.is/. -------------------------------------------------------------------------------------------. ### Hail version: devel-b1d7ad8506d7. ### What you did:. ```; x = hl.literal(hl.set(['A','B'])); x; Out[5]: <SetExpression of type set<str>>; x.contains('A'); Out[6]: <BooleanExpression of type bool>; x.contains('A').value; ```. ### What went wrong (all error messages here, including the full java stack trace):. ```; Traceback (most recent call last):; File ""/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py"", line 2910, in run_code; exec(code_obj, self.user_global_ns, self.user_ns); File ""<ipython-input-7-21a57f32eefb>"", line 1, in <module>; x.contains('A').value; File ""/Users/laurent/tools/hail/python/hail/expr/expressions/base_expression.py"", line 786, in value; return hl.eval_expr(self); File ""/Users/laurent/tools/hail/python/hail/typecheck/check.py"", line 547, in wrapper; return f(*args_, **kwargs_); File ""/Users/laurent/tools/hail/python/hail/expr/expressions/expression_utils.py"", line 137, in eval_expr; return eval_expr_typed(expression)[0]; File ""/Users/laurent/tools/hail/python/hail/typecheck/check.py"", line 547, in wrapper; return f(*args_, **kwargs_); File ""/Users/laurent/tools/hail/python/hail/expr/expressions/expression_utils.py"", line 171, in eval_expr_typed; return expression.collect()[0], expression.dtype; File ""/Users/laurent/tools/hail/python/hail/expr/expressions/base_expression.py"", line 768, in collect; t = self._to_table(uid); File ""/Users/laurent/tools/hail/python/hail/expr/expressions/base_expression.py"", line 591, in _to_table; df = df.select(**{name: self}); File ""/Users/laurent/tools/hail/python/hail/typecheck/check.py"", line 547, in wrapper; return f(*args_, **kwargs_); File ""/Users/laurent/tools/hail/python/hail/table.py"", line 893, in select; return self._select('Table.select', value_st",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4078:489,error,error,489,https://hail.is,https://github.com/hail-is/hail/issues/4078,1,['error'],['error']
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: http://discuss.hail.is/. -------------------------------------------------------------------------------------------. ### Hail version: devel-ccaf3640241f. ### What you did:. ```; ht = hl.import_table('gs://gnomad/annotations/hail-0.2/ht/genomes/score_rankings/gnomad.sites.RF.newStats24.txt.bgz', types={'chrom': hl.tstr}, impute=True, min_partitions=100).cache(); ht.export('gs://gnomad-tmp/genomes_rf.txt.bgz', parallel=True); ```. ### What went wrong (all error messages here, including the full java stack trace):; ```; ---------------------------------------------------------------------------; Py4JError Traceback (most recent call last); <ipython-input-17-671d2e9c22c8> in <module>(); 1 #ht = hl.import_table('gs://gnomad/annotations/hail-0.2/ht/genomes/score_rankings/gnomad.sites.RF.newStats24.txt.bgz', types={'chrom': hl.tstr}, impute=True, min_partitions=100).cache(); ----> 2 ht.export('gs://gnomad-tmp/genomes_rf.txt.bgz', parallel=True). /home/hail/hail.zip/hail/table.py in export(self, output, types_file, header, parallel); 994 """"""; 995 ; --> 996 self._jt.export(output, types_file, header, Env.hail().utils.ExportType.getExportType(parallel)); 997 ; 998 def group_by(self, *exprs, **named_exprs) -> 'GroupedTable':. /usr/lib/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py in __call__(self, *args); 1131 answer = self.gateway_client.send_command(command); 1132 return_value = get_return_value(; -> 1133 answer, self.gateway_client, self.target_id, self.name); 1134 ; 1135 for temp_arg in temp_args:. /home/hail/hail.zip/hail/utils/java.py in deco(*args, **kwargs); 186 import pyspark; 187 try:; --> 188 return f(*args, **kwargs); 189 except py4j.protocol.Py4JJavaError as e:; 190 s = e.java_exception.toString(). /usr/lib/spark/python/lib/py4j-0.10.4-src.zip/py4j/protocol.py in get_return_value(answer, gateway_client, target_id, name); 321 raise Py4JE",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4033:577,error,error,577,https://hail.is,https://github.com/hail-is/hail/issues/4033,1,['error'],['error']
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: http://discuss.hail.is/. -------------------------------------------------------------------------------------------. ### Hail version: f7631a0c96cd. ### What you did:. ```; hl.empty_dict(hl.tint32, hl.tint32).get(0).value; ```. ### What went wrong (all error messages here, including the full java stack trace):; ```; Hail version: devel-f7631a0c96cd; Error summary: HailException: array index out of bounds: 0 / 0. IR: (ArrayRef; (ToArray; (ApplyIR dict; (ArrayFilter __uid_191; (MakeArray Array[Tuple[I ...; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3937:371,error,error,371,https://hail.is,https://github.com/hail-is/hail/issues/3937,2,"['Error', 'error']","['Error', 'error']"
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: http://discuss.hail.is/. -------------------------------------------------------------------------------------------. ### Hail version:. ### What you did:. ### What went wrong (all error messages here, including the full java stack trace):",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2604:298,error,error,298,https://hail.is,https://github.com/hail-is/hail/issues/2604,4,['error'],['error']
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: http://discuss.hail.is/. -------------------------------------------------------------------------------------------. ### Hail version:. devel-406fc7f6af42. ### What you did:. Calling `export_elasticsearch` without a `config` argument works fine.; ```python; hl.export_elasticsearch(table, ""host"", 9200, ""someindex"", ""sometype"", 1000, config=None); ```. However, attempting to pass `config`, for example:; ```python; es_config = {""es.write.operation"": ""index""}; hl.export_elasticsearch(table, ""host"", 9200, ""someindex"", ""sometype"", 1000, config=es_config); ```; causes the following error:. ### What went wrong (all error messages here, including the full java stack trace):. ```; Traceback (most recent call last):; File ""/tmp/0ba8fc2c770d4b2ba96dc23c50fd6eab/load_clinvar_to_es.py"", line 105, in <module>; verbose=True,; File ""/tmp/0ba8fc2c770d4b2ba96dc23c50fd6eab/hail_v02_scripts.zip/hail_v02_scripts/utils/elasticsearch/client.py"", line 234, in export_table_to_elasticsearch; File ""/home/hail/hail.zip/hail/typecheck/check.py"", line 547, in wrapper; File ""/home/hail/hail.zip/hail/methods/impex.py"", line 1885, in export_elasticsearch; File ""/usr/lib/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py"", line 1133, in __call__; File ""/home/hail/hail.zip/hail/utils/java.py"", line 188, in deco; File ""/usr/lib/spark/python/lib/py4j-0.10.4-src.zip/py4j/protocol.py"", line 323, in get_return_value; py4j.protocol.Py4JError: An error occurred while calling z:is.hail.io.ElasticsearchConnector.export. Trace:; py4j.Py4JException: Method export([class is.hail.table.Table, class java.lang.String, class java.lang.Integer, class java.lang.String, class java.lang.String, class java.lang.Integer, class java.util.HashMap, class java.lang.Boolean]) does not exist; 	at py4j.reflection.ReflectionEngine.getMethod(ReflectionEngine.java:318); 	at py4j.reflection.ReflectionEngine.getM",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4063:700,error,error,700,https://hail.is,https://github.com/hail-is/hail/issues/4063,2,['error'],['error']
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: http://discuss.hail.is/. -------------------------------------------------------------------------------------------. ### Hail version:. eb1e04205793. ### What you did:. https://hail.zulipchat.com/#narrow/stream/123010-Hail-0.2E2.20support/topic/Class.20file.20too.20large!. Ran filter_intervals with 200k intervals, got Java ""Class file too large!"" error.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3942:467,error,error,467,https://hail.is,https://github.com/hail-is/hail/issues/3942,1,['error'],['error']
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: http://discuss.hail.is/. -------------------------------------------------------------------------------------------. ### Hail version:; .2, Spark 2.2. ### What you did:; Getting an error about a missing header file when I try to run ./gradlew during Hail installation. ### What went wrong (all error messages here, including the full java stack trace):. In file included from Encoder.cpp:1:0:; ../resources/include/hail/Encoder.h:3:17: fatal error: lz4.h: No such file or directory; #include ""lz4.h""; ^; compilation terminated.; make: *** [build/Encoder.o] Error 1. FAILURE: Build failed with an exception.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4651:299,error,error,299,https://hail.is,https://github.com/hail-is/hail/issues/4651,5,"['Error', 'FAILURE', 'error']","['Error', 'FAILURE', 'error']"
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: http://discuss.hail.is/. -------------------------------------------------------------------------------------------. ### Hail version:; 0.2-48fb15983780. ### What you did:; Plotting a histogram of mt.sample_qc.r_ti_tv, using tutorial data:. import hail as hl; import bokeh. hl.init(); mt = hl.read_matrix_table('data/1kg.mt'); mt = hl.sample_qc(mt); p = hl.plot.histogram(mt.sample_qc.r_ti_tv); bokeh.io.save(p, 'test.html'). ### What went wrong (all error messages here, including the full java stack trace):. The resulting histogram has very high numbers for Frequency labels (y-axis). There are 284 samples in the tutorial dataset, so I expected frequencies to sum up to that, but y-axis labels are 5.000e+4, 1.000e+5, 1.500e+5, implying much higher counts. . I'm new to Hail and I could be plotting the values wrong and misunderstanding this particular plot (what I wanted to plot was the histogram of Ti/Tv ratios of all the samples). I've noticed the same y-axis labels in the GWAS tutorial in the docs (In [29]). . Thank you for your time.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4776:569,error,error,569,https://hail.is,https://github.com/hail-is/hail/issues/4776,1,['error'],['error']
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: http://discuss.hail.is/. -------------------------------------------------------------------------------------------. ### Hail version:; 0.2-a2eaf89baa0c; ### What you did:; Executed first four lines in https://github.com/hail-is/hail/blob/master/hail/python/hail/docs/tutorials/01-genome-wide-association-study.ipynb; ### What went wrong (all error messages here, including the full java stack trace):. ```; ---------------------------------------------------------------------------; FatalError Traceback (most recent call last); <ipython-input-4-758eefccad3d> in <module>; ----> 1 hl.import_vcf('data/1kg.vcf.bgz').write('data/1kg.mt', overwrite=True). <decorator-gen-1074> in import_vcf(path, force, force_bgz, header_file, min_partitions, drop_samples, call_fields, reference_genome, contig_recoding, array_elements_required, skip_invalid_loci). ~/bin/anaconda3/lib/python3.6/site-packages/hail/typecheck/check.py in wrapper(__original_func, *args, **kwargs); 558 def wrapper(__original_func, *args, **kwargs):; 559 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 560 return __original_func(*args_, **kwargs_); 561 ; 562 return wrapper. ~/bin/anaconda3/lib/python3.6/site-packages/hail/methods/impex.py in import_vcf(path, force, force_bgz, header_file, min_partitions, drop_samples, call_fields, reference_genome, contig_recoding, array_elements_required, skip_invalid_loci); 1893 skip_invalid_loci,; 1894 force_bgz,; -> 1895 force; 1896 ); 1897 return MatrixTable(jmt). ~/bin/anaconda3/lib/python3.6/site-packages/py4j/java_gateway.py in __call__(self, *args); 1255 answer = self.gateway_client.send_command(command); 1256 return_value = get_return_value(; -> 1257 answer, self.gateway_client, self.target_id, self.name); 1258 ; 1259 for temp_arg in temp_args:. ~/bin/anaconda3/lib/python3.6/site-packages/hail/utils/java.py in dec",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4775:461,error,error,461,https://hail.is,https://github.com/hail-is/hail/issues/4775,1,['error'],['error']
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: http://discuss.hail.is/. -------------------------------------------------------------------------------------------. ### Hail version:; 0.2. ### What you did:; Visited top hit for ""hail matrix table"": https://hail.is/docs/0.2/hailpedia/matrix_table.html. ### What went wrong (all error messages here, including the full java stack trace):; 404 / Not Found . ### Solution; We should add a 301 / permanent redirect: https://support.google.com/webmasters/answer/93633?hl=en",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5095:398,error,error,398,https://hail.is,https://github.com/hail-is/hail/issues/5095,1,['error'],['error']
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: http://discuss.hail.is/. -------------------------------------------------------------------------------------------. ### Hail version:; 0.2. ### What you did:; ```; mt = hl.read_matrix_table('gs://...'); mt = mt.filter_cols(mt.used_in_pca_calculation); print(mt.count_cols()); ```; The MatrixTable has a lot of row and column annotations. `mt.used_in_pca_calculation` is a Boolean column annotation. ### What went wrong (all error messages here, including the full java stack trace):; ```; Traceback (most recent call last):; File ""/tmp/8d5cc778-fdc7-4210-a60b-5efd1f67c45f/subset_genotype_pca.py"", line 8, in <module>; print(mt.count_cols()); File ""/home/hail/hail.zip/hail/matrixtable.py"", line 1950, in count_cols; File ""/usr/lib/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py"", line 1133, in __call__; File ""/home/hail/hail.zip/hail/utils/java.py"", line 206, in deco; hail.utils.java.FatalError: AssertionError: assertion failed. Java stack trace:; java.lang.AssertionError: assertion failed; 	at scala.Predef$.assert(Predef.scala:156); 	at is.hail.expr.MatrixValue.filterSamplesKeep(Relational.scala:110); 	at is.hail.expr.MatrixValue.filterCols(Relational.scala:133); 	at is.hail.expr.FilterCols.execute(Relational.scala:333); 	at is.hail.variant.MatrixTable.value$lzycompute(MatrixTable.scala:536); 	at is.hail.variant.MatrixTable.value(MatrixTable.scala:534); 	at is.hail.variant.MatrixTable.x$16$lzycompute(MatrixTable.scala:541); 	at is.hail.variant.MatrixTable.x$16(MatrixTable.scala:541); 	at is.hail.variant.MatrixTable.colValues$lzycompute(MatrixTable.scala:541); 	at is.hail.variant.MatrixTable.colValues(MatrixTable.scala:541); 	at is.hail.variant.MatrixTable.numCols(MatrixTable.scala:2378); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3173:543,error,error,543,https://hail.is,https://github.com/hail-is/hail/issues/3173,1,['error'],['error']
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: http://discuss.hail.is/. -------------------------------------------------------------------------------------------. ### Hail version:; 0.2; ### What you did:. 1. edited build.gradle to it will accept my spark version like this if (sparkVersion == '2.2.0.2.6.3.0-235') {. 2. Then I ran ./gradlew -Dspark.version=2.2.0.2.6.3.0-235 shadowJar archiveZip command. ### What went wrong (all error messages here, including the full java stack trace):; bild fails. ```; [luffy@wp-hdp-ctrl03 hail]$ ./gradlew -Dspark.version=2.2.0.2.6.3.0-235 shadowJar archiveZip --stacktrace; 1f253167d53c; :compileJava UP-TO-DATE; :generateBuildInfo; :nativeLib; tar -xzf libsimdpp-2.0-rc2.tar.gz; g++ -O3 -march=native -g -std=c++11 -Ilibsimdpp-2.0-rc2 -Wall -Werror -fPIC -ggdb -c -o ibs.o ibs.cpp; cc1plus: error: unrecognized command line option ""-std=c++11""; make: *** [ibs.o] Error 1; :nativeLib FAILED. FAILURE: Build failed with an exception. * What went wrong:; Execution failed for task ':nativeLib'.; > Process 'command 'make'' finished with non-zero exit value 2. * Try:; Run with --info or --debug option to get more log output. * Exception is:; org.gradle.api.tasks.TaskExecutionException: Execution failed for task ':nativeLib'.; at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.executeActions(ExecuteActionsTaskExecuter.java:69); at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.execute(ExecuteActionsTaskExecuter.java:46); at org.gradle.api.internal.tasks.execution.PostExecutionAnalysisTaskExecuter.execute(PostExecutionAnalysisTaskExecuter.java:35); at org.gradle.api.internal.tasks.execution.SkipUpToDateTaskExecuter.execute(SkipUpToDateTaskExecuter.java:66); at org.gradle.api.internal.tasks.execution.ValidatingTaskExecuter.execute(ValidatingTaskExecuter.java:58); at org.gradle.api.internal.tasks.execution.SkipEmptySourceFilesTaskExecuter.e",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3705:503,error,error,503,https://hail.is,https://github.com/hail-is/hail/issues/3705,3,"['Error', 'error']","['Error', 'error']"
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: http://discuss.hail.is/. -------------------------------------------------------------------------------------------. ### Hail version:; 0.2; ### What you did:; Export hail table to elasticsearch; >>> hl.utils.get_movie_lens('data/'); >>> users = hl.read_table('data/users.ht'); >>> hl.export_elasticsearch(users, 'XX.XXX.XXX.XXX', XXXX, 'data', 'variant', 200,config=N; one, verbose=True). ### What went wrong (all error messages here, including the full java stack trace):. Error:; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""</usr/local/lib/python3.6/site-packages/decorator.py:decorator-gen-1118>"", line 2, in export_elasticsearch; File ""/opt/hail-on-EMR/src/hail/hail/build/distributions/hail-python.zip/hail/typecheck/check.py"", line 561, in wrapper; File ""/opt/hail-on-EMR/src/hail/hail/build/distributions/hail-python.zip/hail/methods/impex.py"", line 2104, in export_elasticsearch; File ""/opt/hail-on-EMR/src/hail/hail/build/distributions/hail-python.zip/hail/table.py"", line 101, in __getattr__; AttributeError: Table instance has no attribute '_jt'",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5583:533,error,error,533,https://hail.is,https://github.com/hail-is/hail/issues/5583,2,"['Error', 'error']","['Error', 'error']"
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: http://discuss.hail.is/. -------------------------------------------------------------------------------------------. ### Hail version:; 0.2; ### What you did:; users = hl.read_table('data/users.ht'); hl.export_elasticsearch(users, 'XX.XXX.XXX.XXX', 32565, 'users', 'movies', 200,config=None, verbose=True ). ### What went wrong (all error messages here, including the full java stack trace):; Gotten this error even though the elasticsearch IP and port number 32565 is correct. The IP mentioned in the error 192.168.185.157:9200 was not found anywhere in our EMR or elasticsearch cluster. ; >>> hl.export_elasticsearch(users, 'XX.XXX.XXX.XXX', 32565, 'users', 'movies', 200,config=None, verbose=True ); Config Map(es.nodes -> XX.XXX.XXX.XXX, es.port -> 32565, es.batch.size.entries -> 200, es.index.auto.create -> true); [Stage 0:> (0 + 32) / 65]Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""</usr/local/lib/python3.6/site-packages/decorator.py:decorator-gen-1122>"", line 2, in export_elasticsearch; File ""/opt/hail-on-EMR/src/hail/hail/build/distributions/hail-python.zip/hail/typecheck/check.py"", line 561, in wrapper; File ""/opt/hail-on-EMR/src/hail/hail/build/distributions/hail-python.zip/hail/methods/impex.py"", line 2106, in export_elasticsearch; File ""/usr/lib/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py"", line 1257, in __call__; File ""/opt/hail-on-EMR/src/hail/hail/build/distributions/hail-python.zip/hail/utils/java.py"", line 227, in deco; hail.utils.java.FatalError: EsHadoopNoNodesLeftException: Connection error (check network and/or proxy settings)- all nodes failed; tried [[192.168.185.157:9200, 192.168.81.209:9200]] . Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 0.0 failed 4 times, most recent failure: Lost task 1.3 in stage 0.0 (TID 73, ip-172-31-10-234.ap",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5643:451,error,error,451,https://hail.is,https://github.com/hail-is/hail/issues/5643,3,['error'],['error']
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: http://discuss.hail.is/. -------------------------------------------------------------------------------------------. ### Hail version:; 19213e50. ### What you did:; Tried compiling hail with GCC-8.1.0. ### What went wrong (all error messages here, including the full java stack trace):. Full output from `make` invocation:; ```; echo ""make debug""; make debug; echo ""JAVA_HOME is /usr/lib/jvm/java-8-openjdk-amd64""; JAVA_HOME is /usr/lib/jvm/java-8-openjdk-amd64; echo ""CXX is g++""; CXX is g++; g++ --version; g++ (GCC) 8.1.0; Copyright (C) 2018 Free Software Foundation, Inc.; This is free software; see the source for copying conditions. There is NO; warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. tar -xzf libsimdpp-2.0-rc2.tar.gz; g++ -O3 -march=native -std=c++11 -Ilibsimdpp-2.0-rc2 -Wall -Werror -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/usr/lib/jvm/java-8-openjdk-amd64/include -I/usr/lib/jvm/java-8-openjdk-amd64/include/linux -c -o ibs.o ibs.cpp; In file included from libsimdpp-2.0-rc2/simdpp/simd.h:132,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl: In instantiation of R simdpp::arch_avx2::detail::cast_memcpy(const T&) [with R = simdpp::arch_avx2::float64<2>; T = simdpp::arch_avx2::float32<4, simdpp::arch_avx2::expr_empty>]:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::arch_avx2::float64<2>; T = simdpp::arch_avx2::float32<4, simdpp::arch_avx2::expr_empty>; unsigned int MaskCastOverride = 0]; libsimdpp-2.0-rc2/simdpp/core/cast.h:63:89: required from R simdpp::arch_avx2::bit_cast(const T&) [with R = simdpp::arch_avx2::float64<2>; T = simdpp::arch_avx2::float32<4, simdpp::arch_avx2::expr_empty>]; libsimdpp-2.0-rc2/simdpp/detail/insn/transpose.h:253:",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3955:345,error,error,345,https://hail.is,https://github.com/hail-is/hail/issues/3955,4,"['echo', 'error']","['echo', 'error']"
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: http://discuss.hail.is/. -------------------------------------------------------------------------------------------. ### Hail version:; Hail .2, Spark 2.2. ### What you did:; Error when I run one of several methods of MatrixTable (write(), count_rows(), etc). ### What went wrong (all error messages here, including the full java stack trace):; org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 1.0 failed 4 times, most recent failure: Lost task 1.3 in stage 1.0 (TID 23, ip-172-31-66-74.ec2.internal, executor 1): java.io.InvalidClassException: is.hail.expr.types.TInterval; local class incompatible: stream classdesc serialVersionUID = -1783603148272890463, local class serialVersionUID = 7653437602465004618",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4650:293,Error,Error,293,https://hail.is,https://github.com/hail-is/hail/issues/4650,4,"['Error', 'error', 'failure']","['Error', 'error', 'failure']"
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: http://discuss.hail.is/. -------------------------------------------------------------------------------------------. ### Hail version:; Hail version: devel-eb1e04205793. ### What you did:. Attempt to `export_vcf` with a MT where some `locus` values are `NA`. ### What went wrong (all error messages here, including the full java stack trace):. Bad error message. Didn't really tell me anything except Java Assertion Error. [Stage 2:===========================================> (1709 + 291) / 2000]Traceback (most recent call last):; File ""/tmp/0eccddcf-0d49-4280-8b79-c43e193b044d/vdstovcf.py"", line 12, in <module>; hail.export_vcf(myvds, 'gs://ibd-exomes/v34meta/exomes.ccdg.vcf.bgz'); File ""/home/hail/hail.zip/hail/typecheck/check.py"", line 547, in wrapper; File ""/home/hail/hail.zip/hail/methods/impex.py"", line 422, in export_vcf; File ""/usr/lib/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py"", line 1133, in __call__; File ""/home/hail/hail.zip/hail/utils/java.py"", line 196, in deco; hail.utils.java.FatalError: AssertionError: assertion failed",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4011:402,error,error,402,https://hail.is,https://github.com/hail-is/hail/issues/4011,3,"['Error', 'error']","['Error', 'error']"
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: http://discuss.hail.is/. -------------------------------------------------------------------------------------------. ### Hail version:; Running on Apache Spark version 2.2.0 version devel-cfdbb87; ### What you did:; This error message is related to this filter:; passed=passed.filter_rows((passed.variant_qc.AC>= 10)); Without this filter it runs OK. This file is a merged vcf file from Lumpy. Some sites may have no alternate alleles called (all 0/0 or ./.). ### What went wrong (all error messages here, including the full java stack trace):; [Stage 2:> (0 + 72) / 125]Traceback (most recent call last):; File ""/restricted/projectnb/casa/wgs.hg38/hail/lumpy/models.all.py"", line 80, in <module>; print(""Filtered Passed Rows:"",passed.count_rows()); File ""/restricted/projectnb/genpro/github/hail/build/distributions/hail-python.zip/hail/matrixtable.py"", line 2072, in count_rows; File ""/share/pkg/spark/2.2.0/install/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py"", line 1133, in __call__; File ""/restricted/projectnb/genpro/github/hail/build/distributions/hail-python.zip/hail/utils/java.py"", line 196, in deco; hail.utils.java.FatalError: NegativeArraySizeException: null. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 30 in stage 2.0 failed 4 times, most recent failure: Lost task 30.3 in stage 2.0 (TID 91, scc-q05.scc.bu.edu, executor 9): java.lang.NegativeArraySizeException; 	at java.util.Arrays.copyOf(Arrays.java:3236); 	at is.hail.annotations.Region.ensure(Region.scala:139); 	at is.hail.annotations.Region.allocate(Region.scala:152); 	at is.hail.annotations.Region.allocate(Region.scala:159); 	at is.hail.codegen.generated.C4.apply(Unknown Source); 	at is.hail.codegen.generated.C4.apply(Unknown Source); 	at is.hail.io.CompiledPackDecoder.readRegionValue(RowStore.scala:649); 	at is.hail.HailContext$$anon$2.next(HailCon",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3901:339,error,error,339,https://hail.is,https://github.com/hail-is/hail/issues/3901,2,['error'],['error']
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: http://discuss.hail.is/. -------------------------------------------------------------------------------------------. ### Hail version:; `devel-17d79be1221e`; ### What you did:; ```; import hail as hl. mt = hl.balding_nichols_model(3, 100, 100); hl.export_vcf(mt, 'foo.vcf.bgz'); ```; ### What went wrong (all error messages here, including the full java stack trace):; ```; Traceback (most recent call last):; File ""foo.py"", line 4, in <module>; hl.export_vcf(mt, 'foo.vcf.bgz'); File ""<decorator-gen-878>"", line 2, in export_vcf; File ""/Users/dking/projects/hail/python/hail/typecheck/check.py"", line 546, in wrapper; return __original_func(*args_, **kwargs_); File ""/Users/dking/projects/hail/python/hail/methods/impex.py"", line 424, in export_vcf; joption(typ._convert_to_j(metadata))); File ""/Users/dking/borg/spark-2.2.0-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py"", line 1133, in __call__; File ""/Users/dking/projects/hail/python/hail/utils/java.py"", line 210, in deco; 'Error summary: %s' % (deepest, full, hail.__version__, deepest)) from None; hail.utils.java.FatalError: HailException: in export_vcf: column key must be type 'str', found: [Lis.hail.expr.types.Type;@1e5a1972. Java stack trace:; is.hail.utils.HailException: in export_vcf: column key must be type 'str', found: [Lis.hail.expr.types.Type;@1e5a1972; 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:9); 	at is.hail.utils.package$.fatal(package.scala:26); 	at is.hail.variant.MatrixTable.requireColKeyString(MatrixTable.scala:392); 	at is.hail.io.vcf.ExportVCF$.apply(ExportVCF.scala:202); 	at is.hail.io.vcf.ExportVCF.apply(ExportVCF.scala); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.j",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4283:427,error,error,427,https://hail.is,https://github.com/hail-is/hail/issues/4283,1,['error'],['error']
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: http://discuss.hail.is/. -------------------------------------------------------------------------------------------. ### Hail version:; `devel-3b014af` (off of `0c96180`); ### What you did:; ```; mt = mt.select_entries(GT=hl.cond(hl.is_defined(mt.GT), hl.struct(), hl.null(hl.tstruct()))); ```; ### What went wrong (all error messages here, including the full java stack trace):; ```; TypeError: 'cond' requires the 'consequent' and 'alternate' arguments to have the same type; consequent: type struct{}; alternate: type struct{}; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3103:438,error,error,438,https://hail.is,https://github.com/hail-is/hail/issues/3103,1,['error'],['error']
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: http://discuss.hail.is/. -------------------------------------------------------------------------------------------. ### Hail version:; devel-45429b1. ### What you did:; ```; x = functions.capture(5); y = -1.2e-7; eval_expr(x * y); ```. ### What went wrong (all error messages here, including the full java stack trace):; ```; ---------------------------------------------------------------------------; FatalError Traceback (most recent call last); <ipython-input-53-69c81b591366> in <module>(); ----> 1 eval_expr(x * y). <decorator-gen-365> in eval_expr(expression). /hadoop_gcs_connector_metadata_cache/hail/hail-devel-45429b164934.zip/hail/expr/expression.py in args_to_expr(func, *args); 176 @decorator; 177 def args_to_expr(func, *args):; --> 178 return func(*(to_expr(a) for a in args)); 179; 180. /hadoop_gcs_connector_metadata_cache/hail/hail-devel-45429b164934.zip/hail/expr/expression.py in eval_expr(expression); 3576 Result of evaluating `expression`.; 3577 """"""; -> 3578 return eval_expr_typed(expression)[0]; 3579; 3580. <decorator-gen-366> in eval_expr_typed(expression). /hadoop_gcs_connector_metadata_cache/hail/hail-devel-45429b164934.zip/hail/expr/expression.py in args_to_expr(func, *args); 176 @decorator; 177 def args_to_expr(func, *args):; --> 178 return func(*(to_expr(a) for a in args)); 179; 180. /hadoop_gcs_connector_metadata_cache/hail/hail-devel-45429b164934.zip/hail/expr/expression.py in eval_expr_typed(expression); 3612 if len(expression._joins) > 0:; 3613 raise ExpressionException(""'eval_expr' methods do not support joins or broadcasts""); -> 3614 r, t = Env.hc().eval_expr_typed(expression._ast.to_hql()); 3615 return r, t; 3616. <decorator-gen-1049> in eval_expr_typed(self, expr). /hadoop_gcs_connector_metadata_cache/hail/hail-devel-45429b164934.zip/hail/utils/java.py in handle_py4j(func, *args, **kwargs); 153 raise FatalError('%s\n\nJava st",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2655:380,error,error,380,https://hail.is,https://github.com/hail-is/hail/issues/2655,1,['error'],['error']
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: http://discuss.hail.is/. -------------------------------------------------------------------------------------------. ### Hail version:; devel-64a1fac. ### What you did:; run split_multi_hts on a VDS with only GT genotype field. ### What went wrong (all error messages here, including the full java stack trace):; ```; is.hail.utils.HailException: Struct has no field `AD'; Available fields:; GT: Call; <input>:4: newad = if (isDefined(g.AD)); ^; at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:6); at is.hail.utils.package$.fatal(package.scala:27); at is.hail.expr.ParserUtils$.error(Parser.scala:33); at is.hail.expr.AST.parseError(AST.scala:255); at is.hail.expr.Select.typecheckThis(AST.scala:333); at is.hail.expr.AST.typecheckThis(AST.scala:246); at is.hail.expr.AST.typecheck(AST.scala:252); at is.hail.expr.AST$$anonfun$typecheck$1.apply(AST.scala:251); at is.hail.expr.AST$$anonfun$typecheck$1.apply(AST.scala:251); at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186); at is.hail.expr.AST.typecheck(AST.scala:251); at is.hail.expr.Apply.typecheck(AST.scala:663); at is.hail.expr.AST$$anonfun$typecheck$1.apply(AST.scala:251); at is.hail.expr.AST$$anonfun$typecheck$1.apply(AST.scala:251); at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186); at is.hail.expr.AST.typecheck(AST.scala:251); at is.hail.expr.Let$$anonfun$typecheck$18.apply(AST.scala:850); at is.hail.expr.Let$$anonfun$typecheck$18.apply(AST.scala:849); at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733); at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); at scala.collection.mutable.ArrayOps$ofRef.foreach(",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2755:371,error,error,371,https://hail.is,https://github.com/hail-is/hail/issues/2755,5,"['Avail', 'Error', 'error']","['Available', 'ErrorHandling', 'error']"
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: http://discuss.hail.is/. -------------------------------------------------------------------------------------------. ### Hail version:; devel-6bb4670. ### What you did:; A number of variant QC steps, then a `vds.write`; The error is probably caused by one of the previous steps. If it helps I can comment out earlier parts to narrow down what actually triggers the error. ### What went wrong (all error messages here, including the full java stack trace):; ```; [Stage 6:> (0 + 8) / 5000]; [Stage 6:> (0 + 4) / 5000]; [Stage 6:> (0 + 8) / 5000]Traceback (most recent call last):; File ""/home/hail/hail.zip/hail/utils/java.py"", line 185, in handle_py4j; File ""/home/hail/hail.zip/hail/table.py"", line 1058, in aggregate; File ""/usr/lib/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py"", line 1133, in __call__; File ""/usr/lib/spark/python/lib/pyspark.zip/pyspark/sql/utils.py"", line 63, in deco; File ""/usr/lib/spark/python/lib/py4j-0.10.4-src.zip/py4j/protocol.py"", line 319, in get_return_value; py4j.protocol.Py4JJavaError: An error occurred while calling o30335.query.; : org.apache.spark.SparkException: Job aborted due to stage failure: Task 7 in stage 6.0 failed 20 times, most recent failure: Lost task 7.19 in stage 6.0 (TID 179, robert1-w-0.c.ccdg-wgs.internal, executor 4): java.lang.AssertionError: assertion failed; at scala.Predef$.assert(Predef.scala:156); at is.hail.annotations.RegionValueBuilder.endStruct(RegionValueBuilder.scala:109); at is.hail.variant.MatrixTable$$anonfun$filterGenotypes$1$$anonfun$apply$80.apply(MatrixTable.scala:2645); at is.hail.variant.MatrixTable$$anonfun$filterGenotypes$1$$anonfun$apply$80.apply(MatrixTable.scala:2615); at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); at is.hail.rvd.OrderedRVD$$anonfun$apply$6$$anon$5.next(OrderedRVD.scala:736); at is.hail.rvd.OrderedRVD$$anonfun$apply$6$$anon$5.next(Ordered",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3063:342,error,error,342,https://hail.is,https://github.com/hail-is/hail/issues/3063,4,"['down', 'error']","['down', 'error']"
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: http://discuss.hail.is/. -------------------------------------------------------------------------------------------. ### Hail version:; devel-92bbe4b. ### What you did:; I used `join` to combine two VDS. Empty sample schema, different variant schema, no overlapping samples, hardcalls. ### What went wrong (all error messages here, including the full java stack trace):; Got an AssertionError:; ```; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 5.0 failed 20 times, most recent failure: Lost task 0.19 in stage 5.0 (TID 677, mycluster3-w-1.c.ccdg-wgs.internal): java.lang.AssertionError: assertion failed; at scala.Predef$.assert(Predef.scala:156); at is.hail.annotations.Region.loadInt(Region.scala:36); at is.hail.expr.types.TContainer$.loadLength(TContainer.scala:9); at is.hail.expr.types.TContainer.loadLength(TContainer.scala:27); at is.hail.variant.MatrixTable$$anonfun$105$$anonfun$apply$58.apply(MatrixTable.scala:1702); at is.hail.variant.MatrixTable$$anonfun$105$$anonfun$apply$58.apply(MatrixTable.scala:1685); at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); at is.hail.rvd.OrderedRVD$$anonfun$apply$9$$anon$5.next(OrderedRVD.scala:661); at is.hail.rvd.OrderedRVD$$anonfun$apply$9$$anon$5.next(OrderedRVD.scala:655); ```. I can make it work by copying the variant annotation from one VDS to the other before calling `join`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2763:429,error,error,429,https://hail.is,https://github.com/hail-is/hail/issues/2763,3,"['error', 'failure']","['error', 'failure']"
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: http://discuss.hail.is/. -------------------------------------------------------------------------------------------. ### Hail version:; devel-c8ca698. ### What you did:; ```; mt_path = ""gs://gnomad-berylc/myoseq/qc/variant_qc/MYOSEQ.variant.qc.filtered.040318.mt""; myoseq = hl.read_matrix_table(mt_path); qc_mt_common = myoseq.filter_rows(myoseq.va_qc.AF > 0.05). qc_mt_common_syn = qc_mt_common.filter_rows(qc_mt_common.worst_csq == ""synonymous""); results_per_gene_common = (qc_mt_common_syn.group_rows_by(qc_mt_common_syn.vep.ensg_with_most_severe_csq).aggregate(n_non_ref=agg.count_where((qc_mt_common_syn.GT.is_non_ref())))); ```. ### What went wrong (all error messages here, including the full java stack trace):; 2018-05-14 23:45:22 Hail: WARN: modified row key, rescanning to compute ordering...; [Stage 9:=====> (163 + 76) / 1526]---------------------------------------------------------------------------; FatalError Traceback (most recent call last); <ipython-input-12-cefffae1d4ba> in <module>(); ----> 1 results_per_gene_common = (qc_mt_common_syn.group_rows_by(qc_mt_common_syn.vep.ensg_with_most_severe_csq).aggregate(n_non_ref=agg.count_where((qc_mt_common_syn.GT.is_non_ref())))). /hadoop_gcs_connector_metadata_cache/hail/hail-devel-c8ca698c6ed5.zip/hail/matrixtable.py in aggregate(self, **named_exprs); 349 rest_of_key = {k: self._row_keys[k] for k in self._row_keys.keys() if k not in self._partition_key}; 350 base = MatrixTable(; --> 351 base._key_rows_by(""GroupedMatrixTable.group_rows_by"", pk, rest_of_key)._jvds.aggregateRowsByKey(; 352 ',\n'.join(strs))); 353 else:. /hadoop_gcs_connector_metadata_cache/hail/hail-devel-c8ca698c6ed5.zip/hail/matrixtable.py in _key_rows_by(self, caller, pk_dict, rest_of_keys_dict); 706 key_fields = dict(pk_dict, **rest_of_keys_dict); 707; --> 708 return self._select_rows(caller, key_struct=hl.struct(**key_fields), pk_si",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3583:778,error,error,778,https://hail.is,https://github.com/hail-is/hail/issues/3583,1,['error'],['error']
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: http://discuss.hail.is/. -------------------------------------------------------------------------------------------. ### Hail version:; devel. ### What you did:; ```; hc = HailContext(); past_vds = hc.read(args.past); future_vds = hc.read(args.future). bi_past_vds = past_vds.filter_rows(past_vds.v.is_biallelic()); bi_future_vds = future_vds.filter_rows(future_vds.v.is_biallelic()); bi_summary, bi_samples, bi_variants = methods.concordance(bi_past_vds, bi_future_vds); ```. ### What went wrong (all error messages here, including the full java stack trace):; ```; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version devel-08a1543; WARNING: This is an unstable development build.; 2018-01-17 18:32:09 Hail: INFO: Found 729 overlapping samples; Left: 729 total samples; Right: 729 total samples; 2018-01-17 18:32:10 Hail: WARN: converting OrderedRVD => OrderedRDD; [Stage 0:====================================================>(4627 + 1) / 4628]2018-01-17 18:47:04 Hail: INFO: Coerced sorted dataset; 2018-01-17 18:47:04 Hail: WARN: converting OrderedRVD => OrderedRDD; [Stage 1:> (7 + 28) / 4969]Traceback (most recent call last):; File ""/tmp/f93de2d1-2d89-43f9-9868-f266eb88a6f1/concordance.py"", line 38, in <module>; main(args); File ""/tmp/f93de2d1-2d89-43f9-9868-f266eb88a6f1/concordance.py"", line 19, in main; bi_summary, bi_samples, bi_variants = methods.concordance(bi_past_vds, bi_future_vds); File ""<decorator-gen-1304>"", line 2, in concordance; File ""/tmp/f93de2d1-2d89-43f9-9868-f266eb88a6f1/hail-devel-08a15431a0ef.zip/hail/utils/java.py"", line 155, in handle_py4j; hail.utils.java.FatalError: AssertionError: assertion failed. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 30 in stage 1.0 failed 20 times, most recent failure: Lost task 30.19 in stage 1.0 (TID 4847, lfdev2-sw-f5w2.c.broad-mpg",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2743:620,error,error,620,https://hail.is,https://github.com/hail-is/hail/issues/2743,1,['error'],['error']
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: http://discuss.hail.is/. -------------------------------------------------------------------------------------------. ### Hail version:; hail: `hail-devel-c8ca698`; ### What you did:; ```; hl.init(); ds = hl.import_plink('gs://testdata/1kg_phase1_chr22.bed',; 'gs://testdata/1kg_phase1_chr22.bim',; 'gs://testdata/1kg_phase1_chr22.fam'); ds = hl.sample_qc(ds); ```; Data was downloaded from [here](https://www.cog-genomics.org/plink/1.9/resources).; ; ### What went wrong (all error messages here, including the full java stack trace):; Spark jobs fail at `treeReduce at SampleQC.scala:206`.; Java Error: `java.lang.NegativeArraySizeException`. Full stack:; See file attached.; [error_message.txt](https://github.com/hail-is/hail/files/2003301/error_message.txt)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3585:492,down,downloaded,492,https://hail.is,https://github.com/hail-is/hail/issues/3585,3,"['Error', 'down', 'error']","['Error', 'downloaded', 'error']"
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: http://discuss.hail.is/. -------------------------------------------------------------------------------------------. ### Hail version:; version 0.2.4-f1e6526d34b1. ### What you did:; cd hail/hail. ./gradlew -Dspark.version=2.2.1 -Dbreeze.version=0.13.1 -Dpy4j.version=0.10.4 shadowJar archiveZip. ### What went wrong (all error messages here, including the full java stack trace):; In file included from Decoder.cpp:3:0:; ../resources/include/hail/Decoder.h:3:10: fatal error: lz4.h: No such file or directory; #include ""lz4.h""; ^~~~~~~; compilation terminated.; make: *** [build/Decoder.o] Error 1; :nativeLib FAILED. FAILURE: Build failed with an exception. * What went wrong:; Execution failed for task ':nativeLib'.; > Process 'command 'make'' finished with non-zero exit value 2. * Try:; Run with --stacktrace option to get the stack trace. Run with --info or --debug option to get more log output. BUILD FAILED. Total time: 36.47 secs",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4880:440,error,error,440,https://hail.is,https://github.com/hail-is/hail/issues/4880,4,"['Error', 'FAILURE', 'error']","['Error', 'FAILURE', 'error']"
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: http://discuss.hail.is/. -------------------------------------------------------------------------------------------. ### Hail version:; version devel-51961fa0ef80. ### What you did:; ```v7_gene_maximums_kt = hl.read_table(""gs://gnomad-berylc/tx-annotation/hail2/data/GTEx.v7.max_expression_per_gene_per_tissue.031318.kt"")```. ### What went wrong (all error messages here, including the full java stack trace):; ```---------------------------------------------------------------------------; FatalError Traceback (most recent call last); <ipython-input-5-daf7d8347376> in <module>(); ----> 1 v7_gene_maximums_kt = hl.read_table(""gs://gnomad-berylc/tx-annotation/hail2/data/GTEx.v7.max_expression_per_gene_per_tissue.031318.kt""). <decorator-gen-1046> in read_table(path). /home/hail/hail.zip/hail/typecheck/check.py in wrapper(__original_func, *args, **kwargs); 558 def wrapper(__original_func, *args, **kwargs):; 559 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 560 return __original_func(*args_, **kwargs_); 561 ; 562 return wrapper. /home/hail/hail.zip/hail/methods/impex.py in read_table(path); 1865 :class:`.Table`; 1866 """"""; -> 1867 return Table(Env.hc()._jhc.readTable(path)); 1868 ; 1869 @typecheck(t=Table,. /usr/lib/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py in __call__(self, *args); 1131 answer = self.gateway_client.send_command(command); 1132 return_value = get_return_value(; -> 1133 answer, self.gateway_client, self.target_id, self.name); 1134 ; 1135 for temp_arg in temp_args:. /home/hail/hail.zip/hail/utils/java.py in deco(*args, **kwargs); 208 raise FatalError('%s\n\nJava stack trace:\n%s\n'; 209 'Hail version: %s\n'; --> 210 'Error summary: %s' % (deepest, full, hail.__version__, deepest)) from None; 211 except pyspark.sql.utils.CapturedException as e:; 212 raise FatalError('%s\n\nJava stack tr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4325:469,error,error,469,https://hail.is,https://github.com/hail-is/hail/issues/4325,1,['error'],['error']
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: http://discuss.hail.is/. -------------------------------------------------------------------------------------------. ### Hail version:devel-abac611. ### What you did: spark-submit --jars build/libs/hail-all-spark.jar --conf spark.kryo.registrator=is.hail.kryo.HailKryoRegistrator --py-files build/distributions/hail-python.zip --num-executors 6 test.py; where test.y is:; import hail as hl; hl.init(master='yarn',default_reference='GRCh38'); hl.import_vcf('/project/casa/vcf.5k/gatk.hc/adsp-5k.hg38.tileDB.recalibrate_SNP.chr22.biallelic.4795samples.g.vcf.bgz').write('/project/casa/vdf.5k/test.vdf'). ### What went wrong (all error messages here, including the full java stack trace):; Error summary: ClassNotFoundException: is.hail.utils.SerializableHadoopConfiguration; Running on Apache Spark version 2.2.0; SparkUI available at http://10.48.225.55:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version devel-abac611; NOTE: This is a beta version. Interfaces may change; during the beta period. We also recommend pulling; the latest changes weekly.; [Stage 1:======================================================>(243 + 1) / 244]2018-04-10 09:30:24 Hail: INFO: Coerced sorted dataset; Traceback (most recent call last):; File ""/restricted/projectnb/genpro/github/hail/test.py"", line 3, in <module>; hl.import_vcf('/project/casa/vcf.5k/gatk.hc/adsp-5k.hg38.tileDB.recalibrate_SNP.chr22.biallelic.4795samples.g.vcf.bgz').write('/project/casa/vdf.5k/test. vdf'); File ""<decorator-gen-546>"", line 2, in write; File ""/restricted/projectnb/genpro/github/hail/build/distributions/hail-python.zip/hail/typecheck/check.py"", line 481, in _typecheck; File ""/restricted/projectnb/genpro/github/hail/build/distributions/hail-python.zip/hail/matrixtable.py"", line 1956, in write; File ""/share/pkg/spark/2.2.0/install/python/lib/py4j-0.10.4-src.zip/py4j/java",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3342:745,error,error,745,https://hail.is,https://github.com/hail-is/hail/issues/3342,3,"['Error', 'avail', 'error']","['Error', 'available', 'error']"
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: http://discuss.hail.is/. -------------------------------------------------------------------------------------------. Running on Ubuntu 18.04. I had installed openjdk-11-jre-headless instead of openjdk-8-jre-headless. ### Hail version:; 0.2 ; ### What you did:. ### What went wrong (all error messages here, including the full java stack trace):; 2018-12-04 22:13:57 root: ERROR: IllegalArgumentException: null; From java.lang.IllegalArgumentException: null; at org.apache.xbean.asm5.ClassReader.<init>(Unknown Source); at org.apache.xbean.asm5.ClassReader.<init>(Unknown Source); at org.apache.xbean.asm5.ClassReader.<init>(Unknown Source); at org.apache.spark.util.ClosureCleaner$.getClassReader(ClosureCleaner.scala:46); at org.apache.spark.util.FieldAccessFinder$$anon$3$$anonfun$visitMethodInsn$2.apply(ClosureCleaner.scala:443); at org.apache.spark.util.FieldAccessFinder$$anon$3$$anonfun$visitMethodInsn$2.apply(ClosureCleaner.scala:426); at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733); at scala.collection.mutable.HashMap$$anon$1$$anonfun$foreach$2.apply(HashMap.scala:103); at scala.collection.mutable.HashMap$$anon$1$$anonfun$foreach$2.apply(HashMap.scala:103); at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230); at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40); at scala.collection.mutable.HashMap$$anon$1.foreach(HashMap.scala:103); at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732); at org.apache.spark.util.FieldAccessFinder$$anon$3.visitMethodInsn(ClosureCleaner.scala:426); at org.apache.xbean.asm5.ClassReader.a(Unknown Source); at org.apache.xbean.asm5.ClassReader.b(Unknown Source); at org.apache.xbean.asm5.ClassReader.accept(Unknown Source); at org.apache.xbean.asm5.ClassReader.accept(Unknown Source); at org.apache.spark.util.Closu",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4896:404,error,error,404,https://hail.is,https://github.com/hail-is/hail/issues/4896,2,"['ERROR', 'error']","['ERROR', 'error']"
Availability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: http://discuss.hail.is/. -------------------------------------------------------------------------------------------. Tutorials 05 and 08. ### What you did:; (From tutorial 05-tables). import hail as hl; hl.init(); hl.utils.get_movie_lens('data/'); users = hl.read_table('data/users.ht'). ### What went wrong (all error messages here, including the full java stack trace):. Py4JError: An error occurred while calling o1.readTable. Trace:; py4j.Py4JException: Method readTable([class java.lang.String]) does not exist; 	at py4j.reflection.ReflectionEngine.getMethod(ReflectionEngine.java:318); 	at py4j.reflection.ReflectionEngine.getMethod(ReflectionEngine.java:326); 	at py4j.Gateway.invoke(Gateway.java:272); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:214); 	at java.lang.Thread.run(Thread.java:748)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3989:431,error,error,431,https://hail.is,https://github.com/hail-is/hail/issues/3989,2,['error'],['error']
Availability,"To reproduce:. ```; >>> import hail as hl; >>> hl._set_flags(cpp='true'); >>> mt = hl.read_table('gs://gnomad-public/release/2.1/ht/exomes/gnomad.exomes.r2.1.sites.ht'); >>> mt._force_count(); ```. gets:. ```; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x0000000113aae924, pid=29051, tid=0x0000000000004003; #; ```. This is on OSX. Smaller examples work fine with C++ on.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4816:223,error,error,223,https://hail.is,https://github.com/hail-is/hail/issues/4816,1,['error'],['error']
Availability,Topics:; https://hail.zulipchat.com/#narrow/stream/123010-Hail-0.2E2.20support/topic/key.20not.20found.3A.20GRCh38/near/247317975; https://discuss.hail.is/t/potential-liftover-issue-error-summary-nosuchelementexception-key-not-found-grch37/2154. Stack trace:; ```; java.util.NoSuchElementException: key not found: GRCh37; 	at scala.collection.MapLike.default(MapLike.scala:235); 	at scala.collection.MapLike.default$(MapLike.scala:234); 	at scala.collection.AbstractMap.default(Map.scala:65); 	at scala.collection.mutable.HashMap.apply(HashMap.scala:69); 	at is.hail.variant.ReferenceGenome.getLiftover(ReferenceGenome.scala:412); 	at is.hail.variant.ReferenceGenome.liftoverLocus(ReferenceGenome.scala:423); 	at __C700Compiled.applyregion0_8(Emit.scala); 	at __C700Compiled.apply(Emit.scala); 	at is.hail.expr.ir.TableMapRows.$anonfun$execute$43(TableIR.scala:1936); ```. See Lindo's comment in the Zulip thread to replicate (hopefully),MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/10722:182,error,error-summary-nosuchelementexception-key-not-found-,182,https://hail.is,https://github.com/hail-is/hail/issues/10722,1,['error'],['error-summary-nosuchelementexception-key-not-found-']
Availability,"Traceback (most recent call last):; File ""foo.py"", line 4, in <module>; hl.export_vcf(mt, 'foo.vcf.bgz'); File ""<decorator-gen-878>"", line 2, in export_vcf; File ""/Users/dking/projects/hail/python/hail/typecheck/check.py"", line 546, in wrapper; return __original_func(*args_, **kwargs_); File ""/Users/dking/projects/hail/python/hail/methods/impex.py"", line 424, in export_vcf; joption(typ._convert_to_j(metadata))); File ""/Users/dking/borg/spark-2.2.0-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py"", line 1133, in __call__; File ""/Users/dking/projects/hail/python/hail/utils/java.py"", line 210, in deco; 'Error summary: %s' % (deepest, full, hail.__version__, deepest)) from None; hail.utils.java.FatalError: HailException: in export_vcf: column key must be type 'str', found: [Lis.hail.expr.types.Type;@1e5a1972. Java stack trace:; is.hail.utils.HailException: in export_vcf: column key must be type 'str', found: [Lis.hail.expr.types.Type;@1e5a1972; 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:9); 	at is.hail.utils.package$.fatal(package.scala:26); 	at is.hail.variant.MatrixTable.requireColKeyString(MatrixTable.scala:392); 	at is.hail.io.vcf.ExportVCF$.apply(ExportVCF.scala:202); 	at is.hail.io.vcf.ExportVCF.apply(ExportVCF.scala); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:280); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:214); 	at java.lang.Thread.run(Thread.java:745). Hail versi",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4283:1482,Error,ErrorHandling,1482,https://hail.is,https://github.com/hail-is/hail/issues/4283,1,['Error'],['ErrorHandling']
Availability,Treat them analogously to ref. I think there's potential for an assertion failure now.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/539:74,failure,failure,74,https://hail.is,https://github.com/hail-is/hail/issues/539,1,['failure'],['failure']
Availability,Treat warnings as errors.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/498:18,error,errors,18,https://hail.is,https://github.com/hail-is/hail/pull/498,1,['error'],['errors']
Availability,"Tried running ; `hail read -i file:///mnt/lustre/bavila/denovo/myrioux3.vep.vds exportvcf -o file:///mnt/lustre/bavila/denovo/myrioux3.vep.vcf`. got the following; ```; hail: info: running: read -i file:///mnt/lustre/bavila/denovo/myrioux3.vep.vds; [Stage 1:======================================================>(255 + 1) / 256]hail: info: running: exportvcf -o file:///mnt/lustre/bavila/denovo/myrioux3.vep.vcf; [Stage 2:=====> (2117 + 256) / 19042]hail: exportvcf: caught exception: org.apache.spark.SparkException: Job aborted due to stage failure: Task 2137 in stage 2.0 failed 4 times, most recent failure: Lost task 2137.3 in stage 2.0 (TID 3028, nid00013.urika.com): java.lang.IllegalArgumentException: Self-suppression not permitted; 	at java.lang.Throwable.addSuppressed(Throwable.java:1043); 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1219); 	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13.apply(PairRDDFunctions.scala:1116); 	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13.apply(PairRDDFunctions.scala:1095); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66); 	at org.apache.spark.scheduler.Task.run(Task.scala:88); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745); ```. Full error and log below:. [error.txt](https://github.com/hail-is/hail/files/652656/error.txt); [hail.log.txt](https://github.com/hail-is/hail/files/652665/hail.log.txt)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1185:544,failure,failure,544,https://hail.is,https://github.com/hail-is/hail/issues/1185,5,"['error', 'failure']","['error', 'failure']"
Availability,"Tried to load 1kg public VCF using newest version of hail:; ```; tgp = hl.import_vcf('gs://genomics-public-data/1000-genomes-phase-3/vcf-20150220/ALL.chr22.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf'); tgp.describe(); tgp.rows().show(); ```; Getting:; ```; hail.utils.java.FatalError: NoSuchElementException: key not found: GT. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 2.0 failed 20 times, most recent failure: Lost task 0.19 in stage 2.0 (TID 104, pca-w-1.c.daly-ibd.internal, executor 2): is.hail.utils.HailException: ALL.chr22.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf: caught java.util.NoSuchElementException: key not found: GT; offending line: 22	16050075	rs587697622	A	G	100	PASS	AC=1;AF=0.000199681;AN=...; 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:17); 	at is.hail.utils.package$.fatal(package.scala:26); 	at is.hail.utils.Context.wrapException(Context.scala:23); 	at is.hail.io.vcf.LoadVCF$$anonfun$parseLines$1$$anon$1.hasNext(LoadVCF.scala:761); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); 	at scala.collection.Iterator$$anon$1.hasNext(Iterator.scala:1004); 	at is.hail.rvd.OrderedRVD$$anon$2.hasNext(OrderedRVD.scala:413); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$10$$anon$3.hasNext(OrderedRVD.scala:815); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$10$$anon$3.hasNext(OrderedRVD.scala:815); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:389); 	at scal",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3467:424,failure,failure,424,https://hail.is,https://github.com/hail-is/hail/issues/3467,4,"['Error', 'failure']","['ErrorHandling', 'failure']"
Availability,"Tried to run this code:. `vds.annotate_samples_expr('sa.variant1 = gs.filter(g => v == Variant(""1:55505447:C:T"")).collect()[0].gt')`. But the variant was not in the dataset at all, so got an out of bounds error, but it looked like this:. ```; [Stage 2:======================================================>(278 + 1) / 279]// class version 52.0 (52); // access flags 0x1; public class is/hail/codegen/generated/C0 implements java/io/Serializable scala/Function2 {. // access flags 0x1; public apply(Ljava/lang/Object;Ljava/lang/Object;)Ljava/lang/Object;; L0; ALOAD 1; CHECKCAST [Ljava/lang/Object;; LDC 0; AALOAD; INVOKEINTERFACE scala/Function0.apply ()Ljava/lang/Object;; CHECKCAST scala/collection/IndexedSeq; ASTORE 3; ALOAD 3; IFNULL L1; NEW java/lang/Integer; DUP; LDC 0; INVOKESPECIAL java/lang/Integer.<init> (I)V; ASTORE 4; ALOAD 4; IFNULL L2; ALOAD 4; INVOKEVIRTUAL java/lang/Number.intValue ()I; ISTORE 5; ALOAD 3; ILOAD 5; LDC 0; IF_ICMPGE L3; GOTO L4; L4; FRAME FULL [is/hail/codegen/generated/C0 java/lang/Object java/lang/Object scala/collection/IndexedSeq java/lang/Integer I] [scala/collection/IndexedSeq]; ILOAD 5; ALOAD 3; INVOKEINTERFACE scala/collection/IndexedSeq.size ()I; IADD; GOTO L5; L3; FRAME SAME1 scala/collection/IndexedSeq; ILOAD 5; L5; FRAME FULL [is/hail/codegen/generated/C0 java/lang/Object java/lang/Object scala/collection/IndexedSeq java/lang/Integer I] [scala/collection/IndexedSeq I]; INVOKEINTERFACE scala/collection/IndexedSeq.apply (I)Ljava/lang/Object;; GOTO L6; L2; FRAME CHOP 1; ACONST_NULL; L6; FRAME SAME1 java/lang/Object; GOTO L7; L1; FRAME CHOP 1; ACONST_NULL; L7; FRAME SAME1 java/lang/Object; CHECKCAST is/hail/variant/Genotype; ASTORE 6; ALOAD 6; IFNULL L8; ALOAD 6; INVOKEVIRTUAL is/hail/variant/Genotype.unboxedGT ()I; ISTORE 7; ILOAD 7; LDC -1; IF_ICMPEQ L9; GOTO L10; L10; FRAME FULL [is/hail/codegen/generated/C0 java/lang/Object java/lang/Object scala/collection/IndexedSeq T T is/hail/variant/Genotype I] []; NEW java/lang/Integer; DUP; I",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1705:205,error,error,205,https://hail.is,https://github.com/hail-is/hail/issues/1705,1,['error'],['error']
Availability,"Try to ""read"" a vcf, and get this error:. ```; running: read -i chr22.vcf.bgz; Exception in thread ""main"" java.lang.IllegalArgumentException: requirement failed; at scala.Predef$.require(Predef.scala:221); at org.broadinstitute.hail.variant.VariantSampleMatrix$.read(VariantSampleMatrix.scala:23); at org.broadinstitute.hail.driver.Read$.run(Read.scala:21); at org.broadinstitute.hail.driver.Read$.run(Read.scala:6); at org.broadinstitute.hail.driver.Command.run(Command.scala:59); at org.broadinstitute.hail.driver.Main$$anonfun$main$2$$anonfun$4.apply(Main.scala:182); ...; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/163:34,error,error,34,https://hail.is,https://github.com/hail-is/hail/issues/163,1,['error'],['error']
Availability,"Try to give the user information about the failure. A follow up to this is to give a mode to ignore the error, and filter the variant.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6877:43,failure,failure,43,https://hail.is,https://github.com/hail-is/hail/pull/6877,2,"['error', 'failure']","['error', 'failure']"
Availability,"Trying to annotate a table with a reference genome creates tons of temp files, and ultimately fails with errors like:; ```; Mkdirs failed to create file:/tmp/hail.aHapwOHwB9LA (exists=false, cwd=file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1550247966765_0004/container_1550247966765_0004_02_000051). at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:456); at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:441); at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:929); at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:910); at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:807); at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:796); at is.hail.utils.richUtils.RichHadoopConfiguration$.is$hail$utils$richUtils$RichHadoopConfiguration$$create$extension(RichHadoopConfiguration.scala:24); at is.hail.utils.richUtils.RichHadoopConfiguration$.writeFile$extension(RichHadoopConfiguration.scala:296); at is.hail.io.reference.FASTAReader$$anonfun$setup$1.apply(FASTAReader.scala:45); at is.hail.io.reference.FASTAReader$$anonfun$setup$1.apply(FASTAReader.scala:44); at is.hail.utils.package$.using(package.scala:587); at is.hail.utils.richUtils.RichHadoopConfiguration$.readFile$extension(RichHadoopConfiguration.scala:293); at is.hail.io.reference.FASTAReader$.setup(FASTAReader.scala:44); at is.hail.io.reference.FASTAReader$$anonfun$getLocalFastaFileName$1.apply(FASTAReader.scala:30); at is.hail.io.reference.FASTAReader$$anonfun$getLocalFastaFileName$1.apply(FASTAReader.scala:30); at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:901); at is.hail.io.reference.FASTAReader$.getLocalFastaFileName(FASTAReader.scala:30); at is.hail.io.reference.SerializableReferenceSequenceFile.value$lzycompute(FASTAReader.scala:18); at is.hail.io.reference.SerializableReferenceSequenceFile.value(FASTAReader.scala:17); at is.hail.io.reference.FASTAReader.<init>(FASTAReader.scala:77); at is.hai",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5371:105,error,errors,105,https://hail.is,https://github.com/hail-is/hail/issues/5371,1,['error'],['errors']
Availability,Trying to build on ubuntu ; Welcome to Ubuntu Xenial Xerus (development branch) (GNU/Linux 4.4.0-16-generic x86_64). This tree builds fine on mac using grade installDist. ; On ubuntu it gives the below failure message. We wondered if it might have something to do with case sensitivity issues in file/path naming (mac maintaining case but being case-insensitive). Let me know if you would like more info. ; :compileJava UP-TO-DATE; :compileScala FAILED. FAILURE: Build failed with an exception.; - What went wrong:; A problem was found with the configuration of task ':compileScala'.; > No value has been specified for property 'zincClasspath'.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/275:202,failure,failure,202,https://hail.is,https://github.com/hail-is/hail/issues/275,2,"['FAILURE', 'failure']","['FAILURE', 'failure']"
Availability,Trying to construct a genotype stream fails with assertion error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1976:59,error,error,59,https://hail.is,https://github.com/hail-is/hail/issues/1976,1,['error'],['error']
Availability,"Trying to make it more ergonomic to simply do `python3 -m pytest batch/test/test_batch.py::test_job` (now works without any extra environment variables or configuration). This involved the following changes:; - Deleted of some env vars that are no longer used / can be easily consolidated into existing ones; - Gave defaults to those testing env variables for which there are reasonable defaults. E.g. `DOCKER_ROOT_IMAGE` and `HAIL_GENETICS_HAIL_IMAGE`.; - Pushed other environment variables for which there are not reasonable defaults into the tests that need them. If you run a test that requires `HAIL_CLOUD`, you'll still get an error that that env variable is unset and you should set it. But, if you just want to run a single test that doesn't need `HAIL_CLOUD` it won't get in the way.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12862:633,error,error,633,https://hail.is,https://github.com/hail-is/hail/pull/12862,1,['error'],['error']
Availability,"Trying to run a bunch of 201 aggregators + uniroot on a custom branch (https://github.com/konradjk/hail/tree/freq_filter), and getting:; ```; Traceback (most recent call last):; File ""/tmp/9c7c1cdf3da74749a388ecb2e4365430/generate_frequency_data.py"", line 141, in <module>; try_slack(args.slack_channel, main, args); File ""/tmp/9c7c1cdf3da74749a388ecb2e4365430/pyscripts_CSD0RS.zip/gnomad_hail/utils/slack.py"", line 112, in try_slack; File ""/tmp/9c7c1cdf3da74749a388ecb2e4365430/pyscripts_CSD0RS.zip/gnomad_hail/utils/slack.py"", line 95, in try_slack; File ""/tmp/9c7c1cdf3da74749a388ecb2e4365430/generate_frequency_data.py"", line 121, in main; mt, sample_table = generate_frequency_data(mt, args.subpop, args.downsampling, args.genomes); File ""/tmp/9c7c1cdf3da74749a388ecb2e4365430/generate_frequency_data.py"", line 102, in generate_frequency_data; mt = mt.annotate_rows(freq=frequency_expression); File ""/tmp/9c7c1cdf3da74749a388ecb2e4365430/hail-1e2e8c7e8.zip/hail/matrixtable.py"", line 905, in annotate_rows; File ""/tmp/9c7c1cdf3da74749a388ecb2e4365430/hail-1e2e8c7e8.zip/hail/typecheck/check.py"", line 547, in wrapper; File ""/tmp/9c7c1cdf3da74749a388ecb2e4365430/hail-1e2e8c7e8.zip/hail/matrixtable.py"", line 2893, in _select_rows; File ""/usr/lib/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py"", line 1133, in __call__; File ""/tmp/9c7c1cdf3da74749a388ecb2e4365430/hail-1e2e8c7e8.zip/hail/utils/java.py"", line 196, in deco; hail.utils.java.FatalError: RuntimeException: Method code too large!. Java stack trace:; java.lang.RuntimeException: Method code too large!; 	at is.hail.relocated.org.objectweb.asm.MethodWriter.a(Unknown Source); 	at is.hail.relocated.org.objectweb.asm.ClassWriter.toByteArray(Unknown Source); 	at is.hail.asm4s.FunctionBuilder.classAsBytes(FunctionBuilder.scala:306); 	at is.hail.asm4s.FunctionBuilder.result(FunctionBuilder.scala:340); 	at is.hail.expr.CM.runWithDelayedValues(CM.scala:80); 	at is.hail.expr.Parser$.is$hail$expr$Parser$$evalNoTypeCheck(Parser.s",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3746:709,down,downsampling,709,https://hail.is,https://github.com/hail-is/hail/issues/3746,1,['down'],['downsampling']
Availability,Trying to slowly add more reliability to the `hailctl` CLI. This adds some very basic tests for the `hailctl batch billing` subcommand that mocks the `BatchClient` so it's just testing that command line parsing and yaml dumping don't break. Most of the other noise in this PR is a refactor. I moved `hail/python/test/hailtop/hailctl/config/conftest.py` up a level so I could reuse its `CLIRunner` fixture across all `hailctl` test modules. That fixture sets a new config directory per test so if you use it in a test the test won't accidentally use or modify the user's actual hailctl config.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13490:26,reliab,reliability,26,https://hail.is,https://github.com/hail-is/hail/pull/13490,1,['reliab'],['reliability']
Availability,"Turns out we didn't support `--dry-run` on `dataproc connect`. I'm not totally satisfied with this, as the command that gets printed out isn't runnable, because it will lack quotes around the `--ssh-flag=-D 1000` part. I tried adding the quotes into the command, thinking it would work but just be redundant, but I couldn't get it to work. I suppose I could have the printing logic go through the list and replace that bit with a quoted version. Let me know what you think.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7128:298,redundant,redundant,298,https://hail.is,https://github.com/hail-is/hail/pull/7128,1,['redundant'],['redundant']
Availability,Two big changes. Catch any errors and release the semaphore. Restart failed workers in the concurrent worker pool.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6804:27,error,errors,27,https://hail.is,https://github.com/hail-is/hail/pull/6804,1,['error'],['errors']
Availability,Two rare events is notable and probably indicates an error anyway. Let us prefer; to get information as soon as possible.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11769:53,error,error,53,https://hail.is,https://github.com/hail-is/hail/pull/11769,1,['error'],['error']
Availability,TypeCheck bottom-up instead of top-down.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6002:35,down,down,35,https://hail.is,https://github.com/hail-is/hail/pull/6002,1,['down'],['down']
Availability,"Unclear what changed. GKE release history doesn't specify when Docker was upgraded to 19.03.1. We think Notebook worked in the past. Anyway, the fix is to never specify ""m"" (lowercase m) as the size modifier for a Kubernetes memory limit. Docker silently drops the ""m"" which means the limit is set to a few thousand bytes (e.g. 3500m becomes 3.5kB). The resulting error message is this:; ```; Failed create pod sandbox: rpc error: code = Unknown desc = failed to start sandbox container for pod ""notebook-worker-9l2wq"": Error response from daemon: OCI runtime create failed: container_linux.go:345: starting container process caused ""process_linux.go:303: getting the final child's pid from pipe caused \""read init-p: connection reset by peer\"""": unknown; ```; Which you can see in `kubectl describe pod`:; ```; Warning FailedCreatePodSandBox 73s (x13 over 85s) kubelet, gke-vdc-non-preemptible-pool-5-80798769-kp8n Failed create pod sandbox: rpc error: code = Unknown desc = failed to start sandbox container for pod ""notebook-worker-9l2wq"": Error response from daemon: OCI runtime create failed: container_linux.go:345: starting container process caused ""process_linux.go:303: getting the final child's pid from pipe caused \""read init-p: connection reset by peer\"""": unknown; Normal SandboxChanged 73s (x12 over 84s) kubelet, gke-vdc-non-preemptible-pool-5-80798769-kp8n Pod sandbox changed, it will be killed and re-created.; ```. We narrowed down to this error by trial and error of removing and adding lines of the YAML file. https://github.com/kubernetes/kubernetes/issues/79950. The fix is to use `Mi` not `m`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8165:364,error,error,364,https://hail.is,https://github.com/hail-is/hail/issues/8165,8,"['Error', 'down', 'error']","['Error', 'down', 'error']"
Availability,"Unclear what's wrong, but this k8s container got stuck in container creating. ```; (base) dking@wmb16-359 # k describe pods -n test job-4-7xqf9; Name: job-4-7xqf9; Namespace: test; Node: gke-vdc-non-preemptible-pool-0106a51b-zsmg/10.128.0.5; Start Time: Thu, 17 Jan 2019 16:31:42 -0500; Labels: app=batch-job; hail.is/batch-instance=21706daa42404f5489a53bb5ad22a068; uuid=b4fbcb0d4e2045e8bc4aea6b012ffad6; Annotations: <none>; Status: Pending; IP: ; Containers:; default:; Container ID: ; Image: alpine; Image ID: ; Port: <none>; Host Port: <none>; Command:; sleep; 1; State: Waiting; Reason: ContainerCreating; Ready: False; Restart Count: 0; Environment:; POD_IP: (v1:status.podIP); POD_NAME: job-4-7xqf9 (v1:metadata.name); Mounts:; /var/run/secrets/kubernetes.io/serviceaccount from default-token-85kwr (ro); Conditions:; Type Status; Initialized True ; Ready False ; PodScheduled True ; Volumes:; default-token-85kwr:; Type: Secret (a volume populated by a Secret); SecretName: default-token-85kwr; Optional: false; QoS Class: BestEffort; Node-Selectors: <none>; Tolerations: node.kubernetes.io/not-ready:NoExecute for 300s; node.kubernetes.io/unreachable:NoExecute for 300s; Events:; Type Reason Age From Message; ---- ------ ---- ---- -------; Normal SandboxChanged 11m (x171 over 1h) kubelet, gke-vdc-non-preemptible-pool-0106a51b-zsmg Pod sandbox changed, it will be killed and re-created.; Warning FailedSync 6m kubelet, gke-vdc-non-preemptible-pool-0106a51b-zsmg error determining status: rpc error: code = Unknown desc = Error: No such container: 741291eb67b9026c0fe4ac52d1f5a553ea420f07f5a7d7368c9dba93e707a079; Warning FailedCreatePodSandBox 1m (x203 over 1h) kubelet, gke-vdc-non-preemptible-pool-0106a51b-zsmg Failed create pod sandbox: rpc error: code = Unknown desc = NetworkPlugin kubenet failed to set up pod ""job-4-7xqf9_test"" network: Error adding container to network: failed to allocate for range 0: no IP addresses available in range set: 10.32.3.1-10.32.3.254; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5168:1068,Toler,Tolerations,1068,https://hail.is,https://github.com/hail-is/hail/issues/5168,7,"['Error', 'Toler', 'avail', 'error']","['Error', 'Tolerations', 'available', 'error']"
Availability,"Unexcludes the `hail/` subdirectory from the files the `ruff` linter (not to be confused with the `ruff` formatter) looks at, and fixes the errors it raises.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14150:140,error,errors,140,https://hail.is,https://github.com/hail-is/hail/pull/14150,1,['error'],['errors']
Availability,Update ErrorMessages.md,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1212:7,Error,ErrorMessages,7,https://hail.is,https://github.com/hail-is/hail/pull/1212,1,['Error'],['ErrorMessages']
Availability,Update FAQ ErrorMessages.md on changing SPARK_LOCAL_DIRS,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1027:11,Error,ErrorMessages,11,https://hail.is,https://github.com/hail-is/hail/pull/1027,1,['Error'],['ErrorMessages']
Availability,"Updated db.py to allow user to specify region as shown below. `db = hl.experimental.DB(region='us')`; `mt = db.annotate_rows_db(mt, 'gnomad_lof_metrics')`. Data will be accessed from the requester pays bucket in the region specified by the user, available regions are `'us'` and `'eu'`. Modified the following to include region parameter:; - `DB` class ; - `Dataset.from_name_and_json()`. Added method `DatasetVersion.insert_region()` to replace `'{region}'` in `DatasetVersion.url` instance variable with the specified region.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9410:246,avail,available,246,https://hail.is,https://github.com/hail-is/hail/pull/9410,1,['avail'],['available']
Availability,"Updated db.py to require user to specify region as shown below, so that data will be accessed from the requester pays bucket in the region specified by the user, available regions are `'us'` and `'eu'`. . `db = hl.experimental.DB(region='us')`; `mt = db.annotate_rows_db(mt, 'gnomad_lof_metrics')`. Entries in the `annotation_db.json` file were modified to the following format:. ```; ""dataset_name"": { ""description"": ""some description here"",; ""key_properties"": [],; ""url"": ""https://www.someurlhere.com"",; ""versions"": [{""url"": {""eu"": ""gs://hail-datasets-eu/dataset"",; ""us"": ""gs://hail-datasets-us/dataset""},; ""version"": ""one_version""},; {""url"": {""eu"": ""gs://hail-datasets-eu/dataset"",; ""us"": ""gs://hail-datasets-us/dataset""},; ""version"": ""another_version""}]}; ```. The `annotation_db.json` file is now used by the `load_dataset()` function in `datasets.py` as well, any dataset in the JSON file should now be able to be loaded this way. Made changes to the following:; - `DB` class now requires a `region` parameter.; - `Dataset.from_name_and_json()` has had a `custom_config` parameter added that indicates whether or not the user has supplied their own `config` or `url`. `Dataset.from_name_and_json()` now calls `DatasetVersion.get_region()` method to retrieve the dataset from the bucket in the selected region if `custom_config` is `False`. ; - The `DatasetVersion.get_region()` method takes the dataset `name`, a list of `DatasetVersion` objects, and a `region`, and returns a list of the versions that are available for that region. This method calls the instance method `in_region()` to check if the dataset is available in the requested region.; - If `in_region()` determines the desired region is not available for some dataset that otherwise is available in another region, it will raise a warning. If user still tries to call `db.annotate_rows_db()` using a dataset unavailable in their region, then it will get caught by the `_check_availability` instance method in the `DB` class and rai",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9496:162,avail,available,162,https://hail.is,https://github.com/hail-is/hail/pull/9496,1,['avail'],['available']
Availability,"Updated the datasets/annotation_db.json config file with datasets currently available in bucket at gs://hail-datasets-hail-data, also updated docs to reflect the datasets available via the `load_datasets()` function.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9331:76,avail,available,76,https://hail.is,https://github.com/hail-is/hail/pull/9331,2,['avail'],['available']
Availability,"Updates the requirements on [avro](https://github.com/apache/avro) to permit the latest version.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/apache/avro/releases"">avro's releases</a>.</em></p>; <blockquote>; <h2>Apache Avro 1.11.0</h2>; <p>The Apache Avro community is pleased to announce the release of Avro 1.11.0!</p>; <p>All signed release artifacts, signatures and verification instructions can; be found here: <a href=""https://avro.apache.org/releases.html"">https://avro.apache.org/releases.html</a></p>; <p>This release includes 120 Jira issues, including some interesting features:</p>; <p>Specification: AVRO-3212 Support documentation tags for FIXED types; C#: AVRO-2961 Support dotnet framework 5.0; C#: AVRO-3225 Prevent memory errors when deserializing untrusted data; C++: AVRO-2923 Logical type corrections; Java: AVRO-2863 Support Avro core on android; Javascript: AVRO-3131 Drop support for node.js 10; Perl: AVRO-3190 Fix error when reading from EOF; Python: AVRO-2906 Improved performance validating deep record data; Python: AVRO-2914 Drop Python 2 support; Python: AVRO-3004 Drop Python 3.5 support; Ruby: AVRO-3108 Drop Ruby 2.5 support</p>; <p>For the first time, the 1.11.0 release includes experimental support for; Rust. Work is continuing on this donated SDK, but we have not versioned and; published official artifacts for this release.</p>; <p>Python: The avro package fully supports Python 3. We will no longer publish a; separate avro-python3 package</p>; <p>And of course upgraded dependencies to latest versions, CVE fixes and more:; <a href=""https://issues.apache.org/jira/issues/?jql=project%3DAVRO%20AND%20fixVersion%3D1.11.0"">https://issues.apache.org/jira/issues/?jql=project%3DAVRO%20AND%20fixVersion%3D1.11.0</a></p>; <p>The link to all fixed JIRA issues and a brief summary can be found at:; <a href=""https://github.com/apache/avro/releases/tag/release-1.11.0"">https://github.com/apache/avro/releases/tag/relea",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11475:790,error,errors,790,https://hail.is,https://github.com/hail-is/hail/pull/11475,1,['error'],['errors']
Availability,"Updates the requirements on [pandas](https://github.com/pandas-dev/pandas) to permit the latest version.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/pandas-dev/pandas/releases"">pandas's releases</a>.</em></p>; <blockquote>; <h2>Pandas 1.4.1</h2>; <p>This is the first patch release in the 1.4.x series and includes some regression fixes and bug fixes. We recommend that all users upgrade to this version.</p>; <p>See the <a href=""https://pandas.pydata.org/pandas-docs/version/1.4.1/whatsnew/v1.4.1.html"">full whatsnew</a> for a list of all the changes.</p>; <p>The release will be available on the defaults and conda-forge channels:</p>; <pre><code>conda install pandas; </code></pre>; <p>Or via PyPI:</p>; <pre><code>python3 -m pip install --upgrade pandas; </code></pre>; <p>Please report any issues with the release on the <a href=""https://github.com/pandas-dev/pandas/issues"">pandas issue tracker</a>.</p>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/pandas-dev/pandas/commit/06d230151e6f18fdb8139d09abf539867a8cd481""><code>06d2301</code></a> RLS: 1.4.1</li>; <li><a href=""https://github.com/pandas-dev/pandas/commit/47e3b409deb41f18e30e447579cba3a246db050e""><code>47e3b40</code></a> Backport PR <a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/45587"">#45587</a>: DOC: append deprecation (<a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/45942"">#45942</a>)</li>; <li><a href=""https://github.com/pandas-dev/pandas/commit/f61dfde6abbe33e143e83c6685e4b3c1c488f92b""><code>f61dfde</code></a> Backport PR <a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/45936"">#45936</a>: DOC: 1.4.1 release date (<a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/45941"">#45941</a>)</li>; <li><a href=""https://github.com/pandas-dev/pandas/commit/28f5e9093377f72742b60e458949b7b4714141ed""><code>28f5e90</code></a> B",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11521:631,avail,available,631,https://hail.is,https://github.com/hail-is/hail/pull/11521,1,['avail'],['available']
Availability,"Users/dking/hail-20190327-1827-0.2.11-cf54f08305d1.log; Traceback (most recent call last):; File ""<stdin>"", line 4, in <module>; File ""/Users/dking/anaconda2/envs/hail/lib/python3.6/site-packages/hail/matrixtable.py"", line 2371, in count; return (self.count_rows(), self.count_cols()); File ""/Users/dking/anaconda2/envs/hail/lib/python3.6/site-packages/hail/matrixtable.py"", line 2331, in count_rows; TableCount(MatrixRowsTable(self._mir))); File ""/Users/dking/anaconda2/envs/hail/lib/python3.6/site-packages/hail/backend/backend.py"", line 94, in execute; self._to_java_ir(ir))); File ""/Users/dking/anaconda2/envs/hail/lib/python3.6/site-packages/py4j/java_gateway.py"", line 1257, in __call__; answer, self.gateway_client, self.target_id, self.name); File ""/Users/dking/anaconda2/envs/hail/lib/python3.6/site-packages/hail/utils/java.py"", line 227, in deco; 'Error summary: %s' % (deepest, full, hail.__version__, deepest)) from None; hail.utils.java.FatalError: HailException: Error parsing row fields in row 0:; expected 5 fields but only 5 found.; File: foo; Line:; 7	75216143	75216143	C/T	+. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 1.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1.0 (TID 1, localhost, executor driver): is.hail.utils.HailException: foo: Error parsing row fields in row 0:; expected 5 fields but only 5 found.; File: foo; Line:; 7	75216143	75216143	C/T	+; offending line: 7	75216143	75216143	C/T	+; 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:20); 	at is.hail.utils.package$.fatal(package.scala:28); 	at is.hail.utils.Context.wrapException(Context.scala:19); 	at is.hail.utils.WithContext.wrap(Context.scala:43); 	at is.hail.io.LoadMatrix$$anonfun$16$$anonfun$apply$6.apply(LoadMatrix.scala:377); 	at is.hail.io.LoadMatrix$$anonfun$16$$anonfun$apply$6.apply(LoadMatrix.scala:375); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at scala.collection.Iterator$$anon",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5718:2322,Error,Error,2322,https://hail.is,https://github.com/hail-is/hail/issues/5718,1,['Error'],['Error']
Availability,"Using hail 0.2.32, `hailctl dataproc submit` results in the following error:. ```; hailctl dataproc submit hail-test {python file} -- {arguments to script}; Submitting to cluster 'hail-test'...; gcloud command:; gcloud dataproc jobs submit pyspark {python file} \; --cluster=hail-test \; --files= \; --py-files=/var/folders/7y/hvrzyxts3xg74r3m2jbq0kc0zt3g3z/T/pyscripts_srh2ze4a.zip \; --properties= \; -- \; {arguments to script}; ERROR: (gcloud.dataproc.jobs.submit.pyspark) The required property [region] is not currently set.; It can be set on a per-command basis by re-running your command with the [--region] flag. You may set it for your current workspace by running:. $ gcloud config set dataproc/region VALUE. or it can be set temporarily by the environment variable [CLOUDSDK_DATAPROC_REGION]; Traceback (most recent call last):; File ""/Users/aarong/Documents/gtex-wgs/.devenv/bin/hailctl"", line 8, in <module>; sys.exit(main()); File ""/Users/aarong/Documents/gtex-wgs/.devenv/lib/python3.7/site-packages/hailtop/hailctl/__main__.py"", line 94, in main; cli.main(args); File ""/Users/aarong/Documents/gtex-wgs/.devenv/lib/python3.7/site-packages/hailtop/hailctl/dataproc/cli.py"", line 107, in main; jmp[args.module].main(args, pass_through_args); File ""/Users/aarong/Documents/gtex-wgs/.devenv/lib/python3.7/site-packages/hailtop/hailctl/dataproc/submit.py"", line 78, in main; check_call(cmd); File ""/usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/subprocess.py"", line 363, in check_call; raise CalledProcessError(retcode, cmd); subprocess.CalledProcessError; ``` . However, adding `--region us-central1` to any location in the argument string to hailctl dataproc submit results in the argument being picked up as an input to the script, not to the underlying gcloud command",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8078:70,error,error,70,https://hail.is,https://github.com/hail-is/hail/issues/8078,2,"['ERROR', 'error']","['ERROR', 'error']"
Availability,"Using this TSV,; ```; id	foo_1	foo_2	foo_3	bar_1	bar_2	bar_3; a	1	2	3	4	5	6; b	7	8	9	10	11	12; c	13	14	15	16	17	18; ```. This code; ```; import hail as hl. ds = hl.import_matrix_table(""test.tsv"", row_fields={""id"": hl.tstr}, entry_type=hl.tfloat); ds = ds.annotate_cols(prefix=ds.col_id.split(""_"")[0]). t = ds.group_cols_by(ds.prefix).aggregate(**{"""": hl.agg.approx_median(ds.x)}).make_table(); t.show(); ```. Throws an error `HailException: approx_cdf already initialized` on Hail 0.2.28 and 0.2.30. On Hail 0.2.26, that code worked and output; ```; +--------+-----+----------+----------+; | row_id | id | bar | foo |; +--------+-----+----------+----------+; | int64 | str | float64 | float64 |; +--------+-----+----------+----------+; | 0 | ""a"" | 5.00e+00 | 2.00e+00 |; | 1 | ""b"" | 1.10e+01 | 8.00e+00 |; | 2 | ""c"" | 1.70e+01 | 1.40e+01 |; +--------+-----+----------+----------+; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7824:419,error,error,419,https://hail.is,https://github.com/hail-is/hail/issues/7824,1,['error'],['error']
Availability,VCF combiner assertion error about schema mismatches,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/10813:23,error,error,23,https://hail.is,https://github.com/hail-is/hail/issues/10813,1,['error'],['error']
Availability,VD$.$anonfun$getKeyInfo$2(RVD.scala:1030); 	at is.hail.rvd.RVD$.$anonfun$getKeyInfo$2$adapted(RVD.scala:1029); 	at is.hail.sparkextras.ContextRDD.$anonfun$crunJobWithIndex$1(ContextRDD.scala:242); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90); 	at org.apache.spark.scheduler.Task.run(Task.scala:136); 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548); 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551); 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128); 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628); 	at java.base/java.lang.Thread.run(Thread.java:829); Caused by: is.hail.utils.HailException: cannot set missing field for required type +PFloat64; 	at is.hail.utils.ErrorHandling.fatal(ErrorHandling.scala:18); 	at is.hail.utils.ErrorHandling.fatal$(ErrorHandling.scala:18); 	at is.hail.utils.package$.fatal(package.scala:81); 	at is.hail.annotations.RegionValueBuilder.setMissing(RegionValueBuilder.scala:207); 	at is.hail.io.vcf.VCFLine.parseAddInfoArrayDouble(LoadVCF.scala:1034); 	at is.hail.io.vcf.VCFLine.parseAddInfoField(LoadVCF.scala:1055); 	at is.hail.io.vcf.VCFLine.addInfoField(LoadVCF.scala:1075); 	at is.hail.io.vcf.VCFLine.parseAddInfo(LoadVCF.scala:1112); 	at is.hail.io.vcf.LoadVCF$.parseLineInner(LoadVCF.scala:1541); 	at is.hail.io.vcf.LoadVCF$.parseLine(LoadVCF.scala:1409); 	at is.hail.io.vcf.MatrixVCFReader.$anonfun$executeGeneric$7(LoadVCF.scala:1916); 	... 21 more. Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2673); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2609); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2608); 	at scala.collection.mutable.ResizableArray.foreach(R,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14102:9212,Error,ErrorHandling,9212,https://hail.is,https://github.com/hail-is/hail/issues/14102,1,['Error'],['ErrorHandling']
Availability,"VDS.write(VariantSampleMatrix.scala:1073); 	at org.broadinstitute.hail.driver.Write$.run(Write.scala:35); 	at org.broadinstitute.hail.driver.Write$.run(Write.scala:6); 	at org.broadinstitute.hail.driver.Command.runCommand(Command.scala:259); 	at org.broadinstitute.hail.driver.Command.run(Command.scala:264); 	at sun.reflect.GeneratedMethodAccessor54.invoke(Unknown Source); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:280); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:214); 	at java.lang.Thread.run(Thread.java:745); Caused by: org.apache.spark.SparkException: Job aborted due to stage failure: Task 35 in stage 7.0 failed 20 times, most recent failure: Lost task 35.19 in stage 7.0 (TID 6963, gnomad-prod-sw-m8lk.c.broad-mpg-gnomad.internal): org.apache.spark.SparkException: Task failed while writing rows; 	at org.apache.spark.sql.execution.datasources.DefaultWriterContainer.writeRows(WriterContainer.scala:261); 	at org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand$$anonfun$run$1$$anonfun$apply$mcV$sp$1.apply(InsertIntoHadoopFsRelationCommand.scala:143); 	at org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand$$anonfun$run$1$$anonfun$apply$mcV$sp$1.apply(InsertIntoHadoopFsRelationCommand.scala:143); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); 	at org.apache.spark.scheduler.Task.run(Task.scala:86); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.Thread",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1202:3892,failure,failure,3892,https://hail.is,https://github.com/hail-is/hail/issues/1202,1,['failure'],['failure']
Availability,VEP error - Can't zip RDDs with unequal numbers of partitions,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2666:4,error,error,4,https://hail.is,https://github.com/hail-is/hail/issues/2666,1,['error'],['error']
Availability,VEP tolerates invalid json,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4465:4,toler,tolerates,4,https://hail.is,https://github.com/hail-is/hail/pull/4465,1,['toler'],['tolerates']
Availability,"VMs or use a single multi-threaded JVM, we'll need to ensure the top-level; ClassLoader *does not have Hail on its classpath*. I looked briefly at this approach and found it; more work than the current approach. ---. My apologies for eliminating JVMProcess in this PR. It's an unrelated change which facilitated my; understanding of worker.py. I essentially inlined JVMProcess into JVMJob and eliminated any duplicative; code. ---. After making this change I restored the tests. Some tests had bitrotted. In the process of fixing; those tests, I found a few other bugs. Fixing these lower-level bugs unlocked a number of new; tests. One test (which was added since the service tests were removed) had to be marked as failing. Some; Hail operations rely on writing to the local file system. Implementing that properly in the Query; Worker will take some thought. Here are the bugs I fixed:. 1. Correct the error message raised when tests are run in a non-main thread (we look for this; message and start an event loop for Hail's async code because asyncio refuses to start an event; loop in a non-main thread). 2. Use a `SafeRow` to copy the globals data out of a Region and into durable, GC'ed objects. 3. Re-enable serialization of GoogleStorageFS (including its private key, which we really shouldn't; do; Tim is working on it), which was broken (presumably) when we changed Scala versions. The; `var` modifier ensures the name is compiled as a JVM field. 4. Correctly convert from a `Byte` to an `Int`. By default `Byte` to `Int` conversion (which is done; automatically when you return a `Byte` from a function whose return type is `Int`) is; sign-preserving. That means that the byte `0000 1111` is converted to the `Int` 15 and the byte; `1000 1111` is converted to the `Int` -113. The contract of; [`InputStream.read`](https://docs.oracle.com/javase/8/docs/api/java/io/InputStream.html#read--); is to return the unsigned integeral value of the next `Byte` or `-1` if we've reached the end of; t",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10314:1842,error,error,1842,https://hail.is,https://github.com/hail-is/hail/pull/10314,1,['error'],['error']
Availability,Validation code was not updated when adding azure https support. Made this check a bit more robust and tested locally. Resolves #13049,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13051:92,robust,robust,92,https://hail.is,https://github.com/hail-is/hail/pull/13051,1,['robust'],['robust']
Availability,VariantSampleMatrix$$anonfun$1.apply(VariantSampleMatrix.scala:72); 	at is.hail.utils.richUtils.RichHadoopConfiguration$.is$hail$utils$richUtils$RichHadoopConfiguration$$using$extension(RichHadoopConfiguration.scala:226); 	at is.hail.utils.richUtils.RichHadoopConfiguration$.readFile$extension(RichHadoopConfiguration.scala:251); 	at is.hail.variant.VariantSampleMatrix$.readFileMetadata(VariantSampleMatrix.scala:72); 	at is.hail.variant.VariantSampleMatrix$.read(VariantSampleMatrix.scala:51); 	at is.hail.HailContext$$anonfun$10.apply(HailContext.scala:434); 	at is.hail.HailContext$$anonfun$10.apply(HailContext.scala:433); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); 	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186); 	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); 	at scala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:186); 	at is.hail.HailContext.readAll(HailContext.scala:433); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:280); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:214); 	at java.lang.Thread.run(Thread.java:745). Hail version: devel-6ee2919; Error summary: MappingException: Did not find value which can be converted into java.lang.String; ```,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2159:8640,Error,Error,8640,https://hail.is,https://github.com/hail-is/hail/issues/2159,1,['Error'],['Error']
Availability,"Version:; Apache Spark version 2.4.3; Hail version 0.2.19-c6ec8b76eb26. When exporting a table, the following error occurs when running on a yarn cluster. It does not occur when running locally. Any suggestions on this?. ```; Container exited with a non-zero exit code 127. Error file: prelaunch.err.; Last 4096 bytes of prelaunch.err :; Last 4096 bytes of stderr :; SLF4J: Class path contains multiple SLF4J bindings.; SLF4J: Found binding in [jar:file:/data04/hadoop/yarn/local/usercache/farrell/filecache/291/__spark_libs__4347827829503170766.zip/slf4j-log4j12-1.7.16.jar!/org/slf4j/impl/StaticLoggerBinder.class]; SLF4J: Found binding in [jar:file:/usr/hdp/2.6.5.0-292/hadoop/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]; SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.; SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]; 19/09/06 15:54:22 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 19/09/06 15:54:30 WARN shortcircuit.DomainSocketFactory: The short-circuit local reads feature cannot be used because libhadoop cannot be loaded.; /usr/java/default/bin/java: symbol lookup error: /data01/hadoop/yarn/local/usercache/farrell/appcache/application_1565788829616_0098/container_e2451_1565788829616_0098_01_000011/tmp/jniloader3452911880890326608netlib-native_system-linux-x86_64.so: undefined symbol: cblas_dgemv. ```; -----------------------------------------------------------------------------",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7008:110,error,error,110,https://hail.is,https://github.com/hail-is/hail/issues/7008,3,"['Error', 'error']","['Error', 'error']"
Availability,"Very preliminary. Builds test instead of main by default, output looks like this:. ```; ~/hail/libhail/build$ ./test; RUN test_int64_value; RUN test_int64_value OK; RUN test_int32_value; RUN test_int32_value OK; RUN test_bool_value; RUN test_bool_value OK; ...; ```. Added `std::string render(...)` to format module. Added some format tests. Added `CHECK_EQ` macro that prints the details on failure:. ```; ../src/hail/test.hpp:42: assert failed:; CHECK_EQ(render(FormatAddress(nullptr)), ""0x0000000000000000""); with values:; CHECK_EQ(0000000000000000, 0x0000000000000000); ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10231:392,failure,failure,392,https://hail.is,https://github.com/hail-is/hail/pull/10231,1,['failure'],['failure']
Availability,"WIP pull request. - [x] Write tests to replicate existing errors. - [ ] Write test to replicate stalled request. - [ ] Resolve stalled request. However, I think we should consider writing a more complete solution to this. As far as I can tell, our use of threads is fragile; following Flask recommendations w.r.t reliance on production-ready WSGI server seems a good idea. Happy to take that on. I'd also like to move away from Flask for API stuff. While not likely to be a bottleneck for many moons, there are solutions rumored to be far faster (Falcon, esp using Cpython).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5065:58,error,errors,58,https://hail.is,https://github.com/hail-is/hail/pull/5065,1,['error'],['errors']
Availability,"Was throwing exception failures. Return optional by default. Handle; TInt32 since there can be two TInt32, required and optional.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2455:23,failure,failures,23,https://hail.is,https://github.com/hail-is/hail/pull/2455,1,['failure'],['failures']
Availability,Wasn't sure if this should raise an error or just continue.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6539:36,error,error,36,https://hail.is,https://github.com/hail-is/hail/pull/6539,1,['error'],['error']
Availability,We almost always want to raise an error on a bad status.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9864:34,error,error,34,https://hail.is,https://github.com/hail-is/hail/pull/9864,1,['error'],['error']
Availability,"We always ensure that `cleanup` is run, but in order to ensure that `post_job_complete` is run we need to ensure we get through any computation in cleanup and `mark_complete` that could potentially hang. So we add timeouts to any yield points in those functions and broadly catch exceptions so we always continue in the cleanup/mark_complete process regardless of failure.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12944:364,failure,failure,364,https://hail.is,https://github.com/hail-is/hail/pull/12944,1,['failure'],['failure']
Availability,"We apparently did not exercise this code path much before I fixed batch to treat ImagePullBackOff as failure. Really confusing error message because `write_gs_file` returns `None` which is not iterable so you get a type error on line 565. The real issue is that you're trying to deconstruct a pair as `uri, err` and you received `None`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6810:101,failure,failure,101,https://hail.is,https://github.com/hail-is/hail/pull/6810,3,"['error', 'failure']","['error', 'failure']"
Availability,We are down to 164 docs failures and I am tired. I will work on it more another time. Then we will be able to enable nitpicky and our docs will never have broken links.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9403:7,down,down,7,https://hail.is,https://github.com/hail-is/hail/pull/9403,2,"['down', 'failure']","['down', 'failures']"
Availability,"We are increasingly seeing errors from ""Connection reset"" which we switched from ""transient"" to ""retry once"". The current code makes it impossible to determine if we are correctly retrying this error once. If we see that there are a lot of ""Connection reset"" errors that happen twice we should perhaps change ""retry once"" to ""retry five times"" or use a more generous delay.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12984:27,error,errors,27,https://hail.is,https://github.com/hail-is/hail/pull/12984,3,['error'],"['error', 'errors']"
Availability,We can directly download the key and specify the repository. I used these instructions:; - https://wiki.debian.org/DebianRepository/UseThirdParty; - https://launchpad.net/~deadsnakes/+archive/ubuntu/ppa. This builds in like 2 minutes rather than 4. The frontend part avoids issues in downstream docker files where the installer might try to interact with the user. I noticed that some package was updated and now pulls in `tzdata` which asks you to select a timezone at install-time (if Debian frontend is interactive).,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10356:16,down,download,16,https://hail.is,https://github.com/hail-is/hail/pull/10356,2,['down'],"['download', 'downstream']"
Availability,"We cancel in two cases:; 1. A (dev|) deploy failed.; 2. A batch was found open but unknown to us. In the former case, we should delete the batch. The batch contains no extra information; everything we need to know is in the failure message. In the latter case, an open batch does not cost us anything and; cannot be cancelled anyway, so we choose to ignore them. Such a batch; should only come into existence when CI dies in the middle of submission; which should be quite rare.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9725:224,failure,failure,224,https://hail.is,https://github.com/hail-is/hail/pull/9725,1,['failure'],['failure']
Availability,"We currently have several hail sparse matrix tables that contain up to 10,000 aggregated gVCF files that we aggregated using run_combiner(). We are trying to merge these tables together with a script that makes use of your combine_gvcfs function that is defined in your experimental vcf combiner library. We have successfully succeeded in doing this for merging multiple sparse matrix table into a final table of around 18,000 gVCFs. We are now trying to do this for just under 110,00 gVCFs. The script runs for a while and seems to fail at the very end. Based on the logs, it looks like it is writing to output when it fails. We monitored our resources on google cloud and there is not an issue with cluster CPU or memory usage. We believe the problem stems from not having enough memory in the individual executors at this stage. We are currently using the default of:. spark.executor.memory=10117m; spark.executor.memoryOverhead=15175m. We would like to scale this up and re-run. Do you have any recommended settings for a job of this size?. For reference, below is the error message that we received. Thank you in advance.; ````; Hail version: 0.2.81-edeb70bc789c; Error summary: SparkException: Job aborted due to stage failure: Task 2476 in stage 0.0 failed 20 times, most recent failure: Lost task 2476.20 in stage 0.0 (TID 6571) (<clusterinfo>.internal executor 1128): ExecutorLostFailure (executor 1128 exited caused by one of the running tasks) Reason: Container from a bad node: container_1659731953912_0002_01_001691 on host: cluster-himem-w-0.c.gbsc-gcp-project.internal. Exit status: 143. Diagnostics: [2022-08-10 20:11:38.904]Container killed on request. Exit code is 143; [2022-08-10 20:11:38.904]Container exited with a non-zero exit code 143. ; [2022-08-10 20:11:38.905]Killed by external signal-; ````",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12083:1073,error,error,1073,https://hail.is,https://github.com/hail-is/hail/issues/12083,4,"['Error', 'error', 'failure']","['Error', 'error', 'failure']"
Availability,"We do not yet have pyright running on the Hail python package nor the tests. Without this change, I get failures on push.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14124:104,failure,failures,104,https://hail.is,https://github.com/hail-is/hail/pull/14124,1,['failure'],['failures']
Availability,We don't have any examples here: https://hail.is/docs/0.2/aggregators.html?highlight=filter#hail.expr.aggregators.downsample,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8241:114,down,downsample,114,https://hail.is,https://github.com/hail-is/hail/issues/8241,1,['down'],['downsample']
Availability,We get a lot of errors about files that already exist. Hail commands are usually not retryable because there are file paths that might have been partly written to. This tightly scopes the retries to just the I/O. It also avoids keeping the output stream open for a long period of time.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13152:16,error,errors,16,https://hail.is,https://github.com/hail-is/hail/pull/13152,1,['error'],['errors']
Availability,"We get a lot of spurious Grafana alerts because batch-driver has unclosed `aiohttp.ClientSession` objects. `aiohttp` can [report the creation location](https://github.com/aio-libs/aiohttp/blob/master/aiohttp/client.py#L242-L247), but only when aysncio is in debug mode. I am hesitant to enable debug mode because I suspect it will slow down everything by grabbing stack traces for every coroutine (so that it can report an error later). I adapted the code from the linked asyncio code and tested it as follows:. ```; In [1]: import aiohttp; ...: import traceback; ...: import sys; ...:; ...: oldinit = aiohttp.ClientSession.__init__; ...: def newinit(self, *args, **kwargs):; ...: oldinit(self, *args, **kwargs); ...: self._source_traceback: Optional[; ...: traceback.StackSummary; ...: ] = traceback.extract_stack(sys._getframe(1)); ...: aiohttp.ClientSession.__init__ = newinit. In [2]: aiohttp.ClientSession(); <ipython-input-1-028690903e5f>:7: DeprecationWarning: The object should be created within an async function; oldinit(self, *args, **kwargs); Out[2]: <aiohttp.client.ClientSession at 0x104ab3850>. In [3]: aiohttp.ClientSession(); <ipython-input-1-028690903e5f>:7: DeprecationWarning: The object should be created within an async function; oldinit(self, *args, **kwargs); Out[3]: <aiohttp.client.ClientSession at 0x104dac8b0>. In [4]: aiohttp.ClientSession(); <ipython-input-1-028690903e5f>:7: DeprecationWarning: The object should be created within an async function; oldinit(self, *args, **kwargs); Out[4]: <aiohttp.client.ClientSession at 0x104daeec0>. In [5]:. Do you really want to exit ([y]/n)? y; Unclosed client session; client_session: <aiohttp.client.ClientSession object at 0x104ab3850>; source_traceback: Object created at (most recent call last):; File ""/Users/dking/miniconda3/bin/ipython"", line 8, in <module>; sys.exit(start_ipython()); File ""/Users/dking/miniconda3/lib/python3.10/site-packages/IPython/__init__.py"", line 128, in start_ipython; return launch_new_instance(",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13421:336,down,down,336,https://hail.is,https://github.com/hail-is/hail/pull/13421,2,"['down', 'error']","['down', 'error']"
Availability,We got an error because a BatchBuilder has no id attribute,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8121:10,error,error,10,https://hail.is,https://github.com/hail-is/hail/pull/8121,1,['error'],['error']
Availability,"We had a couple PRs fail because the database reached its [max connections](https://portal.azure.com/#@haildev.onmicrosoft.com/resource/subscriptions/22cd45fe-f996-4c51-af67-ef329d977519/resourceGroups/haildev/providers/Microsoft.DBforMySQL/servers/db-393222c4/metrics). We should probably be resilient to this, but I figured we should be able to handle our normal PR load. I also checked GCP and their default is 4k. Azure sets its cap at 1250. I haven't applied any terraform since you've made your changes. Is that safe to do?",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11329:293,resilien,resilient,293,https://hail.is,https://github.com/hail-is/hail/pull/11329,1,['resilien'],['resilient']
Availability,We have configured curl to retry so we should always prefer it to wget. I also; fixed that long-standing mistake I made when I added retry-all-errors before; it was supported in our version of curl.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11649:143,error,errors,143,https://hail.is,https://github.com/hail-is/hail/pull/11649,1,['error'],['errors']
Availability,"We have some problem with running nirvana in hail and we use the sample file of GWAS Tutorial. Code: ; hl.utils.get_1kg('data/'); vcfVds = hl.import_vcf('data/1kg.vcf.bgz', min_partitions=8); vds = hl.nirvana(vcfVds,'data/nirvana.properties'). Version:; Running on Apache Spark version 2.2.1; Hail version: 0.2.10-ceb85fc87544. We got this error massage:; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""</usr/local/lib/python3.6/dist-packages/decorator.py:decorator-gen-1226>"", line 2, in nirvana; File ""/seqslab/hail/hail/build/distributions/hail-python.zip/hail/typecheck/check.py"", line 561, in wrapper; File ""/seqslab/hail/hail/build/distributions/hail-python.zip/hail/methods/qc.py"", line 860, in nirvana; File ""/usr/local/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py"", line 1133, in __call__; File ""/seqslab/hail/hail/build/distributions/hail-python.zip/hail/utils/java.py"", line 227, in deco; hail.utils.java.FatalError: AssertionError: assertion failed. Java stack trace:; java.lang.AssertionError: assertion failed; at scala.Predef$.assert(Predef.scala:156); at is.hail.methods.Nirvana$.annotate(Nirvana.scala:361); at is.hail.methods.Nirvana$.apply(Nirvana.scala:487); at is.hail.methods.Nirvana.apply(Nirvana.scala); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); at py4j.Gateway.invoke(Gateway.java:280); at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); at py4j.commands.CallCommand.execute(CallCommand.java:79); at py4j.GatewayConnection.run(GatewayConnection.java:214); at java.lang.Thread.run(Thread.java:748). Hail version: 0.2.10-ceb85fc",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5657:340,error,error,340,https://hail.is,https://github.com/hail-is/hail/issues/5657,1,['error'],['error']
Availability,We have to mirror a lot of our utilities across python and scala. Looks like this error never made it to python and we just hadn't encountered it in our python client until a user hit it yesterday.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12170:82,error,error,82,https://hail.is,https://github.com/hail-is/hail/pull/12170,1,['error'],['error']
Availability,"We mix the two right now, with most of the new code using quotes. I; feel that quotes are a better solution given the prevalence of markdown; editors (like Zulip) where copy-pasting an error message with backticks; leads to badly formatted renderings. cc @cseed who I believe favored the use of the backtick style in the first place.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5761:185,error,error,185,https://hail.is,https://github.com/hail-is/hail/pull/5761,1,['error'],['error']
Availability,"We need at least one pool without taints to schedule the kube-system services (e.g. dns). Therefore, I propose:; - make the non-preemptible pool untainted,; - keep taint on preemptibles so kube-system pods are not scheduled there,; - and keep tolerations for preemptible pods,; - use nodeSelector to force preemptible pods to be scheduled on the preemptible pool. In fact, I put nodeSelectos on all pods, although it isn't strictly necessary for non-preemptible pods. Sound good?",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7784:243,toler,tolerations,243,https://hail.is,https://github.com/hail-is/hail/pull/7784,1,['toler'],['tolerations']
Availability,"We observed some sporadic failures, but the error was always less than .011. This raises the tolerance to .015, which should be a comfortable margin.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14058:26,failure,failures,26,https://hail.is,https://github.com/hail-is/hail/pull/14058,3,"['error', 'failure', 'toler']","['error', 'failures', 'tolerance']"
Availability,"We only have `make` commands for running `pylint` on subdirectories that have been kept up to date with its rules, but the `pylintrc` doesn't actually contain any indication of which subdirectories should be ignored when running `pylint`. This makes the use of language servers that run `pylint` on the file that's open frustrating, as files in the ignored subdirectories will often be full of `pylint` suggestions. This change adds the relevant subdirectories to the `pylintrc` file. Note that this does not necessarily enable us to run `pylint` directly on those subdirectories with the equivalent `make` commands to the ones that already exist, because there is no way that I've found to make `pylint` ignore the `__init__.py` file of whatever module it's being run on, so running it on `hail/python/hail`, for example, produces many errors.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14060:837,error,errors,837,https://hail.is,https://github.com/hail-is/hail/pull/14060,1,['error'],['errors']
Availability,"We probably should have better retry logic, but hopefully this will alleviate some of the errors in the short term.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11883:90,error,errors,90,https://hail.is,https://github.com/hail-is/hail/pull/11883,1,['error'],['errors']
Availability,"We recently encountered a batch submission that eventually failed after numerous errors like this one  but nonetheless submitted a new batch containing zero jobs. ```; []; File ""/usr/local/lib/python3.10/site-packages/hailtop/utils/utils.py"", line 792, in retry_transient_errors; return await retry_transient_errors_with_debug_string('', 0, f, *args, **kwargs); File ""/usr/local/lib/python3.10/site-packages/hailtop/utils/utils.py"", line 834, in retry_transient_errors_with_debug_string; st = ''.join(traceback.format_stack()); . The most recent error was <class 'hailtop.httpx.ClientResponseError'> 500, message='Internal Server Error', url=URL('http://batch.hail/api/v1alpha/batches/485962/updates/1/jobs/create') body='500 Internal Server Error\n\nServer got itself in trouble'. ; Traceback (most recent call last):; File ""/usr/local/lib/python3.10/site-packages/hailtop/utils/utils.py"", line 809, in retry_transient_errors_with_debug_string; return await f(*args, **kwargs); File ""/usr/local/lib/python3.10/site-packages/hailtop/aiocloud/common/session.py"", line 117, in _request_with_valid_authn; return await self._http_session.request(method, url, **kwargs); File ""/usr/local/lib/python3.10/site-packages/hailtop/httpx.py"", line 148, in request_and_raise_for_status; raise ClientResponseError(; hailtop.httpx.ClientResponseError: 500, message='Internal Server Error', url=URL('http://batch.hail/api/v1alpha/batches/485962/updates/1/jobs/create') body='500 Internal Server Error\n\nServer got itself in trouble'; 2024-09-25 01:54:55,288 - hailtop.utils 835 - WARNING - A transient error occured. We will automatically retry. We have thus far seen 50 transient errors (next delay: 60.0s).; ```. The corresponding server-side error was. ```; pymysql.err.DataError: (1406, \""Data too long for column 'value' at row 106\""); ```. coming from the `INSERT INTO job_attributes ` query in `insert_jobs_into_db()`. We write a list of the samples being processed as a job attribute, and it turned out th",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14702:81,error,errors,81,https://hail.is,https://github.com/hail-is/hail/issues/14702,4,"['Error', 'error']","['Error', 'error', 'errors']"
Availability,"We recently had a debugging odyssey due to the following code:. ```python; import hailtop.batch as hb. def make_job(batch):; job = batch.new_job(name='test'); return job # Oops, forgot to also return the output resource. batch = hb.Batch(name='test'); my_job, my_output = make_job(batch); ```. This lead to the following error message:. ```; Traceback (most recent call last):; File ""/borkscript.py"", line 8, in <module>; my_job, my_output = make_job(batch); File ""/site-packages/hailtop/batch/job.py"", line 125, in __getitem__; return self._get_resource(item); File ""/site-packages/hailtop/batch/job.py"", line 118, in _get_resource; r = self._batch._new_job_resource_file(self, value=item); File ""/site-packages/hailtop/batch/batch.py"", line 405, in _new_job_resource_file; jrf = _resource.JobResourceFile(value, source); File ""/site-packages/hailtop/batch/resource.py"", line 128, in __init__; super().__init__(value); File ""/site-packages/hailtop/batch/resource.py"", line 48, in __init__; assert value is None or isinstance(value, str); AssertionError; ```. Of course, in a 400-line script it took a long while to figure out what the traceback that seemed to have little to do with any dubious code of ours was trying to tell us, and to notice that the actual problem was the `return` 200 lines away!. The problem is that these classes define `__getitem__()` so their resources can be accessed as if via a dict. The assignment into multiple variables causes Python to try to interpret the RHS as something iterable, and as `__getitem__` is defined, it will use `__getitem__(0)`, `__getitem__(1)`,... to implement that iteration. These classes are not really iterable, so define a no-op `__iter__()` to prevent this. With this, we get:. ```; Traceback (most recent call last):; File ""/borkscript.py"", line 8, in <module>; my_job, my_output = make_job(batch); File ""/site-packages/hailtop/batch/job.py"", line 127, in __iter__; raise TypeError(f'{type(self).__name__!r} object is not iterable')",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14390:321,error,error,321,https://hail.is,https://github.com/hail-is/hail/pull/14390,1,['error'],['error']
Availability,"We saw this error in production:; ```; pymysql.err.IntegrityError: (1062, ""Duplicate entry '7433-432443' for key 'PRIMARY'""); ```; hand deploy in progress already.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8014:12,error,error,12,https://hail.is,https://github.com/hail-is/hail/pull/8014,1,['error'],['error']
Availability,"We seem to be running into spark/yarn scheduling limitations causing stages to often fail with a large number of partitions. Here, we implement a very simple chunking strategy to run spark jobs with a limited number of partitions at a time. The maximum parallelism is controlled by a new `spark_max_stage_parallelism` feature flag, which defaults to MAXINT until we can figure out a good default. Also, this change corrects a small error in logic for partition indices for call caching. The `resultHandler` argument of [`runJob`] is called with the job's partition index, not the index of the partition within the RDD. So we need to index into the `partitions` sequence when populating the results buffer. CHANGELOG: Add 'spark_max_stage_parallelism' flag to allow users to run pipelines with a large number of partitions in chunks. By default, hail still attempts to run all partitions in a stage at once. . [`runJob`]: https://spark.apache.org/docs/latest/api/scala/org/apache/spark/SparkContext.html#runJob[T,U](rdd:org.apache.spark.rdd.RDD[T],func:(org.apache.spark.TaskContext,Iterator[T])=%3EU,partitions:Seq[Int],resultHandler:(Int,U)=%3EUnit)(implicitevidence$11:scala.reflect.ClassTag[U]):Unit",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14590:432,error,error,432,https://hail.is,https://github.com/hail-is/hail/pull/14590,1,['error'],['error']
Availability,"We should treat `python-dill` like other images in the `hailgenetics` DockerHub repo and not hard-code our own registry into the docs. I also removed the `batch-worker` image from the publicly available images, not sure why that was in there but it seems wrong.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12230:193,avail,available,193,https://hail.is,https://github.com/hail-is/hail/pull/12230,1,['avail'],['available']
Availability,We still have the error log. This produces a lot of logs and I have never used it for debugging purposes.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11978:18,error,error,18,https://hail.is,https://github.com/hail-is/hail/pull/11978,1,['error'],['error']
Availability,We throw an error if field is nested and the name argument is passed.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5321:12,error,error,12,https://hail.is,https://github.com/hail-is/hail/pull/5321,1,['error'],['error']
Availability,"We tried loading a large bgen file (chr21 - 950k Variants, 150k samples) from UK Biobank. It seemed to proceed ok and generate a VDS file that was loadable, but upon looking at variantqc, it appears that at the large majority of sites, all homref calls are missing. There were no 'tolerance too low' messages while loading, and this property seems to be retained across several runs with difference tolerances.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/714:281,toler,tolerance,281,https://hail.is,https://github.com/hail-is/hail/issues/714,2,['toler'],"['tolerance', 'tolerances']"
Availability,"We want to error if the output exists since the combiner will overwrite the output path. However we don't want to do this if the combiner is done, since if the user is rerunning a script with the combiner in the middle of it, they are generally doing some post-processing on the combiner's output and we (and the users) would probably rather just skip the combiner if possible.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14397:11,error,error,11,https://hail.is,https://github.com/hail-is/hail/pull/14397,1,['error'],['error']
Availability,"We want to track Hail's performance with every release for a number of reasons, including but not limited to: ; - Measure how we are doing in delivering value to scientists; - Measure the effect of changes, test our intuition and learn how to improve the product. ; - Compare our solution with others; - Catch unexpected regressions. As of the time of writing, benchmarks are run rarely and have rotted somewhat. There's a bit of work required to get them going again. There's also some work in getting them running in CI and capturing the results. Very roughly, I think work can broken down as follows:; - [ ] get benchmarks passing; - [ ] organise trials with learnings from https://www.zora.uzh.ch/id/eprint/170445/1/emse_smb_cloud.pdf; - [x] run bechmarks in ci on deploy and store the results somewhere appropriate, fail if there's something really awful ; - [ ] visualise results on some appropriate cadance for trends. Might be nice to have a graphic on our github page. . I think many of these can be done in parallel.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14221:587,down,down,587,https://hail.is,https://github.com/hail-is/hail/issues/14221,1,['down'],['down']
Availability,"We were getting lots of exceptions when an instance was no longer reachable because it had either been preempted or idled out. The driver could have been offline or the monitor instances / health check loop ran before the activity log monitor was able to process the delete instance events. This PR attempts to tone down the exceptions such that we only get errors for instances that are likely to be zombies (no contact for 5 minutes) rather than normally disappearing instances. However, I do think we should have a separate Grafana alert for when we have lots of instances being deactivated because they couldn't contact the driver as that's a sign of a bigger problem.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12184:316,down,down,316,https://hail.is,https://github.com/hail-is/hail/pull/12184,2,"['down', 'error']","['down', 'errors']"
Availability,"We weren't actually testing the compaction in test and dev, which is probably why we had those initial errors in production.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13476:103,error,errors,103,https://hail.is,https://github.com/hail-is/hail/pull/13476,1,['error'],['errors']
Availability,We weren't checking for a key even though the docs said the table needed to be keyed. This led to undefined behavior for `distinct`. Not sure what the error mode for `collect_by_key` was.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5548:151,error,error,151,https://hail.is,https://github.com/hail-is/hail/pull/5548,1,['error'],['error']
Availability,"We will get errors about methods not being well formed if we don't define every label on an IEmitCode, so we have to consume each one even if we don't do anything with it. . I also moved `StreamLen` to `emitI`, because we were pointlessly switching back and forth from `EmitCode` to `IEmitCode`",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10330:12,error,errors,12,https://hail.is,https://github.com/hail-is/hail/pull/10330,1,['error'],['errors']
Availability,We'll likely use the [ASM library](http://asm.ow2.org/index.html) which is available in [maven](https://mvnrepository.com/artifact/org.ow2.asm/asm-parent/5.1). For:. ```; if cond then cnsq else altr; ```. the emitter should produce the byte code:. ```; COMPILE[[cond]]; ifnull (lengthOf(COMPILE[[cnsq]]) + lengthOf(COMPILE[[altr]]) + 4); checkcast offset_to_java_lang_Boolean_class; invokevirtual offset_to_java_lang_Boolean_booleanValue; ifne (lengthOf(COMPILE[[cnsq]]) + 1); COMPILE[[cnsq]]; COMPILE[[altr]]; checkcast offset_to_resultType; ```,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/813:75,avail,available,75,https://hail.is,https://github.com/hail-is/hail/issues/813,1,['avail'],['available']
Availability,"We're upsetting the robots of the world by not having a `robots.txt` to instruct how they should crawl the website. As retribution, they crawl everything, so this robots.txt doesn't change any indexing behavior but if there's anything we don't want indexed I can add here. Requests for `/robots.txt` and `/favicon.ico` make up a non-trivial amount of site's error logs now, so I also added a symlink to the image we use as our favicon. Hopefully this helps to further quiet the logs.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10052:358,error,error,358,https://hail.is,https://github.com/hail-is/hail/pull/10052,1,['error'],['error']
Availability,"We've had a number of pip issues recently, particularly incompatibilities with the `six` package. The central issue is that pip will install incompatible package versions with only a warning message. This primarily happens when a set of packages is installed (say in a parent image) and then a new set of packages are installed later. Pip attempts to satisfy all requirements of the packages in an installed set, but it does not consider the versions of packages already installed. In this PR, I pervasively change every use of `pip` to be followed by the use of `pip check`. Pip check errors if there are incompatible package versions installed. Rather than change every place that we use `pip install`, I created an ubuntu image with a script, `hail-pip-install`, and pip configuration which makes it easy to do the right thing. Now, we should always install python packages like this:. ```; hail-pip-install package1 package2 package3; ```. The script will ensure that all packages are compatible with existing packages. Moreover, it will retry downloads five times. I did not make every Dockerfile depend on the new hail-ubuntu-image because they are legacy Dockerfile that I didn't want to edit. These include the benchmark Dockerfile and some notebook workers. PySpark presented a challenge because we did not install it via pip. As a result, packages, such as Hail, which depend on PySpark failed the `pip check`. I modified all uses of PySpark to instead use the standard pip-installed version of PySpark. In particular, take a look at how query and shuffler changed. cc: @Dania-Abuhijleh @catoverdrive",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9593:586,error,errors,586,https://hail.is,https://github.com/hail-is/hail/pull/9593,2,"['down', 'error']","['downloads', 'errors']"
Availability,"We've run into this on Hail Batch 0.2.108. Binaries unfortunately sometimes produce binary output in logs (through `stdout` or `stderr`), e.g. `tabix` does that when it encounters the wrong input format. It appears that Hail Batch doesn't display _any_ log in such circumstances. That makes debugging the underlying issue really hard. For some reason, this seems to specifically happen with the byte value of 128. A simple way to reproduce this is to run the following commands in a batch:. ```python; job.command(""echo 'hi there :)'""); job.command(""echo -n -e '\\x80'""); ```. This will result in a `ERROR: could not find log file`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12614:515,echo,echo,515,https://hail.is,https://github.com/hail-is/hail/issues/12614,3,"['ERROR', 'echo']","['ERROR', 'echo']"
Availability,"Website is an aiohttp application which templates docs pages and normal pages. This opens the path; towards unifying the visual appearance of hail.is, the docs, and the services. I simplified documentation generation at the cost of building the docs twice per commit. A new step,; `make_pip_versioned_docs` builds the pip version of the docs without testing them. `make_docs`; continues to work as it did before. The website uses the docs from `make_pip_versioned_docs`. The; GCS docs location is now completely unused. Website has four key folders:. - `website/website/pages/`: Jinja2 templated HTML pages. Served at `/`. - `website/website/docs/`: Hail & Batch docs pages, all HTML pages are templated with Jinja2.; Served at `/docs`. - `website/website/templates/`: Jinaj2 templates that are used in pages or in docs. - `website/website/static/`: Non-templated files. Served at `/static`. The website can be developed locally in or outside of Docker:; ```; make -C website run; ```; or; ```; make -C website rundocker; ```. ---. I had to rename site to website due to a Python package conflict. I also deleted two unused css; files. I also removed PLINK from hail_run_image because it was slowing down my iteration speed; and was a long-term FIXME anyway.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10056:1200,down,down,1200,https://hail.is,https://github.com/hail-is/hail/pull/10056,1,['down'],['down']
Availability,"Weirdly, GCR returns a 500 for an invalid repository name instead of a 404, so we retry it endlessly. We need to special-case our transient errors to treat 500s with ""Invalid repository name"" messages as *not* transient errors, and then give the user the error message that their image repository is invalid. This follows the same pattern that we use for invalid image names.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12152:140,error,errors,140,https://hail.is,https://github.com/hail-is/hail/pull/12152,3,['error'],"['error', 'errors']"
Availability,"Wenhan observed this error after I gave her a branch using google cloud storage 2.30.1. I've reported this new transient error to the client API repo, but I doubt it will be fixed. https://github.com/googleapis/java-storage/issues/2337. SSL errors seem like the kind of thing we should not retry forever since they could indicate a bad actor.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14094:21,error,error,21,https://hail.is,https://github.com/hail-is/hail/pull/14094,3,['error'],"['error', 'errors']"
Availability,What might be the issue as I had an error reported while running:. hail importvcf /user/jkoskela/ibd/vcf/v30_ibd_exomes.vcf.bgz splitmulti \. > write -o /user/jkoskela/ibd/hail/v30_split_ibd.vds; > hail: info: running: importvcf /user/jkoskela/ibd/vcf/v30_ibd_exomes.vcf.bgz; > [Stage 0:====================================================>(4569 + 1) / 4570]hail: info: Coerced sorted dataset; > hail: info: running: splitmulti; > hail: info: running: write -o /user/jkoskela/ibd/hail/v30_split_ibd.vds; > [Stage 2:> (0 + 162) / 4570]hail: write: caught exception: org.apache.spark.SparkException: Job aborted. Log can be found in:. /humgen/atgu1/fs03/jkoskela/hail.log,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/913:36,error,error,36,https://hail.is,https://github.com/hail-is/hail/issues/913,1,['error'],['error']
Availability,"When I last tried to fix this up, I somehow missed the GCS client dependency. This; uses the in cluster location if it is available otherwise it lets Google try to find; the key.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8652:122,avail,available,122,https://hail.is,https://github.com/hail-is/hail/pull/8652,1,['avail'],['available']
Availability,"When I ran the tutorial with the downloadable 'data/1kg.vds', it throws a fatal error ; ``HailException: Invalid VDS: old version [4]; Recreate VDS with current version of Hail.``. Would it be possible for you to provide an updated VDS or the underlying VCF to build a new VDS? I'm running Hail version devel-6d7d270",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2067:33,down,downloadable,33,https://hail.is,https://github.com/hail-is/hail/issues/2067,2,"['down', 'error']","['downloadable', 'error']"
Availability,"When I test this, I get; ```; FatalError: IllegalFormatConversionException: d != java.lang.String. Java stack trace:; is.hail.utils.HailException: Encountered invalid type for format string %d: format specifier d does not accept type java.lang.String; 	at is.hail.utils.ErrorHandling.fatal(ErrorHandling.scala:15); 	at is.hail.utils.ErrorHandling.fatal$(ErrorHandling.scala:15); 	at is.hail.utils.package$.fatal(package.scala:78); 	at is.hail.expr.ir.functions.UtilFunctions$.format(UtilFunctions.scala:168); 	at __C12Compiled.__m15format(Emit.scala); ... java.util.IllegalFormatConversionException: d != java.lang.String; 	at java.util.Formatter$FormatSpecifier.failConversion(Formatter.java:4302); 	at java.util.Formatter$FormatSpecifier.printInteger(Formatter.java:2793); 	at java.util.Formatter$FormatSpecifier.print(Formatter.java:2747); 	at java.util.Formatter.format(Formatter.java:2520); 	at java.util.Formatter.format(Formatter.java:2455); 	at java.lang.String.format(String.java:2940); 	at is.hail.expr.ir.functions.UtilFunctions$.format(UtilFunctions.scala:165); 	at __C12Compiled.__m15format(Emit.scala); ... Hail version: 0.2.74-4d495f1c5e01; Error summary: IllegalFormatConversionException: d != java.lang.String; ```. Why is the summary not the `HailException` string?",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10827:270,Error,ErrorHandling,270,https://hail.is,https://github.com/hail-is/hail/pull/10827,5,['Error'],"['Error', 'ErrorHandling']"
Availability,"When accessing two VDS files in `gs://hail-common/`, I got two errors. 1. gs://hail-common/all_coding_plus_minus_50bp_vep.vds. ```; File ""<decorator-gen-162>"", line 2, in read; File ""/home/ec2-user/BuildAgent/work/c38e75e72b769a7c/python/hail/java.py"", line 113, in handle_py4j; hail.java.FatalError: HailException: missing partitioner.json.gz when loading VDS, create with HailContext.write_partitioning. Java stack trace:; is.hail.utils.HailException: missing partitioner.json.gz when loading VDS, create with HailContext.write_partitioning.; 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:6); 	at is.hail.utils.package$.fatal(package.scala:20); 	at is.hail.variant.VariantDataset$.liftedTree1$1(VariantDataset.scala:89); 	at is.hail.variant.VariantDataset$.read(VariantDataset.scala:84); 	at is.hail.HailContext$$anonfun$10.apply(HailContext.scala:414); 	at is.hail.HailContext$$anonfun$10.apply(HailContext.scala:413); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); 	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186); 	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); 	at scala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:186); 	at is.hail.HailContext.readAll(HailContext.scala:413); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:280); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractC",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1683:63,error,errors,63,https://hail.is,https://github.com/hail-is/hail/issues/1683,3,"['Error', 'error']","['ErrorHandling', 'errors']"
Availability,When building hail from source on an Apple M1 MacBook Pro . `make install HAIL_COMPILE_NATIVES=1 `. I get . ```; /Library/Developer/CommandLineTools/usr/bin/make -C src/main/c prebuilt; c++ -march=native -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/Library/Java/JavaVirtualMachines/jdk-17.0.1.jdk/Contents/include -I/Library/Java/JavaVirtualMachines/jdk-17.0.1.jdk/Contents/include/darwin testutils/unit-tests.cpp -MG -M -MF build/testutils/unit-tests.d -MT build/testutils/unit-tests.o; clang: error: the clang compiler does not support '-march=native'; ```. This issue is related specifically to new MacBook hardware and not hail itself but I cannot find an obvious way to fix this from searching online. Has anyone seen this and know how to resolve the issue?,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/11729:554,error,error,554,https://hail.is,https://github.com/hail-is/hail/issues/11729,1,['error'],['error']
Availability,"When buliding hail , There are several problems please helpthanks. [root@**\* hail]# gradle shadowJar; Using a seed of [1] for testing.; Build file '/**_/hail/build.gradle': line 188; useAnt has been deprecated and is scheduled to be removed in Gradle 3.0. The Ant-Based Scala compiler is deprecated, please see https://docs.gradle.org/current/userguide/scala_plugin.html.; :compileJava UP-TO-DATE; :compileScala; /**_/hail/src/main/scala/org/broadinstitute/hail/expr/AST.scala:135: not enough arguments for constructor AnnotationPathException: (msg: String)org.broadinstitute.hail.annotations.AnnotationPathException; throw new AnnotationPathException(); ^; /**_/hail/src/main/scala/org/broadinstitute/hail/expr/AST.scala:153: not enough arguments for constructor AnnotationPathException: (msg: String)org.broadinstitute.hail.annotations.AnnotationPathException; throw new AnnotationPathException(); ^; /**_/hail/src/main/scala/org/broadinstitute/hail/expr/AST.scala:162: not enough arguments for constructor AnnotationPathException: (msg: String)org.broadinstitute.hail.annotations.AnnotationPathException; throw new AnnotationPathException(); ^; /**_/hail/src/main/scala/org/broadinstitute/hail/expr/AST.scala:661: not enough arguments for constructor AnnotationPathException: (msg: String)org.broadinstitute.hail.annotations.AnnotationPathException; case None => throw new AnnotationPathException(); ^; /**_/hail/src/main/scala/org/broadinstitute/hail/expr/AST.scala:753: not enough arguments for constructor AnnotationPathException: (msg: String)org.broadinstitute.hail.annotations.AnnotationPathException; throw new AnnotationPathException(); ^; 5 errors found; :compileScala FAILED. FAILURE: Build failed with an exception.; - What went wrong:; Execution failed for task ':compileScala'.; ; > Compilation failed; - Try:; Run with --stacktrace option to get the stack trace. Run with --info or --debug option to get more log output. BUILD FAILED. Total time: 39.537 secs",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/454:1656,error,errors,1656,https://hail.is,https://github.com/hail-is/hail/issues/454,2,"['FAILURE', 'error']","['FAILURE', 'errors']"
Availability,"When commands are submitted there's currently an error when I don't provide the proper arguments for a function. This way I don't waste time running things only to have the job crash after it's been going for a while. There should be similar functionality when I submit a command that tries to filter by/annotate with a file that doesn't exist. If you can distinguish when this file will be automatically generated by earlier commands in the script, then that would be nice. If not, then you could just have a warning if the command line has a function using a file that doesn't currently exist.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/413:49,error,error,49,https://hail.is,https://github.com/hail-is/hail/issues/413,1,['error'],['error']
Availability,"When creating a global map using annotateglobal exprbysample, any variant annotation after that fails by Map not serializable error",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1179:126,error,error,126,https://hail.is,https://github.com/hail-is/hail/issues/1179,1,['error'],['error']
Availability,"When loading a plink binary file, if the delimiter is incorrect it currently fails with the following cryptic error:. caught scala.MatchError: [Ljava.lang.String;@459f703f (of class [Ljava.lang.String;). This was a file with spaces (where the default is tab). As space seems to be the default for plink2, which was used to make these files, it may be worth allowing either by default.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/709:110,error,error,110,https://hail.is,https://github.com/hail-is/hail/issues/709,1,['error'],['error']
Availability,"When the number of fields in `x` is really huge, this optimization creates huge chains of `Let` bindings which cause stack size issues in downstream IR analysis passes. (we can remove this cap once our passes will no longer run into stack size issues on very deep IRs.)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7726:138,down,downstream,138,https://hail.is,https://github.com/hail-is/hail/pull/7726,1,['down'],['downstream']
Availability,When the user fails to provide a lambda to an aggregation; they now receive a suggestion to use a lambda rather than; a Scala match error. @tpoterba this should hold us over until we have something nicer like that `projectT` function. resolves #786,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/788:132,error,error,132,https://hail.is,https://github.com/hail-is/hail/pull/788,1,['error'],['error']
Availability,"When trying to create a dataproc cluster using the results of `make -C hail install-editable` and `make -C hail install-hailctl`, the Jupyter server can't be connected to because it runs into the error described [here](https://stackoverflow.com/questions/77549493/modulenotfounderror-no-module-named-jupyter-server-contents). This change bumps the version of `notebook` that we use in the `init_notebook.py` script in order to make that work again.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14563:196,error,error,196,https://hail.is,https://github.com/hail-is/hail/pull/14563,1,['error'],['error']
Availability,"When trying to lift over the gnomAD 3.1 hail table to GRCh37, I encounter the error mentioned above. This code works:. ```python; import hail as hl. hail_table = 'gs://gcp-public-data--gnomad/release/3.1.1/ht/genomes/gnomad.genomes.v3.1.1.sites.ht'; chain_file = 'gs://hail-common/references/grch38_to_grch37.over.chain.gz'; ht = hl.read_table(hail_table).head(10_000). GRCh37 = hl.get_reference('GRCh37'); GRCh38 = hl.get_reference('GRCh38'); GRCh38.add_liftover(chain_file, GRCh37). hl.eval(hl.liftover(hl.locus('chr1', 1034245, 'GRCh38'), 'GRCh37')); # Locus(contig=1, position=969625, reference_genome=GRCh37); ```. However, when trying to lift over the entire table it fails:; ```; ht = ht.annotate(; locus_GRCh37 = hl.liftover(ht.locus, 'GRCh37'); ); ht.show(); ```. I got the same error when trying to lift over an older gnomAD version (2.1) from GRCh37 to GRCh38, which used to work according to my best knowledge. Also, this way of lifting over a hail table is following the recommended process on the documentation [here](https://hail.is/docs/0.2/guides/genetics.html?highlight=prs#liftover-variants-from-one-coordinate-system-to-another). I'm quite confident there must be something I'm doing wrong, but now I'm stuck, any help would be highly welcome. Thanks!. The code is running on a Google Cloud Dataproc cluster, Python 3.8, hail version: `'0.2.71-f3a54b530979'`. Error stack:; ```python; --------------------------------------------------------------------------- / 1]; FatalError Traceback (most recent call last); /opt/conda/miniconda3/lib/python3.8/site-packages/IPython/core/formatters.py in __call__(self, obj); 700 type_pprinters=self.type_printers,; 701 deferred_pprinters=self.deferred_printers); --> 702 printer.pretty(obj); 703 printer.flush(); 704 return stream.getvalue(). /opt/conda/miniconda3/lib/python3.8/site-packages/IPython/lib/pretty.py in pretty(self, obj); 392 if cls is not object \; 393 and callable(cls.__dict__.get('__repr__')):; --> 394 return _repr_pprint(",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/10682:78,error,error,78,https://hail.is,https://github.com/hail-is/hail/issues/10682,2,['error'],['error']
Availability,"When using this command `filtervariants -c /user/xiaoli/LCR-hs37d5.interval_list --remove`, I got this error message: ; `hail: filtervariants: caught exception: scala.MatchError: [Ljava.lang.String;@56d822dc (of class [Ljava.lang.String;)`. The input file is formatted:; 1 1 10000; 1 10016 10464; 1 10656 10784; 1 28576 28603; 1 30852 30959; 1 31712 31733; 1 33440 33464; 1 33504 33541. It might be because that it cannot take tab delimited file with only three columns. At least we need a clear warning message.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/319:103,error,error,103,https://hail.is,https://github.com/hail-is/hail/issues/319,1,['error'],['error']
Availability,"When we attempt to build the vep 95 docker image, we have issues installing LibXML causing later failures. Not sure why this is happening.; From https://batch.hail.is/batches/8209583/jobs/27; ```; #13 423.5 Building and testing XML-LibXML-2.0210 ... ! Installing XML::LibXML failed. See /root/.cpanm/work/1727981951.12888/build.log for details. Retry with --force to force install it.; #13 453.0 FAIL; ```; leading to; ```; #13 724.7 ! Installing the dependencies failed: Module 'XML::LibXML' is not installed, Module 'XML::LibXML::Reader' is not installed; #13 724.7 ! Bailing out the installation for BioPerl-1.7.8.; #13 724.7 ! Installing the dependencies failed: Module 'Bio::Root::Version' is not installed; #13 724.7 ! Bailing out the installation for Bio-BigFile-1.07.; #13 724.7 63 distributions installed; #13 ERROR: executor failed running [/bin/sh -c export KENT_SRC=$PWD/kent-335_base/src && export MACHTYPE=$(uname -m) && export CFLAGS=""-fPIC"" && export MYSQLINC=""mysql_config --include | sed -e 's/^-I//g'"" && export MYSQLLIBS=""mysql_config --libs"" && wget https://github.com/ucscGenomeBrowser/kent/archive/v335_base.tar.gz && tar xzf v335_base.tar.gz && cd $KENT_SRC/lib && echo 'CFLAGS=""-fPIC""' > ../inc/localEnvironment.mk && make clean && make && cd ../jkOwnLib && make clean && make && mkdir -p $VEP_DIR/cpanm && export PERL5LIB=\$PERL5LIB:$HOME/cpanm/lib/perl5 && cpanm Bio::DB::BigFile]: exit code: 1; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14710:97,failure,failures,97,https://hail.is,https://github.com/hail-is/hail/issues/14710,3,"['ERROR', 'echo', 'failure']","['ERROR', 'echo', 'failures']"
Availability,"When we download files from GCS, they lose their permissions. Git complains and then the checkout fails.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10414:8,down,download,8,https://hail.is,https://github.com/hail-is/hail/pull/10414,1,['down'],['download']
Availability,"When workers shut down, we get warning logs about unclosed client sessions, as seen in #14261. While it can be difficult to derive the source of the client session, I think it's the one held by the `GCPWorkerAPI`. I've added an exit stack and added the session's close method to it. I also made a small change to `Worker`. I find it can be difficult to determine whether or not a particular class should close a client session because it's not always clear who owns it. Without a clear way to communicate this in python, I think we should just never transfer ownership of a `ClientSession` and always assume that if an object's constructor takes a client session, it should be assumed a borrow and not close the session when the object is closed. As such, I moved the call to `client_session()` into the `Worker` constructor so it's clear that the worker owns the session.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14418:18,down,down,18,https://hail.is,https://github.com/hail-is/hail/pull/14418,1,['down'],['down']
Availability,"Whenever the batch driver shuts down we have some errors due to unclosed aiohttp `ClientSession`s. Deploying the driver in asyncio debug mode revealed that these sessions were in the `ComputeClient` and `LoggingClient`, which we don't call `close` on (and we don't use them as context managers). After this change I was able to delete my driver pod without any unclosed client session errors (though plenty of cancelled errors, which is a separate issue.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10634:32,down,down,32,https://hail.is,https://github.com/hail-is/hail/pull/10634,4,"['down', 'error']","['down', 'errors']"
Availability,"While I was running the script shown below. I got the error message. I attach the log file. Do you know what cause the errors ? Thanks . ```; hail -l /medpop/afib/schoi/projects/TOPMed/Script/log/TopMed.Chr22.QC.vds.log \; importvcf file:///medpop/afib/schoi/projects/TOPMed/Data/BROAD/Link/Chr22/*.bgz splitmulti \; filtervariants expr -c 'v.contig == ""X"" || v.contig == ""Y"" || v.contig == ""MT""' --remove \; filtersamples list -i file:///medpop/afib/schoi/projects/TOPMed/Result/TopMed_nodup.6998.sample.map --keep \; sampleqc -o file:///medpop/afib/schoi/projects/TOPMed/Result/SampleQC/chrom/TOPMed.PreQC.sampleqc.chr22.tsv \; variantqc -o file:///medpop/afib/schoi/projects/TOPMed/Result/VariantQC/chrom/TOPMed.PreQC.variantqc.chr22.tsv \; annotatevariants expr -c 'va.info.AC = va.info.AC[va.aIndex]' \; filtergenotypes -c '(g.ad[0] + g.ad[1]) / g.dp < 0.9 || (g.isHomRef && (g.ad[0] / g.dp < 0.9 || g.gq < 20)) || (g.isHet && (g.ad[1] / g.dp < 0.20 || g.pl[0] < 20)) || (g.isHomVar && (g.ad[1] / g.dp < 0.9 || g.pl[0] < 20)) || g.dp > 200' --remove \; variantqc -o file:///medpop/afib/schoi/projects/TOPMed/Result/VariantQC/chrom/TOPMed.QCstep1.variantqc.Chr22.tsv \; annotatevariants intervals -r va.isLCF -i file:///medpop/afib/schoi/projects/TOPMed/Data/LCR/LCR.interval_list \; annotatevariants expr -c 'va.AC1 = va.qc.AC,; va.good = ((va.info.QD > 3 && v.altAllele.isIndel) || (va.info.QD > 2 && v.altAllele.isSNP)) && (va.qc.callRate > 0.95)' \; annotateglobal expr -c 'global.badVQSLOD = variants.count(va.pass),; global.badQD = variants.count((va.info.QD <= 3 && v.altAllele.isIndel) || (va.info.QD <= 2 && v.altAllele.isSNP)),; global.badCallRate = variants.count(va.qc.callRate <= 0.95),; global.nIndel_1 = variants.count(v.altAllele.isIndel && va.AC1 > 0),; global.nSNP_1 = variants.count(v.altAllele.isSNP && va.AC1 > 0),; global.nIndel_2 = variants.count(v.altAllele.isIndel && va.AC1 > 0 && va.pass),; global.nSNP_2 = variants.count(v.altAllele.isSNP && va.AC1 > 0 && va.pass),; gl",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/660:54,error,error,54,https://hail.is,https://github.com/hail-is/hail/issues/660,2,['error'],"['error', 'errors']"
Availability,"While only used in a few places, this helps us generate; much better code in the case where we emit error-checking; IRs as below:. ```; If; <error_condition>; Die err_msg; <value we want>; ```. The code generator for the `If` node uses `SType.canonical` to; choose its result type, and casts both consequent and alternate; values to that type. We want the stype of the result here to be; the type of the alternate `<value we want>`, which we can achieve; by adding unreachable types/codes for the `SType.canonical` logic.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10539:100,error,error-checking,100,https://hail.is,https://github.com/hail-is/hail/pull/10539,1,['error'],['error-checking']
Availability,"While running QoB jobs, we observed some errors relating to compression validation or unexpected end of line/file. It was suggested that after certain errors, the reader may be in an unsuable state, so we recreate it after an error.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13371:41,error,errors,41,https://hail.is,https://github.com/hail-is/hail/pull/13371,3,['error'],"['error', 'errors']"
Availability,"While running mendel_errors:; ```; hail.utils.java.FatalError: ClassCastException: is.hail.codegen.generated.C71 cannot be cast to is.hail.asm4s.AsmFunction7. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 143 in stage 13.0 failed 20 times, most recent failure: Lost task 143.19 in stage 13.0 (TID 4198, exomes2-sw-k2p2.c.broad-mpg-gnomad.internal, executor 212): java.lang.ClassCastException: is.hail.codegen.generated.C71 cannot be cast to is.hail.asm4s.AsmFunction7; 	at is.hail.expr.MatrixFilterEntries$$anonfun$54.apply(Relational.scala:1752); 	at is.hail.expr.MatrixFilterEntries$$anonfun$54.apply(Relational.scala:1750); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:797); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:797); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); [...]; 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); 	at org.apache.spark.rdd.RDD.withScope(RDD.scala:362); 	at org.apache.spark.rdd.RDD.collect(RDD.scala:935); 	at is.hail.sparkextras.ContextRDD.collect(ContextRDD.scala:132); 	at is.hail.rvd.OrderedRVD$.getPartitionKeyInfo(OrderedRVD.scala:478); 	at is.hail.rvd.OrderedRVD$.getPartitionKeyInfo(OrderedRVD.scala:488); 	at is.hail.rvd.OrderedRVD$.coerce(OrderedRVD.scala:556); 	at is.hail.rvd.OrderedRVD$.coerce(OrderedRVD.scala:514); 	at is.hail.table.Table.toOrderedRVD(Table.scala:1152); 	at is.hail.table.Table.distinctByKey(Table.scala:540); 	at sun.reflect.Nati",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3446:236,failure,failure,236,https://hail.is,https://github.com/hail-is/hail/issues/3446,2,['failure'],['failure']
Availability,"While trying to fix some weird errors, I realized this was more complicated than necessary and, I; think, broken. In the new implementation, a BatchPoolFuture is a thin wrapper around an asyncio.Future. Instead of; tracking the value and any exceptions manually, the BatchPoolFuture relies on asyncio.Future. I think the diff is not very helpful, just look at the new, simpler implementation. I also forgot to close the ServiceBackend, I now do that in the cleanup method that happens after all future complete.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10322:31,error,errors,31,https://hail.is,https://github.com/hail-is/hail/pull/10322,1,['error'],['errors']
Availability,"While working on Hail Query on Hail Batch, I frequently encountered transient; errors in rmtree when cleaning up temporary cloud directories. This change; ensures rmtree is resilient to such failures.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10935:79,error,errors,79,https://hail.is,https://github.com/hail-is/hail/pull/10935,3,"['error', 'failure', 'resilien']","['errors', 'failures', 'resilient']"
Availability,"Will merge cleanly when https://github.com/hail-is/hail/pull/3560 lands. I needed to remove `RegionValue.copy` and `Region.copy` because they necessarily create regions that aren't managed by an `RVDContext`. `RegionValue.copy` is only used in three places. . - `Table.toMatrixTable`: Here, I took the somewhat inefficient choice of creating `SafeRow`s. If `toMatrixTable` is a performance bottleneck, we might want to reconsider this. It's not totally obvious how to do this. I think I'd need to explicitly serialize/deserialize these values and modify `reduceByKey` to explicitly provide the `RVDContext`. Anyway, this works and I don't think it's _that_ slow. (I guess I should check that). - `OrderedRVD.localKeySort` & `LocalLDPrune.pruneLocal`: in both cases we need keep a handful of region values around per-partition. This does not lend itself to region-based-allocation. I solve this with two copies and a fresh region per value. Putting a value into `localKeySort`'s queue requires copying it into a fresh region. Taking a value out of the queue requires copying it into the consumer's region and closing/freeing the region it was living in. There fresh region is alive as long as the value is in the queue. I had to modify `RVDContext` to track `Region`s that get closed early. This seems a bit inefficient. Maybe I should track children as a `Set`?. cc: @cseed",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3579:1175,alive,alive,1175,https://hail.is,https://github.com/hail-is/hail/pull/3579,1,['alive'],['alive']
Availability,"Without these changes, my IDE cannot deduce that the return value of, say, `select` is a `Table` which prevents jump-to-definition on subsequent method calls. I also received an error about `Table.collect` returning an `ArrayExpression` which it will only do when `_localize=False`. `overload` teaches this fact to the type system. I didn't use the specific expression in `base_expression.py` because that would require an import circularity.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13468:178,error,error,178,https://hail.is,https://github.com/hail-is/hail/pull/13468,1,['error'],['error']
Availability,"Without this `make test-local` fails because there is no running server. This ensures that `make test-local` first starts a server to test against. Recreated for stacked PRs from #4785. ---. The `until curl ...` nonsense is because the server takes some time to start up, so we poll until we get a successful return value from `curl`. `-f` means return non-zero-exit-code on failure. `-L` means follow redirects (not really necessary here, but I think it's good practice to use `-L`). `BATCH_USE_KUBE_CONFG=1` tells batch to use the latent kubernetes configuration, which means the developer must already have set up `kubectl`. This is a reasonable expectation for a developer of `batch`. The `trap cleanup EXIT` ensures we run cleanup before the shell exits. `trap ""exit 24"" INT TERM` converts interruption (`Ctrl-c`) and termination (`kill -15`) into an `EXIT` signal. We do this to ensure that the exit handler is called once. if we did `trap cleanup EXIT INT TERM` some shells would call `cleanup` twice. Once for the interruption and once for the shell exiting. Inside `cleanup` we `trap """" INT TERM` to make `Ctrl-c` do nothing, because the user COUGH cotton COUGH might smash ctrl-c repeatedly and we might not kill the subprocess before they kills us ;).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4786:375,failure,failure,375,https://hail.is,https://github.com/hail-is/hail/pull/4786,1,['failure'],['failure']
Availability,"Without this `make test-local` fails because there is no running server. This ensures that `make test-local` first starts a server to test against. The `until curl ...` nonsense is because the server takes some time to start up, so we poll until we get a successful return value from `curl`. `-f` means return non-zero-exit-code on failure. `-L` means follow redirects (not really necessary here, but I think it's good practice to use `-L`). `BATCH_USE_KUBE_CONFG=1` tells batch to use the latent kubernetes configuration, which means the developer must already have set up `kubectl`. This is a reasonable expectation for a developer of `batch`. The `trap cleanup EXIT` ensures we run cleanup before the shell exits. `trap ""exit 24"" INT TERM` converts interruption (`Ctrl-c`) and termination (`kill -15`) into an `EXIT` signal. We do this to ensure that the exit handler is called once. if we did `trap cleanup EXIT INT TERM` some shells would call `cleanup` twice. Once for the interruption and once for the shell exiting. Inside `cleanup` we `trap """" INT TERM` to make `Ctrl-c` do nothing, because the user COUGH cotton COUGH might smash ctrl-c repeatedly and we might not kill the subprocess before they kills us ;).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4785:332,failure,failure,332,https://hail.is,https://github.com/hail-is/hail/pull/4785,1,['failure'],['failure']
Availability,"Without this change, no error is raised and we never record; that there was a check incremental failure.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11279:24,error,error,24,https://hail.is,https://github.com/hail-is/hail/pull/11279,2,"['error', 'failure']","['error', 'failure']"
Availability,"Without this empty file, mypy ignores the type annotations present in these modules. Adding; this file enables downstream modules (like CI and batch) to check the type annotations; provided by hailtop, gear, and web_common. See more information here: https://mypy.readthedocs.io/en/stable/installed_packages.html#making-pep-561-compatible-packages",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9899:111,down,downstream,111,https://hail.is,https://github.com/hail-is/hail/pull/9899,1,['down'],['downstream']
Availability,"Workers can dynamically attach disks to themselves to accommodate jobs that request storage that the VM cannot accommodate. In certain circumstances like preemption, the VM can disappear before it is able to delete its own disks, so the Batch Driver scans for disks that are no longer attached (orphaned) and deletes them. It looks like our disk cleanup loop was broken due to inadvertent mutation that leads to an assertion error if the same `params` argument is used in multiple invocations of `GoogleComputeClient.list`. This is preventing orphaned disks from being deleted, costing us money. Additional details are in #14613. Fixes #14613",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14614:425,error,error,425,https://hail.is,https://github.com/hail-is/hail/pull/14614,1,['error'],['error']
Availability,"Working in cluster. Fixes the below error, the origin of which I'm not quite sure: does it happen because wherever CI builds this has spark2.4 installed, or is spark2.4 pulled by gradlew shadowJar (I don't see where this happens, but I also haven't looked very carefully). ```; install-hail-locally:; 	rm -rf build; 	(cd ../hail && GRADLE_OPTS=-Xmx2048m ./gradlew shadowJar --gradle-user-home /gradle-cache); 	mkdir -p build/hail/jars; 	mkdir -p build/hail/python; 	cp -a ../hail/build/libs/hail-all-spark.jar build/hail/jars; 	cp -a ../hail/python/hail build/hail/python. build-hail-base: build-spark-base install-hail-locally; ```. <img width=""814"" alt=""Screenshot 2019-04-10 13 22 01"" src=""https://user-images.githubusercontent.com/5543229/55902941-79ea4c00-5b9a-11e9-9899-8e37311c4d06.png"">. ; Only issue I see is; """"""; 2019-04-10 18:00:59 WARN NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; Setting default log level to ""WARN""; """""""". not sure if that's new, but googling around suggests the typical solution is warning suppression. cc @cseed",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5850:36,error,error,36,https://hail.is,https://github.com/hail-is/hail/pull/5850,1,['error'],['error']
Availability,"YGMENTS-1086606](https://snyk.io/vuln/SNYK-PYTHON-PYGMENTS-1086606) | `pygments:` <br> `2.5.2 -> 2.15.0` <br> | No | Proof of Concept ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | **589/1000** <br/> **Why?** Has a fix available, CVSS 7.5 | Denial of Service (DoS) <br/>[SNYK-PYTHON-PYGMENTS-1088505](https://snyk.io/vuln/SNYK-PYTHON-PYGMENTS-1088505) | `pygments:` <br> `2.5.2 -> 2.15.0` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **479/1000** <br/> **Why?** Has a fix available, CVSS 5.3 | Regular Expression Denial of Service (ReDoS) <br/>[SNYK-PYTHON-PYGMENTS-5750273](https://snyk.io/vuln/SNYK-PYTHON-PYGMENTS-5750273) | `pygments:` <br> `2.5.2 -> 2.15.0` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **519/1000** <br/> **Why?** Has a fix available, CVSS 6.1 | Information Exposure <br/>[SNYK-PYTHON-REQUESTS-5595532](https://snyk.io/vuln/SNYK-PYTHON-REQUESTS-5595532) | `requests:` <br> `2.27.1 -> 2.31.0` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **509/1000** <br/> **Why?** Has a fix available, CVSS 5.9 | Regular Expression Denial of Service (ReDoS) <br/>[SNYK-PYTHON-SETUPTOOLS-3180412](https://snyk.io/vuln/SNYK-PYTHON-SETUPTOOLS-3180412) | `setuptools:` <br> `39.0.1 -> 65.5.1` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **711/1000** <br/> **Why?** Mature exploit, Has a fix available, CVSS 6.5 | Cross-site Scripting (XSS) <br/>[SNYK-PYTHON-SPHINX-570772](https://snyk.io/vuln/SNYK-PYTHON-SPHINX-570772) | `sphinx:` <br> `1.8.6 -> 3.3.0` <br> | No | Mature ; ![medium severity](https://res.cloudi",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13717:5874,avail,available,5874,https://hail.is,https://github.com/hail-is/hail/pull/13717,3,['avail'],['available']
Availability,"YK-PYTHON-JUPYTERSERVER-5862882) | `jupyter-server:` <br> `1.24.0 -> 2.11.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **/1000** <br/> **Why?** | Generation of Error Message Containing Sensitive Information <br/>[SNYK-PYTHON-JUPYTERSERVER-6099119](https://snyk.io/vuln/SNYK-PYTHON-JUPYTERSERVER-6099119) | `jupyter-server:` <br> `1.24.0 -> 2.11.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **509/1000** <br/> **Why?** Has a fix available, CVSS 5.9 | Regular Expression Denial of Service (ReDoS) <br/>[SNYK-PYTHON-SETUPTOOLS-3180412](https://snyk.io/vuln/SNYK-PYTHON-SETUPTOOLS-3180412) | `setuptools:` <br> `39.0.1 -> 65.5.1` <br> | No | No Known Exploit ; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **384/1000** <br/> **Why?** Has a fix available, CVSS 3.4 | Open Redirect <br/>[SNYK-PYTHON-TORNADO-5537286](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-5537286) | `tornado:` <br> `6.2 -> 6.3.3` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **494/1000** <br/> **Why?** Has a fix available, CVSS 5.6 | HTTP Request Smuggling <br/>[SNYK-PYTHON-TORNADO-5840803](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-5840803) | `tornado:` <br> `6.2 -> 6.3.3` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **539/1000** <br/> **Why?** Has a fix available, CVSS 6.5 | HTTP Request Smuggling <br/>[SNYK-PYTHON-TORNADO-6041512](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-6041512) | `tornado:` <br> `6.2 -> 6.3.3` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities co",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14211:3169,avail,available,3169,https://hail.is,https://github.com/hail-is/hail/pull/14211,1,['avail'],['available']
Availability,"YK-PYTHON-JUPYTERSERVER-5862882) | `jupyter-server:` <br> `1.24.0 -> 2.11.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **/1000** <br/> **Why?** | Generation of Error Message Containing Sensitive Information <br/>[SNYK-PYTHON-JUPYTERSERVER-6099119](https://snyk.io/vuln/SNYK-PYTHON-JUPYTERSERVER-6099119) | `jupyter-server:` <br> `1.24.0 -> 2.11.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **509/1000** <br/> **Why?** Has a fix available, CVSS 5.9 | Regular Expression Denial of Service (ReDoS) <br/>[SNYK-PYTHON-SETUPTOOLS-3180412](https://snyk.io/vuln/SNYK-PYTHON-SETUPTOOLS-3180412) | `setuptools:` <br> `40.5.0 -> 65.5.1` <br> | No | No Known Exploit ; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **384/1000** <br/> **Why?** Has a fix available, CVSS 3.4 | Open Redirect <br/>[SNYK-PYTHON-TORNADO-5537286](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-5537286) | `tornado:` <br> `6.2 -> 6.3.3` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **494/1000** <br/> **Why?** Has a fix available, CVSS 5.6 | HTTP Request Smuggling <br/>[SNYK-PYTHON-TORNADO-5840803](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-5840803) | `tornado:` <br> `6.2 -> 6.3.3` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **539/1000** <br/> **Why?** Has a fix available, CVSS 6.5 | HTTP Request Smuggling <br/>[SNYK-PYTHON-TORNADO-6041512](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-6041512) | `tornado:` <br> `6.2 -> 6.3.3` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities co",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14365:3239,avail,available,3239,https://hail.is,https://github.com/hail-is/hail/pull/14365,1,['avail'],['available']
Availability,"You can now say:. ```; async with db.start() as tx:; await tx.just_execute(sql); row = await tx.execute_fetchone(sql, args); ...; ```. Transactions support all the database utility functions. If the transaction context manager exists with an exception, the transaction is rolled back, otherwise it is committed. You also can explicitly rollback or commit the transaction, although it can't be used again after that. I also added an execute_many function. I use this in the front end instead of dropping down to aiomysql to create explicit transactions. Note on internal changes: I no longer use autocommit now that transaction boundaries are explicit. You can start a read only transaction, and I do that by default for execute_and_fetch{one, all}, although maybe those should be renamed select_and_fetch{one, all} to make their read-only nature apparent (MySQL throws an error if you try to modify something in a read-only transaction). This follows mysql best transaction performance recommendations as described here: https://dev.mysql.com/doc/refman/5.6/en/optimizing-innodb-transaction-management.html and https://dev.mysql.com/doc/refman/5.6/en/innodb-performance-ro-txn.html. FYI @jigold",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7641:336,rollback,rollback,336,https://hail.is,https://github.com/hail-is/hail/pull/7641,3,"['down', 'error', 'rollback']","['down', 'error', 'rollback']"
Availability,Zstd bgen error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12608:10,error,error,10,https://hail.is,https://github.com/hail-is/hail/issues/12608,1,['error'],['error']
Availability,[AzureStorageFS] more transient errors,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12873:32,error,errors,32,https://hail.is,https://github.com/hail-is/hail/pull/12873,1,['error'],['errors']
Availability,[Benchmark] fix error by adding .json ext to file name,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9669:16,error,error,16,https://hail.is,https://github.com/hail-is/hail/pull/9669,1,['error'],['error']
Availability,[Benchmark] fixes (for 500 server error),MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9477:34,error,error,34,https://hail.is,https://github.com/hail-is/hail/pull/9477,1,['error'],['error']
Availability,[CI] Do not error if a job for an unknown PR is received,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4669:12,error,error,12,https://hail.is,https://github.com/hail-is/hail/pull/4669,1,['error'],['error']
Availability,[DB] Remove redundant f-strings and validate ints,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14669:12,redundant,redundant,12,https://hail.is,https://github.com/hail-is/hail/pull/14669,1,['redundant'],['redundant']
Availability,[QoB] Driver does not retry transient errors in the one-partition fast path,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12982:38,error,errors,38,https://hail.is,https://github.com/hail-is/hail/issues/12982,1,['error'],['errors']
Availability,[QoB] Novel transient error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12980:22,error,error,22,https://hail.is,https://github.com/hail-is/hail/issues/12980,1,['error'],['error']
Availability,[QoB] new transient error: java.net.SocketTimeoutException: connect timed out,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13074:20,error,error,20,https://hail.is,https://github.com/hail-is/hail/issues/13074,1,['error'],['error']
Availability,[QoB] protect reference download with a lock,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11949:24,down,download,24,https://hail.is,https://github.com/hail-is/hail/pull/11949,1,['down'],['download']
Availability,"[This](https://github.com/hail-is/hail/commit/9f186be0111d241756484136a2ffa8eb1a8a1feb) commit imports the `decorator` library, which isn't available by default on google cloud dataproc machines. . One can get around it (by rolling this commit back or by installing the library), but it makes the google cloud tutorial not work by default.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1459:140,avail,available,140,https://hail.is,https://github.com/hail-is/hail/issues/1459,1,['avail'],['available']
Availability,[WIP] Fix billing tables with redundant billing information,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12715:30,redundant,redundant,30,https://hail.is,https://github.com/hail-is/hail/pull/12715,1,['redundant'],['redundant']
Availability,[aiocloud] refresh access tokens after transient errors,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14083:49,error,errors,49,https://hail.is,https://github.com/hail-is/hail/pull/14083,1,['error'],['errors']
Availability,[aiogoogle] make aiogoogle tests resilient,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10947:33,resilien,resilient,33,https://hail.is,https://github.com/hail-is/hail/pull/10947,1,['resilien'],['resilient']
Availability,[aiogoogle] use resumable uploads to make writes resilient,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10023:49,resilien,resilient,49,https://hail.is,https://github.com/hail-is/hail/pull/10023,1,['resilien'],['resilient']
Availability,[aiotools.fs] retry transient errors in tests,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10954:30,error,errors,30,https://hail.is,https://github.com/hail-is/hail/pull/10954,1,['error'],['errors']
Availability,[aiotools] Log exception is task manager task errors,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13453:46,error,errors,46,https://hail.is,https://github.com/hail-is/hail/pull/13453,1,['error'],['errors']
Availability,[annotationdb] more informative error when can't find compatible annotation dataset,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10515:32,error,error,32,https://hail.is,https://github.com/hail-is/hail/pull/10515,1,['error'],['error']
Availability,[auth] retry transient errors,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8677:23,error,errors,23,https://hail.is,https://github.com/hail-is/hail/pull/8677,1,['error'],['errors']
Availability,[auth] teach token to error on missing token file,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7020:22,error,error,22,https://hail.is,https://github.com/hail-is/hail/pull/7020,1,['error'],['error']
Availability,[batch-client] teach java about another transient error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9785:50,error,error,50,https://hail.is,https://github.com/hail-is/hail/pull/9785,1,['error'],['error']
Availability,[batch/copy] fix for sporadic copy failures (1/2),MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10260:35,failure,failures,35,https://hail.is,https://github.com/hail-is/hail/pull/10260,1,['failure'],['failures']
Availability,[batch2] a config error won't have a timing field,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7542:18,error,error,18,https://hail.is,https://github.com/hail-is/hail/pull/7542,1,['error'],['error']
Availability,[batch2] fix startup failure,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7442:21,failure,failure,21,https://hail.is,https://github.com/hail-is/hail/pull/7442,1,['failure'],['failure']
Availability,[batch2] fix status if error occurred when getting the job config,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7522:23,error,error,23,https://hail.is,https://github.com/hail-is/hail/pull/7522,1,['error'],['error']
Availability,[batch2] lock down secrets and service accounts to non-ci users,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7662:14,down,down,14,https://hail.is,https://github.com/hail-is/hail/pull/7662,1,['down'],['down']
Availability,[batch2] slim down worker image,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7233:14,down,down,14,https://hail.is,https://github.com/hail-is/hail/pull/7233,1,['down'],['down']
Availability,[batch] Add container str to deletion error messages,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10805:38,error,error,38,https://hail.is,https://github.com/hail-is/hail/pull/10805,1,['error'],['error']
Availability,[batch] Add download logs button,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11841:12,down,download,12,https://hail.is,https://github.com/hail-is/hail/pull/11841,1,['down'],['download']
Availability,[batch] Add error to missing k8s log message,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6461:12,error,error,12,https://hail.is,https://github.com/hail-is/hail/pull/6461,1,['error'],['error']
Availability,[batch] Add failure reason to logs,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6260:12,failure,failure,12,https://hail.is,https://github.com/hail-is/hail/pull/6260,1,['failure'],['failure']
Availability,[batch] Add k8s secret/sa cache and retry transient errors,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7850:52,error,errors,52,https://hail.is,https://github.com/hail-is/hail/pull/7850,1,['error'],['errors']
Availability,[batch] Add more logging for disk formatting errors,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11867:45,error,errors,45,https://hail.is,https://github.com/hail-is/hail/pull/11867,1,['error'],['errors']
Availability,[batch] Add user error for bad gcsfuse creds,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10645:17,error,error,17,https://hail.is,https://github.com/hail-is/hail/pull/10645,1,['error'],['error']
Availability,[batch] Batch Client needs robust tests,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6722:27,robust,robust,27,https://hail.is,https://github.com/hail-is/hail/issues/6722,1,['robust'],['robust']
Availability,[batch] Batch charges for private instance creation that fails with exhausted resource errors.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14505:87,error,errors,87,https://hail.is,https://github.com/hail-is/hail/issues/14505,1,['error'],['errors']
Availability,[batch] Batch should give useful error message on 401 unauthorized,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7839:33,error,error,33,https://hail.is,https://github.com/hail-is/hail/issues/7839,1,['error'],['error']
Availability,[batch] Batch workers log with ERROR severity when job is canceled,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13803:31,ERROR,ERROR,31,https://hail.is,https://github.com/hail-is/hail/issues/13803,1,['ERROR'],['ERROR']
Availability,[batch] Catch 500 error messages in dev ui pages,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10503:18,error,error,18,https://hail.is,https://github.com/hail-is/hail/pull/10503,1,['error'],['error']
Availability,[batch] Clarify DockerHub error message,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11148:26,error,error,26,https://hail.is,https://github.com/hail-is/hail/pull/11148,1,['error'],['error']
Availability,[batch] Do not log user errors as exceptions,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14253:24,error,errors,24,https://hail.is,https://github.com/hail-is/hail/pull/14253,1,['error'],['errors']
Availability,[batch] Don't create jobs while shutting down the worker,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10594:41,down,down,41,https://hail.is,https://github.com/hail-is/hail/pull/10594,1,['down'],['down']
Availability,[batch] Don't error if no regions are in the database on startup,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12374:14,error,error,14,https://hail.is,https://github.com/hail-is/hail/pull/12374,1,['error'],['error']
Availability,[batch] Don't rmtree if any errors occur while unmounting,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12985:28,error,errors,28,https://hail.is,https://github.com/hail-is/hail/pull/12985,1,['error'],['errors']
Availability,[batch] Dont log an exception if the exception is a user error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10636:57,error,error,57,https://hail.is,https://github.com/hail-is/hail/pull/10636,1,['error'],['error']
Availability,[batch] Dont log user errors from JVM jobs,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11376:22,error,errors,22,https://hail.is,https://github.com/hail-is/hail/pull/11376,1,['error'],['errors']
Availability,[batch] Error if PythonJob functions are called with incompatible signature,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12734:8,Error,Error,8,https://hail.is,https://github.com/hail-is/hail/pull/12734,1,['Error'],['Error']
Availability,[batch] Fix JVM file exists error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12397:28,error,error,28,https://hail.is,https://github.com/hail-is/hail/pull/12397,1,['error'],['error']
Availability,[batch] Fix UI to make user errors clear,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10329:28,error,errors,28,https://hail.is,https://github.com/hail-is/hail/pull/10329,2,['error'],['errors']
Availability,[batch] Fix checking error message for crun kill,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10988:21,error,error,21,https://hail.is,https://github.com/hail-is/hail/pull/10988,1,['error'],['error']
Availability,[batch] Fix deadlock errors when inserting attempts and attempt resources,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11959:21,error,errors,21,https://hail.is,https://github.com/hail-is/hail/pull/11959,1,['error'],['errors']
Availability,[batch] Fix errors on the worker,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11686:12,error,errors,12,https://hail.is,https://github.com/hail-is/hail/pull/11686,1,['error'],['errors']
Availability,[batch] Fix local backend too many args error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10508:40,error,error,40,https://hail.is,https://github.com/hail-is/hail/pull/10508,1,['error'],['error']
Availability,[batch] Fix publicly available images to include the right mirror,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11048:21,avail,available,21,https://hail.is,https://github.com/hail-is/hail/pull/11048,1,['avail'],['available']
Availability,[batch] Ignore device not found errors in resource usage code,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12752:32,error,errors,32,https://hail.is,https://github.com/hail-is/hail/pull/12752,1,['error'],['errors']
Availability,[batch] Job groups transient error causing a 400 to the user,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14413:29,error,error,29,https://hail.is,https://github.com/hail-is/hail/issues/14413,1,['error'],['error']
Availability,[batch] Logging error: hail_logging.py: 18 fails assertion.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14261:16,error,error,16,https://hail.is,https://github.com/hail-is/hail/issues/14261,1,['error'],['error']
Availability,[batch] Make error messages clearer in the UI and formatted correctly,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10545:13,error,error,13,https://hail.is,https://github.com/hail-is/hail/pull/10545,2,['error'],['error']
Availability,[batch] Mitigate accrued_costs test failure,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11420:36,failure,failure,36,https://hail.is,https://github.com/hail-is/hail/pull/11420,1,['failure'],['failure']
Availability,[batch] Mitigate test failures by extending batch client timeout,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12709:22,failure,failures,22,https://hail.is,https://github.com/hail-is/hail/pull/12709,1,['failure'],['failures']
Availability,[batch] More debugging information for network namespace errors,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13509:57,error,errors,57,https://hail.is,https://github.com/hail-is/hail/pull/13509,1,['error'],['errors']
Availability,[batch] More graceful resource usage error handling,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12609:37,error,error,37,https://hail.is,https://github.com/hail-is/hail/pull/12609,1,['error'],['error']
Availability,[batch] Quiet down MJC and MJS logging exceptions,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12496:14,down,down,14,https://hail.is,https://github.com/hail-is/hail/pull/12496,1,['down'],['down']
Availability,[batch] Reduce non-essential warning / error messages,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10702:39,error,error,39,https://hail.is,https://github.com/hail-is/hail/pull/10702,1,['error'],['error']
Availability,[batch] Reduce redundant SQL queries for mark_healthy,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11889:15,redundant,redundant,15,https://hail.is,https://github.com/hail-is/hail/pull/11889,1,['redundant'],['redundant']
Availability,[batch] Remove lint errors from test_batch and test_accounts,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12147:20,error,errors,20,https://hail.is,https://github.com/hail-is/hail/pull/12147,1,['error'],['errors']
Availability,[batch] Remove redundant env variable for internal gateway ip,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12005:15,redundant,redundant,15,https://hail.is,https://github.com/hail-is/hail/pull/12005,1,['redundant'],['redundant']
Availability,"[batch] Submitting a Batch using the hailtop.batch library may raise ""Cannot enter into task"" errors",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14051:94,error,errors,94,https://hail.is,https://github.com/hail-is/hail/issues/14051,1,['error'],['errors']
Availability,[batch] Teach BatchPoolExecutor how to handle container errors,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9543:56,error,errors,56,https://hail.is,https://github.com/hail-is/hail/pull/9543,1,['error'],['errors']
Availability,[batch] Tone down access log messages that are not helpful,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11897:13,down,down,13,https://hail.is,https://github.com/hail-is/hail/pull/11897,1,['down'],['down']
Availability,[batch] Tone down healthcheck exception,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12184:13,down,down,13,https://hail.is,https://github.com/hail-is/hail/pull/12184,1,['down'],['down']
Availability,[batch] Treat unauthorized in docker error message as permission denied,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12708:37,error,error,37,https://hail.is,https://github.com/hail-is/hail/pull/12708,1,['error'],['error']
Availability,[batch] Type checker for dictionaries causes a 500 on failure,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14350:54,failure,failure,54,https://hail.is,https://github.com/hail-is/hail/issues/14350,1,['failure'],['failure']
Availability,[batch] Update docker client timeout transient error message,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11942:47,error,error,47,https://hail.is,https://github.com/hail-is/hail/pull/11942,1,['error'],['error']
Availability,[batch] Use /io if available for container volumes,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12777:19,avail,available,19,https://hail.is,https://github.com/hail-is/hail/pull/12777,1,['avail'],['available']
Availability,[batch] a deleted batch zombie jobs causes assertion errors,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6737:53,error,errors,53,https://hail.is,https://github.com/hail-is/hail/issues/6737,1,['error'],['errors']
Availability,[batch] a little gcloud auth resilience,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6797:29,resilien,resilience,29,https://hail.is,https://github.com/hail-is/hail/pull/6797,1,['resilien'],['resilience']
Availability,[batch] add docker retry for specific 500 errors,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7715:42,error,errors,42,https://hail.is,https://github.com/hail-is/hail/pull/7715,1,['error'],['errors']
Availability,[batch] add error information to debug message,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6469:12,error,error,12,https://hail.is,https://github.com/hail-is/hail/pull/6469,1,['error'],['error']
Availability,[batch] add more error information when missing header,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10216:17,error,error,17,https://hail.is,https://github.com/hail-is/hail/pull/10216,1,['error'],['error']
Availability,[batch] add short error message for batch job with unknown image,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10506:18,error,error,18,https://hail.is,https://github.com/hail-is/hail/pull/10506,1,['error'],['error']
Availability,[batch] add transient error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8189:22,error,error,22,https://hail.is,https://github.com/hail-is/hail/pull/8189,1,['error'],['error']
Availability,[batch] adjust Hail's cost structure to recover operating expenses,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13526:40,recover,recover,40,https://hail.is,https://github.com/hail-is/hail/issues/13526,1,['recover'],['recover']
Availability,[batch] assertion error in delete_pod,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6753:18,error,error,18,https://hail.is,https://github.com/hail-is/hail/issues/6753,1,['error'],['error']
Availability,[batch] better debug info on batch test failure,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10948:40,failure,failure,40,https://hail.is,https://github.com/hail-is/hail/pull/10948,1,['failure'],['failure']
Availability,[batch] better error message,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6911:15,error,error,15,https://hail.is,https://github.com/hail-is/hail/pull/6911,1,['error'],['error']
Availability,[batch] catch errors reading logs,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6034:14,error,errors,14,https://hail.is,https://github.com/hail-is/hail/pull/6034,1,['error'],['errors']
Availability,[batch] cleanup error message for unknown instance,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10325:16,error,error,16,https://hail.is,https://github.com/hail-is/hail/pull/10325,1,['error'],['error']
Availability,[batch] close all the jvms when the worker shuts down,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11432:49,down,down,49,https://hail.is,https://github.com/hail-is/hail/pull/11432,1,['down'],['down']
Availability,[batch] db must rollback if spec write fails or is cancelled,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11404:16,rollback,rollback,16,https://hail.is,https://github.com/hail-is/hail/pull/11404,1,['rollback'],['rollback']
Availability,[batch] demote callback failure to info,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11383:24,failure,failure,24,https://hail.is,https://github.com/hail-is/hail/pull/11383,1,['failure'],['failure']
Availability,[batch] do not log user errors,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11377:24,error,errors,24,https://hail.is,https://github.com/hail-is/hail/pull/11377,1,['error'],['errors']
Availability,[batch] downgrade gcsfuse to avoid gcsfuse bug,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12749:8,down,downgrade,8,https://hail.is,https://github.com/hail-is/hail/pull/12749,1,['down'],['downgrade']
Availability,"[batch] driver holds open aiomysql connections after the event loop is destroyed, this triggers a bunch of error logs and a grafana alert",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13863:107,error,error,107,https://hail.is,https://github.com/hail-is/hail/issues/13863,1,['error'],['error']
Availability,[batch] enable 5 JP instances in tests and alleviate failures,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11928:53,failure,failures,53,https://hail.is,https://github.com/hail-is/hail/pull/11928,1,['failure'],['failures']
Availability,[batch] ensure batches are cancelled on error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10762:40,error,error,40,https://hail.is,https://github.com/hail-is/hail/pull/10762,1,['error'],['error']
Availability,[batch] error in get container status results in exit code set to zero even though log retrieval failed,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8083:8,error,error,8,https://hail.is,https://github.com/hail-is/hail/issues/8083,1,['error'],['error']
Availability,[batch] failure resilience on insert,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7875:8,failure,failure,8,https://hail.is,https://github.com/hail-is/hail/pull/7875,2,"['failure', 'resilien']","['failure', 'resilience']"
Availability,[batch] fix another logging error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8975:28,error,error,28,https://hail.is,https://github.com/hail-is/hail/pull/8975,1,['error'],['error']
Availability,[batch] fix assertion error in mark_job_task_complete,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6367:22,error,error,22,https://hail.is,https://github.com/hail-is/hail/pull/6367,1,['error'],['error']
Availability,[batch] fix cancellation notification error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7990:38,error,error,38,https://hail.is,https://github.com/hail-is/hail/pull/7990,1,['error'],['error']
Availability,[batch] fix container process is already dead error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8131:46,error,error,46,https://hail.is,https://github.com/hail-is/hail/pull/8131,1,['error'],['error']
Availability,[batch] fix duplicate key insert error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8307:33,error,error,33,https://hail.is,https://github.com/hail-is/hail/pull/8307,1,['error'],['error']
Availability,[batch] fix error msg with multiple jobs with same pod,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6476:12,error,error,12,https://hail.is,https://github.com/hail-is/hail/pull/6476,1,['error'],['error']
Availability,[batch] fix exit code if error is in container execution,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8784:25,error,error,25,https://hail.is,https://github.com/hail-is/hail/pull/8784,1,['error'],['error']
Availability,[batch] fix exit code when error occurred,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8088:27,error,error,27,https://hail.is,https://github.com/hail-is/hail/pull/8088,1,['error'],['error']
Availability,[batch] fix http error code,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7820:17,error,error,17,https://hail.is,https://github.com/hail-is/hail/pull/7820,1,['error'],['error']
Availability,[batch] fix infinite attempts of pvc creation with failure code 403,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6249:51,failure,failure,51,https://hail.is,https://github.com/hail-is/hail/pull/6249,1,['failure'],['failure']
Availability,[batch] fix insertion error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7912:22,error,error,22,https://hail.is,https://github.com/hail-is/hail/pull/7912,1,['error'],['error']
Availability,[batch] fix scheduler error if allocated_cores not found,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7707:22,error,error,22,https://hail.is,https://github.com/hail-is/hail/pull/7707,1,['error'],['error']
Availability,[batch] fix syntax errors in cancel_batch_in_db,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9724:19,error,errors,19,https://hail.is,https://github.com/hail-is/hail/pull/9724,1,['error'],['errors']
Availability,[batch] fix test unauthorized users to be resilient to transient errors,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8230:42,resilien,resilient,42,https://hail.is,https://github.com/hail-is/hail/pull/8230,2,"['error', 'resilien']","['errors', 'resilient']"
Availability,[batch] fix user cancel/delete request blocking if driver down,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7913:58,down,down,58,https://hail.is,https://github.com/hail-is/hail/pull/7913,1,['down'],['down']
Availability,[batch] fix worker error handling and add types,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10987:19,error,error,19,https://hail.is,https://github.com/hail-is/hail/pull/10987,1,['error'],['error']
Availability,[batch] give a reasonable error message when no batch billing project is set,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8651:26,error,error,26,https://hail.is,https://github.com/hail-is/hail/pull/8651,1,['error'],['error']
Availability,[batch] handle error in post_job_complete in worker,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8094:15,error,error,15,https://hail.is,https://github.com/hail-is/hail/pull/8094,1,['error'],['error']
Availability,[batch] high log retrieval failure rate (at least 5%),MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6545:27,failure,failure,27,https://hail.is,https://github.com/hail-is/hail/issues/6545,1,['failure'],['failure']
Availability,[batch] image pull back off means container failure,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6784:44,failure,failure,44,https://hail.is,https://github.com/hail-is/hail/pull/6784,1,['failure'],['failure']
Availability,[batch] improve error messages on checks,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9497:16,error,error,16,https://hail.is,https://github.com/hail-is/hail/pull/9497,1,['error'],['error']
Availability,[batch] instance RAM and disk usage is not available in GCP Monitoring,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13903:43,avail,available,43,https://hail.is,https://github.com/hail-is/hail/issues/13903,1,['avail'],['available']
Availability,[batch] lock down disk size until cost calculation is per-instance,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7854:13,down,down,13,https://hail.is,https://github.com/hail-is/hail/pull/7854,1,['down'],['down']
Availability,[batch] locking down secrets and service accounts,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8155:16,down,down,16,https://hail.is,https://github.com/hail-is/hail/pull/8155,1,['down'],['down']
Availability,[batch] log setup failure,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6961:18,failure,failure,18,https://hail.is,https://github.com/hail-is/hail/pull/6961,1,['failure'],['failure']
Availability,[batch] make tests resilient to concurrent batches,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10928:19,resilien,resilient,19,https://hail.is,https://github.com/hail-is/hail/pull/10928,1,['resilien'],['resilient']
Availability,[batch] merge failure,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6871:14,failure,failure,14,https://hail.is,https://github.com/hail-is/hail/pull/6871,1,['failure'],['failure']
Availability,[batch] mitigate some of the cost test failures,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11448:39,failure,failures,39,https://hail.is,https://github.com/hail-is/hail/pull/11448,1,['failure'],['failures']
Availability,[batch] more information on integrity error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8632:38,error,error,38,https://hail.is,https://github.com/hail-is/hail/pull/8632,1,['error'],['error']
Availability,[batch] more robust k8s event stream watch,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6511:13,robust,robust,13,https://hail.is,https://github.com/hail-is/hail/pull/6511,1,['robust'],['robust']
Availability,[batch] mysterious error related to unicode,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7769:19,error,error,19,https://hail.is,https://github.com/hail-is/hail/issues/7769,1,['error'],['error']
Availability,[batch] new docker error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8029:19,error,error,19,https://hail.is,https://github.com/hail-is/hail/issues/8029,1,['error'],['error']
Availability,[batch] new transient docker error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11488:29,error,error,29,https://hail.is,https://github.com/hail-is/hail/pull/11488,1,['error'],['error']
Availability,[batch] novel error in copying container logs,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8053:14,error,error,14,https://hail.is,https://github.com/hail-is/hail/issues/8053,1,['error'],['error']
Availability,[batch] provide sufficient information to debug transient errors,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14151:58,error,errors,58,https://hail.is,https://github.com/hail-is/hail/pull/14151,1,['error'],['errors']
Availability,[batch] quiet down every kind of transient error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12712:14,down,down,14,https://hail.is,https://github.com/hail-is/hail/pull/12712,2,"['down', 'error']","['down', 'error']"
Availability,[batch] raise error in check incremental,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11279:14,error,error,14,https://hail.is,https://github.com/hail-is/hail/pull/11279,1,['error'],['error']
Availability,[batch] remove redundant super class,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13541:15,redundant,redundant,15,https://hail.is,https://github.com/hail-is/hail/pull/13541,1,['redundant'],['redundant']
Availability,[batch] retry docker image not found error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8442:37,error,error,37,https://hail.is,https://github.com/hail-is/hail/pull/8442,1,['error'],['error']
Availability,[batch] retry downloading jar file,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11857:14,down,downloading,14,https://hail.is,https://github.com/hail-is/hail/pull/11857,1,['down'],['downloading']
Availability,[batch] robust against job tasks running multiple times,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6537:8,robust,robust,8,https://hail.is,https://github.com/hail-is/hail/pull/6537,1,['robust'],['robust']
Availability,[batch] skip ERROR events,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6800:13,ERROR,ERROR,13,https://hail.is,https://github.com/hail-is/hail/pull/6800,1,['ERROR'],['ERROR']
Availability,[batch] sometimes a posting to a keep-alive container fails,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6754:38,alive,alive,38,https://hail.is,https://github.com/hail-is/hail/issues/6754,1,['alive'],['alive']
Availability,[batch] sometimes k8s can send you an error event with no content,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6750:38,error,error,38,https://hail.is,https://github.com/hail-is/hail/issues/6750,1,['error'],['error']
Availability,[batch] track various failure modes,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6604:22,failure,failure,22,https://hail.is,https://github.com/hail-is/hail/pull/6604,1,['failure'],['failure']
Availability,[batch] use correct not found error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10918:30,error,error,30,https://hail.is,https://github.com/hail-is/hail/pull/10918,1,['error'],['error']
Availability,[batch] validation errors should be 400 BAD REQUEST,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5032:19,error,errors,19,https://hail.is,https://github.com/hail-is/hail/pull/5032,1,['error'],['errors']
Availability,[batch] variety of errors from the 3000 pod test,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6707:19,error,errors,19,https://hail.is,https://github.com/hail-is/hail/issues/6707,1,['error'],['errors']
Availability,[batch] workers have open tasks on shutting down,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13908:44,down,down,44,https://hail.is,https://github.com/hail-is/hail/issues/13908,1,['down'],['down']
Availability,[batch][ci] better error message when the deploy test fails,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8337:19,error,error,19,https://hail.is,https://github.com/hail-is/hail/pull/8337,1,['error'],['error']
Availability,[batch][ci] tolerate preemptibles,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6664:12,toler,tolerate,12,https://hail.is,https://github.com/hail-is/hail/pull/6664,1,['toler'],['tolerate']
Availability,[batch][dag6] Include first 500 character of HTTP body on errors,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4792:58,error,errors,58,https://hail.is,https://github.com/hail-is/hail/pull/4792,2,['error'],['errors']
Availability,[batch][hail] pervasively retry transient errors in synchronous code,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8391:42,error,errors,42,https://hail.is,https://github.com/hail-is/hail/pull/8391,1,['error'],['errors']
Availability,[batch][hotfix] address driver looping failure,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8814:39,failure,failure,39,https://hail.is,https://github.com/hail-is/hail/pull/8814,1,['failure'],['failure']
Availability,[benchmark] Don't double-log about downloading,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11813:35,down,downloading,35,https://hail.is,https://github.com/hail-is/hail/pull/11813,1,['down'],['downloading']
Availability,[benchmark] Fix errors in running and analyzing benchmarks,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7878:16,error,errors,16,https://hail.is,https://github.com/hail-is/hail/pull/7878,1,['error'],['errors']
Availability,[benchmark] Make benchmark-on-pipeline more robust,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7877:44,robust,robust,44,https://hail.is,https://github.com/hail-is/hail/pull/7877,1,['robust'],['robust']
Availability,"[benchmark] Tolerate failure in `run`, improve `compare`",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6630:12,Toler,Tolerate,12,https://hail.is,https://github.com/hail-is/hail/pull/6630,2,"['Toler', 'failure']","['Tolerate', 'failure']"
Availability,[benchmark] Tolerate tests that kill backend and mark as failed,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12838:12,Toler,Tolerate,12,https://hail.is,https://github.com/hail-is/hail/pull/12838,1,['Toler'],['Tolerate']
Availability,[benchmark] Use `wget` instead of urllib to download resources,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7747:44,down,download,44,https://hail.is,https://github.com/hail-is/hail/pull/7747,1,['down'],['download']
Availability,[benchmark] cat output file in case of permissions errors,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8329:51,error,errors,51,https://hail.is,https://github.com/hail-is/hail/pull/8329,1,['error'],['errors']
Availability,[bugfix][hail] Capture error rather than printing it,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8150:23,error,error,23,https://hail.is,https://github.com/hail-is/hail/pull/8150,1,['error'],['error']
Availability,[build.yaml] Scale down batch-driver before deleting instances,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11896:19,down,down,19,https://hail.is,https://github.com/hail-is/hail/pull/11896,1,['down'],['down']
Availability,[build.yaml] fix deploy failures,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12486:24,failure,failures,24,https://hail.is,https://github.com/hail-is/hail/pull/12486,1,['failure'],['failures']
Availability,"[build] Clarify tag target to echo about release, open browser on OSX",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7072:30,echo,echo,30,https://hail.is,https://github.com/hail-is/hail/pull/7072,1,['echo'],['echo']
Availability,[build] Quiet down tar commands,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7036:14,down,down,14,https://hail.is,https://github.com/hail-is/hail/pull/7036,1,['down'],['down']
Availability,[ci2] loud failure,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6054:11,failure,failure,11,https://hail.is,https://github.com/hail-is/hail/pull/6054,1,['failure'],['failure']
Availability,[ci] Bring max number of concurrent PRs down to three,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11762:40,down,down,40,https://hail.is,https://github.com/hail-is/hail/pull/11762,1,['down'],['down']
Availability,[ci] Handle errors in heal loop,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13115:12,error,errors,12,https://hail.is,https://github.com/hail-is/hail/pull/13115,1,['error'],['errors']
Availability,[ci] Make git clone resilient to failure,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8667:20,resilien,resilient,20,https://hail.is,https://github.com/hail-is/hail/pull/8667,2,"['failure', 'resilien']","['failure', 'resilient']"
Availability,[ci] Recover from missing deploy jobs as well,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4683:5,Recover,Recover,5,https://hail.is,https://github.com/hail-is/hail/pull/4683,1,['Recover'],['Recover']
Availability,[ci] We should scan the logs of every service for error conditions on PR tests,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7625:50,error,error,50,https://hail.is,https://github.com/hail-is/hail/issues/7625,1,['error'],['error']
Availability,[ci] add url to zulip failure notification,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7917:22,failure,failure,22,https://hail.is,https://github.com/hail-is/hail/pull/7917,1,['failure'],['failure']
Availability,[ci] better ci information on deploy failure,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9781:37,failure,failure,37,https://hail.is,https://github.com/hail-is/hail/pull/9781,1,['failure'],['failure']
Availability,[ci] better errors on bad github response and fix too many status updates,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8480:12,error,errors,12,https://hail.is,https://github.com/hail-is/hail/pull/8480,1,['error'],['errors']
Availability,[ci] change mention for deploy failure,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10178:31,failure,failure,31,https://hail.is,https://github.com/hail-is/hail/pull/10178,1,['failure'],['failure']
Availability,[ci] do not tag anyone in deploy failures,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11386:33,failure,failures,33,https://hail.is,https://github.com/hail-is/hail/pull/11386,1,['failure'],['failures']
Availability,"[ci] fix ""GitHubAPI object has no attribute 'get'"" error",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8402:51,error,error,51,https://hail.is,https://github.com/hail-is/hail/pull/8402,1,['error'],['error']
Availability,[ci] fix ci bug when a PR hits a merge failure,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8428:39,failure,failure,39,https://hail.is,https://github.com/hail-is/hail/pull/8428,1,['failure'],['failure']
Availability,[ci] fix index.html template parse error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6414:35,error,error,35,https://hail.is,https://github.com/hail-is/hail/pull/6414,1,['error'],['error']
Availability,[ci] fix print logs on failure,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8437:23,failure,failure,23,https://hail.is,https://github.com/hail-is/hail/pull/8437,1,['failure'],['failure']
Availability,[ci] hail_curl_image is redundant. kill it.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14490:24,redundant,redundant,24,https://hail.is,https://github.com/hail-is/hail/pull/14490,1,['redundant'],['redundant']
Availability,[ci] handle assertion errors in update_github loop,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6377:22,error,errors,22,https://hail.is,https://github.com/hail-is/hail/pull/6377,1,['error'],['errors']
Availability,"[ci] if no logs are available for a job, do not 500",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6586:20,avail,available,20,https://hail.is,https://github.com/hail-is/hail/issues/6586,1,['avail'],['available']
Availability,[ci] improve error message when we exceed the commit SHA status limit,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8540:13,error,error,13,https://hail.is,https://github.com/hail-is/hail/pull/8540,1,['error'],['error']
Availability,[ci] improve formatting of build errors,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6811:33,error,errors,33,https://hail.is,https://github.com/hail-is/hail/pull/6811,1,['error'],['errors']
Availability,[ci] make ci tests resilient to slow ci,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5801:19,resilien,resilient,19,https://hail.is,https://github.com/hail-is/hail/pull/5801,1,['resilien'],['resilient']
Availability,[ci] make scope available to migrations,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7708:16,avail,available,16,https://hail.is,https://github.com/hail-is/hail/pull/7708,1,['avail'],['available']
Availability,[ci] make test deployment tolerate preemptibles,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7871:26,toler,tolerate,26,https://hail.is,https://github.com/hail-is/hail/pull/7871,1,['toler'],['tolerate']
Availability,[ci] recover from deleted batches,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6406:5,recover,recover,5,https://hail.is,https://github.com/hail-is/hail/pull/6406,1,['recover'],['recover']
Availability,[ci] report merge failure exception in deploy_status,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9387:18,failure,failure,18,https://hail.is,https://github.com/hail-is/hail/pull/9387,1,['failure'],['failure']
Availability,[ci] teach CI to raise an error when a buildstep duplicates parents,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8829:26,error,error,26,https://hail.is,https://github.com/hail-is/hail/pull/8829,1,['error'],['error']
Availability,[ci] we need a pip install that retries transient errors for use inside docker.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8390:50,error,errors,50,https://hail.is,https://github.com/hail-is/hail/issues/8390,1,['error'],['errors']
Availability,[compiler] Add Trap node for error handling in FoldConstants,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10611:29,error,error,29,https://hail.is,https://github.com/hail-is/hail/pull/10611,1,['error'],['error']
Availability,[compiler] Add more informative failure for methods with too many params,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12513:32,failure,failure,32,https://hail.is,https://github.com/hail-is/hail/pull/12513,1,['failure'],['failure']
Availability,[compiler] Fix bad export_vcf filters error message,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11168:38,error,error,38,https://hail.is,https://github.com/hail-is/hail/pull/11168,1,['error'],['error']
Availability,[compiler] rewrite ExtractIntervalFilters to be more robust,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13355:53,robust,robust,53,https://hail.is,https://github.com/hail-is/hail/pull/13355,1,['robust'],['robust']
Availability,[copy] Fix assertion error on exceptions,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10226:21,error,error,21,https://hail.is,https://github.com/hail-is/hail/pull/10226,1,['error'],['error']
Availability,"[curl] pervasively use retries, report errors, follow redirects",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11183:39,error,errors,39,https://hail.is,https://github.com/hail-is/hail/pull/11183,1,['error'],['errors']
Availability,[datasets api] switch to https for downloading CADD,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8509:35,down,downloading,35,https://hail.is,https://github.com/hail-is/hail/pull/8509,1,['down'],['downloading']
Availability,[datasets] update gnomAD datasets available via Datasets API/Annotation DB,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11608:34,avail,available,34,https://hail.is,https://github.com/hail-is/hail/pull/11608,1,['avail'],['available']
Availability,[datasets] update pan-UKB datasets and make available via GCS,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12073:44,avail,available,44,https://hail.is,https://github.com/hail-is/hail/pull/12073,1,['avail'],['available']
Availability,[dbuf] more resilience to intermitent failure,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8219:12,resilien,resilience,12,https://hail.is,https://github.com/hail-is/hail/pull/8219,2,"['failure', 'resilien']","['failure', 'resilience']"
Availability,[debug] hailctl batch submit transient errors,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14149:39,error,errors,39,https://hail.is,https://github.com/hail-is/hail/pull/14149,1,['error'],['errors']
Availability,[deploy] assert sufficient space is available at PyPI in deploy,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13118:36,avail,available,36,https://hail.is,https://github.com/hail-is/hail/pull/13118,1,['avail'],['available']
Availability,[dev] Make test-dataproc target robust to __pycache__,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6622:32,robust,robust,32,https://hail.is,https://github.com/hail-is/hail/pull/6622,1,['robust'],['robust']
Availability,[docker] Teach Hail Ubuntu Image how to resiliently install apt packages,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9594:40,resilien,resiliently,40,https://hail.is,https://github.com/hail-is/hail/pull/9594,1,['resilien'],['resiliently']
Availability,[docker] Trim down service images,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12578:14,down,down,14,https://hail.is,https://github.com/hail-is/hail/pull/12578,1,['down'],['down']
Availability,[docker] bump nest_asyncio version to fix transient error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10705:52,error,error,52,https://hail.is,https://github.com/hail-is/hail/pull/10705,1,['error'],['error']
Availability,[docker] retry apt download at most 3 times,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9565:19,down,download,19,https://hail.is,https://github.com/hail-is/hail/pull/9565,1,['down'],['download']
Availability,[docker] slim down base image by 700 MB,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9414:14,down,down,14,https://hail.is,https://github.com/hail-is/hail/pull/9414,1,['down'],['down']
Availability,[docs] Add a download link for a .tar.gz with tutorials,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6986:13,down,download,13,https://hail.is,https://github.com/hail-is/hail/pull/6986,1,['down'],['download']
Availability,[docs] Document fix for BLAS error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7051:29,error,error,29,https://hail.is,https://github.com/hail-is/hail/pull/7051,1,['error'],['error']
Availability,[echo] implement a TCP echo server,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9681:1,echo,echo,1,https://hail.is,https://github.com/hail-is/hail/pull/9681,2,['echo'],['echo']
Availability,[feature] Add checkpoint methods to MT/Table,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5528:14,checkpoint,checkpoint,14,https://hail.is,https://github.com/hail-is/hail/pull/5528,1,['checkpoint'],['checkpoint']
Availability,[fs] Add azure blob path to FileNotFound error in read,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11214:41,error,error,41,https://hail.is,https://github.com/hail-is/hail/pull/11214,1,['error'],['error']
Availability,[fs] Add sink write failure in ABS to transient errors,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14430:20,failure,failure,20,https://hail.is,https://github.com/hail-is/hail/pull/14430,2,"['error', 'failure']","['errors', 'failure']"
Availability,[fs] Fix some errors closing sessions,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10522:14,error,errors,14,https://hail.is,https://github.com/hail-is/hail/pull/10522,1,['error'],['errors']
Availability,[fs] rare transient error when writing to google cloud storage,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13742:20,error,error,20,https://hail.is,https://github.com/hail-is/hail/issues/13742,1,['error'],['error']
Availability,[gear/auth] do not log on cancelled error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10916:36,error,error,36,https://hail.is,https://github.com/hail-is/hail/pull/10916,1,['error'],['error']
Availability,[gear] Retry Too many connections error for mysql,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11330:34,error,error,34,https://hail.is,https://github.com/hail-is/hail/pull/11330,1,['error'],['error']
Availability,[gear] Retry transient errors on database pool creation,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14309:23,error,errors,23,https://hail.is,https://github.com/hail-is/hail/pull/14309,1,['error'],['errors']
Availability,[gear] add retry on deadlock errors,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7782:29,error,errors,29,https://hail.is,https://github.com/hail-is/hail/pull/7782,1,['error'],['errors']
Availability,[gear] retry can't connect to mysql error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8237:36,error,error,36,https://hail.is,https://github.com/hail-is/hail/pull/8237,1,['error'],['error']
Availability,[ggplot] avoid weird dataframe error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12337:31,error,error,31,https://hail.is,https://github.com/hail-is/hail/pull/12337,1,['error'],['error']
Availability,[hail.fs] make rmtree retry transient errors,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10935:38,error,errors,38,https://hail.is,https://github.com/hail-is/hail/pull/10935,1,['error'],['errors']
Availability,[hail] Bad error message from export_vcf,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7584:11,error,error,11,https://hail.is,https://github.com/hail-is/hail/issues/7584,1,['error'],['error']
Availability,[hail] Fix bad error messages in aggregator transformations,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7762:15,error,error,15,https://hail.is,https://github.com/hail-is/hail/pull/7762,1,['error'],['error']
Availability,[hail] Fix crash when constant-folding functions that throw errors,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7642:60,error,errors,60,https://hail.is,https://github.com/hail-is/hail/pull/7642,1,['error'],['errors']
Availability,[hail] Implement staged downsample aggregator,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7197:24,down,downsample,24,https://hail.is,https://github.com/hail-is/hail/pull/7197,1,['down'],['downsample']
Availability,[hail] Push down interval filters into reads with index,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7342:12,down,down,12,https://hail.is,https://github.com/hail-is/hail/pull/7342,1,['down'],['down']
Availability,[hail] Raise a warning instead of an error on `hl.init(sc=sc)`,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7172:37,error,error,37,https://hail.is,https://github.com/hail-is/hail/pull/7172,1,['error'],['error']
Availability,[hail] RegionPool echoes at a doubling size threshold,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7076:18,echo,echoes,18,https://hail.is,https://github.com/hail-is/hail/pull/7076,1,['echo'],['echoes']
Availability,[hail] Useful error message instead of NPE on missing resource,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4678:14,error,error,14,https://hail.is,https://github.com/hail-is/hail/pull/4678,1,['error'],['error']
Availability,[hail] Warnings are errors,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5951:20,error,errors,20,https://hail.is,https://github.com/hail-is/hail/pull/5951,1,['error'],['errors']
Availability,[hail] Wrap AbstractRVDSpec.read failure to log the path,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9514:33,failure,failure,33,https://hail.is,https://github.com/hail-is/hail/pull/9514,1,['failure'],['failure']
Availability,[hail] bad error message in import_matrix_table,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5718:11,error,error,11,https://hail.is,https://github.com/hail-is/hail/issues/5718,1,['error'],['error']
Availability,[hail] bad error on locus_from_global_position OOB,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8114:11,error,error,11,https://hail.is,https://github.com/hail-is/hail/issues/8114,1,['error'],['error']
Availability,[hail] error if IR is defined in neither emit nor emitI,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8713:7,error,error,7,https://hail.is,https://github.com/hail-is/hail/pull/8713,1,['error'],['error']
Availability,[hail] fix init_notebook.py error handling,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9002:28,error,error,28,https://hail.is,https://github.com/hail-is/hail/pull/9002,1,['error'],['error']
Availability,[hail] fix init_notebook.py error handling 2,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9003:28,error,error,28,https://hail.is,https://github.com/hail-is/hail/pull/9003,1,['error'],['error']
Availability,[hail] fix location of hail jar in error message,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11179:35,error,error,35,https://hail.is,https://github.com/hail-is/hail/pull/11179,1,['error'],['error']
Availability,[hail] improve error message for MatrixTable.__getitem__,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6781:15,error,error,15,https://hail.is,https://github.com/hail-is/hail/pull/6781,1,['error'],['error']
Availability,[hail] include Python stack trace in ArrayRef out-of-bounds error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7792:60,error,error,60,https://hail.is,https://github.com/hail-is/hail/pull/7792,1,['error'],['error']
Availability,[hail] make Hail PyPI deployment robust,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4812:33,robust,robust,33,https://hail.is,https://github.com/hail-is/hail/pull/4812,1,['robust'],['robust']
Availability,[hail] nicer error msg for ibd,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6063:13,error,error,13,https://hail.is,https://github.com/hail-is/hail/pull/6063,1,['error'],['error']
Availability,[hail] no more double close errors,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9001:28,error,errors,28,https://hail.is,https://github.com/hail-is/hail/pull/9001,1,['error'],['errors']
Availability,[hail] retry gradle download,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8782:20,down,download,20,https://hail.is,https://github.com/hail-is/hail/pull/8782,1,['down'],['download']
Availability,[hail] retry transient errors in get_1kg,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8218:23,error,errors,23,https://hail.is,https://github.com/hail-is/hail/pull/8218,1,['error'],['errors']
Availability,[hail] using a reference fasta seems to trigger mkdirs errors,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6564:55,error,errors,55,https://hail.is,https://github.com/hail-is/hail/issues/6564,1,['error'],['errors']
Availability,[hail][bad error message] Improve errors when trying to import dirs,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5302:11,error,error,11,https://hail.is,https://github.com/hail-is/hail/pull/5302,2,['error'],"['error', 'errors']"
Availability,[hail][bugfix] Don't push down intervals into old files,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7588:26,down,down,26,https://hail.is,https://github.com/hail-is/hail/pull/7588,1,['down'],['down']
Availability,[hail][bugfix] Fix divide by zero error in `hl.concordance`,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7976:34,error,error,34,https://hail.is,https://github.com/hail-is/hail/pull/7976,1,['error'],['error']
Availability,[hail][feature] Improve DictExpression.__getitem__ error message.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6202:51,error,error,51,https://hail.is,https://github.com/hail-is/hail/pull/6202,1,['error'],['error']
Availability,[hail][hailctl] hailctl fails with cryptic error messages,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6565:43,error,error,43,https://hail.is,https://github.com/hail-is/hail/issues/6565,1,['error'],['error']
Availability,[hail][internal] Improve error messages when normalize names fails,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8764:25,error,error,25,https://hail.is,https://github.com/hail-is/hail/pull/8764,1,['error'],['error']
Availability,[hail][ir] improve error message when unify fails in PruneDeadFields,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8728:19,error,error,19,https://hail.is,https://github.com/hail-is/hail/pull/8728,1,['error'],['error']
Availability,[hail][ir] teach function registry to raise helpful errors,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8716:52,error,errors,52,https://hail.is,https://github.com/hail-is/hail/pull/8716,1,['error'],['errors']
Availability,[hailctl dataproc] Tolerate user passing --pkgs that we set,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8946:19,Toler,Tolerate,19,https://hail.is,https://github.com/hail-is/hail/pull/8946,1,['Toler'],['Tolerate']
Availability,[hailctl] Error in `hailctl dataproc modify` instead of silently exit,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7717:10,Error,Error,10,https://hail.is,https://github.com/hail-is/hail/pull/7717,1,['Error'],['Error']
Availability,[hailctl] Improve VEP region error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8462:29,error,error,29,https://hail.is,https://github.com/hail-is/hail/pull/8462,1,['error'],['error']
Availability,[hailctl] error on unrecognized arguments,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12524:10,error,error,10,https://hail.is,https://github.com/hail-is/hail/pull/12524,1,['error'],['error']
Availability,[hailctl] generate a friendly error message if not authenticated,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7035:30,error,error,30,https://hail.is,https://github.com/hail-is/hail/pull/7035,1,['error'],['error']
Availability,[hailctl] retry copy paste login on transient error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8669:46,error,error,46,https://hail.is,https://github.com/hail-is/hail/pull/8669,1,['error'],['error']
Availability,[hailctl][devdeploy] improve error messages,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8846:29,error,error,29,https://hail.is,https://github.com/hail-is/hail/pull/8846,1,['error'],['error']
Availability,[hailgenetics/hail] slim down to ~1.5GiB from 2.8GiB,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12526:25,down,down,25,https://hail.is,https://github.com/hail-is/hail/pull/12526,1,['down'],['down']
Availability,[hailtop.batch] Fix BatchPoolExecutor to cancel batches on errors,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10696:59,error,errors,59,https://hail.is,https://github.com/hail-is/hail/pull/10696,1,['error'],['errors']
Availability,[hailtop.utils] Add address not available as a retryable error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14185:32,avail,available,32,https://hail.is,https://github.com/hail-is/hail/pull/14185,2,"['avail', 'error']","['available', 'error']"
Availability,[hailtop.utils] Add new transient error to the list,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11817:34,error,error,34,https://hail.is,https://github.com/hail-is/hail/pull/11817,1,['error'],['error']
Availability,[hailtop.utils] Add quota exceeded to transient error list,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10620:48,error,error,48,https://hail.is,https://github.com/hail-is/hail/pull/10620,1,['error'],['error']
Availability,"[hailtop.utils] include std{out, err} in subprocess failure exception",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7457:52,failure,failure,52,https://hail.is,https://github.com/hail-is/hail/pull/7457,1,['failure'],['failure']
Availability,[hailtop] Add TransportError to list of transient errors,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8111:50,error,errors,50,https://hail.is,https://github.com/hail-is/hail/pull/8111,1,['error'],['errors']
Availability,[hailtop] Don't log rate limit errors,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14605:31,error,errors,31,https://hail.is,https://github.com/hail-is/hail/pull/14605,1,['error'],['errors']
Availability,[hailtop] Don't log rate limit errors at info or warning level,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14595:31,error,errors,31,https://hail.is,https://github.com/hail-is/hail/issues/14595,1,['error'],['errors']
Availability,[hailtop] Dont assume exact error message match for ClientPayloadError retrying,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14545:28,error,error,28,https://hail.is,https://github.com/hail-is/hail/pull/14545,1,['error'],['error']
Availability,[hailtop] add new transient error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11169:28,error,error,28,https://hail.is,https://github.com/hail-is/hail/pull/11169,1,['error'],['error']
Availability,[hailtop] add retry once errors,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11917:25,error,errors,25,https://hail.is,https://github.com/hail-is/hail/pull/11917,1,['error'],['errors']
Availability,[hailtop] avoid errors on rare transient errors,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13921:16,error,errors,16,https://hail.is,https://github.com/hail-is/hail/pull/13921,2,['error'],['errors']
Availability,[hailtop] batch client: only retry temporary failures,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7215:45,failure,failures,45,https://hail.is,https://github.com/hail-is/hail/pull/7215,1,['failure'],['failures']
Availability,[hailtop] better errors in Azure FS,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11292:17,error,errors,17,https://hail.is,https://github.com/hail-is/hail/pull/11292,1,['error'],['errors']
Availability,[hailtop] eagerly give transient error info and include delay,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11769:33,error,error,33,https://hail.is,https://github.com/hail-is/hail/pull/11769,1,['error'],['error']
Availability,[hailtop] fix retry transient errors not falling through if statements,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8103:30,error,errors,30,https://hail.is,https://github.com/hail-is/hail/pull/8103,1,['error'],['errors']
Availability,[hailtop] improve stack traces for retry once errors,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11948:46,error,errors,46,https://hail.is,https://github.com/hail-is/hail/pull/11948,1,['error'],['errors']
Availability,[hailtop] less noisy and less scary warning for transient errors,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11818:58,error,errors,58,https://hail.is,https://github.com/hail-is/hail/pull/11818,1,['error'],['errors']
Availability,[hailtop] log every tenth error message,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7759:26,error,error,26,https://hail.is,https://github.com/hail-is/hail/pull/7759,1,['error'],['error']
Availability,[hailtop] use the exact same error message for sync and async,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10312:29,error,error,29,https://hail.is,https://github.com/hail-is/hail/pull/10312,1,['error'],['error']
Availability,[hailtop] we forgot to note one of the two error codes,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11043:43,error,error,43,https://hail.is,https://github.com/hail-is/hail/pull/11043,1,['error'],['error']
Availability,[hailtop] yet another transient error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13817:32,error,error,32,https://hail.is,https://github.com/hail-is/hail/pull/13817,1,['error'],['error']
Availability,[hailtop][batch] unify & simplify docker transient error handling,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11943:51,error,error,51,https://hail.is,https://github.com/hail-is/hail/pull/11943,2,['error'],['error']
Availability,[hdinsight] fix syntax error in hdinisght/resources/install-vep.sh,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12870:23,error,error,23,https://hail.is,https://github.com/hail-is/hail/pull/12870,1,['error'],['error']
Availability,"[image-fetcher,site] clean up normal bash output from error logs",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9991:54,error,error,54,https://hail.is,https://github.com/hail-is/hail/pull/9991,1,['error'],['error']
Availability,[image-fetcher] only redirect errors to stderr and remove old Make rules,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9930:30,error,errors,30,https://hail.is,https://github.com/hail-is/hail/pull/9930,1,['error'],['errors']
Availability,[infra] dev namespaces should scale down,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14020:36,down,down,36,https://hail.is,https://github.com/hail-is/hail/issues/14020,1,['down'],['down']
Availability,[infra] use skopeo for copying when its available,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11190:40,avail,available,40,https://hail.is,https://github.com/hail-is/hail/pull/11190,1,['avail'],['available']
Availability,[is.hail.services] more transient errors,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10945:34,error,errors,34,https://hail.is,https://github.com/hail-is/hail/pull/10945,1,['error'],['errors']
Availability,[java-services] add new transient error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11402:34,error,error,34,https://hail.is,https://github.com/hail-is/hail/pull/11402,1,['error'],['error']
Availability,[jvm-services] add retry once errors to JVM too,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11947:30,error,errors,30,https://hail.is,https://github.com/hail-is/hail/pull/11947,1,['error'],['errors']
Availability,[k8s] Hail should have no k8s error logs,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13557:30,error,error,30,https://hail.is,https://github.com/hail-is/hail/issues/13557,1,['error'],['error']
Availability,[k8s] Scale down dev namespaces every night,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13462:12,down,down,12,https://hail.is,https://github.com/hail-is/hail/pull/13462,1,['down'],['down']
Availability,[k8s] more PDBs to allow scale down of non-preemptibles,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13384:31,down,down,31,https://hail.is,https://github.com/hail-is/hail/pull/13384,1,['down'],['down']
Availability,[linting] Catch unintended errors in check-sql.sh,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13745:27,error,errors,27,https://hail.is,https://github.com/hail-is/hail/pull/13745,1,['error'],['errors']
Availability,[notebook] Fix error page,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7158:15,error,error,15,https://hail.is,https://github.com/hail-is/hail/pull/7158,1,['error'],['error']
Availability,[notebook] Make notebook deletion reliable,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4863:34,reliab,reliable,34,https://hail.is,https://github.com/hail-is/hail/pull/4863,1,['reliab'],['reliable']
Availability,[notebook] Tolerate spot instances on Azure,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11107:11,Toler,Tolerate,11,https://hail.is,https://github.com/hail-is/hail/pull/11107,1,['Toler'],['Tolerate']
Availability,[notebook] download the course tar,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4965:11,down,download,11,https://hail.is,https://github.com/hail-is/hail/pull/4965,1,['down'],['download']
Availability,[notebook] fix notebook error message,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7255:24,error,error,24,https://hail.is,https://github.com/hail-is/hail/pull/7255,1,['error'],['error']
Availability,[notebook] fix resource requests so deployment can downscale,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10230:51,down,downscale,51,https://hail.is,https://github.com/hail-is/hail/pull/10230,1,['down'],['downscale']
Availability,[notebook] fix syntactic error in JSON,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4990:25,error,error,25,https://hail.is,https://github.com/hail-is/hail/pull/4990,1,['error'],['error']
Availability,[notebook] workaround for pip error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5227:30,error,error,30,https://hail.is,https://github.com/hail-is/hail/pull/5227,1,['error'],['error']
Availability,[pipeline] fix failed jobs error message,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6354:27,error,error,27,https://hail.is,https://github.com/hail-is/hail/pull/6354,1,['error'],['error']
Availability,[pipeline] fix job id in error message,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6255:25,error,error,25,https://hail.is,https://github.com/hail-is/hail/pull/6255,1,['error'],['error']
Availability,[pipeline] tricky errors on typos,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8011:18,error,errors,18,https://hail.is,https://github.com/hail-is/hail/issues/8011,1,['error'],['errors']
Availability,[pytest] Treat most warnings as errors,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12322:32,error,errors,32,https://hail.is,https://github.com/hail-is/hail/pull/12322,1,['error'],['errors']
Availability,"[qob] In GCS, recreate the ReadChannel if a transient error occurs",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13730:54,error,error,54,https://hail.is,https://github.com/hail-is/hail/pull/13730,1,['error'],['error']
Availability,[qob] Invalidate batch cache on error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12519:32,error,error,32,https://hail.is,https://github.com/hail-is/hail/pull/12519,1,['error'],['error']
Availability,[qob] cleanup QoB tests without erroring,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13564:32,error,erroring,32,https://hail.is,https://github.com/hail-is/hail/pull/13564,1,['error'],['erroring']
Availability,[qob] install-for-qob errors if javac is not 1.8,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13734:22,error,errors,22,https://hail.is,https://github.com/hail-is/hail/pull/13734,1,['error'],['errors']
Availability,[qob] log4j errors are showing up in JVM container logs,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13242:12,error,errors,12,https://hail.is,https://github.com/hail-is/hail/issues/13242,1,['error'],['errors']
Availability,[qob] novel transient error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13075:22,error,error,22,https://hail.is,https://github.com/hail-is/hail/pull/13075,1,['error'],['error']
Availability,[qob] permissions error is not propagated back to driver job properly,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13697:18,error,error,18,https://hail.is,https://github.com/hail-is/hail/issues/13697,1,['error'],['error']
Availability,[qob] retry transient errors reading the results file,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12867:22,error,errors,22,https://hail.is,https://github.com/hail-is/hail/pull/12867,1,['error'],['errors']
Availability,[qob][batch] do not list all jobs on failure (plus: types!),MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13500:37,failure,failure,37,https://hail.is,https://github.com/hail-is/hail/pull/13500,1,['failure'],['failure']
Availability,[query/service] fast path for checkpoint and persist,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11677:30,checkpoint,checkpoint,30,https://hail.is,https://github.com/hail-is/hail/pull/11677,1,['checkpoint'],['checkpoint']
Availability,[query/service] fix some errors revealed by pyright,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11600:25,error,errors,25,https://hail.is,https://github.com/hail-is/hail/pull/11600,1,['error'],['errors']
Availability,[query/service] make available driver progress information,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11746:21,avail,available,21,https://hail.is,https://github.com/hail-is/hail/pull/11746,1,['avail'],['available']
Availability,[query/service] retry entire partition when we encounter transient errors in compiled code,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11716:67,error,errors,67,https://hail.is,https://github.com/hail-is/hail/pull/11716,1,['error'],['errors']
Availability,[query/service] use error id to raise user-friendly errors,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11624:20,error,error,20,https://hail.is,https://github.com/hail-is/hail/pull/11624,4,['error'],"['error', 'errors']"
Availability,[query/services] retry Azure errors,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11919:29,error,errors,29,https://hail.is,https://github.com/hail-is/hail/pull/11919,1,['error'],['errors']
Availability,[query/vds] Don't error if combiner is finished and output exists,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14397:18,error,error,18,https://hail.is,https://github.com/hail-is/hail/pull/14397,1,['error'],['error']
Availability,[query] Add `hl.die` function for error checking.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8865:34,error,error,34,https://hail.is,https://github.com/hail-is/hail/pull/8865,1,['error'],['error']
Availability,[query] Add back line context to table parsing errors,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8900:47,error,errors,47,https://hail.is,https://github.com/hail-is/hail/pull/8900,1,['error'],['errors']
Availability,[query] Add better error to CastMatrixToTable length check,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12178:19,error,error,19,https://hail.is,https://github.com/hail-is/hail/pull/12178,1,['error'],['error']
Availability,"[query] Add good error messages for semi/anti join, fix semantics",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12316:17,error,error,17,https://hail.is,https://github.com/hail-is/hail/pull/12316,1,['error'],['error']
Availability,[query] Add more transient error handling,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14516:27,error,error,27,https://hail.is,https://github.com/hail-is/hail/pull/14516,1,['error'],['error']
Availability,[query] Add nicer errors for unsupported functionality in the service,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11641:18,error,errors,18,https://hail.is,https://github.com/hail-is/hail/pull/11641,1,['error'],['errors']
Availability,[query] Automatically copy logs off spark driver before failure,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14431:56,failure,failure,56,https://hail.is,https://github.com/hail-is/hail/issues/14431,1,['failure'],['failure']
Availability,[query] Better error message on locus_windows,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11321:15,error,error,15,https://hail.is,https://github.com/hail-is/hail/pull/11321,1,['error'],['error']
Availability,[query] Better error message when using `in` incorrectly,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9164:15,error,error,15,https://hail.is,https://github.com/hail-is/hail/pull/9164,1,['error'],['error']
Availability,[query] Better error messages for unsupported types in export_vcf,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13682:15,error,error,15,https://hail.is,https://github.com/hail-is/hail/pull/13682,1,['error'],['error']
Availability,[query] Better import vcf error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10819:26,error,error,26,https://hail.is,https://github.com/hail-is/hail/pull/10819,1,['error'],['error']
Availability,[query] Better intersect assertion error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8701:35,error,error,35,https://hail.is,https://github.com/hail-is/hail/pull/8701,1,['error'],['error']
Availability,[query] Copy spark driver log to remote tmpdir on error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14447:50,error,error,50,https://hail.is,https://github.com/hail-is/hail/pull/14447,1,['error'],['error']
Availability,[query] Don't error on VCF export when haploid call is unphased,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14375:14,error,error,14,https://hail.is,https://github.com/hail-is/hail/pull/14375,1,['error'],['error']
Availability,[query] Erroneous error on export_vcf when exporting haploid calls,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14330:18,error,error,18,https://hail.is,https://github.com/hail-is/hail/issues/14330,1,['error'],['error']
Availability,[query] ErrorIDs,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10655:8,Error,ErrorIDs,8,https://hail.is,https://github.com/hail-is/hail/pull/10655,1,['Error'],['ErrorIDs']
Availability,[query] Failures to communicate with the spark/local backend result in cryptic error message,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14557:8,Failure,Failures,8,https://hail.is,https://github.com/hail-is/hail/issues/14557,2,"['Failure', 'error']","['Failures', 'error']"
Availability,[query] Fix Benchmark Failures,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13954:22,Failure,Failures,22,https://hail.is,https://github.com/hail-is/hail/pull/13954,1,['Failure'],['Failures']
Availability,[query] Fix `hl.agg.downsample` inside array_agg or group_by,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8273:20,down,downsample,20,https://hail.is,https://github.com/hail-is/hail/pull/8273,1,['down'],['downsample']
Availability,[query] Fix attr error for struct collections,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8466:17,error,error,17,https://hail.is,https://github.com/hail-is/hail/pull/8466,1,['error'],['error']
Availability,[query] Fix bad error message from `mt.make_table()` with missing keys,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8275:16,error,error,16,https://hail.is,https://github.com/hail-is/hail/pull/8275,1,['error'],['error']
Availability,"[query] Fix bug in call decoding, add error ID to lgt_to_gt",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11022:38,error,error,38,https://hail.is,https://github.com/hail-is/hail/pull/11022,2,['error'],['error']
Availability,[query] Fix corner case assertion failure in tabix read,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9304:34,failure,failure,34,https://hail.is,https://github.com/hail-is/hail/pull/9304,1,['failure'],['failure']
Availability,[query] Fix error context for import_table impute too,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8906:12,error,error,12,https://hail.is,https://github.com/hail-is/hail/pull/8906,1,['error'],['error']
Availability,[query] Fix errors in LowerToCDA.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9202:12,error,errors,12,https://hail.is,https://github.com/hail-is/hail/pull/9202,1,['error'],['errors']
Availability,[query] Fix int overflow in generic lines and add error for size limit,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10790:50,error,error,50,https://hail.is,https://github.com/hail-is/hail/pull/10790,1,['error'],['error']
Availability,[query] Fix magic collection struct errors,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10608:36,error,errors,36,https://hail.is,https://github.com/hail-is/hail/pull/10608,1,['error'],['errors']
Availability,[query] Fix partitioner memory error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8987:31,error,error,31,https://hail.is,https://github.com/hail-is/hail/pull/8987,1,['error'],['error']
Availability,[query] Good error for `localize_entries` to existing field name,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12080:13,error,error,13,https://hail.is,https://github.com/hail-is/hail/pull/12080,1,['error'],['error']
Availability,[query] GoogleFS: recreate reader on transient error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13371:47,error,error,47,https://hail.is,https://github.com/hail-is/hail/pull/13371,1,['error'],['error']
Availability,[query] Improve error handling and job tracking in ServiceBackend,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14751:16,error,error,16,https://hail.is,https://github.com/hail-is/hail/pull/14751,1,['error'],['error']
Availability,[query] Improve error message from hadoop_ls when file does not exist,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10007:16,error,error,16,https://hail.is,https://github.com/hail-is/hail/pull/10007,1,['error'],['error']
Availability,[query] Improve file compatibility error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10191:35,error,error,35,https://hail.is,https://github.com/hail-is/hail/pull/10191,1,['error'],['error']
Availability,"[query] In Azure, QoB sees elevated rates of weird errors from the Azure Blob Storage SDK",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13351:51,error,errors,51,https://hail.is,https://github.com/hail-is/hail/issues/13351,1,['error'],['errors']
Availability,"[query] In Google, large pipelines which encounter transient errors often fail to cleanly restart.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13356:61,error,errors,61,https://hail.is,https://github.com/hail-is/hail/issues/13356,1,['error'],['errors']
Availability,[query] Include file in metadata parse error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8879:39,error,error,39,https://hail.is,https://github.com/hail-is/hail/pull/8879,1,['error'],['error']
Availability,[query] Include info field key in parse error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10211:40,error,error,40,https://hail.is,https://github.com/hail-is/hail/pull/10211,1,['error'],['error']
Availability,[query] Inspect error causes in isRetryOnceError,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11963:16,error,error,16,https://hail.is,https://github.com/hail-is/hail/pull/11963,1,['error'],['error']
Availability,[query] Log FASTA downloads,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12217:18,down,downloads,18,https://hail.is,https://github.com/hail-is/hail/pull/12217,1,['down'],['downloads']
Availability,[query] Make export entries by col more fault-tolerant,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8558:40,fault,fault-tolerant,40,https://hail.is,https://github.com/hail-is/hail/pull/8558,1,['fault'],['fault-tolerant']
Availability,[query] MakeNDArray uses Better Python Error system,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10095:39,Error,Error,39,https://hail.is,https://github.com/hail-is/hail/pull/10095,1,['Error'],['Error']
Availability,[query] Match Error Unreachable Interval,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10765:14,Error,Error,14,https://hail.is,https://github.com/hail-is/hail/pull/10765,1,['Error'],['Error']
Availability,"[query] Memory error in VDS combiner after adding, then immidiately dropping a field.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14705:15,error,error,15,https://hail.is,https://github.com/hail-is/hail/issues/14705,1,['error'],['error']
Availability,[query] NDArray Matmul Better Error Message,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10298:30,Error,Error,30,https://hail.is,https://github.com/hail-is/hail/pull/10298,1,['Error'],['Error']
Availability,[query] Provide more informative error on tabix crash,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9065:33,error,error,33,https://hail.is,https://github.com/hail-is/hail/pull/9065,1,['error'],['error']
Availability,[query] Remove unused and redundant requirements,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13988:26,redundant,redundant,26,https://hail.is,https://github.com/hail-is/hail/pull/13988,1,['redundant'],['redundant']
Availability,[query] Retry downloadStreamWithResponse in AzureStorageFS,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12261:14,down,downloadStreamWithResponse,14,https://hail.is,https://github.com/hail-is/hail/pull/12261,1,['down'],['downloadStreamWithResponse']
Availability,[query] Retry transient errors in HadoopFS,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12411:24,error,errors,24,https://hail.is,https://github.com/hail-is/hail/pull/12411,1,['error'],['errors']
Availability,[query] SIGSEGV from downsample aggregator,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8240:21,down,downsample,21,https://hail.is,https://github.com/hail-is/hail/issues/8240,1,['down'],['downsample']
Availability,[query] Slightly better Error Message from realized_relationship_matrix,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9733:24,Error,Error,24,https://hail.is,https://github.com/hail-is/hail/pull/9733,1,['Error'],['Error']
Availability,[query] Throw a validation error for queries that read/write same path,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8327:27,error,error,27,https://hail.is,https://github.com/hail-is/hail/pull/8327,1,['error'],['error']
Availability,[query] Throw better error in VCFLine.nextField if separator is not a tab,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9494:21,error,error,21,https://hail.is,https://github.com/hail-is/hail/pull/9494,1,['error'],['error']
Availability,[query] Unhandled transient error for GCS 503s,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13937:28,error,error,28,https://hail.is,https://github.com/hail-is/hail/issues/13937,1,['error'],['error']
Availability,[query] Update ExportVCF error messages,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14742:25,error,error,25,https://hail.is,https://github.com/hail-is/hail/pull/14742,1,['error'],['error']
Availability,[query] Update requiredness of DownsampleAggregator,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8299:31,Down,DownsampleAggregator,31,https://hail.is,https://github.com/hail-is/hail/pull/8299,1,['Down'],['DownsampleAggregator']
Availability,[query] Use error code for ArrayRef,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10119:12,error,error,12,https://hail.is,https://github.com/hail-is/hail/pull/10119,1,['error'],['error']
Availability,[query] Use fast LZ4 codec for Table.checkpoint,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9264:37,checkpoint,checkpoint,37,https://hail.is,https://github.com/hail-is/hail/pull/9264,1,['checkpoint'],['checkpoint']
Availability,[query] Zip length mismatch error on join,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13486:28,error,error,28,https://hail.is,https://github.com/hail-is/hail/issues/13486,1,['error'],['error']
Availability,[query] add a small & incomplete test suite for good index errors,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12566:59,error,errors,59,https://hail.is,https://github.com/hail-is/hail/pull/12566,1,['error'],['errors']
Availability,[query] add max_iterations and tolerance parameters to all iterative regressions,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11759:31,toler,tolerance,31,https://hail.is,https://github.com/hail-is/hail/pull/11759,1,['toler'],['tolerance']
Availability,[query] address another rare Google error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12523:36,error,error,36,https://hail.is,https://github.com/hail-is/hail/pull/12523,1,['error'],['error']
Availability,[query] await batch debug info on error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12494:34,error,error,34,https://hail.is,https://github.com/hail-is/hail/pull/12494,1,['error'],['error']
Availability,[query] bad error message in ir/renderer.py,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13788:12,error,error,12,https://hail.is,https://github.com/hail-is/hail/issues/13788,1,['error'],['error']
Availability,[query] bad error message when indexing a matrix table with row keys,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14237:12,error,error,12,https://hail.is,https://github.com/hail-is/hail/issues/14237,1,['error'],['error']
Availability,[query] bad error message when user needs to use array_elements_required=False,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13346:12,error,error,12,https://hail.is,https://github.com/hail-is/hail/issues/13346,1,['error'],['error']
Availability,[query] better error message in union_cols,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13144:15,error,error,15,https://hail.is,https://github.com/hail-is/hail/pull/13144,1,['error'],['error']
Availability,[query] better error message when info array field has missing elements,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14105:15,error,error,15,https://hail.is,https://github.com/hail-is/hail/pull/14105,1,['error'],['error']
Availability,[query] better error messages for hstack and vstack,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12636:15,error,error,15,https://hail.is,https://github.com/hail-is/hail/pull/12636,1,['error'],['error']
Availability,[query] better hl.nd.concatenate error message,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12750:33,error,error,33,https://hail.is,https://github.com/hail-is/hail/pull/12750,1,['error'],['error']
Availability,[query] cleave Backend paths into normal parallelize and parallelize returning errors,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14085:79,error,errors,79,https://hail.is,https://github.com/hail-is/hail/pull/14085,1,['error'],['errors']
Availability,[query] error in Make if git is missing,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12872:8,error,error,8,https://hail.is,https://github.com/hail-is/hail/pull/12872,1,['error'],['error']
Availability,[query] error when annotating a matrix table with a table (joins),MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13339:8,error,error,8,https://hail.is,https://github.com/hail-is/hail/issues/13339,1,['error'],['error']
Availability,[query] error when sampling an entries table,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14303:8,error,error,8,https://hail.is,https://github.com/hail-is/hail/issues/14303,1,['error'],['error']
Availability,[query] fix error in hardy_weinberg_test docs,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10750:12,error,error,12,https://hail.is,https://github.com/hail-is/hail/pull/10750,1,['error'],['error']
Availability,[query] fix lint errors in matrixtable.py,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8749:17,error,errors,17,https://hail.is,https://github.com/hail-is/hail/pull/8749,1,['error'],['errors']
Availability,[query] fix matrix table query error message,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9110:31,error,error,31,https://hail.is,https://github.com/hail-is/hail/pull/9110,1,['error'],['error']
Availability,[query] handle retry once errors in the correct order,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12160:26,error,errors,26,https://hail.is,https://github.com/hail-is/hail/pull/12160,2,['error'],['errors']
Availability,"[query] hl.plot.manhattan uses `collect_all=True` to mean ""do not downsample",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13696:66,down,downsample,66,https://hail.is,https://github.com/hail-is/hail/issues/13696,1,['down'],['downsample']
Availability,[query] import_table better error empty missing,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11078:28,error,error,28,https://hail.is,https://github.com/hail-is/hail/pull/11078,1,['error'],['error']
Availability,[query] import_vcf: tolerate Flag fields with invalid number,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10491:20,toler,tolerate,20,https://hail.is,https://github.com/hail-is/hail/pull/10491,1,['toler'],['tolerate']
Availability,[query] improve error message when HAIL_CLOUD is unset,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12687:16,error,error,16,https://hail.is,https://github.com/hail-is/hail/pull/12687,1,['error'],['error']
Availability,[query] improve error message when rng_nonce is unparseable,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12688:16,error,error,16,https://hail.is,https://github.com/hail-is/hail/pull/12688,1,['error'],['error']
Availability,[query] improve hl.agg.call_stats error messages,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12676:34,error,error,34,https://hail.is,https://github.com/hail-is/hail/pull/12676,1,['error'],['error']
Availability,[query] increase tolerance in approx_cdf tests,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14058:17,toler,tolerance,17,https://hail.is,https://github.com/hail-is/hail/pull/14058,1,['toler'],['tolerance']
Availability,[query] increase whitening test tolerance,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12921:32,toler,tolerance,32,https://hail.is,https://github.com/hail-is/hail/pull/12921,1,['toler'],['tolerance']
Availability,[query] persist is checkpoint,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11936:19,checkpoint,checkpoint,19,https://hail.is,https://github.com/hail-is/hail/pull/11936,1,['checkpoint'],['checkpoint']
Availability,[query] persist=checkpoint in all backends,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12309:16,checkpoint,checkpoint,16,https://hail.is,https://github.com/hail-is/hail/pull/12309,1,['checkpoint'],['checkpoint']
Availability,[query] pipeline triggers type inference failure,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13699:41,failure,failure,41,https://hail.is,https://github.com/hail-is/hail/issues/13699,1,['failure'],['failure']
Availability,[query] provide a better error message in test_ndarray_solve,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10365:25,error,error,25,https://hail.is,https://github.com/hail-is/hail/pull/10365,1,['error'],['error']
Availability,[query] rare Google Cloud Storage error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13721:34,error,error,34,https://hail.is,https://github.com/hail-is/hail/issues/13721,1,['error'],['error']
Availability,[query] relax tolerance in local whitening test,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14053:14,toler,tolerance,14,https://hail.is,https://github.com/hail-is/hail/pull/14053,1,['toler'],['tolerance']
Availability,[query] show and checkpoint are very slow in Jupyter Notebooks; they are not slow outside Jupyter,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13690:17,checkpoint,checkpoint,17,https://hail.is,https://github.com/hail-is/hail/issues/13690,1,['checkpoint'],['checkpoint']
Availability,[query][qob] simplify QoB error handling and fix flaky test,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12470:26,error,error,26,https://hail.is,https://github.com/hail-is/hail/pull/12470,2,['error'],['error']
Availability,"[ruff](https://beta.ruff.rs/docs/) is a *very* fast linter that we can use as a drop-in replacement for flake8 and isort. Fast enough to run in a pre-commit hook. While there are many pylint rules implemented in ruff, it is not at parity with pylint yet. This PR replaces flake8 and isort in favor of ruff but does not remove pylint yet. Nevertheless, from what I have seen so far ruff + mypy does catch a vast swath of everyday errors, and I have found that the 30+ seconds it can take to run pylint on any of our python modules is a deterrent to me linting often and catching lint errors early. So I added Makefile targets such as `check-batch-fast` that run all the linters except for pylint. The `check-batch` rule now does `check-batch-fast` and `pylint-batch`. So linter coverage should have strictly increased in CI, but there is a <5s linting target now available for devs in addition to the >30s it can take to also run pylint. You can also now just run `ruff .` in the root of the repo and it completes for me in 0.293 seconds. For the most part in this PR, I added ruff, with the config enabling flake8 + isort + pylint rules, then disabled rules until there were no errors, save for a few rules that I thought to just fix immediately. These mostly line up with the flake8 rules we had already disabled. I also then added ruff's own ruleset ([RUF](https://beta.ruff.rs/docs/rules/#ruff-specific-rules-ruf)) particularly because I appreciated the `asyncio-dangling-task` and `unused-noqa` rules.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12967:429,error,errors,429,https://hail.is,https://github.com/hail-is/hail/pull/12967,4,"['avail', 'error']","['available', 'errors']"
Availability,[scorecard] tolerate rate limiting,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6303:12,toler,tolerate,12,https://hail.is,https://github.com/hail-is/hail/pull/6303,1,['toler'],['tolerate']
Availability,[service-base] fix libsass by downgrading google-cloud-profiler,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12544:30,down,downgrading,30,https://hail.is,https://github.com/hail-is/hail/pull/12544,1,['down'],['downgrading']
Availability,[services-java] new transient error observed,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11407:30,error,error,30,https://hail.is,https://github.com/hail-is/hail/pull/11407,1,['error'],['error']
Availability,[services/Java] retry retryable http client errors,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8802:44,error,errors,44,https://hail.is,https://github.com/hail-is/hail/pull/8802,1,['error'],['errors']
Availability,[services] Yet Another Transient Error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10468:33,Error,Error,33,https://hail.is,https://github.com/hail-is/hail/pull/10468,1,['Error'],['Error']
Availability,[services] also increase memory available,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9453:32,avail,available,32,https://hail.is,https://github.com/hail-is/hail/pull/9453,1,['avail'],['available']
Availability,[services] indicate how many errors we have seen,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12984:29,error,errors,29,https://hail.is,https://github.com/hail-is/hail/pull/12984,1,['error'],['errors']
Availability,[services] more transient errors,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10310:26,error,errors,26,https://hail.is,https://github.com/hail-is/hail/pull/10310,1,['error'],['errors']
Availability,[services] reliably retry all requests,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13029:11,reliab,reliably,11,https://hail.is,https://github.com/hail-is/hail/pull/13029,1,['reliab'],['reliably']
Availability,[services] stop treating all logs as error logs,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9845:37,error,error,37,https://hail.is,https://github.com/hail-is/hail/pull/9845,1,['error'],['error']
Availability,[shuffler] retry transient errors,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9404:27,error,errors,27,https://hail.is,https://github.com/hail-is/hail/pull/9404,1,['error'],['errors']
Availability,[site] actually check that site is alive,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8492:35,alive,alive,35,https://hail.is,https://github.com/hail-is/hail/pull/8492,1,['alive'],['alive']
Availability,[transient-error] new transient error from GCS,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13170:11,error,error,11,https://hail.is,https://github.com/hail-is/hail/pull/13170,2,['error'],['error']
Availability,[transient-errors] will it ever end?,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13043:11,error,errors,11,https://hail.is,https://github.com/hail-is/hail/pull/13043,1,['error'],['errors']
Availability,[utils] Add invalid grant to python retry-once errors,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12170:47,error,errors,47,https://hail.is,https://github.com/hail-is/hail/pull/12170,1,['error'],['errors']
Availability,[utils] Fix cancelled task errors,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10534:27,error,errors,27,https://hail.is,https://github.com/hail-is/hail/pull/10534,1,['error'],['errors']
Availability,[utils] Fix transient error for rateLimitExceeded,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10613:22,error,error,22,https://hail.is,https://github.com/hail-is/hail/pull/10613,1,['error'],['error']
Availability,[utils] YATE: Yet Another Transient Error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10442:36,Error,Error,36,https://hail.is,https://github.com/hail-is/hail/pull/10442,1,['Error'],['Error']
Availability,[utils] include stack trace in retry-transient-errors log,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9716:47,error,errors,47,https://hail.is,https://github.com/hail-is/hail/pull/9716,1,['error'],['errors']
Availability,[utils] more transient errors,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10924:23,error,errors,23,https://hail.is,https://github.com/hail-is/hail/pull/10924,1,['error'],['errors']
Availability,[utils] treat 500 as a transient error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8044:33,error,error,33,https://hail.is,https://github.com/hail-is/hail/pull/8044,1,['error'],['error']
Availability,[vcf combiner] Fix error in determining intermidiate file names,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11962:19,error,error,19,https://hail.is,https://github.com/hail-is/hail/pull/11962,1,['error'],['error']
Availability,[website] fix change_log.md & treat pandoc warnings as errors,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11960:55,error,errors,55,https://hail.is,https://github.com/hail-is/hail/pull/11960,1,['error'],['errors']
Availability,[website] fix linting errors,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10171:22,error,errors,22,https://hail.is,https://github.com/hail-is/hail/pull/10171,1,['error'],['errors']
Availability,[website] minimal changes to enable downloading the tutorials.tar.gz,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10302:36,down,downloading,36,https://hail.is,https://github.com/hail-is/hail/pull/10302,1,['down'],['downloading']
Availability,[wip] replicate rvd partitioner failure,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11354:32,failure,failure,32,https://hail.is,https://github.com/hail-is/hail/pull/11354,1,['failure'],['failure']
Availability,"](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3315331) | `cryptography:` <br> `3.3.2 -> 41.0.6` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **509/1000** <br/> **Why?** Has a fix available, CVSS 5.9 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3315452](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3315452) | `cryptography:` <br> `3.3.2 -> 41.0.6` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **509/1000** <br/> **Why?** Has a fix available, CVSS 5.9 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3315972](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3315972) | `cryptography:` <br> `3.3.2 -> 41.0.6` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **509/1000** <br/> **Why?** Has a fix available, CVSS 5.9 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3315975](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3315975) | `cryptography:` <br> `3.3.2 -> 41.0.6` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **509/1000** <br/> **Why?** Has a fix available, CVSS 5.9 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3316038](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3316038) | `cryptography:` <br> `3.3.2 -> 41.0.6` <br> | No | No Known Exploit ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | **589/1000** <br/> **Why?** Has a fix available, CVSS 7.5 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3316211](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3316211) | `cryptography:` <br> `3.3.2 -> 41.0.6` <br> | No | No Known Exploit ; ![medium severity](https://res.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14148:4526,avail,available,4526,https://hail.is,https://github.com/hail-is/hail/pull/14148,1,['avail'],['available']
Availability,"](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3315331) | `cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **509/1000** <br/> **Why?** Has a fix available, CVSS 5.9 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3315452](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3315452) | `cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **509/1000** <br/> **Why?** Has a fix available, CVSS 5.9 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3315972](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3315972) | `cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **509/1000** <br/> **Why?** Has a fix available, CVSS 5.9 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3315975](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3315975) | `cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **509/1000** <br/> **Why?** Has a fix available, CVSS 5.9 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3316038](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3316038) | `cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No | No Known Exploit ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | **589/1000** <br/> **Why?** Has a fix available, CVSS 7.5 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3316211](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3316211) | `cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No | No Known Exploit ; ![medium severity](https://res.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14327:4518,avail,available,4518,https://hail.is,https://github.com/hail-is/hail/pull/14327,2,['avail'],['available']
Availability,"](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3315452) | `cryptography:` <br> `3.3.2 -> 41.0.6` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **509/1000** <br/> **Why?** Has a fix available, CVSS 5.9 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3315972](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3315972) | `cryptography:` <br> `3.3.2 -> 41.0.6` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **509/1000** <br/> **Why?** Has a fix available, CVSS 5.9 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3315975](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3315975) | `cryptography:` <br> `3.3.2 -> 41.0.6` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **509/1000** <br/> **Why?** Has a fix available, CVSS 5.9 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3316038](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3316038) | `cryptography:` <br> `3.3.2 -> 41.0.6` <br> | No | No Known Exploit ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | **589/1000** <br/> **Why?** Has a fix available, CVSS 7.5 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3316211](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3316211) | `cryptography:` <br> `3.3.2 -> 41.0.6` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **509/1000** <br/> **Why?** Has a fix available, CVSS 5.9 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-5663682](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5663682) | `cryptography:` <br> `3.3.2 -> 41.0.6` <br> | No | No Known Exploit ; ![high severity](https://res.cl",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14148:4895,avail,available,4895,https://hail.is,https://github.com/hail-is/hail/pull/14148,1,['avail'],['available']
Availability,"](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3315452) | `cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **509/1000** <br/> **Why?** Has a fix available, CVSS 5.9 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3315972](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3315972) | `cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **509/1000** <br/> **Why?** Has a fix available, CVSS 5.9 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3315975](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3315975) | `cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **509/1000** <br/> **Why?** Has a fix available, CVSS 5.9 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3316038](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3316038) | `cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No | No Known Exploit ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | **589/1000** <br/> **Why?** Has a fix available, CVSS 7.5 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3316211](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3316211) | `cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **509/1000** <br/> **Why?** Has a fix available, CVSS 5.9 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-5663682](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5663682) | `cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No | No Known Exploit ; ![high severity](https://res.cl",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14327:4887,avail,available,4887,https://hail.is,https://github.com/hail-is/hail/pull/14327,2,['avail'],['available']
Availability,"_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _. func = <function export_vcf at 0x7fa13c4d9938>, args = (<hail.dataset.VariantDataset object at 0x7fa13c3c9390>, 'file:///scratch/test_vcf_export.vcf.bgz', None, False, False), kwargs = {}; e = Py4JJavaError(u'An error occurred while calling o160.exportVCF.\n', JavaObject id=o162), tpl = JavaObject id=o210; deepest = 'ClassNotFoundException: Class org.apache.hadoop.mapred.DirectFileOutputCommitter not found'; full = 'java.lang.RuntimeException: java.lang.RuntimeException: java.lang.ClassNotFoundException: Class org.apache.hadoop.map...mmand.java:79); at py4j.GatewayConnection.run(GatewayConnection.java:214); at java.lang.Thread.run(Thread.java:748). '. @decorator; def handle_py4j(func, *args, **kwargs):; try:; r = func(*args, **kwargs); except py4j.protocol.Py4JJavaError as e:; tpl = Env.jutils().handleForPython(e.java_exception); deepest, full = tpl._1(), tpl._2(); raise FatalError('%s\n\nJava stack trace:\n%s\n'; 'Hail version: %s\n'; > 'Error summary: %s' % (deepest, full, Env.hc().version, deepest)); E FatalError: ClassNotFoundException: Class org.apache.hadoop.mapred.DirectFileOutputCommitter not found; E; E Java stack trace:; E java.lang.RuntimeException: java.lang.RuntimeException: java.lang.ClassNotFoundException: Class org.apache.hadoop.mapred.DirectFileOutputCommitter not found; E at org.apache.hadoop.conf.Configuration.getClass(Configuration.java:2227); E at org.apache.hadoop.mapred.JobConf.getOutputCommitter(JobConf.java:726); E at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$4.apply$mcV$sp(PairRDDFunctions.scala:1051); E at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$4.apply(PairRDDFunctions.scala:1035); E at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$4.apply(PairRDDFunctions.scala:1035); E at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); E at org.apache.spark.rdd.RDDOperationScope$.withScope(RDD",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3946:3374,Error,Error,3374,https://hail.is,https://github.com/hail-is/hail/issues/3946,1,['Error'],['Error']
Availability,"_From @alexb-3 on October 20, 2015 19:43_. These could be implemented as infix methods of a no-overhead RichDouble wrapper class, though we need some flexibility in setting the tolerance. For example, a computation like an exact test might use a stricter tolerance (say 1e-12) than a test (say 1e-6). _Copied from original issue: cseed/hail#84_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/51:177,toler,tolerance,177,https://hail.is,https://github.com/hail-is/hail/issues/51,2,['toler'],['tolerance']
Availability,"_From @alexb-3 on September 30, 2015 20:42_. Note that we are using BibTeX with the common `bibfile.bib`, and that we need a make tool that runs PDFTeX and BibTeX until no errors remain. _Copied from original issue: cseed/hail#68_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/47:172,error,errors,172,https://hail.is,https://github.com/hail-is/hail/issues/47,1,['error'],['errors']
Availability,"_From @cseed on August 26, 2015 14:37_. When designing, consider plinkseq `--mask` option:. https://atgu.mgh.harvard.edu/plinkseq/masks.shtml. and bcftools filter expressions:. https://samtools.github.io/bcftools/bcftools.html#expressions. _Copied from original issue: cseed/hail#15_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/16:77,mask,mask,77,https://hail.is,https://github.com/hail-is/hail/issues/16,2,['mask'],"['mask', 'masks']"
Availability,"_From @cseed on October 22, 2015 13:56_. Andrea is running into some problems with the Estonian dataset in sampleqc:. ```; Exception in thread ""main"" org.apache.spark.SparkException: Job aborted due to stage failure: Total size of serialized results of 2689 tasks (2.0 GB) is bigger than spark.driver.maxResultSize (2.0 GB); ```. _Copied from original issue: cseed/hail#89_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/53:208,failure,failure,208,https://hail.is,https://github.com/hail-is/hail/issues/53,1,['failure'],['failure']
Availability,"_From @cseed on September 1, 2015 15:48_. Need general strategy for error reporting. We can't use asserts for input data validation (e.g., reading tsv files, command line flags, etc.) Need to generate good error messages with feedback about line numbers, etc. _Copied from original issue: cseed/hail#42_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/33:68,error,error,68,https://hail.is,https://github.com/hail-is/hail/issues/33,2,['error'],['error']
Availability,"_From @jbloom22 on September 29, 2015 17:21_. Once we handle multi-allelic sites, we will need to adapt mendel errors so that, for example, it does not double count errors in multi-allelic trios. _Copied from original issue: cseed/hail#65_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/45:111,error,errors,111,https://hail.is,https://github.com/hail-is/hail/issues/45,2,['error'],['errors']
Availability,"__6} --varianceRatioFile=${__RESOURCE_FILE__8}; --SAIGEOutputFile=${__RESOURCE_FILE__748} --groupFile=${__RESOURCE_FILE__20}; --sparseSigmaFile=${__RESOURCE_FILE__9} --IsSingleVarinGroupTest=TRUE --IsOutputAFinCaseCtrl=TRUE; 2>&1 | tee ${__RESOURCE_FILE__749}; env:; - name: POD_IP; valueFrom:; fieldRef:; apiVersion: v1; fieldPath: status.podIP; - name: POD_NAME; valueFrom:; fieldRef:; apiVersion: v1; fieldPath: metadata.name; image: konradjk/saige:0.35.8.2.2; imagePullPolicy: IfNotPresent; name: main; resources:; requests:; cpu: ""1""; memory: 500M; terminationMessagePath: /dev/termination-log; terminationMessagePolicy: File; volumeMounts:; - mountPath: /gsa-key; name: gsa-key; - mountPath: /io; name: batch-2554-job-4-8vvgl; - mountPath: /var/run/secrets/kubernetes.io/serviceaccount; name: default-token-8h99c; readOnly: true; dnsPolicy: ClusterFirst; enableServiceLinks: true; nodeName: gke-vdc-preemptible-pool-9c7148b2-4gq2; priority: 500000; priorityClassName: user; restartPolicy: Never; schedulerName: default-scheduler; securityContext: {}; serviceAccount: default; serviceAccountName: default; terminationGracePeriodSeconds: 30; tolerations:; - key: preemptible; value: ""true""; - effect: NoExecute; key: node.kubernetes.io/not-ready; operator: Exists; tolerationSeconds: 300; - effect: NoExecute; key: node.kubernetes.io/unreachable; operator: Exists; tolerationSeconds: 300; volumes:; - name: gsa-key; secret:; defaultMode: 420; secretName: konradk-gsa-key; - name: batch-2554-job-4-8vvgl; persistentVolumeClaim:; claimName: batch-2554-job-4-8vvgl; - name: default-token-8h99c; secret:; defaultMode: 420; secretName: default-token-8h99c; status:; conditions:; - lastProbeTime: null; lastTransitionTime: ""2019-06-25T03:09:04Z""; status: ""True""; type: Initialized; - lastProbeTime: null; lastTransitionTime: ""2019-06-25T03:09:04Z""; message: 'containers with unready status: [main]'; reason: ContainersNotReady; status: ""False""; type: Ready; - lastProbeTime: null; lastTransitionTime: """,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6466:6367,toler,tolerations,6367,https://hail.is,https://github.com/hail-is/hail/issues/6466,1,['toler'],['tolerations']
Availability,"_avx2::uint16<8>; T = simdpp::arch_avx2::uint8<16>]:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::arch_avx2::uint16<8>; T = simdpp::arch_avx2::uint8<16>; unsigned int MaskCastOverride = 0]; libsimdpp-2.0-rc2/simdpp/core/cast.h:63:89: required from R simdpp::arch_avx2::bit_cast(const T&) [with R = simdpp::arch_avx2::uint16<8>; T = simdpp::arch_avx2::uint8<16>]; libsimdpp-2.0-rc2/simdpp/types/int16x8.h:129:36: required from simdpp::arch_avx2::uint16<8>::uint16(const simdpp::arch_avx2::any_vec<16, V>&) [with V = simdpp::arch_avx2::uint8<16>]; libsimdpp-2.0-rc2/simdpp/detail/insn/bit_or.h:69:58: required from here; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:40:13: error: void* memcpy(void*, const void*, size_t) copying an object of type class simdpp::arch_avx2::uint16<8> with private member simdpp::arch_avx2::uint16<8>::d_ from an array of const class simdpp::arch_avx2::uint8<16>; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/types.h:21,; from libsimdpp-2.0-rc2/simdpp/core/align.h:15,; from libsimdpp-2.0-rc2/simdpp/simd.h:22,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/types/int16x8.h:104:7: note: class simdpp::arch_avx2::uint16<8> declared here; class uint16<8, void> : public any_int16<8, uint16<8,void>> {; ^~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/simd.h:132,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl: In instantiation of R simdpp::arch_avx2::detail::cast_memcpy(const T&) [with R = simdpp::arch_avx2::uint8<16>; T = simdpp::arch_avx2::uint32<4>]:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp:",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3955:7376,error,error,7376,https://hail.is,https://github.com/hail-is/hail/issues/3955,1,['error'],['error']
Availability,"_avx2::uint8<16>; T = simdpp::arch_avx2::uint32<4>]:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::arch_avx2::uint8<16>; T = simdpp::arch_avx2::uint32<4>; unsigned int MaskCastOverride = 0]; libsimdpp-2.0-rc2/simdpp/core/cast.h:63:89: required from R simdpp::arch_avx2::bit_cast(const T&) [with R = simdpp::arch_avx2::uint8<16>; T = simdpp::arch_avx2::uint32<4>]; libsimdpp-2.0-rc2/simdpp/types/int8x16.h:129:36: required from simdpp::arch_avx2::uint8<16>::uint8(const simdpp::arch_avx2::any_vec<16, V>&) [with V = simdpp::arch_avx2::uint32<4>]; libsimdpp-2.0-rc2/simdpp/detail/insn/bit_or.h:101:42: required from here; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:40:13: error: void* memcpy(void*, const void*, size_t) copying an object of type class simdpp::arch_avx2::uint8<16> with private member simdpp::arch_avx2::uint8<16>::d_ from an array of const class simdpp::arch_avx2::uint32<4>; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/types.h:19,; from libsimdpp-2.0-rc2/simdpp/core/align.h:15,; from libsimdpp-2.0-rc2/simdpp/simd.h:22,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/types/int8x16.h:104:7: note: class simdpp::arch_avx2::uint8<16> declared here; class uint8<16, void> : public any_int8<16, uint8<16,void>> {; ^~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/simd.h:132,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl: In instantiation of R simdpp::arch_avx2::detail::cast_memcpy(const T&) [with R = simdpp::arch_avx2::uint32<4>; T = simdpp::arch_avx2::uint8<16>]:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp:",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3955:9144,error,error,9144,https://hail.is,https://github.com/hail-is/hail/issues/3955,1,['error'],['error']
Availability,"_avx2::uint8<16>; T = simdpp::arch_avx2::uint64<2>]:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::arch_avx2::uint8<16>; T = simdpp::arch_avx2::uint64<2>; unsigned int MaskCastOverride = 0]; libsimdpp-2.0-rc2/simdpp/core/cast.h:63:89: required from R simdpp::arch_avx2::bit_cast(const T&) [with R = simdpp::arch_avx2::uint8<16>; T = simdpp::arch_avx2::uint64<2>]; libsimdpp-2.0-rc2/simdpp/types/int8x16.h:129:36: required from simdpp::arch_avx2::uint8<16>::uint8(const simdpp::arch_avx2::any_vec<16, V>&) [with V = simdpp::arch_avx2::uint64<2>]; libsimdpp-2.0-rc2/simdpp/detail/insn/bit_or.h:150:42: required from here; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:40:13: error: void* memcpy(void*, const void*, size_t) copying an object of type class simdpp::arch_avx2::uint8<16> with private member simdpp::arch_avx2::uint8<16>::d_ from an array of const class simdpp::arch_avx2::uint64<2>; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/types.h:19,; from libsimdpp-2.0-rc2/simdpp/core/align.h:15,; from libsimdpp-2.0-rc2/simdpp/simd.h:22,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/types/int8x16.h:104:7: note: class simdpp::arch_avx2::uint8<16> declared here; class uint8<16, void> : public any_int8<16, uint8<16,void>> {; ^~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/simd.h:132,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl: In instantiation of R simdpp::arch_avx2::detail::cast_memcpy(const T&) [with R = simdpp::arch_avx2::uint64<2>; T = simdpp::arch_avx2::uint8<16>]:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp:",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3955:12681,error,error,12681,https://hail.is,https://github.com/hail-is/hail/issues/3955,1,['error'],['error']
Availability,"_avx2::uint8<32>; T = simdpp::arch_avx2::uint32<8>]:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::arch_avx2::uint8<32>; T = simdpp::arch_avx2::uint32<8>; unsigned int MaskCastOverride = 0]; libsimdpp-2.0-rc2/simdpp/core/cast.h:63:89: required from R simdpp::arch_avx2::bit_cast(const T&) [with R = simdpp::arch_avx2::uint8<32>; T = simdpp::arch_avx2::uint32<8>]; libsimdpp-2.0-rc2/simdpp/types/int8x32.h:110:36: required from simdpp::arch_avx2::uint8<32>::uint8(const simdpp::arch_avx2::any_vec<32, V>&) [with V = simdpp::arch_avx2::uint32<8>]; libsimdpp-2.0-rc2/simdpp/detail/insn/bit_not.h:64:43: required from here; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:40:13: error: void* memcpy(void*, const void*, size_t) copying an object of type class simdpp::arch_avx2::uint8<32> with private member simdpp::arch_avx2::uint8<32>::d_ from an array of const class simdpp::arch_avx2::uint32<8>; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/types.h:20,; from libsimdpp-2.0-rc2/simdpp/core/align.h:15,; from libsimdpp-2.0-rc2/simdpp/simd.h:22,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/types/int8x32.h:91:7: note: class simdpp::arch_avx2::uint8<32> declared here; class uint8<32, void> : public any_int8<32, uint8<32,void>> {; ^~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/simd.h:132,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl: In instantiation of R simdpp::arch_avx2::detail::cast_memcpy(const T&) [with R = simdpp::arch_avx2::uint32<8>; T = simdpp::arch_avx2::uint8<32>]:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3955:23372,error,error,23372,https://hail.is,https://github.com/hail-is/hail/issues/3955,1,['error'],['error']
Availability,"_avx2::uint8<32>; T = simdpp::arch_avx2::uint64<4>]:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::arch_avx2::uint8<32>; T = simdpp::arch_avx2::uint64<4>; unsigned int MaskCastOverride = 0]; libsimdpp-2.0-rc2/simdpp/core/cast.h:63:89: required from R simdpp::arch_avx2::bit_cast(const T&) [with R = simdpp::arch_avx2::uint8<32>; T = simdpp::arch_avx2::uint64<4>]; libsimdpp-2.0-rc2/simdpp/types/int8x32.h:110:36: required from simdpp::arch_avx2::uint8<32>::uint8(const simdpp::arch_avx2::any_vec<32, V>&) [with V = simdpp::arch_avx2::uint64<4>]; libsimdpp-2.0-rc2/simdpp/detail/insn/bit_not.h:94:43: required from here; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:40:13: error: void* memcpy(void*, const void*, size_t) copying an object of type class simdpp::arch_avx2::uint8<32> with private member simdpp::arch_avx2::uint8<32>::d_ from an array of const class simdpp::arch_avx2::uint64<4>; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/types.h:20,; from libsimdpp-2.0-rc2/simdpp/core/align.h:15,; from libsimdpp-2.0-rc2/simdpp/simd.h:22,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/types/int8x32.h:91:7: note: class simdpp::arch_avx2::uint8<32> declared here; class uint8<32, void> : public any_int8<32, uint8<32,void>> {; ^~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/simd.h:132,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl: In instantiation of R simdpp::arch_avx2::detail::cast_memcpy(const T&) [with R = simdpp::arch_avx2::uint64<4>; T = simdpp::arch_avx2::uint8<32>]:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3955:26907,error,error,26907,https://hail.is,https://github.com/hail-is/hail/issues/3955,1,['error'],['error']
Availability,"_configuration,; 491 optimizer_iterations,; 492 gcs_requester_pays_project=gcs_requester_pays_project,; 493 gcs_requester_pays_buckets=gcs_requester_pays_buckets,; 494 ); 495 if not backend.fs.exists(tmpdir):; 496 backend.fs.mkdir(tmpdir); File /databricks/python/lib/python3.10/site-packages/hail/backend/spark_backend.py:126, in SparkBackend.__init__(self, idempotent, sc, spark_conf, app_name, master, local, log, quiet, append, min_block_size, branching_factor, tmpdir, local_tmpdir, skip_logging_configuration, optimizer_iterations, gcs_requester_pays_project, gcs_requester_pays_buckets); 124 jhc = hail_package.HailContext.getOrCreate(jbackend, branching_factor, optimizer_iterations); 125 else:; --> 126 jbackend = hail_package.backend.spark.SparkBackend.apply(; 127 jsc,; 128 app_name,; 129 master,; 130 local,; 131 log,; 132 True,; 133 append,; 134 skip_logging_configuration,; 135 min_block_size,; 136 tmpdir,; 137 local_tmpdir,; 138 gcs_requester_pays_project,; 139 gcs_requester_pays_buckets,; 140 ); 141 jhc = hail_package.HailContext.apply(jbackend, branching_factor, optimizer_iterations); 143 self._jsc = jbackend.sc(); File /databricks/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1355, in JavaMember.__call__(self, *args); 1349 command = proto.CALL_COMMAND_NAME +\; 1350 self.command_header +\; 1351 args_command +\; 1352 proto.END_COMMAND_PART; 1354 answer = self.gateway_client.send_command(command); -> 1355 return_value = get_return_value(; 1356 answer, self.gateway_client, self.target_id, self.name); 1358 for temp_arg in temp_args:; 1359 if hasattr(temp_arg, ""_detach""):; File /databricks/spark/python/pyspark/errors/exceptions/captured.py:230, in capture_sql_exception.<locals>.deco(*a, **kw); 226 converted = convert_exception(e.java_exception); 227 if not isinstance(converted, UnknownException):; 228 # Hide where the exception came from that shows a non-Pythonic; 229 # JVM exception message.; --> 230 raise converted from None; 231 else:; 232 raise; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14462:5777,error,errors,5777,https://hail.is,https://github.com/hail-is/hail/issues/14462,1,['error'],['errors']
Availability,"_debug_string('', 0, f, *args, **kwargs); File ""/Users/rye/opt/anaconda3/lib/python3.9/site-packages/hailtop/utils/utils.py"", line 792, in retry_transient_errors_with_debug_string; return await f(*args, **kwargs); File ""/Users/rye/opt/anaconda3/lib/python3.9/site-packages/hail/backend/service_backend.py"", line 515, in _read_output; raise reconstructed_error.maybe_user_error(ir); hail.utils.java.FatalError: GoogleJsonResponseException: 404 Not Found; GET https://storage.googleapis.com/download/storage/v1/b/wes-bipolar-tmp-4day/o/bge-wave-1-VQSR%2FparallelizeAndComputeWithIndex%2FgCyfD7XOt_MQrrCGc4Q-RrrWPb3cTAbhhcV28BCntiU=%2Fresult.2706?alt=media; No such object: wes-bipolar-tmp-4day/bge-wave-1-VQSR/parallelizeAndComputeWithIndex/gCyfD7XOt_MQrrCGc4Q-RrrWPb3cTAbhhcV28BCntiU=/result.2706. Java stack trace:; is.hail.relocated.com.google.cloud.storage.StorageException: 404 Not Found; GET https://storage.googleapis.com/download/storage/v1/b/wes-bipolar-tmp-4day/o/bge-wave-1-VQSR%2FparallelizeAndComputeWithIndex%2FgCyfD7XOt_MQrrCGc4Q-RrrWPb3cTAbhhcV28BCntiU=%2Fresult.2706?alt=media; No such object: wes-bipolar-tmp-4day/bge-wave-1-VQSR/parallelizeAndComputeWithIndex/gCyfD7XOt_MQrrCGc4Q-RrrWPb3cTAbhhcV28BCntiU=/result.2706; 	at is.hail.relocated.com.google.cloud.storage.StorageException.translate(StorageException.java:163); 	at is.hail.relocated.com.google.cloud.storage.spi.v1.HttpStorageRpc.translate(HttpStorageRpc.java:297); 	at is.hail.relocated.com.google.cloud.storage.spi.v1.HttpStorageRpc.load(HttpStorageRpc.java:730); 	at is.hail.relocated.com.google.cloud.storage.StorageImpl.lambda$readAllBytes$24(StorageImpl.java:574); 	at com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:103); 	at is.hail.relocated.com.google.cloud.RetryHelper.run(RetryHelper.java:76); 	at is.hail.relocated.com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:50); 	at is.hail.relocated.com.google.cloud.storage.Retrying.run(Retrying.java:60); 	at is.hail.r",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13409:4807,down,download,4807,https://hail.is,https://github.com/hail-is/hail/issues/13409,1,['down'],['download']
Availability,"_typecheck(__orig_func__, *args, **kwargs):; 492 args_, kwargs_ = check_all(__orig_func__, args, kwargs, checkers, is_method=False); --> 493 return __orig_func__(*args_, **kwargs_); 494; 495 return decorator(_typecheck). /hadoop_gcs_connector_metadata_cache/hail/hail-devel-0c961806173f.zip/hail/methods/qc.py in vep(dataset, config, block_size, name, csq); 545; 546 require_row_key_variant(dataset, 'vep'); --> 547 return MatrixTable(Env.hail().methods.VEP.apply(dataset._jvds, config, 'va.`{}`'.format(name), csq, block_size)); 548; 549. /usr/lib/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py in __call__(self, *args); 1131 answer = self.gateway_client.send_command(command); 1132 return_value = get_return_value(; -> 1133 answer, self.gateway_client, self.target_id, self.name); 1134; 1135 for temp_arg in temp_args:. /hadoop_gcs_connector_metadata_cache/hail/hail-devel-0c961806173f.zip/hail/utils/java.py in deco(*args, **kwargs); 236 # this is a hack to suppress the original error's stack trace; 237 if _exception:; --> 238 raise _exception; 239; 240 return deco. FatalError: AssertionError: assertion failed. Java stack trace:; java.lang.AssertionError: assertion failed; 	at scala.Predef$.assert(Predef.scala:156); 	at is.hail.variant.MatrixTable.orderedRVDLeftJoinDistinctAndInsert(MatrixTable.scala:982); 	at is.hail.methods.VEP$.annotate(VEP.scala:429); 	at is.hail.methods.VEP$.apply(VEP.scala:434); 	at is.hail.methods.VEP.apply(VEP.scala); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:280); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractComma",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3099:2703,error,error,2703,https://hail.is,https://github.com/hail-is/hail/issues/3099,1,['error'],['error']
Availability,"_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::arch_avx2::int8<32>; T = simdpp::arch_avx2::uint16<16>; unsigned int MaskCastOverride = 0]; libsimdpp-2.0-rc2/simdpp/core/cast.h:63:89: required from R simdpp::arch_avx2::bit_cast(const T&) [with R = simdpp::arch_avx2::int8<32>; T = simdpp::arch_avx2::uint16<16>]; libsimdpp-2.0-rc2/simdpp/types/int8x32.h:51:35: required from simdpp::arch_avx2::int8<32>::int8(const simdpp::arch_avx2::any_vec<32, V>&) [with V = simdpp::arch_avx2::uint16<16, simdpp::arch_avx2::expr_bit_or<simdpp::arch_avx2::uint16<16, simdpp::arch_avx2::uint16<16> >, simdpp::arch_avx2::uint16<16, simdpp::arch_avx2::uint16<16> > > >]; libsimdpp-2.0-rc2/simdpp/detail/insn/i_shift_r.h:69:36: required from here; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:40:13: error: void* memcpy(void*, const void*, size_t) copying an object of type class simdpp::arch_avx2::int8<32> with private member simdpp::arch_avx2::int8<32>::d_ from an array of const class simdpp::arch_avx2::uint16<16>; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/types.h:20,; from libsimdpp-2.0-rc2/simdpp/core/align.h:15,; from libsimdpp-2.0-rc2/simdpp/simd.h:22,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/types/int8x32.h:32:7: note: class simdpp::arch_avx2::int8<32> declared here; class int8<32, void> : public any_int8<32, int8<32,void>> {; ^~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/simd.h:132,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl: In instantiation of R simdpp::arch_avx2::detail::cast_memcpy(const T&) [with R = simdpp::arch_avx2::int32<4>; T = simdpp::arch_avx2::int64<2>]:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::arch_av",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3955:65970,error,error,65970,https://hail.is,https://github.com/hail-is/hail/issues/3955,1,['error'],['error']
Availability,"_ from an array of const class simdpp::arch_avx2::int64<2>; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/types.h:23,; from libsimdpp-2.0-rc2/simdpp/core/align.h:15,; from libsimdpp-2.0-rc2/simdpp/simd.h:22,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/types/int32x4.h:33:7: note: class simdpp::arch_avx2::int32<4> declared here; class int32<4, void> : public any_int32<4, int32<4,void>> {; ^~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/simd.h:132,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl: In instantiation of R simdpp::arch_avx2::detail::cast_memcpy(const T&) [with R = simdpp::arch_avx2::int64<2>; T = simdpp::arch_avx2::int32<4>]:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::arch_avx2::int64<2>; T = simdpp::arch_avx2::int32<4>; unsigned int MaskCastOverride = 0]; libsimdpp-2.0-rc2/simdpp/core/cast.h:63:89: required from R simdpp::arch_avx2::bit_cast(const T&) [with R = simdpp::arch_avx2::int64<2>; T = simdpp::arch_avx2::int32<4>]; libsimdpp-2.0-rc2/simdpp/types/int64x2.h:56:35: required from simdpp::arch_avx2::int64<2>::int64(const simdpp::arch_avx2::any_vec<16, V>&) [with V = simdpp::arch_avx2::int32<4>]; libsimdpp-2.0-rc2/simdpp/detail/insn/i_shift_r.h:265:25: required from here; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:40:13: error: void* memcpy(void*, const void*, size_t) copying an object of type class simdpp::arch_avx2::int64<2> with private member simdpp::arch_avx2::int64<2>::d_ from an array of const class simdpp::arch_avx2::int32<4>; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/type",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3955:68892,Mask,MaskCastOverride,68892,https://hail.is,https://github.com/hail-is/hail/issues/3955,2,['Mask'],['MaskCastOverride']
Availability,"_ from an array of const class simdpp::arch_avx2::int64<4>; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/types.h:24,; from libsimdpp-2.0-rc2/simdpp/core/align.h:15,; from libsimdpp-2.0-rc2/simdpp/simd.h:22,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/types/int32x8.h:32:7: note: class simdpp::arch_avx2::int32<8> declared here; class int32<8, void> : public any_int32<8, int32<8,void>> {; ^~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/simd.h:132,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl: In instantiation of R simdpp::arch_avx2::detail::cast_memcpy(const T&) [with R = simdpp::arch_avx2::int64<4>; T = simdpp::arch_avx2::int32<8>]:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::arch_avx2::int64<4>; T = simdpp::arch_avx2::int32<8>; unsigned int MaskCastOverride = 0]; libsimdpp-2.0-rc2/simdpp/core/cast.h:63:89: required from R simdpp::arch_avx2::bit_cast(const T&) [with R = simdpp::arch_avx2::int64<4>; T = simdpp::arch_avx2::int32<8>]; libsimdpp-2.0-rc2/simdpp/types/int64x4.h:51:35: required from simdpp::arch_avx2::int64<4>::int64(const simdpp::arch_avx2::any_vec<32, V>&) [with V = simdpp::arch_avx2::int32<8>]; libsimdpp-2.0-rc2/simdpp/detail/insn/i_shift_r.h:296:25: required from here; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:40:13: error: void* memcpy(void*, const void*, size_t) copying an object of type class simdpp::arch_avx2::int64<4> with private member simdpp::arch_avx2::int64<4>::d_ from an array of const class simdpp::arch_avx2::int32<8>; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/type",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3955:77823,Mask,MaskCastOverride,77823,https://hail.is,https://github.com/hail-is/hail/issues/3955,2,['Mask'],['MaskCastOverride']
Availability,"`'/api/v1alpha/batches/create-fast'` is a Batch API endpoint that allows you to create a batch, submit jobs, and start them running all in one HTTP request. It makes a few transactions within the endpoint and must be idempotent. One of the failure modes it must watch for is when a Batch Update to add some new jobs and/or job groups to a batch has already successfully been committed, but the request is retried for X reason. In that scenario, we want to just return a 200 to the client. We do this already, but there was an oversight when creating job groups where those branches did not include the full response payload, which results in intermittent errors on the client when it can't retrieve `resp['last_job_group_id']`. This fixes that so we always return the same JSON.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14589:240,failure,failure,240,https://hail.is,https://github.com/hail-is/hail/pull/14589,2,"['error', 'failure']","['errors', 'failure']"
Availability,"`), 0) AS SIGNED) AS `usage`; FROM aggregated_billing_project_user_resources_v3; + LEFT JOIN resources ON resources.resource_id = aggregated_billing_project_user_resources_v3.resource_id; {where_statement}; - GROUP BY billing_project, `user`, resource_id; + GROUP BY billing_project, `user`, deduped_resource_id; LOCK IN SHARE MODE; -) AS new ON old.billing_project = new.billing_project AND old.`user` = new.`user` AND old.deduped_resource_id = new.resource_id; +) AS new ON old.billing_project = new.billing_project AND old.`user` = new.`user` AND old.deduped_resource_id = new.deduped_resource_id; WHERE new.`usage` != old.`usage`; LIMIT 100;; ''',; where_args + where_args); ; bad_bp_user_records = [record async for record in bad_bp_user_records]; - failing_bp_users = []; for record in bad_bp_user_records:; print(f'found bad bp user record {record}'); failing_bp_users.append((record['billing_project'], record['user'])); ; - if bad_bp_user_records:; - raise Exception(f'errors found in audit'); + if failing_bp_users:; + raise Exception(f'errors found in audit'); ; print(f'finished auditing bp user records in {time.time() - bp_user_audit_start}s'); ```; Manual audit succeeded:. ```; mysql> SELECT old.billing_project, old.`user`, old.deduped_resource_id, old.`usage`, new.`usage`, ABS(new.`usage` - old.`usage`) AS usage_diff; -> FROM (; -> SELECT billing_project, `user`, deduped_resource_id, CAST(COALESCE(SUM(`usage`), 0) AS SIGNED) AS `usage`; -> FROM aggregated_billing_project_user_resources_v2; -> LEFT JOIN resources ON resources.resource_id = aggregated_billing_project_user_resources_v2.resource_id; -> GROUP BY billing_project, `user`, deduped_resource_id; -> LOCK IN SHARE MODE; -> ) AS old; -> LEFT JOIN (; -> SELECT billing_project, `user`, deduped_resource_id, CAST(COALESCE(SUM(`usage`), 0) AS SIGNED) AS `usage`; -> FROM aggregated_billing_project_user_resources_v3; -> LEFT JOIN resources ON resources.resource_id = aggregated_billing_project_user_resources_v3.resource_id",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13117:1921,error,errors,1921,https://hail.is,https://github.com/hail-is/hail/pull/13117,2,['error'],['errors']
Availability,`-x` logs each line of `start-nginx.sh` that runs and I don't expect anything in here to fail / the code itself to provide useful context in a failure,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9945:143,failure,failure,143,https://hail.is,https://github.com/hail-is/hail/pull/9945,1,['failure'],['failure']
Availability,"`. activate NAME` might silently fail if `NAME` does not exist or `conda` is not configured. `. ./loadconda` tries to find conda in a variety of places and configure it (meaning source `conda.sh`). After this, `conda activate NAME` will work correctly. ---. This is already in my batch dag PR, but that's getting bogged down in test issues, and this is blocking @akotlar 's https://github.com/hail-is/hail/pull/5065 PR.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5066:320,down,down,320,https://hail.is,https://github.com/hail-is/hail/pull/5066,1,['down'],['down']
Availability,"`0.2.39-d38fca12930d`. ```; ht_out = ht.group_by(_x=True).aggregate(; ...: data=hl.agg.downsample(; ...: hl.log10(eur_freq.gnomad_genomes_af), hl.log10(eur_freq.af / 2),; ...: [ht.pass_status, hl.str(hl.abs(hl.log(eur_freq.gnomad_genomes_af / eur_freq.gnomad_exomes_af, 2)) > 2)]); ...: ).explode('data').key_by().drop('_x'); Traceback (most recent call last):; File ""/opt/local/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py"", line 3331, in run_code; exec(code_obj, self.user_global_ns, self.user_ns); File ""<ipython-input-59-3a16f061373b>"", line 5, in <module>; ).explode('data').key_by().drop('_x'); File ""<decorator-gen-1731>"", line 2, in drop; File ""/Users/konradk/hail/hail/python/hail/typecheck/check.py"", line 585, in wrapper; return __original_func(*args_, **kwargs_); File ""/Users/konradk/hail/hail/python/hail/table.py"", line 965, in drop; protected_key = set(self._row_indices.protected_key); File ""/Users/konradk/hail/hail/python/hail/expr/expressions/indices.py"", line 42, in protected_key; self._cached_key = self._get_key(); File ""/Users/konradk/hail/hail/python/hail/expr/expressions/indices.py"", line 56, in _get_key; assert isinstance(self.source, hl.MatrixTable); AssertionError; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8751:87,down,downsample,87,https://hail.is,https://github.com/hail-is/hail/issues/8751,1,['down'],['downsample']
Availability,"`; [Stage 3:> (0 + 140) / 415]Traceback (most recent call last):; File ""/restricted/projectnb/genpro/github/hail.qc/delly-qc.py"", line 35, in <module>; ds = hl.sample_qc(ds); File ""<decorator-gen-902>"", line 2, in sample_qc; File ""/restricted/projectnb/genpro/github/hail/python/hail/typecheck/check.py"", line 490, in _typecheck; return __orig_func__(*args_, **kwargs_); File ""/restricted/projectnb/genpro/github/hail/python/hail/methods/qc.py"", line 91, in sample_qc; return MatrixTable(Env.hail().methods.SampleQC.apply(require_biallelic(dataset, 'sample_qc')._jvds, name)); File ""/share/pkg/spark/2.2.0/install/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py"", line 1133, in __call__; File ""/restricted/projectnb/genpro/github/hail/python/hail/utils/java.py"", line 196, in deco; 'Error summary: %s' % (deepest, full, hail.__version__, deepest)) from None; hail.utils.java.FatalError: HailException: invalid allele ""<DEL>"". Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 2 in stage 3.0 failed 4 times, most recent failure: Lost task 2.3 in stage 3.0 (TID 160, scc-q01.scc.bu.edu, executor 4): is.hail.utils.HailException: invalid allele ""<DEL>""; at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:6); at is.hail.utils.package$.fatal(package.scala:26); at is.hail.variant.AltAlleleMethods$.validate(AltAlleleMethods.scala:24); at is.hail.variant.AltAlleleMethods$.altAlleleType(AltAlleleMethods.scala:29); at is.hail.methods.SampleQCCombiner$.alleleIndices(SampleQC.scala:44); at is.hail.methods.SampleQC$$anonfun$results$1$$anonfun$apply$1.apply(SampleQC.scala:178); at is.hail.methods.SampleQC$$anonfun$results$1$$anonfun$apply$1.apply(SampleQC.scala:175); at scala.collection.Iterator$class.foreach(Iterator.scala:893); at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); at is.hail.methods.SampleQC$$anonfun$results$1.apply(SampleQC.scala:175); at is.hail.methods.SampleQC$$anonfun$results$1.apply(SampleQC.scala:170); a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3413:1512,failure,failure,1512,https://hail.is,https://github.com/hail-is/hail/issues/3413,1,['failure'],['failure']
Availability,"`; aiosignal 1.3.1 requires frozenlist, which is not installed.; aiohttp 3.8.5 requires frozenlist, which is not installed. ```; </details>. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **471/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 3.7 | Insufficient Verification of Data Authenticity <br/>[SNYK-PYTHON-CRYPTOGRAPHY-5813745](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5813745) | `cryptography:` <br> `41.0.2 -> 41.0.3` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **551/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 5.3 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-5813746](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5813746) | `cryptography:` <br> `41.0.2 -> 41.0.3` <br> | No | No Known Exploit ; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **471/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 3.7 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-5813750](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5813750) | `cryptography:` <br> `41.0.2 -> 41.0.3` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure th",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13366:1467,avail,available,1467,https://hail.is,https://github.com/hail-is/hail/pull/13366,2,['avail'],['available']
Availability,"`; {""levelname"": ""ERROR"", ""asctime"": ""2019-09-30 19:09:54,555"", ""filename"": ""ci.py"", ""funcNameAndLine"": ""update_loop:315"", ""message"": ""hail-is/hail:master update failed due to exception"", ""exc_info"": ""Traceback (most recent call last):\n File \""/usr/local/lib/python3.6/dist-packages/aiohttp/connector.py\"", line 929, in _wrap_create_connection\n await self._loop.create_connection(*args, **kwargs))\n File \""uvloop/loop.pyx\"", line 1904, in create_connection\n File \""uvloop/loop.pyx\"", line 1883, in uvloop.loop.Loop.create_connection\nConnectionRefusedError: [Errno 111] Connection refused\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n File \""/usr/local/lib/python3.6/dist-packages/ci/ci.py\"", line 311, in update_loop\n await wb.update(app)\n File \""/usr/local/lib/python3.6/dist-packages/ci/github.py\"", line 518, in update\n await self._update(app)\n File \""/usr/local/lib/python3.6/dist-packages/ci/github.py\"", line 540, in _update\n await self._update_batch(batch_client)\n File \""/usr/local/lib/python3.6/dist-packages/ci/github.py\"", line 652, in _update_batch\n await self._update_deploy(batch_client)\n File \""/usr/local/lib/python3.6/dist-packages/ci/github.py\"", line 609, in _update_deploy\n 'target_branch': self.branch.short_str()\n File \""/usr/local/lib/python3.6/dist-packages/hailtop/batch_client/aioclient.py\"", line 476, in list_batches\n batches = await self._get('/api/v1alpha/batches', params=params)\n File \""/usr/local/lib/python3.6/dist-packages/hailtop/batch_client/aioclient.py\"", line 455, in _get\n self.url + path, params=params, headers=self._headers)\n File \""/usr/local/lib/python3.6/dist-packages/aiohttp/client.py\"", line 484, in _request\n timeout=real_timeout\n File \""/usr/local/lib/python3.6/dist-packages/aiohttp/connector.py\"", line 523, in connect\n proto = await self._create_connection(req, traces, timeout)\n File \""/usr/local/lib/python3.6/dist-packages/aiohttp/connector.py\"", line 85",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7166:18,ERROR,ERROR,18,https://hail.is,https://github.com/hail-is/hail/issues/7166,1,['ERROR'],['ERROR']
Availability,"`>=` is not compatible with wildcards:; ```; cd build/deploy; rm -rf build; python3 setup.py -q sdist bdist_wheel; /usr/local/lib/python3.7/dist-packages/setuptools/installer.py:30: SetuptoolsDeprecationWarning: setuptools.installer is deprecated. Requirements should be satisfied by a PEP 517 installer.; SetuptoolsDeprecationWarning,; error in hail setup command: 'install_requires' must be a string or list of strings containing valid project/version requirement specifiers; Expected end or semicolon (after version specifier); google-cloud-storage>=1.25.*; ~~~~~~^; make: *** [Makefile:248: build/deploy/dist/hail-0.2.109-py3-none-any.whl] Error 1; ```. I'm not sure why this hasn't shown up before, but we couldn't deploy 0.2.109 without this fix. #assign services",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12677:337,error,error,337,https://hail.is,https://github.com/hail-is/hail/pull/12677,2,"['Error', 'error']","['Error', 'error']"
Availability,"`ArrayScan` is implemented in such a way that a scan on an empty array will read some uninitialized memory:. ```; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.2.23-7f06f94534d5; >>> hl.eval(hl.empty_array(hl.tint32).scan(lambda x,y: x + y, 0)); [0]; >>> hl.eval(hl.array([1, 2, 3]).scan(lambda x,y: x + y, 0)); [0, 1, 3, 6]; >>> hl.eval(hl.empty_array(hl.tint32).scan(lambda x,y: x + y, 0)); [643629112]; >>> hl.eval(hl.empty_array(hl.tarray(hl.tint32)).scan(lambda x,y: y, hl.empty_array(hl.tint32))); #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x000000010ef85ded, pid=49261, tid=0x0000000000009903; #; # JRE version: Java(TM) SE Runtime Environment (8.0_211-b12) (build 1.8.0_211-b12); # Java VM: Java HotSpot(TM) 64-Bit Server VM (25.211-b12 mixed mode bsd-amd64 compressed oops); # Problematic frame:; # V [libjvm.dylib+0x585ded]; #; # Failed to write core dump. Core dumps have been disabled. To enable core dumping, try ""ulimit -c unlimited"" before starting Java again; #; # An error report file with more information is saved as:; # /Users/mturner/Documents/hail/hail/python/hs_err_pid49261.log; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; #; ```. This is because `ArrayScan` claims to have `len+1` elements, where `len` is the length of the inner stream. However, it will only call the consumer continuation during the `addElements` loop of the inner stream. Thus, if the inner stream is empty, the consumer continuation is never called. So the resulting effect is that we return an initialized array with length 1.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7135:556,error,error,556,https://hail.is,https://github.com/hail-is/hail/issues/7135,2,['error'],['error']
Availability,"`BlockMatrix.filterCols` and `BlockMatrix.filterRows` has a bug where the smaller blocks located on the edge of the matrix are not always correctly handled when they're of a smaller size than the rest of the blocks. The source of this problem was the fact that `BlockMatrix.scala` line 1515 below, which was calling `blockDims(split.index)`. This was a problem because `split.index` is a partition index, not a block index. The fix was to convert it to a block index and then call `blockDims`. The rest of this PR is some white space fixes, a spelling error, and an additional test case for BlockMatrix filtering that would fail in current master because of this bug.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7146:552,error,error,552,https://hail.is,https://github.com/hail-is/hail/pull/7146,1,['error'],['error']
Availability,"`IRSuite.scala` has a class `IRSuite` which has this inheritance sequence:; - `HailSuite`; - `TestNGSuite`; - `Suite`; - `Assertions` (among other interfaces). `Assertions` has [`assertThrows` with one argument](http://doc.scalatest.org/3.0.8/org/scalatest/testng/TestNGSuite.html#assertThrows[T<:AnyRef](f:=>Any)(implicitclassTag:scala.reflect.ClassTag[T],implicitpos:org.scalactic.source.Position):org.scalatest.Assertion). Unfortunately, `IRSuite.scala` also contains `import is.hail.TestUtils._`. This also brings into scope an `assertThrows` with two parameters. I have not bothered to understand Scala's name resolution strategy. SBT 1.3.8 refuses to acknowledge the existence of the `TestUtils.assertThrows` and instead tries to convert the two arguments into a pair and then pass those to `Assertions.assertThrows`. This rightfully raises a warning which we treat as errors. Both gradle and SBT have Scala version set to 2.11.8. I've fixed this by prefixing the assertThrows with `is.hail.TestUtils.assertThrows`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8359:875,error,errors,875,https://hail.is,https://github.com/hail-is/hail/issues/8359,1,['error'],['errors']
Availability,"`Invalid method, methods may have at most 255 arguments` error when running the gnomad-browser pipeline with Hail 0.2.105",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12533:57,error,error,57,https://hail.is,https://github.com/hail-is/hail/issues/12533,1,['error'],['error']
Availability,`MT.make_table` throws a bad error if a key is NA,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8222:29,error,error,29,https://hail.is,https://github.com/hail-is/hail/issues/8222,1,['error'],['error']
Availability,`Method too large` error when running the gnomad-browser pipeline with Hail 0.2.105,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12531:19,error,error,19,https://hail.is,https://github.com/hail-is/hail/issues/12531,1,['error'],['error']
Availability,"`Table._select` got way too complicated (mostly my fault) when key changing moved from `TableMapRows` to `TableKeyBy`. Making `_select` a simple wrapper around `TableMapRows`, and moving the key logic to `key_by`, made both way simpler. I then realized the `key_by` code could be even simpler by adding some rules to the optimizer to clean up the case where all new keys are existing fields. I actually think some things had gotten broken in the old `_select` (performance wise). In particular, in `split_multi`, in the `split_rows` function with `rekey=false`, I think it's supposed to extend the key from `['locus']` to `['locus', 'alleles']`, but that wasn't happening. I changed `key_by` to no longer accept `key_by(None)` or `key_by([])`, both of which should now be `key_by()`, which is more consistent with the rest of our interface, but is a breaking change. Is it worth the disruption? Should I add a warning? Or just continue to accept both?",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4455:51,fault,fault,51,https://hail.is,https://github.com/hail-is/hail/pull/4455,1,['fault'],['fault']
Availability,`Too many arguments in method signature in class file` error when running the gnomad-browser pipeline with Hail 0.2.105,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12532:55,error,error,55,https://hail.is,https://github.com/hail-is/hail/issues/12532,1,['error'],['error']
Availability,"`_delete` retries transient errors. The `.../delete` endpoints return 404 for batches that do not exist, which, I suppose, is reasonable. On the client-side, we need to ignore 404s to ensure idempotency.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12478:28,error,errors,28,https://hail.is,https://github.com/hail-is/hail/pull/12478,1,['error'],['errors']
Availability,"``; prometheus-async 19.2.0 requires prometheus-client, which is not installed. ```; </details>. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **581/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 5.9 | Improper Limitation of a Pathname to a Restricted Directory (&#x27;Path Traversal&#x27;) <br/>[SNYK-PYTHON-AIOHTTP-6209406](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-6209406) | `aiohttp:` <br> `3.8.6 -> 3.9.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **718/1000** <br/> **Why?** Proof of Concept exploit, Recently disclosed, Has a fix available, CVSS 6.5 | HTTP Request Smuggling <br/>[SNYK-PYTHON-AIOHTTP-6209407](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-6209407) | `aiohttp:` <br> `3.8.6 -> 3.9.2` <br> | No | Proof of Concept . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI3ZGRlNzcwZi0yMzMyLTQ5ZjktOWI1My05ZDY1OGJlOTVjMm",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14228:1464,avail,available,1464,https://hail.is,https://github.com/hail-is/hail/pull/14228,1,['avail'],['available']
Availability,"```; ""error"": ""Traceback (most recent call last):; File ""/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py"", line 384, in _make_request; six.raise_from(e, None); File ""<string>"", line 2, in raise_from; File ""/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py"", line 380, in _make_request; httplib_response = conn.getresponse(); File ""/usr/local/lib/python3.6/http/client.py"", line 1354, in getresponse; response.begin(); File ""/usr/local/lib/python3.6/http/client.py"", line 307, in begin; version, status, reason = self._read_status(); File ""/usr/local/lib/python3.6/http/client.py"", line 268, in _read_status; line = str(self.fp.readline(_MAXLINE + 1), ""iso-8859-1""); File ""/usr/local/lib/python3.6/socket.py"", line 586, in readinto; return self._sock.recv_into(b); File ""/usr/local/lib/python3.6/ssl.py"", line 1012, in recv_into; return self.read(nbytes, buffer); File ""/usr/local/lib/python3.6/ssl.py"", line 874, in read; return self._sslobj.read(len, buffer); File ""/usr/local/lib/python3.6/ssl.py"", line 631, in read; v = self._sslobj.read(len, buffer); socket.timeout: The read operation timed out. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/usr/local/lib/python3.6/site-packages/requests/adapters.py"", line 449, in send; timeout=timeout; File ""/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py"", line 638, in urlopen; _stacktrace=sys.exc_info()[2]); File ""/usr/local/lib/python3.6/site-packages/urllib3/util/retry.py"", line 368, in increment; raise six.reraise(type(error), error, _stacktrace); File ""/usr/local/lib/python3.6/site-packages/urllib3/packages/six.py"", line 686, in reraise; raise value; File ""/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py"", line 600, in urlopen; chunked=chunked); File ""/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py"", line 386, in _make_request; self._raise_timeout(err=e, url=url, timeout_value=read_timeout); F",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8053:6,error,error,6,https://hail.is,https://github.com/hail-is/hail/issues/8053,1,['error'],['error']
Availability,"```; # cat foo; 7	75216143	75216143	C/T	+; # python <<EOF; import hail as hl; hl.import_matrix_table(; 'foo',; row_fields={f'f{i}': hl.tstr for i in range(5)},; no_header=True).count(); EOF; ```; produces:; ```; Hail version: 0.2.11-cf54f08305d1; Error summary: HailException: Error parsing row fields in row 0:; expected 5 fields but only 5 found.; File: foo; Line:; 7	75216143	75216143	C/T	+; ```; I expect it to say something like ""yo dawg, you forgot to have entries, maybe you actually want import_table"". full output:; ```; Initializing Spark and Hail with default parameters...; using hail jar at /Users/dking/anaconda2/envs/hail/lib/python3.6/site-packages/hail/hail-all-spark.jar; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).; 19/03/27 18:27:22 WARN Utils: Your hostname, wmb16-359 resolves to a loopback address: 127.0.0.1; using 10.1.1.163 instead (on interface en0); 19/03/27 18:27:22 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address; Running on Apache Spark version 2.2.3; SparkUI available at http://10.1.1.163:4041; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.2.11-cf54f08305d1; LOGGING: writing to /Users/dking/hail-20190327-1827-0.2.11-cf54f08305d1.log; Traceback (most recent call last):; File ""<stdin>"", line 4, in <module>; File ""/Users/dking/anaconda2/envs/hail/lib/python3.6/site-packages/hail/matrixtable.py"", line 2371, in count; return (self.count_rows(), self.count_cols()); File ""/Users/dking/anaconda2/envs/hail/lib/python3.6/site-packages/hail/matrixtable.py"", line 2331, in count_rows; TableCount(MatrixRowsTable(self._mir))); File ""/Users/dking/anaconda2/envs/hail/lib/python3.6/site-packages/hail/backend/backend.py"", line 94, in execute; self._to_java_ir(ir))); File ""/Users/dking/anaconda2/envs/hail/lib/python3.6/site-packages/py4j/java_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5718:247,Error,Error,247,https://hail.is,https://github.com/hail-is/hail/issues/5718,2,['Error'],['Error']
Availability,"```; # gsutil cat gs://hail-ci-0-1/ci/46808cb\*/038a6de7ce33b218b8d45160f224cae1feaf1c5a/job.log; failed to get container status {"""" """"}: rpc error: code = OutOfRange desc = EOF% . ```; The three most recent commits:. ```; * 6d17db60a - (23 minutes ago) add batch client timeouts, set timeout in ci (#4586) - Daniel King (HEAD -> fix-batch-client, hi/master, master); * 74d5e7560 - (23 minutes ago) fix a few issues with hl.plot.histogram (#4681) - Tim Poterba; * 038a6de7c - (45 minutes ago) refresh from batch (#4670) - Daniel King; ```. #4586 was never tested against 75d5e7560. This is bad. We can look at the log of statuses posted to GitHub:; ```; # curl -sSL api.github.com/repos/hail-is/hail/commits/46808cb224dbaa2d4fbae9f4fc90439e2eed8730/statuses | less; ```; [46808cb224dbaa2d4fbae9f4fc90439e2eed8730-statuses.txt](https://github.com/hail-is/hail/files/2531246/46808cb224dbaa2d4fbae9f4fc90439e2eed8730-statuses.txt). Before the merge status goes in we see this one:; ```; {; ""url"": ""https://api.github.com/repos/hail-is/hail/statuses/46808cb224dbaa2d4fbae9f4fc90439e2eed8730"",; ""avatar_url"": ""https://avatars2.githubusercontent.com/u/106194?v=4"",; ""id"": 5728320639,; ""node_id"": ""MDEzOlN0YXR1c0NvbnRleHQ1NzI4MzIwNjM5"",; ""state"": ""success"",; ""description"": ""successful build"",; ""target_url"": ""https://storage.googleapis.com/hail-ci-0-1/ci/46808cb224dbaa2d4fbae9f4fc90439e2eed8730/038a6de7ce33b218b8d45160f224cae1feaf1c5a/index.html"",; ""context"": ""hail-ci-0-1"",; ""created_at"": ""2018-10-30T18:51:09Z"",; ""updated_at"": ""2018-10-30T18:51:09Z"",; ""creator"": {; ""login"": ""danking"", ...; }; },; ```. and before that:. ```; {; ""url"": ""https://api.github.com/repos/hail-is/hail/statuses/46808cb224dbaa2d4fbae9f4fc90439e2eed8730"",; ""avatar_url"": ""https://avatars2.githubusercontent.com/u/106194?v=4"",; ""id"": 5728220065,; ""node_id"": ""MDEzOlN0YXR1c0NvbnRleHQ1NzI4MjIwMDY1"",; ""state"": ""pending"",; ""description"": ""build 38 pending. target: 038a6de7ce33"",; ""target_url"": null,; ""context"": ""hail-ci-0-1"",; ""cr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4685:142,error,error,142,https://hail.is,https://github.com/hail-is/hail/issues/4685,1,['error'],['error']
Availability,"```; (1146, \""Table 'pr-7592-notebook-yi0bdn43fu8g.workshops' doesn't exist\"")""; ```. I'm not sure what's going on, but I noticed the notebook server cannot respond to /images due to this error. We should be scanning the logs of every service for ERROR log messages on each PR. I saw this because the image-fetchers are failing",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7624:188,error,error,188,https://hail.is,https://github.com/hail-is/hail/issues/7624,2,"['ERROR', 'error']","['ERROR', 'error']"
Availability,"```; (b'', b""+ mkdir -p repos/hail-is/hail; + cd repos/hail-is/hail; + '[' '!' -d .git ']'; + git reset --merge; error: Entry 'hail/src/main/scala/is/hail/HailContext.scala' not uptodate. Cannot merge.; fatal: Could not reset index file to revision 'HEAD'.; ""); ```; https://ci.hail.is/watched_branches/0/pr/9048",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/9051:113,error,error,113,https://hail.is,https://github.com/hail-is/hail/issues/9051,1,['error'],['error']
Availability,"```; + CHANGED=yes; + [[ -e notebook/get-deployed-sha.sh ]]; + [[ yes != no ]]; + cd notebook; + /bin/bash hail-ci-deploy.sh; cat: notebook-image: No such file or directory; sed -e ""s,@sha@,17a365c57d0f,"" \; -e ""s,@image@,,"" \; < deployment.yaml.in > deployment.yaml; kubectl apply -f deployment.yaml; Error from server (Forbidden): error when retrieving current configuration of:; Resource: ""/v1, Resource=services"", GroupVersionKind: ""/v1, Kind=Service""; Name: ""notebook"", Namespace: ""batch-pods""; Object: &{map[""metadata"":map[""labels"":map[""app"":""notebook""] ""name"":""notebook"" ""namespace"":""batch-pods"" ""annotations"":map[""kubectl.kubernetes.io/last-applied-configuration"":""""]] ""spec"":map[""ports"":[map[""port"":'P' ""protocol"":""TCP"" ""targetPort"":'\u1388']] ""selector"":map[""app"":""notebook""]] ""apiVersion"":""v1"" ""kind"":""Service""]}; from server for: ""deployment.yaml"": services ""notebook"" is forbidden: User ""system:serviceaccount:batch-pods:deploy-svc"" cannot get services in the namespace ""batch-pods"": Unknown user ""system:serviceaccount:batch-pods:deploy-svc""; Makefile:4: recipe for target 'deploy' failed; make: *** [deploy] Error 1; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4656:302,Error,Error,302,https://hail.is,https://github.com/hail-is/hail/issues/4656,3,"['Error', 'error']","['Error', 'error']"
Availability,```; + cd /io; + rm -rf repo; + mkdir repo; + cd repo; + '[' '!' -d .git ']'; + retry clone; + clone; ++ mktemp -d; + dir=/tmp/tmp.Txkg8yv5oW; + git clone https://github.com/hail-is/hail.git /tmp/tmp.Txkg8yv5oW; Cloning into '/tmp/tmp.Txkg8yv5oW'...; error: RPC failed; curl 56 GnuTLS recv error (-54): Error in the pull function.; fatal: The remote end hung up unexpectedly; fatal: protocol error: bad pack header; ++ ls -A /tmp/tmp.Txkg8yv5oW. real	1m0.562s; user	0m0.135s; sys	0m0.086s; + git config user.email ci@hail.is; fatal: not in a git directory; ```,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8170:251,error,error,251,https://hail.is,https://github.com/hail-is/hail/issues/8170,4,"['Error', 'error']","['Error', 'error']"
Availability,```; + date; Mon Mar 30 22:11:05 UTC 2020; + rm -rf repo; + mkdir repo; + cd repo; + '[' '!' -d .git ']'; + retry clone; + clone; + set -e; ++ mktemp -d; + dir=/tmp/tmp.3H7wTmq0R2; + git clone https://github.com/danking/hail.git /tmp/tmp.3H7wTmq0R2; Cloning into '/tmp/tmp.3H7wTmq0R2'...; error: RPC failed; curl 56 GnuTLS recv error (-54): Error in the pull function.; fatal: The remote end hung up unexpectedly; fatal: early EOF; fatal: index-pack failed; ++ ls -A /tmp/tmp.3H7wTmq0R2. real	0m3.373s; user	0m0.006s; sys	0m0.025s; + git config user.email ci@hail.is; fatal: not in a git directory; ```,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8397:289,error,error,289,https://hail.is,https://github.com/hail-is/hail/issues/8397,3,"['Error', 'error']","['Error', 'error']"
Availability,```; /usr/local/lib/python3.6/dist-packages/aiomysql/cursors.py:192: Warning: Converting column '' from VARCHAR to TEXT; await self._do_get_result(); ```. These mysterious two lines are printed to my batch log when I run a big test (1000 jobs). The [Server Error Reference](https://dev.mysql.com/doc/refman/8.0/en/server-error-reference.html) indicates this is error 1246. A [MySQL bug](https://bugs.mysql.com/bug.php?id=26090) suggests that ER_AUTO_CONVERT might be raised when one attempts to insert unicode into a varchar column. I don't understand why our column has the empty string as a name.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7769:257,Error,Error,257,https://hail.is,https://github.com/hail-is/hail/issues/7769,3,"['Error', 'error']","['Error', 'error', 'error-reference']"
Availability,"```; : is.hail.utils.package$FatalException: symbol `v' not found; Available symbols:; va: Struct; table: Struct; x: Dict[Int, Struct]; <input>:1:va.split_allele = let x = table.`va.split_allele` in range(v.nAltAlleles)[1:].map(i => if(x.contains(i)) x[i].val else NA: String); ```. Note: No idea if this impacts other `annotate_variants...`",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1378:67,Avail,Available,67,https://hail.is,https://github.com/hail-is/hail/issues/1378,1,['Avail'],['Available']
Availability,"```; ERROR	| 2019-07-09 09:52:15,823 	| web_protocol.py 	| log_exception:355 | Error handling request; Jul 9, 2019 @ 05:52:15.824; Traceback (most recent call last):; Jul 9, 2019 @ 05:52:15.824; File ""/usr/local/lib/python3.6/dist-packages/aiohttp/web_protocol.py"", line 418, in start; Jul 9, 2019 @ 05:52:15.824; resp = await task; Jul 9, 2019 @ 05:52:15.824; File ""/usr/local/lib/python3.6/dist-packages/aiohttp/web_app.py"", line 458, in _handle; Jul 9, 2019 @ 05:52:15.824; resp = await handler(request); Jul 9, 2019 @ 05:52:15.824; File ""/usr/local/lib/python3.6/dist-packages/aiohttp/web_urldispatcher.py"", line 157, in handler_wrapper; Jul 9, 2019 @ 05:52:15.824; result = await result; Jul 9, 2019 @ 05:52:15.824; File ""/usr/local/lib/python3.6/dist-packages/aiohttp_jinja2/__init__.py"", line 91, in wrapped; Jul 9, 2019 @ 05:52:15.824; context = await coro(*args); Jul 9, 2019 @ 05:52:15.824; File ""/ci/ci.py"", line 118, in get_pr; Jul 9, 2019 @ 05:52:15.824; status = await pr.batch.status(); Jul 9, 2019 @ 05:52:15.824; File ""/usr/local/lib/python3.6/dist-packages/hailtop/batch_client/aioclient.py"", line 209, in status; Jul 9, 2019 @ 05:52:15.824; return await self._client._get(f'/api/v1alpha/batches/{self.id}'); Jul 9, 2019 @ 05:52:15.824; File ""/usr/local/lib/python3.6/dist-packages/hailtop/batch_client/aioclient.py"", line 412, in _get; Jul 9, 2019 @ 05:52:15.824; self.url + path, params=params, cookies=self._cookies, headers=self._headers); Jul 9, 2019 @ 05:52:15.824; File ""/usr/local/lib/python3.6/dist-packages/aiohttp/client.py"", line 581, in _request; Jul 9, 2019 @ 05:52:15.824; resp.raise_for_status(); Jul 9, 2019 @ 05:52:15.824; File ""/usr/local/lib/python3.6/dist-packages/aiohttp/client_reqrep.py"", line 942, in raise_for_status; Jul 9, 2019 @ 05:52:15.824; headers=self.headers); Jul 9, 2019 @ 05:52:15.824; aiohttp.client_exceptions.ClientResponseError: 404, message='Not Found'; Jul 9, 2019 @ 05:52:15.824; INFO	| 2019-07-09 09:52:15,824 	| web_log.py 	| log:233 | 1",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6587:5,ERROR,ERROR,5,https://hail.is,https://github.com/hail-is/hail/issues/6587,2,"['ERROR', 'Error']","['ERROR', 'Error']"
Availability,```; Error summary: ClassCastException: is.hail.annotations.BroadcastValue cannot be cast to org.apache.spark.sql.Row; ```,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3236:5,Error,Error,5,https://hail.is,https://github.com/hail-is/hail/issues/3236,1,['Error'],['Error']
Availability,```; Error summary: FileNotFoundException: Item not found: gnomad-berylc/tx-annotation/hail0.2/gnomad.exomes.r2.0.2.tx_annotated.PLIgenes.012618.kt; ```,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2818:5,Error,Error,5,https://hail.is,https://github.com/hail-is/hail/issues/2818,1,['Error'],['Error']
Availability,"```; Error summary: ZipException: File does not conform to block gzip format.; ```; Good to print the file in a large pipeline, but especially tricky in a glob",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8118:5,Error,Error,5,https://hail.is,https://github.com/hail-is/hail/issues/8118,1,['Error'],['Error']
Availability,"```; FilterGenotypes.run(state, Array(""--remove"", ""-c"", ""g.ad(0) < 5"")); hail: fatal: parse error in condition: org.broadinstitute.hail.methods.FilterOption[Array[Int]] does not take parameters; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/147:92,error,error,92,https://hail.is,https://github.com/hail-is/hail/issues/147,1,['error'],['error']
Availability,"```; Hail version: 0.2.38-16624ac88829; Error summary: AssertionError: assertion failed: +PCStruct{locus:PCLocus(GRCh37),alleles:PCArray[PCString],gene:+PCString,annotation:+PCString,__iruid_97596:+PCArray[+PCStruct{gene:+PCString,annotation:+PCString,`the entries! [877f12a8827e18f61222c6c8c5fb04a8]`:+PCArray[PCStruct{AF_Allele2:PFloat64,imputationInfo:PFloat64,BETA:PFloat64,SE:PFloat64,`p.value.NA`:PFloat64,`AF.Cases`:PFloat64,`AF.Controls`:PFloat64,Pvalue:PFloat64}]}]}, struct{locus: locus<GRCh37>, alleles: array<str>, __iruid_97596: array<struct{gene: str, annotation: str, `the entries! [877f12a8827e18f61222c6c8c5fb04a8]`: array<struct{AF_Allele2: float64, imputationInfo: float64, BETA: float64, SE: float64, `p.value.NA`: float64, `AF.Cases`: float64, `AF.Controls`: float64, Pvalue: float64}>}>}; ...; at scala.Predef$.assert(Predef.scala:170); at is.hail.expr.ir.TableAggregateByKey.execute(TableIR.scala:1879); at is.hail.expr.ir.TableFilter.execute(TableIR.scala:581); at is.hail.expr.ir.TableOrderBy.execute(TableIR.scala:1971); at is.hail.expr.ir.TableSubset$class.execute(TableIR.scala:626); at is.hail.expr.ir.TableHead.execute(TableIR.scala:634); at is.hail.expr.ir.TableMapRows.execute(TableIR.scala:1176); ```; pipeline:; ```; mt = hl.read_matrix_table(...); x = mt._filter_partitions(range(1)); x.entries().show(); ```; version is some minor commits off of f836e49cb179117837aaae7614b6bdd28febe857",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8694:40,Error,Error,40,https://hail.is,https://github.com/hail-is/hail/issues/8694,1,['Error'],['Error']
Availability,"```; Hi, Today I updated the new verion of hail and try to re-build it, but I encountered some issues. ; ```; ## 1 gradle check ERROR /tmp/jniloader803664626041947143netlib-native_system-linux-x86_64.so: undefined symbol: cblas_dgemv. The ~/hail $ gradle installDist went successfullybut when I do ""~/hail $ gradle check"",it got some error:. ........; Gradle suite > Gradle test > org.broadinstitute.hail.methods.LinearRegressionSuite.testNonNumericPheno PASSED; Running test: Test method testWithImportFam(org.broadinstitute.hail.methods.LinearRegressionSuite); /opt/BioDir/jdk/jdk1.8.0_91/bin/java: symbol lookup error: /tmp/jniloader803664626041947143netlib-native_system-linux-x86_64.so: undefined symbol: cblas_dgemv; :test FAILED. FAILURE: Build failed with an exception.; - What went wrong:; Execution failed for task ':test'.; ; > Process 'Gradle Test Executor 1' finished with non-zero exit value 127; - Try:; Run with --stacktrace option to get the stack trace. Run with --info or --debug option to get more log output. BUILD FAILED. Total time: 5 mins 6.833 secs",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/565:133,ERROR,ERROR,133,https://hail.is,https://github.com/hail-is/hail/issues/565,4,"['ERROR', 'FAILURE', 'error']","['ERROR', 'FAILURE', 'error']"
Availability,"```; In [10]: eval_expr_typed(functions.capture([1,2,3]).map(lambda x: x.to_int64()).append([1.0, 2.0, 3.0])); Error summary: HailException: No function found with name `append' and argument types (Array[Int64], Array[Float64]); <input>:1:[ 1, 2, 3 ].map(__uid_2 => `__uid_2`.toInt64()).append([ 1.0, 2.0, 3.0 ]); ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2691:111,Error,Error,111,https://hail.is,https://github.com/hail-is/hail/issues/2691,1,['Error'],['Error']
Availability,"```; In [1]: hl.utils.range_table(1).annotate(**{'a b c' : 5}).order_by('a b c')._force_count(); ```. ```. is.hail.utils.HailException: invalid struct filter operation: fields [ ``, ` b c` ] not found; Existing struct fields: [ idx, `a b c` ]; 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:9); 	at is.hail.utils.package$.fatal(package.scala:26); 	at is.hail.expr.types.virtual.TStruct.filterSet(TStruct.scala:295); ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5277:262,Error,ErrorHandling,262,https://hail.is,https://github.com/hail-is/hail/issues/5277,2,['Error'],['ErrorHandling']
Availability,"```; Lots of local cleanups.; Use `' for quoting inside error messages.; Added SuperCommand, ToplevelCommands. Use for annotatevariants and annotatesamples.; Try to make multiple instances of (essentially) same error message consistent.; Added option to LoadVCF, ImportVCF to skip genotypes. Use in importannotations.; Fixed some bugs in FatalException handling.; Moved Type.parse to trait Parsable.; Added Parser.parseAnnotationTypes.; Added `type_expr' non-terminal to Parser.; Prefer `import ...expr._' to `import ...expr' and `expr.Foo'.; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/228:56,error,error,56,https://hail.is,https://github.com/hail-is/hail/pull/228,2,['error'],['error']
Availability,```; Py4JJavaError: An error occurred while calling z:is.hail.HailContext.apply.; : java.util.NoSuchElementException: spark.serializer; at org.apache.spark.SparkConf$$anonfun$get$1.apply(SparkConf.scala:245); at org.apache.spark.SparkConf$$anonfun$get$1.apply(SparkConf.scala:245); at scala.Option.getOrElse(Option.scala:121); at org.apache.spark.SparkConf.get(SparkConf.scala:245); at is.hail.HailContext$.checkSparkConfiguration(HailContext.scala:108); at is.hail.HailContext$.apply(HailContext.scala:180); at is.hail.HailContext.apply(HailContext.scala); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); at py4j.Gateway.invoke(Gateway.java:282); at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); at py4j.commands.CallCommand.execute(CallCommand.java:79); at py4j.GatewayConnection.run(GatewayConnection.java:214); at java.lang.Thread.run(Thread.java:745); ```,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3860:23,error,error,23,https://hail.is,https://github.com/hail-is/hail/issues/3860,1,['error'],['error']
Availability,"```; Traceback (most recent call last):; File ""/tmp/09d98b2f-4a41-4652-9eba-e319bfda2ca4/sandbox.py"", line 17, in <module>; pprint(hc.read('%s/variantqc/exacv2_rf.vds' % root, sites_only=True).filter_variants_intervals('gs://exac2/temp').head()); File ""/tmp/09d98b2f-4a41-4652-9eba-e319bfda2ca4/utils.py"", line 201, in head; return json.loads(self.variants_keytable().to_dataframe().toJSON().first()); File ""/usr/lib/spark/python/lib/pyspark.zip/pyspark/rdd.py"", line 1328, in first; File ""/usr/lib/spark/python/lib/pyspark.zip/pyspark/rdd.py"", line 1310, in take; File ""/usr/lib/spark/python/lib/pyspark.zip/pyspark/context.py"", line 933, in runJob; File ""/usr/lib/spark/python/lib/py4j-0.10.3-src.zip/py4j/java_gateway.py"", line 1133, in __call__; File ""/usr/lib/spark/python/lib/pyspark.zip/pyspark/sql/utils.py"", line 63, in deco; for criterion, pop in criteria_pops:; File ""/usr/lib/spark/python/lib/py4j-0.10.3-src.zip/py4j/protocol.py"", line 319, in get_return_value; py4j.protocol.Py4JJavaError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.runJob.; : org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 5.0 failed 20 times, most recent failure: Lost task 0.19 in stage 5.0 (TID 20022, exac-sw-3pdd.c.broad-mpg-gnomad.internal): java.lang.ClassCastException: scala.Tuple2 cannot be cast to org.apache.spark.sql.Row; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1311:1007,error,error,1007,https://hail.is,https://github.com/hail-is/hail/issues/1311,3,"['error', 'failure']","['error', 'failure']"
Availability,"```; Traceback (most recent call last):; File ""/tmp/aa0cd79aaa1a4f1ba652555c05c4bf85/pyscripts_rlCXpu.zip/gnomad_hail/slack_utils.py"", line 77, in try_slack; func(*args); File ""/tmp/aa0cd79aaa1a4f1ba652555c05c4bf85/assign_subpops.py"", line 16, in main; pop_table = exome_pop_table.union(genome_pop_table); File ""<decorator-gen-484>"", line 2, in union; File ""/tmp/aa0cd79aaa1a4f1ba652555c05c4bf85/hail-devel-3da0e7424af0.zip/hail/typecheck/check.py"", line 481, in _typecheck; return __orig_func__(*args_, **kwargs_); File ""/tmp/aa0cd79aaa1a4f1ba652555c05c4bf85/hail-devel-3da0e7424af0.zip/hail/table.py"", line 1496, in union; return Table(self._jt.union([table._jt for table in tables])); File ""/usr/lib/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py"", line 1133, in __call__; answer, self.gateway_client, self.target_id, self.name); File ""/tmp/aa0cd79aaa1a4f1ba652555c05c4bf85/hail-devel-3da0e7424af0.zip/hail/utils/java.py"", line 196, in deco; 'Error summary: %s' % (deepest, full, hail.__version__, deepest)) from None; hail.utils.java.FatalError: AssertionError: assertion failed. Java stack trace:; java.lang.AssertionError: assertion failed; at scala.Predef$.assert(Predef.scala:156); at is.hail.table.Table.union(Table.scala:931); at is.hail.table.Table.union(Table.scala:928); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); at py4j.Gateway.invoke(Gateway.java:280); at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); at py4j.commands.CallCommand.execute(CallCommand.java:79); at py4j.GatewayConnection.run(GatewayConnection.java:214); at java.lang.Thread.run(Thread.java:748). Hail v",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3404:957,Error,Error,957,https://hail.is,https://github.com/hail-is/hail/issues/3404,1,['Error'],['Error']
Availability,"```; Traceback (most recent call last):; File ""<stdin>"", line 5, in <module>; File ""/mnt/lustre/tpoterba/hail-inst/python/pyhail/dataset.py"", line 77, in annotate_samples_expr; return self.hc.run_command(self, pargs); File ""/mnt/lustre/tpoterba/hail-inst/python/pyhail/context.py"", line 45, in run_command; cmd_args); File ""/opt/spark/spark-1.5.2/python/lib/py4j-0.8.2.1-src.zip/py4j/java_gateway.py"", line 538, in __call__; File ""/opt/spark/spark-1.5.2/python/pyspark/sql/utils.py"", line 36, in deco; return f(*a, **kw); File ""/opt/spark/spark-1.5.2/python/lib/py4j-0.8.2.1-src.zip/py4j/protocol.py"", line 300, in get_return_value; py4j.protocol.Py4JJavaError: An error occurred while calling o417.run.; : org.apache.spark.SparkDriverExecutionException: Execution error; at org.apache.spark.scheduler.DAGScheduler.handleTaskCompletion(DAGScheduler.scala:1024); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1493); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1458); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1447); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:567); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1824); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1944); at org.apache.spark.rdd.RDD$$anonfun$reduce$1.apply(RDD.scala:1007); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108); at org.apache.spark.rdd.RDD.withScope(RDD.scala:310); at org.apache.spark.rdd.RDD.reduce(RDD.scala:989); at org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1.apply(RDD.scala:1118); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:1",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1107:665,error,error,665,https://hail.is,https://github.com/hail-is/hail/issues/1107,2,['error'],['error']
Availability,"```; body='{\\n \""error\"": {\\n \""code\"": 403,\\n \""message\"": \""Quota exceeded for quota group \\'default\\' and limit \\'Queries per user per 100 seconds\\' of service \\'compute.googleapis.com\\' for consumer \\'project_number:859893752941\\'.\"",\\n \""errors\"": [\\n {\\n \""message\"": \""Quota exceeded for quota group \\'default\\' and limit \\'Queries per user per 100 seconds\\' of service \\'compute.googleapis.com\\' for consumer \\'project_number:859893752941\\'.\"",\\n \""domain\"": \""usageLimits\"",\\n \""reason\"": \""rateLimitExceeded\""\\n }\\n ],\\n \""status\"": \""PERMISSION_DENIED\""\\n }\\n}; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10613:18,error,error,18,https://hail.is,https://github.com/hail-is/hail/pull/10613,2,['error'],"['error', 'errors']"
Availability,"```; from hail import *; hc = HailContext(); input_vcf = ""gs://seqr-hail/reference_data/GRCh38/1kg/ALL.GRCh38_sites.20170504.vcf.gz""; vds = hc.import_vcf(input_vcf, npartitions=1000, force=True); ```. causes. ```; FatalErrorTraceback (most recent call last); <ipython-input-4-5e86630fbae5> in <module>(); ----> 1 vds = hc.import_vcf(input_vcf, npartitions=1000, force=True). <decorator-gen-291> in import_vcf(self, path, force, force_bgz, header_file, npartitions, sites_only, store_gq, pp_as_pl, skip_bad_ad, generic, call_fields). /home/hail/pyhail-hail-is-master-ebabd77.zip/hail/java.pyc in handle_py4j(func, *args, **kwargs); 111 raise FatalError('%s\n\nJava stack trace:\n%s\n'; 112 'Hail version: %s\n'; --> 113 'Error summary: %s' % (deepest, full, Env.hc().version, deepest)); 114 except py4j.protocol.Py4JError as e:; 115 if e.args[0].startswith('An error occurred while calling'):. FatalError: IllegalArgumentException: Size exceeds Integer.MAX_VALUE. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 0.0 failed 20 times, most recent failure: Lost task 0.19 in stage 0.0 (TID 19, seqr-pipeline-cluster-grch38-w-0.c.seqr-project.internal): java.lang.IllegalArgumentException: Size exceeds Integer.MAX_VALUE; 	at sun.nio.ch.FileChannelImpl.map(FileChannelImpl.java:869); 	at org.apache.spark.storage.DiskStore$$anonfun$getBytes$2.apply(DiskStore.scala:103); 	at org.apache.spark.storage.DiskStore$$anonfun$getBytes$2.apply(DiskStore.scala:91); 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1310); 	at org.apache.spark.storage.DiskStore.getBytes(DiskStore.scala:105); 	at org.apache.spark.storage.BlockManager.getLocalValues(BlockManager.scala:438); 	at org.apache.spark.storage.BlockManager.get(BlockManager.scala:606); 	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:663); 	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:330); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:281); 	at or",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1806:720,Error,Error,720,https://hail.is,https://github.com/hail-is/hail/issues/1806,2,"['Error', 'error']","['Error', 'error']"
Availability,"```; gsutil cat gs://hail-ci-0-1/deploy/ef349a51016f\*/job-log; ```. the last few lines:. ```; + make push-batch; docker build -t batch .; time=""2018-09-26T00:14:20Z"" level=error msg=""failed to dial gRPC: cannot connect to the Docker daemon. Is 'docker daemon' running on this host?: dial unix /var/run/docker.sock: connect: permission denied""; Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Post http://%2Fvar%2Frun%2Fdocker.sock/v1.38/build?buildargs=%7B%7D&cachefrom=%5B%5D&cgroupparent=&cpuperiod=0&cpuquota=0&cpusetcpus=&cpusetmems=&cpushares=0&dockerfile=Dockerfile&labels=%7B%7D&memory=0&memswap=0&networkmode=default&rm=1&session=vhnl6wchhs00sgt8raa35j7m7&shmsize=0&t=batch&target=&ulimits=null&version=1: dial unix /var/run/docker.sock: connect: permission denied; time=""2018-09-26T00:14:20Z"" level=error msg=""Can't add file /hail/repo/batch/batch/server.py to tar: io: read/write on closed pipe""; Makefile:14: recipe for target 'build-batch' failed; make: *** [build-batch] Error 1; ```. this is failing all deploys of hail, which is safe, but it prevents our users from getting updates.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4443:173,error,error,173,https://hail.is,https://github.com/hail-is/hail/issues/4443,3,"['Error', 'error']","['Error', 'error']"
Availability,"```; hail read -i profile.vds annotatesamples tsv -i sampleInfo.tsv -t 'Age: Int, Health: Double' -r sa.info filtersamples --keep -c 'sa.info.Health > 0.2' linreg -y sa.info.Health -c 'sa.info.Age' -r va.linreg exportvariants -c 'Variant=v, Beta = va.linreg.beta, Pval = va.linreg.pval' -o linreg.tsv; ```. ```; [Stage 1:> (0 + 7) / 7]hail: exportvariants: caught exception: org.apache.spark.SparkException: Job aborted due to stage failure: Task 5 in stage 1.0 failed 1 times, most recent failure: Lost task 5.0 in stage 1.0 (TID 13, localhost): java.lang.ArrayIndexOutOfBoundsException: 357; at org.broadinstitute.hail.methods.LinRegBuilder$$anonfun$stats$1.apply$mcVI$sp(LinearRegression.scala:80); at org.broadinstitute.hail.methods.LinRegBuilder$$anonfun$stats$1.apply(LinearRegression.scala:80); at org.broadinstitute.hail.methods.LinRegBuilder$$anonfun$stats$1.apply(LinearRegression.scala:80); at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); at scala.collection.mutable.ArrayOps$ofInt.foreach(ArrayOps.scala:156); at org.broadinstitute.hail.methods.LinRegBuilder.stats(LinearRegression.scala:80); at org.broadinstitute.hail.methods.LinearRegression$$anonfun$apply$4.apply(LinearRegression.scala:130); at org.broadinstitute.hail.methods.LinearRegression$$anonfun$apply$4.apply(LinearRegression.scala:129); at org.apache.spark.rdd.PairRDDFunctions$$anonfun$mapValues$1$$anonfun$apply$41$$anonfun$apply$42.apply(PairRDDFunctions.scala:700); at org.apache.spark.rdd.PairRDDFunctions$$anonfun$mapValues$1$$anonfun$apply$41$$anonfun$apply$42.apply(PairRDDFunctions.scala:700); at scala.collection.Iterator$$anon$11.next(Iterator.scala:328); at scala.collection.Iterator$$anon$20.next(Iterator.scala:635); at scala.collection.Iterator$$anon$20.next(Iterator.scala:633); at scala.collection.Iterator$$anon$11.next(Iterator.scala:328); at scala.collection.Iterator$$anon$11.next(Iterator.scala:328); at scala.collection.Iterator$$anon$11.next(Iterator.scala:328); a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/336:433,failure,failure,433,https://hail.is,https://github.com/hail-is/hail/issues/336,2,['failure'],['failure']
Availability,"```; hail.utils.java.FatalError: AssertionError: assertion failed. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 567 in stage 86.0 failed 20 times, most recent failure: Lost task 567.19 in stage 86.0 (TID 59449, exomes-sw-73zg.c.broad-mpg-gnomad.internal, executor 41): java.lang.AssertionError: assertion failed; 	at scala.Predef$.assert(Predef.scala:156); 	at is.hail.annotations.RegionValueBuilder.addRegionValue(RegionValueBuilder.scala:417); 	at is.hail.annotations.RegionValueBuilder.addField(RegionValueBuilder.scala:345); 	at is.hail.annotations.RegionValueBuilder.addField(RegionValueBuilder.scala:351); 	at is.hail.expr.ir.MatrixAggregateColsByKey$$anonfun$33$$anonfun$apply$15.apply(MatrixIR.scala:1016); 	at is.hail.expr.ir.MatrixAggregateColsByKey$$anonfun$33$$anonfun$apply$15.apply(MatrixIR.scala:972); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$18$$anon$3.next(OrderedRVD.scala:1106); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$18$$anon$3.next(OrderedRVD.scala:1100); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$18$$anon$3.next(OrderedRVD.scala:1106); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$18$$anon$3.next(OrderedRVD.scala:1100); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$18$$anon$3.next(OrderedRVD.scala:1106); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$18$$anon$3.next(OrderedRVD.scala:1100); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at scala.collection.Iterator$class.foreach(Iterator.scala:89",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4263:144,failure,failure,144,https://hail.is,https://github.com/hail-is/hail/issues/4263,2,['failure'],['failure']
Availability,"```; import hail as hl; ds = hl.balding_nichols_model(3, 100, 100); ds.annotate_globals(x=[1,2,3]); ```; The above script breaks on devel clusters.; ```; py4j.protocol.Py4JJavaError: An error occurred while calling o64.annotateGlobalExpr.; : java.lang.NoClassDefFoundError: is/hail/asm4s/AsmFunction2; 	at java.lang.ClassLoader.defineClass1(Native Method); 	at java.lang.ClassLoader.defineClass(ClassLoader.java:763); 	at java.lang.ClassLoader.defineClass(ClassLoader.java:642); 	at is.hail.asm4s.package$HailClassLoader$.liftedTree1$1(package.scala:174); 	at is.hail.asm4s.package$HailClassLoader$.loadOrDefineClass(package.scala:170); 	at is.hail.asm4s.package$.loadClass(package.scala:181); 	at is.hail.asm4s.FunctionBuilder$$anon$1.apply(FunctionBuilder.scala:312); 	at is.hail.expr.CM$$anonfun$runWithDelayedValues$1.apply(CM.scala:84); 	at is.hail.expr.CM$$anonfun$runWithDelayedValues$1.apply(CM.scala:82); 	at is.hail.expr.Parser$$anonfun$is$hail$expr$Parser$$evalNoTypeCheck$1.apply(Parser.scala:64); 	at is.hail.expr.Parser$$anonfun$12$$anonfun$apply$6.apply(Parser.scala:172); ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2982:186,error,error,186,https://hail.is,https://github.com/hail-is/hail/issues/2982,1,['error'],['error']
Availability,"```; is.hail.utils.HailException: hybrid.m37m.vcf.bgz: caught htsjdk.tribble.TribbleException: The provided VCF file is malformed at approximately line number 458249: unparsable vcf record with allele M; offending line: 3	60830534	.	M	C	40	.	.	GT:AD	1/1:0,40; 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:17); 	at is.hail.utils.package$.fatal(package.scala:26); 	at is.hail.utils.Context.wrapException(Context.scala:23); 	at is.hail.io.vcf.LoadVCF$$anonfun$parseLines$1$$anon$1.hasNext(LoadVCF.scala:742); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$6$$anon$5.hasNext(OrderedRVD.scala:733); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:439); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at is.hail.rvd.OrderedRVD$$anonfun$11.apply(OrderedRVD.scala:491); 	at is.hail.rvd.OrderedRVD$$anonfun$11.apply(OrderedRVD.scala:490); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$26.apply(RDD.scala:844); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$26.apply(RDD.scala:844); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748); Caused by: htsjdk.tribble.TribbleException: The provided VCF file is malformed at approximately line number 458249: unparsable vcf record with allele M; 	at htsjdk.variant.vcf.AbstractVCFCodec.generateException(AbstractVCFCodec.j",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3015:278,Error,ErrorHandling,278,https://hail.is,https://github.com/hail-is/hail/issues/3015,2,['Error'],['ErrorHandling']
Availability,"```; kubectl apply -f deployment.yaml; Error from server (Forbidden): error when retrieving current configuration of:; Resource: ""/v1, Resource=namespaces"", GroupVersionKind: ""/v1, Kind=Namespace""; Name: ""batch-pods"", Namespace: """"; Object: &{map[""apiVersion"":""v1"" ""kind"":""Namespace"" ""metadata"":map[""annotations"":map[""kubectl.kubernetes.io/last-applied-configuration"":""""] ""name"":""batch-pods"" ""namespace"":""""]]}; from server for: ""deployment.yaml"": namespaces ""batch-pods"" is forbidden: User ""system:serviceaccount:batch-pods:deploy-svc"" cannot get namespaces in the namespace ""batch-pods"": Unknown user ""system:serviceaccount:batch-pods:deploy-svc""; Error from server (Forbidden): error when retrieving current configuration of:; Resource: ""/v1, Resource=serviceaccounts"", GroupVersionKind: ""/v1, Kind=ServiceAccount""; Name: ""batch-svc"", Namespace: ""batch-pods""; Object: &{map[""kind"":""ServiceAccount"" ""metadata"":map[""name"":""batch-svc"" ""namespace"":""batch-pods"" ""annotations"":map[""kubectl.kubernetes.io/last-applied-configuration"":""""]] ""apiVersion"":""v1""]}; from server for: ""deployment.yaml"": serviceaccounts ""batch-svc"" is forbidden: User ""system:serviceaccount:batch-pods:deploy-svc"" cannot get serviceaccounts in the namespace ""batch-pods"": Unknown user ""system:serviceaccount:batch-pods:deploy-svc""; Error from server (Forbidden): error when retrieving current configuration of:; Resource: ""rbac.authorization.k8s.io/v1, Resource=roles"", GroupVersionKind: ""rbac.authorization.k8s.io/v1, Kind=Role""; Name: ""batch-pods-admin"", Namespace: ""batch-pods""; Object: &{map[""apiVersion"":""rbac.authorization.k8s.io/v1"" ""kind"":""Role"" ""metadata"":map[""name"":""batch-pods-admin"" ""namespace"":""batch-pods"" ""annotations"":map[""kubectl.kubernetes.io/last-applied-configuration"":""""]] ""rules"":[map[""apiGroups"":[""""] ""resources"":[""pods""] ""verbs"":[""get"" ""list"" ""watch"" ""create"" ""update"" ""patch"" ""delete""]] map[""apiGroups"":[""""] ""resources"":[""pods/log""] ""verbs"":[""get""]]]]}; from server for: ""deployment.yaml"": roles.rbac.author",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4609:39,Error,Error,39,https://hail.is,https://github.com/hail-is/hail/issues/4609,4,"['Error', 'error']","['Error', 'error']"
Availability,"```; mu = mutation_ht.aggregate(hl.agg.group_by(; hl.struct(context=mutation_ht.context, ref=mutation_ht.ref, alt=mutation_ht.alt,; methylation_level=mutation_ht.methylation_level),; hl.agg.collect(mutation_ht.mu_snp))); ```; got:; ```; Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 1.0 failed 1 times, most recent failure: Lost task 1.0 in stage 1.0 (TID 11, localhost, executor driver): com.esotericsoftware.kryo.KryoException: sun.reflect.generics.reflectiveObjects.NotImplementedException; Serialization trace:; m (is.hail.annotations.aggregators.KeyedRegionValueAggregator); 	at com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectField.java:101); 	at com.esotericsoftware.kryo.serializers.FieldSerializer.write(FieldSerializer.java:518); 	at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:628); 	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.write(DefaultArraySerializers.java:366); 	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.write(DefaultArraySerializers.java:307); 	at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:628); 	at org.apache.spark.serializer.KryoSerializerInstance.serialize(KryoSerializer.scala:315); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:386); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); Caused by: sun.reflect.generics.reflectiveObjects.NotImplementedException; 	at is.hail.annotations.UnKryoSerializable$class.write(UnsafeRow.scala:15); 	at is.hail.annotations.UnsafeRow.write(UnsafeRow.scala:141); 	at com.esotericsoftware.kryo.serializers.DefaultSerializers$KryoSerializableSerializer.write(DefaultSerializers.java:505); 	at com.esotericsoftware.kryo.serializers.DefaultSerializers$KryoSerializa",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4215:314,failure,failure,314,https://hail.is,https://github.com/hail-is/hail/issues/4215,2,['failure'],['failure']
Availability,"```; {""levelname"": ""ERROR"", ""asctime"": ""2019-07-22 22:20:29,378"", ""filename"": ""batch.py"", ""funcNameAndLine"": ""kube_event_loop:1273"", ""message"": ""k8s event stream failed due to: 'NoneType' object is not subscriptable"", ""exc_info"": ""Traceback (most recent call last):\n File \""/usr/local/lib/python3.6/dist-packages/batch/batch.py\"", line 1271, in kube_event_loop\n await pod_changed(object)\n File \""/usr/local/lib/python3.6/dist-packages/batch/batch.py\"", line 1256, in pod_changed\n await update_job_with_pod(job, pod)\n File \""/usr/local/lib/python3.6/dist-packages/batch/batch.py\"", line 1234, in update_job_with_pod\n await job.mark_complete(pod)\n File \""/usr/local/lib/python3.6/dist-packages/batch/batch.py\"", line 580, in mark_complete\n setup_container = pod.status.init_container_statuses[0]\nTypeError: 'NoneType' object is not subscriptable""}; {""levelname"": ""ERROR"", ""asctime"": ""2019-07-22 22:20:42,418"", ""filename"": ""batch.py"", ""funcNameAndLine"": ""kube_event_loop:1273"", ""message"": ""k8s event stream failed due to: 'NoneType' object is not subscriptable"", ""exc_info"": ""Traceback (most recent call last):\n File \""/usr/local/lib/python3.6/dist-packages/batch/batch.py\"", line 1271, in kube_event_loop\n await pod_changed(object)\n File \""/usr/local/lib/python3.6/dist-packages/batch/batch.py\"", line 1256, in pod_changed\n await update_job_with_pod(job, pod)\n File \""/usr/local/lib/python3.6/dist-packages/batch/batch.py\"", line 1234, in update_job_with_pod\n await job.mark_complete(pod)\n File \""/usr/local/lib/python3.6/dist-packages/batch/batch.py\"", line 580, in mark_complete\n setup_container = pod.status.init_container_statuses[0]\nTypeError: 'NoneType' object is not subscriptable""}; {""levelname"": ""ERROR"", ""asctime"": ""2019-07-22 22:20:49,707"", ""filename"": ""batch.py"", ""funcNameAndLine"": ""kube_event_loop:1273"", ""message"": ""k8s event stream failed due to: Object of type 'datetime' is not JSON serializable"", ""exc_info"": ""Traceback (most recent call last):\n File \""/usr/local/l",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6707:20,ERROR,ERROR,20,https://hail.is,https://github.com/hail-is/hail/issues/6707,2,['ERROR'],['ERROR']
Availability,"```; {""levelname"": ""ERROR"", ""asctime"": ""2019-07-29 12:31:18,857"", ""filename"": ""batch.py"", ""funcNameAndLine"": ""kube_event_loop:1270"", ""message"": ""k8s event stream failed due to: "", ""exc_info"": ""Traceback (most recent call last):\n File \""/usr/local/lib/python3.6/dist-packages/batch/batch.py\"", line 1268, in kube_event_loop\n await pod_changed(object)\n File \""/usr/local/lib/python3.6/dist-packages/batch/batch.py\"", line 1253, in pod_changed\n await update_job_with_pod(job, pod)\n File \""/usr/local/lib/python3.6/dist-packages/batch/batch.py\"", line 1195, in update_job_with_pod\n err = await app['k8s'].delete_pod(name=pod.metadata.name)\n File \""/usr/local/lib/python3.6/dist-packages/batch/k8s.py\"", line 46, in delete_pod\n assert name is not None\nAssertionError""}; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6753:20,ERROR,ERROR,20,https://hail.is,https://github.com/hail-is/hail/issues/6753,1,['ERROR'],['ERROR']
Availability,"```; {""levelname"": ""INFO"", ""asctime"": ""2019-07-26 23:46:41,095"", ""filename"": ""batch.py"", ""funcNameAndLine"": ""kube_event_loop:1263"", ""message"": ""received event ERROR None""}; {""levelname"": ""ERROR"", ""asctime"": ""2019-07-26 23:46:41,095"", ""filename"": ""batch.py"", ""funcNameAndLine"": ""kube_event_loop:1266"", ""message"": ""k8s event stream failed due to: 'NoneType' object is not subscriptable"", ""exc_info"": ""Traceback (most recent call last):\n File \""/usr/local/lib/python3.6/dist-packages/batch/batch.py\"", line 1264, in kube_event_loop\n await pod_changed(object)\n File \""/usr/local/lib/python3.6/dist-packages/batch/batch.py\"", line 1248, in pod_changed\n job = await Job.from_k8s_labels(pod)\n File \""/usr/local/lib/python3.6/dist-packages/batch/batch.py\"", line 388, in from_k8s_labels\n batch_id = pod.metadata.labels['batch_id']\nTypeError: 'NoneType' object is not subscriptable""}; {""levelname"": ""INFO"", ""asctime"": ""2019-07-26 23:46:44,287"", ""filename"": ""web_log.py"", ""funcNameAndLine"": ""log:233"", ""message"": ""10.32.34.1 [26/Jul/2019:23:46:44 +0000] \""GET /healthcheck HTTP/1.1\"" 200 177 \""-\"" \""kube-probe/1.13+\"""", ""remote_address"": ""10.32.34.1"", ""request_start_time"": ""[26/Jul/2019:23:46:44 +0000]"", ""first_request_line"": ""GET /healthcheck HTTP/1.1"", ""response_status"": 200, ""response_size"": 177, ""request_header"": {""Referer"": ""-"", ""User-Agent"": ""kube-probe/1.13+""}}; ```. why even send this ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6750:159,ERROR,ERROR,159,https://hail.is,https://github.com/hail-is/hail/issues/6750,2,['ERROR'],['ERROR']
Availability,"```; {; ""levelname"": ""ERROR"",; ""asctime"": ""2019-07-02 13:17:00,483"",; ""filename"": ""web_protocol.py"",; ""funcNameAndLine"": ""log_exception:355"",; ""message"": ""Error handling request"",; ""exc_info"": ""Traceback (most recent call last):\n File \""/usr/local/lib/python3.6/dist-packages/aiohttp/web_protocol.py\"", line 418, in start\n resp = await task\n File \""/usr/local/lib/python3.6/dist-packages/aiohttp/web_app.py\"", line 458, in _handle\n resp = await handler(request)\n File \""/usr/local/lib/python3.6/dist-packages/aiohttp/web_urldispatcher.py\"", line 157, in handler_wrapper\n result = await result\n File \""/usr/local/lib/python3.6/dist-packages/batch/batch.py\"", line 914, in create_jobs\n success = await jobs_builder.commit()\n File \""/usr/local/lib/python3.6/dist-packages/batch/database.py\"", line 161, in commit\n await cursor.executemany(self._jobs_sql, self._jobs)\n File \""/usr/local/lib/python3.6/dist-packages/aiomysql/cursors.py\"", line 283, in executemany\n self._get_db().encoding))\n File \""/usr/local/lib/python3.6/dist-packages/aiomysql/cursors.py\"", line 318, in _do_execute_many\n r = await self.execute(sql + postfix)\n File \""/usr/local/lib/python3.6/dist-packages/aiomysql/cursors.py\"", line 239, in execute\n await self._query(query)\n File \""/usr/local/lib/python3.6/dist-packages/aiomysql/cursors.py\"", line 457, in _query\n await conn.query(q)\n File \""/usr/local/lib/python3.6/dist-packages/aiomysql/connection.py\"", line 428, in query\n await self._read_query_result(unbuffered=unbuffered)\n File \""/usr/local/lib/python3.6/dist-packages/aiomysql/connection.py\"", line 622, in _read_query_result\n await result.read()\n File \""/usr/local/lib/python3.6/dist-packages/aiomysql/connection.py\"", line 1105, in read\n first_packet = await self.connection._read_packet()\n File \""/usr/local/lib/python3.6/dist-packages/aiomysql/connection.py\"", line 593, in _read_packet\n packet.check_error()\n File \""/usr/local/lib/python3.6/dist-packages/pymysql/protocol.py\"", line 220, in ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6543:22,ERROR,ERROR,22,https://hail.is,https://github.com/hail-is/hail/issues/6543,2,"['ERROR', 'Error']","['ERROR', 'Error']"
Availability,```Error summary: Error: Multiple ES-Hadoop versions detected in the classpath; please use only one; jar:file:/tmp/7a54aa23-f38b-40e4-8068-3ea48ee212a0/hail-annotateAlleles01.jar; jar:file:/usr/lib/spark/jars/hail-0.1-6e815ac3d973-Spark-2.0.2.jar; ```,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2272:3,Error,Error,3,https://hail.is,https://github.com/hail-is/hail/issues/2272,2,['Error'],['Error']
Availability,"```pycon; In [1]: import hail as hl. In [2]: hl.init(); 2022-03-11 14:49:23 WARN Utils:69 - Your hostname, metis resolves to a loopback address: 127.0.0.1; using 192.168.1.169 instead (on interface eth0); 2022-03-11 14:49:23 WARN Utils:69 - Set SPARK_LOCAL_IP if you need to bind to another address; 2022-03-11 14:49:23 WARN NativeCodeLoader:60 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).; Running on Apache Spark version 3.1.2; SparkUI available at http://192.168.1.169:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.2.90-92e40ce648a8; LOGGING: writing to /home/cdv/src/hail/hail/hail-20220311-1449-0.2.90-92e40ce648a8.log. In [3]: mt = hl.import_vcf('src/test/resources/sample.vcf').filter_rows(False). In [4]: ht = mt._localize_entries('entries', 'columns'). In [5]: groups = ht.group_by(the_key=ht.key).aggregate(value=hl.agg.collect(ht.row_value)).collect(); 2022-03-11 14:50:08 Hail: INFO: Coerced sorted dataset; 2022-03-11 14:50:10 Hail: INFO: Ordering unsorted dataset with network shuffle1]. In [6]: len(groups); Out[6]: 346. In [7]: mt = mt.checkpoint('~/tmp/hail/sample.vcf.filtered.mt'); 2022-03-11 14:51:14 Hail: INFO: wrote matrix table with 0 rows and 100 columns in 0 partitions to ~/tmp/hail/sample.vcf.filtered.mt. In [8]: ht = mt._localize_entries('entries', 'columns'). In [9]: groups_native = ht.group_by(the_key=ht.key).aggregate(value=hl.agg.collect(ht.row_value)).collect(). In [10]: len(groups_native); Out[10]: 0; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/11562:629,avail,available,629,https://hail.is,https://github.com/hail-is/hail/issues/11562,2,"['avail', 'checkpoint']","['available', 'checkpoint']"
Availability,"```python; >>> hl.eval(hl.min_rep(hl.locus('1', 10000), ['G', hl.null(hl.tstr)])); ```; I don't have any problem with this erroring, but it's mode should be more user friendly. Either that or we allow `NA` in `min_rep` (just return the NA) in the `alleles` array and don't use it for the purposes of actually `min_rep`ping.; ```; java.lang.NullPointerException: null ; at is.hail.codegen.generated.C172.method_2(Unknown Source) ; at is.hail.codegen.generated.C172.method_1(Unknown Source) ; at is.hail.codegen.generated.C172.apply(Unknown Source) ; at is.hail.codegen.generated.C172.apply(Unknown Source) ; at is.hail.expr.ir.Interpret$$anonfun$apply$33.apply(Interpret.scala:711) ; at is.hail.expr.ir.Interpret$$anonfun$apply$33.apply(Interpret.scala:690) ; at is.hail.utils.package$.using(package.scala:596); at is.hail.annotations.Region$.scoped(Region.scala:18); at is.hail.expr.ir.Interpret$.apply(Interpret.scala:690); at is.hail.expr.ir.Interpret$.apply(Interpret.scala:91); at is.hail.expr.ir.Interpret$.apply(Interpret.scala:61); at is.hail.expr.ir.FoldConstants$$anonfun$apply$1$$anonfun$apply$2.apply(FoldConstants.scala:30); at is.hail.expr.ir.FoldConstants$$anonfun$apply$1$$anonfun$apply$2.apply(FoldConstants.scala:8); at is.hail.expr.ir.RewriteBottomUp$.is$hail$expr$ir$RewriteBottomUp$$rewrite$1(RewriteBottomUp.scala:15); at is.hail.expr.ir.RewriteBottomUp$.apply(RewriteBottomUp.scala:25); at is.hail.expr.ir.FoldConstants$$anonfun$apply$1.apply(FoldConstants.scala:8); at is.hail.expr.ir.FoldConstants$$anonfun$apply$1.apply(FoldConstants.scala:7); at is.hail.expr.ir.ExecuteContext$$anonfun$scoped$1.apply(ExecuteContext.scala:8); at is.hail.expr.ir.ExecuteContext$$anonfun$scoped$1.apply(ExecuteContext.scala:7); at is.hail.utils.package$.using(package.scala:596); ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6889:123,error,erroring,123,https://hail.is,https://github.com/hail-is/hail/issues/6889,2,"['error', 'ping']","['erroring', 'ping']"
Availability,"```python; import hail as hl; hl.init(); hl.utils.get_1kg('data'); mt = hl.read_matrix_table('data/1kg.mt'); mt.entries().show(10); df = mt.entries().to_pandas(); ```. ```; Hail version: 0.2.18-08ec699f0fd4; Error summary: HailException: optimization changed type!; before: Table{global:Struct{},key:[],row:Struct{`locus.contig`:String,`locus.position`:Int32,alleles:Array[String],rsid:String,qual:Float64,filters:Array[String],`info.AC`:Array[Int32],`info.AF`:Array[Float64],`info.AN`:Int32,`info.BaseQRankSum`:Float64,`info.ClippingRankSum`:Float64,`info.DP`:Int32,`info.DS`:Boolean,`info.FS`:Float64,`info.HaplotypeScore`:Float64,`info.InbreedingCoeff`:Float64,`info.MLEAC`:Array[Int32],`info.MLEAF`:Array[Float64],`info.MQ`:Float64,`info.MQ0`:Int32,`info.MQRankSum`:Float64,`info.QD`:Float64,`info.ReadPosRankSum`:Float64,`info.set`:String,s:String,`GT.alleles`:Array[Int32],`GT.phased`:Boolean,AD:Array[Int32],DP:Int32,GQ:Int32,PL:Array[Int32]}}; after: Table{global:Struct{},key:[],row:Struct{`locus.contig`:String,`locus.position`:Int32,alleles:Array[String],rsid:String,qual:Float64,filters:Array[String],`info.AC`:Array[Int32],`info.AF`:Array[Float64],`info.AN`:Int32,`info.BaseQRankSum`:Float64,`info.ClippingRankSum`:Float64,`info.DP`:Int32,`info.DS`:Boolean,`info.FS`:Float64,`info.HaplotypeScore`:Float64,`info.InbreedingCoeff`:Float64,`info.MLEAC`:Array[Int32],`info.MLEAF`:Array[Float64],`info.MQ`:Float64,`info.MQ0`:Int32,`info.MQRankSum`:Float64,`info.QD`:Float64,`info.ReadPosRankSum`:Float64,`info.set`:String,s:String,`GT.alleles`:Array[Int32],`GT.phased`:Boolean,AD:Array[+Int32],DP:Int32,GQ:Int32,PL:Array[+Int32]}}; ```. Randomly assigned @catoverdrive, cc: @tpoterba",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6766:208,Error,Error,208,https://hail.is,https://github.com/hail-is/hail/issues/6766,1,['Error'],['Error']
Availability,"```python; vds.filter_variants_expr('v => va.pass').count(); ```. ```; vds.filter_variants_expr('v => va.pass').count(); ---------------------------------------------------------------------------; FatalError Traceback (most recent call last); <ipython-input-44-0380f72331b7> in <module>(); ----> 1 vds.filter_variants_expr('v => va.pass').count(). <decorator-gen-223> in filter_variants_expr(self, condition, keep). /Users/tpoterba/hail/python/hail/java.py in handle_py4j(func, *args, **kwargs); 111 raise FatalError('%s\n\nJava stack trace:\n%s\n'; 112 'Hail version: %s\n'; --> 113 'Error summary: %s' % (deepest, full, Env.hc().version, deepest)); 114 except py4j.protocol.Py4JError as e:; 115 if e.args[0].startswith('An error occurred while calling'):. FatalError: UnsupportedOperationException: null. Java stack trace:; java.lang.UnsupportedOperationException: null; 	at is.hail.expr.AST.typecheckThis(AST.scala:215); 	at is.hail.expr.AST.typecheckThis(AST.scala:213); 	at is.hail.expr.AST.typecheck(AST.scala:219); 	at is.hail.expr.Parser$.is$hail$expr$Parser$$eval(Parser.scala:57); 	at is.hail.expr.Parser$.parseExpr(Parser.scala:67); 	at is.hail.expr.Parser$.parseTypedExpr(Parser.scala:77); 	at is.hail.variant.VariantSampleMatrix.filterVariantsExpr(VariantSampleMatrix.scala:1229); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:497); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:280); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:214); 	at java.lang.Thread.run(Thread.java:7",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1623:586,Error,Error,586,https://hail.is,https://github.com/hail-is/hail/issues/1623,2,"['Error', 'error']","['Error', 'error']"
Availability,"`aiohttp.ClientOSError` inherits from `OSError`, so we can just use `errno` or `strerror` directly. We should not directly use the `args` because one of the subclasses of `ClientOSError` sets them to *its* arguments after initializing its super classes with the expected arguments:. ```python3; class ClientConnectorError(ClientOSError):; """"""Client connector error. Raised in :class:`aiohttp.connector.TCPConnector` if; a connection can not be established.; """""". def __init__(self, connection_key: ConnectionKey, os_error: OSError) -> None:; self._conn_key = connection_key; self._os_error = os_error; super().__init__(os_error.errno, os_error.strerror); self.args = (connection_key, os_error); ```. I also tried to remove `e.args` from the `ClientPayloadError` case (the one right above this, and the only one still using `e.args`), but neither that class nor any super class sets a field with the error message (in fact, no fields are ever set so we can only use `e.args`).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13921:359,error,error,359,https://hail.is,https://github.com/hail-is/hail/pull/13921,2,['error'],['error']
Availability,"`create_database_pool` does not actually make a connection, rather it sets up a `_PoolContextManager`. We need to make sure this line. ```python; self.pool = await self.async_exit_stack.enter_async_context(x); ```. is covered by transient error handling.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14309:239,error,error,239,https://hail.is,https://github.com/hail-is/hail/pull/14309,1,['error'],['error']
Availability,`hail: fatal: parse error in condition: reflective typecheck has failed: value DUMMY is not a member of __infoClass; `. There's got to be a better way to do this.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/84:20,error,error,20,https://hail.is,https://github.com/hail-is/hail/issues/84,1,['error'],['error']
Availability,"`hl.balding_nichols_model` generates a MatrixTable representing a genetic dataset randomly drawn according to the Balding Nichols model.; ```; In [5]: hl.balding_nichols_model(2,3,3).show() ; 2019-08-15 10:38:05 Hail: INFO: balding_nichols_model: generating genotypes for 2 populations, 3 samples, and 3 variants...; +---------------+------------+------+------+------+; | locus | alleles | 0.GT | 1.GT | 2.GT |; +---------------+------------+------+------+------+; | locus<GRCh37> | array<str> | call | call | call |; +---------------+------------+------+------+------+; | 1:1 | [""A"",""C""] | 0/0 | 0/0 | 0/1 |; | 1:2 | [""A"",""C""] | 1/1 | 1/1 | 1/1 |; | 1:3 | [""A"",""C""] | 1/1 | 0/1 | 0/0 |; +---------------+------------+------+------+------+. ```; These MatrixTables are useful both as examples and test datasets for genetics-related Hail code. Unfortunately, the loci are chosen sequentially starting with chromosome 1, position 1. This region of chromosome 1 is in the telomere. Many genetic annotations contain no information in this region. As a result, `hl.balding_nichols_model` is not useful when demonstrating the annotation database or third-party genetic annotations. We want to enhance `hl.balding_nichols_model` to select variants (loci-allele-array pairs) that are likely to appear in real genetic datasets. One very simple model would be to draw variants according to their alternate/minor allele frequency in the gnomAD or 1000 Genomes datasets. An additional improvement would be to generate chromosomes roughly proportionally to their true sizes. These changes should not significantly slow down the method. We may want to include a small dataset of allele frequencies with Hail for use when the requested number of variants is small, only loading the full gnomAD or 1000 Genomes allele frequencies when the requested number of variants is in the millions or tens of millions. This functionality should be enabled and disabled by a parameter to `hl.balding_nichols_model`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6880:1606,down,down,1606,https://hail.is,https://github.com/hail-is/hail/issues/6880,1,['down'],['down']
Availability,"`hl.eval_expr(hl.literal([1,2,3])/hl.literal([1,2]))`. ```; FatalError: HailException: array index out of bounds: 2 / 2. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 36.0 failed 20 times, most recent failure: Lost task 0.19 in stage 36.0 (TID 55, exomes-w-1.c.broad-mpg-gnomad.internal, executor 3): is.hail.utils.HailException: array index out of bounds: 2 / 2; 	at is.hail.codegen.generated.C166.apply(Unknown Source); 	at is.hail.codegen.generated.C166.apply(Unknown Source); 	at is.hail.expr.TableMapRows$$anonfun$55$$anonfun$apply$29.apply(Relational.scala:1877); 	at is.hail.expr.TableMapRows$$anonfun$55$$anonfun$apply$29.apply(Relational.scala:1872); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at scala.collection.Iterator$class.foreach(Iterator.scala:893); 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); 	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59); 	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104); 	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48); 	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310); 	at scala.collection.AbstractIterator.to(Iterator.scala:1336); 	at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302); 	at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1336); 	at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289); 	at scala.collection.AbstractIte",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3653:198,failure,failure,198,https://hail.is,https://github.com/hail-is/hail/issues/3653,2,['failure'],['failure']
Availability,`hl.eval_expr(ht.globals)` errors when globals is empty,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3728:27,error,errors,27,https://hail.is,https://github.com/hail-is/hail/issues/3728,1,['error'],['errors']
Availability,"`hl.literal(float('nan')).value` works as expected, the trouble arised when parsing non-numeric values inside an array, e.g. `[float('nan'), float('inf'), float('-inf')]`. ```; Error summary: JsonParseException: Non-standard token 'NaN': enable JsonParser.Feature.ALLOW_NON_NUMERIC_NUMBERS to allow; at [Source: {""__uid_3"": [NaN, Infinity, -Infinity]}; line: 1, column: 17]; ```. I'm not sure how to enable this feature:; https://github.com/FasterXML/jackson-core/wiki/JsonParser-Features. ### Hail version:; master; c908fd74abd819f4fcfbcdad88c5db6bf77083b2. ### What you did:. `hl.literal([float('nan')]).value`. ### What went wrong (all error messages here, including the full java stack trace):. hl.literal([float('nan'), float('inf'), float('-inf')]).value; ---------------------------------------------------------------------------; FatalError Traceback (most recent call last); <ipython-input-3-ea2ec4f5df06> in <module>(); ----> 1 hl.literal([float('nan'), float('inf'), float('-inf')]).value. ~/hail/python/hail/expr/expressions/base_expression.py in value(self); 773 ; 774 """"""; --> 775 return hl.eval_expr(self); 776 ; 777 . ~/hail/python/hail/typecheck/check.py in wrapper(*args, **kwargs); 545 def wrapper(*args, **kwargs):; 546 args_, kwargs_ = check_all(f, args, kwargs, checkers, is_method=is_method); --> 547 return f(*args_, **kwargs_); 548 ; 549 update_wrapper(wrapper, f). ~/hail/python/hail/expr/expressions/expression_utils.py in eval_expr(expression); 135 Result of evaluating `expression`.; 136 """"""; --> 137 return eval_expr_typed(expression)[0]; 138 ; 139 . ~/hail/python/hail/typecheck/check.py in wrapper(*args, **kwargs); 545 def wrapper(*args, **kwargs):; 546 args_, kwargs_ = check_all(f, args, kwargs, checkers, is_method=is_method); --> 547 return f(*args_, **kwargs_); 548 ; 549 update_wrapper(wrapper, f). ~/hail/python/hail/expr/expressions/expression_utils.py in eval_expr_typed(expression); 169 analyze('eval_expr_typed', expression, Indices(expression._indices.sou",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3785:177,Error,Error,177,https://hail.is,https://github.com/hail-is/hail/issues/3785,2,"['Error', 'error']","['Error', 'error']"
Availability,"`ht = ht.join(possible_ht, 'outer')`; gave:; ```; Java stack trace:; java.lang.IllegalArgumentException: requirement failed; at scala.Predef$.require(Predef.scala:212); at is.hail.rvd.OrderedRVD.<init>(OrderedRVD.scala:37); at is.hail.rvd.KeyedOrderedRVD.orderedJoin(KeyedOrderedRVD.scala:38); at is.hail.rvd.OrderedRVD.orderedJoin(OrderedRVD.scala:283); at is.hail.expr.ir.TableJoin.execute(TableIR.scala:436); at is.hail.expr.ir.TableMapGlobals.execute(TableIR.scala:652); at is.hail.expr.ir.TableMapRows.execute(TableIR.scala:495); at is.hail.expr.ir.TableMapGlobals.execute(TableIR.scala:652); at is.hail.expr.ir.TableMapGlobals.execute(TableIR.scala:652); at is.hail.expr.ir.TableMapRows.execute(TableIR.scala:495); at is.hail.expr.ir.TableMapGlobals.execute(TableIR.scala:652); at is.hail.expr.ir.Interpret$.apply(Interpret.scala:591); at is.hail.expr.ir.Interpret$.apply(Interpret.scala:49); at is.hail.expr.ir.Interpret$.apply(Interpret.scala:24); at is.hail.table.Table.write(Table.scala:606); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); at py4j.Gateway.invoke(Gateway.java:280); at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); at py4j.commands.CallCommand.execute(CallCommand.java:79); at py4j.GatewayConnection.run(GatewayConnection.java:214); at java.lang.Thread.run(Thread.java:748). Hail version: devel-02b7ad0299d7; Error summary: IllegalArgumentException: requirement failed; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4216:1737,Error,Error,1737,https://hail.is,https://github.com/hail-is/hail/issues/4216,1,['Error'],['Error']
Availability,"`import_bgen` fails because there are no reference genomes on worker nodes. `import_bgen` needs to read the index file. Reading the index file means parsing a type. Parsing a locus type means looking up a reference genome. The error message comes from line 588 in `ReferenceGenome.scala` by way of line 70 of `IndexReader.scala`:; ```scala; val keyType = IRParser.parseType(metadata.keyType); ```. The root cause seems to be #5512, in which we [stop loading the genomes from resources](https://github.com/hail-is/hail/pull/5512/files#diff-16c24a9c4265932816e9e88806f5a2abL527).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5673:227,error,error,227,https://hail.is,https://github.com/hail-is/hail/issues/5673,1,['error'],['error']
Availability,`max-idle` and `max-age` have been available since 258 https://cloud.google.com/sdk/docs/release-notes#25800_2019-08-13; We already require >=285 https://github.com/hail-is/hail/blob/main/hail/python/hailtop/hailctl/dataproc/cli.py#L16,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10362:35,avail,available,35,https://hail.is,https://github.com/hail-is/hail/pull/10362,1,['avail'],['available']
Availability,"`monitor_billing_updates` occasionally fails due to deadlocks on this query, but as it's read-only it should be fine to retry. Changing to `select_and_fetchall` uses read-only transactions and retries those transient errors.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14337:217,error,errors,217,https://hail.is,https://github.com/hail-is/hail/pull/14337,1,['error'],['errors']
Availability,`oldwarn` is somehow `None` which spams us with instance log errors. We can revisit the warning level in a PR if this is really important. https://cloudlogging.app.goo.gl/VmUohrJSNo6EjsK56,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14243:61,error,errors,61,https://hail.is,https://github.com/hail-is/hail/pull/14243,1,['error'],['errors']
Availability,`orjson` 3.9.15 fixed the rare segfault that we saw in `3.9.11`. Besides just updating to latest patch and minor versions:. - Removed a redundant requirement of `orjson` in `gear/requirements.txt` -- it inherits `orjson` from hailtop; - Bokeh `3.4` made a breaking change w.r.t. the `circle` method on figures. I have restricted the bounds for `bokeh` to avoid this breaking change but will follow up with a PR that changes our usage of bokeh to follow the deprecation/upgrade advice and undo the bounds restriction,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14471:136,redundant,redundant,136,https://hail.is,https://github.com/hail-is/hail/pull/14471,1,['redundant'],['redundant']
Availability,"`pheno_file = p.read_input_group(**{'gz': pheno_path})` works if `pheno_path` is a string. But if it's a ResourceFile object (don't ask how I arrived at that), the pipeline still submits, but the localizing files step fails without obvious error (localizes the other files and then dies silently).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6979:240,error,error,240,https://hail.is,https://github.com/hail-is/hail/issues/6979,1,['error'],['error']
Availability,`request_retry_transient_errors` is a charlatan. It does not retry errors that occur in reading the response body. I eliminated it in favor of the tried and true `retry_transient_errors` and some new helper methods that initiate the request *and* read the response.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13029:67,error,errors,67,https://hail.is,https://github.com/hail-is/hail/pull/13029,1,['error'],['errors']
Availability,"`self._run_fut` will blow up with a `ContainerDeletedError` when the container is forcibly stopped in `Container.kill`. The task running `Container.kill` wants to block on the deletion and cleanup of the container, hence the `await self._run_fut`, but it shouldn't itself be interrupted by the container deletion error. This fixes a bug where if a JVM job wanted to delete the JVM a job was running in for X reason, it wouldn't get passed `jvm.kill` and the user would see a Job deleted error stacktrace instead of useful diagnostic information.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11848:313,error,error,313,https://hail.is,https://github.com/hail-is/hail/pull/11848,2,['error'],['error']
Availability,"`test_weighted_linear_regression`?. ### Version. 0.2.131-37a5ba226bae. ### Relevant log output. ```shell; ----> 1 gwas_weights = hl._linear_regression_rows_nd(y=mt.y,; 2 x=mt.GT.n_alt_alleles(),; 3 covariates=[1.0],; 4 weights=mt.weights). File <decorator-gen-1734>:2, in _linear_regression_rows_nd(y, x, covariates, block_size, weights, pass_through). File ~/hail/hail/python/hail/typecheck/check.py:585, in _make_dec.<locals>.wrapper(__original_func, *args, **kwargs); 582 @decorator; 583 def wrapper(__original_func: Callable[..., T], *args, **kwargs) -> T:; 584 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 585 return __original_func(*args_, **kwargs_). File ~/hail/hail/python/hail/methods/statgen.py:717, in _linear_regression_rows_nd(y, x, covariates, block_size, weights, pass_through); 714 res = res.select_globals(); 716 temp_file_name = hl.utils.new_temp_file(""_linear_regression_rows_nd"", ""result""); --> 717 res = res.checkpoint(temp_file_name); 719 return res. File <decorator-gen-1234>:2, in checkpoint(self, output, overwrite, stage_locally, _codec_spec, _read_if_exists, _intervals, _filter_intervals). File ~/hail/hail/python/hail/typecheck/check.py:585, in _make_dec.<locals>.wrapper(__original_func, *args, **kwargs); 582 @decorator; 583 def wrapper(__original_func: Callable[..., T], *args, **kwargs) -> T:; 584 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 585 return __original_func(*args_, **kwargs_). File ~/hail/hail/python/hail/table.py:1963, in Table.checkpoint(self, output, overwrite, stage_locally, _codec_spec, _read_if_exists, _intervals, _filter_intervals); 1960 hl.current_backend().validate_file(output); 1962 if not _read_if_exists or not hl.hadoop_exists(f'{output}/_SUCCESS'):; -> 1963 self.write(output=output, overwrite=overwrite, stage_locally=stage_locally, _codec_spec=_codec_spec); 1964 _assert_type = self._type; 1965 _load_refs = False. File <decorator-gen-1",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14594:1550,checkpoint,checkpoint,1550,https://hail.is,https://github.com/hail-is/hail/issues/14594,1,['checkpoint'],['checkpoint']
Availability,`to_json` was broken on `Failure` objects,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5229:25,Failure,Failure,25,https://hail.is,https://github.com/hail-is/hail/pull/5229,1,['Failure'],['Failure']
Availability,"`va` needs to be available inside the aggregator init operations, so needs to be bound outside the arrayagg.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5883:17,avail,available,17,https://hail.is,https://github.com/hail-is/hail/pull/5883,1,['avail'],['available']
Availability,a few errors,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7858:6,error,errors,6,https://hail.is,https://github.com/hail-is/hail/pull/7858,1,['error'],['errors']
Availability,"a few things happening here, most of which was me trying to not have to explicitly list dependencies in the shadowJar/shadowTestJar tasks:; - upgraded gradle to 5.0 and some plugins to be compatible; - split compile dependencies into ""bundled"" and ""unbundled"" to more explicitly separate the things we want in the jars and dependencies that we don't want bundled/are currently depending on the spark installation for. I did it this way because the shadowJar `exclude` filter does not let you exclude transitive dependencies, and I just wanted to exclude the entire spark/scala dependency tree.; - there was a problem where trying to run the tests kept giving me the ""Could not find or load main class org.testng.TestNG"" error, despite the class clearly being findable from the classpath I was providing. I added some excludes per this:; https://stackoverflow.com/questions/51455197/gradle-fatjar-could-not-find-or-load-main-class; (although I believe this is no longer strictly necessary after excluding all the transitive spark dependencies)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6248:720,error,error,720,https://hail.is,https://github.com/hail-is/hail/pull/6248,1,['error'],['error']
Availability,"a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/92784"">kubernetes/kubernetes#92784</a>, <a href=""https://github.com/pohly""><code>@pohly</code></a>) [SIG API Machinery, Apps, Auth, CLI, Instrumentation, Node, Scheduling, Storage and Testing]</li>; <li>Go1.14.4 is now the minimum version required for building Kubernetes (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/92438"">kubernetes/kubernetes#92438</a>, <a href=""https://github.com/liggitt""><code>@liggitt</code></a>) [SIG API Machinery, Auth, CLI, Cloud Provider, Cluster Lifecycle, Instrumentation, Network, Node, Release, Storage and Testing]</li>; <li>Hide managedFields from kubectl edit command (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/91946"">kubernetes/kubernetes#91946</a>, <a href=""https://github.com/soltysh""><code>@soltysh</code></a>) [SIG CLI]</li>; <li>K8s.io/apimachinery - scheme.Convert() now uses only explicitly registered conversions - default reflection based conversion is no longer available. <code>+k8s:conversion-gen</code> tags can be used with the <code>k8s.io/code-generator</code> component to generate conversions. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/90018"">kubernetes/kubernetes#90018</a>, <a href=""https://github.com/wojtek-t""><code>@wojtek-t</code></a>) [SIG API Machinery, Apps and Testing]</li>; <li>Kube-proxy: add <code>--bind-address-hard-fail</code> flag to treat failure to bind to a port as fatal (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/89350"">kubernetes/kubernetes#89350</a>, <a href=""https://github.com/SataQiu""><code>@SataQiu</code></a>) [SIG Cluster Lifecycle and Network]</li>; <li>Kubebuilder validation tags are set on metav1.Condition for CRD generation (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/92660"">kubernetes/kubernetes#92660</a>, <a href=""https://github.com/damemi""><code>@damemi</code></",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11462:8796,avail,available,8796,https://hail.is,https://github.com/hail-is/hail/pull/11462,1,['avail'],['available']
Availability,"a14a00fed93dc55a5e01e4eba0e3d77b0a89fc""><code>5da14a0</code></a> Add benchmark for loading empty objects</li>; <li><a href=""https://github.com/ijl/orjson/commit/12b867c7bfbd9c6404b2f2e859c134822af05e73""><code>12b867c</code></a> cargo update, nightly-2022-02-13</li>; <li><a href=""https://github.com/ijl/orjson/commit/ab633b6d0fa064b0c4b248bee8dc1062f0fe9d32""><code>ab633b6</code></a> Build x86_64 musllinux wheels (<a href=""https://github-redirect.dependabot.com/ijl/orjson/issues/242"">#242</a>)</li>; <li><a href=""https://github.com/ijl/orjson/commit/8bf078b27e7479f2cfbea1bac7155d4449ce7e30""><code>8bf078b</code></a> Cross compile wheels for armv7l on GitHub Actions (<a href=""https://github-redirect.dependabot.com/ijl/orjson/issues/241"">#241</a>)</li>; <li><a href=""https://github.com/ijl/orjson/commit/c196f0e55bd51d3693d381ccc06f2fd4b5443d86""><code>c196f0e</code></a> 3.6.6</li>; <li><a href=""https://github.com/ijl/orjson/commit/81890b097f7a479d1c1e697d21467952e0be24a9""><code>81890b0</code></a> Fix 53-bit error on value between isize and usize</li>; <li><a href=""https://github.com/ijl/orjson/commit/8fc1e8989d6a72581aa71533384cb1ef9a260ebc""><code>8fc1e89</code></a> Fast conditional for zoneinfo.ZoneInfo</li>; <li><a href=""https://github.com/ijl/orjson/commit/853ffbdf8dc5f34792765c22aa835e1b67d90a76""><code>853ffbd</code></a> fix(errors): adjust column offset if not at char boundary</li>; <li>Additional commits viewable in <a href=""https://github.com/ijl/orjson/compare/3.6.4...3.6.7"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=orjson&package-manager=pip&previous-version=3.6.4&new-version=3.6.7)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11572:3786,error,error,3786,https://hail.is,https://github.com/hail-is/hail/pull/11572,1,['error'],['error']
Availability,"a2:. https://github.com/holoviz/panel/issues/3260. This may be transient and may be solved by bokeh / jinja2 folks but thought I'd let you know in case you hit this issue. ```; ../conda/envs/glow/lib/python3.7/site-packages/bokeh/core/templates.py:43: in <module>; from jinja2 import Environment, Markup, FileSystemLoader; E ImportError: cannot import name 'Markup' from 'jinja2' (/home/circleci/conda/envs/lib/python3.7/site-packages/jinja2/__init__.py); [error] java.lang.IllegalArgumentException: requirement failed: Python tests in Hail environment failed; [error] 	at scala.Predef$.require(Predef.scala:281); [error] 	at $1fb87e3247134917ca70$.$anonfun$pythonSettings$14(build.sbt:288); [error] 	at $1fb87e3247134917ca70$.$anonfun$pythonSettings$14$adapted(build.sbt:278); [error] 	at scala.Function1.$anonfun$compose$1(Function1.scala:49); [error] 	at sbt.internal.util.$tilde$greater.$anonfun$$u2219$1(TypeFunctions.scala:62); [error] 	at sbt.std.Transform$$anon$4.work(Transform.scala:67); [error] 	at sbt.Execute.$anonfun$submit$2(Execute.scala:280); [error] 	at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:19); [error] 	at sbt.Execute.work(Execute.scala:289); [error] 	at sbt.Execute.$anonfun$submit$1(Execute.scala:280); [error] 	at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178); [error] 	at sbt.CompletionService$$anon$2.call(CompletionService.scala:37); [error] 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); [error] 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); [error] 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); [error] 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); [error] 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); [error] 	at java.lang.Thread.run(Thread.java:748); [error] (hail / hailtest) java.lang.IllegalArgumentException: requirement failed: Python tests in Hail en",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/11705:1350,error,error,1350,https://hail.is,https://github.com/hail-is/hail/issues/11705,1,['error'],['error']
Availability,"a931de0"",""dependencies"":[{""name"":""certifi"",""from"":""2021.10.8"",""to"":""2023.7.22""},{""name"":""cryptography"",""from"":""3.3.2"",""to"":""42.0.2""},{""name"":""requests"",""from"":""2.27.1"",""to"":""2.31.0""}],""packageManager"":""pip"",""projectPublicId"":""c1c98f6a-57c6-4ecc-a329-3b744cab74bd"",""projectUrl"":""https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-CERTIFI-3164749"",""SNYK-PYTHON-CERTIFI-5805047"",""SNYK-PYTHON-CRYPTOGRAPHY-3172287"",""SNYK-PYTHON-CRYPTOGRAPHY-3314966"",""SNYK-PYTHON-CRYPTOGRAPHY-3315324"",""SNYK-PYTHON-CRYPTOGRAPHY-3315328"",""SNYK-PYTHON-CRYPTOGRAPHY-3315331"",""SNYK-PYTHON-CRYPTOGRAPHY-3315452"",""SNYK-PYTHON-CRYPTOGRAPHY-3315972"",""SNYK-PYTHON-CRYPTOGRAPHY-3315975"",""SNYK-PYTHON-CRYPTOGRAPHY-3316038"",""SNYK-PYTHON-CRYPTOGRAPHY-3316211"",""SNYK-PYTHON-CRYPTOGRAPHY-5663682"",""SNYK-PYTHON-CRYPTOGRAPHY-5777683"",""SNYK-PYTHON-CRYPTOGRAPHY-5813745"",""SNYK-PYTHON-CRYPTOGRAPHY-5813746"",""SNYK-PYTHON-CRYPTOGRAPHY-5813750"",""SNYK-PYTHON-CRYPTOGRAPHY-5914629"",""SNYK-PYTHON-CRYPTOGRAPHY-6036192"",""SNYK-PYTHON-CRYPTOGRAPHY-6050294"",""SNYK-PYTHON-CRYPTOGRAPHY-6092044"",""SNYK-PYTHON-CRYPTOGRAPHY-6126975"",""SNYK-PYTHON-CRYPTOGRAPHY-6210214"",""SNYK-PYTHON-REQUESTS-5595532""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""pr-warning-shown"",""priorityScore""],""priorityScoreList"":[554,704,509,454,616,584,479,509,509,509,509,589,509,691,399,479,399,539,479,479,616,616,489,519],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**.  [Use After Free](https://learn.snyk.io/lesson/use-after-free/?loc&#x3D;fix-pr);  [Access of Resource Using Incompatible Type (&#x27;Type Confusion&#x27;)](https://learn.snyk.io/lesson/type-confusion/?loc&#x3D;fix-pr);  [Denial of Service (DoS)](https://learn.snyk.io/lesson/redos/?loc&#x3D;fix-pr);  [More lessons are available in Snyk Learn](https://learn.snyk.io/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14329:13446,avail,available,13446,https://hail.is,https://github.com/hail-is/hail/pull/14329,1,['avail'],['available']
Availability,a:1147); at is.hail.expr.ir.MatrixMapGlobals.execute(MatrixIR.scala:1634); at is.hail.expr.ir.MatrixMapGlobals.execute(MatrixIR.scala:1634); at is.hail.expr.ir.MatrixMapCols.execute(MatrixIR.scala:1364); at is.hail.expr.ir.MatrixMapGlobals.execute(MatrixIR.scala:1634); at is.hail.expr.ir.MatrixMapGlobals.execute(MatrixIR.scala:1634); at is.hail.expr.ir.MatrixMapCols.execute(MatrixIR.scala:1364); at is.hail.expr.ir.MatrixMapGlobals.execute(MatrixIR.scala:1634); at is.hail.expr.ir.MatrixMapGlobals.execute(MatrixIR.scala:1634); at is.hail.expr.ir.MatrixAggregateColsByKey.execute(MatrixIR.scala:839); at is.hail.expr.ir.MatrixMapGlobals.execute(MatrixIR.scala:1634); at is.hail.expr.ir.MatrixMapGlobals.execute(MatrixIR.scala:1634); at is.hail.expr.ir.MatrixMapRows.execute(MatrixIR.scala:1147); at is.hail.expr.ir.MatrixMapGlobals.execute(MatrixIR.scala:1634); at is.hail.expr.ir.MatrixRowsTable.execute(TableIR.scala:763); at is.hail.expr.ir.Interpret$.apply(Interpret.scala:603); at is.hail.expr.ir.Interpret$.apply(Interpret.scala:48); at is.hail.expr.ir.Interpret$.apply(Interpret.scala:23); at is.hail.table.Table.write(Table.scala:604); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); at py4j.Gateway.invoke(Gateway.java:280); at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); at py4j.commands.CallCommand.execute(CallCommand.java:79); at py4j.GatewayConnection.run(GatewayConnection.java:214); at java.lang.Thread.run(Thread.java:748). Hail version: devel-cb98819b64ad; Error summary: AssertionError: assertion failed: type mismatch:; name: global; actual: +Struct{}; expect: Struct{}; ```,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4127:3899,Error,Error,3899,https://hail.is,https://github.com/hail-is/hail/issues/4127,1,['Error'],['Error']
Availability,"a:2069); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:108); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); at java.lang.Thread.run(Thread.java:748); Hail version: devel-824968e; Error summary: AssertionError: assertion failed; ```; import_vcf error:; Just stayed at 0 out of 1 complete on the cloud, looked into the processes, it had failed 9 times, and here's the message I could dig out:; ```; is.hail.utils.HailException: hapmap_3.3_hg19_pop_stratified_af.vcf.gz: caught java.lang.NegativeArraySizeException: null; offending line: chr7 71494997 rs844684 A C . PASS AC=1191;AF=0.42627;ALL={A*...; at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:17); at is.hail.utils.package$.fatal(package.scala:26); at is.hail.utils.Context.wrapException(Context.scala:23); at is.hail.io.vcf.LoadVCF$$anonfun$parseLines$1$$anon$1.hasNext(LoadVCF.scala:767); at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); at is.hail.rvd.OrderedRVD$$anonfun$apply$16$$anon$3.hasNext(OrderedRVD.scala:911); at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); at scala.collection.Iterator$class.foreach(Iterator.scala:893); at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); at is.hail.io.RichContextRDDRegionValue$$anonfun$6$$anonfun$apply$1$$anonfun$apply$2$$anonfun$apply$3$$anonfun$apply$4.apply(RowStore.scala:922); at is.hail.io.RichContextRDDRegionValue$$anonfun$6$$anonfun$apply$1$$anonfun$apply$2$$anonfun$apply$3$$anonfun$apply$4.apply(RowStore.scala:915); at is.hail.utils.package$.using(package.scala:577); at is.hail.io.RichContextRD",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3507:11977,Error,ErrorHandling,11977,https://hail.is,https://github.com/hail-is/hail/issues/3507,1,['Error'],['ErrorHandling']
Availability,"a> chore(main): release 2.17.1 (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1854"">#1854</a>)</li>; <li><a href=""https://github.com/googleapis/java-storage/commit/1425dd97cb7d4a58f0bbededeca543f1a89c7d5d""><code>1425dd9</code></a> fix: update BaseStorageReadChannel to be left open unless explicitly closed (...</li>; <li><a href=""https://github.com/googleapis/java-storage/commit/4491f73e1fe4baed1ace132cba9f8cc1557ffa33""><code>4491f73</code></a> chore(main): release 2.17.1-SNAPSHOT (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1849"">#1849</a>)</li>; <li><a href=""https://github.com/googleapis/java-storage/commit/fb3ae9c172f6176a52815cc7ffc09175f23d0df8""><code>fb3ae9c</code></a> chore(main): release 2.17.0 (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1804"">#1804</a>)</li>; <li><a href=""https://github.com/googleapis/java-storage/commit/3ab745207badbd4971f2fb62ed92e1703625214a""><code>3ab7452</code></a> chore(test): increase debug logging for failure cases in GapicUnbufferedWrita...</li>; <li><a href=""https://github.com/googleapis/java-storage/commit/c8bf3c70cca81ed87a52939fe7da58889c8f55ce""><code>c8bf3c7</code></a> fix: update GrpcStorageImpl#update to support fine-grained update of BucketIn...</li>; <li><a href=""https://github.com/googleapis/java-storage/commit/3345ac9eec286ee3108c08bdbe263eba59085ad3""><code>3345ac9</code></a> test: add test to verify <code>lifecycle.rule.condition.age_days = 0</code> (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1846"">#1846</a>)</li>; <li><a href=""https://github.com/googleapis/java-storage/commit/45dc983a4af8e7feb937263ce611bd34eda37e03""><code>45dc983</code></a> feat: update GrpcBlobReadChannel to allow seek/limit after read (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1834"">#1834</a>)</li>; <li><a href=""https://github.com/googleapis/java-storage/commit/b8f43169a504080",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12598:14715,failure,failure,14715,https://hail.is,https://github.com/hail-is/hail/pull/12598,1,['failure'],['failure']
Availability,"a>; thread_pool, lambda: fun(*args, **kwargs)); OSError: [Errno 39] Directory not empty: '/tmp/JnQ2m'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/usr/local/lib/python3.9/dist-packages/hailtop/aiotools/local_fs.py"", line 409, in rmtree; await rm_dir(pool, contents_tasks_by_dir.get(path, []), path); File ""/usr/local/lib/python3.9/dist-packages/hailtop/aiotools/local_fs.py"", line 387, in rm_dir; excs = [exc; File ""/usr/local/lib/python3.9/dist-packages/hailtop/aiotools/local_fs.py"", line 389, in <listcomp>; for exc in [t.exception()]; File ""/usr/lib/python3.9/asyncio/futures.py"", line 214, in exception; raise exc; asyncio.exceptions.CancelledError. [2023-08-02 05:33:14] test/hail/utils/test_hl_hadoop_and_hail_fs.py::test_hadoop_methods_3[local] ERROR; [2023-08-02 05:43:14] test/hail/utils/test_hl_hadoop_and_hail_fs.py::test_read_overwrite[remote] SKIPPED; ```; ```; ==================================== ERRORS ====================================; ______________ ERROR at teardown of test_hadoop_methods_3[local] _______________. pool = <hailtop.utils.utils.OnlineBoundedGather2 object at 0x7f263d7a6fa0>; contents_tasks = [<Task finished name='Task-63869' coro=<OnlineBoundedGather2.call.<locals>.run_and_cleanup() done, defined at /usr/loc...2.call.<locals>.run_and_cleanup() done, defined at /usr/local/lib/python3.9/dist-packages/hailtop/utils/utils.py:398>>]; path = '/tmp/JnQ2m'. async def rm_dir(pool: OnlineBoundedGather2,; contents_tasks: List[asyncio.Task],; path: str):; assert listener is not None; listener(1); if contents_tasks:; await pool.wait(contents_tasks); try:; > await self.rmdir(path). /usr/local/lib/python3.9/dist-packages/hailtop/aiotools/local_fs.py:378: ; _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ; /usr/local/lib/python3.9/dist-packages/hailtop/aiotools/local_fs.py:352: in rmdir; return await blocking_to_async(self._thread_pool, os.rmdir, path); /usr/l",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13361:4710,ERROR,ERRORS,4710,https://hail.is,https://github.com/hail-is/hail/issues/13361,2,['ERROR'],"['ERROR', 'ERRORS']"
Availability,"a></li>; </ul>; <h3>Fixed</h3>; <ul>; <li>Some text goes missing during wrapping when it contains double width characters <a href=""https://redirect.github.com/Textualize/rich/issues/3176"">Textualize/rich#3176</a></li>; <li>Ensure font is correctly inherited in exported HTML <a href=""https://redirect.github.com/Textualize/rich/issues/3104"">Textualize/rich#3104</a></li>; <li>Fixed typing for <code>FloatPrompt</code>.</li>; </ul>; <h2>[13.6.0] - 2023-09-30</h2>; <h3>Added</h3>; <ul>; <li>Added Python 3.12 to classifiers.</li>; </ul>; <h2>[13.5.3] - 2023-09-17</h2>; <h3>Fixed</h3>; <ul>; <li>Markdown table rendering issue with inline styles and links <a href=""https://redirect.github.com/Textualize/rich/issues/3115"">Textualize/rich#3115</a></li>; <li>Fix Markdown code blocks on a light background <a href=""https://redirect.github.com/Textualize/rich/issues/3123"">Textualize/rich#3123</a></li>; </ul>; <h2>[13.5.2] - 2023-08-01</h2>; <h3>Fixed</h3>; <ul>; <li>Fixed Text.expand_tabs assertion error</li>; </ul>; <h2>[13.5.1] - 2023-07-31</h2>; <h3>Fixed</h3>; <ul>; <li>Fix tilde character (<code>~</code>) not included in link regex when printing to console <a href=""https://redirect.github.com/Textualize/rich/issues/3057"">Textualize/rich#3057</a></li>; </ul>; <h2>[13.5.0] - 2023-07-29</h2>; <h3>Fixed</h3>; <ul>; <li>Fixed Text.expand_tabs not expanding spans.</li>; <li>Fixed TimeElapsedColumn from showing negative.</li>; <li>Fix for escaping strings with a trailing backslash <a href=""https://redirect.github.com/Textualize/rich/issues/2987"">Textualize/rich#2987</a></li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/Textualize/rich/commit/7f580bdcf07a3b269a0e786b6a3aa9c804f393cf""><code>7f580bd</code></a> Merge pull request <a href=""https://redirect.github.com/Textualize/rich/issues/3293"">#3293</a> from Textualize/bump1371</li>; <li><a href=""https://github.com/Textua",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14376:3597,error,error,3597,https://hail.is,https://github.com/hail-is/hail/pull/14376,2,['error'],['error']
Availability,"a></li>; </ul>; <h3>Fixed</h3>; <ul>; <li>Some text goes missing during wrapping when it contains double width characters <a href=""https://redirect.github.com/Textualize/rich/issues/3176"">Textualize/rich#3176</a></li>; <li>Ensure font is correctly inherited in exported HTML <a href=""https://redirect.github.com/Textualize/rich/issues/3104"">Textualize/rich#3104</a></li>; <li>Fixed typing for <code>FloatPrompt</code>.</li>; </ul>; <h2>[13.6.0] - 2023-09-30</h2>; <h3>Added</h3>; <ul>; <li>Added Python 3.12 to classifiers.</li>; </ul>; <h2>[13.5.3] - 2023-09-17</h2>; <h3>Fixed</h3>; <ul>; <li>Markdown table rendering issue with inline styles and links <a href=""https://redirect.github.com/Textualize/rich/issues/3115"">Textualize/rich#3115</a></li>; <li>Fix Markdown code blocks on a light background <a href=""https://redirect.github.com/Textualize/rich/issues/3123"">Textualize/rich#3123</a></li>; </ul>; <h2>[13.5.2] - 2023-08-01</h2>; <h3>Fixed</h3>; <ul>; <li>Fixed Text.expand_tabs assertion error</li>; </ul>; <h2>[13.5.1] - 2023-07-31</h2>; <h3>Fixed</h3>; <ul>; <li>Fix tilde character (<code>~</code>) not included in link regex when printing to console <a href=""https://redirect.github.com/Textualize/rich/issues/3057"">Textualize/rich#3057</a></li>; </ul>; <h2>[13.5.0] - 2023-07-29</h2>; <h3>Fixed</h3>; <ul>; <li>Fixed Text.expand_tabs not expanding spans.</li>; <li>Fixed TimeElapsedColumn from showing negative.</li>; <li>Fix for escaping strings with a trailing backslash <a href=""https://redirect.github.com/Textualize/rich/issues/2987"">Textualize/rich#2987</a></li>; <li>Fixed exception in Markdown with partial table <a href=""https://redirect.github.com/Textualize/rich/issues/3053"">Textualize/rich#3053</a></li>; <li>Fixed the HTML export template so that the <code>&lt;html&gt;</code> tag comes before the <code>&lt;head&gt;</code> tag <a href=""https://redirect.github.com/Textualize/rich/issues/3021"">Textualize/rich#3021</a></li>; <li>Fixed issue with custom classes overwriting",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14012:3624,error,error,3624,https://hail.is,https://github.com/hail-is/hail/pull/14012,2,['error'],['error']
Availability,"ability: float64, h2_liability_se: float64, h2_z: float64, h2_observed: float64, h2_observed_se: float64, intercept: float64, intercept_se: float64, ratio: float64, ratio_se: float64}, sldsc_25bin: struct{h2_liability: float64, h2_liability_se: float64, h2_z: float64, h2_observed: float64, h2_observed_se: float64, intercept: float64, intercept_se: float64, ratio: float64, ratio_se: float64}, rhemc_25bin: struct{h2_liability: float64, h2_liability_se: float64, h2_z: float64, h2_observed: float64, h2_observed_se: float64}, rhemc_8bin: struct{h2_liability: float64, h2_liability_se: float64, h2_observed: float64, h2_observed_se: float64, h2_z: float64}, rhemc_25bin_50rv: struct{h2_observed: float64, h2_observed_se: float64, h2_liability: float64, h2_liability_se: float64, h2_z: float64}, final: struct{h2_observed: float64, h2_observed_se: float64, h2_liability: float64, h2_liability_se: float64, h2_z: float64}}, qcflags: struct{GWAS_run: bool, defined_h2: bool, significant_z: bool, in_bounds_h2: bool, normal_lambda: bool, normal_ratio: bool, EUR_plus_1: bool, pass_all: bool}, N_ancestry_QC_pass: int32}, saige_version: str, inv_normalized: bool, pop: str, lambda_gc: float64, n_variants: int64, n_sig_variants: int64, saige_heritability: float64}))}; at is.hail.utils.ErrorHandling.fatal(ErrorHandling.scala:15); at is.hail.utils.ErrorHandling.fatal$(ErrorHandling.scala:15); at is.hail.utils.package$.fatal(package.scala:78); at is.hail.expr.ir.PruneDeadFields$.isSupertype(PruneDeadFields.scala:75); at is.hail.rvd.RVDCoercer.coerce(RVD.scala:31); at is.hail.rvd.RVD$.coerce(RVD.scala:1262); at is.hail.rvd.RVD.changeKey(RVD.scala:143); at is.hail.rvd.RVD.changeKey(RVD.scala:136); [...]; java.util.NoSuchElementException: key not found: 0; at scala.collection.immutable.Map$Map1.apply(Map.scala:114); at is.hail.expr.ir.PruneDeadFields$.$anonfun$isSupertype$2(PruneDeadFields.scala:62); at is.hail.expr.ir.PruneDeadFields$.$anonfun$isSupertype$2$adapted(PruneDeadFields.scala:61); ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/10858:3483,Error,ErrorHandling,3483,https://hail.is,https://github.com/hail-is/hail/issues/10858,4,['Error'],['ErrorHandling']
Availability,"abot.com/grpc/grpc/issues/30655"">#30655</a>)</li>; <li><a href=""https://github.com/grpc/grpc/commit/d0f491285f74f8b07dec7f1c745a6636f3a691de""><code>d0f4912</code></a> Bump version to 1.48.1-pre1 (on v1.48.x branch) (<a href=""https://github-redirect.dependabot.com/grpc/grpc/issues/30627"">#30627</a>)</li>; <li><a href=""https://github.com/grpc/grpc/commit/a8065cb662ca35f2b57efd636b1ac193d327ed74""><code>a8065cb</code></a> Backport EventEngine Forkables (<a href=""https://github-redirect.dependabot.com/grpc/grpc/issues/30605"">#30605</a>)</li>; <li><a href=""https://github.com/grpc/grpc/commit/796a8ddcfe629c1ef7beae117efce2004886ecd9""><code>796a8dd</code></a> xDS interop: add missing image tagging to the buildscripts (<a href=""https://github-redirect.dependabot.com/grpc/grpc/issues/30520"">#30520</a>) (<a href=""https://github-redirect.dependabot.com/grpc/grpc/issues/30529"">#30529</a>)</li>; <li><a href=""https://github.com/grpc/grpc/commit/0d20b3fac16f901bd19f116b71cfec538bb57160""><code>0d20b3f</code></a> subchannel list: fix ubsan error (<a href=""https://github-redirect.dependabot.com/grpc/grpc/issues/30393"">#30393</a>) (<a href=""https://github-redirect.dependabot.com/grpc/grpc/issues/30412"">#30412</a>)</li>; <li><a href=""https://github.com/grpc/grpc/commit/9479089ac8cb99e66a71eab687b06ce220a94838""><code>9479089</code></a> xds interop: choose correct cluster in grpc_xds_k8s_lb_python.sh (1.48.x back...</li>; <li><a href=""https://github.com/grpc/grpc/commit/d2054ec6c6e8abcecf0e24b0b4ee75035d80c3cc""><code>d2054ec</code></a> Bump version to 1.48.0 (on v1.48.x branch) (<a href=""https://github-redirect.dependabot.com/grpc/grpc/issues/30326"">#30326</a>)</li>; <li><a href=""https://github.com/grpc/grpc/commit/4c51abf12053e3c43a62059c693322ea992b35ce""><code>4c51abf</code></a> Bump version to 1.48.0-pre1 (on v1.48.x branch) (<a href=""https://github-redirect.dependabot.com/grpc/grpc/issues/30194"">#30194</a>)</li>; <li><a href=""https://github.com/grpc/grpc/commit/46bd0be2c99aa8228ec5d93d",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12201:4826,error,error,4826,https://hail.is,https://github.com/hail-is/hail/pull/12201,1,['error'],['error']
Availability,ach(IndexedSeqOptimized.scala:33); 	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35); 	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); 	at scala.collection.AbstractTraversable.map(Traversable.scala:104); 	at is.hail.expr.ir.RewriteBottomUp$.is$hail$expr$ir$RewriteBottomUp$$rewrite$1(RewriteBottomUp.scala:6); 	at is.hail.expr.ir.RewriteBottomUp$.apply(RewriteBottomUp.scala:25); 	at is.hail.expr.ir.ExtractIntervalFilters$.apply(ExtractIntervalFilters.scala:254); 	at is.hail.expr.ir.Optimize$.optimize(Optimize.scala:19); 	at is.hail.expr.ir.Optimize$.apply(Optimize.scala:49); 	at is.hail.expr.ir.CompileAndEvaluate$$anonfun$optimizeIR$1$1.apply(CompileAndEvaluate.scala:20); 	at is.hail.expr.ir.CompileAndEvaluate$$anonfun$optimizeIR$1$1.apply(CompileAndEvaluate.scala:20); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:20); 	at is.hail.expr.ir.CompileAndEvaluate$.optimizeIR$1(CompileAndEvaluate.scala:20); 	at is.hail.expr.ir.CompileAndEvaluate$.apply(CompileAndEvaluate.scala:24); 	at is.hail.backend.Backend.execute(Backend.scala:86); 	at is.hail.backend.Backend.executeJSON(Backend.scala:92); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:282); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:238); 	at java.lang.Thread.run(Thread.java:748). Hail version: 0.2.16-e95038bbed35; Error summary: MatchError: locus<GRCh37> (of class is.hail.expr.types.virtual.TLocus); ```,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6458:6757,Error,Error,6757,https://hail.is,https://github.com/hail-is/hail/issues/6458,1,['Error'],['Error']
Availability,"ache.spark.SparkException: Job aborted due to stage failure: Task 56 in stage 4.0 failed 20 times, most recent failure: Lost task 56.19 in stage 4.0 (TID 48622) (jsealock-schema-sw-43bq.c.daly-neale-sczmeta.internal executor 3): is.hail.utils.HailException: VEP command '/vep --format vcf --json --everything --allele_number --no_stats --cache --offline --minimal --assembly GRCh38 --fasta /opt/vep/.vep/homo_sapiens/95_GRCh38/Homo_sapiens.GRCh38.dna.toplevel.fa.gz --plugin LoF,loftee_path:/opt/vep/Plugins/,gerp_bigwig:/opt/vep/.vep/gerp_conservation_scores.homo_sapiens.GRCh38.bw,human_ancestor_fa:/opt/vep/.vep/human_ancestor.fa.gz,conservation_file:/opt/vep/.vep/loftee.sql --dir_plugins /opt/vep/Plugins/ -o STDOUT' failed with non-zero exit status 125; VEP Error output:; docker: Cannot connect to the Docker daemon at unix:///var/run/docker.sock. Is the docker daemon running?.; See 'docker run --help'. 	at is.hail.utils.ErrorHandling.fatal(ErrorHandling.scala:17); 	at is.hail.utils.ErrorHandling.fatal$(ErrorHandling.scala:17); 	at is.hail.utils.package$.fatal(package.scala:78); 	at is.hail.methods.VEP$.waitFor(VEP.scala:73); 	at is.hail.methods.VEP.$anonfun$execute$5(VEP.scala:231); 	at scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:490); 	at is.hail.utils.richUtils.RichContextRDD$$anon$1.hasNext(RichContextRDD.scala:69); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:490); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:490); 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:490); 	at scala.collection.Iterator.foreach(Iterator.scala:943); 	at scala.collection.Iterator.foreach$(Iterator.scala:943); 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431); 	at is.hail.io.RichContextRDDRegionValue$.writeRowsPar",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12936:1216,Error,ErrorHandling,1216,https://hail.is,https://github.com/hail-is/hail/issues/12936,1,['Error'],['ErrorHandling']
Availability,ache.spark.sql.execution.datasources.FileFormatWriter$.org$apache$spark$sql$execution$datasources$FileFormatWriter$$executeTask(FileFormatWriter.scala:204); at org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$write$1$$anonfun$3.apply(FileFormatWriter.scala:129); at org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$write$1$$anonfun$3.apply(FileFormatWriter.scala:128); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:99); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); at java.lang.Thread.run(Thread.java:748); Caused by: is.hail.utils.HailException: Hail only supports diploid genotypes. Found min ploidy equals `1' and max ploidy equals `2'.; at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:6); at is.hail.utils.package$.fatal(package.scala:27); at is.hail.io.bgen.BgenRecordV12.getValue(BgenRecord.scala:203); at is.hail.io.bgen.BgenLoader$$anonfun$10$$anonfun$apply$5.apply(BgenLoader.scala:76); at is.hail.io.bgen.BgenLoader$$anonfun$10$$anonfun$apply$5.apply(BgenLoader.scala:75); at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); at scala.collection.Iterator$$anon$1.next(Iterator.scala:1010); at is.hail.sparkextras.OrderedRDD$$anon$3.next(OrderedRDD.scala:241); at is.hail.sparkextras.OrderedRDD$$anon$3.next(OrderedRDD.scala:234); at is.hail.sparkextras.OrderedRDD$$anonfun$apply$8$$anon$2.next(OrderedRDD.scala:202); at is.hail.sparkextras.OrderedRDD$$anonfun$apply$8$$anon$2.next(OrderedRDD.scala:195); at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); at scala.collection.Iterator$$anon$11.next(Iterator.scal,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2407:5335,Error,ErrorHandling,5335,https://hail.is,https://github.com/hail-is/hail/issues/2407,1,['Error'],['ErrorHandling']
Availability,"action$$anonfun$extract$6.apply(Extraction.scala:392); 	at org.json4s.Extraction$.customOrElse(Extraction.scala:606); 	at org.json4s.Extraction$.extract(Extraction.scala:392); 	at org.json4s.Extraction$.extract(Extraction.scala:39); 	at org.json4s.ExtractableJsonAstNode.extract(ExtractableJsonAstNode.scala:21); 	at org.json4s.jackson.Serialization$.read(Serialization.scala:50); 	at org.json4s.Serialization$class.read(Serialization.scala:30); 	at org.json4s.jackson.Serialization$.read(Serialization.scala:17); 	at is.hail.expr.ir.IRParser$.matrix_ir_1(Parser.scala:1117); 	at is.hail.expr.ir.IRParser$.matrix_ir(Parser.scala:1053); 	at is.hail.expr.ir.IRParser$$anonfun$parse_matrix_ir$2.apply(Parser.scala:1269); 	at is.hail.expr.ir.IRParser$$anonfun$parse_matrix_ir$2.apply(Parser.scala:1269); 	at is.hail.expr.ir.IRParser$.parse(Parser.scala:1253); 	at is.hail.expr.ir.IRParser$.parse_matrix_ir(Parser.scala:1269); 	at is.hail.expr.ir.IRParser$.parse_matrix_ir(Parser.scala:1268); 	at is.hail.expr.ir.IRParser.parse_matrix_ir(Parser.scala); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:483); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:282); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:238); 	at java.lang.Thread.run(Thread.java:745). Hail version: 0.2.14-8dcb6722c72a; Error summary: MatchError: 17 (of class java.lang.Integer); ```. Any ideas on what is causing this? It seems like something in Spark itself, but I can't trace it down. I'm running Apache Spark version 2.4.1",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6299:18709,Error,Error,18709,https://hail.is,https://github.com/hail-is/hail/issues/6299,2,"['Error', 'down']","['Error', 'down']"
Availability,"ad-task/commit/0fdebf3c7ad43ed4739d0400c333a72b32f5d514""><code>0fdebf3</code></a> Improve verify example</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/019089b9554692674d6baee7df7d4d884f310cc9""><code>019089b</code></a> Correctly create list of output files</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/fa2739ded05333ba46d8f50bb3b2a3721cf0ca86""><code>fa2739d</code></a> Create target directories at a central place</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/02b8e1a79d9e00acd61f9ac42e5555619fe2247a""><code>02b8e1a</code></a> Prevent duplicate destination files</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/0b65ca2f17c8890a3ec34cf80cde52ee5413cbec""><code>0b65ca2</code></a> Call eachFile action only once per source</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/717877121299cea8f216d3a595eaa56731a6acd3""><code>7178771</code></a> Support changing a target file's relative path in an eachFile action</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/e5af1bd7f9daa8a9222aee0dd1b703727cb5e94e""><code>e5af1bd</code></a> Bump version number to 5.3.0-SNAPSHOT</li>; <li>Additional commits viewable in <a href=""https://github.com/michel-kraemer/gradle-download-task/compare/3.2.0...5.3.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=de.undercouch.download&package-manager=gradle&previous-version=3.2.0&new-version=5.3.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12345:4678,down,download-task,4678,https://hail.is,https://github.com/hail-is/hail/pull/12345,1,['down'],['download-task']
Availability,"ad_namespaced_pod_log_with_http_info; collection_formats=collection_formats); File ""/usr/local/lib/python3.6/dist-packages/kubernetes/client/api_client.py"", line 334, in call_api; _return_http_data_only, collection_formats, _preload_content, _request_timeout); File ""/usr/local/lib/python3.6/dist-packages/kubernetes/client/api_client.py"", line 168, in __call_api; _request_timeout=_request_timeout); File ""/usr/local/lib/python3.6/dist-packages/kubernetes/client/api_client.py"", line 355, in request; headers=headers); File ""/usr/local/lib/python3.6/dist-packages/kubernetes/client/rest.py"", line 231, in GET; query_params=query_params); File ""/usr/local/lib/python3.6/dist-packages/kubernetes/client/rest.py"", line 222, in request; raise ApiException(http_resp=r); {""levelname"": ""INFO"", ""asctime"": ""2019-07-02 13:36:45,525"", ""filename"": ""batch.py"", ""funcNameAndLine"": ""mark_complete:542"", ""message"": ""no logs for batch-278-job-6858-5879db due to previous error, rescheduling pod Error: (404)\nReason: Not Found\nHTTP response headers: HTTPHeaderDict({'Audit-Id': '891f2153-6a94-42ff-8fe1-edf644051234', 'Content-Type': 'application/json', 'Date': 'Tue, 02 Jul 2019 13:36:45 GMT', 'Content-Length': '218'})\nHTTP response body: {\""kind\"":\""Status\"",\""apiVersion\"":\""v1\"",\""metadata\"":{},\""status\"":\""Failure\"",\""message\"":\""pods \\\""batch-278-job-6858-5879db\\\"" not found\"",\""reason\"":\""NotFound\"",\""details\"":{\""name\"":\""batch-278-job-6858-5879db\"",\""kind\"":\""pods\""},\""code\"":404}\n\n""}; {""levelname"": ""INFO"", ""asctime"": ""2019-07-02 13:36:45,541"", ""filename"": ""batch.py"", ""funcNameAndLine"": ""set_state:457"", ""message"": ""job (278, 6858, 'main') changed state: Running -> Ready""}; ```. Here are events that don't contain the string ""Successfully assigned batch-pods"": [events.log](https://github.com/hail-is/hail/files/3350320/events.log). There's a lot of issue with secrets getting mounted and a couple container creation failures, but nothing that obviously suggests a problem with reading logs.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6545:2192,error,error,2192,https://hail.is,https://github.com/hail-is/hail/issues/6545,4,"['Error', 'Failure', 'error', 'failure']","['Error', 'Failure', 'error', 'failures']"
Availability,add triangle and downcode to docs,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3025:17,down,downcode,17,https://hail.is,https://github.com/hail-is/hail/pull/3025,1,['down'],['downcode']
Availability,add useful error messages,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/788:11,error,error,11,https://hail.is,https://github.com/hail-is/hail/pull/788,1,['error'],['error']
Availability,"added `curlylint` to lint jinja templates in `check` targets and fixed existing errors that it found. Also standardized on two-space indentation and a more consistent style of indenting jinja templates: everything inside an html div is indented two spaces, no exceptions.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10172:80,error,errors,80,https://hail.is,https://github.com/hail-is/hail/pull/10172,1,['error'],['errors']
Availability,added cmake download to python docs,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1241:12,down,download,12,https://hail.is,https://github.com/hail-is/hail/pull/1241,1,['down'],['download']
Availability,adding _read_if_exists to checkpoint,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5636:26,checkpoint,checkpoint,26,https://hail.is,https://github.com/hail-is/hail/pull/5636,1,['checkpoint'],['checkpoint']
Availability,"adings"", version='2.1', reference_genome='GRCh38'). File ~/.local/lib/python3.8/site-packages/hail/experimental/datasets.py:115, in load_dataset(name, version, reference_genome, region, cloud); 107 raise ValueError(f'Region {repr(region)} not available for dataset'; 108 f' {repr(name)} on cloud platform {repr(cloud)}.\n'; 109 f'Available regions: {regions}.'); 111 path = [dataset['url'][cloud][region]; 112 for dataset in datasets[name]['versions']; 113 if all([dataset['version'] == version,; 114 dataset['reference_genome'] == reference_genome])]; --> 115 assert len(path) == 1; 116 path = path[0]; 117 if path.startswith('s3://'):. AssertionError: ; ```. I'm a new Hail user and don't have the full context here, but it seems like there are at least three problems:. 1. An assert failed in production code, which indicates either the presence of a bug or an incorrect use of assert (e.g. using assert to check for value errors).; 2. The assert has no corresponding error message, so the user learns that something has gone wrong but can't easily tell what.; 3. The assert is bare. Bare asserts can get optimized out of code in ways that are difficult to foresee in advance, and are generally deprecated in favor of the `if error_condition: raise AssertionError(...)` pattern (see: https://discuss.python.org/t/stop-ignoring-asserts-when-running-in-optimized-mode/13132). **The Big Picture**. The bare assert pattern is used over 3k times in Hail. To be fair, many of these usages occur in test directories, where they're fine. But they also occur in application code, and often in the dangerous form `assert(expr1, expr2)` which will never fail (because a tuple with two falsy elements is truthy in python). These asserts are never actually getting checked. . Fixing all of them would be a heavy lift. One compromise solution might be to add a bare assert rule to the linter (e.g. https://pypi.org/project/flake8-assert-msg/). This would prevent the introduction of further bare asserts to the ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12952:1302,error,error,1302,https://hail.is,https://github.com/hail-is/hail/issues/12952,1,['error'],['error']
Availability,"adius': 1e7, 'overwrite': True }). with hl.TemporaryDirectory(ensure_exists=True) as tmp:; mt = hl.balding_nichols_model(3, 100, 100); bm_ldadj = hl.linalg.BlockMatrix.random(100, 100). starts_and_stops = hl.linalg.utils.locus_windows(mt.locus, radius=args.radius, _localize=False); bm_ldadj = bm_ldadj._sparsify_row_intervals_expr(starts_and_stops, blocks_only=False). # sparcify to a triangle matrix; bm_ldadj = bm_ldadj.sparsify_triangle(); bm_ldadj = bm_ldadj.checkpoint(f'{tmp}/ldadj', overwrite=args.overwrite, force_row_major=True). # This is required, as the squaring/multiplication densifies, so this re-sparsifies.; ht = hl.utils.genomic_range_table(100); n = 100. r2 = bm_ldadj ** 2; r2_adj = ((n - 1.0) / (n - 2.0)) * r2 - (1.0 / (n - 2.0)); starts_and_stops = hl.linalg.utils.locus_windows(ht.locus, args.radius, _localize=False); r2_adj = r2_adj._sparsify_row_intervals_expr(starts_and_stops, blocks_only=False); r2_adj = r2_adj.sparsify_triangle(); r2_adj = r2_adj.checkpoint(f'{tmp}/adj', overwrite=args.overwrite). if __name__ == '__main__':; main(); ```. ### Version. 0.2.128. ### Relevant log output. ```shell; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.2.128-17247d8990c6; LOGGING: writing to /home/edmund/.local/src/hail/hail-20240508-1553-0.2.128-17247d8990c6.log; Traceback (most recent call last):; File ""/home/edmund/.local/share/pyenv/versions/3.9.18/lib/python3.9/runpy.py"", line 197, in _run_module_as_main; return _run_code(code, main_globals, None,; File ""/home/edmund/.local/share/pyenv/versions/3.9.18/lib/python3.9/runpy.py"", line 87, in _run_code; exec(code, run_globals); File ""/home/edmund/.vscode/extensions/ms-python.debugpy-2024.6.0-linux-x64/bundled/libs/debugpy/adapter/../../debugpy/launcher/../../debugpy/__main__.py"", line 39, in <module>; cli.main(); File ""/home/edmund/.vscode/extensions/ms-python.debugpy-2024.6.0-linux-x64/bundled/libs/debugpy/adapter/../../debugpy/launcher/../../debugpy/../debugpy/server/cli",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14537:1169,checkpoint,checkpoint,1169,https://hail.is,https://github.com/hail-is/hail/issues/14537,1,['checkpoint'],['checkpoint']
Availability,"ages can be buffered in memory. The default is to write both to stdout without buffering, as before. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/104873"">kubernetes/kubernetes#104873</a>, <a href=""https://github.com/pohly""><code>@pohly</code></a>)</li>; <li>JobTrackingWithFinalizers graduates to beta. Feature is enabled by default. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/105687"">kubernetes/kubernetes#105687</a>, <a href=""https://github.com/alculquicondor""><code>@alculquicondor</code></a>)</li>; <li>Kube-apiserver: Fixes handling of CRD schemas containing literal null values in enums. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/104969"">kubernetes/kubernetes#104969</a>, <a href=""https://github.com/liggitt""><code>@liggitt</code></a>)</li>; <li>Kube-apiserver: The <code>rbac.authorization.k8s.io/v1alpha1</code> API version is removed; use the <code>rbac.authorization.k8s.io/v1</code> API, available since v1.8. The <code>scheduling.k8s.io/v1alpha1</code> API version is removed; use the <code>scheduling.k8s.io/v1</code> API, available since v1.14. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/104248"">kubernetes/kubernetes#104248</a>, <a href=""https://github.com/liggitt""><code>@liggitt</code></a>)</li>; <li>Kube-scheduler: support for configuration file version <code>v1beta1</code> is removed. Update configuration files to v1beta2(xref: <a href=""https://github-redirect.dependabot.com/kubernetes/enhancements/issues/2901"">kubernetes/enhancements#2901</a>) or v1beta3 before upgrading to 1.23. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/104782"">kubernetes/kubernetes#104782</a>, <a href=""https://github.com/kerthcet""><code>@kerthcet</code></a>)</li>; <li>KubeSchedulerConfiguration provides a new field <code>MultiPoint</code> which will register a plugin for all valid extension points (<a href=""https://github-redirect",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11957:8002,avail,available,8002,https://hail.is,https://github.com/hail-is/hail/pull/11957,1,['avail'],['available']
Availability,"ages/py4j/java_gateway.py in __call__(self, *args); 1255 answer = self.gateway_client.send_command(command); 1256 return_value = get_return_value(; -> 1257 answer, self.gateway_client, self.target_id, self.name); 1258 ; 1259 for temp_arg in temp_args:. /fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/hail/backend/py4j_backend.py in deco(*args, **kwargs); 14 import pyspark; 15 try:; ---> 16 return f(*args, **kwargs); 17 except py4j.protocol.Py4JJavaError as e:; 18 s = e.java_exception.toString(). /fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/protocol.py in get_return_value(answer, gateway_client, target_id, name); 334 raise Py4JError(; 335 ""An error occurred while calling {0}{1}{2}"".; --> 336 format(target_id, ""."", name)); 337 else:; 338 type = answer[1]. Py4JError: An error occurred while calling o1.pyPersistTable; --------------- end of error -------------------. The above is for running the GWAS tutorial. While running my own GWAS, I have encountered a similar error when running GWAS with the line :. gwas = hl.agg.linreg(hl.float(mt.phenos.height),; [1.0, mt.hapcounts0.x, mt.anc1dos.x, mt.anc2dos.x]). The error message is as follows:. -------------- start of error ------------------. ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:38197); Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 977, in _get_connection; connection = self.deque.pop(); IndexError: pop from an empty deque. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 1115, in start; self.socket.connect((self.address, self.port)); ConnectionRefusedError: [Errno 111] Connection refused; ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:38197); Traceback (m",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/9939:7836,error,error,7836,https://hail.is,https://github.com/hail-is/hail/issues/9939,1,['error'],['error']
Availability,"ail version devel-17a988f2a628; 2018-10-09 15:04:33 SharedState: INFO: loading hive config file: file:/Users/michafla/spark/spark-2.2.0-bin-hadoop2.7/conf/hive-site.xml; 2018-10-09 15:04:33 SharedState: INFO: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/michafla/projects/R/pkg/hailr/inst/unitTests/spark-warehouse/').; 2018-10-09 15:04:33 SharedState: INFO: Warehouse path is 'file:/Users/michafla/projects/R/pkg/hailr/inst/unitTests/spark-warehouse/'.; 2018-10-09 15:04:33 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@16ba3696{/SQL,null,AVAILABLE,@Spark}; 2018-10-09 15:04:33 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@2780d0b8{/SQL/json,null,AVAILABLE,@Spark}; 2018-10-09 15:04:33 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@7cea1161{/SQL/execution,null,AVAILABLE,@Spark}; 2018-10-09 15:04:33 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@696b1f0{/SQL/execution/json,null,AVAILABLE,@Spark}; 2018-10-09 15:04:33 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@14d32b0c{/static/sql,null,AVAILABLE,@Spark}; 2018-10-09 15:04:34 StateStoreCoordinatorRef: INFO: Registered StateStoreCoordinator endpoint; 2018-10-09 15:04:34 SparkSession$Builder: WARN: Using an existing SparkSession; some configuration may not take effect.; 2018-10-09 15:04:34 SparkSqlParser: INFO: Parsing command: SHOW TABLES; 2018-10-09 15:04:36 SparkContext: INFO: Starting job: collect at utils.scala:44; 2018-10-09 15:04:36 DAGScheduler: INFO: Got job 0 (collect at utils.scala:44) with 1 output partitions; 2018-10-09 15:04:36 DAGScheduler: INFO: Final stage: ResultStage 0 (collect at utils.scala:44); 2018-10-09 15:04:36 DAGScheduler: INFO: Parents of final stage: List(); 2018-10-09 15:04:36 DAGScheduler: INFO: Missing parents: List(); 2018-10-09 15:04:36 DAGScheduler: INFO: Submitting ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:41), which has no missing parents; 2018-10-09 15:0",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4513:14518,AVAIL,AVAILABLE,14518,https://hail.is,https://github.com/hail-is/hail/issues/4513,1,['AVAIL'],['AVAILABLE']
Availability,"ail.expr.ir.Infer$.apply(Infer.scala:59); 	at is.hail.expr.ir.InferIR$class.typ(IR.scala:58); 	at is.hail.expr.ir.InsertFields.typ(IR.scala:154); 	at is.hail.expr.ir.MatrixMapEntries.<init>(MatrixIR.scala:1075); 	at is.hail.variant.MatrixTable.selectEntries(MatrixTable.scala:641); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:280); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:214); 	at java.lang.Thread.run(Thread.java:748). Hail version: devel-0eb009391fd5; Error summary: AssertionError: assertion failed: mismatch:; array<int32>; array<int32>; ApplyComparisonOp(GT(int32,int32),GetField(ArrayRef(GetField(Ref(va,struct{locus: locus<GRCh37>, alleles: array<str>, rsid: str, qual: float64, filters: set<str>, info: struct{NEGATIVE_TRAIN_SITE: bool, HWP: float64, AC: array<int32>, culprit: str, MQ0: int32, ReadPosRankSum: float64, AN: int32, InbreedingCoeff: float64, AF: array<float64>, GQ_STDDEV: float64, FS: float64, DP: int32, GQ_MEAN: float64, POSITIVE_TRAIN_SITE: bool, VQSLOD: float64, ClippingRankSum: float64, BaseQRankSum: float64, MLEAF: array<float64>, MLEAC: array<int32>, MQ: float64, QD: float64, END: int32, DB: bool, HaplotypeScore: float64, MQRankSum: float64, CCC: int32, NCC: int32, DS: bool}, `the entries! [877f12a8827e18f61222c6c8c5fb04a8]`: array<struct{GT: call, AD: array<int32>, DP: int32, GQ: int32, PL: array<int32>}>}),the entries! [877f12a8827e18f61222c6c8c5fb04a8]),Ref(i,int32)),DP),I32(20)); ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4134:5067,Error,Error,5067,https://hail.is,https://github.com/hail-is/hail/issues/4134,1,['Error'],['Error']
Availability,"ail/hail-devel-0c961806173f.zip/hail/methods/qc.py in vep(dataset, config, block_size, name, csq); 545; 546 require_row_key_variant(dataset, 'vep'); --> 547 return MatrixTable(Env.hail().methods.VEP.apply(dataset._jvds, config, 'va.`{}`'.format(name), csq, block_size)); 548; 549. /usr/lib/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py in __call__(self, *args); 1131 answer = self.gateway_client.send_command(command); 1132 return_value = get_return_value(; -> 1133 answer, self.gateway_client, self.target_id, self.name); 1134; 1135 for temp_arg in temp_args:. /hadoop_gcs_connector_metadata_cache/hail/hail-devel-0c961806173f.zip/hail/utils/java.py in deco(*args, **kwargs); 236 # this is a hack to suppress the original error's stack trace; 237 if _exception:; --> 238 raise _exception; 239; 240 return deco. FatalError: AssertionError: assertion failed. Java stack trace:; java.lang.AssertionError: assertion failed; 	at scala.Predef$.assert(Predef.scala:156); 	at is.hail.variant.MatrixTable.orderedRVDLeftJoinDistinctAndInsert(MatrixTable.scala:982); 	at is.hail.methods.VEP$.annotate(VEP.scala:429); 	at is.hail.methods.VEP$.apply(VEP.scala:434); 	at is.hail.methods.VEP.apply(VEP.scala); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:280); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:214); 	at java.lang.Thread.run(Thread.java:748). Hail version: devel-2c596b7; Error summary: AssertionError: assertion failed; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3099:3916,Error,Error,3916,https://hail.is,https://github.com/hail-is/hail/issues/3099,1,['Error'],['Error']
Availability,"aio-libs/aiohttp/issues/7374"">#7374</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/01d9b70e5477cd746561b52225992d8a2ebde953""><code>01d9b70</code></a> [PR <a href=""https://redirect.github.com/aio-libs/aiohttp/issues/7370"">#7370</a>/22c264ce backport][3.8] fix: Spelling error fixed (<a href=""https://redirect.github.com/aio-libs/aiohttp/issues/7371"">#7371</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/3577b1e3719d4648fa973dbdec927f78f9df34dd""><code>3577b1e</code></a> [PR <a href=""https://redirect.github.com/aio-libs/aiohttp/issues/7359"">#7359</a>/7911f1e9 backport][3.8]  Set up secretless publishing to PyPI (<a href=""https://redirect.github.com/aio-libs/aiohttp/issues/7360"">#7360</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/8d45f9c99511cd80140d6658bd9c11002c697f1c""><code>8d45f9c</code></a> [PR <a href=""https://redirect.github.com/aio-libs/aiohttp/issues/7333"">#7333</a>/3a54d378 backport][3.8] Fix TLS transport is <code>None</code> error (<a href=""https://redirect.github.com/aio-libs/aiohttp/issues/7357"">#7357</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/dd8e24e77351df9c0f029be49d3c6d7862706e79""><code>dd8e24e</code></a> [PR <a href=""https://redirect.github.com/aio-libs/aiohttp/issues/7343"">#7343</a>/18057581 backport][3.8] Mention encoding in <code>yarl.URL</code> (<a href=""https://redirect.github.com/aio-libs/aiohttp/issues/7355"">#7355</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/40874103ebfaa1007d47c25ecc4288af873a07cf""><code>4087410</code></a> [PR <a href=""https://redirect.github.com/aio-libs/aiohttp/issues/7346"">#7346</a>/346fd202 backport][3.8]  Bump vendored llhttp to v8.1.1 (<a href=""https://redirect.github.com/aio-libs/aiohttp/issues/7352"">#7352</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/aio-libs/aiohttp/compare/v3.8.4...v3.8.5"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://depend",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13270:5348,error,error,5348,https://hail.is,https://github.com/hail-is/hail/pull/13270,5,['error'],['error']
Availability,"aio-libs/aioredis-py/releases"">aioredis's releases</a>.</em></p>; <blockquote>; <h2>v2.0.1</h2>; <p>Version v2.0.1</p>; <h2>Features</h2>; <ul>; <li>Added Python 3.10 to CI &amp; Updated the Docs (see <a href=""https://github-redirect.dependabot.com/aio-libs/aioredis-py/issues/1160"">#1160</a>)</li>; <li>Enable mypy in CI (see <a href=""https://github-redirect.dependabot.com/aio-libs/aioredis-py/issues/1101"">#1101</a>)</li>; <li>Synchronized reading the responses from a connection (see <a href=""https://github-redirect.dependabot.com/aio-libs/aioredis-py/issues/1106"">#1106</a>)</li>; </ul>; <h2>Fixes</h2>; <ul>; <li>Remove del from Redis (Fixes <a href=""https://github-redirect.dependabot.com/aio-libs/aioredis-py/issues/1115"">#1115</a>) (see <a href=""https://github-redirect.dependabot.com/aio-libs/aioredis-py/issues/1227"">#1227</a>)</li>; <li>fix socket.error raises (see <a href=""https://github-redirect.dependabot.com/aio-libs/aioredis-py/issues/1129"">#1129</a>)</li>; <li>Fix buffer is closed error when using PythonParser class (see <a href=""https://github-redirect.dependabot.com/aio-libs/aioredis-py/issues/1213"">#1213</a>)</li>; </ul>; <h2>Version v2.0.0</h2>; <p>Version 2.0 is a complete rewrite of aioredis. Starting with this version, aioredis now follows the API of <a href=""https://github.com/andymccurdy/redis-py"">redis-py</a>, so you can easily adapt synchronous code that uses redis-py for async applications with aioredis-py.</p>; <p><strong>NOTE:</strong> This version is <em>not</em> compatible with earlier versions of aioredis. If you upgrade, you will need to make code changes.</p>; <p>For more details, read our <a href=""https://aioredis.readthedocs.io/en/latest/migration/"">documentation on migrating to version 2.0</a>.</p>; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/aio-libs/aioredis-py/blob/master/CHANGELOG.md"">aioredis's changelog</a>.</em></p>; <blockquote>; <h2>2.0.1 - (2021-12-20)</h2>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11569:1176,error,error,1176,https://hail.is,https://github.com/hail-is/hail/pull/11569,1,['error'],['error']
Availability,"aiosignal 1.3.1 requires frozenlist, which is not installed.; aiodns 2.0.0 requires pycares, which is not installed. ```; </details>. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **663/1000** <br/> **Why?** Proof of Concept exploit, Recently disclosed, Has a fix available, CVSS 5.4 | Improper Input Validation <br/>[SNYK-PYTHON-AIOHTTP-6091621](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-6091621) | `aiohttp:` <br> `3.8.6 -> 3.9.0` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **663/1000** <br/> **Why?** Proof of Concept exploit, Recently disclosed, Has a fix available, CVSS 5.4 | Improper Input Validation <br/>[SNYK-PYTHON-AIOHTTP-6091622](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-6091622) | `aiohttp:` <br> `3.8.6 -> 3.9.0` <br> | No | Proof of Concept . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI3M2M5M2ZlNi0yOWM3LTQ4MWMtYTBiYy1lMzFkYzc3N2Q",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14041:1544,avail,available,1544,https://hail.is,https://github.com/hail-is/hail/pull/14041,1,['avail'],['available']
Availability,"aiosignal 1.3.1 requires frozenlist, which is not installed.; aiodns 2.0.0 requires pycares, which is not installed. ```; </details>. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **663/1000** <br/> **Why?** Proof of Concept exploit, Recently disclosed, Has a fix available, CVSS 5.4 | Improper Input Validation <br/>[SNYK-PYTHON-AIOHTTP-6091621](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-6091621) | `aiohttp:` <br> `3.8.6 -> 3.9.0` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **663/1000** <br/> **Why?** Proof of Concept exploit, Recently disclosed, Has a fix available, CVSS 5.4 | Improper Input Validation <br/>[SNYK-PYTHON-AIOHTTP-6091622](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-6091622) | `aiohttp:` <br> `3.8.6 -> 3.9.0` <br> | No | Proof of Concept . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI4ZmFmZmYwNi1jOTI2LTQ5NjEtOTI4MC1iNGI0OTczNTg",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14038:1552,avail,available,1552,https://hail.is,https://github.com/hail-is/hail/pull/14038,1,['avail'],['available']
Availability,"al support of <code>Kernel32Util.formatMessage</code> - <a href=""https://github.com/overpathz""><code>@overpathz</code></a>.</li>; <li><a href=""https://redirect.github.com/java-native-access/jna/pull/1490"">#1490</a>: Adds support for a custom <code>SymbolProvider</code> in <code>NativeLibrary</code> &amp; <code>Library</code> - <a href=""https://github.com/soywiz""><code>@soywiz</code></a>.</li>; <li><a href=""https://redirect.github.com/java-native-access/jna/pull/1491"">#1491</a>: Update libffi to v3.4.4 - <a href=""https://github.com/matthiasblaesing""><code>@matthiasblaesing</code></a>.</li>; <li><a href=""https://redirect.github.com/java-native-access/jna/issues/1487"">#1487</a>: Add 'uses' information to OSGI metadata in MANIFEST.MF to improve stability of package resolution - <a href=""https://github.com/sratz""><code>@sratz</code></a>.</li>; </ul>; <h2>Bug Fixes</h2>; <ul>; <li><a href=""https://redirect.github.com/java-native-access/jna/issues/1452"">#1452</a>: Fix memory allocation/handling for error message generation in native library code (<code>dispatch.c</code>) - <a href=""https://github.com/matthiasblaesing""><code>@matthiasblaesing</code></a>.</li>; <li><a href=""https://redirect.github.com/java-native-access/jna/issues/1460"">#1460</a>: Fix win32 variant date conversion in DST offest window and with millisecond values - <a href=""https://github.com/eranl""><code>@eranl</code></a>.</li>; <li><a href=""https://redirect.github.com/java-native-access/jna/issues/1472"">#1472</a>: Fix incorrect bitmask in <code>c.s.j.Pointer#createConstant(int)</code> - <a href=""https://github.com/dbwiddis""><code>@dbwiddis</code></a>.</li>; <li><a href=""https://redirect.github.com/java-native-access/jna/issues/1481"">#1481</a>: Fix NPE in NativeLibrary when unpacking from classpath is disabled - <a href=""https://github.com/trespasserw""><code>@trespasserw</code></a>.</li>; <li><a href=""https://redirect.github.com/java-native-access/jna/pull/1489"">#1489</a>: Fixes typo in <code>OpenGL3",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12886:2559,error,error,2559,https://hail.is,https://github.com/hail-is/hail/pull/12886,1,['error'],['error']
Availability,"al user.</p><br /><h3>Snyk has created this PR to fix one or more vulnerable packages in the `pip` dependencies of this project.</h3>. #### Changes included in this PR. - Changes to the following files to upgrade the vulnerable dependencies to a fixed version:; - hail/python/pinned-requirements.txt. <details>; <summary> <b>Warning</b></summary>. ```; msal-extensions 1.0.0 requires portalocker, which is not installed.; aiosignal 1.3.1 requires frozenlist, which is not installed.; aiodns 2.0.0 requires pycares, which is not installed. ```; </details>. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **509/1000** <br/> **Why?** Has a fix available, CVSS 5.9 | Use of a Broken or Risky Cryptographic Algorithm <br/>[SNYK-PYTHON-CRYPTOGRAPHY-6149518](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-6149518) | `cryptography:` <br> `41.0.7 -> 42.0.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **581/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 5.9 | Uncontrolled Resource Consumption (&#x27;Resource Exhaustion&#x27;) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-6157248](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-6157248) | `cryptography:` <br> `41.0.7 -> 42.0.2` <br> | No | No Known Exploit ; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **451/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 3.3 | NULL Pointer Dereference <br/>[SNYK-PYTHON-CRYPTOGRAPHY-6210214](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-62",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14234:1097,avail,available,1097,https://hail.is,https://github.com/hail-is/hail/pull/14234,1,['avail'],['available']
Availability,"al user.</p><br /><h3>Snyk has created this PR to fix one or more vulnerable packages in the `pip` dependencies of this project.</h3>. #### Changes included in this PR. - Changes to the following files to upgrade the vulnerable dependencies to a fixed version:; - hail/python/pinned-requirements.txt. <details>; <summary> <b>Warning</b></summary>. ```; msal-extensions 1.1.0 requires portalocker, which is not installed.; aiosignal 1.3.1 requires frozenlist, which is not installed.; aiodns 2.0.0 requires pycares, which is not installed. ```; </details>. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **554/1000** <br/> **Why?** Has a fix available, CVSS 6.8 | Insufficient Verification of Data Authenticity <br/>[SNYK-PYTHON-CERTIFI-3164749](https://snyk.io/vuln/SNYK-PYTHON-CERTIFI-3164749) | `certifi:` <br> `2021.10.8 -> 2023.7.22` <br> | No | No Known Exploit ; ![critical severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/c.png ""critical severity"") | **704/1000** <br/> **Why?** Has a fix available, CVSS 9.8 | Improper Following of a Certificate&#x27;s Chain of Trust <br/>[SNYK-PYTHON-CERTIFI-5805047](https://snyk.io/vuln/SNYK-PYTHON-CERTIFI-5805047) | `certifi:` <br> `2021.10.8 -> 2023.7.22` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **509/1000** <br/> **Why?** Has a fix available, CVSS 5.9 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-3172287](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-3172287) | `cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No | N",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14327:1097,avail,available,1097,https://hail.is,https://github.com/hail-is/hail/pull/14327,1,['avail'],['available']
Availability,"al(signal.SIGINT, signal.SIG_IGN); ---> 77 proc = Popen(command, stdin=PIPE, preexec_fn=preexec_func, env=env); 78 else:; 79 # preexec_fn not supported on Windows. /scratch/PI/dpwall/computeEnvironments/miniconda2/lib/python2.7/subprocess.pyc in __init__(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags); 388 p2cread, p2cwrite,; 389 c2pread, c2pwrite,; --> 390 errread, errwrite); 391 except Exception:; 392 # Preserve original exception in case os.close raises. /scratch/PI/dpwall/computeEnvironments/miniconda2/lib/python2.7/subprocess.pyc in _execute_child(self, args, executable, preexec_fn, close_fds, cwd, env, universal_newlines, startupinfo, creationflags, shell, to_close, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite); 1022 raise; 1023 child_exception = pickle.loads(data); -> 1024 raise child_exception; 1025; 1026. OSError: [Errno 2] No such file or directory. and the second error we would get would be. ------------------------------------------------------------------------- Py4JJavaError Traceback (most recent call last) <ipython-input-6-93fa734a63bb> in <module>() ----> 1 hc_nate = HailContext() /scratch/PI/dpwall/computeEnvironments/hail/python/hail/context.pyc in __init__(self, sc, appName, master, local, log, quiet, append, parquet_compression, min_block_size, branching_factor, tmp_dir) 60 self._jhc = scala_object(self._hail, 'HailContext').apply( 61 jsc, appName, joption(master), local, log, quiet, append, ---> 62 parquet_compression, min_block_size, branching_factor, tmp_dir) 63 64 self._jsc = self._jhc.sc() /share/sw/free/spark.2.1.0/spark-2.1.0-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py in __call__(self, *args) 1131 answer = self.gateway_client.send_command(command) 1132 return_value = get_return_value( -> 1133 answer, self.gateway_client, self.target_id, self.name) 1134 1135 for temp_arg in temp_args: /share/sw/free/spark.2.1.0/",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1525:3175,error,error,3175,https://hail.is,https://github.com/hail-is/hail/issues/1525,1,['error'],['error']
Availability,"alize/rich/issues/3176"">Textualize/rich#3176</a></li>; <li>Ensure font is correctly inherited in exported HTML <a href=""https://redirect.github.com/Textualize/rich/issues/3104"">Textualize/rich#3104</a></li>; <li>Fixed typing for <code>FloatPrompt</code>.</li>; </ul>; <h2>The Python 3.12 release</h2>; <p>Mostly a meta update in readiness for the release of Python3.12</p>; <h2>[13.6.0] - 2023-09-30</h2>; <h3>Added</h3>; <ul>; <li>Added Python 3.12 to classifiers.</li>; </ul>; <h2>Markdown fixes</h2>; <h2>[13.5.3] - 2023-09-17</h2>; <h3>Fixed</h3>; <ul>; <li>Markdown table rendering issue with inline styles and links <a href=""https://redirect.github.com/Textualize/rich/issues/3115"">Textualize/rich#3115</a></li>; <li>Fix Markdown code blocks on a light background <a href=""https://redirect.github.com/Textualize/rich/issues/3123"">Textualize/rich#3123</a></li>; </ul>; <h2>v13.5.2</h2>; <p>Bugfix</p>; <h2>[13.5.2] - 2023-08-01</h2>; <h3>Fixed</h3>; <ul>; <li>Fixed Text.expand_tabs assertion error</li>; </ul>; <h2>v13.5.1</h2>; <p>Very minor update to URL highlighting</p>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/Textualize/rich/blob/master/CHANGELOG.md"">rich's changelog</a>.</em></p>; <blockquote>; <h2>[13.7.1] - 2023-02-28</h2>; <h3>Fixed</h3>; <ul>; <li>Updated the widths of some characters <a href=""https://redirect.github.com/Textualize/rich/pull/3289"">Textualize/rich#3289</a></li>; </ul>; <h2>[13.7.0] - 2023-11-15</h2>; <h3>Added</h3>; <ul>; <li>Adds missing parameters to Panel.fit <a href=""https://redirect.github.com/Textualize/rich/issues/3142"">Textualize/rich#3142</a></li>; </ul>; <h3>Fixed</h3>; <ul>; <li>Some text goes missing during wrapping when it contains double width characters <a href=""https://redirect.github.com/Textualize/rich/issues/3176"">Textualize/rich#3176</a></li>; <li>Ensure font is correctly inherited in exported HTML <a href=""",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14376:1880,error,error,1880,https://hail.is,https://github.com/hail-is/hail/pull/14376,2,['error'],['error']
Availability,"alize/rich/issues/3176"">Textualize/rich#3176</a></li>; <li>Ensure font is correctly inherited in exported HTML <a href=""https://redirect.github.com/Textualize/rich/issues/3104"">Textualize/rich#3104</a></li>; <li>Fixed typing for <code>FloatPrompt</code>.</li>; </ul>; <h2>The Python 3.12 release</h2>; <p>Mostly a meta update in readiness for the release of Python3.12</p>; <h2>[13.6.0] - 2023-09-30</h2>; <h3>Added</h3>; <ul>; <li>Added Python 3.12 to classifiers.</li>; </ul>; <h2>Markdown fixes</h2>; <h2>[13.5.3] - 2023-09-17</h2>; <h3>Fixed</h3>; <ul>; <li>Markdown table rendering issue with inline styles and links <a href=""https://redirect.github.com/Textualize/rich/issues/3115"">Textualize/rich#3115</a></li>; <li>Fix Markdown code blocks on a light background <a href=""https://redirect.github.com/Textualize/rich/issues/3123"">Textualize/rich#3123</a></li>; </ul>; <h2>v13.5.2</h2>; <p>Bugfix</p>; <h2>[13.5.2] - 2023-08-01</h2>; <h3>Fixed</h3>; <ul>; <li>Fixed Text.expand_tabs assertion error</li>; </ul>; <h2>v13.5.1</h2>; <p>Very minor update to URL highlighting</p>; <h2>[13.5.1] - 2023-07-31</h2>; <h3>Fixed</h3>; <ul>; <li>Fix tilde character (<code>~</code>) not included in link regex when printing to console <a href=""https://redirect.github.com/Textualize/rich/issues/3057"">Textualize/rich#3057</a></li>; </ul>; <h2>Mostly cake, one or two puppies</h2>; <p><a href=""https://textual.textualize.io/blog/2023/07/29/pull-requests-are-cake-or-puppies/"">https://textual.textualize.io/blog/2023/07/29/pull-requests-are-cake-or-puppies/</a></p>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/Textualize/rich/blob/master/CHANGELOG.md"">rich's changelog</a>.</em></p>; <blockquote>; <h2>[13.7.0] - 2023-11-15</h2>; <h3>Added</h3>; <ul>; <li>Adds missing parameters to Panel.fit <a href=""https://redirect.github.com/Textualize/rich/issues/3142"">Textualize/rich#3142</a></l",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14012:1628,error,error,1628,https://hail.is,https://github.com/hail-is/hail/pull/14012,2,['error'],['error']
Availability,"alled parameters. `a` and `c` which do not start with dashes, are called arguments. `-o`, which starts with a dash, is an option. This PR makes the following changes:. - For dataproc commands taking extra gcloud parameters, all parameters after a double-dash (--) are passed to gcloud.; - The actual rule is slightly more complicated, but I think the above rule is the right take away. In detail, extra parameters are passed to gcloud. Unknown options (starting with a dash) before `--` are reported as an error. So arguments (not options) before `--` and all parameters after are passed to gcloud. ; - Short options don't need a `=` when specifying a value. It is now `-p2`, not `-p=2`.; - While I was making breaking changes, I changed `dataproc submit` `--gcloud_configuration` to `--gcloud-configuration`. I am happy to undo this one.; - Group arguments must go before the next command. Write `hailctl dataproc --beta start ...` not `hailctl dataproc start --beta ...`, which is an error since `start` has no option `--beta`. This PR rewrites argument parsing to use click instead of argparse: https://click.palletsprojects.com/en/7.x/. Things you need to know about click:; - A group is a group of commands or subgroups, like `hailctl dataproc`, `hailctl batch`, etc. Groups are defined like this:; ; ```; @hailctl.group(; help=""Manage the Hail Batch service.""); def batch():; pass; ```; - A command in a group is defined like this:. ```; @batch.command(; help=""Get a particular batch's info.""); @click.argument('batch_id', type=int); @click.option('--output-format', '-o',; type=click.Choice(['yaml', 'json']),; default='yaml', show_default=True,; help=""Specify output format"",); def get(batch_id, output_format):; ...; ```. The command decorator replaces the function with one that takes a `List[str]` of command line parameters, parses them, and calls the original function. The option options are pretty self-explanatory. - To access an argument to a group (like `dataproc --beta`) in a (sub",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9842:1264,error,error,1264,https://hail.is,https://github.com/hail-is/hail/pull/9842,1,['error'],['error']
Availability,"alse`, step 3 succeeds. ### What went wrong (all error messages here, including the full java stack trace):; ```; 2018-06-19 17:15:41 Hail: INFO: vep: annotated 2 variants; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/opt/hail/python/hail/typecheck/check.py"", line 547, in wrapper; return f(*args_, **kwargs_); File ""/opt/hail/python/hail/table.py"", line 1195, in show; print(self._show(n,width, truncate, types)); File ""/opt/hail/python/hail/table.py"", line 1198, in _show; return self._jt.showString(n, joption(truncate), types, width); File ""/opt/spark-2.2.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py"", line 1133, in __call__; File ""/opt/hail/python/hail/utils/java.py"", line 196, in deco; 'Error summary: %s' % (deepest, full, hail.__version__, deepest)) from None; hail.utils.java.FatalError: MatchError: [Ljava.lang.String;@7cd5fe91 (of class [Ljava.lang.String;). Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 11.0 failed 1 times, most recent failure: Lost task 0.0 in stage 11.0 (TID 11, localhost, executor driver): scala.MatchError: [Ljava.lang.String;@7cd5fe91 (of class [Ljava.lang.String;); 	at is.hail.annotations.RegionValueBuilder.addAnnotation(RegionValueBuilder.scala:489); 	at is.hail.methods.VEP$$anonfun$9$$anonfun$apply$4.apply(VEP.scala:350); 	at is.hail.methods.VEP$$anonfun$9$$anonfun$apply$4.apply(VEP.scala:345); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$16$$anon$3.next(OrderedRVD.scala:926); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$16$$anon$3.next(OrderedRVD.scala:920); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:462); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3790:1363,failure,failure,1363,https://hail.is,https://github.com/hail-is/hail/issues/3790,1,['failure'],['failure']
Availability,also add module functions to download and import 1KG and Movie Lens data,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3203:29,down,download,29,https://hail.is,https://github.com/hail-is/hail/pull/3203,1,['down'],['download']
Availability,also added test for this change:; https://github.com/hail-is/hail/pull/4228. made sure that it errored without that change,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4237:95,error,errored,95,https://hail.is,https://github.com/hail-is/hail/pull/4237,1,['error'],['errored']
Availability,also changes the error message to display `<<<empty key>>>` as the list of keys. fixes #6663,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6736:17,error,error,17,https://hail.is,https://github.com/hail-is/hail/pull/6736,1,['error'],['error']
Availability,"amp;to=2024-04-08&amp;type=c"">GitHub contributors page for this release</a>)</p>; <p><a href=""https://github.com/search?q=repo%3Ajupyterlab%2Fjupyterlab_server+involves%3AAshokChoudhary11+updated%3A2024-03-11..2024-04-08&amp;type=Issues""><code>@AshokChoudhary11</code></a> | <a href=""https://github.com/search?q=repo%3Ajupyterlab%2Fjupyterlab_server+involves%3Aholzman+updated%3A2024-03-11..2024-04-08&amp;type=Issues""><code>@holzman</code></a> | <a href=""https://github.com/search?q=repo%3Ajupyterlab%2Fjupyterlab_server+involves%3Amanics+updated%3A2024-03-11..2024-04-08&amp;type=Issues""><code>@manics</code></a> | <a href=""https://github.com/search?q=repo%3Ajupyterlab%2Fjupyterlab_server+involves%3Awelcome+updated%3A2024-03-11..2024-04-08&amp;type=Issues""><code>@welcome</code></a></p>; <h2>v2.25.4</h2>; <h2>2.25.4</h2>; <p>(<a href=""https://github.com/jupyterlab/jupyterlab_server/compare/v2.25.3...15e796699f04e06db9ed23a689d454feae36ffbd"">Full Changelog</a>)</p>; <h3>Maintenance and upkeep improvements</h3>; <ul>; <li>Use updated releaser workflows <a href=""https://redirect.github.com/jupyterlab/jupyterlab_server/pull/442"">#442</a> (<a href=""https://github.com/blink1073""><code>@blink1073</code></a>)</li>; <li>Use json5 typings <a href=""https://redirect.github.com/jupyterlab/jupyterlab_server/pull/441"">#441</a> (<a href=""https://github.com/blink1073""><code>@blink1073</code></a>)</li>; <li>Enforce pytest 7 <a href=""https://redirect.github.com/jupyterlab/jupyterlab_server/pull/439"">#439</a> (<a href=""https://github.com/blink1073""><code>@blink1073</code></a>)</li>; <li>Fix test util typings <a href=""https://redirect.github.com/jupyterlab/jupyterlab_server/pull/437"">#437</a> (<a href=""https://github.com/blink1073""><code>@blink1073</code></a>)</li>; </ul>; <h3>Contributors to this release</h3>; <p>(<a href=""https://github.com/jupyterlab/jupyterlab_server/graphs/contributors?from=2024-02-14&amp;to=2024-03-11&amp;type=c"">GitHub contributors page for this release</a>)</p>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14483:2089,Mainten,Maintenance,2089,https://hail.is,https://github.com/hail-is/hail/pull/14483,1,['Mainten'],['Maintenance']
Availability,"an array of const class simdpp::arch_avx2::int16<16>; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/types.h:20,; from libsimdpp-2.0-rc2/simdpp/core/align.h:15,; from libsimdpp-2.0-rc2/simdpp/simd.h:22,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/types/int8x32.h:91:7: note: class simdpp::arch_avx2::uint8<32> declared here; class uint8<32, void> : public any_int8<32, uint8<32,void>> {; ^~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/simd.h:132,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl: In instantiation of R simdpp::arch_avx2::detail::cast_memcpy(const T&) [with R = simdpp::arch_avx2::uint8<32>; T = simdpp::arch_avx2::uint32<8>]:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::arch_avx2::uint8<32>; T = simdpp::arch_avx2::uint32<8>; unsigned int MaskCastOverride = 0]; libsimdpp-2.0-rc2/simdpp/core/cast.h:63:89: required from R simdpp::arch_avx2::bit_cast(const T&) [with R = simdpp::arch_avx2::uint8<32>; T = simdpp::arch_avx2::uint32<8>]; libsimdpp-2.0-rc2/simdpp/types/int8x32.h:110:36: required from simdpp::arch_avx2::uint8<32>::uint8(const simdpp::arch_avx2::any_vec<32, V>&) [with V = simdpp::arch_avx2::uint32<8>]; libsimdpp-2.0-rc2/simdpp/detail/insn/bit_not.h:64:43: required from here; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:40:13: error: void* memcpy(void*, const void*, size_t) copying an object of type class simdpp::arch_avx2::uint8<32> with private member simdpp::arch_avx2::uint8<32>::d_ from an array of const class simdpp::arch_avx2::uint32<8>; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdp",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3955:22747,Mask,MaskCastOverride,22747,https://hail.is,https://github.com/hail-is/hail/issues/3955,2,['Mask'],['MaskCastOverride']
Availability,"an array of const class simdpp::arch_avx2::int16<8>; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/types.h:19,; from libsimdpp-2.0-rc2/simdpp/core/align.h:15,; from libsimdpp-2.0-rc2/simdpp/simd.h:22,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/types/int8x16.h:104:7: note: class simdpp::arch_avx2::uint8<16> declared here; class uint8<16, void> : public any_int8<16, uint8<16,void>> {; ^~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/simd.h:132,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl: In instantiation of R simdpp::arch_avx2::detail::cast_memcpy(const T&) [with R = simdpp::arch_avx2::int16<16>; T = simdpp::arch_avx2::uint8<32>]:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::arch_avx2::int16<16>; T = simdpp::arch_avx2::uint8<32>; unsigned int MaskCastOverride = 0]; libsimdpp-2.0-rc2/simdpp/core/cast.h:63:89: required from R simdpp::arch_avx2::bit_cast(const T&) [with R = simdpp::arch_avx2::int16<16>; T = simdpp::arch_avx2::uint8<32>]; libsimdpp-2.0-rc2/simdpp/types/int16x16.h:56:36: required from simdpp::arch_avx2::int16<16>& simdpp::arch_avx2::int16<16>::operator=(const simdpp::arch_avx2::any_vec<32, V>&) [with V = simdpp::arch_avx2::uint8<32>]; libsimdpp-2.0-rc2/simdpp/detail/insn/shuffle_bytes16.h:85:11: required from here; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:40:13: error: void* memcpy(void*, const void*, size_t) copying an object of type class simdpp::arch_avx2::int16<16> with private member simdpp::arch_avx2::int16<16>::d_ from an array of const class simdpp::arch_avx2::uint8<32>; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3955:19161,Mask,MaskCastOverride,19161,https://hail.is,https://github.com/hail-is/hail/issues/3955,2,['Mask'],['MaskCastOverride']
Availability,"an array of const class simdpp::arch_avx2::int16<8>; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/types.h:23,; from libsimdpp-2.0-rc2/simdpp/core/align.h:15,; from libsimdpp-2.0-rc2/simdpp/simd.h:22,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/types/int32x4.h:104:7: note: class simdpp::arch_avx2::uint32<4> declared here; class uint32<4, void> : public any_int32<4, uint32<4,void>> {; ^~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/simd.h:132,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl: In instantiation of R simdpp::arch_avx2::detail::cast_memcpy(const T&) [with R = simdpp::arch_avx2::uint32<8>; T = simdpp::arch_avx2::int16<16>]:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::arch_avx2::uint32<8>; T = simdpp::arch_avx2::int16<16>; unsigned int MaskCastOverride = 0]; libsimdpp-2.0-rc2/simdpp/core/cast.h:63:89: required from R simdpp::arch_avx2::bit_cast(const T&) [with R = simdpp::arch_avx2::uint32<8>; T = simdpp::arch_avx2::int16<16>]; libsimdpp-2.0-rc2/simdpp/types/int32x8.h:110:36: required from simdpp::arch_avx2::uint32<8>::uint32(const simdpp::arch_avx2::any_vec<32, V>&) [with V = simdpp::arch_avx2::int16<16>]; libsimdpp-2.0-rc2/simdpp/detail/insn/i_reduce_mul.h:181:30: required from here; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:40:13: error: void* memcpy(void*, const void*, size_t) copying an object of type class simdpp::arch_avx2::uint32<8> with private member simdpp::arch_avx2::uint32<8>::d_ from an array of const class simdpp::arch_avx2::int16<16>; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3955:86928,Mask,MaskCastOverride,86928,https://hail.is,https://github.com/hail-is/hail/issues/3955,2,['Mask'],['MaskCastOverride']
Availability,"an array of const class simdpp::arch_avx2::uint32<16>; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/types.h:38,; from libsimdpp-2.0-rc2/simdpp/core/align.h:15,; from libsimdpp-2.0-rc2/simdpp/simd.h:22,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/types/int64.h:87:7: note: class simdpp::arch_avx2::uint64<8> declared here; class uint64<N, void> : public any_int64<N, uint64<N,void>> {; ^~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/simd.h:132,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl: In instantiation of R simdpp::arch_avx2::detail::cast_memcpy(const T&) [with R = simdpp::arch_avx2::uint32<16>; T = simdpp::arch_avx2::uint64<8>]:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::arch_avx2::uint32<16>; T = simdpp::arch_avx2::uint64<8>; unsigned int MaskCastOverride = 0]; libsimdpp-2.0-rc2/simdpp/core/cast.h:63:89: required from R simdpp::arch_avx2::bit_cast(const T&) [with R = simdpp::arch_avx2::uint32<16>; T = simdpp::arch_avx2::uint64<8>]; libsimdpp-2.0-rc2/simdpp/types/int32.h:105:36: required from simdpp::arch_avx2::uint32<N>& simdpp::arch_avx2::uint32<N>::operator=(const simdpp::arch_avx2::any_vec<(N * 4), V>&) [with V = simdpp::arch_avx2::uint64<8, simdpp::arch_avx2::expr_empty>; unsigned int N = 16]; libsimdpp-2.0-rc2/simdpp/detail/insn/transpose.h:598:8: required from void simdpp::arch_avx2::detail::insn::v_sse_transpose32x4(V&, V&, V&, V&) [with V = simdpp::arch_avx2::uint32<16>; D = simdpp::arch_avx2::uint64<8>]; libsimdpp-2.0-rc2/simdpp/detail/insn/transpose.h:533:62: required from here; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:40:13: error: void* memcpy(void*, const void*, size_t) copying an object of type class simdpp::ar",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3955:97934,Mask,MaskCastOverride,97934,https://hail.is,https://github.com/hail-is/hail/issues/3955,2,['Mask'],['MaskCastOverride']
Availability,"an array of const class simdpp::arch_avx2::uint32<8>; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/types.h:20,; from libsimdpp-2.0-rc2/simdpp/core/align.h:15,; from libsimdpp-2.0-rc2/simdpp/simd.h:22,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/types/int8x32.h:91:7: note: class simdpp::arch_avx2::uint8<32> declared here; class uint8<32, void> : public any_int8<32, uint8<32,void>> {; ^~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/simd.h:132,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl: In instantiation of R simdpp::arch_avx2::detail::cast_memcpy(const T&) [with R = simdpp::arch_avx2::uint32<8>; T = simdpp::arch_avx2::uint8<32>]:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::arch_avx2::uint32<8>; T = simdpp::arch_avx2::uint8<32>; unsigned int MaskCastOverride = 0]; libsimdpp-2.0-rc2/simdpp/core/cast.h:63:89: required from R simdpp::arch_avx2::bit_cast(const T&) [with R = simdpp::arch_avx2::uint32<8>; T = simdpp::arch_avx2::uint8<32>]; libsimdpp-2.0-rc2/simdpp/types/int32x8.h:110:36: required from simdpp::arch_avx2::uint32<8>::uint32(const simdpp::arch_avx2::any_vec<32, V>&) [with V = simdpp::arch_avx2::uint8<32>]; libsimdpp-2.0-rc2/simdpp/detail/insn/bit_not.h:64:45: required from here; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:40:13: error: void* memcpy(void*, const void*, size_t) copying an object of type class simdpp::arch_avx2::uint32<8> with private member simdpp::arch_avx2::uint32<8>::d_ from an array of const class simdpp::arch_avx2::uint8<32>; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simd",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3955:24514,Mask,MaskCastOverride,24514,https://hail.is,https://github.com/hail-is/hail/issues/3955,2,['Mask'],['MaskCastOverride']
Availability,"an array of const class simdpp::arch_avx2::uint32<8>; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/types.h:27,; from libsimdpp-2.0-rc2/simdpp/core/align.h:15,; from libsimdpp-2.0-rc2/simdpp/simd.h:22,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/types/int64x4.h:91:7: note: class simdpp::arch_avx2::uint64<4> declared here; class uint64<4, void> : public any_int64<4, uint64<4,void>> {; ^~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/simd.h:132,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl: In instantiation of R simdpp::arch_avx2::detail::cast_memcpy(const T&) [with R = simdpp::arch_avx2::uint32<8>; T = simdpp::arch_avx2::uint64<4>]:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::arch_avx2::uint32<8>; T = simdpp::arch_avx2::uint64<4>; unsigned int MaskCastOverride = 0]; libsimdpp-2.0-rc2/simdpp/core/cast.h:63:89: required from R simdpp::arch_avx2::bit_cast(const T&) [with R = simdpp::arch_avx2::uint32<8>; T = simdpp::arch_avx2::uint64<4>]; libsimdpp-2.0-rc2/simdpp/types/int32x8.h:114:36: required from simdpp::arch_avx2::uint32<8>& simdpp::arch_avx2::uint32<8>::operator=(const simdpp::arch_avx2::any_vec<32, V>&) [with V = simdpp::arch_avx2::uint64<4, simdpp::arch_avx2::expr_empty>]; libsimdpp-2.0-rc2/simdpp/detail/insn/transpose.h:181:24: required from here; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:40:13: error: void* memcpy(void*, const void*, size_t) copying an object of type class simdpp::arch_avx2::uint32<8> with private member simdpp::arch_avx2::uint32<8>::d_ from an array of const class simdpp::arch_avx2::uint64<4>; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3955:44902,Mask,MaskCastOverride,44902,https://hail.is,https://github.com/hail-is/hail/issues/3955,2,['Mask'],['MaskCastOverride']
Availability,"an array of const class simdpp::arch_avx2::uint64<4>; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/types.h:20,; from libsimdpp-2.0-rc2/simdpp/core/align.h:15,; from libsimdpp-2.0-rc2/simdpp/simd.h:22,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/types/int8x32.h:91:7: note: class simdpp::arch_avx2::uint8<32> declared here; class uint8<32, void> : public any_int8<32, uint8<32,void>> {; ^~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/simd.h:132,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl: In instantiation of R simdpp::arch_avx2::detail::cast_memcpy(const T&) [with R = simdpp::arch_avx2::uint64<4>; T = simdpp::arch_avx2::uint8<32>]:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::arch_avx2::uint64<4>; T = simdpp::arch_avx2::uint8<32>; unsigned int MaskCastOverride = 0]; libsimdpp-2.0-rc2/simdpp/core/cast.h:63:89: required from R simdpp::arch_avx2::bit_cast(const T&) [with R = simdpp::arch_avx2::uint64<4>; T = simdpp::arch_avx2::uint8<32>]; libsimdpp-2.0-rc2/simdpp/types/int64x4.h:110:36: required from simdpp::arch_avx2::uint64<4>::uint64(const simdpp::arch_avx2::any_vec<32, V>&) [with V = simdpp::arch_avx2::uint8<32>]; libsimdpp-2.0-rc2/simdpp/detail/insn/bit_not.h:94:45: required from here; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:40:13: error: void* memcpy(void*, const void*, size_t) copying an object of type class simdpp::arch_avx2::uint64<4> with private member simdpp::arch_avx2::uint64<4>::d_ from an array of const class simdpp::arch_avx2::uint8<32>; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simd",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3955:28049,Mask,MaskCastOverride,28049,https://hail.is,https://github.com/hail-is/hail/issues/3955,2,['Mask'],['MaskCastOverride']
Availability,"an array of const class simdpp::arch_avx2::uint8<32>; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/types.h:24,; from libsimdpp-2.0-rc2/simdpp/core/align.h:15,; from libsimdpp-2.0-rc2/simdpp/simd.h:22,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/types/int32x8.h:91:7: note: class simdpp::arch_avx2::uint32<8> declared here; class uint32<8, void> : public any_int32<8, uint32<8,void>> {; ^~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/simd.h:132,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl: In instantiation of R simdpp::arch_avx2::detail::cast_memcpy(const T&) [with R = simdpp::arch_avx2::uint8<32>; T = simdpp::arch_avx2::uint64<4>]:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::arch_avx2::uint8<32>; T = simdpp::arch_avx2::uint64<4>; unsigned int MaskCastOverride = 0]; libsimdpp-2.0-rc2/simdpp/core/cast.h:63:89: required from R simdpp::arch_avx2::bit_cast(const T&) [with R = simdpp::arch_avx2::uint8<32>; T = simdpp::arch_avx2::uint64<4>]; libsimdpp-2.0-rc2/simdpp/types/int8x32.h:110:36: required from simdpp::arch_avx2::uint8<32>::uint8(const simdpp::arch_avx2::any_vec<32, V>&) [with V = simdpp::arch_avx2::uint64<4>]; libsimdpp-2.0-rc2/simdpp/detail/insn/bit_not.h:94:43: required from here; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:40:13: error: void* memcpy(void*, const void*, size_t) copying an object of type class simdpp::arch_avx2::uint8<32> with private member simdpp::arch_avx2::uint8<32>::d_ from an array of const class simdpp::arch_avx2::uint64<4>; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdp",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3955:26282,Mask,MaskCastOverride,26282,https://hail.is,https://github.com/hail-is/hail/issues/3955,2,['Mask'],['MaskCastOverride']
Availability,"an; from pprint import pprint; # hail; import hail as hl; import hail.expr.aggregators as agg; import hail.expr.functions. hl.init(default_reference='GRCh38'); print(""Read in PASS SNVs""); passed=hl.read_matrix_table('/project/casa/hail.ds/gatk.hc/gcad.5k.snv.vqsr.pass'); print(""Filtering Common Variants""); common=passed.filter_rows(passed.variant_qc.AF > 0.01).persist(); common.write('/project/casa/hail.ds/gatk.hc/gcad.5k.snv.vqsr.pass.common'); print(""Pruning LD Variants""); pruned =hl.ld_prune(common,30,r2=0.1, memory_per_core=2048); pruned.write('/project/casa/hail.ds/gatk.hc/gcad.5k.snv.vqsr.pruned'); print(""Sample 20% of variants for running PC-Relate""); pruned_subsample = pruned.sample_rows(0.2).persist(); print(""Running PC_Relate""); rel = hl.pc_relate(pruned_subsample.GT, 0.01, k=10); rel_df = rel.to_pandas(); rel_df.describe(); pprint(rel_df); rel_df.to_csv('gcad_5k.snv.rel.csv'); ```. ### What went wrong (all error messages here, including the full java stack trace):. Got a memory error. but not sure what memory needs to be increased. The job seems to restart but does not progress and need to kill. . java.lang.OutOfMemoryError: Java heap spaceop. Running on Apache Spark version 2.2.0; SparkUI available at http://10.48.225.55:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version devel-63d60cc; NOTE: This is a beta version. Interfaces may change; during the beta period. We also recommend pulling; the latest changes weekly.; Read in PASS SNVs; Filtering Common Variants; [Stage 0:==================================================>(96600 + 1) / 96601]2018-04-27 20:54:43 Hail: INFO: wrote 11341822 items in 96601 partitions; Pruning LD Variants; [Stage 1:==================================================>(96598 + 3) / 96601]2018-04-27 21:19:04 Hail: INFO: Running LD prune with nSamples=4795, nVariants=11341822, nPartitions=96601, and maxQueueSize=429841.; [Stage 2:=========================================> (79823 + 18) / 96601]jav",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3463:2003,error,error,2003,https://hail.is,https://github.com/hail-is/hail/issues/3463,1,['error'],['error']
Availability,"anager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:236); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:305); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:84); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748). Container exited with a non-zero exit code 134; ```; When I dig into the container logs, the stdout is empty on most, stderr is full of warnings, but no errors:; ```; 18/03/02 15:28:07 WARN com.google.cloud.hadoop.gcsio.GoogleCloudStorageReadChannel: Channel for 'gs://gnomad/coverage/hail-0.2/coverage/exomes/parts/part_partition1049.vds/entries/rows/parts/part-0095' is not open.; ```; But then one machine I logged into had:; ```; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x00007fa70eb59074, pid=4361, tid=0x00007fa707702700; #; # JRE version: OpenJDK Runtime Environment (8.0_131-b11) (build 1.8.0_131-8u131-b11-1~bpo8+1-b11); # Java VM: OpenJDK 64-Bit Server VM (25.131-b11 mixed mode linux-amd64 compressed oops); # Problematic frame:; # C [libconscrypt_openjdk_jni.so+0x43074]; [error occurred during error reporting (printing problematic frame), id 0xb]. # Failed to write core dump. Core dumps have been disabled. To enable core dumping, try ""ulimit -c unlimited"" before starting Java again; #; # An error report file with more information is saved as:; # /hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1519994715701_0001/container_1519994715701_0001_01_000558/hs_err_pid4361.log; # [ timer expired, abort... ]; ```; But said log file has no information. The job is finishing, just with a high (~50-100%) task failure rate.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3053:4213,error,error,4213,https://hail.is,https://github.com/hail-is/hail/issues/3053,5,"['error', 'failure']","['error', 'failure']"
Availability,"and feature requests, please use the discussion forum: ; https://discuss.hail.is/. Please include the full Hail version and as much detail as possible. -----------------------------------------------------------------------------; Versions of software products:. Running on Apache Spark version 2.4.5; SparkUI available at http://vhabosgen72:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.2.61-3c86d3ba497a; LOGGING: writing to /dacs1/team/vhabhsxum/tasks/ancestryPainting/hail-20210125-1235-0.2.61-3c86d3ba497a.log. I am running the GWAS tutorial hosted at https://hail.is/docs/0.2/tutorials/01-genome-wide-association-study.html#Let's-do-a-GWAS. Everything is OK until the line to do GWAS. The error I have is as follows:. -------------- start of error ------------------; 2021-01-25 12:36:11 Hail: INFO: linear_regression_rows: running on 250 samples for 1 response variable y,; with input variable x, and 1 additional covariate...; ERROR:root:Exception while sending command.; Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 1159, in send_command; raise Py4JNetworkError(""Answer from Java side is empty""); py4j.protocol.Py4JNetworkError: Answer from Java side is empty. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 985, in send_command; response = connection.send_command(command); File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 1164, in send_command; ""Error while receiving"", e, proto.ERROR_ON_RECEIVE); py4j.protocol.Py4JNetworkError: Error while receiving; ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:44859); Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/9939:1042,ERROR,ERROR,1042,https://hail.is,https://github.com/hail-is/hail/issues/9939,1,['ERROR'],['ERROR']
Availability,annotate_rows failure,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5147:14,failure,failure,14,https://hail.is,https://github.com/hail-is/hail/issues/5147,1,['failure'],['failure']
Availability,anonfun$apply$22.apply(ContextRDD.scala:308); 	at is.hail.sparkextras.ContextRDD$$anonfun$run$1$$anonfun$apply$5.apply(ContextRDD.scala:139); 	at is.hail.sparkextras.ContextRDD$$anonfun$run$1$$anonfun$apply$5.apply(ContextRDD.scala:139); 	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440); 	at scala.collection.Iterator$class.foreach(Iterator.scala:893); 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); 	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59); 	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104); 	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48); 	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310); 	at scala.collection.AbstractIterator.to(Iterator.scala:1336); 	at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302); 	at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1336); 	at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289); 	at scala.collection.AbstractIterator.toArray(Iterator.scala:1336); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:936); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:936); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Hail version: devel-c8ca698; Error summary: NegativeArraySizeException: null,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3583:15798,Error,Error,15798,https://hail.is,https://github.com/hail-is/hail/issues/3583,1,['Error'],['Error']
Availability,"api server bits into CI (maybe should be prioritized earlier...I prefer to get draft of major functions done first; am new to writing tests for React/Node). ## Near-term goals (<= 6 mo); 1. Upload, download; 2. Launch clusters, pay for them; 3. ?. ## Longer-term goals; 1. Much simpler interface to Hail. I would like steps that can be performed without programming to be done so. I would prefer fasta->variant filtering to be done as in Bystro (at least from the interface standpoint), i.e without opening up a notebook. Common analyses pipelines should also be possible without any interaction with a python notebook: GWAS, rare-variant (SKAT) analyses have, it seems, relatively few permutations. Those should be behind UI primitives. At each stage of a ; 2. Social network bits: users should be able to share job state with other users (requested by Bystro users on 22q consortium project) at the least.; 3. Record job state using something like Merkle tree. Checkout state. Aka ""blockchain""; 4. Cooperative analysis: provide system for people to validate analyses; ; Basic idea: . 1) People donate computational resources for ad-hoc heterogenous clusters. ; 2) People donate intellectual capital. Re-run analyses without the full available code. See if they can replicate (not p-values, but order). Could generate multiple-hypothesis-test corrected aggregate. These users get publication credit as consortia; 3) People donate minor intellectual capital: Re-run analysis with full available code. Report on success. This will catch bugs, and non-deterministic results (for instance, if reported accuracy depends on local minima..similar or better minima may only occur once in a great while). Similar to 2. ## Timetables; 1-3a: 12/10/18; 3b: by 12/15/18; 4a-4b: by 12/12/18; 4c-d: by 12/15/18. This probably shouldn't be merged for a while. Still working on authentication handling for third party APIs. All first party APIs (our stuff) is well controlled, can be extended from existing codebase.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4931:9045,avail,available,9045,https://hail.is,https://github.com/hail-is/hail/pull/4931,2,['avail'],['available']
Availability,application/octet-stream 2023-06-09T12:44:22+00:00; batch/logs/we5a79QlczzdluUx8kT2Vh/batch/1148/2/31Owgv/status.json BlockBlob Hot 4453 application/octet-stream 2023-06-09T12:44:22+00:00; batch/logs/we5a79QlczzdluUx8kT2Vh/batch/1148/bunch/dK3o5ZfXmYSkP5TA/specs BlockBlob Hot 1264 application/octet-stream 2023-06-09T12:43:37+00:00; batch/logs/we5a79QlczzdluUx8kT2Vh/batch/1148/bunch/dK3o5ZfXmYSkP5TA/specs.idx BlockBlob Hot 16 application/octet-stream 2023-06-09T12:43:37+00:00; batch/logs/we5a79QlczzdluUx8kT2Vh/batch/1148/bunch/eOrFpVrN98GBIizi/specs BlockBlob Hot 1264 application/octet-stream 2023-06-09T12:43:34+00:00; batch/logs/we5a79QlczzdluUx8kT2Vh/batch/1148/bunch/eOrFpVrN98GBIizi/specs.idx BlockBlob Hot 16 application/octet-stream 2023-06-09T12:43:34+00:00; ```. I looked at the status:. ```; az storage blob download --account-name haildevtest --container test --name batch/logs/we5a79QlczzdluUx8kT2Vh/batch/1148/2/31Owgv/status.json | jq '.' | less; ```. which contained an error (I un-escaped the string here):. ```; JVMUserError: java.util.concurrent.ExecutionException: java.lang.RuntimeException: java.lang.reflect.InvocationTargetException; 	at java.util.concurrent.FutureTask.report(FutureTask.java:122); 	at java.util.concurrent.FutureTask.get(FutureTask.java:192); 	at is.hail.JVMEntryway.retrieveException(JVMEntryway.java:253); 	at is.hail.JVMEntryway.finishFutures(JVMEntryway.java:215); 	at is.hail.JVMEntryway.main(JVMEntryway.java:185); Caused by: java.lang.RuntimeException: java.lang.reflect.InvocationTargetException; 	at is.hail.JVMEntryway$1.run(JVMEntryway.java:122); 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadP,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13160:3663,error,error,3663,https://hail.is,https://github.com/hail-is/hail/pull/13160,1,['error'],['error']
Availability,"apt) from 1.13.3 to 1.14.1.; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/GrahamDumpleton/wrapt/blob/develop/docs/changes.rst"">wrapt's changelog</a>.</em></p>; <blockquote>; <h2>Version 1.14.1</h2>; <p><strong>Bugs Fixed</strong></p>; <ul>; <li>When the post import hooks mechanism was being used, and a Python package with; its own custom module importer was used, importing modules could fail if the; custom module importer didn't use the latest Python import hook finder/loader; APIs and instead used the deprecated API. This was actually occurring with the; <code>zipimporter</code> in Python itself, which was not updated to use the newer Python; APIs until Python 3.10.</li>; </ul>; <h2>Version 1.14.0</h2>; <p><strong>Bugs Fixed</strong></p>; <ul>; <li>; <p>Python 3.11 dropped <code>inspect.formatargspec()</code> which was used in creating; signature changing decorators. Now bundling a version of this function; which uses <code>Parameter</code> and <code>Signature</code> from <code>inspect</code> module when; available. The replacement function is exposed as <code>wrapt.formatargspec()</code>; if need it for your own code.</p>; </li>; <li>; <p>When using a decorator on a class, <code>isinstance()</code> checks wouldn't previously; work as expected and you had to manually use <code>Type.__wrapped__</code> to access; the real type when doing instance checks. The <code>__instancecheck__</code> hook is; now implemented such that you don't have to use <code>Type.__wrapped__</code> instead; of <code>Type</code> as last argument to <code>isinstance()</code>.</p>; </li>; <li>; <p>Eliminated deprecation warnings related to Python module import system, which; would have turned into broken code in Python 3.12. This was used by the post; import hook mechanism.</p>; </li>; </ul>; <p><strong>New Features</strong></p>; <ul>; <li>Binary wheels provided on PyPi for <code>aarch64</code> Linux systems and macOS; native silicon where supported b",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12102:1117,avail,available,1117,https://hail.is,https://github.com/hail-is/hail/pull/12102,1,['avail'],['available']
Availability,"arch` without a `config` argument works fine.; ```python; hl.export_elasticsearch(table, ""host"", 9200, ""someindex"", ""sometype"", 1000, config=None); ```. However, attempting to pass `config`, for example:; ```python; es_config = {""es.write.operation"": ""index""}; hl.export_elasticsearch(table, ""host"", 9200, ""someindex"", ""sometype"", 1000, config=es_config); ```; causes the following error:. ### What went wrong (all error messages here, including the full java stack trace):. ```; Traceback (most recent call last):; File ""/tmp/0ba8fc2c770d4b2ba96dc23c50fd6eab/load_clinvar_to_es.py"", line 105, in <module>; verbose=True,; File ""/tmp/0ba8fc2c770d4b2ba96dc23c50fd6eab/hail_v02_scripts.zip/hail_v02_scripts/utils/elasticsearch/client.py"", line 234, in export_table_to_elasticsearch; File ""/home/hail/hail.zip/hail/typecheck/check.py"", line 547, in wrapper; File ""/home/hail/hail.zip/hail/methods/impex.py"", line 1885, in export_elasticsearch; File ""/usr/lib/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py"", line 1133, in __call__; File ""/home/hail/hail.zip/hail/utils/java.py"", line 188, in deco; File ""/usr/lib/spark/python/lib/py4j-0.10.4-src.zip/py4j/protocol.py"", line 323, in get_return_value; py4j.protocol.Py4JError: An error occurred while calling z:is.hail.io.ElasticsearchConnector.export. Trace:; py4j.Py4JException: Method export([class is.hail.table.Table, class java.lang.String, class java.lang.Integer, class java.lang.String, class java.lang.String, class java.lang.Integer, class java.util.HashMap, class java.lang.Boolean]) does not exist; 	at py4j.reflection.ReflectionEngine.getMethod(ReflectionEngine.java:318); 	at py4j.reflection.ReflectionEngine.getMethod(ReflectionEngine.java:339); 	at py4j.Gateway.invoke(Gateway.java:274); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:214); 	at java.lang.Thread.run(Thread.java:748); ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4063:1553,error,error,1553,https://hail.is,https://github.com/hail-is/hail/issues/4063,1,['error'],['error']
Availability,"ark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324) at org.apache.spark.rdd.RDD.iterator(RDD.scala:288) at org.apache.sparkapache.spark.rdd.RDD.iterator(RDD.scala:288) at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52) at org.apache.sparkitionsRDD.compute(MapPartitionsRDD.scala:52) at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324) at org.apache.spark.rdd.RDDputeOrReadCheckpoint(RDD.scala:324) at org.apache.spark.rdd.RDD.iterator(RDD.scala:288) at org.apache.spark.rdd.MapPartitionsRDD.compute(MaD.scala:288) at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52) at org.apache.spark.rdd.RDD.computeOrReadCheckpointla:90) at org.apache.spark.scheduler.Task.run(Task.scala:121) at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:4cala:414) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) at java.util.concurrent.ThreadPoolExecutor$ailureException: Failure while fetching StreamChunkId{streamId=830947795015, chunkIndex=0}: java.nio.file.NoSuchFileException: /data03/hadoop/yarn/t sun.nio.fs.UnixException.translateToIOException(UnixException.java:86) at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.javannel(UnixFileSystemProvider.java:214) at java.nio.file.Files.newByteChannel(Files.java:361) at java.nio.file.Files.newByteChannel(Files.java:40rage.BlockManager.getBlockData(BlockManager.scala:382) at org.apache.spark.network.netty.NettyBlockRpcServer$$anonfun$1.apply(NettyBlockRpcServer.rator$$anon$11.next(Iterator.scala:410) at scala.collection.convert.Wrappers$IteratorWrapper.next(Wrappers.scala:31) at org.apache.sparkler.processFetchRequest(TransportRequestHandler.java:130) at org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHetty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362) at io.netty.channel.AbstractChannelHandlerCactChannelHandlerContext.java:340) at io.n",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8106:7424,Failure,Failure,7424,https://hail.is,https://github.com/hail-is/hail/issues/8106,1,['Failure'],['Failure']
Availability,"ark.rdd.ZippedPartitionsBaseRDD.getPartitions(ZippedPartitionsRDD.scala:57); 	 at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:248); 	 at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:246); 	 at scala.Option.getOrElse(Option.scala:121); 	 at org.apache.spark.rdd.RDD.partitions(RDD.scala:246); 	 at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35); 	 at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:248); 	 at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:246); 	 at scala.Option.getOrElse(Option.scala:121); 	 at org.apache.spark.rdd.RDD.partitions(RDD.scala:246); 	 at is.hail.sparkextras.OrderedRDD$.coerce(OrderedRDD.scala:58); 	 at is.hail.sparkextras.OrderedRDD$.apply(OrderedRDD.scala:48); 	 at is.hail.utils.richUtils.RichPairRDD$.toOrderedRDD$extension1(RichPairRDD.scala:44); 	 at is.hail.variant.MatrixTable$.fromLegacy(MatrixTable.scala:84); 	 at is.hail.variant.MatrixTable.copyLegacy(MatrixTable.scala:2019); 	 at is.hail.methods.VEP$.annotate(VEP.scala:407); 	 at is.hail.methods.VEP$.apply(VEP.scala:412); 	 at is.hail.methods.VEP.apply(VEP.scala); 	 at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	 at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	 at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	 at java.lang.reflect.Method.invoke(Method.java:498); 	 at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237); 	 at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	 at py4j.Gateway.invoke(Gateway.java:280); 	 at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	 at py4j.commands.CallCommand.execute(CallCommand.java:79); 	 at py4j.GatewayConnection.run(GatewayConnection.java:214); 	 at java.lang.Thread.run(Thread.java:748); Hail version: devel-6191d4c; Error summary: Can't zip RDDs with unequal numbers of partitions: List(16979, 16992)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2666:2799,Error,Error,2799,https://hail.is,https://github.com/hail-is/hail/issues/2666,1,['Error'],['Error']
Availability,"ark_backend('to_pandas').to_pandas(self, flatten); 2706 ; 2707 @staticmethod. ~/anaconda3/lib/python3.6/site-packages/hail/backend/backend.py in to_pandas(self, t, flatten); 66 ; 67 def to_pandas(self, t, flatten):; ---> 68 return self.to_spark(t, flatten).toPandas(); 69 ; 70 def from_pandas(self, df, key):. ~/anaconda3/lib/python3.6/site-packages/hail/backend/backend.py in to_spark(self, t, flatten); 63 if flatten:; 64 t = t.flatten(); ---> 65 return pyspark.sql.DataFrame(t._jt.toDF(Env.hc()._jsql_context), Env.sql_context()); 66 ; 67 def to_pandas(self, t, flatten):. ~/anaconda3/lib/python3.6/site-packages/py4j/java_gateway.py in __call__(self, *args); 1255 answer = self.gateway_client.send_command(command); 1256 return_value = get_return_value(; -> 1257 answer, self.gateway_client, self.target_id, self.name); 1258 ; 1259 for temp_arg in temp_args:. ~/anaconda3/lib/python3.6/site-packages/hail/utils/java.py in deco(*args, **kwargs); 225 raise FatalError('%s\n\nJava stack trace:\n%s\n'; 226 'Hail version: %s\n'; --> 227 'Error summary: %s' % (deepest, full, hail.__version__, deepest)) from None; 228 except pyspark.sql.utils.CapturedException as e:; 229 raise FatalError('%s\n\nJava stack trace:\n%s\n'. FatalError: AssertionError: assertion failed: type mismatch:; name: global; actual: Struct{bn:Struct{n_populations:Int32,n_samples:Int32,n_variants:Int32,n_partitions:Int32,pop_dist:Array[Int32],fst:Array[Float64],mixture:Boolean},__uid_882:Array[Struct{sample_idx:Int32,pop:Int32,s:String}]}; expect: Struct{bn:Struct{n_populations:Int32,n_samples:Int32,n_variants:Int32,n_partitions:Int32,pop_dist:Array[Int32],fst:Array[Float64],mixture:Boolean},__cols:Array[Struct{sample_idx:Int32,pop:Int32,s:String}]}. Java stack trace:; is.hail.utils.HailException: Error while typechecking IR:; (MakeStruct; (bn; (GetField bn; (Ref global)))); 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:11); 	at is.hail.utils.package$.fatal(package.scala:26); 	at is.hail.expr.ir.T",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5212:2415,Error,Error,2415,https://hail.is,https://github.com/hail-is/hail/issues/5212,1,['Error'],['Error']
Availability,"array of const class simdpp::arch_avx2::float32<4>; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/types.h:23,; from libsimdpp-2.0-rc2/simdpp/core/align.h:15,; from libsimdpp-2.0-rc2/simdpp/simd.h:22,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/types/int32x4.h:104:7: note: class simdpp::arch_avx2::uint32<4> declared here; class uint32<4, void> : public any_int32<4, uint32<4,void>> {; ^~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/simd.h:132,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl: In instantiation of R simdpp::arch_avx2::detail::cast_memcpy(const T&) [with R = simdpp::arch_avx2::uint32<4>; T = simdpp::arch_avx2::float64<2>]:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::arch_avx2::uint32<4>; T = simdpp::arch_avx2::float64<2>; unsigned int MaskCastOverride = 0]; libsimdpp-2.0-rc2/simdpp/core/cast.h:63:89: required from R simdpp::arch_avx2::bit_cast(const T&) [with R = simdpp::arch_avx2::uint32<4>; T = simdpp::arch_avx2::float64<2>]; libsimdpp-2.0-rc2/simdpp/types/int32x4.h:129:36: required from simdpp::arch_avx2::uint32<4>::uint32(const simdpp::arch_avx2::any_vec<16, V>&) [with V = simdpp::arch_avx2::float64<2>]; libsimdpp-2.0-rc2/simdpp/detail/insn/test_bits.h:73:39: required from here; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:40:13: error: void* memcpy(void*, const void*, size_t) copying an object of type class simdpp::arch_avx2::uint32<4> with private member simdpp::arch_avx2::uint32<4>::d_ from an array of const class simdpp::arch_avx2::float64<2>; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3955:94075,Mask,MaskCastOverride,94075,https://hail.is,https://github.com/hail-is/hail/issues/3955,2,['Mask'],['MaskCastOverride']
Availability,"array of const class simdpp::arch_avx2::float64<2>; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/types.h:23,; from libsimdpp-2.0-rc2/simdpp/core/align.h:15,; from libsimdpp-2.0-rc2/simdpp/simd.h:22,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/types/int32x4.h:104:7: note: class simdpp::arch_avx2::uint32<4> declared here; class uint32<4, void> : public any_int32<4, uint32<4,void>> {; ^~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/simd.h:132,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl: In instantiation of R simdpp::arch_avx2::detail::cast_memcpy(const T&) [with R = simdpp::arch_avx2::uint64<8>; T = simdpp::arch_avx2::uint32<16>]:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::arch_avx2::uint64<8>; T = simdpp::arch_avx2::uint32<16>; unsigned int MaskCastOverride = 0]; libsimdpp-2.0-rc2/simdpp/core/cast.h:63:89: required from R simdpp::arch_avx2::bit_cast(const T&) [with R = simdpp::arch_avx2::uint64<8>; T = simdpp::arch_avx2::uint32<16>]; libsimdpp-2.0-rc2/simdpp/types/int64.h:106:36: required from simdpp::arch_avx2::uint64<N>& simdpp::arch_avx2::uint64<N>::operator=(const simdpp::arch_avx2::any_vec<(N * 8), V>&) [with V = simdpp::arch_avx2::uint32<16, simdpp::arch_avx2::expr_empty>; unsigned int N = 8]; libsimdpp-2.0-rc2/simdpp/detail/insn/transpose.h:590:8: required from void simdpp::arch_avx2::detail::insn::v_sse_transpose32x4(V&, V&, V&, V&) [with V = simdpp::arch_avx2::uint32<16>; D = simdpp::arch_avx2::uint64<8>]; libsimdpp-2.0-rc2/simdpp/detail/insn/transpose.h:533:62: required from here; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:40:13: error: void* memcpy(void*, const void*, size_t) copying an object of type class simdpp::ar",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3955:95851,Mask,MaskCastOverride,95851,https://hail.is,https://github.com/hail-is/hail/issues/3955,2,['Mask'],['MaskCastOverride']
Availability,"array of const class simdpp::arch_avx2::uint64<4>; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/types.h:24,; from libsimdpp-2.0-rc2/simdpp/core/align.h:15,; from libsimdpp-2.0-rc2/simdpp/simd.h:22,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/types/int32x8.h:91:7: note: class simdpp::arch_avx2::uint32<8> declared here; class uint32<8, void> : public any_int32<8, uint32<8,void>> {; ^~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/simd.h:132,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl: In instantiation of R simdpp::arch_avx2::detail::cast_memcpy(const T&) [with R = simdpp::arch_avx2::float64<4>; T = simdpp::arch_avx2::float32<8>]:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::arch_avx2::float64<4>; T = simdpp::arch_avx2::float32<8>; unsigned int MaskCastOverride = 0]; libsimdpp-2.0-rc2/simdpp/core/cast.h:63:89: required from R simdpp::arch_avx2::bit_cast(const T&) [with R = simdpp::arch_avx2::float64<4>; T = simdpp::arch_avx2::float32<8>]; libsimdpp-2.0-rc2/simdpp/types/float64x4.h:55:37: required from simdpp::arch_avx2::float64<4>& simdpp::arch_avx2::float64<4>::operator=(const simdpp::arch_avx2::any_vec<32, V>&) [with V = simdpp::arch_avx2::float32<8, simdpp::arch_avx2::expr_empty>]; libsimdpp-2.0-rc2/simdpp/detail/insn/transpose.h:275:24: required from here; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:40:13: error: void* memcpy(void*, const void*, size_t) copying an object of type class simdpp::arch_avx2::float64<4> with private member simdpp::arch_avx2::float64<4>::d_ from an array of const class simdpp::arch_avx2::float32<8>; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3955:46739,Mask,MaskCastOverride,46739,https://hail.is,https://github.com/hail-is/hail/issues/3955,2,['Mask'],['MaskCastOverride']
Availability,"as automatically created by Snyk using the credentials of a real user.</p><br /><h3>Snyk has created this PR to fix one or more vulnerable packages in the `pip` dependencies of this project.</h3>. #### Changes included in this PR. - Changes to the following files to upgrade the vulnerable dependencies to a fixed version:; - gear/pinned-requirements.txt. <details>; <summary> <b>Warning</b></summary>. ```; aiosignal 1.3.1 requires frozenlist, which is not installed.; aiohttp 3.8.5 requires frozenlist, which is not installed. ```; </details>. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **496/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 4.2 | Information Exposure Through Sent Data <br/>[SNYK-PYTHON-URLLIB3-6002459](https://snyk.io/vuln/SNYK-PYTHON-URLLIB3-6002459) | `urllib3:` <br> `1.26.17 -> 1.26.18` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiIxNGQyZDIxMi00ZjI4LTQ0OGEtYWRkNS02NThkNDE",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13847:1045,avail,available,1045,https://hail.is,https://github.com/hail-is/hail/pull/13847,1,['avail'],['available']
Availability,"as automatically created by Snyk using the credentials of a real user.</p><br /><h3>Snyk has created this PR to fix one or more vulnerable packages in the `pip` dependencies of this project.</h3>. #### Changes included in this PR. - Changes to the following files to upgrade the vulnerable dependencies to a fixed version:; - gear/pinned-requirements.txt. <details>; <summary> <b>Warning</b></summary>. ```; aiosignal 1.3.1 requires frozenlist, which is not installed.; aiohttp 3.8.5 requires frozenlist, which is not installed. ```; </details>. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **581/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 5.9 | Information Exposure Through Sent Data <br/>[SNYK-PYTHON-URLLIB3-5926907](https://snyk.io/vuln/SNYK-PYTHON-URLLIB3-5926907) | `urllib3:` <br> `1.26.16 -> 1.26.17` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI4MmZhNTRjZC0yOGI4LTQ3OTUtYWFjNy02MDE0NjY",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13771:1045,avail,available,1045,https://hail.is,https://github.com/hail-is/hail/pull/13771,1,['avail'],['available']
Availability,"aset['reference_genome'] == reference_genome])]; --> 115 assert len(path) == 1; 116 path = path[0]; 117 if path.startswith('s3://'):. AssertionError: ; ```. I'm a new Hail user and don't have the full context here, but it seems like there are at least three problems:. 1. An assert failed in production code, which indicates either the presence of a bug or an incorrect use of assert (e.g. using assert to check for value errors).; 2. The assert has no corresponding error message, so the user learns that something has gone wrong but can't easily tell what.; 3. The assert is bare. Bare asserts can get optimized out of code in ways that are difficult to foresee in advance, and are generally deprecated in favor of the `if error_condition: raise AssertionError(...)` pattern (see: https://discuss.python.org/t/stop-ignoring-asserts-when-running-in-optimized-mode/13132). **The Big Picture**. The bare assert pattern is used over 3k times in Hail. To be fair, many of these usages occur in test directories, where they're fine. But they also occur in application code, and often in the dangerous form `assert(expr1, expr2)` which will never fail (because a tuple with two falsy elements is truthy in python). These asserts are never actually getting checked. . Fixing all of them would be a heavy lift. One compromise solution might be to add a bare assert rule to the linter (e.g. https://pypi.org/project/flake8-assert-msg/). This would prevent the introduction of further bare asserts to the codebase, and encourage authors to clean up existing bare asserts on files they touch. The `assert` keyword is an unfortunate language wart that makes it very easy for developers to write error-checking code that is itself incorrect. I'd encourage considering the alternate pattern `if error_condition: raise AssertionError(...)` and gradually migrating the codebase off of bare asserts. Thanks for all of your work on Hail!. ### Version. hail 0.2.115-10932c754edb. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12952:2519,error,error-checking,2519,https://hail.is,https://github.com/hail-is/hail/issues/12952,1,['error'],['error-checking']
Availability,"assLoader. That's why ClassLoaders always prefer to load a class from the parent ClassLoader's; classes. When we decide to re-use JVMs or use a single multi-threaded JVM, we'll need to ensure the top-level; ClassLoader *does not have Hail on its classpath*. I looked briefly at this approach and found it; more work than the current approach. ---. My apologies for eliminating JVMProcess in this PR. It's an unrelated change which facilitated my; understanding worker.py. I essentially inlined JVMProcess into JVMJob and eliminated any duplicative; code. ---. After making this change I restored the tests. Some tests had bitrotted. In the process of fixing; those tests, I found a few other bugs. Fixing these lower-level bugs unlocked a number of new; tests. A couple tests (which were added since the service tests were removed) had to be marked as; failing. Here are the bugs I fixed:. 1. Correct the error message raised when tests are run in a non-main thread (we look for this; message and start an event loop for Hail's async code because asyncio refuses to start an event; loop in a non-main thread). 2. Use a `SafeRow` to copy the globals data out of a Region and into durable, GC'ed objects. 3. Re-enable serialization of GoogleStorageFS (including its private key, which we really shouldn't; do; Tim is working on it), which was broken (presumably) when we changed Scala versions. The; `var` modifier ensures the name is compiled as a JVM field. 4. Correctly convert from a `Byte` to an `Int`. By default `Byte` to `Int` conversion (which is done; automatically when you return a `Byte` from a function whose return type is `Int`) is; sign-preserving. That means that the byte `0000 1111` is converted to the `Int` 15 and the byte; `1000 1111` is converted to the `Int` -113. The contract of; [`InputStream.read`](https://docs.oracle.com/javase/8/docs/api/java/io/InputStream.html#read--); is to return the unsigned integeral value of the next `Byte` or `-1` if we've reached the end of; t",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10390:1701,error,error,1701,https://hail.is,https://github.com/hail-is/hail/pull/10390,1,['error'],['error']
Availability,assertion error near the end of writing out a VDS to bucket,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1822:10,error,error,10,https://hail.is,https://github.com/hail-is/hail/issues/1822,1,['error'],['error']
Availability,assertion failed error when using concordance,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2743:17,error,error,17,https://hail.is,https://github.com/hail-is/hail/issues/2743,1,['error'],['error']
Availability,"ast):; File ""/restricted/projectnb/genpro/github/hail.qc/delly-qc.py"", line 35, in <module>; ds = hl.sample_qc(ds); File ""<decorator-gen-902>"", line 2, in sample_qc; File ""/restricted/projectnb/genpro/github/hail/python/hail/typecheck/check.py"", line 490, in _typecheck; return __orig_func__(*args_, **kwargs_); File ""/restricted/projectnb/genpro/github/hail/python/hail/methods/qc.py"", line 91, in sample_qc; return MatrixTable(Env.hail().methods.SampleQC.apply(require_biallelic(dataset, 'sample_qc')._jvds, name)); File ""/share/pkg/spark/2.2.0/install/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py"", line 1133, in __call__; File ""/restricted/projectnb/genpro/github/hail/python/hail/utils/java.py"", line 196, in deco; 'Error summary: %s' % (deepest, full, hail.__version__, deepest)) from None; hail.utils.java.FatalError: HailException: invalid allele ""<DEL>"". Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 2 in stage 3.0 failed 4 times, most recent failure: Lost task 2.3 in stage 3.0 (TID 160, scc-q01.scc.bu.edu, executor 4): is.hail.utils.HailException: invalid allele ""<DEL>""; at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:6); at is.hail.utils.package$.fatal(package.scala:26); at is.hail.variant.AltAlleleMethods$.validate(AltAlleleMethods.scala:24); at is.hail.variant.AltAlleleMethods$.altAlleleType(AltAlleleMethods.scala:29); at is.hail.methods.SampleQCCombiner$.alleleIndices(SampleQC.scala:44); at is.hail.methods.SampleQC$$anonfun$results$1$$anonfun$apply$1.apply(SampleQC.scala:178); at is.hail.methods.SampleQC$$anonfun$results$1$$anonfun$apply$1.apply(SampleQC.scala:175); at scala.collection.Iterator$class.foreach(Iterator.scala:893); at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); at is.hail.methods.SampleQC$$anonfun$results$1.apply(SampleQC.scala:175); at is.hail.methods.SampleQC$$anonfun$results$1.apply(SampleQC.scala:170); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3413:1569,failure,failure,1569,https://hail.is,https://github.com/hail-is/hail/issues/3413,1,['failure'],['failure']
Availability,"astOverride>::run(const T&) [with R = simdpp::arch_avx2::int32<8>; T = simdpp::arch_avx2::uint64<4>; unsigned int MaskCastOverride = 0]; libsimdpp-2.0-rc2/simdpp/core/cast.h:63:89: required from R simdpp::arch_avx2::bit_cast(const T&) [with R = simdpp::arch_avx2::int32<8>; T = simdpp::arch_avx2::uint64<4>]; libsimdpp-2.0-rc2/simdpp/types/int32x8.h:55:35: required from simdpp::arch_avx2::int32<8>& simdpp::arch_avx2::int32<8>::operator=(const simdpp::arch_avx2::any_vec<32, V>&) [with V = simdpp::arch_avx2::uint64<4, simdpp::arch_avx2::expr_bit_and<simdpp::arch_avx2::uint64<4, simdpp::arch_avx2::int32<8> >, simdpp::arch_avx2::uint64<4, simdpp::arch_avx2::uint64<4> > > >]; libsimdpp-2.0-rc2/simdpp/detail/insn/i_shift_r.h:305:32: required from here; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:40:13: error: void* memcpy(void*, const void*, size_t) copying an object of type class simdpp::arch_avx2::int32<8> with private member simdpp::arch_avx2::int32<8>::d_ from an array of const class simdpp::arch_avx2::uint64<4>; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/types.h:24,; from libsimdpp-2.0-rc2/simdpp/core/align.h:15,; from libsimdpp-2.0-rc2/simdpp/simd.h:22,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/types/int32x8.h:32:7: note: class simdpp::arch_avx2::int32<8> declared here; class int32<8, void> : public any_int32<8, int32<8,void>> {; ^~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/simd.h:132,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl: In instantiation of R simdpp::arch_avx2::detail::cast_memcpy(const T&) [with R = simdpp::arch_avx2::uint8<16>; T = simdpp::arch_avx2::int8<16>]:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::arch_a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3955:82190,error,error,82190,https://hail.is,https://github.com/hail-is/hail/issues/3955,1,['error'],['error']
Availability,"astOverride>::run(const T&) [with R = simdpp::arch_avx2::int64<2>; T = simdpp::arch_avx2::uint64<2>; unsigned int MaskCastOverride = 0]; libsimdpp-2.0-rc2/simdpp/core/cast.h:63:89: required from R simdpp::arch_avx2::bit_cast(const T&) [with R = simdpp::arch_avx2::int64<2>; T = simdpp::arch_avx2::uint64<2>]; libsimdpp-2.0-rc2/simdpp/types/int64x2.h:60:35: required from simdpp::arch_avx2::int64<2>& simdpp::arch_avx2::int64<2>::operator=(const simdpp::arch_avx2::any_vec<16, V>&) [with V = simdpp::arch_avx2::uint64<2>]; libsimdpp-2.0-rc2/simdpp/types/int64x2.h:53:73: required from simdpp::arch_avx2::int64<2>::int64(const simdpp::arch_avx2::uint64<2, E>&) [with E = void]; libsimdpp-2.0-rc2/simdpp/detail/insn/i_shift_r.h:277:25: required from here; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:40:13: error: void* memcpy(void*, const void*, size_t) copying an object of type class simdpp::arch_avx2::int64<2> with private member simdpp::arch_avx2::int64<2>::d_ from an array of const class simdpp::arch_avx2::uint64<2>; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/types.h:26,; from libsimdpp-2.0-rc2/simdpp/core/align.h:15,; from libsimdpp-2.0-rc2/simdpp/simd.h:22,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/types/int64x2.h:33:7: note: class simdpp::arch_avx2::int64<2> declared here; class int64<2, void> : public any_int64<2, int64<2,void>> {; ^~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/simd.h:132,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl: In instantiation of R simdpp::arch_avx2::detail::cast_memcpy(const T&) [with R = simdpp::arch_avx2::int64<4>; T = simdpp::arch_avx2::uint64<4>]:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::arch_a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3955:108904,error,error,108904,https://hail.is,https://github.com/hail-is/hail/issues/3955,1,['error'],['error']
Availability,"astOverride>::run(const T&) [with R = simdpp::arch_avx2::int64<4>; T = simdpp::arch_avx2::uint64<4>; unsigned int MaskCastOverride = 0]; libsimdpp-2.0-rc2/simdpp/core/cast.h:63:89: required from R simdpp::arch_avx2::bit_cast(const T&) [with R = simdpp::arch_avx2::int64<4>; T = simdpp::arch_avx2::uint64<4>]; libsimdpp-2.0-rc2/simdpp/types/int64x4.h:55:35: required from simdpp::arch_avx2::int64<4>& simdpp::arch_avx2::int64<4>::operator=(const simdpp::arch_avx2::any_vec<32, V>&) [with V = simdpp::arch_avx2::uint64<4>]; libsimdpp-2.0-rc2/simdpp/types/int64x4.h:48:73: required from simdpp::arch_avx2::int64<4>::int64(const simdpp::arch_avx2::uint64<4, E>&) [with E = void]; libsimdpp-2.0-rc2/simdpp/detail/insn/i_shift_r.h:307:25: required from here; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:40:13: error: void* memcpy(void*, const void*, size_t) copying an object of type class simdpp::arch_avx2::int64<4> with private member simdpp::arch_avx2::int64<4>::d_ from an array of const class simdpp::arch_avx2::uint64<4>; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/types.h:27,; from libsimdpp-2.0-rc2/simdpp/core/align.h:15,; from libsimdpp-2.0-rc2/simdpp/simd.h:22,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/types/int64x4.h:32:7: note: class simdpp::arch_avx2::int64<4> declared here; class int64<4, void> : public any_int64<4, int64<4,void>> {; ^~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/simd.h:132,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl: In instantiation of R simdpp::arch_avx2::detail::cast_memcpy(const T&) [with R = simdpp::arch_avx2::uint8<32>; T = simdpp::arch_avx2::int8<32>]:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::arch_a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3955:110852,error,error,110852,https://hail.is,https://github.com/hail-is/hail/issues/3955,1,['error'],['error']
Availability,"at __C2005collect_distributed_array_matrix_native_writer.apply_region1_27(Unknown Source); 	at __C2005collect_distributed_array_matrix_native_writer.apply(Unknown Source); 	at __C2005collect_distributed_array_matrix_native_writer.apply(Unknown Source); 	at is.hail.backend.BackendUtils.$anonfun$collectDArray$6(BackendUtils.scala:52); 	at is.hail.utils.package$.using(package.scala:635); 	at is.hail.annotations.RegionPool.scopedRegion(RegionPool.scala:162); 	at is.hail.backend.BackendUtils.$anonfun$collectDArray$5(BackendUtils.scala:51); 	at is.hail.backend.spark.SparkBackendComputeRDD.compute(SparkBackend.scala:751); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:329); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90); 	at org.apache.spark.scheduler.Task.run(Task.scala:136); 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548); 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551); 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128); 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628); 	at java.base/java.lang.Thread.run(Thread.java:829). is.hail.utils.HailException: cannot set missing field for required type +PCString; ```. Notice in particular:; ```; AS_VQSLOD=.,.;AS_YNG=.,.; ```; These fields are array fields containing missing values. By default, Hail errors when parsing these due to the inherent ambiguity of a single dot: is it a missing array or an array with one, missing, element. The error message should suggest that the user try using array_elements_required. The docs for `import_vcf` should provide enough information for the user to understand what this does. We should also consider making this the default. ### Version. 0.2.120. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13346:2871,error,errors,2871,https://hail.is,https://github.com/hail-is/hail/issues/13346,2,['error'],"['error', 'errors']"
Availability,"at is.hail.annotations.Region$.scoped(Region.scala:18); 	at is.hail.expr.ir.ExecuteContext$.scoped(ExecuteContext.scala:9); 	at is.hail.backend.Backend.execute(Backend.scala:56); 	at is.hail.backend.Backend.executeJSON(Backend.scala:62); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:282); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:238); 	at java.lang.Thread.run(Thread.java:745). org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 3.0 failed 1 times, most recent failure: Lost task 0.0 in stage 3.0 (TID 3, localhost, executor driver): is.hail.utils.HailException: Hail only supports 8-bit probabilities, found 16.; 	at is.hail.codegen.generated.C_bgen_rdd_decoder_13.apply(Unknown Source); 	at is.hail.codegen.generated.C_bgen_rdd_decoder_13.apply(Unknown Source); 	at is.hail.io.bgen.BgenRecordIteratorWithoutFilter.next(BgenRDD.scala:222); 	at is.hail.io.bgen.BgenRecordIteratorWithoutFilter.next(BgenRDD.scala:206); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:410); 	at scala.collection.TraversableOnce$FlattenOps$$anon$1.hasNext(TraversableOnce.scala:464); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:439); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:439); 	at scala.collection.Iterator$class.foreach(Iterator.scala:891); 	at scala.collection.AbstractIterator.foreach(Iterato",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8545:4093,failure,failure,4093,https://hail.is,https://github.com/hail-is/hail/issues/8545,1,['failure'],['failure']
Availability,"at is.hail.annotations.Region$.scoped(Region.scala:18); 	at is.hail.expr.ir.ExecuteContext$.scoped(ExecuteContext.scala:9); 	at is.hail.backend.Backend.execute(Backend.scala:77); 	at is.hail.backend.Backend.executeJSON(Backend.scala:96); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:282); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:238); 	at java.lang.Thread.run(Thread.java:748). org.apache.spark.SparkException: Job aborted due to stage failure: Task 40 in stage 7.0 failed 20 times, most recent failure: Lost task 40.19 in stage 7.0 (TID 3171, seqr-loading-cluster-sw-z91p.c.seqr-project.internal, executor 14): is.hail.utils.HailException: cannot set missing field for required type +PCStruct{info:PCStruct{ALLELEID:PInt32}}; 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:9); 	at is.hail.utils.package$.fatal(package.scala:74); 	at is.hail.annotations.RegionValueBuilder.setMissing(RegionValueBuilder.scala:210); 	at is.hail.rvd.RVD$$anonfun$24$$anonfun$apply$17.apply(RVD.scala:974); 	at is.hail.rvd.RVD$$anonfun$24$$anonfun$apply$17.apply(RVD.scala:967); 	at is.hail.utils.FlipbookIterator$$anon$5.<init>(FlipbookIterator.scala:176); 	at is.hail.utils.FlipbookIterator.map(FlipbookIterator.scala:174); 	at is.hail.utils.FlipbookIterator.map(FlipbookIterator.scala:145); 	at is.hail.rvd.RVD$$anonfun$24.apply(RVD.scala:967); 	at is.hail.rvd.RVD$$anonfun$24.apply(RVD.scala:963); 	at is.hail.rvd.KeyedRVD$$anonf",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8469:51113,failure,failure,51113,https://hail.is,https://github.com/hail-is/hail/issues/8469,1,['failure'],['failure']
Availability,"at java.lang.reflect.Method.invoke(Method.java:498); 	at is.hail.JVMEntryway$1.run(JVMEntryway.java:119); 	... 7 more; Caused by: is.hail.backend.service.EndOfInputException; 	at is.hail.backend.service.ServiceBackendSocketAPI2.read(ServiceBackend.scala:497); 	at is.hail.backend.service.ServiceBackendSocketAPI2.readInt(ServiceBackend.scala:510); 	at is.hail.backend.service.ServiceBackendSocketAPI2.executeOneCommand(ServiceBackend.scala:561); 	at is.hail.backend.service.ServiceBackendSocketAPI2$.$anonfun$main$6(ServiceBackend.scala:462); 	at is.hail.backend.service.ServiceBackendSocketAPI2$.$anonfun$main$6$adapted(ServiceBackend.scala:461); 	at is.hail.utils.package$.using(package.scala:635); 	at is.hail.backend.service.ServiceBackendSocketAPI2$.$anonfun$main$5(ServiceBackend.scala:461); 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23); 	at is.hail.services.package$.retryTransientErrors(package.scala:141); 	at is.hail.backend.service.ServiceBackendSocketAPI2$.$anonfun$main$4(ServiceBackend.scala:460); 	at is.hail.backend.service.ServiceBackendSocketAPI2$.$anonfun$main$4$adapted(ServiceBackend.scala:459); 	at is.hail.utils.package$.using(package.scala:635); 	at is.hail.backend.service.ServiceBackendSocketAPI2$.$anonfun$main$3(ServiceBackend.scala:459); 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23); 	at is.hail.services.package$.retryTransientErrors(package.scala:141); 	at is.hail.backend.service.ServiceBackendSocketAPI2$.main(ServiceBackend.scala:458); 	at is.hail.backend.service.Main$.main(Main.scala:15); 	at is.hail.backend.service.Main.main(Main.scala); 	... 11 more; ```. Which suggests that the service backend experienced an EOF somewhere in the first four bytes of the input file. Unfortunately, we automatically cleanup the input and output files, so I can't investigate further. This PR reads the input and output files and stores them in the error message so that next time this happens we get more information.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13160:6913,error,error,6913,https://hail.is,https://github.com/hail-is/hail/pull/13160,1,['error'],['error']
Availability,atReceiver$$anonfun$org$apache$spark$HeartbeatReceiver$$expireDeadHosts$3.apply(HeartbeatReceiver.scala:198); at org.apache.spark.HeartbeatReceiver$$anonfun$org$apache$spark$HeartbeatReceiver$$expireDeadHosts$3.apply(HeartbeatReceiver.scala:196); at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733); at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99); at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99); at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230); at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40); at scala.collection.mutable.HashMap.foreach(HashMap.scala:99); at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732); at org.apache.spark.HeartbeatReceiver.org$apache$spark$HeartbeatReceiver$$expireDeadHosts(HeartbeatReceiver.scala:196); at org.apache.spark.HeartbeatReceiver$$anonfun$receiveAndReply$1.applyOrElse(HeartbeatReceiver.scala:119); at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105); at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205); at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101); at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:216); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); java.lang.OutOfMemoryError: GC overhead limit exceeded; at scala.collection.mutable.ListBuffer.$plus$eq(ListBuffer.scala:170); at scala.collection.mutable.ListBuffer.$plus$eq(ListBuffer.scala:45); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.mutable.HashMap$$anon$2$$anonfun$foreach$3.apply(HashMap.scala:108); at scala.colle,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4780:2966,Heartbeat,HeartbeatReceiver,2966,https://hail.is,https://github.com/hail-is/hail/issues/4780,1,['Heartbeat'],['HeartbeatReceiver']
Availability,"atch.py\"", line 580, in mark_complete\n setup_container = pod.status.init_container_statuses[0]\nTypeError: 'NoneType' object is not subscriptable""}; {""levelname"": ""ERROR"", ""asctime"": ""2019-07-22 22:20:42,418"", ""filename"": ""batch.py"", ""funcNameAndLine"": ""kube_event_loop:1273"", ""message"": ""k8s event stream failed due to: 'NoneType' object is not subscriptable"", ""exc_info"": ""Traceback (most recent call last):\n File \""/usr/local/lib/python3.6/dist-packages/batch/batch.py\"", line 1271, in kube_event_loop\n await pod_changed(object)\n File \""/usr/local/lib/python3.6/dist-packages/batch/batch.py\"", line 1256, in pod_changed\n await update_job_with_pod(job, pod)\n File \""/usr/local/lib/python3.6/dist-packages/batch/batch.py\"", line 1234, in update_job_with_pod\n await job.mark_complete(pod)\n File \""/usr/local/lib/python3.6/dist-packages/batch/batch.py\"", line 580, in mark_complete\n setup_container = pod.status.init_container_statuses[0]\nTypeError: 'NoneType' object is not subscriptable""}; {""levelname"": ""ERROR"", ""asctime"": ""2019-07-22 22:20:49,707"", ""filename"": ""batch.py"", ""funcNameAndLine"": ""kube_event_loop:1273"", ""message"": ""k8s event stream failed due to: Object of type 'datetime' is not JSON serializable"", ""exc_info"": ""Traceback (most recent call last):\n File \""/usr/local/lib/python3.6/dist-packages/batch/batch.py\"", line 1271, in kube_event_loop\n await pod_changed(object)\n File \""/usr/local/lib/python3.6/dist-packages/batch/batch.py\"", line 1256, in pod_changed\n await update_job_with_pod(job, pod)\n File \""/usr/local/lib/python3.6/dist-packages/batch/batch.py\"", line 1234, in update_job_with_pod\n await job.mark_complete(pod)\n File \""/usr/local/lib/python3.6/dist-packages/batch/batch.py\"", line 608, in mark_complete\n json.dumps(pod_status.to_dict()))\n File \""/usr/lib/python3.6/json/__init__.py\"", line 231, in dumps\n return _default_encoder.encode(obj)\n File \""/usr/lib/python3.6/json/encoder.py\"", line 199, in encode\n chunks = self.iterencode(o, _one_shot=T",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6707:1722,ERROR,ERROR,1722,https://hail.is,https://github.com/hail-is/hail/issues/6707,1,['ERROR'],['ERROR']
Availability,"atch.py\"", line 580, in mark_complete\n setup_container = pod.status.init_container_statuses[0]\nTypeError: 'NoneType' object is not subscriptable""}; {""levelname"": ""ERROR"", ""asctime"": ""2019-07-22 22:21:41,499"", ""filename"": ""batch.py"", ""funcNameAndLine"": ""kube_event_loop:1273"", ""message"": ""k8s event stream failed due to: 'NoneType' object is not subscriptable"", ""exc_info"": ""Traceback (most recent call last):\n File \""/usr/local/lib/python3.6/dist-packages/batch/batch.py\"", line 1271, in kube_event_loop\n await pod_changed(object)\n File \""/usr/local/lib/python3.6/dist-packages/batch/batch.py\"", line 1256, in pod_changed\n await update_job_with_pod(job, pod)\n File \""/usr/local/lib/python3.6/dist-packages/batch/batch.py\"", line 1234, in update_job_with_pod\n await job.mark_complete(pod)\n File \""/usr/local/lib/python3.6/dist-packages/batch/batch.py\"", line 580, in mark_complete\n setup_container = pod.status.init_container_statuses[0]\nTypeError: 'NoneType' object is not subscriptable""}; {""levelname"": ""ERROR"", ""asctime"": ""2019-07-22 22:22:42,128"", ""filename"": ""batch.py"", ""funcNameAndLine"": ""kube_event_loop:1273"", ""message"": ""k8s event stream failed due to: 'NoneType' object is not subscriptable"", ""exc_info"": ""Traceback (most recent call last):\n File \""/usr/local/lib/python3.6/dist-packages/batch/batch.py\"", line 1271, in kube_event_loop\n await pod_changed(object)\n File \""/usr/local/lib/python3.6/dist-packages/batch/batch.py\"", line 1256, in pod_changed\n await update_job_with_pod(job, pod)\n File \""/usr/local/lib/python3.6/dist-packages/batch/batch.py\"", line 1234, in update_job_with_pod\n await job.mark_complete(pod)\n File \""/usr/local/lib/python3.6/dist-packages/batch/batch.py\"", line 580, in mark_complete\n setup_container = pod.status.init_container_statuses[0]\nTypeError: 'NoneType' object is not subscriptable""}; {""levelname"": ""ERROR"", ""asctime"": ""2019-07-22 22:23:31,398"", ""filename"": ""batch.py"", ""funcNameAndLine"": ""kube_event_loop:1273"", ""message"": ""k8s event",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6707:4685,ERROR,ERROR,4685,https://hail.is,https://github.com/hail-is/hail/issues/6707,1,['ERROR'],['ERROR']
Availability,"atch.py\"", line 580, in mark_complete\n setup_container = pod.status.init_container_statuses[0]\nTypeError: 'NoneType' object is not subscriptable""}; {""levelname"": ""ERROR"", ""asctime"": ""2019-07-22 22:22:42,128"", ""filename"": ""batch.py"", ""funcNameAndLine"": ""kube_event_loop:1273"", ""message"": ""k8s event stream failed due to: 'NoneType' object is not subscriptable"", ""exc_info"": ""Traceback (most recent call last):\n File \""/usr/local/lib/python3.6/dist-packages/batch/batch.py\"", line 1271, in kube_event_loop\n await pod_changed(object)\n File \""/usr/local/lib/python3.6/dist-packages/batch/batch.py\"", line 1256, in pod_changed\n await update_job_with_pod(job, pod)\n File \""/usr/local/lib/python3.6/dist-packages/batch/batch.py\"", line 1234, in update_job_with_pod\n await job.mark_complete(pod)\n File \""/usr/local/lib/python3.6/dist-packages/batch/batch.py\"", line 580, in mark_complete\n setup_container = pod.status.init_container_statuses[0]\nTypeError: 'NoneType' object is not subscriptable""}; {""levelname"": ""ERROR"", ""asctime"": ""2019-07-22 22:23:31,398"", ""filename"": ""batch.py"", ""funcNameAndLine"": ""kube_event_loop:1273"", ""message"": ""k8s event stream failed due to: 'NoneType' object is not subscriptable"", ""exc_info"": ""Traceback (most recent call last):\n File \""/usr/local/lib/python3.6/dist-packages/batch/batch.py\"", line 1271, in kube_event_loop\n await pod_changed(object)\n File \""/usr/local/lib/python3.6/dist-packages/batch/batch.py\"", line 1256, in pod_changed\n await update_job_with_pod(job, pod)\n File \""/usr/local/lib/python3.6/dist-packages/batch/batch.py\"", line 1234, in update_job_with_pod\n await job.mark_complete(pod)\n File \""/usr/local/lib/python3.6/dist-packages/batch/batch.py\"", line 580, in mark_complete\n setup_container = pod.status.init_container_statuses[0]\nTypeError: 'NoneType' object is not subscriptable""}; {""levelname"": ""ERROR"", ""asctime"": ""2019-07-22 22:25:18,329"", ""filename"": ""batch.py"", ""funcNameAndLine"": ""kube_event_loop:1273"", ""message"": ""k8s event",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6707:5536,ERROR,ERROR,5536,https://hail.is,https://github.com/hail-is/hail/issues/6707,1,['ERROR'],['ERROR']
Availability,"atch.py\"", line 580, in mark_complete\n setup_container = pod.status.init_container_statuses[0]\nTypeError: 'NoneType' object is not subscriptable""}; {""levelname"": ""ERROR"", ""asctime"": ""2019-07-22 22:23:31,398"", ""filename"": ""batch.py"", ""funcNameAndLine"": ""kube_event_loop:1273"", ""message"": ""k8s event stream failed due to: 'NoneType' object is not subscriptable"", ""exc_info"": ""Traceback (most recent call last):\n File \""/usr/local/lib/python3.6/dist-packages/batch/batch.py\"", line 1271, in kube_event_loop\n await pod_changed(object)\n File \""/usr/local/lib/python3.6/dist-packages/batch/batch.py\"", line 1256, in pod_changed\n await update_job_with_pod(job, pod)\n File \""/usr/local/lib/python3.6/dist-packages/batch/batch.py\"", line 1234, in update_job_with_pod\n await job.mark_complete(pod)\n File \""/usr/local/lib/python3.6/dist-packages/batch/batch.py\"", line 580, in mark_complete\n setup_container = pod.status.init_container_statuses[0]\nTypeError: 'NoneType' object is not subscriptable""}; {""levelname"": ""ERROR"", ""asctime"": ""2019-07-22 22:25:18,329"", ""filename"": ""batch.py"", ""funcNameAndLine"": ""kube_event_loop:1273"", ""message"": ""k8s event stream failed due to: Object of type 'datetime' is not JSON serializable"", ""exc_info"": ""Traceback (most recent call last):\n File \""/usr/local/lib/python3.6/dist-packages/batch/batch.py\"", line 1271, in kube_event_loop\n await pod_changed(object)\n File \""/usr/local/lib/python3.6/dist-packages/batch/batch.py\"", line 1256, in pod_changed\n await update_job_with_pod(job, pod)\n File \""/usr/local/lib/python3.6/dist-packages/batch/batch.py\"", line 1234, in update_job_with_pod\n await job.mark_complete(pod)\n File \""/usr/local/lib/python3.6/dist-packages/batch/batch.py\"", line 608, in mark_complete\n json.dumps(pod_status.to_dict()))\n File \""/usr/lib/python3.6/json/__init__.py\"", line 231, in dumps\n return _default_encoder.encode(obj)\n File \""/usr/lib/python3.6/json/encoder.py\"", line 199, in encode\n chunks = self.iterencode(o, _one_shot=T",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6707:6387,ERROR,ERROR,6387,https://hail.is,https://github.com/hail-is/hail/issues/6707,1,['ERROR'],['ERROR']
Availability,ate.evaluateToJSON(CompileAndEvaluate.scala); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:282); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:238); 	at java.lang.Thread.run(Thread.java:745). is.hail.utils.HailException: foo: Error parsing row fields in row 0:; expected 5 fields but only 5 found.; File: foo; Line:; 7	75216143	75216143	C/T	+; offending line: 7	75216143	75216143	C/T	+; 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:20); 	at is.hail.utils.package$.fatal(package.scala:28); 	at is.hail.utils.Context.wrapException(Context.scala:19); 	at is.hail.utils.WithContext.wrap(Context.scala:43); 	at is.hail.io.LoadMatrix$$anonfun$16$$anonfun$apply$6.apply(LoadMatrix.scala:377); 	at is.hail.io.LoadMatrix$$anonfun$16$$anonfun$apply$6.apply(LoadMatrix.scala:375); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at scala.collection.Iterator$class.foreach(Iterator.scala:893); 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); 	at is.hail.rvd.RVD$$anonfun$count$2.apply(RVD.scala:575); 	at is.hail.rvd.RVD$$anonfun$count$2.apply(RVD.scala:573); 	at is.hail.sparkextras.ContextRDD$$anonfun$cmapPartitions$1$$anonfun$apply$28.apply(ContextRDD.scala:405); 	at is.hail.sparkextras.ContextRDD$$anonfun$cmapPartitions$1$$anonfun$apply$28.apply(ContextRDD.scala:405); 	at is.hail.sparkextras.ContextRDD$$anonfun$run$1,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5718:10219,Error,ErrorHandling,10219,https://hail.is,https://github.com/hail-is/hail/issues/5718,1,['Error'],['ErrorHandling']
Availability,ate.scala:45); at is.hail.backend.spark.SparkBackend._execute(SparkBackend.scala:600); at is.hail.backend.spark.SparkBackend.$anonfun$execute$4(SparkBackend.scala:636); at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:84); at is.hail.backend.spark.SparkBackend.$anonfun$execute$3(SparkBackend.scala:631); at is.hail.backend.spark.SparkBackend.$anonfun$execute$3$adapted(SparkBackend.scala:630); at is.hail.backend.ExecuteContext$.$anonfun$scoped$3(ExecuteContext.scala:78); at is.hail.utils.package$.using(package.scala:664); at is.hail.backend.ExecuteContext$.$anonfun$scoped$2(ExecuteContext.scala:78); at is.hail.utils.package$.using(package.scala:664); at is.hail.annotations.RegionPool$.scoped(RegionPool.scala:13); at is.hail.backend.ExecuteContext$.scoped(ExecuteContext.scala:65); at is.hail.backend.spark.SparkBackend.$anonfun$withExecuteContext$2(SparkBackend.scala:407); at is.hail.utils.ExecutionTimer$.time(ExecutionTimer.scala:55); at is.hail.utils.ExecutionTimer$.logTime(ExecutionTimer.scala:62); at is.hail.backend.spark.SparkBackend.withExecuteContext(SparkBackend.scala:393); at is.hail.backend.spark.SparkBackend.execute(SparkBackend.scala:630); at is.hail.backend.BackendHttpHandler.handle(BackendServer.scala:88); at com.sun.net.httpserver.Filter$Chain.doFilter(Filter.java:79); at sun.net.httpserver.AuthFilter.doFilter(AuthFilter.java:83); at com.sun.net.httpserver.Filter$Chain.doFilter(Filter.java:82); at sun.net.httpserver.ServerImpl$Exchange$LinkHandler.handle(ServerImpl.java:822); at com.sun.net.httpserver.Filter$Chain.doFilter(Filter.java:79); at sun.net.httpserver.ServerImpl$Exchange.run(ServerImpl.java:794); at sun.net.httpserver.ServerImpl$DefaultExecutor.execute(ServerImpl.java:199); at sun.net.httpserver.ServerImpl$Dispatcher.handle(ServerImpl.java:544); at sun.net.httpserver.ServerImpl$Dispatcher.run(ServerImpl.java:509); at java.lang.Thread.run(Thread.java:750). Hail version: 0.2.127-d82c34a83360; Error summary: NullPointerException: null; ```,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14249:7469,Error,Error,7469,https://hail.is,https://github.com/hail-is/hail/issues/14249,1,['Error'],['Error']
Availability,"ate</code> header in 401 response</li>; <li>Log request and response headers in debug mode</li>; </ul>; <p>Maintenance:</p>; <ul>; <li>Add integration tests for Gradle 7.4.1 and 7.4.2</li>; <li>Update dependencies</li>; </ul>; <h2>5.0.5</h2>; <p>Maintenance:</p>; <ul>; <li>Publish signed artifacts to Gradle plugin portal</li>; <li>Update dependencies</li>; </ul>; <h2>5.0.4</h2>; <p>Bug fixes:</p>; <ul>; <li>Fix deadlock in <code>DownloadExtension</code> if <code>max-workers</code> equals 1 (thanks to <a href=""https://github.com/beatbrot""><code>@beatbrot</code></a> for spotting this, see <a href=""https://github-redirect.dependabot.com/michel-kraemer/gradle-download-task/issues/205"">#205</a>)</li>; </ul>; <p>Maintenance:</p>; <ul>; <li>Update dependencies</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/1b5d69760d19cb7f88cbc837ee46456c494c0696""><code>1b5d697</code></a> Bump up version number to 5.2.1</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/7d6de83037ca41cd2f2f31830b43e43720e45b3a""><code>7d6de83</code></a> Update dependencies</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/1da8f078e22412475b694ce07b890148b8a5e4fc""><code>1da8f07</code></a> Add comment</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/9703f764df56c52626f7d6f44bca8b1d51312389""><code>9703f76</code></a> Use pooling connection manager instead of basic one</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/306172e4c6532e185c8a6a9998bca7d22d2d0c63""><code>306172e</code></a> Bump up version number to 5.2.0</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/b9df0c0daa080450772c365f16a9406fe0ca607a""><code>b9df0c0</code></a> Document eachFile action</li>; <li><a href=""https://github.com/michel",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12332:3048,down,download-task,3048,https://hail.is,https://github.com/hail-is/hail/pull/12332,1,['down'],['download-task']
Availability,"ated by Snyk using the credentials of a real user.</p><br /><h3>Snyk has created this PR to fix one or more vulnerable packages in the `pip` dependencies of this project.</h3>. #### Changes included in this PR. - Changes to the following files to upgrade the vulnerable dependencies to a fixed version:; - gear/requirements.txt. <details>; <summary> <b>Warning</b></summary>. ```; kubernetes-asyncio 19.15.1 requires aiohttp, which is not installed.; aiohttp-session 2.12.0 requires aiohttp, which is not installed. ```; </details>. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **663/1000** <br/> **Why?** Proof of Concept exploit, Recently disclosed, Has a fix available, CVSS 5.4 | Improper Input Validation <br/>[SNYK-PYTHON-AIOHTTP-6091621](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-6091621) | `aiohttp:` <br> `3.8.6 -> 3.9.0` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **663/1000** <br/> **Why?** Proof of Concept exploit, Recently disclosed, Has a fix available, CVSS 5.4 | Improper Input Validation <br/>[SNYK-PYTHON-AIOHTTP-6091622](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-6091622) | `aiohttp:` <br> `3.8.6 -> 3.9.0` <br> | No | Proof of Concept . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14039:1078,avail,available,1078,https://hail.is,https://github.com/hail-is/hail/pull/14039,1,['avail'],['available']
Availability,"ated size 34.3 KiB, free 434.4 MiB); 2022-05-14 12:09:09 MemoryStore: INFO: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.2 KiB, free 434.4 MiB); 2022-05-14 12:09:09 BlockManagerInfo: INFO: Added broadcast_0_piece0 in memory on 10.40.3.21:33951 (size: 3.2 KiB, free: 434.4 MiB); 2022-05-14 12:09:09 SparkContext: INFO: Created broadcast 0 from broadcast at SparkBackend.scala:311; 2022-05-14 12:09:11 root: INFO: RegionPool: FREE: 64.0K allocated (64.0K blocks / 0 chunks), regions.size = 1, 0 current java objects, thread 30: Thread-4; 2022-05-14 12:09:11 root: ERROR: HailException: Invalid locus '11:135009883' found. Position '135009883' is not within the range [1-135006516] for reference genome 'GRCh37'.; From is.hail.utils.HailException: /data/public/prs/ex_antonk.bim:1013423: Invalid locus '11:135009883' found. Position '135009883' is not within the range [1-135006516] for reference genome 'GRCh37'.; offending line: 11	.	0	135009883	CT	C; 	at is.hail.utils.ErrorHandling.fatal(ErrorHandling.scala:30); 	at is.hail.utils.ErrorHandling.fatal$(ErrorHandling.scala:28); 	at is.hail.utils.package$.fatal(package.scala:78); 	at is.hail.utils.Context.wrapException(Context.scala:21); 	at is.hail.utils.WithContext.foreach(Context.scala:51); 	at is.hail.io.plink.LoadPlink$.$anonfun$parseBim$2(LoadPlink.scala:37); 	at is.hail.io.plink.LoadPlink$.$anonfun$parseBim$2$adapted(LoadPlink.scala:36); 	at scala.collection.Iterator.foreach(Iterator.scala:941); 	at scala.collection.Iterator.foreach$(Iterator.scala:941); 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1429); 	at is.hail.io.plink.LoadPlink$.$anonfun$parseBim$1(LoadPlink.scala:36); 	at is.hail.io.plink.LoadPlink$.$anonfun$parseBim$1$adapted(LoadPlink.scala:35); 	at is.hail.io.fs.FS.$anonfun$readLines$1(FS.scala:222); 	at is.hail.utils.package$.using(package.scala:640); 	at is.hail.io.fs.FS.readLines(FS.scala:213); 	at is.hail.io.fs.FS.readLines$(FS.scala:211); 	at is.hail.io.fs.HadoopFS.readL",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/11836:1555,Error,ErrorHandling,1555,https://hail.is,https://github.com/hail-is/hail/issues/11836,1,['Error'],['ErrorHandling']
Availability,"ates (including the; > VeriSign root certs that signed the public certs that gateway uses, different; > from the internal certs that our services use).; >; > In particular, note that the error says ""unable to get local issuer; > certificate."" That means that the local trust store lacks a certificate that; > trusts the remote server's certificate. In Dania's case, the default python on; > OS X lacks all certificates, so every remote server is untrusted. In notebook's; > case, ssl_client_session creates an SSL/TLS session that only trusts Hail; > internal services (in particular, it does not trust the certificates that; > gateway uses for incoming public traffic). The error also says that the server; > in question is workshop.hail.is which is a public domain (note the hail.is), so; > that traffic is going through the public gateway with its public certificates.; >; > ```; > # don't have dev credentials to connect through internal.hail.is; > ready_url = deploy_config.external_url(; > service,; > f'/instance/{notebook[""notebook_token""]}/?token={notebook[""jupyter_token""]}'); > try:; > async with ssl_client_session(; > timeout=aiohttp.ClientTimeout(total=1),; > headers=headers,; > cookies=cookies) as session:; > async with session.get(ready_url) as resp:; > ```. I also changed the names and functionality of the functions in tls. Now; `in_cluster_ssl_context` will error if there is no ssl configuration found; instead of silently (and confusingly) using an SSLContext suited for public; communication (and wrong for in-cluster communication). I added `get_context_specific_client_ssl_context` which should only be used in; publicly consumable tools (*never* in a service). This function allows the same; tool to be used inside and outside the cluster. It will load the correct certs; for your environment (it will load public certs if you're outside the cluster,; it will load in-cluster-only certs if you're in the cluster). I also added types to `tls.py` and fixed some type errors.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9120:1792,error,error,1792,https://hail.is,https://github.com/hail-is/hail/pull/9120,2,['error'],"['error', 'errors']"
Availability,"ation_1519994715701_0003/container_1519994715701_0003_01_000102/stderr. 	at org.apache.hadoop.util.Shell.runCommand(Shell.java:972); 	at org.apache.hadoop.util.Shell.run(Shell.java:869); 	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:1170); 	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:236); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:305); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:84); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748). Container exited with a non-zero exit code 134; ```; When I dig into the container logs, the stdout is empty on most, stderr is full of warnings, but no errors:; ```; 18/03/02 15:28:07 WARN com.google.cloud.hadoop.gcsio.GoogleCloudStorageReadChannel: Channel for 'gs://gnomad/coverage/hail-0.2/coverage/exomes/parts/part_partition1049.vds/entries/rows/parts/part-0095' is not open.; ```; But then one machine I logged into had:; ```; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x00007fa70eb59074, pid=4361, tid=0x00007fa707702700; #; # JRE version: OpenJDK Runtime Environment (8.0_131-b11) (build 1.8.0_131-8u131-b11-1~bpo8+1-b11); # Java VM: OpenJDK 64-Bit Server VM (25.131-b11 mixed mode linux-amd64 compressed oops); # Problematic frame:; # C [libconscrypt_openjdk_jni.so+0x43074]; [error occurred during error reporting (printing problematic frame), id 0xb]. # Failed to write core dump. Core dumps have been disabled. To enable core dumping, try ""ulimit -c unlimited"" before starting Java again; #; # An error report file with more infor",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3053:3919,error,errors,3919,https://hail.is,https://github.com/hail-is/hail/issues/3053,1,['error'],['errors']
Availability,"ator.scala:435); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:441); 	at scala.collection.Iterator$class.foreach(Iterator.scala:891); 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1334); 	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59); 	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104); 	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48); 	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310); 	at scala.collection.AbstractIterator.to(Iterator.scala:1334); 	at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302); 	at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1334); 	at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289); 	at scala.collection.AbstractIterator.toArray(Iterator.scala:1334); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:945); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:945); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2101); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2101); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90); 	at org.apache.spark.scheduler.Task.run(Task.scala:121); 	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:403); 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:409); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745). Hail version: 0.2.31-6060f9c971cc; Error summary: HailException: Hail only supports 8-bit probabilities, found 16. How can I solve it? Or why is it happening?. Thank you very much!. Kind regards,; Catarina",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8545:19854,Error,Error,19854,https://hail.is,https://github.com/hail-is/hail/issues/8545,1,['Error'],['Error']
Availability,"ators$.apply(Compile.scala:249); 	at is.hail.expr.ir.Interpret$.apply(Interpret.scala:618); 	at is.hail.expr.ir.Interpret$.apply(Interpret.scala:50); 	at is.hail.table.Table.aggregate(Table.scala:373); 	at is.hail.table.Table.aggregate(Table.scala:369); 	at is.hail.table.Table.aggregateJSON(Table.scala:364); 	at sun.reflect.GeneratedMethodAccessor45.invoke(Unknown Source); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:280); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:214); 	at java.lang.Thread.run(Thread.java:748). Hail version: devel-414f3f183bd5; Error summary: RuntimeException: Class file too large!; ```; Code was:; ```; cutoff = 10. agg_expr = {; 'downsampling': hl.agg.collect(ht.downsamplings)[0]; }; locations = list(zip(('syn', 'mis', 'lof'), ('', '', '_classic_hc'))); agg_expr.update({; f'median_expected_{var}_{pop}': [hl.median(hl.agg.collect(ht[f'exp_{var}_{pop}{var_loc}'][i])) for i in range(length)]; for length, pop in pop_lengths; for var, var_loc in locations; }); agg_expr.update({; f'median_observed_{var}_{pop}': [hl.median(hl.agg.collect(ht[f'obs_{var}_{pop}{var_loc}'][i])) for i in range(length)]; for length, pop in pop_lengths; for var, var_loc in locations; }); agg_expr.update({; f'mean_expected_{var}_{pop}': [hl.agg.mean(ht[f'exp_{var}_{pop}{var_loc}'][i]) for i in range(length)]; for length, pop in pop_lengths; for var, var_loc in locations; }); agg_expr.update({; f'mean_observed_{var}_{pop}': [hl.agg.mean(ht[f'obs_{var}_{pop}{var_loc}'][i]) for i in range(length)]; for length, pop in pop_lengths; for var, var_loc in locations; }); agg_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4516:1826,Error,Error,1826,https://hail.is,https://github.com/hail-is/hail/issues/4516,1,['Error'],['Error']
Availability,attribute name for compatibility with &lt;code&gt;pytest-xdist&lt;/code&gt; 2. (&lt;code&gt;[#305](https://github.com/pytest-dev/pytest-html/issues/305) &amp;lt;https://github.com/pytest-dev/pytest-html/issues/305&amp;gt;&lt;/code&gt;_)&lt;/p&gt;; &lt;ul&gt;; &lt;li&gt;Thanks to &lt;code&gt;@Zac-HD &amp;lt;https://github.com/Zac-HD&amp;gt;&lt;/code&gt;_ for the fix&lt;/li&gt;; &lt;/ul&gt;; &lt;/li&gt;; &lt;li&gt;; &lt;p&gt;Post process HTML generation to allow teardown to appear in the HTML output. (&lt;code&gt;[#131](https://github.com/pytest-dev/pytest-html/issues/131) &amp;lt;https://github.com/pytest-dev/pytest-html/issues/131&amp;gt;&lt;/code&gt;_)&lt;/p&gt;; &lt;ul&gt;; &lt;li&gt;Thanks to &lt;code&gt;@iwanb &amp;lt;https://github.com/iwanb&amp;gt;&lt;/code&gt;_ for reporting and &lt;code&gt;@csm10495 &amp;lt;https://github.com/csm10495&amp;gt;&lt;/code&gt;_ for the fix&lt;/li&gt;; &lt;/ul&gt;; &lt;/li&gt;; &lt;/ul&gt;; &lt;p&gt;2.1.1 (2020-03-18)&lt;/p&gt;; &lt;pre&gt;&lt;code&gt;; * Fix issue with funcargs causing failures. (`[#282](https://github.com/pytest-dev/pytest-html/issues/282) &amp;lt;https://github.com/pytest-dev/pytest-html/issues/282&amp;gt;`_). * Thanks to `@ssbarnea &amp;lt;https://github.com/ssbarnea&amp;gt;`_ for reporting and `@christiansandberg &amp;lt;https://github.com/christiansandberg&amp;gt;`_ for the fix. 2.1.0 (2020-03-09); &lt;/code&gt;&lt;/pre&gt;; &lt;!-- raw HTML omitted --&gt;; &lt;/blockquote&gt;; &lt;p&gt;... (truncated)&lt;/p&gt;; &lt;/details&gt;; &lt;details&gt;; &lt;summary&gt;Commits&lt;/summary&gt;. &lt;ul&gt;; &lt;li&gt;&lt;a href=&quot;https://github.com/pytest-dev/pytest-html/commit/a1639ef4d9bdc89daa037fd0bfc003bdf2e99865&quot;&gt;&lt;code&gt;a1639ef&lt;/code&gt;&lt;/a&gt; Update CHANGES.rst (&lt;a href=&quot;https://github-redirect.dependabot.com/pytest-dev/pytest-html/issues/411&quot;&gt;#411&lt;/a&gt;)&lt;/li&gt;; &lt;li&gt;&lt;a href=&quot;https://github.com/pytest-dev/pytest-html/commit/727b305a5707a937b42789436,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11524:12878,failure,failures,12878,https://hail.is,https://github.com/hail-is/hail/pull/11524,1,['failure'],['failures']
Availability,"ature requests, please use the discussion forum: http://discuss.hail.is/. -------------------------------------------------------------------------------------------. ### Hail version: . current master. ### What you did:. Read in a giant table of phenotypes (~500k rows x ~3k columns). `; raw_phenos = hl.import_table('gs://phenotype_31063/ukb31063.raw_phenotypes.tsv.bgz',; key='eid', impute=True, types={'eid': hl.tstr}, missing='NA', min_partitions=100); raw_phenos.write('gs://armartin/disparities/ukbb_afr/ukb31063.raw_phenotypes.ht'); `; ### What went wrong (all error messages here, including the full java stack trace):. [Stage 1:> (0 + 100) / 100]Traceback (most recent call last):; File ""/tmp/0fdaf26ceb274d679f571483f658e509/run_prs_afr.py"", line 266, in <module>; main(args); File ""/tmp/0fdaf26ceb274d679f571483f658e509/run_prs_afr.py"", line 125, in main; raw_phenos.write('gs://armartin/disparities/ukbb_afr/ukb31063.raw_phenotypes.ht'); File ""<decorator-gen-652>"", line 2, in write; File ""/tmp/0fdaf26ceb274d679f571483f658e509/hail-devel-5dfbe2ec29f8.zip/hail/typecheck/check.py"", line 546, in wrapper; File ""/tmp/0fdaf26ceb274d679f571483f658e509/hail-devel-5dfbe2ec29f8.zip/hail/table.py"", line 1218, in write; File ""/usr/lib/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py"", line 1133, in __call__; File ""/tmp/0fdaf26ceb274d679f571483f658e509/hail-devel-5dfbe2ec29f8.zip/hail/utils/java.py"", line 210, in deco; hail.utils.java.FatalError: NumberFormatException: For input string: ""1001101010010110"". Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 46 in stage 1.0 failed 20 times, most recent failure: Lost task 46.19 in stage 1.0 (TID 1559, arm-sw-vq41.c.daly-ibd.internal, executor 6): is.hail.utils.HailException: ukb31063.raw_phenotypes.tsv.bgz: java.lang.NumberFormatException: could not convert ""1001101010010110"" to int32 in column ""10145-0.3""; offending line: 3314275 NA 1 NA NA NA NA NA 0 1959 31 NA NA 36 NA NA 98 NA N...",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4268:1671,failure,failure,1671,https://hail.is,https://github.com/hail-is/hail/issues/4268,2,['failure'],['failure']
Availability,"atures:</p>; <ul>; <li>Add possibility to set request <code>method</code> and <code>body</code></li>; </ul>; <p>Maintenance:</p>; <ul>; <li>Update dependencies</li>; <li>Improve documentation</li>; <li>Add integration tests for Gradle 8.0.1</li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/4c983ed5cd229fa64912294737c858c2ba8486d6""><code>4c983ed</code></a> Bump up version number to 5.4.0</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/cc20442ab67bf37687c08e67af7e7de3a21c8fbe""><code>cc20442</code></a> Add integration tests for Gradle 8.0.2</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/472920e572e4cf45d321868874ced50ad8d1e2d5""><code>472920e</code></a> Add possibility to set request method and body</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/82e70cae2a8d48b4f5165a9b543d4e65bb793d88""><code>82e70ca</code></a> Update dependencies</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/86a15f1c16eb729dc71b6caf30237d07b8e0bb01""><code>86a15f1</code></a> Fix compiler warnings and deprecations</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/86363072c8239330b28976109a622bdd073507b6""><code>8636307</code></a> Negative timeouts are actually not allowed</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/4ff0ff0e63e0dd45f231990d0dcebffde6e6b709""><code>4ff0ff0</code></a> Update dependencies</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/a1858b494b5f3a51ccef7580c243c6dfdf520731""><code>a1858b4</code></a> Merge pull request <a href=""https://redirect.github.com/michel-kraemer/gradle-download-task/issues/295"">#295</a> from michel-kraemer/dependabot/npm_and_yarn/screencas...</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/c1e21",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12893:1278,down,download-task,1278,https://hail.is,https://github.com/hail-is/hail/pull/12893,1,['down'],['download-task']
Availability,"auth.py"", line 86, in wrapped; return await fun(request, userdata, *args, **kwargs); File ""/usr/local/lib/python3.6/dist-packages/batch/front_end/front_end.py"", line 383, in ui_get_job_log; 'job_log': await _get_job_log(request.app, batch_id, job_id, user); File ""/usr/local/lib/python3.6/dist-packages/batch/front_end/front_end.py"", line 112, in _get_job_log; job_log = await job._read_logs(); File ""/usr/local/lib/python3.6/dist-packages/batch/batch.py"", line 49, in _read_logs; return await self.app['driver'].read_pod_logs(self._pod_name); File ""/usr/local/lib/python3.6/dist-packages/aiohttp/web_app.py"", line 160, in __getitem__; return self._state[key]; KeyError: 'driver'; ```. ```; Traceback (most recent call last):; File ""/usr/local/lib/python3.6/dist-packages/google/cloud/storage/blob.py"", line 636, in download_to_file; self._do_download(transport, file_obj, download_url, headers, start, end); File ""/usr/local/lib/python3.6/dist-packages/google/cloud/storage/blob.py"", line 574, in _do_download; download.consume(transport); File ""/usr/local/lib/python3.6/dist-packages/google/resumable_media/requests/download.py"", line 171, in consume; self._process_response(result); File ""/usr/local/lib/python3.6/dist-packages/google/resumable_media/_download.py"", line 171, in _process_response; response, _ACCEPTABLE_STATUS_CODES, self._get_status_code; File ""/usr/local/lib/python3.6/dist-packages/google/resumable_media/_helpers.py"", line 96, in require_status_code; *status_codes; google.resumable_media.common.InvalidResponse: ('Request failed with status code', 403, 'Expected one of', <HTTPStatus.OK: 200>, <HTTPStatus.PARTIAL_CONTENT: 206>). During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/usr/local/lib/python3.6/dist-packages/aiohttp/web_protocol.py"", line 418, in start; resp = await task; File ""/usr/local/lib/python3.6/dist-packages/aiohttp/web_app.py"", line 458, in _handle; resp = await handler(request); File ""/usr/l",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7412:1933,down,download,1933,https://hail.is,https://github.com/hail-is/hail/pull/7412,1,['down'],['download']
Availability,"automatically created by Snyk using the credentials of a real user.</p><br /><h3>Snyk has created this PR to fix one or more vulnerable packages in the `pip` dependencies of this project.</h3>. #### Changes included in this PR. - Changes to the following files to upgrade the vulnerable dependencies to a fixed version:; - hail/python/pinned-requirements.txt. <details>; <summary> <b>Warning</b></summary>. ```; aiosignal 1.3.1 requires frozenlist, which is not installed.; aiohttp 3.8.5 requires frozenlist, which is not installed. ```; </details>. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **471/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 3.7 | Insufficient Verification of Data Authenticity <br/>[SNYK-PYTHON-CRYPTOGRAPHY-5813745](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5813745) | `cryptography:` <br> `41.0.2 -> 41.0.3` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **551/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 5.3 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-5813746](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5813746) | `cryptography:` <br> `41.0.2 -> 41.0.3` <br> | No | No Known Exploit ; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **471/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 3.7 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-5813750](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5813750) | `cryptography:` <br> `41.0.2 ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13370:1046,avail,available,1046,https://hail.is,https://github.com/hail-is/hail/pull/13370,1,['avail'],['available']
Availability,"avigate to `http://localhost:3000`. \# lines: Most come from the package.json.lock files. These maintain versioning information.; * [It is recommended to check in .lock files]( https://stackoverflow.com/questions/44206782/do-i-commit-the-package-lock-json-file-created-by-npm-5); * They're huge, sorry.; # Documentation; ### JS; https://javascript.info. We use the subset termed [ES2018](https://flaviocopes.com/es2018/). Compatibility across all browsers is ensured by [transpilation using BabelJS, to some lower JS target](https://babeljs.io/docs/en/). Polyfills should not be used, except when impossible to support a browser (this is configurable). I mostly don't care about anything that isn't an evergreen browser, so I think we should support: Edge, Safari, Chrome, Firefox. Among those we *may* want to care about, [IE11 has ~2% global use (more if only desktop browsers)](https://caniuse.com/#feat=flexbox); ### NodeJS; We use 10.15. [This is the latest LTS release](https://nodejs.org/en/download/). ### Versioning / dependency management; TL;DR: `npm`; ```sh; npm init # creates a package.json file, which tracks dependencies; npm install next react react-dom # install 3 packages and save them to the dependencies property; ```. #### package.json; The file that tracks dependencies, and their semantic versioning numbers. Shape:; ```json; {; ""name"": ""hail-web-client"",; ""version"": ""0.2.0"",; ""scripts"": {; ""dev"": ""next"",; ""build"": ""next build"",; ""start"": ""NODE_ENV=production SSL=true next start""; },; ""author"": ""Hail Team"",; ""license"": ""MIT"",; ""dependencies"": {; ""next"": ""^7.0.2-canary.50"",; ""react"": ""^16.7.0"",; ""react-dom"": ""^16.7.0""; },; ""devDependencies"": {; }; }; ```; * Scripts are thing that can be run by typing, in shell `npm run`. Ex: `npm run dev`. ### Async, Await, Promises and callback (WIP); Javascript is async-first. This is most obvious in Node.js, which is the most popular library for server-side JS.; * [How event loop works](https://nodejs.org/en/docs/guides/event-l",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5162:2216,down,download,2216,https://hail.is,https://github.com/hail-is/hail/pull/5162,1,['down'],['download']
Availability,"avro) to permit the latest version.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/apache/avro/releases"">avro's releases</a>.</em></p>; <blockquote>; <h2>Apache Avro 1.11.0</h2>; <p>The Apache Avro community is pleased to announce the release of Avro 1.11.0!</p>; <p>All signed release artifacts, signatures and verification instructions can; be found here: <a href=""https://avro.apache.org/releases.html"">https://avro.apache.org/releases.html</a></p>; <p>This release includes 120 Jira issues, including some interesting features:</p>; <p>Specification: AVRO-3212 Support documentation tags for FIXED types; C#: AVRO-2961 Support dotnet framework 5.0; C#: AVRO-3225 Prevent memory errors when deserializing untrusted data; C++: AVRO-2923 Logical type corrections; Java: AVRO-2863 Support Avro core on android; Javascript: AVRO-3131 Drop support for node.js 10; Perl: AVRO-3190 Fix error when reading from EOF; Python: AVRO-2906 Improved performance validating deep record data; Python: AVRO-2914 Drop Python 2 support; Python: AVRO-3004 Drop Python 3.5 support; Ruby: AVRO-3108 Drop Ruby 2.5 support</p>; <p>For the first time, the 1.11.0 release includes experimental support for; Rust. Work is continuing on this donated SDK, but we have not versioned and; published official artifacts for this release.</p>; <p>Python: The avro package fully supports Python 3. We will no longer publish a; separate avro-python3 package</p>; <p>And of course upgraded dependencies to latest versions, CVE fixes and more:; <a href=""https://issues.apache.org/jira/issues/?jql=project%3DAVRO%20AND%20fixVersion%3D1.11.0"">https://issues.apache.org/jira/issues/?jql=project%3DAVRO%20AND%20fixVersion%3D1.11.0</a></p>; <p>The link to all fixed JIRA issues and a brief summary can be found at:; <a href=""https://github.com/apache/avro/releases/tag/release-1.11.0"">https://github.com/apache/avro/releases/tag/release-1.11.0</a></p>; <p>In addition, language-specific release ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11475:990,error,error,990,https://hail.is,https://github.com/hail-is/hail/pull/11475,1,['error'],['error']
Availability,"avx2::uint32<4>; T = simdpp::arch_avx2::int32<4>; unsigned int MaskCastOverride = 0]; libsimdpp-2.0-rc2/simdpp/core/cast.h:63:89: required from R simdpp::arch_avx2::bit_cast(const T&) [with R = simdpp::arch_avx2::uint32<4>; T = simdpp::arch_avx2::int32<4>]; libsimdpp-2.0-rc2/simdpp/types/int32x4.h:133:36: required from simdpp::arch_avx2::uint32<4>& simdpp::arch_avx2::uint32<4>::operator=(const simdpp::arch_avx2::any_vec<16, V>&) [with V = simdpp::arch_avx2::int32<4, simdpp::arch_avx2::expr_empty>]; libsimdpp-2.0-rc2/simdpp/detail/insn/i_avg.h:250:8: required from V simdpp::arch_avx2::detail::insn::v_emul_avg_i32(const V&, const V&) [with V = simdpp::arch_avx2::int32<4>]; libsimdpp-2.0-rc2/simdpp/detail/insn/i_avg.h:199:31: required from here; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:40:13: error: void* memcpy(void*, const void*, size_t) copying an object of type class simdpp::arch_avx2::uint32<4> with private member simdpp::arch_avx2::uint32<4>::d_ from an array of const class simdpp::arch_avx2::int32<4>; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/types.h:23,; from libsimdpp-2.0-rc2/simdpp/core/align.h:15,; from libsimdpp-2.0-rc2/simdpp/simd.h:22,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/types/int32x4.h:104:7: note: class simdpp::arch_avx2::uint32<4> declared here; class uint32<4, void> : public any_int32<4, uint32<4,void>> {; ^~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/simd.h:132,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl: In instantiation of R simdpp::arch_avx2::detail::cast_memcpy(const T&) [with R = simdpp::arch_avx2::uint32<8>; T = simdpp::arch_avx2::int32<8>]:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3955:115099,error,error,115099,https://hail.is,https://github.com/hail-is/hail/issues/3955,1,['error'],['error']
Availability,"avx2::uint32<4>; T = simdpp::arch_avx2::uint8<16>]:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::arch_avx2::uint32<4>; T = simdpp::arch_avx2::uint8<16>; unsigned int MaskCastOverride = 0]; libsimdpp-2.0-rc2/simdpp/core/cast.h:63:89: required from R simdpp::arch_avx2::bit_cast(const T&) [with R = simdpp::arch_avx2::uint32<4>; T = simdpp::arch_avx2::uint8<16>]; libsimdpp-2.0-rc2/simdpp/types/int32x4.h:129:36: required from simdpp::arch_avx2::uint32<4>::uint32(const simdpp::arch_avx2::any_vec<16, V>&) [with V = simdpp::arch_avx2::uint8<16>]; libsimdpp-2.0-rc2/simdpp/detail/insn/bit_or.h:101:58: required from here; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:40:13: error: void* memcpy(void*, const void*, size_t) copying an object of type class simdpp::arch_avx2::uint32<4> with private member simdpp::arch_avx2::uint32<4>::d_ from an array of const class simdpp::arch_avx2::uint8<16>; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/types.h:23,; from libsimdpp-2.0-rc2/simdpp/core/align.h:15,; from libsimdpp-2.0-rc2/simdpp/simd.h:22,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/types/int32x4.h:104:7: note: class simdpp::arch_avx2::uint32<4> declared here; class uint32<4, void> : public any_int32<4, uint32<4,void>> {; ^~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/simd.h:132,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl: In instantiation of R simdpp::arch_avx2::detail::cast_memcpy(const T&) [with R = simdpp::arch_avx2::uint8<16>; T = simdpp::arch_avx2::uint64<2>]:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp:",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3955:10913,error,error,10913,https://hail.is,https://github.com/hail-is/hail/issues/3955,1,['error'],['error']
Availability,"avx2::uint32<8>; T = simdpp::arch_avx2::int32<8>; unsigned int MaskCastOverride = 0]; libsimdpp-2.0-rc2/simdpp/core/cast.h:63:89: required from R simdpp::arch_avx2::bit_cast(const T&) [with R = simdpp::arch_avx2::uint32<8>; T = simdpp::arch_avx2::int32<8>]; libsimdpp-2.0-rc2/simdpp/types/int32x8.h:114:36: required from simdpp::arch_avx2::uint32<8>& simdpp::arch_avx2::uint32<8>::operator=(const simdpp::arch_avx2::any_vec<32, V>&) [with V = simdpp::arch_avx2::int32<8, simdpp::arch_avx2::expr_empty>]; libsimdpp-2.0-rc2/simdpp/detail/insn/i_avg.h:250:8: required from V simdpp::arch_avx2::detail::insn::v_emul_avg_i32(const V&, const V&) [with V = simdpp::arch_avx2::int32<8>]; libsimdpp-2.0-rc2/simdpp/detail/insn/i_avg.h:211:31: required from here; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:40:13: error: void* memcpy(void*, const void*, size_t) copying an object of type class simdpp::arch_avx2::uint32<8> with private member simdpp::arch_avx2::uint32<8>::d_ from an array of const class simdpp::arch_avx2::int32<8>; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/types.h:24,; from libsimdpp-2.0-rc2/simdpp/core/align.h:15,; from libsimdpp-2.0-rc2/simdpp/simd.h:22,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/types/int32x8.h:91:7: note: class simdpp::arch_avx2::uint32<8> declared here; class uint32<8, void> : public any_int32<8, uint32<8,void>> {; ^~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/simd.h:132,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl: In instantiation of R simdpp::arch_avx2::detail::cast_memcpy(const T&) [with R = simdpp::arch_avx2::int32<4>; T = simdpp::arch_avx2::uint32<4>]:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::ar",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3955:117104,error,error,117104,https://hail.is,https://github.com/hail-is/hail/issues/3955,1,['error'],['error']
Availability,"avx2::uint32<8>; T = simdpp::arch_avx2::uint8<32>]:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::arch_avx2::uint32<8>; T = simdpp::arch_avx2::uint8<32>; unsigned int MaskCastOverride = 0]; libsimdpp-2.0-rc2/simdpp/core/cast.h:63:89: required from R simdpp::arch_avx2::bit_cast(const T&) [with R = simdpp::arch_avx2::uint32<8>; T = simdpp::arch_avx2::uint8<32>]; libsimdpp-2.0-rc2/simdpp/types/int32x8.h:110:36: required from simdpp::arch_avx2::uint32<8>::uint32(const simdpp::arch_avx2::any_vec<32, V>&) [with V = simdpp::arch_avx2::uint8<32>]; libsimdpp-2.0-rc2/simdpp/detail/insn/bit_not.h:64:45: required from here; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:40:13: error: void* memcpy(void*, const void*, size_t) copying an object of type class simdpp::arch_avx2::uint32<8> with private member simdpp::arch_avx2::uint32<8>::d_ from an array of const class simdpp::arch_avx2::uint8<32>; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/types.h:24,; from libsimdpp-2.0-rc2/simdpp/core/align.h:15,; from libsimdpp-2.0-rc2/simdpp/simd.h:22,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/types/int32x8.h:91:7: note: class simdpp::arch_avx2::uint32<8> declared here; class uint32<8, void> : public any_int32<8, uint32<8,void>> {; ^~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/simd.h:132,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl: In instantiation of R simdpp::arch_avx2::detail::cast_memcpy(const T&) [with R = simdpp::arch_avx2::uint8<32>; T = simdpp::arch_avx2::uint64<4>]:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3955:25140,error,error,25140,https://hail.is,https://github.com/hail-is/hail/issues/3955,1,['error'],['error']
Availability,"avx2::uint64<2>; T = simdpp::arch_avx2::uint8<16>]:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::arch_avx2::uint64<2>; T = simdpp::arch_avx2::uint8<16>; unsigned int MaskCastOverride = 0]; libsimdpp-2.0-rc2/simdpp/core/cast.h:63:89: required from R simdpp::arch_avx2::bit_cast(const T&) [with R = simdpp::arch_avx2::uint64<2>; T = simdpp::arch_avx2::uint8<16>]; libsimdpp-2.0-rc2/simdpp/types/int64x2.h:125:36: required from simdpp::arch_avx2::uint64<2>::uint64(const simdpp::arch_avx2::any_vec<16, V>&) [with V = simdpp::arch_avx2::uint8<16>]; libsimdpp-2.0-rc2/simdpp/detail/insn/bit_or.h:150:58: required from here; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:40:13: error: void* memcpy(void*, const void*, size_t) copying an object of type class simdpp::arch_avx2::uint64<2> with private member simdpp::arch_avx2::uint64<2>::d_ from an array of const class simdpp::arch_avx2::uint8<16>; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/types.h:26,; from libsimdpp-2.0-rc2/simdpp/core/align.h:15,; from libsimdpp-2.0-rc2/simdpp/simd.h:22,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/types/int64x2.h:102:7: note: class simdpp::arch_avx2::uint64<2> declared here; class uint64<2, void> : public any_int64<2, uint64<2,void>> {; ^~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/simd.h:132,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl: In instantiation of R simdpp::arch_avx2::detail::cast_memcpy(const T&) [with R = simdpp::arch_avx2::int16<8>; T = simdpp::arch_avx2::uint8<16>]:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3955:14450,error,error,14450,https://hail.is,https://github.com/hail-is/hail/issues/3955,1,['error'],['error']
Availability,"avx2::uint64<4>; T = simdpp::arch_avx2::uint8<32>]:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::arch_avx2::uint64<4>; T = simdpp::arch_avx2::uint8<32>; unsigned int MaskCastOverride = 0]; libsimdpp-2.0-rc2/simdpp/core/cast.h:63:89: required from R simdpp::arch_avx2::bit_cast(const T&) [with R = simdpp::arch_avx2::uint64<4>; T = simdpp::arch_avx2::uint8<32>]; libsimdpp-2.0-rc2/simdpp/types/int64x4.h:110:36: required from simdpp::arch_avx2::uint64<4>::uint64(const simdpp::arch_avx2::any_vec<32, V>&) [with V = simdpp::arch_avx2::uint8<32>]; libsimdpp-2.0-rc2/simdpp/detail/insn/bit_not.h:94:45: required from here; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:40:13: error: void* memcpy(void*, const void*, size_t) copying an object of type class simdpp::arch_avx2::uint64<4> with private member simdpp::arch_avx2::uint64<4>::d_ from an array of const class simdpp::arch_avx2::uint8<32>; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/types.h:27,; from libsimdpp-2.0-rc2/simdpp/core/align.h:15,; from libsimdpp-2.0-rc2/simdpp/simd.h:22,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/types/int64x4.h:91:7: note: class simdpp::arch_avx2::uint64<4> declared here; class uint64<4, void> : public any_int64<4, uint64<4,void>> {; ^~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/simd.h:132,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl: In instantiation of R simdpp::arch_avx2::detail::cast_memcpy(const T&) [with R = simdpp::arch_avx2::uint8<32>; T = simdpp::arch_avx2::uint16<16>]:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp:",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3955:28675,error,error,28675,https://hail.is,https://github.com/hail-is/hail/issues/3955,1,['error'],['error']
Availability,"ay of const class simdpp::arch_avx2::int16<16>; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/types.h:22,; from libsimdpp-2.0-rc2/simdpp/core/align.h:15,; from libsimdpp-2.0-rc2/simdpp/simd.h:22,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/types/int16x16.h:92:7: note: class simdpp::arch_avx2::uint16<16> declared here; class uint16<16, void> : public any_int16<16, uint16<16,void>> {; ^~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/simd.h:132,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl: In instantiation of R simdpp::arch_avx2::detail::cast_memcpy(const T&) [with R = simdpp::arch_avx2::int8<32>; T = simdpp::arch_avx2::uint16<16>]:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::arch_avx2::int8<32>; T = simdpp::arch_avx2::uint16<16>; unsigned int MaskCastOverride = 0]; libsimdpp-2.0-rc2/simdpp/core/cast.h:63:89: required from R simdpp::arch_avx2::bit_cast(const T&) [with R = simdpp::arch_avx2::int8<32>; T = simdpp::arch_avx2::uint16<16>]; libsimdpp-2.0-rc2/simdpp/types/int8x32.h:51:35: required from simdpp::arch_avx2::int8<32>::int8(const simdpp::arch_avx2::any_vec<32, V>&) [with V = simdpp::arch_avx2::uint16<16, simdpp::arch_avx2::expr_bit_or<simdpp::arch_avx2::uint16<16, simdpp::arch_avx2::uint16<16> >, simdpp::arch_avx2::uint16<16, simdpp::arch_avx2::uint16<16> > > >]; libsimdpp-2.0-rc2/simdpp/detail/insn/i_shift_r.h:69:36: required from here; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:40:13: error: void* memcpy(void*, const void*, size_t) copying an object of type class simdpp::arch_avx2::int8<32> with private member simdpp::arch_avx2::int8<32>::d_ from an array of const class simdpp::arch_avx2::uint16<16>; use assignment or ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3955:65185,Mask,MaskCastOverride,65185,https://hail.is,https://github.com/hail-is/hail/issues/3955,2,['Mask'],['MaskCastOverride']
Availability,"ay of const class simdpp::arch_avx2::int8<32>; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/types.h:22,; from libsimdpp-2.0-rc2/simdpp/core/align.h:15,; from libsimdpp-2.0-rc2/simdpp/simd.h:22,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/types/int16x16.h:92:7: note: class simdpp::arch_avx2::uint16<16> declared here; class uint16<16, void> : public any_int16<16, uint16<16,void>> {; ^~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/simd.h:132,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl: In instantiation of R simdpp::arch_avx2::detail::cast_memcpy(const T&) [with R = simdpp::arch_avx2::uint16<16>; T = simdpp::arch_avx2::int16<16>]:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::arch_avx2::uint16<16>; T = simdpp::arch_avx2::int16<16>; unsigned int MaskCastOverride = 0]; libsimdpp-2.0-rc2/simdpp/core/cast.h:63:89: required from R simdpp::arch_avx2::bit_cast(const T&) [with R = simdpp::arch_avx2::uint16<16>; T = simdpp::arch_avx2::int16<16>]; libsimdpp-2.0-rc2/simdpp/types/int16x16.h:115:37: required from simdpp::arch_avx2::uint16<16>& simdpp::arch_avx2::uint16<16>::operator=(const simdpp::arch_avx2::any_vec<32, V>&) [with V = simdpp::arch_avx2::int16<16, simdpp::arch_avx2::expr_empty>]; libsimdpp-2.0-rc2/simdpp/detail/insn/i_shift_r.h:64:37: required from here; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:40:13: error: void* memcpy(void*, const void*, size_t) copying an object of type class simdpp::arch_avx2::uint16<16> with private member simdpp::arch_avx2::uint16<16>::d_ from an array of const class simdpp::arch_avx2::int16<16>; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3955:63338,Mask,MaskCastOverride,63338,https://hail.is,https://github.com/hail-is/hail/issues/3955,2,['Mask'],['MaskCastOverride']
Availability,"ay of const class simdpp::arch_avx2::uint32<8>; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/types.h:22,; from libsimdpp-2.0-rc2/simdpp/core/align.h:15,; from libsimdpp-2.0-rc2/simdpp/simd.h:22,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/types/int16x16.h:92:7: note: class simdpp::arch_avx2::uint16<16> declared here; class uint16<16, void> : public any_int16<16, uint16<16,void>> {; ^~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/simd.h:132,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl: In instantiation of R simdpp::arch_avx2::detail::cast_memcpy(const T&) [with R = simdpp::arch_avx2::uint32<4>; T = simdpp::arch_avx2::uint16<8>]:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::arch_avx2::uint32<4>; T = simdpp::arch_avx2::uint16<8>; unsigned int MaskCastOverride = 0]; libsimdpp-2.0-rc2/simdpp/core/cast.h:63:89: required from R simdpp::arch_avx2::bit_cast(const T&) [with R = simdpp::arch_avx2::uint32<4>; T = simdpp::arch_avx2::uint16<8>]; libsimdpp-2.0-rc2/simdpp/types/int32x4.h:133:36: required from simdpp::arch_avx2::uint32<4>& simdpp::arch_avx2::uint32<4>::operator=(const simdpp::arch_avx2::any_vec<16, V>&) [with V = simdpp::arch_avx2::uint16<8, simdpp::arch_avx2::expr_empty>]; libsimdpp-2.0-rc2/simdpp/detail/insn/transpose.h:114:24: required from here; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:40:13: error: void* memcpy(void*, const void*, size_t) copying an object of type class simdpp::arch_avx2::uint32<4> with private member simdpp::arch_avx2::uint32<4>::d_ from an array of const class simdpp::arch_avx2::uint16<8>; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3955:35719,Mask,MaskCastOverride,35719,https://hail.is,https://github.com/hail-is/hail/issues/3955,2,['Mask'],['MaskCastOverride']
Availability,"ay of const class simdpp::arch_avx2::uint8<32>; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/types.h:22,; from libsimdpp-2.0-rc2/simdpp/core/align.h:15,; from libsimdpp-2.0-rc2/simdpp/simd.h:22,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/types/int16x16.h:92:7: note: class simdpp::arch_avx2::uint16<16> declared here; class uint16<16, void> : public any_int16<16, uint16<16,void>> {; ^~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/simd.h:132,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl: In instantiation of R simdpp::arch_avx2::detail::cast_memcpy(const T&) [with R = simdpp::arch_avx2::uint16<8>; T = simdpp::arch_avx2::uint64<2>]:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::arch_avx2::uint16<8>; T = simdpp::arch_avx2::uint64<2>; unsigned int MaskCastOverride = 0]; libsimdpp-2.0-rc2/simdpp/core/cast.h:63:89: required from R simdpp::arch_avx2::bit_cast(const T&) [with R = simdpp::arch_avx2::uint16<8>; T = simdpp::arch_avx2::uint64<2>]; libsimdpp-2.0-rc2/simdpp/types/int16x8.h:133:36: required from simdpp::arch_avx2::uint16<8>& simdpp::arch_avx2::uint16<8>::operator=(const simdpp::arch_avx2::any_vec<16, V>&) [with V = simdpp::arch_avx2::uint64<2, simdpp::arch_avx2::expr_empty>]; libsimdpp-2.0-rc2/simdpp/detail/insn/transpose.h:453:24: required from here; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:40:13: error: void* memcpy(void*, const void*, size_t) copying an object of type class simdpp::arch_avx2::uint16<8> with private member simdpp::arch_avx2::uint16<8>::d_ from an array of const class simdpp::arch_avx2::uint64<2>; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3955:52298,Mask,MaskCastOverride,52298,https://hail.is,https://github.com/hail-is/hail/issues/3955,2,['Mask'],['MaskCastOverride']
Availability,"b config; INFO	2022-03-02 19:06:31,656	job.py	schedule_job:443	schedule job (99, 1) on instance batch-worker-pr-11438-default-g6cibyji6520-standard-9xy2q: made job config; INFO	2022-03-02 19:06:31,662	job.py	schedule_job:443	schedule job (100, 1) on instance batch-worker-pr-11438-default-g6cibyji6520-standard-9xy2q: made job config; INFO	2022-03-02 19:06:31,663	job.py	schedule_job:443	schedule job (98, 1) on instance batch-worker-pr-11438-default-g6cibyji6520-standard-9xy2q: made job config; INFO	2022-03-02 19:06:32,455	job.py	schedule_job:443	schedule job (101, 1) on instance batch-worker-pr-11438-default-g6cibyji6520-standard-9xy2q: made job config; INFO	2022-03-02 19:06:32,455	job.py	schedule_job:443	schedule job (102, 1) on instance batch-worker-pr-11438-default-g6cibyji6520-standard-9xy2q: made job config; INFO	2022-03-02 19:06:33,456	hail_logging.py	log:40	https POST /pr-11438-default-g6cibyji6520/batch-driver/api/v1alpha/instances/activate done in 3.2369999999998527s: 200; ERROR	2022-03-02 19:06:33,492	job.py	schedule_job:473	error while scheduling job (95, 1) on instance batch-worker-pr-11438-default-g6cibyji6520-standard-9xy2q	Traceback (most recent call last):\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 969, in _wrap_create_connection\n return await self._loop.create_connection(*args, **kwargs) # type: ignore # noqa\n File ""uvloop/loop.pyx"", line 1974, in create_connection\n File ""uvloop/loop.pyx"", line 1951, in uvloop.loop.Loop.create_connection\nConnectionRefusedError: [Errno 111] Connection refused\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n File ""/usr/local/lib/python3.7/dist-packages/batch/driver/job.py"", line 449, in schedule_job\n timeout=aiohttp.ClientTimeout(total=2),\n File ""/usr/local/lib/python3.7/dist-packages/hailtop/httpx.py"", line 113, in request_and_raise_for_status\n resp = await self.client_session._request(method, url, **kwargs)\n File ""/u",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11451:2921,ERROR,ERROR,2921,https://hail.is,https://github.com/hail-is/hail/pull/11451,1,['ERROR'],['ERROR']
Availability,"b': 1},; {'a': 'bar', 'b': 2},; {'a': 'bar', 'b': 2}],; hl.tstruct(a=hl.tstr, b=hl.tint32),; key='a'); t2 = hl.Table.parallelize([; {'t': 'foo', 'x': 3.14},; {'t': 'bar', 'x': 2.78},; {'t': 'bar', 'x': -1},; {'t': 'quam', 'x': 0}],; hl.tstruct(t=hl.tstr, x=hl.tfloat64),; key='t'). t1.join(t2, how='outer').show(). # or. t1.join(t2, how='right').show(); ```. ### What went wrong (all error messages here, including the full java stack trace):. FatalError: HailException: OrderedRVD error! Unexpected PK in partition 1; Range bounds for partition 1: ([bar]-[foo]]; Invalid PK: [quam]; Full key: [quam]. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 19.0 failed 1 times, most recent failure: Lost task 0.0 in stage 19.0 (TID 24, localhost, executor driver): is.hail.utils.HailException: OrderedRVD error! Unexpected PK in partition 1; Range bounds for partition 1: ([bar]-[foo]]; Invalid PK: [quam]; Full key: [quam]; 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:9); 	at is.hail.utils.package$.fatal(package.scala:26); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$21$$anon$3.next(OrderedRVD.scala:1031); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$21$$anon$3.next(OrderedRVD.scala:1012); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:462); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); 	at is.hail.rvd.RVD$$anonfun$4$$anon$1.hasNext(RVD.scala:226); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$21$$anon$3.hasNext(OrderedRVD.scala:1015); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); 	at scala.collection.Iterator$$anon$1.hasNext(Iterator.scala:1004); 	at is.hail.utils.richUtils.RichIterator$$anon$5.isValid(RichIterator.scala:21); 	at is.hail.utils.StagingIterator.isValid(Fli",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4055:1090,Error,ErrorHandling,1090,https://hail.is,https://github.com/hail-is/hail/issues/4055,1,['Error'],['ErrorHandling']
Availability,"b.com/Azure/azure-sdk-for-python/commit/9f66f6bce7d777b34c03dc9a633148acd0c4f238""><code>9f66f6b</code></a> [Storage] Revert removing aiohttp dependency for storage.blob.aio (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/25084"">#25084</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/e40d3e1d985cee13a2e0d070fb8e04958905f468""><code>e40d3e1</code></a> [storage.blob] Remove aiohttp as dependency for storage.blob.aio (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/24965"">#24965</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/7915719f211cc1217dfca6f3973a2b1f04c2e3f5""><code>7915719</code></a> [Storage] Prepare for STG83 GA release (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/25040"">#25040</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/155eb8b69b3cd2f8ef992cf1436bf2751769ac42""><code>155eb8b</code></a> [Storage] Add <code>progress_hook</code> to file-share upload/download (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/24997"">#24997</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/66dd3bef2d6e531e83cefd65be4cbbf41fcf2531""><code>66dd3be</code></a> [Storage] Fix more flaky lease tests (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/25011"">#25011</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/030141734a239fa6fb1aa7a8c43d322c82753510""><code>0301417</code></a> [Storage] Add argument to perf tests to use client-side encryption (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/24978"">#24978</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/Azure/azure-sdk-for-python/compare/azure-storage-blob_12.11.0...azure-storage-blob_12.13.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility sc",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12109:3742,down,download,3742,https://hail.is,https://github.com/hail-is/hail/pull/12109,1,['down'],['download']
Availability,"b.com/alden-ilao""><code>@alden-ilao</code></a>)</li>; </ul>; <h3>Documentation improvements</h3>; <ul>; <li>Fix link to yarn docs in extension migration guide <a href=""https://redirect.github.com/jupyterlab/jupyterlab/pull/15640"">#15640</a> (<a href=""https://github.com/krassowski""><code>@krassowski</code></a>)</li>; </ul>; <h3>Contributors to this release</h3>; <p>(<a href=""https://github.com/jupyterlab/jupyterlab/graphs/contributors?from=2023-12-29&amp;to=2024-01-19&amp;type=c"">GitHub contributors page for this release</a>)</p>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/jupyterlab/jupyterlab/blob/@jupyterlab/lsp@4.0.12/CHANGELOG.md"">jupyterlab's changelog</a>.</em></p>; <blockquote>; <h2>4.0.12</h2>; <p>(<a href=""https://github.com/jupyterlab/jupyterlab/compare/v4.0.11...69079ec413cbe6d173f0a667c15802b76423ece5"">Full Changelog</a>)</p>; <h3>Bugs fixed</h3>; <ul>; <li>Fix jupyterlab downgrade issue on extension installation <a href=""https://redirect.github.com/jupyterlab/jupyterlab/pull/15650"">#15650</a> (<a href=""https://github.com/Sarthug99""><code>@Sarthug99</code></a>)</li>; <li>Fix search highlights removal on clearing input box <a href=""https://redirect.github.com/jupyterlab/jupyterlab/pull/15690"">#15690</a> (<a href=""https://github.com/krassowski""><code>@krassowski</code></a>)</li>; <li>Add scroll margin to headings for better alignment <a href=""https://redirect.github.com/jupyterlab/jupyterlab/pull/15703"">#15703</a> (<a href=""https://github.com/krassowski""><code>@krassowski</code></a>)</li>; <li>Fix shortcut UI failing on filtering when empty command is given <a href=""https://redirect.github.com/jupyterlab/jupyterlab/pull/15695"">#15695</a> (<a href=""https://github.com/krassowski""><code>@krassowski</code></a>)</li>; <li>Fix connection loop issue with standalone foreign document in LSP <a href=""https://redirect.github.com/jupyterlab/",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14218:6130,down,downgrade,6130,https://hail.is,https://github.com/hail-is/hail/pull/14218,1,['down'],['downgrade']
Availability,"b/python3.6/ssl.py"", line 874, in read; return self._sslobj.read(len, buffer); File ""/usr/lib/python3.6/ssl.py"", line 631, in read; v = self._sslobj.read(len, buffer); socket.timeout: The read operation timed out. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/usr/lib/python3/dist-packages/pip/basecommand.py"", line 215, in main; status = self.run(options, args); File ""/usr/lib/python3/dist-packages/pip/commands/install.py"", line 342, in run; requirement_set.prepare_files(finder); File ""/usr/lib/python3/dist-packages/pip/req/req_set.py"", line 380, in prepare_files; ignore_dependencies=self.ignore_dependencies)); File ""/usr/lib/python3/dist-packages/pip/req/req_set.py"", line 620, in _prepare_file; session=self.session, hashes=hashes); File ""/usr/lib/python3/dist-packages/pip/download.py"", line 821, in unpack_url; hashes=hashes; File ""/usr/lib/python3/dist-packages/pip/download.py"", line 659, in unpack_http_url; hashes); File ""/usr/lib/python3/dist-packages/pip/download.py"", line 882, in _download_http_url; _download_url(resp, link, content_file, hashes); File ""/usr/lib/python3/dist-packages/pip/download.py"", line 603, in _download_url; hashes.check_against_chunks(downloaded_chunks); File ""/usr/lib/python3/dist-packages/pip/utils/hashes.py"", line 46, in check_against_chunks; for chunk in chunks:; File ""/usr/lib/python3/dist-packages/pip/download.py"", line 571, in written_chunks; for chunk in chunks:; File ""/usr/lib/python3/dist-packages/pip/utils/ui.py"", line 139, in iter; for x in it:; File ""/usr/lib/python3/dist-packages/pip/download.py"", line 560, in resp_read; decode_content=False):; File ""/usr/share/python-wheels/urllib3-1.22-py2.py3-none-any.whl/urllib3/response.py"", line 436, in stream; data = self.read(amt=amt, decode_content=decode_content); File ""/usr/share/python-wheels/urllib3-1.22-py2.py3-none-any.whl/urllib3/response.py"", line 401, in read; raise IncompleteRead(self._fp_bytes_read, self.leng",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8390:1706,down,download,1706,https://hail.is,https://github.com/hail-is/hail/issues/8390,1,['down'],['download']
Availability,"b1.</li>; <li>Added support for deleting versions in <code>delete_blobs</code> by supplying <code>version_id</code>.</li>; </ul>; <h2>azure-storage-blob_12.13.0b1</h2>; <h2>12.13.0b1 (2022-06-15)</h2>; <h3>Features Added</h3>; <ul>; <li>Added support for service version 2021-08-06.</li>; <li>Added a new version of client-side encryption for blobs (version 2.0) which utilizes AES-GCM-256 encryption.; If you are currently using client-side encryption, it is <strong>highly recommended</strong> to switch to a form of server-side; encryption (Customer-Provided Key, Encryption Scope, etc.) or version 2.0 of client-side encryption. The encryption; version can be specified on any client constructor via the <code>encryption_version</code> keyword (<code>encryption_version='2.0'</code>).</li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/13989b5b1253e26f3f3ee24013a3013fea1bdf73""><code>13989b5</code></a> [Storage] Fix ranged download for client-side encryption (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/25522"">#25522</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/e90af4374bfd7c139737ad2888fcd269b3023520""><code>e90af43</code></a> DataLake funny dependency (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/25129"">#25129</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/cbec3383039ffeb46760268d1a8f81cf1b4d2219""><code>cbec338</code></a> [AutoRelease] t2-storagecache-2022-07-06-35884(Do not merge) (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/25089"">#25089</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/dc7c5a16d39df8a8d4b838a7240e58f64fc824f2""><code>dc7c5a1</code></a> [Storage] API View Feedback For STG84 GA (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/25",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12109:1659,down,download,1659,https://hail.is,https://github.com/hail-is/hail/pull/12109,1,['down'],['download']
Availability,"b>Warning</b></summary>. ```; jupyter 1.0.0 requires notebook, which is not installed.; beautifulsoup4 4.12.2 requires soupsieve, which is not installed. ```; </details>. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **554/1000** <br/> **Why?** Has a fix available, CVSS 6.8 | Insufficient Verification of Data Authenticity <br/>[SNYK-PYTHON-CERTIFI-3164749](https://snyk.io/vuln/SNYK-PYTHON-CERTIFI-3164749) | `certifi:` <br> `2021.10.8 -> 2023.7.22` <br> | No | No Known Exploit ; ![critical severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/c.png ""critical severity"") | **704/1000** <br/> **Why?** Has a fix available, CVSS 9.8 | Improper Following of a Certificate&#x27;s Chain of Trust <br/>[SNYK-PYTHON-CERTIFI-5805047](https://snyk.io/vuln/SNYK-PYTHON-CERTIFI-5805047) | `certifi:` <br> `2021.10.8 -> 2023.7.22` <br> | No | No Known Exploit ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | **624/1000** <br/> **Why?** Has a fix available, CVSS 8.2 | Arbitrary Code Execution <br/>[SNYK-PYTHON-IPYTHON-2348630](https://snyk.io/vuln/SNYK-PYTHON-IPYTHON-2348630) | `ipython:` <br> `5.10.0 -> 8.10.0` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **531/1000** <br/> **Why?** Proof of Concept exploit, Has a fix available, CVSS 4.2 | Remote Code Execution (RCE) <br/>[SNYK-PYTHON-IPYTHON-3318382](https://snyk.io/vuln/SNYK-PYTHON-IPYTHON-3318382) | `ipython:` <br> `5.10.0 -> 8.10.0` <br> | No | Proof of Concept ; !",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13717:1427,avail,available,1427,https://hail.is,https://github.com/hail-is/hail/pull/13717,1,['avail'],['available']
Availability,"b_private_instance_cancel ; -------------------------------- live log setup --------------------------------; 2023-09-06T21:45:24 INFO test.conftest conftest.py:14:log_before_after starting test; 2023-09-06T21:45:24 INFO hailtop.aiocloud.aioazure.credentials credentials.py:99:default_credentials using credentials file /test-gsa-key/key.json; -------------------------------- live log call ---------------------------------; 2023-09-06T21:45:25 INFO azure.identity.aio._internal.get_token_mixin get_token_mixin.py:93:get_token ClientSecretCredential.get_token succeeded; 2023-09-06T21:45:25 INFO batch_client.aioclient aioclient.py:809:_submit created batch 191; submit job bunches  100% 1/1 0:00:00 0:00:00; 2023-09-06T21:47:17 WARNING hailtop.utils utils.py:842:retry_transient_errors_with_debug_string A transient error occured. We will automatically retry. Do not be alarmed. We have thus far seen 2 transient errors (next delay: 3.794s). The most recent error was <class 'asyncio.exceptions.TimeoutError'> . . +++++++++++++++++++++++++++++++++++ Timeout ++++++++++++++++++++++++++++++++++++. ~~~~~~~~~~~~~~~~~~~~~ Stack of asyncio_0 (140387515627072) ~~~~~~~~~~~~~~~~~~~~~; File ""/usr/lib/python3.9/threading.py"", line 937, in _bootstrap; self._bootstrap_inner(); File ""/usr/lib/python3.9/threading.py"", line 980, in _bootstrap_inner; self.run(); File ""/usr/lib/python3.9/threading.py"", line 917, in run; self._target(*self._args, **self._kwargs); File ""/usr/lib/python3.9/concurrent/futures/thread.py"", line 81, in _worker; work_item = work_queue.get(block=True). +++++++++++++++++++++++++++++++++++ Timeout ++++++++++++++++++++++++++++++++++++; FAILED; _________________ test_always_run_job_private_instance_cancel __________________. client = <hailtop.batch_client.client.BatchClient object at 0x7fae899806a0>. def test_always_run_job_private_instance_cancel(client: BatchClient):; b = create_batch(client); resources = {'machine_type': smallest_machine_ty",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13582:1116,error,error,1116,https://hail.is,https://github.com/hail-is/hail/issues/13582,1,['error'],['error']
Availability,bad 'analyze' error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3020:14,error,error,14,https://hail.is,https://github.com/hail-is/hail/issues/3020,1,['error'],['error']
Availability,bad error message and crash for files named .bgz that are plaintext,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/425:4,error,error,4,https://hail.is,https://github.com/hail-is/hail/issues/425,1,['error'],['error']
Availability,bad error message if spark.serializer is wrong,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3860:4,error,error,4,https://hail.is,https://github.com/hail-is/hail/issues/3860,1,['error'],['error']
Availability,bad error message in Table.order_by(field from other table),MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4920:4,error,error,4,https://hail.is,https://github.com/hail-is/hail/issues/4920,1,['error'],['error']
Availability,bad error message on export_vcf,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4283:4,error,error,4,https://hail.is,https://github.com/hail-is/hail/issues/4283,1,['error'],['error']
Availability,bad error message related to indices,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4039:4,error,error,4,https://hail.is,https://github.com/hail-is/hail/issues/4039,1,['error'],['error']
Availability,bad error messages for Table.group_by,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4070:4,error,error,4,https://hail.is,https://github.com/hail-is/hail/issues/4070,1,['error'],['error']
Availability,bad error on hl.import_table(hail_table_path),MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5129:4,error,error,4,https://hail.is,https://github.com/hail-is/hail/issues/5129,1,['error'],['error']
Availability,"bands.append(keep_fams_ht.mother_id).append(keep_fams_ht.father_id)); ----> 2 relateds = keep_fams_ht.explode(keep_fams_ht.relateds).key_by('relateds').distinct(). /home/hail/hail.zip/hail/table.py in distinct(self); 2607 """"""; 2608 hail.methods.misc.require_key(self, ""distinct""); -> 2609 return Table(self._jt.distinctByKey()); 2610 ; 2611 table_type.set(Table). /usr/lib/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py in __call__(self, *args); 1131 answer = self.gateway_client.send_command(command); 1132 return_value = get_return_value(; -> 1133 answer, self.gateway_client, self.target_id, self.name); 1134 ; 1135 for temp_arg in temp_args:. /home/hail/hail.zip/hail/utils/java.py in deco(*args, **kwargs); 182 import pyspark; 183 try:; --> 184 return f(*args, **kwargs); 185 except py4j.protocol.Py4JJavaError as e:; 186 s = e.java_exception.toString(). /usr/lib/spark/python/lib/py4j-0.10.4-src.zip/py4j/protocol.py in get_return_value(answer, gateway_client, target_id, name); 317 raise Py4JJavaError(; 318 ""An error occurred while calling {0}{1}{2}.\n"".; --> 319 format(target_id, ""."", name), value); 320 else:; 321 raise Py4JError(. Py4JJavaError: An error occurred while calling o1507.distinctByKey.; : java.util.NoSuchElementException: None.get; 	at scala.None$.get(Option.scala:347); 	at scala.None$.get(Option.scala:345); 	at is.hail.expr.TableMapRows.execute(Relational.scala:2089); 	at is.hail.expr.TableMapRows.execute(Relational.scala:2064); 	at is.hail.expr.TableExplode.execute(Relational.scala:2166); 	at is.hail.expr.TableUnkey.execute(Relational.scala:1857); 	at is.hail.expr.TableMapRows.execute(Relational.scala:2064); 	at is.hail.expr.TableKeyBy.execute(Relational.scala:1820); 	at is.hail.expr.TableKeyBy.execute(Relational.scala:1820); 	at is.hail.table.Table.value$lzycompute(Table.scala:237); 	at is.hail.table.Table.value(Table.scala:232); 	at is.hail.table.Table.x$5$lzycompute(Table.scala:240); 	at is.hail.table.Table.x$5(Table.scala:240); 	at is.hail.tab",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3814:2475,error,error,2475,https://hail.is,https://github.com/hail-is/hail/issues/3814,1,['error'],['error']
Availability,"batch checks authentication for all endpoints except `/alive`. Two endpoints are now considered ""internal"" and must originate from the batch server itself. Summary of Changes; - hailjwt is used by batch to verify cookies; - all batch endpoints except `/alive` require a valid cookie or are internal; - a make target `test-deploy` and associated files for testing a deploy of batch; - update pipeline to use batch and users",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5844:55,alive,alive,55,https://hail.is,https://github.com/hail-is/hail/pull/5844,2,['alive'],['alive']
Availability,"batch log:. ```; {""levelname"": ""ERROR"", ""asctime"": ""2019-07-29 12:35:40,389"", ""filename"": ""batch.py"", ""funcNameAndLine"": ""polling_event_loop:1343"", ""message"": ""Could not poll due to exception: HTTPConnectionPool(host='10.32.16.16', port=5001): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ff2413b8470>: Failed to establish a new connection: [Errno 113] No route to host',))"", ""exc_info"": ""Traceback (most recent call last):\n File \""/usr/local/lib/python3.6/dist-packages/urllib3/connection.py\"", line 159, in _new_conn\n (self._dns_host, self.port), self.timeout, **extra_kw)\n File \""/usr/local/lib/python3.6/dist-packages/urllib3/util/connection.py\"", line 80, in create_connection\n raise err\n File \""/usr/local/lib/python3.6/dist-packages/urllib3/util/connection.py\"", line 70, in create_connection\n sock.connect(sa)\nOSError: [Errno 113] No route to host\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n File \""/usr/local/lib/python3.6/dist-packages/urllib3/connectionpool.py\"", line 600, in urlopen\n chunked=chunked)\n File \""/usr/local/lib/python3.6/dist-packages/urllib3/connectionpool.py\"", line 354, in _make_request\n conn.request(method, url, **httplib_request_kw)\n File \""/usr/lib/python3.6/http/client.py\"", line 1239, in request\n self._send_request(method, url, body, headers, encode_chunked)\n File \""/usr/lib/python3.6/http/client.py\"", line 1285, in _send_request\n self.endheaders(body, encode_chunked=encode_chunked)\n File \""/usr/lib/python3.6/http/client.py\"", line 1234, in endheaders\n self._send_output(message_body, encode_chunked=encode_chunked)\n File \""/usr/lib/python3.6/http/client.py\"", line 1026, in _send_output\n self.send(msg)\n File \""/usr/lib/python3.6/http/client.py\"", line 964, in send\n self.connect()\n File \""/usr/local/lib/python3.6/dist-packages/urllib3/connection.py\"", line 181, in connect\n conn = self._new_conn()\n ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6754:32,ERROR,ERROR,32,https://hail.is,https://github.com/hail-is/hail/issues/6754,1,['ERROR'],['ERROR']
Availability,batch sometimes shows exit code 0 success when a job is a failure,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8473:58,failure,failure,58,https://hail.is,https://github.com/hail-is/hail/issues/8473,1,['failure'],['failure']
Availability,better error handling on initial read of vds metadata,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2173:7,error,error,7,https://hail.is,https://github.com/hail-is/hail/pull/2173,1,['error'],['error']
Availability,better error message and behaviour when parsing malformed vcf,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/361:7,error,error,7,https://hail.is,https://github.com/hail-is/hail/issues/361,1,['error'],['error']
Availability,better error message for partition mismatch,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1183:7,error,error,7,https://hail.is,https://github.com/hail-is/hail/pull/1183,1,['error'],['error']
Availability,better error messages for invalid dev deploy,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7074:7,error,error,7,https://hail.is,https://github.com/hail-is/hail/issues/7074,1,['error'],['error']
Availability,better fb error handling,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2330:10,error,error,10,https://hail.is,https://github.com/hail-is/hail/pull/2330,1,['error'],['error']
Availability,"ble(); .flatten(); .select(['va.info.MQRankSum']); ); print(rf_kt.schema()). rf_df = rf_kt.to_dataframe(); rf_df.printSchema(); rf_df.show(); ```. And here is the output and stacktrace as it crashes when running `show()`:. ```; Struct {; `va.info.MQRankSum`: Double; }; root; |-- va.info.MQRankSum: double (nullable = true); Traceback (most recent call last):; File ""/tmp/db4d8e04-85c9-4eba-b0b3-4ade69200fd3/test.py"", line 60, in <module>; rf_df.show(); File ""/usr/lib/spark/python/lib/pyspark.zip/pyspark/sql/dataframe.py"", line 287, in show; File ""/usr/lib/spark/python/lib/py4j-0.10.3-src.zip/py4j/java_gateway.py"", line 1133, in __call__; File ""/usr/lib/spark/python/lib/pyspark.zip/pyspark/sql/utils.py"", line 63, in deco; for criterion, pop in criteria_pops:; File ""/usr/lib/spark/python/lib/py4j-0.10.3-src.zip/py4j/protocol.py"", line 319, in get_return_value; py4j.protocol.Py4JJavaError: An error occurred while calling o73.showString.; : org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 2.0 failed 20 times, most recent failure: Lost task 0.19 in stage 2.0 (TID 2520, gnomad-prod-sw-s89f.c.broad-mpg-gnomad.internal): java.lang.IndexOutOfBoundsException: 21; at scala.collection.mutable.ResizableArray$class.apply(ResizableArray.scala:43); at scala.collection.mutable.ArrayBuffer.apply(ArrayBuffer.scala:48); at is.hail.keytable.KeyTable$$anonfun$8$$anonfun$10.apply(KeyTable.scala:68); at is.hail.keytable.KeyTable$$anonfun$8$$anonfun$10.apply(KeyTable.scala:68); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); at scala.collection.AbstractTraversable.map(Traversable.scala:104); at is.hail.keytable.KeyT",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1275:1111,failure,failure,1111,https://hail.is,https://github.com/hail-is/hail/issues/1275,1,['failure'],['failure']
Availability,"bot.com/michel-kraemer/gradle-download-task/issues/284"">#284</a>). Thanks to <a href=""https://github.com/liblit""><code>@liblit</code></a> for testing!</li>; </ul>; <p>Maintenance:</p>; <ul>; <li>Update dependencies</li>; <li>Improve documentation</li>; <li>Add integration tests for Gradle 6.9.3 and 7.6</li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/a0374fc7c895ae53309ea351e989571204e0ea5f""><code>a0374fc</code></a> Bump up version number to 5.3.1</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/612f57a382b8640cc730dc5e75d1c809e3e772bd""><code>612f57a</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/michel-kraemer/gradle-download-task/issues/291"">#291</a> from michel-kraemer/dependabot/npm_and_yarn/screencas...</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/53af1049f5514afe58e884d487d7c57dae47759d""><code>53af104</code></a> Bump http-cache-semantics from 4.1.0 to 4.1.1 in /screencast</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/398c14c05c6448b380ac35c6095598299c5e23c5""><code>398c14c</code></a> Update dependencies</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/15cf7eecfbc17d2466143828b9b69494c6cb6f2b""><code>15cf7ee</code></a> Bump up version number to 5.3.1-SNAPSHOT</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/e3c65ffcb49b9c5a33fde5f31fb63043dbf21134""><code>e3c65ff</code></a> Allow extensions to be created from tasks</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/34e2dd41477f18b1ae3d6d5a71dca5449d6cd1e0""><code>34e2dd4</code></a> Downgrade slf4j to fix warning on console about missing slf4j provider</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/b3fa29f9ffb4d4544e13ef84601e371fb2778ddf""><code>b3fa",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12707:1611,down,download-task,1611,https://hail.is,https://github.com/hail-is/hail/pull/12707,1,['down'],['download-task']
Availability,"bout modifying the client code and how the current billing information is calculated. How this migration works is there are 5 phases:; 1. Compute the expected number of attempts to process for format version < 3. ; 2. Divide the search space into chunks of size 100 attempts (empirically determined this was the best chunk size) and randomize the order of the chunks.; 3. Serially process 5000 chunks with only 10 out of the 100 records as a ""burn in period"" to avoid the birthday problem when trying to insert records in parallel.; 4. In parallel, process all the chunks with 10 way parallelism (empirically determined to max CPU for a 4 core db instance); 5. Do an audit of the results to make sure the attempt resources now has the correct number of rows and the billing is within $0.001 per job with the old way and new way of computing the billing. The tolerance of $0.001 was empirically determined. At a threshold of $0.0001, 33/30,000,000 attempts failed. I think this is good enough as there's always going to be rounding errors. I did not do an explicit audit in the code to make sure the other aggregated_*_resources tables did not change. I spot checked this was correct in my test database. To do the complete audit during the actual migration would take more time. I made sure all the inserts were idempotent. Please double check this. The inserts use a temporary table with an isolation level of read committed. The reason for this is because `INSERT INTO ... SELECT` locks the next gap lock if the isolation level is not read committed. Maybe what I did is overkill and it's no longer a problem with the new burn in period. https://dev.mysql.com/doc/refman/8.0/en/innodb-locks-set.html I'd be interested to hear @danking feedback on what the best query here is to allow parallelism. There are ~30 million attempts that need to be processed for hail-vdc (~60% of the attempts). This will add ~20Gi to the existing database. I use 4 cores to get this migration to be ~3 hours, so we will",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11990:2036,error,errors,2036,https://hail.is,https://github.com/hail-is/hail/pull/11990,1,['error'],['errors']
Availability,"brew/lib/python3.10/site-packages/hail/typecheck/check.py"", line 577, in wrapper; return __original_func(*args_, **kwargs_); File ""/opt/homebrew/lib/python3.10/site-packages/hail/context.py"", line 345, in init; return init_spark(; File ""<decorator-gen-1760>"", line 2, in init_spark; File ""/opt/homebrew/lib/python3.10/site-packages/hail/typecheck/check.py"", line 577, in wrapper; return __original_func(*args_, **kwargs_); File ""/opt/homebrew/lib/python3.10/site-packages/hail/context.py"", line 424, in init_spark; backend = SparkBackend(; File ""/opt/homebrew/lib/python3.10/site-packages/hail/backend/spark_backend.py"", line 188, in __init__; self._jbackend = hail_package.backend.spark.SparkBackend.apply(; File ""/opt/homebrew/lib/python3.10/site-packages/py4j/java_gateway.py"", line 1304, in __call__; return_value = get_return_value(; File ""/opt/homebrew/lib/python3.10/site-packages/py4j/protocol.py"", line 326, in get_return_value; raise Py4JJavaError(; py4j.protocol.Py4JJavaError: An error occurred while calling z:is.hail.backend.spark.SparkBackend.apply.; : java.lang.IllegalAccessError: class org.apache.spark.storage.StorageUtils$ (in unnamed module @0x4d740d85) cannot access class sun.nio.ch.DirectBuffer (in module java.base) because module java.base does not export sun.nio.ch to unnamed module @0x4d740d85; 	at org.apache.spark.storage.StorageUtils$.<init>(StorageUtils.scala:213); 	at org.apache.spark.storage.StorageUtils$.<clinit>(StorageUtils.scala); 	at org.apache.spark.storage.BlockManagerMasterEndpoint.<init>(BlockManagerMasterEndpoint.scala:109); 	at org.apache.spark.SparkEnv$.$anonfun$create$9(SparkEnv.scala:371); 	at org.apache.spark.SparkEnv$.registerOrLookupEndpoint$1(SparkEnv.scala:311); 	at org.apache.spark.SparkEnv$.create(SparkEnv.scala:359); 	at org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:189); 	at org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:277); 	at org.apache.spark.SparkContext.<init>(SparkContext.scala:458); 	at is.hai",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12630:1793,error,error,1793,https://hail.is,https://github.com/hail-is/hail/issues/12630,1,['error'],['error']
Availability,bug report here: https://discuss.hail.is/t/ld-prune-starts-and-stops-error/. @jbloom22 any ideas? You've worked on this stuff a bit,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6223:69,error,error,69,https://hail.is,https://github.com/hail-is/hail/issues/6223,1,['error'],['error']
Availability,"bugpy-2024.6.0-linux-x64/bundled/libs/debugpy/adapter/../../debugpy/launcher/../../debugpy/../debugpy/server/cli.py"", line 284, in run_file; runpy.run_path(target, run_name=""__main__""); File ""/home/edmund/.vscode/extensions/ms-python.debugpy-2024.6.0-linux-x64/bundled/libs/debugpy/_vendored/pydevd/_pydevd_bundle/pydevd_runpy.py"", line 321, in run_path; return _run_module_code(code, init_globals, run_name,; File ""/home/edmund/.vscode/extensions/ms-python.debugpy-2024.6.0-linux-x64/bundled/libs/debugpy/_vendored/pydevd/_pydevd_bundle/pydevd_runpy.py"", line 135, in _run_module_code; _run_code(code, mod_globals, init_globals,; File ""/home/edmund/.vscode/extensions/ms-python.debugpy-2024.6.0-linux-x64/bundled/libs/debugpy/_vendored/pydevd/_pydevd_bundle/pydevd_runpy.py"", line 124, in _run_code; exec(code, run_globals); File ""/home/edmund/.local/src/hail/test.py"", line 34, in <module>; main(); File ""/home/edmund/.local/src/hail/test.py"", line 28, in main; r2_adj = r2_adj.checkpoint(f'{tmp}/adj', overwrite=args.overwrite); File ""<decorator-gen-1508>"", line 2, in checkpoint; File ""/home/edmund/.local/src/hail/hail/python/hail/typecheck/check.py"", line 584, in wrapper; return __original_func(*args_, **kwargs_); File ""/home/edmund/.local/src/hail/hail/python/hail/linalg/blockmatrix.py"", line 679, in checkpoint; self.write(path, overwrite, force_row_major, stage_locally); File ""<decorator-gen-1506>"", line 2, in write; File ""/home/edmund/.local/src/hail/hail/python/hail/typecheck/check.py"", line 584, in wrapper; return __original_func(*args_, **kwargs_); File ""/home/edmund/.local/src/hail/hail/python/hail/linalg/blockmatrix.py"", line 656, in write; Env.backend().execute(BlockMatrixWrite(self._bmir, writer)); File ""/home/edmund/.local/src/hail/hail/python/hail/backend/backend.py"", line 190, in execute; raise e.maybe_user_error(ir) from None; File ""/home/edmund/.local/src/hail/hail/python/hail/backend/backend.py"", line 188, in execute; result, timings = self._rpc(ActionTag.EXECUT",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14537:3251,checkpoint,checkpoint,3251,https://hail.is,https://github.com/hail-is/hail/issues/14537,1,['checkpoint'],['checkpoint']
Availability,"bugpy/launcher/../../debugpy/../debugpy/server/cli.py"", line 284, in run_file; runpy.run_path(target, run_name=""__main__""); File ""/home/edmund/.vscode/extensions/ms-python.debugpy-2024.6.0-linux-x64/bundled/libs/debugpy/_vendored/pydevd/_pydevd_bundle/pydevd_runpy.py"", line 321, in run_path; return _run_module_code(code, init_globals, run_name,; File ""/home/edmund/.vscode/extensions/ms-python.debugpy-2024.6.0-linux-x64/bundled/libs/debugpy/_vendored/pydevd/_pydevd_bundle/pydevd_runpy.py"", line 135, in _run_module_code; _run_code(code, mod_globals, init_globals,; File ""/home/edmund/.vscode/extensions/ms-python.debugpy-2024.6.0-linux-x64/bundled/libs/debugpy/_vendored/pydevd/_pydevd_bundle/pydevd_runpy.py"", line 124, in _run_code; exec(code, run_globals); File ""/home/edmund/.local/src/hail/test.py"", line 34, in <module>; main(); File ""/home/edmund/.local/src/hail/test.py"", line 28, in main; r2_adj = r2_adj.checkpoint(f'{tmp}/adj', overwrite=args.overwrite); File ""<decorator-gen-1508>"", line 2, in checkpoint; File ""/home/edmund/.local/src/hail/hail/python/hail/typecheck/check.py"", line 584, in wrapper; return __original_func(*args_, **kwargs_); File ""/home/edmund/.local/src/hail/hail/python/hail/linalg/blockmatrix.py"", line 679, in checkpoint; self.write(path, overwrite, force_row_major, stage_locally); File ""<decorator-gen-1506>"", line 2, in write; File ""/home/edmund/.local/src/hail/hail/python/hail/typecheck/check.py"", line 584, in wrapper; return __original_func(*args_, **kwargs_); File ""/home/edmund/.local/src/hail/hail/python/hail/linalg/blockmatrix.py"", line 656, in write; Env.backend().execute(BlockMatrixWrite(self._bmir, writer)); File ""/home/edmund/.local/src/hail/hail/python/hail/backend/backend.py"", line 190, in execute; raise e.maybe_user_error(ir) from None; File ""/home/edmund/.local/src/hail/hail/python/hail/backend/backend.py"", line 188, in execute; result, timings = self._rpc(ActionTag.EXECUTE, payload); File ""/home/edmund/.local/src/hail/hail/python/ha",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14537:3343,checkpoint,checkpoint,3343,https://hail.is,https://github.com/hail-is/hail/issues/14537,1,['checkpoint'],['checkpoint']
Availability,build and make available devel jar artifacts in ci,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/754:15,avail,available,15,https://hail.is,https://github.com/hail-is/hail/issues/754,1,['avail'],['available']
Availability,but ends up throwing odd non-specific errors down the line,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1137:38,error,errors,38,https://hail.is,https://github.com/hail-is/hail/issues/1137,2,"['down', 'error']","['down', 'errors']"
Availability,bytecode verification error related to hl.agg._prev_nonnull,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5345:22,error,error,22,https://hail.is,https://github.com/hail-is/hail/issues/5345,1,['error'],['error']
Availability,"c.indexBgen(jindexed_seq_args(path), index_file_map, joption(rg), contig_recoding, skip_invalid_loci); 1958; 1959. /share/pkg/spark/2.2.1/install/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py in __call__(self, *args); 1131 answer = self.gateway_client.send_command(command); 1132 return_value = get_return_value(; -> 1133 answer, self.gateway_client, self.target_id, self.name); 1134; 1135 for temp_arg in temp_args:. /share/pkg/hail/2018-10-31/install/build/distributions/hail-python.zip/hail/utils/java.py in deco(*args, **kwargs); 208 raise FatalError('%s\n\nJava stack trace:\n%s\n'; 209 'Hail version: %s\n'; --> 210 'Error summary: %s' % (deepest, full, hail.__version__, deepest)) from None; 211 except pyspark.sql.utils.CapturedException as e:; 212 raise FatalError('%s\n\nJava stack trace:\n%s\n'. FatalError: OutOfMemoryError: GC overhead limit exceeded. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 1.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1.0 (TID 1, localhost, executor driver): java.lang.OutOfMemoryError: GC overhead limit exceeded; at scala.collection.immutable.VectorBuilder.<init>(Vector.scala:713); at scala.collection.immutable.Vector$.newBuilder(Vector.scala:22); at scala.collection.immutable.IndexedSeq$.newBuilder(IndexedSeq.scala:46); at scala.collection.IndexedSeq$.newBuilder(IndexedSeq.scala:36); at scala.collection.IndexedSeq$$anon$1.apply(IndexedSeq.scala:34); at com.twitter.chill.TraversableSerializer.read(Traversable.scala:39); at com.twitter.chill.TraversableSerializer.read(Traversable.scala:21); at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:708); at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.read(DefaultArraySerializers.java:396); at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.read(DefaultArraySerializers.java:307); at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:708); at co",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4780:7030,failure,failure,7030,https://hail.is,https://github.com/hail-is/hail/issues/4780,1,['failure'],['failure']
Availability,"cal/lib/python3.6/dist-packages/aiomysql/cursors.py\"", line 239, in execute\n await self._query(query)\n File \""/usr/local/lib/python3.6/dist-packages/aiomysql/cursors.py\"", line 457, in _query\n await conn.query(q)\n File \""/usr/local/lib/python3.6/dist-packages/aiomysql/connection.py\"", line 428, in query\n await self._read_query_result(unbuffered=unbuffered)\n File \""/usr/local/lib/python3.6/dist-packages/aiomysql/connection.py\"", line 622, in _read_query_result\n await result.read()\n File \""/usr/local/lib/python3.6/dist-packages/aiomysql/connection.py\"", line 1105, in read\n first_packet = await self.connection._read_packet()\n File \""/usr/local/lib/python3.6/dist-packages/aiomysql/connection.py\"", line 593, in _read_packet\n packet.check_error()\n File \""/usr/local/lib/python3.6/dist-packages/pymysql/protocol.py\"", line 220, in check_error\n err.raise_mysql_exception(self._data)\n File \""/usr/local/lib/python3.6/dist-packages/pymysql/err.py\"", line 109, in raise_mysql_exception\n raise errorclass(errno, errval)\npymysql.err.OperationalError: (1213, 'Deadlock found when trying to get lock; try restarting transaction')""; }; {; ""levelname"": ""INFO"",; ""asctime"": ""2019-07-02 13:17:00,609"",; ""filename"": ""web_log.py"",; ""funcNameAndLine"": ""log:233"",; ""message"": ""10.32.4.181 [02/Jul/2019:13:17:00 +0000] \""POST /api/v1alpha/batches/278/jobs/create HTTP/1.0\"" 500 225 \""-\"" \""Python/3.7 aiohttp/3.5.4\"""",; ""remote_address"": ""10.32.4.181"",; ""request_start_time"": ""[02/Jul/2019:13:17:00 +0000]"",; ""first_request_line"": ""POST /api/v1alpha/batches/278/jobs/create HTTP/1.0"",; ""response_status"": 500,; ""response_size"": 225,; ""request_header"": {; ""Referer"": ""-"",; ""User-Agent"": ""Python/3.7 aiohttp/3.5.4""; }; }; ```; ```; Traceback (most recent call last):; File ""/usr/local/lib/python3.6/dist-packages/aiohttp/web_protocol.py"", line 418, in start; resp = await task; File ""/usr/local/lib/python3.6/dist-packages/aiohttp/web_app.py"", line 458, in _handle; resp = await handler(request); Fil",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6543:2162,error,errorclass,2162,https://hail.is,https://github.com/hail-is/hail/issues/6543,1,['error'],['errorclass']
Availability,"cal/lib/python3.6/dist-packages/batch/front_end/front_end.py"", line 383, in ui_get_job_log; 'job_log': await _get_job_log(request.app, batch_id, job_id, user); File ""/usr/local/lib/python3.6/dist-packages/batch/front_end/front_end.py"", line 112, in _get_job_log; job_log = await job._read_logs(); File ""/usr/local/lib/python3.6/dist-packages/batch/batch.py"", line 49, in _read_logs; return await self.app['driver'].read_pod_logs(self._pod_name); File ""/usr/local/lib/python3.6/dist-packages/aiohttp/web_app.py"", line 160, in __getitem__; return self._state[key]; KeyError: 'driver'; ```. ```; Traceback (most recent call last):; File ""/usr/local/lib/python3.6/dist-packages/google/cloud/storage/blob.py"", line 636, in download_to_file; self._do_download(transport, file_obj, download_url, headers, start, end); File ""/usr/local/lib/python3.6/dist-packages/google/cloud/storage/blob.py"", line 574, in _do_download; download.consume(transport); File ""/usr/local/lib/python3.6/dist-packages/google/resumable_media/requests/download.py"", line 171, in consume; self._process_response(result); File ""/usr/local/lib/python3.6/dist-packages/google/resumable_media/_download.py"", line 171, in _process_response; response, _ACCEPTABLE_STATUS_CODES, self._get_status_code; File ""/usr/local/lib/python3.6/dist-packages/google/resumable_media/_helpers.py"", line 96, in require_status_code; *status_codes; google.resumable_media.common.InvalidResponse: ('Request failed with status code', 403, 'Expected one of', <HTTPStatus.OK: 200>, <HTTPStatus.PARTIAL_CONTENT: 206>). During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/usr/local/lib/python3.6/dist-packages/aiohttp/web_protocol.py"", line 418, in start; resp = await task; File ""/usr/local/lib/python3.6/dist-packages/aiohttp/web_app.py"", line 458, in _handle; resp = await handler(request); File ""/usr/local/lib/python3.6/dist-packages/aiohttp/web_middlewares.py"", line 119, in impl; return await hand",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7412:2039,down,download,2039,https://hail.is,https://github.com/hail-is/hail/pull/7412,1,['down'],['download']
Availability,cala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); 	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186); 	at is.hail.expr.Parser$$anonfun$parseNamedExprs$3.apply(Parser.scala:229); 	at is.hail.expr.Parser$$anonfun$parseNamedExprs$3.apply(Parser.scala:228); 	at is.hail.expr.Parser$$anonfun$parseAnnotationExprs$4.apply(Parser.scala:115); 	at is.hail.expr.Parser$$anonfun$parseAnnotationExprs$4.apply(Parser.scala:114); 	at is.hail.variant.VariantSampleMatrix$$anonfun$34.apply(VariantSampleMatrix.scala:544); 	at is.hail.variant.VariantSampleMatrix$$anonfun$34.apply(VariantSampleMatrix.scala:540); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); 	at scala.collection.AbstractTraversable.map(Traversable.scala:104); 	at is.hail.variant.VariantSampleMatrix.annotateSamplesExpr(VariantSampleMatrix.scala:540); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:280); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:214); 	at java.lang.Thread.run(Thread.java:745). Hail version: devel-e081278; Error summary: IndexOutOfBoundsException: 0; ```,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1705:5904,Error,Error,5904,https://hail.is,https://github.com/hail-is/hail/issues/1705,1,['Error'],['Error']
Availability,cala.collection.Iterator$$anon$11.hasNext(Iterator.scala:490); 	at is.hail.rvd.RVD$.$anonfun$getKeyInfo$2(RVD.scala:1030); 	at is.hail.rvd.RVD$.$anonfun$getKeyInfo$2$adapted(RVD.scala:1029); 	at is.hail.sparkextras.ContextRDD.$anonfun$crunJobWithIndex$1(ContextRDD.scala:242); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90); 	at org.apache.spark.scheduler.Task.run(Task.scala:136); 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548); 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551); 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128); 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628); 	at java.base/java.lang.Thread.run(Thread.java:829); Caused by: is.hail.utils.HailException: cannot set missing field for required type +PFloat64; 	at is.hail.utils.ErrorHandling.fatal(ErrorHandling.scala:18); 	at is.hail.utils.ErrorHandling.fatal$(ErrorHandling.scala:18); 	at is.hail.utils.package$.fatal(package.scala:81); 	at is.hail.annotations.RegionValueBuilder.setMissing(RegionValueBuilder.scala:207); 	at is.hail.io.vcf.VCFLine.parseAddInfoArrayDouble(LoadVCF.scala:1034); 	at is.hail.io.vcf.VCFLine.parseAddInfoField(LoadVCF.scala:1055); 	at is.hail.io.vcf.VCFLine.addInfoField(LoadVCF.scala:1075); 	at is.hail.io.vcf.VCFLine.parseAddInfo(LoadVCF.scala:1112); 	at is.hail.io.vcf.LoadVCF$.parseLineInner(LoadVCF.scala:1541); 	at is.hail.io.vcf.LoadVCF$.parseLine(LoadVCF.scala:1409); 	at is.hail.io.vcf.MatrixVCFReader.$anonfun$executeGeneric$7(LoadVCF.scala:1916); 	... 21 more. Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2673); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2609); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapte,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14102:9128,Error,ErrorHandling,9128,https://hail.is,https://github.com/hail-is/hail/issues/14102,1,['Error'],['ErrorHandling']
Availability,"cala:198); at org.apache.spark.sql.DataFrameWriter.parquet(DataFrameWriter.scala:494); at is.hail.variant.VariantDatasetFunctions$.write$extension(VariantDataset.scala:751); at is.hail.variant.VariantDatasetFunctions.write(VariantDataset.scala:721); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); at py4j.Gateway.invoke(Gateway.java:280); at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); at py4j.commands.CallCommand.execute(CallCommand.java:79); at py4j.GatewayConnection.run(GatewayConnection.java:214); at java.lang.Thread.run(Thread.java:748)org.apache.spark.SparkException: Job aborted due to stage failure: Task 754 in stage 1.0 failed 1 times, most recent failure: Lost task 754.0 in stage 1.0 (TID 1625, localhost, executor driver): org.apache.spark.SparkException: Task failed while writing rows; at org.apache.spark.sql.execution.datasources.FileFormatWriter$.org$apache$spark$sql$execution$datasources$FileFormatWriter$$executeTask(FileFormatWriter.scala:204); at org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$write$1$$anonfun$3.apply(FileFormatWriter.scala:129); at org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$write$1$$anonfun$3.apply(FileFormatWriter.scala:128); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:99); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); at jav",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2407:4128,failure,failure,4128,https://hail.is,https://github.com/hail-is/hail/issues/2407,1,['failure'],['failure']
Availability,"cala:2118); at org.apache.spark.SparkContext$$anonfun$33.apply(SparkContext.scala:2118); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:108); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); ... 1 more. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/tmp/b09ec92a-49f4-4d16-ad6d-efc5a5805e92/05_variant_qc.py"", line 201, in <module>; cumcounts = {'step0': rt.aggregate(hl.agg.sum(hl.cond(rt.qccum.step0, 1, 0))),; File ""<decorator-gen-519>"", line 2, in aggregate; File ""/home/hail/hail.zip/hail/utils/java.py"", line 191, in handle_py4j; hail.utils.java.FatalError: AssertionError: assertion failed. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 7 in stage 6.0 failed 20 times, most recent failure: Lost task 7.19 in stage 6.0 (TID 179, robert1-w-0.c.ccdg-wgs.internal, executor 4): java.lang.AssertionError: assertion failed; at scala.Predef$.assert(Predef.scala:156); at is.hail.annotations.RegionValueBuilder.endStruct(RegionValueBuilder.scala:109); at is.hail.variant.MatrixTable$$anonfun$filterGenotypes$1$$anonfun$apply$80.apply(MatrixTable.scala:2645); at is.hail.variant.MatrixTable$$anonfun$filterGenotypes$1$$anonfun$apply$80.apply(MatrixTable.scala:2615); at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); at is.hail.rvd.OrderedRVD$$anonfun$apply$6$$anon$5.next(OrderedRVD.scala:736); at is.hail.rvd.OrderedRVD$$anonfun$apply$6$$anon$5.next(OrderedRVD.scala:730); at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); at is.hail.rvd.OrderedRVD$$anonfun$apply$6$$anon$5.next(OrderedRVD.scala:736); at is.hail.rvd.OrderedRVD$$anonfun$apply$6$$anon$5.next(OrderedRVD.scala:730); at scala.colle",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3063:11852,failure,failure,11852,https://hail.is,https://github.com/hail-is/hail/issues/3063,1,['failure'],['failure']
Availability,cala:490); 	at is.hail.rvd.RVD$.$anonfun$getKeyInfo$2(RVD.scala:1030); 	at is.hail.rvd.RVD$.$anonfun$getKeyInfo$2$adapted(RVD.scala:1029); 	at is.hail.sparkextras.ContextRDD.$anonfun$crunJobWithIndex$1(ContextRDD.scala:242); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90); 	at org.apache.spark.scheduler.Task.run(Task.scala:136); 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548); 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551); 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128); 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628); 	at java.base/java.lang.Thread.run(Thread.java:829). is.hail.utils.HailException: cannot set missing field for required type +PFloat64; 	at is.hail.utils.ErrorHandling.fatal(ErrorHandling.scala:18); 	at is.hail.utils.ErrorHandling.fatal$(ErrorHandling.scala:18); 	at is.hail.utils.package$.fatal(package.scala:81); 	at is.hail.annotations.RegionValueBuilder.setMissing(RegionValueBuilder.scala:207); 	at is.hail.io.vcf.VCFLine.parseAddInfoArrayDouble(LoadVCF.scala:1034); 	at is.hail.io.vcf.VCFLine.parseAddInfoField(LoadVCF.scala:1055); 	at is.hail.io.vcf.VCFLine.addInfoField(LoadVCF.scala:1075); 	at is.hail.io.vcf.VCFLine.parseAddInfo(LoadVCF.scala:1112); 	at is.hail.io.vcf.LoadVCF$.parseLineInner(LoadVCF.scala:1541); 	at is.hail.io.vcf.LoadVCF$.parseLine(LoadVCF.scala:1409); 	at is.hail.io.vcf.MatrixVCFReader.$anonfun$executeGeneric$7(LoadVCF.scala:1916); 	at is.hail.io.vcf.MatrixVCFReader.$anonfun$executeGeneric$7$adapted(LoadVCF.scala:1909); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:515); 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460); 	at __C678stream_Let.apply(Emit.scala); 	at is.hail.expr.ir.CompileIterator$$anon$2.step(Compile.scala:302); 	at is.hail.expr.ir.Comp,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14102:18734,Error,ErrorHandling,18734,https://hail.is,https://github.com/hail-is/hail/issues/14102,1,['Error'],['ErrorHandling']
Availability,"call last):; File ""foo.py"", line 7, in <module>; t.write('foo.ht', overwrite=True); File ""/Users/cseed/hail/python/hail/typecheck/check.py"", line 547, in wrapper; return f(*args_, **kwargs_); File ""/Users/cseed/hail/python/hail/table.py"", line 1183, in write; self._jt.write(output, overwrite, stage_locally, _codec_spec); File ""/Users/cseed/py4j/java_gateway.py"", line 1133, in __call__; answer, self.gateway_client, self.target_id, self.name); File ""/Users/cseed/hail/python/hail/utils/java.py"", line 200, in deco; 'Error summary: %s' % (deepest, full, hail.__version__, deepest)) from None; hail.utils.java.FatalError: HailException: OrderedRVD error! Unexpected key in partition 7; Range bounds for partition 7: ([0.8599223493342859]-[0.9976076885349009]]; Key should be in partition 7: ([0.8599223493342859]-[0.9976076885349009]]; Invalid key: [0.9986274705095608]. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 7 in stage 2.0 failed 1 times, most recent failure: Lost task 7.0 in stage 2.0 (TID 23, localhost, executor driver): is.hail.utils.HailException: OrderedRVD error! Unexpected key in partition 7; Range bounds for partition 7: ([0.8599223493342859]-[0.9976076885349009]]; Key should be in partition 7: ([0.8599223493342859]-[0.9976076885349009]]; Invalid key: [0.9986274705095608]; 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:9); 	at is.hail.utils.package$.fatal(package.scala:26); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$21$$anon$3.next(OrderedRVD.scala:1031); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$21$$anon$3.next(OrderedRVD.scala:1011); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at scala.collection.Iterator$class.foreach(Iterator.scala:893); 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); 	at is.hail.io.RichContextRDDRegionValue$.writeRowsPartition(RowStore.scala:1071); 	at is.hail.io.RichContextRDDRegionValue$$anonfun$writeRows$extension$1.apply(RowStore.scala:1",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4096:1289,failure,failure,1289,https://hail.is,https://github.com/hail-is/hail/issues/4096,1,['failure'],['failure']
Availability,"cally created by Snyk using the credentials of a real user.</p><br /><h3>Snyk has created this PR to fix one or more vulnerable packages in the `pip` dependencies of this project.</h3>. #### Changes included in this PR. - Changes to the following files to upgrade the vulnerable dependencies to a fixed version:; - hail/python/hailtop/pinned-requirements.txt. <details>; <summary> <b>Warning</b></summary>. ```; aiosignal 1.3.1 requires frozenlist, which is not installed.; aiohttp 3.8.5 requires frozenlist, which is not installed. ```; </details>. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **471/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 3.7 | Insufficient Verification of Data Authenticity <br/>[SNYK-PYTHON-CRYPTOGRAPHY-5813745](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5813745) | `cryptography:` <br> `41.0.2 -> 41.0.3` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **551/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 5.3 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-5813746](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5813746) | `cryptography:` <br> `41.0.2 -> 41.0.3` <br> | No | No Known Exploit ; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **471/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 3.7 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-5813750](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5813750) | `cryptography:` <br> `41.0.2 ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13366:1054,avail,available,1054,https://hail.is,https://github.com/hail-is/hail/pull/13366,1,['avail'],['available']
Availability,"casa/hail.ds/gatk.hc/gcad.5k.snv.vqsr.pass'); print(""Filtering Common Variants""); common=passed.filter_rows(passed.variant_qc.AF > 0.01).persist(); common.write('/project/casa/hail.ds/gatk.hc/gcad.5k.snv.vqsr.pass.common'); print(""Pruning LD Variants""); pruned =hl.ld_prune(common,30,r2=0.1, memory_per_core=2048); pruned.write('/project/casa/hail.ds/gatk.hc/gcad.5k.snv.vqsr.pruned'); print(""Sample 20% of variants for running PC-Relate""); pruned_subsample = pruned.sample_rows(0.2).persist(); print(""Running PC_Relate""); rel = hl.pc_relate(pruned_subsample.GT, 0.01, k=10); rel_df = rel.to_pandas(); rel_df.describe(); pprint(rel_df); rel_df.to_csv('gcad_5k.snv.rel.csv'); ```. ### What went wrong (all error messages here, including the full java stack trace):. Got a memory error. but not sure what memory needs to be increased. The job seems to restart but does not progress and need to kill. . java.lang.OutOfMemoryError: Java heap spaceop. Running on Apache Spark version 2.2.0; SparkUI available at http://10.48.225.55:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version devel-63d60cc; NOTE: This is a beta version. Interfaces may change; during the beta period. We also recommend pulling; the latest changes weekly.; Read in PASS SNVs; Filtering Common Variants; [Stage 0:==================================================>(96600 + 1) / 96601]2018-04-27 20:54:43 Hail: INFO: wrote 11341822 items in 96601 partitions; Pruning LD Variants; [Stage 1:==================================================>(96598 + 3) / 96601]2018-04-27 21:19:04 Hail: INFO: Running LD prune with nSamples=4795, nVariants=11341822, nPartitions=96601, and maxQueueSize=429841.; [Stage 2:=========================================> (79823 + 18) / 96601]java.lang.OutOfMemoryError: Java heap spaceop""; at java.util.Arrays.copyOf(Arrays.java:3181); at java.util.ArrayList.toArray(ArrayList.java:376); at java.util.Collections$SynchronizedCollection.toArray(Collections.java:2024); at ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3463:2219,avail,available,2219,https://hail.is,https://github.com/hail-is/hail/issues/3463,1,['avail'],['available']
Availability,"case. I do explicitly pull the worker image (with one retry) before trying to run it.; - Batch and Job are gone. database.py is effectively gone. Almost everywhere interacts directly with the database using the simple gear.Database interface, and drops down to aiomysql directly when that is insufficient (e.g. transaction with multiple executemany for /jobs/create). When we pass around data representing a job or batch, it's normally a data record (a dict).; - Added the running log test from your PR.; - The job status is no longer written to a file, just in the database jobs.status.; - I moved the INSTANCE_ID to the database. There is now a table called tokens. It has the instance id and a token for securing communication between the front end and the driver (currently unused).; - Operations that need to be atomic in the database are now implemented as stored procedures which can be called with the check_call_procedure helper in database.py. They return a row with a field rc (return code) that is 0 on success and non-zero on failure.; - Renamed Driver => Scheduler. Scheduler has two threads, one that schedules jobs that are in the Ready state, and one that cancels cancelled jobs in the Running state. There is a new job state Ready. A job is Ready if its parents are complete and it is not scheduled (instance_id is null). A job is Running if it is scheduled (instance_id is not null).; - The full set of instances are mirrored in memory as Instance objects.; - Added a ready_cores table with a single row that has the total core count of the ready jobs. It is updated by the stored procedures as jobs are scheduled/unscheduled/marked complete. It is used by the instance pool control loop. This is great, and something we couldn't easily see before. Things that got removed that I will add back in the next PRs:; - Database retries; - Instance pool heal loop; - Instance health; - attempt tokens (from the Google backend). These are all pretty easy. Then back to scale tests. Let me",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7420:1598,failure,failure,1598,https://hail.is,https://github.com/hail-is/hail/pull/7420,1,['failure'],['failure']
Availability,"cc @cseed . Is this something you would be interested in having back in the codebase? Konrad and Alicia would like it, and it could be helpful for debugging, since Hail errors (say stuck jobs) often require the log, and users have to remember to persist those logs and send them to us.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7392:169,error,errors,169,https://hail.is,https://github.com/hail-is/hail/issues/7392,1,['error'],['errors']
Availability,"cc: @cseed . ---. Root issue is that `alpine` does not have `/bin/bash`, so we use `/bin/sh` instead. The syntax for the loops is POSIX compliant. ---. Interesting, these pods were failing due to:. ```; State: Terminated; Reason: ContainerCannotRun; Message: oci runtime error: container_linux.go:247: starting container process caused ""exec: \""/bin/bash\"": stat /bin/bash: no such file or directory"". Exit Code: 127; Started: Fri, 18 Jan 2019 16:15:45 -0500; Finished: Fri, 18 Jan 2019 16:15:45 -0500; Ready: False; ```. But this didn't fail the tests. I suppose because we cancel it faster than k8s realizes the container cannot run and notifies batch?",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5175:271,error,error,271,https://hail.is,https://github.com/hail-is/hail/pull/5175,1,['error'],['error']
Availability,"cc: @cseed @konradjk . This PCRelate should handle larger data sizes than the previous one by avoiding shuffles. It avoids the shuffle by writing the vds to a temporary directory in block matrix form. It then loads this BlockMatrix directly. Form that point forward, the PCRelate algorithm is just non-shuffling linear algebra (however: matrix multiplication will require each node to communicate with approximately `n+m` other nodes). I'm vaguely uncomfortable with two things:. 1. I've added some hail expr lang to mean impute missing values. This is written in python. As such, correctly mean imputing is not tested by our test system any more. The mean imputation is pretty simple, so maybe we should just verify my code is right?. 2. I noticed that at some earlier point PCA was moved outside of Java as well. This also makes me uncomfortable for the same reason. Moving the tests into python is a fair lift because, AFAIK, we don't have as robust test infrastructure over there. I'm torn between the desire to get this out for @konradjk and the desire to follow our normal testing standards. ---. I've played a bit with this locally, but have not tried it on a large cluster. @konradjk, I would be very interested in how this performs on a large dataset, if you would be so kind. Please don't try this until the CI tests and doc builds pass on this PR though. I haven't run the tests locally, so I'm not certain it passes them :P",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2821:946,robust,robust,946,https://hail.is,https://github.com/hail-is/hail/pull/2821,1,['robust'],['robust']
Availability,"cc: @daniel-goldstein, this is a tricky asyncio situation which you should also keep in mind. OK, there were two problems:. 1. A timeout of 5s appears to be now too short for Google Cloud Storage. I am not sure why but we; timeout substantially more frequently. I have observed this myself on my laptop. Just this; morning I saw it happen to Daniel. 2. When using an `aiohttp.AsyncIterablePayload`, it is *critical* to always check if the coroutine; which actually writes to GCS (which is stashed in the variable `request_task`) is still; alive. In the current `main`, we do not do this which causes hangs (in particular the timeout; exceptions are never thrown ergo we never retry). To understand the second problem, you must first recall how writing works in aiogoogle. There are; two Tasks and an `asyncio.Queue`. The terms ""writer"" and ""reader"" are somewhat confusing, so let's; use left and right. The left Task has the owning reference to both the source ""file"" and the; destination ""file"". In particular, it is the *left* Task which closes both ""files"". Moreover, the; left Task reads chunks from the source file and places those chunks on the `asyncio.Queue`. The; right Task takes chunks off the queue and writes those chunks to the destination file. This situation can go awry in two ways. First, if the right Task encounters any kind of failure, it will stop taking chunks off of the; queue. When the queue (which has a size limit of one) is full, the left Task will hang. The system; is stuck. The left Task will wait forever for the right Task to empty the queue. The second scenario is exactly the same except that the left Task is trying to add the ""stop""; message to the queue rather than a chunk. In either case, it is critical that the left Task waits simultaneously on the queue operation *and*; on the right Task completing. If the right Task has died, no further writes can occur and the left; Task must raise an exception. In the first scenario, we do not observe the right Task'",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11830:539,alive,alive,539,https://hail.is,https://github.com/hail-is/hail/pull/11830,1,['alive'],['alive']
Availability,"cc: @danking . Here is the first major database migration. The goal is to add all attempt resources into the database for any attempt with batch format version less than 3. The node configuration was the same for all attempts back then with standard instances, 16 cores, and a 100GB boot disk. I figured out what the quantity for each resource should be by looking at how we compute quantities for resources in `batch/batch/resources.py`. I checked the inserted quantities are identical to the attempts that already exist in the database right after we converted the billing over to using resources. Once we have all resources for all attempts, the next step (future PR) is to do a scan and repopulate the new aggregated billing tables **by date**. In this PR, I don't try and add the usage to the existing `aggregated_*_resources` tables. I did this to cut down on time and space since we're eventually going to deprecate those tables anyways. Because I don't touch those tables, we don't need to worry about modifying the client code and how the current billing information is calculated. How this migration works is there are 5 phases:; 1. Compute the expected number of attempts to process for format version < 3. ; 2. Divide the search space into chunks of size 100 attempts (empirically determined this was the best chunk size) and randomize the order of the chunks.; 3. Serially process 5000 chunks with only 10 out of the 100 records as a ""burn in period"" to avoid the birthday problem when trying to insert records in parallel.; 4. In parallel, process all the chunks with 10 way parallelism (empirically determined to max CPU for a 4 core db instance); 5. Do an audit of the results to make sure the attempt resources now has the correct number of rows and the billing is within $0.001 per job with the old way and new way of computing the billing. The tolerance of $0.001 was empirically determined. At a threshold of $0.0001, 33/30,000,000 attempts failed. I think this is good enough as t",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11990:858,down,down,858,https://hail.is,https://github.com/hail-is/hail/pull/11990,1,['down'],['down']
Availability,cc: @jigold. I am honestly not sure how this should interact with terraform. We do specify the; node pools there. I worry that using terraform to change the node pools would create; downtime.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11443:182,downtime,downtime,182,https://hail.is,https://github.com/hail-is/hail/pull/11443,1,['downtime'],['downtime']
Availability,cc: @tpoterba . Previously stderr ended up in the build log while stdout ended up in the per-task log. This change ensures all output (err or out) goes to the log. The only information in the build log is about the orchestration script. This should make debugging CI build failures much easier because stderr and stdout are in one place.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4581:273,failure,failures,273,https://hail.is,https://github.com/hail-is/hail/pull/4581,1,['failure'],['failures']
Availability,"cc: @tpoterba @konradjk . Include the words success and failure and some color, but preserve the exit code. Also, banish tabs.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6054:56,failure,failure,56,https://hail.is,https://github.com/hail-is/hail/pull/6054,1,['failure'],['failure']
Availability,"cc: @tpoterba @patrick-schultz @catoverdrive . We are not allowed to clear a region we do not own. Someone should test this doesn't blow memory on a severe filter in the cloud. ---. Prevent segfaults when joining two tables using `t1.join(t2)`. This syntax does a ""product join"", i.e., a normal join. The `t2[t1.key]` syntax takes only one matching element from `t2` for each element in `t1`. When performing a ""product join"", hail keeps a side-buffer of region values from the right-hand-side table. This side buffer *must not be cleared* by down stream operations (it is owned by the join node). Unfortunately, hail's filter method was incorrectly clearing regions it might not own. This bug only appeared as a segfault when `t1.join(t2)` was followed by a filter.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5421:543,down,down,543,https://hail.is,https://github.com/hail-is/hail/pull/5421,1,['down'],['down']
Availability,"cc: @tpoterba I added some new type check stuff. I added `round` `ceil` and `floor` as I was writing tests and then I didn't need them. They still seem useful, so I included them. I had to add a tolerance parameter to `Table.same` and my implementation is kind of ugly and bad but I can't think of an obviously better way to do this. Example usages:. ```python; imputed_sex = methods.impute_sex(ds.v.locus(), ds.GT); ```. ```python; imputed_sex = methods.impute_sex(ds.v.locus(), ; ds.GT,; aaf=gnomad.AF); ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2852:195,toler,tolerance,195,https://hail.is,https://github.com/hail-is/hail/pull/2852,1,['toler'],['tolerance']
Availability,"cc: the ""services team"" @cseed, @johnc1231. This fixes gateway to log the user's IP. Forthcoming PRs will fix all downstream; services. ---. There are two important pieces of which to be aware:. - The gateway pod are exposed via the gateway Service, which is the only; object modified in this PR.; - K8s fulfills our request for the gateway Service by creating a [Google TCP; LoadBalancer](https://console.cloud.google.com/net-services/loadbalancing/loadBalancers/list). Moreover,; we specify `loadBalancerIP` which is a manually (outside of k8s) allocated IP; which we expose on the public internet. When you `curl https://hail.is` this is what happens:. - Your packet travels across the internet until it reaches the Google TCP; LoadBalancer; - The Google TCP LoadBalancer selects one of the kubernetes nodes to send the; packet to (in principle, it could send the packet to *any* node, even nodes; that do not have a gateway pod).; - Some part of k8s receives the packet and discovers the nodes that host a; gateway pod.; - It selects a gateway pod and forwards the packet to the node (possibly itself); hosting that gateway pod. In doing so, *it must replace the source IP of the; packet with its own, internal, IP*. Note that this is happening at the TCP layer, so no HTTP headers are set. When; the gateway `nginx` receives the packet, there is no trace of the source; IP. Kubernetes has a feature called `externalTrafficPolicy` which is available; in GCP and Azure and preserves the source IP. Kubernetes achieves this by; failing the TCP LoadBalancer healthchecks on nodes without matching pods (in our; case, gateway). The k8s docs on [Source IPs](https://kubernetes.io/docs/tutorials/services/source-ip/#source-ip-for-services-with-type-loadbalancer) further explain this strategy. Here's what the healthchecks look like for two; nodes, one hosting a gateway pod and one not hosting a gateway pod (note the; HTTP status code):. ```; dking@gke-vdc-preemptible-pool-2-9aa4dbeb-wvxk ~ $ curl -v",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8045:114,down,downstream,114,https://hail.is,https://github.com/hail-is/hail/pull/8045,1,['down'],['downstream']
Availability,"ccessfully, the job is marked as scheduled.; 4. Once all requests complete, goto 1. On the worker, what happens inside `/api/v1alpha/batches/jobs/create`:; 1. Read metadata describing the job to schedule from the request body; 2. Using that information, load the full job spec from blob storage; 3. Spawn a task to run the job asynchronously; 4. Respond to the driver with a 200. The key point relevant to this issue is that the driver currently must wait for all the requests to workers in an iteration to complete before it starts the next iteration of the scheduler. This leaves the scheduler vulnerable to problematic workers or workers that happen to be preempted during the scheduling process. So, the driver sets a [2 second timeout](https://github.com/hail-is/hail/blob/b27737f67bf9e69f1abed2fec07fc7c921790ef8/batch/batch/driver/job.py#L585) on the call to `/api/v1alpha/batches/jobs/create`. Additionally, this general design means that in the event of a request timeout or transient error, Batch cannot guarantee that there is always at most one concurrent running attempt for a given job. This ends up being a fine (and intentional) concession in practice because the idempotent design of preemptible jobs tends to cover this scenario, but it is regardless wasted compute and cost to users. Nevertheless, we strive to minimize cases where we might halt the scheduling loop or double-schedule work, and one way to do that in the current design is to minimize the variance in latency of `/api/v1alpha/batches/jobs/create`. The largest source of this latency is the request to blob storage. While GCS and ABS are relatively fast and highly available, Batch in Azure Terra requires first obtaining SAS tokens from the Terra control plane, which can introduce much higher and more variable latency. There have also been occurrences in the past of corrupted or deleted specs, which introduce unexpected failure modes that should error the job but instead disrupt the scheduling loop. Many of the",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14456:1435,error,error,1435,https://hail.is,https://github.com/hail-is/hail/issues/14456,1,['error'],['error']
Availability,"cda4ca9a617?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr).  [Adjust project settings](https://app.snyk.io/org/danking/project/fa47fca0-549b-41a3-8bf7-bcda4ca9a617?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings).  [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""8f2f7ae4-0cec-47e6-822f-e81b1067da22"",""prPublicId"":""8f2f7ae4-0cec-47e6-822f-e81b1067da22"",""dependencies"":[{""name"":""ipython"",""from"":""7.34.0"",""to"":""8.10.0""},{""name"":""jupyter-server"",""from"":""1.24.0"",""to"":""2.7.2""},{""name"":""numpy"",""from"":""1.21.3"",""to"":""1.22.2""},{""name"":""setuptools"",""from"":""39.0.1"",""to"":""65.5.1""},{""name"":""tornado"",""from"":""6.2"",""to"":""6.3.3""}],""packageManager"":""pip"",""projectPublicId"":""fa47fca0-549b-41a3-8bf7-bcda4ca9a617"",""projectUrl"":""https://app.snyk.io/org/danking/project/fa47fca0-549b-41a3-8bf7-bcda4ca9a617?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-IPYTHON-3318382"",""SNYK-PYTHON-JUPYTERSERVER-5862881"",""SNYK-PYTHON-JUPYTERSERVER-5862882"",""SNYK-PYTHON-NUMPY-2321964"",""SNYK-PYTHON-NUMPY-2321966"",""SNYK-PYTHON-NUMPY-2321970"",""SNYK-PYTHON-SETUPTOOLS-3180412"",""SNYK-PYTHON-TORNADO-5537286"",""SNYK-PYTHON-TORNADO-5840803""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""pr-warning-shown"",""priorityScore""],""priorityScoreList"":[531,null,null,null,null,null,509,384,494],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**.  [Remote Code Execution (RCE)](https://learn.snyk.io/lesson/improper-input-validation/?loc&#x3D;fix-pr);  [Access Control Bypass](https://learn.snyk.io/lesson/broken-access-control/?loc&#x3D;fix-pr);  [Open Redirect](https://learn.snyk.io/lesson/open-redirect/?loc&#x3D;fix-pr);  [More lessons are available in Snyk Learn](https://learn.snyk.io/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13871:7086,avail,available,7086,https://hail.is,https://github.com/hail-is/hail/pull/13871,1,['avail'],['available']
Availability,"cda4ca9a617?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings).  [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""f06f3836-ea3a-4143-ba99-12b7ad33753d"",""prPublicId"":""f06f3836-ea3a-4143-ba99-12b7ad33753d"",""dependencies"":[{""name"":""aiohttp"",""from"":""3.8.6"",""to"":""3.9.2""},{""name"":""ipython"",""from"":""7.34.0"",""to"":""8.10.0""},{""name"":""jupyter-server"",""from"":""1.24.0"",""to"":""2.11.2""},{""name"":""setuptools"",""from"":""39.0.1"",""to"":""65.5.1""},{""name"":""tornado"",""from"":""6.2"",""to"":""6.3.3""}],""packageManager"":""pip"",""projectPublicId"":""fa47fca0-549b-41a3-8bf7-bcda4ca9a617"",""projectUrl"":""https://app.snyk.io/org/danking/project/fa47fca0-549b-41a3-8bf7-bcda4ca9a617?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-AIOHTTP-6091621"",""SNYK-PYTHON-AIOHTTP-6091622"",""SNYK-PYTHON-AIOHTTP-6209406"",""SNYK-PYTHON-AIOHTTP-6209407"",""SNYK-PYTHON-IPYTHON-3318382"",""SNYK-PYTHON-JUPYTERSERVER-5862881"",""SNYK-PYTHON-JUPYTERSERVER-5862882"",""SNYK-PYTHON-JUPYTERSERVER-6099119"",""SNYK-PYTHON-SETUPTOOLS-3180412"",""SNYK-PYTHON-TORNADO-5537286"",""SNYK-PYTHON-TORNADO-5840803"",""SNYK-PYTHON-TORNADO-6041512""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""pr-warning-shown""],""priorityScoreList"":[null,null,null,null,531,null,null,null,509,384,494,539],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**.  [Improper Input Validation](https://learn.snyk.io/lesson/improper-input-validation/?loc&#x3D;fix-pr);  [Improper Limitation of a Pathname to a Restricted Directory (&#x27;Path Traversal&#x27;)](https://learn.snyk.io/lesson/directory-traversal/?loc&#x3D;fix-pr);  [Access Control Bypass](https://learn.snyk.io/lesson/broken-access-control/?loc&#x3D;fix-pr);  [More lessons are available in Snyk Learn](https://learn.snyk.io/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14259:7735,avail,available,7735,https://hail.is,https://github.com/hail-is/hail/pull/14259,1,['avail'],['available']
Availability,"ced from <a href=""https://github.com/pallets/click/releases"">click's releases</a>.</em></p>; <blockquote>; <h2>8.1.3</h2>; <p>This is a fix release for the <a href=""https://github.com/pallets/click/releases/tag/8.1.0"">8.1.0</a> feature release.</p>; <ul>; <li>Changes: <a href=""https://click.palletsprojects.com/en/8.1.x/changes/#version-8-1-3"">https://click.palletsprojects.com/en/8.1.x/changes/#version-8-1-3</a></li>; <li>Milestone: <a href=""https://github.com/pallets/click/milestone/18?closed=1"">https://github.com/pallets/click/milestone/18?closed=1</a></li>; </ul>; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/pallets/click/blob/main/CHANGES.rst"">click's changelog</a>.</em></p>; <blockquote>; <h2>Version 8.1.3</h2>; <p>Released 2022-04-28</p>; <ul>; <li>Use verbose form of <code>typing.Callable</code> for <code>@command</code> and; <code>@group</code>. :issue:<code>2255</code></li>; <li>Show error when attempting to create an option with; <code>multiple=True, is_flag=True</code>. Use <code>count</code> instead.; :issue:<code>2246</code></li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/pallets/click/commit/9c6f4c8e1bb8670ce827c98559f57f6ee5935cd0""><code>9c6f4c8</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pallets/click/issues/2262"">#2262</a> from pallets/release-8.1.3</li>; <li><a href=""https://github.com/pallets/click/commit/5ec77494bdf2c294d3b082bed429ebce78321431""><code>5ec7749</code></a> release version 8.1.3</li>; <li><a href=""https://github.com/pallets/click/commit/2ac3211cb79a63bae8e6f0441136b432ec2126bc""><code>2ac3211</code></a> update requirements</li>; <li><a href=""https://github.com/pallets/click/commit/5fd87bdf80ed450334b37344f6c99890c217d3db""><code>5fd87bd</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pallets/click/issues/2248"">#2248</a> from jreese/8.1.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11973:1102,error,error,1102,https://hail.is,https://github.com/hail-is/hail/pull/11973,1,['error'],['error']
Availability,cessorImpl.invoke0(Native Method); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.base/java.lang.reflect.Method.invoke(Method.java:566); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:282); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:238); 	at java.base/java.lang.Thread.run(Thread.java:834). is.hail.utils.HailException: Invalid locus '11:135009883' found. Position '135009883' is not within the range [1-135006516] for reference genome 'GRCh37'.; 	at is.hail.utils.ErrorHandling.fatal(ErrorHandling.scala:17); 	at is.hail.utils.ErrorHandling.fatal$(ErrorHandling.scala:17); 	at is.hail.utils.package$.fatal(package.scala:78); 	at is.hail.variant.ReferenceGenome.checkLocus(ReferenceGenome.scala:210); 	at is.hail.variant.Locus$.apply(Locus.scala:18); 	at is.hail.variant.Locus$.annotation(Locus.scala:24); 	at is.hail.io.plink.LoadPlink$.$anonfun$parseBim$3(LoadPlink.scala:43); 	at is.hail.io.plink.LoadPlink$.$anonfun$parseBim$3$adapted(LoadPlink.scala:37); 	at is.hail.utils.WithContext.foreach(Context.scala:49); 	at is.hail.io.plink.LoadPlink$.$anonfun$parseBim$2(LoadPlink.scala:37); 	at is.hail.io.plink.LoadPlink$.$anonfun$parseBim$2$adapted(LoadPlink.scala:36); 	at scala.collection.Iterator.foreach(Iterator.scala:941); 	at scala.collection.Iterator.foreach$(Iterator.scala:941); 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1429); 	at is.hail.io.plink.LoadPlink$.$anonfun$parseBim$1(LoadPlink.scala:36); 	at is.hail.io.plink.LoadPlink$.$anonfun$parseBim$1$adapted(LoadPlink.scala:35); 	at is.hail.io.fs.FS.$anonfun$readLines$1,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/11836:5221,Error,ErrorHandling,5221,https://hail.is,https://github.com/hail-is/hail/issues/11836,1,['Error'],['ErrorHandling']
Availability,"ch bucket to pull the VEP cache data from. In more recent versions (tested with 0.2.130), this `VEP_REPLICATE` variable has been changed to `VEP_REPLICATE=australia-southeast1`, however the Australian bucket containing the VEP cache data is still `aus-sydney`, meaning that the VEP data is not copied into the dataproc cluster, and when trying to run VEP I get the error `No cache found for homo_sapiens, version 95`. ### Version. 0.2.130. ### Relevant log output. ```shell; FatalError: HailException: VEP command '/vep --format vcf --json --everything --allele_number --no_stats --cache --offline --minimal --assembly GRCh38 --fasta /opt/vep/.vep/homo_sapiens/95_GRCh38/Homo_sapiens.GRCh38.dna.toplevel.fa.gz --plugin LoF,loftee_path:/opt/vep/Plugins/,gerp_bigwig:/opt/vep/.vep/gerp_conservation_scores.homo_sapiens.GRCh38.bw,human_ancestor_fa:/opt/vep/.vep/human_ancestor.fa.gz,conservation_file:/opt/vep/.vep/loftee.sql --dir_plugins /opt/vep/Plugins/ -o STDOUT' failed with non-zero exit status 2; VEP Error output:; Smartmatch is experimental at /opt/vep/Plugins/de_novo_donor.pl line 175.; Smartmatch is experimental at /opt/vep/Plugins/de_novo_donor.pl line 214.; Smartmatch is experimental at /opt/vep/Plugins/splice_site_scan.pl line 191.; Smartmatch is experimental at /opt/vep/Plugins/splice_site_scan.pl line 194.; Smartmatch is experimental at /opt/vep/Plugins/splice_site_scan.pl line 238.; Smartmatch is experimental at /opt/vep/Plugins/splice_site_scan.pl line 241.; DBI connect('dbname=/opt/vep/.vep/loftee.sql','',...) failed: unable to open database file at /opt/vep/Plugins/LoF.pm line 126. -------------------- EXCEPTION --------------------; MSG: ERROR: No cache found for homo_sapiens, version 95. STACK Bio::EnsEMBL::VEP::CacheDir::dir /opt/vep/src/ensembl-vep/modules/Bio/EnsEMBL/VEP/CacheDir.pm:328; STACK Bio::EnsEMBL::VEP::CacheDir::init /opt/vep/src/ensembl-vep/modules/Bio/EnsEMBL/VEP/CacheDir.pm:227; STACK Bio::EnsEMBL::VEP::CacheDir::new /opt/vep/src/ensembl-vep/modul",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14513:1527,Error,Error,1527,https://hail.is,https://github.com/hail-is/hail/issues/14513,1,['Error'],['Error']
Availability,"ch is annoying. Anyway now when someone asks how to count the mutations in each gene by consequence type we can point them to the `counter` docs. ---. Adding a dataset caused a bunch of docs failure that lead me to change how we do doctesting. The changes are summarized below.; - ignore `python/.eggs`; - make `PARALLELISM` configurable in `Makefile`; - fix `make pytest` (it referenced a non-extant target); - add `make doctest` (this and `pytest` use setup.py to replicate the environment the user would have after installation, I prefer this approach because I need not manually install any dependencies, setup.py handles that, it also configures spark correctly without environment variables); - harmonize `doctest` and `pytest` parameters in `build.gradle` and `Makefile`; - clean up import order in `conftest.py` to match pylint's desired ordering; - use a `temple.TemporaryDirectory` for all doctest and test output, which is automatically cleaned up (if you want to interrogate it you can `ctrl-z` a running doctest); this allows us to not copy the entire python directory into a build directory before running pytest; - *important:* re-generate all input datasets on every run of the tests. Previously, there was a file `doctest_write_data.py` which you were supposed to run when you changed the datasets, but if Hail changes then the random datasets generated by `doctest_write_data.py` might change. This means when I came along to add a new dataset, I had to address all the test failures introduced since the last time `doctest_write_data.py`'s results were checked in. (the doctests still only take about 2 minutes); - I fixed several latent doc bugs caused by the aforementioned situation; - I changed ""Using Variants as Covariates"" in `guides/genetics.rst` because it seemed complicated and was broken by the aforementioned situation; - I removed `NOTEST` which was a custom pytest annotation that duplicates the functionality of `SKIP` (I changed all `NOTEST` annotations to `SKIP`)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6856:2024,failure,failures,2024,https://hail.is,https://github.com/hail-is/hail/pull/6856,1,['failure'],['failures']
Availability,chRDDRegionValue$$anonfun$5.apply(RowStore.scala:757); at is.hail.io.RichRDDRegionValue$$anonfun$5.apply(RowStore.scala:756); at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$26.apply(RDD.scala:844); at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$26.apply(RDD.scala:844); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:108); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); Caused by: com.esotericsoftware.kryo.KryoException: Error during Java deserialization.; at com.esotericsoftware.kryo.serializers.JavaSerializer.read(JavaSerializer.java:65); at com.esotericsoftware.kryo.Kryo.readClassAndObject(Kryo.java:790); at org.apache.spark.serializer.KryoDeserializationStream.readObject(KryoSerializer.scala:246); at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$8.apply(TorrentBroadcast.scala:293); at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337); at org.apache.spark.broadcast.TorrentBroadcast$.unBlockifyObject(TorrentBroadcast.scala:294); at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$readBroadcastBlock$1.apply(TorrentBroadcast.scala:226); at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1303); ... 18 more; Caused by: java.lang.ClassNotFoundException: is.hail.utils.SerializableHadoopConfiguration; at java.net.URLClassLoader.findClass(URLClassLoader.java:381); at java.lang.ClassLoader.loadClass(ClassLoader.java:424); at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:3,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3342:4069,Error,Error,4069,https://hail.is,https://github.com/hail-is/hail/issues/3342,1,['Error'],['Error']
Availability,"ch_avx2::int32<8>]:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::arch_avx2::uint64<4>; T = simdpp::arch_avx2::int32<8>; unsigned int MaskCastOverride = 0]; libsimdpp-2.0-rc2/simdpp/core/cast.h:63:89: required from R simdpp::arch_avx2::bit_cast(const T&) [with R = simdpp::arch_avx2::uint64<4>; T = simdpp::arch_avx2::int32<8>]; libsimdpp-2.0-rc2/simdpp/types/int64x4.h:114:36: required from simdpp::arch_avx2::uint64<4>& simdpp::arch_avx2::uint64<4>::operator=(const simdpp::arch_avx2::any_vec<32, V>&) [with V = simdpp::arch_avx2::int32<8>]; libsimdpp-2.0-rc2/simdpp/detail/insn/i_shift_r.h:300:19: required from here; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:40:13: error: void* memcpy(void*, const void*, size_t) copying an object of type class simdpp::arch_avx2::uint64<4> with private member simdpp::arch_avx2::uint64<4>::d_ from an array of const class simdpp::arch_avx2::int32<8>; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/types.h:27,; from libsimdpp-2.0-rc2/simdpp/core/align.h:15,; from libsimdpp-2.0-rc2/simdpp/simd.h:22,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/types/int64x4.h:91:7: note: class simdpp::arch_avx2::uint64<4> declared here; class uint64<4, void> : public any_int64<4, uint64<4,void>> {; ^~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/simd.h:132,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl: In instantiation of R simdpp::arch_avx2::detail::cast_memcpy(const T&) [with R = simdpp::arch_avx2::int32<8>; T = simdpp::arch_avx2::uint64<4>]:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::ar",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3955:80237,error,error,80237,https://hail.is,https://github.com/hail-is/hail/issues/3955,1,['error'],['error']
Availability,"ch_avx2::int64<2>]:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::arch_avx2::uint64<2>; T = simdpp::arch_avx2::int64<2>; unsigned int MaskCastOverride = 0]; libsimdpp-2.0-rc2/simdpp/core/cast.h:63:89: required from R simdpp::arch_avx2::bit_cast(const T&) [with R = simdpp::arch_avx2::uint64<2>; T = simdpp::arch_avx2::int64<2>]; libsimdpp-2.0-rc2/simdpp/types/int64x2.h:129:36: required from simdpp::arch_avx2::uint64<2>& simdpp::arch_avx2::uint64<2>::operator=(const simdpp::arch_avx2::any_vec<16, V>&) [with V = simdpp::arch_avx2::int64<2>]; libsimdpp-2.0-rc2/simdpp/detail/insn/i_shift_r.h:270:19: required from here; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:40:13: error: void* memcpy(void*, const void*, size_t) copying an object of type class simdpp::arch_avx2::uint64<2> with private member simdpp::arch_avx2::uint64<2>::d_ from an array of const class simdpp::arch_avx2::int64<2>; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/types.h:26,; from libsimdpp-2.0-rc2/simdpp/core/align.h:15,; from libsimdpp-2.0-rc2/simdpp/simd.h:22,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/types/int64x2.h:102:7: note: class simdpp::arch_avx2::uint64<2> declared here; class uint64<2, void> : public any_int64<2, uint64<2,void>> {; ^~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/simd.h:132,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl: In instantiation of R simdpp::arch_avx2::detail::cast_memcpy(const T&) [with R = simdpp::arch_avx2::int32<4>; T = simdpp::arch_avx2::uint64<2>]:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3955:71306,error,error,71306,https://hail.is,https://github.com/hail-is/hail/issues/3955,1,['error'],['error']
Availability,change OrderedRVD assertion to better error message for split_multi,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4130:38,error,error,38,https://hail.is,https://github.com/hail-is/hail/pull/4130,1,['error'],['error']
Availability,chaos failure,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4541:6,failure,failure,6,https://hail.is,https://github.com/hail-is/hail/issues/4541,1,['failure'],['failure']
Availability,checkpoint could only run upstream if file is missing,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5599:0,checkpoint,checkpoint,0,https://hail.is,https://github.com/hail-is/hail/issues/5599,1,['checkpoint'],['checkpoint']
Availability,"chel-kraemer/gradle-download-task) from 3.2.0 to 5.2.1.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/michel-kraemer/gradle-download-task/releases"">de.undercouch.download's releases</a>.</em></p>; <blockquote>; <h2>5.2.1</h2>; <p>Bug fixes:</p>; <ul>; <li>Use pooling connection manager of Apache HttpClient instead of basic one. The basic one is not meant to be used by multiple threads. This fixes an issue that could cause an <code>IllegalStateException</code> with the message <code>Connection is still allocated</code>. Thanks to <a href=""https://github.com/dmarks2""><code>@dmarks2</code></a> for spotting this.</li>; </ul>; <p>Maintenance:</p>; <ul>; <li>Update dependencies</li>; </ul>; <h2>5.2.0</h2>; <p>New features:</p>; <ul>; <li>Add <code>eachFile</code> method that adds an action to be applied to each source URL before it is downloaded. The action can be used to modify the filename of the target file.</li>; <li>Add <code>runAsync</code> method to download extension. This allows multiple files to be downloaded in parallel if the download extension is used. For normal download tasks, multiple files were downloaded in parallel already.</li>; </ul>; <h2>5.1.3</h2>; <p>Bug fixes:</p>; <ul>; <li>Initialize progress logger just before the download starts (see <a href=""https://github-redirect.dependabot.com/michel-kraemer/gradle-download-task/issues/243"">#243</a>)</li>; </ul>; <h2>5.1.2</h2>; <p>Bug fixes:</p>; <ul>; <li>Do not include default HTTP and HTTPS ports in <code>Host</code> header unless explicitly specified by the user</li>; </ul>; <h2>5.1.1</h2>; <p>Bug fixes:</p>; <ul>; <li>Correctly update cached sources</li>; </ul>; <p>Maintenance:</p>; <ul>; <li>Add integration tests for Gradle 7.5 and 7.5.1</li>; <li>Update dependencies</li>; </ul>; <h2>5.1.0</h2>; <p>New features:</p>; <ul>; <li>Add possibility to enable preemptive Basic authentication (through the new <code>preemptiveAuth</code> flag)</li>; <li>Warn if",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12332:1066,down,download,1066,https://hail.is,https://github.com/hail-is/hail/pull/12332,1,['down'],['download']
Availability,"ches in 17 ms; 2020-06-10 10:09:36 INFO ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 17 ms; 2020-06-10 10:09:36 INFO ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 17 ms; [thread 46926922934016 also had an error][thread 46922053207808 also had an error][thread 46926901880576 also had an error][thread 46926888195840 also had an error][thread 46926887143168 also had an error][thread 46924854015744 also had an error]; [thread 46924847699712 also had an error]. 	#. 	# A fatal error has been detected by the Java Runtime Environment:. 	[thread 46926905038592 also had an error]#; 	# ; 	[thread 46926895564544 also had an error][thread 46926900827904 also had an error]. 	SIGSEGV (0xb) at pc=0x00002aaab5115c88, pid=34051, tid=0x00002aae05d1a700; 	#; 	# JRE version: OpenJDK Runtime Environment (8.0_242-b08) (build 1.8.0_242-b08); 	# Java VM: OpenJDK 64-Bit Server VM (25.242-b08 mixed mode linux-amd64 compressed oops); 	# Problematic frame:; 	[thread 46926929250048 also had an error]# ; 	[thread 46926881888000 also had an error]; 	J 5583 C2 __C111CompiledWithAggs.__m131wrapped(Lis/hail/annotations/Region;J)V (280 bytes) @ 0x00002aaab5115c88 [0x00002aaab5115ae0+0x1a8]; 	#; 	# Failed to write core dump. Core dumps have been disabled. To enable core dumping, try ""ulimit -c unlimited"" before starting Java again; 	#; 	[thread 46924863489792 also had an error]; 	[thread 46924861384448 also had an error]; 	# An error report file with more information is saved as:; 	# /local/scratch/app-20200610100916-0000/0/hs_err_pid34051.log; 	[thread 46926913459968 also had an error]; 	[thread 46924843489024 also had an error][thread 46926917670656 also had an error]. 	#; 	# If you would like to submit a bug report, please visit:; 	# http://bugreport.java.com/bugreport/crash.jsp; 	#. To summarize our observations:; * The issue does not occur when hail is initialized without an existing spark master; * The issue does not occur in HAIL versions prior to 0.2.43 (tested: 0",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8944:19272,error,error,19272,https://hail.is,https://github.com/hail-is/hail/issues/8944,2,['error'],['error']
Availability,"chols_model: generating genotypes for 1 populations, 1000 samples, and 50000 variants...; 	[Stage 9:> (0 + 18) / 18]; 	[FAIL] with 354 partitions; 	Traceback (most recent call last):; 	 File ""test_11_cluster_sampleqc.py"", line 20, in <module>; 		print(""\n[PASS] with"", N, ""partitions:"", Y.count()); 	 File ""/bmrn/apps/hail/0.2.44/python/hail-0.2.44-py3-none-any.egg/hail/matrixtable.py"", line 2426, in count; 		return Env.backend().execute(count_ir); 	 File ""/bmrn/apps/hail/0.2.44/python/hail-0.2.44-py3-none-any.egg/hail/backend/spark_backend.py"", line 296, in execute; 		result = json.loads(self._jhc.backend().executeJSON(jir)); 	 File ""/bmrn/apps/spark/2.4.5/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py"", line 1257, in __call__; 	 File ""/bmrn/apps/hail/0.2.44/python/hail-0.2.44-py3-none-any.egg/hail/backend/spark_backend.py"", line 41, in deco; 		'Error summary: %s' % (deepest, full, hail.__version__, deepest)) from None; 	hail.utils.java.FatalError: SparkException: Job aborted due to stage failure: ResultStage 9 (runJob at RVD.scala:688) has failed the maximum allowable number of times: 4. Most recent failure reason: org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 0 at org.apache.spark.MapOutputTracker$$anonfun$convertMapStatuses$2.apply(MapOutputTracker.scala:882) at org.apache.spark.MapOutputTracker$$anonfun$convertMapStatuses$2.apply(MapOutputTracker.scala:878) at scala.collection.Iterator$class.foreach(Iterator.scala:891) at scala.collection.AbstractIterator.foreach(Iterator.scala:1334) at org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:878) at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:691) at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49) at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105) at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346) at org.apache.spark.rdd.RDD.ite",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8944:3774,failure,failure,3774,https://hail.is,https://github.com/hail-is/hail/issues/8944,1,['failure'],['failure']
Availability,"ci""><code>@pre-commit-ci</code></a>)</li>; </ul>; <h3>Contributors to this release</h3>; <p>(<a href=""https://github.com/jupyter/jupyter_core/graphs/contributors?from=2024-01-08&amp;to=2024-03-12&amp;type=c"">GitHub contributors page for this release</a>)</p>; <p><a href=""https://github.com/search?q=repo%3Ajupyter%2Fjupyter_core+involves%3Ablink1073+updated%3A2024-01-08..2024-03-12&amp;type=Issues""><code>@blink1073</code></a> | <a href=""https://github.com/search?q=repo%3Ajupyter%2Fjupyter_core+involves%3Apre-commit-ci+updated%3A2024-01-08..2024-03-12&amp;type=Issues""><code>@pre-commit-ci</code></a></p>; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/jupyter/jupyter_core/blob/main/CHANGELOG.md"">jupyter-core's changelog</a>.</em></p>; <blockquote>; <h2>5.7.2</h2>; <p>(<a href=""https://github.com/jupyter/jupyter_core/compare/v5.7.1...1264a81fc834f18db2b41e136ec4ac9d1a4ad993"">Full Changelog</a>)</p>; <h3>Maintenance and upkeep improvements</h3>; <ul>; <li>Update Release Scripts <a href=""https://redirect.github.com/jupyter/jupyter_core/pull/396"">#396</a> (<a href=""https://github.com/blink1073""><code>@blink1073</code></a>)</li>; <li>Enforce pytest 7 <a href=""https://redirect.github.com/jupyter/jupyter_core/pull/393"">#393</a> (<a href=""https://github.com/blink1073""><code>@blink1073</code></a>)</li>; <li>chore: update pre-commit hooks <a href=""https://redirect.github.com/jupyter/jupyter_core/pull/392"">#392</a> (<a href=""https://github.com/pre-commit-ci""><code>@pre-commit-ci</code></a>)</li>; </ul>; <h3>Contributors to this release</h3>; <p>(<a href=""https://github.com/jupyter/jupyter_core/graphs/contributors?from=2024-01-08&amp;to=2024-03-12&amp;type=c"">GitHub contributors page for this release</a>)</p>; <p><a href=""https://github.com/search?q=repo%3Ajupyter%2Fjupyter_core+involves%3Ablink1073+updated%3A2024-01-08..2024-03-12&amp;type=Issues""><code>@blink1073</code></a> | <a href=""https://github.com/",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14484:1974,Mainten,Maintenance,1974,https://hail.is,https://github.com/hail-is/hail/pull/14484,1,['Mainten'],['Maintenance']
Availability,"cies [0x00007fbeaec3cbb8,0x00007fbeaec3cbc0] = 8; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; #; FATAL: caught signal 6 SIGABRT; /tmp/libhail7224206977949339430.so(+0x1788c)[0x7fbdea5db88c]; /lib/x86_64-linux-gnu/libc.so.6(+0x33060)[0x7fbec2eae060]; /lib/x86_64-linux-gnu/libc.so.6(gsignal+0xcf)[0x7fbec2eadfff]; /lib/x86_64-linux-gnu/libc.so.6(abort+0x16a)[0x7fbec2eaf42a]; /usr/lib/jvm/java-8-openjdk-amd64/jre/lib/amd64/server/libjvm.so(+0x8c0259)[0x7fbec27f0259]; /usr/lib/jvm/java-8-openjdk-amd64/jre/lib/amd64/server/libjvm.so(+0xa744f8)[0x7fbec29a44f8]; /usr/lib/jvm/java-8-openjdk-amd64/jre/lib/amd64/server/libjvm.so(JVM_handle_linux_signal+0x265)[0x7fbec27f9e45]; /usr/lib/jvm/java-8-openjdk-amd64/jre/lib/amd64/server/libjvm.so(+0x8bd4c8)[0x7fbec27ed4c8]; /lib/x86_64-linux-gnu/libpthread.so.0(+0x110c0)[0x7fbec38580c0]; [0x7fbeaec3ca22]; ERROR: (gcloud.dataproc.jobs.submit.pyspark) Job [828e66d5a71741d7ab2c8d6580997da3] entered state [ERROR] while waiting for [DONE].; Traceback (most recent call last):; File ""pyhail.py"", line 132, in <module>; main(args, pass_through_args); File ""pyhail.py"", line 113, in main; subprocess.check_output(job); File ""/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/subprocess.py"", line 573, in check_output; raise CalledProcessError(retcode, cmd, output=output); subprocess.CalledProcessError: Command '['gcloud', 'dataproc', 'jobs', 'submit', 'pyspark', '/Users/gtiao/gnomad_qc/hail/variant_qc/make_var_annot_hists.py', '--cluster', 'gt3', '--files=gs://hail-common/builds/devel/jars/hail-devel-cadc5eefca6e-Spark-2.2.0.jar', '--py-files=gs://hail-common/builds/devel/python/hail-devel-cadc5eefca6e.zip,/var/folders/rn/t2xcx1ps4h96txll46qkkfsj2q8bnl/T/pyscripts_K7Vs59.zip', '--driver-log-levels', 'root=FATAL,is.hail=INFO', '--properties=spark.executor.extraClassPath=./hail-devel-cadc5eefca6e-Spark-2.2.0.jar,spark.driver.extraClassPath=./hail-devel-cadc5eefca6",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4418:4075,ERROR,ERROR,4075,https://hail.is,https://github.com/hail-is/hail/issues/4418,1,['ERROR'],['ERROR']
Availability,"cies"":[{""name"":""certifi"",""from"":""2021.10.8"",""to"":""2023.7.22""},{""name"":""cryptography"",""from"":""3.3.2"",""to"":""41.0.6""},{""name"":""pyjwt"",""from"":""1.7.1"",""to"":""2.4.0""},{""name"":""requests"",""from"":""2.27.1"",""to"":""2.31.0""},{""name"":""rsa"",""from"":""4.5"",""to"":""4.7""}],""packageManager"":""pip"",""projectPublicId"":""e7c92c7b-5282-49ea-940f-7a5797e2a45a"",""projectUrl"":""https://app.snyk.io/org/danking/project/e7c92c7b-5282-49ea-940f-7a5797e2a45a?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-CERTIFI-3164749"",""SNYK-PYTHON-CERTIFI-5805047"",""SNYK-PYTHON-CRYPTOGRAPHY-3172287"",""SNYK-PYTHON-CRYPTOGRAPHY-3314966"",""SNYK-PYTHON-CRYPTOGRAPHY-3315324"",""SNYK-PYTHON-CRYPTOGRAPHY-3315328"",""SNYK-PYTHON-CRYPTOGRAPHY-3315331"",""SNYK-PYTHON-CRYPTOGRAPHY-3315452"",""SNYK-PYTHON-CRYPTOGRAPHY-3315972"",""SNYK-PYTHON-CRYPTOGRAPHY-3315975"",""SNYK-PYTHON-CRYPTOGRAPHY-3316038"",""SNYK-PYTHON-CRYPTOGRAPHY-3316211"",""SNYK-PYTHON-CRYPTOGRAPHY-5663682"",""SNYK-PYTHON-CRYPTOGRAPHY-5777683"",""SNYK-PYTHON-CRYPTOGRAPHY-5813745"",""SNYK-PYTHON-CRYPTOGRAPHY-5813746"",""SNYK-PYTHON-CRYPTOGRAPHY-5813750"",""SNYK-PYTHON-CRYPTOGRAPHY-5914629"",""SNYK-PYTHON-CRYPTOGRAPHY-6036192"",""SNYK-PYTHON-CRYPTOGRAPHY-6092044"",""SNYK-PYTHON-PYJWT-2840625"",""SNYK-PYTHON-REQUESTS-5595532"",""SNYK-PYTHON-RSA-1038401""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[],""priorityScoreList"":[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**.  [Use After Free](https://learn.snyk.io/lesson/use-after-free/?loc&#x3D;fix-pr);  [Access of Resource Using Incompatible Type (&#x27;Type Confusion&#x27;)](https://learn.snyk.io/lesson/type-confusion/?loc&#x3D;fix-pr);  [Denial of Service (DoS)](https://learn.snyk.io/lesson/redos/?loc&#x3D;fix-pr);  [More lessons are available in Snyk Learn](https://learn.snyk.io/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14134:11188,avail,available,11188,https://hail.is,https://github.com/hail-is/hail/pull/14134,1,['avail'],['available']
Availability,"ck/check.py"", line 585, in wrapper; return __original_func(*args_, **kwargs_); File ""/home/catarina.gouveia/miniconda3/envs/hail/lib/python3.7/site-packages/hail/matrixtable.py"", line 2508, in write; Env.backend().execute(MatrixWrite(self._mir, writer)); File ""/home/catarina.gouveia/miniconda3/envs/hail/lib/python3.7/site-packages/hail/backend/backend.py"", line 109, in execute; result = json.loads(Env.hc()._jhc.backend().executeJSON(self._to_java_ir(ir))); File ""/home/catarina.gouveia/miniconda3/envs/hail/lib/python3.7/site-packages/py4j/java_gateway.py"", line 1257, in __call__; answer, self.gateway_client, self.target_id, self.name); File ""/home/catarina.gouveia/miniconda3/envs/hail/lib/python3.7/site-packages/hail/utils/java.py"", line 225, in deco; 'Error summary: %s' % (deepest, full, hail.__version__, deepest)) from None; hail.utils.java.FatalError: HailException: Hail only supports 8-bit probabilities, found 16. Java stack trace:; java.lang.RuntimeException: error while applying lowering 'InterpretNonCompilable'; 	at is.hail.expr.ir.lowering.LoweringPipeline$$anonfun$apply$1.apply(LoweringPipeline.scala:26); 	at is.hail.expr.ir.lowering.LoweringPipeline$$anonfun$apply$1.apply(LoweringPipeline.scala:18); 	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); 	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35); 	at is.hail.expr.ir.lowering.LoweringPipeline.apply(LoweringPipeline.scala:18); 	at is.hail.expr.ir.CompileAndEvaluate$$anonfun$apply$1.apply(CompileAndEvaluate.scala:16); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:69); 	at is.hail.expr.ir.CompileAndEvaluate$.apply(CompileAndEvaluate.scala:14); 	at is.hail.backend.Backend$$anonfun$execute$1.apply(Backend.scala:56); 	at is.hail.backend.Backend$$anonfun$execute$1.apply(Backend.scala:56); 	at is.hail.utils.package$.using(package.scala:596); 	at is.hail.expr.ir.ExecuteContext$$anonfun$scoped$1.apply(ExecuteContext.scala:10); 	at is.hail.expr.ir",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8545:1944,error,error,1944,https://hail.is,https://github.com/hail-is/hail/issues/8545,1,['error'],['error']
Availability,"ckendHttpHandler.handle(BackendServer.scala:81); 	at jdk.httpserver/com.sun.net.httpserver.Filter$Chain.doFilter(Filter.java:77); 	at jdk.httpserver/sun.net.httpserver.AuthFilter.doFilter(AuthFilter.java:82); 	at jdk.httpserver/com.sun.net.httpserver.Filter$Chain.doFilter(Filter.java:80); 	at jdk.httpserver/sun.net.httpserver.ServerImpl$Exchange$LinkHandler.handle(ServerImpl.java:848); 	at jdk.httpserver/com.sun.net.httpserver.Filter$Chain.doFilter(Filter.java:77); 	at jdk.httpserver/sun.net.httpserver.ServerImpl$Exchange.run(ServerImpl.java:817); 	at jdk.httpserver/sun.net.httpserver.ServerImpl$DefaultExecutor.execute(ServerImpl.java:201); 	at jdk.httpserver/sun.net.httpserver.ServerImpl$Dispatcher.handle(ServerImpl.java:560); 	at jdk.httpserver/sun.net.httpserver.ServerImpl$Dispatcher.run(ServerImpl.java:526); 	at java.base/java.lang.Thread.run(Thread.java:829). is.hail.utils.HailException: gs://path/to/bucket/chrY.0002.hard_filtered_with_genotypes.vcf.gz:offset 23933331019603: error while parsing line; chrY	113	.	GG	G,*,AG,CG	596	PASS	AC=2,4,6,1;AF=1.23e-03,5.550e-05,4.44e-05,2.00e-04;AN=265;AS_AltDP=10,0,3,10;AS_BaseQRankSum=0.000,.,0.100,0.500;AS_FS=7.777,.,2.144,8.001;AS_MQ=55.75,.,38.98,40.20;AS_MQRankSum=0.200,.,-1.050,-0.500;AS_QD=0.50,0.00,0.25,0.52;AS_ReadPosRankSum=-0.200,.,0.500,-0.220;AS_SOR=2.300,.,1.600,3.000;BaseQRankSum=0.200;DP=600000;ExcessHet=0.0477;FS=0.900;MQ=55.02;MQRankSum=-0.553;QD=1.00;ReadPosRankSum=-0.162;SOR=0.792;VarDP=650	GT:AD:DP:GQ:PGT:PID:PL:PS:SB	0/0:.:21:30	0/0:.:300:20	0/0:.:30:72	0/0:.:31:98	0|1:29,3,0,0,0:33:78:0|1:113_GG_G:78,0,1100,140,1400,1200,172,1600,1200,1000,175,1100,1100,1300,1000:113:19,19,2,1	0/0:.:20:19	0/0:.:19:20	0/0:.:25:50		0|1:90,2,0,0,0:30:40:0|1:113_GG_G:40,0,600,70,650,600,90,640,900,300,60,800,400,900,900:113:2,14,2,0	0/0:.:20:10	0/0:.:9:20	0/0:.:30:40	0/0:.:37:38		0/4:5,0,0,0,1:5:33:.:.:30,40,400,50,220,220,38,270,270,270,0,200,200,200,202:.:5,0,0,1	. 	at is.hail.utils.ErrorHandling.fatal(ErrorHandling.sc",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14102:15849,error,error,15849,https://hail.is,https://github.com/hail-is/hail/issues/14102,1,['error'],['error']
Availability,clang: error: the clang compiler does not support '-march=native',MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/11729:7,error,error,7,https://hail.is,https://github.com/hail-is/hail/issues/11729,1,['error'],['error']
Availability,cloud.storage.StorageImpl.readAllBytes(StorageImpl.java:563); 	at is.hail.io.fs.GoogleStorageFS.$anonfun$readNoCompression$1(GoogleStorageFS.scala:288); 	at is.hail.services.package$.retryTransientErrors(package.scala:163); 	at is.hail.io.fs.GoogleStorageFS.readNoCompression(GoogleStorageFS.scala:286); 	at is.hail.io.fs.RouterFS.readNoCompression(RouterFS.scala:26); 	at is.hail.backend.service.ServiceBackend$$anon$4.call(ServiceBackend.scala:239); 	at is.hail.backend.service.ServiceBackend$$anon$4.call(ServiceBackend.scala:235); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:750). com.google.api.client.googleapis.json.GoogleJsonResponseException: 404 Not Found; GET https://storage.googleapis.com/download/storage/v1/b/wes-bipolar-tmp-4day/o/bge-wave-1-VQSR%2FparallelizeAndComputeWithIndex%2FgCyfD7XOt_MQrrCGc4Q-RrrWPb3cTAbhhcV28BCntiU=%2Fresult.2706?alt=media; No such object: wes-bipolar-tmp-4day/bge-wave-1-VQSR/parallelizeAndComputeWithIndex/gCyfD7XOt_MQrrCGc4Q-RrrWPb3cTAbhhcV28BCntiU=/result.2706; 	at com.google.api.client.googleapis.json.GoogleJsonResponseException.from(GoogleJsonResponseException.java:146); 	at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:118); 	at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:37); 	at com.google.api.client.googleapis.services.AbstractGoogleClientRequest$1.interceptResponse(AbstractGoogleClientRequest.java:439); 	at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1111); 	at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:525); 	at com.google.api.clie,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13409:7009,down,download,7009,https://hail.is,https://github.com/hail-is/hail/issues/13409,1,['down'],['download']
Availability,cmd line:. ```; hail: info: running: importvcf TT.head.vcf.bgz; hail: importvcf: caught exception: null; ```. in hail.log:. ```; 2016-06-16 11:40:11 ERROR Hail:88 - hail: importvcf: caught exception: java.util.zip.ZipException: null; at org.broadinstitute.hail.io.compress.BGzipInputStream$BGzipHeader.<init>(BGzipInputStream.java:31); at org.broadinstitute.hail.io.compress.BGzipInputStream.decompressNextBlock(BGzipInputStream.java:139); at org.broadinstitute.hail.io.compress.BGzipInputStream.read(BGzipInputStream.java:170); at sun.nio.cs.StreamDecoder.readBytes(StreamDecoder.java:284); at sun.nio.cs.StreamDecoder.implRead(StreamDecoder.java:326); at sun.nio.cs.StreamDecoder.read(StreamDecoder.java:178); at java.io.InputStreamReader.read(InputStreamReader.java:184); ...; ```,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/425:149,ERROR,ERROR,149,https://hail.is,https://github.com/hail-is/hail/issues/425,1,['ERROR'],['ERROR']
Availability,"code>12.20.1</code>.</li>; </ul>; <h2>azure-storage-file-share_12.16.1</h2>; <h2>12.16.1 (2022-11-15)</h2>; <h3>Other Changes</h3>; <h4>Dependency Updates</h4>; <ul>; <li>Upgraded <code>azure-core</code> from <code>1.33.0</code> to version <code>1.34.0</code>.</li>; <li>Upgraded <code>azure-core-http-netty</code> from <code>1.12.6</code> to version <code>1.12.7</code>.</li>; <li>Upgraded <code>azure-storage-common</code> from <code>12.19.0</code> to version <code>12.19.1</code>.</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/Azure/azure-sdk-for-java/commit/1b1b22e999541e8ce7ac3147eb468e0cde6c157a""><code>1b1b22e</code></a> Patch Release 11/15/2022 (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-java/issues/32171"">#32171</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-java/commit/68d7b8992d77ad00cdd985bfd764b81f42085fe3""><code>68d7b89</code></a> Eagerly Convert Headers Always in Download (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-java/issues/32173"">#32173</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-java/commit/c10e612d913b03f044ddd58aa591850615b61ecd""><code>c10e612</code></a> Sync eng/common directory with azure-sdk-tools for PR 4701 (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-java/issues/32168"">#32168</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-java/commit/44682b71c0216aae1530af287e745803feeec2fc""><code>44682b7</code></a> Regenerate Storage Blobs with Fix for Download to File (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-java/issues/32163"">#32163</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-java/commit/11f065d4d592d14977d178ddd58f6a6ec6b16276""><code>11f065d</code></a> Increment package versions for keyvault releases (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-j",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12477:3159,Down,Download,3159,https://hail.is,https://github.com/hail-is/hail/pull/12477,1,['Down'],['Download']
Availability,"code></a></li>; <li>Internationalise <code>intcomma</code> for de_DE locale (<a href=""https://github-redirect.dependabot.com/python-humanize/humanize/issues/49"">#49</a>) <a href=""https://github.com/Luflosi""><code>@Luflosi</code></a></li>; </ul>; <h2>Fixed</h2>; <ul>; <li>Replace short scale with long scale for Polish numbers (<a href=""https://github-redirect.dependabot.com/python-humanize/humanize/issues/54"">#54</a>) <a href=""https://github.com/mjmikulski""><code>@mjmikulski</code></a></li>; <li>Fix <code>intcomma()</code> failing with a string as input when <code>ndigits</code> is not <code>None</code> (<a href=""https://github-redirect.dependabot.com/python-humanize/humanize/issues/52"">#52</a>) <a href=""https://github.com/Luflosi""><code>@Luflosi</code></a></li>; <li>Fix some pylint findings (<a href=""https://github-redirect.dependabot.com/python-humanize/humanize/issues/42"">#42</a>) <a href=""https://github.com/hugovk""><code>@hugovk</code></a></li>; <li>Fix &quot;ValueError: math domain error&quot; for <code>metric(0)</code> (<a href=""https://github-redirect.dependabot.com/python-humanize/humanize/issues/47"">#47</a>) <a href=""https://github.com/liukun""><code>@liukun</code></a></li>; </ul>; <h2>4.3.0</h2>; <h2>Added</h2>; <ul>; <li>Add Greek translation (<a href=""https://github-redirect.dependabot.com/python-humanize/humanize/issues/46"">#46</a>) <a href=""https://github.com/waseigo""><code>@waseigo</code></a></li>; <li>Polish: Added thousand, fixed big numbers (<a href=""https://github-redirect.dependabot.com/python-humanize/humanize/issues/43"">#43</a>) <a href=""https://github.com/dejurin""><code>@dejurin</code></a></li>; </ul>; <h2>Fixed</h2>; <ul>; <li>Fix intword for negative numbers (<a href=""https://github-redirect.dependabot.com/python-humanize/humanize/issues/41"">#41</a>) <a href=""https://github.com/vishket""><code>@vishket</code></a></li>; </ul>; <h2>4.2.3</h2>; <h2>Fixed</h2>; <ul>; <li>Update annotations, docs, and tests: <code>naturaltime</code> can also ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12329:1718,error,error,1718,https://hail.is,https://github.com/hail-is/hail/pull/12329,1,['error'],['error']
Availability,"code>botocore</code>] Adds operation for custom plugin deletion (DeleteCustomPlugin) and adds new StateDescription field to DescribeCustomPlugin and DescribeConnector responses to return errors from asynchronous resource creation.</li>; </ul>; <h1>1.21.9</h1>; <ul>; <li>api-change:<code>finspace-data</code>: [<code>botocore</code>] Add new APIs for managing Users and Permission Groups.</li>; <li>api-change:<code>amplify</code>: [<code>botocore</code>] Add repositoryCloneMethod field for hosting an Amplify app. This field shows what authorization method is used to clone the repo: SSH, TOKEN, or SIGV4.</li>; <li>api-change:<code>fsx</code>: [<code>botocore</code>] This release adds support for the following FSx for OpenZFS features: snapshot lifecycle transition messages, force flag for deleting file systems with child resources, LZ4 data compression, custom record sizes, and unsetting volume quotas and reservations.</li>; <li>api-change:<code>fis</code>: [<code>botocore</code>] This release adds logging support for AWS Fault Injection Simulator experiments. Experiment templates can now be configured to send experiment activity logs to Amazon CloudWatch Logs or to an S3 bucket.</li>; <li>api-change:<code>route53-recovery-cluster</code>: [<code>botocore</code>] This release adds a new API option to enable overriding safety rules to allow routing control state updates.</li>; <li>api-change:<code>amplifyuibuilder</code>: [<code>botocore</code>] We are adding the ability to configure workflows and actions for components.</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/boto/boto3/commit/67b84e02c185294c54a8e49510d4cb962e89cee2""><code>67b84e0</code></a> Merge branch 'release-1.21.13'</li>; <li><a href=""https://github.com/boto/boto3/commit/99acd545b20fe30ffa2f589a674c5a7ad74c266b""><code>99acd54</code></a> Bumping version to 1.21.13</li>; <li><a href=""https:",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11504:4936,Fault,Fault,4936,https://hail.is,https://github.com/hail-is/hail/pull/11504,1,['Fault'],['Fault']
Availability,"code>botocore</code>] Adds operation for custom plugin deletion (DeleteCustomPlugin) and adds new StateDescription field to DescribeCustomPlugin and DescribeConnector responses to return errors from asynchronous resource creation.</li>; </ul>; <h1>1.21.9</h1>; <ul>; <li>api-change:<code>finspace-data</code>: [<code>botocore</code>] Add new APIs for managing Users and Permission Groups.</li>; <li>api-change:<code>amplify</code>: [<code>botocore</code>] Add repositoryCloneMethod field for hosting an Amplify app. This field shows what authorization method is used to clone the repo: SSH, TOKEN, or SIGV4.</li>; <li>api-change:<code>fsx</code>: [<code>botocore</code>] This release adds support for the following FSx for OpenZFS features: snapshot lifecycle transition messages, force flag for deleting file systems with child resources, LZ4 data compression, custom record sizes, and unsetting volume quotas and reservations.</li>; <li>api-change:<code>fis</code>: [<code>botocore</code>] This release adds logging support for AWS Fault Injection Simulator experiments. Experiment templates can now be configured to send experiment activity logs to Amazon CloudWatch Logs or to an S3 bucket.</li>; <li>api-change:<code>route53-recovery-cluster</code>: [<code>botocore</code>] This release adds a new API option to enable overriding safety rules to allow routing control state updates.</li>; <li>api-change:<code>amplifyuibuilder</code>: [<code>botocore</code>] We are adding the ability to configure workflows and actions for components.</li>; <li>api-change:<code>athena</code>: [<code>botocore</code>] This release adds support for updating an existing named query.</li>; <li>api-change:<code>ec2</code>: [<code>botocore</code>] This release adds support for new AMI property 'lastLaunchedTime'</li>; <li>api-change:<code>servicecatalog-appregistry</code>: [<code>botocore</code>] AppRegistry is deprecating Application and Attribute-Group Name update feature. In this release, we are marking th",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11486:3489,Fault,Fault,3489,https://hail.is,https://github.com/hail-is/hail/pull/11486,1,['Fault'],['Fault']
Availability,"code>drs</code>: [<code>botocore</code>] Non breaking changes to existing APIs, and additional APIs added to support in-AWS failing back using AWS Elastic Disaster Recovery.</li>; <li>api-change:<code>ecs</code>: [<code>botocore</code>] This release adds support for ECS Service Connect, a new capability that simplifies writing and operating resilient distributed applications. This release updates the TaskDefinition, Cluster, Service mutation APIs with Service connect constructs and also adds a new ListServicesByNamespace API.</li>; <li>api-change:<code>efs</code>: [<code>botocore</code>] Update efs client to latest version</li>; <li>api-change:<code>iot-data</code>: [<code>botocore</code>] This release adds support for MQTT5 properties to AWS IoT HTTP Publish API.</li>; <li>api-change:<code>iot</code>: [<code>botocore</code>] Job scheduling enables the scheduled rollout of a Job with start and end times and a customizable end behavior when end time is reached. This is available for continuous and snapshot jobs. Added support for MQTT5 properties to AWS IoT TopicRule Republish Action.</li>; <li>api-change:<code>iotwireless</code>: [<code>botocore</code>] This release includes a new feature for customers to calculate the position of their devices by adding three new APIs: UpdateResourcePosition, GetResourcePosition, and GetPositionEstimate.</li>; <li>api-change:<code>kendra</code>: [<code>botocore</code>] Amazon Kendra now supports preview of table information from HTML tables in the search results. The most relevant cells with their corresponding rows, columns are displayed as a preview in the search result. The most relevant table cell or cells are also highlighted in table preview.</li>; <li>api-change:<code>logs</code>: [<code>botocore</code>] Updates to support CloudWatch Logs data protection and CloudWatch cross-account observability</li>; <li>api-change:<code>mgn</code>: [<code>botocore</code>] This release adds support for Application and Wave management. We a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12507:1695,avail,available,1695,https://hail.is,https://github.com/hail-is/hail/pull/12507,1,['avail'],['available']
Availability,collect(float32) triggers serialization error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5490:40,error,error,40,https://hail.is,https://github.com/hail-is/hail/issues/5490,1,['error'],['error']
Availability,"collections import Counter; from math import log, isnan; from pprint import pprint; # hail; import hail as hl; import hail.expr.aggregators as agg; import hail.expr.functions. hl.init(default_reference='GRCh38'); print(""Read in PASS SNVs""); passed=hl.read_matrix_table('/project/casa/hail.ds/gatk.hc/gcad.5k.snv.vqsr.pass'); print(""Filtering Common Variants""); common=passed.filter_rows(passed.variant_qc.AF > 0.01).persist(); common.write('/project/casa/hail.ds/gatk.hc/gcad.5k.snv.vqsr.pass.common'); print(""Pruning LD Variants""); pruned =hl.ld_prune(common,30,r2=0.1, memory_per_core=2048); pruned.write('/project/casa/hail.ds/gatk.hc/gcad.5k.snv.vqsr.pruned'); print(""Sample 20% of variants for running PC-Relate""); pruned_subsample = pruned.sample_rows(0.2).persist(); print(""Running PC_Relate""); rel = hl.pc_relate(pruned_subsample.GT, 0.01, k=10); rel_df = rel.to_pandas(); rel_df.describe(); pprint(rel_df); rel_df.to_csv('gcad_5k.snv.rel.csv'); ```. ### What went wrong (all error messages here, including the full java stack trace):. Got a memory error. but not sure what memory needs to be increased. The job seems to restart but does not progress and need to kill. . java.lang.OutOfMemoryError: Java heap spaceop. Running on Apache Spark version 2.2.0; SparkUI available at http://10.48.225.55:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version devel-63d60cc; NOTE: This is a beta version. Interfaces may change; during the beta period. We also recommend pulling; the latest changes weekly.; Read in PASS SNVs; Filtering Common Variants; [Stage 0:==================================================>(96600 + 1) / 96601]2018-04-27 20:54:43 Hail: INFO: wrote 11341822 items in 96601 partitions; Pruning LD Variants; [Stage 1:==================================================>(96598 + 3) / 96601]2018-04-27 21:19:04 Hail: INFO: Running LD prune with nSamples=4795, nVariants=11341822, nPartitions=96601, and maxQueueSize=429841.; [Stage 2:===============",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3463:1930,error,error,1930,https://hail.is,https://github.com/hail-is/hail/issues/3463,1,['error'],['error']
Availability,"com/cbeust/testng/pull/2826"">cbeust/testng#2826</a></li>; <li>GITHUB-2830 - Failsafe parameter.toString by <a href=""https://github.com/seregamorph""><code>@seregamorph</code></a> in <a href=""https://github-redirect.dependabot.com/cbeust/testng/pull/2831"">cbeust/testng#2831</a></li>; <li>Changing assertion message of the osgitest by <a href=""https://github.com/krmahadevan""><code>@krmahadevan</code></a> in <a href=""https://github-redirect.dependabot.com/cbeust/testng/pull/2832"">cbeust/testng#2832</a></li>; <li>hidden spotbugs in release <a href=""https://github-redirect.dependabot.com/cbeust/testng/issues/2829"">#2829</a> by <a href=""https://github.com/bobshie""><code>@bobshie</code></a> in <a href=""https://github-redirect.dependabot.com/cbeust/testng/pull/2833"">cbeust/testng#2833</a></li>; <li>Enhancing the Matrix by <a href=""https://github.com/krmahadevan""><code>@krmahadevan</code></a> in <a href=""https://github-redirect.dependabot.com/cbeust/testng/pull/2834"">cbeust/testng#2834</a></li>; <li>Avoid Compilation errors on Semeru JDK flavour. by <a href=""https://github.com/krmahadevan""><code>@krmahadevan</code></a> in <a href=""https://github-redirect.dependabot.com/cbeust/testng/pull/2835"">cbeust/testng#2835</a></li>; <li>Add addition yml extension by <a href=""https://github.com/speedythesnail""><code>@speedythesnail</code></a> in <a href=""https://github-redirect.dependabot.com/cbeust/testng/pull/2837"">cbeust/testng#2837</a></li>; <li>Support getting dependencies info for a test by <a href=""https://github.com/krmahadevan""><code>@krmahadevan</code></a> in <a href=""https://github-redirect.dependabot.com/cbeust/testng/pull/2839"">cbeust/testng#2839</a></li>; <li>Honour regex in dependsOnMethods by <a href=""https://github.com/krmahadevan""><code>@krmahadevan</code></a> in <a href=""https://github-redirect.dependabot.com/cbeust/testng/pull/2838"">cbeust/testng#2838</a></li>; <li>Ensure All tests run all the time by <a href=""https://github.com/krmahadevan""><code>@krmahadevan<",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12665:6023,error,errors,6023,https://hail.is,https://github.com/hail-is/hail/pull/12665,1,['error'],['errors']
Availability,"com/pyca/cryptography/issues/8218"">#8218</a>) (<a href=""https://github-redirect.dependabot.com/pyca/cryptography/issues/8228"">#8228</a>)</li>; <li><a href=""https://github.com/pyca/cryptography/commit/69527bc79095c9646d7e839121f0783477892ecc""><code>69527bc</code></a> bookworm is py311 now (<a href=""https://github-redirect.dependabot.com/pyca/cryptography/issues/8200"">#8200</a>)</li>; <li><a href=""https://github.com/pyca/cryptography/commit/111deefb659b8d73c56d3ce89458f2df973d60e4""><code>111deef</code></a> backport main branch CI to 39.0.x (<a href=""https://github-redirect.dependabot.com/pyca/cryptography/issues/8153"">#8153</a>)</li>; <li><a href=""https://github.com/pyca/cryptography/commit/338a65a7df74e189f6b5d1d3a6315ffa911b21c2""><code>338a65a</code></a> 39.0.0 version bump (<a href=""https://github-redirect.dependabot.com/pyca/cryptography/issues/7954"">#7954</a>)</li>; <li><a href=""https://github.com/pyca/cryptography/commit/84a3cd7abb16f594d8c315e8aedb4be02583bf6a""><code>84a3cd7</code></a> automatically download and upload circleci wheels (<a href=""https://github-redirect.dependabot.com/pyca/cryptography/issues/7949"">#7949</a>)</li>; <li><a href=""https://github.com/pyca/cryptography/commit/525c0b3d5d89eab7f953be5de5d2b75da1c816f8""><code>525c0b3</code></a> Type annotate release.py (<a href=""https://github-redirect.dependabot.com/pyca/cryptography/issues/7951"">#7951</a>)</li>; <li><a href=""https://github.com/pyca/cryptography/commit/46d2a94d1b574abf5b9e88f84fa7400a138c4edb""><code>46d2a94</code></a> Use the latest 3.10 release when wheel building (<a href=""https://github-redirect.dependabot.com/pyca/cryptography/issues/7953"">#7953</a>)</li>; <li><a href=""https://github.com/pyca/cryptography/commit/f150dc15582c05b1b94cf08ed3b1fbc9c4f52267""><code>f150dc1</code></a> fix CI to work with ubuntu 22.04 (<a href=""https://github-redirect.dependabot.com/pyca/cryptography/issues/7950"">#7950</a>)</li>; <li><a href=""https://github.com/pyca/cryptography/commit/8867724b2b6db528d2900",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12668:4837,down,download,4837,https://hail.is,https://github.com/hail-is/hail/pull/12668,4,['down'],['download']
Availability,"command:. hail-new read -i /user/tpoterba/exac_reimport.vds \; filtersamples --remove -c ""file:///humgen/atgu1/fs03/wip/aganna/HCSCORE/CANCER/samples_to_keep.sample_list"" \; variantqc \; filtervariants --keep -c 'va.qc.MAC > 0' \; count \; filtersamples --keep -c 'false' \; write -o /user/aganna/exac_noCANCER.split.onlygeno.vep.NEWHAIL.vds. Error:. hail: info: running: write -o /user/aganna/exac_noCANCER.split.onlygeno.vep.NEWHAIL.vds; [Stage 2:> (0 + 72) / 14038]hail: write: caught exception: org.apache.spark.SparkException: Job aborted. [hail.log.txt](https://github.com/broadinstitute/hail/files/223029/hail.log.txt)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/304:343,Error,Error,343,https://hail.is,https://github.com/hail-is/hail/issues/304,1,['Error'],['Error']
Availability,"commend pulling; the latest changes weekly.; [Stage 1:======================================================>(414 + 2) / 416]2018-04-15 14:38:32 Hail: INFO: Coerced almost-sorted dataset; [Stage 2:> (0 + 34) / 416]Traceback (most recent call last):; File ""/restricted/projectnb/genpro/github/hail/delly_vcf2vdf.py"", line 3, in <module>; hl.import_vcf('/project/casa/vcf.5k/delly/gcad.sv.delly.5k.vcf.bgz').write('/project/casa/vdf.5k/delly'); File ""<decorator-gen-552>"", line 2, in write; File ""/restricted/projectnb/genpro/github/hail/python/hail/typecheck/check.py"", line 481, in _typecheck; return __orig_func__(*args_, **kwargs_); File ""/restricted/projectnb/genpro/github/hail/python/hail/matrixtable.py"", line 1935, in write; self._jvds.write(output, overwrite, _codec_spec); File ""/share/pkg/spark/2.2.0/install/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py"", line 1133, in __call__; File ""/restricted/projectnb/genpro/github/hail/python/hail/utils/java.py"", line 196, in deco; 'Error summary: %s' % (deepest, full, hail.__version__, deepest)) from None; hail.utils.java.FatalError: HailException: gcad.sv.delly.5k.vcf.bgz:column 80816: invalid character '-' in integer literal; ... 2:0:0:0:6 ./.:0,0,0:0:LowQual:0:0:0:-1:0:0:0:0 ./.:0,0,0:0:LowQual:0:0:0 ...; ^; offending line: chr1 152267996 DEL00028254 AATATATATACTTTACGTAAAGT A . PASS ...; see the Hail log for the full offending line. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 20 in stage 2.0 failed 4 times, most recent failure: Lost task 20.3 in stage 2.0 (TID 485, scc-q08.scc.bu.edu, executor 2): is.hail.utils.HailException: gcad.sv.delly.5k.vcf.bgz:column 80816: invalid character '-' in integer literal; ... 2:0:0:0:6 ./.:0,0,0:0:LowQual:0:0:0:-1:0:0:0:0 ./.:0,0,0:0:LowQual:0:0:0 ...; ^; offending line: chr1 152267996 DEL00028254 AATATATATACTTTACGTAAAGT A . PASS ...; see the Hail log for the full offending line; at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.sca",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3379:2460,Error,Error,2460,https://hail.is,https://github.com/hail-is/hail/issues/3379,1,['Error'],['Error']
Availability,"computeOrReadCheckpoint(RDD.scala:324) at org.apache.spark.rdd.RDD.iterator(RDD.scala:288) at org.apache.spark.rdd.Mappark.rdd.RDD.iterator(RDD.scala:288) at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52) at org.apache.spark.rdd.RDDD.compute(MapPartitionsRDD.scala:52) at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324) at org.apache.spark.rdd.RDD.iteratoadCheckpoint(RDD.scala:324) at org.apache.spark.rdd.RDD.iterator(RDD.scala:288) at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartiti288) at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52) at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scat org.apache.spark.scheduler.Task.run(Task.scala:121) at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408) at ) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) at java.util.concurrent.ThreadPoolExecutor$Worker.rception: Failure while fetching StreamChunkId{streamId=830947795015, chunkIndex=0}: java.nio.file.NoSuchFileException: /data03/hadoop/yarn/local/usnio.fs.UnixException.translateToIOException(UnixException.java:86) at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) xFileSystemProvider.java:214) at java.nio.file.Files.newByteChannel(Files.java:361) at java.nio.file.Files.newByteChannel(Files.java:407) at ckManager.getBlockData(BlockManager.scala:382) at org.apache.spark.network.netty.NettyBlockRpcServer$$anonfun$1.apply(NettyBlockRpcServer.scala:61non$11.next(Iterator.scala:410) at scala.collection.convert.Wrappers$IteratorWrapper.next(Wrappers.scala:31) at org.apache.spark.networkessFetchRequest(TransportRequestHandler.java:130) at org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.jnnel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362) at io.netty.channel.AbstractChannelHandlerContext.ielHandlerContext.java:340) at io.netty.handler.ti",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8106:20244,Failure,Failure,20244,https://hail.is,https://github.com/hail-is/hail/issues/8106,2,['Failure'],['Failure']
Availability,"cope in comprehensions</li>; <li>Add support for new python 3.11 syntax</li>; <li>Unify output so it is always <code>filename:lineno:col: message</code></li>; <li>Properly report <code>SyntaxError</code> from stdin in python &lt; 3.9</li>; <li>Fix offsets of <code>SyntaxError</code>s in pypy</li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/PyCQA/pyflakes/commit/2a6e36bd43af9829e0818961b60a1e3aab01fafc""><code>2a6e36b</code></a> Release 2.5.0 (<a href=""https://github-redirect.dependabot.com/PyCQA/pyflakes/issues/720"">#720</a>)</li>; <li><a href=""https://github.com/PyCQA/pyflakes/commit/a153aeed8df60f4190e6114f77cd254d1493e411""><code>a153aee</code></a> remove special handling of pypy offsets since modern pypy gets it right (<a href=""https://github-redirect.dependabot.com/PyCQA/pyflakes/issues/717"">#717</a>)</li>; <li><a href=""https://github.com/PyCQA/pyflakes/commit/d875b02835fb9b1480a95c5245040eb31a384357""><code>d875b02</code></a> fix syntax error reporting from stdin (<a href=""https://github-redirect.dependabot.com/PyCQA/pyflakes/issues/357"">#357</a>) (<a href=""https://github-redirect.dependabot.com/PyCQA/pyflakes/issues/716"">#716</a>)</li>; <li><a href=""https://github.com/PyCQA/pyflakes/commit/44ef321b0e608c61182ecf5d88f9edeececa5403""><code>44ef321</code></a> Fix pylint URL in README (<a href=""https://github-redirect.dependabot.com/PyCQA/pyflakes/issues/714"">#714</a>)</li>; <li><a href=""https://github.com/PyCQA/pyflakes/commit/2246217295dc8cb30ef4a7b9d8dc449ce32e603a""><code>2246217</code></a> burn the bridges with python 2.x (<a href=""https://github-redirect.dependabot.com/PyCQA/pyflakes/issues/707"">#707</a>)</li>; <li><a href=""https://github.com/PyCQA/pyflakes/commit/becbab65bae84e3e19fc388a42dfabcff0c323c8""><code>becbab6</code></a> upgrade flake8 to 4.0.1 (<a href=""https://github-redirect.dependabot.com/PyCQA/pyflakes/issues/706"">#706</a>)</li>; <li><a href=""https://github.com/PyCQA/pyflakes/commit",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12149:1556,error,error,1556,https://hail.is,https://github.com/hail-is/hail/pull/12149,1,['error'],['error']
Availability,"core, and 8Gi/core.; - Spot price is set to -1 for now until we figure out a better billing strategy; - We look for existing network security groups to tell if a VM has been fully cleaned up already in the garbage collection loop. # To-Do:. ## Services. - Use global config and make an `AzureConfig` (@daniel-goldstein not sure if you're already doing this) instead of optional environment variables; - Azure user disks are not implemented; There's a maximum number of disks that can be mounted per machine type with a maximum of 32 along with figuring out the API calls. We'll need a semaphore of some sort.; - No activity logs loop. Not necessary for initial development and preemption billing is not working how intended anyways (will add to the list to fix!). We also don't track vm creation success rates per zone like we do with GCP. It might be good to look for VM deletion events to remove instances that are no longer present and then do a deep delete as then we'll have some redundancy and faster response times.; - Figure out how to do a deep-delete as much as possible for VMs when using the create VM REST API. This is essential for cleaning up resources for idled out workers when the driver is down for a long period of time.; - User billing based on resources used based on the `AzureInstanceConfig`; - Spot billing strategy; - Check network IP settings in the worker; - Add garbage collection CLI commands to build.yaml to clean up VMs, disks, nics, public ip addresses, and network security groups based on a tag; - Fix batch tests to be cloud agnostic. ## Infrastructure. - Create a shared SSH public key on the VMs for development purposes; - Consider having every PR / namespace deploy resources in a separate resource group rather than having one resource group for all Batch resources! We'd need something to name the resource groups something like `hail-dev_jigold` and `jigold_jigold` for example to handle the case where we have two k8s clusters running in our subscription.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10970:2302,down,down,2302,https://hail.is,https://github.com/hail-is/hail/pull/10970,1,['down'],['down']
Availability,correction on downcode doc,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2487:14,down,downcode,14,https://hail.is,https://github.com/hail-is/hail/pull/2487,1,['down'],['downcode']
Availability,"cpu: 100m; memory: 500M; terminationMessagePath: /dev/termination-log; terminationMessagePolicy: File; volumeMounts:; - mountPath: /test-gsa-key; name: test-gsa-key; - mountPath: /gsa-key; name: gsa-key; - mountPath: /var/run/secrets/kubernetes.io/serviceaccount; name: default-token-8h99c; readOnly: true; dnsPolicy: ClusterFirst; enableServiceLinks: true; nodeName: gke-vdc-preemptible-pool-9c7148b2-1f89; priority: 500000; priorityClassName: user; restartPolicy: Never; schedulerName: default-scheduler; securityContext: {}; serviceAccount: default; serviceAccountName: default; terminationGracePeriodSeconds: 30; tolerations:; - key: preemptible; value: ""true""; - effect: NoExecute; key: node.kubernetes.io/not-ready; operator: Exists; tolerationSeconds: 300; - effect: NoExecute; key: node.kubernetes.io/unreachable; operator: Exists; tolerationSeconds: 300; volumes:; - name: test-gsa-key; secret:; defaultMode: 420; optional: false; secretName: test-gsa-key; - name: gsa-key; secret:; defaultMode: 420; secretName: ci-gsa-key; - name: default-token-8h99c; secret:; defaultMode: 420; secretName: default-token-8h99c; status:; conditions:; - lastProbeTime: null; lastTransitionTime: ""2019-07-12T17:17:15Z""; status: ""True""; type: Initialized; - lastProbeTime: null; lastTransitionTime: ""2019-07-12T17:17:15Z""; message: 'containers with unready status: [main]'; reason: ContainersNotReady; status: ""False""; type: Ready; - lastProbeTime: null; lastTransitionTime: ""2019-07-12T17:17:15Z""; message: 'containers with unready status: [main]'; reason: ContainersNotReady; status: ""False""; type: ContainersReady; - lastProbeTime: null; lastTransitionTime: ""2019-07-12T17:17:15Z""; status: ""True""; type: PodScheduled; containerStatuses:; - image: gcr.io/hail-vdc/ci-intermediate:oyyg6y2um4kx; imageID: """"; lastState: {}; name: main; ready: false; restartCount: 0; state:; waiting:; reason: ContainerCreating; hostIP: 10.128.0.101; phase: Pending; qosClass: Burstable; startTime: ""2019-07-12T17:17:15Z""; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6625:4541,toler,tolerationSeconds,4541,https://hail.is,https://github.com/hail-is/hail/issues/6625,1,['toler'],['tolerationSeconds']
Availability,"created by Snyk using the credentials of a real user.</p><br /><h3>Snyk has created this PR to fix one or more vulnerable packages in the `pip` dependencies of this project.</h3>. #### Changes included in this PR. - Changes to the following files to upgrade the vulnerable dependencies to a fixed version:; - hail/python/dev/pinned-requirements.txt. <details>; <summary> <b>Warning</b></summary>. ```; jupyter 1.0.0 requires notebook, which is not installed.; beautifulsoup4 4.12.2 requires soupsieve, which is not installed. ```; </details>. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **531/1000** <br/> **Why?** Proof of Concept exploit, Has a fix available, CVSS 4.2 | Remote Code Execution (RCE) <br/>[SNYK-PYTHON-IPYTHON-3318382](https://snyk.io/vuln/SNYK-PYTHON-IPYTHON-3318382) | `ipython:` <br> `7.34.0 -> 8.10.0` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **/1000** <br/> **Why?** | Access Control Bypass <br/>[SNYK-PYTHON-JUPYTERSERVER-5862881](https://snyk.io/vuln/SNYK-PYTHON-JUPYTERSERVER-5862881) | `jupyter-server:` <br> `1.24.0 -> 2.7.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **/1000** <br/> **Why?** | Open Redirect <br/>[SNYK-PYTHON-JUPYTERSERVER-5862882](https://snyk.io/vuln/SNYK-PYTHON-JUPYTERSERVER-5862882) | `jupyter-server:` <br> `1.24.0 -> 2.7.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.p",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13718:1065,avail,available,1065,https://hail.is,https://github.com/hail-is/hail/pull/13718,1,['avail'],['available']
Availability,"created this PR to fix one or more vulnerable packages in the `pip` dependencies of this project.</h3>. #### Changes included in this PR. - Changes to the following files to upgrade the vulnerable dependencies to a fixed version:; - hail/python/hailtop/pinned-requirements.txt. <details>; <summary> <b>Warning</b></summary>. ```; msal-extensions 1.0.0 requires portalocker, which is not installed.; aiosignal 1.3.1 requires frozenlist, which is not installed.; aiodns 2.0.0 requires pycares, which is not installed. ```; </details>. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **663/1000** <br/> **Why?** Proof of Concept exploit, Recently disclosed, Has a fix available, CVSS 5.4 | Improper Input Validation <br/>[SNYK-PYTHON-AIOHTTP-6091621](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-6091621) | `aiohttp:` <br> `3.8.6 -> 3.9.0` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **663/1000** <br/> **Why?** Proof of Concept exploit, Recently disclosed, Has a fix available, CVSS 5.4 | Improper Input Validation <br/>[SNYK-PYTHON-AIOHTTP-6091622](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-6091622) | `aiohttp:` <br> `3.8.6 -> 3.9.0` <br> | No | Proof of Concept . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14038:1151,avail,available,1151,https://hail.is,https://github.com/hail-is/hail/pull/14038,1,['avail'],['available']
Availability,"cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **616/1000** <br/> **Why?** Proof of Concept exploit, Has a fix available, CVSS 5.9 | NULL Pointer Dereference <br/>[SNYK-PYTHON-CRYPTOGRAPHY-6092044](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-6092044) | `cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **616/1000** <br/> **Why?** Proof of Concept exploit, Has a fix available, CVSS 5.9 | Information Exposure <br/>[SNYK-PYTHON-CRYPTOGRAPHY-6126975](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-6126975) | `cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **561/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 5.5 | NULL Pointer Dereference <br/>[SNYK-PYTHON-CRYPTOGRAPHY-6210214](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-6210214) | `cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **519/1000** <br/> **Why?** Has a fix available, CVSS 6.1 | Information Exposure <br/>[SNYK-PYTHON-REQUESTS-5595532](https://snyk.io/vuln/SNYK-PYTHON-REQUESTS-5595532) | `requests:` <br> `2.27.1 -> 2.31.0` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with yo",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14327:9425,avail,available,9425,https://hail.is,https://github.com/hail-is/hail/pull/14327,1,['avail'],['available']
Availability,"csearch. ### What went wrong (all error messages here, including the full java stack trace):; ```; Traceback (most recent call last):; File ""/hail-elasticsearch-pipelines/hail_scripts/v01/load_clinvar_to_es_pipeline.py"", line 112, in <module>; export_globals_to_index_meta=True,; File ""/hail-elasticsearch-pipelines/hail_scripts/v01/utils/elasticsearch_client.py"", line 142, in export_vds_to_elasticsearch; verbose=verbose); File ""/hail-elasticsearch-pipelines/hail_scripts/v01/utils/elasticsearch_client.py"", line 287, in export_kt_to_elasticsearch; kt.export_elasticsearch(self._host, int(self._port), index_name, index_type_name, block_size, config=elasticsearch_config); File ""<decorator-gen-143>"", line 2, in export_elasticsearch; File ""/hail/build/distributions/hail-python.zip/hail/java.py"", line 121, in handle_py4j; hail.java.FatalError: EsHadoopIllegalArgumentException: Unsupported/Unknown Elasticsearch version 6.0.0. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 12.0 failed 1 times, most recent failure: Lost task 0.0 in stage 12.0 (TID 20050, localhost): org.elasticsearch.hadoop.EsHadoopIllegalArgumentException: Cannot detect ES version - typically this happens if the network/Elasticsearch cluster is not accessible or when targeting a WAN/Cloud instance without the proper setting 'es.nodes.wan.only'; 	at org.elasticsearch.hadoop.rest.InitializationUtils.discoverEsVersion(InitializationUtils.java:247); 	at org.elasticsearch.hadoop.rest.RestService.createWriter(RestService.java:545); 	at org.elasticsearch.spark.rdd.EsRDDWriter.write(EsRDDWriter.scala:58); 	at org.elasticsearch.spark.rdd.EsSpark$$anonfun$doSaveToEs$1.apply(EsSpark.scala:102); 	at org.elasticsearch.spark.rdd.EsSpark$$anonfun$doSaveToEs$1.apply(EsSpark.scala:102); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); 	at org.apache.spark.scheduler.Task.run(Task.scala:86); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4138:1473,failure,failure,1473,https://hail.is,https://github.com/hail-is/hail/issues/4138,1,['failure'],['failure']
Availability,css nesting &amp;amp; variables (&lt;a href=&quot;https://github-redirect.dependabot.com/pytest-dev/pytest-html/issues/393&quot;&gt;#393&lt;/a&gt;)&lt;/li&gt;; &lt;li&gt;&lt;a href=&quot;https://github.com/pytest-dev/pytest-html/commit/9bd4907682f10849dde1fe866b5a71402c74e551&quot;&gt;&lt;code&gt;9bd4907&lt;/code&gt;&lt;/a&gt; remove all read the doc documentation from the repo (&lt;a href=&quot;https://github-redirect.dependabot.com/pytest-dev/pytest-html/issues/405&quot;&gt;#405&lt;/a&gt;)&lt;/li&gt;; &lt;li&gt;&lt;a href=&quot;https://github.com/pytest-dev/pytest-html/commit/21fafe40b19e7d1c8b4b8bceb7fe1410e2cbdc2a&quot;&gt;&lt;code&gt;21fafe4&lt;/code&gt;&lt;/a&gt; Document how to modify the environment section after tests are finished (&lt;a href=&quot;https://github-redirect.dependabot.com/pytest-dev/pytest-html/issues/400&quot;&gt;#400&lt;/a&gt;)&lt;/li&gt;; &lt;li&gt;&lt;a href=&quot;https://github.com/pytest-dev/pytest-html/commit/8b7bdc1fc5f21e94610c3b7bcb06006271c27390&quot;&gt;&lt;code&gt;8b7bdc1&lt;/code&gt;&lt;/a&gt; Better error on missing CSS files. (&lt;a href=&quot;https://github-redirect.dependabot.com/pytest-dev/pytest-html/issues/390&quot;&gt;#390&lt;/a&gt;)&lt;/li&gt;; &lt;li&gt;&lt;a href=&quot;https://github.com/pytest-dev/pytest-html/commit/817d04df5875b143bc23fa6f4c78d0bc9ccece58&quot;&gt;&lt;code&gt;817d04d&lt;/code&gt;&lt;/a&gt; Move documentation to read the docs (&lt;a href=&quot;https://github-redirect.dependabot.com/pytest-dev/pytest-html/issues/402&quot;&gt;#402&lt;/a&gt;)&lt;/li&gt;; &lt;li&gt;&lt;a href=&quot;https://github.com/pytest-dev/pytest-html/commit/ba4f15431c42f6b650e78c9d3895e9212cf35663&quot;&gt;&lt;code&gt;ba4f154&lt;/code&gt;&lt;/a&gt; Re-enable pypy3-windows. Closes &lt;a href=&quot;https://github-redirect.dependabot.com/pytest-dev/pytest-html/issues/358&quot;&gt;#358&lt;/a&gt; (&lt;a href=&quot;https://github-redirect.dependabot.com/pytest-dev/pytest-html/issues/403&quot;&gt;#403&lt;/a&gt;)&lt;/li&gt;; &lt;li&gt;&lt;a,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11524:15614,error,error,15614,https://hail.is,https://github.com/hail-is/hail/pull/11524,1,['error'],['error']
Availability,"ct.</h3>. #### Changes included in this PR. - Changes to the following files to upgrade the vulnerable dependencies to a fixed version:; - hail/python/dev/requirements.txt. <details>; <summary> <b>Warning</b></summary>. ```; sphinx 5.3.0 has requirement docutils<0.20,>=0.14, but you have docutils 0.20.1.; sphinx-rtd-theme 1.3.0 has requirement docutils<0.19, but you have docutils 0.20.1.; notebook 6.5.6 has requirement pyzmq<25,>=17, but you have pyzmq 25.1.2.; aiohttp-devtools 1.1 requires aiohttp, which is not installed. ```; </details>. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **581/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 5.9 | Improper Limitation of a Pathname to a Restricted Directory (&#x27;Path Traversal&#x27;) <br/>[SNYK-PYTHON-AIOHTTP-6209406](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-6209406) | `aiohttp:` <br> `3.8.6 -> 3.9.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **718/1000** <br/> **Why?** Proof of Concept exploit, Recently disclosed, Has a fix available, CVSS 6.5 | HTTP Request Smuggling <br/>[SNYK-PYTHON-AIOHTTP-6209407](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-6209407) | `aiohttp:` <br> `3.8.6 -> 3.9.2` <br> | No | Proof of Concept . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencie",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14227:1232,avail,available,1232,https://hail.is,https://github.com/hail-is/hail/pull/14227,1,['avail'],['available']
Availability,ct.NativeMethodAccessorImpl.invoke0(Native Method); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.base/java.lang.reflect.Method.invoke(Method.java:566); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:282); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:238); 	at java.base/java.lang.Thread.run(Thread.java:834). is.hail.utils.HailException: Invalid locus '11:135009883' found. Position '135009883' is not within the range [1-135006516] for reference genome 'GRCh37'.; 	at is.hail.utils.ErrorHandling.fatal(ErrorHandling.scala:17); 	at is.hail.utils.ErrorHandling.fatal$(ErrorHandling.scala:17); 	at is.hail.utils.package$.fatal(package.scala:78); 	at is.hail.variant.ReferenceGenome.checkLocus(ReferenceGenome.scala:210); 	at is.hail.variant.Locus$.apply(Locus.scala:18); 	at is.hail.variant.Locus$.annotation(Locus.scala:24); 	at is.hail.io.plink.LoadPlink$.$anonfun$parseBim$3(LoadPlink.scala:43); 	at is.hail.io.plink.LoadPlink$.$anonfun$parseBim$3$adapted(LoadPlink.scala:37); 	at is.hail.utils.WithContext.foreach(Context.scala:49); 	at is.hail.io.plink.LoadPlink$.$anonfun$parseBim$2(LoadPlink.scala:37); 	at is.hail.io.plink.LoadPlink$.$anonfun$parseBim$2$adapted(LoadPlink.scala:36); 	at scala.collection.Iterator.foreach(Iterator.scala:941); 	at scala.collection.Iterator.foreach$(Iterator.scala:941); 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1429); 	at is.hail.io.plink.LoadPlink$.$anonfun$parseBim$1(LoadPlink.scala:36); 	at is.hail.io.plink.LoadPlink$.$anonfun$parseBim$1$adapted(LoadPlink.scala:35); 	at is.hail.io.fs.FS.$a,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/11836:5200,Error,ErrorHandling,5200,https://hail.is,https://github.com/hail-is/hail/issues/11836,1,['Error'],['ErrorHandling']
Availability,"ct.dependabot.com/kubernetes/kubernetes/pull/91637"">kubernetes/kubernetes#91637</a>, <a href=""https://github.com/robscott""><code>@robscott</code></a>) [SIG API Machinery, Apps, Auth, Cloud Provider, Instrumentation, Network and Testing]</li>; <li>CustomResourceDefinitions added support for marking versions as deprecated by setting <code>spec.versions[*].deprecated</code> to <code>true</code>, and for optionally overriding the default deprecation warning with a <code>spec.versions[*].deprecationWarning</code> field. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/92329"">kubernetes/kubernetes#92329</a>, <a href=""https://github.com/liggitt""><code>@liggitt</code></a>) [SIG API Machinery]</li>; <li>EnvVarSource api doc bug fixes (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/91194"">kubernetes/kubernetes#91194</a>, <a href=""https://github.com/wawa0210""><code>@wawa0210</code></a>) [SIG Apps]</li>; <li>Fix bug in reflector that couldn't recover from &quot;Too large resource version&quot; errors (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/92537"">kubernetes/kubernetes#92537</a>, <a href=""https://github.com/wojtek-t""><code>@wojtek-t</code></a>) [SIG API Machinery]</li>; <li>Fixed: log timestamps now include trailing zeros to maintain a fixed width (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/91207"">kubernetes/kubernetes#91207</a>, <a href=""https://github.com/iamchuckss""><code>@iamchuckss</code></a>) [SIG Apps and Node]</li>; <li>Generic ephemeral volumes, a new alpha feature under the <code>GenericEphemeralVolume</code> feature gate, provide a more flexible alternative to <code>EmptyDir</code> volumes: as with <code>EmptyDir</code>, volumes are created and deleted for each pod automatically by Kubernetes. But because the normal provisioning process is used (<code>PersistentVolumeClaim</code>), storage can be provided by third-party storage vendors and al",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11462:6628,recover,recover,6628,https://hail.is,https://github.com/hail-is/hail/pull/11462,2,"['error', 'recover']","['errors', 'recover']"
Availability,"ct/Next make DOM modification declarative, and very very easy. They provide a great deal of structure (especially with Next handling tooling), and thanks to the virtual dom / reconciliation process, performs, in many cases, much faster than directly modifying the DOM (HTML) (i.e plain JS). React also handles necessities like properly escaping all inputs, for XSS attack prevention. All of this in a bundle size that isn't significantly bigger than JQuery, without all of those benefits (and React is rapidly shrinking). It's possible to avoid Javascript. One can simulate interactivity by issuing a server GET request for a new page, i.e click on a link with a GET variable ?someVar=val and get a new page. This is slow (full round trip cost), and puts much more load on the server (since it not only needs to make the db call, but interpret PHP/Python to render the view). . There is a good reason why JS and monolithic single page applications became popular, with all of the initial-load (bundle size) downsides: client-side rendering allows perceived performance on the order of native mobile or desktop applications. Achieving interactive UI's without JS or Web Assembly, by using server-rendered pages, is ~impossible. We will achieve this interactivity without suffering the bundle-size-before-first-render cost, at minor developer costs vs server-side-only rendering. Lastly, it is possible to abuse any technology. Javascript brings to mind ""bloated""; this is an implementation issue. PHP/Python/Perl websites also used to be slow and ugly (Geocities).; * NodeJS/Javascript/V8 JIT is consistently faster than PHP, Python, and ~Java: https://www.techempower.com/benchmarks/. ## Why NodeJS, React, etc; 1. Javascript is the only language supported by modern browsers. Web assembly will change this (compile target == web assembly, language == rust | go | python), but is not nearly as mature; 2. Ecosystem. Chosen technologies are (likely) by far the most popular. We should quantify this be",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4931:2341,down,downsides,2341,https://hail.is,https://github.com/hail-is/hail/pull/4931,1,['down'],['downsides']
Availability,"ction\n raise last_exc\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 1032, in _create_direct_connection\n client_error=client_error,\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 975, in _wrap_create_connection\n raise client_error(req.connection_key, exc) from exc\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 10.128.0.11:5000 ssl:default [Connection refused]; INFO	2022-03-02 19:06:33,503	job_private.py	schedule_jobs_loop_body:142	starting scheduling jobs for jpim job-private; INFO	2022-03-02 19:06:33,533	job_private.py	schedule_jobs_loop_body:186	scheduled 0 jobs for jpim job-private; INFO	2022-03-02 19:06:34,964	pool.py	create_instances:244	pool highcpu n_instances 0 {'pending': 0, 'active': 0, 'inactive': 0, 'deleted': 0} free_cores 0.0 live_free_cores 0.0 ready_cores 0.0; ERROR	2022-03-02 19:06:35,376	job.py	schedule_job:473	error while scheduling job (94, 2) on instance batch-worker-pr-11438-default-g6cibyji6520-standard-9xy2q	Traceback (most recent call last):\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 969, in _wrap_create_connection\n return await self._loop.create_connection(*args, **kwargs) # type: ignore # noqa\n File ""uvloop/loop.pyx"", line 1974, in create_connection\n File ""uvloop/loop.pyx"", line 1951, in uvloop.loop.Loop.create_connection\nConnectionRefusedError: [Errno 111] Connection refused\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n File ""/usr/local/lib/python3.7/dist-packages/batch/driver/job.py"", line 449, in schedule_job\n timeout=aiohttp.ClientTimeout(total=2),\n File ""/usr/local/lib/python3.7/dist-packages/hailtop/httpx.py"", line 113, in request_and_raise_for_status\n resp = await self.client_session._request(method, url, **kwargs)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/client.py"", line 521, in _request\n req, traces=traces, timeout=real_timeout\n F",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11451:5404,error,error,5404,https://hail.is,https://github.com/hail-is/hail/pull/11451,1,['error'],['error']
Availability,"cts with <code>__getattr__</code>, like; :class:<code>~unittest.mock.Mock</code> to be treated as a; :func:<code>contextfunction</code>. :issue:<code>1145</code></li>; <li>Update <code>wordcount</code> filter to trigger :class:<code>Undefined</code> methods; by wrapping the input in :func:<code>soft_str</code>. :pr:<code>1160</code></li>; <li>Fix a hang when displaying tracebacks on Python 32-bit.; :issue:<code>1162</code></li>; <li>Showing an undefined error for an object that raises; <code>AttributeError</code> on access doesn't cause a recursion error.; :issue:<code>1177</code></li>; <li>Revert changes to :class:<code>~loaders.PackageLoader</code> from 2.10 which; removed the dependency on setuptools and pkg_resources, and added; limited support for namespace packages. The changes caused issues; when using Pytest. Due to the difficulty in supporting Python 2 and; :pep:<code>451</code> simultaneously, the changes are reverted until 3.0.; :pr:<code>1182</code></li>; <li>Fix line numbers in error messages when newlines are stripped.; :pr:<code>1178</code></li>; <li>The special <code>namespace()</code> assignment object in templates works in; async environments. :issue:<code>1180</code></li>; <li>Fix whitespace being removed before tags in the middle of lines when; <code>lstrip_blocks</code> is enabled. :issue:<code>1138</code></li>; <li>:class:<code>~nativetypes.NativeEnvironment</code> doesn't evaluate; intermediate strings during rendering. This prevents early; evaluation which could change the value of an expression.; :issue:<code>1186</code></li>; </ul>; <h2>Version 2.11.1</h2>; <p>Released 2020-01-30</p>; <ul>; <li>Fix a bug that prevented looking up a key after an attribute; (<code>{{ data.items[1:] }}</code>) in an async template. :issue:<code>1141</code></li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/pallets/jinja/commit/cf215390d4a4d6f0a4",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10209:4170,error,error,4170,https://hail.is,https://github.com/hail-is/hail/pull/10209,1,['error'],['error']
Availability,current error message is a FileNotFoundException,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3856:8,error,error,8,https://hail.is,https://github.com/hail-is/hail/issues/3856,1,['error'],['error']
Availability,"current.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_382]; 		at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_382]; 		at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_382]; 		at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_382]; 		at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_382]; 		at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_382]; 	Caused by: com.google.api.client.http.HttpResponseException: 403 Forbidden; POST https://storage.googleapis.com/upload/storage/v1/b/neale-bge/o?name=foo.ht/index/part-0-c7ba7549-bf68-42db-a8ef-0f1b13721c79.idx/index&uploadType=resumable; {; ""error"": {; ""code"": 403,; ""message"": ""dking-ae4q6@hail-vdc.iam.gserviceaccount.com does not have storage.objects.create access to the Google Cloud Storage object. Permission 'storage.objects.create' denied on resource (or it may not exist)."",; ""errors"": [; {; ""message"": ""dking-ae4q6@hail-vdc.iam.gserviceaccount.com does not have storage.objects.create access to the Google Cloud Storage object. Permission 'storage.objects.create' denied on resource (or it may not exist)."",; ""domain"": ""global"",; ""reason"": ""forbidden""; }; ]; }; }. 		at com.google.api.client.http.HttpResponseException$Builder.build(HttpResponseException.java:293) ~[gs:__hail-query-ger0g_jars_b115f6a6ec23f111a4512b562b52d9f8a52ec41c.jar.jar:0.0.1-SNAPSHOT]; 		at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1118) ~[gs:__hail-query-ger0g_jars_b115f6a6ec23f111a4512b562b52d9f8a52ec41c.jar.jar:0.0.1-SNAPSHOT]; 		at is.hail.relocated.com.google.cloud.storage.spi.v1.HttpStorageRpc.open(HttpStorageRpc.java:1022) ~[gs:__hail-query-ger0g_jars_b115f6a6ec23f111a4512b562b52d9f8a52ec41c.jar.jar:0.0.1-SNAPSHOT]; 		... 48 more; Caused by: com.google.api.client.http.HttpResponseException: 403 Forbidden; POST https://storage.googleapis.com/upload/storage/v1/b/neale-bge/o?name=foo.ht/i",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13697:26161,error,errors,26161,https://hail.is,https://github.com/hail-is/hail/issues/13697,1,['error'],['errors']
Availability,"d generic methods. We should have done this a long time ago.; - ModuleBuilder can now create type-specialized tuple types. This is used for EmitCode return values. I'm not sure if this is actually used yet.; - Require RVDType rowType to be required. Require TypeValue global type to be required. Fix lots of places to make this true. In a few spots (e.g. TableMap{Rows, Globals}), I had to wrap the IR being compiled in a Coalesce with a Die to make sure the return type is required.; - Cleaned up the dependent function interface to be closer to what we have now with MethodBuilder, etc. DependentFunctionBuilder is now just an `apply_method: DependentMethodBuilder`, EmitFunctionBuilder analogously. DependentMethodBuilder wraps a MethodBuilder, EmitMethodBuilder wraps a DependentMethodBuilder and an EmitMethodBuilder.; - Add equality comparison to TypeInfo[_]; - Add methods to convert IndexedSeq[Code[_]] to/from PCode and EmitCode. These are used to pass EmitCode as arguments to method invocation. If an emit parameter is required, the missingness boolean is omitted, otherwise it is present. Furthermore, this change also adds requiredness to many things and improves ptype interfaces:; - added PType.literalPType that infers PTypes from Scala literals, use in a few places (emit for Literal, BroadcastRegionValue constructor from annotation, etc.); - require Table global and row types to be required; - same for MatrixValue, but also cols and entries (the entries array, not individual entries, which an be missing); - Don't upcast globals in TableKeyBy and TableOrderBy; - added EType setRequired; - AbstractCodecSpecs assert row and global etypes are present at the toplevel, and setRequired(true) if they are coming from encoders written by previous versions; - rename PType.copyFromType to PType.copyFromAdddres. Modify it so it can ""downcast"": convert to a PType with greater requiredness. This is used in converting TableValues to MatrixValues to satisfy the requiredness assertions.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8371:2810,down,downcast,2810,https://hail.is,https://github.com/hail-is/hail/pull/8371,1,['down'],['downcast']
Availability,"d | probands | n_probands | r_prob | idx | n_cum_probands |; +----------------+----------------+------------------------------------------+------------+-------------+-------+----------------+; | str | str | array<str> | int64 | float64 | int64 | int64 |; +----------------+----------------+------------------------------------------+------------+-------------+-------+----------------+; | RG1692 | RG1695 | [""RG1655"",""RG1681"",""RG1691"",""RG1706"",... | 8 | 1.71331e-01 | 0 | 8 |; | G01-GEA-28-PA | G01-GEA-28-MA | [""G01-GEA-28-HI""] | 1 | 4.93356e-02 | 867 | 717 |; | DEASD_0210_500 | DEASD_0210_600 | [""DEASD_0210_001""] | 1 | 4.93218e-02 | 866 | 716 |. ```; Then I do:; ```; keep_fams_ht = keep_fams_ht.annotate(relateds=keep_fams_ht.probands.append(keep_fams_ht.mother_id).append(keep_fams_ht.father_id)); relateds = keep_fams_ht.explode(keep_fams_ht.relateds).key_by('relateds').distinct(). ```; ### What went wrong (all error messages here, including the full java stack trace):; ```; Py4JJavaError Traceback (most recent call last); <ipython-input-99-84209896ffb7> in <module>(); 1 keep_fams_ht = keep_fams_ht.annotate(relateds=keep_fams_ht.probands.append(keep_fams_ht.mother_id).append(keep_fams_ht.father_id)); ----> 2 relateds = keep_fams_ht.explode(keep_fams_ht.relateds).key_by('relateds').distinct(). /home/hail/hail.zip/hail/table.py in distinct(self); 2607 """"""; 2608 hail.methods.misc.require_key(self, ""distinct""); -> 2609 return Table(self._jt.distinctByKey()); 2610 ; 2611 table_type.set(Table). /usr/lib/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py in __call__(self, *args); 1131 answer = self.gateway_client.send_command(command); 1132 return_value = get_return_value(; -> 1133 answer, self.gateway_client, self.target_id, self.name); 1134 ; 1135 for temp_arg in temp_args:. /home/hail/hail.zip/hail/utils/java.py in deco(*args, **kwargs); 182 import pyspark; 183 try:; --> 184 return f(*args, **kwargs); 185 except py4j.protocol.Py4JJavaError as e:; 186 s = e.java_except",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3814:1220,error,error,1220,https://hail.is,https://github.com/hail-is/hail/issues/3814,1,['error'],['error']
Availability,d.foreach$(IndexedSeqOptimized.scala:33); at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:38); at is.hail.expr.ir.lowering.LoweringPipeline.apply(LoweringPipeline.scala:13); at is.hail.expr.ir.CompileAndEvaluate$._apply(CompileAndEvaluate.scala:47); at is.hail.backend.spark.SparkBackend._execute(SparkBackend.scala:416); at is.hail.backend.spark.SparkBackend.$anonfun$executeEncode$2(SparkBackend.scala:452); at is.hail.backend.ExecuteContext$.$anonfun$scoped$3(ExecuteContext.scala:70); at is.hail.utils.package$.using(package.scala:646); at is.hail.backend.ExecuteContext$.$anonfun$scoped$2(ExecuteContext.scala:70); at is.hail.utils.package$.using(package.scala:646); at is.hail.annotations.RegionPool$.scoped(RegionPool.scala:17); at is.hail.backend.ExecuteContext$.scoped(ExecuteContext.scala:59); at is.hail.backend.spark.SparkBackend.withExecuteContext(SparkBackend.scala:310); at is.hail.backend.spark.SparkBackend.$anonfun$executeEncode$1(SparkBackend.scala:449); at is.hail.utils.ExecutionTimer$.time(ExecutionTimer.scala:52); at is.hail.backend.spark.SparkBackend.executeEncode(SparkBackend.scala:448); at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.base/java.lang.reflect.Method.invoke(Method.java:566); at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); at py4j.Gateway.invoke(Gateway.java:282); at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); at py4j.commands.CallCommand.execute(CallCommand.java:79); at py4j.GatewayConnection.run(GatewayConnection.java:238); at java.base/java.lang.Thread.run(Thread.java:829). Hail version: 0.2.100-2ea2615a797a; Error summary: AssertionError: assertion failed; ```,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12280:6308,Error,Error,6308,https://hail.is,https://github.com/hail-is/hail/issues/12280,1,['Error'],['Error']
Availability,d.scala:687); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.base/java.lang.reflect.Method.invoke(Method.java:566); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:282); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:238); 	at java.base/java.lang.Thread.run(Thread.java:834). is.hail.utils.HailException: Invalid locus '11:135009883' found. Position '135009883' is not within the range [1-135006516] for reference genome 'GRCh37'.; 	at is.hail.utils.ErrorHandling.fatal(ErrorHandling.scala:17); 	at is.hail.utils.ErrorHandling.fatal$(ErrorHandling.scala:17); 	at is.hail.utils.package$.fatal(package.scala:78); 	at is.hail.variant.ReferenceGenome.checkLocus(ReferenceGenome.scala:210); 	at is.hail.variant.Locus$.apply(Locus.scala:18); 	at is.hail.variant.Locus$.annotation(Locus.scala:24); 	at is.hail.io.plink.LoadPlink$.$anonfun$parseBim$3(LoadPlink.scala:43); 	at is.hail.io.plink.LoadPlink$.$anonfun$parseBim$3$adapted(LoadPlink.scala:37); 	at is.hail.utils.WithContext.foreach(Context.scala:49); 	at is.hail.io.plink.LoadPlink$.$anonfun$parseBim$2(LoadPlink.scala:37); 	at is.hail.io.plink.LoadPlink$.$anonfun$parseBim$2$adapted(LoadPlink.scala:36); 	at scala.collection.Iterator.foreach(Iterator.scala:941); 	at scala.collection.Iterator.foreach$(Iterator.scala:941); 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1429); 	at is.hail.io.plink.LoadPlink$.$anonfun$parseBim$1(LoadPlink.scala:36); 	at is.hail.io.plink.LoadPlink$.$anonfun$parseBim$1$adapte,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/11836:5157,Error,ErrorHandling,5157,https://hail.is,https://github.com/hail-is/hail/issues/11836,1,['Error'],['ErrorHandling']
Availability,"d.status and Container.status in worker.py for the format. Example at the end. Note, ""container_statuses"" items have a field ""container_status"", because container is used in two ways: as a substep of a pod/job, and as docker container. My last renaming proposal got shot down, but we clearly need to improve this in a later PR.; - Heavily reworked worker.py. I believe this fixes https://github.com/hail-is/hail/issues/7350. The main design idea is to having all state creation and cleanup in Pod.run and Container.run.; - worker: Just support pods/status and pods/log, not container level status or logs.; - Pod now writes final status, not containers. Individual containers write their logs.; - I time all the steps of the Pod container (creating, starting, running, uploading log, etc.) with a timing called ""runtime"" which is how long the docker container itself took to start/run. That's usually 4-6 seconds. However, if you log into a machine and run `docker run --rm ubuntu:18.04 echo hi` it takes 1-2 seconds. It would be good to find out where the extra 3-4 seconds are coming from (I feel like @jigold might have some insight into this. Comparing our container config to the docker command line's might be useful here.); - Stop using (value, err) style exception handling. I think we should be able to design this with very little explicit exception handling, mainly in critical blocks to maintain the program invariants.; - Pods can have error status in 1 of 3 ways: the pod itself failed (e.g. couldn't read k8s secrets), one of the pod containers error out (e.g. pull failed due to invalid image), and the docker container finished but the final container status had an ""Error"" field. Next step is to remove pods and merge the pod and job tables. ```; {; ""name"": ""batch-2-job-1"",; ""batch_id"": 2,; ""job_id"": 1,; ""user"": ""test"",; ""state"": ""succeeded"",; ""container_statuses"": {; ""setup"": {; ""name"": ""setup"",; ""state"": ""succeeded"",; ""timing"": {; ""pulling"": 0.038861751556396484,; ""creating"": ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7354:1176,echo,echo,1176,https://hail.is,https://github.com/hail-is/hail/pull/7354,1,['echo'],['echo']
Availability,"d/Decoder.d -MT build/Decoder.o; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Werror -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/usr/lib/jvm/java-8-openjdk-amd64/include -I/usr/lib/jvm/java-8-openjdk-amd64/include/linux ApproximateQuantiles_test.cpp -MG -M -MF build/ApproximateQuantiles_test.d -MT build/ApproximateQuantiles_test.o; g++ -o build/NativeBoot.o -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Werror -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/usr/lib/jvm/java-8-openjdk-amd64/include -I/usr/lib/jvm/java-8-openjdk-amd64/include/linux -MD -MF build/NativeBoot.d -MT build/NativeBoot.o -c NativeBoot.cpp; g++ -fvisibility=default -rdynamic -shared -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Werror -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/usr/lib/jvm/java-8-openjdk-amd64/include -I/usr/lib/jvm/java-8-openjdk-amd64/include/linux build/NativeBoot.o -o lib/linux-x86-64/libboot.so; g++ -o build/davies.o -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Werror -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/usr/lib/jvm/java-8-openjdk-amd64/include -I/usr/lib/jvm/java-8-openjdk-amd64/include/linux -MD -MF build/davies.d -MT build/davies.o -c davies.cpp; davies.cpp: In member function real DaviesAlgo::qf(real*, real*, int*, int, real, real, int, real, real*, int*):; davies.cpp:241:8: error: variable qfval might be clobbered by longjmp or vfork [-Werror=clobbered]; real qfval;; ^; cc1plus: all warnings being treated as errors; make: *** [build/davies.o] Error 1; Makefile:63: recipe for target 'build/davies.o' failed; :nativeLib FAILED. FAILURE: Build failed with an exception. * What went wrong:; Execution failed for task ':nativeLib'.; > Process 'command 'make'' finished with non-zero exit value 2. * Try:; Run with --stacktrace option to get the stack trace. Run with --info or --debug option to get more log output. BUILD FAILED",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5659:7545,error,error,7545,https://hail.is,https://github.com/hail-is/hail/issues/5659,4,"['Error', 'FAILURE', 'error']","['Error', 'FAILURE', 'error', 'errors']"
Availability,"dBulk.doWriteObject(TemplatedBulk.java:71); 	at org.elasticsearch.hadoop.serialization.bulk.TemplatedBulk.write(TemplatedBulk.java:58); 	at org.elasticsearch.hadoop.rest.RestRepository.writeToIndex(RestRepository.java:168); 	at org.elasticsearch.spark.rdd.EsRDDWriter.write(EsRDDWriter.scala:67); 	at org.elasticsearch.spark.rdd.EsSpark$$anonfun$doSaveToEs$1.apply(EsSpark.scala:107); 	at org.elasticsearch.spark.rdd.EsSpark$$anonfun$doSaveToEs$1.apply(EsSpark.scala:107); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); 	at org.apache.spark.scheduler.Task.run(Task.scala:86); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Hail version: 0.1-408f188; Error summary: EsHadoopIllegalArgumentException: Spark SQL types are not handled through basic RDD saveToEs() calls; typically this is a mistake(as the SQL schema will be ignored). Use 'org.elasticsearch.spark.sql' package instead; ERROR: (gcloud.dataproc.jobs.submit.pyspark) Job [ffc9fb0b99f64080b674ab7a07962df9] entered state [ERROR] while waiting for [DONE].; ```. Ideally it would get exported as nested objects: https://www.elastic.co/guide/en/elasticsearch/reference/current/nested.html#_using_literal_nested_literal_fields_for_arrays_of_objects. with elasticsearch mapping:; ```; u'vep': {'type': 'nested', 'properties': {u'category': {'type': 'keyword'}, u'major_consequence': {'type': 'keyword'}, u'gene_id': {'type': 'keyword'}, u'major_consequence_rank': {'type': 'integer'}, u'gene_symbol': {'type': 'keyword'}, u'transcript_id': {'type': 'keyword'}, u'hgvs': {'type': 'keyword'}, u'protein_id': {'type': 'keyword'}}}, ; ```. I thought about switching to saveJsonToEs here: ; https://github.com/hail-is/hail/blob/0.1/src/main/scala/is/hail/io/ElasticsearchConnector.scala",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4250:11109,Error,Error,11109,https://hail.is,https://github.com/hail-is/hail/issues/4250,1,['Error'],['Error']
Availability,"dError as exc:; raise FatalError('Hail internal error. Please contact the Hail team and provide the following information.\n\n' + yamlx.dump({; 'service_backend_debug_info': self.debug_info(),; 'batch_debug_info': await self._batch.debug_info(); })) from exc; ; async with driver_output as outfile:; success = await read_bool(outfile); if success:; return await read_bytes(outfile); ; short_message = await read_str(outfile); expanded_message = await read_str(outfile); error_id = await read_int(outfile); ; reconstructed_error = fatal_error_from_java_error_triplet(short_message, expanded_message, error_id); if ir is None:; raise reconstructed_error; > raise reconstructed_error.maybe_user_error(ir); E hail.utils.java.FatalError: NativeIoException: readAddress(..) failed: Connection reset by peer; E ; E Java stack trace:; E io.netty.channel.unix.Errors$NativeIoException: readAddress(..) failed: Connection reset by peer; E 	at ; E ; E ; E ; E Hail version: 0.2.115-330031a5d973; E Error summary: NativeIoException: readAddress(..) failed: Connection reset by peer. /usr/local/lib/python3.8/dist-packages/hail/backend/service_backend.py:477: FatalError; ------------------------------ Captured log call -------------------------------; INFO batch_client.aioclient:aioclient.py:753 created batch 3780293; INFO batch_client.aioclient:aioclient.py:770 updated batch 3780293; INFO backend.service_backend:java.py:190 _make_tsm: found 1000 variants after filtering out monomorphic sites.; INFO batch_client.aioclient:aioclient.py:770 updated batch 3780293; INFO batch_client.aioclient:aioclient.py:770 updated batch 3780293; INFO batch_client.aioclient:aioclient.py:770 updated batch 3780293; INFO batch_client.aioclient:aioclient.py:770 updated batch 3780293; INFO batch_client.aioclient:aioclient.py:770 updated batch 3780293; INFO batch_client.aioclient:aioclient.py:770 updated batch 3780293; INFO batch_client.aioclient:aioclient.py:770 updated batch 3780293; INFO batch_client.aioclient:aioclien",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12980:4542,Error,Error,4542,https://hail.is,https://github.com/hail-is/hail/issues/12980,1,['Error'],['Error']
Availability,dSeqOptimized.foreach$(IndexedSeqOptimized.scala:33); 	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:38); 	at is.hail.expr.ir.lowering.LoweringPipeline.apply(LoweringPipeline.scala:13); 	at is.hail.expr.ir.CompileAndEvaluate$._apply(CompileAndEvaluate.scala:47); 	at is.hail.backend.spark.SparkBackend._execute(SparkBackend.scala:381); 	at is.hail.backend.spark.SparkBackend.$anonfun$executeEncode$2(SparkBackend.scala:417); 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$3(ExecuteContext.scala:47); 	at is.hail.utils.package$.using(package.scala:638); 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$2(ExecuteContext.scala:47); 	at is.hail.utils.package$.using(package.scala:638); 	at is.hail.annotations.RegionPool$.scoped(RegionPool.scala:17); 	at is.hail.backend.ExecuteContext$.scoped(ExecuteContext.scala:46); 	at is.hail.backend.spark.SparkBackend.withExecuteContext(SparkBackend.scala:275); 	at is.hail.backend.spark.SparkBackend.$anonfun$executeEncode$1(SparkBackend.scala:414); 	at is.hail.utils.ExecutionTimer$.time(ExecutionTimer.scala:52); 	at is.hail.backend.spark.SparkBackend.executeEncode(SparkBackend.scala:413); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:282); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:238); 	at java.lang.Thread.run(Thread.java:748). Hail version: 0.2.81-edeb70bc789c; Error summary: ClassTooLargeException: Class too large: __C185collect_distributed_array; ```,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12533:24319,Error,Error,24319,https://hail.is,https://github.com/hail-is/hail/issues/12533,1,['Error'],['Error']
Availability,"dStateSig +PInt64)) ()); (InitOp 1 (CallStats (CallStatsStateSig)); ((ArrayLen; (GetField alleles (Ref __iruid_4247)))))); (StreamFor __iruid_4244; (StreamFilter __iruid_4245; (StreamRange -1 False; (I32 0); (ArrayLen (Ref __iruid_4243)); (I32 1)); (ApplyUnaryPrimOp Bang; (IsNA; (ArrayRef -1; (Ref __iruid_4243); (Ref __iruid_4245))))); (Let __iruid_4246; (GetField GT; (ArrayRef -1; (Ref __iruid_4243); (Ref __iruid_4244))); (Let __void; (SeqOp 0 (Sum (TypedStateSig +PInt64)); ((Apply 18 toInt64 () Int64; (ApplyUnaryPrimOp Bang; (IsNA (Ref __iruid_4246)))))); (SeqOp 1 (CallStats (CallStatsStateSig)); ((Ref __iruid_4246))))))); (MakeTuple (0 1); (ResultOp 0 (Sum (TypedStateSig +PInt64))); (ResultOp 1 (CallStats (CallStatsStateSig))))); (InsertFields; (Ref __iruid_4247); None; (foo; (ApplyBinaryPrimOp Subtract; (GetTupleElement 0 (Ref __iruid_4268)); (Let __iruid_4249; (ToArray; (StreamFilter __iruid_4248; (ToStream False; (GetField homozygote_count; (GetTupleElement 1 (Ref __iruid_4268)))); (ApplyUnaryPrimOp Bang; (IsNA (Ref __iruid_4248))))); (Cast Int64; (StreamFold __iruid_4250 __iruid_4251; (ToStream False (Ref __iruid_4249)); (I32 0); (ApplyBinaryPrimOp Add; (Ref __iruid_4250); (Ref __iruid_4251)))))))))); None; (__uid___row_uid20; (GetField __uid___row_uid20 (Ref __iruid_4235))))); ```; (using sexpr printouts because ssa still doesn't handle aggregation well). The problem is the `AggLet` at the root of the result, which is not in an aggregation context. This happens because `__iruid_4247` is used inside an initOp arg, so the `StreamAgg` is rewritten inside the scope of `__iruid_4247` so it can be available in both init ops and the result post-processing. This behavior was added in #12092. As noted there, it was always an incomplete solution. I was already working on cleaning up and reorganizing `Extract.scala` when we got this bug report from a user; I will make sure the redesign handles this correctly. ### Version. 0.2.127. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14305:3479,avail,available,3479,https://hail.is,https://github.com/hail-is/hail/issues/14305,1,['avail'],['available']
Availability,"dapter.send(self, request, stream, timeout, verify, cert, proxies); 486 try:; --> 487 resp = conn.urlopen(; 488 method=request.method,; 489 url=url,; 490 body=request.body,; 491 headers=request.headers,; 492 redirect=False,; 493 assert_same_host=False,; 494 preload_content=False,; 495 decode_content=False,; 496 retries=self.max_retries,; 497 timeout=timeout,; 498 chunked=chunked,; 499 ); 501 except (ProtocolError, OSError) as err:. File /opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py:787, in HTTPConnectionPool.urlopen(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw); 785 e = ProtocolError(""Connection aborted."", e); --> 787 retries = retries.increment(; 788 method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]; 789 ); 790 retries.sleep(). File /opt/conda/lib/python3.10/site-packages/urllib3/util/retry.py:550, in Retry.increment(self, method, url, response, error, _pool, _stacktrace); 549 if read is False or not self._is_method_retryable(method):; --> 550 raise six.reraise(type(error), error, _stacktrace); 551 elif read is not None:. File /opt/conda/lib/python3.10/site-packages/urllib3/packages/six.py:769, in reraise(tp, value, tb); 768 if value.__traceback__ is not tb:; --> 769 raise value.with_traceback(tb); 770 raise value. File /opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py:703, in HTTPConnectionPool.urlopen(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw); 702 # Make the request on the httplib connection object.; --> 703 httplib_response = self._make_request(; 704 conn,; 705 method,; 706 url,; 707 timeout=timeout_obj,; 708 body=body,; 709 headers=headers,; 710 chunked=chunked,; 711 ); 713 # If we're going to release the connection in ``finally:``, then; 714 # the response doesn't need to know about the connection. Otherwise; 715 # it ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13960:7287,error,error,7287,https://hail.is,https://github.com/hail-is/hail/issues/13960,1,['error'],['error']
Availability,"dataset metadata and dataset versions.; - Simplify JS logic based on new JSON structure.; - Check-in and implement versioned deployment of the annotation db configuration JSON.; - Add a JS file to the website that defines `hail_version` and `hail_pip_version`.; - Add `key_properties` which currently supports two properties `gene` and `unique`. Gene keyed datasets require using the `gencode` dataset to crosswalk from locus to gene before joining.; - Rudimentary test of key properties functionality. Foundational Changes Outside Annotation DB:; - Define `__pip_version__` in `hail`.; - Teach `StructExpression` and `TupleExpression` how to slice by integers, facilitating the construction of structs of a prefix of fields.; - Make `ttuple` a mapping from integers to the tuple elements.; - Implement `Table._maybe_flexindex_table_by_expr` which, given a indexer expression, finds a prefix of the expression that can index the indexee, if such an expression exists. Unrelated changes:; - Clarify Makefile error echos with `ERROR:`. ---. ## flexindex. The primary use case for this is a dataset which is `locus, allele` keyed and needs to index into a `locus` keyed or `interval<locus>` keyed dataset. Hail's normal join logic will return a key mismatch error:. ```python; import hail as hl; t = hl.utils.range_table(10); t2 = t.key_by(x=t.idx, y=t.idx); t.index(t2.key); ```; ```; Traceback (most recent call last):; File ""<ipython-input-6-3ddc90774dfe>"", line 1, in <module>; t.index(t2.key); File ""/usr/local/lib/python3.7/site-packages/hail/table.py"", line 1536, in index; raise ExpressionException(f""Key type mismatch: cannot index table with given expressions:\n""; ExpressionException: Key type mismatch: cannot index table with given expressions:; Table key: int32; Index Expressions: int32, int32; ```. This new, private, method facilitates the annotation db which users expect to automatically find a compatible prefix of the key to use as an indexer. ---. Dice came up @chrisvittal, but I'",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7178:1521,error,error,1521,https://hail.is,https://github.com/hail-is/hail/pull/7178,3,"['ERROR', 'echo', 'error']","['ERROR', 'echos', 'error']"
Availability,"dates for Security Hub</li>; <li>api-change:<code>ssm-incidents</code>: [<code>botocore</code>] RelatedItems now have an ID field which can be used for referencing them else where. Introducing event references in TimelineEvent API and increasing maximum length of &quot;eventData&quot; to 12K characters.</li>; </ul>; <h1>1.26.7</h1>; <ul>; <li>api-change:<code>autoscaling</code>: [<code>botocore</code>] This release adds a new price capacity optimized allocation strategy for Spot Instances to help customers optimize provisioning of Spot Instances via EC2 Auto Scaling, EC2 Fleet, and Spot Fleet. It allocates Spot Instances based on both spare capacity availability and Spot Instance price.</li>; <li>api-change:<code>ec2</code>: [<code>botocore</code>] This release adds a new price capacity optimized allocation strategy for Spot Instances to help customers optimize provisioning of Spot Instances via EC2 Auto Scaling, EC2 Fleet, and Spot Fleet. It allocates Spot Instances based on both spare capacity availability and Spot Instance price.</li>; <li>api-change:<code>ecs</code>: [<code>botocore</code>] This release adds support for task scale-in protection with updateTaskProtection and getTaskProtection APIs. UpdateTaskProtection API can be used to protect a service managed task from being terminated by scale-in events and getTaskProtection API to get the scale-in protection status of a task.</li>; <li>api-change:<code>es</code>: [<code>botocore</code>] Amazon OpenSearch Service now offers managed VPC endpoints to connect to your Amazon OpenSearch Service VPC-enabled domain in a Virtual Private Cloud (VPC). This feature allows you to privately access OpenSearch Service domain without using public IPs or requiring traffic to traverse the Internet.</li>; <li>api-change:<code>resource-explorer-2</code>: [<code>botocore</code>] Text only updates to some Resource Explorer descriptions.</li>; <li>api-change:<code>scheduler</code>: [<code>botocore</code>] AWS introduces the new Ama",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12458:2555,avail,availability,2555,https://hail.is,https://github.com/hail-is/hail/pull/12458,2,['avail'],['availability']
Availability,"dbalancing/loadBalancers/list). Moreover,; we specify `loadBalancerIP` which is a manually (outside of k8s) allocated IP; which we expose on the public internet. When you `curl https://hail.is` this is what happens:. - Your packet travels across the internet until it reaches the Google TCP; LoadBalancer; - The Google TCP LoadBalancer selects one of the kubernetes nodes to send the; packet to (in principle, it could send the packet to *any* node, even nodes; that do not have a gateway pod).; - Some part of k8s receives the packet and discovers the nodes that host a; gateway pod.; - It selects a gateway pod and forwards the packet to the node (possibly itself); hosting that gateway pod. In doing so, *it must replace the source IP of the; packet with its own, internal, IP*. Note that this is happening at the TCP layer, so no HTTP headers are set. When; the gateway `nginx` receives the packet, there is no trace of the source; IP. Kubernetes has a feature called `externalTrafficPolicy` which is available; in GCP and Azure and preserves the source IP. Kubernetes achieves this by; failing the TCP LoadBalancer healthchecks on nodes without matching pods (in our; case, gateway). The k8s docs on [Source IPs](https://kubernetes.io/docs/tutorials/services/source-ip/#source-ip-for-services-with-type-loadbalancer) further explain this strategy. Here's what the healthchecks look like for two; nodes, one hosting a gateway pod and one not hosting a gateway pod (note the; HTTP status code):. ```; dking@gke-vdc-preemptible-pool-2-9aa4dbeb-wvxk ~ $ curl -v localhost:32029; * Trying 127.0.0.1...; * TCP_NODELAY set; * Connected to localhost (127.0.0.1) port 32029 (#0); > GET / HTTP/1.1; > Host: localhost:32029; > User-Agent: curl/7.64.1; > Accept: */*; >; < HTTP/1.1 200 OK; < Content-Type: application/json; < Date: Wed, 05 Feb 2020 20:59:27 GMT; < Content-Length: 88; <; {; 	""service"": {; 		""namespace"": ""default"",; 		""name"": ""gateway""; 	},; 	""localEndpoints"": 1; }; ```; ```; }dking@gke-vd",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8045:1444,avail,available,1444,https://hail.is,https://github.com/hail-is/hail/pull/8045,1,['avail'],['available']
Availability,"dcasts""); -> 3614 r, t = Env.hc().eval_expr_typed(expression._ast.to_hql()); 3615 return r, t; 3616. <decorator-gen-1049> in eval_expr_typed(self, expr). /hadoop_gcs_connector_metadata_cache/hail/hail-devel-45429b164934.zip/hail/utils/java.py in handle_py4j(func, *args, **kwargs); 153 raise FatalError('%s\n\nJava stack trace:\n%s\n'; 154 'Hail version: %s\n'; --> 155 'Error summary: %s' % (deepest, full, Env.hc().version, deepest)); 156 except py4j.protocol.Py4JError as e:; 157 if e.args[0].startswith('An error occurred while calling'):. FatalError: HailException: `(' expected but `i' found; <input>:1:(if (true) ""T"" else ""F"" + if (true) ""T"" else ""F""); ^. Java stack trace:; is.hail.utils.HailException: `(' expected but `i' found; <input>:1:(if (true) ""T"" else ""F"" + if (true) ""T"" else ""F""); ^; 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:6); 	at is.hail.utils.package$.fatal(package.scala:27); 	at is.hail.expr.ParserUtils$.error(Parser.scala:32); 	at is.hail.expr.RichParser.parse(Parser.scala:16); 	at is.hail.expr.Parser$.parseExpr(Parser.scala:85); 	at is.hail.HailContext.eval(HailContext.scala:613); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:280); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:214); 	at java.lang.Thread.run(Thread.java:748). Hail version: devel-45429b1; Error summary: HailException: `(' expected but `i' found; <input>:1:(if (true) ""T"" else ""F"" + if (true) ""T"" else ""F""); ^; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2653:3711,Error,Error,3711,https://hail.is,https://github.com/hail-is/hail/issues/2653,1,['Error'],['Error']
Availability,"de = 0]; libsimdpp-2.0-rc2/simdpp/core/cast.h:63:89: required from R simdpp::arch_avx2::bit_cast(const T&) [with R = simdpp::arch_avx2::uint32<16>; T = simdpp::arch_avx2::uint64<8>]; libsimdpp-2.0-rc2/simdpp/types/int32.h:105:36: required from simdpp::arch_avx2::uint32<N>& simdpp::arch_avx2::uint32<N>::operator=(const simdpp::arch_avx2::any_vec<(N * 4), V>&) [with V = simdpp::arch_avx2::uint64<8, simdpp::arch_avx2::expr_empty>; unsigned int N = 16]; libsimdpp-2.0-rc2/simdpp/detail/insn/transpose.h:598:8: required from void simdpp::arch_avx2::detail::insn::v_sse_transpose32x4(V&, V&, V&, V&) [with V = simdpp::arch_avx2::uint32<16>; D = simdpp::arch_avx2::uint64<8>]; libsimdpp-2.0-rc2/simdpp/detail/insn/transpose.h:533:62: required from here; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:40:13: error: void* memcpy(void*, const void*, size_t) copying an object of type class simdpp::arch_avx2::uint32<16> with private member simdpp::arch_avx2::uint32<16>::d_ from an array of const class simdpp::arch_avx2::uint64<8>; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/types.h:37,; from libsimdpp-2.0-rc2/simdpp/core/align.h:15,; from libsimdpp-2.0-rc2/simdpp/simd.h:22,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/types/int32.h:86:7: note: class simdpp::arch_avx2::uint32<16> declared here; class uint32<N, void> : public any_int32<N, uint32<N,void>> {; ^~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/simd.h:132,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl: In instantiation of R simdpp::arch_avx2::detail::cast_memcpy(const T&) [with R = simdpp::arch_avx2::float64<2>; T = simdpp::arch_avx2::float32<4>]:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3955:98875,error,error,98875,https://hail.is,https://github.com/hail-is/hail/issues/3955,1,['error'],['error']
Availability,"de> has been fixed for draft 2019. It's nonetheless; discouraged to use draft 2019 for any schemas, new or old.</li>; <li>Fix a number of minor annotation issues in <code>protocols.Validator</code></li>; </ul>; <h1>v4.13.0</h1>; <ul>; <li>Add support for creating validator classes whose metaschema uses a different; dialect than its schemas. In other words, they may use draft2020-12 to define; which schemas are valid, but the schemas themselves use draft7 (or a custom; dialect, etc.) to define which <em>instances</em> are valid. Doing this is likely; not something most users, even metaschema authors, may need, but occasionally; will be useful for advanced use cases.</li>; </ul>; <h1>v4.12.1</h1>; <ul>; <li>Fix some stray comments in the README.</li>; </ul>; <h1>v4.12.0</h1>; <ul>; <li>Warn at runtime when subclassing validator classes. Doing so was not; intended to be public API, though it seems some downstream libraries; do so. A future version will make this an error, as it is brittle and; better served by composing validator objects instead. Feel free to reach; out if there are any cases where changing existing code seems difficult; and I can try to provide guidance.</li>; </ul>; <h1>v4.11.0</h1>; <ul>; <li>Make the rendered README in PyPI simpler and fancier. Thanks Hynek (<a href=""https://github-redirect.dependabot.com/python-jsonschema/jsonschema/issues/983"">#983</a>)!</li>; </ul>; <h1>v4.10.3</h1>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/python-jsonschema/jsonschema/commit/420fc6bd9a3ecc4cd637ece97cb4b482b4d0d37e""><code>420fc6b</code></a> Minor verbiage tweak for protocols.</li>; <li><a href=""https://github.com/python-jsonschema/jsonschema/commit/8ce8250897e1b2e9b1fea6825965dbc876ec1f4d""><code>8ce8250</code></a> Don't show type checker functions in TypeChecker reprs.</li>; <li><a href=""https://github.com/python-jsonschema/jsonschema/commit/6533d32",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12163:5764,error,error,5764,https://hail.is,https://github.com/hail-is/hail/pull/12163,1,['error'],['error']
Availability,"de> option and also introduces a new optional <code>--pod-interface-name-prefix</code> and <code>--pod-bridge-interface</code> flags to kube-proxy. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/95400"">kubernetes/kubernetes#95400</a>, <a href=""https://github.com/tssurya""><code>@tssurya</code></a>)</li>; <li>CEL CRD validation expressions may now reference existing object state using the identifier <code>oldSelf</code>. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/108073"">kubernetes/kubernetes#108073</a>, <a href=""https://github.com/benluddy""><code>@benluddy</code></a>)</li>; <li>CRD deep copies should no longer contain shallow copies of <code>JSONSchemaProps.XValidations</code>. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/107956"">kubernetes/kubernetes#107956</a>, <a href=""https://github.com/benluddy""><code>@benluddy</code></a>)</li>; <li>CRD writes will generate validation errors if a CEL validation rule references the identifier <code>oldSelf</code> on a part of the schema that does not support it. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/108013"">kubernetes/kubernetes#108013</a>, <a href=""https://github.com/benluddy""><code>@benluddy</code></a>)</li>; <li>CSIStorageCapacity.storage.k8s.io: The v1beta1 version of this API is deprecated in favor of v1, and will be removed in v1.27. If a CSI driver supports storage capacity tracking, then it must get deployed with a release of external-provisioner that supports the v1 API. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/108445"">kubernetes/kubernetes#108445</a>, <a href=""https://github.com/pohly""><code>@pohly</code></a>)</li>; <li>Custom resource requests with <code>fieldValidation=Strict</code> consistently require <code>apiVersion</code> and <code>kind</code>, matching non-strict requests (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pul",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12196:3676,error,errors,3676,https://hail.is,https://github.com/hail-is/hail/pull/12196,1,['error'],['errors']
Availability,"de></a> Bump pylint to 2.13.3, update changelog</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/a880bd6d85d2487f509d1505b5146d608b15d870""><code>a880bd6</code></a> Change 'nonexistent-operator' to allow repeated unary ops (with space or pare...</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/c73353064f934ae49472eb6138e1f8071b6b733e""><code>c733530</code></a> <code>unnecessary-ellipsis</code> false positive: allow ellipsis as default argument (<a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/6"">#6</a>...</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/19e6531068cf95d602054ff8638adcb79971d552""><code>19e6531</code></a> Fix crash on unbalanced tuple unpacking</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/2066cab9bbe43341b84014ac9610e275db586431""><code>2066cab</code></a> Bump pylint to 2.13.2, update changelog</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/6a25d7048edadc18a05e999021049ade86ef2bd9""><code>6a25d70</code></a> Better error message when we cant write the crash files (<a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/5987"">#5987</a>)</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/c42fe73a1613bbfb52a5ba9129efa45a3fd76401""><code>c42fe73</code></a> Fix false negative for <code>protected-access</code> on functions (<a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/5990"">#5990</a>)</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/dec241b1787e6c99a092bb9ef6a993abf51fea91""><code>dec241b</code></a> Add regression test for <a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/5982"">#5982</a> upgrade astroid to 2.11.2 (<a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/5988"">#5988</a>)</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/b25859c4a56ccce61087f7a1270f40deaed68169""><code>b25859c</code></a> Fix false positive for <code>superfluous-parens</code> for <code>return (a or b) in iterable</code>...</li>; <l",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11702:3432,error,error,3432,https://hail.is,https://github.com/hail-is/hail/pull/11702,1,['error'],['error']
Availability,"de></a> Update dependencies</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/86a15f1c16eb729dc71b6caf30237d07b8e0bb01""><code>86a15f1</code></a> Fix compiler warnings and deprecations</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/86363072c8239330b28976109a622bdd073507b6""><code>8636307</code></a> Negative timeouts are actually not allowed</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/4ff0ff0e63e0dd45f231990d0dcebffde6e6b709""><code>4ff0ff0</code></a> Update dependencies</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/a1858b494b5f3a51ccef7580c243c6dfdf520731""><code>a1858b4</code></a> Merge pull request <a href=""https://redirect.github.com/michel-kraemer/gradle-download-task/issues/295"">#295</a> from michel-kraemer/dependabot/npm_and_yarn/screencas...</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/c1e212c0fb41b3ea9185a9ea463fb1ea7142f748""><code>c1e212c</code></a> Add integration tests for Gradle 8.0 and 8.0.1</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/304f68e25f53633a92a4d2d6ce003a4986929503""><code>304f68e</code></a> Fix type inference issue</li>; <li>Additional commits viewable in <a href=""https://github.com/michel-kraemer/gradle-download-task/compare/5.3.1...5.4.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=de.undercouch.download&package-manager=gradle&previous-version=5.3.1&new-version=5.4.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12893:2310,down,download-task,2310,https://hail.is,https://github.com/hail-is/hail/pull/12893,1,['down'],['download-task']
Availability,"de>b94395d</code></a> Bump version to 7.7.1 for release</li>; <li><a href=""https://github.com/cbeust/testng/commit/89dc5845fcb46c26af187e50ea907a7382d06e72""><code>89dc584</code></a> Streamline overloaded assertion methods for Groovy</li>; <li><a href=""https://github.com/cbeust/testng/commit/5ac0021d14f7eb00804fe235aaefc5c2fbce57d1""><code>5ac0021</code></a> Adding release notes</li>; <li><a href=""https://github.com/cbeust/testng/commit/c0e1e772f1fc0ab2142f3a4114a2b8cfe60fa7e1""><code>c0e1e77</code></a> Adjust version reference in deprecation msgs.</li>; <li><a href=""https://github.com/cbeust/testng/commit/011527d9bf0f91a40539f5e5467cc106888810d9""><code>011527d</code></a> Bump version to 7.7.0 for release</li>; <li><a href=""https://github.com/cbeust/testng/commit/7846c444a411647f7e401a097224702188c93835""><code>7846c44</code></a> Deprecate support for running JUnit tests</li>; <li><a href=""https://github.com/cbeust/testng/commit/8630a7e8fe12985d71c00212f9362fd38fb0cb9e""><code>8630a7e</code></a> Ensure ITestContext available for JUnit4 tests</li>; <li><a href=""https://github.com/cbeust/testng/commit/7070b020def0089d0d9dc695a5762ad16e974ce6""><code>7070b02</code></a> Streamline dependsOnMethods for configurations</li>; <li><a href=""https://github.com/cbeust/testng/commit/d7e0bb1cbcd7933d34d704678e75cbaf42704505""><code>d7e0bb1</code></a> Deprecate support for running Spock Tests</li>; <li><a href=""https://github.com/cbeust/testng/commit/ca7a3a293008389096be75fea4936af8e5f79650""><code>ca7a3a2</code></a> Ensure All tests run all the time</li>; <li>Additional commits viewable in <a href=""https://github.com/cbeust/testng/compare/testng-6.8.21...7.7.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=org.testng:testng&package-manager=gradle&previous-version=6.8.21&new-version=7.7.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-depend",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12665:15897,avail,available,15897,https://hail.is,https://github.com/hail-is/hail/pull/12665,1,['avail'],['available']
Availability,"ded_gather`, allows it to be used recursively. In particular, suppose we had a semaphore of; 50. The outer `bounded_gather2` might need 20 slots to run its 20 paths in parallel. That leaves 30 slots of parallelism left over for its children. By passing the semaphore down, we let our children optimistically use some of that excess parallelism. 2. If we happen to have the `StatResult` for a particular object, we should never again look it up. In particular, getting the `StatResult` for every file in a directory can be done in O(1) requests. Getting the `StatResult` for each of those files individually (using their full paths) is necessarily O(N). If there was at least one glob and also there are no `suffix_components`, then we can use the `StatResult`s that we learned when checking the glog pattern. The latter point is perhaps a bit more clear with examples:. 1. `gs://foo/bar/baz`. Since there are no globs, we can make exactly one API request to list `gs://foo/bar/baz`. 2. `gs://foo/b*r/baz`. In this case, we must make one API request to list `gs://foo/`. This gives us a list of paths under that prefix. We check each path for conformance to the glob pattern `gs://foo/b*r`. For any path that matches, we must then list `<the matching path>/baz` which may itself be a directory containing files. Overall we make O(1) API requests to do the glob and then O(K) API requests to get the final `StatResult`s, where K is the number of paths matching the glob pattern. 3. `gs://foo/bar/b*z`. In this case, we must make one API request to list `gs://foo/bar/`. In `main`, we then throw away the `StatResult`s we got from that API request! Now we have to make O(K) requests to recover those `StatResult`s for all K paths that match the glob pattern. This PR just caches the `StatResult`s of the most recent globbing. If there is no suffix to later append, then we can just re-use the `StatResult`s we already have!. cc: @daniel-goldstein since you've reviewed this before. Might be of interest.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13253:1973,recover,recover,1973,https://hail.is,https://github.com/hail-is/hail/pull/13253,1,['recover'],['recover']
Availability,"def main(args):; hl.init(log='/variant_histograms.log'); data_type = 'genomes' if args.genomes else 'exomes'. metrics = ['FS', 'InbreedingCoeff', 'MQ', 'MQRankSum', 'QD', 'ReadPosRankSum', 'SOR', 'BaseQRankSum',; 'ClippingRankSum', 'DP', 'VQSLOD', 'rf_tp_probability', 'pab_max']. ht = hl.read_table(release_ht_path(data_type, nested=False)); # NOTE: histogram aggregations are done on the entire callset (not just PASS variants), on raw data. # Compute median and MAD on variant metrics; medmad_dict = {}; for metric in metrics:; medmad_dict[metric] = hl.struct(median=hl.median(hl.agg.collect(ht[metric])), mad=4*1.48268*hl.median(hl.abs(hl.agg.collect(ht[metric])-hl.median(hl.agg.collect(ht[metric]))))); medmad = ht.aggregate(hl.struct(**medmad_dict)); print(medmad); print(hl.eval_expr(hl.json(medmad))); ```. ### What went wrong (all error messages here, including the full java stack trace):; ```; [Stage 0:==================================================>(9853 + 93) / 10000]#; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x00007fbeaec3ca22, pid=6662, tid=0x00007fbe3dd81700; #; # JRE version: OpenJDK Runtime Environment (8.0_181-b13) (build 1.8.0_181-8u181-b13-1~deb9u1-b13); # Java VM: OpenJDK 64-Bit Server VM (25.181-b13 mixed mode linux-amd64 compressed oops); # Problematic frame:; # J 14270 C1 is.hail.annotations.Region.storeInt(JI)V (6 bytes) @ 0x00007fbeaec3ca22 [0x00007fbeaec3c980+0xa2]; #; # Failed to write core dump. Core dumps have been disabled. To enable core dumping, try ""ulimit -c unlimited"" before starting Java again; #; # An error report file with more information is saved as:; # /tmp/828e66d5a71741d7ab2c8d6580997da3/hs_err_pid6662.log; Compiled method (c1) 88328 14270 3 is.hail.annotations.Region::storeInt (6 bytes); total in heap [0x00007fbeaec3c810,0x00007fbeaec3cbc0] = 944; relocation [0x00007fbeaec3c938,0x00007fbeaec3c968] = 48; main code [0x00007fbeaec3c980,0x00007fbeaec3caa0] = 288; stub code [0x00007",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4418:1633,error,error,1633,https://hail.is,https://github.com/hail-is/hail/issues/4418,2,['error'],['error']
Availability,"defun patch code for Click 8.1.0 (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2966"">#2966</a>)</li>; <li><a href=""https://github.com/psf/black/commit/ac7402cbf6a0deb5c74e9abcffc5bd7b1148fda5""><code>ac7402c</code></a> Bump sphinx from 4.4.0 to 4.5.0 in /docs (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2959"">GH-2959</a>)</li>; <li><a href=""https://github.com/psf/black/commit/f239d227c003c52126239e1b9a37c36c2b2b8305""><code>f239d22</code></a> Enforce no formatting changes for PRs via CI (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2951"">GH-2951</a>)</li>; <li><a href=""https://github.com/psf/black/commit/bd1e98034907463f5d86f4d87e89202dc6c34dd4""><code>bd1e980</code></a> Remove unnecessary parentheses from <code>except</code> clauses (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2939"">#2939</a>)</li>; <li><a href=""https://github.com/psf/black/commit/14d84ba2e96c5ca1351b8fe4d0d415cc148f4117""><code>14d84ba</code></a> Resolve new flake8-bugbear errors (B020) (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2950"">GH-2950</a>)</li>; <li><a href=""https://github.com/psf/black/commit/14e5ce5412efa53438df0180e735b3834df3b579""><code>14e5ce5</code></a> Remove unnecessary parentheses from tuple unpacking in <code>for</code> loops (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2945"">#2945</a>)</li>; <li><a href=""https://github.com/psf/black/commit/3800ebd81df6a1c31d1eac8cc15899537b9cbb61""><code>3800ebd</code></a> Avoid magic-trailing-comma in single-element subscripts (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2942"">#2942</a>)</li>; <li><a href=""https://github.com/psf/black/commit/062b54931dc3ea35f673e755893fe28ff1f5a889""><code>062b549</code></a> Github now supports .git-blame-ignore-revs (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2948"">GH-2948</a>)</li>; <li><a href=""https://github.com/psf/black/commit/5379d4f3f460ec9b706",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11696:7790,error,errors,7790,https://hail.is,https://github.com/hail-is/hail/pull/11696,1,['error'],['errors']
Availability,"dependabot.com/aio-libs/aiodocker/issues/411"">#411</a>)</li>; <li>Implement docker exec protocol. (<a href=""https://github-redirect.dependabot.com/aio-libs/aiodocker/issues/415"">#415</a>)</li>; <li>Implement container commit, pause and unpause functionality. (<a href=""https://github-redirect.dependabot.com/aio-libs/aiodocker/issues/418"">#418</a>)</li>; <li>Implement auto-versioning of the docker API by default. (<a href=""https://github-redirect.dependabot.com/aio-libs/aiodocker/issues/419"">#419</a>)</li>; </ul>; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/aio-libs/aiodocker/blob/master/CHANGES.rst"">aiodocker's changelog</a>.</em></p>; <blockquote>; <h1>0.21.0 (2021-07-23)</h1>; <h2>Bugfixes</h2>; <ul>; <li>Use ssl_context passsed to Docker constructor for creating underlying connection to docker engine. (<a href=""https://github-redirect.dependabot.com/aio-libs/aiodocker/issues/536"">#536</a>)</li>; <li>Fix an error when attach/exec when container stops before close connection to it. (<a href=""https://github-redirect.dependabot.com/aio-libs/aiodocker/issues/608"">#608</a>)</li>; </ul>; <h1>0.20.0 (2021-07-21)</h1>; <h2>Bugfixes</h2>; <ul>; <li>Accept auth parameter by <code>run()</code> method; it allows auto-pulling absent image from private storages. (<a href=""https://github-redirect.dependabot.com/aio-libs/aiodocker/issues/295"">#295</a>)</li>; <li>Fix passing of JSON params. (<a href=""https://github-redirect.dependabot.com/aio-libs/aiodocker/issues/543"">#543</a>)</li>; <li>Fix issue with unclosed response object in attach/exec. (<a href=""https://github-redirect.dependabot.com/aio-libs/aiodocker/issues/604"">#604</a>)</li>; </ul>; <h1>0.19.1 (2020-07-09)</h1>; <h2>Bugfixes</h2>; <ul>; <li>Fix type annotations for <code>exec.start()</code>, <code>docker.images.pull()</code>,; <code>docker.images.push()</code>. Respect default arguments again.</li>; </ul>; <h1>0.19.0 (2020-07-07)</h1>; <h2>Features<",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11537:1412,error,error,1412,https://hail.is,https://github.com/hail-is/hail/pull/11537,1,['error'],['error']
Availability,"dependabot.com/jupyter/jupyter_client/pull/882"">#882</a> (<a href=""https://github.com/kevin-bates""><code>@kevin-bates</code></a>)</li>; <li>Reconcile connection information <a href=""https://github-redirect.dependabot.com/jupyter/jupyter_client/pull/879"">#879</a> (<a href=""https://github.com/kevin-bates""><code>@kevin-bates</code></a>)</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/jupyter/jupyter_client/commit/5a12a3842563c682dd462eb73000adff1fcedd0f""><code>5a12a38</code></a> Publish 8.0.2</li>; <li><a href=""https://github.com/jupyter/jupyter_client/commit/717d36edcd9ce595f727d8b5a27e270c2a6e2c46""><code>717d36e</code></a> Adopt more ruff rules (<a href=""https://github-redirect.dependabot.com/jupyter/jupyter_client/issues/924"">#924</a>)</li>; <li><a href=""https://github.com/jupyter/jupyter_client/commit/666eab0b8cd7991697a9957001cf78401a76c52d""><code>666eab0</code></a> Add papermill downstream check and fix kernel client replies (<a href=""https://github-redirect.dependabot.com/jupyter/jupyter_client/issues/925"">#925</a>)</li>; <li><a href=""https://github.com/jupyter/jupyter_client/commit/fac9c3a890599ca8d7ee73206f98d75574cf4ca8""><code>fac9c3a</code></a> Prefer print in kernelspecapp (<a href=""https://github-redirect.dependabot.com/jupyter/jupyter_client/issues/923"">#923</a>)</li>; <li><a href=""https://github.com/jupyter/jupyter_client/commit/9904c4163a60c5e98737c7934b9a876c806c58fa""><code>9904c41</code></a> Publish 8.0.1</li>; <li><a href=""https://github.com/jupyter/jupyter_client/commit/dc6113c360e05122430b8e130374e9f4e4b701d7""><code>dc6113c</code></a> Fix json_output in kernelspec app (<a href=""https://github-redirect.dependabot.com/jupyter/jupyter_client/issues/921"">#921</a>)</li>; <li><a href=""https://github.com/jupyter/jupyter_client/commit/dac3cc2caa83dde06a69012e610717019026aa4e""><code>dac3cc2</code></a> Publish 8.0.0</li>; <li><a href=""htt",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12656:6885,down,downstream,6885,https://hail.is,https://github.com/hail-is/hail/pull/12656,1,['down'],['downstream']
Availability,"des, but I want to add three things on top of that:. 1. I don't want to have to do as much custom per IR node work; 2. I don't want to send the entire python stack trace over py4j to scala for every node; 3. I don't want the user to see a Java stack trace in this scenarios. This first PR is a proof of concept that adds this behavior for the `Die` node, which will catch any errors generated by uses of `CaseBuilder.or_error`. Follow up PRs should change `ArrayRef` to work this way, as well as catch things like looking up a key in a dictionary but not finding it. In an ideal future, we'd bolt on some extra mechanism to give types to these errors, and we could throw a proper `IndexError` in the `ArrayRef` case or `KeyError` in the dictionary case. . It feels a little bit messy right now, open to suggestions. I don't love using `-1` as the ""no error"" situation, but I thought it was probably easier than dealing with optionals between python and scala. . To give an example of what it looks like, the error message for this script:. ```; import hail as hl. ht = hl.utils.range_table(10); ht = ht.annotate(foo = hl.nd.array([[1], [2], [3]])); ht = ht.annotate(bar = ht.foo[0:4, 12]); ht.collect(); ```. is. ```; Traceback (most recent call last):; File ""better_error_test.py"", line 6, in <module>; ht.collect(); File ""<decorator-gen-1103>"", line 2, in collect; File ""/Users/johnc/Code/hail/hail/python/hail/typecheck/check.py"", line 614, in wrapper; return __original_func(*args_, **kwargs_); File ""/Users/johnc/Code/hail/hail/python/hail/table.py"", line 1903, in collect; return Env.backend().execute(e._ir); File ""/Users/johnc/Code/hail/hail/python/hail/backend/spark_backend.py"", line 325, in execute; raise HailUserError(message_and_trace) from None; hail.utils.java.HailUserError: Error summary: HailException: Index 12 is out of bounds for axis 1 with size 1; ------------; Hail stack trace:; File ""better_error_test.py"", line 5, in <module>; ht = ht.annotate(bar = ht.foo[0:4, 12]). File",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9398:1305,error,error,1305,https://hail.is,https://github.com/hail-is/hail/pull/9398,1,['error'],['error']
Availability,"ding the full java stack trace):; ```; Traceback (most recent call last):; File ""/hail-elasticsearch-pipelines/hail_scripts/v01/load_clinvar_to_es_pipeline.py"", line 112, in <module>; export_globals_to_index_meta=True,; File ""/hail-elasticsearch-pipelines/hail_scripts/v01/utils/elasticsearch_client.py"", line 142, in export_vds_to_elasticsearch; verbose=verbose); File ""/hail-elasticsearch-pipelines/hail_scripts/v01/utils/elasticsearch_client.py"", line 287, in export_kt_to_elasticsearch; kt.export_elasticsearch(self._host, int(self._port), index_name, index_type_name, block_size, config=elasticsearch_config); File ""<decorator-gen-143>"", line 2, in export_elasticsearch; File ""/hail/build/distributions/hail-python.zip/hail/java.py"", line 121, in handle_py4j; hail.java.FatalError: EsHadoopIllegalArgumentException: Unsupported/Unknown Elasticsearch version 6.0.0. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 12.0 failed 1 times, most recent failure: Lost task 0.0 in stage 12.0 (TID 20050, localhost): org.elasticsearch.hadoop.EsHadoopIllegalArgumentException: Cannot detect ES version - typically this happens if the network/Elasticsearch cluster is not accessible or when targeting a WAN/Cloud instance without the proper setting 'es.nodes.wan.only'; 	at org.elasticsearch.hadoop.rest.InitializationUtils.discoverEsVersion(InitializationUtils.java:247); 	at org.elasticsearch.hadoop.rest.RestService.createWriter(RestService.java:545); 	at org.elasticsearch.spark.rdd.EsRDDWriter.write(EsRDDWriter.scala:58); 	at org.elasticsearch.spark.rdd.EsSpark$$anonfun$doSaveToEs$1.apply(EsSpark.scala:102); 	at org.elasticsearch.spark.rdd.EsSpark$$anonfun$doSaveToEs$1.apply(EsSpark.scala:102); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); 	at org.apache.spark.scheduler.Task.run(Task.scala:86); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); 	at java.util.concurrent.ThreadPoolExecutor.run",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4138:1531,failure,failure,1531,https://hail.is,https://github.com/hail-is/hail/issues/4138,1,['failure'],['failure']
Availability,"direct.dependabot.com/inveniosoftware/dictdiffer/issues/85"">#85</a>)</li>; <li>Improves API documentation for <code>ignore</code> argument in <code>diff</code> function.; (<a href=""https://github-redirect.dependabot.com/inveniosoftware/dictdiffer/issues/79"">#79</a>)</li>; <li>Executes doctests during PyTest invocation.</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/inveniosoftware/dictdiffer/commit/36506e4046e07e4d43e0b5af6f76c75ff7b2b6a3""><code>36506e4</code></a> ci: remove compilie_catalog</li>; <li><a href=""https://github.com/inveniosoftware/dictdiffer/commit/2cc6ff223bdc2f2fa6b3a1842c68fc12d9555645""><code>2cc6ff2</code></a> release: v0.9.0 (<a href=""https://github-redirect.dependabot.com/inveniosoftware/dictdiffer/issues/161"">#161</a>)</li>; <li><a href=""https://github.com/inveniosoftware/dictdiffer/commit/d2f84b7dbe5e2ea871c25f7cb013d36e3be221e8""><code>d2f84b7</code></a> diff: add support for absolute tolerance of floats (<a href=""https://github-redirect.dependabot.com/inveniosoftware/dictdiffer/issues/152"">#152</a>)</li>; <li><a href=""https://github.com/inveniosoftware/dictdiffer/commit/fb2064ad9400c3b1c46a9c5cc58a0d509b1c99fd""><code>fb2064a</code></a> global: drop support for Python&lt;3.5 (<a href=""https://github-redirect.dependabot.com/inveniosoftware/dictdiffer/issues/160"">#160</a>)</li>; <li><a href=""https://github.com/inveniosoftware/dictdiffer/commit/02446475a71a22de6f7ee3d1aba2655e625c8e31""><code>0244647</code></a> testing: add <code>assert_no_diff</code> helper to assist pytest users (<a href=""https://github-redirect.dependabot.com/inveniosoftware/dictdiffer/issues/153"">#153</a>)</li>; <li><a href=""https://github.com/inveniosoftware/dictdiffer/commit/09372ecfe8bccaacfeaf3d6bab5ce69f1947a949""><code>09372ec</code></a> tests: set minimum numpy installation to earliest version with a wheel (<a href=""https://github-redirect.dependabot.co",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11485:6379,toler,tolerance,6379,https://hail.is,https://github.com/hail-is/hail/pull/11485,1,['toler'],['tolerance']
Availability,"direct.dependabot.com/psf/black/issues/3150"">#3150</a>)</li>; </ul>; <h3>Integrations</h3>; <ul>; <li>Vim plugin: prefix messages with <code>Black: </code> so it's clear they come from Black (<a href=""https://github-redirect.dependabot.com/psf/black/issues/3194"">#3194</a>)</li>; <li>Docker: changed to a /opt/venv installation + added to PATH to be available to non-root users (<a href=""https://github-redirect.dependabot.com/psf/black/issues/3202"">#3202</a>)</li>; </ul>; <h3>Output</h3>; <ul>; <li>Change from deprecated <code>asyncio.get_event_loop()</code> to create our event loop which removes DeprecationWarning (<a href=""https://github-redirect.dependabot.com/psf/black/issues/3164"">#3164</a>)</li>; <li>Remove logging from internal <code>blib2to3</code> library since it regularly emits error logs about failed caching that can and should be ignored (<a href=""https://github-redirect.dependabot.com/psf/black/issues/3193"">#3193</a>)</li>; </ul>; <h3>Parser</h3>; <ul>; <li>Type comments are now included in the AST equivalence check consistently so accidental deletion raises an error. Though type comments can't be tracked when running on PyPy 3.7 due to standard library limitations. (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2874"">#2874</a>)</li>; </ul>; <h3>Performance</h3>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/psf/black/blob/main/CHANGES.md"">black's changelog</a>.</em></p>; <blockquote>; <h2>22.8.0</h2>; <h3>Highlights</h3>; <ul>; <li>Python 3.11 is now supported, except for <em>blackd</em> as aiohttp does not support 3.11 as; of publishing (<a href=""https://github-redirect.dependabot.com/psf/black/issues/3234"">#3234</a>)</li>; <li>This is the last release that supports running <em>Black</em> on Python 3.6 (formatting 3.6; code will continue to be supported until further notice)</li>; <li>Reword the stability policy to ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12174:4768,error,error,4768,https://hail.is,https://github.com/hail-is/hail/pull/12174,1,['error'],['error']
Availability,"dle/pydevd_runpy.py"", line 321, in run_path; return _run_module_code(code, init_globals, run_name,; File ""/home/edmund/.vscode/extensions/ms-python.debugpy-2024.6.0-linux-x64/bundled/libs/debugpy/_vendored/pydevd/_pydevd_bundle/pydevd_runpy.py"", line 135, in _run_module_code; _run_code(code, mod_globals, init_globals,; File ""/home/edmund/.vscode/extensions/ms-python.debugpy-2024.6.0-linux-x64/bundled/libs/debugpy/_vendored/pydevd/_pydevd_bundle/pydevd_runpy.py"", line 124, in _run_code; exec(code, run_globals); File ""/home/edmund/.local/src/hail/test.py"", line 34, in <module>; main(); File ""/home/edmund/.local/src/hail/test.py"", line 28, in main; r2_adj = r2_adj.checkpoint(f'{tmp}/adj', overwrite=args.overwrite); File ""<decorator-gen-1508>"", line 2, in checkpoint; File ""/home/edmund/.local/src/hail/hail/python/hail/typecheck/check.py"", line 584, in wrapper; return __original_func(*args_, **kwargs_); File ""/home/edmund/.local/src/hail/hail/python/hail/linalg/blockmatrix.py"", line 679, in checkpoint; self.write(path, overwrite, force_row_major, stage_locally); File ""<decorator-gen-1506>"", line 2, in write; File ""/home/edmund/.local/src/hail/hail/python/hail/typecheck/check.py"", line 584, in wrapper; return __original_func(*args_, **kwargs_); File ""/home/edmund/.local/src/hail/hail/python/hail/linalg/blockmatrix.py"", line 656, in write; Env.backend().execute(BlockMatrixWrite(self._bmir, writer)); File ""/home/edmund/.local/src/hail/hail/python/hail/backend/backend.py"", line 190, in execute; raise e.maybe_user_error(ir) from None; File ""/home/edmund/.local/src/hail/hail/python/hail/backend/backend.py"", line 188, in execute; result, timings = self._rpc(ActionTag.EXECUTE, payload); File ""/home/edmund/.local/src/hail/hail/python/hail/backend/service_backend.py"", line 498, in _rpc; return self._cancel_on_ctrl_c(self._async_rpc(action, payload)); File ""/home/edmund/.local/src/hail/hail/python/hail/backend/service_backend.py"", line 488, in _cancel_on_ctrl_c; return async_to_bloc",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14537:3582,checkpoint,checkpoint,3582,https://hail.is,https://github.com/hail-is/hail/issues/14537,1,['checkpoint'],['checkpoint']
Availability,"docker_prefix is not exactly the ""registry name"" in azure's definition, but it is `<registry_name>.azurecr.io` which `az acr login` accepts alternatively to just the registry name. Didn't seem worth adding a mostly redundant config field.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11301:215,redundant,redundant,215,https://hail.is,https://github.com/hail-is/hail/pull/11301,1,['redundant'],['redundant']
Availability,don't throw old version error when trying to read keytable as vds,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1689:24,error,error,24,https://hail.is,https://github.com/hail-is/hail/issues/1689,1,['error'],['error']
Availability,"doop.rest.RestRepository.writeToIndex(RestRepository.java:168); 	at org.elasticsearch.spark.rdd.EsRDDWriter.write(EsRDDWriter.scala:67); 	at org.elasticsearch.spark.rdd.EsSpark$$anonfun$doSaveToEs$1.apply(EsSpark.scala:107); 	at org.elasticsearch.spark.rdd.EsSpark$$anonfun$doSaveToEs$1.apply(EsSpark.scala:107); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); 	at org.apache.spark.scheduler.Task.run(Task.scala:86); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Hail version: 0.1-408f188; Error summary: EsHadoopIllegalArgumentException: Spark SQL types are not handled through basic RDD saveToEs() calls; typically this is a mistake(as the SQL schema will be ignored). Use 'org.elasticsearch.spark.sql' package instead; ERROR: (gcloud.dataproc.jobs.submit.pyspark) Job [ffc9fb0b99f64080b674ab7a07962df9] entered state [ERROR] while waiting for [DONE].; ```. Ideally it would get exported as nested objects: https://www.elastic.co/guide/en/elasticsearch/reference/current/nested.html#_using_literal_nested_literal_fields_for_arrays_of_objects. with elasticsearch mapping:; ```; u'vep': {'type': 'nested', 'properties': {u'category': {'type': 'keyword'}, u'major_consequence': {'type': 'keyword'}, u'gene_id': {'type': 'keyword'}, u'major_consequence_rank': {'type': 'integer'}, u'gene_symbol': {'type': 'keyword'}, u'transcript_id': {'type': 'keyword'}, u'hgvs': {'type': 'keyword'}, u'protein_id': {'type': 'keyword'}}}, ; ```. I thought about switching to saveJsonToEs here: ; https://github.com/hail-is/hail/blob/0.1/src/main/scala/is/hail/io/ElasticsearchConnector.scala#L33; but not sure how to auto-convert to json before exporting; https://www.elastic.co/guide/en/elasticsearch/hadoop/6.x/spark.html#spark-streaming-write-json",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4250:11440,ERROR,ERROR,11440,https://hail.is,https://github.com/hail-is/hail/issues/4250,1,['ERROR'],['ERROR']
Availability,"doop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/eshadoop-8.2.2.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/eshadoop-8.2.2.html</a></p>; <h2>Elasticsearch Hadoop 8.2.1</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/eshadoop-8.2.1.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/eshadoop-8.2.1.html</a></p>; <h2>Elasticsearch Hadoop 8.2.0</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/eshadoop-8.2.0.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/eshadoop-8.2.0.html</a></p>; <h2>Elasticsearch Hadoop 8.1.3</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a></p>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/elastic/elasticsearch-hadoop/commit/a7873eb46985d849286ab89fa0a51f8b5374e02e""><code>a7873eb</code></a> Update index.adoc (<a href=""https://github-redirect.dependabot.com/elastic/elasticsearch-hadoop/issues/2000"">#2000</a>) (<a href=""https://github-redirect.dependabot.com/elastic/elasticsearch-hadoop/issues/2002"">#2002</a>)</li>; <li><a href=""https://github.com/elastic/elasticsearch-hadoop/commit/9f44fe66d0ff82f18a13a38cae6abf3f72183a94""><code>9f44fe6</code></a> Bump to version 8.4.3</li>; <li><a href=""https://github.com/elastic/elasticsearch-hadoop/commit/c9e3b114b98bb0e340555311c82e2d9f32c880b6""><code>c9e3b11</code></a> [DOCS] Add 8.4.2 release notes (<a href=""https://github-redirect.dependabot.com/elastic/elasticsearch-hadoop/issues/1998"">#1998</a>) (<a href=""https://github-redirect.dependabot.com/elastic/elasticsearch-hadoop/issues/1999"">#",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12319:4335,down,downloads,4335,https://hail.is,https://github.com/hail-is/hail/pull/12319,2,['down'],['downloads']
Availability,"download-task/commit/fa2739ded05333ba46d8f50bb3b2a3721cf0ca86""><code>fa2739d</code></a> Create target directories at a central place</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/02b8e1a79d9e00acd61f9ac42e5555619fe2247a""><code>02b8e1a</code></a> Prevent duplicate destination files</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/0b65ca2f17c8890a3ec34cf80cde52ee5413cbec""><code>0b65ca2</code></a> Call eachFile action only once per source</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/717877121299cea8f216d3a595eaa56731a6acd3""><code>7178771</code></a> Support changing a target file's relative path in an eachFile action</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/e5af1bd7f9daa8a9222aee0dd1b703727cb5e94e""><code>e5af1bd</code></a> Bump version number to 5.3.0-SNAPSHOT</li>; <li>Additional commits viewable in <a href=""https://github.com/michel-kraemer/gradle-download-task/compare/3.2.0...5.3.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=de.undercouch.download&package-manager=gradle&previous-version=3.2.0&new-version=5.3.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12345:5112,down,download-task,5112,https://hail.is,https://github.com/hail-is/hail/pull/12345,1,['down'],['download-task']
Availability,downsample aggregator throws null pointer exception for empty table,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4226:0,down,downsample,0,https://hail.is,https://github.com/hail-is/hail/pull/4226,1,['down'],['downsample']
Availability,"ds != None else None); 44 result = cmd.run(jstate,; ---> 45 cmd_args); 46 return VariantDataset(self, result.vds()); 47 . /Users/tpoterba/spark-1.6.2-bin-hadoop2.6/python/lib/py4j-0.9-src.zip/py4j/java_gateway.py in __call__(self, *args); 811 answer = self.gateway_client.send_command(command); 812 return_value = get_return_value(; --> 813 answer, self.gateway_client, self.target_id, self.name); 814 ; 815 for temp_arg in temp_args:. /Users/tpoterba/spark-1.6.2-bin-hadoop2.6/python/pyspark/sql/utils.pyc in deco(*a, **kw); 43 def deco(*a, **kw):; 44 try:; ---> 45 return f(*a, **kw); 46 except py4j.protocol.Py4JJavaError as e:; 47 s = e.java_exception.toString(). /Users/tpoterba/spark-1.6.2-bin-hadoop2.6/python/lib/py4j-0.9-src.zip/py4j/protocol.py in get_return_value(answer, gateway_client, target_id, name); 306 raise Py4JJavaError(; 307 ""An error occurred while calling {0}{1}{2}.\n"".; --> 308 format(target_id, ""."", name), value); 309 else:; 310 raise Py4JError(. Py4JJavaError: An error occurred while calling o92.run.; : org.broadinstitute.hail.utils.package$FatalException: arguments refer to no files; 	at org.broadinstitute.hail.utils.package$.fatal(package.scala:27); 	at org.broadinstitute.hail.driver.VCFImporter$class.globAllVcfs(ImportVCF.scala:17); 	at org.broadinstitute.hail.driver.ImportVCF$.globAllVcfs(ImportVCF.scala:33); 	at org.broadinstitute.hail.driver.ImportVCF$.run(ImportVCF.scala:83); 	at org.broadinstitute.hail.driver.ImportVCF$.run(ImportVCF.scala:33); 	at org.broadinstitute.hail.driver.Command.runCommand(Command.scala:258); 	at org.broadinstitute.hail.driver.Command.run(Command.scala:263); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:497); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:231); 	at py4j",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1096:1633,error,error,1633,https://hail.is,https://github.com/hail-is/hail/issues/1096,1,['error'],['error']
Availability,"e (ReDoS) <br/>[SNYK-PYTHON-SETUPTOOLS-3180412](https://snyk.io/vuln/SNYK-PYTHON-SETUPTOOLS-3180412) | `setuptools:` <br> `39.0.1 -> 65.5.1` <br> | No | No Known Exploit ; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **384/1000** <br/> **Why?** Has a fix available, CVSS 3.4 | Open Redirect <br/>[SNYK-PYTHON-TORNADO-5537286](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-5537286) | `tornado:` <br> `6.2 -> 6.3.3` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **494/1000** <br/> **Why?** Has a fix available, CVSS 5.6 | HTTP Request Smuggling <br/>[SNYK-PYTHON-TORNADO-5840803](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-5840803) | `tornado:` <br> `6.2 -> 6.3.3` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **496/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 4.2 | Information Exposure Through Sent Data <br/>[SNYK-PYTHON-URLLIB3-6002459](https://snyk.io/vuln/SNYK-PYTHON-URLLIB3-6002459) | `urllib3:` <br> `1.26.17 -> 1.26.18` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiIxMjY5MWQyMS0wMzk1LTQxYjMtODBkMi1mMjEyODM",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13873:3250,avail,available,3250,https://hail.is,https://github.com/hail-is/hail/pull/13873,1,['avail'],['available']
Availability,"e 2, in write; File ""/restricted/projectnb/genpro/github/hail/python/hail/typecheck/check.py"", line 481, in _typecheck; return __orig_func__(*args_, **kwargs_); File ""/restricted/projectnb/genpro/github/hail/python/hail/matrixtable.py"", line 1935, in write; self._jvds.write(output, overwrite, _codec_spec); File ""/share/pkg/spark/2.2.0/install/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py"", line 1133, in __call__; File ""/restricted/projectnb/genpro/github/hail/python/hail/utils/java.py"", line 196, in deco; 'Error summary: %s' % (deepest, full, hail.__version__, deepest)) from None; hail.utils.java.FatalError: HailException: gcad.sv.delly.5k.vcf.bgz:column 80816: invalid character '-' in integer literal; ... 2:0:0:0:6 ./.:0,0,0:0:LowQual:0:0:0:-1:0:0:0:0 ./.:0,0,0:0:LowQual:0:0:0 ...; ^; offending line: chr1 152267996 DEL00028254 AATATATATACTTTACGTAAAGT A . PASS ...; see the Hail log for the full offending line. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 20 in stage 2.0 failed 4 times, most recent failure: Lost task 20.3 in stage 2.0 (TID 485, scc-q08.scc.bu.edu, executor 2): is.hail.utils.HailException: gcad.sv.delly.5k.vcf.bgz:column 80816: invalid character '-' in integer literal; ... 2:0:0:0:6 ./.:0,0,0:0:LowQual:0:0:0:-1:0:0:0:0 ./.:0,0,0:0:LowQual:0:0:0 ...; ^; offending line: chr1 152267996 DEL00028254 AATATATATACTTTACGTAAAGT A . PASS ...; see the Hail log for the full offending line; at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:12); at is.hail.utils.package$.fatal(package.scala:26); at is.hail.io.vcf.LoadVCF$$anonfun$parseLines$1$$anon$1.hasNext(LoadVCF.scala:744); at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); at scala.collection.Iterator$$anon$1.hasNext(Iterator.scala:1004); at is.hail.rvd.OrderedRVD$$anon$2.hasNext(OrderedRVD.scala:413); at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); at is.hail.rvd.OrderedRVD$$anonfun$apply$10$$anon$3.hasNext(Order",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3379:2949,failure,failure,2949,https://hail.is,https://github.com/hail-is/hail/issues/3379,1,['failure'],['failure']
Availability,"e = True, center = True, normalize = True); bm_norm = BlockMatrix.read(out_dir + out_name + ""_norm"" + ""_bm""). # LD (unadjusted); starts_and_stops = hl.linalg.utils.locus_windows(mt.locus, radius = 2.1e6, _localize = False); bm_ld = (bm_norm @ bm_norm.T); bm_ld = BlockMatrix._from_java(bm_ld._jbm.filterRowIntervalsIR(Env.backend()._to_java_ir(starts_and_stops._ir), False)); bm_ld.write(out_dir + out_name + ""_LD"" + ""_bm"", overwrite = True); bm_ld = BlockMatrix.read(out_dir + out_name + ""_LD"" + ""_bm""). # Export LD matrices; list_range = [list(range(x.start_idx, x.end_idx + 1)) for x in list_meta[0:5]]; bms = [bm_ld.filter(x,x) for x in list_range]; hl.experimental.export_block_matrices(bms, out_dir + out_name + ""_tissue"" + ""_ld""). # Example image of problem:; <img width=""594"" alt=""Screen Shot 2019-06-13 at 5 36 58 PM"" src=""https://user-images.githubusercontent.com/24594616/59470325-52676800-8e05-11e9-93fe-e48c0e06e70b.png"">. If genotypes are normalized to N(0,1), then X @ X.T should never have values larger than 1 except for floating point precision. This is anecdotal, but I never had this problem when using > 100k samples, but here I'm using ~700 samples. I'm not sure what's causing this, but I had a conversation with @liameabbott a while ago about how one should normalize these matrices. His understanding was that hail normalizes by dividing by `sqrt(sum(x^2))` whereas one may prefer to divide `sd(x)`. The example he sent me to do this is below:. # Liam's example; g = BlockMatrix.read('gs://ukbb-ldsc-dev/1000_genomes.phase_3.europeans.GT.autosomes.bm'). n = g.shape[1]; m1 = g.sum(axis=1).cache(); m2 = (g**2).sum(axis=1).cache(). mean = m1 / n; stdev = ((m2-m1**2 / n) / (n-1)).sqrt(); g_std = ((g - mean) / stdev). g_std.write('gs://ukbb-ldsc-dev/1000_genomes.phase_3.europeans.GT_standardized.autosomes.bm', overwrite=True). I'll try this way of normalizing tomorrow to see if this is the root of the error and post back. Tagging @jbloom22 and @tpoterba 'cause why not :).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6351:2335,error,error,2335,https://hail.is,https://github.com/hail-is/hail/issues/6351,1,['error'],['error']
Availability,"e Hail 0.2.15, the memory in use by system processes on Dataproc driver nodes appears to have increased. Due to these two circumstances, the driver VM's memory usage can grow high enough to trigger the OOMKiller before the JVM triggers a GC. Consider, for example, these slices of the syslog of the n1-highmem-8 driver VM of a Dataproc cluster:. ```; Nov 22 14:26:51 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: earlyoom v1.6.2; Nov 22 14:26:51 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: mem total: 52223 MiB, swap total: 0 MiB; Nov 22 14:26:51 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: sending SIGTERM when mem <= 0.12% and swap <= 1.00%,; Nov 22 14:26:51 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: SIGKILL when mem <= 0.06% and swap <= 0.50%; ...; Nov 22 14:30:05 vds-cluster-91f3f4c1-b737-m post-hdfs-startup-script[7747]: + echo 'All done'; Nov 22 14:30:05 vds-cluster-91f3f4c1-b737-m post-hdfs-startup-script[7747]: All done; Nov 22 14:30:06 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: mem avail: 42760 of 52223 MiB (81.88%), swap free: 0 of 0 MiB ( 0.00%); ```. Notice:. 1. The total memory available on the machine is less than 52 GiB (= 53,248 MiB), indeed it is a full 1025 MiB below the advertised amount. 2. Once all the components of the Dataproc cluster have started (but before any Hail Query jobs are submitted) the total memory available is already depleted to 42760 MiB. Recall that Hail allocates 41 GiB (= 41,984 MiB) to its JVM. This leaves the Python process and all other daemons on the system only 776 MiB of excess RAM. For reference python3 -c 'import hail' needs 206 MiB. This PR modifies `hailctl dataproc start` and the meaning of `--master-memory-fraction`. Now, `--master-memory-fraction` is the precentage of the memory available to the master node after accounting for the missing 1GiB and the system daemons. We also increase the default memory fraction to 90%. For an n1-highmem-8, the driver has 36 GiB instead of 41 GiB. An n1-highmem-16 is unchanged at 83 GiB.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14066:2474,avail,available,2474,https://hail.is,https://github.com/hail-is/hail/pull/14066,3,['avail'],['available']
Availability,"e Windows PyPI builds.</li>; </ul>; <h2>3.9.15 - 2024-02-23</h2>; <h3>Fixed</h3>; <ul>; <li>Implement recursion limit of 1024 on <code>orjson.loads()</code>.</li>; <li>Use byte-exact read on <code>str</code> formatting SIMD path to avoid crash.</li>; </ul>; <h2>3.9.14 - 2024-02-14</h2>; <h3>Fixed</h3>; <ul>; <li>Fix crash serializing <code>str</code> introduced in 3.9.11.</li>; </ul>; <h3>Changed</h3>; <ul>; <li>Build now depends on Rust 1.72 or later.</li>; </ul>; <h2>3.9.13 - 2024-02-03</h2>; <h3>Fixed</h3>; <ul>; <li>Serialization <code>str</code> escape uses only 128-bit SIMD.</li>; <li>Fix compatibility with CPython 3.13 alpha 3.</li>; </ul>; <h3>Changed</h3>; <ul>; <li>Publish <code>musllinux_1_2</code> instead of <code>musllinux_1_1</code> wheels.</li>; <li>Serialization uses small integer optimization in CPython 3.12 or later.</li>; </ul>; <h2>3.9.12 - 2024-01-18</h2>; <h3>Changed</h3>; <ul>; <li>Update benchmarks in README.</li>; </ul>; <h3>Fixed</h3>; <ul>; <li>Minimal <code>musllinux_1_1</code> build due to sporadic CI failure.</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/ijl/orjson/commit/11c7de8e5846fa65449aa1f6ffc05c5a1090df03""><code>11c7de8</code></a> 3.10.0</li>; <li><a href=""https://github.com/ijl/orjson/commit/1fc3ed80c24864607be709d29e0d5f47fc507626""><code>1fc3ed8</code></a> Support numpy.float16</li>; <li><a href=""https://github.com/ijl/orjson/commit/56c1a03216426c54dfbe9a4b6c3f70013c65a1f8""><code>56c1a03</code></a> cargo update, build misc</li>; <li><a href=""https://github.com/ijl/orjson/commit/a348f59f0b55d92a1364523560f52f5b3cf9c12a""><code>a348f59</code></a> 3.9.15</li>; <li><a href=""https://github.com/ijl/orjson/commit/b0e4d2c06ce06c6e63981bf0276e4b7c74e5845e""><code>b0e4d2c</code></a> yyjson 0eca326, recursion limit</li>; <li><a href=""https://github.com/ijl/orjson/commit/5067eadc84cf516e4eb33bcb09ad756bb59dc42e""><code>506",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14427:3112,failure,failure,3112,https://hail.is,https://github.com/hail-is/hail/pull/14427,1,['failure'],['failure']
Availability,"e an IR. This PR removes environment maintenance from the parser by deferring type annotation to a separate pass (which is simple, because it can use the Binds.scala infrastructure). One consequence is that we can't assign types to nodes like `Ref` during parsing, which means we can't ask for the type of any node during parsing, and by extension we can't ask for types of children in IR node constructors. Instead, all typechecking logic is moved to the `TypeCheck` pass. Some benefits of this change:; * The parser is simpler, as it doesn't have to maintain a typing environment.; * Binds.scala is now the single source of truth on the binding structure of the IR.; * Instead of typechecking being split in an ad-hoc way between IR constructors and the `TypeCheck` pass, all typechecking and type error reporting logic is in one place.; * The parser parses a context-free grammar, no more and no less. If the input is gramatically correct, the parser succeeds.; * We can round trip IR with type errors through the text representation. For instance, if we log an IR that fails TypeCheck, we can copy the IR from the log, parse it, then debug. This change was motivated by my work in progress to convert the parser to use the SSA grammar, which this should greatly simplify. I chose to make the type annotation pass after parsing mutate the IR in place (with the unfortunate exception of `Apply`, which can change into an `ApplyIR` or `ApplySpecial`. Do these really need to be separate nodes?). The type of a `Ref` node was already mutable to allow this sort of deferred annotation, and I've had to make a few other things mutable as well. Alternatively we could rebuild the entire IR to include type annotations, but I think the mutation is sufficiently well localized, and this is a common compiler pattern. This touches a lot of lines, but the high level changes are:; * Remove the `refMap` from the `IRParserEnvironment`, and remove all code that modifies the typing environment from the parser",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13990:1300,error,errors,1300,https://hail.is,https://github.com/hail-is/hail/pull/13990,1,['error'],['errors']
Availability,"e copy in Batch. After this goes in, these can mostly be developed in parallel. A few principles guided the implementation of copy: perform the minimal number of system calls or API requests per copy, and only do error checking when it doesn't involve additional FS operations. For example, it is too expensive to exhaustively check if we're creating a path that is a file and a directory in Google Storage. I considered doing additional and exhaustive checking for the actual copy arguments. For example, currently, `cp -T /path/to/file /path/to/dir` will not generate an error on Google Storage. In the end, I decided to go with the current behavior and I will add an option to do a postpass to check for file-and-dir paths. To achieve this, for each transfer, I simultaneously stat the destination (if needd) to determine if it is a file, directory or doesn't exist. For each source, I simultaneously try to copy it as a file and a directory. When copying each source, we don't need to know the type of the destination until after we've stat'ed the source, so stat'ing the sources and destinations are all overlapping. This avoids dependencies where I have to e.g. stat the input, decide what to do, and then perform a second action. I approached testing two ways: First, hand test common operations and errors (copy file, copy dir, overwrite, overwrite dir with file and vice versa, the various treat_dest_as settings, large files, detecting copy-and-files on input on Google Storage, etc.) Second, I enumerated essentially all single input transfers and recorded the results. These are then tested on every pair of file systems: file to file, file to gs, gs to file, etc. To make this run reasonably, I parallelize using xdist and the full tests (1364 tests) now take about 2 minutes. (If you restrict to the just the local filesystem, the tests just take a couple seconds.) The second test verifies that all cases run without unexpected errors, and that the behavior is file system independent.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9822:2252,error,errors,2252,https://hail.is,https://github.com/hail-is/hail/pull/9822,2,['error'],['errors']
Availability,"e creation and cleanup in Pod.run and Container.run.; - worker: Just support pods/status and pods/log, not container level status or logs.; - Pod now writes final status, not containers. Individual containers write their logs.; - I time all the steps of the Pod container (creating, starting, running, uploading log, etc.) with a timing called ""runtime"" which is how long the docker container itself took to start/run. That's usually 4-6 seconds. However, if you log into a machine and run `docker run --rm ubuntu:18.04 echo hi` it takes 1-2 seconds. It would be good to find out where the extra 3-4 seconds are coming from (I feel like @jigold might have some insight into this. Comparing our container config to the docker command line's might be useful here.); - Stop using (value, err) style exception handling. I think we should be able to design this with very little explicit exception handling, mainly in critical blocks to maintain the program invariants.; - Pods can have error status in 1 of 3 ways: the pod itself failed (e.g. couldn't read k8s secrets), one of the pod containers error out (e.g. pull failed due to invalid image), and the docker container finished but the final container status had an ""Error"" field. Next step is to remove pods and merge the pod and job tables. ```; {; ""name"": ""batch-2-job-1"",; ""batch_id"": 2,; ""job_id"": 1,; ""user"": ""test"",; ""state"": ""succeeded"",; ""container_statuses"": {; ""setup"": {; ""name"": ""setup"",; ""state"": ""succeeded"",; ""timing"": {; ""pulling"": 0.038861751556396484,; ""creating"": 0.7245609760284424,; ""starting"": 4.770207166671753,; ""running"": 1.1384251117706299,; ""runtime"": 5.909235715866089,; ""uploading_log"": 0.3659687042236328,; ""deleting"": 0.013197660446166992; },; ""container_status"": {; ""state"": ""exited"",; ""started_at"": ""2019-10-22T09:25:42.477556224Z"",; ""finished_at"": ""2019-10-22T09:25:42.476019599Z"",; ""exit_code"": 0; }; },; ""main"": {; ""name"": ""main"",; ""state"": ""succeeded"",; ""timing"": {; ""pulling"": 0.031185626983642578,; ""creating"":",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7354:1638,error,error,1638,https://hail.is,https://github.com/hail-is/hail/pull/7354,1,['error'],['error']
Availability,"e full java stack trace): ; When exporting vcf to path that begins with 'file://', I get the error: `ClassNotFoundException: Class org.apache.hadoop.mapred.DirectFileOutputCommitter not found`. I am using Spark 2.2.1 (prebuilt with hadoop2.7) with AWS-Hadoop 2.7.4. I have the following settings in spark config and am using a custom directParquetOutputCommitter. Standard writes to 'file://' of Spark dataframes work without issue. Thanks for any help!. ```; spark.sql.parquet.output.committer.class org.apache.spark.sql.parquet.DirectParquetOutputCommitter; spark.hadoop.mapred.output.committer.class org.apache.hadoop.mapred.DirectFileOutputCommitter; spark.hadoop.mapreduce.use.directfileoutputcommitter true; spark.hadoop.spark.sql.parquet.output.committer.class org.apache.spark.sql.parquet.DirectParquetOutputCommitter; ```. Code and stack trace:; ```; ================================================================================================== FAILURES ===================================================================================================; __________________________________________________________________________________________ TestHAIL.test_export_vcf ___________________________________________________________________________________________. self = <test_hail.TestHAIL testMethod=test_export_vcf>. def test_export_vcf(self):; # define files; bgen_file = os.path.join(self.testdir, 'example.10bits.bgen'); sample_file = os.path.join(self.testdir, 'example.sample'); # make index; self.hc.index_bgen(bgen_file); # load to vds; bgen_vds = self.hc.import_bgen(bgen_file, sample_file=sample_file); # export vcf; out_path = 'file://' + os.path.join(self.tmpdir, 'test_vcf_export.vcf.bgz'); > bgen_vds.export_vcf(out_path, export_pp=False, parallel=False). tests/hail/test_hail.py:55:; _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3946:1104,FAILURE,FAILURES,1104,https://hail.is,https://github.com/hail-is/hail/issues/3946,1,['FAILURE'],['FAILURES']
Availability,"e handled exactly as described in input/output dependencies above.; - [ ] allow ""finalizer"" jobs. A finalizer job executes when its parents are all complete or cancelled. It is not cancelled when its parents are cancelled.; - [ ] add namespace dependencies. CI allocates anonymous namespaces as requested by the build process. All `exec`s are, by default, run in an anonymous namespace. CI adds a finalizer job that deletes namespaces when all relevant `exec`s are finished; - [ ] add image dependencies. CI can create a batch job that builds a docker image with an anonymous name and pushes it to the project's GCR. CI adds a finalizer job that deletes the image when all relevant `exec`s are finished.; - [ ] batch and notebook are parameterized by their worker namespace so they can use the namespaces described above; - [ ] hail's build steps are parameterized in a way that permits them to use a jar not built locally on this machine (hopefully the Make PR makes this easy, otherwise we have to fool gradle into not rebuilding the jar). To reliably handle clean up, we *must* persist batch jobs, so I think that should be either higher priority or at least happening in parallel to the above (i.e. two developers working in parallel). - [ ] persist batch jobs in a durable store with all of the fields in the beginning of `Job.__init__`. When batch starts up, before serving any requests, it restores its state from the durable store and then refreshes from k8s. The k8s label `hail.is/batch-instance` is retired. Instead, pods have `hail.is/batch-version` which is a monotonically increasing natural number. It is only incremented if batch is backwards incompatible with the pod specs. Probably batch should destroy any pods that are alive from an out-of-date version of batch.; - [ ] persist CI information in a durable store [this needs more detail]; - [ ] How do we configure the database? How do we create new tables? Should this be done in the applications themselves or during deployment?",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5193:2864,reliab,reliably,2864,https://hail.is,https://github.com/hail-is/hail/issues/5193,2,"['alive', 'reliab']","['alive', 'reliably']"
Availability,"e information, describing how the alternate alleles are phased in relation to one another"">; ##FORMAT=<ID=PID,Number=1,Type=String,Description=""Physical phasing ID information, where each unique ID within a given sample (but not across samples) connects records within a phasing group"">; ##FORMAT=<ID=RGQ,Number=1,Type=Integer,Description=""Unconditional reference genotype confidence, encoded as a phred quality -10*log10 p(genotype call is wrong)"">; ##FORMAT=<ID=SB,Number=4,Type=Integer,Description=""Per-sample component statistics which comprise the Fisher's Exact Test to detect strand bias."">; ##GATKCommandLine=<ID=GenotypeGVCFs,CommandLine=""GenotypeGVCFs --output 3P5CH.new.vcf --use-new-qual-calculator true --annotation-group StandardAnnotation --annotation-group StandardHCAnnotation --dbsnp /home/fgc3/dbsnp/150/GRCh38/All_20170710.vcf.gz --variant 3P5CH.new.g.vcf.gz --reference /home/fgc3/10x/refdata-GRCh38-2.1.0/fasta/genome.fa --create-output-variant-index false --verbosity ERROR --annotate-with-num-discovered-alleles false --heterozygosity 0.001 --indel-heterozygosity 1.25E-4 --heterozygosity-stdev 0.01 --standard-min-confidence-threshold-for-calling 10.0 --max-alternate-alleles 6 --max-genotype-count 1024 --sample-ploidy 2 --disable-tool-default-annotations false --only-output-calls-starting-in-intervals false --interval-set-rule UNION --interval-padding 0 --interval-exclusion-padding 0 --interval-merging-rule ALL --read-validation-stringency SILENT --seconds-between-progress-updates 10.0 --disable-sequence-dictionary-validation false --create-output-bam-index true --create-output-bam-md5 false --create-output-variant-md5 false --lenient false --add-output-sam-program-record true --add-output-vcf-command-line true --cloud-prefetch-buffer 40 --cloud-index-prefetch-buffer -1 --disable-bam-index-caching false --help false --version false --showHidden false --QUIET false --use-jdk-deflater false --use-jdk-inflater false --gcs-max-retries 20 --disable-tool-default-rea",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8469:23292,ERROR,ERROR,23292,https://hail.is,https://github.com/hail-is/hail/issues/8469,1,['ERROR'],['ERROR']
Availability,"e pyzmq 25.1.2.; aiohttp-devtools 1.1 requires aiohttp, which is not installed. ```; </details>. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **581/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 5.9 | Improper Limitation of a Pathname to a Restricted Directory (&#x27;Path Traversal&#x27;) <br/>[SNYK-PYTHON-AIOHTTP-6209406](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-6209406) | `aiohttp:` <br> `3.8.6 -> 3.9.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **718/1000** <br/> **Why?** Proof of Concept exploit, Recently disclosed, Has a fix available, CVSS 6.5 | HTTP Request Smuggling <br/>[SNYK-PYTHON-AIOHTTP-6209407](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-6209407) | `aiohttp:` <br> `3.8.6 -> 3.9.2` <br> | No | Proof of Concept . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJhZDFmMzFlYi1hYTcyLTQyMTYtOTgzNC01MDljMDdhOWFmNT",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14227:1696,avail,available,1696,https://hail.is,https://github.com/hail-is/hail/pull/14227,1,['avail'],['available']
Availability,"e retention was set so using the default time retention"" duration=15d; level=info ts=2019-07-31T15:45:51.991Z caller=main.go:322 msg=""Starting Prometheus"" version=""(version=2.10.0, branch=HEAD, revision=d20e84d0fb64aff2f62a977adc8cfb656da4e286)""; level=info ts=2019-07-31T15:45:51.991Z caller=main.go:323 build_context=""(go=go1.12.5, user=root@a49185acd9b0, date=20190525-12:28:13)""; level=info ts=2019-07-31T15:45:51.991Z caller=main.go:324 host_details=""(Linux 4.14.127+ #1 SMP Tue Jun 18 18:32:10 PDT 2019 x86_64 prometheus-0 (none))""; level=info ts=2019-07-31T15:45:51.991Z caller=main.go:325 fd_limits=""(soft=1048576, hard=1048576)""; level=info ts=2019-07-31T15:45:51.991Z caller=main.go:326 vm_limits=""(soft=unlimited, hard=unlimited)""; level=info ts=2019-07-31T15:45:51.993Z caller=main.go:645 msg=""Starting TSDB ...""; level=info ts=2019-07-31T15:45:51.994Z caller=web.go:417 component=web msg=""Start listening for connections"" address=0.0.0.0:9090; level=info ts=2019-07-31T15:45:51.996Z caller=repair.go:59 component=tsdb msg=""found healthy block"" mint=1563105600000 maxt=1563170400000 ulid=01DFTDRJHCX1S9B0KPJTG8CRGW; level=info ts=2019-07-31T15:45:51.997Z caller=repair.go:59 component=tsdb msg=""found healthy block"" mint=1563170400000 maxt=1563235200000 ulid=01DFWBK0336Z71ZCRRKS79T18P; level=info ts=2019-07-31T15:45:51.997Z caller=repair.go:59 component=tsdb msg=""found healthy block"" mint=1563235200000 maxt=1563300000000 ulid=01DFY9C92NRA1S7FDVHFRFMFPF; level=info ts=2019-07-31T15:45:51.998Z caller=repair.go:59 component=tsdb msg=""found healthy block"" mint=1563300000000 maxt=1563364800000 ulid=01DG075GN2MME91GM1DA5G3H07; level=info ts=2019-07-31T15:45:51.999Z caller=repair.go:59 component=tsdb msg=""found healthy block"" mint=1563364800000 maxt=1563429600000 ulid=01DG24Z1SDJ7VXW96YYSY1FC8Y; level=info ts=2019-07-31T15:45:51.999Z caller=repair.go:59 component=tsdb msg=""found healthy block"" mint=1563429600000 maxt=1563494400000 ulid=01DG42SDMFEK1AJPRJ5YWKZFJ8; level=info ts=2019",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6773:3401,repair,repair,3401,https://hail.is,https://github.com/hail-is/hail/issues/6773,1,['repair'],['repair']
Availability,"e script successfully downloaded and installed the various Java dependencies, but gcc chokes on the C source code. I get:; $ ./gradlew shadowJar; :compileJava UP-TO-DATE; :nativeLib; (cd libsimdpp-2.0-rc2 && cmake .); -- Configuring done; -- Generating done; -- Build files have been written to: /home/rmk/package_sources/hail/hail/src/main/c/libsimdpp-2.0-rc2; mkdir -p lib/linux-x86-64; g++ -fvisibility=hidden -rdynamic -shared -fPIC -ggdb -O3 -march=native -g -std=c++11 -Ilibsimdpp-2.0-rc2 -Wall -Werror ibs.cpp -o lib/linux-x86-64/libibs.so; In file included from ibs.cpp:1:0:; /usr/lib/gcc/x86_64-linux-gnu/4.9/include/popcntintrin.h: In function uint64_t vector_popcnt(uint64vector):; /usr/lib/gcc/x86_64-linux-gnu/4.9/include/popcntintrin.h:42:1: error: inlining failed in call to always_inline long long int _mm_popcnt_u64(long long unsigned int): target specific option mismatch; _mm_popcnt_u64 (unsigned long long __X); ^; ibs.cpp:14:48: error: called from here; uint64_t count = _mm_popcnt_u64(extract<0>(x));; ^; In file included from ibs.cpp:1:0:; /usr/lib/gcc/x86_64-linux-gnu/4.9/include/popcntintrin.h:42:1: error: inlining failed in call to always_inline long long int _mm_popcnt_u64(long long unsigned int): target specific option mismatch; _mm_popcnt_u64 (unsigned long long __X); ^; ibs.cpp:16:41: error: called from here; count += _mm_popcnt_u64(extract<1>(x));; ^; make: *** [lib/linux-x86-64/libibs.so] Error 1; Makefile:52: recipe for target 'lib/linux-x86-64/libibs.so' failed; :nativeLib FAILED. Tim Poterba suggested defining `CXXFLAGS='-DHAIL_OVERRIDE_ARCH -DSIMDPP_ARCH_X86_SSE2'`, but to no avail. So, he suggested I open this issue. I'm running gcc version 4.9.2. Possibly relevant might be the processor I'm running,; $ lscpu; Architecture: x86_64; CPU op-mode(s): 32-bit, 64-bit; Byte Order: Little Endian; CPU(s): 2; On-line CPU(s) list: 0,1; Thread(s) per core: 1; Core(s) per socket: 2; Socket(s): 1; NUMA node(s): 1; Vendor ID: GenuineIntel; CPU family: 6",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1520:1108,error,error,1108,https://hail.is,https://github.com/hail-is/hail/issues/1520,1,['error'],['error']
Availability,"e should load the; class?). Every `ClassLoader` has a `parent` `ClassLoader`. The default implementation of `loadClass` and; `getResource` prefers loading classes from its parent ClassLoader before anything else. We invert; the loading order to allow multiple definitions of the same Class in the same JVM. In particular,; each instance of `LoadSelfFirstURLClassLoader` prefers to use its own definition of a Class. Each; `LoadSelfFirstURLClassLoader` instance knows about one version of the Hail JAR. The remaining subtle issue is how to load resources. For example, `HailBuildInfo` needs to load the; build info resource file. To do so, you need an instance of a `ClassLoader` that can find the; file you want. Often times, you use `this.getClass().getClassLoader()`, which is the class loader; used to load the current class. Hail does not do this. I believe we do not do this because of issues; with how TestNG loads classes. :sigh: As a result, I also modify the worker Thread's; ContextClassLoader for the duration of the execution of an alternative version of Hail. ---. I've already updated the cluster with the new bucket and the corresponding change to the; `global-config` secret. We'll should notify Leo et al. about the Terraform changes. ---. Small changes and fixes:. - Rename `key.json` to `/worker-key.json` for clarity, this is the worker's own GCP service account; key.; - Create a test query-gsa-key in test and dev namespaces.; - Add terraform rules for the query service account. It already existed, but it was missing from the; Terraform file. You can verify the permissions grant by inspecting `gsutil iam get; gs://hail-query`.; - The `query` user was missing from bootstrap-create-accounts.; - `hail-ubuntu-stmp` was missing from `docker/Makefile`'s `clean` rule; - Use a dummy `WorkerBackend` when we're on the worker. The worker isn't allowed to call these; methods anyway, that would amount to Hail Queries inside of Hail Queries, madness!; - New transient error in Java.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10279:2980,error,error,2980,https://hail.is,https://github.com/hail-is/hail/pull/10279,1,['error'],['error']
Availability,"e vulnerable packages in the `pip` dependencies of this project.</h3>. #### Changes included in this PR. - Changes to the following files to upgrade the vulnerable dependencies to a fixed version:; - hail/python/dev/requirements.txt. <details>; <summary> <b>Warning</b></summary>. ```; sphinx 5.3.0 has requirement docutils<0.20,>=0.14, but you have docutils 0.20.1.; sphinx-rtd-theme 1.3.0 has requirement docutils<0.19, but you have docutils 0.20.1.; notebook 6.5.6 has requirement pyzmq<25,>=17, but you have pyzmq 25.1.1. ```; </details>. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **531/1000** <br/> **Why?** Proof of Concept exploit, Has a fix available, CVSS 4.2 | Remote Code Execution (RCE) <br/>[SNYK-PYTHON-IPYTHON-3318382](https://snyk.io/vuln/SNYK-PYTHON-IPYTHON-3318382) | `ipython:` <br> `7.34.0 -> 8.10.0` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **/1000** <br/> **Why?** | Access Control Bypass <br/>[SNYK-PYTHON-JUPYTERSERVER-5862881](https://snyk.io/vuln/SNYK-PYTHON-JUPYTERSERVER-5862881) | `jupyter-server:` <br> `1.24.0 -> 2.7.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **/1000** <br/> **Why?** | Open Redirect <br/>[SNYK-PYTHON-JUPYTERSERVER-5862882](https://snyk.io/vuln/SNYK-PYTHON-JUPYTERSERVER-5862882) | `jupyter-server:` <br> `1.24.0 -> 2.7.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.p",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14026:1174,avail,available,1174,https://hail.is,https://github.com/hail-is/hail/pull/14026,1,['avail'],['available']
Availability,"e"",""from"":""0.8.4"",""to"":""2.0.3""},{""name"":""nbconvert"",""from"":""5.6.1"",""to"":""6.3.0b0""},{""name"":""notebook"",""from"":""5.7.16"",""to"":""6.4.12""},{""name"":""pygments"",""from"":""2.5.2"",""to"":""2.15.0""},{""name"":""requests"",""from"":""2.27.1"",""to"":""2.31.0""},{""name"":""setuptools"",""from"":""39.0.1"",""to"":""65.5.1""},{""name"":""sphinx"",""from"":""1.8.6"",""to"":""3.3.0""},{""name"":""tornado"",""from"":""5.1.1"",""to"":""6.3.3""}],""packageManager"":""pip"",""projectPublicId"":""20159ae6-a5aa-42fa-845a-c89f5bcbf999"",""projectUrl"":""https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-CERTIFI-3164749"",""SNYK-PYTHON-CERTIFI-5805047"",""SNYK-PYTHON-IPYTHON-2348630"",""SNYK-PYTHON-IPYTHON-3318382"",""SNYK-PYTHON-JUPYTERCORE-3063766"",""SNYK-PYTHON-MISTUNE-2940625"",""SNYK-PYTHON-NBCONVERT-2979829"",""SNYK-PYTHON-NOTEBOOK-1041707"",""SNYK-PYTHON-NOTEBOOK-2441824"",""SNYK-PYTHON-NOTEBOOK-2928995"",""SNYK-PYTHON-PYGMENTS-1086606"",""SNYK-PYTHON-PYGMENTS-1088505"",""SNYK-PYTHON-PYGMENTS-5750273"",""SNYK-PYTHON-REQUESTS-5595532"",""SNYK-PYTHON-SETUPTOOLS-3180412"",""SNYK-PYTHON-SPHINX-570772"",""SNYK-PYTHON-SPHINX-570773"",""SNYK-PYTHON-SPHINX-5811865"",""SNYK-PYTHON-SPHINX-5812109"",""SNYK-PYTHON-TORNADO-5537286"",""SNYK-PYTHON-TORNADO-5840803""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""pr-warning-shown"",""priorityScore""],""priorityScoreList"":[554,704,624,531,604,589,726,434,589,449,696,589,479,519,509,711,701,586,586,384,494],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**.  [Remote Code Execution (RCE)](https://learn.snyk.io/lesson/improper-input-validation/?loc&#x3D;fix-pr);  [Improper Privilege Management](https://learn.snyk.io/lesson/insecure-design/?loc&#x3D;fix-pr);  [Regular Expression Denial of Service (ReDoS)](https://learn.snyk.io/lesson/redos/?loc&#x3D;fix-pr);  [More lessons are available in Snyk Learn](https://learn.snyk.io/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13717:12316,avail,available,12316,https://hail.is,https://github.com/hail-is/hail/pull/13717,1,['avail'],['available']
Availability,"e, GRCh37). hl.eval(hl.liftover(hl.locus('chr1', 1034245, 'GRCh38'), 'GRCh37')); # Locus(contig=1, position=969625, reference_genome=GRCh37); ```. However, when trying to lift over the entire table it fails:; ```; ht = ht.annotate(; locus_GRCh37 = hl.liftover(ht.locus, 'GRCh37'); ); ht.show(); ```. I got the same error when trying to lift over an older gnomAD version (2.1) from GRCh37 to GRCh38, which used to work according to my best knowledge. Also, this way of lifting over a hail table is following the recommended process on the documentation [here](https://hail.is/docs/0.2/guides/genetics.html?highlight=prs#liftover-variants-from-one-coordinate-system-to-another). I'm quite confident there must be something I'm doing wrong, but now I'm stuck, any help would be highly welcome. Thanks!. The code is running on a Google Cloud Dataproc cluster, Python 3.8, hail version: `'0.2.71-f3a54b530979'`. Error stack:; ```python; --------------------------------------------------------------------------- / 1]; FatalError Traceback (most recent call last); /opt/conda/miniconda3/lib/python3.8/site-packages/IPython/core/formatters.py in __call__(self, obj); 700 type_pprinters=self.type_printers,; 701 deferred_pprinters=self.deferred_printers); --> 702 printer.pretty(obj); 703 printer.flush(); 704 return stream.getvalue(). /opt/conda/miniconda3/lib/python3.8/site-packages/IPython/lib/pretty.py in pretty(self, obj); 392 if cls is not object \; 393 and callable(cls.__dict__.get('__repr__')):; --> 394 return _repr_pprint(obj, self, cycle); 395; 396 return _default_pprint(obj, self, cycle). /opt/conda/miniconda3/lib/python3.8/site-packages/IPython/lib/pretty.py in _repr_pprint(obj, p, cycle); 698 """"""A pprint that just redirects to the normal repr function.""""""; 699 # Find newlines and replace them with p.break_(); --> 700 output = repr(obj); 701 lines = output.splitlines(); 702 with p.group():. /opt/conda/miniconda3/lib/python3.8/site-packages/hail/table.py in __repr__(self); 1295; 1296",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/10682:1380,Error,Error,1380,https://hail.is,https://github.com/hail-is/hail/issues/10682,1,['Error'],['Error']
Availability,"e-account; --key-file=/gsa-key/privateKeyData)) && gsutil -m cp -R /io/pipeline/pipeline-1cac3dd4e66d/__TASK__286/8926feac; gs://hail-wang-ukps2/pipeline/pipeline-1cac3dd4e66d/__TASK__286/8926feac; image: gcr.io/hail-vdc/batch:s32fqwbuz8nv; imagePullPolicy: IfNotPresent; name: cleanup; ports:; - containerPort: 5000; protocol: TCP; resources:; requests:; cpu: 500m; terminationMessagePath: /dev/termination-log; terminationMessagePolicy: File; volumeMounts:; - mountPath: /batch-gsa-key; name: batch-gsa-key; - mountPath: /gsa-key; name: gsa-key; - mountPath: /io; name: batch-12728-job-287-742170; - mountPath: /var/run/secrets/kubernetes.io/serviceaccount; name: batch-output-pod-token-8pkmz; readOnly: true; - command:; - /bin/sh; - -c; - ""\n set -ex\n python3 -m batch.keep_alive_sidecar\n ""; image: gcr.io/hail-vdc/batch:s32fqwbuz8nv; imagePullPolicy: IfNotPresent; name: keep-alive; ports:; - containerPort: 5001; protocol: TCP; resources:; requests:; cpu: 1m; terminationMessagePath: /dev/termination-log; terminationMessagePolicy: File; volumeMounts:; - mountPath: /gsa-key; name: gsa-key; - mountPath: /io; name: batch-12728-job-287-742170; - mountPath: /var/run/secrets/kubernetes.io/serviceaccount; name: batch-output-pod-token-8pkmz; readOnly: true; dnsPolicy: ClusterFirst; enableServiceLinks: true; initContainers:; - command:; - /bin/sh; - -c; - ""\n set -ex\n (gcloud -q auth activate-service-account --key-file=/batch-gsa-key/privateKeyData; || (sleep $(( 5 + (RANDOM % 5) )); gcloud -q auth activate-service-account --key-file=/batch-gsa-key/privateKeyData))\n; \ gsutil -q stat gs://hail-batch-3jmp5/cd50b95a89914efb897965a5e982a29d/12728/287/742170/container_logs; && exit 1\n rm -rf /io/*\n set -ex; (gcloud -q auth activate-service-account; --key-file=/gsa-key/privateKeyData || (sleep $(( 5 + (RANDOM % 5) )); gcloud; -q auth activate-service-account --key-file=/gsa-key/privateKeyData)) && mkdir; -p /io/pipeline/pipeline-1cac3dd4e66d/__TASK__0; gsutil -m cp -R gs://hail-wang-",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7016:7655,alive,alive,7655,https://hail.is,https://github.com/hail-is/hail/issues/7016,1,['alive'],['alive']
Availability,"e-packages/hail/backend/spark_backend.py in persist_table(self, t, storage_level); 283 ; 284 def persist_table(self, t, storage_level):; --> 285 return Table._from_java(self._jbackend.pyPersistTable(storage_level, self._to_java_table_ir(t._tir))); 286 ; 287 def unpersist_table(self, t):. /fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py in __call__(self, *args); 1255 answer = self.gateway_client.send_command(command); 1256 return_value = get_return_value(; -> 1257 answer, self.gateway_client, self.target_id, self.name); 1258 ; 1259 for temp_arg in temp_args:. /fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/hail/backend/py4j_backend.py in deco(*args, **kwargs); 14 import pyspark; 15 try:; ---> 16 return f(*args, **kwargs); 17 except py4j.protocol.Py4JJavaError as e:; 18 s = e.java_exception.toString(). /fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/protocol.py in get_return_value(answer, gateway_client, target_id, name); 334 raise Py4JError(; 335 ""An error occurred while calling {0}{1}{2}"".; --> 336 format(target_id, ""."", name)); 337 else:; 338 type = answer[1]. Py4JError: An error occurred while calling o1.pyPersistTable; --------------- end of error -------------------. The above is for running the GWAS tutorial. While running my own GWAS, I have encountered a similar error when running GWAS with the line :. gwas = hl.agg.linreg(hl.float(mt.phenos.height),; [1.0, mt.hapcounts0.x, mt.anc1dos.x, mt.anc2dos.x]). The error message is as follows:. -------------- start of error ------------------. ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:38197); Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 977, in _get_connection; connection = self.deque.pop(); IndexError: pop from an empty deque. During handling of the above exception, another exception occurred:. Traceback (most recent",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/9939:7510,error,error,7510,https://hail.is,https://github.com/hail-is/hail/issues/9939,1,['error'],['error']
Availability,"e. session, packages, modules, classes, functions) and allows tests to be run in those loops when marked accordingly. Pytest-asyncio currently assumes that async fixture scope is correlated with the new event loop scope. This prevents fixtures from being evaluated independently from the event loop scope and breaks some existing test suites (see <a href=""https://redirect.github.com/pytest-dev/pytest-asyncio/issues/706"">#706</a>). For example, a test suite may require all fixtures and tests to run in the same event loop, but have async fixtures that are set up and torn down for each module. If you're affected by this issue, please continue using the v0.21 release, until it is resolved.</p>; <h2>pytest-asyncio 0.23.4</h2>; <h1>0.23.4 (2024-01-28)</h1>; <ul>; <li>pytest-asyncio no longer imports additional, unrelated packages during test collection <a href=""https://redirect.github.com/pytest-dev/pytest-asyncio/issues/729"">#729</a></li>; <li>Addresses further issues that caused an internal pytest error during test collection</li>; <li>Declares incompatibility with pytest 8 <a href=""https://redirect.github.com/pytest-dev/pytest-asyncio/issues/737"">#737</a></li>; </ul>; <h2>pytest-asyncio 0.23.4a2</h2>; <h1>0.23.4 (UNRELEASED)</h1>; <ul>; <li>pytest-asyncio no longer imports additional, unrelated packages during test collection <a href=""https://redirect.github.com/pytest-dev/pytest-asyncio/issues/729"">#729</a></li>; <li>Addresses further issues that caused an internal pytest error during test collection</li>; </ul>; <h2>Known issues</h2>; <p>As of v0.23, pytest-asyncio attaches an asyncio event loop to each item of the test suite (i.e. session, packages, modules, classes, functions) and allows tests to be run in those loops when marked accordingly. Pytest-asyncio currently assumes that async fixture scope is correlated with the new event loop scope. This prevents fixtures from being evaluated independently from the event loop scope and breaks some existing test suites (see ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14507:5515,error,error,5515,https://hail.is,https://github.com/hail-is/hail/pull/14507,1,['error'],['error']
Availability,"e. | version | cold | warm |; | --- | --- | --- |; | this PR | 48 | 39.35 |; | this PR with one monolithic method | 235 | 73 |; | master (5fe6737263b4) | 91s | 83.5 |. I was disappointed with the performance of the monolithic method, so I dug in with `-XX:+PrintCompilation` and found that the JIT was having trouble doing on-stack replacement of the entry parsing loop. There was a cryptic message about the stack not being empty during an OSR compilation. I take this result as evidence that, in the JVM, small, fine-grained methods are critical for reliable performance. The new code, after JIT warming, is reading at 250 MB/s (1GB / 40 seconds) which is a half to a third of the performance of `cat`. It's more than twice as fast as the old code. Aside: using the staged stuff is hard, especially when using multiple methods. A couple thoughts:; - Because SRVB generates a fresh SRVB for arrays and structs, you must thread the srvb through your code gen rather than using a single field, this is annoying and error prone; - `init` is not a first class thing in `FunctionBuilder` and I've arguably made the whole situation more ugly by exposing `addInitInstructions`. Without the ability to place code in the constructor, it is hard to coordinate work between multiple methods.; - When using lots of methods, there's a lot of bookkeeping. I would like a way to define a ""staged class"" that wraps up some of the boilerplate. Not totally clear what I want here, just less boilerplate. Aside2: This is still pretty slow!? Splitting into multiple methods allowed me to interrogate where time was spent. The answer is ""method4"" which is `parseEntries`. This code includes the loop, the srvb state management, the Region manipulation, and checking for the missing value. I'd be surprised its the checking for missing value because I delegate to `String.regionMatches` for the heavy lifting and that does not show up in the profiler. I'm left to conclude that either srvb state management or writing/rea",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6987:2261,error,error,2261,https://hail.is,https://github.com/hail-is/hail/pull/6987,1,['error'],['error']
Availability,e.g. https://ci.hail.is/repository/download/HailSourceCode_HailMainline_BuildDocsSpark220/55915:id/www/index.html,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2878:35,down,download,35,https://hail.is,https://github.com/hail-is/hail/issues/2878,1,['down'],['download']
Availability,e.parseAddInfoField(LoadVCF.scala:1055); 	at is.hail.io.vcf.VCFLine.addInfoField(LoadVCF.scala:1075); 	at is.hail.io.vcf.VCFLine.parseAddInfo(LoadVCF.scala:1112); 	at is.hail.io.vcf.LoadVCF$.parseLineInner(LoadVCF.scala:1541); 	at is.hail.io.vcf.LoadVCF$.parseLine(LoadVCF.scala:1409); 	at is.hail.io.vcf.MatrixVCFReader.$anonfun$executeGeneric$7(LoadVCF.scala:1916); 	at is.hail.io.vcf.MatrixVCFReader.$anonfun$executeGeneric$7$adapted(LoadVCF.scala:1909); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:515); 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460); 	at __C678stream_Let.apply(Emit.scala); 	at is.hail.expr.ir.CompileIterator$$anon$2.step(Compile.scala:302); 	at is.hail.expr.ir.CompileIterator$LongIteratorWrapper.hasNext(Compile.scala:155); 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:490); 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:490); 	at is.hail.rvd.RVD$.$anonfun$getKeyInfo$2(RVD.scala:1030); 	at is.hail.rvd.RVD$.$anonfun$getKeyInfo$2$adapted(RVD.scala:1029); 	at is.hail.sparkextras.ContextRDD.$anonfun$crunJobWithIndex$1(ContextRDD.scala:242); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90); 	at org.apache.spark.scheduler.Task.run(Task.scala:136); 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548); 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551); 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128); 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628); 	at java.base/java.lang.Thread.run(Thread.java:829). Hail version: 0.2.126-ee77707f4fab; Error summary: HailException: cannot set missing field for required type +PFloat64; ```,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14102:20927,Error,Error,20927,https://hail.is,https://github.com/hail-is/hail/issues/14102,1,['Error'],['Error']
Availability,"e2e3d2996 [query-service] switch to services team approved logging; - [ ] (@tpoterba) b18f86e647 [query-service] query workers need a hail context; - [ ] (@daniel-goldstein, @catoverdrive) 6d5d0b68af [query-service] use a UNIX Domain Socket for Py-Scala communication; - [ ] (@daniel-goldstein, @catoverdrive) 0d42df8b08 [query-service] run tests against query service; - [x] (@jigold) f9d361e686 [query-service] aiohttp.ClientSession must be created in async code; - [ ] (@cseed) c35f2e10e3 [query-service][hail][build.yaml] address miscellaneous comments from cotton; - [x] (@daniel-goldstein) 7f1b1363e9 [query-service] use two containers sharing an empty volume; - [x] (@daniel-goldstein) 2a8f23404a [query-service] in the service, log everything to stdout; - [x] (trivial) d8104a1dc4 [query-service] do not catch CancelledError; - [x] (trivial) efcb345185 [query-service] slightly more useful error message when socket dies; - [ ] (@tpoterba) f79c4023cf [shuffler] if we have an ExecuteContext, use it; - [x] (@daniel-goldstein,fyi: @tpoterba) 259f70dd25 [query-service] JSON Logging; - [ ] (@catoverdrive) f5c3ffcbd1 [query-service] pervasively retry all idempotent operations; - [ ] (@tpoterba) 507db4b468 [hail] fix using; - [x] (@jigold) c32a253bb9 [query] when testing, ensure our thread has an event loop; - [ ] (@tpoterba) 110469c2da [query][lir] avoid dumping massive classes onto stderr; - [ ] (@tpoterba) e4aa1c15fe [query] do not print misleading log in RegionPool.finalizer; - [x] (trivial) 33eab9a80e [query-service] better logging information; - [ ] (@catoverdrive) e358e8feeb [query-service] remove race conditions in user management; - [ ] (@tpoterba) b60cb2bae5 [lir] make LIR genName thread-safe; - [ ] (@catoverdrive) 2d82e5faf5 [query-service] send a token for job identifiability; - [x] (@daniel-goldstein) fd78caedcb [query-service] reduce image size by ~2GB; - [ ] (@catoverdrive) 00d1840421 [query-service] retry CLOSE, CLOSED (i.e. connection dropped); - [ ] (@catoverdri",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10100:2324,error,error,2324,https://hail.is,https://github.com/hail-is/hail/pull/10100,1,['error'],['error']
Availability,"e756f08dc78616040ab8fbd7db20903137ccf0c7"">e756f08</a>)</li>; </ul>; <h3>Documentation</h3>; <ul>; <li>fix intersphinx link for 'requests-oauthlib' (<a href=""https://github-redirect.dependabot.com/googleapis/google-auth-library-python/issues/921"">#921</a>) (<a href=""https://github.com/googleapis/google-auth-library-python/commit/967be4f4e2a43ba7e240d7acb01b6b992d40e6ec"">967be4f</a>)</li>; <li>note ValueError in <code>verify_oauth2_token</code> (<a href=""https://github-redirect.dependabot.com/googleapis/google-auth-library-python/issues/928"">#928</a>) (<a href=""https://github.com/googleapis/google-auth-library-python/commit/82bc5f08111de78a2b475b0310d3f35470680dbe"">82bc5f0</a>)</li>; </ul>; <h2>v2.3.3</h2>; <h3>Bug Fixes</h3>; <ul>; <li>add fetch_id_token_credentials (<a href=""https://github-redirect.dependabot.com/googleapis/google-auth-library-python/issues/866"">#866</a>) (<a href=""https://www.github.com/googleapis/google-auth-library-python/commit/8f1e9cfd56dbaae0dff64499e1d0cf55abc5b97e"">8f1e9cf</a>)</li>; <li>fix error in sign_bytes (<a href=""https://github-redirect.dependabot.com/googleapis/google-auth-library-python/issues/905"">#905</a>) (<a href=""https://www.github.com/googleapis/google-auth-library-python/commit/ef3128474431b07d1d519209ea61622bc245ce91"">ef31284</a>)</li>; <li>use 'int.to_bytes' and 'int.from_bytes' for py3 (<a href=""https://github-redirect.dependabot.com/googleapis/google-auth-library-python/issues/904"">#904</a>) (<a href=""https://www.github.com/googleapis/google-auth-library-python/commit/bd0ccc5fe77d55f7a19f5278d6b60587c393ee3c"">bd0ccc5</a>)</li>; </ul>; <h2>v2.3.2</h2>; <h3>Bug Fixes</h3>; <ul>; <li>add clock_skew_in_seconds to verify_token functions (<a href=""https://github-redirect.dependabot.com/googleapis/google-auth-library-python/issues/894"">#894</a>) (<a href=""https://www.github.com/googleapis/google-auth-library-python/commit/8e95c1e458793593972b6b05a355aaeaecd31670"">8e95c1e</a>)</li>; </ul>; <!-- raw HTML omitted -->; </blockquote",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11546:3950,error,error,3950,https://hail.is,https://github.com/hail-is/hail/pull/11546,1,['error'],['error']
Availability,"e: ubuntu; Port: <none>; Host Port: <none>; Command:; /bin/bash; -c; set -e; mkdir -p /io/pipeline/pipeline-cb568b8f204e/__TASK__2750/; /bin/sh -c ""sleep $(( 60 + (RANDOM % 20) ))""; Requests:; cpu: 100m; memory: 500M; Environment:; POD_IP: (v1:status.podIP); POD_NAME: batch-101-job-2751-90f13d (v1:metadata.name); Mounts:; /gsa-key from gsa-key (rw); /var/run/secrets/kubernetes.io/serviceaccount from batch-output-pod-token-8pkmz (ro); cleanup:; Image: gcr.io/hail-vdc/batch:w1eqo739af4d; Port: <none>; Host Port: <none>; Command:; /bin/sh; -c; ; set -ex; python3 -m batch.sidecar; ; Requests:; cpu: 500m; Environment:; INSTANCE_ID: cd50b95a89914efb897965a5e982a29d; BATCH_ID: 101; JOB_ID: 2751; TOKEN: 90f13d; BATCH_BUCKET_NAME: hail-batch-3jmp5; COPY_OUTPUT_CMD: true; HAIL_POD_NAMESPACE: batch-pods; KUBERNETES_TIMEOUT_IN_SECONDS: 5.0; REFRESH_INTERVAL_IN_SECONDS: 300; POD_NAME: batch-101-job-2751-90f13d (v1:metadata.name); Mounts:; /batch-gsa-key from batch-gsa-key (rw); /gsa-key from gsa-key (rw); /var/run/secrets/kubernetes.io/serviceaccount from batch-output-pod-token-8pkmz (ro); Volumes:; gsa-key:; Type: Secret (a volume populated by a Secret); SecretName: dking-gsa-key; Optional: false; batch-gsa-key:; Type: Secret (a volume populated by a Secret); SecretName: batch-gsa-key; Optional: false; batch-output-pod-token-8pkmz:; Type: Secret (a volume populated by a Secret); SecretName: batch-output-pod-token-8pkmz; Optional: false; QoS Class: Burstable; Node-Selectors: <none>; Tolerations: node.kubernetes.io/not-ready:NoExecute for 300s; node.kubernetes.io/unreachable:NoExecute for 300s; preemptible=true; Events:; Type Reason Age From Message; ---- ------ ---- ---- -------; Normal Scheduled 21m default-scheduler Successfully assigned batch-pods/batch-101-job-2751-90f13d to gke-vdc-non-preemptible-pool-0106a51b-5znv; Warning OutOfcpu 21m kubelet, gke-vdc-non-preemptible-pool-0106a51b-5znv Node didn't have enough resource: cpu, requested: 600, used: 7371, capacity: 7910; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6709:2650,Toler,Tolerations,2650,https://hail.is,https://github.com/hail-is/hail/issues/6709,1,['Toler'],['Tolerations']
Availability,"e; -- Build files have been written to: /home/rmk/package_sources/hail/hail/src/main/c/libsimdpp-2.0-rc2; mkdir -p lib/linux-x86-64; g++ -fvisibility=hidden -rdynamic -shared -fPIC -ggdb -O3 -march=native -g -std=c++11 -Ilibsimdpp-2.0-rc2 -Wall -Werror ibs.cpp -o lib/linux-x86-64/libibs.so; In file included from ibs.cpp:1:0:; /usr/lib/gcc/x86_64-linux-gnu/4.9/include/popcntintrin.h: In function uint64_t vector_popcnt(uint64vector):; /usr/lib/gcc/x86_64-linux-gnu/4.9/include/popcntintrin.h:42:1: error: inlining failed in call to always_inline long long int _mm_popcnt_u64(long long unsigned int): target specific option mismatch; _mm_popcnt_u64 (unsigned long long __X); ^; ibs.cpp:14:48: error: called from here; uint64_t count = _mm_popcnt_u64(extract<0>(x));; ^; In file included from ibs.cpp:1:0:; /usr/lib/gcc/x86_64-linux-gnu/4.9/include/popcntintrin.h:42:1: error: inlining failed in call to always_inline long long int _mm_popcnt_u64(long long unsigned int): target specific option mismatch; _mm_popcnt_u64 (unsigned long long __X); ^; ibs.cpp:16:41: error: called from here; count += _mm_popcnt_u64(extract<1>(x));; ^; make: *** [lib/linux-x86-64/libibs.so] Error 1; Makefile:52: recipe for target 'lib/linux-x86-64/libibs.so' failed; :nativeLib FAILED. Tim Poterba suggested defining `CXXFLAGS='-DHAIL_OVERRIDE_ARCH -DSIMDPP_ARCH_X86_SSE2'`, but to no avail. So, he suggested I open this issue. I'm running gcc version 4.9.2. Possibly relevant might be the processor I'm running,; $ lscpu; Architecture: x86_64; CPU op-mode(s): 32-bit, 64-bit; Byte Order: Little Endian; CPU(s): 2; On-line CPU(s) list: 0,1; Thread(s) per core: 1; Core(s) per socket: 2; Socket(s): 1; NUMA node(s): 1; Vendor ID: GenuineIntel; CPU family: 6; Model: 23; Model name: Intel(R) Core(TM)2 CPU P8600 @ 2.40GHz; Stepping: 10; CPU MHz: 800.000; CPU max MHz: 2401.0000; CPU min MHz: 800.0000; BogoMIPS: 4800.16; Virtualization: VT-x; L1d cache: 32K; L1i cache: 32K; L2 cache: 3072K; NUMA node0 CPU(s): 0,1",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1520:1480,error,error,1480,https://hail.is,https://github.com/hail-is/hail/issues/1520,3,"['Error', 'avail', 'error']","['Error', 'avail', 'error']"
Availability,"e>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/PyMySQL/PyMySQL/commit/2cab9ecc641e962565c6254a5091f90c47f59b35""><code>2cab9ec</code></a> v1.1.1</li>; <li><a href=""https://github.com/PyMySQL/PyMySQL/commit/521e40050cb386a499f68f483fefd144c493053c""><code>521e400</code></a> forbid dict parameter</li>; <li><a href=""https://github.com/PyMySQL/PyMySQL/commit/7f032a699d55340f05101deb4d7d4f63db4adc11""><code>7f032a6</code></a> remove coveralls from requirements</li>; <li><a href=""https://github.com/PyMySQL/PyMySQL/commit/69f6c7439bee14784e0ea70ae107af6446cc0c67""><code>69f6c74</code></a> ruff format</li>; <li><a href=""https://github.com/PyMySQL/PyMySQL/commit/b4ed6884a1105df0a27f948f52b3e81d5585634f""><code>b4ed688</code></a> test json - mariadb without JSON type (<a href=""https://redirect.github.com/PyMySQL/PyMySQL/issues/1165"">#1165</a>)</li>; <li><a href=""https://github.com/PyMySQL/PyMySQL/commit/bbd049f40db9c696574ce6f31669880042c56d79""><code>bbd049f</code></a> Support error packet without sqlstate (<a href=""https://redirect.github.com/PyMySQL/PyMySQL/issues/1160"">#1160</a>)</li>; <li><a href=""https://github.com/PyMySQL/PyMySQL/commit/9694747ae619e88b792a8e0b4c08036572452584""><code>9694747</code></a> pyupgrade</li>; <li><a href=""https://github.com/PyMySQL/PyMySQL/commit/1f0b7856de4008e7e4c1e8c1b215d5d4dfaecd1a""><code>1f0b785</code></a> chore(deps): update codecov/codecov-action action to v4 (<a href=""https://redirect.github.com/PyMySQL/PyMySQL/issues/1158"">#1158</a>)</li>; <li><a href=""https://github.com/PyMySQL/PyMySQL/commit/1e28be81c24dde66f8acbf4c5e24f60d6b5e72e7""><code>1e28be8</code></a> chore(deps): update github/codeql-action action to v3 (<a href=""https://redirect.github.com/PyMySQL/PyMySQL/issues/1154"">#1154</a>)</li>; <li><a href=""https://github.com/PyMySQL/PyMySQL/commit/f13f054abcc18b39855a760a84be0a517f0da658""><code>f13f054</code></a> chore(deps): update actions/setup-python action to v5 (<a href=""https://redirect.g",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14556:6230,error,error,6230,https://hail.is,https://github.com/hail-is/hail/pull/14556,1,['error'],['error']
Availability,"eContext.scala:18); at is.hail.backend.spark.SparkBackend.withExecuteContext(SparkBackend.scala:229); at is.hail.backend.spark.SparkBackend.execute(SparkBackend.scala:303); at is.hail.backend.spark.SparkBackend.executeJSON(SparkBackend.scala:323); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); at py4j.Gateway.invoke(Gateway.java:282); at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); at py4j.commands.CallCommand.execute(CallCommand.java:79); at py4j.GatewayConnection.run(GatewayConnection.java:238); at java.lang.Thread.run(Thread.java:745). org.apache.spark.SparkException: Job aborted due to stage failure: Task 9586 in stage 2.0 failed 4 times, most recent failure: Lost task 9586.3 in stage 2.0 (TID 40203, scc-q21.scc.bu.edu, executor 13): java.lang.IllegalArgumentException: Self-suppression not permitted; at java.lang.Throwable.addSuppressed(Throwable.java:1043); at java.io.FilterOutputStream.close(FilterOutputStream.java:159); at is.hail.utils.package$.using(package.scala:603); at is.hail.io.RichContextRDDRegionValue$.writeSplitRegion(RichContextRDDRegionValue.scala:99); at is.hail.rvd.RVD$$anonfun$25.apply(RVD.scala:939); at is.hail.rvd.RVD$$anonfun$25.apply(RVD.scala:937); at is.hail.sparkextras.ContextRDD$$anonfun$cmapPartitionsWithIndex$1$$anonfun$apply$18.apply(ContextRDD.scala:248); at is.hail.sparkextras.ContextRDD$$anonfun$cmapPartitionsWithIndex$1$$anonfun$apply$18.apply(ContextRDD.scala:248); at is.hail.utils.richUtils.RichContextRDD$$anonfun$cleanupRegions$1$$anonfun$1.apply(RichContextRDD.scala:22); at is.hail.utils.richUtils.RichContextRDD$$anonfun$cleanupReg",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/9293:5141,failure,failure,5141,https://hail.is,https://github.com/hail-is/hail/issues/9293,1,['failure'],['failure']
Availability,"e_genome); 255; 256 def remove_liftover(self, name, dest_reference_genome):. /opt/conda/miniconda3/lib/python3.10/site-packages/py4j/java_gateway.py in __call__(self, *args); 1319; 1320 answer = self.gateway_client.send_command(command); -> 1321 return_value = get_return_value(; 1322 answer, self.gateway_client, self.target_id, self.name); 1323. /opt/conda/miniconda3/lib/python3.10/site-packages/hail/backend/py4j_backend.py in deco(*args, **kwargs); 63 tpl = Env.jutils().handleForPython(e.java_exception); 64 deepest, full, error_id = tpl._1(), tpl._2(), tpl._3(); ---> 65 raise fatal_error_from_java_error_triplet(deepest, full, error_id) from None; 66 except pyspark.sql.utils.CapturedException as e:; 67 raise FatalError('%s\n\nJava stack trace:\n%s\n'. FatalError: HailException: Chain file 'grch37_to_grch38.over.chain.gz' does not exist. Java stack trace:; is.hail.utils.HailException: Chain file 'grch37_to_grch38.over.chain.gz' does not exist.; 	at is.hail.utils.ErrorHandling.fatal(ErrorHandling.scala:18); 	at is.hail.utils.ErrorHandling.fatal$(ErrorHandling.scala:18); 	at is.hail.utils.package$.fatal(package.scala:81); 	at is.hail.variant.ReferenceGenome.addLiftover(ReferenceGenome.scala:407); 	at is.hail.backend.spark.SparkBackend.$anonfun$pyAddLiftover$2(SparkBackend.scala:613); 	at is.hail.backend.spark.SparkBackend.$anonfun$pyAddLiftover$2$adapted(SparkBackend.scala:612); 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$3(ExecuteContext.scala:76); 	at is.hail.utils.package$.using(package.scala:657); 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$2(ExecuteContext.scala:76); 	at is.hail.utils.package$.using(package.scala:657); 	at is.hail.annotations.RegionPool$.scoped(RegionPool.scala:17); 	at is.hail.backend.ExecuteContext$.scoped(ExecuteContext.scala:62); 	at is.hail.backend.spark.SparkBackend.$anonfun$withExecuteContext$1(SparkBackend.scala:347); 	at is.hail.backend.spark.SparkBackend.$anonfun$pyAddLiftover$1(SparkBackend.scala:612); 	at is.hail.backen",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13993:3438,Error,ErrorHandling,3438,https://hail.is,https://github.com/hail-is/hail/issues/13993,1,['Error'],['ErrorHandling']
Availability,"e_outer[i].row_field_name),; hl.range(0, hl.len(ht.global_field_name_outer[i].global_field_name)); .map(lambda _: hl.null(ht.row_field_name_outer[i].row_field_name.dtype.element_type)),; ht.row_field_name_outer[i].row_field_name),; hl.range(hl.len(ht.global_field_name_outer)))); ht = ht.transmute_globals(inner_global=hl.flatmap(lambda x: x.global_field_name, ht.global_field_name_outer)); mt = ht._unlocalize_entries('inner_row', 'inner_global', globals_for_col_key); return mt. all_hts = list(map(lambda x: unify_saige_ht_schema(hl.read_table(x)), all_variant_outputs)); mt = join_pheno_hts_to_mt(all_hts, row_keys, col_keys, pheno_dict, f'{temp_bucket}/{pop}/variant',; inner_mode=inner_mode, repartition_final=20000); mt = mt.annotate_cols(saige_heritability=heritability_dict[mt.col_key]); mt = mt.filter_cols(mt.pheno != """").drop('varT', 'varTstar', 'Is.SPA.converge'); mt.key_rows_by('locus', 'alleles').write(get_variant_results_path(pop, 'mt'), overwrite=args.overwrite); ```; I'm getting the following error:; ```; hail.utils.java.FatalError: RuntimeException: found inconsistent agg or scan environments:; left: true, true; right: false, false. Java stack trace:; java.lang.RuntimeException: found inconsistent agg or scan environments:; left: true, true; right: false, false; at is.hail.expr.ir.BindingEnv.merge(Env.scala:68); at is.hail.expr.ir.FreeVariables$$anonfun$is$hail$expr$ir$FreeVariables$$compute$1$2.apply(FreeVariables.scala:38); at is.hail.expr.ir.FreeVariables$$anonfun$is$hail$expr$ir$FreeVariables$$compute$1$2.apply(FreeVariables.scala:38); at scala.collection.TraversableOnce$$anonfun$foldLeft$1.apply(TraversableOnce.scala:157); at scala.collection.TraversableOnce$$anonfun$foldLeft$1.apply(TraversableOnce.scala:157); at scala.collection.Iterator$class.foreach(Iterator.scala:891); at scala.collection.AbstractIterator.foreach(Iterator.scala:1334); at scala.collection.TraversableOnce$class.foldLeft(TraversableOnce.scala:157); at scala.collection.AbstractIterator.fo",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8338:2999,error,error,2999,https://hail.is,https://github.com/hail-is/hail/issues/8338,1,['error'],['error']
Availability,"eac; Mounts:; /batch-gsa-key from batch-gsa-key (rw); /gsa-key from gsa-key (rw); /io from batch-12728-job-287-742170 (rw); /var/run/secrets/kubernetes.io/serviceaccount from batch-output-pod-token-8pkmz (ro); keep-alive:; Container ID: ; Image: gcr.io/hail-vdc/batch:s32fqwbuz8nv; Image ID: ; Port: 5001/TCP; Host Port: 0/TCP; Command:; /bin/sh; -c; ; set -ex; python3 -m batch.keep_alive_sidecar; ; State: Waiting; Reason: PodInitializing; Ready: False; Restart Count: 0; Requests:; cpu: 1m; Environment: <none>; Mounts:; /gsa-key from gsa-key (rw); /io from batch-12728-job-287-742170 (rw); /var/run/secrets/kubernetes.io/serviceaccount from batch-output-pod-token-8pkmz (ro); Conditions:; Type Status; Initialized False ; Ready False ; ContainersReady False ; PodScheduled True ; Volumes:; gsa-key:; Type: Secret (a volume populated by a Secret); SecretName: wang-gsa-key; Optional: false; batch-gsa-key:; Type: Secret (a volume populated by a Secret); SecretName: batch-gsa-key; Optional: false; batch-12728-job-287-742170:; Type: PersistentVolumeClaim (a reference to a PersistentVolumeClaim in the same namespace); ClaimName: batch-12728-job-287-742170; ReadOnly: false; batch-output-pod-token-8pkmz:; Type: Secret (a volume populated by a Secret); SecretName: batch-output-pod-token-8pkmz; Optional: false; QoS Class: Burstable; Node-Selectors: <none>; Tolerations: node.kubernetes.io/not-ready:NoExecute for 300s; node.kubernetes.io/unreachable:NoExecute for 300s; preemptible=true; Events: <none>; ```; ```; # k get pods -n batch-pods batch-12728-job-287-742170 -o yaml; apiVersion: v1; kind: Pod; metadata:; creationTimestamp: 2019-09-05T19:12:22Z; labels:; app: batch-job; batch_id: ""12728""; hail.is/batch-instance: cd50b95a89914efb897965a5e982a29d; job_id: ""287""; user: wang; uuid: ca985fd90f9d46968ab9c480af9c931c; name: batch-12728-job-287-742170; namespace: batch-pods; resourceVersion: ""116541360""; selfLink: /api/v1/namespaces/batch-pods/pods/batch-12728-job-287-742170; uid: 1681dd0",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7016:4743,Toler,Tolerations,4743,https://hail.is,https://github.com/hail-is/hail/issues/7016,1,['Toler'],['Tolerations']
Availability,"ead.py"", line 58, in run; result = self.fn(*self.args, **self.kwargs); File ""/usr/local/lib/python3.9/dist-packages/hailtop/utils/utils.py"", line 163, in <lambda>; thread_pool, lambda: fun(*args, **kwargs)); OSError: [Errno 39] Directory not empty: '/tmp/JnQ2m'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/usr/local/lib/python3.9/dist-packages/hailtop/aiotools/local_fs.py"", line 409, in rmtree; await rm_dir(pool, contents_tasks_by_dir.get(path, []), path); File ""/usr/local/lib/python3.9/dist-packages/hailtop/aiotools/local_fs.py"", line 387, in rm_dir; excs = [exc; File ""/usr/local/lib/python3.9/dist-packages/hailtop/aiotools/local_fs.py"", line 389, in <listcomp>; for exc in [t.exception()]; File ""/usr/lib/python3.9/asyncio/futures.py"", line 214, in exception; raise exc; asyncio.exceptions.CancelledError. [2023-08-02 05:33:14] test/hail/utils/test_hl_hadoop_and_hail_fs.py::test_hadoop_methods_3[local] ERROR; [2023-08-02 05:43:14] test/hail/utils/test_hl_hadoop_and_hail_fs.py::test_read_overwrite[remote] SKIPPED; ```; ```; ==================================== ERRORS ====================================; ______________ ERROR at teardown of test_hadoop_methods_3[local] _______________. pool = <hailtop.utils.utils.OnlineBoundedGather2 object at 0x7f263d7a6fa0>; contents_tasks = [<Task finished name='Task-63869' coro=<OnlineBoundedGather2.call.<locals>.run_and_cleanup() done, defined at /usr/loc...2.call.<locals>.run_and_cleanup() done, defined at /usr/local/lib/python3.9/dist-packages/hailtop/utils/utils.py:398>>]; path = '/tmp/JnQ2m'. async def rm_dir(pool: OnlineBoundedGather2,; contents_tasks: List[asyncio.Task],; path: str):; assert listener is not None; listener(1); if contents_tasks:; await pool.wait(contents_tasks); try:; > await self.rmdir(path). /usr/local/lib/python3.9/dist-packages/hailtop/aiotools/local_fs.py:378: ; _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13361:4550,ERROR,ERROR,4550,https://hail.is,https://github.com/hail-is/hail/issues/13361,1,['ERROR'],['ERROR']
Availability,"eamBufferSpec""}', timed); 177 try:; --> 178 result, timings = self._rpc(ActionTag.EXECUTE, payload); 179 except FatalError as e:; 180 raise e.maybe_user_error(ir) from None. File /opt/conda/lib/python3.10/site-packages/hail/backend/py4j_backend.py:213, in Py4JBackend._rpc(self, action, payload); 211 if resp.status_code >= 400:; 212 error_json = orjson.loads(resp.content); --> 213 raise fatal_error_from_java_error_triplet(error_json['short'], error_json['expanded'], error_json['error_id']); 214 return resp.content, resp.headers.get('X-Hail-Timings', ''). FatalError: HailException: cannot set missing field for required type +PFloat64. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 5 in stage 6.0 failed 4 times, most recent failure: Lost task 5.3 in stage 6.0 (TID 67) (saturn-machinenumber.c.terra-code.internal executor 4): is.hail.utils.HailException: gs://path/to/bucket/chrY.0002.hard_filtered_with_genotypes.vcf.gz:offset 23933331019603: error while parsing line; chrY	113	.	GG	G,*,AG,CG	596	PASS	AC=2,4,6,1;AF=1.23e-03,5.550e-05,4.44e-05,2.00e-04;AN=265;AS_AltDP=10,0,3,10;AS_BaseQRankSum=0.000,.,0.100,0.500;AS_FS=7.777,.,2.144,8.001;AS_MQ=55.75,.,38.98,40.20;AS_MQRankSum=0.200,.,-1.050,-0.500;AS_QD=0.50,0.00,0.25,0.52;AS_ReadPosRankSum=-0.200,.,0.500,-0.220;AS_SOR=2.300,.,1.600,3.000;BaseQRankSum=0.200;DP=600000;ExcessHet=0.0477;FS=0.900;MQ=55.02;MQRankSum=-0.553;QD=1.00;ReadPosRankSum=-0.162;SOR=0.792;VarDP=650	GT:AD:DP:GQ:PGT:PID:PL:PS:SB	0/0:.:21:30	0/0:.:300:20	0/0:.:30:72	0/0:.:31:98	0|1:29,3,0,0,0:33:78:0|1:113_GG_G:78,0,1100,140,1400,1200,172,1600,1200,1000,175,1100,1100,1300,1000:113:19,19,2,1	0/0:.:20:19	0/0:.:19:20	0/0:.:25:50		0|1:90,2,0,0,0:30:40:0|1:113_GG_G:40,0,600,70,650,600,90,640,900,300,60,800,400,900,900:113:2,14,2,0	0/0:.:20:10	0/0:.:9:20	0/0:.:30:40	0/0:.:37:38		0/4:5,0,0,0,1:5:33:.:.:30,40,400,50,220,220,38,270,270,270,0,200,200,200,202:.:5,0,0,1	. 	at is.hail.utils.ErrorHandling.fatal(ErrorHandling.sc",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14102:6295,error,error,6295,https://hail.is,https://github.com/hail-is/hail/issues/14102,1,['error'],['error']
Availability,"ebook-create-services-and-pods; subjects:; - kind: ServiceAccount; name: notebook; namespace: default; roleRef:; kind: Role; name: create-services #this was causing the error, and of course the create-services role is superseded by the the create-services-and-pods role; apiGroup: """"; ---; ```. After:; ```yaml; kind: Role; apiVersion: rbac.authorization.k8s.io/v1; metadata:; namespace: default; name: create-services-and-pods; rules:; - apiGroups: [""""]; resources: [""services""]; verbs: [""*""]; - apiGroups: [""""]; resources: [""pods""]; verbs: [""*""]; ---; kind: RoleBinding; apiVersion: rbac.authorization.k8s.io/v1; metadata:; namespace: default; name: notebook-create-services-and-pods; subjects:; - kind: ServiceAccount; name: notebook; namespace: default; roleRef:; kind: Role; name: create-services-and-pods; apiGroup: """"; ---; ```. ### Results of test runs. Before:. ```sh; kubectl apply -f k8s-config.yaml; ERROR: (gcloud.compute.addresses.describe) Could not fetch resource:; - Required 'compute.addresses.get' permission for 'projects/hail-vdc-staging/regions/us-central1/addresses/site'. namespace/batch-pods unchanged; ...; The RoleBinding ""notebook-create-services-and-pods"" is invalid: roleRef: Invalid value: rbac.RoleRef{APIGroup:""rbac.authorization.k8s.io"", Kind:""Role"", Name:""create-services""}: cannot change roleRef; make: *** [k8s-config] Error 1; ```. After:; ```sh; ERROR: (gcloud.compute.addresses.describe) Could not fetch resource:; - Required 'compute.addresses.get' permission for 'projects/hail-vdc-staging/regions/us-central1/addresses/site'. ...; role.rbac.authorization.k8s.io/create-services-and-pods unchanged; rolebinding.rbac.authorization.k8s.io/notebook-create-services-and-pods configured; role.rbac.authorization.k8s.io/read-get-user-secret unchanged; rolebinding.rbac.authorization.k8s.io/notebook-read-get-users-secret configured; ```. I think the error just reflects my not having hail-vdc-staging permissions, that is unaffected by this PR. cc @cseed, @danking",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5746:2853,Error,Error,2853,https://hail.is,https://github.com/hail-is/hail/pull/5746,3,"['ERROR', 'Error', 'error']","['ERROR', 'Error', 'error']"
Availability,"ebug_string; st = ''.join(traceback.format_stack()); . The most recent error was <class 'hailtop.httpx.ClientResponseError'> 500, message='Internal Server Error', url=URL('http://batch.hail/api/v1alpha/batches/485962/updates/1/jobs/create') body='500 Internal Server Error\n\nServer got itself in trouble'. ; Traceback (most recent call last):; File ""/usr/local/lib/python3.10/site-packages/hailtop/utils/utils.py"", line 809, in retry_transient_errors_with_debug_string; return await f(*args, **kwargs); File ""/usr/local/lib/python3.10/site-packages/hailtop/aiocloud/common/session.py"", line 117, in _request_with_valid_authn; return await self._http_session.request(method, url, **kwargs); File ""/usr/local/lib/python3.10/site-packages/hailtop/httpx.py"", line 148, in request_and_raise_for_status; raise ClientResponseError(; hailtop.httpx.ClientResponseError: 500, message='Internal Server Error', url=URL('http://batch.hail/api/v1alpha/batches/485962/updates/1/jobs/create') body='500 Internal Server Error\n\nServer got itself in trouble'; 2024-09-25 01:54:55,288 - hailtop.utils 835 - WARNING - A transient error occured. We will automatically retry. We have thus far seen 50 transient errors (next delay: 60.0s).; ```. The corresponding server-side error was. ```; pymysql.err.DataError: (1406, \""Data too long for column 'value' at row 106\""); ```. coming from the `INSERT INTO job_attributes ` query in `insert_jobs_into_db()`. We write a list of the samples being processed as a job attribute, and it turned out that for at least some of the jobs of this batch this list had grown to longer than 64K of text. The `job_attributes.value` database field is of type TEXT, which limits each individual attribute to 64KiB bytes. While writing a long list of sample ids as an attribute may or may not be a great idea :smile: it is fair to say that 64K is not a large maximum for user-supplied data here in the 21st century!. It may be worth adding a database migration to change the `job_attribute",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14702:1481,Error,Error,1481,https://hail.is,https://github.com/hail-is/hail/issues/14702,1,['Error'],['Error']
Availability,"ec3cb48,0x00007fbeaec3cb78] = 48; scopes pcs [0x00007fbeaec3cb78,0x00007fbeaec3cbb8] = 64; dependencies [0x00007fbeaec3cbb8,0x00007fbeaec3cbc0] = 8; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; #; FATAL: caught signal 6 SIGABRT; /tmp/libhail7224206977949339430.so(+0x1788c)[0x7fbdea5db88c]; /lib/x86_64-linux-gnu/libc.so.6(+0x33060)[0x7fbec2eae060]; /lib/x86_64-linux-gnu/libc.so.6(gsignal+0xcf)[0x7fbec2eadfff]; /lib/x86_64-linux-gnu/libc.so.6(abort+0x16a)[0x7fbec2eaf42a]; /usr/lib/jvm/java-8-openjdk-amd64/jre/lib/amd64/server/libjvm.so(+0x8c0259)[0x7fbec27f0259]; /usr/lib/jvm/java-8-openjdk-amd64/jre/lib/amd64/server/libjvm.so(+0xa744f8)[0x7fbec29a44f8]; /usr/lib/jvm/java-8-openjdk-amd64/jre/lib/amd64/server/libjvm.so(JVM_handle_linux_signal+0x265)[0x7fbec27f9e45]; /usr/lib/jvm/java-8-openjdk-amd64/jre/lib/amd64/server/libjvm.so(+0x8bd4c8)[0x7fbec27ed4c8]; /lib/x86_64-linux-gnu/libpthread.so.0(+0x110c0)[0x7fbec38580c0]; [0x7fbeaec3ca22]; ERROR: (gcloud.dataproc.jobs.submit.pyspark) Job [828e66d5a71741d7ab2c8d6580997da3] entered state [ERROR] while waiting for [DONE].; Traceback (most recent call last):; File ""pyhail.py"", line 132, in <module>; main(args, pass_through_args); File ""pyhail.py"", line 113, in main; subprocess.check_output(job); File ""/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/subprocess.py"", line 573, in check_output; raise CalledProcessError(retcode, cmd, output=output); subprocess.CalledProcessError: Command '['gcloud', 'dataproc', 'jobs', 'submit', 'pyspark', '/Users/gtiao/gnomad_qc/hail/variant_qc/make_var_annot_hists.py', '--cluster', 'gt3', '--files=gs://hail-common/builds/devel/jars/hail-devel-cadc5eefca6e-Spark-2.2.0.jar', '--py-files=gs://hail-common/builds/devel/python/hail-devel-cadc5eefca6e.zip,/var/folders/rn/t2xcx1ps4h96txll46qkkfsj2q8bnl/T/pyscripts_K7Vs59.zip', '--driver-log-levels', 'root=FATAL,is.hail=INFO', '--properties=spark.executor.extraClas",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4418:3976,ERROR,ERROR,3976,https://hail.is,https://github.com/hail-is/hail/issues/4418,1,['ERROR'],['ERROR']
Availability,"ecrets/kubernetes.io/serviceaccount from default-token-8h99c (ro); Conditions:; Type Status; Initialized True ; Ready False ; ContainersReady False ; PodScheduled True ; Volumes:; test-gsa-key:; Type: Secret (a volume populated by a Secret); SecretName: test-gsa-key; Optional: false; gsa-key:; Type: Secret (a volume populated by a Secret); SecretName: ci-gsa-key; Optional: false; default-token-8h99c:; Type: Secret (a volume populated by a Secret); SecretName: default-token-8h99c; Optional: false; QoS Class: Burstable; Node-Selectors: <none>; Tolerations: node.kubernetes.io/not-ready:NoExecute for 300s; node.kubernetes.io/unreachable:NoExecute for 300s; preemptible=true; Events:; Type Reason Age From Message; ---- ------ ---- ---- -------; Normal Scheduled 13m default-scheduler Successfully assigned batch-pods/batch-3-job-41-39d17b to gke-vdc-preemptible-pool-9c7148b2-1f89; Warning FailedCreatePodSandBox 13m kubelet, gke-vdc-preemptible-pool-9c7148b2-1f89 Failed create pod sandbox: rpc error: code = Unknown desc = failed to set up sandbox container ""99ac9edad98221dbfaf4ab8eb443bc6d3fdc6df84164594469900813652fd913"" network for pod ""batch-3-job-41-39d17b"": NetworkPlugin kubenet failed to set up pod ""batch-3-job-41-39d17b_batch-pods"" network: Error adding container to network: failed to set bridge addr: could not add IP address to ""cbr0"": file exists; ```. ```; $ kubectl -n batch-pods get pods -o yaml batch-3-job-41-39d17b; apiVersion: v1; kind: Pod; metadata:; creationTimestamp: ""2019-07-12T17:17:15Z""; labels:; app: batch-job; batch_id: ""3""; hail.is/batch-instance: cd50b95a89914efb897965a5e982a29d; job_id: ""41""; task: main; user: ci; uuid: f53f127847864f1cbf7d4bdc911a6646; name: batch-3-job-41-39d17b; namespace: batch-pods; resourceVersion: ""87247110""; selfLink: /api/v1/namespaces/batch-pods/pods/batch-3-job-41-39d17b; uid: e4d87ac3-a4c8-11e9-a4bb-42010a8000af; spec:; containers:; - command:; - bash; - -c; - |-; set -e; gcloud -q auth activate-service-account --key-fil",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6625:2296,error,error,2296,https://hail.is,https://github.com/hail-is/hail/issues/6625,2,"['Error', 'error']","['Error', 'error']"
Availability,"ect <br/>[SNYK-PYTHON-NOTEBOOK-1041707](https://snyk.io/vuln/SNYK-PYTHON-NOTEBOOK-1041707) | `notebook:` <br> `5.7.16 -> 6.4.12` <br> | No | No Known Exploit ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | **589/1000** <br/> **Why?** Has a fix available, CVSS 7.5 | Information Exposure <br/>[SNYK-PYTHON-NOTEBOOK-2441824](https://snyk.io/vuln/SNYK-PYTHON-NOTEBOOK-2441824) | `notebook:` <br> `5.7.16 -> 6.4.12` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **449/1000** <br/> **Why?** Has a fix available, CVSS 4.7 | Access Restriction Bypass <br/>[SNYK-PYTHON-NOTEBOOK-2928995](https://snyk.io/vuln/SNYK-PYTHON-NOTEBOOK-2928995) | `notebook:` <br> `5.7.16 -> 6.4.12` <br> | No | No Known Exploit ; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **399/1000** <br/> **Why?** Has a fix available, CVSS 3.7 | Race Condition <br/>[SNYK-PYTHON-PROMPTTOOLKIT-6141120](https://snyk.io/vuln/SNYK-PYTHON-PROMPTTOOLKIT-6141120) | `prompt-toolkit:` <br> `1.0.18 -> 3.0.13` <br> | No | No Known Exploit ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | **696/1000** <br/> **Why?** Proof of Concept exploit, Has a fix available, CVSS 7.5 | Regular Expression Denial of Service (ReDoS) <br/>[SNYK-PYTHON-PYGMENTS-1086606](https://snyk.io/vuln/SNYK-PYTHON-PYGMENTS-1086606) | `pygments:` <br> `2.5.2 -> 2.15.0` <br> | No | Proof of Concept ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | **589/1000** <br/> **Why?** Has a fix available, CVSS 7.5 | Denial of Service (DoS) <br/>[SNYK-PYTHON-PYGMENTS-1088505](https://snyk.io/vuln/SNYK-PYTHON-PYGMENTS-1088505) | `pygments:` <br> `2.5.2 -> 2.15.0` <br> | No | No Known Exploit ; ![medium severity",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14205:5429,avail,available,5429,https://hail.is,https://github.com/hail-is/hail/pull/14205,1,['avail'],['available']
Availability,"ect.dependabot.com/axios/axios/pull/3712"">#3712</a>, <a href=""https://github-redirect.dependabot.com/axios/axios/pull/3717"">#3717</a>)</li>; <li>Updating content-type header for application/json to not contain charset field, according do RFC 8259 (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/2154"">#2154</a>)</li>; <li>Fixing tests by bumping karma-sauce-launcher version (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3813"">#3813</a>)</li>; <li>Changing testing process from Travis CI to GitHub Actions (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3938"">#3938</a>)</li>; </ul>; <p>Documentation:</p>; <ul>; <li>Updating documentation around the use of <code>AUTH_TOKEN</code> with multiple domain endpoints (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3539"">#3539</a>)</li>; <li>Remove duplication of item in changelog (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3523"">#3523</a>)</li>; <li>Fixing gramatical errors (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/2642"">#2642</a>)</li>; <li>Fixing spelling error (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3567"">#3567</a>)</li>; <li>Moving gitpod metion (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/2637"">#2637</a>)</li>; <li>Adding new axios documentation website link (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3681"">#3681</a>, <a href=""https://github-redirect.dependabot.com/axios/axios/pull/3707"">#3707</a>)</li>; <li>Updating documentation around dispatching requests (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3772"">#3772</a>)</li>; <li>Adding documentation for the type guard isAxiosError (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3767"">#3767</a>)</li>; <li>Adding explanation of cancel token (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3803"">#3803</a>)</li>; <li>Updating CI status bad",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11080:3314,error,errors,3314,https://hail.is,https://github.com/hail-is/hail/pull/11080,4,['error'],['errors']
Availability,"ects/hail/hail/python/hail/backend/backend.py:188, in Backend.execute(self, ir, timed); 186 payload = ExecutePayload(self._render_ir(ir), '{""name"":""StreamBufferSpec""}', timed); 187 try:; --> 188 result, timings = self._rpc(ActionTag.EXECUTE, payload); 189 except FatalError as e:; 190 raise e.maybe_user_error(ir) from None. File ~/projects/hail/hail/python/hail/backend/py4j_backend.py:223, in Py4JBackend._rpc(self, action, payload); 221 if resp.status_code >= 400:; 222 error_json = orjson.loads(resp.content); --> 223 raise fatal_error_from_java_error_triplet(; 224 error_json['short'], error_json['expanded'], error_json['error_id']; 225 ); 226 return resp.content, resp.headers.get('X-Hail-Timings', ''). FatalError: NoSuchElementException: Ref with name __iruid_1834 could not be resolved in env BindingEnv((__iruid_1832 -> struct{},__iruid_2157 -> struct{}),None,None,()). Java stack trace:; is.hail.utils.HailException: error after applying LowerToDistributedArray; 	at is.hail.utils.ErrorHandling.fatal(ErrorHandling.scala:23); 	at is.hail.utils.ErrorHandling.fatal$(ErrorHandling.scala:23); 	at is.hail.utils.package$.fatal(package.scala:89); 	at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1(LoweringPipeline.scala:32); 	at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1$adapted(LoweringPipeline.scala:19); 	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62); 	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49); 	at is.hail.expr.ir.lowering.LoweringPipeline.apply(LoweringPipeline.scala:19); 	at is.hail.backend.local.LocalBackend._jvmLowerAndExecute(LocalBackend.scala:205); 	at is.hail.backend.local.LocalBackend._execute(LocalBackend.scala:249); 	at is.hail.backend.local.LocalBackend.$anonfun$execute$2(LocalBackend.scala:314); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:84); 	at is.hail.backend.local.LocalBackend.$ano",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14245:3403,Error,ErrorHandling,3403,https://hail.is,https://github.com/hail-is/hail/issues/14245,1,['Error'],['ErrorHandling']
Availability,"ecutor.Executor$TaskRunner.run(Executor.scala:414) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748). Spark Worker Logs (truncated to crash):. 2020-06-10 10:09:36 INFO ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 16 ms; 2020-06-10 10:09:36 INFO ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 17 ms; 2020-06-10 10:09:36 INFO ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 17 ms; 2020-06-10 10:09:36 INFO ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 17 ms; [thread 46926922934016 also had an error][thread 46922053207808 also had an error][thread 46926901880576 also had an error][thread 46926888195840 also had an error][thread 46926887143168 also had an error][thread 46924854015744 also had an error]; [thread 46924847699712 also had an error]. 	#. 	# A fatal error has been detected by the Java Runtime Environment:. 	[thread 46926905038592 also had an error]#; 	# ; 	[thread 46926895564544 also had an error][thread 46926900827904 also had an error]. 	SIGSEGV (0xb) at pc=0x00002aaab5115c88, pid=34051, tid=0x00002aae05d1a700; 	#; 	# JRE version: OpenJDK Runtime Environment (8.0_242-b08) (build 1.8.0_242-b08); 	# Java VM: OpenJDK 64-Bit Server VM (25.242-b08 mixed mode linux-amd64 compressed oops); 	# Problematic frame:; 	[thread 46926929250048 also had an error]# ; 	[thread 46926881888000 also had an error]; 	J 5583 C2 __C111CompiledWithAggs.__m131wrapped(Lis/hail/annotations/Region;J)V (280 bytes) @ 0x00002aaab5115c88 [0x00002aaab5115ae0+0x1a8]; 	#; 	# Failed to write core dump. Core dumps have been disabled. To enable core dumping, try ""ulimit -c unlimited"" before starting Java again; 	#; 	[thread 46924863489792 also had an error]; 	[thread 46924861384448 also had an error]; 	# An error report file with more information is saved as:; 	# /local/scratch/app-20200610",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8944:18769,error,error,18769,https://hail.is,https://github.com/hail-is/hail/issues/8944,1,['error'],['error']
Availability,"ed URLs which don't have an explicit scheme <a href=""https://redirect.github.com/urllib3/urllib3/pull/2950"">#2950</a></li>; <li>Fixed response decoding with Zstandard when compressed data is made of several frames. <a href=""https://redirect.github.com/urllib3/urllib3/issues/3008"">#3008</a></li>; <li>Fixed <code>assert_hostname=False</code> to correctly skip hostname check. <a href=""https://redirect.github.com/urllib3/urllib3/issues/3051"">#3051</a></li>; </ul>; <h2>2.0.2</h2>; <ul>; <li>Fixed <code>HTTPResponse.stream()</code> to continue yielding bytes if buffered decompressed data was still available to be read even if the underlying socket is closed. This prevents a compressed response from being truncated. (<a href=""https://redirect.github.com/urllib3/urllib3/issues/3009"">urllib3/urllib3#3009</a>)</li>; </ul>; <h2>2.0.1</h2>; <ul>; <li>Fixed a socket leak when fingerprint or hostname verifications fail. (<a href=""https://redirect.github.com/urllib3/urllib3/issues/2991"">#2991</a>)</li>; <li>Fixed an error when <code>HTTPResponse.read(0)</code> was the first <code>read</code> call or when the internal response body buffer was otherwise empty. (<a href=""https://redirect.github.com/urllib3/urllib3/issues/2998"">#2998</a>)</li>; </ul>; <h2>2.0.0</h2>; <p>Read the <a href=""https://urllib3.readthedocs.io/en/latest/v2-migration-guide.html"">v2.0 migration guide</a> for help upgrading to the latest version of urllib3.</p>; <h1>Removed</h1>; <ul>; <li>Removed support for Python 2.7, 3.5, and 3.6 (<a href=""https://redirect.github.com/urllib3/urllib3/issues/883"">#883</a>, <a href=""https://redirect.github.com/urllib3/urllib3/issues/2336"">#2336</a>).</li>; <li>Removed fallback on certificate <code>commonName</code> in <code>match_hostname()</code> function. This behavior was deprecated in May 2000 in RFC 2818. Instead only <code>subjectAltName</code> is used to verify the hostname by default. To enable verifying the hostname against <code>commonName</code> use <code>SSLContext.ho",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13768:2993,error,error,2993,https://hail.is,https://github.com/hail-is/hail/pull/13768,3,['error'],['error']
Availability,"ed dataset; Traceback (most recent call last):; File ""/restricted/projectnb/genpro/github/hail/test.py"", line 3, in <module>; hl.import_vcf('/project/casa/vcf.5k/gatk.hc/adsp-5k.hg38.tileDB.recalibrate_SNP.chr22.biallelic.4795samples.g.vcf.bgz').write('/project/casa/vdf.5k/test. vdf'); File ""<decorator-gen-546>"", line 2, in write; File ""/restricted/projectnb/genpro/github/hail/build/distributions/hail-python.zip/hail/typecheck/check.py"", line 481, in _typecheck; File ""/restricted/projectnb/genpro/github/hail/build/distributions/hail-python.zip/hail/matrixtable.py"", line 1956, in write; File ""/share/pkg/spark/2.2.0/install/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py"", line 1133, in __call__; File ""/restricted/projectnb/genpro/github/hail/build/distributions/hail-python.zip/hail/utils/java.py"", line 196, in deco; hail.utils.java.FatalError: ClassNotFoundException: is.hail.utils.SerializableHadoopConfiguration. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 6 in stage 2.0 failed 4 times, most recent failure: Lost task 6.3 in stage 2.0 (TID 2 53, scc-q15.scc.bu.edu, executor 1): java.io.IOException: com.esotericsoftware.kryo.KryoException: Error during Java deserialization.; at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1310); at org.apache.spark.broadcast.TorrentBroadcast.readBroadcastBlock(TorrentBroadcast.scala:206); at org.apache.spark.broadcast.TorrentBroadcast._value$lzycompute(TorrentBroadcast.scala:66); at org.apache.spark.broadcast.TorrentBroadcast._value(TorrentBroadcast.scala:66); at org.apache.spark.broadcast.TorrentBroadcast.getValue(TorrentBroadcast.scala:96); at org.apache.spark.broadcast.Broadcast.value(Broadcast.scala:70); at is.hail.io.RichRDDRegionValue$$anonfun$5.apply(RowStore.scala:757); at is.hail.io.RichRDDRegionValue$$anonfun$5.apply(RowStore.scala:756); at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$26.apply(RDD.scala:844); at org.apache.spark.rdd.R",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3342:2338,failure,failure,2338,https://hail.is,https://github.com/hail-is/hail/issues/3342,1,['failure'],['failure']
Availability,"ed due to stage failure: Task 0 in stage 24.0 failed 20 times, most recent failure: Lost task 0.19 in stage 24.0 (TID 1813, lfrani-sw-hqb8.c.broad-mpg-gnomad.internal, executor 159): is.hail.utils.HailException: found out of bounds index -1; Resulted from trying to merge -0.0; Indices are [0.0, 2.0, 4.0, 6.0, 8.0, 10.0, 12.0, 14.0, 16.0, 18.0, 20.0, 22.0, 24.0, 26.0, 28.0, 30.0, 32.0, 34.0, 36.0, 38.0, 40.0, 42.0, 44.0, 46.0, 48.0, 50.0, 52.0, 54.0, 56.0, 58.0, 60.0, 62.0, 64.0, 66.0, 68.0, 70.0, 72.0, 74.0, 76.0, 78.0, 80.0, 82.0, 84.0, 86.0, 88.0, 90.0, 92.0, 94.0, 96.0, 98.0, 100.0, 102.0, 104.0, 106.0, 108.0, 110.0, 112.0, 114.0, 116.0, 118.0, 120.0, 122.0, 124.0, 126.0, 128.0, 130.0, 132.0, 134.0, 136.0, 138.0, 140.0, 142.0, 144.0, 146.0, 148.0, 150.0, 152.0, 154.0, 156.0, 158.0, 160.0, 162.0, 164.0, 166.0, 168.0, 170.0, 172.0, 174.0, 176.0, 178.0, 180.0, 182.0, 184.0, 186.0, 188.0, 190.0, 192.0, 194.0, 196.0, 198.0, 200.0]; Binary search index was -1; 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:9); 	at is.hail.utils.package$.fatal(package.scala:28); 	at is.hail.stats.HistogramCombiner.merge(HistogramCombiner.scala:42); 	at is.hail.annotations.aggregators.RegionValueHistogramAggregator.seqOp(RegionValueHistogramAggregator.scala:31); 	at is.hail.codegen.generated.C95.apply(Unknown Source); 	at is.hail.codegen.generated.C95.apply(Unknown Source); 	at is.hail.expr.ir.Interpret$$anonfun$27.apply(Interpret.scala:809); 	at is.hail.expr.ir.Interpret$$anonfun$27.apply(Interpret.scala:808); 	at is.hail.rvd.RVD$$anonfun$20$$anonfun$apply$11.apply(RVD.scala:551); 	at is.hail.rvd.RVD$$anonfun$20$$anonfun$apply$11.apply(RVD.scala:550); 	at scala.collection.Iterator$class.foreach(Iterator.scala:893); 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); 	at is.hail.rvd.RVD$$anonfun$20.apply(RVD.scala:550); 	at is.hail.rvd.RVD$$anonfun$20.apply(RVD.scala:547); 	at is.hail.sparkextras.ContextRDD$$anonfun$cmapPartitionsWithIndex$1$$anonfun$appl",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5846:3777,Error,ErrorHandling,3777,https://hail.is,https://github.com/hail-is/hail/issues/5846,1,['Error'],['ErrorHandling']
Availability,"ed in two places: Binds.scala, and the parser. We need the binding structure in the parser to propagate the environment, so we can annotate `Ref` nodes (and a few other things) with their types. But we can't use Binds.scala because we don't yet have an IR. This PR removes environment maintenance from the parser by deferring type annotation to a separate pass (which is simple, because it can use the Binds.scala infrastructure). One consequence is that we can't assign types to nodes like `Ref` during parsing, which means we can't ask for the type of any node during parsing, and by extension we can't ask for types of children in IR node constructors. Instead, all typechecking logic is moved to the `TypeCheck` pass. Some benefits of this change:; * The parser is simpler, as it doesn't have to maintain a typing environment.; * Binds.scala is now the single source of truth on the binding structure of the IR.; * Instead of typechecking being split in an ad-hoc way between IR constructors and the `TypeCheck` pass, all typechecking and type error reporting logic is in one place.; * The parser parses a context-free grammar, no more and no less. If the input is gramatically correct, the parser succeeds.; * We can round trip IR with type errors through the text representation. For instance, if we log an IR that fails TypeCheck, we can copy the IR from the log, parse it, then debug. This change was motivated by my work in progress to convert the parser to use the SSA grammar, which this should greatly simplify. I chose to make the type annotation pass after parsing mutate the IR in place (with the unfortunate exception of `Apply`, which can change into an `ApplyIR` or `ApplySpecial`. Do these really need to be separate nodes?). The type of a `Ref` node was already mutable to allow this sort of deferred annotation, and I've had to make a few other things mutable as well. Alternatively we could rebuild the entire IR to include type annotations, but I think the mutation is sufficien",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13990:1102,error,error,1102,https://hail.is,https://github.com/hail-is/hail/pull/13990,1,['error'],['error']
Availability,"ed int MaskCastOverride = 0]; libsimdpp-2.0-rc2/simdpp/core/cast.h:63:89: required from R simdpp::arch_avx2::bit_cast(const T&) [with R = simdpp::arch_avx2::uint8<32>; T = simdpp::arch_avx2::int32<8>]; libsimdpp-2.0-rc2/simdpp/types/int8x32.h:110:36: required from simdpp::arch_avx2::uint8<32>::uint8(const simdpp::arch_avx2::any_vec<32, V>&) [with V = simdpp::arch_avx2::int32<8>]; libsimdpp-2.0-rc2/simdpp/detail/extract128.h:40:82: required from simdpp::arch_avx2::int32x4 simdpp::arch_avx2::detail::extract128(const int32x8&) [with unsigned int s = 0; simdpp::arch_avx2::int32x4 = simdpp::arch_avx2::int32<4>; simdpp::arch_avx2::int32x8 = simdpp::arch_avx2::int32<8>]; libsimdpp-2.0-rc2/simdpp/detail/insn/i_reduce_add.h:356:49: required from here; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:40:13: error: void* memcpy(void*, const void*, size_t) copying an object of type class simdpp::arch_avx2::uint8<32> with private member simdpp::arch_avx2::uint8<32>::d_ from an array of const class simdpp::arch_avx2::int32<8>; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/types.h:20,; from libsimdpp-2.0-rc2/simdpp/core/align.h:15,; from libsimdpp-2.0-rc2/simdpp/simd.h:22,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/types/int8x32.h:91:7: note: class simdpp::arch_avx2::uint8<32> declared here; class uint8<32, void> : public any_int8<32, uint8<32,void>> {; ^~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/simd.h:132,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl: In instantiation of R simdpp::arch_avx2::detail::cast_memcpy(const T&) [with R = simdpp::arch_avx2::int32<4>; T = simdpp::arch_avx2::uint8<16>]:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::ar",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3955:121179,error,error,121179,https://hail.is,https://github.com/hail-is/hail/issues/3955,1,['error'],['error']
Availability,"ed int MaskCastOverride = 0]; libsimdpp-2.0-rc2/simdpp/core/cast.h:63:89: required from R simdpp::arch_avx2::bit_cast(const T&) [with R = simdpp::arch_avx2::uint8<32>; T = simdpp::arch_avx2::int64<4>]; libsimdpp-2.0-rc2/simdpp/types/int8x32.h:110:36: required from simdpp::arch_avx2::uint8<32>::uint8(const simdpp::arch_avx2::any_vec<32, V>&) [with V = simdpp::arch_avx2::int64<4>]; libsimdpp-2.0-rc2/simdpp/detail/extract128.h:42:82: required from simdpp::arch_avx2::int64x2 simdpp::arch_avx2::detail::extract128(const int64x4&) [with unsigned int s = 0; simdpp::arch_avx2::int64x2 = simdpp::arch_avx2::int64<2>; simdpp::arch_avx2::int64x4 = simdpp::arch_avx2::int64<4>]; libsimdpp-2.0-rc2/simdpp/detail/insn/i_reduce_max.h:478:40: required from here; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:40:13: error: void* memcpy(void*, const void*, size_t) copying an object of type class simdpp::arch_avx2::uint8<32> with private member simdpp::arch_avx2::uint8<32>::d_ from an array of const class simdpp::arch_avx2::int64<4>; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/types.h:20,; from libsimdpp-2.0-rc2/simdpp/core/align.h:15,; from libsimdpp-2.0-rc2/simdpp/simd.h:22,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/types/int8x32.h:91:7: note: class simdpp::arch_avx2::uint8<32> declared here; class uint8<32, void> : public any_int8<32, uint8<32,void>> {; ^~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/simd.h:132,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl: In instantiation of R simdpp::arch_avx2::detail::cast_memcpy(const T&) [with R = simdpp::arch_avx2::int64<2>; T = simdpp::arch_avx2::uint8<16>]:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::ar",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3955:125293,error,error,125293,https://hail.is,https://github.com/hail-is/hail/issues/3955,1,['error'],['error']
Availability,"ed?. Note: this is an Azure-specific issue. When submitting a batch/job that requests more storage than is available on the temp disk of any standing worker, but doesn't request a specific number of cores or amount of memory, a NotImplementedError is raised in `batch/cloud/azure/worker/disk.py`. See this Batch record for an example of the issue in action: https://batch.azure.hail.is/batches/4563654/jobs/1. The corresponding base case to reproduce this is:. ```python; import hailtop.batch as hb; backend = hb.ServiceBackend(billing_project=""<YOUR BILLING PROJECT>""); b = hb.Batch(backend=backend, name=""storage_test""); j = b.new_job(); j.image(""ubuntu:20.04""); j.storage(""700GiB""); j.command(""df -h""); b.run(wait=False); ```. On the cluster azure.hail.is this job gets scheduled on a `Standard_D16ds_v4` instance which has a 600 GiB temp disk. On GCP, when requests exceed this amount a data disk is provisioned to service the request. While this is feasible on Azure and could be implemented, it may not be the recommended solution as temp disks are much better suited to ephemeral workloads than data disks. On clusters with a smaller standing worker (i.e. fewer cores) there is a workaround, which also possibly suggests a reasonable partial solution. This workaround is to specify a required number of cores that forces a larger VM of the same family to be provisioned. This makes a larger temp disk available for the job to leverage. The corresponding partial solution would be to take knowledge of the temp disk size for any VM into account when scheduling jobs and provision larger VMs when warranted by the storage requirement of a job. . Based on current limitations for VM core count (16) this suggests a ceiling on storage that can be allocated to any job in Azure of 600 GiB. At that point it would be necessary to allocate a data disk. This issue reproduces on both azure.hail.is and our own Azure cluster.; . ### Version. 0.2.126-cdd2c132bfa2. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14522:1423,avail,available,1423,https://hail.is,https://github.com/hail-is/hail/issues/14522,1,['avail'],['available']
Availability,"edRVD.scala:649); 	at is.hail.methods.SplitMulti$.unionMovedVariants(SplitMulti.scala:237); 	at is.hail.methods.SplitMulti.split(SplitMulti.scala:332); 	at is.hail.methods.SplitMulti$.apply(SplitMulti.scala:232); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:280); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:214); 	at java.lang.Thread.run(Thread.java:748)is.hail.utils.HailException: invalid allele ""GN""; 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:6); 	at is.hail.utils.package$.fatal(package.scala:26); 	at is.hail.variant.AltAlleleMethods$.validate(AltAlleleMethods.scala:24); 	at is.hail.variant.AltAlleleMethods$.altAlleleType(AltAlleleMethods.scala:28); 	at is.hail.variant.AltAlleleMethods$.isStar(AltAlleleMethods.scala:73); 	at is.hail.variant.VariantMethods$$anonfun$minRep$1.apply(VariantMethods.scala:43); 	at is.hail.variant.VariantMethods$$anonfun$minRep$1.apply(VariantMethods.scala:43); 	at scala.collection.IndexedSeqOptimized$class.prefixLengthImpl(IndexedSeqOptimized.scala:38); 	at scala.collection.IndexedSeqOptimized$class.forall(IndexedSeqOptimized.scala:43); 	at scala.collection.mutable.WrappedArray.forall(WrappedArray.scala:35); 	at is.hail.variant.VariantMethods$.minRep(VariantMethods.scala:43); 	at is.hail.methods.SplitMultiPartitionContext$$anonfun$2.apply(SplitMulti.scala:196); 	at is.hail.methods.SplitMultiPartitionContext$$anonfun$2.apply(SplitMulti.scala:192); 	at scala.coll",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3480:8746,Error,ErrorHandling,8746,https://hail.is,https://github.com/hail-is/hail/issues/3480,1,['Error'],['ErrorHandling']
Availability,edited line in Docs formatting error in multi-way-zip-join #7945,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7985:31,error,error,31,https://hail.is,https://github.com/hail-is/hail/pull/7985,1,['error'],['error']
Availability,"ef=""https://github-redirect.dependabot.com/prometheus/client_python/issues/726"">#726</a></p>; <h2>0.12.0 / 2021-10-29</h2>; <p>[FEATURE] Exemplar support (excludes multiprocess) <a href=""https://github-redirect.dependabot.com/prometheus/client_python/issues/669"">#669</a>; [ENHANCEMENT] Add support for Python 3.10 <a href=""https://github-redirect.dependabot.com/prometheus/client_python/issues/706"">#706</a>; [ENHANCEMENT] Restricted Registry will handle metrics added after restricting <a href=""https://github-redirect.dependabot.com/prometheus/client_python/issues/675"">#675</a>, <a href=""https://github-redirect.dependabot.com/prometheus/client_python/issues/680"">#680</a><br />; [ENHANCEMENT] Raise a more helpful error if a metric is not observable <a href=""https://github-redirect.dependabot.com/prometheus/client_python/issues/666"">#666</a>; [BUGFIX] Fix instance_ip_grouping_key not working on MacOS <a href=""https://github-redirect.dependabot.com/prometheus/client_python/issues/687"">#687</a>; [BUGFIX] Fix assertion error from favicion.ico with Python 2.7 <a href=""https://github-redirect.dependabot.com/prometheus/client_python/issues/715"">#715</a></p>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/prometheus/client_python/commit/a234283a853238dc73fa22651532590330fd72a1""><code>a234283</code></a> Release 0.13.1</li>; <li><a href=""https://github.com/prometheus/client_python/commit/557d123b349f3881cd6475a29ff4c79088a85a26""><code>557d123</code></a> Relax type constraints Timestamp</li>; <li><a href=""https://github.com/prometheus/client_python/commit/b44b63e59b168c6a8498ca31ddcce3ea5e46dcdc""><code>b44b63e</code></a> Declare <code>registry</code> on <code>MetricWrapperBase</code> as <code>Optional</code> (<a href=""https://github-redirect.dependabot.com/prometheus/client_python/issues/754"">#754</a>)</li>; <li><a href=""https://github.com/prometheus/client_python/commit/b3271a3f1842dbbddeab822063a3f08911f3c190""><code>b3271a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11515:2800,error,error,2800,https://hail.is,https://github.com/hail-is/hail/pull/11515,1,['error'],['error']
Availability,"eh / jinja2 folks but thought I'd let you know in case you hit this issue. ```; ../conda/envs/glow/lib/python3.7/site-packages/bokeh/core/templates.py:43: in <module>; from jinja2 import Environment, Markup, FileSystemLoader; E ImportError: cannot import name 'Markup' from 'jinja2' (/home/circleci/conda/envs/lib/python3.7/site-packages/jinja2/__init__.py); [error] java.lang.IllegalArgumentException: requirement failed: Python tests in Hail environment failed; [error] 	at scala.Predef$.require(Predef.scala:281); [error] 	at $1fb87e3247134917ca70$.$anonfun$pythonSettings$14(build.sbt:288); [error] 	at $1fb87e3247134917ca70$.$anonfun$pythonSettings$14$adapted(build.sbt:278); [error] 	at scala.Function1.$anonfun$compose$1(Function1.scala:49); [error] 	at sbt.internal.util.$tilde$greater.$anonfun$$u2219$1(TypeFunctions.scala:62); [error] 	at sbt.std.Transform$$anon$4.work(Transform.scala:67); [error] 	at sbt.Execute.$anonfun$submit$2(Execute.scala:280); [error] 	at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:19); [error] 	at sbt.Execute.work(Execute.scala:289); [error] 	at sbt.Execute.$anonfun$submit$1(Execute.scala:280); [error] 	at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178); [error] 	at sbt.CompletionService$$anon$2.call(CompletionService.scala:37); [error] 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); [error] 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); [error] 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); [error] 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); [error] 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); [error] 	at java.lang.Thread.run(Thread.java:748); [error] (hail / hailtest) java.lang.IllegalArgumentException: requirement failed: Python tests in Hail environment failed; ```. To report a bug, fill in the information below. ; For support and feature ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/11705:1441,Error,ErrorHandling,1441,https://hail.is,https://github.com/hail-is/hail/issues/11705,1,['Error'],['ErrorHandling']
Availability,"el.AbstractChannelHandlerContext$AbstractWriteTask.write(AbstractChannelHandlerContext.java:1081); at io.netty.channel.AbstractChannelHandlerContext$WriteAndFlushTask.write(AbstractChannelHandlerContext.java:1128); at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.run(AbstractChannelHandlerContext.java:1070); at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:163); at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:403); at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:463); at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858); at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138); at java.lang.Thread.run(Thread.java:748); Caused by: java.nio.channels.ClosedChannelException; at io.netty.channel.AbstractChannel$AbstractUnsafe.write(...)(Unknown Source); 2019-07-14 20:55:04 YarnScheduler: ERROR: Lost executor 1 on bw2-sw-dp3j.c.seqr-project.internal: Slave lost; 2019-07-14 20:55:04 TaskSetManager: WARN: Lost task 1574.1 in stage 8.0 (TID 21699, bw2-sw-dp3j.c.seqr-project.internal, executor 1): ExecutorLostFailure (executor 1 exited caused by one of the running tasks) Reason: Slave lost; 2019-07-14 20:55:04 TaskSetManager: WARN: Lost task 1559.1 in stage 8.0 (TID 21702, bw2-sw-dp3j.c.seqr-project.internal, executor 1): ExecutorLostFailure (executor 1 exited caused by one of the running tasks) Reason: Slave lost; 2019-07-14 20:55:04 TaskSetManager: WARN: Lost task 1561.1 in stage 8.0 (TID 21701, bw2-sw-dp3j.c.seqr-project.internal, executor 1): ExecutorLostFailure (executor 1 exited caused by one of the running tasks) Reason: Slave lost; 2019-07-14 20:55:04 TaskSetManager: WARN: Lost task 1541.2 in stage 8.0 (TID 21700, bw2-sw-dp3j.c.seqr-project.internal, executor 1): ExecutorLostFailure (executor 1 exited caused by one of the running tasks) Reason: Slave lost; 2",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6635:3972,ERROR,ERROR,3972,https://hail.is,https://github.com/hail-is/hail/issues/6635,1,['ERROR'],['ERROR']
Availability,"elasticsearch.hadoop.rest.RestRepository.writeToIndex(RestRepository.java:168); 	at org.elasticsearch.spark.rdd.EsRDDWriter.write(EsRDDWriter.scala:67); 	at org.elasticsearch.spark.rdd.EsSpark$$anonfun$doSaveToEs$1.apply(EsSpark.scala:107); 	at org.elasticsearch.spark.rdd.EsSpark$$anonfun$doSaveToEs$1.apply(EsSpark.scala:107); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); 	at org.apache.spark.scheduler.Task.run(Task.scala:86); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Hail version: 0.1-408f188; Error summary: EsHadoopIllegalArgumentException: Spark SQL types are not handled through basic RDD saveToEs() calls; typically this is a mistake(as the SQL schema will be ignored). Use 'org.elasticsearch.spark.sql' package instead; ERROR: (gcloud.dataproc.jobs.submit.pyspark) Job [ffc9fb0b99f64080b674ab7a07962df9] entered state [ERROR] while waiting for [DONE].; ```. Ideally it would get exported as nested objects: https://www.elastic.co/guide/en/elasticsearch/reference/current/nested.html#_using_literal_nested_literal_fields_for_arrays_of_objects. with elasticsearch mapping:; ```; u'vep': {'type': 'nested', 'properties': {u'category': {'type': 'keyword'}, u'major_consequence': {'type': 'keyword'}, u'gene_id': {'type': 'keyword'}, u'major_consequence_rank': {'type': 'integer'}, u'gene_symbol': {'type': 'keyword'}, u'transcript_id': {'type': 'keyword'}, u'hgvs': {'type': 'keyword'}, u'protein_id': {'type': 'keyword'}}}, ; ```. I thought about switching to saveJsonToEs here: ; https://github.com/hail-is/hail/blob/0.1/src/main/scala/is/hail/io/ElasticsearchConnector.scala#L33; but not sure how to auto-convert to json before exporting; https://www.elastic.co/guide/en/elasticsearch/hadoop/6.x/spark.html#spark-strea",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4250:11341,ERROR,ERROR,11341,https://hail.is,https://github.com/hail-is/hail/issues/4250,1,['ERROR'],['ERROR']
Availability,"elasticsearch; disable_index_for_fields=(""sortedTranscriptConsequences"", ),; File ""/tmp/ffc9fb0b99f64080b674ab7a07962df9/load_dataset_to_es.py"", line 358, in export_to_elasticsearch; verbose=True,; File ""/tmp/ffc9fb0b99f64080b674ab7a07962df9/hail_scripts.zip/hail_scripts/v01/utils/elasticsearch_client.py"", line 140, in export_vds_to_elasticsearch; File ""/tmp/ffc9fb0b99f64080b674ab7a07962df9/hail_scripts.zip/hail_scripts/v01/utils/elasticsearch_client.py"", line 287, in export_kt_to_elasticsearch; File ""<decorator-gen-143>"", line 2, in export_elasticsearch; File ""/tmp/ffc9fb0b99f64080b674ab7a07962df9/hail-0.1-es-6.2.4-with-strip-chr-prefix.zip/hail/java.py"", line 121, in handle_py4j; hail.java.FatalError: EsHadoopIllegalArgumentException: Spark SQL types are not handled through basic RDD saveToEs() calls; typically this is a mistake(as the SQL schema will be ignored). Use 'org.elasticsearch.spark.sql' package instead. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 68 in stage 3.0 failed 20 times, most recent failure: Lost task 68.19 in stage 3.0 (TID 3771, vep-grch37-sw-9767.c.seqr-project.internal): org.elasticsearch.hadoop.EsHadoopIllegalArgumentException: Spark SQL types are not handled through basic RDD saveToEs() calls; typically this is a mistake(as the SQL schema will be ignored). Use 'org.elasticsearch.spark.sql' package instead; 	at org.elasticsearch.spark.serialization.ScalaValueWriter.doWriteScala(ScalaValueWriter.scala:124); 	at org.elasticsearch.spark.serialization.ScalaValueWriter.doWrite(ScalaValueWriter.scala:50); 	at org.elasticsearch.spark.serialization.ScalaValueWriter$$anonfun$doWriteScala$3.apply(ScalaValueWriter.scala:78); 	at org.elasticsearch.spark.serialization.ScalaValueWriter$$anonfun$doWriteScala$3.apply(ScalaValueWriter.scala:77); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.elast",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4250:2464,failure,failure,2464,https://hail.is,https://github.com/hail-is/hail/issues/4250,1,['failure'],['failure']
Availability,"elease notes</summary>; <p><em>Sourced from <a href=""https://github.com/michel-kraemer/gradle-download-task/releases"">de.undercouch.download's releases</a>.</em></p>; <blockquote>; <h2>5.2.1</h2>; <p>Bug fixes:</p>; <ul>; <li>Use pooling connection manager of Apache HttpClient instead of basic one. The basic one is not meant to be used by multiple threads. This fixes an issue that could cause an <code>IllegalStateException</code> with the message <code>Connection is still allocated</code>. Thanks to <a href=""https://github.com/dmarks2""><code>@dmarks2</code></a> for spotting this.</li>; </ul>; <p>Maintenance:</p>; <ul>; <li>Update dependencies</li>; </ul>; <h2>5.2.0</h2>; <p>New features:</p>; <ul>; <li>Add <code>eachFile</code> method that adds an action to be applied to each source URL before it is downloaded. The action can be used to modify the filename of the target file.</li>; <li>Add <code>runAsync</code> method to download extension. This allows multiple files to be downloaded in parallel if the download extension is used. For normal download tasks, multiple files were downloaded in parallel already.</li>; </ul>; <h2>5.1.3</h2>; <p>Bug fixes:</p>; <ul>; <li>Initialize progress logger just before the download starts (see <a href=""https://github-redirect.dependabot.com/michel-kraemer/gradle-download-task/issues/243"">#243</a>)</li>; </ul>; <h2>5.1.2</h2>; <p>Bug fixes:</p>; <ul>; <li>Do not include default HTTP and HTTPS ports in <code>Host</code> header unless explicitly specified by the user</li>; </ul>; <h2>5.1.1</h2>; <p>Bug fixes:</p>; <ul>; <li>Correctly update cached sources</li>; </ul>; <p>Maintenance:</p>; <ul>; <li>Add integration tests for Gradle 7.5 and 7.5.1</li>; <li>Update dependencies</li>; </ul>; <h2>5.1.0</h2>; <p>New features:</p>; <ul>; <li>Add possibility to enable preemptive Basic authentication (through the new <code>preemptiveAuth</code> flag)</li>; <li>Warn if server does not send <code>WWW-Authenticate</code> header in 401 response</li>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12332:1119,down,downloaded,1119,https://hail.is,https://github.com/hail-is/hail/pull/12332,2,['down'],"['download', 'downloaded']"
Availability,"elect_rows(self, caller, key_struct, value_struct, pk_size); 2814; 2815 return cleanup(MatrixTable(base._jvds.selectRows(row._ast.to_hql(),; -> 2816 new_key))); 2817; 2818 @typecheck_method(caller=str,. /usr/lib/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py in __call__(self, *args); 1131 answer = self.gateway_client.send_command(command); 1132 return_value = get_return_value(; -> 1133 answer, self.gateway_client, self.target_id, self.name); 1134; 1135 for temp_arg in temp_args:. /hadoop_gcs_connector_metadata_cache/hail/hail-devel-c8ca698c6ed5.zip/hail/utils/java.py in deco(*args, **kwargs); 194 raise FatalError('%s\n\nJava stack trace:\n%s\n'; 195 'Hail version: %s\n'; --> 196 'Error summary: %s' % (deepest, full, hail.__version__, deepest)) from None; 197 except pyspark.sql.utils.CapturedException as e:; 198 raise FatalError('%s\n\nJava stack trace:\n%s\n'. FatalError: NegativeArraySizeException: null. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 24 in stage 9.0 failed 20 times, most recent failure: Lost task 24.19 in stage 9.0 (TID 2874, berylc-sw-68wx.c.broad-mpg-gnomad.internal, executor 39): java.lang.NegativeArraySizeException; 	at java.util.Arrays.copyOf(Arrays.java:3236); 	at is.hail.annotations.Region.ensure(Region.scala:140); 	at is.hail.annotations.Region.allocate(Region.scala:153); 	at is.hail.annotations.Region.allocate(Region.scala:160); 	at is.hail.codegen.generated.C11.apply(Unknown Source); 	at is.hail.codegen.generated.C11.apply(Unknown Source); 	at is.hail.io.CompiledPackDecoder.readRegionValue(RowStore.scala:650); 	at is.hail.HailContext$$anon$2.next(HailContext.scala:245); 	at is.hail.HailContext$$anon$2.next(HailContext.scala:218); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at is.hail.sparkextras.ContextRDD$$anonfun$czip$1$$anon$1.next(ContextRDD.scala:333); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$1",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3583:3647,failure,failure,3647,https://hail.is,https://github.com/hail-is/hail/issues/3583,1,['failure'],['failure']
Availability,"elf, exprs, broadcast_f); 1487 ; 1488 def cache(self):. ~/hail/python/hail/utils/misc.py in process_joins(obj, exprs, broadcast_f); 364 data = hail.Struct(**{b.uid: b.value for b in broadcasts}); 365 data_json = t._to_json(data); --> 366 left = broadcast_f(left, data_json, t._jtype); 367 ; 368 def cleanup(table):. ~/hail/python/hail/table.py in broadcast_f(left, data, jt); 1483 def _process_joins(self, *exprs):; 1484 def broadcast_f(left, data, jt):; -> 1485 return Table(left._jt.annotateGlobalJSON(data, jt)); 1486 return process_joins(self, exprs, broadcast_f); 1487 . ~/apache/spark-2.2.0-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py in __call__(self, *args); 1131 answer = self.gateway_client.send_command(command); 1132 return_value = get_return_value(; -> 1133 answer, self.gateway_client, self.target_id, self.name); 1134 ; 1135 for temp_arg in temp_args:. ~/hail/python/hail/utils/java.py in deco(*args, **kwargs); 194 raise FatalError('%s\n\nJava stack trace:\n%s\n'; 195 'Hail version: %s\n'; --> 196 'Error summary: %s' % (deepest, full, hail.__version__, deepest)) from None; 197 except pyspark.sql.utils.CapturedException as e:; 198 raise FatalError('%s\n\nJava stack trace:\n%s\n'. FatalError: JsonParseException: Non-standard token 'NaN': enable JsonParser.Feature.ALLOW_NON_NUMERIC_NUMBERS to allow; at [Source: {""__uid_3"": [NaN, Infinity, -Infinity]}; line: 1, column: 17]. Java stack trace:; com.fasterxml.jackson.core.JsonParseException: Non-standard token 'NaN': enable JsonParser.Feature.ALLOW_NON_NUMERIC_NUMBERS to allow; at [Source: {""__uid_3"": [NaN, Infinity, -Infinity]}; line: 1, column: 17]; 	at com.fasterxml.jackson.core.JsonParser._constructError(JsonParser.java:1581); 	at com.fasterxml.jackson.core.base.ParserMinimalBase._reportError(ParserMinimalBase.java:533); 	at com.fasterxml.jackson.core.json.ReaderBasedJsonParser._handleOddValue(ReaderBasedJsonParser.java:1602); 	at com.fasterxml.jackson.core.json.ReaderBasedJsonParser.nextToken(R",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3785:4787,Error,Error,4787,https://hail.is,https://github.com/hail-is/hail/issues/3785,1,['Error'],['Error']
Availability,"emory parameters, but once we have some user feedback I'd like to consider re-implementing computeGramianLargeN to use BLAS3 outer product on blocks of (fewer than m) rows of the n x m matrix rather than inner product on all pairs of columns, which I think will boost speed and make it reasonable to kill the smallN routine entirely (the current largeN case benefits from dot product of sparse vectors when using hard calls, but that also goes away when we move to generic 0.2 and rip out the hardcall/dosage complexity). Then it will be natural for maxSize to control the number of rows in a block. - Added accuracy and iterations parameters to allow users to tune Davies, with R settings for Davies (1e-6, 10k) as default. This allows users to re-run groups with tiny p-values if desired to obtain greater accuracy. The R package runs additional p-value routines that may be faster when the p-value is very small, will keep in mind should this become an issue. - In remark above the Skat class, I've added an overview of how math in paper corresponds to implementation. - Simplified and re-organized the Skat class to cut down on the number and complexity of passed parameters and make the meaning of the code more transparent with respect to the overview. Killed the SkatModel class. - Fixed an oversight whereby the largeN route was never called by logistic. - Fixed a bug whereby a weight of null was passed to DoubleNumericConversion.to and then Option rather than the other way around to prevent null match exception. - Modified R test code to use Adjustment=False to avoid the small-sample adjustment made in the logistic case when running using than 2000 samples. I could then reduce the Balding-Nichols example from 2001 and 500 samples and run logistic on the smaller test set as well. - Further cleaned up the tests, and added a test of the size column and maxSize parameter. - More descriptive error message should Cholesky or inversion fail in logistic case. - Updated docs accordingly.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2248:1719,down,down,1719,https://hail.is,https://github.com/hail-is/hail/pull/2248,2,"['down', 'error']","['down', 'error']"
Availability,"emoving batch workers' reliance on the docker daemon and docker in general, in favor of a lower level of abstraction that gives us finer control over resources on the worker like overlays and network namespaces, allowing us to shortcut and pre-configure some of the overhead that goes into running a job. ## What this does differently; Currently, the high-level process for running a job involves communicating with the docker daemon to:; 1. Pull an image for a job; 2. Start a container from that image; 3. Run the container; 4. Delete the container and its associated resources. We offload some of these responsibilities into the worker code and onto [crun](https://github.com/containers/crun), a lightweight low-level runtime with the same API as `runc`, what docker uses to run containers. Once docker has retrieved an image, if we see that the pulled image has a new digest from one we currently have cached on the worker, we extract the image's filesystem into a directory on the worker's disk. We then:. - use `mount` to create an overlay on top of the image that the container will use as its rootfs; - use `xfs_quota` to limit the container's storage in the overlay; - invoke `crun` to run a container with the overlay as its root filesystem and an appropriate network namespace that we set up at worker-start time. Since we control the overlay, we can set the XFS quota before creating the container. So what was separate calls to docker create/start/run/delete is just a single `crun run`. Fewer steps, less back and forth with a single daemon, and pre-configuring the networks gives some sizable performance gains reliable, as well as reliable and consistent performance. ## What this doesn't solve; - Docker is still running the worker container. I don't see any real challenge to this it's just a matter of translating the docker parameters; - Still using docker to pull images and extract filesystems / environment variables from them. I don't have a substitute for this at the moment.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10376:1653,reliab,reliable,1653,https://hail.is,https://github.com/hail-is/hail/pull/10376,2,['reliab'],['reliable']
Availability,"emp_args:. /fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/hail/backend/py4j_backend.py in deco(*args, **kwargs); 14 import pyspark; 15 try:; ---> 16 return f(*args, **kwargs); 17 except py4j.protocol.Py4JJavaError as e:; 18 s = e.java_exception.toString(). /fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/protocol.py in get_return_value(answer, gateway_client, target_id, name); 334 raise Py4JError(; 335 ""An error occurred while calling {0}{1}{2}"".; --> 336 format(target_id, ""."", name)); 337 else:; 338 type = answer[1]. Py4JError: An error occurred while calling o1.pyPersistTable; --------------- end of error -------------------. The above is for running the GWAS tutorial. While running my own GWAS, I have encountered a similar error when running GWAS with the line :. gwas = hl.agg.linreg(hl.float(mt.phenos.height),; [1.0, mt.hapcounts0.x, mt.anc1dos.x, mt.anc2dos.x]). The error message is as follows:. -------------- start of error ------------------. ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:38197); Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 977, in _get_connection; connection = self.deque.pop(); IndexError: pop from an empty deque. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 1115, in start; self.socket.connect((self.address, self.port)); ConnectionRefusedError: [Errno 111] Connection refused; ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:38197); Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 977, in _get_connection; connection = self.deque.pop(); IndexError: pop from an empty deque. During handling of the above ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/9939:8064,ERROR,ERROR,8064,https://hail.is,https://github.com/hail-is/hail/issues/9939,1,['ERROR'],['ERROR']
Availability,"empty>]; libsimdpp-2.0-rc2/simdpp/detail/insn/mem_unpack.h:471:8: required from void simdpp::arch_avx2::detail::insn::v_mem_unpack4_impl16_128(T&, T&, T&, T&) [with T = simdpp::arch_avx2::uint16<8>]; libsimdpp-2.0-rc2/simdpp/detail/insn/mem_unpack.h:585:29: required from void simdpp::arch_avx2::detail::insn::mem_unpack4(simdpp::arch_avx2::uint16<N>&, simdpp::arch_avx2::uint16<N>&, simdpp::arch_avx2::uint16<N>&, simdpp::arch_avx2::uint16<N>&) [with unsigned int N = 8]; libsimdpp-2.0-rc2/simdpp/detail/insn/load_packed4.h:238:16: required from void simdpp::arch_avx2::detail::insn::v128_load_packed4(V&, V&, V&, V&, const char*) [with V = simdpp::arch_avx2::uint16<8>]; libsimdpp-2.0-rc2/simdpp/detail/insn/load_packed4.h:71:36: required from here; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:40:13: error: void* memcpy(void*, const void*, size_t) copying an object of type class simdpp::arch_avx2::uint64<2> with private member simdpp::arch_avx2::uint64<2>::d_ from an array of const class simdpp::arch_avx2::uint16<8>; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/types.h:26,; from libsimdpp-2.0-rc2/simdpp/core/align.h:15,; from libsimdpp-2.0-rc2/simdpp/simd.h:22,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/types/int64x2.h:102:7: note: class simdpp::arch_avx2::uint64<2> declared here; class uint64<2, void> : public any_int64<2, uint64<2,void>> {; ^~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/simd.h:132,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl: In instantiation of R simdpp::arch_avx2::detail::cast_memcpy(const T&) [with R = simdpp::arch_avx2::uint64<4>; T = simdpp::arch_avx2::uint16<16>]:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3955:140998,error,error,140998,https://hail.is,https://github.com/hail-is/hail/issues/3955,1,['error'],['error']
Availability,"ems()}; --> 896 base, cleanup = self._process_joins(*named_exprs.values()); 897; 898 for k, v in named_exprs.items():. /home/hail/hail.zip/hail/matrixtable.py in _process_joins(self, *exprs); 2205 for j in list(e._joins)[::-1]:; 2206 if j.uid not in used_uids:; -> 2207 left = j.join_function(left); 2208 all_uids.extend(j.temp_vars); 2209 used_uids.add(j.uid). /home/hail/hail.zip/hail/matrixtable.py in <lambda>(left); 2157 prefix = 'va'; 2158 joiner = lambda left: (; -> 2159 MatrixTable(left._jvds.annotateRowsVDS(right._jvds, uid))); 2160 else:; 2161 return self.rows().index(*exprs). /usr/lib/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py in __call__(self, *args); 1131 answer = self.gateway_client.send_command(command); 1132 return_value = get_return_value(; -> 1133 answer, self.gateway_client, self.target_id, self.name); 1134; 1135 for temp_arg in temp_args:. /home/hail/hail.zip/hail/utils/java.py in deco(*args, **kwargs); 236 # this is a hack to suppress the original error's stack trace; 237 if _exception:; --> 238 raise _exception; 239; 240 return deco. FatalError: AssertionError: assertion failed. Java stack trace:; java.lang.AssertionError: assertion failed; 	at scala.Predef$.assert(Predef.scala:156); 	at is.hail.variant.MatrixTable.orderedRVDLeftJoinDistinctAndInsert(MatrixTable.scala:982); 	at is.hail.variant.MatrixTable.annotateRowsVDS(MatrixTable.scala:1449); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:280); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.ja",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3119:2219,error,error,2219,https://hail.is,https://github.com/hail-is/hail/issues/3119,1,['error'],['error']
Availability,"en/2.2.x/changes/#version-2-2-0</a></li>; <li>Milestone: <a href=""https://github.com/pallets/werkzeug/milestone/20?closed=1"">https://github.com/pallets/werkzeug/milestone/20?closed=1</a></li>; </ul>; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/pallets/werkzeug/blob/main/CHANGES.rst"">werkzeug's changelog</a>.</em></p>; <blockquote>; <h2>Version 2.2.2</h2>; <p>Released 2022-08-08</p>; <ul>; <li>Fix router to restore the 2.1 <code>strict_slashes == False</code> behaviour; whereby leaf-requests match branch rules and vice; versa. :pr:<code>2489</code></li>; <li>Fix router to identify invalid rules rather than hang parsing them,; and to correctly parse <code>/</code> within converter arguments. :pr:<code>2489</code></li>; <li>Update subpackage imports in :mod:<code>werkzeug.routing</code> to use the; <code>import as</code> syntax for explicitly re-exporting public attributes.; :pr:<code>2493</code></li>; <li>Parsing of some invalid header characters is more robust. :pr:<code>2494</code></li>; <li>When starting the development server, a warning not to use it in a; production deployment is always shown. :issue:<code>2480</code></li>; <li><code>LocalProxy.__wrapped__</code> is always set to the wrapped object when; the proxy is unbound, fixing an issue in doctest that would cause it; to fail. :issue:<code>2485</code></li>; <li>Address one <code>ResourceWarning</code> related to the socket used by; <code>run_simple</code>. :issue:<code>2421</code></li>; </ul>; <h2>Version 2.2.1</h2>; <p>Released 2022-07-27</p>; <ul>; <li>Fix router so that <code>/path/</code> will match a rule <code>/path</code> if strict; slashes mode is disabled for the rule. :issue:<code>2467</code></li>; <li>Fix router so that partial part matches are not allowed; i.e. <code>/2df</code> does not match <code>/&lt;int&gt;</code>. :pr:<code>2470</code></li>; <li>Fix router static part weighting, so that simpler routes are matched; before",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12119:2802,robust,robust,2802,https://hail.is,https://github.com/hail-is/hail/pull/12119,1,['robust'],['robust']
Availability,"en/anaconda/envs/hail-env/lib/python3.7/site-packages/hailctl/dataproc/cli.py"", line 99, in main; jmp[args.module].main(args, pass_through_args); File ""/Users/cchen/anaconda/envs/hail-env/lib/python3.7/site-packages/hailctl/dataproc/submit.py"", line 72, in main; check_call(cmd); File ""/Users/cchen/anaconda/envs/hail-env/lib/python3.7/subprocess.py"", line 347, in check_call; raise CalledProcessError(retcode, cmd); subprocess.CalledProcessError: Command '['gcloud', 'dataproc', 'jobs', 'submit', 'pyspark', 'ukbb_hdpca.py', '--cluster=chen', '--files=', '--py-files=/var/folders/6h/ll2dv8t15zs9pzf4g6kjb2rrt2fc9q/T/pyscripts_2740r0cj.zip', '--properties=']' returned non-zero exit status 1.; ```; The file does not exist but there are files with the same prefix but a `.000000001` suffix or similar. Grace reports (a possibly unrelated issue) https://hail.zulipchat.com/#narrow/stream/123010-Hail-0.2E2.20support/topic/Cryptic.20array.20concordance.20error:; ```; ERROR: (gcloud.dataproc.jobs.submit.pyspark) Job [873db5659acd43f7b539dcb17182959d] entered state [ERROR] while waiting for [DONE].; Traceback (most recent call last):; File ""/miniconda3/bin/hailctl"", line 10, in <module>; sys.exit(main()); File ""/miniconda3/lib/python3.7/site-packages/hailctl/__main__.py"", line 90, in main; module(args); File ""/miniconda3/lib/python3.7/site-packages/hailctl/dataproc/cli.py"", line 99, in main; jmp[args.module].main(args, pass_through_args); File ""/miniconda3/lib/python3.7/site-packages/hailctl/dataproc/submit.py"", line 72, in main; check_call(cmd); File ""/miniconda3/lib/python3.7/subprocess.py"", line 341, in check_call; raise CalledProcessError(retcode, cmd); subprocess.CalledProcessError: Command '['gcloud', 'dataproc', 'jobs', 'submit', 'pyspark', '/Users/gtiao/ukbb_qc/scratch.py', '--cluster=gt1', '--files=', '--py-files=/var/folders/rn/t2xcx1ps4h96txll46qkkfsj2q8bnl/T/pyscripts_lh2k36v4.zip', '--properties=', '--', '--slack_channel', '@grace']' returned non-zero exit status 1.; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6565:1871,ERROR,ERROR,1871,https://hail.is,https://github.com/hail-is/hail/issues/6565,1,['ERROR'],['ERROR']
Availability,"end.py"", line 94, in execute; self._to_java_ir(ir))); File ""/Users/dking/anaconda2/envs/hail/lib/python3.6/site-packages/py4j/java_gateway.py"", line 1257, in __call__; answer, self.gateway_client, self.target_id, self.name); File ""/Users/dking/anaconda2/envs/hail/lib/python3.6/site-packages/hail/utils/java.py"", line 227, in deco; 'Error summary: %s' % (deepest, full, hail.__version__, deepest)) from None; hail.utils.java.FatalError: HailException: Error parsing row fields in row 0:; expected 5 fields but only 5 found.; File: foo; Line:; 7	75216143	75216143	C/T	+. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 1.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1.0 (TID 1, localhost, executor driver): is.hail.utils.HailException: foo: Error parsing row fields in row 0:; expected 5 fields but only 5 found.; File: foo; Line:; 7	75216143	75216143	C/T	+; offending line: 7	75216143	75216143	C/T	+; 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:20); 	at is.hail.utils.package$.fatal(package.scala:28); 	at is.hail.utils.Context.wrapException(Context.scala:19); 	at is.hail.utils.WithContext.wrap(Context.scala:43); 	at is.hail.io.LoadMatrix$$anonfun$16$$anonfun$apply$6.apply(LoadMatrix.scala:377); 	at is.hail.io.LoadMatrix$$anonfun$16$$anonfun$apply$6.apply(LoadMatrix.scala:375); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at scala.collection.Iterator$class.foreach(Iterator.scala:893); 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); 	at is.hail.rvd.RVD$$anonfun$count$2.apply(RVD.scala:575); 	at is.hail.rvd.RVD$$anonfun$count$2.apply(RVD.scala:573); 	at is.hail.sparkextras.ContextRDD$$anonfun$cmapPartitions$1$$anonfun$apply$28.apply(ContextRDD.scala:405); 	at is.hail.sparkextras.ContextRDD$$anonfun$cmapPartitions$1$$anonfun$apply$28.apply(ContextRDD.scala:405); 	at is.hail.sparkextras.Conte",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5718:2860,Error,ErrorHandling,2860,https://hail.is,https://github.com/hail-is/hail/issues/5718,1,['Error'],['ErrorHandling']
Availability,"endencies</li>; <li>update linters</li>; <li>update docs deployment branches</li>; </ul>; </li>; <li>misc test/ci updates; <ul>; <li>test forks</li>; <li>tidy OS &amp; Python version tests</li>; <li>bump primary python version 3.7 =&gt; 3.8</li>; <li>beta py3.10 testing</li>; <li>fix py2.7 tests</li>; <li>better timeout handling</li>; </ul>; </li>; </ul>; <h2>tqdm v4.62.2 stable</h2>; <ul>; <li>fix notebook memory leak (<a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1216"">#1216</a>)</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/tqdm/tqdm/commit/6791e8c5b3d6c30bdd2060c346996bfb5a6f10d1""><code>6791e8c</code></a> bump version, merge pull request <a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1366"">#1366</a> from tqdm/devel</li>; <li><a href=""https://github.com/tqdm/tqdm/commit/754186291e6b4e28ea8b56c9493adc03bf14c404""><code>7541862</code></a> tests: hotfix skip windows errors</li>; <li><a href=""https://github.com/tqdm/tqdm/commit/8fb3d91f561e2a286a7fda13291eda16613dac39""><code>8fb3d91</code></a> fix ipywidgets&gt;=8 display</li>; <li><a href=""https://github.com/tqdm/tqdm/commit/05e3d32a5fc8559e133e6d627d44afda93018637""><code>05e3d32</code></a> fix jupyterlab display</li>; <li><a href=""https://github.com/tqdm/tqdm/commit/4f208e72552c4d916aa4fe6a955349ee8b2ed353""><code>4f208e7</code></a> bump version, merge branch 'slack'</li>; <li><a href=""https://github.com/tqdm/tqdm/commit/1d29dec4b07de3dab34d3557baa9520cd9d46e38""><code>1d29dec</code></a> add <code>[slack]</code> extra dependency</li>; <li><a href=""https://github.com/tqdm/tqdm/commit/4a1d10e19fdca00db47fd50725715dc5e4aa68e6""><code>4a1d10e</code></a> consistent ordering</li>; <li><a href=""https://github.com/tqdm/tqdm/commit/bf6c960f60f8a390b47ac55d2ece3ffc419e5dcd""><code>bf6c960</code></a> emoji bars</li>; <li><a href=""https://github.com/tqdm/tqdm/commit/7994aa828",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12260:4390,error,errors,4390,https://hail.is,https://github.com/hail-is/hail/pull/12260,1,['error'],['errors']
Availability,"ents. We recommend that all users upgrade to this version.</p>; <p>See the <a href=""https://pandas.pydata.org/pandas-docs/version/1.4.0/whatsnew/v1.4.0.html"">full whatsnew</a> for a list of all the changes. pandas 1.4.0 supports Python 3.8 and higher.</p>; <p>The release will be available on the defaults and conda-forge channels:</p>; <pre><code>conda install -c conda-forge pandas; </code></pre>; <p>Or via PyPI:</p>; <pre><code>python3 -m pip install --upgrade pandas; </code></pre>; <p>Please report any issues with the release on the <a href=""https://github.com/pandas-dev/pandas/issues"">pandas issue tracker</a>.</p>; <h2>Pandas 1.4.0rc0</h2>; <p>We are pleased to announce a release candidate for pandas 1.4.0. If all goes well, we'll release pandas 1.4.0 in about two weeks.</p>; <p>See the <a href=""https://pandas.pydata.org/pandas-docs/version/1.4/whatsnew/v1.4.0.html"">whatsnew</a> for a list of all the changes. pandas 1.4.0 supports Python 3.8 and higher.</p>; <p>The release will be available on conda-forge and PyPI.</p>; <p>The release can be installed from PyPI</p>; <pre><code>python -m pip install --upgrade --pre pandas==1.4.0rc0; </code></pre>; <p>Or from conda-forge</p>; <pre><code>conda install -c conda-forge/label/pandas_rc pandas==1.4.0rc0; </code></pre>; <p>Please report any issues with the release candidate on the pandas issue tracker.</p>; <h2>Pandas 1.3.5</h2>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/pandas-dev/pandas/commit/06d230151e6f18fdb8139d09abf539867a8cd481""><code>06d2301</code></a> RLS: 1.4.1</li>; <li><a href=""https://github.com/pandas-dev/pandas/commit/47e3b409deb41f18e30e447579cba3a246db050e""><code>47e3b40</code></a> Backport PR <a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/45587"">#45587</a>: DOC: append deprecation (<a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/45942"">#45942</",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11539:2030,avail,available,2030,https://hail.is,https://github.com/hail-is/hail/pull/11539,1,['avail'],['available']
Availability,"ependabot.com/pallets/click/issues/2238"">#2238</a> from pallets/release-8.1.2</li>; <li><a href=""https://github.com/pallets/click/commit/2f1c35a43652e565802c230dbc47a9a358a0c6fd""><code>2f1c35a</code></a> release version 8.1.2</li>; <li><a href=""https://github.com/pallets/click/commit/77dd30f8c54ebbdfbf461cedcd3d1fc1d7673f95""><code>77dd30f</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pallets/click/issues/2237"">#2237</a> from pallets/param-order</li>; <li><a href=""https://github.com/pallets/click/commit/b36bf8f9b36ab7db8cf03cd8eff714dfc33f0c29""><code>b36bf8f</code></a> restore Path param order</li>; <li><a href=""https://github.com/pallets/click/commit/a66119abe973f55b4f5e28dbb0da6f3c32c21af7""><code>a66119a</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pallets/click/issues/2236"">#2236</a> from shadchin/patch-1</li>; <li><a href=""https://github.com/pallets/click/commit/92cebe902aa7f03a89f6b261d897964dd9c5fa43""><code>92cebe9</code></a> fix readable path check error message</li>; <li><a href=""https://github.com/pallets/click/commit/456fbb6b0053fb01bedf90b64999b0a3c645a3cd""><code>456fbb6</code></a> start version 8.1.2</li>; <li><a href=""https://github.com/pallets/click/commit/a41e349ae738c55bce46dfb8715159463074d6e9""><code>a41e349</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pallets/click/issues/2234"">#2234</a> from pallets/release-8.1.1</li>; <li><a href=""https://github.com/pallets/click/commit/3c301ebacbfe8ec7dc3d9d46ebf517082a8ee4b1""><code>3c301eb</code></a> release version 8.1.1</li>; <li><a href=""https://github.com/pallets/click/commit/d5741a2ca2ebc21d525c903f628b1bebad75b735""><code>d5741a2</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pallets/click/issues/2233"">#2233</a> from henryiii/henryiii/fix/commandtype</li>; <li>Additional commits viewable in <a href=""https://github.com/pallets/click/compare/8.0.4...8.1.2"">compare view</a></li>; </u",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11801:5769,error,error,5769,https://hail.is,https://github.com/hail-is/hail/pull/11801,1,['error'],['error']
Availability,"ependabot.com/pallets/click/issues/2238"">#2238</a> from pallets/release-8.1.2</li>; <li><a href=""https://github.com/pallets/click/commit/2f1c35a43652e565802c230dbc47a9a358a0c6fd""><code>2f1c35a</code></a> release version 8.1.2</li>; <li><a href=""https://github.com/pallets/click/commit/77dd30f8c54ebbdfbf461cedcd3d1fc1d7673f95""><code>77dd30f</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pallets/click/issues/2237"">#2237</a> from pallets/param-order</li>; <li><a href=""https://github.com/pallets/click/commit/b36bf8f9b36ab7db8cf03cd8eff714dfc33f0c29""><code>b36bf8f</code></a> restore Path param order</li>; <li><a href=""https://github.com/pallets/click/commit/a66119abe973f55b4f5e28dbb0da6f3c32c21af7""><code>a66119a</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pallets/click/issues/2236"">#2236</a> from shadchin/patch-1</li>; <li><a href=""https://github.com/pallets/click/commit/92cebe902aa7f03a89f6b261d897964dd9c5fa43""><code>92cebe9</code></a> fix readable path check error message</li>; <li><a href=""https://github.com/pallets/click/commit/456fbb6b0053fb01bedf90b64999b0a3c645a3cd""><code>456fbb6</code></a> start version 8.1.2</li>; <li>See full diff in <a href=""https://github.com/pallets/click/compare/8.1.1...8.1.2"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=click&package-manager=pip&previous-version=8.1.1&new-version=8.1.2)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot act",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11726:2581,error,error,2581,https://hail.is,https://github.com/hail-is/hail/pull/11726,1,['error'],['error']
Availability,"ependencies</h3>; <ul>; <li>Update dependency org.graalvm.buildtools:native-maven-plugin to v0.9.24 (<a href=""https://redirect.github.com/googleapis/java-storage/issues/2158"">#2158</a>) (<a href=""https://github.com/googleapis/java-storage/commit/4f5682a4f6d6d5372a2d382ae3e47dace490ca0d"">4f5682a</a>)</li>; </ul>; <h2>v2.26.0</h2>; <h2><a href=""https://github.com/googleapis/java-storage/compare/v2.25.0...v2.26.0"">2.26.0</a> (2023-08-03)</h2>; <h3>Features</h3>; <ul>; <li>Implement BufferToDiskThenUpload BlobWriteSessionConfig (<a href=""https://redirect.github.com/googleapis/java-storage/issues/2139"">#2139</a>) (<a href=""https://github.com/googleapis/java-storage/commit/4dad2d5c3a81eda7190ad4f95316471e7fa30f66"">4dad2d5</a>)</li>; <li>Introduce new BlobWriteSession (<a href=""https://redirect.github.com/googleapis/java-storage/issues/2123"">#2123</a>) (<a href=""https://github.com/googleapis/java-storage/commit/e0191b518e50a49fae0691894b50f0c5f33fc6af"">e0191b5</a>)</li>; </ul>; <h3>Bug Fixes</h3>; <ul>; <li><strong>grpc:</strong> Return error if credentials are detected to be null (<a href=""https://redirect.github.com/googleapis/java-storage/issues/2142"">#2142</a>) (<a href=""https://github.com/googleapis/java-storage/commit/b61a9764a9d953d2b214edb2b543b8df42fbfa06"">b61a976</a>)</li>; <li>Possible NPE when HttpStorageOptions deserialized (<a href=""https://redirect.github.com/googleapis/java-storage/issues/2153"">#2153</a>) (<a href=""https://github.com/googleapis/java-storage/commit/68ad8e7357097e3dd161c2ab5f7a42a060a3702c"">68ad8e7</a>)</li>; <li>Update grpc default metadata projection to include acl same as json (<a href=""https://redirect.github.com/googleapis/java-storage/issues/2150"">#2150</a>) (<a href=""https://github.com/googleapis/java-storage/commit/330e795040592e5df22d44fb5216ad7cf2448e81"">330e795</a>)</li>; </ul>; <h3>Dependencies</h3>; <ul>; <li>Update dependency com.google.cloud:google-cloud-shared-dependencies to v3.14.0 (<a href=""https://redirect.github.com/google",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13605:2082,error,error,2082,https://hail.is,https://github.com/hail-is/hail/pull/13605,1,['error'],['error']
Availability,"eps, then a `vds.write`; The error is probably caused by one of the previous steps. If it helps I can comment out earlier parts to narrow down what actually triggers the error. ### What went wrong (all error messages here, including the full java stack trace):; ```; [Stage 6:> (0 + 8) / 5000]; [Stage 6:> (0 + 4) / 5000]; [Stage 6:> (0 + 8) / 5000]Traceback (most recent call last):; File ""/home/hail/hail.zip/hail/utils/java.py"", line 185, in handle_py4j; File ""/home/hail/hail.zip/hail/table.py"", line 1058, in aggregate; File ""/usr/lib/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py"", line 1133, in __call__; File ""/usr/lib/spark/python/lib/pyspark.zip/pyspark/sql/utils.py"", line 63, in deco; File ""/usr/lib/spark/python/lib/py4j-0.10.4-src.zip/py4j/protocol.py"", line 319, in get_return_value; py4j.protocol.Py4JJavaError: An error occurred while calling o30335.query.; : org.apache.spark.SparkException: Job aborted due to stage failure: Task 7 in stage 6.0 failed 20 times, most recent failure: Lost task 7.19 in stage 6.0 (TID 179, robert1-w-0.c.ccdg-wgs.internal, executor 4): java.lang.AssertionError: assertion failed; at scala.Predef$.assert(Predef.scala:156); at is.hail.annotations.RegionValueBuilder.endStruct(RegionValueBuilder.scala:109); at is.hail.variant.MatrixTable$$anonfun$filterGenotypes$1$$anonfun$apply$80.apply(MatrixTable.scala:2645); at is.hail.variant.MatrixTable$$anonfun$filterGenotypes$1$$anonfun$apply$80.apply(MatrixTable.scala:2615); at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); at is.hail.rvd.OrderedRVD$$anonfun$apply$6$$anon$5.next(OrderedRVD.scala:736); at is.hail.rvd.OrderedRVD$$anonfun$apply$6$$anon$5.next(OrderedRVD.scala:730); at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); at is.hail.rvd.OrderedRVD$$anonfun$apply$6$$anon$5.next(OrderedRVD.scala:736); at is.hail.rvd.OrderedRVD$$anonfun$apply$6$$anon$5.next(OrderedRVD.scala:730); at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); at is.hail",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3063:1318,failure,failure,1318,https://hail.is,https://github.com/hail-is/hail/issues/3063,1,['failure'],['failure']
Availability,"eption.java:293) ~[gs:__hail-query-ger0g_jars_b115f6a6ec23f111a4512b562b52d9f8a52ec41c.jar.jar:0.0.1-SNAPSHOT]; 		at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1118) ~[gs:__hail-query-ger0g_jars_b115f6a6ec23f111a4512b562b52d9f8a52ec41c.jar.jar:0.0.1-SNAPSHOT]; 		at is.hail.relocated.com.google.cloud.storage.spi.v1.HttpStorageRpc.open(HttpStorageRpc.java:1022) ~[gs:__hail-query-ger0g_jars_b115f6a6ec23f111a4512b562b52d9f8a52ec41c.jar.jar:0.0.1-SNAPSHOT]; 		... 48 more; Caused by: com.google.api.client.http.HttpResponseException: 403 Forbidden; POST https://storage.googleapis.com/upload/storage/v1/b/neale-bge/o?name=foo.ht/index/part-0-c7ba7549-bf68-42db-a8ef-0f1b13721c79.idx/index&uploadType=resumable; {; ""error"": {; ""code"": 403,; ""message"": ""dking-ae4q6@hail-vdc.iam.gserviceaccount.com does not have storage.objects.create access to the Google Cloud Storage object. Permission 'storage.objects.create' denied on resource (or it may not exist)."",; ""errors"": [; {; ""message"": ""dking-ae4q6@hail-vdc.iam.gserviceaccount.com does not have storage.objects.create access to the Google Cloud Storage object. Permission 'storage.objects.create' denied on resource (or it may not exist)."",; ""domain"": ""global"",; ""reason"": ""forbidden""; }; ]; }; }. 	at com.google.api.client.http.HttpResponseException$Builder.build(HttpResponseException.java:293) ~[gs:__hail-query-ger0g_jars_b115f6a6ec23f111a4512b562b52d9f8a52ec41c.jar.jar:0.0.1-SNAPSHOT]; 	at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1118) ~[gs:__hail-query-ger0g_jars_b115f6a6ec23f111a4512b562b52d9f8a52ec41c.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.spi.v1.HttpStorageRpc.open(HttpStorageRpc.java:1022) ~[gs:__hail-query-ger0g_jars_b115f6a6ec23f111a4512b562b52d9f8a52ec41c.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.ResumableMedia.lambda$startUploadForBlobInfo$0(ResumableMedia.java:40) ~[gs:__hail-query-ger0g_jars_b115f6a6ec23f111a4512b562b52",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13697:27512,error,errors,27512,https://hail.is,https://github.com/hail-is/hail/issues/13697,1,['error'],['errors']
Availability,"eputy problem: it issues a callback in response; to a batch finishing. That callback is issued from within the cluster and; therefore can name many of our services which are not exposed to the; internet. With the introduction of TLS everywhere, a confused deputy callback; will fail because the victim will not receive a valid Batch certificate (batch; purposely does not send certificates with the callbacks). Batch only uses its; certificate to send a callback for CI. This is safe because we control CI and; ensure it is not compromised. In the long run, I want to fix batch to use an entirely different network for; callbacks. ### Notes of Annoyance. `aiohttp` silently ignores most invalid TLS requests, this makes debugging a TLS; issue difficult. `aiohttp`'s `raise_for_status` does not include the HTTP body in the; message. NGINX sometimes returns 400 in response to TLS issues with a proxy. It; includes crucial details in the HTTP body. I usually debug these issues by; sshing to the client pod and using curl to manually reproduce the error. Readiness and liveness probes cannot use HTTP. Although k8s supports HTTPS, it; does not support so-called ""mTLS"" or ""mutual TLS."" This is fancy verbiage for; servers that require clients to send trusted certificates. I will eventually require; this. There is a lot of information in GitHub issues and the Istio web pages; about this, but at the end of the day, kubernetes does not support this. TCP; probes are the best we can do. There [was a; PR](kubernetes/kubernetes#61231) to allow httpGet probes; to send the kubelet certificate, but it was closed because, apparently, the; [httpGet probes can be targeted at arbitrary IP; addresses](kubernetes/kubernetes#61231 (review)) (what; the hell?), ergo Confused Deputy. ### Future Work. - Require TLS 1.3 everywhere.; - Comply with Mozilla's ""Modern"" recommendations.; - [Incoming Trust](#incoming-trust).; - Refresh certificates after deploying new ones. ### Footnotes. [1] TLS: Transport Layer ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8561:10621,error,error,10621,https://hail.is,https://github.com/hail-is/hail/pull/8561,1,['error'],['error']
Availability,"eqr_loading.py"", line 54, in run; self.read_vcf_write_mt(); File ""/tmp/c7e0443c47b54e91b295e2bff7b554b9/seqr_loading.py"", line 84, in read_vcf_write_mt; mt.write(self.output().path, stage_locally=True, overwrite=True); File ""<decorator-gen-1092>"", line 2, in write; File ""/opt/conda/default/lib/python3.6/site-packages/hail/typecheck/check.py"", line 585, in wrapper; return __original_func(*args_, **kwargs_); File ""/opt/conda/default/lib/python3.6/site-packages/hail/matrixtable.py"", line 2529, in write; Env.backend().execute(MatrixWrite(self._mir, writer)); File ""/opt/conda/default/lib/python3.6/site-packages/hail/backend/backend.py"", line 109, in execute; result = json.loads(Env.hc()._jhc.backend().executeJSON(self._to_java_ir(ir))); File ""/usr/lib/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py"", line 1257, in __call__; answer, self.gateway_client, self.target_id, self.name); File ""/opt/conda/default/lib/python3.6/site-packages/hail/utils/java.py"", line 225, in deco; 'Error summary: %s' % (deepest, full, hail.__version__, deepest)) from None; hail.utils.java.FatalError: HailException: cannot set missing field for required type +PCStruct{info:PCStruct{ALLELEID:PInt32}}. Java stack trace:; java.lang.RuntimeException: error while applying lowering 'InterpretNonCompilable'; 	at is.hail.expr.ir.lowering.LoweringPipeline$$anonfun$apply$1.apply(LoweringPipeline.scala:26); 	at is.hail.expr.ir.lowering.LoweringPipeline$$anonfun$apply$1.apply(LoweringPipeline.scala:18); 	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); 	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35); 	at is.hail.expr.ir.lowering.LoweringPipeline.apply(LoweringPipeline.scala:18); 	at is.hail.expr.ir.CompileAndEvaluate$._apply(CompileAndEvaluate.scala:27); 	at is.hail.backend.Backend.is$hail$backend$Backend$$_execute(Backend.scala:90); 	at is.hail.backend.Backend$$anonfun$execute$1.apply(Backend.scala:78); 	at is.hail.backend.Backend$$anonfun$",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8469:48786,Error,Error,48786,https://hail.is,https://github.com/hail-is/hail/issues/8469,1,['Error'],['Error']
Availability,"equirement pyzmq<25,>=17, but you have pyzmq 25.1.1.; aiohttp-devtools 1.1 requires aiohttp, which is not installed. ```; </details>. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **663/1000** <br/> **Why?** Proof of Concept exploit, Recently disclosed, Has a fix available, CVSS 5.4 | Improper Input Validation <br/>[SNYK-PYTHON-AIOHTTP-6091621](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-6091621) | `aiohttp:` <br> `3.8.6 -> 3.9.0` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **663/1000** <br/> **Why?** Proof of Concept exploit, Recently disclosed, Has a fix available, CVSS 5.4 | Improper Input Validation <br/>[SNYK-PYTHON-AIOHTTP-6091622](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-6091622) | `aiohttp:` <br> `3.8.6 -> 3.9.0` <br> | No | Proof of Concept . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI1M2U3Mjk0MS01YmVjLTQ2MjYtYTY2Ny0wNzIxYjUwNjZ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14043:1659,avail,available,1659,https://hail.is,https://github.com/hail-is/hail/pull/14043,1,['avail'],['available']
Availability,"er$.logTime(ExecutionTimer.scala:62); 	at is.hail.backend.spark.SparkBackend.withExecuteContext(SparkBackend.scala:393); 	at is.hail.backend.spark.SparkBackend.execute(SparkBackend.scala:631); 	at is.hail.backend.BackendHttpHandler.handle(BackendServer.scala:89); 	at jdk.httpserver/com.sun.net.httpserver.Filter$Chain.doFilter(Filter.java:77); 	at jdk.httpserver/sun.net.httpserver.AuthFilter.doFilter(AuthFilter.java:82); 	at jdk.httpserver/com.sun.net.httpserver.Filter$Chain.doFilter(Filter.java:80); 	at jdk.httpserver/sun.net.httpserver.ServerImpl$Exchange$LinkHandler.handle(ServerImpl.java:848); 	at jdk.httpserver/com.sun.net.httpserver.Filter$Chain.doFilter(Filter.java:77); 	at jdk.httpserver/sun.net.httpserver.ServerImpl$Exchange.run(ServerImpl.java:817); 	at jdk.httpserver/sun.net.httpserver.ServerImpl$DefaultExecutor.execute(ServerImpl.java:201); 	at jdk.httpserver/sun.net.httpserver.ServerImpl$Dispatcher.handle(ServerImpl.java:560); 	at jdk.httpserver/sun.net.httpserver.ServerImpl$Dispatcher.run(ServerImpl.java:526); 	at java.base/java.lang.Thread.run(Thread.java:829). Hail version: 0.2.127-bb535cd096c5; Error summary: ClassTooLargeException: Class too large: __C67907collect_distributed_array_table_collect; ```. Hail log (in chunks, as it is 77 MB large):; [hail-20240227-1113-0.2.127-bb535cd096c5.log.chunk1.txt](https://github.com/hail-is/hail/files/14418491/hail-20240227-1113-0.2.127-bb535cd096c5.log.chunk1.txt); [hail-20240227-1113-0.2.127-bb535cd096c5.log.chunk2.txt](https://github.com/hail-is/hail/files/14418492/hail-20240227-1113-0.2.127-bb535cd096c5.log.chunk2.txt); [hail-20240227-1113-0.2.127-bb535cd096c5.log.chunk3.txt](https://github.com/hail-is/hail/files/14418560/hail-20240227-1113-0.2.127-bb535cd096c5.log.chunk3.txt); [hail-20240227-1113-0.2.127-bb535cd096c5.log.chunk4.txt](https://github.com/hail-is/hail/files/14418551/hail-20240227-1113-0.2.127-bb535cd096c5.log.chunk4.txt). ### Version. 0.2.127-bb535cd096c5. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14362:19744,Error,Error,19744,https://hail.is,https://github.com/hail-is/hail/issues/14362,1,['Error'],['Error']
Availability,"er-call</code> for non-direct parents (<a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/6956"">#6956</a>)</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/fb6be5933ab270d542d80589be6fdea8abc82665""><code>fb6be59</code></a> Fix <code>undefined-variable</code> for <code>__class__</code> in inner methods (<a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/6957"">#6957</a>)</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/b9ecb4d70d23f7a6d05cc14e94c26fd8d3261d0f""><code>b9ecb4d</code></a> Fix false positive for <code>useless-super-delegation</code> for variadics (<a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/6949"">#6949</a>)</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/f881219a66deaf9cef6467ba27c3385bc98dad82""><code>f881219</code></a> Bump pylint to 2.14.2, update changelog</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/988d882b56f9eca8ba1825b86b59e92b824ca1c3""><code>988d882</code></a> Treat <code>--errors-only</code> as a disable, not a paired enable/disable (<a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/6937"">#6937</a>)</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/386e7782b78a6e1baf0edd57cff893f3a08fb33c""><code>386e778</code></a> Mix incorrect parsing of multi-line options in <code>ini</code> files</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/7cd7c8cbedd8258ad151e13da4036b42602351a7""><code>7cd7c8c</code></a> Add regression test for <a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/6895"">#6895</a> (<a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/6898"">#6898</a>)</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/d6fa3416825fb7c398e4d8bee11a8ae0b3a39f07""><code>d6fa341</code></a> Mark <code>no-self-use</code> as moved to extensions (<a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/6932"">#6932</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/P",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11971:1688,error,errors-only,1688,https://hail.is,https://github.com/hail-is/hail/pull/11971,1,['error'],['errors-only']
Availability,"er-event-loop-8"" Exception in thread ""refresh progress"" java.lang.OutOfMemoryError: GC overhead limit exceeded; at java.util.zip.ZipCoder.getBytes(ZipCoder.java:80); at java.util.zip.ZipFile.getEntry(ZipFile.java:310); at java.util.jar.JarFile.getEntry(JarFile.java:240); at java.util.jar.JarFile.getJarEntry(JarFile.java:223); at sun.misc.URLClassPath$JarLoader.getResource(URLClassPath.java:1042); at sun.misc.URLClassPath.getResource(URLClassPath.java:239); at java.net.URLClassLoader$1.run(URLClassLoader.java:365); at java.net.URLClassLoader$1.run(URLClassLoader.java:362); at java.security.AccessController.doPrivileged(Native Method); at java.net.URLClassLoader.findClass(URLClassLoader.java:361); at java.lang.ClassLoader.loadClass(ClassLoader.java:424); at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331); at java.lang.ClassLoader.loadClass(ClassLoader.java:357); at org.apache.spark.HeartbeatReceiver$$anonfun$org$apache$spark$HeartbeatReceiver$$expireDeadHosts$3.apply(HeartbeatReceiver.scala:198); at org.apache.spark.HeartbeatReceiver$$anonfun$org$apache$spark$HeartbeatReceiver$$expireDeadHosts$3.apply(HeartbeatReceiver.scala:196); at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733); at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99); at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99); at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230); at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40); at scala.collection.mutable.HashMap.foreach(HashMap.scala:99); at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732); at org.apache.spark.HeartbeatReceiver.org$apache$spark$HeartbeatReceiver$$expireDeadHosts(HeartbeatReceiver.scala:196); at org.apache.spark.HeartbeatReceiver$$anonfun$receiveAndReply$1.applyOrElse(HeartbeatReceiver.scala:119); at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.appl",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4780:2049,Heartbeat,HeartbeatReceiver,2049,https://hail.is,https://github.com/hail-is/hail/issues/4780,1,['Heartbeat'],['HeartbeatReceiver']
Availability,"er; as such it's easier to hide sensitive information. . Mobile and desktop apps have dealt with this for 2 decades. We should build a robust infrastructure, and not one that requires server-rendered web pages for security. Currently it seems Auth0 may not be the best choice: it does not interface for us with third-party API's; requires us to either insecurely store 3rd party access tokens (with at least 1 extra round trip), or altogether proxy all third-party requests through our own resource server... Firebase Auth seems to avoid these limitations. ## TODO:; 1. Create a structured description of this pull request; 2. Incorporate Firebase Auth in place of Auth0 for 3rd party access token benefits.; 3: Scorecard; 3a. Draft working GraphQL V4 scorecard implementation; 3b. Finish authenticated GraphQL V4 scorecard implementation; 4. Batch; 4a: Setup dev batch endpoint; 4b: Call batch endpoint (no auth), and return any data; 4c: List all available jobs; * By querying Batch api, or Kubernetes directly; 4d: Receive current status of 1 job; 4e: Authentication; 4f: Polish (longest step): make interacting with batch achievable within perceived 16ms.; * goal: subscribe to events in web socket; * may want to save user job state in a Hail-controlled database (possible to use Firebase or Mongo, may prefer relational db, maybe Postgres or MySQL).; 4other: Figure out state question (sufficient to use Kubernetes); 5. Basic notebook interface.; 6. Connect websocket logic (non-GraphQL); 7. Authenticate web socket via Oauth2; 8. Incorporate GraphQL subscriptions (first: GitHub API); 9. Write tests; 10. Mock GraphQL endpoints; 11. Integrate web and api server bits into CI (maybe should be prioritized earlier...I prefer to get draft of major functions done first; am new to writing tests for React/Node). ## Near-term goals (<= 6 mo); 1. Upload, download; 2. Launch clusters, pay for them; 3. ?. ## Longer-term goals; 1. Much simpler interface to Hail. I would like steps that can be perform",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4931:7101,avail,available,7101,https://hail.is,https://github.com/hail-is/hail/pull/4931,1,['avail'],['available']
Availability,"ernetes#92438</a>, <a href=""https://github.com/liggitt""><code>@liggitt</code></a>) [SIG API Machinery, Auth, CLI, Cloud Provider, Cluster Lifecycle, Instrumentation, Network, Node, Release, Storage and Testing]</li>; <li>Hide managedFields from kubectl edit command (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/91946"">kubernetes/kubernetes#91946</a>, <a href=""https://github.com/soltysh""><code>@soltysh</code></a>) [SIG CLI]</li>; <li>K8s.io/apimachinery - scheme.Convert() now uses only explicitly registered conversions - default reflection based conversion is no longer available. <code>+k8s:conversion-gen</code> tags can be used with the <code>k8s.io/code-generator</code> component to generate conversions. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/90018"">kubernetes/kubernetes#90018</a>, <a href=""https://github.com/wojtek-t""><code>@wojtek-t</code></a>) [SIG API Machinery, Apps and Testing]</li>; <li>Kube-proxy: add <code>--bind-address-hard-fail</code> flag to treat failure to bind to a port as fatal (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/89350"">kubernetes/kubernetes#89350</a>, <a href=""https://github.com/SataQiu""><code>@SataQiu</code></a>) [SIG Cluster Lifecycle and Network]</li>; <li>Kubebuilder validation tags are set on metav1.Condition for CRD generation (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/92660"">kubernetes/kubernetes#92660</a>, <a href=""https://github.com/damemi""><code>@damemi</code></a>) [SIG API Machinery]</li>; <li>Kubelet's --runonce option is now also available in Kubelet's config file as <code>runOnce</code>. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/89128"">kubernetes/kubernetes#89128</a>, <a href=""https://github.com/vincent178""><code>@vincent178</code></a>) [SIG Node]</li>; <li>Kubelet: add '--logging-format' flag to support structured logging (<a href=""https://github-redirect.d",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11462:9235,failure,failure,9235,https://hail.is,https://github.com/hail-is/hail/pull/11462,1,['failure'],['failure']
Availability,"erride>::run(const T&) [with R = simdpp::arch_avx2::uint16<8>; T = simdpp::arch_avx2::uint32<4>; unsigned int MaskCastOverride = 0]; libsimdpp-2.0-rc2/simdpp/core/cast.h:63:89: required from R simdpp::arch_avx2::bit_cast(const T&) [with R = simdpp::arch_avx2::uint16<8>; T = simdpp::arch_avx2::uint32<4>]; libsimdpp-2.0-rc2/simdpp/types/int16x8.h:133:36: required from simdpp::arch_avx2::uint16<8>& simdpp::arch_avx2::uint16<8>::operator=(const simdpp::arch_avx2::any_vec<16, V>&) [with V = simdpp::arch_avx2::uint32<4, simdpp::arch_avx2::expr_bit_and<simdpp::arch_avx2::uint32<4, simdpp::arch_avx2::uint16<8> >, simdpp::arch_avx2::uint32<4, simdpp::arch_avx2::uint32<4> > > >]; libsimdpp-2.0-rc2/simdpp/detail/insn/unzip_lo.h:80:24: required from here; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:40:13: error: void* memcpy(void*, const void*, size_t) copying an object of type class simdpp::arch_avx2::uint16<8> with private member simdpp::arch_avx2::uint16<8>::d_ from an array of const class simdpp::arch_avx2::uint32<4>; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/types.h:21,; from libsimdpp-2.0-rc2/simdpp/core/align.h:15,; from libsimdpp-2.0-rc2/simdpp/simd.h:22,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/types/int16x8.h:104:7: note: class simdpp::arch_avx2::uint16<8> declared here; class uint16<8, void> : public any_int16<8, uint16<8,void>> {; ^~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/simd.h:132,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl: In instantiation of R simdpp::arch_avx2::detail::cast_memcpy(const T&) [with R = simdpp::arch_avx2::uint16<16>; T = simdpp::arch_avx2::uint32<8>]:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3955:32601,error,error,32601,https://hail.is,https://github.com/hail-is/hail/issues/3955,1,['error'],['error']
Availability,"error for using ""importannotations table""",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/561:0,error,error,0,https://hail.is,https://github.com/hail-is/hail/issues/561,1,['error'],['error']
Availability,error if compiling PackDecoder on master,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3521:0,error,error,0,https://hail.is,https://github.com/hail-is/hail/pull/3521,1,['error'],['error']
Availability,error in annotation filtering for t2d vcf,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/120:0,error,error,0,https://hail.is,https://github.com/hail-is/hail/issues/120,1,['error'],['error']
Availability,error in linreg aggregator based on placement of '1',MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8349:0,error,error,0,https://hail.is,https://github.com/hail-is/hail/issues/8349,1,['error'],['error']
Availability,error message for TStruct.insert when inserting into missing struct with a required field,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2424:0,error,error,0,https://hail.is,https://github.com/hail-is/hail/pull/2424,1,['error'],['error']
Availability,error message from lambda in filter expr,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1623:0,error,error,0,https://hail.is,https://github.com/hail-is/hail/issues/1623,1,['error'],['error']
Availability,error message needs fixing,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3362:0,error,error,0,https://hail.is,https://github.com/hail-is/hail/issues/3362,1,['error'],['error']
Availability,error with textTableReader --impute with one-line file,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/750:0,error,error,0,https://hail.is,https://github.com/hail-is/hail/issues/750,1,['error'],['error']
Availability,"es portalocker, which is not installed.; aiosignal 1.3.1 requires frozenlist, which is not installed.; aiodns 2.0.0 requires pycares, which is not installed. ```; </details>. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **479/1000** <br/> **Why?** Has a fix available, CVSS 5.3 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-6050294](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-6050294) | `cryptography:` <br> `41.0.7 -> 42.0.0` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **616/1000** <br/> **Why?** Proof of Concept exploit, Has a fix available, CVSS 5.9 | Information Exposure <br/>[SNYK-PYTHON-CRYPTOGRAPHY-6126975](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-6126975) | `cryptography:` <br> `41.0.7 -> 42.0.0` <br> | No | Proof of Concept . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiIxNjVmNDVkMi00ZDM3LTRmNzAtOGU1OC00OGIxOGJhN",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14203:1501,avail,available,1501,https://hail.is,https://github.com/hail-is/hail/pull/14203,1,['avail'],['available']
Availability,"es some new features, bug fixes, and performance improvements. We recommend that all users upgrade to this version.</p>; <p>See the <a href=""https://pandas.pydata.org/pandas-docs/version/1.5.0/whatsnew/v1.5.0.html"">full whatsnew</a> for a list of all the changes. pandas 1.5.0 supports Python 3.8 and higher.</p>; <p>The release will be available on the defaults and conda-forge channels:</p>; <p><code>conda install -c conda-forge pandas</code></p>; <p>Or via PyPI:</p>; <p><code>python3 -m pip install --upgrade pandas</code></p>; <p>Please report any issues with the release on the <a href=""https://github.com/pandas-dev/pandas/issues"">pandas issue tracker</a>.</p>; <h2>Pandas 1.5.0rc0</h2>; <p>We are pleased to announce a release candidate for pandas 1.5.0. If all goes well, we'll release pandas 1.5.0 in about two weeks.</p>; <p>See the <a href=""https://pandas.pydata.org/pandas-docs/version/1.5/whatsnew/v1.5.0.html"">whatsnew</a> for a list of all the changes.</p>; <p>The release will be available on conda-forge and PyPI.</p>; <p>The release can be installed from PyPI</p>; <pre><code>python -m pip install --upgrade --pre pandas==1.5.0rc0; </code></pre>; <p>Or from conda-forge</p>; <pre><code>conda install -c conda-forge/label/pandas_rc pandas==1.5.0rc0; </code></pre>; <p>Please report any issues with the release candidate on the pandas issue tracker.</p>; <h2>Pandas 1.4.4</h2>; <p>This is a patch release in the 1.4.x series and includes some regression and bug fixes. We recommend that all users upgrade to this version.</p>; <p>See the <a href=""https://pandas.pydata.org/pandas-docs/version/1.4.4/whatsnew/v1.4.4.html"">full whatsnew</a> for a list of all the changes.</p>; <p>The release will be available on the defaults and conda-forge channels:</p>; <pre><code>conda install pandas; </code></pre>; <p>Or via PyPI:</p>; <pre><code>python3 -m pip install --upgrade pandas; </code></pre>; <p>Please report any issues with the release on the <a href=""https://github.com/pandas-dev/p",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12292:1286,avail,available,1286,https://hail.is,https://github.com/hail-is/hail/pull/12292,1,['avail'],['available']
Availability,"es were respected (<a href=""https://github-redirect.dependabot.com/psf/black/issues/3237"">#3237</a>)</li>; </ul>; <h3>Documentation</h3>; <ul>; <li>Recommend using BlackConnect in IntelliJ IDEs (<a href=""https://github-redirect.dependabot.com/psf/black/issues/3150"">#3150</a>)</li>; </ul>; <h3>Integrations</h3>; <ul>; <li>Vim plugin: prefix messages with <code>Black: </code> so it's clear they come from Black (<a href=""https://github-redirect.dependabot.com/psf/black/issues/3194"">#3194</a>)</li>; <li>Docker: changed to a /opt/venv installation + added to PATH to be available to non-root users (<a href=""https://github-redirect.dependabot.com/psf/black/issues/3202"">#3202</a>)</li>; </ul>; <h3>Output</h3>; <ul>; <li>Change from deprecated <code>asyncio.get_event_loop()</code> to create our event loop which removes DeprecationWarning (<a href=""https://github-redirect.dependabot.com/psf/black/issues/3164"">#3164</a>)</li>; <li>Remove logging from internal <code>blib2to3</code> library since it regularly emits error logs about failed caching that can and should be ignored (<a href=""https://github-redirect.dependabot.com/psf/black/issues/3193"">#3193</a>)</li>; </ul>; <h3>Parser</h3>; <ul>; <li>Type comments are now included in the AST equivalence check consistently so accidental deletion raises an error. Though type comments can't be tracked when running on PyPy 3.7 due to standard library limitations. (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2874"">#2874</a>)</li>; </ul>; <h3>Performance</h3>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/psf/black/blob/main/CHANGES.md"">black's changelog</a>.</em></p>; <blockquote>; <h2>22.8.0</h2>; <h3>Highlights</h3>; <ul>; <li>Python 3.11 is now supported, except for <em>blackd</em> as aiohttp does not support 3.11 as; of publishing (<a href=""https://github-redirect.dependabot.com/psf/black/issue",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12174:4476,error,error,4476,https://hail.is,https://github.com/hail-is/hail/pull/12174,1,['error'],['error']
Availability,"es. Notably, <code>Allele</code> became an interface instead of a concrete class. <code>SimpleAllele</code> may be used as a replacement if you have classes which previously subclassed allele.</p>; <p>New Plugin Infrastructure:; 6a60de7c2 Move API marker annotations into new annotation package. (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1558"">#1558</a>); 7ac95d5f7 Plugin framework and interfaces for versioned file format codecs (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1525"">#1525</a>); d40fe5412 Beta implementation of Bundles. (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1546"">#1546</a>)</p>; <p>CRAM; 489c4192d Support CRAM reference regions. (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1605"">#1605</a>); 22aec6782 Fix decoding of CRAM Scores read feature during normalization. (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1592"">#1592</a>); 6507249a4 Make the CRAM MD5 failure message more user friendly. (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1607"">#1607</a>); b5af659e6 Fix restoration of read base feature code. <a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1379"">#1379</a> (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1590"">#1590</a>); e63c34a92 Ignore TC, TN on CRAM read (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1578"">#1578</a>)</p>; <p>BAM/SAM; 1449dec45 Support loading of CSI from URLs/streams. <a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1507"">#1507</a> (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1595"">#1595</a>); a38c78d6c Add an option to SAMFileWriter to disable checking of ordering of rec (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1599"">#1599</a>); 51aa6ed2b Validate that SAM header tag keys are exactly 2 characters long (<a href",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12229:2420,failure,failure,2420,https://hail.is,https://github.com/hail-is/hail/pull/12229,2,['failure'],['failure']
Availability,"es/aiohttp/connector.py"", line 1032, in _create_direct_connection\n client_error=client_error,\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 975, in _wrap_create_connection\n raise client_error(req.connection_key, exc) from exc\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 10.128.0.11:5000 ssl:default [Connection refused]; INFO	2022-03-02 19:06:35,620	pool.py	create_instances:244	pool standard n_instances 1 {'pending': 0, 'active': 1, 'inactive': 0, 'deleted': 0} free_cores 0.0 live_free_cores 8.0 ready_cores 11.0; INFO	2022-03-02 19:06:35,620	pool.py	create_instances_from_ready_cores:206	creating 1 new instances; INFO	2022-03-02 19:06:35,848	pool.py	create_instances:244	pool highmem n_instances 1 {'pending': 0, 'active': 1, 'inactive': 0, 'deleted': 0} free_cores 4.0 live_free_cores 4.0 ready_cores 0.0; ERROR	2022-03-02 19:06:37,336	job.py	schedule_job:473	error while scheduling job (94, 1) on instance batch-worker-pr-11438-default-g6cibyji6520-standard-9xy2q	Traceback (most recent call last):\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 969, in _wrap_create_connection\n return await self._loop.create_connection(*args, **kwargs) # type: ignore # noqa\n File ""uvloop/loop.pyx"", line 1974, in create_connection\n File ""uvloop/loop.pyx"", line 1951, in uvloop.loop.Loop.create_connection\nConnectionRefusedError: [Errno 111] Connection refused\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n File ""/usr/local/lib/python3.7/dist-packages/batch/driver/job.py"", line 449, in schedule_job\n timeout=aiohttp.ClientTimeout(total=2),\n File ""/usr/local/lib/python3.7/dist-packages/hailtop/httpx.py"", line 113, in request_and_raise_for_status\n resp = await self.client_session._request(method, url, **kwargs)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/client.py"", line 521, in _request\n req, traces=traces, timeout=real_timeout\n F",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11451:9905,error,error,9905,https://hail.is,https://github.com/hail-is/hail/pull/11451,1,['error'],['error']
Availability,"ess=progress); /usr/local/lib/python3.8/dist-packages/hail/backend/service_backend.py:451: in _rpc; result_bytes = await retry_transient_errors(self._read_output, ir, iodir + '/out'); /usr/local/lib/python3.8/dist-packages/hailtop/utils/utils.py:781: in retry_transient_errors; return await retry_transient_errors_with_debug_string('', 0, f, *args, **kwargs); /usr/local/lib/python3.8/dist-packages/hailtop/utils/utils.py:794: in retry_transient_errors_with_debug_string; return await f(*args, **kwargs); _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . self = <hail.backend.service_backend.ServiceBackend object at 0x7f63d6b90bb0>; ir = <hail.ir.ir.TableWrite object at 0x7f63d4e70c70>; output_uri = 'hail-az://haildevtest/test/tmp/hail/FCIxoO1REfjctjXVpyHiF1/vwzzlTSQqo/out'. async def _read_output(self, ir: Optional[BaseIR], output_uri: str) -> bytes:; assert self._batch; ; try:; driver_output = await self._async_fs.open(output_uri); except FileNotFoundError as exc:; raise FatalError('Hail internal error. Please contact the Hail team and provide the following information.\n\n' + yamlx.dump({; 'service_backend_debug_info': self.debug_info(),; 'batch_debug_info': await self._batch.debug_info(); })) from exc; ; async with driver_output as outfile:; success = await read_bool(outfile); if success:; return await read_bytes(outfile); ; short_message = await read_str(outfile); expanded_message = await read_str(outfile); error_id = await read_int(outfile); ; reconstructed_error = fatal_error_from_java_error_triplet(short_message, expanded_message, error_id); if ir is None:; raise reconstructed_error; > raise reconstructed_error.maybe_user_error(ir); E hail.utils.java.FatalError: NativeIoException: readAddress(..) failed: Connection reset by peer; E ; E Java stack trace:; E io.netty.channel.unix.Errors$NativeIoException: readAddress(..) failed: Connection reset by peer; E 	at ; E ; E ; E ; E Hail version: 0.2.115-330031a5d973; E Error summary: NativeI",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12980:3603,error,error,3603,https://hail.is,https://github.com/hail-is/hail/issues/12980,1,['error'],['error']
Availability,"ession source mismatch, which may be due to `annotate_entries` being done separately from `_annotate_all` in the joiner for `index_entries` AST:; ```; def joiner(left: MatrixTable):; localized = Table(self._jvds.localizeEntries(row_uid)); src_cols_indexed = self.cols().add_index(col_uid); src_cols_indexed = src_cols_indexed.annotate(**{col_uid: hl.int32(src_cols_indexed[col_uid])}); left = left._annotate_all(row_exprs = {row_uid: localized.index(*row_exprs)[row_uid]},; col_exprs = {col_uid: src_cols_indexed.index(*col_exprs)[col_uid]}); return left.annotate_entries(**{uid: left[row_uid][left[col_uid]]}); ```. ### Hail version:; master; b1ac051d34bcc4c26fe9dea58aeac53038f2963e. ### What you did:. ```; mt = hl.utils.range_matrix_table(4, 4); mt2 = hl.utils.range_matrix_table(4, 4); mt2 = mt2.annotate_entries(x=mt2.row_idx + mt2.col_idx); mt.select_entries(a=mt2[mt.row_idx, mt.col_idx].x,; b=mt2[mt.row_idx, mt.col_idx].x)._force_count_rows(); ```. ### What went wrong (all error messages here, including the full java stack trace):. ```; Error; Traceback (most recent call last):; File ""/Users/jbloom/anaconda/envs/py36/lib/python3.6/unittest/case.py"", line 59, in testPartExecutor; yield; File ""/Users/jbloom/anaconda/envs/py36/lib/python3.6/unittest/case.py"", line 605, in run; testMethod(); File ""/Users/jbloom/hail/python/hail/tests/test_api.py"", line 1557, in test_force_bug; b=mt2[mt.row_idx, mt.col_idx].x)._force_count_rows(); File ""/Users/jbloom/hail/python/hail/matrixtable.py"", line 1171, in select_entries; return self._select_entries(""MatrixTable.select_entries"", hl.struct(**entry)); File ""/Users/jbloom/hail/python/hail/typecheck/check.py"", line 547, in wrapper; return f(*args_, **kwargs_); File ""/Users/jbloom/hail/python/hail/matrixtable.py"", line 2844, in _select_entries; base, cleanup = self._process_joins(s); File ""/Users/jbloom/hail/python/hail/matrixtable.py"", line 2503, in _process_joins; return process_joins(self, exprs, broadcast_f); File ""/Users/jbloom/hail/p",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3763:1164,error,error,1164,https://hail.is,https://github.com/hail-is/hail/issues/3763,1,['error'],['error']
Availability,"est version of jinja2. Downgrading jinja2 to 3.0.0 solves the problem, and it seems like other people have seen this too with the latest release of jinja2:. https://github.com/holoviz/panel/issues/3260. This may be transient and may be solved by bokeh / jinja2 folks but thought I'd let you know in case you hit this issue. ```; ../conda/envs/glow/lib/python3.7/site-packages/bokeh/core/templates.py:43: in <module>; from jinja2 import Environment, Markup, FileSystemLoader; E ImportError: cannot import name 'Markup' from 'jinja2' (/home/circleci/conda/envs/lib/python3.7/site-packages/jinja2/__init__.py); [error] java.lang.IllegalArgumentException: requirement failed: Python tests in Hail environment failed; [error] 	at scala.Predef$.require(Predef.scala:281); [error] 	at $1fb87e3247134917ca70$.$anonfun$pythonSettings$14(build.sbt:288); [error] 	at $1fb87e3247134917ca70$.$anonfun$pythonSettings$14$adapted(build.sbt:278); [error] 	at scala.Function1.$anonfun$compose$1(Function1.scala:49); [error] 	at sbt.internal.util.$tilde$greater.$anonfun$$u2219$1(TypeFunctions.scala:62); [error] 	at sbt.std.Transform$$anon$4.work(Transform.scala:67); [error] 	at sbt.Execute.$anonfun$submit$2(Execute.scala:280); [error] 	at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:19); [error] 	at sbt.Execute.work(Execute.scala:289); [error] 	at sbt.Execute.$anonfun$submit$1(Execute.scala:280); [error] 	at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178); [error] 	at sbt.CompletionService$$anon$2.call(CompletionService.scala:37); [error] 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); [error] 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); [error] 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); [error] 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); [error] 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); [err",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/11705:1198,error,error,1198,https://hail.is,https://github.com/hail-is/hail/issues/11705,1,['error'],['error']
Availability,"est='wald', covariates=[1.0]).describe(); ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); Cell In[9], line 4; 2 mt = hl.utils.range_matrix_table(2,2); 3 mt = mt.annotate_entries(prod = mt.row_idx * mt.col_idx); ----> 4 hl.logistic_regression_rows(y=mt.row_idx, x=mt.prod, test='wald', covariates=[1.0]).describe(). File <decorator-gen-1708>:2, in logistic_regression_rows(test, y, x, covariates, pass_through, max_iterations, tolerance). File ~/projects/hail/hail/python/hail/typecheck/check.py:587, in _make_dec.<locals>.wrapper(__original_func, *args, **kwargs); 584 @decorator; 585 def wrapper(__original_func: Callable[..., T], *args, **kwargs) -> T:; 586 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 587 return __original_func(*args_, **kwargs_). File ~/projects/hail/hail/python/hail/methods/statgen.py:921, in logistic_regression_rows(test, y, x, covariates, pass_through, max_iterations, tolerance); 918 if not y_is_list:; 919 result = result.transmute(**result.logistic_regression[0]); --> 921 return result.persist(). File <decorator-gen-1242>:2, in persist(self, storage_level). File ~/projects/hail/hail/python/hail/typecheck/check.py:587, in _make_dec.<locals>.wrapper(__original_func, *args, **kwargs); 584 @decorator; 585 def wrapper(__original_func: Callable[..., T], *args, **kwargs) -> T:; 586 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 587 return __original_func(*args_, **kwargs_). File ~/projects/hail/hail/python/hail/table.py:2112, in Table.persist(self, storage_level); 2076 @typecheck_method(storage_level=storage_level); 2077 def persist(self, storage_level='MEMORY_AND_DISK') -> 'Table':; 2078 """"""Persist this table in memory or on disk.; 2079 ; 2080 Examples; (...); 2110 Persisted table.; 2111 """"""; -> 2112 return Env.backend().persist(self). File ~/projects/hail/hail/python/hail/backend/backend.py",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13788:1236,toler,tolerance,1236,https://hail.is,https://github.com/hail-is/hail/issues/13788,1,['toler'],['tolerance']
Availability,estimate standard error for h2 in lmmreg,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1720:18,error,error,18,https://hail.is,https://github.com/hail-is/hail/pull/1720,1,['error'],['error']
Availability,"ethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:282); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:238); 	at java.lang.Thread.run(Thread.java:748). org.apache.spark.SparkException: Job aborted due to stage failure: Task 40 in stage 7.0 failed 20 times, most recent failure: Lost task 40.19 in stage 7.0 (TID 3171, seqr-loading-cluster-sw-z91p.c.seqr-project.internal, executor 14): is.hail.utils.HailException: cannot set missing field for required type +PCStruct{info:PCStruct{ALLELEID:PInt32}}; 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:9); 	at is.hail.utils.package$.fatal(package.scala:74); 	at is.hail.annotations.RegionValueBuilder.setMissing(RegionValueBuilder.scala:210); 	at is.hail.rvd.RVD$$anonfun$24$$anonfun$apply$17.apply(RVD.scala:974); 	at is.hail.rvd.RVD$$anonfun$24$$anonfun$apply$17.apply(RVD.scala:967); 	at is.hail.utils.FlipbookIterator$$anon$5.<init>(FlipbookIterator.scala:176); 	at is.hail.utils.FlipbookIterator.map(FlipbookIterator.scala:174); 	at is.hail.utils.FlipbookIterator.map(FlipbookIterator.scala:145); 	at is.hail.rvd.RVD$$anonfun$24.apply(RVD.scala:967); 	at is.hail.rvd.RVD$$anonfun$24.apply(RVD.scala:963); 	at is.hail.rvd.KeyedRVD$$anonfun$orderedLeftJoinDistinct$1.apply(KeyedRVD.scala:147); 	at is.hail.rvd.KeyedRVD$$anonfun$orderedLeftJoinDistinct$1.apply(KeyedRVD.scala:146); 	at is.hail.sparkextras.ContextRDD$$anonfun$czipPartitions$1$$anonfun$apply$19.apply(ContextRDD.scala:280); 	at is.hail.sparkextras.ContextRDD$$anonfun$czipPartitions$1$$anonfun$appl",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8469:51422,Error,ErrorHandling,51422,https://hail.is,https://github.com/hail-is/hail/issues/8469,1,['Error'],['ErrorHandling']
Availability,"ets/jinja/security/advisories/GHSA-h5c8-rqwp-cp95"">GHSA-h5c8-rqwp-cp95</a>. You are affected if you are using <code>xmlattr</code> and passing user input as attribute keys.</li>; <li>Changes: <a href=""https://jinja.palletsprojects.com/en/3.1.x/changes/#version-3-1-3"">https://jinja.palletsprojects.com/en/3.1.x/changes/#version-3-1-3</a></li>; <li>Milestone: <a href=""https://github.com/pallets/jinja/milestone/15?closed=1"">https://github.com/pallets/jinja/milestone/15?closed=1</a></li>; </ul>; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/pallets/jinja/blob/main/CHANGES.rst"">jinja2's changelog</a>.</em></p>; <blockquote>; <h2>Version 3.1.3</h2>; <p>Released 2024-01-10</p>; <ul>; <li>Fix compiler error when checking if required blocks in parent templates are; empty. :pr:<code>1858</code></li>; <li><code>xmlattr</code> filter does not allow keys with spaces. GHSA-h5c8-rqwp-cp95</li>; <li>Make error messages stemming from invalid nesting of <code>{% trans %}</code> blocks; more helpful. :pr:<code>1918</code></li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/pallets/jinja/commit/d9de4bb215fd1cc8092a410fb834c7c4060b1fc1""><code>d9de4bb</code></a> release version 3.1.3</li>; <li><a href=""https://github.com/pallets/jinja/commit/50124e16561f17f6c1ec85a692f6551418971cdc""><code>50124e1</code></a> skip test pypi</li>; <li><a href=""https://github.com/pallets/jinja/commit/9ea7222ef3f184480be0d0884e30ccfb4172b17b""><code>9ea7222</code></a> use trusted publishing</li>; <li><a href=""https://github.com/pallets/jinja/commit/da703f7aae36b1e88baaa20de334d7ff6378fdde""><code>da703f7</code></a> use trusted publishing</li>; <li><a href=""https://github.com/pallets/jinja/commit/bce174692547464512383ec40e0f8338b8811983""><code>bce1746</code></a> use trusted publishing</li>; <li><a href=""https://github.com/pallets/jinja/commit/7277d8068be593deab3555c7c14f974ada373a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14144:1332,error,error,1332,https://hail.is,https://github.com/hail-is/hail/pull/14144,3,['error'],['error']
Availability,"evel to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).; Running on Apache Spark version 2.2.3; SparkUI available at http://10.200.100.39:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.2.11-cf54f08305d1; LOGGING: writing to /home/unix/dking/hail-20190307-1908-0.2.11-cf54f08305d1.log; 2019-03-07 19:08:30 Hail: INFO: balding_nichols_model: generating genotypes for 3 populations, 100 samples, and 100 variants...; ^[[A; In [3]: t = hl.linear_regression_rows(x=mt.GT.n_alt_alleles(), y=mt.pop, covariates=[1]) ; [Stage 0:============================================> (6 + 1) / 8]2019-03-07 19:08:39 Hail: INFO: Coerced sorted dataset; 2019-03-07 19:08:40 Hail: INFO: linear_regression_rows: running on 100 samples for 1 response variable y,; with input variable x, and 1 additional covariate...; /broad/software/free/Linux/redhat_7_x86_64/pkgs/jdk1.8.0_181/bin/java: symbol lookup error: /tmp/jniloader1327638724610654731netlib-native_system-linux-x86_64.so: undefined symbol: cblas_dgemm; ERROR:root:Exception while sending command.; Traceback (most recent call last):; File ""/home/unix/dking/.conda/envs/hail/lib/python3.7/site-packages/py4j/java_gateway.py"", line 1159, in send_command; raise Py4JNetworkError(""Answer from Java side is empty""); py4j.protocol.Py4JNetworkError: Answer from Java side is empty. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/home/unix/dking/.conda/envs/hail/lib/python3.7/site-packages/py4j/java_gateway.py"", line 985, in send_command; response = connection.send_command(command); File ""/home/unix/dking/.conda/envs/hail/lib/python3.7/site-packages/py4j/java_gateway.py"", line 1164, in send_command; ""Error while receiving"", e, proto.ERROR_ON_RECEIVE); py4j.protocol.Py4JNetworkError: Error while receiving; ---------------------------------------------------------------------------; Py4JError Traceback",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5559:1513,error,error,1513,https://hail.is,https://github.com/hail-is/hail/issues/5559,1,['error'],['error']
Availability,"evel-5d0f74cef4f2-Spark-2.2.0.zip. ### What you did:; 1. Import VCF file into MatrixTable.; 2. Annotate VCF file with `output = hl.vep(input, 'vep.properties', csq=True)`.; 3. Attempt to view output with `output.rows().show()`. With `csq=False`, step 3 succeeds. ### What went wrong (all error messages here, including the full java stack trace):; ```; 2018-06-19 17:15:41 Hail: INFO: vep: annotated 2 variants; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/opt/hail/python/hail/typecheck/check.py"", line 547, in wrapper; return f(*args_, **kwargs_); File ""/opt/hail/python/hail/table.py"", line 1195, in show; print(self._show(n,width, truncate, types)); File ""/opt/hail/python/hail/table.py"", line 1198, in _show; return self._jt.showString(n, joption(truncate), types, width); File ""/opt/spark-2.2.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py"", line 1133, in __call__; File ""/opt/hail/python/hail/utils/java.py"", line 196, in deco; 'Error summary: %s' % (deepest, full, hail.__version__, deepest)) from None; hail.utils.java.FatalError: MatchError: [Ljava.lang.String;@7cd5fe91 (of class [Ljava.lang.String;). Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 11.0 failed 1 times, most recent failure: Lost task 0.0 in stage 11.0 (TID 11, localhost, executor driver): scala.MatchError: [Ljava.lang.String;@7cd5fe91 (of class [Ljava.lang.String;); 	at is.hail.annotations.RegionValueBuilder.addAnnotation(RegionValueBuilder.scala:489); 	at is.hail.methods.VEP$$anonfun$9$$anonfun$apply$4.apply(VEP.scala:350); 	at is.hail.methods.VEP$$anonfun$9$$anonfun$apply$4.apply(VEP.scala:345); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$16$$anon$3.next(OrderedRVD.scala:926); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$16$$anon$3.next(OrderedRVD.scala:920); 	at scala.colle",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3790:1109,Error,Error,1109,https://hail.is,https://github.com/hail-is/hail/issues/3790,1,['Error'],['Error']
Availability,"ex: in importing annotations from a dbNSFP table, using --impute imputes the Chromosome as an Int as opposed to a String, and brings up errors.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/520:136,error,errors,136,https://hail.is,https://github.com/hail-is/hail/issues/520,1,['error'],['errors']
Availability,"exit code 0 but actually a timeout. ```; {; ""batch_id"": 27671,; ""job_id"": 65,; ""name"": ""test_pipeline"",; ""state"": ""Error"",; ""exit_code"": 0,; ""duration"": 1211266,; ""msec_mcpu"": 1200805000,; ""cost"": ""$0.0072"",; ""status"": {; ""worker"": ""batch-worker-default-i68pm"",; ""batch_id"": 27671,; ""job_id"": 65,; ""attempt_id"": ""bpqqnj"",; ""user"": ""ci"",; ""state"": ""error"",; ""format_version"": 2,; ""container_statuses"": {; ""input"": {; ""name"": ""input"",; ""state"": ""succeeded"",; ""timing"": {; ""pulling"": {; ""start_time"": 1586188234696,; ""finish_time"": 1586188234698,; ""duration"": 2; },; ""creating"": {; ""start_time"": 1586188234699,; ""finish_time"": 1586188234766,; ""duration"": 67; },; ""runtime"": {; ""start_time"": 1586188234766,; ""finish_time"": 1586188245227,; ""duration"": 10461; },; ""starting"": {; ""start_time"": 1586188234767,; ""finish_time"": 1586188236190,; ""duration"": 1423; },; ""running"": {; ""start_time"": 1586188236190,; ""finish_time"": 1586188245227,; ""duration"": 9037; },; ""uploading_log"": {; ""start_time"": 1586188245231,; ""finish_time"": 1586188245276,; ""duration"": 45; },; ""deleting"": {; ""start_time"": 1586188245276,; ""finish_time"": 1586188245305,; ""duration"": 29; }; },; ""container_status"": {; ""state"": ""exited"",; ""started_at"": ""2020-04-06T15:50:36.182009912Z"",; ""finished_at"": ""2020-04-06T15:50:44.884808909Z"",; ""out_of_memory"": false,; ""exit_code"": 0; }; },; ""main"": {; ""name"": ""main"",; ""state"": ""error"",; ""timing"": {; ""pulling"": {; ""start_time"": 1586188245305,; ""finish_time"": 1586188245404,; ""duration"": 99; },; ""creating"": {; ""start_time"": 1586188245404,; ""finish_time"": 1586188245457,; ""duration"": 53; },; ""runtime"": {; ""start_time"": 1586188245458,; ""finish_time"": 1586189446263,; ""duration"": 1200805; },; ""starting"": {; ""start_time"": 1586188245458,; ""finish_time"": 1586188246261,; ""duration"": 803; },; ""running"": {; ""start_time"": 1586188246262,; ""finish_time"": 1586189446263,; ""duration"": 1200001; },; ""uploading_log"": {; ""start_time"": 1586189446266,; ""finish_time"": 1586189446350,; ""duration"": 84; },; ""deleting",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8473:115,Error,Error,115,https://hail.is,https://github.com/hail-is/hail/issues/8473,2,"['Error', 'error']","['Error', 'error']"
Availability,export_bgen bad error message,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8161:16,error,error,16,https://hail.is,https://github.com/hail-is/hail/issues/8161,1,['error'],['error']
Availability,expr.ir.CompileAndEvaluate$.apply(CompileAndEvaluate.scala:39); 	at is.hail.expr.ir.CompileAndEvaluate$.evaluateToJSON(CompileAndEvaluate.scala:14); 	at is.hail.expr.ir.CompileAndEvaluate.evaluateToJSON(CompileAndEvaluate.scala); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:282); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:238); 	at java.lang.Thread.run(Thread.java:745). is.hail.utils.HailException: foo: Error parsing row fields in row 0:; expected 5 fields but only 5 found.; File: foo; Line:; 7	75216143	75216143	C/T	+; offending line: 7	75216143	75216143	C/T	+; 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:20); 	at is.hail.utils.package$.fatal(package.scala:28); 	at is.hail.utils.Context.wrapException(Context.scala:19); 	at is.hail.utils.WithContext.wrap(Context.scala:43); 	at is.hail.io.LoadMatrix$$anonfun$16$$anonfun$apply$6.apply(LoadMatrix.scala:377); 	at is.hail.io.LoadMatrix$$anonfun$16$$anonfun$apply$6.apply(LoadMatrix.scala:375); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at scala.collection.Iterator$class.foreach(Iterator.scala:893); 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); 	at is.hail.rvd.RVD$$anonfun$count$2.apply(RVD.scala:575); 	at is.hail.rvd.RVD$$anonfun$count$2.apply(RVD.scala:573); 	at is.hail.sparkextras.ContextRDD$$anonfun$cmapPartitions$1$$anonfun$apply$28.app,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5718:10014,Error,Error,10014,https://hail.is,https://github.com/hail-is/hail/issues/5718,1,['Error'],['Error']
Availability,"extensions-for-python/issues/110"">#110</a> from AzureAD/persistence-factory</li>; <li><a href=""https://github.com/AzureAD/microsoft-authentication-extensions-for-python/commit/d0696aeb6f65168b1e0d405cd871b80bb101cd76""><code>d0696ae</code></a> Add build_encrypted_persistence() factory</li>; <li><a href=""https://github.com/AzureAD/microsoft-authentication-extensions-for-python/commit/289a94f694645c642ae67b2d5972d3f9fdadb928""><code>289a94f</code></a> Remove old classes that are deprecated for 2 years</li>; <li><a href=""https://github.com/AzureAD/microsoft-authentication-extensions-for-python/commit/fa1f45b556341b2c34e9bf63c06a5068571cd337""><code>fa1f45b</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/AzureAD/microsoft-authentication-extensions-for-python/issues/108"">#108</a> from AzureAD/actionable-encryption-exceptions</li>; <li><a href=""https://github.com/AzureAD/microsoft-authentication-extensions-for-python/commit/effe77842d25a8b093d18d9e33347f13e2ee094f""><code>effe778</code></a> Provide actionable messages for 2 dpapi errors</li>; <li><a href=""https://github.com/AzureAD/microsoft-authentication-extensions-for-python/commit/b674b6a07ca27b2c1b6f371040f035a546cfd468""><code>b674b6a</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/AzureAD/microsoft-authentication-extensions-for-python/issues/107"">#107</a> from AzureAD/file600</li>; <li>Additional commits viewable in <a href=""https://github.com/AzureAD/microsoft-authentication-extensions-for-python/compare/0.3.1...1.0.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=msal-extensions&package-manager=pip&previous-version=0.3.1&new-version=1.0.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11992:4065,error,errors,4065,https://hail.is,https://github.com/hail-is/hail/pull/11992,1,['error'],['errors']
Availability,"f const class simdpp::arch_avx2::float64<4>; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ~~~~~~~~^~~~~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/types.h:30,; from libsimdpp-2.0-rc2/simdpp/core/align.h:15,; from libsimdpp-2.0-rc2/simdpp/simd.h:22,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/types/float32x8.h:32:7: note: class simdpp::arch_avx2::float32<8> declared here; class float32<8, void> : public any_float32<8, float32<8,void>> {; ^~~~~~~~~~~~~~~~; In file included from libsimdpp-2.0-rc2/simdpp/simd.h:132,; from ibs.h:17,; from ibs.cpp:5:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl: In instantiation of R simdpp::arch_avx2::detail::cast_memcpy(const T&) [with R = simdpp::arch_avx2::uint16<16>; T = simdpp::arch_avx2::uint8<32>]:; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:120:30: required from static R simdpp::arch_avx2::detail::cast_wrapper<false, false, MaskCastOverride>::run(const T&) [with R = simdpp::arch_avx2::uint16<16>; T = simdpp::arch_avx2::uint8<32>; unsigned int MaskCastOverride = 0]; libsimdpp-2.0-rc2/simdpp/core/cast.h:63:89: required from R simdpp::arch_avx2::bit_cast(const T&) [with R = simdpp::arch_avx2::uint16<16>; T = simdpp::arch_avx2::uint8<32>]; libsimdpp-2.0-rc2/simdpp/types/int16x16.h:115:37: required from simdpp::arch_avx2::uint16<16>& simdpp::arch_avx2::uint16<16>::operator=(const simdpp::arch_avx2::any_vec<32, V>&) [with V = simdpp::arch_avx2::uint8<32, simdpp::arch_avx2::expr_empty>]; libsimdpp-2.0-rc2/simdpp/detail/insn/transpose.h:404:25: required from here; libsimdpp-2.0-rc2/simdpp/detail/cast.inl:40:13: error: void* memcpy(void*, const void*, size_t) copying an object of type class simdpp::arch_avx2::uint16<16> with private member simdpp::arch_avx2::uint16<16>::d_ from an array of const class simdpp::arch_avx2::uint8<32>; use assignment or copy-initialization instead [-Werror=class-memaccess]; ::memcpy(&r, &t, sizeof(R));; ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3955:50450,Mask,MaskCastOverride,50450,https://hail.is,https://github.com/hail-is/hail/issues/3955,2,['Mask'],['MaskCastOverride']
Availability,"f). /share/pkg/hail/2018-06-18/install/build/distributions/hail-python.zip/hail/matrixtable.py in write(self, output, overwrite, _codec_spec); 2111 """"""; 2112; -> 2113 self._jvds.write(output, overwrite, _codec_spec); 2114; 2115 def globals_table(self) -> Table:. /share/pkg/spark/2.2.0/install/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py in __call__(self, *args); 1131 answer = self.gateway_client.send_command(command); 1132 return_value = get_return_value(; -> 1133 answer, self.gateway_client, self.target_id, self.name); 1134; 1135 for temp_arg in temp_args:. /share/pkg/hail/2018-06-18/install/build/distributions/hail-python.zip/hail/utils/java.py in deco(*args, **kwargs); 194 raise FatalError('%s\n\nJava stack trace:\n%s\n'; 195 'Hail version: %s\n'; --> 196 'Error summary: %s' % (deepest, full, hail.__version__, deepest)) from None; 197 except pyspark.sql.utils.CapturedException as e:; 198 raise FatalError('%s\n\nJava stack trace:\n%s\n'. FatalError: SparkException: Job 2 cancelled because SparkContext was shut down. Java stack trace:; org.apache.spark.SparkException: Job 2 cancelled because SparkContext was shut down; at org.apache.spark.scheduler.DAGScheduler$$anonfun$cleanUpAfterSchedulerStop$1.apply(DAGScheduler.scala:820); at org.apache.spark.scheduler.DAGScheduler$$anonfun$cleanUpAfterSchedulerStop$1.apply(DAGScheduler.scala:818); at scala.collection.mutable.HashSet.foreach(HashSet.scala:78); at org.apache.spark.scheduler.DAGScheduler.cleanUpAfterSchedulerStop(DAGScheduler.scala:818); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onStop(DAGScheduler.scala:1732); at org.apache.spark.util.EventLoop.stop(EventLoop.scala:83); at org.apache.spark.scheduler.DAGScheduler.stop(DAGScheduler.scala:1651); at org.apache.spark.SparkContext$$anonfun$stop$8.apply$mcV$sp(SparkContext.scala:1921); at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1317); at org.apache.spark.SparkContext.stop(SparkContext.scala:1920); at org.apache.spark.SparkC",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4755:3156,down,down,3156,https://hail.is,https://github.com/hail-is/hail/issues/4755,1,['down'],['down']
Availability,"f, ir, timed=False):; --> 108 result = json.loads(Env.hc()._jhc.backend().executeJSON(self._to_java_ir(ir))); 109 value = ir.typ._from_json(result['value']); 110 timings = result['timings']. /usr/lib/spark/python/lib/py4j-src.zip/py4j/java_gateway.py in __call__(self, *args); 1255 answer = self.gateway_client.send_command(command); 1256 return_value = get_return_value(; -> 1257 answer, self.gateway_client, self.target_id, self.name); 1258 ; 1259 for temp_arg in temp_args:. /usr/local/lib/python3.6/site-packages/hail/utils/java.py in deco(*args, **kwargs); 223 raise FatalError('%s\n\nJava stack trace:\n%s\n'; 224 'Hail version: %s\n'; --> 225 'Error summary: %s' % (deepest, full, hail.__version__, deepest)) from None; 226 except pyspark.sql.utils.CapturedException as e:; 227 raise FatalError('%s\n\nJava stack trace:\n%s\n'. FatalError: NoSuchElementException: key not found: GRCh37. ```. ### Traces No. 1: . ```java ; Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 15 in stage 16.0 failed 4 times, most recent failure: Lost task 15.3 in stage 16.0 (TID 178, ip-172-31-1-20.ec2.internal, executor 4): org.json4s.package$MappingException: unknown error; 	at org.json4s.Extraction$.extract(Extraction.scala:43); 	at org.json4s.ExtractableJsonAstNode.extract(ExtractableJsonAstNode.scala:21); 	at is.hail.io.index.IndexReader$.readMetadata(IndexReader.scala:65); 	at is.hail.io.index.IndexReader.<init>(IndexReader.scala:90); 	at is.hail.io.index.IndexReaderBuilder$$anonfun$withDecoders$1.apply(IndexReader.scala:50); 	at is.hail.io.index.IndexReaderBuilder$$anonfun$withDecoders$1.apply(IndexReader.scala:50); 	at is.hail.HailContext$$anon$3$$anonfun$20.apply(HailContext.scala:879); 	at is.hail.HailContext$$anon$3$$anonfun$20.apply(HailContext.scala:877); 	at scala.Option.map(Option.scala:146); 	at is.hail.HailContext$$anon$3.compute(HailContext.scala:877); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); 	at org.apache.s",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7044:5177,failure,failure,5177,https://hail.is,https://github.com/hail-is/hail/issues/7044,1,['failure'],['failure']
Availability,"f01ce""><code>3e4c14b</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pytest-dev/pytest/issues/9751"">#9751</a> from fabianegli/main</li>; <li><a href=""https://github.com/pytest-dev/pytest/commit/7f924b13a50a05b8dc894418fa7faf779201e129""><code>7f924b1</code></a> Fix typo in deprecation documentation</li>; <li><a href=""https://github.com/pytest-dev/pytest/commit/4a8f8ada431974f2837260af3ed36299fd382814""><code>4a8f8ad</code></a> build(deps): Bump django from 4.0.2 to 4.0.3 in /testing/plugins_integration ...</li>; <li><a href=""https://github.com/pytest-dev/pytest/commit/c0fd2d883940f1292d5e8234803beaacd08315e6""><code>c0fd2d8</code></a> build(deps): Bump pytest-asyncio from 0.18.1 to 0.18.2 in /testing/plugins_in...</li>; <li><a href=""https://github.com/pytest-dev/pytest/commit/843e01824c257c3190792a9df430289c3abe349d""><code>843e018</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pytest-dev/pytest/issues/9732"">#9732</a> from nicoddemus/9730-toml-failure</li>; <li><a href=""https://github.com/pytest-dev/pytest/commit/bc43d66b47b917d43a22e0c703ecfe4eea342263""><code>bc43d66</code></a> [automated] Update plugin list (<a href=""https://github-redirect.dependabot.com/pytest-dev/pytest/issues/9733"">#9733</a>)</li>; <li><a href=""https://github.com/pytest-dev/pytest/commit/e38d1cac489e42f4bdbecbb50f9f25dc9c36c19f""><code>e38d1ca</code></a> Improve error message for malformed pyproject.toml files</li>; <li>Additional commits viewable in <a href=""https://github.com/pytest-dev/pytest/compare/6.2.5...7.1.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pytest&package-manager=pip&previous-version=6.2.5&new-version=7.1.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11571:6144,failure,failure,6144,https://hail.is,https://github.com/hail-is/hail/pull/11571,2,['failure'],['failure']
Availability,f41a81995c53a28e375c26b.jar.jar:?]; 	at is.hail.relocated.org.json4s.jackson.JsonMethods$.parse(JsonMethods.scala:71) ~[gs:__hail-query-daaf463550_jars_4c60fddb171a52c21f41a81995c53a28e375c26b.jar.jar:?]; 	at is.hail.backend.service.ServiceBackendAPI$.$anonfun$main$5(ServiceBackend.scala:467) ~[gs:__hail-query-daaf463550_jars_4c60fddb171a52c21f41a81995c53a28e375c26b.jar.jar:?]; 	at is.hail.utils.package$.using(package.scala:673) ~[gs:__hail-query-daaf463550_jars_4c60fddb171a52c21f41a81995c53a28e375c26b.jar.jar:?]; 	at is.hail.backend.service.ServiceBackendAPI$.main(ServiceBackend.scala:467) ~[gs:__hail-query-daaf463550_jars_4c60fddb171a52c21f41a81995c53a28e375c26b.jar.jar:?]; 	at is.hail.backend.service.Main$.main(Main.scala:10) ~[gs:__hail-query-daaf463550_jars_4c60fddb171a52c21f41a81995c53a28e375c26b.jar.jar:?]; 	at is.hail.backend.service.Main.main(Main.scala) ~[gs:__hail-query-daaf463550_jars_4c60fddb171a52c21f41a81995c53a28e375c26b.jar.jar:?]; 	... 12 more; 2024-11-05 02:43:37.787 JVMEntryway: ERROR: Exception encountered in QoB cancel thread.; org.newsclub.net.unix.SocketClosedException: Not open; 	at org.newsclub.net.unix.AFCore.validFdOrException(AFCore.java:90) ~[jvm-entryway.jar:?]; 	at org.newsclub.net.unix.AFSocketImpl$AFInputStreamImpl.read(AFSocketImpl.java:510) ~[jvm-entryway.jar:?]; 	at java.io.DataInputStream.readInt(DataInputStream.java:393) ~[?:?]; 	at is.hail.JVMEntryway$2.run(JVMEntryway.java:136) [jvm-entryway.jar:?]; 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]; 	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]; 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]; 	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]; 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]; 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]; 	at java.lang.Thread.run(Thread.java:829) [?:?]; ```,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14749:6848,ERROR,ERROR,6848,https://hail.is,https://github.com/hail-is/hail/issues/14749,1,['ERROR'],['ERROR']
Availability,"f; priority: 500000; priorityClassName: user; restartPolicy: Never; schedulerName: default-scheduler; securityContext: {}; serviceAccount: batch-output-pod; serviceAccountName: batch-output-pod; terminationGracePeriodSeconds: 30; tolerations:; - key: preemptible; value: ""true""; - effect: NoExecute; key: node.kubernetes.io/not-ready; operator: Exists; tolerationSeconds: 300; - effect: NoExecute; key: node.kubernetes.io/unreachable; operator: Exists; tolerationSeconds: 300; volumes:; - name: gsa-key; secret:; defaultMode: 420; secretName: wang-gsa-key; - name: batch-gsa-key; secret:; defaultMode: 420; secretName: batch-gsa-key; - name: batch-12728-job-287-742170; persistentVolumeClaim:; claimName: batch-12728-job-287-742170; - name: batch-output-pod-token-8pkmz; secret:; defaultMode: 420; secretName: batch-output-pod-token-8pkmz; status:; conditions:; - lastProbeTime: null; lastTransitionTime: 2019-09-05T19:15:42Z; message: 'containers with incomplete status: [setup]'; reason: ContainersNotInitialized; status: ""False""; type: Initialized; - lastProbeTime: null; lastTransitionTime: 2019-09-05T19:15:42Z; message: 'containers with unready status: [main cleanup keep-alive]'; reason: ContainersNotReady; status: ""False""; type: Ready; - lastProbeTime: null; lastTransitionTime: 2019-09-05T19:15:42Z; message: 'containers with unready status: [main cleanup keep-alive]'; reason: ContainersNotReady; status: ""False""; type: ContainersReady; - lastProbeTime: null; lastTransitionTime: 2019-09-05T19:15:42Z; status: ""True""; type: PodScheduled; containerStatuses:; - image: gcr.io/hail-vdc/batch:s32fqwbuz8nv; imageID: """"; lastState: {}; name: cleanup; ready: false; restartCount: 0; state:; waiting:; reason: PodInitializing; - image: gcr.io/hail-vdc/batch:s32fqwbuz8nv; imageID: """"; lastState: {}; name: keep-alive; ready: false; restartCount: 0; state:; waiting:; reason: PodInitializing; - image: gcr.io/broad-ctsa/benchmark_wang:latest; imageID: """"; lastState: {}; name: main; ready: false; r",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7016:9856,toler,tolerationSeconds,9856,https://hail.is,https://github.com/hail-is/hail/issues/7016,3,"['alive', 'toler']","['alive', 'tolerationSeconds']"
Availability,"f=""https://github-redirect.dependabot.com/docker/docker-py/pull/3056"">docker/docker-py#3056</a></li>; </ul>; <h2>New Contributors</h2>; <ul>; <li><a href=""https://github.com/ArchiMoebius""><code>@ArchiMoebius</code></a> made their first contribution in <a href=""https://github-redirect.dependabot.com/docker/docker-py/pull/3031"">docker/docker-py#3031</a></li>; <li><a href=""https://github.com/nicks""><code>@nicks</code></a> made their first contribution in <a href=""https://github-redirect.dependabot.com/docker/docker-py/pull/3056"">docker/docker-py#3056</a></li>; </ul>; <p><strong>Full Changelog</strong>: <a href=""https://github.com/docker/docker-py/compare/6.0.0...6.0.1"">https://github.com/docker/docker-py/compare/6.0.0...6.0.1</a></p>; <h2>6.0.0</h2>; <h3> Upgrade Notes</h3>; <ul>; <li>Minimum supported Python version is 3.7+</li>; <li>When installing with pip, the <code>docker[tls]</code> extra is deprecated and a no-op,; use <code>docker</code> for same functionality (TLS support is always available now)</li>; <li>Native Python SSH client (used by default / <code>use_ssh_client=False</code>) will now; reject unknown host keys with <code>paramiko.ssh_exception.SSHException</code></li>; <li>Short IDs are now 12 characters instead of 10 characters (same as Docker CLI)</li>; <li>Version metadata is now exposed as <code>__version__</code></li>; </ul>; <h3> Features</h3>; <ul>; <li>Python 3.10 support</li>; <li>Automatically negotiate most secure TLS version</li>; <li>Add <code>platform</code> (e.g. <code>linux/amd64</code>, <code>darwin/arm64</code>) to container create &amp; run</li>; <li>Add support for <code>GlobalJob</code> and <code>ReplicatedJobs</code> for Swarm</li>; <li>Add <code>remove()</code> method on <code>Image</code></li>; <li>Add <code>force</code> param to <code>disable()</code> on <code>Plugin</code></li>; </ul>; <h3> Bugfixes</h3>; <ul>; <li>Fix install issues on Windows related to <code>pywin32</code></li>; <li>Do not accept unknown SSH host keys ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12475:2720,avail,available,2720,https://hail.is,https://github.com/hail-is/hail/pull/12475,1,['avail'],['available']
Availability,"f=""https://github-redirect.dependabot.com/prometheus/client_python/issues/747"">#747</a>; [BUGFIX] Remove trailing slashes from pushgateway URLS. <a href=""https://github-redirect.dependabot.com/prometheus/client_python/issues/722"">#722</a>; [BUGFIX] Catch non-integer bucket/count values. <a href=""https://github-redirect.dependabot.com/prometheus/client_python/issues/726"">#726</a></p>; <h2>0.12.0 / 2021-10-29</h2>; <p>[FEATURE] Exemplar support (excludes multiprocess) <a href=""https://github-redirect.dependabot.com/prometheus/client_python/issues/669"">#669</a>; [ENHANCEMENT] Add support for Python 3.10 <a href=""https://github-redirect.dependabot.com/prometheus/client_python/issues/706"">#706</a>; [ENHANCEMENT] Restricted Registry will handle metrics added after restricting <a href=""https://github-redirect.dependabot.com/prometheus/client_python/issues/675"">#675</a>, <a href=""https://github-redirect.dependabot.com/prometheus/client_python/issues/680"">#680</a><br />; [ENHANCEMENT] Raise a more helpful error if a metric is not observable <a href=""https://github-redirect.dependabot.com/prometheus/client_python/issues/666"">#666</a>; [BUGFIX] Fix instance_ip_grouping_key not working on MacOS <a href=""https://github-redirect.dependabot.com/prometheus/client_python/issues/687"">#687</a>; [BUGFIX] Fix assertion error from favicion.ico with Python 2.7 <a href=""https://github-redirect.dependabot.com/prometheus/client_python/issues/715"">#715</a></p>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/prometheus/client_python/commit/a234283a853238dc73fa22651532590330fd72a1""><code>a234283</code></a> Release 0.13.1</li>; <li><a href=""https://github.com/prometheus/client_python/commit/557d123b349f3881cd6475a29ff4c79088a85a26""><code>557d123</code></a> Relax type constraints Timestamp</li>; <li><a href=""https://github.com/prometheus/client_python/commit/b44b63e59b168c6a8498ca31ddcce3ea5e46dcdc""><code>b44b63e</code></a> Declare <code>reg",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11515:2492,error,error,2492,https://hail.is,https://github.com/hail-is/hail/pull/11515,1,['error'],['error']
Availability,"f=""https://github.com/aio-libs/aioredis-py/commit/7f65c4ccb0e954c17f2a3e1ecc665c62e4a1aaeb""><code>7f65c4c</code></a> Remove <strong>del</strong> from Redis (Fixes <a href=""https://github-redirect.dependabot.com/aio-libs/aioredis-py/issues/1115"">#1115</a>) (<a href=""https://github-redirect.dependabot.com/aio-libs/aioredis-py/issues/1227"">#1227</a>)</li>; <li><a href=""https://github.com/aio-libs/aioredis-py/commit/5062740974e493c390fb8db33982f97d6e08df2d""><code>5062740</code></a> Fix typing on blpop (etc) timeout argument (<a href=""https://github-redirect.dependabot.com/aio-libs/aioredis-py/issues/1224"">#1224</a>)</li>; <li><a href=""https://github.com/aio-libs/aioredis-py/commit/dbdd0add63f986f2ed2d56c9736303d133add23c""><code>dbdd0ad</code></a> fix socket.error raises (<a href=""https://github-redirect.dependabot.com/aio-libs/aioredis-py/issues/1129"">#1129</a>)</li>; <li><a href=""https://github.com/aio-libs/aioredis-py/commit/2ba15fb6947fa2347d401ba436e362ad62ed38ff""><code>2ba15fb</code></a> Fix buffer is closed error when using PythonParser class (<a href=""https://github-redirect.dependabot.com/aio-libs/aioredis-py/issues/1213"">#1213</a>)</li>; <li><a href=""https://github.com/aio-libs/aioredis-py/commit/0aa06df10b9531f4ba734ec7567f8621c00e65e9""><code>0aa06df</code></a> Fix typing on evalsha keys_and_args argument (<a href=""https://github-redirect.dependabot.com/aio-libs/aioredis-py/issues/1215"">#1215</a>)</li>; <li><a href=""https://github.com/aio-libs/aioredis-py/commit/33b2dbd0a40ac148e6a36ba2fc7ab5d438a9a71d""><code>33b2dbd</code></a> [pre-commit.ci] pre-commit autoupdate (<a href=""https://github-redirect.dependabot.com/aio-libs/aioredis-py/issues/1201"">#1201</a>)</li>; <li><a href=""https://github.com/aio-libs/aioredis-py/commit/a708bd14b1a8bec0a1f3d469bf5384eb2726b5fa""><code>a708bd1</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/aio-libs/aioredis-py/issues/1162"">#1162</a> from aio-libs/dependabot/pip/flake8-4.0.1</li>; <li><a href=""htt",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11569:5262,error,error,5262,https://hail.is,https://github.com/hail-is/hail/pull/11569,1,['error'],['error']
Availability,"f=""https://github.com/jupyter/jupyter_client/compare/v7.3.5...760a7835d8b20a9daea3737759b1751d5e55dad8"">Full Changelog</a>)</p>; <p>This release is primarily focused on improving <code>asyncio</code> support, while aiming to have minimal API changes.</p>; <h3>Enhancements made</h3>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/jupyter/jupyter_client/blob/main/CHANGELOG.md"">jupyter-client's changelog</a>.</em></p>; <blockquote>; <h2>8.0.2</h2>; <p>(<a href=""https://github.com/jupyter/jupyter_client/compare/v8.0.1...717d36edcd9ce595f727d8b5a27e270c2a6e2c46"">Full Changelog</a>)</p>; <h3>Bugs fixed</h3>; <ul>; <li>Add papermill downstream check and fix kernel client replies <a href=""https://github-redirect.dependabot.com/jupyter/jupyter_client/pull/925"">#925</a> (<a href=""https://github.com/blink1073""><code>@blink1073</code></a>)</li>; </ul>; <h3>Maintenance and upkeep improvements</h3>; <ul>; <li>Adopt more ruff rules <a href=""https://github-redirect.dependabot.com/jupyter/jupyter_client/pull/924"">#924</a> (<a href=""https://github.com/blink1073""><code>@blink1073</code></a>)</li>; <li>Prefer print in kernelspecapp <a href=""https://github-redirect.dependabot.com/jupyter/jupyter_client/pull/923"">#923</a> (<a href=""https://github.com/blink1073""><code>@blink1073</code></a>)</li>; </ul>; <h3>Contributors to this release</h3>; <p>(<a href=""https://github.com/jupyter/jupyter_client/graphs/contributors?from=2023-01-26&amp;to=2023-01-30&amp;type=c"">GitHub contributors page for this release</a>)</p>; <p><a href=""https://github.com/search?q=repo%3Ajupyter%2Fjupyter_client+involves%3Ablink1073+updated%3A2023-01-26..2023-01-30&amp;type=Issues""><code>@blink1073</code></a></p>; <!-- raw HTML omitted -->; <h2>8.0.1</h2>; <p>(<a href=""https://github.com/jupyter/jupyter_client/compare/v8.0.0...dc6113c360e05122430b8e130374e9f4e4b701d7"">Full Changelog</a>)</p>; <h3>B",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12656:3366,Mainten,Maintenance,3366,https://hail.is,https://github.com/hail-is/hail/pull/12656,1,['Mainten'],['Maintenance']
Availability,"f=""https://github.com/pre-commit/pre-commit/commit/b22b313e4b042867bf0835f0e842a7281f6faf91""><code>b22b313</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2158"">#2158</a> from mblayman/lua</li>; <li><a href=""https://github.com/pre-commit/pre-commit/commit/54331dca6fcfff1a06c43defb29b395898c65ce8""><code>54331dc</code></a> get lua version from luarocks itself</li>; <li><a href=""https://github.com/pre-commit/pre-commit/commit/3f8be7400d523fafe8c6d2d0fa4fb1560e7ae21d""><code>3f8be74</code></a> Add naive and untested version of Lua language support.</li>; <li><a href=""https://github.com/pre-commit/pre-commit/commit/7a305e5d9ab5e94f2d93599008d20e38f5842ac9""><code>7a305e5</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2210"">#2210</a> from pre-commit/git-version</li>; <li><a href=""https://github.com/pre-commit/pre-commit/commit/c05f58b776603dc2a5222f035c2dc058426497de""><code>c05f58b</code></a> add git version to error output</li>; <li><a href=""https://github.com/pre-commit/pre-commit/commit/12b482345b4eee0153ebabbd3911614ac48d6687""><code>12b4823</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2207"">#2207</a> from xhochy/mamba</li>; <li><a href=""https://github.com/pre-commit/pre-commit/commit/83aa65c4291b8a1a134cd024fbe071323f400c83""><code>83aa65c</code></a> Add mamba support to <code>language: conda</code></li>; <li><a href=""https://github.com/pre-commit/pre-commit/commit/657e76ba77ef4ae5b6e2ebe5f06cacdbf22a19a2""><code>657e76b</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2205"">#2205</a> from jalessio/jamie/upgrade-rbenv</li>; <li><a href=""https://github.com/pre-commit/pre-commit/commit/428dc6e46eb68065bfc115419927949cdd056811""><code>428dc6e</code></a> Update rbenv / ruby-build versions</li>; <li>Additional commits viewable in <a href=""http",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11460:13347,error,error,13347,https://hail.is,https://github.com/hail-is/hail/pull/11460,2,['error'],['error']
Availability,"fc428ad</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/9822"">#9822</a> from jakobandersen/intersphinx_role</li>; <li><a href=""https://github.com/sphinx-doc/sphinx/commit/5d595ec0c4294f45f3138c4c581b84c39cae5e29""><code>5d595ec</code></a> intersphinx role, simplify role_name check</li>; <li><a href=""https://github.com/sphinx-doc/sphinx/commit/6ee0ecbe40ab8a3251538409cf35ffcc04765bfa""><code>6ee0ecb</code></a> intersphinx role, simplify role name matching</li>; <li><a href=""https://github.com/sphinx-doc/sphinx/commit/3bf8bcd6e151a78b0dd003a3e76ff4c65566b6e6""><code>3bf8bcd</code></a> intersphinx role, update docs</li>; <li><a href=""https://github.com/sphinx-doc/sphinx/commit/c11b109d591a74f87de071ec4782ac3ab782ea38""><code>c11b109</code></a> intersphinx role: :external+inv:<strong>: instead of :external:inv+</strong>:</li>; <li><a href=""https://github.com/sphinx-doc/sphinx/commit/9589a2bc0531598cdd69f260f2f2c2dbc5852d6e""><code>9589a2b</code></a> intersphinx role, remove redundant method</li>; <li><a href=""https://github.com/sphinx-doc/sphinx/commit/941db550f02d76ee2b93300584ac85dc599d21e6""><code>941db55</code></a> intersphinx role, fix flake8 warnings</li>; <li><a href=""https://github.com/sphinx-doc/sphinx/commit/9a3f2b85421948c98647b10106c1bbb5ff1b0628""><code>9a3f2b8</code></a> intersphinx role, CHANGES</li>; <li><a href=""https://github.com/sphinx-doc/sphinx/commit/540d76035cc6bbf7ee18d0eb9bf63e4c3651d1f9""><code>540d760</code></a> intersphinx role, documentation</li>; <li>Additional commits viewable in <a href=""https://github.com/sphinx-doc/sphinx/compare/v3.5.4...v4.4.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=sphinx&package-manager=pip&previous-version=3.5.4&new-version=4.4.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-comp",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11522:6597,redundant,redundant,6597,https://hail.is,https://github.com/hail-is/hail/pull/11522,2,['redundant'],['redundant']
Availability,"figuration option (<code>python-cell-magics</code>) to format cells with custom magics in Jupyter Notebooks (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2744"">#2744</a>)</li>; <li>Allow setting custom cache directory on all platforms with environment variable <code>BLACK_CACHE_DIR</code> (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2739"">#2739</a>).</li>; <li>Enable Python 3.10+ by default, without any extra need to specify -<code>-target-version=py310</code>. (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2758"">#2758</a>)</li>; <li>Make passing <code>SRC</code> or <code>--code</code> mandatory and mutually exclusive (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2804"">#2804</a>)</li>; </ul>; <h3>Output</h3>; <ul>; <li>Improve error message for invalid regular expression (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2678"">#2678</a>)</li>; <li>Improve error message when parsing fails during AST safety check by embedding the underlying SyntaxError (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2693"">#2693</a>)</li>; <li>No longer color diff headers white as it's unreadable in light themed terminals (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2691"">#2691</a>)</li>; <li>Text coloring added in the final statistics (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2712"">#2712</a>)</li>; <li>Verbose mode also now describes how a project root was discovered and which paths will be formatted. (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2526"">#2526</a>)</li>; </ul>; <h3>Packaging</h3>; <ul>; <li>All upper version bounds on dependencies have been removed (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2718"">#2718</a>)</li>; <li><code>typing-extensions</code> is no longer a required dependency in Python 3.10+ (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2772"">#2772",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11468:5697,error,error,5697,https://hail.is,https://github.com/hail-is/hail/pull/11468,1,['error'],['error']
Availability,"file. ```; # hexdump /tmp/bar; 0000000 ef bb bf 73 61 6d 70 6c 65 5f 69 64 0a 66 6f 6f; 0000010 0a ; 0000011; # ipython; import hail asPython 3.7.3 (default, Mar 27 2019, 09:23:15) ; Type 'copyright', 'credits' or 'license' for more information; IPython 7.5.0 -- An enhanced Interactive Python. Type '?' for help. In [1]: import hail as hl ; hl.import_; In [2]: t = hl.import_table('/tmp/bar') ; ...: t.describe() ; ...: t = t.key_by('sample_id') ; Initializing Spark and Hail with default parameters...; using hail jar at /usr/local/lib/python3.7/site-packages/hail/hail-all-spark.jar; 19/06/13 14:08:11 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).; Running on Apache Spark version 2.4.1; SparkUI available at http://wm06b-953.broadinstitute.org:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.2.14-5cb00c115421; LOGGING: writing to /Users/dking/projects/hail/hail/hail-20190613-1408-0.2.14-5cb00c115421.log; 2019-06-13 14:08:15 Hail: INFO: Reading table with no type imputation; Loading column '?sample_id' as type 'str' (type not specified). ----------------------------------------; Global fields:; None; ----------------------------------------; Row fields:; 'sample_id': str ; ----------------------------------------; Key: []; ----------------------------------------; ---------------------------------------------------------------------------; LookupError Traceback (most recent call last); <ipython-input-2-6b119cf7ec41> in <module>; 1 t = hl.import_table('/tmp/bar'); 2 t.describe(); ----> 3 t = t.key_by('sample_id'). </usr/local/lib/python3.7/site-packages/decorator.py:decorator-gen-958> in key_by(self, *keys, **named_keys). /usr/local/lib/python3.7",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6342:1539,avail,available,1539,https://hail.is,https://github.com/hail-is/hail/issues/6342,1,['avail'],['available']
Availability,filteralleles needs to error when running on hardcalls,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1283:23,error,error,23,https://hail.is,https://github.com/hail-is/hail/issues/1283,1,['error'],['error']
Availability,"filteralleles, or more specifically, the subset and downcode processes do not particularly work on hardcalls (it finds the next most likely genotypes in the PLs, which are nonexistent). One possible workaround would be to force users to `filter_altered_genotypes=True` but this will probably require some new code. But otherwise, this should definitely throw an error.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1283:52,down,downcode,52,https://hail.is,https://github.com/hail-is/hail/issues/1283,2,"['down', 'error']","['downcode', 'error']"
Availability,fix CallStatsCombiner error message when it gets an allele > nAlleles,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4379:22,error,error,22,https://hail.is,https://github.com/hail-is/hail/issues/4379,1,['error'],['error']
Availability,fix VCF format parser missing array element error message,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5169:44,error,error,44,https://hail.is,https://github.com/hail-is/hail/issues/5169,1,['error'],['error']
